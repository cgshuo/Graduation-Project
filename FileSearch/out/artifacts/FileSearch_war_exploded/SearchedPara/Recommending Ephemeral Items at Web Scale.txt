 We describe an innovative and scalable recommendation sys-tem successfully deployed at eBay. To build recommenders for long-tail marketplaces requires projection of volatile items into a persistent space of latent products. We first present a generative clustering model for collections of unstructured, heterogeneous, and ephemeral item data, under the assump-tion that items are generated from latent products. An item is represented as a vector of independently and distinctly distributed variables, while a latent product is character-ized as a vector of probability distributions, respectively. The probability distributions are chosen as natural stochas-tic models for different types of data. The learning objective is to maximize the total intra-cluster coherence measured by the sum of log likelihoods of items under such a generative process. In the space of latent products, robust recommen-dations can then be derived using na  X   X ve Bayes for ranking, from historical transactional data. Item-based recommenda-tions are achieved by inferring latent products from unseen items. In particular, we develop a probabilistic scoring func-tion of recommended items, which takes into account item-product membership, product purchase probability, and the important auction-end-time factor. With the holistic prob-abilistic measure of a prospective item purchase, one can further maximize the expected revenue and the more sub-jective user satisfaction as well. We evaluated the latent product clustering and recommendation ranking models us-ing real-world e-commerce data from eBay, in both forms of offline simulation and online A/B testing. In the recent production launch, our system yielded 3-5 folds improve-ment over the existing production system in click-through, purchase-through and gross merchandising value; thus now driving 100% related recommendation traffic with billions of items at eBay. We believe that this work provides a prac-tical yet principled framework for recommendation in the domains with affluent user self-input data.
This work was mainly conducted when the authors were affiliated with eBay Inc.
 H.3.3 [ Information Search and Retrieval ]: Clustering, Information filtering.
 Algorithms, Experimentation, Performance Recommender systems, collaborative filtering, generative mod-els, clustering, Bayesian methods, evaluation
Recommendation for online marketplaces such as eBay raises several unique challenges. First, a majority of items are ad hoc listings not covered by any predefined product or catalog taxonomy. This can be partially attributed to the nature of the inventory under study, which features a very long tail of item types and, not uncommon,  X  X ne-of-a-kind X  inventory. Besides, to maintain such a catalog so to capture a highly dynamic and diverse inventory can be a daunting task. We approach this challenge by deliberately reducing volatile and noisy item data to persistent and ro-bust latent products [6]. The latent products shall discover statistical structure underlying the item data, and may not necessarily have bearings on physical products. The projec-tion space should be ultimately optimized for the effective-ness of recommendation or other information retrieval and filtering tasks.

Second, the historical transactional data at the user level is very sparse. For example, over a three-month period of time at eBay, each buyer on average made 17.31 bids and won 5.63 of them. The publicized Netflix user-movie rat-ing data, on the other hand, has 208.33 ratings on average for each user [3], i.e., more than 30-fold sparser for pur-chases and 10-fold sparser for bids with the eBay transac-tional data. User-item ratings are not available in eBay X  X  dataset 1 , nor this kind of ratings are appropriate or cali-brated preference measure for such a diverse inventory. We argue that historical purchases are at least no worse than rating-based collaborative filtering (CF) data, since pur-chases reflect monetary commitments. However, given the sparsity of historical transactions or bid attempts, the state-of-the-art CF approaches, devised for rating-based datasets,
There does exist a feedback score from a buyer towards a seller with regard to an item purchase, but this cannot be used as user-item rating due to the significant role played by the seller. such as latent factor models [17] may not be directly appli-cable or work as well. From the data perspective, we need to incorporate more implicit preference data such as search queries and results, item views, personalized saved searches and tracked items, bids and purchases. From the method perspective, we apply na  X   X ve Bayes to recognize co-preference or sequential-preference patterns [7]. The compactness of na  X   X ve Bayes is especially desired for such a sparse and noisy dataset, and it provides a probabilistic preference score for each candidate item. Recommendations can then be made by ranking and filtering candidates.
Deriving robust product concepts from item descriptions is an important first step for subsequent delivery of auction suggestions. Since most items are unique, typical modeling methods cannot be applied to user behavior since there is no link between user behaviors with the same or similar items. Items are defined by about 10 title words, possibly attribute values, a leaf category, price, and otherwise by behavioral data such as user views, bids and purchases. Our goal is to map each item ID to a more general product ID, i.e., to derive a map f : I  X  P , where I is the space of possible item features, and P is the set of product labels. so the problem is a clustering problem. In many similar cases such as movie and book recommendation, ad targeting or even text clustering, a projection map g would be applied from I to a lower dimensional space before clustering is applied. However, that approach is not suitable here for several rea-sons. Instead we apply model-based clustering directly to the item data such as a bag-of-words feature vector for title text. The reasons are as follows:
First of all, title descriptions are extremely sparse having only about 10 terms on average in the case of eBay items. By contrast, movie data, texts for document clustering, or user history for targeting have hundreds or thousands of events. These events are highly correlated (e.g., users have similar ratings of similar movies) and projection serves to normalize dependencies (i.e., SVD creates a spherical Gaussian distri-bution in the low-dimensional space) and, most importantly, to robustly estimate the coordinates in the projection space. For such estimate to be accurate, the number of parameters in a typical record should be much larger than the dimension of the projection space. In the examples above, a good ratio of data parameters to dimension is 10:1. If the projection space dimension is too high, there is little or no value to the projection step. The variance is normalized, but this could equally well be achieved by normalizing the metric used in the original space. However, there is no  X  X leaning X  of the data accomplished in such a projection. In practice, perfor-mance is very poor as the projection dimension approaches the number of item parameters in all the examples above.
More importantly, the statistical dependencies between title words in eBay items are very different from the other examples above. In the first place, they are already quite in-dependent. Users consciously try to describe the important features of their item in relatively few words. In many cases, words are genuine attributes or product category names. What dependencies remain are highly localized and product specific. For instance, the term  X  X ed X  has high co-occurrence with products that come in a red version (e.g., iPods), but zero co-occurrence with products that do not come in red (e.g., iPhones). All other attributes have similar properties. Thus dependencies are entirely local in the product space, and it does not make sense to look for a global map from the title word space to a latent space. This differs from the other examples above where there are global dependen-cies based on user preference or document topic. Finally, by using a generative clustering method, we can accurately model these dependencies in the original parameter space. This opportunity is lost after a global projection.
In this section we formally describe the generative clus-tering model for learning latent products. An item x is the basic unit of transaction, embodied by a set of un-structured and heterogeneous data including auction title, description, attribute name-value pairs, price, among oth-ers. The item data can be categorized into three types: (1) binary variables for term occurrences in textual data such as auction title and description, i.e., b = ( b 1 ,b where V is the size of vocabulary; (2) categorical variables for indexed attribute values such as brand and color, i.e., c = ( c 1 ,c 2 ,...,c U ) where U is the number of attributes; and (3) continuous variables for numerical data such as price, i.e., g = ( g 1 ,g 2 ,...,g S ) where S is the dimension of numer-ical feature space. A dense representation of an item thus becomes a 3-tuple of vectors: x = ( b , c , g ).

A latent product z is the persistent concept underlying items. We use a binomial distribution Binom( p ) to model each binary variable, a multinomial distribution Mult(  X  ) for each categorical variable, and a Gaussian distribution N (  X , X  2 ) for each continuous variable, possibly after log transformation. Notice that we only allow one trial for each binomial and multinomial process per item, i.e., Bernoulli and categorical distributions, respectively. The one-trial specialization is appropriate for the item data, since sell-ers tend to use concise words for listing items and repeated terms are less relevant. A categorical attribute X  X  values are mutually exclusive, hence an item has exactly one value. We further assume the variance  X  2 of a continuous vari-able is a constant w.r.t. a collection of items. A latent product is then represented as a vector of Bernoulli success probabilities, multinomial parameters, and Gaussian means: z = ( p 1 ,p 2 ,...,p V , X  1 , X  2 ,..., X  U , X  1 , X  2 ,..., X  longingness of an item to a latent product is stochastically modeled as the following generative process: 1. For binary variables: b v  X  Binom( p v ) ,  X  v  X  X  1 ,...,V } ; 2. For categorical variables: c u  X  Mult(  X  u ) ,  X  u  X  X  1 ,...,U } ; 3. For continuous variables: g s  X  X  (  X  s , X  2 ) ,  X  s  X  X  1 ,...,S } . Given a latent product z k , the likelihood of an item x i where  X  ku is the multinomial probability corresponding to the outcome c iu . The log likelihood is then:
Given a set of items I = { x i } n i =1 , we wish to learn a smaller set of latent products P = { z k } m k =1 and derive as-signments of items x i to latent products z k with maximum likelihood, such that the total intra-product log likelihood of the item data I is maximized. where  X  ik is an indicator variable for item-product member-ship.

The latent product vectors ( z 1 ,..., z m ) are the only model parameters to be estimated, while  X  ik can be viewed as hid-den variables. The hard product membership assumption directly yields the maximum likelihood estimate (MLE) of  X  ik with z k  X  k fixed. Since we use binomial, multinomial and Gaussian distributions to model item generation, the MLE of the latent product parameters z k are simply given by the means of the item random vectors belonging to that product. We thus derive the following EM algorithm:
In a standard EM algorithm, the E-step would compute the expectation of hidden variables. In our formulation how-ever, the expected value of  X  ik is deterministically given by its MLE. This approach is referred to as a variant of the generalized EM, or essentially an alternating coordinate as-cent [20]. The model so far is quite similar to k-means clus-tering. However, there are significant differences in distance metric and cluster assignment. As we show later in the experiments, our probabilistic distance outperforms tradi-tional metrics such as Euclidean and cosine similarity. More importantly, the probabilistic item-product belongingness allows us to derive a probabilistic item preference score for recommendation purpose.

The initialization of ( z 1 ,..., z m ) is obtained by first uni-formly randomly sampling m groups of items and then per-forming a M-step assuming that these groups represent m latent products, respectively. To address the sparsity and possible noise of such initialization, we further smooth the local parameters z k by the background probabilities q , i.e., the Jelinek-Mercer method [16]: where the background probabilities q are obtained by per-forming a M-step assuming that the entire set of items are generated from a single global latent product, and  X  is the smoothing factor with a relatively small value, e.g.,  X  = 0 . 01. It is also desired to perform smoothing after each iteration of EM for the same reason of sparsity, especially at the early stage. A Bayesian smoothing method would impose a con-jugate prior for z k [23]. We choose the interpolation form mainly for computational efficiency, as elaborated in Sec-tion 3.2.

It is important to note that item clustering is an inter-mediate step towards recommendation learning, its primary goal is a mild entropy reduction or data cleaning. Our choice of the hard item-product membership has serious advantages in production in space and time. The current production im-plementation writes belonging latent products to the item search indexing system; hence allowing for two latent prod-ucts for each item would double the precious production storage, as well as the item scoring and ranking time.
The inferential task given a model trained is to assign an unseen item x 0 to a derived latent product with maximum log likelihood: which is identical to a final E-step. The same calculation (E-step) is performed iteratively during clustering, and domi-nates the run-time of training with a complexity of O ( nmV ) for a na  X   X ve dense implementation. Therefore the key to the performance is an efficient method to evaluate Eq. (2). For clarity, we will describe a method for the Bernoulli terms only, which are very numerous and sparse. Since the method involves only association of indices, the generalization to multinomial and Gaussian scores should be obvious. There should be only a few multinomial and Gaussian parameters and they are assumed to be dense. The simplified score after smoothing becomes: Let us define p a = (1  X   X  ) p kv +  X q v and p b =  X q v , and further split the right-hand side of the above according to whether p kv is zero or not: which can be rewritten by pre-computing dense b iv = 0 terms as default: and we can push this idea one step further by assuming p kv = 0 in a densified pre-computation: We notice that of these four right-hand side terms, only the first depends on both the cluster k and the item i . It com-prises only terms which are shared between both the item, and the nonzero components of p kv . By pre-computing the item-independent sparse vectors a kv = (log ( p a )  X  log (1  X  p log ( p b ) + log (1  X  p b )) only at nonzeros of p kv , we can eval-uate this first sum with a sparse matrix product P v a kv The second and third right-hand side sums have been made independent of the item data, and so can be computed only once for each cluster, where the third term is in fact con-stant across all clusters. The fourth sum depends on the item data and p b . But p b depends only on the background probability, and not cluster data. There is no need to com-pute this term when deciding how to assign an item since it is fixed for that item. Therefore if we define then to assign an item to a cluster, we only need compute the partial score: while the complete score including cluster-independent terms is: where f v = log ( p b )  X  log (1  X  p b ).

On typical data (cluster size around 20, several million items), there is only one overlapping term between a random item and a random cluster. With a straightforward sparse matrix multiplication implementation, one item-cluster com-parison takes about 4 nanoseconds on a 3GHz single proces-sor machine. For existing items which should account for the majority of inventory, we perform an offline batch final E-step to build an item-to-product (I2P) map, which is a sparse matrix for latent products lookup from query items. Since recommendations are derived at the latent product level, we also need to store a product-to-item (P2I) map, where P2I = I2P &gt; , to lookup items from recommended la-tent products.

It is important to emphasize that the efficient inference de-scribed above generalizes to standard clustering and other problem domains with high-dimensional sparse data [12], such as language models for information retrieval [23]. A similar decomposition as Eq. (11) can be readily derived for k-means with squared Euclidean distance by pre-computing instance-independent and non-linear (quadratic) terms, while in our case log terms are pre-computed. The complexity of E-step now reduces to O ( nm  X  nnz x ), where nnz x is the average number of nonzeros per item. Given a typical vo-cabulary size of 100K and item size of 10, the speed-up is 10K times.
The number of latent products m , as in other cluster-ing methods, is an input parameter to the algorithm. The choice of m depends on domain requirements, particularly the desired granularity level of latent products. Accurate recommendations require fine-grained latent products, but too fine granularity may suffer noisy and unreliable recom-mendations. This is yet another instance of precision-recall trade-off, and the optimization objective in our case is to maximize the effectiveness of recommendations.

We wish to learn a relatively large number of latent prod-ucts with high intra-product uniformity to make precise rec-ommendations, while keeping the size of each product cluster above a certain threshold to maintain an acceptable recall level. Hence we use the following heuristics for cluster man-agement: 1. Given n input item examples, initialize m = b n/d c cen-2. After each EM iteration, specifically the M-step, dis-3. After every even EM iteration, break clusters with a
Mixture models have been widely used for clustering, where each cluster is represented as a parametric distribution, e.g., a mixture of multinomial for document clustering [21]. Un-der a mixture model for learning latent products, the likeli-hood of an item x i is: where an item x i is modeled as a convex combination of m latent product distributions p ( x i | z k ) with mixture pro-portions p ( z k ). The mixture model assumes soft product membership of items, i.e., an item-level mixture; and model parameters can be estimated by using the standard EM al-gorithm. The mixture approach is more statistically sound for semantically rich data such as documents and images, but less so for the item datasets that we are investigating for recommendation. An ordinary document often exhibits multiple topics, but an item is physically associated with exactly one product. In other words, soft membership is not well-motivated for item-to-product projection. Instead, we want to impose very sparse per-item latent product mixture proportions.

Latent variable models, such as pLSI [14], LDA [4] and recent adaptation for recommendation [1, 2, 15, 22], allow even greater model expressiveness, i.e., a word-level topic mixture. However, these models do not serve the specific purpose of learning latent products, that is, a mild entropy reduction (e.g., 10-fold) with high within-cluster coherence (i.e., intra-product likelihood) in order to subsequently de-rive robust recommendations.

Finally, we shall note that our method is a heterogeneous generalization of the multivariate Bernoulli model originated from text classification [19, 24]. As we showed in Section 3, the same centroid-based generative approach shall work for any heterogeneous combination of parametric distributions, as long as the MLE of model parameters can be obtained as the expectation of feature vectors.
Now that we have inferential machinery mapping volatile items to persistent latent products, we can perform recom-mendation by using the following na  X   X ve Bayes for ranking: where x denotes a contextual or historical transaction of a latent product which will be used as the input to the rec-ommender, e.g., a buyer X  X  last purchase; and y indexes the recommended product for next purchase.
Given the objective of a recommender is to maximize sales, it is desired to compute p ( x,y ) in Eq. (17) as the joint probability of purchasing both x and y . However, pur-chase data is extremely sparse 2 , which makes the estimate noisy. Thus we smooth the pure purchase probability with other less sparse behaviors yet indicative of user preference, including clicks (i.e., clicking on a search result and landing to a view item page) and bids. Furthermore, it is unrealis-tic to assume a user is exposed to the entire inventory, so a normalized preference score should be made conditional on views (i.e., viewing search results). Finally, even the click or bid co-occurrence data can still be sparse, thus we fur-ther smooth the co-preference probability with a unigram popularity score dependent only on the candidate product y using Laplace smoothing.

Formally, let C be an m  X  m matrix of co-occurrences, where a subscript pair index the co-occurring latent products and a superscript pair encode the behavioral types respec-tively. For example, C vb yx is the number of users who bid on x and viewed y . We consider four types of co-occurrence pat-terns: (1) bid-bid (bb), (2) purchase-purchase (pp), (3) click-bid (cb), and (4) view-bid (vb). The product-to-product preference probability is: where (  X  1 , X  2 , X  3 ) are coefficients for a convex combination of the three co-preference patterns,  X  is the smoothing factor,
Over a two-month period in one of the most popular cate-gories at eBay (Clothing, Shoes &amp; Accessories), above 50% of users only made one item purchase. and p ( y ) is the baseline popularity of y : where (  X  1 , X  2 , X  3 ) are mixture weights and  X  is a small value for numerical protection, e.g.,  X  = 1 . 0  X  10  X  8 . Here C with a single subscript denotes a unigram count (for one latent product only) of a behavioral type encoded in a superscript. For instance, C v y is the number of users who viewed y .
To compute the product-to-product co-preference prob-ability in Eq. (18) mainly involves counting co-occurring events, which is the computational bottleneck in offline train-ing. Of the four co-occurrence matrices in Eq. (18), the view-bid matrix C vb is the least sparse. We now use C vb an example to discuss several important design issues for a sound and scalable implementation.

It turns out that one can leverage efficient sparse matrix operations to obtain the co-occurrence matrices. Since we count events in terms of users, we first form product-user count matrices, one for each relevant event type, by scan-ning the transactional data once and performing the infer-ence in Eq. (7). Let D v be an m  X  l product-user matrix of view counts, D b be a bid counts matrix with the same dimensions, and both use sparse representation. The co-occurrence matrix C vb is then obtained by a sparse matrix multiplication D v D &gt; b . Furthermore, one only needs to count C vb entries when at least one of the three numerator terms C bb , C pp , and C cb has a nonzero corresponding entry. A dominant user behavioral conversion flow is: view  X  click  X  bid  X  purchase, and view events are typically an order of magnitude denser than non-view events; thus to leverage the data sparsity further we only count C vb entries when the corresponding C cb count is nonzero:
The time period over which the co-occurrence matrices are defined (counted) is important, since the association be-tween co-occurring events becomes noisier as they are spaced farther apart. Thus we only count co-occurring events if they happened within a relatively short overlapping time window. On the other hand, if the length of an overlapping window gets too short, there will be very few co-occurrences collected. We use a t  X  w sliding window to count co-occurrences, which works as follows. Along the time axis, we increment w -day transactional data into a t  X  w -day sliding window, and over which perform one iteration of counting. The t  X  w -day sliding window thus moves forward by w -day per iteration until the entire training period is exhausted. This design asserts that one pair of events co-occurred within a small w -day window casts t times as many counts as were the pair happened t  X  w -day apart. Our experiments showed that a 3  X  7-day sliding window gives optimal recommenda-tions, as illustrated in Figure 1.

A typical user first issues a search query, then views the search results, and potentially clicks some result landing to an item page. Since this voluntary user conversion course can be considered as a Markov chain and starts with click-through, i.e., view  X  click, it is critical to model the click-through process in a principled manner. It is known that the presentational position or rank of a result link in a search result page has significant impact on click-through rate (CTR) [5, 11]. We adopt the position-bias model de-veloped in [8], which imposes a positional prior to normal-ize (multiply) view count. A bottom position will have a lower prior probability than those higher up in a search re-sult page, where a positional prior can be interpreted as the probability of a user physically viewing the link. Thus a result link showing at a lower position will only have a frac-tion of one normalized view count. From the click-through perspective, a user clicking lower-position item links effec-tively casts more preference votes (to Eq. (18)) than were these links shown at higher positions. We use an empirical positional prior distribution as follows, Here  X  is a positive real number implying the rate at which a prior decreases as the positional rank r moves down in a search result page,  X  is the lowest rank the prior covers, and Z 1 = P  X  r =1 r  X   X  is a normalizing constant. A default eBay search result page shows 50 item links and almost all clicks are from the first page, hence it is not only practically suf-ficient but also computationally efficient to define the prior over a discrete and finite range [1 , 50]. When  X  = 0 . 5, there is a 7-fold a priori difference in CTR between the top and bottom positions, which fits well to the eBay search click-through data and is aligned with other similar domains such as sponsored search [8].

Counting events in number of unique users provides one level of robot filtering mechanism, since each user can only vote once w.r.t. one co-occurrence. In addition, we apply another level of data-driven robot filtering by removing users whose total number of activities during a w -day window is above a certain threshold, e.g., thres 7-day = 2000.
In online recommendation, a triggering event is an item transaction (e.g., previous purchase), one then retrieves a candidate set of items and ranks them to recommend top N items. More formally, let i be a seed item and j be a candidate item. We wish to have a probabilistic scoring function to perform recommendation: Recall that both the latent product clustering and product-level recommendation models are derived in a statistically rigorous manner, and hence provide probabilistic measures. The item-to-item recommendation score can be factorized as the following Markov chain: where x and y denote input and recommended latent prod-ucts, respectively. Under the hard membership assumption, marginalizing over latent variables x,y reduces to the be-terministic. From here onwards, for simplicity we will short-cut x ( i ) ,y ( j ) to x,y as the latent products corresponding to the items i,j respectively.

Additionally, there is one important factor to be incor-porated in the scoring function, that is, the auction end time. User actions burst into the end time (within hours) of an auction; and the experience from search suggests that auction end time is one of the dominant factors in ranking items. We thus impose a time prior distribution biased to-wards ending-soon auction items. The final item-level scor-ing function becomes: ence in hours from recommendation serving time to auction end time of item j . The product-to-product score p ( y | x ) has been derived as Eq. (18) in Section 4.1, we now focus on the item-product membership score p ( j | y ) and the time-dependent factor p ( X  h ( j )).

The inference step in Eq. (7) gives the MLE of latent prod-uct assignment, but even the likelihood cannot be directly used as membership score in Eq. (24) for the purpose of ranking items. The reason is that item likelihood is not well calibrated across latent products, and we typically need to retrieve multiple y  X  X  for a given x to surface a best candi-date set of j  X  X . For example, one latent product y 1 is more catalog-like and its items usually can be described in very few terms (some technological items). Another latent prod-uct y 2 is less structured and its items need more terms to be embodied (some clothing items). The item likelihoods in y are then naturally higher than the ones in y 2 ; but this does not necessarily mean y 1 items are more coherent, nor should they be ranked higher. Within-product item log likelihood empirically appears Gaussian, from which we can transform to a standard Gaussian N (0 , 1) to make it comparable across products. The calibrated item-product membership score is then: where  X  ` (  X | y ) is the mean item log likelihood for a latent prod-uct, and  X  is the standard deviation. Since  X  serves as a normalization factor, we use a constant informed by data 3
For one major category  X  X lothing, Shoes &amp; Accessories X , the item log likelihood variable has mean  X  40 . 5, standard deviation 20 . 6, median  X  38 . 5, and mode  X  26 . 0. e.g.,  X  = 20, for all y  X  X . The normalization constant Z needed to preserve the probabilistic interpretation of p ( j | y ).
The auction-end-time factor p ( X  h ( j )) can be interpreted as a priori purchase probability w.r.t. remaining auction time and made independent of any specific item content. We assume the time prior follows an exponential distribu-tion over discrete hourly time windows traversing backwards from auction end time to the current time; and hence intro-duce a smoothed exponential decay function as the time-dependent score: Here  X  h ( j ) = b ( t end  X  t now ) / 3600 c , and  X  is a positive decay constant. A two-day half-life gives  X  = log (2) / 47. The smoothing factor  X  provides a minimum score; e.g.,  X  = 0 . 5 enforces any items beyond half-life will still get a 0 . 5 time-dependent score. It turns out that this time score lower-bounding provides an important mechanism to mix up time-sensitive items (auction items) and time-insensitive items (fixed-price items). The normalization constant Z 3 makes p ( X  h ( j )) a distribution.

One fundamental advantage of the item ranking model derived so far stems from viewing the user conversion se-quence as a stochastic process, and hence estimating the purchase probability as in Eq. (24). Ranking recommenda-tions directly in purchase probability shall optimize number of purchases, but this statistical framework can be easily ex-tended to maximize other business metrics as well, such as revenue and user satisfaction. User purchase is a Bernoulli process with a success probability estimated by Eq. (24), one can then multiply some utility function f ( u ) by the purchase probability to obtain an estimate of the expected utility: where u j is the unit price of the target item j , which is given for fixed-price items. For active auction items, the price can be estimated as the smoothed average price of closed items belonging to the same latent product: where u j is the winning bid amount of item j belonging to product y ,  X  is a smoothing constant, and u 0 gives a default price. To optimize revenue, the utility function is essentially the pricing model or listing fee structure: where ( a 1 ,a 2 ,a 3 ) are the listing fees for three consecutive price intervals: [0 ,b 1 ], ( b 1 ,b 2 ], and ( b 2 The current values at eBay are: ( b 1 ,b 2 ) = ($25 , $1000) and ( a or satisfaction is more subjective, and we use log-price as a surrogate for simplicity:
Finally, we apply several post-ranking filtering rules in compliance with domain-specific requirements: (1) items are active as of the time of delivery; (2) items with iden-tical titles are de-duplicated; (3) current prices are below a threshold (e.g., $5000 for clothing category) to avoid recom-mending excessively expensive items; and (4) items are from sellers with a trust score above a threshold (e.g., 99.99% pos-itive feedbacks).
Both the latent product clustering and the item ranking models as a whole shall be evaluated by the quality of rec-ommendation. Online A/B testing would evaluate how the new models perform against the current production system in a live environment, but requires a full-fledged produc-tion deployment and a fraction of revenue-sensitive live traf-fic. Offline evaluation thus becomes particularly valuable for a closed-loop exploration before going live [9]. We con-ducted both offline and online evaluation, where offline eval-uation guides us towards a sensible objective function and online testing reports metrics of business significance, in-cluding CTR (click-through rate), BTR (bid-through rate), PTR (purchase-through rate), and GMB (gross merchandis-ing bought).
A common way to evaluate recommendation models is yet to be established. It is not fully satisfactory to use general estimations such as test data log likelihood and perplex-ity, since these metrics fail to emphasize the very important yet small head portion of view recall. Other metrics used in rating-based recommendation such as RMSE (root mean squared error) [18] is not suitable for click-through data in our case. We adapt for the recommendation problem the evaluation method established in other similar domains such as ad targeting [8, 10].

The quality of prediction is measured by two metrics: (1) the area under the click-view ROC curve (AUC), and (2) the relative CTR lift over a baseline predictor at a certain recall level of view. A click-view ROC curve plots the click recall vs. view recall, from the testing examples ranked in descend-ing order of predicted score. The higher the AUC, the more accurate the predictor; and a random predictor would give an AUC of 0.5 (a diagonal ROC). Since view recall equals to click recall by random guess, each point on the ROC curve readily gives the relative CTR lift (click recall / view recall) over a baseline random predictor 4 . It is important to empha-size that in the context of recommendation, positive feed-backs include not only clicks, but also (and more so) bids, purchases, and even revenue. Therefore we use click and CTR in the above evaluation metrics in a generalized sense, which can also refer to other positive feedbacks.

We consider recommendation based on a contextual or his-torical transaction, e.g., a user who has purchased i would also likely purchase j . We first use the item and transac-tional data over a training period to learn the latent prod-uct and recommendation models; thus deriving a scoring function of co-preference item pairs ( i,j ) (Eq. (24) or (27)), where the temporal order of ( i,j ) is deliberately ignored for better coverage. For the transactional data over a testing pe-riod, we form a global event stream of sequential-preference
The lift interpretation, besides easiness of implementation, motivates the use of click-view ROC for click-through data instead of traditional ROC. A traditional ROC plots true positive (TP) rate vs. false positive (FP) rate. For the click-view ROC in our case, we use (TP+FP) or all examples as the x -axis. item pairs, where the temporal order is respected for faithful evaluation. We then apply the scoring function to score and rank test item pairs. Finally, we compare the ranked list against the ground-truth feedbacks to compute ROC curve and lift. The evaluation method using log-price utility for purchase feedback is formalized in Algorithm 1.
 Algorithm 1 : Offline evaluation
We conducted experiments for one major category:  X  X loth-ing, Shoes &amp; Accessories X , which is representative of the un-structuredness, volatility, sparsity, and large scale charac-teristics of the domain. We used three-month worth of item and transactional data for training, and the following week for testing. For the recommendation modeling, the train-ing data contains approximately 50M items, 1500M search events, and 600M down-streaming transactions. We sam-pled 50% search log for counting view-related co-occurrences. For the iterative clustering, the item data was down-sampled to 4M biased towards active ones (with at least one bid). After 10 EM iterations, 118,865 clusters converged with an average item log likelihood  X  14 . 68. With the learned latent products, we then performed an inference step to assign all items including those only seen in testing data to their MLE latent products, which yielded an average item log likelihood  X  29 . 47. All our experiments were run on a single node with 2  X  Quad-Core 3.2GHz 64-bit processors and 8GB RAM, using a multi-core parallel implementation. It took about 4 hours to learn clusters, and 6 hours to assign 50M items. So one item assignment takes less than half a millisecond, which is sufficient for online real-time performance. The recommendation learning (offline for p ( y | x )) used 14 hours. Our implementation achieved above 200 Mflops throughout, and hence highly efficient and scalable [8].

We experimented 10 variations in 2 scoring functions by 5 positive feedback types, as summarized in Table 1. For each type of positive feedback, we benchmarked the co-preference log-price utility scoring with the popularity baseline, with the only difference being that the p ( y | x ) term in Eq. (27) is replaced with p ( y ) for the popularity score. This shows the value added by contextual item. Varying in feedback types demonstrates how the proposed recommendation models op-timize different key metrics. The ROC curves for the pro-posed co-preference scoring and the baseline popularity are plotted in Figures 2(a) and 2(b) respectively, and the lift curves are plotted in Figures 3(a) and 3(b). The numerical results of AUC and lifts are summarized in Table 2.
As the results show, the log-price co-preference scoring outperforms the popularity baseline for all types of positive feedbacks. For the revenue feedback, the proposed recom-mendation model yields an AUC of 0.7595. The gain in lift is more pronounced. Our model obtains 9.92 times relative revenue lift at the 1% view recall, 3.5 times lift at the 10% view recall, and 2-3 folds better than the popularity base-line at the 1-2% view recall range. The proposed recom-mender optimizes key metrics very well including purchase, revenue and log-price; but interestingly and as desired, not as well for operational metrics including click-through and bid-through.

We also compared our generative clustering model with traditional k-means, specifically using squared Euclidean dis-tance and cosine similarity in the tf-idf feature space. In terms of recommendation quality, the generative model is better than both conventional k-means. For log-price co-preference scoring against log-price feedback, generative clus-tering yields an AUC of 0.7536, while k-means gets 0.7488 with Euclidean distance and 0.7471 with cosine similarity. Most importantly, we prefer the generative model since it provides a probabilistic membership score p ( i | y ) and natu-rally fits into the stochastic user conversion process as mod-eled in Eq. (24). With either distortion or cosine similarity, this nice probabilistic property is lost.
The proposed recommendation models were deployed to production. But before live traffic ramp-up, we conducted a longitudinal online A/B testing (the proposed model vs. the existing production system), lasting 4-6 months, explored the model space (positive event types and scoring functions), and tuned free parameters (event mixture weights  X , X   X  X , decaying factors  X , X   X  X , and smoothing factors  X , X   X  X ), on a daily basis. The final production model genuinely reflects an empirically optimal.

One of the major placements is check-out page, where a user just purchased an item and our recommender delivers 12 next-purchase prospects as one campaign impression to the user. The online testing was conducted for four major categories that exhibit a wide spectrum of domain charac-teristics: (1) Clothing, Shoes &amp; Accessories (CSA), (2) Com-puters &amp; Networking (Comp), (3) Electronics (Elec), and (4) Cell Phones &amp; PDAs (Cell). The testing results over a one-week period are shown in Table 3. Our model substantially outperforms the current production recommender, which is a neighborhood-based collaborative filtering at the category level. For CSA, the historical CTR on check-out page was 2-3%, and PTR was about 1%. Thus our system would yield a 3-5 folds improvement should it go live. We also per-formed a paired t -test on the hourly pairwise performance metrics, and showed that all these performance differences were statistically significant at level  X  = 0 . 1%.
We have presented a generative clustering model to learn persistent latent products from otherwise unstructured and dynamic items, a probabilistic recommendation model to learn co-preference patterns from historical transactional data, and hence providing a comprehensive and statistically sound solution to recommendation for long-tail marketplaces such as eBay. The proposed methodology is, however, of much generality.

First, the generative clustering model is a simple yet prin-cipled way to capture hidden structure underlying volatile and heterogeneous data, and thus enables reasoning on such data for applications such as search and recommendation. There has been a remarkable trend of this type of data accumulating on the Web as social-networking sites (e.g., Facebook), video-sharing sites (e.g., YouTube), and micro-blogging services (e.g., Twitter) gain popularity. More im-portantly, we described a sparse and highly efficient inferen-tial method to make the model scalable to large-scale real-world data. As future work, we shall evaluate soft item-product assignment to gauge whether the additional costs in terms of space and computational time could potentially result in additional gains in GMB.

Second, the recommendation model is learned by assum-ing the user conversion flow is a stochastic process and us-ing the position-normalized view count as the denominator. This yields a probabilistic measure of preference, possibly conditioned on some previous transactions. Not only the probabilistic scoring function can be further used for opti-mizing other recommendation metrics of business interest, but also it can be leveraged by other important applications as a user preference feature, such as search results re-ranking by user click-through feedback or perceived relevance [13].
Finally, we have proposed an approach to offline evaluat-ing item-based recommenders, particularly suitable for click-through data. The evaluation metrics, i.e., AUC and lift, are superior to other summary estimations such as test data log likelihood, since the former bears direct business signif-icance. The closed-loop offline evaluation framework would considerably expedite exploration of much larger model and parameter spaces.
The authors would like to thank the eBay merchandising team: Todd Forsyth, Petra Hofer, Jon Conradt, Helen Ye, Yan Huang; eBay Research Labs: Pavel Berkhin (now with Microsoft), Eric Brill, Neel Sundaresan, Dan Shen; eBay executive management: Mark Carges; and many other col-leagues for making this work possible and successfully de-ployed. [1] D. Agarwal and B.-C. Chen. Regression-based latent [2] D. Agarwal and B.-C. Chen. fLDA: Matrix [3] J. Bennett and S. Lanning. The Netflix Prize. In [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [5] O. Chapelle and Y. Zhang. A dynamic Bayesian [6] Y. Chen and J. F. Canny. Probabilistic clustering of [7] Y. Chen and J. F. Canny. Probabilistic [8] Y. Chen, M. Kapralov, D. Pavlov, and J. F. Canny. [9] Y. Chen, D. Pavlov, P. Berkhin, A. Seetharaman, and [10] Y. Chen, D. Pavlov, and J. F. Canny. Large-scale [11] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An [12] R. O. Duda, P. E. Hart, and D. G. Stork. Pattern [13] F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor, [14] T. Hofmann. Probabilistic latent semantic indexing. [15] T. Hofmann and J. Puzicha. Latent class models for [16] F. Jelinek and R. L. Mercer. Interpolated estimation [17] Y. Koren. Factorization meets the neighborhood: a [18] Y. Koren. Collaborative filtering with temporal [19] A. Mccallum and K. Nigam. A comparison of event [20] K. Nigam, A. K. McCallum, S. Thrun, and T. M. [21] D. Pavlov, R. Balasubramanyan, B. Dom, S. Kapur, [22] L. Si and R. Jin. Flexible mixture model for [23] C. Zhai and J. Lafferty. A study of smoothing methods [24] S. Zhong and J. Ghosh. A comparative study of
