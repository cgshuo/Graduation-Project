 Many problems of interest in Computer Vision and Machine Lea rning can be formulated as a prob-Because these point sets can have important internal struct ure, they are often considered not simply as point sets, but as two separate graphs. As a result, the cor respondence problem is commonly re-ferred to as graph matching. In this setting, graph nodes rep resent feature points extracted from each instance (e.g. a test image and a template image) and graph ed ges represent relationships between feature points. The problem of graph matching is to find a mapp ing between the two node sets that preserves as much as possible the relationships between nod es.
 Because of its combinatorial nature, graph matching is eith er solved exactly in a very restricted set-ting (bipartite matching, for example with the Hungarian me thod) or approximately. Most of the re-cent literature on graph matching has followed this second p ath, developing approximate relaxations to the graph matching problem. In this paper, we make two cont ributions. The first contribution is a spectral relaxation for the graph matching problem that in corporates one-to-one or one-to-many mapping constraints, represented as affine constraints. A n ew mathematical tool is developed for that respect, Affinely Constrained Rayleigh Quotients. Our meth od achieves comparable performance to the graph matching scoring function itself, which we argue, is prone to systematic confusion errors. We show how a proper bistochastic normalization of the graph matching compatibility matrix is able to considerably reduce those errors and improve the overall matching performance. This improve-ment is demonstrated both for our spectral relaxation algor ithm, and for three state of the art graph matching algorithms: spectral matching, graduated assign ment and semidefinite programming. Attributed Graph We define an attributed graph[1] as a graph G = ( V, E, A ) where each edge e = ij  X  E is assigned an attribute A e , which could be a real number or a vector in case of multi-attributes. We represent vertex attributes as special edge attributes, i.e. A example, the nodes could represent feature points with attr ibutes for spatial location/orientation and image feature descriptors, while edge attributes could rep resent spatial relationships between two nodes such as relative position/orientation.
 Graph Matching Cost Let G = ( V, E, A ) , G  X  = ( V  X  , E  X  , A  X  ) be two attributed graphs. We want to find a mapping between V and V  X  that best preserves the attributes between edges e = ij  X  E maximize the graph matching score, defined as: between edge attributes. As a special case, f ( A match ii  X  . In the rest of the paper, we let n = | V | , m = | E | , and likewise for n  X  , m  X  . Formulation as Integer Quadratic Program We explain here how to rewrite (1) in a more man-ageable form. Let us represent M as a binary vector x  X  { 0 , 1 } nn  X  : x problems, one requires the matching to have a special struct ure, such as one-to-one or one-to-many: this is the mapping constraint . For one-to-one matching, this is P x binary), and M is a permutation matrix. In general, this is an affine inequal ity constraint of the form Cx  X  b . With those notations, (1) takes the form of an Integer Quadr atic Program (IQP): hard, and approximate solutions are needed.
 Graph Matching Relaxations Continuous relaxations of the IQP (2) are among the most succ ess-ful methods for non-bipartite graph matching, and so we focu s on them. We review three state of the art matching algorithms: semidefinite programming (SDP) [2 , 3], graduated assignment (GA) [4], and spectral matching (SM) [5]. We also introduce a new metho d, Spectral Matching with Affine Constraints (SMAC) that provides a tigher relaxation than S M (and more accurate results in our ex-periments) while still retaining the speed and scalability benefits of spectral methods, which we also quantify in our evaluations. All of these methods relax the o riginal IQP into a continuous program (removing the x  X  { 0 , 1 } constraint), so we omit this step in the derivations below. SDP Relaxation In [2], the authors rewrite the objective as a matrix innner p roduct: x T W x = h X, W eq i , where X = [1; x ] T [1; x ] is a ( nn  X  + 1)  X  ( nn  X  + 1) rank-one matrix and W eq = d/ 2 W  X  D rank-one constraint is further relaxed by only requiring X to be positive semi-definite. Finally the relaxation is: max h X, W squares the problem size, which we will see, prevents SDP fro m scaling to large problems. Graduated Assignment GA[4] relaxes the IQP into a non-convex quadratic program (Q P) by re-moving the constraint x  X  { 0 , 1 } . It then solves a sequence of convex approximations, each ti me by maximizing a Taylor expansion of the QP around the previous a pproximate solution. The accuracy of the approximation is controlled by a continuation parame ter, annealed after each iteration. Spectral Matching (SM) In [5], the authors drop the constraint Cx  X  b during relaxation and only incorporate it during the discretization step. The resulti ng program: max x T W x s.t. || x || = 1 , which is the same as max x T W x verifies x  X  0 when W is nonnegative, by Perron-Frobenius X  theorem. We present here our first contribution, SMAC . Our method is closely related to the spectral match-ing formulation of [5], but we are able to impose affine constr aints Cx = b on the relaxed solution. We demonstrate later that the ability to maintain this const raint, coupled with scalability and speed of spectral methods, results in a very effective solution to graph matching. We solve the following: Note, for one-to-one matching the objective coincides with the IQP for binary x since x T x = n . Computational Solution We can formulate (3) as maximization of a Rayleigh quotient under affine constraint . While the case of linear constraints has been addressed previously[6], imposing affine constraints is novel. We fully address this class of pr oblem in the supplementary material 1 and give a brief summary here. The solution to (3) is given by t he leading eigenpair of where x is scaled so that Cx = b exactly. We introduced P C eq = [ I k  X  1 , 0] ( C  X  (1 /b k ) bC k ) Discretization We show here how to tighten our approximation during the disc retization step in the case of one-to-one matching (we can fall back to this case by introducing dummy nodes). Let us assume for a moment that n = n  X  . It is a well known result that for any n  X  n matrix X , X is a permutation matrix iff X 1 = X T 1 = 1 , X is orthogonal, and X  X  0 elementwise. We show here we can obtain a tighter relaxation by incorporating the first 2 (out of 3) constraints as a post-processing before the final discretization. We carry on the f ollowing steps even when n 6 = n  X  : 1) reshape the solution x of (3) into a n  X  n  X  matrix X , 2) compute the best orthogonal approximation X X orth = arg min {|| X  X  Q || : Q  X  O ( n, n  X  ) } = U V T matrices of R n  X  n  X  , and 3) discretize X The following proposition shows X Proposition 3.1 ( X Y , then u is left and right eigenvector of Y Proof : see supplementary materials. Note that in general, X and X eigenvectors, here we are lucky because of the particular co nstraint induced by C, b . Computational Cost The cost of this algorithm is dominated by the computation of the leading eigenvector of (4), which is function of two terms: 1) number of matrix-vector operations required operation. P be computed in O ( nn  X  ) using the Sherman-Morrison formula (for one-to-one matchi ng). Finally, full-matching, this is O ( mm  X  ) , which is linear in the problem description length. We ran extensive graph matching experiments on both real ima ge graphs and synthetic graphs with the algorithms presented above. We noticed a clear trend: th e algorithms get confused when there is ambiguity in the compatibility matrix. Figure 1 shows a ty pical example of what happens. We extracted a set of feature points (indexed by i and i  X  ) in two airplane images, and for each edge see, the first edge plotted has many correspondences everywh ere in the image and is therefore unin-formative . The second edge on the other hand has correspondences with r oughly only 5 locations, it unbalanced . We illustrate next what happens with a synthetic example. Synthetic noise model example Let us look at a synthetic example to illustrate this concept , on which the IQP can be solved by brute-force. Figure 2 shows two isomorphic graphs with 3 nodes. In our simple noise model, edges 12 and 13 are uninformative and make connections to every edge in the second graph, with strength  X  (our noise parameter). The informative edge 23 on the other hand only connects to 2  X  3  X  . We displayed W of 8 for  X  = 0 . We computed the score of the second best permutation as a fun ction of  X  (see plot of margin), and showed that for  X  greater than  X  with some edges making spurious connections, overwhelming the influence of other edges with few connections. This problem is not incidental. In fact we argu e this is the main source of confusion for graph matching. The next section introduces a normaliza tion algorithm to address this problem. As we saw in the previous section, a main source of confusion f or graph matching algorithms is the unbalance in the compatibility matrix. This confusion occu rs when an edge e  X  E has many good On the other hand, an edge with small number of good matches will help disambiguate the optimal bistochastic normalization . 5.1 Dual Representation: Matching Compatibility Matrix W vs. Edge Similarity Matrix S The similarity function f ( , ) can be interpreted in two ways: either as a similarity between edges ij  X  E and i  X  j  X   X  E  X  , or as a compatibility between match hypothesis ii  X   X  M and jj  X   X  M . We define the similarity matrix S of size m  X  m  X  as S compatibility matrix W of size nn  X   X  nn  X  as W each edge e = ij  X  E should also match to a small number of edges e  X  = i  X  j  X   X  E  X  . Although this constraint would be very hard to enforce, we approach this be havior by normalizing the influence of each edge. This corresponds to having each row and column i n S (not W !) sum to one, in other words, S should be bistochastic . 5.2 Bistochastic Normalization of Edge Similarity Matrix S Recall we are given a compatibility matrix W . Can we enforce its dual representation S to be bis-tochastic? One problem is that, even though W is square (of size nn  X   X  nn  X  ), S could be rectangular (of size m  X  m  X  ), in which case its rows and columns cannot both sum to 1. We de fine a m  X  m  X  matrix B to be Rectangular Bistochastic if it satisfies: B 1 can formulate the normalization as solving the following ba lancing problem: We propose the following algorithm to solve (5), and then sho w its correctness. Proposition 5.1 (Existence and Uniqueness of (D,D X )) Under the condition S &gt; 0 elementwise, normalizing the rows and columns of S .
 Proof Let  X  S = S  X  1 version of (5.1) for square matrices[8]. We conclude the pro of by noticing that normalizing rows and columns of  X  S preserves kronecker structure:  X  D  X  S  X  D  X  = ( D  X  1 We illustrate in Figure 2 the improvement of normalization o n our previous synthetic example of noise model. Spurious correspondences are suppressed and i nformative correspondances such as W normalized correspondences will eventually result in inco rrect matchings. Discretization and Implementation Details Because all of the methods described are continuous relaxations, a post-processing step is needed to discretiz e the continuous solution while satisfying the desired constraints. Given an initial solution estimat e, GA finds a near-discrete local minimum of the IQP by solving a series of Taylor approximations. We ca n therefore use GA as follows: 1) initialize GA with the relaxed solution of each algorithm, a nd 2) discretize the output of GA with a simple greedy procedure described in [5]. Software: For SDP, we used the popular SeDuMi [9] optimization package. Spectral matching and SMAC were impl emented using the standard Lanczos eigensolver available with MATLAB, and we implemented an op timized version of GA in C++. 6.1 One-to-one Attributed Graph Matching on Random Graphs Following [4], we performed a comprehensive evaluation of t he 4 algorithms on random one-to-one graph matching problems. For each matching problem, we cons tructed a graph G with n = 20 nodes, and m random edges ( m = 10% n 2 in a first series of experiments). Each edge ij  X  E , was assigned a random attribute A by adding noise on the edge attributes: A  X  the noise was distributed uniformly in [0 ,  X  ] ,  X  varying from 0 to 6. The compatibility matrix W was computed from graphs G, G  X  as follows: W For each noise level we generated 100 different matching pro blems and computed the average error rate by comparing the discretized matching to the ground tru th permutation.
 Effect of Normalization on each method We computed the average error rates with and without normalization of the compatibility matrix W , for each method: SDP, GA, SM and SMAC, see Figure 4. We can see dramatic improvement due to normalization, reg ardless of the relaxation method used. At higher noise levels, all methods had a 2 to 3-fold decrease in error rate.
 Comparison Across Methods We plotted the performance of all 4 methods using normalized and SMAC give comparable performance, while GA and especial ly SM do worse. These results validate SMAC with normalization as a state-of-the-art rel axation method for graph matching. Influence of edge density and graph size We experimented with varying edge density: noise  X  = 2 , n = 20 , edge density varying from 10% to 100% by increments of 10% wi th 20 trials per increment. For SMAC, the normalization resulted in an avera ge absolute error reduction of 60%, and for all density levels the reduction was at least 40%. For SDP, the respective figures were 31%, 20%. We also did the same experiments, but with fixed edge dens ity and varying graph sizes, from 10 to 100 nodes. For SMAC, normalization resulted in an avera ge absolute error reduction of 52%; for all graph sizes the reduction was at least 40%.
 Scalability and Speed In addition to accuracy, scalability and speed of the method s are also im-portant considerations. Matching problems arising from im ages and other sensor data (e.g., range Figure 4: Comparison of matching performance with normalized and unnormalized compatibility matrices. scans) may have hundreds of nodes in each graph. As mentioned previously, the SDP relaxation squares the problem size (in addition to requiring expensiv e solvers), greatly impacting its speed and scalability. Figure 5 (middle and right) demonstrates t his. For a set of random one-to-one matching problems of varying size n (horizontal axis), we averaged the time for computing the re-laxed solution of all four methods (10 trials for each n ). We can see that SDP scales quite poorly (almost 30 minutes for n = 30 ). In addition, on a machine with 2GB of RAM, SDP typically ran out of memory for n = 60 . By contrast, SMAC and SM scale easily to much larger problem s ( n = 200 ). 6.2 Image correspondence We also tested the effect of normalization on a simple but ins tructive image correspondence task. In each of two images to match, we formed a multiple attribute gr aph by sub-sampling n = 100 canny edge points as graph nodes. Each pair of feature points e = ij within 30 pixels was assigned two iff emphasized the effect of normalization on the energy functi on, rather than feature design. Figure 6 shows an image correspondence example between the t wo airplane images of Figure 1. We display the result of SMAC with and without normalization . Correspondence is represented normalization, large systematic errors are made, such as ma pping the bottom of one plane to the top of the other. With normalization these errors are largely el iminated.
 2 types of connections: 1) horizontal edges (uninformative ) and 2) vertical edges (discriminative). Normalization exploits this disparity to enhance the latte r edges: before normalization, each con-2 contributed up to 0.64 to the overall matching score, versu s 0.08 for connections of type 1, which is 8 times more. We can view normalization as imposing an uppe r bound on the contribution of each connection: the upper bound is smaller for spurious matches , and higher for discriminative matches. While recent literature mostly focuses on improving relaxat ion methods for graph matching prob-lems, we contribute both an improved relaxation algorithm, SMAC, and a method for improving SMAC outperformed GA and SM, with similar accuracy to SDP, it also scaled much better than SDP. We motivate the normalization with an intuitive exampl e, showing it improves noise tolerance by enhancing informative matches and de-enhancing uninfor mative matches. The experiments we performed on random one-to-one matchings show that normali zation dramatically improves both our relaxation method SMAC, and the three algorithms mentio ned. We also demonstrated the value of normalization for establishing one-to-one corresponde nces between image pairs. Normalization imposes an upper bound on the score contribution of each edge in proportion to its saliency. Figure 6: Image correspondence via SMAC with and without normalization; like color s indicate matches.
