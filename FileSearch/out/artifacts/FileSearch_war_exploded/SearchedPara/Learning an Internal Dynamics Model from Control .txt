 Matthew D. Golub mgolub@cmu.edu Inverse optimal control (IOC) and inverse rein-forcement learning (IRL) aim to identify a cost function from demonstrations of successful control ( Boyd et al. , 1994 ; Schaal , 1999 ; Ng &amp; Russell , 2000 ; Abbeel &amp; Ng , 2004 ; Ratliff et al. , 2006 ; Coates et al. , 2008 ; Ziebart et al. , 2008 ). These approaches typically require a model of the plant dynamics, which enables prediction of future states given the current state and control input. In previous work, it has been assumed that the controller X  X  internal belief about the plant dy-namics matches the actual plant dynamics. However, when the controller is a human or animal subject, this internal belief may differ from the actual plant dynam-ics ( Crapse &amp; Sommer , 2008 ), especially if the subject has limited experience driving the plant. This mis-match can exist even when demonstrated control is proficient (e.g., the implemented control strategy may be only locally optimal). Because the plant dynamics and cost function jointly determine the optimal control policy, an incorrect assumption about the dynamics model can lead to misestimation of the cost function via IOC or IRL.
 Ideally, we would like to use demonstrated control to learn both the subject X  X  internal model of the plant dynamics and the cost function together. This joint estimation is difficult, so previous work has focused on learning the cost function while assuming known plant dynamics. Here, we present and solve the complemen-tary problem of learning the subject X  X  internal model of the plant dynamics while assuming knowledge of the task goals. This problem is challenging because at each control decision, the subject must generate an in-ternal estimate of the current plant state based on de-layed sensory feedback ( Miall &amp; Wolpert , 1996 ), and we cannot directly observe these internal state esti-mates.
 We introduce a probabilistic internal model estima-tion (IME) framework through which inference and learning provide a solution to the current problem in the setting of linear-Gaussian internal model dynamics and quadratic cost functions. In IME, the subject X  X  in-ternal model of the plant dynamics defines trajectories of latent variables representing the subject X  X  moment-by-moment internal estimates of the plant state. We assume knowledge of the control signals sent by the subject, the plant state feedback available to the sub-ject, and target states to which the subject intends to drive the plant during control. Importantly, we make no assumption that the subject X  X  internal dynamics model should match the true plant dynamics.
 Beyond the algorithmic advance, the ability to extract a subject X  X  internal model has many potential applica-tions in neuroscience and human-in-the-loop control. Access to a subject X  X  internal model could provide a means for tracking and encouraging skill acquisition in complex tasks, including brain-machine interface (BMI) control, telerobotic surgery or remote control of unmanned-aerial vehicles. In this work we apply the developed methods toward demonstrations of BMI cursor control. BMIs have been developed to assist disabled patients by translating neural activity into control signals for a prosthetic limb or computer cur-sor ( Green &amp; Kalaska , 2011 ). BMI control is an ac-quired skill, akin to driving a car or helicopter. Pre-vious studies have shown that subjects improve BMI control performance over time ( Taylor et al. , 2002 ; Ganguly et al. , 2011 ). This improvement is likely a result of the subject refining an internal model of the BMI plant dynamics through experience. Access to the subject X  X  internal model of the BMI, through the methods we develop here, may inform the design of future BMI systems and may provide neuroscientists with novel tools for investigating the neural basis of feedback motor control and motor learning.
 We begin Section 2 by formalizing the internal model estimation problem. In Section 3 we propose a prob-abilistic framework for solving the internal model es-timation problem. Section 4 details the validation of the framework through application to real neural data underlying BMI control of a computer cursor. A standard control model takes the following form: where f 1 represents the subject X  X  belief about the plant dynamics, x t  X  R n is the subject X  X  belief of the plant state at timestep t , u t  X  R m is the control input issued at timestep t , and J is the cost function that encodes task goals and control effort. We distinguish the sub-ject X  X  internal model of the plant dynamics, f 1 , from the actual plant dynamics, f 2 : where y t  X  R p is the actual plant state at timestep t . Due to sensory feedback delay, the feedback available at timestep t represents the plant state at timestep t  X   X  , where  X  is the feedback delay. To predict the current plant state, the subject can use f 1 as a forward model, propagating y t  X   X  (or a noise-corrupted func-tion of it) forward in time using knowledge of the plant dynamics and previously issued controls u t  X   X  , ..., u t In general, the subject X  X  internal beliefs { x t } may be inconsistent with the actual plant states { y t } due to differences between f 1 and f 2 and due to sensory noise. The problem we seek to solve is: That is, given trajectories of actual plant state and control input, and assuming a cost function, we seek to estimate the subject X  X  internal model of the plant dy-namics, the subject X  X  internal estimates of plant state, and the sensory feedback delay.
 In the remainder of this paper, we focus on the case where f 1 is linear-Gaussian and J is quadratic over the internal states, in analogy to the well-studied linear-quadratic regulator ( Anderson &amp; Moore , 1990 ). These choices allow us to derive an approximation-free algo-rithm to solve the internal model estimation problem. The IME probabilistic model is as follows: At timestep t  X  { 1 , ..., T } , y t  X  R p is the actual plant state, x t k  X  R n is the subject X  X  internal estimate of the timestep k  X  { t  X   X , ..., t +1 } plant state (see below for detailed explanation), u t  X  R m is the subject X  X  control input, and G t  X  R q represents control goals. The subject X  X  internal model parameters { A  X  R n  X  n , B  X  R covariance matrices { W 0  X  R n  X  n , W  X  R n  X  n , V  X  R IME graphical model for a single timestep feedback delay (  X  = 1) is shown in Fig. 1 .
 Due to sensory delays, the plant state feedback avail-able at timestep t is outdated by  X  timesteps. Ac-cordingly, ( 4 ) defines the subject X  X  noisy, partial ob-servation of delayed plant state feedback. Sitting at timestep t , the subject uses this feedback, y t  X   X  , to plant state. The noise covariance W 0 accounts for sensory noise.
 We define the subject X  X  internal dynamics model in ( 5 ) to be a Gaussian linear-dynamical system that prop-agates the subject X  X  internal estimates of plant state given control input. At timestep t , the subject makes current ( k = t ), and future ( k = t + 1) plant states. This timestep t internal state chain (Fig. 1 A) corre-sponds to a row of latent states in the IME graph-ical model (Fig. 1 B). The state chain begins with x feedback, y t  X   X  . Subsequent internal state estimates, t  X   X  +1 , . . . , x t t+1 } , may be inconsistent with the true plant states, { y t  X   X  +1 , . . . , y t+1 } , because i) sensory feedback is not yet available for these timesteps, and ii) there may be mismatch between the subject X  X  in-ternal model ( 5 ) and the true plant dynamics ( 3 ). In-ternal state transitions not explained by the internal model are accounted for by the noise covariance, W . At timestep t + 1, the subject receives new plant feed-back, y t  X   X  +1 , and generates revised internal estimates, { x where we fix k and vary t  X  { k  X  1 , . . . , k +  X  } , cor-respond to a column of latent states in the graphical model and represent successive revisions of the sub-ject X  X  beliefs about the timestep k plant state, given the sensory feedback available at timestep t . Note that ( 5 ) is the IME instantiation of ( 1 ).
 In ( 6 ), we encode the subject X  X  cost function. At timestep t , the subject determines the next control signal to send, u t , which the subject X  X  internal model matrix, C t , relates this internal state estimate to the given control goals, G t . Depending on the applica-tion, C t may be fully specified in advance, or may contain parameters to be learned. For example, in a trajectory tracking task, the G t might encode the (known) desired trajectory, and C t might simply ex-tract appropriate components of the subject X  X  internal tively, C t might compute linear functions of feature counts ( Ng &amp; Russell , 2000 ; Abbeel &amp; Ng , 2004 ) from the subject X  X  internal state estimates. In Section 4 we describe an application in which the G t are constant across timesteps and represent a control goal to be at-tained by some arbitrary time in the future. In this application, we use C t to extract the extent to which the subject is on track to achieve the goal state. Note that ( 6 ) relates to ( 2 ), but does not incorporate con-trol effort. We focus the scope of this work to problems where either i) the cost function is dominated by the state cost, or ii) we can structure the C t in ( 6 ) to ac-count for an unknown control cost (see Section 4 for an example). 3.1. Model Fitting In model fitting, we treat actual plant states, { y t } , control inputs, { u t } , and task goals, { G t } , as observed variables. We treat the internal state estimates, { x t t tent variables. We seek the model parameters, H , W 0 , A , B , b 0 , W , { C t } 1 , V , and  X  , that maximize P( { G t }|{ y t } , { u t } ), the likelihood of the control goals under the distribution induced by ( 4 )-( 6 ). We derived an exact expectation-maximization (EM) algorithm ( Dempster et al. , 1977 ) for a specified feed-back delay,  X  (see APPENDIX ). In the E-step, we in-fer posterior distributions over the latent variables, rent parameter estimates. In the M-step, we update model parameters given the posterior latent variable distributions. Since the relationships in ( 4 )-( 6 ) are linear-Gaussian, all latent and observed variables are jointly Gaussian. Additionally, given all control in-puts, an internal state chain for one timestep is con-ditionally independent of the internal state chains for all other timesteps where t 1 6 = t 2 . These properties of IME enable an ex-act and efficient E-step update to the posterior latent variable distributions, and closed-form M-step param-eter updates.
 To identify the feedback delay,  X  , we fit IME across a sequence of  X  values. As  X  increases, the number of parameters remains fixed, and thus increasing  X  does not lead to overfitting. For this reason we can simply choose  X  ML to be the  X  whose correspond-ing IME fit gives the highest training data likelihood, P( { G t }|{ y t } , { u t } ). We demonstrate an application of the IME framework to closed-loop BMI cursor control. A BMI system can be viewed as a feedback control system, whereby a human or animal subject (controller) generates neu-ral activity (control signal) to drive a computer cursor (plant). The experimenter defines the mapping from recorded neural activity to cursor movements (i.e., the actual plant dynamics). The experimenter also defines the task goals in each trial by displaying a visual tar-get to which the subject is instructed to drive the BMI cursor. At any moment in time, the subject does not know the current cursor position due to visual feed-back delays in the nervous system, and therefore must choose a control signal to issue based on visual feed-back of an outdated cursor position. We assume that the subject always intends to drive the cursor straight to the target from an internal estimate of the current cursor position. We seek to use IME to estimate the subject X  X  internal model of the BMI cursor dynamics along with the subject X  X  timestep-by-timestep internal estimates of the current BMI cursor position. Previous studies have provided behavioral and neuro-physiological evidence that subjects use internal mod-els during motor control ( Crapse &amp; Sommer , 2008 ). In the context of BMI, subjects need to learn to control the cursor, which likely involves refining the internal model with practice controlling the BMI. 4.1. BMI experiments A 96-channel Utah electrode array was implanted in motor cortex of a Rhesus monkey. In each of 36 ex-perimental sessions, we simultaneously recorded from tens (26  X  3 . 44) of neurons, and spike counts were taken in  X  t = 33 ms non-overlapping bins. Two-dimensional cursor velocity was linearly decoded from recorded spike counts, and cursor positions were up-dated according to where y t  X  R 2 is the cursor position displayed at timestep t , u t  X  R m is the raw spike count vector across m simultaneously recorded neuronal units at timestep t , and  X  u t  X  R m is the vector mean spike count over the past 5 timesteps. The decoding pa-the population vector algorithm ( Georgopoulos et al. , 1983 ). Note that ( 8 ) describes the actual dynamics of the BMI cursor, corresponding to ( 3 ).
 In each experimental trial, the subject modulated neu-ral activity to drive the BMI cursor (radius, 8 mm) to a target (radius, 8 mm) that appeared on the perime-ter of a circular workspace (radius, 85 mm). A trial was deemed successful and terminated as soon as the cursor visibly overlapped with the target for 50 ms. A trial was deemed a failure if the subject did not acquire the target within 2 s. The subject typically failed less than 5% of trials. Experimental details were previ-ously described in Chase et al. ( 2012 ). 4.2. IME formulation for BMI control The specific IME formulation we applied to the BMI control data is as follows: where ( 10 )-( 12 ) are specific instances of ( 4 )-( 6 ). A single-timestep slice of this IME graphical model is shown in Fig. 2 .
 Since the BMI experiments used a position-only state, we define the subject X  X  internal state estimates to re-side in the same 2-dimensional position space to allow for interpretable A , B , b 0 , and { x k t } . For simplicity, we assume the BMI subject has noiseless access to de-layed visual feedback of cursor position. These choices are formalized in ( 10 ), where x t t estimate made by the subject at timestep t of the BMI cursor position at timestep t  X   X  , and y t  X   X   X  R 2 is the actual BMI cursor position at timestep t  X   X  . In ( 11 ), x t k  X  R 2 is the subject X  X  internal estimate made at timestep t of the timestep k  X  { t  X   X , ..., t +1 } cursor position, and the control input u t  X  R m is neu-ral activity recorded at timestep t , as defined in Sec-tion 4.1 . Note that the form of the subject X  X  internal dynamics model in ( 11 ) matches the form of the actual cursor dynamics from ( 8 ), allowing for direct compar-ison between the two.
 The cost function in ( 12 ) encodes the subject X  X  inten-tion to drive the cursor straight toward the current visual target position, G t  X  R 2 , from the subject X  X  up-to-date estimate of cursor position, x t t , as illustrated in Fig. 3 . Within a particular BMI trial, all { G t } take the same value. The straight-to-target aiming inten-tion is implemented by the neural control input, u t , which the subject X  X  internal model predicts will bring the cursor to position x t t+1 . The mean of the distribu-tion in ( 12 ) lies on the line defined by the two points, x t and x t t+1 . The length of the line segment between x t+1 and G t is controlled by c t , which is determined by the data. The noise variance,  X  2 G , accounts for motor commands that deviate from straight-to-target aiming.
 In model fitting for this IME formulation, we seek the subject X  X  internal model parameters A  X  R 2  X  2 , B  X  R and  X  2 G  X  R + , the length scale factors c t  X  R + , and the visual feedback delay  X   X  Z + that maximize P( { G t }|{ y t } , { u t } ), the likelihood of the actual target positions under the distribution induced by ( 10 )-( 12 ). To identify these maximum likelihood parameters, we derived an exact EM algorithm (see APPENDIX ). We initialized the EM algorithm with randomly drawn parameters and applied multiple random restarts to avoid local optima.
 Note that the number of c t parameters varies with the amount of data. Although they might be more natu-rally treated as latent variables, the c t were treated as parameters to preserve the joint Gaussian relationship between latent and observed variables. As a result, we optimize the c t rather than integrate over them during model fitting. When cross-validating IME predictions, we will not have access to c t for the held-out data, but this does not pose a problem because, as discussed in Section 4.3 , we can readily evaluate goodness-of-fit on held out data without requiring these c t . 4.3. Results We fit and evaluated IME models using 10-fold cross validation. For each trial that was held out during training, we asked to what extent IME predictions of the subject X  X  internal estimates of cursor position were indicative of straight-to-target aiming. We define aim-ing error at timestep t to be the absolute angle by which the cursor would miss the target had the cursor x t+1 . For this evaluation, we inferred the subject X  X  internal estimates of cursor position to be for k  X  { t  X   X , ..., t } , where A , B , b 0 and  X  were fit to the training data, and the recursive expectations were initialized by ( 10 ). Note that the expectation in ( 13 ) depends only on the visual feedback available at timestep t , neural commands, and the subject X  X  inter-nal model parameters. Critically, ( 13 ) does not depend on the target position, G t , which will be used to evalu-ate the output of the internal model estimated by IME. Additionally, ( 13 ) does not require us to compute { c t for held-out trials.
 To determine the feedback delay,  X  , we fit IME mod-els for  X   X  { 0 , ..., 9 } and assessed model fit by exam-ining the data likelihood, P( { G t }|{ y t } , { u t } ). Recall that  X  controls the number of latent variables, x , in each row of the graphical model in Fig. 1 , and that the number of model parameters does not depend on the setting of  X  . Fig. 4 A shows the training data log-likelihood for a single BMI session across all evaluated choices of  X  , and Fig. 4 B gives the values of  X  that maximized each training fold X  X  data log-likelihood. A feedback delay of 3 timesteps (100 ms) most often gave the best model fit. This result agrees with reaction times we measured from BMI cursor trajectories and previously reported motor-cortical latencies to visual stimuli ( Schwartz et al. , 1988 ).
 On many BMI trials, the subject drove the cursor roughly straight to the target, whereas cursor trajecto-ries were more circuitous on other trials. It is an open question as to why the subject does not always drive the cursor straight to the target. In Figs. 5 A and 5 B, we show a BMI trial with a circuitous cursor trajec-tory, along with cross-validated IME-inferred internal estimates of cursor position from ( 13 ). In Fig. 5 A, the subject X  X  aiming intention at timestep t , as defined by IME predictions of the subject X  X  internal state esti-mates x t t and x t t+1 , points straight toward the target. We would evaluate this aiming command as having a target had it continued along that intended aiming di-rection. For comparison, we computed velocity motor commands, v t , through the actual cursor dynamics: which correspond to the single-timestep ( X  t = 33ms) contribution to the current cursor velocity, implicit in ( 8 ). In Fig. 5 A, if the subject was aiming from a per-fect prediction of the current cursor position, y t , (e.g., by using an internal model that exactly matched the cursor dynamics), the motor command decoded from the actual cursor dynamics would miss the target by Despite the cursor X  X  circuitous trajectory in this exam-ple trial, IME predictions suggest that the subject was indeed aiming straight toward the target throughout the trial (Fig. 5 B). IME-extracted internal state esti-mates diverge from the true cursor trajectory because the extracted internal model differs from the true cur-sor dynamics ( 8 ). The key insights here are that i) the subject appears to be aiming from where it believes the cursor is at each point in time, as determined by the internal model, and ii) the subject X  X  neural com-mands, when evaluated through the internal model, are consistent with straight-to-target movements. In Fig. 5 C, we show a representative trial where the subject drove the BMI cursor along a more direct path to the target. On this trial and many similar to it, IME predictions of the subject X  X  internal state estimates tend to agree quite closely with the actual cursor move-ment. This agreement contrasts with the disagree-ment between IME predictions and cursor movements in Figs. 5 A and 5 B, highlighting the redundancy in the mapping from high-dimensional neural activity to low-dimensional cursor kinematics. Certain patterns of neural activity may produce straight-to-target move-ments through both the subject X  X  internal model and the cursor dynamics, whereas other patterns may pro-duce straight-to-target movements through the inter-nal model, but not through the cursor dynamics. On both trials in Fig. 5 , IME-extracted internal models reveal the subject X  X  internal state estimates tending toward the target, regardless of where the actual cur-sor moves.
 Across 5,760 trials from 36 BMI experiments, we com-puted cross-validated angular aiming errors from IME-inferred internal state estimates (as in the red angular error from Fig. 5 A) and from actual cursor positions (as in the black angular error from Fig. 5 A). IME-based aiming errors were about 5 times smaller than the analogous errors in demonstrated cursor trajecto-ries (Fig. 6 ). Recall that the straight-to-target aiming assumption is only applied to the training data during model fitting and not when evaluating test data. That being said, neural commands in the test data were more consistent with straight-to-target aiming under IME-extracted internal models than under the actual cursor dynamics. Internal models extracted by IME therefore explain the subject X  X  neural commands bet-ter than the actual cursor dynamics. The developed IME framework describes the inter-nal state estimation process, whereby the subject in-tegrates feedback with previously issued control sig-nals to generate an up-to-date estimate of the plant state. IME specifically addresses complicating reali-ties inherent in learning from demonstration, includ-ing i) sensory feedback delays and ii) mismatch be-tween the true plant model and the subject X  X  internal model. This mismatch, often referred as model bias , is typically treated as an obstacle to be overcome, for example by incorporating model uncertainty in pol-icy search ( Deisenroth &amp; Rasmussen , 2011 ) or through policy improvement in the presence of model inaccu-racies ( Abbeel et al. , 2006 ). In this work, we seek to explicitly identify the subject X  X  internal model, rather than attempt to factor it out.
 The internal model estimation problem that we ad-dress is fundamentally different from the problem of learning the actual plant dynamics (i.e., system identi-fication). The internal model estimation problem can-not be solved by simply relating control signals to state transitions. Actual plant state trajectories only enter IME as delayed feedback, and as such, the actual plant dynamics play only an indirect role when extracting the subject X  X  internal model. Additionally, the objec-tive in this work is not to design better plant dynamics, but rather to estimate the subject X  X  knowledge of the current plant dynamics, whatever they may be. The ability to extract the subject X  X  internal model depends critically on the consistency of control relative to the task goals and internal model, and not on the extent to which the subject X  X  demonstrations achieve those goals through the actual plant dynamics.
 Ground truth cannot be known in the BMI appli-cation. For comparison against our IME-based re-sults, we present aiming errors resulting from evaluat-ing recorded neural commands through the true cursor dynamics. We chose this comparison because, for opti-mal control, the subject should learn an internal model that matches the actual plant dynamics. Although the subject is proficient in BMI tasks, our results suggest a mismatch between the subject X  X  internal model and the actual cursor dynamics. IME provides the oppor-tunity to study the brain X  X  deviations from optimality, which may ultimately enable researchers to design spe-cific training paradigms to improve a subject X  X  learn-ing.
 While IME requires specification of a cost function, we have demonstrated notable flexibility in this require-ment. Unlike optimal control in the linear-quadratic Gaussian setting ( Anderson &amp; Moore , 1990 ), IME does not require pre-specification of a control time horizon. Additionally, by learning the c t in ( 12 ), in-ternal model estimation becomes agnostic to control effort. This feature is advantageous because the form of control costs is often unknown, especially in the BMI setting (although see ( K  X ording &amp; Wolpert , 2004 )). In some cases, these control costs may be known a priori , and we are interested in extending IME to handle these scenarios (e.g., when a full quadratic cost function of state and control is specified).
 One potential limitation of IME is the prescription of a static linear-Gaussian form to the internal model. Some applications may require more expressive in-ternal model dynamics, which could be accommo-dated by a nonparametric representation of the inter-nal model ( Deisenroth et al. , 2012 ). Additionally, the ability to extract a time-varying internal model may be needed in settings where the subject updates an internal model as control experience accrues. This work was supported by NSF IGERT Fellow-ship (MDG), NIH-NICHD-CRCNS-R01-HD-071686 (BMY), and PA Department of Health Research Formula Grant SAP#4100057653 under the Com-monwealth Universal Research Enhancement program (SMC). We thank A. Schwartz for access to BMI data. We thank P. Abbeel and Z. Kolter for insightful com-ments on a preliminary version of this paper. Abbeel, P. and Ng, A.Y. Apprenticeship learning via inverse reinforcement learning. In Proc. 21st Inter-national Conf. on Machine Learning , pp. 1 X 8, 2004. Abbeel, P., Quigley, M., and Ng, A.Y. Using inaccu-rate models in reinforcement learning. In Proc. 23rd
International Conf. on Machine learning , pp. 1 X 8, 2006.
 Anderson, B.D.O. and Moore, J.B. Optimal control: linear quadratic methods . Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1990.
 Boyd, S., El Ghaoui, L., Feron, E., and Balakrishnan, V. Linear Matrix Inequalities in System and Control
Theory . Studies in Applied Mathematics, Philadel-phia, PA, 1994.
 Chase, S.M., Kass, R.E., and Schwartz, A.B. Behav-ioral and neural correlates of visuomotor adaptation observed through a brain-computer interface in pri-mary motor cortex. J. Neurophysiol. , 108(2):624 X  644, 2012.
 Coates, A., Abbeel, P., and Y. Ng, A.Y. Learning for control from multiple demonstrations. In Proc. 25th International Conf. on Machine Learning , pp. 144 X 151, 2008.
 Crapse, T.B. and Sommer, M.A. Corollary discharge across the animal kingdom. Nat. Rev. Neurosci. , 9 (8):587 X 600, 2008.
 Deisenroth, M.P. and Rasmussen, C.E. Pilco: A model-based and data-efficient approach to policy search. In Proc. 28th International Conf. on Ma-chine Learning , pp. 465 X 472, 2011.
 Deisenroth, M.P., Turner, R.D., Huber, M.F.,
Hanebeck, U.D., and Rasmussen, C.E. Robust fil-tering and smoothing with gaussian processes. IEEE Trans. Automatic Control , 57(7):1865 X 1871, 2012. Dempster, A.P., Laird, N.M., and Rubin, D.B. Max-imum likelihood from incomplete data via the EM algorithm. J. Royal Stat. Soc., Series B , 39(1):1 X 38, 1977.
 Ganguly, K., Dimitrov, D.F., Wallis, J.D., and Car-mena, J.M. Reversible large-scale modification of cortical networks during neuroprosthetic control. Nature Neurosci. , 14(5):662 X 667, 2011.
 Georgopoulos, A.P., Caminiti, R., Kalaska, J.F., and
Massey, J.T. Spatial coding of movement: a hypoth-esis concerning the coding of movement direction by motor cortical populations. Exp. Brain Res. Suppl. , 7:327 X 336, 1983.
 Green, A.M. and Kalaska, J.F. Learning to move ma-chines with the mind. Trends Neurosci. , 34(2):61 X  75, 2011.
 K  X ording, K.P. and Wolpert, D.M. The loss function of sensorimotor learning. Proc. Natl. Acad. Sci. , 101 (26):9839 X 9842, 2004.
 Miall, R.C. and Wolpert, D.M. Forward models for physiological motor control. Neural Networks , 9(8): 1265 X 1279, 1996.
 Ng, A.Y. and Russell, S. Algorithms for inverse re-inforcement learning. In Proc. 17th International Conf. on Machine Learning , pp. 663 X 670, 2000. Ratliff, N.D., Bagnell, J.A., and Zinkevich, Martin.
Maximum margin planning. In Proc. 23rd Inter-national Conf. on Machine Learning , pp. 729 X 736, 2006.
 Schaal, S. Is imitation learning the route to humanoid robots? Trends in Cognitive Sciences , 3(6):233 X 242, 1999.
 Schwartz, A.B., R.E., Kettner, and Georgopoulos,
A.P. Primate motor cortex and free arm movements to visual targets in 3-dimensional space. 1. relations between single cell discharge and direction of move-ment. J. Neurosci. , 8(8):2913 X 2927, 1988.
 Taylor, D.M., Helms Tillery, S.I., and Schwartz, A.B.
Direct cortical control of 3D neuroprosthetic de-vices. Science , 296:1829 X 1832, 2002.
 Ziebart, B.D., Maas, A.L., Bagnell, J.A., and Dey,
A.K. Maximum entropy inverse reinforcement learn-ing. In Proc. 23rd AAAI Conf. on Artificial Intelli-
