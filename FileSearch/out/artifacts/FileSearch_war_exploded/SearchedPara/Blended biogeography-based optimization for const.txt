 1. Introduction
Many optimization problems in science and engineering have constraints ( Schwefel, 1995; Runarsson and Yao, 2000 ) which can be linear or nonlinear. Evolutionary algorithms (EAs) have been successful for a wide range of constrained optimization problems ( Coello, 2002; Zbigniew and Marc, 1996 ). In the last few years, for example, evolutionary strategy (ES) ( McTavish and Restrepo, 2008; Mezura-Montes and Coello, 2005 ), genetic algorithms (GAs) ( Deb, 2000; Eshelman and Schaffer, 1993; Yao et al., 1999 ), differential evolution (DE) ( Huang et al., 2006; Mezura-Montes and Palomeque-Oritiz, 2009; Zielinske and Laur, 2006 ), and particle swarm optimization (PSO) ( Clerc and Kennedy, 2002;
Eberhart and Shi, 2004 ), have arisen as attractive optimization algorithms due to their competitive results.

Biogeography-based optimization (BBO) ( Simon, 2008 )isa new evolutionary algorithm for global optimization that was introduced in 2008. It is modeled after the immigration and emigration of species between habitats. The application of this idea to optimization allows information sharing between candi-date solutions. One distinctive feature of BBO is that the original population is not discarded after each generation. It is rather modified by migration. Another distinctive feature is that, for each generation, BBO uses the fitness of each solution to determine its immigration and emigration rate. BBO has demonstrated good performance on various unconstrained benchmark functions ( Du et al., 2009; Ma et al., 2009; Simon, 2008 ). It has also been applied to real-world optimization problems, including sensor selection ( Simon, 2008 ), power system optimization ( Rarick et al., 2009 ), groundwater detection ( Kundra et al., 2009 ), and satellite image classification ( Panchal et al., 2009 ). See Ref. Gardner and Simon (2009) for a web-based BBO graphical user interface. blended crossover operator of the GA ( M  X  uhlenbein and Schlier-kamp-Voosen, 1993 ) and use it to derive a blended migration operator for BBO. We show that blended BBO generally outper-forms standard BBO on a set of benchmark problems. Second, we generalize BBO to constrained optimization problems. BBO has been used for unconstrained optimization, but up to now there have not been any reports in the literature of its use for constrained optimization. In this paper blended BBO is used for the optimization of constrained benchmark problems.
 of penalty functions. However, penalty functions have several limitations and problems which are difficult to deal with ( Smith and Coit, 1997; Yeniay, 2005 ), including the difficulty of tuning the penalty parameters. We use a recently-developed method for constrained optimization, based on the superiority of feasible solutions over infeasible solutions, proposed by Deb (2000) . Its performance has been demonstrated in Zielinske and Laur (2006) which deals with constraints in differential evolution. In this paper we handle the constraints by modifying the BBO migration procedure between solutions based on their feasibility. reviews the BBO algorithm and proposes blended BBO. Section 3 describes the constraint-handling method for single-objective optimization problems and shows how it can be applied to BBO.
Simulation results and performance analysis of the blended BBO algorithms are presented in Section 4, and conclusions and directions for future investigations are given in Section 5. A preliminary version of this paper was presented in ( Ma and
Simon, 2010 ). 2. Blended biogeography-based optimization (B-BBO)
BBO is a new population-based global optimization algorithm ( Simon, 2008 ). As its name implies, BBO is based on the study of the distribution of species over time and space. This study, which is a subset of biology, is called biogeography ( Lomolino et al., 2009;
Whittaker, 1998 ). Suppose that we have a global optimization problem and a population of candida te solutions (individuals). Each individual is considered to be analogous to a habitat and is characterized by a habitat suitability index (HSI). The value of HSI, which is the same as fitness in other population-based optimization algorithms, and which measures the goodness of the solution, depends on many features of the habitat. A habitat with a high HSI is a good solution, and a habitat with a low HSI is a poor solution.
High-HSI solutions tend to share their features with low-HSI solutions by emigrating solution features to other habitats. Low-
HSI solutions accept a lot of new features from high-HSI solutions by immigration from other habitats. I mmigration and emigration tend to improve the solutions and thus evolve a solution to the optimization problem. Namely, the BBO algorithm views the value of HSI as the objective function, and the evolutionary procedure of
BBO is to determine the solutions which maximize the HSI by immigrating and emigrating featur es of the habitats. In BBO, there are two main operators: migration ( which includes both emigration and immigration) and mutation. Several options can be used for migration and mutation, but one option for implementing migration is described in Section 2.1. We introduce a blended migration mechanism to BBO, which is called blended BBO. One option for implementing the mutation operator is described in Section 2.2. 2.1. Blended migration
In biogeography, migration is the movement of species between different habitats. In BBO, migration is a probabilistic operator that adjusts each solution H i by sharing features between solutions. In the original BBO paper ( Simon, 2008 ), the probability that the solution H i is selected as the immigrating habitat is proportional to its immigration rate l i , and the probability that the solution H j is selected as the emigrating habitat is propor-tional to the emigration rate m j . Migration can be expressed as
H  X  SIV  X   X  H j  X  SIV  X  :  X  1  X 
In biogeography, an SIV is a suitability index variable which characterizes the habitability of a habitat ( Simon, 2008 ); that is, the
HSI is determined by many SIVs. In BBO, an SIV is a solution feature, equivalent to a gene in a GA. In other words, an SIV is a search variable and the set of all possible SIVs is the search space from which an optimal solution will be determined. Eq. (1) means that a solution feature of solution H i is replaced by a feature from solution H
In BBO, each H i has its own immigration rate l i and emigration rate m i . A good solution has relatively high m and low l , while the converse is true for a poor solution. The immigration rate and the emigration rate are functions of the fitness of the solution. They can be calculated as l  X  I 1  X  E where I is the maximum possible immigration rate; E is the maximum possible emigration rate; k ( i ) is the fitness rank of the i th individual (1 is worst and n is best); and n is the number of candidate solutions in the population. I and E are often set equal to 1, or slightly less than 1. Note that this migration function is a linear curve, but in general it might be a more complicated curve.

We propose a new migration operator called blended migra-tion, which is a generalization of the standard BBO migration operator, and which is motivated by blended crossover in GAs. Blended crossover is frequently used in GAs ( M  X  uhlenbein and Schlierkamp-Voosen, 1993 ). In blended crossover, instead of copying a parent X  X  gene to a child chromosome, the offspring are obtained by combining parents X  genes. In blended migration in BBO, a solution feature of solution H i is not simply replaced by a feature from solution H j . Instead, a new solution feature in a BBO solution is comprised of two components: the migration of a feature from another solution, and the migration of a feature from itself. Blended migration is defined as H  X  SIV  X   X  a H i  X  SIV  X  X  X  1 a  X  H j  X  SIV  X  ,  X  3  X  where a is a real number between 0 and 1. It could be random, or deterministic, or it could be proportional to the relative fitness of the solutions H i and H j . Eq. (3) means that the new solution feature (SIV) of H i comes from a combination of its own SIV and the emigrating solution X  X  SIV.

The core idea of the proposed blended migration operator is based on two considerations. First, the operator is easily used with continuous-domain optimization problems. Second, blended combination operators have been widely and successfully used in other population-based optimization algorithms. Blended migration is an attractive BBO modification from a couple of different viewpoints. On the one hand, good solutions will be less likely to be degraded due to migration. On the other hand, poor solutions can still accept a lot of new features from good solutions. That is, if solution H i is much more fit than solution H it would make sense to have a close to 1; but if solution H less fit than the solution H j , it would make sense to have a close to 0. Blended migration is similar to the blended crossover approach of the breeder GA ( M  X  uhlenbein and Schlierkamp-Voosen, 1993 ) and ES ( McTavish and Restrepo, 2008 ) in which both of the parents can contribute characteristics to a single feature of an offspring. 2.2. Mutation
Mutation is a probabilistic operator that randomly modifies a solution X  X  SIV based on its a priori probability of existence. Namely, a randomly generated SIV replaces a selected SIV in the solution H i according to a mutation probability. Although mutation is not the most important factor in BBO, the improve-ment of solutions is obtained by perturbing the solution after the migration operation. For classic BBO, the mutation probability is inversely proportional to the solution probability ( Simon, 2008 ), and is defined by m where m max is the user-defined maximum mutation probability, P max  X  argmax P i , i  X  1, y , n ( n is population size), and P solution probability. For more details see Simon (2008) .This mutation scheme tends to increase d iversity among the population.
The BBO algorithm, generalized for blended migration, is shown in Fig. 1 .If a  X  0in Fig. 1 , then we have the standard BBO algorithm. If a is random, or is proportional to relative solution fitnesses, then we have blended BBO. 3. Constrained optimization
Constrained optimization problems frequently arise in every field of science, engineering, and industry. Without loss of generality, the single-objective constrained optimization problem can be formalized as follows: find x to minimize f  X  x  X  such that g i  X  x  X  r 0 for i  X  1 , ... , q where x  X  ( x 1 , x 2 , y , x n ) is the vector of decision variables and each x i is bounded by lower and upper limits ( L i r x i of all decision variables which satisfy the constraints of the problem is called the feasible region. q is the number of inequality constraints and m q is the number of equality constraints. Note that constraints could be linear or nonlinear. The objective of an optimization algorithm is to minimize the cost function f ( x ), while at the same time satisfying the constraints g i ( x ) and h the various constraint-handling methods, the use of penalty functions is the most common technique ( Smith and Coit, 1997 ).
In this paper we incorporate into BBO a method for constraint-handling that is based on feasibility rules ( Deb, 2000 ), which have demonstrated promising performance in dealing with constraints.
We incorporate this constraint-handling technique into our blended BBO algorithm as described below.

During the migration procedure, each candidate solution has been modified. We then check each solution to see if it is better than the solution of its original version (i.e., its version before migration). The modified solution will enter the population of the next generation only if it is better than its previous version, otherwise the previous solution will enter the population of the next generation. Note that this is similar to a ( m + l ) ES where the next generation comes from both parents and children. compared to a candidate solution H 2 , solution H 1 is considered better if: 1) both solutions are feasible, but H 1 has a cost that is less than or 2) H 1 is feasible and H 2 is not; or, 3) both solutions are infeasible, but H 1 has a smaller overall that are required for unconstrained problems are needed for this constraint-handling technique. For unconstrained problems, this method is identical to the original unconstrained BBO algorithm. 4. Simulation results based on the constraint-handling approach discussed above. A representative set of benchmark functions with constraints, including linear, nonlinear, and polynomial constraints, have been used for performance verification of the proposed approach.
These functions are briefly summarized in Table 1 . A more detailed description of these functions can be found in the literature Liang et al. (2005) . 4.1. Blended BBO performance blended BBO (which we call B-BBO) to solve the constrained benchmark functions. The aim of this experiment is to inves-tigate how BBO solves constrained problems and how blended migration affects BBO optimization performance for constrained problems. For both BBO methods, the following parameters have to be examined: number of habitats (population size), maximum migration rates, mutation rate, and migration curve shapes. In Ma (2010) these parameters have been discussed in detailed, and we have obtained a reasonable set of tuning parameters. So we have not made any effort in finding the best parameter settings in this paper. For this experiment, the parameters used in the two methods are the same, which are recommended as follows: population size of 50, maximum immigration rate and maximum emigration rate of 1, and maximum mutation rate of 0.01. In addition, we use linear migration curves as suggested in Simon (2008) . For maximum number of fitness function evaluations (Max_NFFEs), we use 50,000.

Moreover, in our experiments, each function is optimized over 25 independent runs. We also use the same set of 25 initial random populations to evaluate the algorithms, and we set the parameter a  X  0, 0.5, or 0.8 in Eq. (3) to investigate its influence on B-BBO performance (when a  X  0, B-BBO reduces to standard BBO).
In addition, we mention that in the original BBO paper a discrete version of BBO was used to minimize benchmark functions. In this paper we adopt a continuous version of BBO. Beside the best, mean, and worst value of benchmark functions, two performance criteria are selected from the literature ( Liang et al., 2005 )to evaluate the performance of the algorithms. 1) Number of feasible runs (NF): The number of feasible runs is the number of runs during which at least one feasible solution is found before the Max_NFFEs condition terminates the run. 2) Number of successful runs (NS): The number of successful runs is the number of runs during which the algorithm finds a feasible solution x satisfying f ( x ) f ( x n ) r 0.0001 before the Max_NFFEs condition terminates the run.

In addition, in order to conclude that one method is  X  X  X etter X  X  than another, we consider all three performance criteria. 1) If the algorithm has a higher NS than another, then it is better. 2) If two algorithms have the same NS, then the one with the higher NF is better. 3) If two algorithms have the same NS and NF, then the one with mean objective function value closer to the best known solution is better.

Tables 2 and 3 summarize the B-BBO performance on the constrained benchmark functions. We observe that, for most of the functions, B-BBO with three different values of a gives good performance except function g20, g21, and g22, for which no feasible solution at all could be found. For 9 (g01, g02, g03, g05, g06, g08, g09, g16, g17) of the 24 functions, B-BBO ( a  X  0.5) has a higher NS than BBO ( a  X  0) and B-BBO ( a  X  0.8). For 3 functions (g10, g15, g23), the three algorithms have the same NS, but B-BBO ( a  X  0.5) has the higher NF. For 3 functions (g11, g18, g24), they all have the same NS and NF, but B-BBO ( a  X  0.5) has the mean values closer to the best known solutions.
 In summary, B-BBO ( a  X  0.5) performs the best on 15 functions, B-BBO ( a  X  0.8) performs the best on 3 functions (g07, g12, g19), and BBO ( a  X  0) performs the best for 1 function (g13). For function g14, all three algorithms attain the global optimum every run, and for function g04, both B-BBO ( a  X  0.5) and B-BBO ( a  X  0.8) attain the global optimum every run.

From Table 3 we also obtain statistically significant differences of two pairs of BBOs (BBO ( a  X  0) vs. B-BBO ( a  X  0.5), and BBO ( a  X  0) vs. B-BBO ( a  X  0.8)) based on the p value, which is the probability that the two sets of data come from the same distribution. From p value comparison between BBO ( a  X  0) vs. B-BBO ( a  X  0.5), and BBO ( a  X  0) vs. B-BBO ( a  X  0.8), we find that there are fourteen p values smaller than 0.05 (which is often used as the significance level or critical p value) for BBO ( a  X  0) vs. B-BBO ( a  X  0.5), and there are thirteen p values smaller than 0.05 for BBO ( a  X  0) vs. B-BBO ( a  X  0.8). Based on this result, the probability that the results of BBO ( a  X  0), B-BBO ( a  X  0.5), and B-BBO ( a  X  0.8) are from the same distribution is low. It indicates that the value of a is influential on BBO performance. B-BBO with a 4 0 generally outperforms BBO ( a  X  0), which means that blended migration can significantly improve the optimization ability of BBO. Also, B-BBO ( a  X  0.5) is better than B-BBO ( a  X  0.8) which indicates that when a new solution feature is contributed equally from itself and the selected emigrating solution, B-BBO performs best. Lastly, we note that the successfully optimized benchmark functions include quadratic, cubic, nonlinear, polynomial, and linear objective functions, thus the type of objective function is not of importance for successful optimization for B-BBO. 4.2. Comparison between BBO and other EAs
The next experiment compares BBO against other popular evolutionary algorithms. We choose to compare the proposed B-BBO with stud GA (which we call SGA) ( Khatib and Fleming, 1998 ) and standard PSO 2007. We compare with an SGA because the SGA is an improvement of the classic GA which uses the best individual at each generation for crossover. We compare with PSO because it often offers good performance and is itself a relatively new evolutionary algorithm. We use the current standard PSO (SPSO 07) ( Bratton and Kennedy, 2007 ), obtainable from Particle Swarm Central ( Particle Swarm Central ). Here, the proposed constraint-handling method is adopted in an identical way, as described in Section 3, for B-BBO, SGA, and SPSO 07.

The parameters used in B-BBO are the same as those described in the previous section, and a  X  0.5. For the SGA we use real coding, roulette wheel selection, single point crossover with a crossover probability of 1, and random mutation with a mutation probability of 0.01. For SPSO 07, we use an inertia weight of 0.8, a cognitive constant of 0.5, a social constant for swarm interaction of 1.0, and a social constant for neighborhood interaction of 1.0.
Each algorithm has a population size of 50, and a maximum number of fitness function evaluations (Max_NFFEs) of 50,000.
The results of solving the 24 constrained benchmark functions are given in Tables 4 and 5 . All numbers are computed from 25 independent runs.

Tables 4 and 5 show the performance comparison on 24 constrained benchmark functions for B-BBO, SGA, and SPSO 07.
We see that for functions g08, g11, g14, and g24, all three algorithms attain the global optimum, but for functions g20, g21, and g22 no feasible solution could be found by any of the algorithms. According to Tables 4 and 5 and the criteria discussed in Section 4.1, B-BBO performs the best on 7 of the 24 benchmark functions, SGA performs the best on 2 functions, and SPSO 07 performs the best on 7 functions. The algorithms tied on the rest of the functions. The results indicate that B-BBO is significantly better than SGA, and performs similarly to SPSO 07. If we adopt more state-of-the-art PSO and GA, they could probably perform better than the results shown here ( Clerc and Kennedy, 2002; Eberhart and Shi, 2004; Zielinske and Laur, 2006 ). However, the same could be said for recently proposed improvements for BBO ( Du et al., 2009; Ergezer et al., 2009 ), and the purpose of these comparisons is to show that BBO is a competitive algorithm for solving constrained optimization problems.
 functions (g08, g11, g12, g24) for which all 25 runs found the minimum have a rather low dimensionality of 2 or 3, with the exception being g14, for which the dimensionality is 10. We also see that the dimensionality of 2 of the functions (g20 and g22) with no successful runs is large ( D Z 20). We see that high dimensionality presents difficulties for EAs.

From Tables 4 and 5 , we further find that the number of constraints for successfully optimized functions (g08, g11, g12, g14, g24) is mostly rather small, with the exception of g16, which contains 38 inequality constraints, and g18, which includes 13 inequality constraints. Therefore, it appears that the number of inequality constraints does not create difficulties for EAs in general.

For functions with a high number of equality constraints (g20 and g22) particularly bad results are obtained: neither a feasible run nor a successful run were accomplished for any of the three algorithms. The function with the next highest number of equality constraints is g21, for which neither a feasible run nor a successful run were accomplished. Therefore, it is concluded that a high number of equality constraints provides a challenge for the three algorithms.

Based on the above results, it appears that the dimensionality of the function and the number of equality constraints create difficulties for EAs, at least for the three algorithms applied here.
Average convergence graphs are shown in Fig. 2 . We see that for most of the benchmark functions considered in this paper, B-BBO, SGA, and SPSO 07 all converge fast and obtain good performance. Note that for some of the graphs, we use a logarithmic scale for the x -axis or y -axis to distinguish the results of the three algorithms. 5. Conclusion
In this paper, we have generalized biogeography-based optimization (BBO) to handle single-objective optimization problems with multiple constraints. Instead of using penalty functions for constraint-handling, we used a method based on Deb X  X  feasibility rules, which does not introduce any additional tuning parameters beyond those required for unconstrained optimization. In addition, we introduced a blended migration operator to BBO to obtain B-BBO, which is motivated by the blended crossover operator in GAs. The experiments that we performed: (1) verify that BBO is a competitive algorithm for solving constrained optimization problems; (2) show that blended migration further improves BBO X  X  performance; (3) show that the parameter a can affect B-BBO X  X  optimization ability; and (4) show that BBO can solve constrained optimization problems better than SGA and similar to SPSO 07 for the benchmark problems that we investigated.
 We do not consider computational cost in this paper.

According to the literature ( Mezura-Montes and Coello, 2005 ), 3/4 of the computational cost of evolutionary search is typically consumed by the fitness function evaluation, and only 1/4 (often less) is consumed by the search process. The mechanism of BBO is simple, like that of GAs and PSO, therefore, the computational cost of BBO and other EAs will be the same since it will be dominated by the difficulty of the landscape of the constrained objective function.
 make a clear distinction between feasible and infeasible solutions, to solve the constrained problems. This approach indicates that a feasible solution is always preferred over an infeasible solution. In reality, a marginally infeasible solution with a good objective g02 g05 g08
NFFEs 10 2 10 3 10 4
NFFEs 10 2 10 3 10 4
NFFEs NFFEs 10 2 10 3 10 4
NFFEs 10 2 10 3 10 4 value could be preferred over a feasible solution with a poor function value ( Wang et al., 2008 ). Solutions to contrained optimization problems are likely to lie on constraint boundaries, and hence preferring a marginally feasible solution could be beneficial. For future work, we will investigate the application of more advanced constrained solution methods in BBO, such as the adaptive tradeoff model ( Wang et al., 2008 ), to balance feasible and infeasible solutions.

BBO presents promising potential but still requires additional theoretical and empirical investigation. For future work, we can further tune the migration operator as inspired by other aspects of biogeography. For example, it has been shown that sigmoid migration curves like those found in nature, rather than the simple linear ones explored in this paper, generally give better
BBO performance ( Ma, 2010 ). It remains to be seen how this and other migration curve changes will affect constrained BBO performance. We intend to explore BBO for real-world con-strained optimization problems. In this paper, 24 benchmark functions have been presented, including quadratic, cubic, non-linear, polynomial, and linear functions. It is a challenge for any algorithm to scale to high-dimension problems, so the exploration of BBO for high-dimension real-world constrained optimization problems is an area for future work. Another area for future work is the development of theoretical results relating to blended migration, and constrained BBO convergence. Some theoretical work for unconstrained BBO has been performed using Markov theory ( Simon et al., 2009 ), but it remains to be seen if that approach, or if other approaches, can give fruitful theoretical results for B-BBO or for constrained BBO. The use of oppositional learning has been incorporated into unconstrained BBO to yield oppositional BBO (OBBO) ( Ergezer et al., 2009 ). Future work could see how OBBO could be modified to solve constrained optimiza-tion problems, or how oppositional learning could be incorpo-rated into the BBO extensions proposed in this paper. Acknowledgment This work was partially supported by the Zhejiang Provincial Natural Science Foundation of China under Grant no. Y1090866, and by Grant 0826124 in the CMMI Division of the Engineering Directorate of the National Science Foundation. NFFEs g14 g17 g23
NFFEs 10
NFFEs 10 References
