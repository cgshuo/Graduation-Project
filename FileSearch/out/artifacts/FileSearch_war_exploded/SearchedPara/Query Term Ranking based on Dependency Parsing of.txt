 Query term ranking approaches are used to select effective terms from a verbose query by ranking terms. Features used for query term ranking and selection in previous work do not consider grammatical relationships between terms. To ad-dress this issue, we use syntactic features extracted from de-pendency parsing results of verbose queries. We also modify the method for measuring the effectiveness of query terms for query term ranking.
 H.3.3 [ Information Search and Retrieval ]: Query for-mulation Algorithm, Experimentation, Performance Dependency Parse, Query Reformulation, Query Term Rank-ing
Most search engines have a tendency to show better re-trieval results with keyword queries than with verbose queries. Verbose queries tend to contain more redundant terms and these terms have grammatical meaning for communication between humans to help identify the important concepts.. Search engines do not typically use syntactic information.. For example, given a verbose query,  X  X dentify positive accom-plishments of the Hubble telescope since it was launched ... X  , search engines cannot recognize that  X  X ubble telescope X  is the key concept of the query whereas  X  X ccomplishments X  should be considered as a complementary concept, while people can readily identify this by analyzing the grammatical structure of the query. Therefore, search engines potentially need a method for exploiting this structure.

In this work, we rank terms in a verbose query and re-formulate a new query using selected highly ranked terms. Good selection methods should be able to leverage the gram-matical roles of terms within a query. To do this, we use syntactic features extracted from dependency parsing trees of queries. In addition, we suggest a new method for mea-suring the effectiveness of terms for query term ranking. have a reliable amount of training data and not all of them are useful. We generalize syntactic features which consist of arcs labeled with dependency types and nodes representing words which are dependent. Figure 2 shows an example of an original syntactic feature and its generalized features. In the figure,  X * X  means any word or any type of dependency.
Our approach aims to rank terms in a query and to re-formulate the query using the ranking. To build training data for a ranking model, Bendersky and Croft [1] manually annotate the concept from each query that had the most impact on effectiveness. For given terms  X  = {  X  1 ,  X  2 , ...,  X   X  } , they used labeled instances (  X   X  ,  X   X  ), where  X   X  is a binary la-bel, as training data. However, queries can have more than one effective term or concept. In addition, it is difficult for annotators to judge the effectiveness of a term. Therefore, we estimate the effectiveness of terms, i.e., the labels for training data, by evaluating the search results of terms in training data. By using these estimated scores, we expect that a ranking model can take account of all terms in a query and consider how effective they are.

Lee et al. [6] point out the importance of underlying cor-relations between terms. Previous work has evaluated the effectiveness of groups of terms instead of individual terms to capture these relationships [5, 6]. The problem is that the number of unique groups will grow exponentially with the size of the term groups and it will cause a data sparse-ness problem. We used the following equation for  X  (  X  ), the effectiveness of a term to reflect the effects of relationships between terms in training labels. where  X   X  is all possible combinations of m terms except  X  . N is the number of elements in  X   X  and  X  (  X  ) is the search performance of  X  . Eq. (1) estimates the effectiveness of term  X  through aggregating the impacts of term  X  on effectiveness when using it with other terms in  X   X  . Thus, the scores of Eq. (1) reflects the correlations between  X  and other terms.
We evaluated our proposed method using two TREC col-lections: Robust 2004 (topic numbers are 301-450 and 601-700) and Wt10g (topic numbers are 450-550). The aver-age number of nouns, adjectives and verbs in queries of Ro-bust2004 and Wt10g are 8.7 and 6.5 per a query, respec-tively. We used the language model framework with Dirich-let smoothing (  X  set to 1,500). Indexing and retrieval were conducted using the Indri toolkit.

To rank query terms, we used RankSVM [4]. We trained query term ranking models for each query using leave-one-out cross-validation in which one query was used for test data and the others were used for training data. We labeled training data based on Key concepts [1] and the effectiveness measured by Eq. 1 in which we chose nDCG as the perfor-mance measure. We used syntactic features in addition to tf, idf, and PoS tag features.

When we combined selected terms with original queries, we used two approaches. First, we assigned uniform weights to selected terms ( binary ). Alternatively, we used query term ranking scores as the weight for selected terms ( weight ).
