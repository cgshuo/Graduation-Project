 The paper proposes a novel approach to appropriately pro-mote those items with few ratings in collaborative filtering. Different from previous works, we force the items with few ratings to be promoted to the users who would potentially be able to give ratings, and then leverage the gathered user preference to punish the promoted items with low quality intrinsically. By slightly sacrificing the benefit of recom-mending the best items in terms of user satisfaction, our approach seeks to provide all of the items with a chance to be visible equally. The results of the experiments conducted on MovieLens and Netflix data demonstrate its feasibility.  X  Information systems  X  Recommender systems; Item Exposure; Novelty; Collaborative Filtering
Collaborative Filtering (CF) is a well-known technique to predict user preference by identifying similar preferences shared by collaborating users (user-based CF) or similar items of interest to the same users (item-based CF). As only popular items are able to collect sufficient rating data and then be recommended more frequently, CF-based solutions often face the problem of monopoly : popular items will be-come more popular while unknown items (those coming with few ratings) will have less and less chance to get noticed.
Numerous studies on CF have investigated the effect of item popularity on user preference [7]. Oh et al. [4] found the phenomenon of personal popularity tendency. Their so-lution tended not to promote popular items to those who preferred relatively obscure items. Liu et al. [3] showed that pushing new items to inactive users could statistically increase the chance of new items to be recommended. Some studies concerned about items with less training data and attempted to save such items. In [8, 9], Steck managed to fix recommendation biases against unpopular items, where items with less training ratings were treated as a result of non-randomly missing data. Park et al. [5] clustered un-known items and recommended them based on their clusters. There have also been studies trying to solve the cold-start problem by considering additional content-based features [6] and latent aspects [1].

Although various methods have been developed to recom-mend unknown items, less investigations paid attention to the integration of item exposure with user preference as a critical determinant of recommendation and balanced the trade-off between them in CF. Here item exposure is defined as the number of ratings an item gets. Unknown items are the items with low exposure. More exposure does not always lead to higher popularity. But more exposure does help us to determine the true quality of unknown items. It moti-vates us to investigate the possibility of forcing unknown items in the user X  X  recommended pool in the beginning as a fair treatment. If the promoted unknown item is potentially good enough, it will become popular soon. Our risk is to promote the unknown items that have low quality intrinsi-cally. In this case, the users would rate them low and prevent them from popularity. Promoting bad unknown items can then be balanced by leveraging user preference.

The goal of this paper is to appropriately promote un-known items by carefully integrating item exposure with user preference in CF. To put user preference and item ex-posure together, we define Recommendation Value (RV) to be how much a system would like to recommend an item to a user. A novel approach is proposed. First, the RVs are moved towards user preference (similar to conventional CF). Secondly, the RVs are appropriately elevated for unknown items, where two main challenges will be encountered: (1) how to balance the trade-off between recommending prefer-able items and unknown items, and (2) how to determine to which users to promote a given unknown item (not all of the users would agree to provide ratings for any items requested by the system). The approach is designed to pro-mote an unknown item to appropriate users until it gets suf-ficient reliable ratings. We have conducted the experiments on MovieLens and Netflix data. The result demonstrates that the proposed approach outperforms state-of-the-art CF solutions in maximizing the exposure-stratified recall.
T he task of a recommendation system is to provide a user with a ranking list of items. Given a set of users U = { u 1 , u 2 , ..., u | U | } and items I = { i 1 , i 2 served rating of user u for item i , denoted r obs u,i , is an actual rating collected from training data. Unrated user-item pairs are called unobserved . For each of the unobserved user-item pairs, the system generates a RV, denoted RV ( u, i )  X  [0 , 1], to indicate how much the system would like to recommend item i to user u . For each user u , the system sorts the RVs of all items unobserved by u , denoted I  X  u  X  I , and recommends the top-k highest RVs, denoted I  X  ,k u  X  I  X  u . The RV of an unobserved user-item pair is defined as: where P p ( i | u ) is preference probability indicating the probability that user u prefers item i . P r ( i | u ) is rating probability indicating the probability that user u would rate item i .  X  ( i ) is the coefficient indicating the condition of being unknown. It varies from 0 to 1. A larger  X  ( i ) value means the lower exposure for item i . That is,  X  ( i ) = 1 if item i is totally unknown. Initially, the RV moves towards user preference P p ( i | u ), i.e., the first term. For unknown items, the RV is appropriately elevated. The remainder 1  X  P p ( i | u ) is added according to how likely user u will provide a rating for item i , i.e., P r ( i | u ). In other words, the RV is augmented only when the unknown item (big  X  ( i )) has a low predicted preference (small P p ( i | u )) and user u has more chance to rate item i (high P r ( i | u )). If it is not the case, the second term approaches to 0.
 P p ( i | u ) is computed based on user preference as follows: where we learn to predict user preference with Matrix Fac-torization (MF). r u,i for unobserved ( u, i ) is computed as the dot product of corresponding user and item vectors.  X   X  R is the exponent that controls the discrimination between high and low ratings. For  X  &gt; 1, the distance between high and low ratings is strengthened. By this transformation, the preference probability is restricted to the range [0 , 1]. The MF-based method proposed in [2] only uses the ob-served data for predicting the preference probability (called MF-preference). Except the MF, we also consider AllRank (AR) [8], which uses the observed data and models the un-observed data, to predict the preference probability (called AF-preference) as an alternative.

To calculate P r ( i | u ), we extend the probability model pre-sented in [1]. The probability of user u to rate item i can be factorized as: where z is the random variable for a latent topic or aspect. The parameters are learned by the EM algorithm as follows. E-step: M-step: where 1 ( . ) is the indicator function outputting 1 if user u rates item i and 0 otherwise. To this end, given user u , the rating probability P r ( i | u ) for item i is computed as: There is an explicit drawback due to the nature of EM. The EM process learns the probability from the observed data so that the probability of unknown items would be underestimated owing to the lack of observed ratings. To solve this issue, we assign a prior to each item when updating P ( i | z ) in Eq.(6) as follows: where s ( . ) is a weighted indicator function and defined as: where N obs i denotes the number of users rating item i in the training data.  X  s determines the discriminative power of the weight (  X  s = 0 leads to identical weight of each rated item).
Alternatively, there are also other choices able to form the rating probability such as the preference probabilities ob-tained from Eq.(2) using MF-preference and AR-preference. The underlying assumption is that a user tends to rate her preferable items. All the choices will be evaluated in the experiments.

In some sense, given an unknown item whose rating prob-ability is equal to the preference probability for a well-known item, the unknown item generally has higher priority to be recommended. The details of the proof are omitted here.
To identify whether an item is unknown, we define expo-sure as the number of users rating this item. In this paper, function  X  ( i ) is simply estimated by a sigmoid function as follows: where N unk is the exposure threshold of unknownness.
To avoid that the recommended pool is full of unknown items, we limit the number of unknown items for each user to a predefined value. Overall, as an unknown item i comes in, no matter how the predicted preference for item i is, the preference predicted based on unreliable, few ratings of item i is regarded as untrusted. The RV of item i can, therefore, be updated due to its low exposure (i.e., big  X  ( i )), especially for users who may rate it (i.e., high P r ( i | u )). There may be a great number of unknown items competing. If item i fails to be promoted, it waits for the next round. If its RV is en-riched by update enough, item i will be promoted and earn more exposure. As the exposure grows, its priority of promo-tion is eventually removed (i.e., small  X  ( i )). Other unknown items which failed previously will have more chance to get promoted in the next iteration.
