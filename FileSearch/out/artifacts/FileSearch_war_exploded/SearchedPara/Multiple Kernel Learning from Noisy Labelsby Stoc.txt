 Tianbao Yang  X  yangtia1@msu.edu Mehrdad Mahdavi  X  mahdavim@msu.edu Rong Jin  X  rongjin@msu.edu Lijun Zhang  X  zljzju@zju.edu.cn Yang Zhou  X  young.zhou@gmail.com Yahoo Labs!, Santa Clara, CA 95054, USA Multiple Kernel Learning (MKL) ( Lanckriet et al. , 2004 ) has attracted a significant amount of in-terest in both machine learning and data mining communities due to the success of kernel meth-ods ( Sch  X olkopf &amp; Smola , 2001 ). MKL aims to learn an optimal combination of multiple kernels and a non-linear classifier from the Reproducing Kernel Hilbert Space (RKHS) endowed with the combined kernel. Most of the previous studies on MKL has focused on designing efficient algorithms for solving the related optimization problem. Research has also been done to study the effect of different regularizers on the combi-nation of multiple kernels, including sparse regularizer  X  1 norm, non-sparse regularizer  X  2 norm, and in gen-eral  X  p norm. One limitation of these studies is that they all assume perfectly labeled training examples, which significantly limits their application to problems where class assignments are often noisy and inaccu-rate. Noisy class assignments could arise either from the biases of human subjects or because the class la-bels are automatically derived from side information (e.g., hyperlink information ( Yang et al. , 2010 )). In this work, we address this limitation by casting MKL from noisy labels into a stochastic programming problem ( Kall &amp; Wallace , 1994 ). The key idea is to introduce a binary random variable for each train-ing example to indicate if the class assignment of the example is correct. Using introduced binary ran-dom variables, we turn the deterministic constraint in MKL into a chance constraint ( Ben-Tal et al. , 2009 ), leading to a stochastic programming formulation 1 . By assuming that the percentage of incorrectly la-beled training examples is given, we approximate the stochastic programming problem into a convex-concave optimization problem. Unlike many previous Yang et al. , 2010 ) on learning with noisy labeled data that make strong assumptions about the noise model (e.g. conditional independence assumption between noisy label and the data given the true label), our framework depends only on a mild assumption about the noise (see section 3.2 ), making it practically more useful. Notably, we do NOT assume the label noise of different examples are independent, a common as-sumption shared by most existing studies on learn-ing from noisy labels ( Biggio et al. , 2011 ; Yang et al. , 2010 ). Based on the mirror prox method ( Nemirovski , 2005 ), we develop a first order method for solving the related convex-concave optimization problem. Our analysis shows the convergence rate of O (1 /T ) for the proposed algorithm, significantly faster than the classi-cal O (1 / sets confirm the effectiveness and the efficiency of the proposed framework and the optimization algorithm. Our work is closely related to MKL. Various cri-teria have been developed to find the optimal ker-nel combination, such as maximum classification margin ( Lanckriet et al. , 2004 ) and kernel align-ment ( Cristianini et al. , 2002 ; Cortes et al. , 2010a ). Among them, maximum margin MKL receives most attention due to its empirical success and its close relationship with Support Vector Machines (SVMs). Many algorithms have been developed for max-margin MKL by formulating the problem into Semi-Definite Programming ( Lanckriet et al. , 2004 ), Sec-ond Order Cone Programming ( Bach et al. , 2004 ), and Semi-Infinite Linear Programming ( Sonnenburg et al. , 2006 ). Due to their high computational cost, these approaches are unable to handle large data sets and a large number of kernels. A number of effi-cient algorithms, based on alternating optimization, have been proposed for MKL ( Rakotomamonjy et al. , 2008 ; Xu et al. , 2010 ). Besides efficient learning algorithms, various regularizers have been studied for MKL, including  X  1 norm ( Rakotomamonjy et al. , 2008 ; Xu et al. , 2010 ),  X  2 norm ( Cortes et al. , 2009 ), and  X  p norm ( Kloft et al. , 2009 ).
 Our work is also related to learning with noisy labels. Lawrence &amp; Sch  X olkopf ( 2001 ) propose a probabilistic model for learning a kernel Fisher Discriminant from noisy labels. Pal et al. ( 2007 ) present a probabilistic model for extracting location information for events with noisy training labels. Ramakrishnan et al. ( 2005 ) propose a Bayeisan model for learning with approxi-mate, noisy or incomplete labels. Yang et al. ( 2010 ) propose a generalized maximum entropy model for learning from noisy side information. These proba-bilistic approaches have to make strong assumptions about label noise, which significantly limit their ap-plications to real-world problems. In addition, it is difficult to adapt them to MKL. Several recent stud-ies ( Huang et al. , 2010 ) address the limitation of prob-abilistic approaches by exploring the robust optimiza-tion ( Ben-Tal et al. , 2009 ). Our study is particularly related to the recent work on robust SVM ( Xu et al. , 2006 ; Yu et al. , 2011 ) in which a SVM classifier is learned in the presence of outliers. Our work differs from these studies in two aspects. First, we address a different learning problem (i.e., MKL from noisy la-bels). Second, our work is based on stochastic pro-gramming that makes least possible assumption about the noise model compared to the other approaches. We first review a formulation of MKL based on the equivalence between MKL and group Lasso ( Xu et al. , 2010 ; Bach , 2008 ). We then describe the problem of MKL from noisy labels and present a stochastic programming framework to formulate it. Finally, we present an efficient algorithm for solving the related convex-concave optimization problem. 3.1. Multiple Kernel Learning (MKL) Let D = { ( x i , y i ) , i = 1 , , n } be the training data, where x i  X  R d denotes the i th instance and y i  X  { X  1 , 1 } denotes its binary label. We use y = ( y 1 , , y n )  X  to represent the class assignment of all training examples. We denote by {  X  j ( , ) : R d  X  R d 7 X  R , j  X  [ m ] } the set of m kernels to be combined, and by H  X  Hilbert Space (RKHS) endowed by  X  j . We use u = ( u 1 , , u m )  X  for the combination weights of multiple kernels,  X  u = H  X  u for the RKHS endowed by  X  u . In this work, we consider u  X   X , where  X  = { u  X  R m + : a simplex. MKL can be cast as the following problem: where  X  ( z ) = max(0 , 1  X  z ) is the hinge loss function. It has been shown that the problem in ( 1 ) is equivalent to the following problem ( Micchelli &amp; Pontil , 2005 ), min or equivalently where f j belongs to H  X  be optimized. Given the solutions f j , j  X  [ m ] to ( 3 ), the final classifier is defined as f ( x ) = the sequel, we use the notation f ( x ) = simplify our presentation. Our formulation for MKL from noisy labels is based on the formulation in ( 3 ). In the next subsection, we present a stochastic program-ming framework for MKL from noisy labels. Due to the limit of space, we put the proofs of most analysis in the supplementary material. 3.2. A Stochastic Programming Framework for In the case of noisy labels, we have some incorrect class assignments for the training examples in D . The key challenge is that we do not know which examples are incorrectly labeled. To facilitate learning from noisy labels, we assume the noise level of class assignments q  X  [0 , 1 / 2), i.e., the expected probability for any ran-domly chosen example to be incorrectly labeled, is given.
 random variable indicating if y is a correct label of x (1) or not (0), and p ( x , y ) = E  X  | ( probability for y to be a correct label of x . Assumption 1. The noise level q is given, i.e., With Assumption 1 , we present the following propo-sition to bound the empirical mean of p ( x , y ) on the training examples.
 Proposition 1. Let  X  i , i  X  [ n ] denote the binary indi-cator variable of noise on the training examples, and p = E[  X  i ] . Given the noise level q , with probability at least 1  X   X  , we have where  X  = The proposition follows directly from the Hoeffding X  X  inequality ( Boucheron et al. , 2004 ).
 To handle the noisy labels, we consider a stochas-tic programming ( Kall &amp; Wallace , 1994 ) framework. More specifically, given the unknown random vari-ables  X  = (  X  1 , . . . ,  X  n ), where  X  i =  X  ( x i , y i the deterministic constraint in ( 4 ) into a chance con-straint ( Ben-Tal et al. , 2009 ) where Pr( ) takes over the unknown joint distribution of binary random variables  X  , and  X   X  (0 , 1) bounds the probability for the constraint in ( 3 ) to be vio-lated. The chance constraint in ( 5 ) requires that there is only a small chance for the constraint to be vio-lated by the unknown correctly labeled examples. It has also been used for handling the uncertainty be-fore. In ( Bhadra et al. , 2010 ), the authors introduce the chance constraints to handle the uncertainty in the elements of a kernel matrix, while the chance con-straint in ( 5 ) is introduced to handle the uncertainty in the class labels.
 Using the chance constraint in ( 5 ), we have the follow-ing stochastic programming problem for MKL from noisy labels: A major challenge of solving the stochastic program-ming problem in ( 6 ) is that the joint distribution for  X  is unknown. The following lemma allows us to alle-viate this challenge.
 Lemma 1. If the following inequality holds, 1 n where  X  = in ( 5 ) is satisfied.
 The proof follows immediately from the McDiarmid inequality ( Boucheron et al. , 2004 ). It is important to note that Lemma 1 holds WITHOUT having to assume that the binary random variables {  X  i } m i =1 are independent, a common assumption that appears in almost all the studies on learning from noisy labels. Using Lemma 1 , we relax the problem in ( 6 ) into the following optimization problem s.t. where p i denotes E[  X  i ]. We can turn the constrained problem into non-constrained problem by replacing t in ( 7 ) with the lower bound in ( 8 ). There are two problems with directly optimizing ( 7 ). First, the sec-ond term in the lower bound of t in ( 8 ) is square-root of a quadratic form on the training loss, making the optimization problem difficult to solve. Second, the variables { p i } n i =1 are unknown. Without knowing the tion problem in ( 7 ).
 To address the first problem, we use the inequality p P into Note that inequality ( 9 ) indicates inequality ( 8 ), and therefore guarantees that the chance constraint in ( 5 ) holds. Then we turn problem ( 7 ) into or equivalently min To address the second problem, we propose the follow-ing minimax formulation min where Q = { p  X  [0 , 1] n , domain for p justified by Proposition 1 .
 Remark: We choose to maximize over p  X  Q be-cause it guarantees that the loss of any choice of cor-rectly labeled examples is minimized. The idea of us-ing the worst case analysis is closely related to robust optimization ( Ben-Tal et al. , 2009 ), which has been adopted by several recent studies, including budget SVM ( Dekel &amp; Singer , 2006 ), and robust metric learn-ing ( Huang et al. , 2010 ). Note that an alternative ap-proach is to consider the best case analysis (a strategy taken in robust SVM ( Xu et al. , 2006 ; Yu et al. , 2011 )) by minimizing the robust hinge loss, which can be de-fined as min p  X  X  loss on i th example, to address the uncertainty arising from noisy labels.
 There are several problems with the alternative ap-proach. First, minimization over p will lead to a non-convex optimization problem, as shown in ( Xu et al. , 2006 ), making it difficult, if not impossible, to develop an efficient learning algorithm to find the global op-timum. Second, unless a strong assumption is made about the examples with incorrect labels, minimiza-tion over p will not provide any guarantee about the generalized performance of the resulting classifier. Third, the formulation with minimization over p does not reduce to the normal case in ( 2 ) when there is no noise.
 In contrast, our problem is a convex-concave problem, which allows us to derive an efficient optimization al-gorithm to solve it. Also, we do NOT make any as-sumption on the noisy labels except assuming that the noise level is given. More ever, the generalization er-ror of the kernel classifier learned from ( 10 ) is given in Theorem 1, which also justifies the maximization over p . Finally, it is straightforward to show that our for-mulation in ( 10 ) reduces to ( 2 ) when there is no noise. This point is also demonstrated by our empirical stud-ies.
 Theorem 1. Assume that the number of incorrectly labeled instances in D is no more than nq. Let f , j  X  [ m ] be the final solutions to ( 10 ) and set f ( x ) = we have Remark: The bound scales with 1 / (1  X  q ), so when the noise level q is large, the generalization bound is also large. Additionally, we can see that with a proba-bility (1  X  m  X  k ), where k is an integer, the generaliza-tion error bound has an additional term of which is a tight bound for  X  1 -regularized MKL in terms of the number of kernels ( Ying &amp; Campbell , 2009 ; Cortes et al. , 2010b ). 3.3. An Efficient Optimization Algorithm In this section, we present an efficient algorithm for solving the minimax problem in ( 10 ). We first present an alternative formulation for ( 10 ), i.e., min where Q  X  = {  X  :  X   X  [0 , 1 +  X  ] n , k  X  k 1  X   X  } , and  X  = (1  X  q +  X  +  X  /  X  ( y i f ( x i )) = max(0 , 1  X  y i f ( x i )) = max  X  y f ( x i )), and introducing {  X  i =  X  i ( p i +  X  ) } n i =1 Before presenting the optimization algorithm, we in-troduce a few notations that will be used throughout this section. We denote by f = ( f 1 , , f m )  X   X  H where H = ( H  X  the first term and the second term in the objective function in ( 11 ), respectively. We write the problem in ( 11 ) as In the following, we refer to f as the primal vari-able and  X  as the dual variable. We denote by  X  f L ( f,  X  ) = (  X  f  X   X  L ( f,  X  ) the partial gradients of L ( f,  X  ) in terms of f and  X  , respectively. We use the notations k f j k = k f note by Q
Q [ b v ] = arg min v  X  X  when it is applied to a vector, and a RKHS norm when applied to a function.
 Next, we present an accelerated mirror prox method that extends the mirror prox method ( Nemirovski , 2005 ) to efficiently solve the convex-concave optimiza-tion problem in ( 11 ). The main limitation of the orig-inal mirror prox method is that it is only applicable to smooth objective functions whose gradients are Lips-chitz continuous, which unfortunately is not the case for the problem in ( 11 ) because R ( f ) is not a smooth function in f . Algorithm 1 outlines the key steps of this method. In Algorithm 1 , we maintain two copies for the dual variables (i.e.,  X  and  X  ), but only one copy for the primal variable f . This is in contrast to the mirror prox method that introduces two copies for both primal and dual variables. Another key difference Algorithm 1 An Accelerated Mirror Prox Method 1: Input : step size  X  = 2: Initialization :  X  0 = 0 , f 0 = 0 3: for t = 1 , 2 , . . . , T do 4:  X  t = 6:  X  t = 7: end for 8: Output: b f T = between Algorithm 1 and the mirror prox method is that in step 5, we update the primal variable f by a composite gradient mapping ( Nesterov , 2007 ), instead of a gradient mapping. It is this step that allows us to solve the convex-concave optimization problems ef-ficiently with a convergence rate of O (1 /T ), without having to assume that the gradients of the objective function are Lipschitz continuous. It is important to point out that accelerated proximal gradient method by Tseng ( Tseng , 2008 ) is not applicable to ( 11 ), since it requires the Lipschitz continuous gradients. In order to efficiently implement Algorithm 1 , we need to efficiently solve the optimization problems in steps 4, 5, and 6. The gradient mapping problems in steps 4 and 6 can be solved by utilizing the following lemma. Lemma 2. The optimal solution  X   X  to is projection of the number s into the range [ a, b ] , and  X  = 0 if to the following equation Since function in  X  , we can efficiently compute  X  in ( 12 ) by bisection search.
 The composite gradient mapping in step 5 is solved by the following lemma.
 Lemma 3. The optimal solution to ( 13 ) denoted by f , j  X  [ m ] is given by where [ z ] + = z if z &gt; 0 and 0 otherwise, and t is the solution to the following equation, where t can be computed by efficient bisection search. Remark: Note that since the partial gradient  X  f j L ( f,  X  ) =  X  (1 /n ) updating the kernel classifier f j , we can write it in a parameterized form f j = We conclude this subsection by presenting the conver-gence rate for Algorithm 1 .
 Theorem 2. By running Algorithm 1 with T itera-tions, we have max where f  X  = ( f  X  1 , , f  X  m )  X  = arg min f F ( f, b  X   X  Theorem 2 indicates a O (1 /T ) convergence rate for the accelerated mirror prox method presented in Al-gorithm 1 that is significantly faster than traditional O (1 / tion problems. This is also demonstrated by our em-pirical studies. In this section, we simulate our experiments on UCI data sets to verify the effectiveness and efficiency of the proposed algorithm for MKL from noisy labels. In a simulated environment, we can control the noise level to better understand the behavior of the pro-posed algorithm under different noise levels compared to baseline algorithms. We choose five data sets from UCI repository that have been used in MKL studies ( Rakotomamonjy et al. , 2008 ; Xu et al. , 2010 ). The statistics of the data sets are summarized in Table 1. We normalize the data by scaling each attribute to [0 , 1]. This is done by first subtracting each attribute from its minimal value and then dividing it by the dif-ference between the maximal and the minimal value of the attribute. To generate label noise, we randomly flip the class label of each example with a probability of q . To create multiple kernels, we follow the setup in ( Xu et al. , 2010 ) to generate Gaussian kernels with as well as for individual features, leading to a total of m = 10( d + 1) kernels for each data set, where d is the number of features. We split the data into 80% for training and 20% for testing.
 In the experiments, we focus on verifying the proposed stochastic programming framework for handling the noise in labels. We choose two baselines for compar-ison where one directly optimizes the objective in ( 2 ) assuming the labels are all correct, and the other one adopts a different strategy (i.e. minimization instead of maximization over p ) to handle the noise. By com-paring with the first baseline, we are able to verify that existence of noise in labels significantly deterio-rates the performance and therefore handling the noise is important. By comparing with the second base-line, we are able to verify the proposed stochastic pro-gramming framework with maximization over p is a good choice for handling the noise. For the first base-line, we choose Simple MKL ( SiPMKL ) algorithm, a state-of-the-art algorithm for  X  1 regularized MKL 2 . For the second baseline, we extend the idea of robust SVM ( Xu et al. , 2006 ) to MKL from noisy labels by using the robust hinge loss and minimizing over p  X  Q . We refer to this baseline as MiPMKL . Finally, we re-fer to proposed algorithm as StPMKL .
 In implementing the proposed algorithm, we project  X  i into [0 , 1] by absorbing the upper bound 1 +  X  into the regularization parameter  X  and the bound parameter  X  (  X  ). The regularization parameter  X  in the proposed algorithm (and baselines as well) is cho-sen by cross validation on a validation data of 10% examples randomly selected from the training data. The parameter  X  (  X  ) is also tuned among several val-make fair comparison, we use the same stopping cri-terion for all algorithms, i.e., algorithms stop if the duality gap is less than threshold  X  = 10  X  2 or the maximum number of iterations T = 1000 is reached. We repeat each experiment five times, and report the results by averaging over the 5 trials.
 The left panels of Figure 1 show the classification ac-curacy of algorithms with noise level q varied from 0 to 0 . 4 on the five data sets. We observe that for almost all cases, (i) the proposed algorithm is significantly more resilient than SiPMKL algorithm to the label noise; (ii) the worst case analysis ( StPMKL ) is better than the best case analysis ( MiPMKL ) for noisy la-bels, particularly when the noise level is high; and (iii) when no noise is added ( q =0), StPMKL achieves sim-ilar performance, if not the same, to SiPMKL , while MiPMKL could give different results (e.g. on iono-sphere, heart, sonar). The reason is that the objective in StPMKL reduces to the objective in SiPMKL when q = 0, however, it is not the case for MiPMKL . This observation is consistent with our discussion in section 3.2 above Theorem 1 .
 Finally, we verify the efficiency of the accelerated mir-ror prox method. We compare the proposed accel-erated mirror prox ( AMP ) method to the variational inequality method ( VI ) ( Nemirovski , 1994 ) (i.e. gradi-ent descent method for convex-concave problem). For fair comparison, we fix  X  = 0 . 01 and  X  = 100. The step size in variational inequality method is set to  X  0 / and the best convergence with the best  X  0 is finally reported. We run both algorithms with 1000 itera-tions, and plot the duality gap versus the number of iterations. The results are shown in the right panels of Figure 1 , which verify that the accelerated mirror prox method is significantly more efficient than the variational inequality method. In this paper, we present a stochastic programming framework for multiple kernel learning from noisy la-bels. We formulate the problem into a convex-concave optimization problem. We also present an efficient ac-celerated mirror prox method for solving the related convex-convex problem. Empirical studies in a simu-lated environment verify the effectiveness of the pro-posed framework and the efficiency of the developed optimization algorithm. For future work, we plan to apply the proposed approach to real-world prob-lems with inherent noise in labels where the noise may not be synthetically generated by independent random flipping. An open problem associated with it would be how to obtain the knowledge of the noise level. This work is in part supported by National Sci-ence Foundation (IIS-0643494), Office of Navy Re-search (ONR Award N00014-09-1-0663 and N00014-12-1-0431).

