 Andreas Maurer am@andreas-maurer.eu Adalbertstrasse 55, D-80799, Munchen, Germany Massimiliano Pontil m.pontil@cs.ucl.ac.uk University College London, Malet Place, London WC1E 6BT, UK Bernardino Romera-Paredes bernardino.paredes.09@ucl.ac.uk Department of Computer Science and UCL Interactive Centre University College London, Malet Place, London WC1E 6BT, UK The last decade has witnessed many efforts of the ma-chine learning community to exploit assumptions of sparsity in the design of algorithms. A central devel-opment in this respect is the Lasso ( Tibshirani , 1996 ), which estimates a linear predictor in a high dimen-sional space under a regularizing  X  1 -penalty. Theo-retical results guarantee a good performance of this method under the assumption that the vector corre-sponding to the underlying predictor is sparse, or at least has a small  X  1 -norm, see e.g. ( B  X uhlmann &amp; van de Geer , 2011 ) and references therein.
 In this work we consider the case where the predic-tors are linear combinations of the atoms of a dictio-nary of linear functions on a high or infinite dimen-sional space, and we assume that we are free to choose the dictionary. We will show that a principled choice is possible, if there are many learning problems, or  X  X asks X , and there exists a dictionary allowing sparse, or nearly sparse representations of all or most of the underlying predictors. In such a case we can exploit the larger quantity of available data to estimate the  X  X ood X  dictionary and still reap the benefits of the Lasso for the individual tasks. This paper gives the-oretical and experimental justification of this claim, both in the domain of multitask learning, where the new representation is applied to the tasks from which it was generated, and in the domain of learning to learn, where the dictionary is applied to new tasks of the same environment.
 Our work combines ideas from sparse coding ( Ol-shausen &amp; Field , 1996 ), multitask learning ( Ando &amp; Zhang , 2005 ; Argyriou, Evgeniou, Pontil , 2008 ; Ar-gyriou, Maurer, Pontil , 2008 ; Ben-David &amp; Schuller , 2003 ; Caruana , 1997 ; Evgeniou, Micchelli, Pontil , 2005 ; Maurer , 2009 ) and learning to learn ( Baxter , 2000 ; Thrun &amp; Pratt , 1998 ). There is a vast litera-ture on these subjects and the list of papers provided here is necessarily incomplete. Learning to learn (also called inductive bias learning or transfer learning) has been proposed by Baxter ( 2000 ) and an error analysis is provided therein, showing that a common represen-tation which performs well on the training tasks will also generalize to new tasks obtained from the same  X  X nvironment X . The precursors of the analysis pre-sented here are ( Maurer &amp; Pontil , 2010 ) and ( Maurer , 2009 ). The first paper provides a bound on the recon-struction error of sparse coding and may be seen as a special case of the ideas presented here when the sam-ple size is infinite. The second paper provides a learn-ing to learn analysis of the multitask feature learning method in ( Argyriou, Evgeniou, Pontil , 2008 ). We note that a method similar to the one presented in this paper has been recently proposed within the mul-titask learning setting ( Kumar &amp; Daum  X e III , 2012 ). Here we highlight the connection between sparse cod-ing and multitask learning and present a probabilistic analysis which complements well with the practical in-sights in the above work. We also address the different problem of learning to learn, demonstrating the util-ity of our approach in this setting by means of both learning bounds and numerical experiments. A fur-ther novelty of our approach is that it applies to a Hilbert spaces setting, thereby providing the possibil-ity of learning nonlinear predictors using reproducing kernel Hilbert spaces.
 The paper is organized in the following manner. In Section 2 , we set up our notation and introduce the learning problem. In Section 3 , we present our learning bounds for multitask learning and learning to learn. In Section 4 we report on numerical experiments. Section 5 contains concluding remarks. In this section, we turn to a technical exposition of the proposed method, introducing some necessary no-tation on the way.
 Let H be a finite or infinite dimensional Hilbert space with inner product h X  ,  X i , norm k X k , and fix an integer K . We study the problem where  X  D K is the set of K -dimensional dictionaries (or  X  C  X  is the set of code vectors  X  in R K satisfying  X  Z = (( x ti , y ti ) : 1  X  i  X  m, 1  X  t  X  T ) is a dataset  X   X  is a loss function where  X  ( y, y  X  ) measures the The minimum in ( 1 ) is zero if the data is gener-ated according to a noise-less model which postulates such that an input x  X  H generates the label y = h D  X   X   X  t , x i in the context of task t . If K  X  K  X  and  X   X   X   X  then the minimum in ( 1 ) is zero. In Sec-tion 4 , we will present experiments with such a gen-erative model, when noise is added to the labels, that is y = h D  X   X   X  t , x i +  X  with  X   X  N (0 ,  X  ), the standard normal distribution.
 The method ( 1 ) should output a minimizing D ( Z )  X  D
K as well as a minimizing  X  1 ( Z ) , . . . ,  X  T ( Z ) cor-responding to the different tasks. Our implementa-tion, described in Section 4.1 , does not guarantee ex-act minimization, because of the non-convexity of the problem. Below predictors are always linear, speci-fied by a vector w  X  H , predicting the label h w, x i for an input x  X  H , and a learning algorithm is a rule which assigns a predictor A ( z ) to a given data set z = (( x i , y i ) : 1  X  i  X  m )  X  ( H  X  R ) m . In this section, we present learning bounds for method ( 1 ), both in the multitask learning and learning to learn settings, and discuss the special case of sparse coding. 3.1. Multitask learning Let  X  1 , . . . ,  X  T be probability measures on H  X  R . We interpret  X  t ( x, y ) as the probability of observ-ing the input/output pair ( x, y ) in the context of task t . For each of these tasks an i.i.d. training sample z t = (( x ti , y ti ) : 1  X  i  X  m ) is drawn from (  X  to algorithm ( 1 ). Upon returning of a minimizing D ( Z ) and  X  1 ( Z ) , . . . ,  X  T ( Z ), we will use the predic-tor D ( Z )  X  t ( Z ) on the t -th task. The average over all tasks of the expected error incurred by these predictors is We compare this task-average risk to the minimal analogous risk obtainable by any dictionary D  X  D K and any set of vectors  X  1 , . . . ,  X  T  X  X   X  . Our first result is a bound on the excess risk.
 Theorem 1. Let  X  &gt; 0 and let  X  1 , . . . ,  X  T be probabil-ity measures on H  X  R . With probability at least 1  X   X  in the draw of Z  X  Q T t =1  X  m t we have T where S 1 ( X ) = 1 covariance of the input data for the t -th task, tr (  X  ) de-notes the trace and  X  max (  X  ) the largest eigenvalue. We state several implications of this theorem. 1. The quantity S 1 ( X ) appearing in the bound is 2. In the regime T &lt; K the bound is dominated by 3. Consider the noiseless generative model men-4. Suppose that we concatenate two sets of tasks. If 5. Consider the alternative method of subspace The proof of Theorem 1 , which is given in Section B.1 of the supplementary appendix, uses standard meth-ods of empirical process theory, but also employs a concentration result related to Talagrand X  X  convex dis-tance inequality to obtain the crucial dependence on S  X  ( X ). At the end of Section B.1 we sketch ap-plications of the proof method to other regulariza-tion schemes, such as the one presented in ( Kumar &amp; Daum  X e III , 2012 ), in which the Frobenius norm on the dictionary D is used in place of the  X  2 / X   X  -norm employed here and the  X  1 / X  1 norm on the coefficient matrix [  X  1 , . . . ,  X  T ] is used in place of the  X  1 / X  3.2. Learning to learn There is no absolute way to assess the quality of a learning algorithm. Algorithms may perform well on one kind of task, but poorly on another kind. It is important that an algorithm performs well on those tasks which it is likely to be applied to. To formalize this, Baxter ( 2000 ) introduced the notion of an envi-ronment , which is a probability measure E on the set of tasks. Thus E (  X  ) is the probability of encountering the task  X  in the environment E , and  X   X  ( x, y ) is the probability of finding the pair ( x, y ) in the context of the task  X  .
 Given E , the transfer risk (or simply risk) of a learning algorithm A is defined as follows. We draw a task from the environment,  X   X  E , which fixes a corresponding distribution  X   X  on H  X  R . Then we draw a training sample z  X   X  m  X  and use the algorithm to compute the predictor A ( z ). Finally we measure the performance of this predictor on test points ( x, y )  X   X   X  . The cor-responding definition of the transfer risk of A reads as which is simply the expected loss incurred by the use of the algorithm A on tasks drawn from the environment E .
 For any given dictionary D  X  D K we consider the learning algorithm A D , which for z  X  Z m computes the predictor Equivalently, we can regard A D as the Lasso operat-ing on data preprocessed by the linear map D  X  , the adjoint of D .
 We can make a single observation of the environment E in the following way: one first draws a task  X   X  E . This task and the corresponding distribution  X   X  are then observed by drawing an i.i.d. sample z from  X   X  , that is z  X   X  m  X  . For simplicity the sample size m will be fixed. Such an observation corresponds to the draw of a sample z from a probability distribution  X  E on ( H  X  R ) m which is defined by To estimate an environment a large number T of in-dependent observations is needed, corresponding to a vector Z = ( z 1 , . . . , z T )  X  (( H  X  R ) m ) T drawn i.i.d. from  X  E , that is Z  X  (  X  E ) T .
 We now propose to solve the problem ( 1 ) with the data Z , ignore the resulting  X  i ( Z ), but retain the dic-tionary D ( Z ) and use the algorithm A D ( Z ) on future tasks drawn from the same environment. The perfor-mance of this method can be quantified as the transfer risk R E A D ( Z ) as defined in equation ( 2 ) and again we are interested in comparing this to the risk of an ideal solution based on complete knowledge of the en-vironment. For any fixed dictionary D and task  X  the best we can do is to choose  X   X  C so as to minimize E as to minimize the average of this over  X   X  E . The quantity thus describes the optimal performance achievable un-der the given constraint. Our second result is Theorem 2. With probability at least 1  X   X  in the multisample Z = ( X , Y )  X   X  T E we have where S 1 ( X ) is as in Theorem 1 and S  X  ( E ) := E We discuss some implications of the above theorem. 1 . 1. The interpretation of S  X  ( E ) is analogous to that 2. In the regime T  X  K 2 the result does not imply 3. There is an important difference with the mul-The proof of Theorem 2 is given in Section B.2 of the supplementary appendix and follows the method out-lined in ( Maurer , 2009 ): one first bounds the estima-tion error for the expected empirical risk on future tasks, and then combines this with a bound of the ex-pected true risk by said expected empirical risk. The term K/ and the conjecture that it can be replaced by p K/T seems plausible. 3.3. Connection to sparse coding We discuss a special case of Theorem 2 in the limit m  X   X  , showing that it subsumes the sparse coding result in ( Maurer &amp; Pontil , 2010 ). To this end, we as-sume the noiseless generative model y ti = h w t , x ti i de-where p is the uniform distribution on the sphere in R d (i.e. the Haar measure). In this case the environment of tasks is fully specified by a measure  X  on the unit ball in R d from which a task w  X  R d is drawn and the measure  X  is identified with the vector w . Note that we do not assume that these tasks are obtained as sparse combinations of some dictionary. Under the above as-sumptions and choosing  X  to be the square loss, we quently, in the limit of m  X  X  X  method ( 1 ) reduces to a constrained version of sparse coding ( Olshausen &amp; Field , 1996 ), namely In turn, the transfer error of a dictionary D is given by the quantity R ( D ) := min  X   X  X  R constraints D  X  D K ,  X   X  C  X  and k x k  X  1, the square be restricted to the interval y  X  [  X   X ,  X  ], where it has the Lipschitz constant 2 (1 +  X  ) for any y  X   X  [  X  1 , 1], as is easily verified. Since S 1 ( X ) = 1 and S  X  ( E ) &lt;  X  , the bound in Theorem 2 becomes
R ( D )  X  R opt  X  2  X  (1 +  X  ) K in the limit m  X  X  X  . The typical choice for  X  is  X   X  1, which ensures that k D X  k  X  1. In this case inequality ( 5 ) provides an improvement over the sparse coding bound in ( Maurer &amp; Pontil , 2010 ) (cf. Theorem 2 and Section 2.4 therein), which contains an additional term of the order of p (ln T ) /T and the same leading term in K as in ( 5 ) but with slightly worse constant (14 instead of 4 coding is experimentally demonstrated in Section 4.4 and illustrated in Figure 6 . In this section, we present experiments on a synthetic and two real datasets. The aim of the experiments is to study the statistical performance of the proposed method, in both settings of multitask learning and learning to learn. We compare our method, denoted as Sparse Coding Multi Task Learning (SC-MTL), with independent ridge regression (RR) as a base line and multitask feature learning (MTFL) ( Argyriou, Evge-niou, Pontil , 2008 ) and GO-MTL ( Kumar &amp; Daum  X e III , 2012 ). We also report on sensitivity analysis of the proposed method versus different number of parame-ters involved. 4.1. Optimization algorithm We solve problem ( 1 ) by alternating minimization over the dictionary matrix D and the code vectors  X  . The techniques we use are very similar to standard meth-ods for sparse coding and dictionary learning, see e.g. ( Jenatton et al. , 2011 ) and references therein for more information. Briefly, assuming that the loss function  X  is convex and has Lipschitz continuous gradient, either minimization problem is convex and can be solved ef-ficiently by proximal gradient methods, see e.g. ( Beck &amp; Teboulle , 2009 ; Combettes &amp; Wajs , 2006 ). The key ingredient in each step is the computation of the prox-imity operator, which in either problem has a closed form expression. 4.2. Toy experiment We generated a synthetic environment of tasks as fol-lows. We choose a d  X  K matrix D by sampling its columns independently from the uniform distribution on the unit sphere in R d . Once D is created, a generic task in the environment is given by w = D X  , where  X  is an s -sparse vector obtained as follows. First, we generate a set J  X  { 1 , . . . , K } of cardinality s , whose elements (indices) are sampled uniformly without re-placement from the set { 1 , . . . , K } . We then set  X  j if j /  X  J and otherwise sample  X  j  X  N (0 , 0 . 1). Fi-nally, we normalize  X  so that it has  X  1 -norm equal to some prescribed value  X  . Using the above proce-dure we generated T tasks w t = D X  t , t = 1 , . . . , T . Further, for each task t we generated a training set z form distribution on the unit sphere in R d . We then the variance of the noise. This procedure also defines the generation of new tasks in the transfer learning experiments below.
 The above model depends on seven parameters: the number K and the dimension d of the atoms, the spar-sity s and the  X  1 -norm  X  of the codes, the noise level  X  , the sample size per task m and the number of training tasks T . In all experiments we report both the multi-task learning (MTL) and learning to learn (LTL) per-formance of the methods. For MTL, we measure per-formance by the estimation error 1 /T P T t =1 k w t  X   X  w where  X  w 1 , . . . ,  X  w T are the estimated task vectors (in the case of SC-MTL,  X  w t = D ( Z )  X  ( Z ) t  X  see the discus-sion in Section 2 . For LTL, we use the same quantity but with a new set of tasks generated by the environ-ment (in the experiment below we generate 100 new tasks). The regularization parameter of each method is chosen by cross validation. Finally, all experiments are repeated 50 times, and the average performance results are reported in the plots below.
 In the first experiment, we fix K = 10 , d = 20 , s = 2 ,  X  = 10 , m = 10 ,  X  = 0 . 1 and study the statistical performance of the methods as a function of the num-ber of tasks. The results, shown in Figure 1 , clearly indicate that the proposed method outperforms the remaining approaches. In this experiment the number of atoms used by dictionary-based approaches, which here we denote by K  X  to avoid confusion with the num-ber of atoms K of the target dictionary, was equal to K = 10. This gives an advantage to both GO-MTL and SC-MTL. We therefore also studied the perfor-mance of those methods in dependence on K  X  . Fig-ure 2 , reporting this result, is in qualitative agreement with our theoretical analysis: the performance of SC-MTL is not too sensitive to K  X  if K  X   X  K , and the method still outperforms independent RR and MTFL if K  X  = 4 K . On the other hand if K  X  &lt; K the per-formance of the method quickly degrades. In the last experiment we study performance vs. the sparsity ra-tio s/K . Intuitively we would expect our method to have greater advantage over MTL if s  X  K . The results, shown in Figure 3 , confirm this fact, also in-dicating that SC-MTL is outperformed by both GO-MTL and MTFL as sparsity becomes less pronounced ( s/K &gt; 0 . 6).
 4.3. Learning to learn optical character We have conducted experiments on real data to study the performance of our method in a learning to learn / transfer learning setting. To this end, we employed the NIST dataset 1 , which is composed of a set of 14  X  14 pixels images of handwritten characters (digits and lower and capital case letters, for a total of 52 charac-ters).
 We considered the following experimental protocol. First, a set of 20 characters are chosen randomly as well as n instances for each character. These are used to learn all possibilities of 1-vs-1 train tasks, which makes T = 190, each of which having m = 2 n in-stances. The knowledge learned in this stage is em-ployed to learn another set of target tasks. In our approach, the assumption that is made is that some of the components in the dictionary learned from the training tasks, can also be useful for representing the target tasks. In order to create the target tasks, an-other set of 10 characters are chosen among the re-maining set of characters in the dataset, inducing a set of 45 1-vs-1 classification tasks. Since we are in-terested in the case where the training set size of the target tasks is small, we sample only 3 instances for each character, hence 6 examples per task.
 In order to tune the hyperparameters of all compared approaches, we have also created another set of 45 val-idation tasks by following the process previously de-scribed, simulating the target set of tasks. Note that there is not overlapping between the digits associated to the train, target and validation tasks.
 We have run 50 trials of the above process for different values of m and the average multiclass accuracy on the target tasks is reported in Figure 4 . 4.4. Sparse coding of images with missing In the last experiment we consider a sparse coding problem ( Olshausen &amp; Field , 1996 ) of optical char-acter images, with missing pixels. We employ the Bi-nary Alphadigits dataset 2 , which is composed of a set of binary 20  X  16 images of all digits and capital let-ters (39 images for each character). In the following experiment only the digits are used. We regard each image as a task, hence the input space is the set of 320 possible pixels indices, while the output space is the real interval [0 , 1], representing the gray level. We sample T = 100 , 130 , 160 , 190 , 220 , 250 images, equally divided among the 10 possible digits. For each of these, a corresponding random set of m = 160 pixel values are sampled (so the set of sample pixels varies from one image to another).
 We test the performance of the dictionary learned by method ( 1 ) in a learning to learn setting, by choosing 100 new images. The regularization parameter for each approach is tuned using cross validation. The results, shown in Figure 5 , indicate some advantage of the pro-posed method over trace norm regularization. A sim-ilar trend, not reported here due to space constraints, is obtained in the multitask setting. Ridge regression performed significantly worse and is not shown in the figure. We also show as a reference the performance of sparse coding (SC) applied when all pixels are known. With the aim of analyzing the atoms learned by the algorithm, we have carried out another experiment where we assume that there are 10 underlying atoms (one for each digit). We compare the resultant dic-tionary to that obtained by sparse coding, where all pixels are known. The results are shown in Figure 6 . In this paper, we have explored an application of sparse coding, which has been widely used in unsuper-vised learning and signal processing, to the domains of multitask learning and learning to learn. Our learn-ing bounds provide a justification of this method and offer insights into its advantage over independent task learning and learning dense representation of the tasks. The bounds, which hold in a Hilbert space setting, de-pend on data dependent quantities which measure the intrinsic dimensionality of the data. Numerical simu-lations presented here indicate that sparse coding is a promising approach to multitask learning and can lead to significant improvements over competing methods. In the future, it would be valuable to study exten-sions of our analysis to more general classes of code vectors. For example, we could use code sets C  X  which arise from structured sparsity norms, such as the group Lasso, see e.g. ( Jenatton et al. , 2011 ; Lounici et al. , 2011 ) or other families of regularizers. A concrete ex-ample which comes to mind is to choose K = Qr , Q, r  X  N and a partition J = {{ ( q  X  1) r + 1 , . . . , qr } : ous index sets of size r . Then using a norm of the type k  X  k = k  X  k 1 + P J  X  X  k  X  J k 2 will encourage codes which are sparse and use only few of the groups in J . Using the ball associated with this norm as our set of codes would allow to model sets of tasks which are di-vided into groups. A further natural extension of our method is nonlinear dictionary learning in which the dictionary columns correspond to functions in a repro-ducing kernel Hilbert space and the tasks are expressed as sparse linear combinations of such functions. This work was supported in part by EPSRC Grant EP/H027203/1 and Royal Society International Joint Project 2012/R2.
 Ando, R.K. and Zhang, T. A framework for learn-ing predictive structures from multiple tasks and unlabeled data. J. of Machine Learning Research , 6:1817 X 1853, 2005.
 Argyriou, A., Evgeniou, T., and Pontil, M. Con-vex multi-task feature learning. Machine Learning , 73(3):243 X 272, 2008.
 Argyriou, A., Maurer, A., and Pontil, M. An algo-rithm for transfer learning in a heterogeneous envi-ronment. Proc. European Conf. Machine Learning , pp. 71 X 85, 2008.
 Bartlett, P.L. and Mendelson, S. Rademacher and gaussian complexities: risk bounds and structural results. J. of Machine Learning Research , 3:463 X  482, 2002.
 Baxter, J. A model for inductive bias learning. J. of Artificial Intelligence Research , 12:149 X 198, 2000. Beck, A. and Teboulle, M. A fast iterative shrinkage-thresholding algorithm for linear inverse problems.
SIAM Journal of Imaging Sciences , 2(1):183 X 202, 2009.
 Ben-David, S. and Schuller, R. Exploiting task re-latedness for multiple task learning. Proceedings of Computational Learning Theory (COLT) , 2003.
 B  X uhlmann, P. and van de Geer, S. Statistics for High-
Dimensional Data: Methods, Theory and Applica-tions . Springer, 2011.
 Caruana, R. Multi-task learning. Machine Learning , 28:41 X 75, 1997.
 Combettes, P.L. and Wajs, V.R. Signal recovery by proximal forward-backward splitting. Multiscale Modeling and Simulation , 4(4):1168 X 1200, 2006. Evgeniou, T., Micchelli, C.A., and Pontil, M. Learning multiple tasks with kernel methods. J. of Machine Learning Research , 6:615 X 637, 2005.
 Jenatton, R., Mairal, J., Obozinski, G., and Bach, F.
Proximal methods for hierarchical sparse coding. J. of Machine Learning Research , 12:2297 X 2334, 2011. Koltchinskii, V. and Panchenko, D. Empirical margin distributions and bounding the generalization error of combined classifiers. Annals of Statistics , 30(1):1 X  50, 2002.
 Kumar, A. and Daum  X e III, H. Learning task group-ing and overlap in multitask learning. International Conference on Machine Learning (ICML) , 2012. Ledoux, M. and Talagrand, M. Probability in Banach Spaces . Springer, 1991.
 Lounici, K., Pontil, M., Tsybakov, A.B. and van de
Geer, S. Oracle inequalities and optimal inference under group sparsity Annals of Statistics , 39(4): 2164-2204, 2011.
 Maurer, A. Concentration inequalities for functions of independent variables. Random Structures and Algorithms , 29:121 X 138, 2006.
 Maurer, A. Transfer bounds for linear feature learning. Machine Learning , 75(3):327 X 350, 2009.
 Maurer, A. and Pontil, M. K-dimensional coding schemes in Hilbert spaces. IEEE Transactions on Information Theory , 56(11):5839 X 5846, 2010.
 McDiarmid, C. Probabilistic Methods of Algorithmic Discrete Mathematics . Springer, 1998.
 Olshausen, B.A. and Field, D.J. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature , 381:607 X 609, 1996. Slepian, D. The one-sided barrier problem for gaussian noise. Bell System Tech. J. , 41:463 X 501, 1962. Thrun, S. and Pratt, L. Learning to Learn . Springer, 1998.
 Tibshirani, R. Regression shrinkage and selection via
