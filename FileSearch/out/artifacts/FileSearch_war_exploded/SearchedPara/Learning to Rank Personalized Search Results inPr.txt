 LinkedIn search is deeply personalized -for the same queries, different searchers expect completely different results. This paper presents our approach to achieving this by mining var-ious data sources available in LinkedIn to infer searchers X  in-tents (such as hiring, job seeking, etc.), as well as extending the concept of homophily to capture the searcher-result sim-ilarities on many aspects. Then, learning-to-rank is applied to combine these signals with standard search features. Learning-to-Rank; Personalization; Federation
LinkedIn has evolved over past few years to become a platform containing various professional information sources -including 400+ million member profiles, 6+ million ac-tive jobs, millions of professional groups and 18+ million presentations. As the number of sources and their doc-ument volumes increase, the problem of serving the right results to fulfill each individual information need becomes increasingly challenging. Moreover, compared to typical in-formation retrieval systems (such as generic Web search), LinkedIn search is deeply personalized. For instance, if a member enters the query  X  X oftware engineer X , depending on whether he or she is a recruiter, job seeker or professional content consumer, the member expects to see very differ-ent results: software engineers X  profiles, software engineer jobs or slideshows on the topic, respectively. Even within a single vertical like Job search, for the query above, if the searcher happens to be an information retrieval expert, he or she is much more likely to be interested in software engi-neer jobs related to the field rather than software engineer jobs focusing on, say, software QA. For these reasons, we use rich information from the professional network -such as the searchers X  identity, profile, network and behavior -to understand their interests and intent, and serve a deeply personalized, relevant search experience.

With this context, we present our approach to personal-ize search ranking, leveraging the information available on LinkedIn. At the vertical level, we extend the concept of homophily to construct personalized features. Traditionally, the main idea of homophily is that in a social network, peo-ple tend to connect or interact with similar people. In the context of LinkedIn, we hypothesize that searchers tend to be interested in results similar or related to them. For exam-ple, in People search, searchers are often interested in people in the same or similar industries or companies and people with similar expertise. In Job search, searchers are usually interested in jobs at similar companies, jobs at nearby lo-cations and jobs requiring expertise similar to their own. In particular, for expertise homophily , we propose an ap-proach incorporating members X  profiles, skill-endorsement graphs and skill co-occurrence patterns to estimate their ex-pertise scores for the skills listed on their profiles, as well as the skills we infer they have. To combine these personalized features with traditional IR features, we apply learning-to-rank (LTR) techniques to learn ranking functions.

Given results from multiple verticals, a federated model blends them into a single search result page. To personalize the federated model, we mine members X  profiles and their recent activities at a large scale to understand their intents , such as, hiring intent, job seeking intent or content consum-ing intent, etc. Then, the federated model is learnt to couple this insight with other signals, including the ones from verti-cals, to select verticals and to aggregate vertical results into a single ranking that is personally relevant to each of our members.
On LinkedIn, skills are an integral part of members X  pro-files that showcase their expertise. A challenge on estimating member expertise is that many members do not explicitly list all skills they have. To overcome this, we employ a two-step approach (Figure 1). In the first step, we use a supervised learning algorithm combining various signals on LinkedIn, such as skill-endorsement graph page rank, skill-profile textual similarity, member seniority, etc., to estimate the expertise scores, i.e., p ( expert | member, skill ). After this step, the expertise matrix ( E 0 ) is very sparse since we can be certain about expertise scores only for a small percentage of the pairs. In the second step, we factorize the matrix into member and skill matrices in K-dimensional latent space. Then, we compute the dot-product of the matrices to fill in the  X  X nknown X  cells. The intuition for this can be illustrated as follows: if a member has  X  X achine learning X  and  X  X nfor-mation retrieval X  skills, based on skill co-occurrence patterns from all of our member base, we could infer that the member is likely to also know  X  X earning-to-rank X . Interested readers can refer to our recent work [3, 2] for more details. The ex-pertise homophily is then estimated by the cosine similarity between the searcher X  X  and results X  scores.
We apply an LTR approach to combine expertise homophily with more traditional search features. In deeply personal-ized settings like LinkedIn search, editorial judgement does not work well since result relevance strongly depends on indi-vidual searchers. Labels derived from search logs containing searchers X  actions on results, on the other hand, are person-alized by nature. However, the logs have both position and sample selection biases. To avoid position bias, we collect labels from a small traffic fraction that randomizes top-K results. The labeled data is then augmented with easy nega-tives , which are sampled from the tails of rankings to reduce sample bias. The labeled data collection approach is de-scribed in [2].
Given a pair of (query, searcher) , the federator selects a primary vertical and a set of secondary verticals, then ranks the primary individual results and the secondary vertical blocks in a single ranked list. The overall framework is de-scribed in Figure 2. When a member issues a query q , the query is passed to verticals and triggers the corresponding vertical search engines to get the top K results for each. In preliminary vertical selection phase, the federated scorer extracts features and computes a relevance score for each of the verticals. The top vertical is selected as the primary and the rest are selected as candidates for secondary ver-ticals. Then, in aggregation phase, these candidates com-pete with individual results in the primary vertical to form the final ranking. Note that these candidates are not guar-anteed to show up in the ranking. Instead, depending on queries, searchers and vertical results, all, some or none of these candidates could be selected. A critical feature used in the federated scorer is searcher intent, which is described in the next subsection.

LinkedIn searchers X  information needs constitute a very di-verse set of intents. For instance, members actively looking for jobs are likely to be more interested in job results than other verticals. Similarly, members hiring new employees should consider people results to be more important. Given this, we personalize search federation by using the searcher X  X  profile and past activity to infer their intents . If a member X  X  job title is recruiter, he is likely to have hiring intent. If a member recently searched for or applied to jobs, he is likely to have job seeking intent. We train machine-learned models combining all of the signals to predict intents for all searchers daily. It is worth noting that a member could have multiple intents at the same time.

The impact of the intents can vary significantly between different verticals. For example, knowing that a searcher has job seeking intent has much more importance for results that are jobs. We address this variation by constructing composite features , capturing both searcher intent and result type. In the example below, the feature is activated only if the searcher has job seeking intent and the result is job. We create combinations of all intents and result categories and learn their weights in our models. In essence, we let the learning algorithm associate evidence with the verticals, and normalize across all verticals from training data. More details can be found in [1]. f = 1 if searcher is a job seeker AND the result is job
We have described how vastly differing intents for the same query arising from different searchers makes LinkedIn search unique and presented the approaches we use to per-sonalize both vertical ranking and federation to deliver a relevant experience to all our searchers. [1] D. Arya, V. Ha-Thuc, , and S. Sinha. Personalized [2] V. Ha-Thuc, G. Venkataraman, M. Rodriguez, [3] V. Ha-Thuc, Y. Xu, S. P. Kanduri, X. Wu, V. Dialani,
