 A number of works have shown that the aggregation of sev-eral Information Retrieval (IR) systems works better than each system working individually. Nevertheless, early in-vestigation in the context of CLEF Robust-WSD task, in which semantics is involved, showed that aggregation strat e-gies achieve only slight improvements. This paper proposes a re-ranking approach which relies on inter-document sim-ilarities . The novelty of our idea is twofold: the output of a semantic based IR system is exploited to re-weigh docu-ments and a new strategy based on Semantic Vectors is used to compute inter-document similarities.

To date, many semantic approaches to IR have been de-veloped. These approaches tackle the word ambiguity prob-lem by shifting from a lexical space towards a semantic one. Among the most investigated techniques are those that words are uniquely identified and linked to each other by se-mantic relations. Ranging from query expansion to concept representation of documents by synset indexing, these at-tempts have not shown a turning point with respect to classi-cal techniques. Further investigations were performed in t he context of Robust-WSD task at Cross Language Evaluation Forum (CLEF). Systems which achieved the best perfor-mance in the last two campaigns [6, 3, 14] adopted strategies based on ranking aggregation. Ranking aggregation meth-ods [7, 9] are founded on the idea that different retrieval methods find different sets of documents with small overlap in both relevant and non-relevant documents sets. Thus, fusing all these sets in a single list of ranked documents should result in the best performance. Although the usage of this kind of strategy showed at times slight improvements , in most cases they are not significant. This paper presents a different approach to document aggregation based on a vari-ation of the  X  inter-document similarities  X  [8, 10] idea. We combine two retrieval strategies that work at two different
To compute the inter-document similarities we build a vector space ( DocSpace ) where similar documents are rep-resented by close vectors by means of the Semantic Vectors package [13]. To build the DocSpace , Semantic Vectors rely on a technique called Random Indexing [4], which performs a matrix reduction of the term-document matrix. Hence, in the DocSpace the similarity between documents is com-puted by the traditional cosine similarity.
Our evaluation aims to establish if a synset-based retrieva l system brings to significative improvements in IR when it is exploited by a re-ranking approach based on inter-document similarities.
 The evaluation is carried out on the CLEF 2009 Ad-Hoc Robust WSD dataset [2]. The document collection is made up of LA Times 94 and Glasgow Herald 95 newspaper docu-ments. Each user X  X  information need is expressed by a topic, a structured sentence consisting of a title, a description a nd a narrative field. The benchmark supplies 150 topics for the training step and 160 for the test step. Documents and topics are automatically annotated with WordNet synsets using two state-of-the art systems [1, 5]. We built a re-trieval system based on the Okapi BM25 model for both levels of representation: keyword and synset. Stemming and stop word removal were applied to keyword-based rep-resentation of documents and topics, but a different list of stop words was used for topics in order to remove frequent words which are poorly discriminating. Queries were built exploiting all topic fields and using different boosting fact ors to adjust their impacts on the result set (title=8, narra-tive=2, description=2). Hence, we retrieved the L k and L s lists of ranked documents. The evaluation was performed using the MAP and GMAP measures. Table 1 summa-rizes the main results. Foremost, we evaluated each system alone ( Keyword and Synset ). Keyword was used as base-line of the evaluation. Then, we evaluated two aggregation strategies, CombM N Z and CombSU M [7]. In particular we adopted a modified version of those strategies to assign different weights to each list during the aggregation. Fi-nally, the result of the proposed method has been denoted by ReRank . After a tuning step, we set the weights for L k and L s to 0 . 8 and 0 . 2, respectively. Moreover, we tested The number of supporters  X  was set to 20 and the smooth-ing parameter  X  was set to 0 . 3. Tuning was performed using training topics provided by the CLEF organizers.
 The ReRank method achieves the best results in term of MAP and GMAP. These improvements are significant with respect to both baseline Keyword and aggregation methods. We validated our experiments using both the parametric Student paired t-test and the non parametric Randomiza-tion test as suggested in [11] (  X  = 5%). Results confirm our hypothesis: the ranking provided by synsets ( L s ) con-tributes significantly to the final document score. In fact, to point up our result, we proposed another experiment in which only the keyword list was exploited. In this experi-ment the supporters score was computed using only L k list and we obtained a MAP of 0 . 3677.
