 As data collection channels and means become diverse, many real-world infor-mation retrieval tasks can involve multiple views for the same samples collected from different information sources. In these cases, people may have some exam-ples in one view while intend to query the database in another view, which we refer to cross-view information retrieval. There are many real-world examples: be used to query images which are stored in color features. Such cross-view sce-narios are inherently different from tag-based image retrieval, where the images in the database are associated with tags thus the underlying retrieval task is indeed text matching. In document retrieval, a document written in French can be used to query documents written in English [ 12 , 20 ]. Other cross-view sce-retrieval [ 23 ], rating-attribute recommendation [ 6 ]. Cross-language text retrieval is one of the earliest applications involving cross-view learning, where different translations of the same document can be viewed as multiple views. An early approach to cross-view learning was based on Latent Semantic Indexing (LSI) [ 12 ] until Canonical Component Analysis (CCA) was introduced [ 8 , 20 ]. CCA is able to find two projections to maximize the cor-relation between two sets of variables. A recent example [ 24 ] applies an improved version of CCA to learning query and image similarities. By applying CCA to cross-view learning, the data in two different feature spaces can be projected to a common low-dimensional space and the projected features thus become in the same representation for similarity comparison. However, directly comparing two sets of data, which have different physical interpretations, is unreasonable, although they have been linearly projected to the  X  X ame X  space. In fact, such  X  X ame X  space only means that the dimensionality is identical for two data sets; while the interpretation of each dimension of this  X  X ame X  space is still different for two data sets. Due to this limitation, CCA shows less advantage in cross-view information retrieval [ 17 ].
 Spectral embedding [ 1 ] can be used as a compatible representation for dif-ferent views of data since the embedded data are derived from affinity graphs, which have the same physical interpretation for different views. Some works have been proposed to solve multi-view learning problems based on spectral embed-ding [ 14 , 23 ]. A limitation is that spectral embedding can be hardly extended to out-of-sample setting. The linear version [ 9 ] of spectral embedding may be applied to address this limitation by using a linear projection. However, linear projection will induce the same problem like that in CCA since linear projection involves comparison of the original different views of data.
 Recently,  X  X earning to hash X  becomes an active research topic in informa-ing (LSH) techniques used in databases [ 3 , 7 ], where hash functions are designed manually, learning to hash aims to learn good hash functions from training data to preserve locality better while using fewer bits. By hashing, the data in the original feature spaces are encoded into binary codes. Some existing works have considered learning to hash in cross-view scenarios: Relational-aware heteroge-neous hashing [ 16 ] and heterogeneous translated hashing [ 21 ] project data from different views to Hamming spaces with different lengths. In contrast, the idea of this work is motivated from the following observation: Hashing indeed performs bi-partitions on the original feature spaces for B times using B hash functions, and the resulting B -bit binary codes of the original data can be interpreted as indices of the cells. If we can match the partitions of original feature spaces for different views, we can compare similarity of the binary codes from different views using Hamming distance. Motivated by the existing  X  X earning to hash X  research, we propose a simple yet effective Cross-View Feature Hashing (CVFH) algorithm via a  X  X artition and match X  approach. The feature space for each view is bi-partitioned multiple times using B hash functions and the resulting binary codes for all the views can thus be represented in a compatible B -bit Hamming space. More specifically, we first bi-partition multiple graphs of different views using Normalized Cuts (NCut) [ 18 ], based on a combined graph Laplacian of multiple views to preserve a consensus locality. The consensus locality preserving balances the geometry structures of multiple views. The NCut results ( B binary label sets for the nodes on the graphs) are used for supervised hash function training. Since the hash functions for different views are all learned on the same labels, the partitions of different feature spaces can be matched. For test, our method hashes features in different views and uses the resulting binary codes of one view to query another view. We apply CVFH to cross-view image retrieval on the NUS-WIDE-LITE image data. The experimental results show that CVFH can clearly outperform the CCA-based cross-view method.
 cross-view information retrieval problem in Sect. 2 . Then we introduce a pre-liminary cross-view information retrieval method based on CCA and spectral hashing in Sect. 3 . Our CVFH algorithm is presented in Sect. 4 . The experimen-tal results are reported in Sect. 5 and the paper is concluded in Sect. 6 . Suppose there are S data sources. A sample x n is generated from these data sources that combine S views of heterogeneous features, i.e. x { x n ,..., x [ x 1 ... x dimension of the feature space of the s -th view.
 R there are B hash functions h ( s ) 1 ,...,h ( s ) B , where h b =1 ,...,B . By the following feature hashing the mapped B -bit binary data for all the data views, { y become comparable in the common Hamming space. Similarly, we let a sample in the mapped Hamming space y n = { y (1) n ,..., y ( S ) n } { X  1 , 1 } B  X  N .
 in the original heterogenous feature spaces, R D (1) ,..., directly compared with one another, are encoded in the same representations, { X  1 , 1 } B , which are compatible across S views of data.
  X  The neighbors in the original feature spaces should be also close in the Ham-ming space; and  X  The binary codes for multiple views of the same sample should be similar in the Hamming space. In this section, we introduce a baseline approach to cross-view information retrieval by combining CCA and spectral hashing. This baseline approach only maximizes the correlation but does not preserve locality between two sets of features in different views. 3.1 Canonical Correlation Analysis Canonical Correlation Analysis (CCA) was proposed by Hotelling in 1936 and is a frequently used method in multivariate analysis. It was introduced to multi-view learning by Shawe-Taylor and his colleagues with a number of studies [ 8 , 20 ]. The aim of CCA is to find basis vectors, v ( s ) and v ( t ) such that the correlation between the projections of the two sets of variables onto these basis vectors is mutually maximized. Take the data in two views, X and X ( t ) , for example, the objective of CCA [ 8 ]isto where  X  ( s,s ) and  X  ( t,t ) are within-sets covariance matrices while  X  sets covariance matrix, which are computed from X ( s ) and X vectors can be obtained by solving an eigen decomposition problem.
 The data in the original feature spaces then can be projected onto a shared B -dimensional space by using the basis vectors with top B eigenvalues, i.e., [ V vectors. The projections from two data views can thus be compared by comput-ing a distance. A large number of cross-view learning methods are based on this approach [ 2 , 4 , 8 , 17 , 20 ]. 3.2 Spectral Hashing Spectral Hashing (SH) [ 22 ] is a recently proposed hashing algorithm based on the well developed graph theory in machine learning. It reveals the fact that Sensitive Hashing (LSH) [ 7 ]. Based on this observation, spectral hashing resorts to bi-partitioning a graph using Laplacian eigenmaps [ 1 ] and uses the signs of a set of eigenvectors 1 as the hashing codes. The objective of spectral hashing [ 22 ] is to where W ( s ) nm denotes the similarity between x ( s ) n W ( s ) is the Laplacian matrix. This is an integer programming known as NP-hard. Spectral hashing relaxes the problem by removing the constraint Y { X  1 , 1 } B  X  N and it reduces to a spectral embedding problem.
 can be used to encode the training samples while the out-of-sample test remains a problem. The authors in [ 22 ] adopt a set of data independent eigenfunctions as the hash functions while the authors in [ 13 ] extend the eigenvectors to eigenfunc-tions using Nystr  X  om method. As a result, the test samples also can be encoded into binary codes. 3.3 CCA+SH Baseline Algorithm We combine the advantages of the above two techniques (i.e., CCA for cross-view and SH for hashing) to introduce a baseline algorithm for cross-view information retrieval: 1. Use CCA to compute two projection matrices, V ( s ) and V 2. Use spectral hashing to hash [ V ( s ) ] X ( s ) and [ V 3. Use a code in one view (e.g., y ( s ) n ) to query the database in the other view in the experiments. Note that this algorithm only can be applied to two-view setting since it is based on CCA. 4.1 Objective The objective of CVFH is twofold: (1) For each view, the distance of any pair other words, CVFH is a locality-preserving mapping. (2) For all the views, the mapped data of different views for the same sample, y (1) close as possible in the Hamming space. In other words, CVFH is a cross-view adaptation mapping.
 Fortunately, we have found a way for our problem to satisfy the above two criteria. Since the objective of spectral hashing can satisfy the first one, we also adopt the idea of graph bi-partition for feature hashing. For the second one, as we argued in Sect. 1 , since linear projection like CCA is not interpretable for comparing samples based on distance, we will resort to another way to bridge different views. 4.2  X  X i-Partition and Match X  Strategy As we have highlighted in Sect. 1 , the essence of partition-based hashing approach is to bi-partition the original feature spaces for B times using B hash functions and then index the obtained cells with binary codes. Thus, the Hamming spaces after feature hashing for different views actually have the same interpretation, that is the cell indices of the original feature spaces. Thus, as long as we can match the partitions of the original feature spaces for different views, we can compute similarity of the binary codes from different views in Hamming distance. To match the partitions of the original feature spaces means that, in the corresponding cells of multi-view original feature spaces, the samples should be the same ones in different views. For example, in Fig. 1 , after bi-partitioning the two original spaces, the samples of two views fall in each cell (e.g., cell  X 11 X ) are the same data points (e.g., the red ones). If the multi-view data in all the partitioned cells are the same ones, we say that the multi-view original spaces are completely matched. Of course, on a real-world data set, we can hardly achieve a complete matching.
 To achieve a good matching between different views, we adopt a combined graph Laplacian of multiple views to preserve a consensus locality, i.e., Since we expect the resulting binary codes are as similar as possible for the multi-view data of the same sample, we let the eigenvectors for all views be identical as Y . We solve the following problem This problem is very similar to the one in spectral hashing. To achieve more balanced graph cuts, we adopt Normalized Cuts (NCut) [ 18 ] to bi-partition the combined graph. The consensus locality preserving is able to balance the geometry structures of multiple views. Then, we can select B sets of eigenvectors with smallest eigenvalues (except the last one) to extract their signs as the binary codes for the training samples. Note that the multi-view data of the same sample in all views will get the same binary codes. These binary codes will be used as supervision information to learn hash functions for different views. 4.3 Hash Functions We will learn S sets of hash functions, based on the supervision information of NCut results ( B binary label sets for the nodes on the consensus graph), for S views and each set has B hash functions. Formally, to learn a hash function h b for the b -th bit in the s -th view, we perform supervised learning to train a functions for different views are learned on the same labels, the cells of different feature spaces partitioned by the learned hash functions can be matched. be naturally extended to nonlinear functions by using kernels. For simplicity, we adopt the following form for the linear case where w ( s ) b = X ( s ) y b , and adopt the following one for the nonlinear case where  X  is a kernel function, such as the Gaussian kernel used in our experiments. Note that no optimization is required for the above two forms of hash functions. h 1 ,...,h in other views. 4.4 CVFH Algorithm We summarize the CVFH algorithm as follows: 1. Use NCut to perform bi-partitions on the consensus graph Laplacian, 2. Perform supervised learning to learn a hash function h spectral hashing, the computational complexity is as same as that for spectral hashing. In this section, we report our experimental results obtained from both synthetic and real-word data sets. In the first part of the experiments, we use a toy data set to intuitively demonstrate the idea of CVFH for matching different views of data in the shared Hamming space. In the second part of the experiments, we use the NUS-WIDE-LITE 2 image data set as our testbed to validate the effectiveness of the CVFH algorithm for cross-view information retrieval. 5.1 Results on Toy Data We generate the toy data as follows: (1) Let the column vectors in be the means of four Gaussians. (2) Let a 4  X  4 identity matrix be the covariance matrices for the four Gaussians. (3) Draw 50 samples from each Gaussian and obtain 200 samples in total, represented by a 4  X  200 matrix X , one column for one sample. (4) Let the first two dimensions be the first view, X rest two dimensions be the second view, X (2) , i.e., X = samples are plotted in Fig. 1 , where the upper row is for the first view and the bottom row for the second view, and four colors are used to indicate the samples from four different Gaussians.
 We perform CVFH on the two views of the toy data using the linear form of hash functions ( 13 ) and the results are shown in Fig. 1 . The first hash functions for both views are illustrated in the second column and the second hash functions in the third column. One can clearly find that the hash functions bi-partition the feature spaces into two parts. By integrating the hashing results of both the first and the second hash functions, we finally partition the two feature spaces into four cells (2-bit Hamming space). One can see that the four cells in both views can be completely matched (e.g., the cells of  X 11 X  in both views comprises the red samples), although the samples in two views have different distributions in the original feature spaces.
 bi-partition the original multi-view feature spaces by preserving the cross-view locality, and match the cells in both views after B bi-partitions. Through this approach, the samples in different views can be finally mapped into a common Hamming space with an interpretable physical meaning. 5.2 Results on NUS-WIDE-LITE Image Data The NUS-WIDE-LITE image data set comprises 55,615 images, half of which (27,807 images) are used for training and the rest (27,808 images) for testing. Some sample images are shown in Fig. 2 . Each image is tagged (or annotated) with one or multiple concepts. There are 81 concepts (organized in a hierar-chical structure) in total for all images in the data set. Examples of concepts include Animal, Person, Sports, Dancing etc. Each image is represented in five sets of low-level features, including (1) 64-D color histogram (CH), (2) 144-D color correlogram (CORR), (3) 225-D block-wise color moments (CM), (4) 73-D edge direction histogram (EDH), and (5) 128-D wavelet texture (WV). We con-catenate the three color-related features as the first view and concatenate the other two texture-related features as the second view, and obtain the data for two views as follows, 1. First View (CH+CORR+CM = 433 dimensions): a 433  X  27807 matrix X 2. Second View (EDH+WV = 201 dimensions): a 201  X  27807 matrix X We first perform CVFH on the training data set with two views to learn hash functions and apply them to the test data set. We then obtain the binary codes of the test data set for two views, represented in two B  X  Y B for the retrieval performance by changing its value in { We follow the same performance evaluation method used in [ 10 , 22 ]bycount-ing the retrieved  X  X ood X  neighbors in Hamming space that the distance between the queried example and the retrieved one is smaller than 2. The  X  X ood X  neigh-bors are defined as pairs of data in the original feature space whose distances are in the top 5th percentile. We plot the cross-view image retrieval results in Fig. 3 . The performances of Spectral Hashing (SH) [ 22 ] and PCA+SH are not cross-view but single-view results and they are plotted as the upper bound for cross-view results. That is, the closer to the performance of SH and PCA+SH, the better the cross-view retrieval is, by approaching the performance of querying and searching in the same view. The CCA+SH approach is used as the cross-view baseline introduced in Sect. 3 . The Matlab implementation for SH used in our experiments is downloaded from the authors X  homepage 3 and CCA methods, we use the built-in functions in Matlab.
 The left panel shows the results of  X  X sing examples in View 2 (texture) to query from the database in View 1 (color) X  for CCA+SH and CVFH; while the right panel shows the results of  X  X sing examples in View 1 (color) to query from the database in View 2 (texture) X  for CCA+SH and CVFH. The performance is averaged over 10 times and, for each time, we randomly select 100 examples in one view of the test set to query the test data in the other view. From Fig. 3 ,we can find that the proposed CVFH algorithm can clearly outperform the baseline method CCA+SH, especially in the second setting (right panel), where CVFH even approaches the upper bound.
 the performance of CVFH tends to decline at 30  X  40 bits after continuous increas-ing. A possible explanation is that, with the increasing number of hash functions, the feature spaces of both views are partitioned into more and more cells, and the feature spaces can be hardly matched in such a fine granularity. In this paper, we propose a simple yet effective Cross-View Feature Hashing (CVFH) algorithm via a  X  X artition and match X  approach. We argue that exist-ing approaches for multi-view learning, such as Canonical Component Analysis (CCA), mainly project different feature spaces to a common low-dimensional space for computing similarities. But directly comparing two sets of features, which have different physical interpretations, may be unreasonable, although they have been linearly projected to the  X  X ame X  space. To address the problem, we propose a  X  X artition and match X  cross-view feature hashing algorithm. By bi-partitioning multi-view feature spaces into cells based on a consensus locality-preserving graph cut, CVFH can match the original feature spaces for different views in a compatible Hamming space. In doing so, the multi-view data from different feature spaces can be directly compared for computing similarities, with an interpretable physical meaning. Experimental results on both synthetic and real-world data sets validated the effectiveness of the proposed CVFH algorithm. match hierarchically partitioned spaces for recursive hashing [ 5 , 11 ].
