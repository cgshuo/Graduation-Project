 networks, or bibliographic citations between scientific articles, is useful in many aspects. Many statistical models for relational data have been presented [10, 1, 18]. The stochastic block model (SBM) [11] and the infinite relational model (IRM) [8] partition objects into clusters so that the relations between clusters abstract the relations between objects well. SBM requires specifying the number of clusters in advance, while IRM automatically estimates the number of clusters. Similarly, the mixed membership model [2] associates each object with multiple clusters (roles) rather than a single cluster.
 These models treat the relations as static information. However, a large amount of relational data in the real world is time-varying . For example, hyperlinks on the Internet are not stationary since links disappear while new ones appear every day. Human relationships in a company sometimes drastically change by the splitting of an organization or the merging of some groups due to e.g. Mergers and Acquisitions. One of our modeling goals is to detect these sudden changes in network structure that occur over time.
 Recently some researchers have investigated the dynamics in relational data. Tang et al.[13] pro-posed a spectral clustering-based model for multi-mode, time-evolving relations. Yang et al.[16] developed the time-varying SBM. They assumed a transition probability matrix like HMM, which probability matrix for the entire data. Thus, it cannot represent more complicated time variations extension of the mixed membership model. [4] assumes a continuous world view: roles follow a mixed membership structure; model parameters evolve continuously in time. This model is very general for time series relational data modeling, and is good for tracking gradual and continuous changes of the relationships. Some works in bioinformatics [17, 5] have also adopted similar strate-gies. However, a continuous model approach does not necessarily best capture sudden transitions of fixed and known, which is di ffi cult to determine a priori. In this paper we propose yet another time-varying relational data model that deals with temporal ters. Instead of the continuous world view of [4], we assume a discrete structure: distinct clusters with discrete transitions over time, allowing for birth, death and split &amp; merge dynamics. More specifically, we extend IRM for time-varying relational data by using a variant of the infinite HMM (iHMM) [15, 3]. By incorporating the idea of iHMM, our model is able to infer clusters of objects without specifying a number of clusters in advance. Furthermore, we assume multiple transition probabilities that are dependent on time steps and clusters. This specific form of iHMM enables the performed e ffi ciently with the slice sampler. We first explain the infinite relational model (IRM) [8], which can estimate the number of hidden We write G DP( ; G 0 ) when a distribution G ( ) is sampled from DP. In this paper, we implement DP by using a stick-breaking process [12], which is based on the fact that G is represented as an infinite mixture of s: G ( ) = infinite elements whose sum equals one, constructed in a stochastic way: Here v k is drawn from a Beta distribution with a parameter .
 The IRM is an application of the DP for relational data. Let us assume a binary two-place relation place relation between the identical domain ( D D ). The IRM divides the set of N objects into is able to infer the number of clusters at the same time because it uses DP as a prior distribution i ; relations x i ; j , x j ; i throughout the paper.
 The probabilistic generative model (Fig. 1(a)) of the IRM is as follows: data x i ; j follows Eq. (5) conditioned by the cluster assignments Z and the strengths H . 3.1 Time-varying relational data First, we define the time-varying relational data considered in this paper. Time-varying relational data X have three subscripts t ; i ; and j : X = f 1 ; 2 ;:::; T g . x and j at time step t . T is the number of time steps, and N is the number of objects. We assume relational data X is a set of T (static) relational data for T time steps. Figure 1: Graphical model of (a)IRM (Eqs.2-5), (b) X  X IRM X  (Eqs.7-10), and (c)dIRM (Eqs.11-15). Circle nodes denote variables, square nodes are constants and shaded nodes indicate observations. lution. Observing several real world time-varying relational data, we assume there are several prop-erties of transitions, as follows: P1 is a common assumption for many kinds of time series data, not limited to relational data. For example, a member of a firm community on SNSs will belong to the same community for a long time. A hyperlink structure in a news website may alter because of breaking news, but most of the site does not change as rapidly every minute.
 P2 tries to model occasional and drastic changes from frequent and minor modifications in rela-tional networks. Such unstable changes are observed elsewhere. For example, human relationships in companies will evolve every day, but a merger of departments sometimes brings about drastic changes. On an SNS, a user community for the upcoming Olympics games may exist for a limited time: it will not last years after the games end. This will cause an addition and deletion of a user cluster (community). P3 is indispensable to track such changes of clusters. 3.2 Naive extensions of IRM We attempt to modify the IRM to satisfy these properties. We first consider several straightforward solutions based on the IRM for analyzing time-varying relational data.
 and apply the IRM to  X  X . For example, we can generate  X  X as follows: where denotes a threshold. This solution cannot represent the time changes of clustering because it assume the same clustering results for all the time steps ( z 1 ; i = z 2 ; i = = z T ; i ). step, but the analysis ignores the dependency of the data over time. ing  X  X IRM X  model is described as follows (Fig. 1(b)): between time steps will have higher correlations. However, this model assumes that z t ; i is condi-modeling time evolutions since the order of time steps are ignored in the model. 3.3 dynamic IRM To address three conditions P1 3 above, we propose a new probabilistic model called the dynamic infinite relational model (dIRM). The generative model is given below: Here,  X  t = f t ; k : k = 1 ;:::; 1g . A graphical model of the dIRM is presented in Fig. 1(c). in Eq. (11) represents time-average memberships (mixing ratios) to clusters. Newly introduced this transition probability is able to handle infinite hidden states like iHMM [14]. The DP used in Eq. (12) has an additional term &gt; 0, which is introduced by Fox et al. [3]. k is a vector whose elements are zero except the k th element, which is one. Because the base measure in Eq. (12) is biased by and k , the k th element of t ; k prefers to take a larger value than other elements. This implies that this DP encourages the self-transitions of objects, and we can achieve the property P1 for time-varying relational data.
 One di ff erence from conventional iHMMs [14, 3] lies in P2, which is achieved by making the transition probability time-dependent. t ; k is sampled for every time step t , thus, we can model extreme cases. These changes happen only temporarily, therefore, time-dependent transition prob-abilities are indispensable for our purpose. Note that the transition probability is also dependent on the cluster index k , as in conventional iHMMs. Also the dIRM can automatically determine the number of clusters thanks to DP: this enables us to hold P3.
 The di ff erence between iHMMs and dIRM is two-fold. One is the time-dependent transition proba-bility of the dIRM discussed above. The another is that the iHMMs have one hidden state sequence s time sequence observation. Thus, we may interpret the dIRM as an extension of the iHMM, which has N ( = a number of objects) hidden sequences to handle relational data. 4.1 Sampling parameters distribution. Also we define the joint distribution of u , z , and x : u i as follows: variable p : t = T to t = 1 using the computed message variables (backward sampling).
 In forward filtering we compute the following equation from t = 1 to t = T : condition is limited to a certain finite number. Thus, we can evaluate the above equation. In backward sampling, we sample z t ; i from t = T to t = 1 from the equation below: of sampled z t ; i will be limited a certain finite number K given U .
 becomes easy and straightforward. First is assumed as a K + 1-dimensional vector (mixing ratios of unrepresented clusters are aggregated in K + 1 = 1 N l . Similarly, n k ; l denotes a number of x t ; i ; j such that z t ; i following posteriors: m k is a K We omit the derivation of the posterior of since it is almost the same with that of Fox et al. [3]. 4.2 Sampling hyperparameters Sampling hyperparameters is important to obtain the best results. This could be done normally by some hyperparameters [3]. Instead, we reparameterize and sample a hyperparameter in terms of a 2 (0 ; 1) [6]. For example, if the hyperparameter is assumed as Gamma-distributed, we convert by a = 1 + . Sampling a can be achieved from a uniform grid on (0 ; 1). We compute (unnormalized) posterior probability densities at several a s and choose one to update the hyperparameter. Figure 2: Example of real-world datasets. (a)IOtables data, observations at t = 1, (b)IOtables data, Performance of the dIRM is compared with the original IRM [8] and its naive extension tIRM (described in Eqs. (7-10)). To apply the IRM to time-varying relational data, we use Eq. (6) to X with a threshold = 0 : 5. The di ff erence between the tIRM (Eqs. (7-10)) and the dIRM is that the tIRM does not incorporate the dependency between successive time steps while the dIRM does. Hyperparameters were estimated simultaneously in all experiments. 5.1 Datasets and measurements We prepared two synthetic datasets (Synth1 and Synth2). To synthesize datasets, we first determined the number of time steps T , the number of clusters K , and the number of objects N . Next, we man-take one of two values = 0 : 1 (weakly connected) or = 0 : 9 (strongly connected). Observation X was randomly generated according to Z and H . Synth1 is smaller ( N = 16) and stable while Synth2 is much larger ( N = 54), and objects actively transit between clusters.
 Two real-world datasets were also collected. The first one is the National Input-Output Tables for Japan (IOtables) provided by the Statistics Bureau of the Ministry of Internal A ff airs and Commu-nications of Japan. IOtables summarize the transactions of goods and services between industrial sectors. We used an inverted coe ffi cient matrix, which is a part of the IOtables. Each element in resolutions. Thus we obtain a time-varying relational data of N = 32 and T = 5.
 We extracted e-mails sent in 2001. The number of time steps was T = 12, so the dataset was divided excluding those who send few e-mails for convenience. Quantitative measurements were computed with this smaller dataset.
 Fig. 2 presents examples of IOtables dataset ((a),(b)) and Enron dataset ((c),(d)). IOtables dataset characterized by its stable relationships, compared to Enron dataset. In Enron dataset, the amount of communication rapidly increases after the media reported on the Enron scandals. We used three evaluating measurements. One is the Rand index, which computes the similarity between true and estimated clustering results [7]. The Rand index takes the maximum value (1) if the two clustering results completely match. We computed the Rand index between the ground truth Z t and the estimated  X  Z t for each time step, and averaged the indices for T steps. We also were computed between Z t and  X  Z t , and we calculated the average of these errors for T steps. We Table 1: Computed Rand indices, numbers of erroneous clusters, and averaged test data log likeli-hoods.
 Synth1 0.796 0.946 0.982 1.00 0.20 0.13 -0.542 -0.508 -0.505 Synth2 0.433 0.734 0.847 3.00 0.98 0.65 -0.692 -0.393 -0.318 IOtables -------0.354 -0.358 -0.291
Enron -------0.120 -0.135 -0.106 calculated these measurements for the synthetic datasets. The third measure is an (approximated) test-data log likelihood. For all datasets, we generated noisy datasets whose observation values are inverted. The number of inverted elements was kept small so that inversions would not a ff ect the two synthetic data, 1% for IOtables data and 0.5% for Enron data. We made inferences on the noisy datasets, and computed the likelihoods that  X  X nverted observations take the real value X . We used the averaged log-likelihood per a observation as a measurement. 5.2 Results First, we present the quantitative results. Table 1 lists the computed Rand index, errors in the es-timated number of clusters, and test-data log likelihoods. We confirmed that dIRM outperformed the other models in all datasets for the all measures. Particularly, dIRM showed good results in the Synth2 and Enron datasets, where the changes in relationships are highly dynamic and unstable. On the other hand, the dIRM did not achieve a remarkable improvement against tIRM for the Synth1 dataset whose temporal changes are small. Thus we can say that the dIRM is superior in modeling time-varying relational data, especially for dynamic ones.
 Next, we evaluate results of the real-world datasets qualitatively. Figure 3 shows the results from the time evolution of cluster assignments, respectively. The dIRM obtained some reasonable and stable industrial clusters, as shown in Fig. 3 (b). For example, dIRM groups the machine industries self-transition bias helps the model find these stable clusters. Also relationships between clusters presented in Fig. 3 (a) are intuitively understandable. For example, demands for machine industries trade X  and  X  X nterprise services X  sectors (cluster 10) connects strongly to almost all the sectors. There are some interesting cluster transitions. First, look at the  X  X inance, insurance X  sector. At t = 1, this sector belongs to cluster 14. However, the sector transits to cluster 1 afterwards, which does not connect strongly with clusters 5 and 7. This may indicates the shift of money from these From 1985 to 2000, this sector is in the cluster 9 which is rather independent from other clusters. However, in 2005 the cluster separated, and telecom industry merged with cluster 1, which is a impact on the world.
 Finally, we discuss results on the Enron dataset. Because this e-mail dataset contains many individ-uals X  names, we refrain from cataloging the object assignments as in the IOtables dataset. Figure 4 (a) tells us that clusters 1 7 are relatively separated communities. For example, members in cluster 4 belong to a restricted domain business such energy, gas, or pipeline businesses. Cluster 5 is a community of financial and monetary departments, and cluster 7 is a community of managers such as vice presidents, and CFOs.
 One interesting result from the dIRM is finding cluster 9. This cluster notably sends many messages to other clusters, especially for management cluster 7. The number of objects belonging to this cluster is only three throughout the time steps, but these members are the key-persons at that time. data by dIRM. (d) Time-varying clustering assignments for selected clusters by dIRM. Figure 4: (a): Example of estimated k ; l for Enron dataset using dIRM. (b): Number of items belonging to clusters at each time step for Enron dataset using dIRM.
 First, the CEO of Enron America stayed at cluster 9 in May ( t = 5). Next, the founder of Enron was a member of the cluster in August t = 8. The CEO of Enron resigned that month, and the founder actually made an announcement to calm down the public. Finally, the COO belongs to the cluster in October t = 10. This is the month that newspapers reported the accounting violations. increase as the scandal is more and more revealed. On the contrary, cluster 4 is stable in member-ship. Thus, we can imagine that the group of energy and gas is a dense and strong community. This is also true for cluster 5. We proposed a new time-varying relational data model that is able to represent dynamic changes of cluster structures. The dynamic IRM (dIRM) model incorporates a variant of the iHMM model generative model of the dIRM, and showed an inference algorithm based on a slice sampler. Exper-iments with synthetic and real-world time series datasets showed that the proposed model improves study the capability and the reliability of the model. We also are interested in modifying the dIRM to deal with multi-valued observation data. [1] A. Clauset, C. Moore, and M. E. J. Newman. Hierarchical structure and the prediction of [2] E. Erosheva, S. Fienberg, and J. La ff erty. Mixed-membership models of scientific publications. [3] E.B. Fox, E.B. Sudderth, M.I. Jordan, and A.S. Willsky. An HDP-HMM for systems with [4] Wenjie Fu, Le Song, and Eric P. Xing. Dynamic mixed membership blockmodel for evolving [5] O. Hirose, R. Yoshida, S. Imoto, R. Yamaguchi, T. Higuchi, D. S. Chamock-Jones, C. Print, [6] P. D. Ho ff . Subset clustering of binary sequences, with an application to genomic abnormality [7] L. Hubert and P. Arabie. Comparing partitions. Journal of Classification , 2(1):193 X 218, 1985. [8] C. Kemp, J. B. Tenenbaum, T. L. Gri ffi ths, T. Yamada, and N. Ueda. Learning systems of [9] B. Klimat and Y. Yang. The enron corpus: A new dataset for email classification research. In [10] D. Liben-Nowell and J. Kleinberg. The link prediction problem for social networks. In Pro-[11] K. Nowicki and T. A. B. Snijders. Estimation and prediction for stochastic blockstructures. [12] J. Sethuraman. A constructive definition of dirichlet process. Statistica Sinica , 4:639 X 650, [13] L. Tang, H. Liu, J. Zhang, and Z. Nazeri. Community evolution in dynamic multi-mode net-[14] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet process. Journal of [15] J. Van Gael, Y. Saatci, Y. W. Teh, and Z. Ghahramani. Beam sampling for the infinite hidden [16] T. Yang, Y. Chi, S. Zhu, Y. Gong, and R. Jin. A Bayesian approach toward finding commu-[17] R. Yoshida, S. Imoto, and T. Higuchi. Estimating time-dependent gene networks from time [18] S. Zhu, K. Yu, and Y. Gong. Stochastic relational models for large-scale dyadic data using
