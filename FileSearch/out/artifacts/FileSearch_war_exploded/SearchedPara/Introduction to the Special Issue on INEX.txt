 1. XML retrieval and evaluation T oday X  X  content is increasingly a mixture of text, multimedia, and metadata. One way to format this mixed content is according to the adopted W3C standard for information repositories and exchanges, the so-called eXtensible Markup Language (XML).

The increasing use of XML in scientific data repositories, Digital Libraries and on the Web, has brought about an explosion in the development of XML systems, and in particular systems to store and access XML content. Whereas many of today X  X  systems still treat documents as single large (text) blocks, XML offers the opportunity to exploit the internal structure of documents in order to allow for more precise access by giving more specific answers. Providing effective access to XML-based content is therefore a key issue.

Effective access to XML-based content is what XML retrieval research is about. XML represented by the XML markup, to retrieve document components (the so-called XML elements) instead of whole documents in response to a user X  X  query. Implementing this more focused retrieval paradigm means that an XML retrieval system needs not only to find relevant information in the XML documents, but also determine the appropriate level of component granularity to return to the user. Evaluating how good these systems are, hence, requires test-beds where the evaluation paradigms are provided according to criteria that take into account the imposed structural aspects.

INEX, 1 the Evaluation Initiative for XML Retrieval, is an initiative currently supported by DELOS. 2 INEX was set up at the beginning of 2002 with the aim to establish infrastruc-tures, XML test collections and appropriate measurements for evaluating XML retrieval approaches. INEX starts every year in April and concludes with a workshop, held a Schloss Dagstuhl (Germany), in December. 516 FUHR AND LALMAS 2. The INEX test-bed The INEX document collection is made up of the full-texts, marked up in XML, of 12,107 articles of the IEEE Computer Society X  X  publications from 12 magazines and 6 transactions, covering the period of 1995 X 2002, and totalling 494 megabytes in size. The collection contains scientific articles of varying length. On average an article contains 1,532 XML elements, where the average depth of an element is 6.9. Overall, the collection contains ove r eight millions XML elements of varying granularity (from table entries to paragraphs, sub-sections, sections and articles, each representing a potential answer to a query).
To consider the additional functionality introduced by the use of XML query languages, which allows the specification of structural query conditions, INEX defined two types of topics:  X  Content-only (CO) queries are standard information retrieval retrieval similar to those used in TREC. Given such a query, the goal of an XML retrieval system is to retrieve the most specific XML element(s) answering the query in a satisfying way. Thus, a system should e.g. not return a complete article where a section or even a paragraph of the same document may also be sufficient.  X  Content and structure (CAS) queries contain conditions referring both to content and structure of the requested answer elements. A query condition may refer to the content of specific elements (e.g. the elements to be returned must contain a section about a particular topic). Furthermore, the query may specify the type of the requested answer elements (e.g. sections should be retrieved). The query language defined for this purpose is a variant of XPath 1.0.

As in TREC, an INEX topic consists of the standard title, description and narrative fields. Keywords used in the topic creation phase are also included. The INEX topics were created by the participating institutions using their own XML retrieval systems or the system provided by the INEX organisers. 3 Tw o retrieval tasks were performed by the participating groups, both ad-hoc retrieval of XML documents, for CO and CAS topics, respectively. Retrieval runs for each task were then submitted to the INEX organisers.

Like the topics, the assessments have been derived in a collaborative effort. For each topic, the retrieval runs from the participants X  submissions have been collected into pools using the pooling method. The assessments pools were assigned then to participants; either groups with expertise in the topic X  X  subject area. Each group was responsible for about two topics.

Fo r the construction of the relevance assessments, INEX employed two relevance dimen-sions: exhaustivity and specificity. Exhaustivity is defined as a measure of how exhaustively an XML elements discusses the topic of request, while specificity is defined as a measure of how focused the element is on the topic of request (i.e. discusses no other, irrelevant topics). Both dimensions are measured on four-point scales with degrees of highly (3), f airly (2), marginally (1), and not (0) exhaustive/specific. The motivation for the use of INTRODUCTION TO THE SPECIAL ISSUE ON INEX 517 multiple grades was the need to reflect the relative relevance of an element with respect to its sub-elements. For example, an XML element may be more exhaustive than any of its sub-elements alone given that it covers all the aspects discussed in each of the sub-elements. Similarly, sub-elements may be more specific than their parent elements, given that the par-ent elements may cover multiple topics, including irrelevant ones. The combination of the two dimensions is used to identify those relevant XML elements, which are both exhaus-tive and specific to the topic of request and hence represent the most appropriate unit of information to return to the user.

To ensure complete assessments, assessors had the use of an on-line assessment system and the task of assessing every relevant element, and their ascendant and descendant ele-ments within the articles of the result pool. The assessors were given detailed information about the evaluation criteria and about how to perform the assessments. In addition, rules were implemented to ensure consistent assessments (e.g. exhaustivity cannot decrease when going from an element to its parent element).

To measure effectiveness, we use a metric based on the measure of precall, which com-putes the probability P ( rel | r etr ) that an XML element viewed by the user is relevant. That is, it interprets precision as the probability P ( rel | retr ) that an XML element viewed by a user is relevant: where esl x denotes the expected search length, that is the expected number of non-relevant elements until an arbitrary recall point x is reached, and n is the total number of relevant elements with respect to the given topic.

To apply the metric, the two relevance dimensions are mapped to a single relevance scale by employing a quantisation function. We therefore use different quantisations to map both dimensions to a single scalar value. For example, a strict quantisation function is applied to ev aluate retrieval methods with respect to their capability of retrieving highly exhaustive and highly specific document components. A generalised function is used to credit document components according to their degree of relevance, thus also allowing to reward fairly and marginally relevant XML elements according to their degree of relevance, i.e. near misses when calculating effectiveness performance. 3. Articles in this special issue This issue contains six articles on XML IR from research groups who are active in INEX. These papers are enhanced and thoroughly reviewed versions of papers presented at the INEX 2003 workshop, held in Dagstuhl, 15 X 17 December 2003. The first three papers are focusing on the architecture of XML IR systems, whereas the other three deal mainly with IR models for XML retrieval.
 The paper Semantic Similarity Search on Semi-structured Data with the XXL Search Engine by Schenkel, Theobald and Weikum presents the query language XXL for XML IR. This query language allows for path queries with wildcards, which supports the child/ descendent axis of XPath as well as XML links (although the present version of the INEX 518 FUHR AND LALMAS collection contains no links). Another unique feature of XXL is  X  X emantic similarity search X  based on ontological information. For this purpose, semantic relations from WordNet are assigned weights using co-occurence statistics from the WWW. Although no full evaluation is available for this feature, the results for single query show that substantial performance gains are possible by using this kind of knowledge. For efficient query processing, the XXL implementation uses several indexes; most important, navigation along the ancestor and descendant axis as well as following links is supported by the so-called HOPI index, which utilises the concept of a 2-hop cover of a graph. The system is implemented on top of a relational database system.
 A database-oriented architecture is the major focus of the article TIJAH: Embracing IR Methods in XML Databases by List, Mihailovi  X  c, Ram  X   X rez, de Vries, Hiemstra, and Blok. They propose a layered database architecture for XML IR, which separates the three standard levels: conceptual, logical and physical level. At the conceptual level, language model is used for performing probabilistic retrieval. For CAS queries, three query patterns are distinguished (according to the structural conditions contained in the original query); for each pattern, a specific mapping into a query execution plan is presented. The logical level consists of a score region algebra, which operates over regions of XML documents, to which retrieval scores are assigned. Finally, the physical level consists of a relational database for storing the XML documents; path expressions are supported using the pre-post numbering scheme. Region algebra expressions from the logical level are translated into relational algebra expressions at this level.

In Hybrid XML Retrieval: Combining Information Retrieval and a Native XML Database by Pehcevski, Thom and Vercoustre, three different architectures for XML retrieval are investigated: 1. a full-text information retrieval system for atomic documents, 2. a native XML database supporting Boolean retrieval only, and 3. a hybrid system that adds a post-processing component to the latter. Retrieval experiments show that the XML database system performs poorly, and that the hybrid system gives the best performance, since it ranks the elements retrieved by the XML database. In addition, the authors describe an analysis of the query topics and relevance assessments, which results into a classification of topics into broad and narrow ones. They show that the query type determines the type of the preferable units of retrieval; thus, using retrieval parameters depending on the topic type results in better retrieval performance.
 The article The Importance of Length Normalization for XML Retrieval by Kamps, de Rijke and Sigurbj  X  ornsson starts with a comparative analysis of arbitrary elements vs. relevant elements. They compare the length distribution of all elements to that of those elements judged relevant to some query, and note significant differences: relevant element are longer than the average XML element. This observation justifies the importance of element length as a parameter for XML retrieval. For this purpose, they introduce an extreme length bias in their language model, which improves performance. They also show that simply removing short elements does not give the same quality
A Fusion Approach to XML Structured Document Retrieval by Larson compares two probabilistic methods, namely logistic regression and the Okapi BM25 formula. The two methods yield similar performance, but fusion gives substantially better results; the analysis shows that this effect is due to the different behaviour of the two methods: they fail at different INTRODUCTION TO THE SPECIAL ISSUE ON INEX 519 topics. Thus, fusion is able to combine the two methods in such a way that the strengths of each approach are exploited, but weaknesses are compensated.
 A Bayesian Network for XML Information Retrieval: Searching and Learning with the INEX Collection by Piwowarski and Gallinari presents a completely new IR model specifi-cally for XML. Based on the theoretical framework of Bayesian networks, a retrieval model is developed which considers the document context of an element to be retrieved; this con-text is modelled in the form of a Bayesian network. The necessary conditional probabilities are learned from a labelled collection of XML documents using a cross-entropy training criterion (in contrast, experiments with the widely-used EM algorithm produced poor re-sults). This learning methods is computationally expensive, but the parameters have to be learned only once per collection. Experimental results show that, even with a good baseline, retrieval performance can be improved through this approach.

The six papers included in this issue give a good survey over current research in XML retrieval.
 Acknowledgment We w ould like to thank all the authors of the papers forming this special issue for their contributions to and involvement in INEX. We would also like to thank Saadia Malik, Norbert G  X  overt, Benjamin Piwowarski and Gabriella Kazai for their active involvement in the evaluation tasks and methodologies.
 Notes
