 ORIGINAL PAPER Joost van Beusekom  X  Faisal Shafait  X  Thomas M. Breuel Abstract In large scale document digitization, orientation detectionplaysanimportantrole,especiallyinthescenarioof digitizing incoming mail. The heavy use of automatic doc-ument feeding scanners and moreover automatic process-ing of facsimiles results in many documents being scanned in the wrong orientation. These misoriented scans have to be corrected, as most subsequent processing steps assume the document to be scanned in the right orientation. Several existing methods for orientation detection use the fact that in Latin script text, ascenders are more likely to occur than descenders. In this paper, we propose a one-step skew and orientation detection method using a well-established geo-metric text-line model. The advantage of our method is that it combines accurate skew estimation with robust, resolution-independent orientation detection. An interesting aspect of our method is that it incorporates orientation detection into a previously published skew detection method allowing to perform orientation detection, skew estimation, and, if nec-essary, text-line extraction in one step. The effectiveness of our orientation detection approach is demonstrated on the UW-I dataset, and on publicly available test images from OCRopus. Our method achieves an accuracy of 99% on the UW-I dataset and 100% on test images from OCRopus. Keywords Orientation detection  X  Pre-processing  X  Line finding 1 Introduction Several initiatives have recently been launched for large scale scanning of documents, books and other paper-based mate-rials [ 1 ]. But also in office environments such as invoice pro-cessing, more and more high-volume digitization is being done. Especially in the domain of mail-room digitization, ori-entation detection is an important pre-processing step. The use of ADF scanners is likely to introduce misoriented scans. According to estimates by a company providing document management system solutions, there are around 1 X 5% of the documents that are scanned in the wrong orientation. A more important number of misoriented pages originates from elec-tronic facsimile processing. As most fax machines are using automatic document feeding that is opposite to the intuitive direction of paper insertion, it often occurs that misoriented facsimiles are received. The estimated percentage of misori-ented facsimiles is about 50%.

Among noise removal [ 2 ] and binarization [ 3 ], skew and orientation detection plays an important role in document image pre-processing, as the subsequent processing methods will fail to work correctly since usually both layout analysis [ 4 ] and OCR [ 5 , 6 ] assume pages to be in the correct orien-tation.

In literature, no clear definition or distinction between both steps can be found. Skew detection methods are often presented with minimum and maximum rotation angles that can be detected. These reach from  X  5  X  to  X  90  X  . For ori-entation detection, the same problem can be noticed. Some authors consider only upside up and upside down as possible orientations, others also consider upside left and upside right as possible orientations.
Due to the fact that most skew estimation methods allow skew angles of  X  45  X  or less, we define the problem of ori-entation detection as a four class problem, namely, detecting one of the following orientations: 0  X  ,90  X  , 180  X  or 270 thus define skew estimation as finding a rotation angle lying between  X  45  X  and + 45  X  .

The remaining sections of the paper are organized as follows: Sect. 2 gives an overview over related methods. Section 3 explains the proposed method. In Sect. 4 , evalua-tion procedures and experimental results are discussed. The paper is concluded by Sect. 5 . 2 Previous work Previous work on orientation and skew detection can be cat-egorized into three parts: 1. skew-only detection methods 2. orientation-only detection methods 3. combined skew and orientation detection methods. 2.1 Skew detection methods For skew detection, a good overview of the state-of-the-art methods is given by Cattoni et al. [ 7 ]. The methods are divided into different categories:  X  analysis of projection profiles: the basic idea is to com- X  Hough transform: using the attributes that text-lines are  X  clustering of connected components: assuming that char- X  other techniques: other approaches include analysis of A more recent work on skew detection is presented by Lu [ 8 ]. Connected components are merged with their near-est neighbor components to chains. The slope is estimated from each of these chains and finally the document skew is estimated using the mean or mode of the slopes. Comparison and evaluation on a non-public dataset showed reasonable results with a mean error of 0 . 32  X  . 2.2 Orientation detection methods For orientation detection, several approaches have been pre-sented in the past. A method using the ascender to descender ratio was presented by Caprari [ 9 ] in 1999. Top up and top down orientations are detected using an asymmetry measure computed from projection profiles, which makes it sensible to skewed pages. An accuracy of 100% is reported on a non-public dataset of 226 images containing mainly text and only little skew.

Aradhye [ 10 ] presented in 2005 an up/down orientation detection method for Roman and Non-Roman scripts. Text blobs are extracted, and the so-called opening to the left and to the right is computed for each blob. The ratio between left and right opening is then used to decide whether the page is rotated 0  X  or 180  X  . The method was tested on different data-sets and reached accuracies from 87 to 100%. On the UW-I dataset, an accuracy of 99% was obtained.

In 2006, Lu et al. [ 11 ] presented a method for language and orientation detection using the distributions of the number and position of white to black transitions of the components in the line. The performance of their method is reported on a partially non-public dataset and achieves a success rate of 98 . 2% for documents with at least 12 text-lines. 2.3 Combined skew and orientation detection methods Methods solving skew and orientation detection together can also be found in literature. However, most often two different approaches are used to detect skew and orientation. In 1994, Le et al. [ 12 ] presented a system capable of detecting portrait or landscape mode images and subsequently the skew angle. Top down document images are not considered. It uses rules based on projection profiles and textual features for orienta-tion detection. Hough transform is then used in the second step to determine the skew of the page. Evaluation has been done on a non-public dataset of pages of medical journal articles. An error rate of 0 . 1% is reported.

In 1995, Bloomberg et al. [ 13 ] presented a method for ori-entation detection that uses the ratio of the number of ascen-der characters to the number of descender characters used in English. As ascenders are more frequent than descenders, this can be used to detect the correct orientation. Ascend-ers and descenders are extracted using morphological opera-tions. Skew detection is also provided. This is done by finding the maximum of the so-called skew function that is maximal for the correct skew angle. Using two different search strat-egies, the best angle is computed. The reported error rate for orientation detection on UW-I [ 14 ] dataset is one wrongly detected orientation versus 938 correctly detected. The ori-entation of 41 documents could not be extracted but are not considered as errors. Skew detection error histograms are also given for the UW-I dataset. An implementation of this method is available in Leptonica, 1 an open source image pro-cessing library.

A more recent method using the ascender to descender ratio for orientation detection is presented by Avila et al. [ 15 ]. Using the x-height line and the base line of the text-lines, the number of ascenders and descenders is computed. If the num-ber of descenders is higher than the number of ascenders, the pageisconsideredbeingupsidedown.Skewdetectionisdone in this paper by grouping connected components to lines and building an angle histogram of the lines. The reported error rate for orientation detection is below 0 . 1% on a non-public dataset.

Lu et al. [ 16 ] presented another method to solve the orien-tation and skew detection problem. Similar to their previous work, white run histograms are used to detect a characteristic peak.Thisisthenusedtoestimatetheskewangle.Orientation detection is classically solved using ascender to descender ratio. A comparison between their method and other meth-ods found in literature is done. Unfortunately, the test set consists of only 52 documents of a non-public dataset.
In this paper, we propose a new method for combined skew and orientation detection using geometric modeling of Latin script text-lines. The method searches for text-line can-didates within a skew range of all four orientations. The best fit of the model gives the estimate of both page skew and orientation. 3 Skew and orientation detection The presented method for page skew and orientation detec-tion is based on Latin script text-line model by Breuel [ 17 ]. We will first illustrate the geometric text-line model since it is crucial for the understanding of this work. 3.1 Geometric text-line model Breuel proposed a parameterized model for a text-line with parameters ( r , X , d ) , where r is the distance of the baseline from the origin,  X  is the angle of the baseline from the hor-izontal axis, and d is the distance of the line of descenders from the baseline. This model is illustrated in Fig. 1 .The advantage of explicitly modeling the line of descenders is that it removes the ambiguities in baseline detection caused by the presence of descenders. A visualization of the different lines composing a text-line can be found in Fig. 2 .
Based on this geometric model of Latin script text-lines, we use geometric matching to extract text-lines from scanned documents as in [ 17 ]. A quality function is defined that gives the quality of matching the text-line model to a given set of points. The goal is to find a collection of parameters ( r for each text-line in the document image that maximizes the number of bounding boxes matching the model and that min-imizes the distance of each reference point from the baseline in a robust least square sense. The RAST algorithm [ 18 , 19 ] is used to find the parameters of all text-lines in a document image. The algorithm is run in a greedy fashion such that it returns text-lines in decreasing order of quality.
Consider a set of reference points { x 1 , x 2 ,..., x n } ned by taking the middle of the bottom line of the bounding boxes of the connected components in a document image. The goal of text-line detection is to find the maximizing set of parameters  X  = ( r , X , d ) with respect to the reference points { x 1 , x 2 ,..., x n } :  X   X  := arg max The quality function used in [ 17 ]is: Q where , X  ) ( x ) = max 0 , 1  X 
The first term in the summation of Eq. 2 calculates the contribution of a reference point x i to baseline, whereas the second term calculates the contribution of a reference point x to the descender line. Since a point can either lie on the baseline or the descender line, maximum of the two contri-butions is taken in the summation. Typically, the value of is set to 0.75, and its role is to compensate for the inequality of priors for baseline and descender line such that a reference point is more likely to be matched with the baseline when compared to the descender line. The contribution of a refer-ence point to a line is measured using Eq. 3 , and its value lies in the interval [ 0 , 1 ] . The contribution q ( r , X  ) for all reference points for which their Euclidean distance ered as outliers, and hence do not belong to the line with parameters ( r , X ) . In practice, = 5 proves to be a good choice for documents scanned at usual resolutions ranging from 150 to 400 dpi: it gives enough flexibility to account for slight variations due to pixel noise, binarization degradations and optical corrections in typography that allow characters to start actually slightly below the baseline. The contribution , X  ) ( x ) = 1if D ( r , X  ) ( x ) = 0 that means the contribution of a point to a line is one if and only if the point lies exactly on the line.

The RAST algorithm is used to extract the text-line with maximumqualityasgivenbyEq. 1 .Then,allreferencepoints that contributed with a non-zero quality to the extracted text-line are removed from the list of reference points, and the algorithm is run again. In this way, the algorithm returns text-lines in decreasing order of quality until all text-lines have been extracted from the document image. 3.2 Text-line extraction As mentioned in Sect. 3.1 , the text-lines are defined by three parameters ( r , X , d ) . The text-line extraction consists in find-ing parameter triples that maximize Eq. 2 . This is done using a branch-and-bound search. In the first step, the parameter space P is defined: P =[ r
For practical applications, r min = 0 and r max can be fixed using the image size. As large skew angles |  X  | &gt; 20  X  unlikely to occur (in the aforementioned applications, such skew angles will likely lead to a paper feed error on the scanning device), the range of the rotation angle [  X  min is set to [ X  20  X  , 20  X  ] . Finally, the possible distances of the descender line to the base line has to be set. For the current setup, this is fixed to [ 0 , 30 ] . The theoretical size of a 12pt character scanned with 300dpi is 50px. For common fonts, the distance between the ascender and the baseline is about 1 / 4to1 / 3 of the total height, thus the above setting of the parameter d gives enough flexibility.

The branch-and-bound algorithm works as follows: 0. initialize the search space and insert it into priority queue 1. stop if Q is empty, else get the top search space S from Q 2. if S is a solution: save S and discard all image points con-3. split S into two subspaces S 1 and S 2 4. compute upper bounds for the quality of S 1 and S 2 5. put S 1 and S 2 on Q . Continue with Step 1.

The computation of the upper bound for the quality of the text-line defined by the parameter subspace is done using interval arithmetic. A priority queue is used to keep track of the subspaces that need to be analyzed. The number of lines to be extracted is used in Step 6 to define the stopping crite-rion. A space is considered as a solution if it is small enough to identify the unique line in the image. The parameters of the solution represent the detected line.

As mentioned in Sect. 3 , the set of reference points { x bottom line of the bounding boxes of the connected com-ponents in a document image. Instead of taking all con-nected components, a filtering step is used to discard too small or too big components, in order to increase the robust-ness of the method. The modes of the width and height of the connected components are computed. Based on these, 0 . and min aspect = 10 . 0 are defined and used as thresholds for the width, height, aspect ratio and area of the connected com-ponents. To simplify the reading, in the following we refer to the filtered set of connected components simply as the connected components. 3.3 One-step skew and orientation detection The key idea in our approach is to use ascender modeling in the same way as modeling descenders. An illustration is shown in Fig. 3 . The x-line (the line passing through the top of non-ascending lower case characters like x, a, c, etc.) is modeled as a straight line with parameters ( r , X ) , and the ascender line is modeled as a line parallel to the x-line at a distance a above the x-line.

Consider a set of reference points { y 1 , y 2 ,..., y n } ned by taking the middle of the top line of the bounding boxes of the connected components in a document image. The goal of text-line detection is to find the maximizing set of parameters  X  = ( r , X , a ) with respect to the reference points { y 1 , y 2 ,..., y n } :  X   X  := arg max The quality function can then be defined as: Q where the local quality can be computed in the same way as Eq. 3 .

Since in Latin script ascenders are more likely to occur than descenders, more components will match the ascen-der line than the descender line. A component matching to descender/ascender gets a lower score (due to the factor  X  Eqs. 2 and 6 ) when compared to a component matching to baseline/x-line. Therefore, in general, the total quality of the descender line (Eq. 2 ) will be higher than the total quality of the ascender line (Eq. 6 ). This information is used in this work to find the upside down orientation of the page. We sum the quality of n best lines returned by RAST first using the descender model and then using the ascender model. If the quality of the ascender model is higher than the descender model, the page is reported as upside down (180  X  rotated).
Note that computing the ascender model for a given page image in a correct orientation is equivalent to computing the descender model for a 180  X  rotated page. Therefore, for any given image we only compute the descender model for the original image and for 180  X  rotated image. The image that results in better descender quality is reported as the one with the correct orientation. This concept is then easily extended to detected pages with a 90  X  and 270  X  orientation. The hori-zontal text-line model does not fit well on vertical text-lines, so for a right side up portrait page the total quality of n best lines in the vertical direction is much lower than the total quality of n best horizontal lines. Hence, by computing the descender quality by rotating the page with all four orienta-tion, we can find out the correct orientation of the page. An illustration is shown in Fig. 4 .

An interesting aspect of our method is that besides an esti-mate of page orientation, we automatically get estimates for page skew since the skew angle  X  of all detected text-lines is known at this stage. We choose the skew of the text-line with the highest quality as the global skew of the page since this has already shown to give very accurate results for skew detection [ 17 ].

Another, even more interesting aspect of the method in the context of a subsequent OCR system, is the line information that is already computed. This information can then be used to extract the lines and feed them to a line recognizer. 3.4 Performance considerations In a high-volume digitization setup, computation time is an important aspect. Although the computation time needed by the text-line extraction process is justifiable in the context of page segmentation, running the extraction 4 times might be too slow if one is only interested in the orientation of the page. Furthermore, the line extraction converges only slowly in the case of pages that have only few aligned components, as it is the case with 90  X  and 270  X  misoriented pages. This computational overhead may render the method impractical.
Therefore, in order to speed up the proposed approach, a fastpre-classificationisdoneonthebasisoftheaspectratioof the bounding boxes of the connected components. Measure-ments on correctly aligned document images showed that the ratio of the number of bounding boxes with an aspect ratio ar &gt; 1 to the number of bounding boxes with an aspect ratio ar &lt; 1 is about 3 . 5 : 1. We use this to discard two possible orientations from the process. The distribution of this ratio can be seen in Fig. 5 . It can be seen that a strict decision at the boundary of ar = 1 leads to some misclassifications. To avoid this, a margin has been defined for which all four orientations are analyzed. According to the measurements in Fig. 5 , this was set to 0 . 66 &lt; ar &lt; 1 . 5. 4 Evaluation The evaluation of the proposed method is divided into two main parts. First, the skew estimation accuracy is evaluated. The second part of the evaluation is dedicated to measure the performance on orientation detection.

The dataset used for adapting the method and the param-eters is composed of 159 images of the UW-II [ 14 ] dataset. The total size of the UW-III dataset is 1,600 images. Every 10th image (in alphabetical order) from the total dataset was included. Hence, the training set consists of images A00A, A00K, ..., W1UA. Image W0H4 was manually removed as it contains text in two different orientations. In order to have equal distribution over all orientations, the first image in alphabeticalorderwasleftunchanged,thesecondwasrotated by 90  X  , the third one by 180  X  ,etc.

The main evaluation of the system X  X  performance was done on UW-I dataset. The UW-I dataset consists of 979 binarized images containing scans of scientific journals. Text is written in Latin script, and the language used in the journal articles is English.

Bloomberg X  X  [ 13 ] measurement on the frequency of ascenders to descenders in English text obtained a ratio of three to one. This is sustained by our measurements for sev-eral different languages that can be found in Table 1 . It can thus be concluded that the proposed method will work on most languages using Latin Script. 4.1 Skew detection accuracy In this experiment, we evaluated the accuracy of the skew detection capability of our method on the UW-I dataset. For this purpose, we chose to use the slope/skew information of the best line (line with the highest quality defined by Eq. 2 ) only. Other possibilities, like the median, mean, weighted median, or weighted mean, of all the different rotations of lines have been reported to give similar results [ 17 ]. Using only one line also makes the skew detection algorithm fast. Figure. 6 shows a scatter plot of the detected rotation angles and the ground-truth rotation angles as supplied with the UW-I dataset. For the sake of comparison, we also evalu-ated the skew detection accuracy of Tesseract [ 5 ] and Le-ptonica [ 13 ] document analysis systems. It is clear from the plot that we are able to accurately find the skew angles of most document images. Some outliers are due to pages hav-ing only formulas or images in them so no reliable text-line could be found.

Page rotations in the UW-I dataset were estimated using a triangulation scheme on multiple sets of three points on each document page [ 20 ]. Since multiple sets of points were used there is an associated standard deviation for each estimated page rotation angle. Figure 7 shows a plot of the histogram of standard deviations of skew angles within one page in UW-I dataset. Hence, there is no single page rotation angle that can be called  X  X orrect X  for these pages. Also for many pages, there is a significant difference in the skew of lines that are near the top of the page and the lines that are near the page bottom. This means that the variance between estimated and ground-truth page rotations may simply be due to the intrinsic variability of baseline orientations on these pages. If we consider a difference of less than 0 . 5  X  between the estimated and the supplied rotation angle as correct, rotation angles of 960 out of 979 documents are correctly identified, resulting in an accuracy of 98%. Using the same criteria, Leptonica correctly identified skew of 966 (98.7%) docu-ments,whereasTesseractidentifiedskewof895(91.4%)doc-uments correctly. 4.2 Orientation detection accuracy Four different tests have been run to evaluate the orientation detecting performance: 1. The overall performance of the full system is analyzed, 2. The performance of the system using the preliminary 3. The performance comparison of the proposed approach 4. As a part of ongoing work, we evaluated the proposed 4.2.1 Orientation detection using four line extraction steps In this evaluation, the performance of the orientation and skew detection method that analyzes the text-lines for all four orientations is presented. The test was run on the UW-1 dataset composed of 979 binary document images with corresponding ground truth. It contains a large variety of document images of scientific journal pages with differ-ent fonts and layouts, many of them including images, graphs and mathematical formulas.

For each image, the output of the orientation detection system was compared to the ground truth. The accuracy of the method is defined as the number of correctly detected orientations divided by the total number of test images. The following test parameter set for the maximum number of extracted lines is used: { 1 , 2 , 4 , 8 , 16 , 32 , 64 , 128 , 256 , 512 }
The plot in Fig. 8 shows the computation time needed with respect to the number of extracted text-lines. Here, it can be seen that the processing time increases with the number of text-lines to be extracted.

In the plot in Fig. 9 , the accuracy of the method in rela-tion to the number of extracted lines is shown. It can be seen that the accuracy for very few lines is already quite high and that it then reaches a maximum around 32 extracted lines and then decreases slightly to finally stay at a constant level. The absolute difference in correctly detected orienta-tions between extracting 32 and 512 lines is only three docu-ments. A manual inspection of different failures showed that extracting more lines on documents with only few text-lines can lead to misdetection of the orientation. Examples can be found in Figs. 10 a and b. It can also be noted that for some documents extracting more lines is advantageous. The orientation of image A00M (see Fig. 10 c), e.g., is recognized correctly when 512 lines are extracted but not if only 32 lines are extracted. In that case a rotation angle of 90  X  is detected, due to the long nicely structured tables.
 Finally, the choice of = 5, which was motivated in Sect. 3.1 is validated empirically. In Fig. 11 , the accuracy versus different values of is shown. The tested values for:  X  X  0 , 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 , 18 , 20 , 22 , It can be seen that for values of between [2 and 20], the performance stays relatively stable at a high value. For values of &gt; 20, the performance drops dramatically. 4.2.2 Orientation detection using two line extraction steps In this experiment, the performance of the orientation and skew detection method using the pre-classification on the basis of the aspect ratio of the connected components is ana-lyzed. Just as before, the 979 images of the UW-I dataset are used for this test. The accuracy is defined as the number of correctly detected page orientations divided by the total number of analyzed document images. The decision whether an orientation is correct or not is made using the ground-truth information. The following test parameter set for the maxi-mum number of extracted lines is used: { 1 , 2 , 4 , 8 , 16 , 32 , 64 , 128 , 256 , 512 }
The plot in Fig. 13 shows the accuracy of the method in relation to the number of extracted lines. We observe again that there is a peak for a moderate number of extracted lines, in this case 16. Then, the accuracy drops slightly but stays sta-ble afterward. A manual inspection was done to find out how many documents were wrongly classified on the aspect ratio of the connected components: it showed that only 7 images were misclassified on the basis of their aspect ratios of the connected components. Examples can be found in Fig. 12 . It can be noticed that all images present areas where many small connected components are present due to binarization. These are likely to disturb the statistics of the total page.
The plot in Fig. 14 shows the time consumption of the method in relation to the number of extracted text-lines. As expected, it can be noted that extracting less text-lines speeds up the method. This information, in combination with the earlier mentioned accuracy considerations allow the user to specify the parameters according to his needs: if only orienta-tion and skew detection are needed, only very few lines have to be extracted. If the full text-lines are needed anyway for subsequent processing steps, then all lines can be extracted with nearly the same overall performance.

Comparing the performance of the full method to the method using fast pre-classification shows that the gain in running time is significant, around the factor of seven. The accuracy however drops only slightly, approximately about 0 . 7%. 4.2.3 Performance comparison on UW-I In this part, we compare our method to a previously published method by Bloomberg [ 13 ]. For this evaluation, we followed the test setup used by Bloomberg, which is the same as has been used in the two previous tests: the document images from the UW-I dataset are fed to the orientation detection system, and the detected orientation is compared to the ground-truth orientation. Examples of resulting images of the one-step skew and orientation detection can be found in Fig. 15 . Our method was set to extract at maximum 512 lines, which for normal documents should cover all lines.
Table 2 shows the results per orientation and a comparison to Bloomberg X  X  method. It shows that although Bloomberg X  X  method works quite well, our approach achieves even better results. From 979 images in the data set, only 9 could not be classified correctly.

A manual verification of the errors showed the following problems:  X  Upper case letters only: in image N02J and N03G no  X  Long columns: in image A00M the main part of the page  X  Mathematical symbols: pages consisting mainly of math-Examples of these failures can be found in Fig. 16 . A performance comparison on single pages showed that Bloomberg X  X  method is about twice as fast as our method using preclassification and only one extracted line. The comparison however is not too significant: on the one hand, different code bases are used. Especially in the case of Le-ptonica, the code base has been very well optimized. On the other hand, the nature and also the resulting information (ori-entation versus orientation, skew angle and line extraction) obtained by both methods widely differ. 4.2.4 Resolution independence In this setup, the resolution independence was tested. There-fore, we used a set of images that are available with OCRopus [ 6 ] open source OCR. 2 These images are synthe-sized from electronic documents using the following reso-lution settings: 150, 200, 300 and 400 dpi. Nine different images are present in four different resolutions. For each image, four different orientations were tested, leading to a total test set size of 144 images. These images were chosen as they can be freely obtained on the web, so that they can be used for comparison by other researchers.

The results for the second test showed a 100% success rate on the 144 test images. This good result is favored by the test images containing no disturbing elements like images, num-bers or mathematical symbols.

The same test was run for Bloomberg X  X  method. The results can be found in Table 3 . It shows that on high res-olutions (400 dpi), it is not able to return high confidences for the obtained orientation estimates. Inspection of the inter-mediate images of Bloomberg X  X  method shows problems for the dilation using the horizontal structuring element for pages with 90  X  and 270  X  rotation. This is likely due to the too small horizontal structuring element. 4.2.5 Application to different scripts As a part of the ongoing work, the method was run on a sub-set of the UW-II dataset consisting of 477 binary images of Japanese journals. The images of UW-II present small skew angles that were not removed beforehand. Example images can be found in Fig. 17 . The images were rotated in the same way as done for the test on the OCRopus dataset.

The idea to extend the method to other scripts bases on the following idea: most scripts known to the authors have the concept of a base line. Most characters should thus be aligned to the baseline. There might be one or even more ascender lines, but under the assumption that less components touch the ascender line than the descender line, it seems reasonable to expect the proposed method to work reasonable on these scripts.

Only the results for the full approach are given. The plot in Fig. 18 shows the dependence of accuracy on the number of extracted lines.

The results of the test on the Japanese images can be found in Table 4 . It shows the confusion matrix between the ground-truth orientation and the detected orientation. Although the line model was not designed for Japanese script, the results are still reasonable with an overall accuracy of 85 . 7%. The reason for this lies in the fact that in Japanese text, characters line up on the baseline, whereas due to varying heights of different characters, alignment of top line is not so strong. Hence, top line gets a lower score in the least square fit that the baseline giving a good hint about the correct orientation of the page. 5 Conclusion In this paper, we presented a one-step method for skew and orientation detection using a line extraction algorithm. We showed the effectiveness of the method on a publicly avail-able dataset. A comparison to a widely used open source ori-entation detection technique was done. Experiments showed that our method outperformed the analyzed method for both UW-I dataset and our own dataset having documents ren-dered at different resolutions. A particular advantage of our method is that we get both orientation and skew estimates in one step. We plan to make our implementation publicly available as a part of OCRopus open source OCR system. References
