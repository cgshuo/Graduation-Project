 Even though queries received by traditional information re-trieval systems are quite short, there are many application scenarios where long natural language queries are more ef-fective. Further, incorporating term position information can help improve results of long queries. However, the tech-niques for incorporating term position information have been developed for terse queries and hence, can not be directly applied to long queries. Though there exist some methods for performing proximal search for long queries, they are not scalable due to long query response times. We describe an intuitive and simple, yet effective technique that implicitly incorporates term position information for long queries in a scalable manner. Our proposed approach achieves more than 700% faster query response times while maintaining the quality of retrieved results when compared with a state-of-the-art method for performing proximal search for very long queries.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Retrieval Models, Search Process Algorithms, Experimentation Verbose queries, long queries, term proximity, proximal search, prior art search, patent search.
Majority of information retrieval research focuses on key-word queries where the user represents her information need in form of a few keywords that representing the key underly-ing concept. Likewise, most of the queries received by com-mercial web search engines are very short  X  2-3 keywords on works on incorporating term proximity information in re-trieval models have focused on short keyword queries [ 13 , 3 , 6 ] and are not suitable for use with longer queries. More-over, these involve additional computation to determine the proximity information and coupled with the already long processing time for verbose queries, make the overall search process very slow. In this paper, we describe a technique for incorporating term proximity information for long queries in a scalable manner. Our approach does not involve a query transformation step and also does not require explicit term position computations at query time. We split the documents and input queries into simpler and smaller sub-units so that the query length reduction step (for handling long queries) and term position computation (for proxim-ity information) are implicit in the retrieval process. For experiments, we chose patent retrieval as the application domain given the very long i nput queries that are usually used for patent search (abstracts of patents). We compare our proposed approach with a state-of-the-art approach for performing proximal search for long queries and we achieve more than 700% faster query response times while maintain-ing, and in many cases, improving the quality of retrieved results.
The major purpose of proximal search operation in docu-ment retrieval is to ensure that documents containing query terms in close proximity to each other are assigned a higher score. This becomes more important for longer documents. The current methods for proximal search utilize the posi-tion information of various terms in the document to assign higher scores to documents that contain query terms in close proximity to each other. The position information for doc-ument terms can be pre-computed at index time and dis-tances between query terms present in the document can be computed at run time. For longer queries, these computa-tions can significantly increase the system X  X  response time. Hence, in order to improve query response time, we propose a method that eliminates these distance computations. Fig-ure 1 describes the intuition behind our approach. At index t ime, we segment the documents in the corpus into much smaller units called snippets . For the proposed method, a snippet consists of three consecutive sentences from the orig-inal document. Even though we generated snippets that were 3 sentences long, number of sentences in a snippet can be varied depending upon the application. Longer snippets will result in smaller number of overall  X  X ocuments X  to in-dex but a weak proximal search operator whereas shorter snippets favor strong proximity operators at the expense of large number of documents in the index. As suggested by Spangler et al. [ 11 ], a snippet length of three sentences of-f ers a fine balance between the two considerations. Thus, a given document is decomposed into a number of snippets that are much shorter in length and each snippet is now treated as a separate document and is indexed by the indexer of the search system. We assign identifiers to each snippet so that all the snippets generated from a given document can be identified. Note that by decomposing a document into snippets and indexing these individual snippets intro-duces an implicit proximal search operator . On receiving a user query, the search system finds snippets containing one or more query terms. These snippets are then ranked us-ing a ranking function that usually assigns higher scores to 2. Split the input long query into its constituent sen-3. Split the input query into its constituent sentences 1 . 4. As described above, transform the snippet results into 5. Sum scores for each document for each sentence and
We use the publicly available Marec 400.000 patent collec-tion that was used in AsPire X 10 workshop 2 collocated with ECIR 2010. The dataset consists of 400,000 randomly se-lected patent documents, with 100,000 patents belonging to EPO (European Patent Office), USPTO (US Patent Office), JPO (Japanese Patent Office) and WIPO (World Intellec-tual Property Organization), respectively. For our exper-iments, we only selected patents belonging to the USPTO set as the patents belonging to other patent offices were writ-ten in languages other than English. Thus the final dataset consists of 100,000 patent documents.
For our experiments, we created queries and relevance judgments using an approach common in patent retrieval community that has been followed in NTCIR [ 4 ]andTREC C hemical track [ 8 ]. We select 50 patents from the dataset having the most number of in-network citations. The ab-stract of these patents were used as the input query for dif-ferent retrieval algorithms with an average query length of 61.23 words and the patents cited by query patent present in the dataset constitute the set of relevant documents.
We compare our proposed approach with a state-of-the-art method for exploratory patent analysis as offered by IBM X  X  SIMPLE platform [ 12 ]. The search algorithm as used in the SIMPLE platform first breaks the input long query into mul-tiple shorter sub-queries by extracting multiple  X  X eywords X  and  X  X hrases X  from the original query. It then uses the shorter  X  X ub-queries X  with appropriate proximity operators and constructs the final result by combining the results of each individual sub-query. Further, the final ranked list of result is determined based on two factors  X  (i) documents returned by very specific sub-queries should be assigned a higher weight and (ii) documents that are returned by many
For extreme cases where the query is a very long sentence, it could be split up into sub-queries of equal length (say 10 words each) http://www.ir-facility.org/aspire-10 Simple 0.055 0.096 0.129 0.153 0.171 0.184 Snippet 0.064 0.098 0.120 0.150 0.180 0.195 Simple 0.053 0.074 0.090 0.113 0.132 0.144 Snippet 0.064 0.080 0.091 0.112 0.130 0.142 Table 1: Recall and PRES scores at various ranks for the two methods.
For each of the two retrieval methods, we ran each query five times and computed the average time taken by each method. This was repeated for all the 50 queries in the dataset giving us average runtime for each method. On an average, the baseline search algorithm (SIMPLE) took 210.854 seconds per query whereas our proposed method took an average of 25.215 seconds  X  an improvement of more than 700%. Further, Figure 2 shows the average time taken by two methods for each individual query. The figure shows a scatter plot where x -axis represents query length (in num-ber of words) and y -axis represents time. Thus, a point ( x, y ) on the plot indicates that for a query consisting of x words, theresponsetimeis y milliseconds. The dotted lines in the plot represent a least square fit for the two methods  X  blue for proposed method and red for the baseline method. We note from the figure that our proposed method consistently achieves much lower query response times as compared to the baseline method. Further, the slope of the line repre-senting the baseline approach is much steeper (22536 ms per query word) when compared to the slope for the pro-posed method (465.74 ms per query word). This indicates that our proposed approach is highly scalable as the rate at which the query response times increases with increasing query length is much lower than the baseline approach.
Table 1 reports PRES and recall values at different ranks f or the two methods. We note from the Table that when compared to the baseline approach, our proposed method achieves higher recall at all the ranks except at rank 50. In terms of PRES, even though the PRES values at higher ranks are slightly lower than the baseline method, both PRES and recall at ranks 10, 20 and 30 are higher than the baseline method. This behavior is desirable as it indi-cates that a larger number of relevant documents are being shown to the user at earlier ranks.
In this work we described a retrieval method to perform proximal search for very long patent queries in a scalable manner. Our proposed approach achieves 700% faster query response times as compared to a state-of-the-art method while maintaining, and in many cases, improving the quality
