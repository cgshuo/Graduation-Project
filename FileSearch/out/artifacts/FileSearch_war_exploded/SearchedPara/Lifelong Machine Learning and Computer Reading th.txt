 This tutorial introduces Lifelong Machine Learning (LML) and Machine Reading. The core idea of LML is to learn con-tinuously and accumulate the learned knowledge, and to use the knowledge to help future learning, which is perhaps the hallmark of human learning and human intelligence. By us-ing prior knowledge seamlessly and effortlessly, we humans can learn without a lot of training data, but current ma-chine learning algorithms tend to need a huge amount of training data. LML aims to mimic this human capability. Machine Reading is a research area with the goal of building systems to read natural language text. Among different ap-proaches employed in Machine Reading, this tutorial focuses on projects and approaches that use the idea of LML.
Most current machine learning (ML) algorithms learn in isolation. They are designed to address a specific problem using a single dataset. That is, given a dataset, an ML algo-rithm is executed on the dataset to build a model. Although this type of isolated learning is very useful, it does not have the ability to accumulate past knowledge and to make use of the knowledge for future learning, which we believe are critical for the future of machine learning and data mining. LML aims to design and develop computational systems and algorithms with this capability, i.e., to learn as humans do in a lifelong manner.

In this tutorial, we introduce this important problem and the existing LML techniques and discuss opportunities and challenges of big data for lifelong machine learning. We also want to motivate researchers and practitioners to actively explore LML as the big data provides us a golden opportu-nity to learn a large volume of diverse knowledge, to connect different pieces of it, and to use it to raise data mining and machine learning to a new level.
 Lifelong Machine Learning; Computer Reading; Never-ending Learning; Transfer Learning; Multi-task Learning.
 Researchers, graduate students, and practitioners who are interested in data mining and machine learning. The tuto-rial will particularly benefit people who intend to develop machine learning techniques and applications that can keep improving themselves after seeing more and diverse data in order to ameliorate data mining tasks.

Prerequisites: basic knowledge of machine learning and data mining.
 Zhiyuan Chen completed his Ph.D. at the University of Illinois at Chicago (UIC) under the direction of Professor Bing Liu. He joined Google in 2016. His Ph.D. thesis is  X  X ifelong Machine Learning for Topic Modeling and Classi-fication X . His research interests are Machine Learning, Nat-ural Language Processing, Text Mining, and Data Mining. He has proposed several lifelong machine learning algorithms to automatically mine valuable information from text docu-ments. He has published more than 15 full research papers at premier conferences including KDD, ICML, WWW, ACL, IJCAI, and AAAI. He is the main speaker for three con-ference tutorials, on IJCAI 2015, KDD 2016, and EMNLP 2015, respectively. He has been active in serving as a PC member for many prestigious conferences. In recognizing his outstanding academic contributions, he was awarded Fifty For The Future from Illinois Technology Foundation in 2015. Estevam R. Hruschka Jr. Estevam R. Hruschka Jr. is co-leader of the Carnegie Mellon Read the Web project (http://rtw.ml.cmu.edu/rtw/), and the head of the Machine Learning Lab (MaLL) at Federal University of Sao Carlos (UFSCar), in Brazil. He is also adjunct professor in the Ma-chine Learning Department at Carnegie Mellon University, USA, associate professor at UFSCar, Brazil and member of the AI4Good Foundation (http://ai4good.org/) Steering Committee. Estevam has been  X  X oung research fellow X  at FAPESP (Sao Paulo state research agency, Brazil) and, cur-rently, he is  X  X esearch fellow X  at CNPq (Brazilian research agency). His main research interests are never-ending learn-ing, machine learning, probabilistic graphical models and natural language understanding. He has been working on machine learning with many international research teams, collaborating with research groups from companies and uni-versities.
 Bing Liu is a professor of Computer Science at the Univer-sity of Illinois at Chicago. He received his PhD in Artificial Intelligence from the University of Edinburgh. His research interests include lifelong machine learning, sentiment analy-sis and opinion mining, data mining, machine learning, and natural language processing. He has published extensively in top conferences and journals in these areas, including a num-ber of papers on lifelong machine learning. Two of his papers have received 10-year Test-of-Time awards from KDD, the premier conference of data mining and data science. He also authored three books: one on Web data mining and two on sentiment analysis. Some of his work has been widely reported in the press, including a front-page article in The New York Times. On professional services, he serves as the current Chair of ACM SIGKDD. He has served as program chairs of many leading data mining conferences including KDD, ICDM, CIKM, WSDM, SDM and PAKDD, as as-sociate editors of leading journals such as TKDE, TWEB, DMKD, and as area chairs of numerous natural language processing, Web research, and data mining conferences. He is an ACM Fellow, an AAAI Fellow, and an IEEE Fellow. In the preparation of this tutorial, Bing Liu was supported in part by a grant from National Science Foundation (NSF) under grant no. IIS-1407927, a NCI grant under grant no. R01CA192240, and a gift from Bosch. Estevam R. Hr-uschka Jr. was supported in part by a grant from Sao Paulo State Research Agency (FAPESP), a grant from CNPq (no. 458542/2014-8) and a grant from Siena Idea.
