 Partitions of sequential data exist either per se or as a result of se-quence segmentation algorithms. It is often the case that the same timeline is partitioned in many different ways. For example, dif-ferent segmentation algorithms pr oduce different partitions of the same underlying data points. In such cases, we are interested in producing an aggregate partition, i. e., a segmentation that agrees as much as possible with the input segmentations . Each partition is defined as a set of continuous non-overlapping segments of the timeline. We show that this problem can be solved optimally in polynomial time using dynamic programming. We also propose faster greedy heuristics that work well in practice. We experiment with our algorithms and we demonstrate their utility in clustering the behavior of mobile-phone users and combining the results of different segmentation algorithms on genomic sequences. Categories and Subject Descriptors: F.2.2 [ANALYSIS OF AL-GORITHMS AND PROBLEM COMPLEXITY] : Nonnumeri-cal Algorithms and Problems; G.3 [PROBABILITY AND STATIS-TICS] : Time series analysis ; H.2.8 [DATABASE MANAGEMENT] : Database Applications X  Data mining General Terms: Algorithms, Experimentation, Theory
Analyzing sequential data has received considerable attention in the data mining community. To that aim many algorithms for ex-tracting different kinds of useful information and representation of sequential data have been proposed. For example, in time-series mining and analysis, a major trend is towards the invention of seg-mentation algorithms . These are algorithms that take as input a sequence of points in R d , and give as output a partition of the se-quence into contiguous and non-overlapping pieces that are called segments . The idea is that the variation of the data points within each segment is as small as possible, while at the same time the variation of the data across different segments is as large as possi-ble. The points in each segment can then be concisely summarized, producing a compact representation of the original sequence that compresses the data at hand, and reveals their underlying structure. The resulting representation depends obviously on the definition of Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00. Figure 1: Segmentation aggregation that takes into considera-tion only the segment information. the measure of variation. There are many different such measures, resulting in different variants of the basic segmentation problem. Numerous segmentation algorithms have appeared in the literature and they have proved useful in time-series mining [4, 16, 21, 34], ubiquitous computing [19] and genomic sequence analysis [14, 27, 32].

The multitude of segmentation algorithms and variation mea-sures raises naturally the question, given a specific dataset, what is the segmentation that best captures the underlying structure of the data? We try to answer this question by adopting a democratic approach that assumes that all segmentations found by different al-gorithms are correct, each one in its own way. That is, each one of them reveals just one aspect of the underlying true segmentation. Therefore, we aggregate the information hidden in the segmenta-tions by constructing a consensus output that reconciles optimally the differences among the given inputs. We call the problem of finding such a segmentation, the segmentation aggregation prob-lem.

The key idea of this paper lies in proposing a different view on sequence segmentation. We segment a sequence via aggrega-tion of already existing, but probably contradicting segmentations. Therefore, the input to our problem is m different segmentations S ,...,S m . The objective is to produce a single segmentation that agrees as much as possible with the given m segmentations. We define a disagreement between two segmentations S and S as a pair of points ( x, y ) such that S places them in the same seg-ment, while S places them in different segments, or vice versa. If D
A ( S, S ) denotes the total number of disagreements between S and S , then the segmentation aggregation asks for segmentation that minimizes continuous case, where each segm entation is a pa rtition of a con-tinuous timeline into segments. The discrete case can be mapped to the continuous by mapping points to elementary intervals of unit length.

As a concrete example, consider a sequence of length 6 and three segmentations of this sequence: S 1 , S 2 and S 3 as shown in Fig-ure 1. Each segmentation is defined by a set of boundaries. For example, segmentation S 1 has boundaries { 0 , 2 , 4 , 6 } boundaries i ,and i +1 defines a segment that contains all points in ( i, i +1] . For segmentation S 1 the first and second segments con-tain only a single point (point 1 and 2 respectively), the third seg-ment contains points 3 and 4, and the last segment contains points 5 and 6. The segmentation  X  S in the bottom is the optimal aggregate segmentation for S 1 , S 2 and S 3 . The total cost of  X  S is 3 , since it has one disagreement with segmentation S 1 and two disagreements with segmentation S 3 .

In this paper, we study the segmentation aggregation problem both theoretically and experimentally. Our contributions can be summarized as follows.
In the next section we give some candidate application domains for segmentation aggregation. In Section 3 we formally define the segmentation aggregation problem and the disagreement distance between segmentations, and in Section 4 we describe exact and heuristic algorithms for solving it. Section 5 provides experimental evidence of the framework X  X  utility. In Section 6 we give alterna-tive formulations of the segmentation aggregation problem and in Section 7 we discuss the related work. We conclude the paper in Section 8. Segmentation aggregation can prove useful in many scenarios. We list some of them below.
 Analysis of genomic sequences: A motivating problem of impor-tant practical value is the haplotype block structure problem. The  X  X lock structure X  discovery in haplotypes is considered one of the most important discoveries for the search of structure in genomic sequences [7]. To explain this notion, consider a collection of DNA sequences over n marker sites for a population of individuals. Con-sider a marker site to be a location on the DNA sequence associated with some value. This value is indicative of the genetic variation of individuals in this location. The  X  X aplotype block structure X  hy-pothesis states that the sequence of markers can be segmented in blocks, so that, in each block most of the haplotypes of the pop-ulation fall into a small number of classes. The description of these haplotypes can be used for further knowledge discovery, e.g., for associating specific blocks with specific genetic-influenced dis-eases [17].

From the computational point of view, the problem of discover-ing haplotype blocks in genetic sequences can be viewed as that of partitioning a multidimensional sequence into segments such that each segment demonstrates low diversity along the different dimen-sions. Different segmentation algorithms have been applied to good effect on this problem. However, these algorithms either assume different generative models for the haplotypes or optimize different criteria. As a result, they output block structures that are, to some extend (small or great) different. In this setting, the segmentation aggregation assumes that all models and optimization criteria con-tain useful information about the underlying haplotype structure, and aggregates their results to obtain a single block structure that is hopefully a better representation of the underlying truth. Segmentation of multidimensional categorical data: The seg-mentation aggregation framework gives a natural way of segment-ing multidimensional categori cal data. Although the problem of segmenting multidimensional numerical data is rather natural, the segmentation problem of multidimensional categorical sequences has not been considered widely, mainly because such data are not easy to handle. Consider an 1 -dimensional sequence of points that take nominal values from a finite domain. In such data, we can naturally define a segment as consecutive points that take the same value. For example, the sequence aaabbbcc ,has 3 segments ( a aa , bbb and cc ). When the number of dimensions in such data increases the corresponding segmentation problems becomes more complicated, and it is not straightforward how to segment the se-quence using conventional segmentation algorithms. Similar diffi-culties in using off-the-shelf segmentation algorithms appear when the multidimensional data exhibit a mix of nominal and numerical dimensions. However, each dimension has its own clear segmental structure. We propose to segment each dimension individually, and aggregate the results.
 Robust segmentation results: Segmentation aggregation provides a concrete methodology for improving segmentation robustness by combining the results of different segmentation algorithms, which may use different criteria for the segmentation, or different initial-izations of the segmentation method. Note also that most of the segmentation algorithms are sensitive to erroneous or noisy data. Such data though are very common in practice. For example, sen-sors reporting measurements over time may fail (e.g., run out of battery), genomic data may have missing values (e.g., due to insuf-ficient wet-lab experiments). Traditional segmentation algorithms show little robustness to such scenarios. However, when their re-sults are combined, via aggregation, the effect of missing or faulty data in the final segmentation is expected to be alleviated. Clustering segmentations: Segmentation aggregation gives a nat-ural way to cluster segmentations. In such a clustering, each cluster is represented by the aggregate segmentation, in the same way that the mean represents a set of points. The cost of the clustering is the sum of the aggregation costs within each cluster. Commonly used algorithms such as k -means can be adapted in this setting. Fur-thermore, the disagreements distance is a metric. Hence, we can apply various distance-based data-mining techniques to segmenta-tions, and provide approximation guarantees for many of them. Summarization of event sequences: An important line of research has focused on mining event sequences [1, 18, 22, 29]. An event sequence consists of a set of events of certain type that occur at certain points on a given timeline. For example, consider a user accessing a database at time points t 1 ,t 2 ,...,t k within a day. Or a mobile phone user making phone calls, or transferring between different cells. Having the activity times of the specific user for a number of different days one could raise the question: How does the user X  X  activity on an average day look like? One can consider the time points at which events occur as segment boundaries. In that way, forming the profile of the user X  X  daily activity is mapped naturally to a segmentation aggregation problem.
 Privacy-preserving segmentations: Consider the scenario where there are multiple parties, each having a sequence defined over the same timeline. The parties would like to find a joint segmentation of the timeline, but they are not willing to share their sequences. (Alternatively, each party might have a segmentation method that is too sensitive to be shared.) A privacy-preserving segmentation protocol for such a scenario is as follows: each party computes a segmentation of their sequence locally and sends the segmentation to one party that aggregates the local segmentations.
Let T be a timeline of bounded length. In order to make our defi-nitions as general as possible, we consider the continuous case. We will assume that T is the real unit interval (0 , 1] . For the purpose of exposition we will some times ta lk about discrete timelines. A discrete timeline T of size N can be thought of as the unit interval discretized into N intervals of equal length.

A segmentation P is a partition of T into continuous intervals (segments). Formally, we define P = { p 0 ,p 1 ,...,p } ,where p i  X  T are the breakpoints (or boundaries ) of the segmentation and it holds that p i &lt;p i +1 for all i  X  X . We will always assume that p 0 =0 and p =1 .Wedefinethe i -th segment  X  p i of P to be the interval  X  p i =( p i  X  1 ,p i ] . The length of P ,definedas the number of segments in P . Note that there is an one to one map-ping between boundaries and segments. We will often abuse the notation and define a segmentation as a set of segments instead of a set of boundaries. In these cases we will always assume that the segments define a partition of the timeline, and thus they uniquely define a set of boundaries.

For a set of m segmentations P 1 ,...,P m we define their union segmentation to be the segmentation with boundaries U = Let S be the space of all possible segmentations, and let D be a dis-tance function between two segmentations P and Q , with D : S X S X  R . Assume that function D captures how differ-ently two segmentations partition timeline T . Given such a distance function, we define the S EGMENTATION A GGREGATION problem as follows: of m segmentations P 1 ,P 2 , ..., P m of timeline T , and a distance function D between them, find a segmentation  X  S  X  X  that min-imizes the sum of the distances from all the input segmentations. That is, We define C (  X  S )= segmentation.

Note that Problem 1 is defined independently of the distance function D used between segmentations. We focus our attention on the disagreement distance D A , which we formally describe in the next subsection. Other natural alternative distance functions are discussed in Section 6. T he results we prove for D A hold for those alternatives as well.
In this section we formally define the notion of distance between two segmentations. Our distance function is based on similar dis-tance functions proposed for clustering [15] and ranking [8]. The intuition for the distance function is drawn from the discrete case. Given two discrete timeline segmentations, the disagreement dis-tance is the total number of pairs of points that are placed into the same segment in one segmentation, while placed in different seg-ments in the other. We now generalize the definition to the contin-uous case.

Let P = { p 1 ,...,p p } and Q = { q 1 ,...,q q } be two segmen-tations. Let U = P  X  Q be their union segmentation with segments {  X  u 1 ,...,  X  u n } . Note that by definition of the union segmentation, for every  X  u i there exist segments  X  p k and  X  q t such that  X  u  X  u  X   X  q t .Wedefine P (  X  u i )= k and Q (  X  u i )= t ,tobethe labeling of interval  X  u i with respect to segmentations P and Q respectively. Similar to the discrete case, we define a disagreement when two segments  X  u i ,and  X  u j receive the same label in one segmentation, but different in the other. The disagreement is weighted by the tures the number of points contained in the interval, and the product the number of disagreements between the points. This notion can be made formal using integrals, but we omit the technical details. In the discrete case points can be thought of as unit intervals.
Formally, the disagreement distance of P and Q on segments  X  u ,  X  u j  X  U is defined as follows. d
P,Q (  X  u i ,  X  u j ):=
Naturally, the overall disagreement distance between two seg-mentations is defined as follows.

It is rather easy to prove that the distance function D A ric. This property is significant for applications such as clustering, where good worst-case approximation bounds can be derived in metric spaces.
For two segmentations P and Q with p and q number of seg-ments respectively, the distance D A ( P, Q ) can be computed triv-ially in time O even faster in time O ( p + q ) . Furthermore, our analysis helps in building intuition on the general aggregation problem. This intu-ition will be useful in the following sections.
 We first define the notion of potential energy .

D EFINITION 1. Let  X  v  X  T be an interval in timeline T that has length |  X  v | . We define the potential energy of the interval to be: Let P = { p 0 ,...,p } be a segmentation with segments {  X  p  X  p } . We define the potential energy of P to be
The potential energy computes the potential disagreements that the interval  X  v can create. To better understa nd the intuition behind it we resort again to the discrete case. Let  X  v be an interval in the discrete time line, and let |  X  v | be the number of points in  X  v .There potentially cause disagreements with other segmentations.
Each of the discrete points in the interval can be thought of as a unit-length elementary subinterval and there are |  X  v | of those in  X  v , all of which are potential disagreements. Considering the continuous case is actually equivalent to focusing on very small (instead of unit length) subintervals. Let their length be  X  with  X &lt;&lt; 1 . In this case the potential disagreements caused by all the  X  -length intervals in  X  v are: when  X   X  0 . 1
The potential energy of a segmentation P is the sum of the poten-tial energies of the segments it contains. Intuitively, it captures the number of potential disagreements due to points placed in the same segment in P , while in different segments in other segmentations. Given this definition we can show the following basic lemma.
L EMMA 1. Let P and Q be two segmentations and U be their union segmentation. The distance D A ( P, Q ) can be computed by the following closed formula
P ROOF . For simplicity of exposition we will present the proof in the discrete case and talk in terms of points (rather than intervals), though the extension to intervals is straightforward. Consider the two segmentations P and Q and a pair of points x, y  X  T .For some point x let P ( x ) ,and Q ( x ) be the index of the segment that contains x in P and Q respectively. By definition, the pair ( x, y ) introduces a disagreement if one of the following two cases is true: Case 1: P ( x )= P ( y ) and Q ( x ) = Q ( y ) , Case 2: Q ( x )= Q ( y ) and P ( x ) = P ( y ) .
 In Equation 2, we can see that the term E ( P ) gives all the pairs of points that are in the same segments in segmentation P . Similarly, the term E ( U ) gives the pairs of points that are in the same seg-ments in the union segmentation U . Their difference gives the num-ber of pairs that are in the same segment in P but not in the same segment in U . However, if for two points x, y it holds that P ( x )= U is the union segmentation of P and Q . Therefore, the potential difference E ( P )  X  E ( U ) counts all the disagreements due to Case 1. Similarly, the disagreements due to Case 2 are counted by the term E ( Q )  X  E ( U ) . Therefore, Equation 2 gives the total number of disagreements between segmentations P and Q .

Lemma 1 allows us to compute the disagreements between two segmentations P and Q of size p and q respectively in time O ( ) .
We can obtain the same result by integration, however, we feel that this helps to better understa nd the intuition of the definition. In this section we give optimal and heuristic algorithms for the S
EGMENTATION A GGREGATION problem. First, we show that the optimal segmentation aggregation contains only segment bound-aries in the union segmentation. That is, no new boundaries are introduced in the aggregate segmentation. Based on this observa-tion we can construct a dynamic-programming algorithm (DP) that solves the problem exactly even in the continuous setting. If n is the size of the union segmentation, the dynamic-programming algo-rithm runs in time O ( n 2 m ) . We also propose faster greedy heuris-tic algorithms that run in time O ( n ( m +log n )) and, as shown in the experimental section, give high-quality results in practice.
Let U be the union segmentation of the segmentations S 1 ,...,S The following theorem establishes the fact that the boundaries of the optimal aggregation are a subset of the boundaries appearing in U . The proof of the theorem appears in the full version of the paper.

T HEOREM 1. Let S 1 ,S 2 ...S m be the m input segmentations to the segmentation aggregation problem for the D A distance, and let U be their union segmentation. For the optimal aggregate seg-mentation  X  S , it holds that  X  S  X  U , that is, all the segment bound-aries in  X  S belong in U .

The consequences of the theorem are twofold. For the discrete version of the problem, where the input segmentations are defined over discrete sequences of N points, Theorem 1 restricts the search space of output aggregations. That is, only 2 n (instead of 2 segmentations are valid candidate aggregations. Furthermore, this pruning of the search space allows us to map the continuous ver-sion of the problem to a discrete combinatorial search problem, and to apply standard algorithmic techniques for solving it.
We now formulate the dynamic-programming algorithm that solves optimally the segmentation aggregation problem. We first need to introduce some notation. Let S 1 ,...,S m be the input segmen-tations, and let U = { u 1 ,...,u n } be the union segmentation. Consider a candidate aggregate segmentation A  X  U ,andlet C ( A ) denote the cost of A , that is, the sum of distances of A to all input segmentations. We write C ( A )= C ( A )= D A ( A, S i ) , the distance between A and segmentation S . The optimal aggregate segmentation is the segmentation  X  minimizes the cost C (  X  S ) .

We also define a j -restricted segmentation A j to be a candidate segmentation such that the next-to-last breakpoint is restricted to be the point u j  X  U . That is, the segmentation is of the form A j = { a 0 ,...,a  X  1 ,a } ,where a  X  1 = u j . Segmentation A contains u j , and does not contain any breakpoint u k &gt;u for the last point of the sequence. To avoid confusion, we note that although a j -restricted segmentation is restricted to select bound-aries from the first j boundaries of U , it does not necessarily have length j +1 , but rather, any length  X  j +1 is possible. We use A j to denote the set of all j -restricted segmentations, and to denote the one with the minimum cost. Note that for j =0 ,  X  S notation, for j = n , where the next-to-last and the last segmenta-tion breakpoints coincide to be u n ,wehavethat  X  S n =  X  the optimal aggregate segmentation.

Let A be a candidate segmentation, and let u k  X  U be a bound-ary point such that u k /  X  A .Wedefinethe impact of u k to A to be the change (increase or decrease) in the cost that is caused by adding breakpoint u k to the A ,thatis, I ( A, u k )= C ( A { u k } )  X  C ( A ) . Wehavethat I ( A, u k )= I ( A, u j )= C i ( A  X  X  u k } )  X  C i ( A ) .
 We can now prove the following theorem.
 T HEOREM 2. The cost of the optimal solution for the S MENTATION A GGREGATION problem can be computed using a dynamic-programming algorithm ( DP ) with the following recur-sion.

P ROOF . For the proof of correctness it suffices to show that the impact of adding breakpoint u j to a k -restricted segmentation is the same for all A k  X  X  k . Recursion 3 calculates the minimum-cost aggregation correctly, since the two terms appearing in the summa-tion are independent.

Formally, for some sequence Q = { q 0 ,...,q } , and some bound-ary value b ,let Pre( Q, b )= { q j  X  Q : q j &lt;b } be the set of breakpoints in Q that precede point b . Consider a k -restricted seg-mentation A k  X  X  k with boundaries { a 0 ,...,a  X  1 ,a } X  We will prove that the impact I ( A k ,u j ) is independent of the set Pre( A k ,u k ) . Since the a  X  1 = u k for all segmentations in we have that I ( A k ,u j ) is invariant in A k .

For proving the above claim it is enough to show that I i is independent of Pre( A k ,u k ) for every input segmentation S Let U k i be the union of segmentation S i with the segmentation A . Using Lemma 1 we have that C i ( A k )= E ( A k )+ E ( S 2 E ( U k i ) . Therefore, we need to show that the change in the poten-tial of A k , S i and U k i is independent of Pre( A k ,u
Adding boundary point u j to A k has obviously no effect on the potential of S i . In order to study the effect on the potential of A and U k i we consider the general question of how the potential of a segmentation changes when adding a new breakpoint. Let Q = { q 0 ,...,q } be a segmentation, and let Q = Q  X  X  b } denote the sequence Q after the addition of breakpoint b . Assume that b falls in segment  X  q t =( q t  X  1 ,q t ] . The addition of b splits the interval  X  q into two segments  X   X  1 =( q t  X  1 ,b ] and  X   X  2 =( b, q |  X  q | = |  X   X  1 | + |  X   X  2 | . We can think of Q as being created by adding of a segmentation is the sum of the potentials of its intervals, we have that Consider now the segmentation A k . Adding u j to segmentation A k splits the last segment  X  a into two sub-segments. From Equa-tion 4 we know that the change in potential of A k depends only on the lengths of these sub-segments. Since these lengths are de-termined solely by the position of the boundary a  X  1 , the potential change is independent of Pre( A k ,u k ) .

For segmentation U k i , we need to consider two cases. If u then the addition of u j to A k does not change U k i , since the bound-ary point was already in the union. Therefore, there is no change in potential. If u j  X  S i , then we need to add breakpoint u segmentation U k i . Assume that the breakpoint u j falls in  X  u ( u  X  1 ,u t ] . The change in the potential of U k depends only on the lengths of sub-intervals into which the segment  X  u t is split. How-ever, since u j &gt;u k , and since we know that u k  X  U k that u t  X  1  X  u k . Therefore, the change in potential is independent of Pre( U k i ,u k ) , and hence independent of Pre( A k ,u
Computing the impact of every point can be done in O ( m ) time (constant time is needed for each S i ) and therefore the total com-putation needed for the evaluation of the dynamic-programming recursion is O ( n 2 m ) .
Here we present faster heuristics as alternatives to the dynamic-programming algorithm, that runs in time quadratic to the size of the union segmentation.

In this section we describe a greedy bottom-up (G REEDY BU) approach to segmentation aggregation. (The idea in the top-down greedy algorithm G REEDY TD is similar but the description is omit-ted due to lack of space.) The algorithm starts with the union seg-mentation U .Let A 1 = U denote this initial aggregate segmenta-tion. At the t -th step of the algorithm we identify the boundary b in A t whose removal causes the maximum decrease in the cost of the segmentation. By removing b we obtain the next aggregate seg-mentation A t +1 . If no boundary that causes cost reduction exists, the algorithm stops and it outputs the segmentation A t .
At some step t of the algorithm, let C ( A t ) denote the cost of the aggregate segmentation A t constructed so far. As in Section 4.2, we have that C ( A t )= b  X  A t , we need to store the impact of removing b from A t that is, the change in C ( A t ) . This may be negative, meaning that the cost decreases, or positive, meaning that the cost increases. We denote this impact by I ( b ) and as before, it can be written as I ( b )=
We will now show how to compute and maintain the impact in an efficient manner. We will show that at any step the impact for a boundary point b can be computed by looking only at local in-formation: the segments adjacent to b . Furthermore, the removal of b affects the impact only of the adjacent boundaries in A updates are also fast.

For the computation of I ( b ) we make use of Lemma 1. Let A the aggregate segmentation at step t ,andlet S i denote one of the in-put segmentations. Also, let U i denote the union segments between A t and S i . Wehavethat C i ( A t )= E ( S i )+ E ( A t )  X  Similar to Section 4.2, we can compute the impact of removing boundary b by computing the change in potential. The potential of S i remains obviously unaffected. We only need to consider the effect of b on the potentials E ( A t ) and E ( U i ) .
Assume that b = a j is the j -th boundary point of A t .Remov-ing a j causes segments  X  a j and  X  a j +1 to be merged, creating a new segment of size |  X  a j | + |  X  a j +1 | and removing two segments of size |  X  a | and |  X  a j +1 | . Therefore, the potential energy of the resulting segmentation A t +1 is
E ( A t +1 )= E ( A t )+ The boundary b that is removed from A t is also a boundary point of U i .If b  X  S i , then the boundary remains in U i even after it is removed from A t ; thus, the potential energy E ( U i ) does not change. Therefore, the impact is I i ( b )= |  X  a j ||  X  a case that b  X  S i . Assume that b = u k is the k -th boundary of U . Therefore, it separates the segments  X  u k and  X  u k I ( b )= |  X  a j ||  X  a j +1 | X  2 |  X  u k ||  X  u k +1 |
Therefore, the computation of I i ( b ) can be done in constant time with the appropriate data structure for obtaining the lengths of the segments adjacent to b . Going through all input segmentations we can compute I ( b ) in time O ( m ) . Computing the impact of all boundary points takes time O ( nm ) . Updating the costs in a naive way would result in an algorithm with cost O ( n 2 m ) .However,we do not need to update all boundary points. Since the impact of a boundary point depends only on the adjacent segments, only the impact values of the neighboring boundary points are affected. If b = a j , we only need to recompute the impact for a j  X  1 which can be done in time O ( m ) .

Therefore, using a simple heap to store the benefits of the break-points, we are able to compute the aggregate segmentation in time O ( n ( m +log n )) .
In this section we experimentally evaluate our methodology. First, on a set of generated data we show that both DP and G REEDY gorithms give results of high quality. Next, we show the usefulness of our methodology in different domains.
For this experiment we generate segmentation datasets as fol-lows. First we create a random segmentation of a sequence of length 1000 by picking a random set of boundary points. Then, we use this segmentation as a basis to create a dataset of 100 seg-mentations to be aggregated. Each segmentation is generated from the basis as follows: each segment boundary of the basis is kept identical in the output segmentation with probability (1  X  it is altered with probability p . There are two types of changes a boundary is subject to: deletion and translocation . In the case of translocation, the new location of the boundary is determined by the variance level ( v ). For small values of v the boundary is placed close to its old location, while for large values it is placed further. Figure 2 shows the ratio of the aggregation costs achieved by G
REEDY TDand G REEDY BU with respect to the optimal DP algo-rithm. It is apparent that in most of the cases the greedy alternatives give results with cost very close (almost identical) to the optimal. We mainly show the results for p&gt; 0 . 5 , since for smaller values of p the ratio is always equal to 1 . Figure 3 shows the distance (measured using D A ) between the aggregation produced by DP, G
REEDY TD and G REEDY BU and the basis segmentation used for generating the datasets. These results demonstrate that not only the quality of the aggregation found by the greedy algorithms is close to that of the optimal, but also that the structure of the algorithms X  outputs is very similar. All the results are averages over 10 inde-pendent runs.
The basic intuition of the haplotype-block problem as well as its significance in biological sciences and medicine have already been discussed in Section 2. Here we show how the segmentation-aggregation methodology can be app lied in this setting. The main problem with the haplotype block-structure problem is that although numerous studies have confirmed its existence, the methodologies that have been proposed for finding the blocks are inconclusive with respect to the number and the exact positions of their boundaries.
The main line of work related to haplotype-block discovery con-sists of a series of segmentation algorithms. These algorithms usu-ally assume different optimization criteria for block quality and segment the data so that bloc ks of good qua lity are produced. Al-though one can argue for or against each one of those optimization functions, we again adopt the aggregation approach. That is, we ag-gregate the results of the different algorithms used for discovering haplotype blocks by doing segmentation aggregation.

For the experiments we use the published dataset of [7] and we aggregate the segmentations produced by the following five differ-ent methods: 1. Daly et al. : This is the original algorithm for finding blocks 2. htSNP : This is a dynamic-programming algorithm proposed 3. DB : This is again a dynamic-programming algorithm, though 4. MDB : This is a Minimum Description Length (MDL) method 5. MDyn : This is another MDL-based method proposed by [23]. Figure 4 shows the block boundaries found by each one of the methods. The solid line shows the block boundaries found by do-ing segmentation aggregation on the results of the aforementioned five methods. The aggregate segmentation has 11 segment bound-aries, while the input segmentations have 12 , 11 , 6 , 12 and 7 seg-ment boundaries respectively, with 29 of them being unique. Note that in the result of the aggregation, block boundaries that are very close to each other in some segmentation methods (for example htSNP) disappear and in most cases they are replaced by a single boundary. Additionally, the algorithm does not always find bound-aries that are in the majority of the input segmentations. For ex-ample, the eighth boundary of the aggregation appears in only two input segmentations, namely the results of Daly et al. and htSNP.
In this experiment we demonstrate the usefulness of the segmen-tation aggregation in producing robust segmentation results, insen-sitive to the existence of outliers in the data. Consider the following scenario, where multiple sensors are sending their measurements to a central server. It can be the case that some of the sensors may fail at certain points in time. For example, they may run out of battery or report erroneous values due to communication delays in the network. Such a scenario causes outliers (missing or erroneous data) to appear. The classical segmentation algorithms are sensitive to such values and usually produce  X  X nintuitive X  results. We here Figure 5: Disagreements of S agg and S blind with the true under-lying segmentation S basis . Figure 6: Anecdote illustrative of the insensitivity of the aggre-gation to the existence of outliers in the data. show that the segmentation aggregation is insensitive to the exis-tence of missing or erroneous data via the following experiment. First, we generate a multidimensional sequence of real numbers that has an a-priori known segmental structure. We fix the num-ber of segments appearing in the data to be k =10 , and all the dimensions have the same segment boundaries. All the points in a segment are normally distributed around some randomly picked mean  X   X  [9 , 11] . One can consider each dimension to correspond to data coming from a different sensor. We report the results from a dataset that has 1000 data points, and 10 dimensions. Standard segmentation methods segment all dimensions together. We do the same using the variance of the segments to measure the quality of the segmentation. We segment all the dimensions to-gether using the standard optimal dynamic-programming algorithm for sequence segmentation [4]. We denote by S basis the segmenta-tion of this data obtained by this dynamic-programming algorithm.
Then, we simulate the erroneous data as follows: first we pick a specific subset of dimensions on which we insert erroneous blocks of data. The cardinality of the subset varies from 1 to 10 (all di-mensions). An erroneous block is a set of consecutive outlier val-ues. Outlier values are represented by 0 sinthisexample. Weuse small blocks of length at most 4 and we insert 1  X  10 such blocks. This means that in the worst case we have at most 4% faulty data points.

We segment this noisy dataset using the standard segmentation algorithm described above that blindly segments all dimensions together. We denote by S blind the segmentation produced by the dynamic-programming segmentation algorithm on this modified dataset. We also experiment with the aggregation approach. We segment each dimension separately in k =10 segments and then we aggre-gate the results. We denote by S agg the resulting aggregate segmen-tation.
 Figure 5 reports the disagreements D A ( S agg , S basis ) and D S basis ) obtained when we fix the number of erroneous blocks in-serted in each dimension and vary the number of dimensions that are faulty, and vice versa. That is, we try to compare the number of disagreements between the segmentations produced by aggrega-Figure 7: Clustering of a single user X  X  logged days into three clusters and the cluster representatives. tion and by blindly segmenting all the dimensions together, to the segmentation that would have been obtained if the erroneous data were ignored. Our claim is that a  X  X orrect X  segmentation should be as close as possible to S basis . Figure 5 indeed demonstrates that the aggregation result is much closer to the underlying true seg-mentation, and thus the aggregation algorithm is less sensitive to the existence of outliers. Figure 6 further verifies this intuition by visualizing the segmentations S basis , S agg and S blind erroneous dimensions containing 5 blocks of consecutive outliers.
The reality-mining dataset 2 contains usage information of 97 mobile phone users [9]. A large percentage of these users are either students (masters students, freshmen, graduate students) or faculty (professors, staff) of the MIT Media Laboratory, while the rest are incoming students at the MIT Sloan business school, located adja-cent to the laboratory. The collected information includes call logs, Bluetooth devices in proximity, cell tower IDs, application usage, and phone status (such as charging and idle) etc. The data spans a period from September 2004 to May 2005 . We mainly focus our analysis on the data related to the callspan of each user. The callspan data has information related to the actual times each user places a phonecall.

From this data we produce segmentations as follows: for each user, and each day during which he has been logged, we take the starting times reported in the callspan and we consider them as seg-ment boundaries on the timeline of the day. For example, a user that is logged for 30 days, produces 30 different segmentations, one for each day.
In our first experiment, we cluster the days of a single user. Since each day is represented as a segmentation of the 24 -hour timeline, clustering the days corresponds to clustering these segmentations. We use distance D A for comparing the different days. The def-inition of segmentation aggregation allows naturally to define the  X  X ean X  of a segmentation cluster to be the aggregation of the seg-mentations that are grouped together in the cluster. We can then readily apply the classical k -means algorithm to the space of seg-mentations.
The interested reader can find the datasets at http:// reality.media.mit.edu/ Figure 8: The clustering structure of the reality-mining user data
Figure 7 shows the clustering of the days of a single user (who is classified as a professor in the dataset) over a period of 213 days starting from September 2004 to May 5 th 2005 (not all days are recorded). The plot on the top shows the clustering of the days. The days are arranged sequentially and the different colors corre-spond to different clusters. It is apparent that at the beginning of the recorded period the patterns of the user are quite different from the patterns observed at later points in the study. More specifically, all the initial days form a single rather homogeneous cluster. From [9] we take the information that during this period the Media Lab sub-jects had been working towards the annual visit of the laboratory X  X  sponsors. It had been previously observed that this had affected the subjects X  schedules. It is possible that our methodology captures this pattern. The rest of Figure 7 shows the representatives of each cluster. We observe that the representatives are rather distinct con-sisting of profiles where the users use their phone either in morning hours, or in evening hours, or both.
In the second experiment we try to build clusters of users that show similar patterns in their activities. For this, we build the pro-file of each user, by aggregating all the days he has been logged for. Next, we cluster the user profiles, using the k -means algorithm for segmentations, as discussed in the previous paragraph. Figure 8 gives visual evidence of the existence of some clusters of users in the dataset. The plot shows the distances between user profiles, in terms of disagreement distance. The rows and the columns of the distance matrix have been rearranged so that users clustered together are put in consecutive rows (columns). The darker the col-oring of a cell at position ( i, j ) the more similar users i and j are. There are some evident clusters in the dataset, like for example the one consisting of users at positions 1  X  10 , 33  X  38 , 39 55  X  68 and 69  X  77 . Note that the cluster containing users 55 is characterized not only by strong similarity between its members, but additionally a strong dissimilarity to almost every other user in the dataset.

From these groups, the third one, consisting of rows 39  X  seems to be very coherent. We further looked at the people consti-tuting this group and found out that most of them are related (being probably students) to the Sloan business school. More specifically, the academic/professional positions of the people in the cluster, as reported in the dataset, are as follows.
 sloan, mlUrop, sloan, sloan, sloan, sloan, 1styeargrad, sloan, 1styeargrad, mlgrad, sloan, sloan, sloan, staff, sloan, sloan Similarly, the relatively large and homogeneous group formed by lines 1  X  10 consists mostly from staff and professors.
The cluster of users 55  X  68 , although quite homogeneous and distinct from the rest of the dataset, it contains a rather diverse set of people, at least with respect to their positions. However there may be another link that makes their phone-usage patterns similar, and separates them from the rest of the users. In this section we discuss alternative formulations of the S MENTATION A GGREGATION problem. The differences are due to the alternative distance functions that can be used for comparing segmentations.
The entropy distance between two segmentations quantifies the information one segmentation reveals about the other. In general, the entropy distance between two random variables X and Y that take values in domains X and Y respectively is defined as where H (  X | X  ) is the conditional entropy function and
For segmentations this can be applied as follows. Let Q = { q 0 ,...,q q } be a segmentation that partions the unit real inter-val. Let i be the label of the interval  X  q i =( q i  X  1 notation, we define a random variable Q :(0 , 1]  X  X  1 ,..., where Q ( x )= i for x  X   X  q i . Assuming that x is drawn uniformly at random, we have that Pr [ Q ( x )= i ]= |  X  q i | . In plain terms, each segment is chosen with proba bility proportional to its length. Given two segmentations Q and P we define the joint distribution of the random variables Q and P as P [ i, j ]= |  X  q i  X  probability that a r andomly chosen point falls in the intersection of the segments  X  q i and  X  p j . We can now define the entropy distance D H ( P, Q ) between segmentations, using Equation 5.

The entropy distance is also a metric. Computing the entropy distance between two segmentations can be done in linear time. The main idea of this linear-time algorithm is a decomposition of D H ( P, Q ) similar to the decomposition of D A ( P, Q ) showed in Lemma 1 (Equation 2), using the concept of potential energy. For the entropy distance the potential energy of segmentation P is E ( P )=  X  H ( P ) .

Furthermore, solving the S EGMENTATION A GGREGATION prob-lem (Problem 1) for D H can also be done optimally using a dynamic-programming algorithm. This algorithm is a variation of the DP algorithm discussed in Section 4. The recursion of the algorithm is again based on the fact that adding a new breakpoint has only a local effect on the cost of the segmentation. The details of the al-gorithms for the entropy distance are omitted due to lack of space.
The Boundary Mover X  X  Distance ( D B ) 3 compares two segmen-tations P and Q considering only the distances between their bound-ary points. Let the boundary points of P and Q be { p 0 ,...,p
The name is inspired by the Earth Mover X  X  Distance [31]. and { q 0 ,...,q q } . We define the Boundary Mover X  X  distance of P with respect to Q to be Two natural choices for r is r =1 and r =2 .For r =1 the Bound-ary Mover X  X  distance employs the Manhattan distance between the segment boundaries, while for r =2 it uses the sum-of-squares distance.

The S EGMENTATION A GGREGATION problem for distance D B with m input segmentations S 1 ,...,S m asks for an aggregate seg-mentation  X  S of at most t boundaries such that:
Note that in this alternative definition of the segmentation aggre-gation problem we have to restrict the number of boundaries that can appear in the aggregation. Otherwise, the optimal  X  S will con-tain the union of boundaries that appear in P and Q  X  such a seg-mentation will have total cost equal to 0 . One can easily see that this alternative definition of the segmentation aggregation problem can also be solved optimally in polynomial time. More specifically, the problem of finding the best aggregation with at most t segment boundaries is equivalent to one-dimensional clustering that can be solved using dynamic programming. For the mapping, consider the boundaries of the input segmentations to be the points to be clustered, and the boundaries of the aggregation to be the cluster representatives. We note that for the case r =1 the boundaries of the aggregate segmentation are again a subset of the union segmen-tation.
Related work on segmentation algorithms and their practical util-ity has already been discussed in Section 1. Though these algo-rithms are related to our work, our goal here is not just to propose a new segmentation algorithm but to aggregate the results of existing algorithms.

There exists a considerable amount of work for building indi-vidual, system or network temporal profiles that can be used in anomaly or misuse detection, prediction of mobile-phone users etc., as for example in [11, 26, 24, 28]. These methods approach the problem from a different view point and segmentations are not a central concept in this approach. Though we explore the applica-bility of segmentation aggregation in clustering users and build-ing user profiles, performing exhaustive experiments on profile-building is beyond the scope of this paper. Exploring the rela-tionship of our method to other profiling methods is an interesting question for future work.

Most related to our work are other aggregation problems that have been extensively studied. The notion of aggregation has re-cently emerged in several data-mining tasks. The problem of ag-gregating clusterings has been studied under the names of cluster-ing aggregation [15], consensus clustering [2, 25] and cluster en-sembles [12, 33]. Ranking aggregation has been studied from the viewpoints of algorithmics [2], Web search [8], databases [10], and machine learning [13]. A third important group of aggregating data mining results is formed by voting classifiers such as bagging [5] and boosting [6].

Our work is similar in spirit, since we are also trying to aggre-gate results of existing data-mining algorithms. However, although the segmentation problem has received considerable attention by the data-mining community, to the best of our knowledge, the seg-mentation aggregation problem has not been previously studied.
We have presented a novel approach to sequence segmentation, that is based on the idea of aggregating existing segmentations. The utility of segmentation aggregation has been extensively discussed via a set of useful potential applications. We have formally de-fined the segmentation aggregation problem and showed some of its interesting properties. From the algorithmic point of view, we showed that we can solve it optimally in polynomial time using dy-namic programming. Furthermore, we designed and experimented with greedy algorithms for the problem, which although not opti-mal, in practice they are both fast and give results of high quality (almost as good as the optimal). Th e practical utility of the problem and the proposed algorithms has been illustrated via a broad exper-imental evaluation that includes applications of the framework on genomic sequences and users X  mobile-phone data. We additionally demonstrated that segmentation aggregation is a noise and error-insensitive segmentation method that can be used to provide trust-worthy segmentation results.
 We would like to thank Aris Gionis and Heikki Mannila for many useful discussions and suggestions. The work was partially sup-ported by APrIL II (FP6-508861). [1] A GRAWAL ,R., AND S RIKANT , R. Mining sequential [3] A NDERSON ,E.C., AND N OVEMBRE , J. Finding haplotype [4] B ELLMAN , R. On the approximation of curves by line [5] B REIMAN , L. Bagging predictors. Machine Learning 24 ,2 [6] C OLLINS ,M.,S CHAPIRE ,R.E., AND S INGER , Y. Logistic [7] D ALY ,M.J.,R IOUX ,J.D.,S CHAFFNER ,S.F.,H UDSON , [8] D WORK ,C.,K UMAR ,R.,N AOR ,M., AND S IVAKUMAR , [9] E AGLE , N. Machine perception and learning of complex [10] F AGIN ,R.,K UMAR ,R.,M AHDIAN ,M.,S IVAKUMAR ,D., [11] F AN ,W., AND S TOLFO , S. J. Ensemble-based adaptive [12] F RED ,A.L., AND J AIN , A. K. Combining multiple [13] F REUND ,Y.,I YER ,R.,S CHAPIRE ,R.E., AND S INGER ,Y. [14] G IONIS ,A., AND M ANNILA , H. Finding recurrent sources [15] G IONIS ,A.,M ANNILA ,H., AND T SAPARAS , P. Clustering [16] G UHA ,S.,K OUDAS ,N., AND S HIM , K. Data-streams and [17] G USFIELD , D. An overview of haplotyping via perfect [19] H IMBERG ,J.,K ORPIAHO ,K.,M ANNILA ,H., [21] K EOGH ,E.,C HU ,S.,H ART ,D., AND P AZZANI ,M.An [22] K LEINBERG , J. Bursty and hierarchical structure in streams. [23] K OIVISTO ,M.,P EROLA ,M.,V ARILO ,T., ET AL .AnMDL [24] L ANE ,T., AND B RODLEY , C. E. Temporal sequence [25] L ANGE ,T., AND B UHMAN , J. M. Combining partitions by [26] L EE ,W., AND S TOLFO , S. J. A framework for constructing [27] L I , W. DNA segmentation as a model selection process. In [28] L I ,Y.,W U ,N.,J AJODIA ,S., AND W ANG , X. S. Enhancing [30] P ATIL ,N.,B ERNO ,A.J.,H INDS ,D.A., ET AL .Blocksof [31] R UBNER ,Y.,T OMASI ,C., AND G UIBAS ,L.J.Theearth [32] S ALMENKIVI ,M.,K ERE ,J., AND M ANNILA , H. Genome [33] S TREHL ,A., AND G HOSH , J. Cluster ensembles  X  a [34] T ERZI ,E., AND T SAPARAS , P. Efficient algorithms for [35] Z HANG ,K.,C HENG ,M.,C HEN ,T.,W ATERMAN ,M.,
