 With the ubiquity of information networks and their broad applications, the issue of similarity computation between en-tities of an information network arises and draws extensive research interests. However, to effectively and comprehen-sively measure  X  how similar two entities are within an in-formation network  X  is nontrivial, and the problem becomes even more challenging when the information network to be examined is massive and diverse. In this paper, we pro-pose a new similarity measure, P-Rank ( P enetrating Rank ), toward effectively computing the structural similarities of entities in real information networks. P-Rank enriches the well-known similarity measure, SimRank ,byjointlyencoding both in-and out-link relationships into structural similarity computation. P-Rank is proven to be a unified structural similarity framework, under which all state-of-the-art simi-larity measures, including CoCitation , Coupling , Amsler and SimRank , are just its special cases. Based on its recursive nature of P-Rank , we propose a fixed point algorithm to reinforce structural similarity of vertex pairs beyond the lo-calized neighborhood scope toward the entire information network. Our experimental studies demonstrate the power of P-Rank as an effective similarity measure in different in-formation networks. Meanwhile, under the same time/space complexity, P-Rank outperforms SimRank as a comprehen-sive and more meaningful structural similarity measure, es-pecially in large real information networks.
 G.2.2 [ Graph Theory ]: Graph algorithms; H.2.8 [ Database Applications ]: Data mining Algorithms, Measurement, Performance, Reliability Structural similarity, Information network, Graph mining
Social and technical information systems usually consist of a large number of interacting physical, conceptual, and human/societal entities. Such individual entities are inter-connected to form large and sophisticated networks. With-out loss of generality, we call these interconnected networks as information networks ( IN s). Examples of INs include the Web [15], highway or urban transportation networks [11], re-search collaboration and publication networks [8], biological networks [21] and social networks [19]. Clearly, INs are ubiq-uitous and form a critical component of modern information infrastructure.

In this paper, we focus on the problem of similarity com-putation on entities of INs. Our study is motivated by recent research and applications on proximity query processing, outlier detection, classification and clustering over different INs, which usually require an effective and trustworthy eval-uation of underlying similarity functions among entities. It is desirable to propose a comprehensive similarity measure onINswhichcanbothmaphumanintuitionandgeneralize well under different IN settings. However, it is nontrivial to systematically compute entity similarity in a general and effective fashion, and it becomes especially challenging when the INs to be examined are massive and diverse.

In the mean time, multiple aspects of entities in INs can be exploited for similarity computation, and the choices are usually made domain-specifically. In this paper, we propose a new structural similarity measure, P-Rank ( P enetrating Rank ),whichsolelyexploresthelinkstructureoftheun-derlying INs for similarity computation. Compared with traditional text contents, the link-based structural informa-tion is more homogenous and language independent, which is critical for similarity computation [18]. Concretely, within anIN,wecomputeP-Rankthatsays X  two entities are simi-lar if (1) they are referenced by similar entities; and (2) they reference similar entities.  X  In comparison with the state-of-the-art structural similarity measure, SimRank [10], which considers the first aforementioned factor only, P-Rank en-codes both in-and out-link relationships into computation toward a semantically complete and robust similarity mea-sure. Moreover, similarity beliefs of entity pairs are prop-agated beyond local neighborhood scope to the entire IN, whose global structure is fully utilized in order to reinforce similarity beliefs of entites in a recursive fashion. P-Rank is also proven to be a general framework for structural simi-larity of INs and can easily be adapted in any IN settings wherever there exist enough interlinked relationships among entities. For practical applicability, P-Rank can be effectively Figure 1: A Heterogenous IN and Structural Simi-larity Scores for SimRank ( C =0 . 8 )and P-Rank ( C = 0 . 8 ,  X  =0 . 5 ) coupled with other non-structural domain-specific similarity measures, for example, textual similarity, toward a unified similarity measure for INs.
 Example 1.1: (A Heterogeneous IN) Consider a het-erogeneous information network G in Figure 1, representing a typical submission, bid, review and acceptance procedure of a conference. G is regarded as heterogeneous if vertices (entities) of G belong to different mutual exclusive cate-gories, such as Conf erence = { c } , CommitterM ember = { m 1 ,m 2 ,m 3 } and Paper = { p 1 ,p 2 ,p 3 ,p 4 } . Directed edges model the relationships between vertices in different cate-gories. Two structural similarity measures, SimRank and P-Rank , for different vertex pairs of G are illustrated as well. As shown in Figure 1, the conference c is considered similar to itself, and the similarity scores (for both SimRank and P-Rank ) are set to be 1. For committee member pairs { m 1 m 2 } , { m 1 , m 3 } ,and { m 2 , m 3 } ,asbothverticesofeach pair are pointed to by c (they both are invited as commit-tee members by the conference, c ), we may infer that they are similar. However, SimRank cannot differentiate among these three pairs. (They have the same SimRank score, 0 . 4). Themainreasonisthatforcommitteememberpairs, Sim-Rank considers the in-link relationships with the vertex c only, while neglecting out-link relationships with paper ver-tices { p 1 ,p 2 ,p 3 ,p 4 } . P-Rank , however, takes into account of both in-and out-link relationships for similarity computa-tion. As to { m 1 , m 2 } , for example, because they both point to p 2 (both m 1 and m 2 bid for paper p 2 ), the structural sim-ilarity between them is further strengthened ( P-Rank score is 0 . 420, which is different from that of { m 2 , m 3 } and that of { m 1 , m 3 } (0 . 380)). We generalize this idea by observing that once we have concluded similarity between m 1 and m 2 , p 1 and p 3 are similar as well because they are pointed to by m 1 and m 2 , respectively, although this in-ference is somehow weakened during similarity propagation. Continuing forth, for every comparable pair of vertices in G , we can infer P-Rank between them.
 Example 1.2: (A Homogeneous IN) Consider a homo-geneous information network G in Figure 2, representing a tiny literature graph. G is homogeneous if vertices of G , which represent scientific publications in this example, all belong to one category ( X  X ublication X ). Edges between vertices are references/citations from one paper to another. Different from heterogeneous INs, any pair of vertices in ho-mogenous INs can be measured by their structural similarity because they all belong to the same category. We present SimRank and P-Rank scores for some of them, as shown in Figure 2. SimRank cannot tell the differences between the vertex pair { P2 , P3 } and { P3 , P4 } , solely because Sim-Rank considers partial relationship information for similarity Figure 2: A Homogeneous IN and Structural Sim-ilarity Measures for SimRank ( C =0 . 8 )and P-Rank ( C =0 . 8 ,  X  =0 . 8 ) computation. More severely, SimRank is unavailable for the vertex pairs { P4 , P5 } and { P2 , P5 } , mainly because these vertex pairs do not have common in-link similarity flows. However, P-Rank can successfully infer structural similarity for all vertex pairs by considering both in-and out-link re-lationships into computation, thus outperforms SimRank in homogeneous INs.

As its name dictates, P-Rank encodes both in-and out-link relationships of entities in similarity computation, i.e. , P-Rank scores flow from in-link neighbors of entities and penetrate through their out-link ones. Furthermore, this process is recursively propagated beyond the localized neigh-borhood scope of entities to the entire IN. The major mer-its of P-Rank are its semantic completeness, generality and robustness. As a comprehensive structural similarity mea-sure, P-Rank can be effectively adapted in INs with different variety and scale, in which most up-to-date similarity mea-sures, like SimRank , may generate biased answers or simply fail due to the incomplete structural information considered during similarity computation, as illustrated in Example 1.1 and Example 1.2. In order to compute P-Rank efficiently, we propose an iterative algorithm which converges fast to a fixed-point. The correctness of the algorithm is proven that the iterative algorithm always converges to its theoretical upper bound.

The contributions of this paper are summarized as follows: 1. We propose a new structural similarity measure, P-2. We propose a fixed-point iterative P-Rank algorithm 3. P-Rank is shown to be a unified structural similarity 4. We do extensive experimental studies on both real and
The rest of the paper is organized as follows. Section 2 discusses related work. In Section 3, we present our struc-tural similarity measure, P-Rank , from both mathematical and algorithmic perspectives. We report our experimental studies in Section 4. Section 5 concludes the paper.
As common standards to determine the closeness of dif-ferent objects, similarity (or proximity) measures are crucial and frequently applied in clustering, nearest neighbor clas-sification, anomaly detection and similarity query process-ing. Compared with traditional textual contents, link-based structural context in INs is of special importance and ex-ploited frequently in similarity computation. In previous studies, SimFusion [23] aimed at  X  X ombining relationships from multiple heterogeneous data sources X . [16] proposed a similarity measure based on PageRank score propagation through link paths. [7] explored methods for ranking partial tuples in a database graph. Maguitman et al. did extensive comparative studies on different similarity measures [18], and the results demonstrate that link-based structural sim-ilarity measures produce systematically better correlation with human judgements compared to the text-based ones.
In bibliometrics, similarities between scientific publica-tions are commonly inferred from their cross-citations. Most noteworthy from this field are the methods of CoCitation [22], Coupling [13] and Amsler [1]. For CoCitation , the similarity between two papers p and q is based on the number of papers which reference both p and q .For Coupling , the similarity is based on the number of papers referenced by both p and q . Amsler fuses both CoCitation and Coupling for similarity computation. These methods have been efficiently applied to cluster scientific publications and web pages [20].
SimRank [10, 6, 17], together with its variant [2], is an iter-ative PageRank-like structural similarity measure for INs. It goes beyond simple CoCitation much as PageRank goes be-yond direct linking for computing importance of web pages. The weakness of SimRank ,calledthe limited information problem , is discussed in [10]. SimRank makes use of in-link relationships only for similarity computation while ne-glecting similarity beliefs conveyed from out-link directions. Therefore, the structural information of INs is partially ex-ploited and the similarity computed is inevitably asymmet-ric and biased. In real INs, those  X  unpopular entities  X , i.e. , entities with very few in-link relationships will be penalized by SimRank . More severely, SimRank canevenbeunavail-able for entities with no in-link similarity flows (shown in Example 1.2). However, those entities with few or no in-links are dominating the INs in quantity, as expressed by the power law distribution and heavy-tailed in(out)-degree distribution [4]. Meanwhile, these entities are often not ne-glectable because they are new, potentially popular, and in-teresting to most users. However, they tend to be harder for humans to find. To overcome the limited information prob-lem of SimRank , we propose P-Rank which refines structural similarity by jointly considering both in-and out-link rela-tionships of entity pairs. Furthermore, the similarity compu-tation goes beyond the localized neighborhood so that the global structural information of INs are exploited to rein-force similarity beliefs of entities. As discussed in the re-minder of the paper, with the same time/space complexity as SimRank , P-Rank can achieve much better results and solve the limited information problem effectively. Heymans et al. [9] proposed similar ideas to model structural simi-larity of enzymes in metabolic pathway graphs in order for the phylogenetic analysis of metabolic pathways. However, their similarity are on vertices in different graphs and if the factors of dissimilarity and absence of edges are not consid-ered, their work can be regarded as a special case of P-Rank ( C =1and  X  =0 . 5).
 Iterative fixed-point algorithms over the web graph, like HITS [14] and PageRank [3], have been studied and applied to compute  X  X mportance X  scores for Web pages. Results show that the usage of structure of INs can greatly improve search performance versus text alone.
The basic recursive intuition of P-Rank can be expressed as  X  two entities in an IN are similar if they are related to similar entities  X . More specifically, the two-fold meaning of P-Rank is elaborated as 1. two entities are similar if they are referenced by similar 2. two entities are similar if they reference similar enti-As the base case, we consider an entity maximally similar to itself, to which we can assign the P-Rank score of 1. (If other entities are known to be similar a-priori , their similar-ities can be pre-assigned as well.) For each pair of distinct entities, we take into consideration both their in-and out-link relationships for similarity computation. This similarity is then penetrating from in-link neighbors to out-link ones and propagated toward the entire IN.
We model an IN as a labeled directed graph G =( V, E,  X ; l ) where vertex v  X  V represents an entity of the domain and adirectededge u, v  X  E represents a relationship from entity u to entity v , where u, v  X  V .  X  is an alphabet set and l : V  X   X  is a labeling function. In heterogeneous INs, V = { V 1 V 2  X  X  X  V n } can be partitioned into n mu-tual exclusive vertex subsets, V 1 ,V 2 ,  X  X  X  ,V n , V i V 1  X  i, j  X  n ,whichbelongto n different domain-specific categories. In homogeneous INs, however, there is no dis-tinction among vertices. Note that our definition of INs can be naturally extended to undirect graph or edge-weighted graph settings.
 For a vertex v in a graph G ,wedenoteby I ( v )and O ( v ) the set of in-link neighbors and out-link neighbors of v , respectively. Note that either I ( v )and O ( v )canbe empty. An individual in-link neighbor is denoted as I i ( v ), for 1  X  i  X | I ( v ) | ,if I ( v ) =  X  , and an individual out-link neighbor is denoted as O i ( v ), for 1  X  i  X | O ( v ) | ,if O ( v ) =
We denote the P-Rank score for vertex a and b by s ( a, b ) [0 , 1]. Following our aforementioned intuition, P-Rank can be formalized recursively in Equation (1), when a = b :
Otherwise, P-Rank is defined as
In Equation (1), the relative weight of in-and out-link directions is balanced by parameter  X   X  [0 , 1]. C is set as a damping factor for in-and out-link directions, C  X  [0 , 1] The reason is that s ( a, b ) will be attenuated during similarity propagation. When I ( a )(or I ( b )) =  X  , the in-link part is invalidated and only the out-link direction takes into effect. Similarly, when O ( a )(or O ( b )) =  X  , only the similarity flows from in-link part are considered. If both I ( a )(or I ( b )) = and O ( a )(or O ( b )) =  X  , we define s ( a, b )=0. Equation (1) is written for every pair of vertices a, b  X  resulting in a set of n 2 equations for a graph of size n .To solve the set of n 2 equations, we rewrite the recursive P-Rank formula (shown in Equation (1)) into the following iterative form and where R k ( a, b )denotesthe P-Rank score between a and b on iteration k ,for a = b and R k ( a, b )=1for a = b .We progressively compute R k +1 (  X  ,  X  )basedon R k (  X  ,  X  is, on iteration ( k + 1), we update R k +1 ( a, b )bythe P-Rank scores from the previous iteration k . This iterative compu-tation starts with R 0 (  X  ,  X  ) where R 0 ( a, b ) is a lower bound of the actual P-Rank score, s ( a, b ).
 Theorem 3.1: The iterative P-Rank equations (shown in Equation (3) and Equation (4)) have the following properties 1. ( Symmetry ) R k ( a, b )= R k ( b, a ) 2. ( Monotonicity )0  X  R k ( a, b )  X  R k +1 ( a, b )  X  1 3. ( Existence ) The solution to the iterative P-Rank equa-4. ( Uniqueness ) the solution to the iterative P-Rank equa-Proof: Shown in Appendix.
 Theorem 3.1 demonstrates four important properties of P-Rank .Foranyvertices a, b  X  G ,theiterative P-Rank be-tween a and b is the same as that between b and a , i.e. , P-Rank is a symmetric measure, as mentioned in property 1( Symmetry ). Property 2 ( Monotonicity ) shows that the iterative P-Rank is non-decreasing during similarity compu-tation. However, the solution will not go to infinity. Prop-erty 3 ( Existence )and4( Uniqueness ) guarantee that there exists a unique solution to n 2 iterative P-Rank equations, which can be reached by iterative computation to a fixed
For a more general form of P-Rank , C canbereplacedby two different parameters C in and C out to represent damping factors for in-and out-link directions, respectively. We omit the details as it is fairly easy to extend our work into that scenario.

Figure 3: Structural Similarity Matrix for INs point, i.e. , the solution to iterative P-Rank converges to a limit which satisfies the recursive P-Rank equation, shown in Equation (1): In real applications, iterative P-Rank converges very fast (de-tails are shown in Section 4). Empirically, we can choose to fix a small number of iterations ( k  X  5) to derive P-Rank for allpairofverticesinrealINs.
Besides its semantic completeness with a consideration of both in-and out-link relationships in similarity computa-tion, P-Rank outperforms other structural similarity mea-sures by its generality and flexibility. As shown in Figure 3, all of the state-of-the-art structural similarity measures pro-posed so far for INs are illustrated in the structural simi-larity matrix. Among all measures shown in Figure 3, P-Rank enjoys the most general form, from both the semantic completeness perspective and the structure perspective. All other measures, such as CoCitation , Coupling , Amsler and SimRank , are just simplified special cases of P-Rank and can be easily derived from P-Rank . P-Rank therefore provides a unified framework for structural similarity computation in INs. By analyzing the iterative P-Rank shown in Equa-tion (4), we can draw the following conclusions: 1. When k =1, C =1and  X  =1, P-Rank is reduced to 2. When k =1, C =1and  X  =0, P-Rank is reduced to 3. When k =1, C =1and  X  =1 / 2, P-Rank is reduced to 4. When k  X  X  X  and  X  =1, P-Rank boils down to Sim-5. When k  X  X  X  and  X  =0, P-Rank is degenerated to a
In real applications, P-Rank can be adapted flexibly to different IN settings, as long as there exist enough inter-linked relationships between entities. Even when the IN to be studied has sparse in-link information or biased edge dis-tributioninwhich SimRank may fail, P-Rank can still work well in modeling structural similarities.

Another important issue is to select appropriate values for parameters C ,  X  and k in P-Rank computation. C represents the degree of attenuation in similarity propagation, and  X  expresses the relative weight of similarity computation be-tween in-link and out-link directions. A priori knowledge of the IN infrastructure is usually helpful to select the values of C and  X  . By sampling a set of subgraphs from the original IN, we can learn the characteristics of the underlying IN, and C ,  X  can be set based on the sampled subgraphs as an approximation. The convergence of iterative P-Rank is fast with only several iterations of computation, so k is usually set empirically as a small constant number. In Section 4, we will systematically study the effects of different parameters on P-Rank computation.
Based on Section 3.2, the solution to the recursive P-Rank formula (Equation (1)) can be reached by computing its it-erative form (Equation (4)) to a fixed point. Algorithm 1 illustrates the iterative procedure for computing P-Rank in an IN, G .Let n bethenumberofverticesin G and k be the number of iterations executed until P-Rank converges to its fixed point. For every vertex pair ( a, b ), an entry R ( a, b ) maintains the intermediate P-Rank score of ( a, b )duringit-erative computation. Because the ( k +1)-th iterative P-Rank score is computed based on P-Rank scores in the k -th itera-tion, an auxiliary data structure R  X  ( a, b ) is maintained ac-cordingly. As proven in Theorem 3.1(1), R k ( a, b )= R k so only one order for each pair is stored explicitly. In real implementations, either sparse matrixes or hash tables can be chosen as core data structures for R (  X  ,  X  )and R  X  ( cause G canbesolargeasnottobeheldinmainmemory, any advanced data structures that optimize external mem-ory accesses can be applied.

Algorithm 1 first initializes R 0 ( a, b ) based on Equation 3 (Lines 1  X  4). During iterative computation, P-Rank in ( k + 1)-th iteration, R  X  (  X  ,  X  ), is updated by R (  X  iteration, based on Equation 4 (Lines 6  X  18). Then R (  X  substituted by R  X  (  X  ,  X  ) for further iteration (Lines 19 This iterative procedure stabilizes rapidly and converges to a fixed point within a small number of iterations. A typical call to the algorithm can be P-Rank ( G ,0 . 5, 0 . 8, ln ( n ) ), where the relative weight  X  is set to be 0 . 5 and the damping factor C is set to be 0 . 8.

The space complexity of Algorithm 1 is O ( n 2 ), the amount to store intermediate and final P-Rank scores of G , i.e. ,the Algorithm 1 : P-Rank ( G ,  X  , C , k ) size of R  X  (  X  ,  X  )and R (  X  ,  X  ). Let d 1 and d 2 be the average in-degree and out-degree over all vertices of G , respectively, the time complexity of the algorithm is O ( k ( d 2 1 + d the worst case time complexity can be O ( n 4 ). In comparison with SimRank whosespaceandtimecomplexitiesare O ( n 2 ) and O ( n 4 ), P-Rank has the same space and time complexities with SimRank .
 In [17], the authors improved the time complexity of Sim-Rank from O ( n 4 )to O ( n 3 ). Thesamememoizationbased algorithms can be applied in the same way on P-Rank to re-duce its time complexity to O ( n 3 ). In [6], the authors sug-gested a scalable framework for SimRank computation based on the Monte Carlo method. Essentially their computation is probabilistic and the SimRank scores computed are an ap-proximation to the exact answer. In order to make full use of characteristics of different INs, we propose different pruning algorithms to efficiently compute P-Rank .
 Homogeneous Information Network: In homogeneous INs, all vertices of G are of the same type. One way to re-duce the space/time complexities in this scenario is to prune less similar vertex pairs while not deteriorating the accuracy of similarity computation too much. For n 2 vertex-pair of G , only those adjacent to each other (say, vertices within a radius of 3 or 4) are similar, while those whose neighbor-hood have little or no overlap are far apart and inevitably not similar. Thus radius-based pruning [10] can be used to set the similarity between two vertices far apart to be 0, and only those vertex-pairs within a radius of r from each other in the underlying undirected graph G are considered in similarity computation. Given a vertex u  X  G , let there be d r such neighbors of u within a radius r on the underly-ing undirect graph G on average, then there will be ( n  X  vertex-pairs considered. The space and time complexities d is likely to be much less than n ,if r is small w.r.t. n ,we can think of this approximate algorithm as being linear with a possibly large constant factor.
 Heterogeneous Information Network: In heterogeneous INs, vertices of G belong to different categories. Given two vertices u, v  X  G , it is meaningless to measure structural similarity between u and v if they belong to different cate-gories. Thus the pruning technique in this scenario, called category-based pruning , is to set the similarity between two vertices belonging to different categories to be 0, and con-sider only those vertex pairs within the same category. Let there be c different categories over the vertices of G ,and for each category i ,therebe n i vertices included, where 1  X  i  X  c , then the total number of vertex pairs is c i =1 The space and time complexities then become O ( c i =1 n 2 holds, Category-based pruning can eliminate a huge number of ver-tex pairs belonging to different categories, especially when c is large. If the number of vertices in a specific category is still so large that they cannot be held in main memory, radius-based pruning can be further applied within this cat-egory to facilitate the computation. [24] presented an ad-vanced index-based algorithm, SimTree , for fast computa-tion of similarity scores in heterogeneous INs if vertices in every category are hierarchically organized. Our category-based pruning algorithm is actually the specialized one-level SimTree .
In this section, we report our experimental studies on the effectiveness of P-Rank as a comprehensive structural sim-ilarity measure over different INs. We show the power of P-Rank in comparison with the state-of-the-art structural similarity measure, SimRank . In addition, the experiments illustrate the feasibility and efficiency of the P-Rank algo-rithm with pruning techniques in INs with different diversity and scale.

We ran our experiments on two different datasets: one is real data from DBLP 2 and the other is synthetic [5]. For the real dataset, we further generate two different INs: one is a heterogeneous IN and the other is a homogeneous IN. All our experiments are performed on an Intel PC with a 2 . 4GHz CPU, 2GB memory, running Redhat Fedora Core 4. All algorithms including P-Rank and SimRank are implemented in C++ and compiled by gcc 3 . 2 . 3. For ease and fairness of comparison, we set the damping factor C =0 . 8forboth SimRank and P-Rank ;Therelativeweight  X  is set to be 0 . 5 for P-Rank , if not specified explicitly. All the default values of parameters are set in accordance with [10].
We first build a heterogeneous INs from DBLP. The down-loaded DBLP data had its time stamp on March 15th, 2008. The heterogeneous IN, G , contains four different kinds of http://www.informatik.uni-trier.de/ ley/db/ Figure 4: The Schema of the Heterogeneous IN from DBLP Datasets. (The Number within Each Rectan-gle Represents the Number of Vertices in the Cor-responding Category.) vertices: paper , author , conference and year . If a paper p is written by an author a , there exists a directed edge from p to a ; If an author a participated in a conference c , there exists a directed edge from a to c ; For a specific year y ,there are bidirectional edges between both p and y and c and y , if the paper p was published in conference c in year y .Fig-ure 4 illustrates the global schema of the heterogenous IN, G . The number of vertices in G is 218930 and the number of edges is 818301. More specifically, the number of paper vertices is 211607; the number of author vertices is 4979; the number of conference vertices is 2292 and the number of year vertices is 52.

In order to evaluate the effectiveness of P-Rank ,wechoose to test how different structural similarity measures perform in clustering authors in G . It is worth noting that P-Rank is not confined only in clustering applications. Any data management applications adopting structural similarity as an underlying function can make use of P-Rank as its sim-ilarity measure. Meanwhile, P-Rank is orthogonal to the specific clustering algorithms applied, i.e. , P-Rank proposes a general structural similarity measure which can be applied in most existing clustering algorithms. We plug P-Rank and SimRank into K-Medoids [12], respectively. The structural distance between two vertices u, v  X  G is defined as where s f ( u, v ) is the similarity score generated by the sim-ilarity function, f , (either p for P-Rank or s for SimRank ). We define compactness of the clustering results, C f ,as where K isthenumberofclusterstobegenerated 3 ; C i is the i -th cluster; m i ,m j are centers for cluster i and cluster j , respectively. Intuitively, the numerator of Equation (7) describes intra-cluster distances and the denominator rep-resents inter-cluster distances. Smaller C f values demon-strate better clustering performance. In the following ex-periments, we compare C p and C s for P-Rank and SimRank , respectively.

We run both P-Rank and SimRank over G until the simi-larity scores converge. We then cluster author vertices by K -Medoids algorithm, and K = 10. At the beginning, we ran-domly choose 10 author vertices (without replacement) as initial centers of clusters and run the K -Medoids algorithm. We perform l = 10 trials and the clustering results are shown in Figure 6. As illustrated, P-Rank consistently achieves more compact clustering results than does SimRank .The main reasons are as follows: (1) P-Rank considers similarity
Note K is different from k in Equation (4), which is the number of iterations performed for iterative P-Rank . (b) Top-10 Nearest Neighbors of  X  X hilip S.

Yu X  propagation from both in-link (paper vertices) and out-link directions (conference vertices), which generates more com-prehensive results than does SimRank for clustering authors; (2) By simply considering in-link propagation only, SimRank fails to measure quite a few vertex pairs in G .For Sim-Rank , only those authors who cooperate (either directly or indirectly) on some papers have significant similarity scores, while others are regarded as dissimilar. In comparison, P-Rank is more robust than SimRank . For two author vertices, although they may not cooperate with each other (no in-link propagation), as long as they participate in common confer-ences (there exists out-link propagation), they are regarded as similar to some extent. Therefore, quite a few vertices which are dissimilar under SimRank  X  X  scheme are now simi-lar in P-Rank , which improves the compactness of clustering results. Figure 6: Compactness vs. Number of Trials for P-Rank and SimRank in the Heterogeneous IN
We then test the algorithmic nature and mathematical property of P-Rank . Figure 7(a) plots structural similar-ity scores of author pairs w.r.t. the number of iterations performed. The scores are averaged by the top 10 high-est ranked scores of author pairs for P-Rank and SimRank , respectively. We see from the figure that the intermediate similarity scores R k (  X  ,  X  ) become more accurate on succes-sive iterations. Iteration 2, which computes R 2 (  X  ,  X  R (  X  ,  X  ), can be thought of as the first iteration taking ad-vantage of the recursive power of algorithms for similarity computation. Subsequent changes become increasingly mi-nor, suggesting a rapid convergence. The figure also mani-fests that the iterative process stabilizes very fast, when k is greater than 5. Figure 7(b) plots the structural similarity scores of P-Rank and SimRank w.r.t. the rank number, N . The downward curves for both P-Rank and SimRank present a decrease in structural similarity as N increases, which is expected because highly ranked authors are more similar.
We further examine the ground truth generated by P-Rank on author vertices of G to test if it really reflects the real-ity to single out similar authors from the DBLP dataset. Although the judgement of similarity might be quite sub-jective and difficult even for human beings, we still find very interesting results by making use of P-Rank . As illustrated in Figure 5(a), the top-10 highly ranked author pairs are listed. We may notice that the author pairs with high P-Rank scores share some common characteristics. First, they are usually co-authors or share quite a few authorities as co-authors. And they are purely dedicated in specific research fields. In the mean time, highly ranked authors are inclined to be clustered into a close related community, in which their authorities are further reinforced. That is also another rea-son why P-Rank outperforms SimRank in entity clustering, as illustrated in the aforementioned experiment. We further issue k-Nearest Neighbor (KNN) queries to retrieve top-k most similar authors in IN G , given an author vertex q as a query. Figure 5(b) shows the ranked results for the query  X  X hilip S. Yu X  and Figure 5(c) shows the ranked results for the query  X  X ichael Stonebraker X , where k = 10. As illus-trated, both results are quite intuitive and conform to our basic understandings. Therefore, P-Rank can be effectively used as an underlying metric for measuring structural simi-larity in heterogenous INs, and its results obey our common sense pretty well. Figure 7: Similarity Measures on Author Pairs in the Heterogeneous IN from DBLP
After the study of P-Rank on heterogeneous INs, we con-tinue generating a homogeneous IN, G , on the DBLP dataset. The vertex set of G is composed of a subset of papers in DBLP and a directed edge exists from paper u to paper v if u cited v . The number of vertices in the homogenous IN G is 21740, and the number of edges is 65186. Figure 8: Compactness vs. Number of Trials for P-Rank and SimRank in the Homogeneous IN
Our first experiment is to study how the different struc-tural similarity measures perform in clustering vertices in homogenous IN. We plug P-Rank and SimRank respectively as underlying similarity functions into K-Medoids ( K = 10). We randomly choose 10 vertices (without replacement) as initial centers of clusters and run the K -Medoids algorithm. We perform l = 10 trials and the clustering results are shown in Figure 8. As illustrated, P-Rank can achieve much bet-ter results in clustering vertices in homogeneous IN, G .The improvement can be at least 6 times better. And the cluster-ing performance of P-Rank is consistently stable in different experimental trials. Figure 9: Vertex Pair Distributions Based on P-Rank and SimRank Scores in Homogeneous DBLP IN
Different from heterogenous INs, homogeneous INs have their vertices in one unique category and every vertex pair is eligible for comparison under the P-Rank framework. How-ever, SimRank may fail in homogeneous INs simply because there might be no common in-link similarity flows for ver-tex pairs. The problem becomes even more severe when the IN is massive and the interlinked relationships are not evenly distributed within the IN. As illustrated in Figure 9, vertex pairs are reorganized into different histograms based on their structural similarity scores computed by P-Rank and SimRank , respectively. For example, vertex pairs whose structural similarity scores are between [0 . 1 , 0 . 2) are put in the third histogram. A special histogram  X  X /A X  represents vertex pairs whose structural similarity can not be measured properly. Because of the very biased information consid-ered during similarity computation, SimRank fails to gen-erate meaningful similarity measures for a majority of ver-tex pairs in the homogenous IN, as shown in the histogram  X  X /A X . However, in the real homogenous IN with very un-even relationship distributions, P-Rank can still work well and is robust enough in structural similarity computation. Figure 10: Vertex Pair Distributions Based on P-Rank and SimRank Scores in Homogeneous Syn-thetic IN We generate a synthetic homogeneous IN G basedonthe Recursive Matrix (R-MAT) model [5], which naturally fol-lows power-law (in-and out-)degree distributions for G .The homogeneous IN G generated is a directed graph with 10 5 vertices and 6  X  10 5 edges.
 In this homogenous IN, we first test how P-Rank and Sim-Rank perform when measuring structural similarity of ver-tices in G . As illustrated in Figure 10, vertex pairs are distributed to different histograms with different similarity score intervals. Similar to Figure 9, SimRank again fails to deliver meaningful structural similarity for a majority of vertex pairs in IN, as shown in the histogram  X  X /A X . How-ever, P-Rank can successfully measure structural similarity for every pair of vertices in the homogeneous IN, G . We are also interested in how different parameters affect P-Rank when computing similarity in the homogeneous IN. We first test how the damping factor C is correlated with P-Rank . Figure 11(a) illustrates P-Rank scores in G w.r.t. the number of iterations performed. The structural similar-ityscoresareaveragedbythetop10highestrankedscores of vertex pairs. The damping factor, C ,issettobe0 . 2, 0 . 5 and 0 . 8, and three curves are plotted, respectively. It is obvious that P-Rank grows proportionally with the in-crease of C .When C =0 . 2, P-Rank converges fast when the number of iterations, k , is larger than 2. However, when C =0 . 8, P-Rank converges approximately at the 7th itera-tion of computation. The reason is that when C is set to a small value, the recursive power of P-Rank will be weakened and only vertices nearby can contribute in the structural similarity computation. When C is set high, more vertices in G can participate in the process of recursive computation. So P-Rank scorescanbeaccumulatedmoreeasilyandthe convergence therefore will take more time.
We then test how the relative weight,  X  , has an impact on P-Rank . As discussed in Section 3.2,  X  trades off P-Rank between the in-link and out-link relationships. When  X  =1, P-Rank is equal to SimRank .Andwhen  X  =0, P-Rank is equal to rvs-SimRank . As shown in Figure 11(b), the curve representing  X  =0 . 5 lies between curves representing  X  =0 ( rvs-SimRank )and  X  =1( SimRank ). It means that when  X  =0 . 5, P-Rank well balances both in-link and out-link fac-tors for measuring structural similarity. When  X  =0 . 2, the out-link relationships are still more important than the in-link ones, and P-Rank is interpolated by similarity scores from both sides. However, the curve representing  X  =0 . 2is quite close to the rvs-SimRank curve (  X  = 0). A similar phe-nomenon occurs for the curve representing  X  =0 . 8, which is quite close to the SimRank curve.
In this paper we propose a comprehensive structural simi-larity measure, P-Rank , for large information networks (INs). We start with the basic philosophy of P-Rank that two enti-ties of an IN are similar if (1) they are referenced by similar entities, and (2) they reference similar entities. In compari-son with other structural similarity measures, P-Rank takes into account of both in-and out-link relationships of entity pairs and penetrates the structural similarity computation beyondneighborhoodofverticestotheentireIN.Theadvan-tages of P-Rank are its semantic completeness, robustness and flexibility under different IN settings. P-Rank is shown to be a unified framework for structural similarity measures over massive INs, under which the state-of-the-art similarity measures as CoCitation , Coupling , Amsler and SimRank are all its special cases. We present a fixed point algorithm for computing P-Rank . Efficient pruning techniques under dif-ferent IN settings are also proposed to reduce the space and time complexity of P-Rank . We perform extensive experi-mental studies on both real datasets and synthetic datasets and the results confirm the applicability and comprehensive-ness of P-Rank ,aswellasitssignificantimprovementover other structural similarity measures. [1] R. Amsler. Application of citation-based automatic [2] I. Antonellis, H. Garcia-Molina, and C.-C. Chang. [3] S. Brin and L. Page. The anatomy of a large-scale [4] D. Chakrabarti and C. Faloutsos. Graph mining: [5] D. Chakrabarti, Y. Zhan, and C. Faloutsos. R-MAT: [6] D. Fogaras and B. R  X  acz. Scaling link-based similarity [7] F. Geerts, H. Mannila, and E. Terzi. Relational [8] C. L. Giles. The future of citeseer. In 10th European [9] M. Heymans and A. K. Singh. Deriving phylogenetic [10] G. Jeh and J. Widom. SimRank: a measure of [11] W. Jiang, J. Vaidya, Z. Balaporia, C. Clifton, and [12] L. Kaufman and P. J. Rousseeuw. Finding groups in [13] M. M. Kessler. Bibliographic coupling between [14] J. M. Kleinberg. Authoritative sources in a [15] R. Kumar, P. Raghavan, S. Rajagopalan, [16] Z. Lin, I. King, and M. R. Lyu. Pagesim: A novel [17] D. Lizorkin, P. Velikhov, M. Grinev, and D. Turdakov. [18] A. G. Maguitman, F. Menczer, F. Erdinc, [19] A. Mislove, M. Marcon, K. P. Gummadi, P. Druschel, [20] A.Popescul,G.Flake,S.Lawrence,L.Ungar,and [21] S. Roy, T. Lane, and M. Werner-Washburne.
 [22] H. G. Small. Co-citation in the scientific literature: A [23] W.Xi,E.A.Fox,W.Fan,B.Zhang,Z.Chen,J.Yan, [24] X. Yin, J. Han, and P. S. Yu. Linkclus: Efficient Proof: [Theorem 3.1] 1. ( Symmetry ) According to Equation (3) and Equa-2. ( Monotonicity ) If a = b , R 0 ( a, b )= R 1 ( a, b )= ... = 3. ( Existence ) According to Theorem 3.1-(2),  X  a, b  X  G , 4. ( Uniqueness ) Suppose s 1 (  X  ,  X  )and s 2 (  X  ,  X  ) are two
