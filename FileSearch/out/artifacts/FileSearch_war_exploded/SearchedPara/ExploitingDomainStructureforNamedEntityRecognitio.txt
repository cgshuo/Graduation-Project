 Named Entity Recognition (NER) is the task of identifying and classifying phrases that denote cer -tain types of named entities (NEs), such as per -sons, or g anizations and locations in ne ws articles, and genes, proteins and chemicals in biomedical lit-erature. NER is a fundamental task in man y natural language processing applications, such as question answering, machine translation, te xt mining, and in-formation retrie v al (Srihari and Li, 1999; Huang and V ogel, 2002).

Existing approaches to NER are mostly based on supervised learning. The y can often achie v e high accurac y pro vided that a lar ge annotated training set similar to the test data is a v ailable (Borthwick, 1999; Zhou and Su, 2002; Florian et al., 2003; Klein et al., 2003; Fink el et al., 2005). Unfortunately , when the test data has some dif ference from the training data, these approaches tend to not perform well. F or e x-ample, Ciaramita and Altun (2005) reported a per -formance de gradation of a named entity recognizer trained on CoNLL 2003 Reuters corpus, where the F1 measure dropped from 0.908 when tested on a similar Reuters set to 0.643 when tested on a W all Street Journal set. The de gradation can be e xpected to be w orse if the training data and the test data are more dif ferent.

The performance de gradation indicates that e xist-ing approaches adapt poorly to ne w domains. W e belie v e one reason for this poor adaptability is that these approaches ha v e not considered the f act that, depending on the genre or domain of the te xt, the entities to be recognized may ha v e dif ferent mor -phological properties or occur in dif ferent conte xts. Indeed, since most e xisting learning-based NER ap-proaches e xplore a lar ge feature space, without re gu-larization, a learned NE recognizer can easily o v erfit the training domain.

Domain o v erfitting is a serious problem in NER because we often need to tag entities in completely ne w domains. Gi v en an y ne w test domain, it is gen-erally quite e xpensi v e to obtain a lar ge amount of labeled entity e xamples in that domain. As a result, in man y real applications, we must train on data that do not fully resemble the test data.

This problem is especially serious in recognizing entities, in particular gene names, from biomedical literature. Gene names of one species can be quite dif f erent from those of another species syntactically due to their dif ferent naming con v entions. F or e xam-ple, some biological species such as yeast use sym-bolic gene names lik e tL(CAA)G3 , while some other species such as fly use descripti v e gene names lik e wingless .

In this paper , we present se v eral strate gies for e x-ploiting the domain structure in the training data to learn a more rob ust named entity recognizer that can perform well on a ne w domain. Our w ork is mo-ti v ated by the f act that in man y real applications, the training data a v ailable to us naturally f alls into se v eral domains that are similar in some aspects b ut dif f erent in others. F or e xample, in biomedical lit-erature, the training data can be naturally grouped by the biological species being discussed, while for ne ws articles, the training data can be di vided by the genre, the time, or the ne ws agenc y of the arti-cles. Our main idea is to e xploit such domain struc-ture in the training data to identify generalizable fea-tures which, presumably , are more useful for rec-ognizing named entities in a ne w domain. Indeed, named entities across dif ferent domains often share certain common features, and it is these common features that are suitable for adaptation to ne w do-mains; features that only w ork for a particular do-main w ould not be as useful as those w orking for multiple domains. In biomedical literature, for e x-ample, surrounding w ords such as e xpr ession and encode are strong indicators of gene mentions, re-g ardless of the specific biological species being dis-cussed, whereas species-specific name characteris-tics (e.g., prefix =  X -less  X ) w ould clearly not gener -alize well, and may e v en hurt the performance on a ne w domain. Similarly , in ne ws articles, the part-of-speeches of surrounding w ords such as  X  X ollowed by a verb X  are more generalizable indicators of name mentions than capitalization, which might be mis-leading if the genre of the ne w domain is dif ferent; an e xtreme case is when e v ery letter in the ne w do-main is capitalized.

Based on these intuitions, we re g ard a feature as g ener alizable if it is useful for NER in all training domains, and propose a generalizability-based fea-ture ranking method, in which we first rank the fea-tures within each training domain, and then combine the rankings to promote the features that are rank ed high in all domains. W e further propose a rank-based prior on logistic re gression models, which puts more emphasis on the more generalizable fea-tures during the learning stage in a principled w ay . Finally , we present a domain-a w are v alidation strat-e gy for setting an appropriate parameter v alue for the rank-based prior . W e e v aluated our method on a biomedical literature data set with annotated gene names from three species, fly , mouse, and yeast, by treating one species as the ne w domain and the other tw o as the training domains. The e xperiment results sho w that the proposed method outperforms a base-line method that represents the state-of-the-art NER techniques.
 The rest of the paper is or g anized as follo ws: In Section 2, we introduce a feature ranking method based on the generalizability of features across do-mains. In Section 3, we briefly introduce the logistic re gression models for NER. W e then propose a rank-based prior on logistic re gression models and de-scribe the domain-a w are v alidation strate gy in Sec-tion 4. The e xperiment results are presented in Sec-tion 5. Finally we discuss related w ork in Section 6 and conclude our w ork in Section 7. W e tak e a commonly used approach and treat NER as a sequential tagging problem (Borthwick, 1999; Zhou and Su, 2002; Fink el et al., 2005). Each tok en is assigned the tag I if it is part of an NE and the tag O otherwise. Let x denote the feature v ector for a tok en, and let y denote the tag for x . W e first com-pute the probability p ( y | x ) for each tok en, using a learned classifier . W e then apply V iterbi algorithm to assign the most lik ely tag sequence to a sequence of tok ens, i.e., a sentence. The features we use fol-lo w the common practice in NER, including surf ace w ord features, orthographic features, POS tags, sub-strings, and conte xtual features in a local windo w of size 5 around the tar get t ok en ( Fink el et al., 2005).
As in an y learning problem, feature selection may af fect the NER performance significantly . In-deed, a v ery lik ely cause of the domain o v erfit-ting problem may be that the learned NE recog-nizer has pick ed up some non-generalizable fea-tures, which are not useful for a ne w domain. Belo w , we present a generalizability-based feature ranking method, which f a v ors more generalizable features.
F ormally , we assume that the training e xamples are di vided into m subsets T 1 , T 2 , . . . , T m , corre-sponding to m dif ferent domains D 1 , D 2 , . . . , D m . W e further assume that the test set T m +1 is from a ne w domain D m +1 , and this n e w domain shares some common features of the m training domains. Note that these are reasonable assumptions that re-flect the situation in real problems.

W e use g ener alizability to denote the amount of contrib ution a feature can mak e to the classification accurac y on an y domain. Thus, a feature with high generalizability should be useful for classification on an y domain. T o identify the highly generalizable features, we must then compare their contrib utions to classification among dif ferent domains.

Suppose in each indi vidual domain, the features can be rank ed by their contrib utions to the classifi-cation accurac y . There are dif ferent feature ranking methods based on dif ferent criteria. W ithout loss of generality , let us use r T : F  X  { 1 , 2 , . . . , | F |} denote a ranking function that maps a feature f  X  F to a rank r T ( f ) based on a set of training e xamples T , where F is the set of all features, and the rank de-notes the position of the feature in the final rank ed list. The smaller the rank r T ( f ) is, the more impor -tant the feature f is in the training set T . F or the m training domains, we thus ha v e m ranking functions r
T o identify the generalizable features across the m dif f erent domains, we propose to combine the m in-di vidual domain ranking functions in the follo wing w ay . The idea is to gi v e high ranks to features that are useful in all training domains . T o achie v e this goal, we first define a scoring function s : F  X  R as follo ws: W e then rank the features in decreasing order of their scores using the abo v e scoring function. This is es-sentially to rank features according to their maxi-mum rank max i r T function r gen return the rank of a feature in this com-bined, generalizability-based rank ed list.

The original ranking function r T used for indi-vidual domain feature ranking can use dif ferent cri-teria such as information g ain or  X  2 statistic (Y ang and Pedersen, 1997). In our e xperiments, we used a ranking function based on the model parameters of the classifier , which we will e xplain in Section 5.2.
Ne xt, we need to incorporate this preference for generalizable features into the classifier . Note that because this generalizability-based feature ranking method is independent of the learning algorithm, it can be applied on top of an y classifier . In this w ork, we choose the logistic re gression classifier . One w ay to incorporate the feature ranking into the classifier is to select the top-k features, where k is chosen by cross v alidation. There are tw o potential problems with this har d feature selection approach. First, once k features are selected, the y are treated equally dur -ing the learning stage, resulting in a loss of the pref-erence among these k features. Second, this incre-mental feature selection approach does not consider the correlation among features. W e propose an al-ternati v e w ay to incorporate the feature ranking into the classifier , where the preference for generalizable features is transformed into a non-uniform prior o v er the feature parameters in the model. This can be re-g arded as a soft feature selection approach. In binary logistic re gression models, the probability of an observ ation x being classified as I is where  X  0 is the bias weight,  X  i ( 1  X  i  X  | F | ) are the weights for the features, and x ! is the aug-mented feature v ector with x 0 = 1 . The weight v ec-tor  X  can be learned from the training e xamples by a maximum lik elihood estimator . It is w orth point-ing out that logistic re gression has a close relation with maximum entrop y models. Indeed, when the features in a maximum entrop y model are defined as conjunctions of a feature on observ ations only and a Kroneck er delta of a class label, which is a com-mon practice in NER, the maximum entrop y model is equi v alent to a logistic re gression model (Fink el et al., 2005). Thus the logistic re gression method we use for NER is essentially the same as the maximum entrop y models used for NER in pre vious w ork.
T o a v oid o v erfitting, a zero mean Gaussian prior on the weights is usually used (Chen and Rosenfeld, 1999; Bender et al., 2003), and a maximum a poste-rior (MAP) estimator is used to maximize the poste-rior probability: where y j is the true class label for x j , N is the num-ber of training e xamples, a nd In pre vious w ork,  X  i are set uniformly to the same v alue for all features, because there is in general no additional prior kno wledge about the features. Instead of using the same  X  i for all features, we pro-pose a rank-based non-uniform Gaussian prior on the weights of the features so that more general-izable features get higher prior v ariances (i.e., lo w prior strength) and features on the bottom of the list get lo w prior v ariances (i.e., high prior strength). Since the prior has a zero mean, such a prior w ould force features on the bottom of the rank ed list, which ha v e the least generalizability , to ha v e near -zero weights, b ut allo w more generalizable features to be assigned higher weights during the training stage. 4.1 T ransf ormation Function W e need to find a transformation function h : { 1 , 2 , . . . , | F |}  X  R + so that we can set  X  2 i = h ( r gen ( f i )) , where r gen ( f i ) is the rank of feature f i in the generalizability-based rank ed feature list, as defined in Section 2. W e choose the follo wing h function because it has the desired properties as described abo v e: where a and b ( a, b &gt; 0 ) are parameters that control the de gree of the confidence in the generalizability-based rank ed feature list. Note that a corresponds to the prior v ariance assigned to the top-most feature in the rank ed list. When b is small, the prior v ariance drops rapidly as the rank r increases, gi ving only a small number of top features high prior v ariances. When b is lar ger , there will be less discrimination among the features. When b approaches infinity , the prior becomes a uniform prior with the v ariance set to a for all features. If we set a small threshold  X  on the v ariance, then we can deri v e that at least m = $ Thus b is proportional to the log arithm of the number of features that are assigned a v ariance greater than the threshold  X  when a is fix ed. Figure 1 sho ws the h function when a is set to 20 and b is set to a set of dif ferent v alues.
Figure 1: T ransformation Function h ( r ) = 20 4.2 P arameter Setting using Domain-A war e W e need to set the appropriate v alues for the param-eters a and b . F or parameter a , we use the follo wing simple strate gy to obtain an estimation. W e first train a logistic re gression model on all the training data using a Gaussian prior with a fix ed v ariance (set to 1 in our e xperiments). W e then find the maximum weight in this trained model. Finally we set a =  X  2 reasoning is that since a is the v ariance of the prior for the best feature, a is related to the  X  X ermissible range X  of  X  for the best feature, and  X  max gi v es us a w ay for adjusting a according to the empirical range of  X  i  X  s.

As we pointed out in Section 4.1, when a is fix ed, parameter b controls the number of top features that are gi v en a relati v ely high prior v ariance, and hence implicitly controls the number of top features to choose for the classifier to put the most weights on. T o select an appropriate v alue of b , we can use a held-out v alidation set to tune the parameter v alue b . Here we present a v alidation strate gy that e xploits the domain structure in the training data to set the parameter b for a ne w domain. Note that in re gular v alidation, both the training set and the v alidation set contain e xamples from all training domains. As a result, the a v erage performance on the v alidation set may be dominated by domains in which the NEs are easy to classify . Since our goal is to b uild a clas-sifier that performs well on ne w domains, we should pay more attention to hard domains that ha v e lo wer classification accurac y . W e should therefore e xam-ine the performance of the classifier on each training domain indi vidually in the v alidation stage to g ain an insight into the appropriate v alue of b for a ne w domain, which has an equal chance of being similar to an y of the training domains.

Our domain-a w are v alidation strate gy first finds the optimal v alue of b for each training domain. F or each subset T i of the training data belonging to do-main D i , we di vide it into a training set T t idation set T v classifier on the training sets of all domains, that is, we train on T v alue of a , and choose the optimal b that gi v es the best performance on T v for domain D i be b i .

Gi v en b i ( 1  X  i  X  m ), we can choose an appropri-ate v alue of b m +1 for an unkno wn test domain D m +1 based on the assumption that D m +1 is a mixture of all the training domains. b m +1 is then chosen to be a weighted a v erage of b i , ( 1  X  i  X  m ): where  X  i indicates ho w similar D m +1 is to D i . In man y cases, the test domain D m +1 is completely unkno wn. In this case, the best we can do is to set  X  an e v en mixture of all training domains. 5.1 Experimental Setup W e e v aluated our domain-a w are approach to NER on the problem of gene recognition in biomedical literature. The data we used is from BioCreAtIvE T ask 1B (Hirschman et al., 2005). W e chose this data set because it contains three subsets of MED-LINE abstracts with gene names from three species (fly , mouse, and yeast), while no other e xisting an-notated NER data set has such e xplicit domain struc-ture. The original BioCreAtIvE 1B data w as not pro vided with e v ery gene annotated, b ut for each ab-stract, a list of genes that were mentioned in the ab-stract w as gi v en. A gene synon ym list w as also gi v en for each species. W e used a simple string matching method with slight relaxation to tag the gene men-tions in the abstracts. W e took 7500 sentences from each species for our e xperiments, where half of the sentences contain gene mentions. W e further split the 7500 sentences of each species into tw o sets, 5000 for training and 2500 for testing.

W e conducted three sets of e xperiments, each combining the 5000-sentence training data of tw o species as training data, and the 2500-sentence test data of the third species as test data. The 2500-sentence test data of the training species w as used for v alidation. W e call these three sets of e xperi-ments F+M  X  Y , F+Y  X  M , and M+Y  X  F . we use FEX 1 for feature e xtraction and BBR 2 for logistic re gression in our e xperiments. 5.2 Comparison with Baseline Method Because the data set w as generated by our automatic tagging procedure using the gi v en gene lists, there is no pre viously reported performance on this data set for us to compare with. Therefore, to see whether using the domain structure in the training data can really help the adaptation to ne w domains, we com-pared our method with a state-of-the-art baseline method based on logistic re gression. It uses a Gaus-sian prior with zero mean and uniform v ariance on all model parameters. It also emplo ys 5-fold re gular cross v alidation to pick the optimal v ariance for the prior . Re gular feature selection is also considered in the baseline method, where the features are first rank ed according to some criterion, and then cross v alidation is used to select the top-k features. W e tested three popular re gular feature ranking meth-ods: featur e fr equency (F), information gain (IG), and  X  2 statistic (CHI). These methods were dis-cussed in (Y ang and Pedersen, 1997). Ho we v er , with an y of the three feature ranking criteria, cross v alida-tion sho wed that selecting all features g a v e the best a v erage v alidation performance. Therefore, the best baseline method which we compare our method with uses all features. W e call the baseline method BL .
In our method, the generalizability-based feature ranking requires a first step of feature ranking within each training domain. While we could also use F , IG or CHI to rank features in each domain, to mak e our method self-contained, we used the follo wing strate gy . W e first train a logistic re gression model on each domain using a zero-mean Gaussian prior with v ariance set to 1. Then, features are rank ed in decreasing order of the absolute v alues of their weights. The rationale is that, in general, features with higher weights in the logistic re gression model are more important. W ith this ranking within each training domain, we then use the generalizability-based feature ranking method to combine the m domain-specific rankings. The obtained rank ed fea-ture list is used to construct the rank-based prior , where the parameters a and b are set in the w ay as discussed in Section 4.2. W e call our method DOM .
In T able 1, we sho w the precision, recall, and F1 measures of our domain-a w are method ( DOM ) and the baseline method ( BL ) in all three sets of e xper -iments. W e see that the domain-a w are method out-performs the baseline method in all three cases when F1 is used as the primary performance measure. In F+Y  X  M and M+Y  X  F , both precision and recall are also impro v ed o v er the baseline method.
 T able 1: Comparison of the domain-a w are method and the baseline method, where in the domain-a w are method, b = 0 . 5 b 1 + 0 . 5 b 2
Note that the absolute performance sho wn in T a-ble 1 is lo wer than the state-of-the-art performance of gene recognition (Fink el et al., 2005). 3 One rea-son is that we e xplicitly e xcluded the test domain from the training data, while most pre vious w ork on gene recognition w as conducted on a test set dra wn from the same collection as the training data. An-other reason is that we used simple string match-ing to generate the data set, which introduced noise to the data because gene names often ha v e irre gular le xical v ariants. 5.3 Comparison with Regular F eatur e Ranking Figure 2: Comparison between re gular feature rank-ing and generalizability-based feature ranking on F+M  X  Y Figure 3: Comparison between re gular feature rank-ing and generalizability-based feature ranking on F+Y  X  M Figure 4: Comparison between re gular feature rank-ing and generalizability-based feature ranking on M+Y  X  F
T o further understand ho w our method impro v ed the performance, we compared the generalizability-based feature ranking method with the three re gular feature ranking methods, F , IG, and CHI, that were used in the baseline method. T o mak e f air compar -ison, for the re gular feature ranking methods, we also used the rank-based prior transformation as de-scribed in Section 4 to incorporate the preference for top-rank ed features. Figure 2, Figure 3 and Figure 4 sho w the performance of dif ferent feature ranking methods in the three sets of e xperiments as the pa-rameter b for the rank-based prior changes. As we pointed out in Section 4, b is proportional to the log-arithm of the number of  X  X f fecti v e features X .
From the figures, we clearly see that the curv e for the generalizability-based ranking method DOM is al w ays abo v e the curv es of the other methods, indi-cating that when the same amount of top features are being emphasized by the prior , the features selected by DOM gi v e better performance on a ne w domain than the features selected by the other methods. This suggests that the top-rank ed features in DOM are in-deed more suitable for adaptation to ne w domains than the top features rank ed by the other methods. The figures also sho w that the ranking method DOM achie v ed better performance than the baseline o v er a wide range of b v alues, especially in F+Y  X  M and M+Y  X  F , whereas for methods F , IG and CHI, the performance quickly con v er ged to the baseline performance as b increased.

It is interesting to note the comparison between F and IG (or CHI). In general, when the test data is similar to the training data, IG (or CHI) is adv anta-geous o v er F (Y ang and Pedersen, 1997). Ho we v er , in this case when the test domain is dif ferent from the training domains, F sho ws adv antages for adap-tation. A possible e xplanation is that frequent fea-tures are in general less lik ely to be domain-specific, and therefore feature frequenc y can also be used as a criterion to select generalizable features and to filter out domain-specific features, although it is still not as ef fecti v e as the method we proposed. The NER problem has been e xtensi v ely studied in the NLP community . Most e xisting w ork has fo-cused on supervised learning approaches, emplo y-ing models such as HMMs (Zhou and Su, 2002), MEMMs (Bender et al., 2003; Fink el et al., 2005), and CRFs (McCallum and Li, 2003). Collins and Singer (1999) proposed an unsupervised method for named entity classification based on the idea of co-training. Ando and Zhang (2005) proposed a semi-supervised learning method to e xploit unlabeled data for b uilding more rob ust NER systems. In all these studies, the e v aluation is conducted on unlabeled data similar to the labeled data.

Recently there ha v e been some studies on adapt-ing NER systems to ne w domains emplo ying tech-niques such as acti v e learning and semi-supervised learning (Shen et al., 2004; Mohit and Hw a, 2005), or incorporating e xternal le xical kno wledge (Cia-ramita and Altun, 2005). Ho we v er , there has not been an y study on e xploiting the domain structure contained in the training e xamples themselv es to b uild generalizable NER systems. W e focus on the domain structure in the training data to b uild a classifier that relies more on features generaliz-able across dif ferent domains to a v oid o v erfitting the training domains. As our method is orthogonal to most of the aforementioned w ork, the y can be com-bined to further impro v e the performance. Named entity recognition is an important problem that can help man y te xt mining and natural lan-guage processing tasks such as information e xtrac-tion and question answering. Currently NER f aces a poor domain adaptability problem when the test data is not from the same domain as the training data. W e present se v eral strate gies to e xploit the domain structure in the training data to impro v e the performance of the learned NER classifier on a ne w domain. Our results sho w that the domain-a w are strate gies we proposed impro v ed the performance o v er a baseline method that represents the state-of-the-art NER techniques.
 This w ork w as in part supported by the National Science F oundation under a w ard numbers 0425852, 0347933, and 0428472. W e w ould lik e to thank Bruce Schatz, Xin He, Qiaozhu Mei, Xu Ling, and some other BeeSpace project members for useful discussions. W e w ould lik e to thank Mark Sammons for his help with FEX. W e w ould also lik e to thank the anon ymous re vie wers for their comments.
