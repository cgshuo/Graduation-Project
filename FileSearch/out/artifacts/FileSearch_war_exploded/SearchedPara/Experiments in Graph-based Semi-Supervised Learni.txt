 Traditionally, named-entity recognition (NER) has focused on a small number of broad classes such as person, location, organization. However, those classes are too coarse to support important ap-plications such as sense disambiguation, seman-tic matching, and textual inference in Web search. For those tasks, we need a much larger inventory of specific classes and accurate classification of terms into those classes. While supervised learn-ing methods perform well for traditional NER, they are impractical for fine-grained classification because sufficient labeled data to train classifiers for all the classes is unavailable and would be very expensive to obtain. In Section 2, we review three graph-based SSL algorithms that are compared for the class-instance acquisition task in Section 3. In Section 3.6, we show how additional instance-attribute based semantic constraints can be used to improve class-instance acquisition performance. We sum-marize the results and outline future work in Sec-tion 4. We now review the three graph-based SSL algo-rithms for class inference over graphs that we have evaluated. 2.1 Notation All the algorithms compute a soft assignment of labels to the nodes of a graph G = ( V,E,W ) , where V is the set of nodes with | V | = n , E is the set of edges, and W is an edge weight ma-trix. Out of the n = n l + n u nodes in G , n l nodes are labeled, while the remaining n u nodes are unlabeled. If edge ( u,v ) 6 X  E , W uv = 0 . The (unnormalized) Laplacian, L , of G is given by L = D  X  W , where D is an n  X  n diagonal degree matrix with D uu = P v W uv . Let S be an n  X  n diagonal matrix with S uu = 1 iff node u  X  V is labeled. That is, S identifies the labeled nodes in the graph. C is the set of labels, with | C | = m representing the total number of labels. Y is the n  X  m matrix storing training label information, if any.  X  Y is an n  X  m matrix of soft label assign-ments, with  X  Y vl representing the score of label l on node v . A graph-based SSL computes  X  Y from { G,SY } . 2.2 Label Propagation (LP-ZGL) The label propagation method presented by Zhu et al. (2003), which we shall refer to as LP-ZGL in this paper, is one of the first graph-based SSL methods. The objective minimized by LP-ZGL is: 2.4 Modified Adsorption (MAD) Talukdar and Crammer (2009) introduced a modi-fication of Adsorption called MAD, which shares Adsorption X  X  desirable properties but can be ex-pressed as an unconstrained optimization problem: where  X  1 ,  X  2 , and  X  3 are hyperparameters; L 0 is the Laplacian of an undirected graph derived from G , but with revised edge weights; and R is an n  X  m matrix of per-node label prior, if any, with R l representing the l th column of R . As in Adsorption, MAD allows labels on seed nodes to change. In case of MAD, the three random-walk probabilities, p inj v , p cont v , and p abnd v , defined by Adsorption on each node are folded inside the ma-trices S,L 0 , and R , respectively. The optimization problem in (3) can be solved with an efficient iter-ative algorithm described in detail by Talukdar and Crammer (2009).

These three algorithms are all easily paralleliz-able in a MapReduce framework (Talukdar et al., 2008; Rao and Yarowsky, 2009), which makes them suitable for SSL on large datasets. Addition-ally, all three algorithms have similar space and time complexity. We now compare the experimental performance of the three graph-based SSL algorithms reviewed in the previous section, using graphs constructed from a variety of sources described below. Fol-lowing previous work (Talukdar et al., 2008), we use Mean Reciprocal Rank (MRR) as the evalua-tion metric in all experiments: where Q  X  V is the set of test nodes, and r v is the rank of the gold label among the labels assigned to node v . Higher MRR reflects better performance. We used iterative implementations of the graph-based SSL algorithms, and the number of itera-tions was treated as a hyperparameter which was tuned, along with other hyperparameters, on sep-arate held-out sets, as detailed in a longer version dataset as a collection of relational tables, where each table is assigned a unique ID. A table con-sists of one or more properties (column names) and their corresponding cell values (column en-tries). Examples of two Freebase tables are shown in Figure 1. In this figure, Gender is a property in the table people-person , and Male is a corre-sponding cell value. We use the following process to convert the Freebase data tables into a single graph:  X  Create a node for each unique cell value  X  Create a node for each unique property name,  X  Add an edge of weight 1.0 from cell-value chemistry, comic books, computer, film, food, ge-ography, location, people, religion, spaceflight, tennis, travel, and wine . The topics in this subset were further filtered so that only cell-value nodes with frequency 10 or more were retained. We call the resulting graph Freebase-1 (see Table 1).
Pantel et al. (2009) have made available a set of gold class-instance pairs derived from Wikipedia, which is downloadable from http://ow.ly/13B57 . From this set, we selected all classes which had more than 10 instances overlapping with the Freebase graph constructed above. This resulted in 23 classes, which along with their overlapping instances were used as the gold standard set for the experiments in this sec-tion.

Experimental results with 2 and 10 seeds (la-beled nodes) per class are shown in Figure 3. From the figure, we see that that LP-ZGL and Adsorp-tion performed comparably on this dataset, with MAD significantly outperforming both methods. 3.2 Freebase-2 Graph with WordNet Classes Figure 4: Comparison of graph transduction meth-ods on a graph constructed from the Freebase dataset (see Section 3.2). All results are averaged over 10 random trials. In each group, MAD is the rightmost bar.

To evaluate how the algorithms scale up, we construct a larger graph from the same 18 domains as in Section 3.1, and using the same graph con-struction process. We shall call the resulting graph Freebase-2 (see Table 1). In order to scale up the number of classes, we selected all Wordnet (WN) classes, available in the YAGO KB (Suchanek et al., 2007), that had more than 100 instances over-directed edges in both directions, with the extrac-tion confidence ( 0.92 ) as edge weights. The graph created with this process from TextRunner out-put is called the TextRunner Graph (see Table 1). As in Section 3.2, we use WordNet class-instance pairs as the gold set. In this case, we considered all WordNet classes, once again from YAGO KB (Suchanek et al., 2007), which had more than 50 instances overlapping with the constructed graph. This resulted in 170 WordNet classes being used for the experiments in this section.

Experimental results with 2 and 10 seeds per class are shown in Figure 5. The three methods are comparable in this setting, with MAD achiev-ing the highest overall MRR. 3.4 Discussion If we correlate the graph statistics in Table 1 with the results of sections 3.1, 3.2, and 3.3, we see that MAD is most effective for graphs with high average degree, that is, graphs where nodes tend to connect to many other nodes. For instance, the Freebase-1 graph has a high average degree of 29.03, with a corresponding large advantage for MAD over the other methods. Even though this might seem mysterious at first, it becomes clearer if we look at the objectives minimized by different algorithms. We find that the objec-tive minimized by LP-ZGL (Equation 1) is under-regularized , i.e., its model parameters (  X  Y ) are not constrained enough, compared to MAD (Equation 3, specifically the third term), resulting in overfit-ting in case of highly connected graphs. In con-trast, MAD is able to avoid such overfitting be-cause of its minimization of a well regularized ob-jective (Equation 3). Based on this, we suggest that average degree, an easily computable struc-tural property of the graph, may be a useful indica-tor in choosing which graph-based SSL algorithm should be applied on a given graph.

Unlike MAD, Adsorption does not optimize any well defined objective (Talukdar and Cram-mer, 2009), and hence any analysis along the lines described above is not possible. The heuristic choices made in Adsorption may have lead to its sub-optimal performance compared to MAD; we leave it as a topic for future investigation. 3.5 Effect of Per-Node Class Sparsity For all the experiments in Sections 3.1, 3.2, and 3.6, each node was allowed to have a maximum of 15 classes during inference. After each update TextRunner graph significantly improves performance. for each attribute is shown in bold. from various sources. In this section, we ex-plore whether class-instance assignment can be improved by incorporating new semantic con-straints derived from (instance, attribute) pairs. In particular, we experiment with the following type of constraint: two instances with a common at-tribute are likely to belong to the same class. For example, in Figure 2 (b), instances Johnny Cash and Bob Dylan are more likely to belong to the same class as they have a common attribute, al-bums . Because of the smooth labeling bias of graph-based SSL methods (see Section 2.2), such constraints are naturally captured by the methods reviewed in Section 2. All that is necessary is the introduction of bidirectional (instance, attribute)
In all experimental conditions with 2 and 10 seeds per class in Figure 7, we observe that the three methods consistently achieved the best per-formance on the TextRunner + YAGO graph. This suggests that addition of attribute based seman-tic constraints from YAGO to the TextRunner graph results in a better connected graph which in turn results in better inference by the graph-based SSL algorithms, compared to using either of the sources, i.e., TextRunner output or YAGO attributes, in isolation. This further illustrates the advantage of aggregating information across sources (Talukdar et al., 2008; Pennacchiotti and Pantel, 2009). However, we are the first, to the best of our knowledge, to demonstrate the effec-tiveness of attributes in class-instance acquisition. We note that this work is similar in spirit to the recent work by Carlson et al. (2010) which also demonstrates the benefits of additional constraints in SSL.

Because of the label propagation behavior, graph-based SSL algorithms assign classes to all nodes reachable in the graph from at least one of the labeled instance nodes. This allows us to check the classes assigned to nodes corre-sponding to YAGO attributes in the TextRunner + YAGO graph, as shown in Table 2. Even though the experiments were designed for class-instance acquisition, it is encouraging to see that the graph-based SSL algorithm (MAD in Table 2) is able to learn class-attribute relationships, an important by-product that has been the fo-cus of recent studies (Reisinger and Pasca, 2009). For example, the algorithm is able to learn that works at is an attribute of the WordNet class word-net scientist 110560637 , and thereby its instances (e.g. Aage Niels Bohr, Adi Shamir ). We have started a systematic experimental com-parison of graph-based SSL algorithms for class-instance acquisition on a variety of graphs con-structed from different domains. We found that MAD, a recently proposed graph-based SSL algo-rithm, is consistently the most effective across the various experimental conditions. We also showed that class-instance acquisition performance can be significantly improved by incorporating additional
