 Pseudo-relevance feedback (PRF) has been proven to be an effective query expansion strategy to improve retrieval per-formance. Several PRF methods have so far been proposed for many retrieval models. Recent theoretical studies of PRF methods show that most of the PRF methods do not satisfy all necessary constraints. Among all, the log-logistic model has been shown to be an effective method that satisfies most of the PRF constraints. In this paper, we first introduce two new PRF constraints. We further analyze the log-logistic feedback model and show that it does not satisfy these two constraints as well as the previously proposed  X  X elevance ef-fect X  constraint. We then modify the log-logistic formula-tion to satisfy all these constraints. Experiments on three TREC newswire and web collections demonstrate that the proposed modification significantly outperforms the original log-logistic model, in all collections.
  X  Information systems  X  Query representation; Que-ry reformulation; Pseudo-relevance feedback; axiomatic analysis; theoretical analysis; query expansion; semantic similarity
Pseudo-relevance feedback (PRF) refers to a query expan-sion strategy to address the vocabulary mismatch problem in information retrieval (IR). PRF assumes that a number of top-retrieved documents are relevant to the initial query. Based on this assumption, it updates the query model using these pseudo-relevant documents to improve the retrieval performance. PRF has been shown to be highly effective in many retrieval models [1, 5, 8, 10].

Several PRF models with different assumptions and for-mulations have so far been proposed. Clinchant and Gaussi-er [2] theoretically analyzed a number of effective PRF mod-els. To this end, they proposed five constraints (axioms) for PRF models and showed that the log-logistic feedback model [1] is the only PRF model (among the studied ones) that satisfies all the constraints. They also showed that its per-formance is superior to the other PRF methods, including the mixture model [10] and the geometric relevance model [9]. Effectiveness of the log-logistic model motivates us, in this paper, to study this state-of-the-art PRF model. Recently, Pal et al. [8] proposed a sixth constraint for PRF models to improve the PRF performance in the diver-gence from randomness framework. This constraint, which is called  X  X elevance effect X , indicates that the terms in the feedback documents with high relevance scores (i.e., rele-vance of document to the initial query) should have higher weights in the feedback model compared to those with ex-actly similar statistics, but appear in the documents with lower relevance scores. Formally writing, if a term w occurs in two documents d 1 , d 2  X  F (F denotes the set of feedback documents) such that d 1 is more relevant to the initial query than d 2 . Then, we can say that the feedback weight of w given the F  X  { d 1 } feedback documents is lower than the weight of the same word in the F  X  { d 2 } feedback docu-ments [8]. It can be shown that the log-logistic feedback model does not satisfy the relevance effect constraint. In this paper, we propose two additional constraints for PRF models. The first constraint considers the semantic similarity of feedback terms to the initial query. Although previous work, such as [4], proposed similar constraints for retrieval models, to the best of our knowledge, it is the first time to study a semantic-related constraint for the PRF task. The second constraint indicates that the weight of each term w in the feedback model not only depends on the distribution of w in the feedback documents, but is also related to the distribution of the other terms in those doc-uments. We further show that the log-logistic model does not satisfy the two proposed constraints. We then propose a modification to the log-logistic feedback model to satisfy the proposed constraints as well as the relevance effect con-straint [8].

We evaluate the modified log-logistic model using three standard TREC collections: AP (Associated Press 1988-89), Robust (TREC 2004 Robust track), and WT10g (TREC 9-10 Web track). The experimental results demonstrate that the proposed method significantly outperforms the original log-logistic feedback model in all collections. The proposed method is also shown to be more robust than the original log-logistic model, especially in the web collection.
I n this section, we introduce two constraints that (pseudo) relevance feedback methods should satisfy (in addition to those proposed in [2, 8]). We further analyze the log-logistic model, a state-of-the-art feedback model, and figure out that this model does not satisfy the proposed constraints as well as the  X  X elevance effect X  constraint introduced in [8]. Based on these observations, we modify the log-logistic feedback model to satisfy all the constraints.

We first introduce our notation. Let F W ( w ; F, P w , Q ) be the feedback weight function that assigns a real-value weight to each feedback term w for a given query Q . F and P w respectively denote the set of feedback documents for the query Q and a set of term-dependent parameters. For sim-plicity, we henceforth use F W ( w ). In the following equa-tions, T F and IDF denote term frequency and inverse doc-ument frequency, respectively. The notation |  X  | is also used for query/document length or size of a given set.
In this subsection, we introduce two constraints for feed-back models. [Semantic effect] Let Q be a single-term query (i.e., Q = { q } ), w 1 and w 2 be two terms such that IDF ( w 1 IDF ( w 2 ),  X  D  X  F : T F ( w 1 , D ) = T F ( w 2 , D ), and where sem (  X  ,  X  ) denotes the semantic similarity of the given terms. Then, we can say:
The intuition behind this constraint is that the feedback terms should be semantically similar to the initial query. [Distribution effect] Let w 1 and w 2 be two vocabulary terms such that T F ( w 1 , D 1 ) = T F ( w 2 , D 2 ), T F ( w T F ( w 2 , D 1 ) = 0, and | D 1 | = | D 2 | , where D 1 and D documents in the feedback set F . Also, assume that w 1 and w 2 do not occur in other feedback documents, and where U niqueT erms (  X  ) denotes the number of unique terms in the given document. Then, we can say: 1
In other words, this constraint implies that for computing the feedback weight of a term w , the distribution of other terms in the feedback documents should also be considered.
The feedback weight of each term w in the log-logistic feedback model [1] is computed as follows: F W ( w ) = 1 where  X  w = N w N ( N w a nd N denote the number of docu-ments in the collection that contain w and the total number of documents in the collection, respectively), and t ( w, D ) = length and c is a free hyper-parameter). It is shown that
T he intuition behind this constraint comes from the defi-nition of information in information theory literature. the log-logistic model satisfies all the PRF constraints intro-duced in [2]. It can be easily proved that this model cannot satisfy the constraints proposed in this paper. In more de-tail, there is no semantic-related or relevance-related com-ponents in the log-logistic formulation and thus it cannot satisfy the proposed  X  X emantic effect X  and the  X  X elevance ef-fect X  [8] constraints. In addition, the log-logistic formula does not consider the distribution of other terms in comput-ing the weight of each term w , and thus it does not satisfy the  X  X istribution effect X  constraint.

To satisfy the  X  X emantic effect X  constraint, we modify the log-logistic feedback weight function as follows: where s (  X  ,  X  ) denotes the semantic similarity between the given two terms. The parameter  X  controls the effect of semantic similarity in the feedback weight function. The se-mantic weighting component comes from the query-growth function, which was previously proposed by Fang and Zhai [4]. Note that in Equation (2), we can ignore the 1 / | Q | term and the  X  parameter, since they are equal for all terms and the feedback weighting function will be normalized. Several methods have so far been proposed to incorporate semantic similarity of terms in various retrieval tasks. In this paper, we consider the mutual information as a basic semantic sim-ilarity metric to compute s (  X  ,  X  ). The mutual information (MI) of two terms w and w  X  is computed as follows: I ( X w , X w  X  ) = X w here X w and X w  X  are two binary random variables that represent the presence or absence of the terms w and w  X  in each document. A simple way to compute the mutual information is to consider the whole collection; but, this choice may not be ideal for ambiguous terms. Another way is to compute the mutual information from the pseudo-relevant documents. However, the top-retrieved documents could be a biased corpus for this goal. Therefore, similar to [4], we extract the mutual information from a corpus containing the top m retrieved documents and r  X  m documents randomly selected from the collection, where r is a free parameter that controls the generality of mutual information scores.
To satisfy the  X  X istribution effect X  constraint, we re-define the function t ( w, D ) as follows: where ut ( D ) denotes the number of unique terms in the document D . A similar approach for modifying the raw TF formula was previously used in [7].

To satisfy the  X  X elevance effect X  constraint, we re-define the function F W ( w, D ) (see Equation (1)) as follows: where RS ( Q, D ) denotes the relevance score of the docu-ment D to the query Q . This function can be computed using the relevance score of D in the first ranking phase in PRF. A similar idea was previously proposed by Lavrenko and Croft [5]. They used the query likelihood similarity as a posterior probability in the relevance models. Lv and 0.4474 0.31 0.2247 0.3188 0.10 0.4490 0.35 0.2289 0 1 0.3289 0.17 0.4401 0.32 0.2194 0.3207 0.13 Zhai [6] also used a similar technique to improve the diver-g ence minimization feedback model [10].

Considering the aforementioned modifications, we can re-write the log-logistic feedback weighting formula as follows:
F W  X  ( w ) = 1
We used three standard TREC collections in our experi-ments: AP (Associated Press 1988-89), Robust (TREC Ro-bust Track 2004 collection), and WT10g (TREC Web Track 2001-2002). The first two collections are newswire collec-tions, and the third collection is a web collection with more noisy documents. The statistics of these datasets are re-ported in Table 1. We consider the title of topics as queries. All documents are stemmed using the Porter stemmer. Stop-words are removed in all the experiments. We used the stan-dard INQUERY stopword list. All experiments were carried out using the Lemur toolkit 2 .
The number of feedback documents, the number of feed-back terms, the feedback coefficient and the parameter that controls the generally of mutual information scores (param-eter r ) are set using 2-fold cross validation over each col-lection. We sweep the number of feedback documents and feedback terms between { 10 , 25 , 50 , 75 , 100 } , the feedback coefficient between { 0 , 0 . 1 ,  X   X   X  , 1 } , and the parameter r be-tween { 2 , 4 , 6 , 8 , 10 } .
To evaluate retrieval effectiveness, we use mean average precision (MAP) of the top-ranked 1000 documents as the h ttp://lemurproject.org/ main evaluation metric. In addition, we also report the pre-cision of the top 10 retrieved documents (P@10). Statisti-cally significant differences of performance are determined using the two-tailed paired t-test computed at a 95% confi-dence level over average precision per query.

To evaluate the robustness of methods, we consider the ro-bustness index (RI) [3] which is defined as N +  X  N  X  N , where N denotes the number of queries and N + / N  X  shows the num-ber of queries improved/decreased by the feedback method. The RI value is always in the [  X  1 , 1] interval and the method with higher value is more robust.
In this subsection, we first evaluate the proposed mod-ifications to the log-logistic model. We further study the sensitivity of the proposed method to the free parameters.
We consider two baselines: (1) the document retrieval method without feedback (NoPRF), and (2) the original log-logistic feedback model (LL). Although several other PRF methods have already been proposed, since in this paper, we propose a modification of the log-logistic model, we do not compare the proposed method with other existing PRF models.

To study the effect of each constraint in the retrieval per-formance, we modify the log-logistic model based on each constraint, separately. LL+Sem, LL+Rel, and LL+Dis de-note the modified log-logistic model based on the  X  X emantic effect X , the  X  X elevance effect X , and the  X  X istribution effect X  constraints, respectively. We also modify the log-logistic model by considering all of these constraints (called LL+All) as introduced in Equation (5). The results obtained by the baselines and those achieved by the proposed modifications are reported in Table 2. According to this table, LL out-performs the NoPRF baseline in all cases, which shows the effectiveness of the log-logistic model. The improvements on the WT10g collection is lower than those on the AP and the Robust collections. This observation demonstrates that the
T o avoid the influence of very small average precision changes in the RI value, we only consider the improve-ments/losses higher than 10% (relatively). Figure 1: Sensitivity of the proposed method to the number o f feedback terms and the parameter r . log-logistic model is less effective and robust in improving the retrieval performance in the web collection, compared to the newswire collections. LL+Sem and LL+Rel perform better than LL in terms of MAP and P@10, in all collec-tions. The MAP improvements are statistically significant in many cases, especially in the LL+Rel method. Except in one case (i.e., LL+Sem in Robust), both LL+Sem and LL+Rel models are shown to be more robust than the LL baseline. It is worth noting that we use very simple modifi-cations to satisfy these two constraints, and thus using more accurate methods to satisfy these constraints can potentially improve the performance. LL+Dis method in general per-forms comparable to or sometimes slightly better than the LL baseline. The results achieved on the WT10g collection shows that LL+Dis can be more effective in noisy conditions, such as web collections. Overall, although the theoretical analysis shows that PRF methods should satisfy the  X  X istri-bution effect X  constraint, it does not substantially affect the retrieval performance in the AP and the Robust collections. The reason is that the values of | D | ut ( D ) ( see Equation (3)) are very close to each other for different documents, especially in newswire collections. Thus, our modification to the log-logistic regarding the  X  X istribution effect X  constraint cannot substantially affect the retrieval performance.

As shown in Table 2, the LL+All method, which is our fi-nal modification to the log-logistic model, outperforms both baselines in all collections in terms of MAP and P@10. The MAP improvements are always statistically significant. The LL+All method is also shown to be more robust than the LL method, in particular in the WT10g collection.
In this set of experiments, we fix one of the parameters r (the generality control parameter for mutual information) and n (the number of feedback terms), and then sweep the other one to show the sensitivity of the method to the input parameters. The results are reported in Figure 1. 4 Ac-cording to this figure, the method is quite stable w.r.t. the changes in the values of these two parameters, especially for the parameter r . The results also indicate that by increasing the number of feedback terms, performance in the Robust collection generally increases, but in the WT10g collection it is not the case. The reason could be related to the noisy nature of this collection compared to the newswire collec-tions.
F or the sake of visualization, we only report the results for the Robust and the WT10g collections. The behaviour of the method in AP is similar to the Robust collection.
In this paper, we proposed two new constraints for pseudo-relevance feedback models. The first constraint considers se-mantic similarity of the feedback terms to the initial query. The second constraint focuses on the effect of distribution of all terms in the feedback documents on each term. We fur-ther studied the log-logistic model, a state-of-the-art feed-back model, and showed that this model does not satisfy the proposed constraints as well as the previously proposed  X  X elevance effect X  constraint [8]. We then modified the log-logistic model to satisfy all of these constraints. The pro-posed modification was evaluated using three TREC news-wire and web collections. Experimental results suggest that the modified model significantly outperforms the original log-logistic model, in all collections.

An interesting future direction is to study other feedback methods, such as the language model-based feedback meth-ods, and modify them in order to satisfy the constraints. In this paper, we only consider simple approaches to satisfy the constraints, such as using mutual information for cap-turing semantic similarities. Future work can focus on more complex and accurate approaches to improve the retrieval performance.
This work was supported in part by the Center for In-telligent Information Retrieval. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor. [1] S. Clinchant and E. Gaussier. Information-based [2] S. Clinchant and E. Gaussier. A Theoretical Analysis [3] K. Collins-Thompson. Reducing the Risk of Query [4] H. Fang and C. Zhai. Semantic Term Matching in [5] V. Lavrenko and W. B. Croft. Relevance Based [6] Y. Lv and C. Zhai. Revisiting the Divergence [7] J. H. Paik. A Novel TF-IDF Weighting Scheme for [8] D. Pal, M. Mitra, and S. Bhattacharya. Improving [9] J. Seo and W. B. Croft. Geometric Representations [10] C. Zhai and J. Lafferty. Model-based Feedback in the
