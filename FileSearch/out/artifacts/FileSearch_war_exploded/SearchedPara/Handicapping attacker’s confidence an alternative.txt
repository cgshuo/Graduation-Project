 REGULAR PAPER Ke Wang  X  Benjamin C. M. Fung  X  Philip S. Yu Abstract We present an approach of limiting the confidence of inferring sensitive properties to protect against the threats caused by data mining abilities. The prob-lem has dual goals: preserve the information for a wanted data analysis request and limit the usefulness of unwanted sensitive inferences that may be derived from the release of data. Sensitive inferences are specified by a set of  X  X rivacy templates X . Each template specifies the sensitive property to be protected, the attributes iden-tifying a group of individuals, and a maximum threshold for the confidence of inferring the sensitive property given the identifying attributes. We show that sup-pressing the domain values monotonically decreases the maximum confidence of such sensitive inferences. Hence, we propose a data transformation that minimally suppresses the domain values in the data to satisfy the set of privacy templates. The transformed data is free of sensitive inferences even in the presence of data mining algorithms. The prior k -anonymizationfocuses on personal identities. This work focuses on the association between personal identities and sensitive proper-ties.
 Keywords Privacy protection  X  k -anonymity  X  Sensitive inference  X  Data mining  X  Classification  X  Data sharing 1 Introduction Knowledge Discovery in Databases (KDD) or data mining aims at finding out new knowledge about an application domain using collected data on the domain, typ-ically data on individual entities like persons, companies, transactions. Naturally, the general concerns over data security and individual privacy are relevant for data mining. The first concern relates to the input of data mining methods due to data access. Many techniques have been proposed [ 4 , 6 , 8 , 9 , 11 , 17 , 21 ] to address this problem while preserving the benefits of data mining. The second concern is related to the output of data mining methods. Although the output of data min-ing methods are aggregate patterns, not intended to identify single individuals, they can be used to infer sensitive properties about individuals. In this paper, we consider the privacy threats caused by such  X  X ata mining abilities X . Let us first consider an example.
 Example 1 (Running Example) Ta b l e 1 contains records about bank customers. After removing irrelevant attributes, each row represents the duplicate records and the count. The class attribute Rating contains the class frequency of credit rating. For example, 0G/4B represents 0 Good and 4 Bad. Suppose that the bank (the data owner) wants to release the data to a data mining firm for classification analysis on Rating , but does not want the data mining firm to infer the bankruptcy state Discharged using the attributes Job and Country . For example, out of the five individuals with Job = Trader and Country = UK , four has the Discharged status. Therefore, the rule { Trader , UK } X  Discharged has support 5 and con-fidence 80%. If the data owner tolerates no more than 75% confidence for this inference, the data is not safe for release. In general, currently bankrupted cus-tomers have a bad rating and simply removing the Bankruptcy column loses too much information for the classification analysis.
 where x identifies a group of individuals and y is a sensitive property. We con-sider this inference  X  X rivate X  if its confidence is high, in which case an individual in the group identified by x tends to be linked to y . The higher the confidence, the stronger the linking. In the context of data mining, association or classifica-tion rules [ 1 , 15 ] are used to capture general patterns of large populations for summarization and prediction, where a low support means the lack of statistical significance. In the context of privacy protection, however, inference rules are used to infer sensitive properties about the existing individuals , and it is important to eliminate sensitive inferences of any support, large or small. In fact, a sensitive inference in a small group could present even more threats than in a large group because individuals in a small group are more identifiable [ 16 ].
 owner wants to release a version of data in the format to achieve two goals. The privacy goal is to limit the ability of data mining tools to derive inferences about sensitive attributes 1 ,..., n . This requirement is spec-ified using one or more templates of the form, QID  X   X , h ,where  X  is a  X  X alue X  or  X  X roperty X  from some i , quasi-identifier QID is a set of  X  X ttributes X  not con-taining i ,and h is a threshold on confidence. Each value over QID identifies a group of individuals. The data satisfies QID  X   X , h if every inference matching the template has a confidence no more than h . The privacy goal is achieved by sup-pressing some values on masking attributes M 1 ,..., M m .The data analysis goal is to preserve as much information as possible for a specified data analysis task. To measure the  X  X nformation X  in a concrete way, we primarily consider the task of modeling some class attribute in the data. Other notions of information utility can be captured by replacing the information component of our metric, therefore, require little modification to our approach. We assume that attributes 1 ,..., n and M 1 ,..., M m are important, thus, simply removing them fails to address the classification goal. We are interested in a suppression of values for M 1 ,..., M m that achieves both goals.
 Example 2 In Example 1 , the inference { Trader , UK } X  Discharged violates the template To eliminate this inference, we can suppress Trader and Clerk to a special value  X 
Job , and suppress UK and Canada to a special value the new inference { X  Job ,  X  Country } X  Discharged has confidence 50%, less than the specified 75%. No information is lost since Rating does not depend on the distinction of the suppressed values Trader and Clerk , UK and Canada . owner can selectively protect certain sensitive properties  X  while not protecting other properties, specify a different threshold h for a different template QID  X   X  , specify multiple quasi-identifiers QID (even for the same  X  ), specify templates for multiple sensitive attributes . These flexibilities provide not only a powerful representation of privacy requirements, but also a way to focus on the problem area in the data to minimize unnecessary information loss. In the case that the inferences through all QID s are to be limited, the data owner only needs to specify the  X  X ost restrictive X  QID containing all the attributes that occur in any QID (more details in Sect. 3.1 ).
 way. The k -anonymity prevents linking personally identifying attributes to sensi-tive properties by requiring that at least k records share each description of the identifying attributes. The focus is on anonymizing the identifying attributes that define groups. However, if all or most individuals in a group are associated with the same sensitive property, the sensitive property for the group can be inferred with little uncertainty. Machanavajjhala et al. [ 13 ] address this problem by requir-ing  X  X iversity X  of the sensitive property in each group. In particular, their  X  X ntropy group, could be used to limit the confidence of attacks. A larger entropy means a more uniform distribution of sensitive properties in a group, therefore, less associ-ation with a particular sensitive property. For example, for a group of 100 records associated with two different diseases, if 90 records are associated with HIV and the other 10 records are associated with Flu, then this group is entropy 1.4-diverse. A major limitation of this approach is that entropy is not a  X  X ser-intuitive X  measure of risk. In particular, the entropy 1.4-diverse does not convey that inferring HIV has 90% probability of success. Therefore, the data holder may find it difficult to specify her risk tolerance in terms of the confidence of attacks. In the case that HIV occurs less frequently but is more sensitive, their method allows the user to incorporate  X  X ackground knowledge X  to specify different protection for HIV and Flu. Our approach incorporates the background knowledge by allowing the data holder to specify different maximum confidence for different sensitive properties, based on prior knowledge such as the sensitivity and frequency of such properties. owner knows exactly how the data recipient may analyze the data. Often, how-ever, this information, even the data recipient in such cases as web publishing, is unknown. For example, in visual data mining the data recipient needs to vi-sualize data records in order to produce a classifier that makes sense, and in the k-nearest neighbor classification the data itself is the classifier; in such cases re-leasing data records is essential. In other cases, some classifiers are preferred for accuracy, some for precision/recall, some for interpretability, and yet some for cer-tain domain-specific properties. The data owner (such as a hospital) does not have the expertise to make such decisions for the data recipient (such as biomedical researchers) due to the lack of domain knowledge and sophisticated data min-ing techniques. For this reason, we consider the data release for the classification problem, not for individual classifiers or algorithms.
 mulate a template-based privacy preservation problem. Second, we show that sup-pression is an effective way to eliminate sensitive inferences. However, finding an optimal suppression is a hard problem since it requires optimization over all possi-ble suppressions. For a table with a total of q distinct values on masking attributes, there are 2 q possible suppressed tables. We present an approximate solution based on a search that iteratively improves the solution and prunes the search whenever no better solution is possible. In particular, we iteratively disclose domain values in a top-down manner by first suppressing all domain values. In each iteration, we disclose the suppressed domain value to maximize some criterion taking into account both information gained and privacy lost. We evaluate this method on real-life data sets. Several features make this approach practically useful:  X  No taxonomy required . Suppression replaces a domain value with  X  without  X  Preserving the truthfulness of values . The special value  X  represents the  X  Subjective notion of privacy . The data owner has the flexibility to define her  X  Anytime solution . At any time, the user can terminate the computation and  X  Extendibility . Though we focus on categorical attributes and classification Section 3 defines the inference limiting problem. Section 4 presents our suppres-sion approach. Section 5 evaluates the effectiveness of the proposed approach. Section 6 discusses several extensions. Section 7 concludes the paper. 2 Related work Most works on privacy preservation address the concern related to the input of data mining where sensitive properties are revealed directly by inspection of the data the concern over the output of data mining in terms of what data mining tools can discover. We focus on this group of works.
 covered group behavior is attached to all members in a group, which is a form of inferences. Clifton [ 3 ] suggested to eliminate sensitive inferences by limiting the data size. Recently, Kantarcioglu et al. [ 10 ] defined an evaluation method to measure the loss of privacy due to releasing data mining results. However, they did not propose a solution to prevent the attacker from getting data mining results that violate privacy.
 in a transaction database with minimal modification to the data. The general idea is to hide one rule at a time by either decreasing its support or its confidence, achieved by removing items from transactions. They need to assume that frequent itemsets of rules are disjoint in order to avoid high time complexity. We eliminate all sensitive inferences including those with a low support. We can efficiently handle overlapping inference rules. Our approach handles the information lose for classification analysis as well as the general notion of data distortion in a uniform manner.
 16 , 21 ] for achieving k -anonymity. In a k -anonymized database, if one record is linked to some external sensitive property, so are at least k  X  1 other records. In other words, at least k records are indistinguishable to the linking algorithm. How-ever, if all or most of these records are associated with similar sensitive property, this indistinguishability becomes irrelevant in that the attacker can reliably infer the sensitive property. In the preliminary work [ 20 ], we proposed the confidence of inference as a way to measure this threat. Recently, Machanavajjhala et al. [ 13 ] proposed the diversity of sensitive property as a way to make inferring a particu-lar sensitive property uncertain. However, as explained earlier, it is more natural and intuitive for the data holder to measure the risk in terms of the probability of success of attacks.
 control. In multilevel secure databases, the focus is detecting and removing quasi-identifiers by combining meta-data with data. Many of these methods operate at the schema-level and consider only precise inferences that always hold. If there is a security problem, the database is redesigned. Yip and Levitt [ 22 ] extended the work to the data-level by monitoring queries using functional dependencies. For example, it is possible for a user to use a series of unsuspicious queries to infer sensitive properties in the database. Yip and Levitt [ 22 ] proposed a method to detect such queries using functional dependencies. This type of inferences is different from ours.
 information by correlating different statistics. For example, Cox [ 5 ] proposed the k %-dominance rule which suppresses a sensitive cell if the attribute values of two or three entities in the cell contribute more than k % of the corresponding SUM statistic. Such  X  X ell suppression X  suppresses the count or other statistics stored in a cell of a statistical table, which is very different from the  X  X alue suppression X  considered in our work. 3 The problem Let v be a single value, V be a set of values, and R be a set of records. att (v) denotes the attribute of a value v . | R | denotes the number of records in R . R [ v ] denotes the set of records in R that contain v . s ( V ) denotes the number of records containing the values in V . f ( R , V ) denotes the number of records in R that con-tain the values in V . Sometimes, we simply list the values in V ,i.e, s (v 1 ,...,v k ) and f ( R ,v 1 ,...,v k ) ,where v j is either a single value or a set of values. tributes . i are called sensitive attributes . is called the class attribute .Allat-tributes have a categorical domain. For each M j , we add the special value  X  j to its domain. M j and i are disjoint.
 eling the class attribute , but wants to limit the ability of making inference about sensitive attributes i . An inference about sensitive property y has the form of  X  X f x then y  X . Such inferences are  X  X robabilistic X , not  X  X recise X , and are easily ob-tained from the released data by applying today X  X  data mining tools. If an inference is highly confident (i.e., accurate), there is little difficulty to infer sensitive prop-erty y about an individual matching the description x . One way to eliminate such threats is to limit the confidence of inferences. Below, we formalize this notion of privacy requirement into a set of privacy templates. 3.1 Privacy templates The data owner specifies sensitive inferences using templates. A template has the form QID  X   X , h .  X  is a sensitive property or value from some i . QID , called an quasi-identifier , is some set of attributes not containing i . h is a confidence threshold. An inference for QID  X   X , h has the form qid  X   X  ,where qid contains values from the attributes in QID .The confidence of qid  X   X  , written conf ( qid  X   X ) , is the percentage of the records that contain  X  among those that contain the values in qid ,thatis, s ( qid , X )/ s ( qid ) . Conf ( QID  X   X ) denotes the maximum conf ( qid  X   X ) for all qid over QID .
 Definition 3.1 (Privacy Templates) T satisfies a template QID  X   X , h if Conf ( QID  X   X )  X  h. T satisfies a set of templates if T satisfies every template in the set.
 inferences, including those involving  X  j . For convenience, all templates QID  X   X  i , h that only differ in  X  i can be abbreviated as QID  X  X   X  1 ,..., X  k } , h .This is only a notational abbreviation, not a new kind of inferences.
 rem 3.1 considers one such case, which can be used to remove  X  X edundant X  tem-plates.
 Theorem 3.1 Consider two templates If  X  =  X  ,h  X  h , and QID  X  QID ,then 1. Conf ( QID  X   X  )  X  Conf ( QID  X   X ) , and 2. If T satisfies QID  X   X  , h , T satisfies QID  X   X , h , and 3. QID  X   X , h can be removed in the presence of QID  X   X  , h .
 Proof (1) Let X = QID  X  QID . Assume that X = X  . Consider an inference qid  X   X  for QID  X   X  .Let { qid , x 1 } X   X ,..., { qid , x k } X   X  be the infer-ences for QID  X   X  involving qid . s ( qid ) = k i = 1 s ( qid , x i ) and s ( qid , X ) = We prove that conf ( qid , x 1  X   X )  X  conf ( qid  X   X ) ; it then follows that Conf ( QID  X   X  )  X  Conf ( QID  X   X ) because  X  =  X  . The intuition of the proof is similar to that of max { avg ( M ), avg ( F ) } X  avg ( G ) ,whereagroup G of people is divided into the male group M and the female group F ,and avg ( x ) computes the average age of a group x .
 we have the following rewriting (2) follows from (1) and h  X  h . (3) follows from (2).
  X  X aximal X  templates need to be specified among those having the same sensitive property  X  and confidence threshold h .
 Corollary 3.1 T satisfies QID  X   X , h if and only if T satisfies { QID  X   X , h | QID  X  QID } . 3.2 Suppression If T violates the set of templates, we can suppress some values on masking at-tributes M j to make it satisfy the templates (under certain conditions). Suppres-sion of a value on M j means replacing all occurrences of the value with the special value  X  j . In the classification modeling,  X  j is treated as a new domain value in M can reduce the confidence of sensitive inference. Indeed, if suppression could in-crease the confidence, we are not getting any closer to the privacy goal but losing information. Below, we show that suppression never increases Conf ( QID  X   X ) . the records that contain v or  X  j before the suppression. Let  X  j and  X  j denote  X  j before and after the suppression. The difference is that does not. After the suppression, two inferences { qid ,v } X   X  and { qid ,  X  j } X   X  become one inference { qid ,  X  j } X   X  .
 Theorem 3.2 max { con f ( qid ,v  X   X ), con f ( qid ,  X  j  X   X ) } X  con f ( qid ,  X  j  X   X ) .
 { qid , x k } X   X  are replaced with { qid ,v } X   X  and { qid ,  X  j } X   X  ,and qid  X   X  is replaced with { qid ,  X  j } X   X  . In words, Theorem 3.2 says that, by suppressing avalue, Conf ( QID  X   X ) does not go up. This property provides the basis for employing suppression to reduce Conf ( QID  X   X ) .
 Corollary 3.2 Conf ( QID  X   X ) is non-increasing with respect to suppression. 3.3 The problem statement Given a table T and a set of privacy templates { QID 1  X   X  1 , h 1 ,..., QID k  X   X  k , h k } , we are interested in finding a suppressed table T that satisfies the set of templates and is useful for modeling the class attribute. The first question is whether it is always possible to satisfy the set of templates by suppressing T .The answer is no if for some QID i  X   X  i , h i , the minimum Conf ( QID i  X   X  i ) among all suppressed T is above h i . From Corollary 3.2 ,the most suppressed T , where all values for M j are suppressed to  X  j for every M j in  X  QID i ,has the minimum Conf ( QID i  X   X  i ) . If this table does not satisfy the templates, no suppressed T does.
 Theorem 3.3 Given a set of privacy templates, there exists a suppressed table T that satisfies the templates if and only if the most suppressed T satisfies the templates.
 ing T .
 Definition 3.2 (Inference Problem) Given a table T and a set of templates, the inference problem is to (1) decide whether there exists a suppressed T that sat-isfies the set of templates, and if yes, (2) produce a satisfying suppressed T that preserves as much information as possible for modeling the class attribute. satisfiable by suppressing T . If not, we inform the data owner and provide the ac-tual Conf ( QID  X   X ) where QID  X   X , h is violated. With this information, the data owner could adjust the templates, such as reconsidering whether the thresh-old h is reasonable. In the subsequent sections, we assume that the given set of privacy templates is satisfiable by suppressing T . 4 The algorithm Given a table T (in which all values are disclosed) and a set of templates {
QID  X   X , h } , there are two approaches to suppress T . One is iteratively suppressing domain values in M j in  X  QID , called bottom-up suppression ,and the other is first suppressing all domain values in M j in  X  QID and then it-eratively disclosing the suppressed domain values, called top-down disclosure . We take the second approach. At any time in the top-down disclosure, we have a set of suppressed values , denoted Sup j for M j ,andasetof suppressed each iteration, we disclose one value v chosen from some Sup j by doing ex-actly the opposite of suppressing v , i.e., replacing  X  j with v in all suppressed records that currently contain  X  j and originally contain v in the input table. This process repeats until no disclosure is possible without violating the set of templates.
 produced by a sequence of disclosures can be produced by a sequence of suppres-sions. In fact, Sup j on the termination of the algorithm tells exactly the suppres-sions on M j needed to produce the suppressed table. Second, Conf ( QID  X   X ) is nondecreasing with respect to disclosures (Corollary 3.2 ). Therefore, any fur-ther disclosure beyond the termination leads to no solution. Third, compared to the bottom-up suppression starting from domain values, the top-down dis-closure can handle restrictive privacy templates with a smaller number of it-erations starting from the most suppressed table. In fact, by walking from a more suppressed table towards a less suppressed table, we always deal with a small number of satisfying inferences and never examine the large number templates.
 Algorithm 4.1. At each iteration, if some Sup j contains a  X  X alid X  and  X  X enefi-cial X  candidate for disclosure, the algorithm chooses the winner candidate w that maximizes the score function denoted Score . A disclosure is valid if it leads to a table satisfying the set of templates. A disclosure from Sup j is beneficial if more than one class is involved in the records containing  X  j . Next, the algorithm dis-closes w , and updates the Score and status of every affected candidate. Below, we focus on the three key steps (Lines 4 X 6): Line 4: Find the winner candidate w . This step finds the valid and beneficial candidate w from  X  Sup j that has the highest Score . We discuss the computation of Score in Sect. 4.1 .
 Line 5: Disclose the winner candidate w . This step discloses w in T and re-moves w from Sup j . We discuss an efficient method for performing a disclosure in Sect. 4.2 .
 Line 6: Update the score and status for candidates. This step updates Score ( x ) and valid/beneficial status for the candidates x in  X  Sup j to reflect the impact of w . We discuss an efficient update in Sect. 4.3 .
 Example 3 Consider the templates: Initially, the values of Job , Country and Child in Table 1 are suppressed to  X  Job ,  X  Child . This is the most suppressed, or the least disclosed, state. 4.1 Find the winner (Line 4) The winner w is a valid and beneficial candidate from  X  Sup j that has the highest Score . Since disclosing a value v gains information and loses privacy, Score (v) measures the information gain , denoted InfoGain (v) , per unit of privacy loss, de-noted PrivLoss (v) , due to the disclosure of v : T [ X  that originally contain v .Let T v denote the set of such records, and let T [ v ] denote T v after replacing  X  j with v . The disclosure of v is to replace T [ X  j ] with T [ v ] and T [ X  j ] X  T v .
 specified class attribute is the standard entropy-based information gain [ 15 ], E ( R ) measures the entropy or impurity of a set of records R wrt the specified class attribute and InfoGain (v) measures the reduction of entropy after the disclosure of v . (See Quinlan [ 15 ] for the definition of E ( R ) .) The important point is that InfoGain (v) depends only on the class frequency and count statistics of the single attribute att (v) in T [ X  j ] , T [ v ] and T [ X  j ] X  T v .
 defined as the average increase of Conf ( QID  X   X ) over all affected QID  X   X  , i.e., those QID such that att (v) is contained in QID , where Conf and Conf v represent the confidence before and after disclosing v .1is added to PrivLoss (v) to avoid division by zero.
 on combinations of attributes. It is inefficient to actually perform the disclosure of v just to compute Conf v because performing disclosures involves record scans. The key to the scalability of our algorithm is incrementally updating Score (v) in each iteration using the statistics collected during performing the winner disclo-sure w . We will present this update algorithm in Sect. 4.3 . 4.2 Disclose the winner (Line 5) To disclose the winner w , we replace  X  j with w in the suppressed records in T [ X  nally contain w . The following data structure facilitates the direct access to all the raw records affected by this disclosure. The general idea is to partition raw records according to their suppressed records on the set of attributes  X  QID .
 Definition 4.1 (VIP) Value Indexed Partitions (VIP) contains the set of sup-pressed records over  X  QID. Each suppressed record represents the set of raw records from which it comes, called a partition . Each raw record is in exactly one partition. For each disclosed value x (including  X  ) on an attribute in  X  QID, P [ x ] links up all partitions P [ x ] s, with the head stored with the value x . records contain the value x .Let  X  w denote the special value  X  for the attribute of the winner w .Todisclose w ,wefollow Link [ X  w ] and find all suppressed records records. So, we do not have to scan unaffected data records.
 record r , create a new suppressed record r as a copy of r except that  X  w is re-that contain w , and remove such records from P [ X  w ] . Link all new P [ w ] sbythe new Link [ w ] , and relink them to the links to which P [ X  w ] is currently linked, except for Link [ X  w ] . Finally, remove w from Sup j .
 each new partition, there are at most m  X | Link [ X  w ]|  X  X elinking X  operations in to-tal for disclosing w ,where m is the number of masking attributes and | Link [ X  w ]| is the length of Link [ X  w ] . This overhead of maintaining Link [ x ] is negligible. The following example illustrates the procedure of disclosing w in VIP. Example 4 Consider the templates in Example 3 .InFig. 1 , the left-most VIP has the most suppressed record  X  Job ,  X  Country ,  X  Child on three links: The shaded fields  X  X otal X  and  X   X   X  contain the number of raw records suppressed (i.e., | P | ) and the number of those records containing Discharged .
  X  We add this new suppressed record to Link [ X  Country ] , Link [ X  Child ] , and to the new Link [ Clerk ] . Finally, we remove Clerk from Sup j . The next winner, Canada , refines the two partitions on Link [ X  Country ] , resulting in the right-most VIP. The overhead of maintaining these links is proportional to the length of Link [ X  w ] and is negligible.
 lowing count statistics for each partition P in the VIP: for every class  X  and sensi-tive property  X  ,(1) | P | , f ( P , X ) and f ( P , X ) , (2) for each masking attribute M j on which P has the value  X  j , for every suppressed value x in Sup j , f ( P , x ) , f ( the partition P and, on disclosing w , are updated as we scan the partitions on Link [ X  w ] .
 are accessed in our algorithm. Subsequently, updating Score ( x ) makes use of the count statistics in the VIP without accessing raw records. 4.3 Update score and status (Line 6) This step updates Score ( x ) and the valid/beneficial status for candidates x in  X  fected only if x and w are from the same attribute, in other words, x  X  Sup w , where Sup w denotes Sup j for the attribute of w . To update InfoGain ( x ) ,wecom-pute over the partitions P on Link [ X  w ] . These information can be computed in the same scan as collecting the count statistics in the previous step. Mark x as  X  X ene-ficial X  if there is more than one class in these partitions.
 using Conf w ( QID  X   X ) that was computed in the previous iteration. Next, we update Conf x ( QID  X   X ) for x in  X  Sup j . We need to update Conf x ( QID  X   X ) only if both att ( x ) and att (w) are contained in QID . We propose the following QID -tree structure to maintain Conf ( QID  X   X ) .
 of u levels, where level i &gt; 0 represents the values for A j . A root-to-leaf path represents an existing qid on QID in the suppressed T , with s ( qid ) and s ( qid , X ) stored at the leaf node.
 max { con f ( qid  X   X ) } for all qid in the QID -tree. If several templates QID  X   X , h have the same QID , they can share a single QID -tree by keeping s ( qid , X ) separately for different  X  .
 att (w)  X  QID to reflect the move of records from Link [ X  w ] to Link [ w ] .First, for each leaf node representing { qid ,  X  w } , we create a new root-to-leaf node rep-resenting the new { qid ,w } . Then, for each partition P on Link [ w ] ,if { qid ,w } is the value on QID , update the QID -tree as follows: This involves one scan of the link Link [ w ] because | P | and f ( P , X ) are kept with the P s on this link. Here is an example.
 Example 5 Figure 2 shows the initial QID 1 -tree and QID 2 -tree on the left, where QID 1 ={ Job , Country } and QID 2 ={ Job , Child } . On disclosing Clerk , { Next, on disclosing Canada , { Clerk ,  X  Country } is refined into { Clerk , Canada } in QID 1 -tree, and a new { X  Job , Canada } is split from { X  Job ,  X  Country } .Forex-ample, to compute s ( qid ) and s ( qid , X ) for the new qid = (  X  Job , Canada ) ,we access all partitions P [ Canada ] in one scan of Link [ Canada ] : The resulting counts are shown on the right most QID -trees.
 Conf x ( QID  X   X ) only if both att ( x ) and att (w) are in QID . Recall that Conf x ( QID  X   X ) is the maximum con f ( qid  X   X ) after disclosing x . There-s ( qid ,  X  x ) and s ( qid ,  X  x , X ) as we did for w . We now follow Link [ X  x ] instead of Link [ w ] . Since we just compute Conf x ( QID  X   X ) , not performing the disclo-sure of x , we do not update the VIP for x , but just make use of the count statistics The computation is on a copy of the QID -trees because we do not actually disclose x on the QID -trees. Conf x ( QID  X   X ) is the new maximum con f ( qid  X   X ) in the copy QID -tree. If Conf x ( QID  X   X )  X  h ,mark x as  X  X alid X . 4.4 Cost analysis The cost at each iteration can be summarized as two operations. The first oper-ation scans the partitions on Link [ X  w ] for disclosing the winner w in VIP and maintaining some count statistics. The second operation simply makes use of the count statistics to update the score and status of every affected candidate without accessing data records. Thus, each iteration accesses only the records suppressed to the masking attributes. 5 Experimental evaluation We evaluated how well the proposed method can preserve the usefulness for clas-sification for some highly restrictive privacy templates. We also evaluated the efficiency of this method. We adopted three widely used benchmarks: Japanese Credit Screening and Adult were obtained from the UCI repository [ 14 ]. German Credit Data was obtained from Silicon Graphics, Inc. 1 We removed all continuous attributes since our current implementation focuses on categorical attributes. We used the C4.5 classifier [ 15 ] for classification modeling. Other classifiers, such as SVM [ 18 ], may produce lower classification error than the C4.5 does; how-conducted on an Intel Pentium IV 3GHz PC with 1GB RAM.
 differ in the choice of sensitive attributes 1 ,..., N and masking attributes M  X  TopN : We chose the  X  X est X  N attributes, denoted TopN , as sensitive attributes  X  RanN : In this experiment, we randomly selected N attributes, denoted RanN , data without suppression. The suppression error ( SE ) refers to the error for the data suppressed by our method. The suppression was performed before splitting the data into the training set and the testing set. SE  X  BE measures the quality loss due to suppression, the smaller the better. We also compared with the error caused by simply removing all sensitive attributes, which is denoted by removal error ( RE ). RE  X  SE measures the benefit of suppression over this simple method, and the larger the better. Finally, RE  X  BE measures the importance of sensitive attributes on classification. SE and RE depend on the privacy template, whereas BE does not. All errors are collected on the testing set. 5.1 Japanese credit screening The Japanese Credit Screening data set, also known as CRX , is based on credit card application. There are nine categorical attributes and a binary class attribute representing the application status succeeded or failed . After removing records with missing values, there are 465 and 188 records for the pre-split training and testing respectively. In the UCI repository, all values and attribute names in CRX have been changed to meaningless symbols, e.g., A 1  X  X  X  A 15 . We used all the nine categorical attributes.
 Top4 attributes are A 9 , A 10 , A 7 , A 6 in that order. BE = 15 . 4%. Table 3 shows the number of inferences above different confidence thresholds h in the original data. For example, the number of inferences that have a confidence larger than 90% is 6in CRX for Top4 .
 The dashed line represents BE . We summarize the results as follows: 1. Small SE  X  BE . SE spans narrowly between 15.4% and 16.5% across different 2. Large RE  X  SE . The minimum RE  X  SE is 10 . 1% for Top1 , and the maximum 3. Small variance of SE . For all templates tested, the variance of SE is less than 4. Larger benefits for larger N . Having more sensitive attributes (i.e., a larger N values of attributes A 4 and A 5 are suppressed, and the entire A 13 is suppressed. Despite such vigorous suppression, SE = 15 . 4% is equal to BE . In fact, there exist multiple classification structures in the data. When suppression eliminates some of them, other structures emerge to take over the classification. Our method makes use of such  X  X ooms X  to eliminate sensitive inferences while preserving the quality of classification.
 previous experiment. Again, SE spans narrowly between 15.4% and 16.5%, i.e., no more than 1.1% above BE . RE for RanN is lower than RE for TopN because some randomly selected sensitive attributes are not important and their removal has less impact on classification.
 above experiments. 5.2 Adult categorical attributes and a binary class attribute representing the income levels  X  50 K or &gt; 50 K. There are 30,162 and 15,060 records without missing values for the pre-split training and testing respectively. Table 4 describes each categorical attribute. Top4 attributes are M , Re , E , S in that order. BE = 17 . 6%. 70%, 90%. We summarize the results as follows: 1. SE  X  BE is less than 0.8% in all cases. This is amazing considering that hun-2. The largest RE  X  SE is approximately 6% for Top4 . 3. The difference between maximum and minimum SE is less than 1%. 4. For Top1 , RE is slightly lower than SE , implying that removing the top at-The experiments on both TopN and RanN strongly suggest that the suppression approach preserves the quality of classification consistently for various privacy templates. Our algorithm spent at most 14 s for all experiments on Adult ,ofwhich approximately 10 s were spent on suppressing the 45,222 data records. 5.3 German credit data The German Credit Data ,orsimply German , has 13 categorical attributes and a binary class attribute representing the good or bad credit risks. There are 666 and 334 records, without missing values, for the pre-split training and testing respec-tively. Table 5 describes each categorical attribute. The Top6 attributes in German are A , Ch , Sa , I , Lp , D in that order. BE = 28 . 8%. Like the Adult data, German also has many sensitive inferences as shown in Table 3 .
 benefit RE  X  SE is approximately 4.3% on average. Interestingly, RE almost stays flat at 36% for Top1 to Top6 . To explain this, we looked into the data set and found that the Top2 attributes, i.e., A and Ch , play a dominant role in modeling the class attribute. Removing any one (or both) of them increases the error by approximately 7% comparing with BE . Thus, after removing the top one attribute, removing the next top five attributes does not degrade the classification quality much.
 to Top6 .This5%dropof SE from Top1 to Top2 is due to the fact that many values of the second top attribute Ch are suppressed in Top1 , but the top two attributes A and Ch are not suppressed in Top2 .
 increases gradually with respect to the number N of sensitive attributes. This is because the importance of A and Ch has been averaged out in these 30 randomly constructed templates. Our algorithm spent less than 3 s for all experiments con-ducted on German . 5.4 Scalability The key to scalability of our method is maintaining count statistics instead of scan-ning raw data records. The purpose of this experiment is to see how scalable our method is for large data sets. We evaluated the scalability on an expanded version of Adult . We first combined the training and testing sets, giving 45,222 records. Then for each original record r in the combined set, we created  X   X  1  X  X ariations X  of r ,where  X &gt; 1isthe expansion scale . For each variation of r , we randomly and uniformly selected y attributes from  X  QID , selected some random values for these y attributes, and inherited the values of r on the remaining attributes, includ-ing the class and sensitive attributes. Together with original records, the expanded data set has  X   X  45 , 222 records.
 data records based on the templates QID  X  X   X  1 ,..., X  k } , 90% , where the set of sensitive properties {  X  1 ,..., X  k } is the set of 50% least frequent values in the Top1 attribute M ,and QID contains the other seven attributes. This is one of the most time consuming settings in the case of single QID because of the largest number of disclosure candidates to consider at each iteration, and a larger h requires more iterations to reach a solution. Our method spent 192 s to suppress 1 M records, of which 150 s were spent on suppression, and the rest was spent on disk I/O operations. We also tried h = 100%. Our method took a total of 296 s to disclose all values due to the increased number of partitions and number of QID s. However, this is not a typical case because typically we want to eliminate inferences with a confidence higher than some h that is below 100%.
 multiple QID s. The number of different QID s determines the number of QID -trees, and more QID s means more maintenance cost of QID -trees. We determined the number of QID s by uniformly and randomly drawing a number between 3 and 6, and the length of QID between 2 and 5. For each QID , we randomly selected the attributes from the seven remaining attributes, and discarded the repeating ones. All QID s in the same set of privacy templates have the same length and same threshold h = 90%. For example, a set of privacy templates having three QID sof length 2 is {  X  1 ,..., X  k } is the same as above.
 erated as described above. Our method spent 318 s to suppress 1 M records. Out of the 318 s, 276 s were spent on suppression. With h = 100%, our method spent 412 s on suppression. Compared to the case of a single QID , more time was re-quired for a requirement with multiple QID s because it has to maintain one QID -tree for each distinct QID . 6 Extensions To bring out the main ideas, our current implementation has assumed that the first compressed by removing irrelevant attributes and collapsing duplicates (as memory but store the data partitions on disk. We can also use the memory to keep those partitions smaller than the page size to avoid page fragmenta-tion. In addition, partitions that cannot be further refined can be discarded and partitions kept in memory, therefore, the memory demand is unlikely to build up.
 extended to suppress continuous values by the means of discretization .Forexam-ple, we can replace specific age values from 51 to 55 with a less specific interval [51 X 55]. This method does not require a priori discretized taxonomy for a con-tinuous attribute, but dynamically obtains one in the top-down disclosure process. Initially, all domain values of a continuous attribute are represented by a single interval v covering the whole range, and Sup j contains v . At each iteration, a dis-closure for an interval v refers to splitting the interval into two sub-intervals v 1 and v , with the splitting point being chosen to maximize InfoGain .Next, v is replaced by v 1 and v 2 in Sup j forming a new set of candidates for the next disclosure. The criterion for choosing the interval for splitting is exactly same as that for choos-ing a suppressed value for disclosure. This process repeats until no disclosure is possible without violating the set of privacy templates. To extend Theorem 3.2 (therefore, Corollary 3.2 ) to cover QID  X   X  in which QID contains continuous attributes as well, we can replace the disclosure  X  j  X  X  X  j ,v } with v  X  X  v 1 ,v 2 } in the proof, and the rest requires little changes.
 information gain wrt the class attribute is used as the information utility InfoGain . Our approach can be extended to other information utility by substituting InfoGain with a proper measure. For example, if the goal is to minimize the  X  X yntax distor-tion X  to the data [ 16 ], we can regard each suppression of a domain value v in a record as one unit of distortion and define InfoGain (v) to be the number of records that contain v . The rest of the algorithm requires little changes. 7 Conclusions We studied the problem of eliminating the sensitive inferences that are made pos-sible by data mining abilities, while preserving the classification value of the data. A sensitive inference has a high confidence in linking a group of individuals to sensitive properties. We eliminated sensitive inferences by letting the user specify the templates and maximum confidence for such inferences. We used suppression of domain values as a way to achieve this goal. We presented a top-down dis-closure algorithm that iteratively searches for a better suppression and prunes the search whenever no better alternative is possible. Experiments on real-life data sets showed that the proposed approach preserves the information for classifica-tion modeling even for very restrictive privacy requirements.
 References Author Biographies
