 1. Introduction
With the rapid development of digital cameras, cell phones, and PDAs with embedded cameras, the ef fi cient representation of the photos from a personal image library or on the web is becoming more and more important. Image retrieval and brows-ing applications have been developed encouraging people to ef fi ciently search and retrieve a set of images which they want to see in a large database ( Goesele et al., 2010; Singhai and Shandilya, 2010; Vasconcelos, 2005; Vassilieva, 2009; Yoon and Kuijper, 2011 ). To retrieve the images that have similar visual elements ( Ilbeygi and Shah-Hosseini, 2012; Yang et al., 2012 ) from a query image has been a challenging topic in the area of computer vision and machine learning and has been coined  X  Content-Based Image Retrieval  X  (CBIR).

CBIR is an attempt to search the images by using contents in the multimedia database in order to derive the meaningful features ( Amayri and Bouguila, 2013 ) as well as to measure the dissimilarity of the visual objects by using distance functions. The performance of typical CBIR methods heavily relies on both the de fi nition of the similarity measures and the con fi guration of the database. The general Euclidean distance similarity measure and naive database con fi guration methodologies are often too image of Fig. 1 . In the hierarchically summarized images with the extracted 3D camera parameters and visual features, we can ef fi ciently visualize its representative images in a balanced layer within a hierarchical structure.

The main contributions of this paper are as follows: 1. Our proposed method provides an ef fi cient image retrieval according to user's viewpoints. 2. It provides a visualization of the representative images accord-ing to a geographical zoom in/out. As we zoom out of the geographical viewpoints, we only show the representative images of the site or building. Otherwise, we zoom in the map, we browse the images according to its 3D camera parameters.

After a discussion of the background in Section 2 we present our new hierarchical database representation methodology with recovery of the 3D camera parameters and the hierarchical clustering in Section 3 . In our experiments in Section 4 we show the effectiveness of our method. We conclude with a discussion in
Section 5 . 2. Background
The research for geographic location based image retrieval or browsing has received much attention during the last few years ( Naaman et al., 2005; Heesch, 2008 ). The organization of image collections has been accomplished by several classi fi cation criteria, such as detecting signi fi cant events, geographical characteristics in a speci fi c location, or tags in titles of a photographs ( Das et al., 2008; Naaman et al., 2005; Reitz and Kuijper, 2009; Lux et al., 2010; Liu et al., 2009 ). However, current research efforts for image retrieval based on common context and visual features within image repositories try to summarize the collection of images. The hierarchical image representation tasks ( Kuijper and Florack, 2003 ) are composed of various technologies of Image Based
Modeling using 3D camera geometry, feature classi fi cation for image clustering, and image similarity measures. There are similar approaches for image representation methods, interactive brows-ing, and exploration of a collection of photographs and image summarization to represent the visual contents from a given set. hierarchical layers exploiting 3D camera parameters and related poses. 3. Hierarchical representation of database
Our hierarchical image representation method which we pro-pose in this paper is composed of multiple layers. In the lowest layer, we extract the 3D extrinsic camera parameters of the images which build the foundation of our hierarchical image clustering. Upper layers of our hierarchical structure are separated by a clustering algorithm, in which the feature space established within the lowest layer consists of the camera's 3D position and orienta-tion. In the following sections, we will explain how we extract the 3D extrinsic camera parameters from multiple images, establish relationship between 3D positions from multiple images and adequate classi fi cation methods of images at the upper layers based on the similarity measure derived from the camera's 3D extrinsic parameters. 3.1. Recovery of relevant 3D camera parameters
Given n images in the database, the extrinsic camera para-rotation matrix, and t is a 1 3 translation vector, are recovered by using available multiple view geometry methods ( Harltey and Zisserman, 2006; Yoon and Graf, 2009 ) combining 1. an adequate feature detection mechanism in each camera, 2. feature matching between multiple images, 3. the calculation of the epipolar geometry, and 4. the 3D position estimation within the world coordinate system.
Fig. 2 highlights this process of recovering the E i  X  r ; t  X  from multiple images. Fig. 2 (left) shows example images within a collection of images. We have no prior knowledge, such as image resolution, tags, or title. It also shows matching features after the Scale Invariant Feature Transform (SIFT) and Random Sample Consensus (RANSAC) ( Lowe, 1999; Wei et al., 2008 ). The derived epipolar lines between two example images are also identi fi ed. Applying this process, we derive the propagation of errors from a camera motion to an epipolar constraint over two corresponding matching points. The error in the epipolar constraint is simply characterized using the distance from an image point to the epipolar line derived from the corresponding image point in the other image. Fig. 2 (right) displays the relative 3D position and rotation of the camera within the world coordinate system. granularity. Hierarchical clustering algorithms are also separated with variants of the single-link , complete-link , and minimum-variance algorithms. The single-link and complete-link algorithms are most popular. These two algorithms differ in the way they characterize the similarity measure between a pair of clusters.
In the single-link method we apply ( Yoon and Graf, 2008 ), the distance between two clusters is the minimum of the distances between all pairs of camera's 3D extrinsic parameters drawn from the two clusters. The basic agglomerative hierarchical clustering algorithm begins with one image per cluster.
 Let
S  X f E 1 ; E 2 ; ... ; E n 1 ; E n g X  1  X  be the set of 3D extrinsic parameters, E i , to be clustered. At the initial status, the number of clusters is same to the number of we progressively join the closest clusters pairwise through the following equations until k  X  1 (all clusters are hierarchically paired). s  X  i ; j  X  X  D  X  C i ; C j  X  ; 8 i ; j  X  2  X  l ; m  X  argmin
C  X  Join  X  C l ; C m  X  X  4  X  Remove  X  C m  X  X  5  X  Here s  X  i ; j  X  is the similarity measure between cluster C i and C j .
In this paper, the similarity measure between clusters are calcu-lated by the Euclidean distance, D , of the camera's 3D extrinsic parameters.

The objective of our hierarchical clustering algorithm is to extract a multi-level partitioning of images based on 3D camera parameters, i.e. a partitioning which groups images into a set of clusters and then, recursively, partitions them into smaller sub-clusters, until some stop criteria are satis fi ed. Agglomerative hierarchical clustering algorithms start with several clusters con-taining only one object, and iteratively two clusters are chosen and merged to form one larger cluster. This process is repeated until only one large cluster is left, that contains all objects. Divisive algorithms work in the symmetrical way.

Fig. 4 (left) shows the original agglomerative hierarchical image clustering. A Similarity measure between multiple images is computed by the Euclidean distance between 3D camera's posi-tion. From multiple images of the Casa Mila, layers are automati-cally clustered into 12 layers. This number of layers is different from site to site or change of viewpoints.

The unconstrained version of agglomerative hierarchical image clustering builds a dendrogram for all values of k . If there are many images at a public site, the dendrogram will be high. However, there are many places that have only few uploaded photographs on the web. To balance the hierarchical layers of each sites, we front, and roof. The number of images in these categories are 55, 21, and 14, respectively.

In the previous section, we already represented the recovered camera's 3D position and unconstrained and constrained on-line image representation methodology. Fig. 5 shows the automatic hierarchical on-line image clustering of on-line images in the near view of the front and images on the roof and representative images in the layers of the cluster.

Our next experiment is the comparison with non-hierarchical clustering algorithms such as the k-Means and Mean-Shift cluster-ing algorithms ( Comaniciu and Meer, 2002; Xu et al., 2005 )to The top row of Fig. 6 shows on the left the images in the computed 3D camera coordinates and on the right the result of the k-Means clustering for k  X  5 and k  X  7. Clearly it is dif fi cult to fi nd and determine a priori the desired amount of clusters appropriate for the set of images. The bottom row of Fig. 6 shows the Mean-Shift cluster method, that automatically separates the cloud into 6 clus-ters. Clearly, here one can also argue if this is the desired amount of clusters. The representative images of the building in the cluster also shown in Fig. 6 are in the center of gravity of the cluster. Here changes. By clustering the image according to camera's view-points, the hierarchical layers are reduced from 11 layers to 8 layers by applying the constrained agglomerative hierarchical clustering method. 4.4. Hierarchical layers
Table 1 shows the number of hierarchical layers of the category when we tested the unconstrained and constrained hierarchical image clustering method. As shown in Table 1 , we can see that the constrained hierarchical image clustering method is reduces the number of layers in balancing the hierarchical layers of the categories. We are able to sort and view the images that are geographically close to an 3D camera position that users want to watch. It gives convenience and immersion related to applications involving large data on web.

Once the clusters are computed, users can easily select a representative image that corresponds to their desired viewpoint using the 3D camera position and orientation.

Our future work aims on improving this system for industrial applications like hierarchical 3D reconstruction from the collected images. We will focus on the advanced interaction with the user where our hierarchical structure is needed for immersive naviga-tion or viewing of the images.
 Acknowledgments S.M. Yoon was funded by the Korea Meteorological Administration Research and Development Program under Grant Weather Information Service Engine (WISE) project, 153-3100-3133-302-350.
 References
