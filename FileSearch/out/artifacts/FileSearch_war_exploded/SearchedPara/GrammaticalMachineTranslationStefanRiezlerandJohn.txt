 Recent approaches to statistical machine translation (SMT) piggyback on the central concepts of phrase-based SMT (Och et al., 1999; Koehn et al., 2003) and at the same time attempt to impro ve some of its shortcomings by incorporating syntactic kno wledge in the translation process. Phrase-based translation with multi-w ord units excels at modeling local or-dering and short idiomatic expressions, howe ver, it lacks a mechanism to learn long-distance dependen-cies and is unable to generalize to unseen phrases that share non-o vert linguistic information. Publicly available statistical parsers can pro vide the syntactic information that is necessary for linguistic general-izations and for the resolution of non-local depen-dencies. This information source is deplo yed in re-cent work either for pre-or dering source sentences before the y are input to to a phrase-based system (Xia and McCord, 2004; Collins et al., 2005), or for re-or dering the output of translation models by statistical ordering models that access linguistic in-formation on dependencies and part-of-speech (Lin, 2004; Ding and Palmer , 2005; Quirk et al., 2005) 1 .
While these approaches deplo y dependenc y-style grammars for parsing source and/or tar get text, a uti-lization of grammar -based generation on the output of translation models has not yet been attempted in dependenc y-based SMT . Instead, simple tar get lan-guage realization models that can easily be trained to reflect the ordering of the reference translations in the training corpus are preferred. The adv antage of such models over grammar -based generation seems to be supported, for example, by Quirk et al. X  X  (2005) impro vements over phrase-based SMT as well as over an SMT system that deplo ys a grammar -based generator (Menezes and Richardson, 2001) on n-gram based automatic evaluation scores (Papineni et al., 2001; Doddington, 2002). Another data point, howe ver, is given by Charniak et al. (2003) who sho w that parsing-based language modeling can im-pro ve grammaticality of translations, even if these impro vements are not recorded under n-gram based evaluation measures.
In this paper we would lik e to step away from n-gram based automatic evaluation scores for a moment, and investigate the possible contrib utions of incorporating a grammar -based generator into a dependenc y-based SMT system. We present a dependenc y-based SMT model that inte grates the idea of multi-w ord translation units from phrase-based SMT into a transfer system for dependenc y structure snippets. The statistical components of our system are modeled on the phrase-based sys-tem of Koehn et al. (2003), and component weights are adjusted by minimum error rate training (Och, 2003). In contrast to phrase-based SMT and to the abo ve cited dependenc y-based SMT approaches, our system feeds dependenc y-structu re snippets into a grammar -based generator , and determines tar get lan-guage ordering by applying n-gram and distortion models after grammar -based generation. The goal of this ordering model is thus not foremost to reflect the ordering of the reference translations, but to impro ve the grammaticality of translations.

Since our system uses standard SMT techniques to learn about correct lexical choice and idiomatic expressions, it allo ws us to investigate the contri-bution of grammar -based generation to dependenc y-based SMT 2 . In an experimental evaluation on the test-set that was used in Koehn et al. (2003) we sho w that for examples that are in coverage of the grammar -based system, we can achie ve state-of-the-art quality on n-gram based evaluation mea-sures. To discern the factors of grammaticality and translational adequac y, we conducted a man-ual evaluation on 500 in-co verage and 500 out-of-coverage examples. This sho wed that an incorpo-ration of a grammar -based generator into an SMT frame work pro vides impro ved grammaticality over phrase-based SMT on in-co verage examples. Since in our system it is determinable whether an example is in-co verage, this opens the possibility for a hy-brid system that achie ves impro ved grammaticality at state-of-the-art translation quality . Our method for extracting transfer rules for depen-denc y structure snippets operates on the paired sen-tences of a sentence-aligned bilingual corpus. Sim-ilar to phrase-based SMT , our approach starts with an impro ved word-alignment that is created by in-tersecting alignment matrices for both translation di-rections, and refining the intersection alignment by adding directly adjacent alignment points, and align-ment points that align pre viously unaligned words (see Och et al. (1999)). Ne xt, source and tar get sen-tences are parsed using source and tar get LFG gram-mars to produce a set of possible f(unctional) de-pendenc y structures for each side (see Riezler et al. (2002) for the English grammar and parser; Butt et al. (2002) for German). The two f-structures that most preserv e dependencies are selected for further consideration. Selecting the most similar instead of the most probable f-structures is adv antageous for rule induction since it pro vides for higher cover-age with simpler rules. In the third step, the man y-to-man y word alignment created in the first step is used to define man y-to-man y correspondences be-tween the substructures of the f-structures selected in the second step. The parsing process maintains an association between words in the string and par -ticular predicate features in the f-structure, and thus the predicates on the two sides are implicitly link ed by virtue of the original word alignment. The word alignment is extended to f-structures by setting into correspondence the f-structure units that immedi-ately contain link ed predicates. These f-structure correspondences are the basis for hypothesizing can-didate transfer rules.

To illustrate, suppose our corpus contains the fol-lowing aligned sentences (this example is tak en from our experiments on German-to-English translation): Suppose further that we have created the man y-to-man y bi-directional word alignment indicating for example that Daf  X  ur is aligned with words 6 and 7 of the English sentence ( for and that ). This results in the links between the predicates of the source and tar get f-structures sho wn in Fig. 1.
From these source-tar get f-structure alignments transfer rules are extracted in two steps. In the first step, primiti ve transfer rules are extracted directly from the alignment of f-structure units. These in-clude simple rules for mapping lexical predicates such as: and some what more complicated rules for mapping local f-structure configurations. For example, the rule sho wn belo w is deri ved from the alignment of the outermost f-structures. It maps any f-structure whose pred is sein to an f-structure with pred have , and in addition interprets the subj-to-subj link as an indication to map the subject of a source with this predicate into the subject of the tar get and the xcomp of the source into the object of the tar get. Features denoting number , person, type, etc. are not sho wn; variables %X denote f-structure values.
 The follo wing rule sho ws how a single source f-structure can be mapped to a local configuration of several units on the tar get side, in this case the sin-gle f-structure headed by daf  X  ur into one that corre-sponds to an English preposition+object f-structure. Transfer rules are required to only operate on con-tiguous units of the f-structure that are consistent with the word alignment. This transfer contiguity constr aint states that 1. source and tar get f-structures are each con-2. f-structures in the transfer source can only be This constraint on f-structures is analogous to the constraint on contiguous and alignment-consisten t phrases emplo yed in phrase-based SMT . It pre vents the extraction of a transfer rule that would trans-late dankbar directly into appr eciation since appr e-ciation is aligned also to zutiefst and its f-structure would also have to be included in the transfer . Thus, the primiti ve transfer rule for these predicates must be:
In the second step, rules for more comple x map-pings are created by combining primiti ve transfer rules that are adjacent in the source and tar get f-structures. For instance, we can combine the prim-itive transfer rule that maps sein to have with the primiti ve transfer rule that maps ich to I to produce the comple x transfer rule:
In the worst case, there can be an exponential number of combinations of primiti ve transfer rules, so we only allo w at most three primiti ve transfer rules to be combined. This produces O ( n 2 ) trans-fer rules in the worst case, where n is the number of f-structures in the source.

Other points where linguistic information comes into play is in morphological stemming in f-structures, and in the optional filtering of f-structure phrases based on consistenc y of linguistic types. For example, the extraction of a phrase-pair that trans-lates zutiefst dankbar into a deep appr eciation is valid in the string-based world, but would be pre-vented in the f-structure world because of the incom-patibility of the types A and N for adjecti val dankbar and nominal appr eciation . Similarly , a transfer rule translating sein to have could be dispreferred be-cause of a mismatch in the the verbal types V/A and V/N . Ho we ver, the transfer of sein zutiefst dankbar to have a deep appr eciation is licensed by compati-ble head types V . We use LFG grammars, producing c(onstituent)-structures (trees) and f(unctional)-struc tur es (at-trib ute value matrices) as output, for parsing source and tar get text (Riezler et al., 2002; Butt et al., 2002). To increase rob ustness, the standard grammar is aug-mented with a FRAGMENT grammar . This allo ws sentences that are outside the scope of the standard grammar to be parsed as well-formed chunks speci-fied by the grammar , with unparsable tok ens possi-bly interspersed. The correct parse is determined by a fewest-chunk method.

Transfer con verts source into a tar get f-structures by non-deterministically applying all of the induced transfer rules in parallel. Each fact in the German f-structure must be transferred by exactly one trans-fer rule. For rob ustness a def ault rule is included that transfers any fact as itself. Similar to parsing, transfer works on a chart. The chart has an edge for each combination of facts that have been transferred. When the chart is complete, the outputs of the trans-fer rules are unified to mak e sure the y are consistent (for instance, that the transfer rules did not produce two determiners for the same noun). Selection of the most probable transfer output is done by beam-decoding on the transfer chart.

LFG grammars can be used bidirectionally for parsing and generation, thus the existing English grammar used for parsing the training data can also be used for generation of English translations. For in-co verage examples, the grammar specifies c-structures that dif fer in linear precedence of sub-trees for a given f-structure, and realizes the termi-nal yield according to morphological rules. In order to guarantee non-empty output for the overall trans-lation system, the generation component has to be fault-tolerant in cases where the transfer system op-erates on a fragmentary parse, or produces non-v alid f-structures from valid input f-structures. For gener -ation from unkno wn predicates, a def ault morphol-ogy is used to inflect the source stem correctly for English. For generation from unkno wn structures, a def ault grammar is used that allo ws any attrib ute to be generated in any order as any cate gory , with op-timality marks set so as to prefer the standard gram-mar over the def ault grammar . The statistical components of our system are mod-eled on the statistical components of the phrase-based system Pharaoh, described in Koehn et al. (2003) and Koehn (2004). Pharaoh inte grates the follo wing 8 statistical models: relati ve frequenc y of phrase translations in source-to-tar get and tar get-to-source direction, lexical weighting in source-to-tar get and tar get-to-source direction, phrase count, language model probability , word count, and distor -tion probability .

Correspondingly , our system computes the fol-lowing statistics for each translation: 1. log-probability of source-to-tar get transfer 2. log-probability of tar get-to-source rules 3. log-probability of lexical translations from 4. log-probability of lexical translations from tar -5. number of transfer rules 6. number of transfer rules with frequenc y 1 7. number of def ault transfer rules (translating 8. log-probability of strings of predicates from 9. number of predicates in tar get f-structure 10. number of constituent mo vements during gen-11. number of generation repairs 12. log-probability of tar get string as computed by 13. number of words in tar get string These statistics are combined into a log-linear model whose parameters are adjusted by minimum error rate training (Och, 2003). The setup for our experimental comparison is German-to-English translation on the Europarl par -allel data set 3 . For quick experimental turnaround we restricted our attention to sentences with 5 to 15 words, resulting in a training set of 163,141 sen-tences and a development set of 1967 sentences. Fi-nal results are reported on the test set of 1,755 sen-tences of length 5-15 that was used in Koehn et al. (2003). To extract transfer rules, an impro ved bidi-rectional word alignment was created for the train-ing data from the word alignment of IBM model 4 as implemented by GIZA++ (Och et al., 1999). Train-ing sentences were parsed using German and En-glish LFG grammars (Riezler et al., 2002; Butt et al., 2002). The grammars obtain 100% coverage on unseen data. 80% are parsed as full parses; 20% re-cei ve FRAGMENT parses. Around 700,000 transfer rules were extracted from f-structures pairs chosen according to a dependenc y similarity measure. For language modeling, we used the trigram model of Stolck e (2002).

When applied to translating unseen text, the sys-tem operates on n-best lists of parses, transferred f-structures, and generated strings. For minimum-error -rate training on the development set, and for translating the test set, we considered 1 German parse for each source sentence, 10 transferred f-structures for each source parse, and 1,000 gener -ated strings for each transferred f-structure. Selec-tion of most probable translations proceeds in two steps: First, the most probable transferred f-structure is computed by a beam search on the transfer chart using the first 10 features described abo ve. These features include tests on source and tar get f-structure snippets related via transfer rules (features 1-7) as well as language model and distortion features on the tar get c-and f-structures (features 8-10). In our experiments, the beam size was set to 20 hypotheses. The second step is based on features 11-13, which are computed on the strings that were actually gen-erated from the selected n-best f-structures.
We compared our system to IBM model 4 as pro-duced by GIZA++ (Och et al., 1999) and a phrase-based SMT model as pro vided by Pharaoh (2004). The same impro ved word alignment matrix and the same training data were used for phrase-e xtraction for phrase-based SMT as well as for transfer -rule extraction for LFG-based SMT . Minimum-error -rate training was done using Koehn X  s implementation of Och X  s (2003) minimum-error -rate model. To train the weights for phrase-based SMT we used the first 500 sentences of the development set; the weights of the LFG-based translator were adjusted on the 750 sentences that were in coverage of our grammars.
For automatic evaluation, we use the NIST metric (Doddington, 2002) combined with the approximate randomization test (Noreen, 1989), pro viding the de-sired combination of a sensiti ve evaluation metric and an accurate significance test (see Riezler and j1 \ j2 P LFG equal P LFG equal
LFG 10 105 18 6 113 17 equal 53 60 192 51 44 223 Maxwell (2005)). In order to avoid a random as-sessment of statistical significance in our three-fold pairwise comparison, we reduce the per -comparison significance level to 0.01 so as to achie ve a standard experimentwise significance level of 0.05 (see Co-hen (1995)). Table 1 sho ws results for IBM model 4, phrase-based SMT , and LFG-based SMT , where examples that are in coverage of the LFG-based sys-tems are evaluated separately . Out of the 1,755 sen-tences of the test set, 44% were in coverage of the LFG-grammars; for 51% the system had to resort to the FRAGMENT technique for parsing and/or repair techniques in generation; in 5% of the cases our sys-tem timed out. Since our grammars are not set up with punctuation in mind, punctuation is ignored in all evaluations reported belo w.
 For in-co verage examples, the dif ference between NIST scores for the LFG system and the phrase-based system is statistically not significant. On the full set of test examples, the suboptimal quality on out-of-co verage examples overwhelms the quality achie ved on in-co verage examples, resulting in a sta-tistically not significant result dif ference in NIST scores between the LFG system and IBM model 4.
In order to discern the factors of grammaticality and translational adequac y, we conducted a manual evaluation on randomly selected 500 examples that were in coverage of the grammar -based generator . Two independent human judges were presented with the source sentence, and the output of the phrase-based and LFG-based systems in a blind test. This was achie ved by displaying the system outputs in random order . The judges were ask ed to indicate a preference for one system translation over the other , or whether the y thought them to be of equal quality . These questions had to be answered separately un-der the criteria of grammaticality/fluenc y and trans-lational/semantic adequac y. As sho wn in Table 2, both judges express a preference for the LFG system over the phrase-based system for both adequac y and grammaticality . If we just look at sentences where judges agree, we see a net impro vement on trans-lational adequac y of 57 sentences, which is an im-pro vement of 11.4% over the 500 sentences. If this were part of a hybrid system, this would amount to a 5% overall impro vement in translational adequac y. Similarly we see a net impro vement on grammat-icality of 77 sentences, which is an impro vement of 15.4% over the 500 sentences or 6.7% overall in a hybrid system. Result dif ferences on agreed-on ratings are statistically significant, where sig-nificance was assessed by approximate randomiza-tion via stratified shuf fling of the preferences be-tween the systems (Noreen, 1989). Examples from the manual evaluation are sho wn in Fig. 2.
Along the same lines, a further manual evaluation was conducted on 500 randomly selected examples that were out of coverage of the LFG-based gram-mars. Across the combined set of 1,000 in-co verage and out-of-co verage sentences, this resulted in an agreed-on preference for the phrase-based system in 204 cases and for the LFG-based system in 158 cases under the measure of translational adequac y. Under the grammaticality measure the phrase-based system was preferred by both judges in 157 cases and the LFG-based system in 136 cases. The abo ve presented evaluation of the LFG-based translator sho ws promising results for examples that are in coverage of the emplo yed LFG grammars. Ho we ver, a back-of f to rob ustness techniques in parsing and/or generation results in a considerable loss in translation quality . The high percentage of examples that fall out of coverage of the LFG-based system can partially be explained by the ac-cumulation of errors in parsing the training data where source and tar get language parser each pro-duce FRAGMENT parses in 20% of the cases. To-gether with errors in rule extraction, this results in a lar ge number ill-formed transfer rules that force the generator to back-of f to rob ustness techniques. In applying the parse-transfer -gener ation pipeline to translating unseen text, parsing errors can cause er-roneous transfer , which can result in generation er-rors. Similar effects can be observ ed for errors in translating in-co verage examples. Here disambigua-tion errors in parsing and transfer propagate through the system, producing suboptimal translations. An error analysis on 100 suboptimal in-co verage exam-ples from the development set sho wed that 69 sub-optimal translations were due to transfer errors, 10 of which were due to errors in parsing.

The discrepanc y between NIST scores and man-ual preference rankings can be explained on the one hand by the suboptimal inte gration of transfer and generation in our system, making it infeasible to work with lar ge n-best lists in training and applica-tion. Moreo ver, despite our use of minimum-error -rate training and n-gram language models, our sys-tem cannot be adjusted to maximize n-gram scores on reference translation in the same way as phrase-based systems since statistical ordering models are emplo yed in our frame work after grammar -based generation, thus giving preference to grammatical-ity over similarity to reference translations. We presented an SMT model that marries phrase-based SMT with traditional grammar -based MT by incorporating a grammar -based generator into a dependenc y-based SMT system. Under the NIST measure, we achie ve results in the range of the state-of-the-art phrase-based system of Koehn et al. (2003) for in-co verage examples of the LFG-based system. A manual evaluation of a lar ge set of such examples sho ws that on in-co verage ex-amples our system achie ves significant impro ve-ments in grammaticality and also translational ad-equac y over the phrase-based system. Fortunately , it is determinable when our system is in-co verage, which opens the possibility for a hybrid system that achie ves impro ved grammaticality at state-of-the-art translation quality . Future work thus will concen-trate on impro vements of in-co verage translations e.g., by stochastic generation. Furthermore, we in-tend to apply our system to other language pairs and lar ger data sets.
 We would lik e to thank Sabine Blum for her invalu-able help with the manual evaluation.

