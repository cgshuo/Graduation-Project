 Masaki Murata  X  Qing Ma  X  Kiyotaka Uchimoto  X  Toshiyuki Kanamaru  X  Hitoshi Isahara Abstract This paper describes experiments carried out utilizing a variety of machine-learning methods (the k-nearest neighborhood, decision list, maximum en-tropy, and support vector machine), and using six machine-translation (MT) systems available on the market for translating tense, aspect, and modality. We found that all these, including the simple string-matching-based k-nearest neighborhood used in a previous study, obtained higher accuracy rates than the MT systems currently available on the market. We also found that the support vector machine obtained the best accuracy rates (98.8%) of these methods. Finally, we analyzed errors against the machine-learning methods and commercially available MT systems and obtained error patterns that should be useful for making future improvements.
 Keywords Tense/aspect/modality Support vector machine Machine translation system On the market 1 Introduction Tense, aspect, and modality are known to cause problems in machine translation (MT) and these have been translated using manually constructed heuristic rules with traditional approaches (Shirai et al. 1990 ). We carried out experiments on translating tense, aspect, and modality using a variety of machine-learning methods (the k-nearest neighborhood, decision list, maximum entropy, and support vector machine) for our study. We also did experiments on translating tense, aspect, and modality using six MT systems on the market and compared these results with those obtained by machine-learning methods. We confirmed that all the machine-learning methods discussed in this paper obtained higher accuracy rates than commercially available MT systems. We also analyzed errors from machine-learning methods and these MT systems and obtained error patterns that should be useful for making future improvements.

We used a method of simple string matching of expressions at the end of a sentence (Murata et al. 1999 ) in our previous study. However, we confirmed that a support vector machine obtained higher precision in the current study than simple matching. We only used one MT system that was available on the market to compare the evaluated results in our previous study. In contrast, we used six commercially available MT systems to compare these results in the current study. We only used one translation of an input sentence for evaluation and only judged system output that had the same tense, aspect, and modality as the translation to be correct in our previous study. The evaluation was not accurate because tense, aspect, and modality that are different from that in a translated sentence can still be correct. In contrast, we increased the number of translations of an input sentence we used for evaluation in the current study. We also manually checked whether all outputs for all systems were correct or not to ensure the evaluation was complete. We also carried out error analysis on all systems. 2 Task descriptions We used the modality corpus described by Murata et al. ( 2005 ). Part of this is in Fig. 1 . It consists of a Japanese X  X nglish bilingual corpus, and the main verb phrase in each English sentence is tagged with &lt;v&gt; . The symbols at the beginning of each Japanese sentence, such as  X  X  X , X  X   X  X  X  X  X  and  X  X  X , X  X  indicate categories of tense, aspect, and modality for the sentence (e.g.,  X  X  X , X  X   X  X  X , X  X  and  X  X  X  X  X  indicate present tense,  X  X  X an, X  X  and past tense).

The following categories were used for tense, aspect, and modality. 1. combinations of all auxiliary verbs ( X  X  X e able to, X  X   X  X  X e going to, X  X   X  X  X an, X  X   X  X  X ave 2. Imperative mood (one category)
These categories of tense, aspect, and modality are defined on the basis of the surface expressions of English sentences. Therefore, if we are able to determine the correct category from a Japanese sentence, we should also be able to translate the Japanese tense, aspect, and modality into English. The task of this paper was to determine the correct category from a Japanese sentence. We used 39,660 bilingual example sentences from the Kodansha Japanese X  X nglish dictionary to construct the modality corpus. 3 Machine-learning methods We used the following four machine-learning methods for our study: (i) k-nearest neighborhood, (ii) Decision list (Yarowsky 1994 ), (iii) Maximum entropy (Ristad 1997 ), and (iv) Support vector machine (Cristianini and Shawe-Taylor 2000 ). We used two kinds of approaches for the k-nearest neighborhood. The first was TiMBL (Daelemans et al. 1995 ) and the second was simple string matching. TiMBL can search for k-most similar examples by calculating the weights of features. Simple string-matching searches k-training-data items with the most-similar strings at the ends of sentences to the input sentence and makes a decision using k-items (Murata et al. 1999 ). We used the pair-wise method (Kudoh and Matsumoto 2000 ) in the support vector machine for data consisting of more than two categories. 4 Features (information used in classification) When a Japanese sentence is input, we output the category for the tense, aspect, and modality, as discussed in Sect. 2 . Therefore, the features are extracted from the input Japanese sentence.

We tested three kinds of feature sets in our experiments.  X  Feature-set 1 : Feature-set 1 consists of 1-gram to 10-gram strings at the ends of  X  Feature-set 2 : Feature-set 2 consists of 1-gram to 10-gram strings at the ends of  X  Feature-set 3 : Feature-set 3 consists of all the morphemes from all the
Feature-set 1 is the combination of Feature-sets 2 and 3. Feature-set 2 was constructed based on the characteristics of Japanese sentences. Tense, aspect, and modality in Japanese sentences are often indicated by the verbs at the ends of sentences. Verb phrases appear at the ends of sentences in Japanese. Therefore, the strings at the ends of sentences were used as features. Feature-set 3 was constructed by taking the fact that because adverbs such as asu (tomorrow) and kinou (yesterday) can also indicate tense, aspect, and modality, they must therefore be used. Only Feature-set 2 was used for simple string matching. 5 Experiments The following describes our experiments on the translation of tense, aspect, and modality that were conducted using the machine-learning methods described in Sect. 3 with the feature sets described in Sect. 4 for the tasks described in Sect. 2 . We undertook the experiments using the modality corpus explained in Sect. 2 . We used 800 sentences that were randomly extracted from the corpus for evaluation. The other sentences in the corpus were used for learning.

The experimental results are listed in Tables 1 and 2 . Since some Japanese sentences can be translated into several kinds of English modal expressions, we created a gold standard data set for evaluation. 1 The gold standard data were created by an outside company as follows. A category for the tag in the corpus was added to the correct category set. Three professional translators, working independently, each rendered a newly translated English sentence from the input Japanese sentences, and categories for the modality of the sentences were added to the correct category set. A fourth professional translator examined both the input Japanese sentences and the translated English sentences, and added additional correct categories to the correct category set. A fifth and a sixth professional translator checked all the results output by all the machine-learning methods and all the commercially available MT systems used in the experiments, and added additional correct categories to the correct category set. The resulting correct category sets became our gold standard data. When a category output by a system was included in the correct category set, it was judged to be correct. Otherwise, it was judged to be incorrect. There is an example of our gold standard data in Fig. 2 .

The rates of occurrence for the correct categories are listed in Table 3 . Categories more than one because more than one category can be correct.

The best accuracy rates have been underlined for all machine-learning methods in Table 1 .
 Table 2 lists the results obtained from a baseline method and six of the newest MT software programs currently available on the market. A sentence ending with ta (a Japanese particle used for the past tense) was judged to be in the past with the baseline method; otherwise, it was judged to be present. When an MT software program could not output a sentence, the output for the baseline method was used instead. 2 We refer to the six translation systems as A, B, C, D, E, and F in this paper.
We were able to learn the following from the experimental results. The k &gt;1 cases performed better than those for k = 1 with the k-nearest neighborhood methods (TiMBL and string matching). This indicates that a decision based on one example was the worst with these methods.

The use of Feature-set 2 was the best with the decision list and maximum entropy. In contrast, the use of Feature-set 1 was the best in terms of TiMBL and the support vector machine.
 The support-vector machine obtained higher precision than all the other methods. The order of accuracy rates for machine learning methods is as follows: Support Vector Machine &gt; TiMBL &gt; Maximum Entropy, String Match &gt; Decision List.
All the machine learning methods obtained higher accuracy rates than commercially available MT systems. The lowest-rated machine-learning method, the decision list, obtained 97.5%. The highest-rated MT systems on the market, Systems A and B obtained 97.0%. 6 Error analysis We next analyzed errors by investigating error patterns for cases where the translations were judged to be incorrect. These cases arose when accuracy rates were calculated. An error pattern was a pair made up of the correct category and a category for incorrect system output. When there were multiple correct categories, each case was considered to be an error pattern (e.g., when both  X  X  X resent X  X  and  X  X  X rogressive X  X  were correct and the system output was  X  X  X ast, X  X  two error patterns made up of the pair  X  X  X resent X  X  and  X  X  X ast X  X  and the pair  X  X  X rogressive X  X  and  X  X  X ast X  X  were extracted as error patterns). The category for  X  X  X o output X  X  was defined for cases when a translation system on the market did not output part of the verb phrase in the English translation; however, as this rarely occurred, this category has not been presented in the tables. The results obtained by investigating the error patterns are listed in Table 4 . Only those patterns with a total frequency of more than nine occurrences are shown or those with an error frequency for an individual system of more than two occurrences. We used the best system for all machine-learning methods in the investigation. We used five machine-leaning methods and six commercially available MT systems.

We investigated what tendency the distribution of error patterns had in the 11 translation systems. We extracted those error patterns for which the frequency of errors for a system was more than two occurrences and calculated the co-occurrence frequency of the error patterns and the 11 translation systems. We constructed cross tables in this way and then did dual scaling (Weller and Romney 1990 ) to obtain Fig. 3 where the X-axis indicates the first eigen value and the Y-axis indicates the second. There are similarities in the error patterns for each system in the figure. We can also roughly see the error patterns for each translation system. For example, the proximity of error patterns  X  X  X ast:perfect, X  X   X  X  X resent:perfect, X  X  and  X  X  X ast progres-sive:perfect X  X  near System F indicate that System F produced incorrect  X  X  X erfect X  X  rather than the correct  X  X  X ast, X  X   X  X  X resent, X  X  or  X  X  X ast progressive X  X  more often than the other systems.
 We were able to learn the following from Table 4 and Fig. 3 .

The error patterns that MT systems on the market very often produced and machine-learning methods rarely produced were pairs of correct present, perfect, past, and incorrect progressives. These are typical errors produced by MT systems on the market. These error patterns can also be seen at the center for MT systems on the market and near System D in Fig. 3 . The following is an example: The system produced the progressive form rather than the correct present form. Machine-learning methods reduced this error much more than the MT systems on the market. When we used the output of the support vector machine using Feature-set 1 instead of System A when the output of System A was progressive, the rate of accuracy for System A increased to 97.8% (782/800). We found that the methods used in our systems could alleviate this problem. Using these methods will thus aid in the development of future MT systems. For example, these methods can be used as follows: We first translate the input Japanese sentence into English using MT systems. When the input Japanese sentence includes teiru (the expression where MT systems often make errors such as in the above example) at the end of the sentence, we use our machine-learning method to determine the tense, aspect, and modality of the sentence. We then change the tense, aspect, and modality expression in the translated English sentence according to the tense, aspect, and modality determined by machine learning. We can make rewriting rules (i.e., toritsuke rareteiru )  X  X  X s laid X  X ) in another way by analyzing errors and use them to improve the outputs of MT systems.

The error patterns that commercially available MT systems and machine-learning methods both often produced were pairs of a correct present and an incorrect  X  X  X ill. X  X  The same base form is used for both the future and present in Japanese. Therefore, translations with respect to  X  X  X ill X  X  and the present form are difficult to render. 7 Conclusion Tense, aspect, and modality are known to present difficulties with MT and these have been translated using manually constructed heuristic rules with traditional approaches. We carried out experiments on translating these in our study by using a variety of machine-learning methods (the k-nearest neighborhood, decision list, maximum entropy, and support vector machine). We also did experiments on translating tense, aspect, and modality using six MT systems currently available on the market. We compared the results obtained by machine-learning methods with those by MT systems on the market. We confirmed that all the machine-learning methods discussed in this paper obtained higher accuracy rates than the MT systems that are commercially available. We also found that the support-vector machine obtained the best accuracy rates (98.8%) of the machine-learning methods. We also analyzed errors against machine-learning methods and MT systems on the market and obtained error patterns that should be useful for making future improvements. For example, we obtained error patterns that commercially available MT systems very often produced and machine-learning methods rarely produced, which were pairs of correct present, perfect, past, and incorrect progressives. These are typical errors with these MT systems. We found that machine-learning methods could alleviate these problems. Using these methods should aid in the development of better MT systems in the future. For example, we should use machine-learning methods to translate tense, aspect, and modality in MT systems. Although machine-learning methods outperformed MT systems (which are presumably rule-based), we expect that data-driven or statistical approaches using machine-learning techniques in systems that are entirely MT will succeed.
 References
