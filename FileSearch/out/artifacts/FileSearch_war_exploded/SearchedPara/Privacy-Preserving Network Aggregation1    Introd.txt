 As the collection of social network data by enterprises increases, so too does the in-cidence of proprietary network data. One simple example arises from so-called  X  X iral marketing X  campaigns, which exploit the social networks of individuals for targeted marketing. In such a program, a new product is distributed to a few (hopefully influen-tial) individuals with the goal that friends will then buy the product on their recommen-dation. If the success of recommendations can be tracked, future campaigns can take advantage of the previously-collected network information by targeting  X  X nfluential X  viral marketers, as identified by network structure.

Another scenario comes from the analysis of transactional data as a network of prod-ucts, where the edge between two products p i and p j has a weight w ij equal to the number of times p i and p j are purchased together. It has been shown that the structure of such a network can be exploited in order to discover meaningful complex relation-ships between products and propose potentially profitable promotions [13].

In both cases outlined above, any one view of the network may be biased [1,7], meaning that it is an incomplete or unfaithful representation of the underlying  X  X rue X  relationships. The simplest way to overcome such a bias is to combine networks from multiple sources on the principle that two networks are unlikely to suffer the same bias, or that the combination of networks will offer a more complete view of the true network. When networks are highly proprietary or private, participants may not be comfortable disclosing their networks to each other. For i nstance, an aggregate social network may be useful in collecting product recommendations (if you trust your friends and their friends more than the general population), but the structure of individual social net-works is often considered private. In the product networks scenario, while different stores may benefit from sharing, they would still like to preserve their proprietary in-formation such as exact sales and product information. It is with this motivation that we discuss secure methods for network aggregation. Specifically, given a series of net-works G 1 =( V 1 ,E 1 ) ,..., G n =( V n ,E n ) from participants P 1 ,..., P n ,weshowhow to produce an aggregate network G in a manner such that no participant learns anything about another participant X  X  network. We then develop a novel protocol for the case of weighted networks that is secure in the presence of malicious adversaries.
 In this paper, we use the product networks scenario of [13] as the driving scenario. Specifically, we develop a protocol with which a set of n stores, selling products be-tween them, participate in joint computation to securely determine c jk , the number of times product j and product k have sold together in all stores combined (without reveal-ing any information about the products that any one store sells). Each store chooses the products about which it would like to learn, and the stores jointly compute the c jk with-out leaking unintended information to any of the participants. That is, each store only learns the total counts for products of its interest and other stores do not learn any of the inputs. In addition to the full pr otocol, we present strategies for efficient implementation and timing results based on real-world data.

It is worth noting that the protocol developed is general and can be applied to any application requiring a secure aggregation of networks. Our focus on product networks is driven by our ability to conduct empirical e xperiments, since we have data available.
The remainder of the paper is organized as follows: Section 2 describes the problem of secure network aggregation in general and outlines the difficulties associated with weighted networks. Section 3 describes our protocol for secure aggregation of weighted networks, makes suggestions for efficient implementation, and provides timing results on real-world data. Finally, Section 4 offers concluding remarks. Assume a series of participants P 1 ... P n wish to combine their private networks G 1 = ( V 1 ,E 1 ) ...
 we assume that if any network has edge weights, all do.

In the case of unweighted networks, we can define an aggregate network as the  X  X nion X  of individual constituent networks: a vertex or edge appears in the aggregate network if it appears in any individual network. In this case, aggregation is simply a union of the sets of vertices and edges, where edges are ordered pairs of vertices. Pro-tocols exist [6] to compute this union efficiently and securely even in the presence of malicious adversaries. Alternatively, one c ould specify that a vertex or edge appears in the aggregate network only if it appears in at least some number k of individual net-works. This is simply a formulation of the secure over-threshold set union problem, which has been solved in [9] for the case of semi-honest adversaries.
The case of weighted networks is more diffi cult. There is no obviously correct way to aggregate edge weights (one could take the minimum, maximum, sum, average, or any other quantity) and no existing secure protocols permit the combination of information such as edge weights during the computation of a set union. If we assume that the de-sired aggregate is  X  X um X , as in the case of the product networks mentioned above, one could adapt a secure association-rules protocol (i.e. [8,15]) to our problem in the fol-lowing manner: For each edge ( a, b ) of weight w , produce w copies of the transaction { a, b } . Then run a secure association rules protocol with support s and zero confi-dence. The two-item association rules in the result will be the edges in the aggregate network whose total weight is at least s .

There are several problems with this approach. First, the size of the transaction database (and therefore the complexity of the algorithm) will depend on the edge weights, which may be arbitrarily large. Second, in these protocols, one participant learns the answer and must forward it to all others rather than informing all participants simultaneously. Third, these protocols do not preserve the actual aggregate (sum), but merely whether the sum exceeds a threshol d. Our approach, which we present in the next section, addresses all these concerns.

Furthermore, we provide a mechanism whereby participants commit upfront to the vertices (i.e. products or individuals) about which they would like to learn. This com-mitment, which can be omitted for efficiency if deemed unnecessary, provides added privacy in that participants can only learn about what they already know. In a viral mar-keting scenario, for ex ample, participant P i could obtain more complete neighborhood information about individuals already in their network but would learn nothing about individuals in P j  X  X  network that P i had never encountered. Thus P j  X  X  competitive ad-vantage is sustained. In this section, after providing background information, we present our solution, which we call Private Product Correlation (PPC) protocol. We analyze its complexity, pro-pose several efficiency improvements and demonstrate performance on real data. Due to space constraints, the formal security proof has been deferred to [12]. 3.1 Preliminaries Homomorphic encryption. Our solution utilizes semantically secure homomorphic encryption that allows computation on encrypted data without knowledge of the cor-responding plaintext. In particular, we use public-key additively homomorphic en-cryption such as Paillier [11]. Suppose there is a public-private key pair ( pk, sk ) ; we denote encryption of message m as E pk ( m ) and decryption of ciphertext c as D sk ( c ) . The additive property gives us D sk ( E pk ( m 1 ) E pute a re-encryption of m such that it is not feasible to tell whether the two ciphertexts correspond to the same message or not; this i s done by multiplying the ciphertext by an encryption of 0.

Our protocols use a threshold version of homomorphic encryption. In an ( n, k ) -threshold encryption scheme, the decryption key is distributed among n parties and the participation of k of them ( k  X  n ) is required to decrypt a ciphertext. Zero-knowledge proofs. Our protocols rely on zero-knowledge proofs of knowledge from prior literature. In particular, we use a proof of plaintext multiplication defined as follows: given ciphertexts c 1 = E pk ( a ) , c 2 = E pk ( b ) ,and c 3 = E pk ( c ) , the prover proves that c corresponds to multiplication of a and b , i.e., c = a  X  b .Crameretal.[2] give a zero-knowledge protocol for this proof using Paillier homomorphic encryption, which is the type of encryption used in this work.
 Privacy-preserving set operations. Prior literature [5,6,9] contains results that permit privacy-preserving operations on sets (or multi-sets). A set S = { s 1 ,s 2 ,...,s } is rep-resented as the polynomial f S ( x )=( x  X  s 1 )( x  X  s 2 )  X  X  X  ( x  X  s ) . This representation has the property that f S ( s )=0 if and only if s  X  S .

Privacy-preserving operations on sets use encrypted representations of sets. Given a polynomial f ( x )= a x + a  X  1 x  X  1 + ... + a 1 x + a 0 , its encryption is formed as encryption of each coefficient a i : E pk ( f )=( E pk ( a ) ,...,E pk ( a 0 )) . This representa-tion can be used to perform set operations in privacy-preserving manner. One such an operation used in our solution is polynomial evaluation , which given E pk ( f ) , y ,and public parameters allows one to compute E pk ( f ( y )) . This is done by computing the product i =0 E pk ( a i ) y i . We also utilize the set union protocol of [6], which is the fastest protocol for computing the union of two sets. 3.2 Private Product Correlation Protocol In our solution we assume that there are n participants (i.e., stores) P 1 ,..., P n . Each participant P i sells a number of products to which we refer as L i . We assume that a unique naming convention is used, and different participants will use the same name for a particular product.
 Overview of the solution. A natural solution to the product correlation problem in a non-private setting proceeds as follows: each participant counts the number of instances two products were sold together at its store, across all pairs of products the participant offers. Given these counts, the aggregate c ounts are computed for each pair of products the participants collectively carry. Each participant then saves the aggregate counts cor-responding to the products it is interested in. The same logic could be used in construct-ing a privacy-preserving protocol for produc t correlation: each participant computes the counts privately, all of them then engage in a variant of a set union protocol preserving (and summing) the counts durin g the protocol, and finally each participant performs a set intersection on the result to recover the counts for the products of interest.
The existing techniques do not allow this functionality to be implemented in the above form. That is, while privacy-preserving protocols for both set union and set in-tersection exist, they are not composable, i.e., they cannot be used as sub-protocols in a larger solution which is required to be secure. F urthermore, the way sets are represented in these protocols does not permit additional information (such as a count) to be stored with an element of the set. These limitations led us to design alternative mechanisms for achieving the above task.
Our protocol first requires that the participants agree on an ( n, n ) -threshold homo-morphic encryption scheme and a naming convention for vertices. The simplest choice would be some sort of hashed unique identifier, such as UPC codes for product net-works, or e-mail addresses, social security numbers, or ID codes in the more general case. Then, every participant commits to the set of products about which it would like to learn without revealing this set to others. Next, we employ a secure set-union protocol to determine the set of products on which we need to compute. Each participant pre-pares counts for all pairs of products in the set union and broadcasts encrypted counts to others. The participants jointly add the counts using the homomorphic properties of the encryption scheme. To allow a participant to learn information about the products to which he or she committed (without others l earning anything), all parties will aid with the decryption of necessary (unknown to others) counts.
 It is conceivably possible to construct a simpler protocol to achieve similar aims. One could repeatedly apply a secure sum protocol to compute the counts we desire, or could omit the commitment step and simply have participants learn about all pairs of products. However, we would argue that these solutions lack potentially desirable security properties. Our full protocol provides added security by preventing participants from learning an arbitrary amount of information regarding products other stores stock (which could result in stores refusing to participate). That is, by limiting the number of products about which a participant learns , we provide the stores with a useful utility without giving anyone the ability to abuse the knowledge they gain.
 Protocol description. The participants agree on a ( n, n ) -threshold homomorphic en-cryption scheme and generate a public-private key pair ( pk, sk ) for it.
 PPCProtocol : 1. Each participant P i creates a list of products D i = { d 1 ,...,d m i } about which 2. Each participant P i prepares a list of its products L i . The participants engage in a 4. Each P i locally computes the encryption of the sum of all counts for each product 5. Now each P i obtains the decryption of counts of the products to which P i commit-Sub-protocols. NZProofProtocol : A user has a ciphertext c andwouldliketoprove that the corresponding plaintext a (where c = E pk ( a ) ) is non-zero. 1. The prover chooses a random value b and posts E pk ( b ) and E pk ( ab ) . 2. The prover proves in zero knowledge that the decryption of E pk ( ab ) corresponds 3. The prover decrypts E pk ( ab ) and posts ab (this value is jointly decrypted in case of NZRMProtocol : Given a ciphertext c = E plaintext by a random non-zero value b , outputs c = E pk ( ab ) and proves correctness of the computation. 1. The participant chooses a random value b and posts E pk ( b ) and c = E pk ( ab ) . 2. The participant proves in zero knowledge that the decryption of E pk ( ab ) corre-3. The participant also proves that E pk ( b ) encrypts a non-zero value using the Complexity Analysis. To simplify the analysis, let m be the upper bound on the num-ber of items to which a participant commits (i.e., m =max i { m i } ). The total work and communication for participant P i in step 1 of the protocol is O ( m + n ) , which amounts to O ( mn + n 2 ) communication across all parties. The computation and communication associated with the proof of nonzero q m i is constant with respect to m and n and does not affect the complexity. In step 2, the overhead associated with the semi-honest (ma-licious) version of the set union protocol is bounded by O ( n ) ( O ( n 2 + n 2 ) ,resp.) computation and communication per person and therefore O ( n 2 ) ( O ( n 2 2 + n 3 ) , resp.) overall communication. In step 3, each participant X  X  work and communication is O ( 2 ) resulting in O ( n 2 ) overall communication. Step 4 involves O ( 2 ) cheaper operations (modular multiplications) per participant and no communication.
To determine the output for a single participant P i in step 5, the overhead is as follows: step 5a requires O ( m ) operations and the same amount of overall commu-nication. Step 5b requires O ( ) work and communication per participant, resulting in the total of O ( n ) communication. Here the work and communication added by the NZProof protocol is constant per participant a nd per product, so the additional com-plexity introduced is O ( n ) , which does not affect the asymptotic running time. Step 5c involves O ( 2 ) computation and overall communication. Finally, step 5d involves O ( 2 ) threshold decryptions, which amounts to O ( 2 ) work and communication per participant resulting in O ( n 2 ) total communication. Since this part is executed for each participant, the total communica tion of step 5 over all participants is O ( n 2 2 ) .
Thus, if the protocol is built to resist malicious adversaries, the work per participant is O ( n 2 + n 2 ) and the overall communication is O ( n 2 2 + n 3 ) . 3.3 Efficiency Improvements Polynomial multiplication and evaluation. As described in [5], polynomial evalu-ation can be performed more efficiently by applying Horner X  X  rule. Recall from sec-tion 3.1 that computing E pk ( f ( y )) amounts to calculating i =0 E pk ( a i ) y i .More efficient computation can be performed by evaluating it from  X  X he inside out X  as E pk ( f ( y )) = (( the polynomial is always evaluated on small values (compared to the size of the encryp-tion modulus), this results in a significant performance improvement.

The set union protocol we utilize [6] also uses polynomial multiplication, which for large polynomials becomes inefficient. Given an encrypted polynomial E pk ( f 1 )= ( E pk ( a 1 ) ,...,E pk ( a 0 )) and another polynomial f 2 ( x )= b 2 x 2 + plication consists of compu ting (encrypted) coefficients c i of their product: E pk ( c i )= ing multi-base exponentiation (see, e.g., [10 ]), where instead of computing exponentia-for a fixed (small) value of k . This can speed up computation by several times. Packing. Assume that the (total) c jk values are at most 2 M . It is likely that M  X  , where  X  is the number of bits in the modulus of the encryption scheme. In Step 3 of the PPC protocol, a participant posts encryptions. We can reduce this number by storing s =  X  M values in a single encryption, which would require only s encryptions.
To do the compression, suppose we want to place M -bit values x 1 , ..., x s into a single encryption. We then compute E pk ( s i =1 2 M ( i  X  1) x i ) . Note that as long as indi-vidual results do not get larger than M bits, we can add to such compressed encryptions (to obtain the value representing the pairwise values) and we can multiply them by con-stants. In the protocol, addition is the onl y operation performed on the counts. Such compressed encryptions of counts can also easily be used in Step 5 of the protocol if only the counts that correspond to the same product are combined together (e.g., c jk and c jk can be included in the same ciphertext for any k, k ). Doing this compression does not reduce the asymptotic communication of the protocol (as this has no effect on the set union), but it does improve the performance of Steps 3 X 5 in the protocol. Leaking products with zero sales. In our data, there are many products that never sell together, either because they are relatively unpopul ar or because they are not available at the same time. If this information is not valuable to an adversary, pairs of products with zero sales can be excluded from the protocol, meaning that their counts do not need to be encrypted, combined, or decrypted. 3.4 Performance One persistent concern with privacy-preserving data mining protocols is that they tend to be unacceptably computation-intensive. We now present a discussion of the perfor-mance of our protocol and the optimizations that were required to make it tractable in practice. Such a discussion serves both to demonstrate the feasibility of our algorithm and to serve as a baseline for evaluating pri vacy-preserving data mining techniques.
We implemented the protocol in C using ( n, n ) -threshold Paillier encryption [2,3,4] as the encryption scheme and the protocol o f [6] for set union. For efficiency, we extend the set union protocol as follows: the participants decide on a number, B ,ofbuckets, and each participant div ides its products among the B buckets according to a hash function. The participants run the set union protocol B times and combine the results of the runs. This can be accomplished without l eaking additional inf ormation since the combination of several unions is the same as the final union. If the participants split the products uniformly among B = log( ) buckets, the buckets will contain log( ) products on average, reducing the time complexity of the set union from O ( n 2 ) to O ( n log( )) . In practice, the participants do not know the size of the union beforehand, so we approximated with n  X  i where i is the number of products in each store. We find that this significantly reduces the running time of the set union.

In conducting the experiment s, we accounted for the parallelism afforded by the pro-tocol (each participant doing co mputation in parallel). However, in situations where the computation must be serialized we time the computation of all participants. Specifically we do not include key generation, the construction of unencrypted polynomials for the set union, or the construction of the commitment polynomials. These are pre-processing steps outside the context of PPC. For steps that can be done by all participants simulta-neously (steps 2, 3, 4, 5d), we only time the effort of one participant. In steps 4 and 5d, the effort to combine results is also timed.

All experiments were done with a 1024-bit key in keeping with modern standards for public-key encryption, and are run on real-wor ld transaction data from a convenience store at the University of Notre Dame. For the purposes of the experiment, we con-structed several stores from a single d ataset by randomly assigning products to each store from a pre-determined list of top-selling products. The size of the set union de-pends on how much overlap there was between the selections of the different stores and is, therefore, random.

Table 1 shows performance as a function of the number of participants n , the size of the set union , and the size of each store. We present timing results for ( i) the full pro-tocol carried out on all pairs of products and (ii) when pairs of products that were never sold together were excluded, as mentioned in Section 3.3. We also report the speedup obtained from the second scenario over the fir st. The time taken to complete the protocol in both cases scales most significantly with the size of the set union. While increases in the number of participants has some effect, it is partially offset by the increase in the amount of available parallelism afforded b y the participatio n of multiple entities.
Improvement as a result of leaking zero counts is substantial, achieving at least 2.22 times speedup. In general, the benefit to leaking zeros increases with the size of the union as zeros become more likely and decreas es with the number of participants, as the overhead of each computation is larger. The only exception was the case with 10 stores and 200 products, in which we observe a decrease in speedup from 2.79 to 2.22. Based on other results, this seems to be an aberration, perhaps caused by unusual activity on the machine running the experiment. In all, we observe that leaking zero counts makes the computation substantially more tractable. Whereas computing all O( 2 ) counts takes almost five days with ten participants and 1500 products in the union, leaking zero counts reduces computation time to just over one day. The goal of this work was to design solutions that utilize the power of networks while ensuring that privacy of the affected parties is preserved and no unintended information leakage takes place. We considered a family of product networks where the stores want to share information about their product/item n etworks to form a global network, such that they can query this global network for efficient marketing and pricing. The collec-tion of large volumes of customer transaction data is commonplace among both large and small retailers of consumer products. The data collected by any one retailer may potentially be biased , i.e., it does not accurately reflect the level of demand for products in the store, for any number of reasons. Moreover, competitive enterprises can mutually improve their standing in a market by sharing information with rivals [14].

To address these concerns, we developed the Private Product Correlation (PPC) pro-tocol for the secure exchange of aggregate network information. The protocol provides more information to participants (namely, a sum of counts) and is secure against mali-cious as well as semi-honest adversaries. While our work targeted the product networks, it is general enough for applicability to any scen ario that requires an aggregation of net-works such that no participant learns anything about another participant X  X  network.
We empirically demonstrate the efficacy of the developed protocol by present-ing timing results, which show that our framework is tractable for participants with reasonable computing power. Our results suggest that execution of the protocol would take on the order of days for participants with a modest number of products using widely-available off-the-shelf hardware. Furthermore, if participants are comfortable with leak-ing pairs of products that they do not sell together at all, they will see significant gains in performance.

We hope that the above-described analytical techniques and privacy-preserving pro-tocol lead to the increased availability of transactional datasets for scientific study. Prod-uct networks contain signifi cantly less information than t ransaction databases, because some information is lost in the aggregation process. The combination of several prod-uct networks, then, should reveal almost nothing about one store X  X  marketing model. As such, retailers could consider an aggregated product network to be devoid of proprietary information and may allow this information to be released and studied.
 Acknowledgments. This work was supported in part by the NET Institute, the Air Force Office of Scientific Research under grant AFOSR-FA9550-09-1-0223 and the National Science Foundation under grants CNS-0915843 and BCS-0826958.

