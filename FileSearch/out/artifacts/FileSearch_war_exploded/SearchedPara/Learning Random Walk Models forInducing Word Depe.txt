 Kristina Toutanova kristina@cs.stanford.edu Christopher D. Manning manning@cs.stanford.edu Andrew Y. Ng ang@cs.stanford.edu Word dependency or co-occurrence probabilities are needed in many natural language tasks. This includes lexicalized parsing, building language models, word sense disambiguation, and information retrieval. How-ever, it is difficult to estimate these probabilities be-cause of the extreme sparseness of data for individ-ual words, and even more so for word pairs, triples, and so on. For instance, Bikel (2003) shows that the parser of Collins (1999) is able to use bi-lexical word dependency probabilities 1 to guide parsing decisions only 1.5% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories. If a system could be built with rea-sonably accurate knowledge about dependency proba-bilities between all words, one would expect the per-formance gains on many tasks to be substantial. Sophisticated back-off and interpolation methods have been developed for language modeling (Goodman, 2001). Dagan et al. (1999) showed that performance on zero-count events can be greatly improved if the model includes estimates based on distributional sim-ilarity. Other kinds of similarity among words have also been used to reduce sparseness. For instance, stemming words is a very traditional way of somewhat lessening sparseness, and resources like WordNet have been used in many natural language models.
 All of these ways of using associations and similar-ities between words to predict the likelihood of un-seen events have their advantages. Symbolic knowl-edge bases, such as WordNet, have the advantage of being based on abundant world knowledge and hu-man intuition, but have the disadvantages of having incomplete coverage and being non-probabilistic. Us-ing stemming or lemmatized words has been helpful for reducing sparseness in some problems, and slightly harmful in others (Hull, 1996).
 Here, we propose a method for combining these in-formation sources that induces a distribution over words by learning a Markov chain (random walk) model, where the states correspond to words, such that its stationary distribution is a good model for a specific word-distribution modeling task. The idea of constructing Markov chains whose stationary dis-tributions are informative has been seen in several other applications, such as the Google PageRank al-gorithm (Brin &amp; Page, 1998), some HITS (Kleinberg, 1998)-like link analysis algorithms (Ng et al., 2001), and for query expansion in IR (Lafferty &amp; Zhai, 2001). Our work is distinguished from these approaches in that rather than using a carefully hand-picked Markov chain, we will automatically learn the parameters for the random walk. This allows us to construct Markov chains with many more parameters, that are much richer in structure and of significantly greater com-plexity than seen in other applications. In doing so, we can also allow our model to learn to exploit di-verse knowledge sources such as WordNet, morphol-ogy, and various features of words derived from depen-dency relations; all of these simply become additional  X  X eatures X  made available to the random walk learning algorithm. The proposed techniques are general and can be applied to other problem domains, such as the web, citation, and clickstream data.
 In this paper, we choose deciding the attachment site of Prepositional Phrases (PPs) as a touchstone prob-lem, and show how random walk methods can be ap-plied to this problem. PP attachment decisions are a central component problem in parsing and one of the major sources of ambiguity in practice. For example, in the sentence: He broke the window with a hammer , the prepositional phrase with a hammer could either modify the verb broke , and thus mean that the ham-mer was the instrument of the breaking event, or it could modify the noun window and thus mean that the window perhaps had a stained glass rendition of a hammer in it. People immediately recognize the more plausible meaning using their world knowledge, but this knowledge is not readily available to parsers. Pre-vious research has shown that by using statistics of lexical co-occurrences, much higher accuracy can be achieved in comparison to approaches that only look at structure (such as preferring attachment to a verb or the closer word, etc.) (Hindle &amp; Rooth, 1993). We briefly review Markov chains (MC). For a more detailed treatment, see, e.g., (Br  X  emaud, 1999). AMCoverasetof states S is specified by an initial distribution p 0 ( S )over S , and a set of state tran-sition probabilities p ( S t | S t  X  1 ). A Markov chain de-fines a distribution over sequences of states, via a gen-erative process in which the initial state S 0 is first sampled from according to p 0 , and then states S t (for t =1 , 2 ,... ) are sampled in order according to the transition probabilities. The stationary distribution of a MC is given by  X  ( s ) = lim t  X  X  X  P ( S t = s ), if the limit exists.
 The MCs used in (Brin &amp; Page, 1998; Ng et al., 2001) have the property that on each step, there is a proba-bility  X &gt; 0 of resetting according to the initial state distribution p 0 . Thus, the state transition probabili-ties can be written for some appropriate p . This ensures that the MC has a unique stationary distribution (Br  X  emaud, 1999), and in practice also prevents the chain from getting stuck in small loops (Brin &amp; Page, 1998).
 Given a MC as described above, we can construct another MC S 0 ,S 1 ,... with the initial state S 0 dis-tributed according to p 0 , and state transitions given by the p in Equation (1). It is straightforward to show that where  X  here is the stationary distribution of the orig-inal MC S 0 ,S 1 ,... . Equation 2 can be used to effi-ciently compute  X  . Also, because terms corresponding to large t have very little weight (1  X   X  ) t , when com-puting  X  , this sequence may be truncated after the first few (on the order 1 / X  ) terms without incurring significant error.
 Equation (2) gives a useful alternative view of  X  . Con-sider a random process in which the state S 0 is ini-tialized according to p 0 . On each time step t , with probability  X  we  X  X top X  the chain and output the cur-rent state S t ; and with probability 1  X   X  , we till take a state transition step and sample S t +1 according to the transition probabilities p ( S t +1 | S t ). This process is continued until the chain is stopped and a state is output. Because the number of steps T taken in the chain until it is stopped is distributed according to a geometric distribution with parameter (1  X   X  ), we can see using Equation (2) that the random state output by this process will also be distributed according to  X  . For the application considered in this paper, it will be useful to consider a generalization of this random process. Specifically, we will construct an MC where, once we have decided to stop the MC (which happens with probability  X  on each step), we will allow the state to transition one final time according to a new set of transition probabilities p ( S t +1 | S t ) (different from the transition probabilities used in the earlier steps of the walk), and finally output S t +1 . Note that if p ( S t +1 | S t )=1iff S t +1 = S t , this reduces to the sim-pler type of random walk described earlier. In Section 3 we will see how permitting an extra state-transition step at the end allows us to build significantly more expressive models. 3.1. The PP attachment model Following most of the literature on Prepositional Phrase (PP) attachment (e.g., Collins &amp; Brooks, 1995; Stetina &amp; Nagao, 1997; Harabagiu &amp; Pasca, 1999; Pantel &amp; Lin, 2000; Brill &amp; Resnik, 1994), we focus on the most common configuration that leads to ambigu-ities: V NP PP. Here, working bottom-up in parsing, the goal is to determine if the PP should be attached to the verb or to the object noun phrase. Previous work has shown the central (but not exclusive) role played by the head words of phrases in resolving such ambiguities, and we follow common practice in rep-resenting the problem using only the head words of these constituents and of the NP inside the PP. For example, given the tuple: (3) v :hang n 1 :painting p :with n 2 :nail we would like to determine if the prepositional phrase with nail should modify the verb hang , or the noun phrase headed by painting . Here, clearly, with (a) nail modifies the verb hang .
 We start by building a generative model for the prob-ability of the sequence of four head words and the at-tachment site P ( V, N 1 ,P,N 2 , Att ), where V is a verb, P a preposition, and N 1 and N 2 are the two head nouns involved in the attachment problem. The vari-able Att has as value either va (for verbal attachment) or na (nominal/noun attachment). Using a model for this joint distribution, we can compute the conditional distribution P ( Att | V, N 1 ,P,N 2 ) and use that to pre-dict the more likely attachment type.
 The model makes only two context-specific indepen-dence assumptions: that given a verbal attachment, the second noun is independent of the first noun, and that given a nominal attachment, the second noun is independent of the verb. More specifically, the model decomposition is as follows: P ( v, n 1 ,p,n 2 , va )= P ( v, n 1 ,p,n 2 , na )= Each of the factors above, except for P ( p, Att ), are estimated using random walks.
 To illustrate the degree of data sparsity for this prob-lem, Table 1 shows the percentage of test cases for which we had a non-zero relative frequency estimate from the training set for each of the factors needed for Equation 4. As can be seen, for the factors involv-ing two words in addition to the preposition, more than 3/4 of the time we have not seen the tuple in the training set. 3.2. Random walks We now describe our random walk model for the word dependency distributions needed for equations 4 X 5. We illustrate with the case of estimating P ( n 2 | p, v, va ). Instantiating the example in (3), this is P ( N 2 = nail | P = with ,V = hang , va ), the probability that, given hang is modified by a PP whose head is with , nail is the head of the noun phrase governed by with . This is strictly a tri-lexical dependency, but because prepositions can often be regarded as just a marker of the semantic role of their object noun phrase, we can informally think of this as estimating the probability of a particular sort of semantic dependency; here it is the likelihood of n 2 :nail bearing a with -type depen-dency to the word v :hang. Thus, given the preposition, we can view this as estimating a bi-lexical dependency between a verb v and a noun n 2 .
 We will estimate this probability using a Markov chain. More precisely, we will construct a MC M (whose tran-sition probabilities will depend on p , v , and the fact that Att = va ) so that its stationary distribution  X  is a good approximation to P ( n 2 | p, v, va ). We let the state space S of our random walk be W X { 0 , 1 } , where W is the set of all words. Thus, a state is a pair consisting of a word and a single  X  X it X  taking on a value of 0 or 1. As we will shortly see, the extra memory bit allows our walk to  X  X emember X  if the word in the current state is a head (0) or a dependent (1), and will permit us to build richer models. 2 For P ( n 2 | p, v, va ), v is a head, and n 2 is a dependent (and the type of the dependency relationship is indicated by p ). Below we will write ( nail ,1)as d nail , both for brevity, and to remind us of the extra bit X  X  meaning. The initial distribution p 0 of our Markov chain puts probability 1 on the state h v (i.e., we always start at the state for the head verb, with the bit-value 0). Let us first walk through some cases using the  X  X ang painting with nail X  example, with the small random walk model shown in figure 1. For the sake of this example, it will be convenient to begin with the case of T = 1. We are trying to estimate If, in a training set of disambiguated PP-attachment examples, we have seen the event ( V = hang ,P = with , Att = va ) before, then clearly one possible es-timate for the probability in (6) might be given by its empirical distribution. Specifically, if nail was frequently seen in the context of the event ( V = hang ,P = with , Att = va ), then we would like to as-sign a large probability to this event. One way to ensure that the random walk frequently visits nail in this setting is therefore to have the probability of transitioning from the initial state to some other state d w , representing a dependent word, be mono-tonically increasing in the empirical distribution of p ( N 2 = w | V = hang ,P = with , Att = va ). Now, suppose that, because of data sparseness prob-lems, we have not seen  X  v :hang p :with n 2 :nail X  in our training set, but that we have seen  X  v :hang p :with n :nails X  several times. Further, our stemmer indi-cates that nail and nails have the same root form. In this setting, we would still like to be able to assign a high probability to p ( nail | hang , with , va ). I.e., we want  X  to give d nail a large probability. Using the state transitions described above, we already have a large probability of visiting d nails . If our random walk now gives a large probability of transitioning from d nails to nail , then we would be done. More broadly, we would like our random walk to be able to make a transition from ( w 1 ,b 1 )to( w 2 ,b 2 ), if w 1 and w 2 are words with the same root form, and b 1 = b 2 .
 Similarly, if we know that p ( rivet | hang , with , va )has a large probability, and if some external knowl-edge source tells us that rivet and nail are seman-tically closely related, then we should infer that p ( nail | hang , with , va ) should also be fairly large. This can be done by using a thesaurus, or a resource like WordNet, a large collection of words classified into a set of senses (synsets), which are organized in a hier-archy, and permitting transitions between ( w 1 ,b 1 )and ( w 2 ,b 2 ) if an external knowledge source tells us that w 1 and w 2 are related, and b 1 = b 2 . 3 More broadly, we have outlined above several different  X  X ypes X  of inferences that can be made about what tu-ples v, p, n 2 are likely. These types of inferences often exploit external knowledge sources (such as a stemmer, or WordNet), and we have shown several examples of how they can be encoded into a random walk frame-work, so that the stationary distribution gives a large probability to events that we would like our procedure to conclude are likely. Note in particular that if there are multiple paths to a node, then that  X  X einforces X  a particular conclusion. By combining multiple steps of these inferences together, in figure 1, we should be able to conclude that if (a) hang with hook ,(b) fasten with hook and (c) fasten with rivet are likely; that (d) hooks and hook have the same root, and if (e) rivet and nail are semantically related, then fasten with nail is also likely. Specifically, the sequence of states the random walk might visit based on this information is h hang a  X  hooks d  X  d hook b  X  h fasten c  X  d rivet e  X  d nail . Thus, by considering multiple steps of the random walk, we can combine multiple steps of inference together. But the model by its nature also captures that long multi-step chains do not give much support to their conclusion. 3.3. Formal model We now describe our model formally. Our Markov chain X  X  transition probabilities are built up using a set of different links , which should be thought of as  X  X a-sic X  transition distributions that correspond to differ-ent possible inference steps.
 Each link type always leads from states where the memory bit takes on some particular value b 1 to states where the bit takes on a value b 2 (not necessarily dif-ferent from b 1 ). The final transition distribution will then be a mixture of the basic transition distributions, where the mixture weights are learned automatically. Let the links l 1 ,...,l k be given by transition matrices T ,...,T k . Each matrix T i has rows for states with memory bits startBit ( i ) and its rows are distributions over successor states with memory bit endBit ( i ). The probability of transitioning from ( w, b )to( w ,b ) in the Markov chain is given by:
P ( w ,b | w, b )= The parameter  X  ( w, b, i ) is the weight of link l i for the state ( w, b ). It can also be viewed as the probabil-ity of taking a link of type l i given the current state ( w, b ). The probabilities  X  ( w, b, i ) sum to 1 over all links l i having a starting bit startBit ( i )= b . Parame-ters of this form for all states are estimated automat-ically from data. Since estimating separate param-eters for each word would introduce too much spar-sity, we define equivalence classes of states for which we tie the parameters. To avoid constrained opti-mization, we handled the constraints i  X  ( w, b, i )= 1 ,  X  w, b and  X  ( w, b, i )  X  0 by representing  X  ( w, b, i )= e the  X  ( w, b, i ) and they are not constrained. As mentioned in Section 2, we also add one more re-finement to the model, by further distinguishing be-tween two different kinds of links: ones that can be followed at any time, and ones that can be taken only in a final ( T -th) step of the walk. We call the lat-ter type final links. The intuition here is that (due to the usual sparseness in NLP data) we do wish to include in our model distributions that back off from conditioning on individual words and that therefore can transition to a highly-smoothed model. But, it would be undesirable to allow transitions to backed-off distributions throughout the random walk. Specif-ically, allowing such transitions would cause us to lose the intuition of the random walk as exploring close neighbors of a word based on some similarity criterion. An additional advantage of having a special stopping distribution is that we can disable transitions to states that don X  X  have the desired memory bit; for example if the random walk is estimating P ( N 2 | v, p, va ), the last state has to be a dependent. Thus in a final step of the walk, the probability of following a link type leading to a non-dependent state is fixed to zero.
 Thus we learn two different transition distributions of the Markov chain  X  a distribution P nf in ( w ,b | w, b ), and a distribution P fin ( w ,b | w, b ). The final links participate only in P fin , whereas the other links par-ticipate in both P fin and P nf in .
 The parameters of the model were fitted to optimize the conditional log-likelihood of the correct attach-ment sites for a development set of samples, disjoint from the training and test sets, including quadratic regularization. That is, we maximized the objective: Here i ranges over the sample set, and s ranges over the model parameters. We performed the optimization using a limited memory quasi-Newton method.
 The number of parameters depends on the scheme for defining equivalence classes over states. The param-eters correspond to distributions over link types for states and stopping probabilities. The stopping prob-abilities can also depend on the particular Markov chain. We experimented with binning the parameters based on observed number of times of occurrence of words but the simplest model having a single equiva-lence class performed on average as well as the more complex models. 3.4. Link types for PP attachment For modeling P ( N 2 | p, v, va ), we have separate Markov chain transition matrices for each preposition p , with the link types given below. The initial state distribu-tion places probability 1 on the state h v . The first eight link types are: 1. V  X  N. Transitions from h w 1 to d w 2 with proba-2. Morphology. Transitions from ( w 1 ,b )to( w 2 ,b ) 3. WordNet Synsets. Transitions from states 4. N  X  V. Transitions from d w 1 to h w 2 with proba-5. External corpus. Same as link L1, but the em-6. V  X  V. Transitions from h w 1 to h w 2 with proba-7. N  X  N. Analogously to the previous link type, 8. V  X  V. Transitions from h w 1 to h w 2 with proba-We also used the following final links to add at the end over-smoothed back-off distributions. These represent all levels in a linear back-off sequence estimated from the training corpus, and a single level of back-off from the additional corpus of noisy samples. Note that these distributions are the same for every state: 9-12. Backoff1 through Backoff4 Transitions to 13. Backoff5. Transitions to d w 2 with probabil-Additionally, we add identity links (self-loops), to avoid situations where no link type can be followed. We work with the Penn Treebank Wall Street Jour-nal data (Ratnaparkhi et al., 1994), which consists of four-tuples of head words and a specification of the type of attachment. There are 20,801 samples in the training set, 4,039 in the development set, and 3,097 samples in the test set. This same data has been used by several other researchers (Ratnaparkhi et al., 1994; Collins &amp; Brooks, 1995; Stetina &amp; Nagao, 1997). The back-off model of (Collins &amp; Brooks, 1995) is the best-performing previously published algorithm for the task of classifying samples by only using statis-tics of word occurrences from the training corpus and we use it as one of our baselines. Better results have been reported on this test set by (Stetina &amp; Nagao, 1997) (88.1%) and on other datasets by (Harabagiu &amp; Pasca, 1999), but the C&amp;B algorithm is the clearest established baseline of good performance, since it does not rely on additional processing stages such as word sense disambiguation or use of named entity recogniz-ers. Previous studies of human performance suggest an upper bound on attachment accuracy, given just the four-tuple of head words, of 88.2% (Ratnaparkhi et al., 1994). Therefore it is plausible to accept a Bayes error of about 10% for this task.
 Our algorithm uses the training set to estimate empir-ical distributions and the development set to train the parameters of the random walk. We report accuracy results on the final test set.
 In addition to this training data set, we generate ad-ditional much noisier training data, using the BLLIP corpus. BLLIP is a corpus of 1,796,386 automatically parsed English sentences (Charniak, 2000). From the parsed sentences, we extracted tuples of four head-words and attachment site for ambiguous verbal or noun PP attachments. This made for a total of 567,582 tuples. We will call this data-set BLLIP-PP. One can expect this data to be rather noisy, since PP at-tachment is one of the weakest areas for state of the art statistical parsers. We pre-processed the data by lower-casing the verbs and prepositions, and by sub-stituting all digits with the X symbol.
 For all models, we ran the Markov chain for at most some d time steps (which may depend on the type of links used); we call d the maximum degree of the Markov chain. (I.e., Equation 2 is truncated after d terms, and renormalized to sum to 1.) Accuracy re-sults on the test set are shown in Table 2. The last column of the table shows significant differences ac-cording to McNemar X  X  test.
 We first report the accuracy of the simplest walk of maximum degree 1, which is of the same form as the familiar linear mixture models. This walk estimates the probability P ( n 2 | p, v, va ), using link types L1, L9, L10, L11, and L12 as follows:
P ( n 2 | p, v, va )=  X  0 ( p, v, va )  X  P ( n 2 | p, v, va ) Similar walks are constructed for all other factors needed for the generative model. Since the maximum degree is 1, only transitions according to a final distri-bution P fin are taken P ( n 2 | p, v, va )= P fin p,va ( n This is our baseline model and we name it Baseline . The accuracy results for the Baseline model are shown in row 4 of table 2. It is worth noting that our sim-ple generative model with linearly interpolated rela-tive frequency estimates (and interpolation parameters fitted discriminatively), performs better than the dis-criminative back-off C&amp;B algorithm (shown in row 1). The last column shows that it is significantly better at level . 005 ( p -value . 0012).
 Next we describe the incremental addition of links to our model, with discussion of the performance achieved. We fix the maximum degree of the walks for estimating the uni-lexical dependencies P ( v | p, Att ) to d = 2, and the maximum degree of all other walks, estimating bi-lexical dependencies, to d =3. 4 1. Morphology. Adding a link between verbs 2. WordNet Synsets. We use WordNet in a simple 3. Similarity based on Jensen-Shannon di-4. Final Model. The major addition to the final Random walk models provide a general framework for unifying and combining various notions of similarity-based smoothing. A walk of length 1 is just a linear interpolation, with interpolation weights typically set empirically as we do here (with the difference that we train to maximize conditional rather than joint likeli-hood). A walk of length 3 following exactly one for-ward link (like L1 ), followed by one backward link (like L4 ), and another forward link gives exactly the same estimate as co-occurrence smoothing (Essen &amp; Stein-biss, 1992; Lee, 1999). A walk of length 2 using only one kind of similarity between head states, and forward links, is similar to distributional similarity smoothing (Lee, 1999).
 But the random walks framework that we propose is much more general. A multitude of link types can be defined in it, and they are automatically weighted by the learning algorithm. Paths of shorter and longer lengths can be followed (though the most highly con-tributing paths are the shorter ones). The general-ity of this approach to similarity-based smoothing not only gives a high performance prepositional phrase at-tachment system, but holds the promise of learning complex but effective random walk models in other domains.
 Acknowledgments. Our thanks to the anonymous reviewers for helpful comments and to Jenny Finkel for the optimization code. This work was supported in part by the ARDA AQUAINT program, and in part by the Department of the Interior/DARPA under con-tract number NBCHD030010.

