 Classifying nodes in networks is a task with a wide range of applications. It can be particularly useful in anomaly and fraud detection. Many resources are invested in the task of fraud detection due to the high cost of fraud, and being able to automatically detect potential fraud quickly and precisely allows human investigators to work more effi-ciently. Many data analytic schemes have been put into use; however, schemes that bolster link analysis prove promis-ing. This work builds upon the belief propagation algorithm for use in detecting collusion and other fraud schemes. We propose an algorithm called SNARE (Social Network Anal-ysis for Risk Evaluation). By allowing one to use domain knowledge as well as link knowledge, the method was very successful for pinpointing misstated accounts in our sampl e of general ledger data, with a significant improvement over the default heuristic in true positive rates, and a lift fact or of up to 6.5 (more than twice that of the default heuris-tic). We also apply SNARE to the task of graph labeling in general on publicly-available datasets. We show that with only some information about the nodes themselves in a net-work, we get surprisingly high accuracy of labels. Not only is SNARE applicable in a wide variety of domains, but it is also robust to the choice of parameters and highly scalable X  linearly with the number of edges in a graph.
 H.2.8 [ Information Systems ]: Database Applications X  Data Mining Algorithms, Security Anomaly Detection, Social Networks, Belief Propagation
Accounting irregularities, in which data are intentionall y or unintentionally misrepresented, raise significant risk for corporations and investors. Settlement amounts awarded in investor lawsuits have been increasing [10], and so has the number of financial restatements in recent years [27]. Audi-tors undertake a variety of procedures to determine whether there is reasonable assurance that financial statements are fairly stated, so automated assistance for detecting risks of misstatement has the potential for making the audit process more efficient.

Most of the well-known techniques for detecting account-ing irregularities, such as ratio analysis, operate at the fi -nancial statement level, a highly aggregated summary of a company X  X  financial activity, and generally offer little use ful guidance to an auditor beyond a broad indicator of risk at a company. We have been investigating analytics that operate at a much more detailed level, on the transactions recorded in a company X  X  general ledger. Past methods in this domain [2] explored the potential of different classification metho ds, such as logistic regression, expectation-maximization, a nd naive Bayes, on individual accounts and transactions. In this paper we show how exploiting the link structure be-tween accounts has the potential to greatly increase the ac-curacy of classification methods while making only a few assumptions. We will be applying belief propagation algo-rithms and link analysis to identify the risk of irregularit ies in corporate accounting.

Furthermore, we will show that this method is highly flex-ible to other tasks. Different domains will have different sources of knowledge about nodes in a network; however, our method allows a simple setting for domain experts to input this information without an understanding of the de-tails of the algorithm.

Our contributions are the following: We introduce SNARE (Social Network Analysis for Risk Evaluation), which de-tects related entities that may be overlooked by using in-dividual risk scores, it extends a well-known algorithm for graphical models into a useful application, and it may be flexibly applied to different domains. We show how it can be applied to the detection of fraud risk in general ledger accounting data as well as typical graph-labeling tasks in other domains such as web data and social networks.
Social networks have become more important as practi-tioners become increasingly aware of the significance of rel a-tions between entities in a network. It has been demon-strated that knowledge of social structure can allow one to help make inferences about an organization [3, 21], to identify individuals [17], or to predict adopters of consum er products [18]. Related work has used knowledge of social structures for detecting securities fraud [23]. The author s later improved the approach by showing that one can often infer links that are not explicitly stated [13], and success fully extended the methods using inferred knowledge [11].
Semi-supervised learning methods may also be useful for graph labeling, as addressed in [30]. Finding authority of a node is one specific labeling task addressed in the literatur e. One way of defining the authority of a node in a network is its  X  X eputation for knowledge, X  that is, how reliable the source is. Guha et al. extends many of these ideas for rep-utation networks applied to eBay or Epinions [16] X  rather than simply trusting someone X  X  knowledge of a topic, one may also trust another X  X  reliability as a seller on eBay or a recommender on Epinions. The authors use matrix methods and model a  X  X eb of trust X , where both trust and distrust are propagated over edges (with different patterns of propa-gation). They were able to predict trust between individual s given a small amount of labeled data.

HITS[20] and Pagerank[24] address reputation for web-pages. Other methods of propagation of trust and distrust are discussed in Ziegler et al. [31], particularly in relati on to trust on the semantic web.

Other work identifies particular anomalous patterns and seeks to spot them in large graphs. Pandit et al. intro-duce NETPROBE , which uses belief propagation to model eBay as a tripartite network of  X  X raudsters X ,  X  X onest users  X , and  X  X ccomplices X . Upon deciding on this model, they then use loopy belief propagation to assign probabilities of eac h node being in the three states [25], by detecting bipartite cores. (Our work differs in that we do not identify a specific network structure such as a bipartite core, only that one can propagate labels using homophily. This allows for more flexibility to different domains.)
Many risk detection methods approach the problem by attempting to detect suspicious behavior in users. This ap-proach has been successful for cellular phone fraud, where a caller X  X  patterns are often disrupted by periods of inacti v-ity. Here, most fraud schemes follow certain signatures, su ch that a rule-based system have lead to some successes [12]. Rule-based approaches have also been applied to the detec-tion of money laundering[7]. A survey of related methods can be found in [6].

The literature contains many methods for detecting ac-counting irregularities which typically use a model-based ap-proach [4, 5, 6, 9, 15]. However, many of these traditional approaches are limited by factors such as the diversity of fraud schemes, errors present in the training data, and ac-cess only to aggregated financial statement data instead of detailed transactions. To counter thihis problem, in pre-vious work, authors set up a system called Sherlock 1 for detecting errors and fraudulent behavior in general ledger data [2]. Sherlock used classification methods for identify -ing suspicious accounts, by evaluating a set of features mea -suring different types of unusual activity. Methods such as naive Bayes, expectation-maximization, and logistic regr es-sion were used and compared. This work will approach the same problem of identifying accounts with high fraud risk from a social network analytic perspective.

This is the first work, to our knowledge, that has adapted generalized belief propagation to the accounting domain, and provided a framework to extend it into other domains for node labeling, incorporating both node and edge infor-mation. In this work, we are using data where all true labels are unknown from the start, and our results are verified by human investigation. We will address the following problem:
Given: Output: A mapping V  X  X from nodes to class labels.
The labels X are binary categorical variables derived from the context (normal or irregular, conservative or liberal, etc.). We also note that while nodes and links can be re-lated to social entities such as persons and relations or ac-tions, the proposed methods can be applied to any sort of entities, such as accounts or webpages.

The basic premise of SNARE is to use neighboring labels to classify a given node. This premise has proven effective for many graph labeling tasks [19]. However, we also take into account domain knowledge, by assigning an initial risk scores to nodes prior to evaluating neighborhood associa-tions between them. To measure risk by association, we then use belief propagation for passing risk to connected nodes. A detailed tutorial of belief propagation may be found in work by Yedidia [29].

Let us summarize the procedure. In a network for a given task, the true label for each node v i is unknown. We are, however, given some local observations about the node, which we use as a local estimation of its risk, or node poten-tial  X  i ( x c ) of v i for class x c (the procedure for determining this will be described shortly). Information about this nod e is inferred from the surrounding nodes. This is obtained
Sherlock is research in progress. As such, the methods we describe should not be interpreted as descriptive of PwC X  X  current standard practice in analyzing general ledger data . through iterative message passing to and from v i to each neighbor v j , where a message from v i to v j with its own assessment of v j  X  X  believed class is denoted by m ij . At the end of the procedure, the belief of a node v i belonging to in class x c is determined. The belief is an estimated prob-ability, which can be thresholded into the classes (e.g. a b ( x c ) &gt; . 5 implies v i belongs to class x c ), or used relatively to compare risk scores between nodes (e.g. b i ( x c ) &gt; b implies v i is more likely to belong to x c than v j ). In more detail, messages are obtained the following way. Each edge e ij has associated messages m ij ( x c ) and m for each possible class. m ij ( x c ) is a message that v to v j about v j believed likelihood of belonging to x c . Iter-atively, messages are updated using the sum-product algo-rithm. Each outgoing message from a node to a neighbor is updated according to incoming messages from the node X  X  other neighbors. Formally, the message-update equation is as follows: where N ( v i ) is the set of neighboring nodes to v i .  X  is the edge potential of an edge between two nodes i,j of classes x c and x d .  X  ij ( x c ,x d ) is generally large if edges be-tween x c and x d occur often, and small if not. Order of message-passing does not matter, provided all messages are passed in each iteration. We also normalize m ij ( x c ) to avoid numerical underflow, as discussed in [8], so each edge X  X  mes-sage vector sums to one: P c m ij ( x c ) = 1.

Convergence occurs when the maximum change between any message between time ticks is less than some value (in our experiments 10  X  6 ). Convergence is not guaranteed in general graphs (only for trees), but typically occurs in pra c-tice. Upon convergence, belief scores are determined by the following equation: where k is a normalizing constant (beliefs for each class must sum to 1).

Adapting the message passing algorithm to our purposes has the following challenge: Find an effective yet intuitive way to choose node and edge potentials. We use two main concepts, homophily over edges and node attributes to influ-ence probability of different classes.

For purposes of explanation, we will have two classes, x R for  X  X isky X  and x NR for  X  X on-risky X . We will subsequently refer to b i ( x R ) is the end probability of a node being risky after completion of the algorithm. A node with b i ( x R ) = 1 is certainly suspect, and b i ( x R ) = 0 is not suspect; most nodes will fall somewhere in between, on the continuum. SNARE will then produce a ranked list of the X  X isky X  X odes, as candidates for further investigation.

For the edge potential term  X  ij ( x c ,x d ) in the message-passing equations, we chose an identity function with a nois e parameter  X  . That is, if v i is risky, v j has a high probabil-ity of being risky, while allowing for some variance. The transition matrix is shown formally in Table 1.

Before beginning the message passing procedure, how-ever, we must also assign a node potential to each individ-ual node. The node potential represents the risk of a node Table 1: Transition matrix, or edge potentials for belief propagation. without considering information from its neighbors. The initial node potential depends on the assumed distribution of class labels X  when classes are evenly divided, default va l-ues (  X  ( x NR ) , X  ( x R )) = (0 . 5 , 0 . 5) may be appropriate, while in cases where risk is sparse (as in most anomaly-detection domains) more skewed values such as (  X  ( x NR ) , X  ( x R (0 . 9 , 0 . 1) may be more reasonable.

However, a key component of SNARE is that the initial node potential is determined for each individual node by an process that can incorporate prior knowledge into the algo-rithm, for example in form of domain knowledge. In most domains where fraud is a challenge, there is rich informatio n available about the potential fraudsters, such as geograph ic location, patterns of activity, or other flags for suspiciou s behavior. Therefore, we adjust node potential by assessing the risk to each individual node. There are many ways of do-ing this; the most useful for our purposes is the use of flags . A node may be flagged for having several different types of suspicious behavior, and the domain expert may assign dif-ferent severity to these flags. Where applicable we chose to use additive risk, increasing with a sigmoid function: where f i is the total flagged risk, summed for all potential causes for suspicion. The node potential for node i , then, is  X  ( R ) = F i and  X  i ( NR ) = 1  X  F i . 2
When a node is highly flagged it also sends a stronger risk signal to its neighbors. However, if a flagged node X  X  neighbors all have a low initial probability of being risky, the flagged node will be dampened. This is a reasonable action, since isolated flags are more likely to occur in error .
One key advantage of SNARE is that it will find risky associated nodes. Fraud schemes as they occur in accounting often involve many accounts, which often allow fraudsters t o hide their actions. Since each account may have a very small risk score associated with it, traditional methods may not pinpoint the accounts as abnormal. However, SNARE will use the fact that the accounts interact with each other, and raise the associated risk of each account, allowing experts to more easily find the fraudulent behavior.

Since the flags are determined by the domain expert, this procedure can be successful on a wide variety of node label-ing tasks, as we will show in the next section.
We developed SNARE to help detect risks in accounting data, so we will primarily evaluate it on its ability to find misstated accounts in a company X  X  general ledger. 3 How-ever, since our G/L data is proprietary, and because we
It may be possible to learn the appropriate flag increments through machine learning techniques; this is left for futur e work.
Some of the terminology we use here is for the purpose of believe SNARE is more generally useful, we also evaluate its performance for graph labeling using public data from social media and political campaigns. A description of the data and the problems addressed may be found in Table 2.
The general ledger (G/L) of a company is an accounting record that summarizes its financial activity with double-entry bookkeeping. Within every G/L is a set of accounts which can be thought of as variables representing the allo-cation of monetary resources. Business events, such as the purchase of machinery, would result in a transaction that reduces the value of the the cash account but increases the value in the fixed asset account by an equivalent amount. The G/L is used to prepare the financial statements by ag-gregating the balances of the accounts and thus auditors are extremely interested in finding misstatements in this data.
Manipulation of records can be found by experts on both the G/L and financial statement level. There are many dif-ferent fraud schemes [14, 28] for which experts have iden-tified  X  X ed flags X  that indicate suspicious behavior based on domain knowledge [9, 14, 22, 26]. For example, one fraud scheme is known as channel stuffing . In order to meet earn-ings expectation, fictitious sales are recorded to increase the revenue for the current quarter. These sales are typically n ot complete and are recorded solely to meet the earnings target . The company overloads their distribution channels to make it appear as if additional sales have been completed. This helps the company appear to meet its target. Such channel stuffing is usually followed by an increase in the number of returns at the beginning of the next quarter. In the gen-eral ledger, one could record the return of a sale by debiting revenue and crediting accounts receivable; thus to look for channel stuffing one might create a threshold test or red flag that highlights an account when there are an excessive number of these transactions.

In practice however, the creation of such a flag to detect channel stuffing or other schemes is fraught with difficulty and pitfalls. For instance with our example of channel stuff-ing one would need to determine what is an excessive amount of returns since some will always occur for normal business reasons. Setting the threshold too high could result in miss -ing potential frauds, but setting the threshold too low coul d result in too many false positives. Furthermore, people who intentionally manipulate the G/L are often well aware of the red flags used by auditors and actively attempt to avoid de-tection. Thus, for example, they may try to hide the activity by spreading the returns over many accounts so as to not set off any thresholds. Our hope with SNARE is that we could set the thresholds relatively low so as to be more sensitive t o risky activity and use belief propagation to aggregate risk in the network to identify misstated accounts with a low false positive rate.

To analyze general ledger data with SNARE we first need to create a network with nodes, edges, and initial risks. For our application, we construct the network as follows: conducting research in the area of accounting and is by ne-cessity highly simplified and abbreviated. It not descripti ve of how PricewaterhouseCoopers analyzes general ledgers.
For example, Figure 1 shows a partial network with nodes for accounts receivable, accounts payable, bad debt, non-trade A/R, and several revenue accounts. In our example of channel stuffing, thresholds for our red flags could be set low enough to flag multiple revenue accounts and SNARE would then propagate the risk to accounts receivable where the collected belief would be strong enough to implicate it. In the next two sections, we present results of SNARE on general ledgers with known misstatements and show that on real data it is effective at aggregating risk across the netwo rk.
In the first set of G/L data there were a total of 1 , 380 accounts, 3 , 820 edges, and 11 , 532 red flags (nearly every node had at least one flag). From prior domain knowledge, 26 accounts were identified as being misstated. We applied SNARE to this network and the message-passing process converged after 6 iterations. Our initial node potentials w ere  X  ( Risky ) = 0 . 1 and  X  i ( NotRisky ) = 0 . 9 for a node i with no flags, and additional flags changed node potential accord-ing to Equation 3, so key information is in the nodes X  number of flags relative to each other.

Figure 2 shows the ROC curve for the SNARE approach under the assumption that the 26 identified accounts was the complete set of true positives (and all other accounts are true negatives). In addition to SNARE , we plotted to ROC curve for a default approach based on simply rank-ing the accounts by the number of tests flagged. From the graph, we note that SNARE dominated the default sum approach over all regions of the ROC curve. Furthermore, SNARE produced an extremely steep initial curve at low false positive rates. This is very promising as this is the region of the operating space most interesting from an ap-plication viewpoint.
The second set of G/L data contained 1 , 678 nodes, 18 , 720 edges, and 11 , 401 red flags. Unfortunately, with this data set we had only coarse label information available that iden -tified general groups of misstated accounts. For our experi-ments we treated all accounts in an identified group as being misstated, resulting in a total of 337 positive labels.
The results for GL2 are shown in Figure 3. The results are not as strong as for the previous G/L, but this may be due to the noisy class labels. However, there is still sig-nificant improvement in the ROC curve compared with the default strategy of using the number of flags as a scoring mechanism.

Relevant non-proprietary risk-related data with a network structure is challenging to collect and institutions are re luc-tant to share data due to privacy concerns. Therefore, we will next show the use of SNARE for labeling nodes in using publicly available social network data. Data Problem description Size (Nodes, Edges) Classes Flags
GL1 Identifying misstated
GL2 Identifying misstated
PoliticalBlogs Labeling political affilia-
Campaigns Correctly classifying polit-shows performance for false positive rates of less than 0.1. shows performance for false positive rates of less than 0.1.
The domain of social media presents the difficult task of automatically assessing political stance of a blog, news si te, or other webpage. Doing so often requires analysis of senti-ment in the text, which is both difficult and computationally expensive. Being able to do so by using the structure of the induced web graph can aid in this problem.

To this end, we tested SNARE on a network of polit-ical blogs, human-labeled as Conservative or Liberal. The data contained 758 Liberal blogs and 732 Conservative blogs , which were joined with edges based on hyperlinks made by the blog owners. (For details of building the network and labeling, see [1].) Of these, 1 , 224 had degree greater than 0 X  558 Liberal and 636 Conservative, which we chose to focus on for our experiments. The network was relatively dense, with 16 , 718 total edges.

In this case, node information was noisy. We chose to flag nodes as more likely to be Conservative/Liberal based on substrings in the blog title. We chose the following flags, an d indicate each substring X  X  prevalence in blogs human-label ed as Conservative and Liberal. 4 Of the connected nodes, 171 had flags. Some blogs had multiple flags, so we used additive risk score.

Since the number of Conservative and Liberal blogs was expected to be approximately equal, we used a default po-
Crawling the blogs themselves and using textual analysis would have potentially provided more accurate flags; how-ever, we chose the more naive flag for experimental purposes, showing that even imperfect node information provides good results. nodes (1 , 188 of 1 , 247) were classified correctly. An addi-tional 233 nodes ended with a belief score b con = 0 . 5, which we did not consider to be classified one way or the other (though most of them were Liberal). Most of these were isolated nodes; fewer than 20 had a degree greater than 0. For isolated nodes we simply classified them based on the flag, which was 0 in most nodes.

SNARE presented improvements over using the flag method alone or through clustering based on structure. Of-ten times the flag was misleading, such as in the case of laughatliberals.com or johnkerrymustlose.com , but the edge effects usually allowed SNARE to correct the classi-fication, without needing to do sentiment analysis on the words. On the other hand, there were occasions where a few blogs of one class formed a sort of  X  X ppendage X  on the main cluster of the opposite class, which typical graph clustering methods would fail to identify but were success-fully labeled using SNARE . One example of this is the two blogs enemykombatant.blogspot.com and democratvoice. org . The former blog was connected to the Conservative cluster, but the flag on the latter blog, its neighbor, propa-gated into it, correctly labeling both blogs as Liberal. Thi s is shown in Figure 4.

In fact, most misclassifications occurred on cases of un-flagged blogs of one class only bordering on blogs of the opposite class, and in cases along the middle between the two clusters. These cases would be difficult to classify using node information or edge information alone.
While labeling political party membership for individuals running for office is not typically a challenge, we used it as a way to test our approach to labeling nodes by leveraging connection structure.

We took subsets of data from the United States Fed-eral Election Commission 5 from the election cycles of 1980 through 2006, that listed donations from political action committees to political candidates for President, Senate, and House of Representatives. We then built a bipartite net-work of committees and candidates, creating edges between www.fec.gov/finance/disclosure/ftpdet.shtml , downloadable in parsed format from www.cs.cmu.edu/ ~mmcgloho/data.html Figure 4: The political blog network, where human-labeled conservative blogs are shown in gray and lib-eral blogs shown in black. Flagged nodes (in either class) are shown as squares. This section highlights two outlier Liberal blogs connected to the cluster of Conservative blogs. Since democratvoice was flagged as Liberal, these two blogs were correctly classified with SNARE . a committee and a candidate if a committee had, at some point, donated funds to the candidate. The largest cycle, 2004, contained 1 , 357 nodes with positive degree (686 can-didates and 671 committees) and 11 , 334 edges. The classi-fication task was to label a candidate as Democrat or Re-publican, based only on the committees it was connected to through donations.
 Of the 671 committees, 583 were labeled with a party. We used these labels as flags (+1 or -1). From there, we ran SNARE on the bipartite graph to propagate labels to candi-dates. SNARE correctly labeled 659, mislabeled 12, and did not label 25, which gave an accuracy of 96 percent. With one exception (the earliest cycle, 1980, with an accuracy of 82%), all other cycles had above 90 percent accuracy. 6
We find that varying parameters does not drastically affect accuracy, and the method is scalable to large graphs, as we will explain in the next section.
We next demonstrate the robustness of SNARE to differ-ent parameter ranges, analyze its computational efficiency, and compare the accuracy to to spectral clustering on the task of graph labeling.
SNARE is very robust and easy to use. Some domain knowledge is necessary for determining the node potential for both flagged and unflagged nodes. Default node poten-tial is typically set at the expected percentage from each class (for example, { 0.9, 0.1 } if one expects 90% of nodes in class 0 and 10% in class 1). Modifications of the sigmoid function tend to work well for additive risk for flagged nodes .
The edge potential parameter  X  may be set in the range of 0 &lt;  X  &lt; . 5 without drastically affecting results. In Cam-
In fact, using very sparse flags (randomly selecting 10 com-mittees from each class to flag) produced comparable results . Accuracy Figure 5: A demonstration of the robustness of SNARE , by varying the  X  for PoliticalBlogs data, between 0 and 0.1. Note that even the smallest  X  is effective. Accuracy results are similar for  X  up to 0 . 5 (omitted to avoid redundancy). paigns , we observed high sensitivity on the node potentials, and putting any bias on class tended to cause one class to dominate. This would seem natural, since the data were approximately split equally among the two classes, so any initial bias will dominate the final result. However, the  X  pa-rameter showed little sensitivity, and varying it between 0 and 0.5 affected results by less than 1 percent on both Cam-paigns and PoliticalBlogs . (Setting  X   X  . 5 would remove the homophily assumption, which would not be useful for tasks addressed here.) Figure 5 shows finer-grained results of varying parameters on blog data; even the smallest  X  is effective, and accuracy does not change up to  X  = 0 . 5.
The most costly operation of SNARE occurs during the message-passing. Each iteration runs in O ( | E | ) time, where | E | is the number of edges in the network. Our experiments also reached convergence in relatively few iterations (les s than 10 for all datasets). Other negligible computational costs are in assessing node potentials and calculating beli efs (both O ( N )), and in all cases convergence occurred within 10 message-passing iterations.

Since the data varied in structure, we chose to run scaling experiments only on Campaigns . To sample, we took differ-ent window-sizes of election cycles, for every possible cyc le, and timed the completion of SNARE 100 times apiece. A plot of average time vs. number of edges in the graph is shown in Figure 6, including the best linear fit.
To compare our performance to the state of the art, we also run spectral clustering on our data, which is an un-supervised method for node labeling. For Campaigns and PoliticalBlogs the data were already well-clustered, and vi-sual analysis could cluster reasonably successfully. Spec tral clustering, however, performed less well than SNARE even on these data sets.
 On PoliticalBlogs , attempting to find two clusters failed. However, clustering results were better by allowing for a third cluster that did not fit with the other two. The two
Time (s) Figure 6: Scalability results for Campaigns data. SNARE scales linearly, with a 50,000 edge graph converging in under 3.5 seconds. major clusters roughly corresponded to the conservative an d liberal sectors. In full, of 1224 non-isolated blogs, 1133 w ere correctly classified. There were 83 misclassifications, and 8 in the third  X  X ndecided X  cluster. This gave an accuracy of 92.5%, slightly less than SNARE .

On Campaigns , results were similar. There were two dis-tinct clusters roughly corresponding to the parties. There were 617 correct classifications, 19 incorrect, and 60 uncla s-sified, for 88.5% accuracy.

However, for data sets such as the general ledger data where the nodes do not form very clear clusters, spectral clustering does not perform well. In this type of data SNARE has a distinct advantage.
We successfully applied link analysis to the domain of risk detection for accounting data and produced results that wer e a significant improvement over a the method that flags sus-picious accounts. Formerly, an automated system simply flagged entities that appeared risky, with some sense of pri-ority. Using link analytic methods, one can rerank the risk of an account not only based on irregularities in a single ac-count, but also in other accounts with which it shares trans-actions. Also, a group of accounts that are closely related and have distributed risk may be identified while under in-dividual flags they would fall below the threshold. In many other domains there may be a cluster of related entities (for example, collaborators in a social network), where the col-lection of evidence from each party may put the collective risk above the threshold.

We also show that SNARE is successful for the task of node labeling in networks in general. Since risky nodes may be relatively sparse in a graph it may be more use-ful in anomaly detection to use an initially low probability for risky nodes; however, by adjusting initial belief score s one can use SNARE on tasks where labels are more evenly divided between two classes. SNARE also has the capabil-ity of considering prior node-specific domain knowledge for flags X  while we used accounting-specific flags in GL1 and GL2 , we chose text flags in PoliticalBlogs and committee information in Campaigns .

The SNARE system is simple to implement and ex-tend to other domains, and may be particularly useful for other types of fraud detection that ordinary graph cluster-ing methods may have difficulty with, such as link farms or botnets in the web graph, or fraud in mobile phone networks.
In summary, our contributions are the following: The authors would like to thank Polo Chau for his help-ful consultation. This work was conducted in collaboration with the PricewaterhouseCoopers X  Center for Advanced Re-search (CAR), directed by Sheldon Laube and Glenn Ri-cart. In addition to their support and feedback, we would like to acknowledge the assistance of our colleagues within the Center for Advanced Research working on the Sherlock system: Jeff DeLisio, Mave Houston, Li Chen, Rohit Kumar and Kamaljeet Kaur. This material is based upon work sup-ported by the National Science Foundation (NSF), Grants No. IIS-0705359, IIS-0808661, and CNS-0721736. This work is also partially supported by an IBM Faculty Award, a Ya-hoo Research Alliance Gift, a SPRINT gift, with additional funding from Intel, NTT and Hewlett-Packard. Mary Mc-Glohon was partially supported by a Yahoo! Key Technical Challenges Grant. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF or other funding parties. [1] L. Adamic and N. Glance. The political blogosphere [2] S. Bay, K. Kumaraswamy, M. G. Anderle, R. Kumar, [3] R. Behrman and K. Carley. Modeling the structure [4] T. Bell and J. Carcello. A decision aid of assessing the [5] M. Beneish. The detection of earnings manipulation. [6] R. Bolton and D. Hand. Statistical fraud detection: A [7] R. J. Bolton and D. J. Hand. Unsupervised profiling [8] T. Cohn. Scaling Conditional Random Fields for [9] P. M. Dechow, W. Ge, C. R. Larson, and R. G. Sloan. [10] D. Dooley and G. Lamont. PwC 2005 securities [11] A. Fast, L. Friedland, M. Maier, B. Taylor, D. Jensen, [12] T. Fawcett and F. J. Provost. Adaptive fraud [13] L. Friedland and D. Jensen. Finding tribes: [14] W. Golden, S. Skalak, and M. Clayton. A Guide to [15] H. Grove and T. Cook. A statistical analysis of [16] R. Guha, R. Kumar, P. Raghavan, and A. Tomkins. [17] S. Hill and F. Provost. The myth of the double-blind [18] S. Hill, F. Provost, and C. Volinsky. Network-based [19] D. Jensen, J. Neville, and B. Gallagher. Why [20] J. M. Kleinberg. Authoritative sources in a [21] S. A. Macskassy and F. Provost. Suspicion scoring [22] C. W. Mulford and E. E. Comiskey. The Financial [23] J. Neville,  X  O.  X Sim  X sek, D. Jensen, J. Komoroske, [24] L. Page, S. Brin, R. Motwani, and T. Winograd. The [25] S. Pandit, D. H. Chau, S. Wang, and C. Faloutsos. [26] H. Schilit. Financial Shenanigans: How to Detect [27] S. Skalak and C. Nestler. Global economic crime [28] J. Wells. Corporate Fraud Handbook: Prevention and [29] J. S. Yedidia, W. T. Freeman, and Y. Weiss.
 [30] X. Zhu. Semi-supervised learning with graphs . PhD [31] C. N. Ziegler and G. Lausen. Propagation models for
