 In civil court proceedings, judges need to read the documents submitted for a litigation case by litigants to settle the points in dispute by finding facts and relevant information. These documents, called plaint and defend, lodged by the litigants, referring to plaintiff and defendant respectively are approximately 20  X  45 pages long. plaintiff and defendant do not agree and take action. There are approximately 13,000 recent advancements in computing resources and data mining techniques, it is feasible to automate some of these tasks for judges. However, the first step is computationally processing Thai documents. 
The computational processing of Thai written language is different and more complicated than the English language. Thai text does not have word boundaries and there is no delimiter to separate two sentences. The spaces found in documents are for making the readers comfortable with reading the passages rather than separating segmentation methods use a dictionary to segment the texts [1, 5, 9]. If the dictionary does not contain the matching word, it leads to error. There is some research that uses general rules about the interested information [12]. Similarly, the work of [9] used the decision tree to extract Thai words from a number of Thai corpora to build a corpus-based Thai dictionary. However, no grammar rules were used. 
To increase the accuracy of the dictionary-based methods, there must be a ambiguous words formed by combining possible syllables. There are some cannot generate the output either. 
This paper proposes a novel method of Thai word segmentation by combining a probability-based model using the six-state left-right Hidden Markov model (HMM) with the dictionary-based model using the decision tree. The HMM model is used to extract possible words combining several possibilities of syllables. If the probability-based model is used alone, the quality of the word segmentation heavily relies on the quality and quantity of the training data set. After words are formed as the output of HMM, the TCL X  X  lexicon dictionary [11] is used to verify those words. The identified formulated from HMM cannot be identified by the dictionary, it is sent as a group of that exist in the lexicon dictionary as a training set. 
In this paper, we study the use of the combination of two different word segmentation techniques. We compared the results obtained by the proposed method lexicon dictionary only. The proposed method significantly outperforms all other methods. The results show improvement in precision and recall for Thai language processing when applying the proposed method to a real-world data set. word segmentation together. Thai characters are members of the Brahmic family of characters descended and modified from Brahmi [13]. The Thai written language does not use the conjunct writing [13]. This makes Thai language processing more difficult [1, 9, 10, 12]. 
There are 44 consonants and 32 vowel forms which can be written in front of, on tonal marks and special characters are used to form a Thai word. The smallest unit of without vowel(s). There is no space to separate among words or even sentences. Figure 1 shows an example of Thai text containing three paragraphs, four sentences, 211 words, and 282 syllables. 
Information processing of documents in Thai language is considered more difficult way to determine where a syllable starts and ends; (2) once a symbol is recognised as a syllable, the problem becomes apparent as to where a word starts and ends; (3) the their context; (4) what words make a senten ce due to the absence of word boundary in a sentence; and (5) what sentences form a paragraph. The proposed method of Thai word segmentation, as depicted in Figure 2, combines is, dictionary based) modeling. The integration of these two techniques allows standard language rules. The process is then followed by word segmentation in Phase 2. The initial word segmentation phase uses the HMM based non-dictionary word segmentation technique. When the first set of identified words are extracted using the HMM, the dictionary-based word segmentati on technique with the lexical dictionary [11] is used in revising and combining the possible list of words before identifying the tree to turn into a tagged word. The process uses the standard Thai syllable formation rules to extract possible pattern of the syllables. The intermediate result may have some ambiguous syllables. Due to this, the segmented syllables are then combined and formulated for the possible words using the Hidden Markov model in the next phase. strings existing in a document. The syllable rules include fifteen (15) Thai consonant combinations of 44 consonants, 21 vowels, and four different tonal marks. It can also The Thai syllable structure is shown in the equation (1): 
The above formula stands true for every syllable formation. For example, a string  X  next consonant  X   X   X  X s detected in the next position of string, the next possible syllable is started. The second syllable consists of Ci= X   X   X , Vc= X   X   X , and Cf= X   X   X . language is unambiguous and can be defined by a set of fifteen (15) Thai consonant that are implemented to process a string:  X 
The initial vowel must not be in the last position of a syllable.  X 
The initial compound consonant must not be in the last position of a syllable.  X 
A final vowel and the previous character have to be grouped into a same unit.  X 
A Final vowel must be in the last position of a syllable.  X 
A Garun (a particular vowel) must not be in the initial vowel position.  X 
An Upper vowel must not be in the initial vowel.  X 
An Upper vowel must not be in the final vowel.  X 
A Lower vowel must not be in the initial vowel.  X 
A Lower vowel must not be in the final vowel.  X 
There must be only one Tonal mark in a syllable. 3.2 Phase 2: Word Segmentation The previous phase merges and groups the characters in the input string into syllables. Once the syllables are extracted, the next task is to identify combinations and form the possible words. 3.2.1 Word Segmentation Using HMM The theory of a Hidden Markov Model (HMM) was derived from the Markov chains observable (i.e. it is hidden). Given a sequence of observation symbols, the HMM will be able to predict the probability of the sequence based on previous observations used decide which one is better. In terms of applying HMM to the Thai word segmentation problem, if each state corresponds to a character position and the character values are the observation symbols, the HMM will be able to tell the best sequence of characters among a number of sequences given to the model. 
In this paper, a left-right Hidden Markov model of six states is developed for Thai dictionary developed by the Thai Computational Linguistics Laboratory [11]. In from left to right [5]. In this model, a one-syllable word is discovered when the loop transition is from state 4 to state 1. A one-syllable word will pass only state 1, while a two-syllable word passes states 1 and 6. A three-syllable word passes states 1, 5, and 6, whereas, a four-syllable word passes states 1, 2, 5, and 6. A five-syllable long word passes states 1, 2, 3, 5, and 6, while, a six-syllable word passes states 1, 2, 3, 4, 5, 6. In order to determine the most suitable words in the document, a Hidden Markov Model can be represented by equation 2: distribution in the vector of i column, which indicates how likely the whole sequence of the trials start from state i . 
With the model in Figure 3, the transition probability for the corresponding HMM model can be formulated as matrix A . This matrix shows the possibility of each word when in transit from one state to another state. Each word will pass a different group of states. The value will be calculated according to matrix A , B , and  X  . of words within one syllable, with more than three syllables, with three syllables, with two syllables, with more than four syllables, with four syllables, with more than five syllables respectively over the number of words in the training data set.

For initial state distribution  X  , every word must start from state 1. Therefore, will be divided by the number of times the specific state is passed through [8]. words with its part-of-speech. 3.2.2 Dictionary-Based Word Segmentation Using Decision Tree part-of-speech to each word. If a word is no t identified by the lexi con, it is processed by the decision tree. The decision tree is trained with various information that a word decision tree include the following in formation gathered from each word: 1 Left Mutual information and Right Mutual Information the attributes in the tree. The mutual information on the left and the right [9] will be calculated as followed in equations (3) and (4): where Lm is the left mutual information of the noticing string 
Rm is the right mutual information of the noticing string x is the leftmost syllable of xyz y is the middle syllable of xyz z is the rightmost syllable of xyz p( ) is the probability of the occurrence 2 Length of word The number of syllables to form a word is c ounted as an attribute in the decision tree. The possible lengths of common Thai words are between one to six syllables. 3 Functional words In the Thai language, there are many functional words such as  X  X hen X  and  X  X ill X . The eliminate these functional words from the string pattern. lexicon dictionary. The C4.5 learning algor ithm [7] is used to train the decision tree with this data set. The unidentified words from the previous phase are tested with this trained decision tree using the patterns of combining syllables that exist in the words of training data. The proposed method starts by applying the Thai language grammar rules to identify the dictionary are checked in the decision tree for identification as suitable words. Data Set : There are two sets of input data used in the experiment. The first set of data is the legal documents that need to be processed for word segmentation. These legal documents are collected from the archive centre of the Court of Justice, Thailand [4]. defend document. Each case also contains about 5  X  10 pages of judgment verdict. 
The second set of data is the TCL X  X  Thai lexicon dictionary [11]. As stated earlier, there are 30000 unique words in the lexicon. The lexicon dictionary is used to verify and tag words from HMM. It is also used for training the decision tree. criteria in experiments. Precision is the ratio of words retrieved compared to all of the harmonic mean of precision and recall. 10-fold CV experiments are used throughout the experiments and the average performance is reported along with standard deviation. 4.1 Empirical Analysis and Discussion HMM and by lexicon only. 
Five (5) sets of comparative experiments are conducted to evaluate the proposed method. They are as follows:  X 
The six-state left-right HMM in the proposed method is replaced with the three-state left-right HMM to check whether the six-state left-right HMM is suitable for Thai processing. Results of the three-stat e left-right HMM are integrated with the 
Lexicon and C 4.5 decision tree as described in our method.  X 
The six-state left-right HMM is used alone for the word segmentation problem. It quality of word segmentation. The output words produced from the HMM become the final word set.  X 
The three-state left-right HMM is also used alone for the word segmentation enhance the quality of word segmentation.  X  experiment is as follows. The Thai language grammar rules are used to identify the syllables, then syllables are segmented. The first combination a group of syllables form becomes the word for lexicon if this word exists. Even though this may not be the correct interpretation.  X 
The decision tree is used alone to identify the words. The process of this experiment is as follows. 
The training dataset from each fold of 270 legal documents consists of an average of 534330 words for HMM. The decision tree training dataset consists of 30,000 made of four (4) input attributes, namely Left mutual information, Right mutual information, length of words, and functional words, and one (1) binary output fold of 30 legal cases consists of an average of 57360 words. 
Table 1 shows the numbers of words and syllables found in the data set. This table also includes the number of words identified by the proposed method and other methods used for comparison. The numbers of words identified by the lexicon are the highest, 677846 for training dataset, and 62413 in test dataset. It can also be observed that the numbers of words identified by the lexicon are even more than the number of words in the documents (that are 534330 in training dataset and 57360 in test dataset). 
The reason is that when a group of syllables in a string is presented to the lexicon as a word. It ignores any other combination that may be formed as a word by adding more syllables next in the string. Consequently, most of the syllables in the input set matched with one-syllable words in the lexicon. It can also be observed from Table 2 that it has the least accuracy as a result. 
The number of words identified by the six-state left-right HMM only is the lowest good quality. There are approximately 20,000 words that HMM is unable to correctly tree model to further identify the words produced from HMM, the number is increased to 348623 for the training data set and 38862 for the test data set. 
Besides, the experiment results also reveal that numbers of identified words by decision tree (356173 in training and 39458 in test dataset) are more in quantity than when only using HMM. This is because the DT is trained on the entire lexicon words. However, it can be seen that their accuracy is lower in comparison to our results. experiments. The precision, recall, F-Score values gained by our proposed method are the highest among other methods, whereas those of the lexicon dictionary only method give the lowest performance among other methods. This is because, when the syllables are compared with the lexicon, most syllables were matched with one-syllable words in the dictionary. The improvement is 55.23% for precision value and 27.27% for recall value for the test data set. improvement is 15.62% for precision value and 12.49% for recall value when the outputs by HMM are combined with lexicon and DT. 
The experiment also reports that if we change the HMM from six-state to be three-state left-right HMM [6] without using the decision tree, the precision ratio is dropped HMM rather than using the three-state left-right HMM. When we combine the outputs 32.57%. It is, however, significantly lower than the proposed method. 
Considering elapsed times in experiments, the proposed method consumed the maximum time of 56.51 seconds on training and 55.16 seconds on testing whereas the HMM. The remaining time consumed are counted when unknown words from the HMM is parsed to the lexicon and the rest of unsegmented words parsed to the minimal since there is no intermediate result to pass to another process. 
It can be ascertained based on the result s reported in Table 1 and Table 2 that the proposed method produces the best results as it utilizes the strength of each individual the decision tree and the overall accuracy is enhanced. In this paper, we combine the techniques of probabilistic method word segmentation as overcoming the shortcomings of each individual technique. Most are different in detail When the first set of words is extracted, the dictionary-based word segmentation is used to help revise and combine the possible list of words before identifying the sentence. 
The proposed method is extensively evaluated against other methods. Results show that the proposed method significantly outperforms all other methods. The word segmentation accuracy (in terms of precision and recall ratio) can be further improved. the accuracy would have been increased. Secondly, the nature of the words in these data not be present in the dictionary. 
Future work includes experimentation with some more datasets and the construction tagged words to discover the relationships of particular paragraphs in the plaint and the defend. 
