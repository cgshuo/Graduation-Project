 associated with minimizing the objective function.
 little theoretical justification in the literature.
 both complete and partial changes of the data.
 covering number in the next section and noting that the resul ting class is VC-type. changes is a sharp transition between stability and instabi lity in these cases. on the sample Z K -means clustering, the quality of C on Z [10]) It is easy to verify that the (scaled) within-point scatter c an be rewritten as where c we will often abuse the notation by associating C with the set { c to its closest center c procedure. Rather, we study stability properties of the min imizers of W ( C ) . tion class Figure 1: The clustering objective is to place the centers c from points to their closest centers. where the functions are obtained by selecting all possible K centers. Functions h also be written as where ties are broken, for instance, in the order of a glued together with centers at a Moreover, if C minimizes the left-hand side, h Hence, we will interchangeably use C and h similarity between the centers { a measure the L choices are essentially equivalent. The following technical Lemma shows that a covering of the ba ll B in the L functions in H Lemma 3.1. For any  X  &gt; 0 , balls of radius  X  (see Lemma 2.5 in [12]). Let T = { t cover. Consider an arbitrary function h of the cover, there exists t Z X  B 2 (0 , R ) , We iterate through all the a and all centers of A H the L The above Lemma shows that H of functions h  X  X  starting point.
 Definition 4.1. For &gt; 0 define the set of almost-minimizers of the expected error.
 In the case of a unique minimum of E h , one can show that the diameter of Q  X   X  0 . 2 Lemma 3.1 implies that the class H uniform Glivenko-Cantelli. Hence, empirical averages of f unctions in H their expectations: Therefore, for any  X ,  X  &gt; 0 for n &gt; n Suppose h the knowledge of P . Then, with probability at least 1  X   X  , for n &gt; n by the optimality of h with probability at least 1  X   X  for n &gt; n Assuming the existence of a unique minimizer, i.e. diam By triangle inequality, we immediately obtain the followin g Proposition. Proposition 4.1. Let Z each other with increasing probability as the number of poin ts increases. If there are finite (but greater than one) number of minimizer s h  X  X  stability is expected for  X (  X  n ) changes, as the next example shows. Example 1. Consider 1 -mean minimization over Z = { x is clear that, given the training set Z x points on x as n , it is clear that by changing  X ( a finite Z .
 theorem for function classes.
 Z according to P . Then, if | S 4 T | = o (  X  n ) , it holds We apply the above theorem to H L that Z X  B would not necessarily hold.
 over the sets S and T , respectively. Suppose that | S 4 T | = o (  X  n ) . Then The above Corollary holds even if the number of minimizers h  X  X  H changes in the number of minimizers. Intuitively, stability of functions h define a notion of distance between centers of two clustering s. Definition 5.1. Suppose { a respectively. Define a distance between these clusterings a s away from 0, i.e. dP &gt; c d X  for some c &gt; 0 . Suppose Then where c Proof. First, we note that d max ( { a 1 , . . . , a K } , { b 1 , . . . , b K } )  X  2 max max b  X  ).
 Consider B to a 1 than to b 1 , we have Refer to Figure 2 for the pictorial representation of the proof. Note that b L that d cannot be large.
 Combining all the information, we obtain the following chai n of inequalities Since, by assumption, we obtain From the above lemma, we immediately obtain the following Pr oposition. | S 4 T | = o ( function of the data by applying Theorem 4.1. H of finding theoretically grounded recipes for choosing the num ber of clusters. References
