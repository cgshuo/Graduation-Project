 Can we spot patterns in fake retweeting behavior? When a large number of Twitter users re-broadcast a given post, should we attribute this burst of activ-ity to organic, genuine expression of interest or rather to a fraudulent, paid contract? Twitter is arguably the most popular micro-blogging site and one of the first sites forbidden by authoritarian regimes. High-quality tweets are re-broadcasted ( retweet ed) by many users, indicating that their authors are influen-tial. Since such influence can be monetized via per-click advertisements, Twitter hosts many fraudsters trying to falsely create the impression of popularity by artificially generating a high volume of retweets for their posts. In our work, we observe a thriving ecosystem of spammers, content advertisers, users paying for content promotion, bots disguised as regular users promoting content and humans retweeting for various incentives. Such content is at best vacuous, but often spammy or malicious and detracts from Twitter content X  X  credibility and honest users X  experiences.
 Despite previous efforts on Twitter fraudsters X  activity [ 8 , 17 , 18 ], the differ-ent manifestations of fake retweets have not been adequately studied. Previ-ous approaches focus mainly on specific URL broadcasting, instead of retweet threads, and rely on temporal and textual features to identify bots [ 5 , 11 ]. Fraud-sters on Twitter, though, constantly evolve and adopt advanced techniques to obscure their activities. The identification of patterns associated with  X  X ake X  retweet activity is, thus, crucial for spotting retweet threads and their authors as fraudulent. This work X  X  primary goal is to distinguish organic from fake retweet activity and the informal problem definition we address is Informal Problem 1 ( Retweet-thread level ) .

Given : the connectivity network (who-follows-whom); the i Find : features of the retweet activity To determine whether the activity is organic or not.
 nectivity and temporal behavior of retweeters that will allow the classification of the motive behind retweet threads as driven by users X  genuine reactions to tweeted content, or resulting from a paid contract. We also aim at spotting users who are suspicious of long-term spam activity, but manage to evade suspension from Twitter by using camouflage . The contributions of this work are the following:  X  Patterns: Our proposed approach, RTScope , identifies multiple patterns  X  Generator: Based on our analysis, we provide RTGen , a data generator  X  Reproducibility: We share an (anonymized) version of our dataset and Related work mainly spans: anomaly detection in social networks and fraud on Twitter.
 Anomaly detection and fraud detection in social networks has led to several methods: NetProbe [ 13 ] identifies fraud on eBay using belief propagation. MalSpot [ 12 ] uses tensor decomposition for computer network intrusion detection. Copy-Catch [ 1 ] spots lockstep behavior in Facebook Page Like patterns. [ 6 ] leverages spectral analysis to reveal various types of lockstep behavior in social networks. FraudonTwitter: [ 18 ] analyzes the relationships of criminal accounts inside and outside of the criminal account community to infer types of accounts which tweeting behavior, tweet content and account properties for computing the like-lihood of an unknown user being a human, bot or cyborg. [ 16 ] shows the strong classification and prediction performance of temporal features for distinguishing between account types. However, all these works address the detection of spam-mers based on their tweeting and/or networking activity, instead of the fake retweeting problem. In addition, most existing methods (e.g. [ 17 ]) consider the typical and out-dated model of a fraudster who has uniform posting frequency and a followers-to-followees ratio close to 1  X  nowadays, many fraudsters are more sophisticated. [ 5 ] addresses a problem similar to ours, but uses the URLs found in tweets instead of retweet threads in conjunction with a time and user-based entropy to classify posting activity and content. [ 9 ] applies disparity , also known as inverse participation ratio [ 3 ], on Twitter data to reveal favoritism in retweets. Table 1 outlines the characteristics of existing methods compared to RTScope .
 Our intitial intuition is that a large proportion of  X  X ake X  retweets originate from bot accounts or human accounts which employ the use of automated software. This implies the existence of similarity in the temporal behavior of the indi-vidual retweeters, due to the posting (and retweeting) scheduling capabilities of automation tools. We also expect that it is highly probable that fraudulent retweeters of a given user will operate concurrently in lockstep fashion. This is indicative of collaboration between spammers or a contract between the author and a third party for a purchase of retweets. To study the retweeting activity in terms of time and retweeting users, given a user u m ( author ) we represent the tweet posted by u m with tw m,i as a tuple ( u m ,t m,i ), where creation time. Then, a retweet thread is defined as follows: Definition 1 (Retweet thread). Given an author u m and a tweet retweet thread R m,i is defined as the set of all tweets that retweeted ated by users with abnormal connectivity in terms of their follow relationships in Twitter. An example of such abnormal connectivity would be a much denser network of fraudulent (compared to honest) retweeters, corresponding to a group of fraudsters following each other in an attempt to maintain reputability. To val-idate our hypothesis on the importance of connectivity as a feature, we consider the following two types of relationship networks: Definition 2 (Relationship networks). Given a retweet thread the  X  X -A X  and  X  X  X  networks as the induced networks of:  X  X -A X  network author u m and all retweeters of tw m,i ;  X  X  X  network all retweeters of tw m,i minus zero-degree nodes, i.e. retweeters of the complete Twitter followers network, since we operate under the constraint of limited visibility. Constraining the followers network to specific subgraphs is important given that the massive size of the Twitter network poses computa-tional burdens to the application of graph algorithms for pattern detection. Problem 1 ( Retweet-thread level ).
 Given : a tweet tw m,i and a retweet thread R m,i , Identify : whether R m,i is organic.
 Problem 2 ( User level ).
 Given : a user u m , a set of tweets tw m,i and their induced retweet threads, Identify : whether u m is a spammer.
 instances of fraud, thus is suitable for  X  X ccasional X  fraudsters (who occasionally purchase retweets or are paid to participate in promotions, but otherwise exhibit normal activity) and promiscuous professional spammers (their fake retweet threads can be spotted without additional data on their past activities). The User level problem addresses also the detection of more cautious spammers, whose retweet threads are not suspicious on their own, but they reveal suspicious recurring patterns when they are jointly analyzed. We examine our hypotheses on a dataset comprising several retweet threads of honest and fraudulent Twitter users. RTScope requires complete retweet threads, i.e. with no gaps in the tuples representing a tweet X  X  retweets. Due to Twitter Streaming API X  X  constraint of allowing access to only a sample of the published posts, our need for complete retweet threads and the lack of a relevant (labeled) dataset, we manually selected a set of target users and tracked all their posts and retweets for a given time period.
 We selected target user accounts based on two approaches. The first involved the examination of a 2-day sample of the Twitter timeline, followed by the identification of the users who had posted the most retweeted tweets, and those who posted tweets containing keywords heavily used in spam campaigns (e.g. casino, followback). The second approach was based on  X  X witter Counter X  web application publishing lists that rank Twitter users based on criteria such as their number of followers and tweets, and involved the selection of users based on their posting frequency and influence (i.e. we kept only users who posted several posts per week and had received more than 100 retweets on some of their recent posts). We manually labeled target users as  X  X raudulent X  (FD) if (a) inspection of their tweets X  content led to the discovery of spammy links to external web pages, spam-related terms, and repetitive posts with the same promotions, or (b) their profile information was clearly fabricated. We labeled the rest of target users (of different popularity scales for the sake of diversity) as  X  X onest X  and further divided them into high-, medium-and low-popularity (HP, MP, LP, respectively), using the cut-offs of &gt; 100K followers for HP and for LP. We monitored the initial set of target users for 30 days and eliminated those who had all their posts retweeted less than 50 times. Then, we reinforced the remaining dataset with an extra number of similarly selected users, and collected data for an additional 60-days period. At the end of this period, we again pruned users using the same filtering criterion. Overall, this process left a total number of 24 users in the dataset, of which 11 honest (5 HP, 4 MP, and 2 LP) and 13 fraudulent, while after the end of the monitoring period we identified that 4 of our fraudulent users had been suspended by Twitter. Table 2 shows the activity characteristics for the dataset X  X  honest and fraudulent users. For the reproducibility of our results, we make available an anonymized version of our dataset at http://oswinds.csd.auth.gr/project/RTSCOPE .
 From our data collection and preliminary analysis, we make two main obser-vations: Observation 1 (Variety) . Fraudsters have various behaviors in terms of their posting frequency and timing.
 Specifically, some fraudsters are hyperactive , posting many tweets ( per day); others are more subtle , posting few tweets per day, while sometimes mixing original posts with retweets to other users X  posts, implying some type of cooperation (half of our dataset X  X  FD users are hyperactive ). We also noticed that some FD users often produced (resembling) honest posts along with fraudulent ones. This may indicate the existence of  X  X ccasional X  fraudsters, or intended camouflage practiced by  X  X rofessional X  fraudsters. Observation 2 (FF imbalance) . Despite earlier reports of success, the followers-to-followees ratio (FF) is uninformative for several fraudsters.
 sidered fraudsters with a similar number of followers and followees, we found that some fraudsters maintain a high FF ratio (in our dataset, only two FD users have a ratio close to 1, while for the rest it ranges in 1.3 -2061). Further complicating the problem, hijacked accounts have honest followers and followees with  X  X ormal X  FF ratio (significantly different from 1).
 commonly used FF ratio, what additional features can we use to spot fake retweets? This is exactly the focus of RTScope , which is described next. In this section we propose RTScope and present the results of its application on our dataset. RTScope includes a series of tests that address:  X  X he Retweet-thread level problem ( 1 ), namely: ConR , connectivity  X  X he User level problem ( 2 ), namely: RAct , detection of retweeters X  activa-We note here that in this approach only the ASum features require the retweets X  timestamps, which, in some cases, may be hard to obtain, or easy for the fraud-sters to manipulate.
 5.1 Retweeter Networks Connectivity: TRIANGLES To study the connectivity between the retweeters of a given tweet, we selected a sample of the largest retweet threads for each user in the dataset, identified their follower relations via the Twitter API and generated the  X  X  X  and  X  X -A X  graphs Interestingly, we observed that for some retweet threads of fraudulent users there were no connections between the retweeters, whereas for others, none of the retweeters was connected to the author. These phenomena were mostly observed in the context of occasional fraudsters . However, we noticed that in these cases, a significant (more than 20%) percentage of the original retweeters were suspended some time afterwards, thus affecting the remaining users X  connectivity. For the rest of the retweet threads (of fraudulent and honest users) the percentage of suspended retweeters was less than 10%.
 The connectivity analysis of the  X  X  X  and  X  X -A X  networks led to Observa-tion 3 . Next, we discuss the details of our analysis approach and findings. Observation 3 ( connectivity ) .  X  X  X  and  X  X -A X  networks of honest and fraudulent users differ substantially and exhibit the triangles satellite patterns, on which we elaborate below: TRIANGLES: Some fraudulent users have a very well connected network of retweeters, resulting in many triangles in their  X  X  X  network. The triangles vs. degree plots of fraudsters often exhibit power-law behavior with high (1.1-2.5) slope. Figure 2 shows that honest users (top row, (a)-(c)) have  X  X  X  networks with &lt; 100 and often 0 triangles. Conversely, the  X  X  X  networks of fraudulent users (bottom row, (d)-(f)) are near-cliques with almost the maximum count of triangles for each node (( d  X  1)( d  X  2) degree d ).

Such networks are probably due to several bot accounts created by a script and made to follow each other in botnet fashion.
 DEGREES: Honest users have  X  X -A X  and  X  X  X  networks with power-law degree distribution (Figure 3 (a)) while fraudulent ones deviate (Figure 3 (b)). The spike at degree  X  30 for the latter, agrees with the botnet hypothesis. SATELLITE: In honest  X  X -A X  networks, the author has many  X  X atellites X , i.e. 5.2 Retweet Activity Frequency: FAVORITISM Given a target user X  X  posts, what is the distribution of retweets across the retweeters? Do most retweets originate from a specific set of dedicated users, or are they distributed uniformely across all the user X  X  connections? given a finite number of instances (in our case, retweets), the number of different states or subsets these instances can be distributed into. With respect to a given target user, the number of instances corresponds to the total number of retweets, while a given state is the number of retweets made by a single user. Disparity reveals whether the retweeting activity spreads homogeneously over a set of users, or if it is strongly heterogeneous , in the sense that it is skewed towards a small set of very active dedicated retweeters.
 j =1 ...k retweeters, we examine disparity with respect to the total retweeting activity of these k users. We define the number of retweets made from user user i as r ij , and the total number of retweets from u j Then, we consider that the number of retweets r ij defines the state of user ranging from r ij =1to r ij = SR .
 Definition 3 (Disparity). The disparity of retweeting activity with respect to author u i and a retweet thread size k is defined as: take the average of the Y ( k, i ) values over retweet threads.
 distribution: (a) the homogeneous , where all users are in the same state (i.e. they have the same r ij value), and (b) the super-skewed , where there exists some user u who is at a state of much larger value compared to the rest  X  that is, as follows: Lemma 1. The disparity Y h ( k, i ) for the homogeneous activity distribution obeys Lemma 2. The disparity for the super-skewed activity distribution is given by: thus it is independent of the retweet thread X  X  size k . Figure 4 exhibits the relation between Y ( k, i )and k averaged over all hon-est (Figure 4a ) and fraudulent users (Figure 4b ). We observe that honest users appears to have exponential relationship to k of less than 1 (from equation 3 ). Fraudulent users X  activity is fundamentally different and is close to the homogeneous case, where kY ( homogeneous behavior is encountered at large values of k which correspond to heavily promoted tweets, whereas less homogeneity is encountered for small retweet threads, likely for camouflage-related reasons.
 We try to approximate the relationship between disparity and hypothesis that the different states r ij of users u j for distribution. If we sort the different r ij states by decreasing order of magnitude, we can express the j th frequency p j = r ij SR as p j = 1 derive the following lemma: Lemma 3. The disparity of a Zipf distribution is given by: Proof. As per equation 1 , the disparity of the Zipf distribution can be approx-imated by: fit for honest users X  behavior ( favoritism pattern). Conversely, fraudulent users X  disparity is characteristic of a zero slope ( homogeneity by Figure 4b .
 Observation 4 ( favoritism ) . The disparity of retweeting activity to honest users X  posts can be modeled under the hypothesis that the participation of users to retweets follows a Zipf law.
 Observation 5 ( homogeneity ) . The disparity of retweeting activity to fraud-ulent users X  posts can be modeled under the hypothesis that the participation of users to retweets is homogeneous. 5.3 Activity Summarization Features: MACHINE-GUN, We further extracted the following temporal and popularity (ASum) features with respect to the retweet threads included in the datasets:  X  ratio of activated followers , i.e. author X  X  followers who retweeted;  X  response time , i.e. time elapsed between the tweet X  X  posting and its first  X  lifespan , i.e. time elapsed between the first and the last (observed) retweet,  X  Arr-IQR , i.e inter-quartile range of interarrival times for retweets. for retweet threads of all target users. Interestingly, several red points of users suspected of fraud are clearly separated from honest users X  retweet threads due to their high or low response time and high activated followers ratio . In addition, the consideration of various feature combinations can be useful for identifying fake retweet threads. Figure 5b , which depicts the scatter plot of the Arr-IQR vs. lifespan for retweets of all target users X  retweet threads, indicates that several retweet threads of the same fraudulent users tend to exhibit similar values for these features, resulting in the formation of dense microclusters of points. For example, the cluster appearing at the figure X  X  bottom-left side is created from retweet threads whose author is fraudulent user FD 5.
 Observation 6 ( enthusiasm ) . Followers of fraudulent retweeters have a high
