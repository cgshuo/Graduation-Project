 Classification is a fundamental data mining problem which has been well studied. Traditional classification procedure can be described as follows. Given a set of training data containing category information, after learning a model from the training set, this model can be used to classify the unseen testing instances. There is always an assumption in it that the new instances classified by using this model always belong to one of the categories in the training data.
Unfortunately, this assumption can X  X  be satisfied in many applications. In practice, some of the testing instances may not belong to any of the predefined classes of the original training set, and these instances are always called negative instances. This situation can also be found in our daily life. For example, assum-ing that there exist two different classes of mails: news and entertainment. If a new email about job description comes, as a result, it X  X  will be assigned to any one of the given two classes. In order to deal with this problem, PU learning is studied in order to deal with this situation where only the positive and unlabeled instances are given while no negative instance is given.

This paper focuses on the problem of learning from positive and unlabeled examples (or PU learning), where the input instances are multiple(at least 2) labeled positive training classes and unlabeled data. Semi-supervised learning addresses this problem by using large amount of unlabeled data, together with small labeled data, to build better classifiers.

There are some former work on this topic. Table 1 gives the comparison of existing methods. All of these former methods follow an one-vs-all schema. In fact, different algorithms achieve good performance in different unlabeled data distribution. The former methods always perform well, when the unlabeled data contain plenty of negative data. Some methods can only deal with textual data. LiKL need extra attention to tune some pa rameters. Since the unlabeled data distribution is unknown, it X  X  hard to choose a proper method that best matches the given situation. This paper shows a new idea about integrating different methods behind the intuition of different methods can make up a loss for each other. Our contributions are as follows: 1. An approach to estimate the percentage of negative data in the unlabeled 2. In order to discover the hidden information in the unlabeled examples, an 3. With the help of the unlabeled distribution information, a framework that 4. A series of experiments are conducted on 20 newsgroups and Reuters corpus, The rest of this paper is organized as follo ws: Section 2 presen ts related works; Section 3 introduces the proposed auto-CiKL approach and describe our way to estimate the proportion of negative data in unlabeled set which is also used to integrate existing algorithms to get a more stable model; Finally, The experi-mental results are in Section 4, followed by the conclusion in Section 5. Several dozen papers have been published on the topic of learning a classifier from only positive and unlabeled training examples. One simple way is to com-pletely ignore the unlabeled examples, namely, learning only from the labeled positive examples, e.g. one-class SVM [1] which aims to approximately covering all labeled positive examples. This work is not always proper. If some reliable negative instances can be identified in the unlabeled data, knowledge provided by unlabeled set will be discarded. And this method makes over-fitting easily.
In semi-supervised learning, unlabeled set is always used for training. These approaches can be covered by two categories. The more common method is (i) to use heuristics to identify unlabeled exam ples that are likely to be negative,and then (ii) to apply a standard learning method to these examples and the positive examples; steps (i) and (ii) may be iterated. For example, PEBL[2] firstly utilizes 1-DNF[4] to find out quite likely negative examples and secondly employs SVM[5] iteratively for classification. S-EM[3] uses spy technique for extraction of likely negative examples in the first step, and sequently EM algorithm is applied for the parameter estimate. Self-training and co-training also belong to this category. For the self-training method, a classifier is first trained with the small amount of labeled data. The classifier is re-trained and the procedure repeated. Rosenberg et al.[10]apply self-training to object detection systems from images, and show the semi-supervised technique compares favorably with a state-of-the-art detec-tor. In the co-training, Each classifier then classifies the unlabeled data, and teaches the other classifier with the few unlabeled examples (and the predicted labels) they feel most confident. Each classifier is retrained with the additional training examples given by the other classifier, and the process repeats. Our work also belongs to this category.

Another common way is to directly modify the training model. Assigning weights somehow to the unlabeled examples is one way. Training a classifier with the unlabeled examples interprete d as weighted negative examples. This approach is used in [6, 7]. B-Pr[8] and W-SVM[9] belong to another probabilistic way. Without needing to extract likely n egative examples, they transform the P is the training set and U is the unlabeled data set.

It has been noticed that constraining the class proportions on unlabeled data can be important for semi-supervised learning. Without any constrains on class proportion, various semi-supervised learning algorithms tend to produce unbal-anced output. For this reason, various semi-supervised learning methods have been using some form of class proportion constraints. For example, Zhu et al.[11] use a heuristic class mean normalization procedure to move towards the desired class proportions; S3VM[18] methods explicitly fit the desired class proportions. However, in these methods the class pr oportion constraint is combined with other model assumptions. To our best knowledge, this paper first introduce an unlabeled data distribution estimate method for PU problem.
 3.1 Preliminaries The KL Divergence[16] between the probability distribution P = { p 1 ,...,p n } and Q = { q 1 ,...,q n } is defined as: In this paper, the KL divergence is calculated just as [17] between the posterior probabilities of every instance d i in the unlabeled set and the prior probabilities of each class, and then the revised formula of KL divergence is defined as: where p ( c j | d i ) is the class posterior probability of instance d i belonging to the j -th class c j ; p ( c j ) is the prior probability of each class; | C | is the number of known or predefined class labels appearing in the training set. The intuition of this revision is that, if an instance belong to a labeled category the KL divergence from posterior probability distribution to prior probability distribution is large; if an instance is negative it will belong to any labeled category equally that lead to small KL Divergence.

For the unlabeled set(labeled as U), the KL divergence of every instance is calculated, and the instances and are obtained as the most likely corresponding sub-positive( c k ) and negative ex-amples respectively. 3.2 Problem Description Given that a training set(P) only containing positive examples, from multiple (at least 2) classes, without negative ones, and one unlabeled set(U) containing both positive and negative examples, our task is to construct a classifier( C ), finding all likely negative examples( U n ) hidden in the unlabeled set and it is formulated as follows: input ( P,U ) C  X  output ( U n ) . 3.3 Auto CiKL Approach This work is based on our former work LiKL[17], which contains three steps. In the first two a probablistic classifier C 1 is trained from the data of positive set. Then use the posterior probability returned by C 1 to calculate the KL divergence of every instance in the unlabeled set and pick up reliable positive instances and reliable negative instances. In the last step, with the help of instances identified from the unlabeled set, the final classifier to identify the instances that don X  X  belong to any class in the training set is trained.

In this paper, a improvement for LiKL called Auto CiKL is introduced. The difference between Auto CiKL and LiKL lies in the first two steps.

The first step is to find the most likely positive examples. The labeled set P is used to learn a classifier for getting posterior probability. Through the poste-rior probability, the KL divergence of each instance in the unlabeled set can be calculated out. Pick out the top K largest and add them into labeled set with labeling them to corresponding class. If the percentage of positive instances in the unlabel data is unknown, it X  X  hard to pick up a proper K, which is the short-coming of LiKL. In Auto CiKL we use a function EstimateProportion ( P,U )to estimate the proportion of negative instances. Then we can easily get the pro-portion of positive instances. After ge tting the proportion, we can decide the K based on it. The function EstimateProportion ( P,U ) will be given in the next subsection.

In the second step, a plenty of labeled dat a are available. The new training set (P+ S p ) is used to build a new classifier FN to classify the remaining unlabeled set (U-S p ), and find the top N most likely negative instances. All the negative instances are denoted as S n ;
Now a training set (P+ S p + S n ) is obtained which contains both positive in-stances and negative instances. Use (P+ S p + S n ) to train the final classifier model and classify the instances in the set (U-S p -S n ). Some classification algorithms such as SVM and logistic regression can be used in the last step. 3.4 Distribution Estimation for Unlabeled Data The step 1 and step 2 of Auto CiKL suffer from the problem of setting the value of K and N respectively. It X  X  difficult to set these two parameters if any extra information is unknown. The reason is as follows. If a small value is given to K, when the percentage of positive instances in the unlabeled set is large, and too many positive instances will be left in the unlabeled set so that the classifier which use the remaining unlabeled set as negative instances set will be ineffective. On the contrary, if a large value is given to K, when the percentage of positive instances in the unlabeled set is small, too many negative instances will be introduced into the labeled set as positive instances, that will pollute the labeled training set. The similar analysis can be found for the value of N.
It X  X  obvious to give different values for different density of positive or nega-tive instances in the unlabeled set. In this paper, we use the density of unla-beled set stands for the percentage of negative instances in the unlabeled set. Unfortunately, the density of unlabeled set is unknown. That means it is impor-tant to estimate the density of the unlabeled data.

The intuition of our method is presented in the Figure 1. The P set stands for the labeled set, while the U set represents the the unlabeled set. Label the instances in the P as the positive ones, and label the instances in the U as the negative one. Then use all of them to learn a classifier. (a) and (b) show the situation that the U set contains low percentage and high percentage of negative instances respectively. It X  X  obviously that the classifier in the (b) can get a higher recall for the positive instances than that in the (a). The reason is that, the more real negative instances which the unlabeled set contains, the easier classifier separat e the P and the U properly.
 The detailed algorithms are shown in Algorithm 1 and 2.
 In the Algorithm 1, Num instances are generated fo r different proportions. The more instances we generate, the higher accuracy for estimation. The main idea of the generate instances method is to find the distribution of each at-tribute for each category and to generate positive instances based on these dis-tributions of attributes in the training set P. Each attribute of each positive instance in UT is generated one by one through the distribution found in P.
In the Algorithm 2, after the training set is produced, a model used for esti-mating proportion could be learned. Take the recall of the P as the input of the model. The estimation for the negative instances proportion of unlabeled data is outputted from this model. As the estimate proportion of negative instances is available, proper values can b e chosen for K and N respectively. 3.5 Integrating Different Methods in the New Framework From the experiment results showed in Figure 6, we can conclude that no one method can achieve the best performance in the all cases. Different methods have their different best fit situations. If the knowledge about the proportion can be accessed, choosing a proper approach for different situation is possible. In another words, these different methods could be integrated into a mixture method. This paper uses the proportion knowledge to integrate KL method and ROC-EM method to achieve a better mixture model, which can always stay good performance than just using only one of them.
Based on the estimate of unlabeled data distribution, a new framework for semi-supervise learning can be proposed. This is based on the estimate of unla-beled data distribution. With the knowledge of distribution, a framework that integrates different performance methods is given. This framework can integrate some former methods which have different performance in different unlabeled data distribution. It automatically choose the proper approach according to the distribution knowledge.The experimental results demonstrate that that hybrid method can achieve a globally high performance.
 The objective of this section is to evaluate our proposed approach in terms of learning accuracy. The experiments are conducted on Intel 2.0 GHZ PC with 2 GB of RAM. The The classisifers used in our approach are implemented in Weka 1 environment. And the existing PU learning methods such as roc-em are downloaded from http://www.cs.uic.edu/  X  liub/LPU/LPU-download.html. 4.1 Data Sets We used the benchmark 20 Newsgroup collection[19] and Reuters corpus[20]. 20 Newsgroup has approximately 20000 documents, divided into 20 differ-ent small subgroups respectively, each of which corresponds to a different topic. Firstly, four subgroups are chosen from computer topic and two topics from sci-ence respectively, i.e. comp.graphics, com p.ibm.hardware, comp.mac.hardware, comp.windows.xsci.crypt, sci.space, C 1 4 C 1 2 = 8 pairs of different experiments. For each pair of classes, i.e. selecting one class from { graphics, ibm.hardware, mac.hardware, windows.x } X { crypt, space } respectively as two positive classes, e.g. graphics  X  crypt , an equal part of documents are chosen randomly for train-ing as corresponding positive instances, and the rest as unlabeled positive data in unlabeled set; Then some examples are extracted randomly from the rest 18 subgroups are viewed as unlabeled negative examples in unlabeled set, and the number is  X   X | U | ,where  X  is a proportion paramet er, showing the per-centage of negative examples in the unlabeled set, and | U | is the number of all instances in the unlabeled set. The similar operation is done to Retuers, and the topic combinations { acq-crude, acq-earn, crude-i nterest, crude-earn, earn-interest, interest-acq } are chosen as the positive topic.
 Feature Extraction. All the documents in our experiments are modeled by Vector Space Model. Feature selection is very important in textual classification. Instead of using PCA or LDA for dimensionality reduction, a light but effective way which is borrowed from information retrieval is used. TF-IDF is a measure used to reflect the importance of the words in documents. The words with high TF-IDF value for each class are retained. The intuition of this method is that it X  X  common to see some certain words in some certain topics. This is similar to the fundamental of LDA. And the result is readable. 4.2 Experimental Results We perform 10 times hold-out tests with random data partitions to get the average F-score value as the final result. In the experiments,  X  is the ratio of the unlabeled negative examples compared to the unlabeled set. E.g.  X  =0 . 1 means that the number of the unlabeled negative examples is only 10% of the unlabeled set.
 Performance for Auto-KL Method Figure 5 records the comparison of the p erformance between using proportion estimate and giving the real proportion. KL-Auto represents the former and KL-ByHand represents the latter respect ively. Both of them have the trend that the F scores increase with the proportio n of the negative instances increase. KL-Random means randomly giving values to K and N. It X  X  obvious that the performance of KL-Auto decreases beca use of the mistakes made by estimator. But the result is much better than the KL-Random, in which all the N and K are chosen randomly. That means our proportion estimate approach is so effective that the estimate given by our method is close to the real proportion. Performance for Different Algorithms Figure 6 records the F scores of Spy-SVM, ROC-EM and KL-Auto. The ROC-EM means using rocchio technique for the first step to identify reliable negative instances and using EM for the second step to build final classifier. The Spy-SVM means use the spy technique for the first step and the use SVM step for the second step.

As shown in Figure 6, no one approach can achieve the best performance all the time. It X  X  easy to see the KL-Auto outperforms the other two methods dramatically in the case of 0.1 and 0.2. KL-Auto perform quite well in the other cases, but not as well as these method proposed by Liu. In the contrary, ROC-EM can get high F score in the high propo rtion case, but have bad performance in the case of 0.1 and 0.2. Each approach has its best fit situation. In another words, if the proportion of the unlabeled data set is unknown, when only one of these methods is chosen, result may fall into the bad case of these methods. Performance for Integration of Different Approaches Since the proportion of negative instances in unlabeled data can be estimated, not just one approach can be used. Methods that can make up a loss for each other can be picked up to produce a hybrid approach. Figure 7 shows the result of integration of spy-svm and KL-Auto. It X  X  clearly to see that the hybrid approach can almost achieve the best all the time.

From the above experiments, we can draw the following conclusion. (1) Using the estimate for proportion, the parameters can be automatically chosen for the KL method effectively. Th e KL method outperform than existing methods in the low proportion case. (2) No one algorithm can always achieve good performance, every approach has its best fit proportion. (3) The new framework for semi-supervise learning can always generate a global optimum hybrid method. In this paper, the problem of learning from positive and unlabeled examples is tackled by using a novel approach called Auto CiKL and propose a framework that can integrate other algorithms to obtain a global high performance hybrid method. The CiKL method can achieve good performance when the negative instances proportion is low. And the hybrid method can always perform better. In the further work, we will further study how to improve the precision of our estimate method and give theoretical analysis for our approach.
 Acknowledgments. This work was supported by the National Major Projects on Science and Technology under grant number 2010ZX01042-002-003-004,NSFC grant (No. 61033007, 60903014 and 61170085), 973 project(No. 2010CB328106), Program for New Century Excellent Talents in China (No.NCET-10-0388).
