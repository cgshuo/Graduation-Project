 Abstract It is a big challenge to clearly identify the boundary between positive and negative streams for information filtering systems. Several attempts have used negative feedback to solve this challenge; however, there are two issues for using negative relevance feedback to improve the effectiveness of information filtering. The first one is how to select constructive negative samples in order to reduce the space of negative documents. The second issue is how to decide noisy extracted features that should be updated based on the selected negative samples. This paper proposes a pattern mining based approach to select some offenders from the negative documents, where an offender can be used to reduce the categories: positive specific terms, general terms, and negative specific terms. In this way, multiple revising strategies can be used to update extracted features. An iterative learning algorithm is also proposed to implement this approach on the RCV1 data collection, and substantial experiments show that the proposed approach achieves encouraging perfor-mance and the performance is also consistent for adaptive filtering as well.
 Keywords Pattern mining Relevance feedback Information filtering 1 Introduction Traditional information filtering (IF) models were developed based on a term-based user profile approach (see [ 15 , 20 , 23 ]). The advantage of term-based profiles is efficient computational performance as well as mature theories for term weighting, which have emerged over the last couple of decades from the information retrieval (IR) and machine learning communities. However, term-based profiles suffer from the problems of polysemy and synonymy. As IF systems are sensitive to data sets, it is still a challenging issue to significantly improve the effectiveness of IF systems.

Over the years, people have often held the hypothesis that phrases would perform better than words, as phrases are more discriminative and arguably carry more  X  X  X emantics X  X . This Recently, language modeling approaches went beyond the term based model that underlies BM25 by considering term dependencies in phrases (N-grams) for information retrieval [ 18 , 35 ]. Although phrases are less ambiguous and more discriminative than individual terms, the likely reasons for the discouraging performance include: (1) phrases have inferior statistical properties to words since they have low frequency of occurrence, (2) the theory of computing probabilities based on term dependencies is not practical, (3) some language model-based feedback methods cannot naturally handle negative feedback, and (4) there are large numbers of redundant and noisy phrases among them.

To overcome the limitations of term-based approaches, pattern mining based techniques have been used for information filtering since data mining has developed some techniques (e.g., maximal patterns, closed patterns and master patterns) for removing redundant and noisy patterns. One special filtering task was to extract usage patterns from Web logs [ 4 , 47 ]. Other promising techniques were pattern taxonomy models (PTM) [ 32 , 37 ] that dis-covered closed sequential patterns in text documents, where a pattern was a set of terms that frequently appeared in paragraphs.
 Pattern based approaches have shown encouraging improvements on effectiveness [ 36 ]. However, two challenging issues have arisen when pattern mining techniques were introduced for IF systems. The first one is how to deal with low frequency patterns because the measures used for data mining (e.g.,  X  X  X upport X  X  and  X  X  X onfidence X  X ) to learn the patterns turn out be not suitable in the filtering stage [ 15 ]. The second issue is how to effectively use negative feedback to revise extracted features (including patterns and terms) for infor-mation filtering.

Many people believe that there are plenty negative information available and negative documents are very useful because they can help users to search for accurate information [ 35 ]. However, whether negative feedback can indeed largely improve filtering accuracy is still an open question. The existing methods of using both positive and negative feedback for IF can be grouped into two approaches. The first approach is to revise terms that appear in both positive samples and negative samples (e.g., Rocchio based models and SVM [ 23 ] based filtering models). This heuristics is obvious when people assume that terms are isolated atoms. The second approach is based on how often terms appear or do not appear in positive samples and negative samples (e.g., probabilistic models [ 2 ], and BM25 [ 23 ]). However, usually people view terms in multiple perspectives when they attempt to find what they want. They normally use two dimensions ( X  X  X pecificity X  X  and  X  X  X xhaustivity X  X ) for deciding the relevance of documents, paragraphes or terms. For example,  X  X  X DK X  X  is a specific term for  X  X  X ava Language X  X , and  X  X  X IB X  X  is more general than  X  X  X DK X  X  because it is also frequently used for C and C ?? as well.

Based on this observation, this paper proposes a pattern mining based approach for using both positive and negative feedback. It firstly extracts an initial list of terms from positive documents and selects some constructive negative documents (or called offend-ers). It then extracts terms from negative patterns in selected negative documents. It also negative specific terms. In this way, multiple revising strategies are used for terms in different categories. In the implementation, it recommends to increment positive specific terms X  weights only and declines negative specific terms X  weights based on their occur-rences in discovered negative patterns. Substantial experiments show that the proposed approach achieves exciting performance.

The remainder of this paper is organized as follows. Section 2 introduces a detailed overview of the related works. Section 3 reviews the concepts of pattern taxonomy mining. Section 4 introduces the equations for evaluating term weights based on discovered pat-terns. Section 5 describes the proposed method of using negative feedback. The empirical results and discussion are reported in Sect. 6 , and the last section describes concluding remarks. 2 Related work Different from IR systems, IF systems were commonly personalized to support long-term information needs of users [ 3 ]. The main distinct difference between IR and IF was that IR included adaptive filtering, and batch or routing filtering. In this paper, the focus is on the breakthrough for batch or routing filtering. Adaptive filtering involves feedback to dynamically adapt IF systems [ 9 , 17 , 33 , 42 , 44 ]. The popular way is to update training sets in a batch classifier fashion. In this paper, we also evaluate the performance of the pro-posed approach for adaptive filtering.

Normally, IF systems tended to learn a map rank : D ! R such that rank ( d ) corre-sponded to the relevance of a document d , where D denoted a set of documents, R was the set of real numbers. In [ 20 ], rank was divided into two functions, such that rank  X  f 1 f 2 , and C 1 ; C 2 ; ... ; C m were clusters. This method used a set of clusters based on a kind of classification method, e.g., the neural network [ 19 ]. The aim of the filtering track in TREC documents to separate relevant and non-relevant documents. The basic term-based IF models used in TREC 2002 were SVM, Rocchio X  X  algorithm, probabilistic models, and BM25.

Feedback techniques are frequently used in IR community to improve the accuracy of filtering. Normally, there are different strategies for considering users feedback informa-tion for information retrieval. They are relevance feedback, pesudo-relevance feedback, implicit feedback and negative feedback [ 6 , 29 , 34 , 38 ]. One of the common objectives of these strategies is to design IR models in order to obtain more accurate term weights based on user feedback for a given query.

Term-based models are most widely used approaches. A term-based model is based on the bag of words or N-grams, which uses terms as elements and evaluates term weights based on terms X  appearances or frequencies in feedback. For example, Rocchio-style classifiers [ 12 ], ranking SVM [ 22 ]; and BM25 for structured documents [ 25 ] are popular IF systems. They can also naturally handle both positive and negative feedback information. However, the research on term-based models has arguably hit somewhat of a wall in terms of effectiveness improvement possibly due to the ambiguity problem mentioned earlier. In addition, modeling the real dependencies between terms is very difficult.

Language models have been developed for considering term dependencies. In a lan-guage model, the key elements are the probabilities of word sequences which include both terms and phrases (or sentences) [ 31 ]. They are often approximated by N-gram models, such as Unigram, Bigram or Trigram, for considering term dependencies easily. Language modeling approaches include model-based methods, and relevance models [ 18 ]. The for-mer finds models that can best describe the features in positive documents while consid-ering a background model [ 45 ]. The later tries to model the notation of relevance in a more generalized level [ 10 ]. Language modeling approaches have been well developed for information retrieval, especially for query expansion techniques [ 18 , 39 , 35 ]. They are also quite effective for exploiting positive feedback information. However, they cannot natu-rally handle negative feedback.

Pattern mining has been extensively studied in data mining communities for many years. A variety of efficient algorithms such as Apriori-like algorithms [ 1 ], PrefixSpan [ 21 ], and FP-tree [ 5 ] have been proposed. These research works have mainly focused on developing efficient mining algorithms for discovering patterns in databases. Usually, the existing data mining techniques return numerous discovered patterns (e.g., sets of terms) from a training set, but large numbers of them are redundant patterns [ 40 ]. Nevertheless, the challenging issue is how to effectively deal with the large amount of discovered patterns and terms with a lot of noises.

Closed patterns have turned out to be a promising alternative to phrases [ 7 , 32 ] because patterns enjoy good statistical properties like terms. To effectively use closed patterns for information filtering, closed sequential patterns have been used in pattern taxonomy models (PTM) [ 32 , 36 , 37 ], which deployed closed sequential patterns into a vector that included a set of terms and a term-weight distribution. The pattern deploying method has shown encouraging improvements on effectiveness in comparing with traditional proba-bilistic models, Rocchio based method and N-gram. The similar research also appeared in [ 41 ] for developing a new methodology of post-processing of pattern mining, pattern summarization, which grouped patterns into some clusters and then composed patterns in distribution.

These approaches introduced data mining techniques to information filtering; however, too many noisy patterns adversely affect PTM systems [ 15 ]. The major research issue is how to use both positive and negative feedback to significantly reduce the effects of noisy patterns. Traditional data mining techniques can only achieve a little progress for the effectiveness because they can only discuss this problem at the pattern level. This paper starts to consider human being X  X  perspective about relevance and uses a two-dimension concept to classify terms into three groups: positive specific terms, general terms and negative specific terms. In this perspective, term weights can be evaluated accurately based on their appearances in both positive patterns and negative patterns.

Our conference paper [ 13 ] is the first study on the problem of mining negative relevance feedback for information filtering. In this paper, we extend previous study by adding more examples, discussing more related research works, and extending the experiments for discussing the proposed iterative learning algorithm and statistic analysis. We also con-ducted some new experiments for using the proposed approach on adaptive filtering. 3 Pattern taxonomy mining In this paper, we assume that all documents are split in paragraphs. So a given document d yields a set of paragraphs PS ( d ). Let D be a training set of documents, which consists of a set of positive documents, D ? ; and a set of negative documents, D -. Let T  X f t 1 ; t 2 ; ... ; t m g be a set of terms (or keywords) which are extracted from the set of positive documents, D ? . 3.1 Frequent and closed patterns Given a termset X , a set of terms, in document d , p X q is used to denote the covering set of X for d , which includes all paragraphs dp [ PS ( d ) such that X dp , i.e., p X q  X f dp j dp 2 PS  X  d  X  ; X dp g . Its absolute support is the number of occurrences of X in PS ( d ), that is sup a  X  X  X  X j p X q j . Its relative support is the fraction of the paragraphs that sup a (or sup r ) min sup , a minimum support.

Table 1 lists a set of paragraphs for a given document d , where PS  X  d  X  X f dp 1 ; ... ; dp 6 g , and duplicate terms are removed. Let min _ sup = 3 giving rise to ten frequent patterns which are illustrated in Table 2 . Normally not all frequent patterns are useful [ 32 , 40 ]. For example, pattern f t 3 ; t 4 g always occurs with term t 6 in paragraphs (see Table 1 ); therefore, we want to keep the larger pattern only.

Given a termset X , its covering set p X q is a subset of paragraphs. Similarly, given a set of paragraphs Y PS  X  d  X  , we can define its termset , which satisfies The closure of X is defined as follows: A pattern X (also a termset) is called closed if and only if X = Cls ( X ).

Let X be a closed pattern. We have for all pattern X 1 X . 3.2 Pattern taxonomy Patterns can be structured into a taxonomy by using the is-a (or subset ) relation and closed patterns. For example, Table 2 contains ten frequent patterns; however, it includes only where non-closed patterns are pruned. After pruning, some direct  X  X  X s-a X  X  retaliations may pruning non-closed patterns h t 3 ; t 6 i and h t 4 ; t 6 i .

Smaller patterns in the taxonomy, for example pattern { t 6 }, are usually more general because they could be used frequently in both positive and negative documents; and larger patterns, for example pattern f t 3 ; t 4 ; t 6 g , in the taxonomy are usually more specific since they may only used in positive documents. 3.3 Closed sequential patterns h x 9 j we usually say s 1 is a sub-pattern of s 2 , and s 2 is a super-pattern of s 1 . In the following, we simply say patterns for sequential patterns.

Given a pattern (an ordered termset ) X in document d , p X q is still used to denote the covering set of X , which includes all paragraphs ps [ PS ( d ) such that X Y ps , i.e., p X q  X f ps j ps 2 PS  X  d  X  ; X Y ps g . Its absolute support and relative support are defined as the same as for the normal patterns.

A sequential pattern X is called frequent pattern if its relative support min sup ,a minimum support. The property of closed patterns (see Eq. 1) can be used to define closed sequential patterns. A frequent sequential pattern X is called closed if not A any super-pattern X 1 of X such that sup a  X  X 1  X  X  sup a  X  X  X  . 4 Deploying patterns on terms The evaluation of term supports (weights) in this paper is different from the term-based approaches. For a term based approach, the evaluation of a given term X  X  weight is based on its appearance in documents. For pattern mining, terms are weighted according to their appearance in discovered patterns.

To improve the efficiency of the pattern taxonomy mining, SPMining ( D ? , min _ sup ) algorithm [ 32 ], was proposed (also used in [ 15 , 37 ]) to find closed sequential patterns for all document d [ D ? , which used the well-known Apriori property in order to reduce the searching space. For all positive document d [ D ? , the SPMining algorithm discovered all closed sequential patterns based on a given min _ sup .
Let SP 1 , SP 2 ,..., SP j D  X  j be the sets of discovered closed sequential patterns for all patterns can be described as follows: Table 3 illustrates a real example of pattern taxonomy for a set of positive documents D  X   X f d 1 ; d 2 ; ; d 5 g . For example, term global appears in three documents ( d 2 , d 3 and d ). Therefore, its support can be calculated based on patterns in the three documents X  X  pattern taxonomies:
After the supports of terms have been computed from the training set, the following rank will be assigned to an incoming document d that can be used to decide its relevance: where weight ( t ) = support ( t , D ? ); and s ( t , d ) = 1if t [ d ; otherwise s ( t , d ) = 0. 5 Mining negative feedback In general, the concept of relevance is subjective; and normally people can describe the relevance of a topic (or document) in two dimensions: the specificity and exhaustivity, where  X  X  X pecificity X  X  describes the extent to which the topic focuses on what users want, and  X  X  X xhaustivity X  X  describes the extent to which the topic discusses what users want. It is easy for human being to do so. However, it is very difficult to use the two dimensions for IF systems. In this section, we first discuss how to use the two dimensions for understanding the different roles of the selected terms. We also presents an algorithm for both negative document selection and term weight revision.
 5.1 Specific and general terms Formally, let DP ? be the union of all discovered positive patterns of pattern taxonomies of D ? , and DP -be the union of all discovered negative patterns of pattern taxonomies of D -, where a closed sequential pattern of D -is called negative pattern. Given a term t [ T , its exhaustivity is the number of discovered patterns in both DP ? and DP -that contain t , and its specificity is the number of discovered patterns in DP ? but not in DP -that contain t . Based on this understanding, in this paper we classify terms into three groups. We call a term a general term if it appears in both positive patterns and negative patterns. We also call terms positive (or negative) specific terms if they appear only in patterns discovered in positive (or negative) documents only.

Based on the above discussion, we have the following definitions for the set of general terms GT , the set of positive specific terms T ? , and the set of negative specific terms T -: It is easy to verify that GT \ T  X  \ T  X ; . Therefore,  X  GT ; T  X  ; T  X  is a partition of all terms in patterns.

To describe user profiles for a given topic, normally we believe that specific terms are very useful for the topic in order to distinguish to other topics. However, some experi-mental results show that using only specific terms are not good enough to improve the performance of information filtering because user information needs cannot simply be covered by documents that only contain the specific terms. Therefore, the best way is to use the specific terms mixed with some of the general terms. 5.2 Strategies of revision After we can classify terms into three categories, we firstly show the basic process of revising discovered features in the training set. This process can help readers to understand the proposed strategies for revising discovered features in different categories.
The process first extracts initial features in the positive documents in the training set, which include terms and patterns. It then selects some negative samples (or called features, including both terms and negative patterns, from the selected negative documents using the same pattern mining technique as used for the feature extraction in positive documents. In addition, it revises the initial features and obtains revised features. The process can be repeated for several times as follows: selecting negative documents, extracting negative features and revising revised features.

Algorithm NFMining ( D ) describes the details of the strategies of the revision, where we assume that the number of negative documents is greater than the number of positive documents. For a given training set D  X f D  X  ; D g , we assume that the initial features, h T ; DP  X  ; DP i , have been extracted from positive documents D ? before we start the algorithm, where we let DP -= [ . We also let the experimental parameter a =-1 that will be used for calculating weights of terms in negative patterns.

Step 1 initializes the set of general terms GT , the set of positive specific terms T ? and the set of negative specific terms T -, where loop is used to control the times of the revision. Step 2 and 3 calculate terms X  weights for all term in T .
Step 4 and 5 rank documents in the set of negative documents, where if t is a negative specific term, its weight is the revised weight that calculates in step 10 and 11. The weight function can be described as follows:
Step 6 and 7 sort the negative documents based on documents X  rank values, and select offenders, some negative documents. If a document X  X  rank less than or equals to 0 that means this document is clearly negative to the system. A document has hight rank that means the document is an offender because it forces the system make mistake. The offenders are normally defined as the top-K negative documents in sorted D -[ 14 ]. In ative documents for offender selection since the initial features only coming from positive documents and we believe that positive features are more important than
Step 8 and 9 extract negative features ( DP -, T 0 ) from selected negative documents D 3 -, where it calls algorithm SPMining  X  D 3 ; min sup  X  to discover negative patterns DP -and T that includes all terms in patterns in DP -.

Step 10 to 12 revise negative specific terms X  weights. These steps will go through a loop negative term is extracted in the first time, the algorithm simply negatives its support obtained from the selected negative documents; otherwise, the algorithm cumulates its weight as follows:
After three loops, the algorithm participates T into general terms GT and positive specific terms T ? in step 14 and 15. It also revises positive specific terms X  weights using the following equation in step 16 and 17: At last, it updates T to include negative specific terms in step 18.

NFMining calls three times SPMining and the total negative documents used in the three times is O (| D ? |); therefore, it takes the same computation time for mining patterns in selected negative documents as the SPMining does for mining patterns in positive docu-ments. NFMining also takes times for sorting D -, assigning weights to terms and parti-tioning terms into groups. The time complexity for these operations is O  X j D j X  log  X j D j X   X j T j X   X  j T j 2  X  .

This algorithm consists of three loops for mining negative specific terms and the corresponding weights. For each loop, after finishing the loop, it is obvious that the number of negative specific terms, | T -|, is not less than the number of negative specific terms before the loop, because of the operation, T  X  T [ X  T 0 T  X  , in Step 12. We expect the three loops can produce enough negative specific terms in order to reduce the side effects of general terms. We will discuss more details for this question in Sect. 6.4 .
 6 Evaluation In this section, we first discuss the data collection used for our experiments. We also describe the baseline models and their implementation. In addition, we present the experimental results and the discussion.
 6.1 Data Reuters Corpus Volume 1 (RCV1) was used to test the effectiveness of the proposed model. RCV1 corpus consists of all and only English language stories produced by Reuter X  X  journalists between August 20, 1996, and August 19, 1997 with total 806,791 documents. The document collection is divided into training sets and testing sets.
TREC (2002) has developed and provided 100 topics for the filtering track aiming at building a robust filtering system. The topics are of two types: (1) A first set of 50 topics are developed by the assessors of the National Institute of Standards and Technology (NIST) (i.e., assessor topics); The relevance judgements have been made by assessor of NIST. (2) A second set of 50 topics have been constructed artificially from intersections of pairs of Reuters categories (i.e., intersection topics) [ 30 ].

Difference from the assessor topics, the relevance judgements have been made by machine learning methods not by human being for intersection topics. The assessor topics are more reliable and the quality of the intersection topics is not quite good [ 23 , 30 ]. For this reason, we use the all 50 assessor topics in this paper.

Documents in the RCV1 collection are marked in XML. To avoid bias in experiments, all of the meta-data information in the collection have been ignored. The documents are treated as plain text documents by preprocessing the documents. The tasks of removing stop-words according to a given stop-words list and stemming term by applying the Porter Stemming algorithm are conducted [ 16 ]. 6.2 Baseline models and setting In this paper, we select three term-based baseline models because they are frequently used for both positive and negative documents. They are a Rocchio model, a BM25 based IF model, and a SVM based model. The PTM model is also used to measure the performance of using negative feedback for pattern mining. In this paper, the proposed approach is called Negative PaTtern Mining model (N-PTM), which firstly discovers sequential closed patterns from positive documents, deploys discovered patterns on their terms. Then, it discovers negative patterns from negative documents to group and revise the extracted features from positive documents as shown in Sect. 5 .

The Rocchio algorithm [ 26 ] has been widely adopted in the areas of text categorization and information filtering. It can be used to build the profile for representing the concept of a topic which consists of a set of relevant (positive) and irrelevant (negative) documents. The Centroid c ~ of a topic can be generated as follows:
There are two sets of setting for a and b : a = 16 and b = 4; and a = b = 1.0. We tested both sets and found a = b = 1.0 was the best set. So, we use a = b = 1.0 in the above equation.

BM25 [ 8 , 24 ] is the one of state-of-the-art retrieval functions used in document retrieval. The term weights are estimated using the following BM25 based equation: where N is the total number of documents in the training set; R is the number of positive documents in the training set; n is the number of documents which contain term t ; r is the number of positive documents which contain term t ; tf is the term frequency; DL and AVDL are the document length and average document length, respectively; and k 1 and b are the experimental parameters (the values of k 1 and b are set as 1.2 and 0.75, respectively, in this paper).
 Information filtering can also be regarded as a special instance of text classification [ 28 ]. SVM is a statistical method that can be used to find a hyperplane that best separates two classes. SVM achieved the best performance on the Reuters-21578 data collection for document classification [ 43 ]. The decision function in SVM is defined as: where x is the input object; b in &lt; is a threshold and w  X  positive (negative). a i [ &lt; is the weight of the training example x i and satisfies the following constraints:
To compare with other baseline models, we tried to use SVM to rank documents rather than to make binary decisions. For this purpose, threshold b can be ignored. We also believe that the positive documents in the training set should have the same importance to user information needs because the training set was only simply divided into positive documents and negative documents. So we assign the same a i value (i.e., 1) to each positive document first, and then determine the same a i (i.e., a ) value to each negative document based on Eq. 2. Therefore, we use the following weighting function to estimate the similarity between a testing document and a given topic: where means inner product ; d is the term vector of the testing document; and For each topic, we also choose 150 terms in the positive documents based on tf*idf values for all term-based baseline models.

PTM model is also selected as one of the baselines models because we want to verify that mining negative feedback can significantly improve the performance of PTM. The maximum size of the term set T is 4000 for PTM. We also set min _ sup = 0.2 (relative support) for both PTM and N-PTM.

The performance of PTM was based on the number of closed patterns that were decided by a minimum support [ 36 ]. If the minimum support is very small, many noisy patterns can be introduced to the system; however, if it is very big then many useful patterns may be missed out. For RCV1, the total number of frequent sequential patterns is 36,202 that includes 28,733 closed patterns if min _ sup = 0.2. PTM can remove 20% of the frequent patterns if min _ sup = 0.2. In this paper, we use a fixed minimum support value, min _ sup = 0.2, suggested by [ 36 ]. 6.3 Results The effectiveness was measured by four different means: The F-beta ( F b ) measure, Mean Average Precision (MAP), the break-even point ( b / p ), and Interpolated Average Precision (IAP) on 11-points . F b is calculated by the following function: The parameter b = 1 is used in our study, which means that recall and precision is weighed equally. Mean Average precision is calculated by measuring precision at each relevant document first, and averaging precision over all topics. The b/p break-even point indicates the value at which precision equals recall. The larger a b/p , MAP, IAP or F b -measure score is, the better the system performs. 11-points measure is also used to compare the perfor-mance of different systems by averaging precisions at 11 standard recall levels (i.e., recall = 0.0, 0.1, ..., 1.0).

Statistical method is also used to analyze the experimental results. The t-test assesses whether the means of two groups are statistically different from each other. The paired two-tailed t-test is used in this paper. If DIF represents the difference between observa-tions, the hypotheses are: Ho : DIF = 0 (the difference between the two observations is 0). Ha : DIF = 0 (the difference is not 0). N is the sample size of group. The test statistic is t with N -1 degrees of freedom ( df ). If the p value associated with t is low ( \ 0.05), there means across the paired observations is significant. The N-PTM model is compared with PTM, Rocchio, BM25, and SVM models for each variable b / p , MAP , IAP , F b =1 over all the 50 topics, respectively. 6.3.1 N-PTM vs baseline models Table 4 illustrates the results of all models against the five measures for all assessor topics. Compared with PTM which uses positive documents only, the proposed N-PTM model uses both positive and negative feedback. It is obvious that N-PTM is extremely better than PTM for all five measures. The proposed model N-PTM is also compared with term-based baseline models in Table 4 including Rocchio, BM25, and SVM, which also use both positive and negative feedback as well. The results of 11-points on all assessor topics are reported in Fig. 1 .

As shown in Table 4 and Fig. 1 , the proposed new model (N-PTM) has achieved the best performance results for the assessor topics.

We also conducted the t test to compare the proposed model with all baseline models and the results are listed in Table 5 . The percentage changes are shown in Table 6 . Comparing with these baseline models, the proposed approach achieves excellent performance with 13.73% (max 17.34% and min 8.76%) average percentage change for all five measures.
These statistic results indicate that the proposed model is extremely statistically sig-nificant. Therefore, we conclude that mining negative relevance feedback for information filtering is an exciting achievement for pattern based approaches.

In the training phase, it is obvious that N-PTM and PTM use more times than other term-based models because of mining patterns in paragraphes. However, for the time complexity in the testing phase, all models take O (| T | 9 | d |) for all incoming documents d . In our experiments, the number of terms used by all models for each topic is less than 300 in average. Therefore, there is no significant difference between these models on time complexity in the testing phase. 6.3.2 Adaptive filtering In this section, we design some experiments for testing the adaptive performance of the proposed N-PTM model. We expect these experiments can achieve the consistent performance like the batch one in the last section.

For each topic, the system starts from an initial training set, then adds a window of new training documents. The size of the window set is 25. Each window of new training documents is selected randomly in the testing set. To test the robustness of the proposed model, we conduct the process of adaptive six times (six windows) for the same initial training set. Table 7 shows the results of the N-PTM models which combine new training documents with the initial one into a big training set and then train the system again.
We also test the adaptive performance of the term-based baseline models for the same settings, and found that the Rocchio model achieves the best performance. Table 8 shows the results of adaptive Rocchio models for using the six windows. The experiment results show that the adaptive N-PTM models also achieve excellent performance with 9.10% (max 12.00% and min 6.28%) average percentage change for all five measures on the assessor topics. We believe that the performance of N-PTM model is consistent and very significant for all five measures on the RCV1 data collection. 6.4 Discussion The main process of the proposed approach consists of two steps: offender selection, and the revision of term weights. It is obvious that not all negative documents are suitable to be selected as offenders, where offenders are the most useful negative documents that can help to balance the percentages of general terms and specific terms in the extracted fea-tures. Informally, the documents that have high weight are called offenders.
 Table 9 shows the statistical information for N-PTM with different values of K including the average numbers of offenders, extracted terms and their weights, and the performance. The results of 11-points on all assessor topics for the different values of K are reported in Fig. 2 . It is obvious that K  X d j D  X  j 3 e is the best one. The statistical information illustrates that the proposed method for offender selection meets the design objectives.
As mentioned in Sect. 5.2 , we used three loops to get negative specific terms in order to reduce the side effects of using general terms. Table 10 illustrates the performance of the loops used in Algorithm NFMining (up to 6 loops). The table shows that the system achieves the best result in average after the third loop.

Table 11 shows the average numbers of positive documents, negative documents, offenders and extracted terms in the training sets for the loops in the algorithm SPMining . Based on the proposed model, we set K  X d j D  X  j 3 e , that is, the number of offender documents should be equal or less than the number of positive documents. We also use loops to calculate the closeness of the offender document to the positive, such as, if a document is very closed to the positive documents it will be ranked at the top for the next loop. As shown in Table 11 the average number of positive documents is about 13 and the average number of negative documents is about 41; however, the average number of offender documents that have been selected in each loop is only 4 or 3. The table also illustrates that proposed method is much efficient for reducing the space of negative documents.

For the revision of term weights, the proposed method first classifies extracted terms into general terms and specific terms that is a distinguish advantage comparing with others [ 35 , 46 ]. The normal belief is that specific terms are more interesting than general terms for a given topic. Therefore, the proposed method increases the weights of positive specific terms when it conduces the revision using negative documents.

General terms are not only frequently appear in positive documents, but also frequently appear in some negative documents because negative documents may describe some extent to which the topic discusses what users want. To reduce the side effects of using general terms in the extracted features, the proposed method adds negative specific terms (and negative weights) into the extracted features by the loops (see Algorithm NFMining ).
Table 11 also shows the average numbers of extracted general terms # GT , specific terms # T ? and negative specific terms # T -, and their average weights. For the system, before terms although the percentage of general terms is 31 : 8 %  X  50 50  X  107 for all extracted terms in positive documents.

After revision, 126 negative specific terms are added into T in average for the system (see Table 11 ), and they are assigned weight -26.54 in average. In this way, these negative specific terms could reduce the side effects of general terms if both general terms and negative specific terms appear in negative documents because now only 45 %  X  56 : 04 26 : 54  X  36 : 33 weights could be distributed to general terms considering positive specific terms get weight 36.33 in average and general terms get 29.5 = 56.04 -26.54 in average.
The above analysis illustrates that the proposed algorithm for finding negative specific terms meets the design objective for reducing the side effects of using general terms. 7 Conclusions Negative relevance feedback is very useful for information filtering. However, whether negative feedback can largely improve filtering accuracy is still an open question. This paper presents a pattern mining based approach for this open question. It introduces a method to select negative documents (or called offenders) that are close to the extracted features in the positive documents. It also proposes an approach to classify extracted terms into three groups: positive specific terms, general terms and negative specific terms. In this perspective, it presents an iterative algorithm to revise extracted features. Compared with the state-of-the-art models, the results of experiments on the RCV1 data collection dem-onstrate that the effectiveness of information filtering can be significantly improved by the proposed new approach, and the performance is also consistent for adaptive filtering. This research provides a promising methodology for evaluating term weights based on dis-covered patterns (rather than documents) in both positive and negative relevance feedback. References
