 Under large scale data, machine learning becomes inefficient. In order to enhance its performances, new methodologies should be adopted. Taking video retrieval as an example, we discuss its two basic problems: representation and classification problems. 
In spite of the form (text, image  X  speech, or video) of information there always exists a big semantic gap between its low-level feature based machine representations and the corresponding high-level concepts used by users, so the traditional single feature machine representation is not available under large scale data. To deal with the problem, the multi-modal and multi-granular representation is introduced. The reasons are the following. On the one hand, the representations from different modalities of the same video such as speech, image, and text may complement each other. On the other hand, a coarse representation of one modality, for example the global feature of an image such as color moment, color correlagram and global representation, a representation with small grain-size, such as a pixel-based representation of an image has a good expressiveness but a poor robustness. Both expressiveness and robustness are needed in machine representation. Therefore, the multi-granular representation in one modality may solve the contradiction among them. We present a set of experimental results in image (and video) retrieval to show how the multi-modal and multi-granular representation improves the performances of machine learning. 
By machine representation, a video (text, speech or image) will be translated into a vector (point) in a high dimensional feature space generally. Then information processing becomes a set of operations on a point set of the space. And the supervised machine learning becomes the classification of a set of points. By using multi-modal and multi-granular representation it means that the number of dimensionality of the feature space increases. It improves the learning performance but increases the computational complexity as well. This is so called dimensionality curse in machine learning. When the size of data increases, the problem becomes more serious. The general methodology used is the multi-classifier strategy. In the multi-classifier system, each classifier has its own classification criterion and input feature set. classifiers, that is, the information fusi on problem. There have been many different information fusion approaches so far. Secondly, the multi-classifier is used in a hierarchical way, that is, multi-level classifiers. In the multi-level classifiers, a set of data is divided into a collection of subsets first and then each subset is further divided computational complexity can be reduced greatly. We will show some experimental results to verify the above statement. Thirdly, new efficient learning algorithms should be invented. Although there have been many learning algorithms recently the performance of most of them worsen when facing large scale data. We will present some learning algorithms that have rather good performances when dealing with the large scale data. 
In conclusion, multi-modal and multi-granular learning is a new methodology inspired by human intelligence. The cognitive power in human learning consists of a set of resourceful strategies such as multi-modal, multi-granular representation, multi-feature fusion, and hierarchical structure, etc. In order to improve the machine learning, it should integrate both the cognitive power of human learning and the computational power of computers. Mr. Bo Zhang graduated from Dept. of Automatic Control, Tsinghua University in 1958. He is now a professor of Computer Science and Technology Department, Tsinghua University, Beijing, China, the member of Chinese Academy of Sciences. and pattern recognition. He has published about 150 papers and 3 monographs in these fields. Mr. Ling Zhang graduated from Dept. of Mathematics, Nanjing University, Nanjing, China in 1960. He is now a professor of Dept. of Computer Science, Anhui University, Hefei, China and the director of Artificial Intelligence Institute, Anhui University. His main interests are artificial intelligence, machine learning, neural networks, genetic algorithms and computational intelligence. He has published more 
