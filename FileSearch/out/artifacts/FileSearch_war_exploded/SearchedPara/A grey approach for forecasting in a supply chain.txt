 Avinash Samvedi, Vipul Jain n 1. Introduction
The mad rush to make the supply chains better, faster and cheaper is making the chain increasingly complex, interdepen-dent and risky. Since the early 1990s, many firms have imple-mented various supply chain initiatives to increase revenue, to reduce costs, and/or to reduce assets. This single minded focus on improving efficiency is having adverse impact on the fragility and vulnerability of supply chains ( Craighead et al., 2007 ; Wagner and
Bode, 2006 ). All this has made managing supply chain risks a challenge that it was never before. It is worth mentioning that today supply continuity is the single biggest business driver, whereas in the past, supply chain managers were mainly con-cerned with reducing cost, reducing purchase price variance, and managing inventory. This is due to the frequent disruptions a supply chain encounters on a regular basis. Supply chain disrup-tions are  X  X  X nplanned events that may occur in the supply chain which might affect the normal or expected flow of materials and components X  X  ( Svensson, 2000 ). Disruption does not only halt the supply chain operations, but without preparation and precaution it takes time for the affected system to recover ( Sheffi and Rice, 2005 ; Hendricks and Singhal, 2005 ). To effectively deal with these risks, there have been calls for  X  X  X esilience X  X  ( Sheffi and Rice, 2005 ) or  X  X  X obustness X  X  ( Tang, 2006 ).

The impact of supply chain disruptions has led to a growing interest in the area of supply chain risk and its management, as evidenced in the number of industry surveys, practitioner conferences and consultancy reports devoted to the topic ( McKinsey, 2008 ).
Adding to situation is strong evidence that catastrophic events such as earthquakes, floods, tornadoe s etc. are becoming more frequent ( Coleman, 2006 ). Elkins et al. (2005) observed that there has been an increase both in the potential for disruptions and in their magnitude.
Supply chain executives in IBM believe that supply chain risk management (SCRM) is the second most important issue for them ( IBM, 2008 ). Also, the research by AMR in 2007 reported that 46% of the executives believe that better SCRM is needed ( Hillman and Keltz, 2007 ). However, as evident from ( McKinsey, 2008 ), few companies have taken commensurate actions.

Risks occur because we can never know exactly what will happen in the future. We can use the best forecasts and do every possible analysis, but there is always uncertainty about future events ( Waters, 2007 ). Fueled by an increasingly dynamic busi-ness environment and growing availability of advanced software and tools, demand forecasting has gained an elevated importance among practitioners in recent years ( Hsu and Wang, 2007 ; Wang, 2002 ). Today, companies spend billions of dollars annually on software, personnel and consulting fees to achieve accurate demand forecasts ( Aiyer and Ledesma, 2004 ). From a broader supply chain perspective, accuracy of a firm X  X  demand forecast is important not only for itself but also for its partners because the quality of forecasts often affects the performance of the entire supply chain, including vertical partners as well as horizontal competitors ( Chen, 2003 ). This work is an effort towards making the supply chain resilient by studying the robustness of different forecasting methods under stable and disruption situations. The methods considered here are moving average (MA), weighted moving average (WMA), exponential smoothing (ES) and grey prediction method (GPM). Although there are several other sophis-ticated methods available, the first three methods have been picked up because of their extensive use in the industry, simply because of their ease of use. The last method GPM has never been tested in the supply chain disruption situation, even though it has been used in similar situations before Wang (2002) , Hsu (2011 ). This made the method an exciting prospect for this study.
The rest of the paper is organized as follows. Section 2 describes the problem being considered here and also reviews the literature on supply chain disruptions and different demand forecasting methods, specifically the grey prediction method. Section 3 gives a brief introduction to the preliminaries of grey theory and grey prediction method. Section 4 describes the simulation set-up used for the current study. Section 5 analyses the results obtained from the simulation runs and discusses their significance in detail. Finally, Section 6 concludes the paper with fut ure research directions. 2. Problem description
A significant feature of the rapidly evolving business climate spurred on by significant technology shifts, innovation, communica-tion technologies and globalization, is the increasing prevalence of risk in almost every aspect of our lives ( Wu and Blackhurst, 2009 ). This has led to a significant increase in the risks faced by the supply chains today. These risks are further enhanced by the outsourced production to overseas locations, extended supply chains, the number of nodes increased, and the increasing complexity of the networks. This results in supply chain players becoming increasingly more coupled, in the sense that decisions taken by one firm in a supply chain directly affects the performance of other firms. One very important aspect of coupling in the context of supply chain is the forecast developed by various part ies in the supply chain. Reduction in forecasting errors, at any stage of a supply chain, helps in vastly improving the demand supply matching ( Zhu et al., 2011 ). From the literature, studies of combined statistical methods have shown better results than individual methods for both forecast accuracy improve-ment and lower forecasting risk ( Hibon and Evgeniou, 2005 ). In Smith and Wallis (2005) , analysis of combining methods using a simple average was explored, where combined methods showed better results than individual methods ( Clemen, 1989 ). Colloby and Armstrong (1992) proposed a rule-based forecasting technique that analyzes time series by combining four extrapolation methods based on some predefined rules. This technique improved the forecast accuracy.

Overcoming the challenges involve d in creating a credible forecast is an incredibly daunting task for most forecasters. There is a constant flow of new products, promotions and changing channels of distribu-tion ( Helms et al., 2000 ). Most of traditional methods for dealing with the predictive problems include si mple regression, multivariate regression, time series analysis, etc. Although these models have the advantage of accurately describing the phenomenon of long-term trends, they have the limitation of requiring at least 50, and preferably 100 or more observations in order to construct the model. Due to the requirements of our society and the rapid innovation in new technologies, we usually are able to make only a few observa-tions within a short time span to forecast future situations in order to formulate a  X  X  X uick response X  X  ( Wang and Hsu, 2008b ). The same requirement arises during the disruption situations as the firms have very little data of the situation and the forecasts should be made using them. Also the forecasting methods are severely tested during disruption situations and forecast ing accuracy takes a hard hit. In recent years, to overcome these short comings, artificial intelligence was proposed to amend traditional forecasting methods.
Artificial intelligence analysis including the artificial neural net-work ( Liang, 2007 ), fuzzy theory ( Lee et al., 2007 ; Wang and Hsu, 2008a ) and grey theory ( Huang et al., 2007 ) are often used to solve traditional forecasting method s. Grey forecasting theory is an important technique in the grey th eory, and it uses approximate differential equations to describe f uture tendencies for a time series. It has the advantage that it can be used in circumstance with as few as four observations in a prediction process ( Chen and Chang, 1998 ). Grey theory, a non-traditional for ecasting technique based on scarce and fuzzy information, was proposed in 1982 by J.L. Deng. The first-order one-variable grey model, GM (1, 1), is the most widely used and is successfully demonstrat ed in many applications such as electricity demand forecasts ( Huang et al., 2007 ), stock market prediction ( Wang, 2002 ), tourism forecast ( Yu and Schwartz, 2006 ), integrated circuit industry output forecasts ( Hsu and Wang, 2007 ), and optoelectronics industry output forecasts ( Chang, 2005 ). In order to increase the grey model accuracy of forecast, many improved versions of GM (1, 1) model were established ( Hsu and Wang, 2007 ; Hsu, 2009 ; Huang and Wang, 1997 ). 3. Grey prediction method
Grey theory is a truly multidisciplinary and generic theory that deals with systems that are characterized by poor information and/or for which information is lacking. The fields covered by grey theory include systems analysis, data processing, modeling, prediction, decision making and control. Grey forecasting models have been extensively used in many applications. The GM (1, 1) is one of the most frequently used grey forecasting model. This model is a time series forecasting model, encompassing a group of differential equations adapted for parameter variance, rather than a first order differential equation. Its difference equations have structures that vary with time rather than being general differ-ence equations ( Chen, 2003 ).

Prediction is an action based on d iscussions and studies of the past to tell about the future. Grey predi ction is based on some theoretical treatment of the original data and establishment of grey models of the data to discover and to control the development laws of the system of interest so that scientific q uantitative predictions about the future of the system can be made ( Liu and Lin, 2006 ). A grey system is a system with characteristics between white and black ones ( Deng, 1982 ). This implies that the grey system has the characteristics to deal with situations where only partial information is available. The grey model (GM) is one of the best features in the grey system theory. Generally, the grey model is written as GM ( m , n ), where m is the order and n is the number of variables of the modeling equation. GM (1, 1) and GM (1, N ) models are more commonly used in the forecast model. Conventional modeling techniques use the given data directly to construct a model to approximate the output behavior of the system. The grey system, however, is based on the accumulated data to establish the model ( Huang and Wang, 1997 ; Deng, 1989 ).
The most commonly used grey model is the GM (1, 1) model, which indicates one variable and one order grey forecasting model. The general procedure for a grey forecasting model is derived as follows ( Hsu, 2011 ).
 Step1 : Establish the original data sequence from observed data Step2 : Generate the first-order accumulated generating opera-
Step3 : Calculate the background value z (1) ( k ), by means of opera-
Step4 : The first-order differential equation of GM (1, 1) and its
Step5: Calculate development coefficient  X  a  X  and grey input  X  b  X . By
Step6: The solution of the whitening equation is
Step7: The recovered data ^ x  X  0  X   X  k  X  can be retrieved by the inverse 4. Simulation setup
The Beer Distribution Game is a role-playing simulation of an industrial production and distribution system developed at MIT to introduce students of management to the concepts of economic dynamics and computer simulation. In use for nearly five decades, the game has been played all over the world by thousands of people ranging from high school students to chief executive officers and government officials ( Croson and Donohue, 2006 ). There are two partsinthisstudy. 1. Two stage scenario: This study first performs the experiments on a two stage scenario, where there is only a customer and a retailer. The study assumed the availability of unlimited supply for the retailer. This simplified scenario helps in bring-ing out the difference in performance of the forecasting methods, without being cluttered by the effect of other factors prevalent in a much complex supply chain. The demand model used for this scenario is given as U[20 X 40]. 2. Four stage scenario: After the above part is completed, we move on to a much realistic situation of the beer game that is a four stage supply chain scenario. Here we analyze the perfor-mance of forecasting methods under all the relevant factors.
The four stage problem of the beer game is a single-product supply chain that includes a retailer, a wholesaler, a distributor and a manufacturer. The system is depicted in Fig. 1 . The demand stream is shown in blue colour and supply stream in maroon colour. The demand from the customer end is gener-ated at retailer. The retailer demands from wholesaler, who in turn demands from distributor and at last distributor demands from the manufacturer. The manufacturer places the order to its shop floor and thus the supply starts downstream. All the players in a supply chain are vulnerable to disruptions and the failure of a single player to perform its duties affects the overall operations of the chain significantly. When a player fails all kinds of flows in the chain are disrupted and all incoming and outgoing flows through that player are stopped.
This study considers only one type of disruption, which is the disruption in demand at the retailer level. This is done by increasing the demand suddenly to 5 times (value randomly chosen such that it is big enough for the experiments results to be clearly visible) of the stable demand. Demand is U(40, 60). This means that values 40, 41, 42, y , 60 are equally likely in any given period Furthermore, in this research, we have considered fre-quency and duration as two parameters, for the modeling severity of disruptions. The longer the run periods, the less frequent and slighter are the disruptions. Contrarily, the longer the failure periods, the longer the disruptions last and thus are more severe.
Theperiodicreviewinventorypolicy( r , S ) has been adopted at each tier of the chain, where r is inter-review period and S is order-up-to level. This policy means that, after every period of time r ,the retailer reviews its inventory po sition and orders an appropriate quantity of products from the supplier such that inventory position is increased to the order-up-to level S . The policy considered here is to add outstanding orders to the current inventory levels and deduct the backorders from the sum. Outstanding orders stand for the orders that have been placed to the supplier but have not yet been received by the retailer. If this value is less than the maximum inventory level then the order is placed. This polic y is adopted to stop reordering for the same demand again and again. Sometimes, although the inven-tory level is less than maximum level, the order has already been placed. This happens due to the cycle lead time between placing the order and receiving the goods.

A simulation model for the beer game has been developed in the MATLAB platform. This is a discrete event simulation with four events namely demand, supply, disruption and inventory review. The simulation starts from an initial pre-defined state with demands and supplies between levels scheduled. The whole process is a combination of weekly cycles involving these events.
A cycle is described in the steps below. (a) The simulation kicks off with first demand from the customer end. During the demand process the player checks if there are (b) Supply event is simpler and requires just the updating of the (c) Inventory review event is called after a fixed review period for (d) Disruption events are scheduled according to the predefined
It is to be noted that all variables follow a continuous distribution in this study. The impact on the system by disrupting the demand in atwostagesystemisstudiedfirst.Thisisfollowedbystudyingthe performance of four tiers of the cha in, in beer game settings, in stable and disrupted conditions. The mean absolute percentage error (MAPE) has been used as the performa nce measure for the forecasting methods. Only in the conditions when it is not feasible to use this measure, such as when the actual value is  X 0 X , the mean absolute error (MAE) is used.

In the simulation study performed in this paper, there is a separate function for demand generation. This function plays the pivotal role, as it generates demand as a uniform random variable in a given interval and is responsible for creating the disruption conditions. This demand generation function can be set to randomly switch over to the disruption conditions in which the demand is increased five times. This switch can be performed suddenly, say in one step or can also smooth out the transition by switching in a number of steps as provided by the user. The disruption duration and disruption frequency, both can be set as a function of the total run duration and can be varied as required.
For a two stage chain no inventory levels, backorders or out-standing orders has been considered. This is done to keep the things simple, and focussed on only the difference in performance of forecasting methods. All unfulfilled demand is considered to be lost and all leftover inventory is written off. It is a weekly affair similar to newsboy problem. On the other hand in the four stage problem, initial inventory level at each of the player is set to mean of demand interval, suppose M .Alsoademandof M units is scheduled for the first day on each player. The supply lead time has been taken as 1 week and order processing time as 1 week. Initially a supply of M units is scheduled for the next week on each player. An inventory review is scheduled to take place during the first week. Later we will warm up the simulation model to re move the influences these initial settings may bring about. Maximum inventory level has been defined as a constant multiple of product of lead time and average demand. The demand varies between 40 and 60 units. The warm up time is kept as 100 weeks in total run duration of 1000 weeks. The simulation is run for 5 iterations for each scenario. 5. Results and analysis
The case considered here is of a major textile company based in India. For reasons of confidentiality the company named is kept anonymous. The company is in process of overhauling its supply chain network, specifically targeting the reduction of overall risks it faces. It is worthwhile to note here that the company faced a major disruption a couple of years back due to the steep rise in the prices of cotton, which is a major input to the company X  X  products. The huge losses faced by the company shook the higher management and they took a strategic decision of investing in risk reduction policies so that the effect on the company can be reduced in wake of any such future events. The demand model associated with this case is used for the experimentation.
The results shown in this section compares the performance of grey prediction method to other established forecasting methods such as moving average, weighted moving average and exponen-tial smoothing. The comprehensive results obtained by running the simulation for 5 iterations of 1000 weeks each have been summarized in the tables. The data for the first 100 weeks was discarded and was considered to be warm up time. This was done to ensure the model remains free of the effect of initial conditions. The data used for results was from the static state of the system. The model was run for a total of 1000 weeks and the weeks from 500 to 550 were used for all figures in the results section. This was done because the said range lies almost at the centre of the entire run length.

Figs. 2 X 5 shows the comparison between the four forecasting methods and the actual demand at the retailer level in a two stage supply chain. Fig. 2 shows the situation when there is no disruption. The demand is uniform in the interval [20, 40]. As we can see from Fig. 2 that the MA and WMA methods do not respond to the changing demand much and mostly tread around the mean value of 30. We can deduce from Fig. 2 that when the values hover around some mean and specifically when the interval is small these two are actually the best choice for forecasting. We can also see that the other two methods ES and GPM, respond very fast to the changing demand. We can infer from this property of ES and GPM methods that they will come handful in the situation when the values do not linger around the mean like during disruptions.

Fig. 3 shows the situation when the demand is frequently disrupted in the sense that the mean value goes five times up during disruption times. It can be seen that the MA and WMA methods again try to find a mean value which in this case is somewhere between the stable mean and the disruption demand mean, depending on how frequently it is disrupted. The other two methods move from one point to another trying to chase the demand. The one property of GPM to notice here is the tendency to overshoot whereas the exponential smoothing does not. The same was observed in Fig. 2 in ES case, but GPM also did not overshoot then. This tendency to overshoot is not consistent and is random in nature.

As mentioned in the literature that in the real situations the disruptions seldom come as a sudden shock but in a gradual manner. Thus, as a next situation in this study, whenever the demand is disrupted the demand is taken to the disruption level in 3 steps gradually rather than in 1 step. The effect can be seen in Fig. 4 .

The shape of MA and WMA has changed and they are also trying to match the actual demand. The tendency of GPM to overshoot is more consistent in this case. But in any case the ES and GPM methods are mostly behind the actual demand. GPM method because of its overshooting property can be seen to sometimes predict the actual demand correctly as the demand is also moving upward. This tendency becomes more pronounced and helpful when the number of gradual steps is increased to 10. This is shown in Fig. 5 .

The GPM method for the first time beats the ES method in this case. When we increase the number of steps taken to reach the peak disruption point, we can see from the graph that MA and WMA methods also get the time to follow the demand up to the peak. The GPM method starts to score over the exponential method as we can see from the values. This can be attributed to the fact that the GPM method has the tendency to overshoot the new demand while ascending or descending. It actually helps in forecasting better as the demand itself is moving in that direction. We can see from the graph that there is a significant overlap between demand and GPM curves than with other methods.
We can clearly see from the results given in Table 1 that as the disruptions frequency increase, there is an overall increase in the value of forecasting error percentage. The amount of increase is though different in each case. MA and WMA are the best methods when there is no disruption, but their performance is quickly beaten by the other two methods in even low frequency of disruption. The difference which is seen, as we move to higher frequency of disruption is the emergence of GPM as the best method. We can conclude from these results that GPM is the best method when the disruptions are frequent. This can be attributed to the property of GPM to overshoot the value of last demand and thus actually helps in forecasting pretty accurately as the demand is also increasing.

This result is especially profound when the number of steps in which the system reaches to the disrupted state is sizeable. This point is clarified by performing some experiments with different number of steps with a high frequency of disruption. The results are given in Table 2 . We can also see form the table that the forecasting error reduces as we increase the number of steps. This is due to the fact that the method gets time to adjust to the changed scenario.

Now the four methods have been tested in the beer game, which is said to very closely simulate the process of supply chain. The performance of forecasting methods is tested in both situations namely when there is no disruption and when there is. The demand model used in this scenario is U[40 X 60]. One thing which we can notice immediately from Fig. 6 is that even when there is no disruption the bullwhip effect creates the disruption type situation in the upstream tiers. Thus, the ES and GPM methods seem to be more useful even without disruptions. The difference in the bullwhip generated situation and the real disruption situations is the fact that even though because of bullwhip the demand variations increases as we move upstream, the values hover around a mean. Therefore, even MA and WMA give acceptable results.
Table 3 shows a general decrease in the forecasting accuracy as we move upstream. Although the decrease is less profound as we move from the distributor to the manufacturer. The forecasting accuracy even increases in case of ES and GPM methods. This can be attributed to the fact that although the demand variation is the largest at this level there is the comfort of assured supply from the source side. It can be deduced from Table 3 that if a firm is upstream in the chain, ES and GPM seems to be better methods for forecasting, even in stable situations.

Fig. 7 shows the performance of forecasting methods during disruption situation and also highlights the overlapping of dis-ruption and bullwhip effect. Adding to that is the filtering of disruption added by the inventory policy. A major portion of the demand can be seen at either the maximum inventory level of 150 or at 0. This helps in containing the extremes of fluctuations under a manageable limit.

From Table 4 it is evident that ES is the best method during frequent disruptions, in upstream tiers. ES easily beats out the
GPM in this case in the upstream levels because of the violent fluctuations in the demand. There is no impact reduction steps involved and the demand sways from one extreme to the other (the amplitude of extremes is controlled by inventory policy).
GPM remains the best method for the retailer level This is because even though the effect of impact reduction steps is nullified in upstream tiers, by inventory policy and bullwhip effect, it remains intact for the retailer stage. Another point to be deduced is the increase in forecasting accuracy as we move upstream. Again this can be attributed to the control exercised by the inventory policy.
Therefore, it can be concluded that MA and WMA are the best methods for the retailer level forecasting when there is no disruption. This should be changed to GPM during disruptions.
For all other levels GPM and ES gives better results during stable times and can be used interchangeably. When during disruptions
ES seems to be the better choice. 6. Conclusion
With an increasing awareness of risk management issues, both from industrial and academic aspects, we believe that developing risk management models should improve a supply chain compe-tence in the new business environment. Even though risk cannot, and may be should not, be completely eliminated, all the tools that lead to some mitigation constitute a source of sound practice for risk management. In this study, performance of four forecast-ing methods (moving average, weighted moving average, expo-nential smoothing and grey prediction method) during disruptions in a supply chain is studied. The tests were performed in two different settings namely two stage and four stage supply chain. The results show that moving average and weighted moving average methods become incompetent during disruptions and are useful only during stable times, when the demand hovers around some predefined mean value. Grey prediction method turns out to be the best method, when the frequency of disruption is at least high, as well as the impact of disruption is reduced by inducing the disruption gradually. From the common experience it can be stated that the disruption normally builds up gradually and seldom comes suddenly. On the other hand the disasters strike suddenly and supply chains are normally shocked by their impact. Also it is a well known fact that it is not possible to prepare for disasters and hence the current study deals only with disruptions. Hence, from the above results grey prediction method can be said to be the best performing method during disruptions. Also it can be deduced that the upstream tiers experience huge fluctuations in demand due to the bullwhip effect and hence exponential smoothing and grey prediction method again score over the other two methods even during stable times. Thus it can be stated that as the part of risk management in supply chain each level in the chain should have different forecasting methods.

From the results it can be seen that none of the forecasting method is the best for every situation. We have different methods performing better in different situations. Thus the question which arises is that whether a forecasting policy can be derived as an integration of these methods, which will give an acceptable level of performance in every situation. Also we have seen the effect of inventory keeping policy on the results. Because of the maximum inventory policy the impact of disruption was somewhat reduced in the upstream tiers. But the problem was the huge bullwhip effect this policy caused during stable situations. A policy which subdues bullwhip effect and also help to mitigate the impact of disruption can be of great value to the firms. A way of doing this is through collaborative forecasting. The performance of collabora-tive forecasting during supply chain disruptions is another pro-mising area to go through. Although it is very clear that it is not possible to completely nullify the disruption effect on supply chains, any area promising to give us a step towards achieving this goal is worth the effort.
 References
