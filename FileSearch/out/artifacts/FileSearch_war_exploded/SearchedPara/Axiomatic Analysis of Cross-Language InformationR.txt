 A major challenge in Cross-Language Information Retrieval (CLIR) is the adoption of translation knowledge in retrieval models, as it affects the term weighting which is known to highly impact the retrieval performance. In this paper, we present an analytical study of using translation knowledge in CLIR. In particular, by adopting axiomatic analysis frame-work, we formulate the impacts of translation knowledge on document ranking as constraints that any cross-language re-trieval model should satisfy. We then consider the state-of-the-art CLIR methods and check whether they satisfy these constraints. Finally, we show through empirical evaluation that violating one of the constraints harms the retrieval per-formance significantly which calls for further investigation. H.3.3 [ Information Search and Retrieval ]: Retrieval Models Cross-Language information retrieval; axiomatic analysis; language modeling framework; structured query
Cross-Language Information Retrieval (CLIR) allows users to formulate queries in one language, usually their native language, in order to seek information in another language. Therefore, some sort of translation is needed to cross the lan-guage barrier between the query and the documents. Machine-readable bilingual dictionaries do not provide suf-ficient coverage for CLIR due to out of vocabulary words and neologisms. To compensate this deficiency, CLIR ap-proaches tend to use learned translation probabilities from other translation resources, such as bilingual corpora, to achieve acceptable performance. Thus, employing word trans-lation probabilities, referred to as a translation model , are essential to improve the CLIR performance.

Using translation models in retrieval approaches is one of the major challenges of doing CLIR [14]. This is because translation models impact retrieval heuristics, e.g. Term Frequency (TF) and Document Frequency (DF), which, in turn, substantially affect the retrieval performance. The im-pacts of retrieval heuristics on the performance of monolin-gual retrieval models are studied in [5], where it is referred to as axiomatic analysis of retrieval models. In this analysis, the desirable impacts of retrieval heuristics are formulated as constraints that any reasonable retrieval model should sat-isfy. However, to the best of our knowledge, the impact of translation models on retrieval heuristics in cross-language environments has not been studied yet.

Following the axiomatic analysis, we define specific con-straints to regulate the utilization of translation models into cross-language retrieval models. More specifically, we aim to address three questions: i) How do constraints on usage of retrieval heuristics in monolingual retrieval models extend to cross-language ones? ii) Are there any additional con-straints specific to cross-language retrieval models? iii) Can we further improve the state-of-the-art CLIR models based on analytical evaluation? We investigate these questions through following contributions: 1. We propose three constraints that a reasonable CLIR 2. We investigate the validity of these constraints on the Background. The goal of CLIR is to score a document D in a collection C with respect to a query Q in another language than that of D . Here, we discuss two CLIR mod-els which seek to optimize the retrieval effectiveness when reliable translation probabilities are available.

PSQ method. The first method is Probabilistic Struc-tured Queries (PSQ) [4] in which translation probabilities are considered in TF and DF computations as follows: where w t  X  V t is a term belonging to the vocabulary set of the target language (the language of documents), q i  X  Q is a query term, and p ( w t | q i ) is the probability of translating word q i into word w t . These TF and DF estimations are then used in BM25 retrieval model to score document D w.r.t. query Q .

LM-based. In this method, the translation model can be integrated into either the query or the document language model [13]. Here, we only mention the Query Translation approach because it has been the dominant approach due to its efficiency. In query translation approach, a new language model is built for the query and documents are ranked using: where S( Q,D ) is the similarity score between query Q and document D , w s and w t are source and target words respec-tively, and p ( w t | w s ) indicates the probability of translating the source word w s to the target word w t .

Related work. Axiomatic analysis, introduced by Fang et al. [5, 7], is based on formal constraints that any reason-able retrieval model should satisfy. Several constraints are defined for different factors impacting the retrieval perfor-mance, such as term frequency, document frequency, docu-ment length [5, 7, 12, 11], semantically related terms [8, 9], feedback information [3], term proximity [16], and evalua-tion metrics [1, 2]. All these studies focus on investigating monolingual retrieval models.

Although there is a substantial body of research on analyt-ical study of monolingual retrieval models, the correspond-ing literature on cross-language retrieval models is very thin. Indeed, to the best of our knowledge, the only relevant stud-ies are [10, 7]. But, none of these studies fulfills our goal in this article, which is to define formal constraints specific to any reasonable CLIR model. In particular, [10] adopted the corrected BM25 retrieval model, proposed in [7] for mono-lingual retrieval through axiomatic analysis, for document ranking in CLIR. The proposed constraints in [9] are to regulate the estimation of relations between words in one language.
We start our analytic evaluation of CLIR models by defin-ing basic constraints on the use of translation models. Before proceeding to formal constraints, let us define some nota-tions. For a document D and a term x , | D | is the length of D , c ( x,D ) is the count of x in D , and DV( x ) is the discrim-ination value of x which can be estimated by a measure like the inverse document frequency .
The first constraint targets queries in which query terms have different numbers of translation alternatives in the tar-get language, in particular when query terms are not am-biguous and translation alternatives are synonyms. Fig-ure 1(a) illustrates this constraint, where the goal is to figure out the reasonable relative scores for documents in language l w.r.t. query Q = { q 1 q 2 } in l 2 . Two documents D 1 in the figure have equal occurrences of translations of query terms, t 1 1 and t 2 1 respectively. Assume that these translations have the same discrimination value. Considering translation probabilities, p ( t 1 1 | q 1 ) &gt; p ( t 2 1 | q 2 ), D the query, because it contains t 1 1 . However, the lower prob-ability for t 2 1 compared to t 1 1 may be due to the presence of two synonymous translations for q 2 compared to only one translation for q 1 . In this case, weighting based on transla-tion probabilities will artificially enhance query terms with fewer synonym translations, which the following constraint intends to avoid.
 CL-C1: Let Q = { q 1 q 2 } be a two-term query. Assume that p ( t 1 1 | q 1 ) =  X  , p ( t 2 1 | q 2 ) =  X  , p ( t | D query terms do not occur in these documents. If q 2 is not ambiguous and its translations, t 2 1 and t 2 2 , are synonyms or related words, then S ( Q,D 2 ) &gt; S ( Q,D 1 ).

Considering that t 2 1 and t 2 2 are synonyms, we can say that p ( t 1 | q 2 ) =  X  +  X  which is greater than p ( t 1 1 | q 1 ). Therefore, CL-C1 assigns a higher score to D 2 compared to D 1 . The constraint states that p ( t 1 1 | q 1 ) &gt; p ( t 2 1 | q ily imply that t 1 1 is a more important word than t 2 1 in the translated query. This can happen because q 2 has more syn-onymous translations in the target language compared to q In this case, it is necessary to consider synonym or related translations of a term.
The TFC3 constraint for monolingual retrieval models im-plies that  X  X f two documents have the same total occurrences of all query terms and all the query terms have the same term discrimination value, a higher score will be given to the document covering more distinct query terms X  [6]. Our goal is to extend this constraint to CLIR models where oc-currences of query terms are determined using a translation model.

The second CLIR constraint is about the coverage of translations of distinct query terms. For illustration, con-Table 1: Performance of CLIR models on selected queries from Ham X 08 &amp; Ham X 09 CLEF topics.
 Method RUN MAP (% All) P@10 R@1000 LM-Based sider the example in Figure 1(b), where t 1 1 and t 1 2 occur in document D 1 with the same total number as the occurrences of t 1 1 and t 2 2 in document D 2 . But, D 1 covers only the trans-lations of one query term q 1 while D 2 covers the translations of both query terms q 1 and q 2 . Assuming t 1 2 and t 2 same discrimination value, D 2 should get a higher score since it covers translations of more distinct original query terms.
CL-C2: Let Q = { q 1 q 2 } be a two-term query. Assume two translations of query terms have the same translation probability and discrimination value, i.e. p ( t 1 i | q 1 and DV( t 1 i ) = DV( t 2 j ). Also, suppose | D 1 | = | D c ( t k ,D 1 ) = c ( t 1 k ,D 2 ) where t 1 k is a translation of q query terms do not occur in these documents, then S ( Q,D 2 ) &gt; S ( Q,D 1 ).

Consider two documents that have the same total occur-rences of translations of query terms and the same coverage of different translation alternatives of all query terms. Ac-cording to CL-C2, the document that covers translations of more distinct original query terms should get a higher score.
The third constraint is about the coverage of different translation alternatives of a query term. As an illustration, consider the example in Figure 1(c). Two documents D and D 2 have the same total occurrences of t 1 and t 2 , which are translations of q with equal probabilities. But, D 2 covers two distinct translations of query term q , while D 1 covers only one translation of q . Assuming that t 1 and t the same discrimination value, D 2 should get a higher score w.r.t. query Q .

CL-C3: Let Q = { q } be a query. Assume that two translations of q have the same translation prob-value, DV( t 1 ) = DV( t 2 ). Also, suppose | D 1 | = | D c ( t 1 ,D 1 ) = c ( t 1 ,D 2 )+ c ( t 2 ,D 2 ), c ( t 2 ,D 1 ) = 0, c ( t c ( t 2 ,D 2 ) &gt; 0 and other translations of query terms do not occur in these documents, then S ( Q,D 2 ) &gt; S ( Q,D 1
This constraint can be derived based on the concavity of scoring functions (see constraint TFC2 in [6]). CL-C3 is merely a tiebreaker rule when t 1 and t 2 are synonyms. On the other hand, the  X  X ne sense per discourse X  heuris-tic suggests that having translations of both meanings of a homonomous query term in the same document would be rare. Therefore, the previous two constraints are more im-portant to be satisfied by a retrieval model compared to this constraint.
Neither the PSQ nor the LM-based method satisfies CL-C1, because these methods do not consider the effect of dif-ferent numbers of translation alternatives. In the sequel, we show that not satisfying CL-C1 constraint harms the CLIR performance.

Data sets and experimental setup. Experiments are done using Hamshahri collection consisting of 166,774 documents in Persian with two sets of CLEF topics, 551-600 and 601-650 in Persian and English. Translation model is trained using the GIZA++ toolkit on TEP , a sentence-aligned English-Persian parallel corpus extracted from movie subtitles [15]. In both Hamshahri and TEP collections, stop-words are removed, Persian words are normalized by re-placing all orthographic variations of letters by one form, and English terms are stemmed using Porter stemmer. We use the title of topics for the evaluation. All experiments are done using the Lemur toolkit. Mean Average Precision (MAP), Precision at top 10 documents (P@10), and Recall at 1000 documents (R@1000) are reported.

Parameter setting. For CLIR using LM-based model, we smooth document language models using Dirichlet Prior smoothing and do not tune the smoothing parameter  X  which is set to the default value of 1000. For retrieval us-ing the PSQ method, we use parameter values as k 1 = 1 . 2, b = 0 . 75, and k 3 = 7 [17].

Impact of synonymous translations. The goal here is to show the importance of how to use word transla-tion probabilities when query terms have different numbers of synonymous translations in the target language. After training using the parallel corpus, we impose a probability threshold of 0.1 to build a translation model. We then ask two volunteers, who are not involved in this work, to manu-ally separate queries in which the query terms have different numbers of synonymous translations in the devised transla-tion model. Twenty seven topics are selected out of 100 CLEF topics. In the following experiments, we want to use these selected topics to study the effectiveness of using all translation alternatives for each query term, where: 1. each translation is weighted according to the devised translation model. 2. we consider the most probable translation with proba-bility one and consider all other translations as instances of the most probable translation.

In item 1, the importance of each translation is determined according to its translation probability in the translation model. This usual strategy of using translation models in CLIR is referred to as  X  X ll X  in the experiments. On the other hand, in item 2, all translations of all query terms are considered as equally important. Runs using this strategy are denoted by  X  X yn X  .

Table 1 shows the performance of PSQ and LM-based re-trieval models on the selected queries. Also, in Table 1, we report the performance of monolingual retrieval for these queries as a baseline. We achieve substantial improvements in the performance using both CLIR models with the second strategy. Statistical significant differences at the 0.01 level using a two-tailed paired t-test are marked with  X * X . Figure 2 provides a complete comparison between the effectiveness of using the  X  X yn X  and the  X  X ll X  strategies by presenting the Average Precision (AP) difference between results obtained using the two strategies for each query in LM-based method. As the figure illustrates, for most queries, the run using the  X  X yn X  strategy outperforms the one using the other strategy.
In the above experiment, our aim is not to show that the second strategy can be a substitution of the first one. In-stead, we have shown that when query terms have different numbers of synonymous translations, the usual adoption of the first strategy harms the CLIR performance. We show this by adopting the second strategy in which having differ-ent numbers of translation alternatives does not impact the retrieval performance. In conclusion, this experiment shows that we need a systematic way to handle the situation where there are different numbers of synonymous translations. PSQ method. This method scores documents using the BM25 model for monolingual retrieval given new estimations of TF and DF statistics. Thus, we validate the constraints on PSQ method according to the behavior of BM25 model given TF and DF estimated using Eq. (1) and Eq. (2) re-spectively.

Applying the assumptions of CL-C2 into Eq. (1), one has TF( q 1 ,D 1 ) + TF( q 2 ,D 1 ) = TF( q 1 ,D 2 ) + TF( q i.e., two documents have the same total frequencies of query terms. But, document D 2 covers q 1 and q 2 while D 1 covers only q 1 . Hence, D 2 covers more distinct query terms. DF ( q 1 ) and DF ( q 2 ) are estimated using Eq. (2) which depends on all translation alternatives for query terms. Therefore, according to the assumptions of CL-C2, we cannot compare DF ( q 1 ) and DF ( q 2 ). But, if DF ( q 1 ) = DF ( q 2 ), then the PSQ method satisfies CL-C2, because the BM25 retrieval model prefers a document covering more distinct query terms in the conditions above [6].
 According to the assumptions of CL-C3, one has TF( q,D 1 ) = TF( q,D 2 ). Thus, D 1 and D 2 get the same score using this method which means that the PSQ method does not satisfy CL-C3.

LM-based method. To score documents using this method, a new language model is built for the query. The similarity score of a document with respect to the new query language model is then calculated similar to monolingual retrieval using the language modeling framework. There-fore, we first estimate the new query language model us-ing Eq. (4). We then validate the constraints on LM-based method. This validation is done according to the behavior of the language modeling framework given the new estimated language model for the query.

Applying the assumptions of CL-C2 into Eq. (4), assumptions of CL-C2, p ( t 1 k |  X  D 1 ) = p ( t 1 k |  X  p ( t i |  X  D 1 ) = p ( t 2 j |  X  D 2 ). Therefore, the scores of these documents, which are calculated using Eq. (3) as: S( Q,D 1 ) = p ( t 1 k |  X  0 Q ) p ( t 1 k |  X  D 1 ) + p ( t S( Q,D 2 ) = p ( t 1 k |  X  0 Q ) p ( t 1 k |  X  D 2 ) + p ( t equal. Thus, LM-based model does not satisfy CL-C2.
Applying the assumptions of CL-C3 into Eq. (4), one has p ( t 1 |  X  0 Q ) = p ( t 2 |  X  0 Q ) &gt; 0. Also, two documents cover differ-ent numbers of terms that have non-zero probabilities in the new query language model, while both documents have the same total occurrences of these terms. Therefore, the lan-guage modeling framework prefers document D 2 (according to TFC3 in [6]) and consequently, LM-based model satisfies CL-C3.
In this paper, we provide formal representations of the im-pacts of translation knowledge on retrieval heuristics and, consequently, on the ranking of documents in CLIR. The main motivation of the proposed formalism is the deficiency of existing CLIR models when one can detect and select the appropriate number of translation alternatives for each source word. Our proposed constraints and their empirical effects stimulate further research. A promising direction is to study the effects that violating constraints on translation coverage has on the CLIR performance and to improve the existing CLIR models to satisfy all of the constraints. In-deed, the proposed constraints are focused on basic retrieval heuristics and there are several aspects affecting document ranking that can also be formalized through constraints.
