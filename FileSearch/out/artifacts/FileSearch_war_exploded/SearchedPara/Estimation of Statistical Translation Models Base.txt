 As a principled approach to capturing semantic relations of words in information retrieval, statistical translation mod-els have been shown to outperform simple document lan-guage models which rely on exact matching of words in the query and documents. A main challenge in applying trans-lation models to ad hoc information retrieval is to estimate a translation model without training data. Existing work has relied on training on synthetic queries generated based on a document collection. However, this method is compu-tationally expensive and does not have a good coverage of query words. In this paper, we propose an alternative way to estimate a translation model based on normalized mu-tual information between words, which is less computation-ally expensive and has better coverage of query words than the synthetic query method of estimation. We also propose to regularize estimated translation probabilities to ensure sufficient probability mass for self-translation. Experiment results show that the proposed mutual information-based estimation method is not onl y more efficient, but also more effective than the synthetic query-based method, and it can be combined with pseudo-relevance feedback to further im-prove retrieval accuracy. The results also show that the proposed regularization strategy is effective and can improve retrieval accuracy for both synthetic query-based estimation and mutual information-based estimation.
 H.3.3 [ Information Search and Retrieval ]: Retrieval Models Algorithms, Theory Statistical Machine Translation, Language Models, Estima-tion, Smoothing, Feedback
Designing effective retrieval models is central for informa-tion retrieval. In the past, many retrieval models such as vector space model [28, 29, 30] and probabilistic model [6, 22, 25, 27, 34] have been proposed and gained certain suc-cess. Recently, language modeling approaches have received considerable attentions because of its sound statistical foun-dation and good empirical performance [22, 42]. In lan-guage modeling approaches, documents are ranked accord-ing to how likely a query is generated from the correspond-ing document models. In basic language models, document models are estimated based on multinomial distribution and smoothing techniques are critical for document model esti-mation [42]. When ranking documents, the basic language modeling approach is primarily based on exact matching of terms between documents and queries. Since queries are generally succinct and relevant documents may use different vocabulary, such an approach can suffer from vocabulary gap problem.

As a principled approach to capturing semantic word rela-tions, statistical translation language models have been pro-posed for information retrieval to reduce the gap between documents and queries [2, 8]. Based on statistical machine translation [3], the basic idea of translation language models is to estimate the likelihood of translating a document to a query. Since a term has certain probability to be translated into a different term, translation language models can alle-viate the vocabulary gap problem in a direct manner. As a result, translation language models have been successfully applied to different tasks such as cross-lingual information retrieval [12, 20, 39], question answering [40], sentence re-trieval [19], and tracking information flow [18].
Surprisingly, there has been little work on applying trans-lation models to ad hoc retrieval. Indeed, the original pa-per [2] that proposed translation models for ad hoc retrieval appears to be the only study that we are aware of. One possible reason may be because of the difficulty in estimat-ing translation models. In [2], authors solved the problem by generating synthetic queries. Unfortunately, this method has two deficiencies: (1) it is inefficient; (2) there is no guar-antee that a query word is covered.

In this paper, we propose a simpler method for estimating a translation model, which is based on normalized mutual information between words. Our Contributions are as fol-lows: 1. We propose an efficient and effective way of estimating 2. We propose regularization of self-translation proba-3. We study the issue of smoothing in the context of 4. We show that with mutual information, the transla-
In this section, we review basic language modeling ap-proach, statistical translation language model and smooth-ing methods for statistical translation model. Finally, we discuss the estimation of translation model.
The language modeling approach to information retrieval was first introduced by Ponte and Croft [22]. The basic idea can be described as follows. We assume that a query q is generated by a probabilistic model based on a document d . Given a query q = q 1 ,q 2 ,...,q m , and a document d ,weare interested in estimating p ( d | q ) , i.e. the probability that document d has been used to generate query q . By applying Bayes X  formula, we have: p ( d ) on the right hand side of the above formula is our prior belief that document d is relevant to any query. p ( q | d )isthe query likelihood for the given document d , which intuitively measures how well document d matches query q . p ( d )is often assumed to be uniform and thus can be ignored for ranking documents. Further assuming that each query word is generated independently, we can rewrite the above formula as (in the form of log likelihood): where rank = means equivalence for the purpose of ranking doc-uments, c ( w,q ) is count of word w in query q ,and V is the vocabulary set. The challenging part is to estimate a docu-ment model p ( w | d ). Based on multinomial distribution, the simplest way to estimate p ( w | d )isthe maximum likelihood estimator : Where c ( w,d ) is count of word w in document d .Dueto the data sparseness problem, maximum likelihood estimator under-estimates the probability of unseen words in a docu-ment. Smoothing techniques address this problem by assign-ing non-zero probabilities to the unseen words and thus im-proving the accuracy of probability estimation. Specifically, smoothing is to discount the probabilities of words seen in the text and then assign extra probability mass to the unseen words according to some fallback model. Usually, collection language model is used as fallback model [42]. Two com-monly used methods are Jelinek-Mercer and Dirichlet Prior smoothing methods:
Jelinek-Mercer Method (JM Smoothing) : This is a linear interpolation of maximum likelihood model with the collec-tion model, using  X  as a coefficient weight. Where p ( w | C ) is probability of word w in collection C . Bayesian Smoothing using Dirichlet Prior (Dirichlet Prior Smoothing) : Since the conjugate prior of a multinomial dis-tribution is the Dirichlet distribution, we can specify a Dirich-let prior distribution parameterized as where  X  is a parameter. The estimated document model based on the posterior mean is then:
Another interesting way of estimating p ( w | d ) introduced by Berger and Lafferty [2] is based on statistical machine translation [3]. In order to assess the relevance of a docu-ment to a user X  X  query, they have estimated the probability that the query would have been generated as a translation of the document. In other words, they allow the query like-lihood to be computed based on a translation model of form p ( w | u ), which is the probability that word u is semantically translated to word w .

To put it more formally, in their model, the query likeli-hood can be calculated by using the following  X  X ranslation document model X : where p t ( w | u ) is the probability of  X  X ranslating X  word u into word w and it allows us to score a document by counting the matches between a query word and semantically related words in the document. If p t ( w | u ) only allows a word to be translated into itself, the simple exact matching query like-lihood would be achieved. However, p t ( w | u ) would in gen-eral allow us to translate u into other semantically related words with non-zero probabilities, thus achieving  X  X emantic smoothing X  of the document language model.
In this section, we consider statistical machine translation when combined with two basic smoothing methods described in section 2.1.

The basic component in the translation language model is p t ( w | d )= u  X  d p t ( w | u ) p ( u | d )whichcanbeusedtore-place p ml ( w | d ) in all basic language model approaches. This will give us 1) translation language model with Dirichlet prior smoothing and 2) translation language model with Jelinek-Mercer smoothing. When we replace p ml ( w | d )with p ( w | d )= u  X  d p ( u | d ) p t ( w | u )inequation2,wehavethe following: p t ( w | d )=
And when p t is replaced with p ml in equation 1, we have the following: Equations 3 and 4 give us Dirichlet prior smoothing and Jelinek-Mercer (JM) smoothing with translation language model, respectively.

Authors in [2] only considered translation language model with Jelinek-Mercer smoothing.
The key part for translation language model is to learn the word-to-word translation probability, p t ( w | u ). It is clear that the performance of the proposed smoothed translation model depends on the quality of the word-to-word trans-lation probabilities. In the scenario of statistical machine translation [3], a parallel corpus of two languages is often assumed to be available, and the EM algorithm [5] can be used to estimate a translation model.

In order to gain word-to-word probabilities in monolingual scenario, ideally, we should have a sample of queries and rel-evant documents, but since we do not often have, Berger and Lafferty [2] use the idea of synthetic queries as their training data. The idea is to take a document and synthesize a query to which the document would be relevant. They proposed a sampling technique which distinguishes a document from other documents.

In order to select words which are representative of a doc-ument, for each document d  X  D , they compute the mutual information statistics [7] for each of its words according to: I ( w, d )= p ( w,d )log p ( w | d ) p ( w | D ) ,where p ( w ity of word w in document d ,and p ( w | D ) is the probabil-ity of word w in the collection. Their proposed algorithm for generating synthetic queries is shown in figure 1, where synthetic queries are sampled based on normalized mutual information  X  I , and the Poisson parameter  X  is set to 15. The resulting ( d , q ) of documents and synthetic queries are used to estimate the probabilities with the EM algorithm. More details can be found in [2].
Although generating synthetic queries is a reasonable way to estimate the translation probabilities, this method has two deficiencies: (1) it is inefficient; (2) there is no guarantee that a query word is covered. In the next section, we pro-pose a mutual information-based estimation which is more efficient than this method and has a better word coverage.
In this section, we propose a more efficient way to estimate translation probabilities which can have a better coverage of query words than the existing method discussed in the previous section. We will also present a way to combine translation language model with pseudo-relevance feedback.
Mutual information [26] is a good measure to assess how two words are related. In our method, for each word in the collection, we compute all words which have high mutual in-formation scores with it and normalize the computed mutual information scores as follows:
First, we compute the mutual information scores for each pair of two words w and u in the collection. Informally, mutual information compares the probability of observing w and u together (the joint probability) with the probabilities of observing w and u independently . The mutual information between words w and u are calculated as follows: I ( w ; u )= where X u and X w are binary variables indicating whether u or w is present or absent.

The probabilities are estimated as follows: where c ( X w =1)and c ( X u = 1) are the numbers of docu-ments containing word w and u ,respectively, c ( X w =1 ,X 1) is the number of documents that contain both w and u , and N in the total number of documents in the collection.
We then normalize the mutual information score to obtain a translation probability: p mi ( w | u ) gives us the probability of translating word u to another word w ; intuitively, the probability would be higher if the two words tend to co-occur with each other.
The approaches described in sections 3.1 and 2.4 might under-estimate the self-transl ation probabilities, i.e., it is possible that p ( w | u ) &gt;p ( w | w ). This may lead to non-optimal retrieval performance because it is possible that a document that matches a query word exactly ( p ( w | w )) gets Table 1: Sample word translation probabilities using less score contribution from matching the query word ex-actly than a document that  X  X atches X  a query word through translation ( p ( w | u )). To overcome this bias, we introduce a parameter  X  to control the effect of self-translation. This is a general method that can be applied to adjust the estimated probabilities from any given estimation method. and p ( w | u ) is estimated either with mutual information or synthetic queries.  X  is a parameter that controls the effect of self-translation probability and when we set  X  =1,we recover the basic query likelihood method.

The  X  X egularized X  translation model p t ( w | u )canthenbe used in Equations 3 and 4 to rank documents.
Feedback techniques have been shown to improve retrieval accuracy substantially[13, 27, 41]. A natural question with translation model is whether translation model can benefit from feedback techniques. In this section, we use pseudo-relevance feedback to expand our query model [41] and then score the expanded query model with translation language model based on the negative cross entropy of the expanded query language model and the translation document model (also equivalent to scoring based on negative KL-divergence): where p ( w |  X  q ) is the query model generated by pseudo-relevance feedback and p t ( w | d ) is a smoothed translation model and can be computed using either of equations 3 or 4.
The experiments in this section use four main document collections: (1) news articles (AP90) with TREC topics 51-100 and 78,321 articles. (2) San Jose Mercury News (SJMN) articles with TREC topics 51-100 and 90,250 articles (3) ad hoc data in TREC7 with topics 351-400 and 528,155 articles and (4) TREC8 with topics 401-450 and 528,155 articles.
In the experiments, we only use title of the queries. As for preprocessing, we do stemming using Porter stemmer [23] and stop word removal. All experiments are done using the Figure 2: Comparison of mutual information and syn-Lemur toolkit 1 . The performance is measured using two standard measures: MAP(mean average precision) and pre-cision @10 (precision at 10).

The optimal value for Dirichlet prior smoothing for base-line is 1000 for all data sets and optimal value for JM smooth-ing for baseline method is gained when coefficient is set to 0 . 5 for AP90 data set and 0 . 3 for the rest of data sets.
The methods used for experiments in the following sec-tions are: BL (baseline), i.e., either Dirichlet prior smooth-ing or JM smoothing [42], TM-MI (translation language model with mutual information 2 for word-to-word transla-tion probabilities), TM-SYN (translation language model with synthetic queries), fb (pseudo-relevance feedback on baseline) and fb+TM(pseudo-relevance feedback combined with translation language model using mutual information).
We first look into the question whether mutual informa-tion (MI) can be an alternative way of estimating translation model. Table 2 shows the results for both TM-SYN and TM-MI methods with both Dirichlet prior smoothing and JM smoothing, respectively. The results indicate that TM-MI method is able to better capture word relatedness. Indeed, statistical significance tests indicate that the difference be-tween TM-MI and TM-SYN is statistically significant. In addition, estimating translation probabilities by mutual in-formation for all data sets is more efficient than learning translation probabilities by synthetic queries. Table 1 shows a document word together with ten most probable query words that it will translate to by both synthetic queries and mutual information estimation methods. The table shows that the related words for word  X  X verest X  in case of mutual information are more specific than for words learned via syn-thetic queries.

Figure 2 shows the sensitivity of mutual information and synthetic queries to  X  parameter according to MAP mea-sure (left) and Precision@ 10 (right). The difference indeed makes clearer that mutual information works better than synthetic queries. (Our results for synthetic queries are com-parable to those reported in [2].)
According to these results, we can conclude that mutual http://www.lemurproject.org/
We use mutual information throughout the paper for sim-plicity but we mean the normalized mutual information de-scribed in section 3.1. information works better than synthetic queries and it is also more efficient.

Because of the high computational complexity of synthetic queries, we cannot compare mutual information with it on larger collections, but later we will further experiment with mutual information on larger collections.
We now look into how well a translation model with our mutual information-based estimation method performs as compared with the standard query likelihood method. Ta-ble 3 shows the results for BL and TM-MI methods accord-ing to two measures MAP and Precision @10.

Comparing the columns TM-MI with BL in both tables indeed indicates that the TM-MI outperforms method BL. Significant tests using Wilcoxon signed-rank test [37] show the difference between these two methods for cases marked in the tables are statistically significant. Comparing TM-MI with Dirichlet prior smoothing and TM-MI with JM smooth-ing shows that TM-MI with Dirichlet prior smoothing has higher MAP than TM-MI with JM smoothing.

Stress Tests : In order to have a better understanding of the translation language model, we applied some stress tests on AP90 data set 3 . This experiment is to help us understand when exactly the translation language model would be most beneficial. For the stress test, we gradually and randomly remove query words from relevant documents and compare the performance of BL method with TM-MI method. The results of MAP and Precision @10 are shown in Figure 3.
The results indeed indicate that the baseline method (BL) is purely based on exact matching and the performance will drop significantly if the exact matching does not happen. On the other hand, translation language model (TM-MI) is still able to find relevant documents by translating query words to semantically related words in the documents. This indicates that the translation language model works signif-icantly better than the baseline when there is a vocabulary gap between queries and documents.
We got the same trends on other data sets, but we only show the results for AP90 data set.
Understanding the influence of smoothing on translation language model is important and no previous work has looked into this. We have a good understanding of smoothing meth-ods for basic language models [42], but it is not clear how smoothing affects the performance of statistical translation language models. In this section, we look into how statistical translation model behaves with the smoothing parameters.
We vary the smoothing parameters (both JM and Dirich-let prior smoothing) for both BL and TM-MI methods. Fig-ure 4 (left and middle) shows the variation of the JM smooth-ing parameter and Dirichlet prior smoothing parameter on AP90, respectively (we do not show the results on other data sets since they are similar). The result of TM-MI with JM smoothing indicates that the translation model does need a very little smoothing. As shown, the optimal values for translation language model with Dirichlet prior smoothing is 1000 and with JM smoothing is 0.1. As a result, translation language model is less sensitive to the choice of smoothing parameter than the baseline method. And this is intuitively expected, as smoothing is implicitly gained by translating a document word to other semantically related words .
Please note that in the translation language model, we have one other parameter to tune, i.e., the number of words used for translation. Figure 4 (right) shows the sensitivity of the number of the words according to MAP measure. As shown in the figure, the translation language model is not so sensitive to the number of words used for translation.
Both statistical translation model and pseudo-relevance feedback are to capture word associations, so it would be interesting to see whether they are essentially taking advan-tage of the same associations or they can be combined to achieve even more improvement.

Table 4 shows the pseudo-relevance feedback results for baseline (fb) and when pseudo-relevance feedback is com-bined with translation language model (fb+TM). For fb+TM method, we first apply pseudo-relevance feedback on ini-tial results (i.e., KL-divergence retrieval model [11]), and then this new query model from pseudo-relevance feedback is used with translation language model to score documents. The feedback parameters are fixed to extract 20 expanded words from the top 10 retrieved documents in the initial run. As shown in table 4, fb-TM method indeed outper-formsfbmethodwhenusedwithJMsmoothing.Statistical significant tests reveal that the difference is indeed statis-tically significant. However, fb+TM method does not sig-nificantly outperform fb method when used with Dirichlet prior smoothing. An interesting observation is that although the performance of pseudo-feedback (fb) method with JM smoothing is lower than pseudo-feedback with Dirichlet prior smoothing, when pseudo-feedback (fb) is combined with trans-lation language model, i.e., fb+TM method, the better per-formance is gained with JM smoothing. In fact, the perfor-mance of fb+TM with JM smoothing is consistently better than the fb+TM with Dirichlet prior smoothing.

Figure 5 shows the P-R curves for BL, fb and fb+TM methods with JM Smoothing on AP90 4 . This figure indeed indicates that the precision of fb+TM method at different recall points is higher than BL and fb methods. This is an interesting conclusion that translation language model brings in co-occurrence word knowledge that once combined with pseudo-relevance feedback, significant improvement is gained.
A potential problem of the estimated translation proba-bilities is that it is possible that p ( w | u ) &gt;p ( w may lead to non-optimal retrieval performance because it is possible that a document that matches a query word ex-actly ( p ( w | w )) gets less score contribution from matching the query word exactly than a document that  X  X atches X  a
We do not show other curves due to their similarity. Figure 5: Comparison of Baseline with Translation query word through translation ( p ( w | u )). The interpolation formula (with  X  ) can help alleviate this problem; indeed, if  X   X  0 . 5, we can always ensure that this constraint be sat-isfied. So, it would be interesting to see how  X  affects the performance. Figure 6 shows the sensitivity of  X  parameter according to MAP measure. We indeed observe that when  X  is very small (close to no interpolation) the performance is poor, suggesting that it is important to regulate the self-translation probabilities to ensure that it is sufficiently large. In Figure 6, we can see that when 0 . 5  X   X   X  0 . 8formost data sets, we can gain the optimal value. Note that when  X  = 1, we reach the baseline. 1. Translation language model is statistically significant bet-
Figure 6: Sensitivity of  X  parameter to MAP measure ter than the baseline query likelihood especially when there is a vocabulary gap. 2. Normalized mutual information can be used for word-to-word translation effectively and the results in the previ-ous sections indicate that it is more accurate than synthetic queries. Synthetic queries are inefficient for a large collection such as TREC7 or TREC8. 3. The performance of translation language model com-bined with pseudo-relevance feedback outperforms pseudo-relevance feedback alone; this indicates that translation lan-guage model brings in co-occurrence knowledge in addition. 4. Translation language model is less sensitive to the choice of smoothing parameter than the baseline. 5. Translation language model is robust as it improves over all individual queries.
Language modeling approaches received considerable at-tentions recently [22]. One of the most important challenges in language model-based information retrieval is to estimate a better document model. Smoothing is an important ap-proach for document model estimation and has been shown to be critical for information retrieval [42]. To further im-prove the estimation of document models, different heuris-tics have been proposed in the past. For example, cluster or topic-model based approaches have been studied in [16, 36]. Tao et al. [33] proposed a document expansion approach to enrich document representati on before estimating document models.

Statistical translation models were originally studied in machine translation with the goal of automatically translat-ing sentences between different languages (e.g., French and English) [3] where authors proposed five different translation models. The simplest model (i.e., IBM 1) [3] ignores position information when learning word-to-word translation proba-bilities. This model has been adopted in information re-trieval by Berger and Lafferty [2]. To train translation mod-els, they synthetically generated (query, document) pairs. An alternative way of estimating the translation model is based on document titles [8]. In this work, the authors pro-posed to use (title, document) pairs as training data. These estimation methods are inefficient and the coverage of query words is low. Our proposed mutual information-based esti-mation is more efficient and has a better query words cov-erage.

Translation models have been naturally used in cross-lingual information retrieval domain [20, 39]. For example, Nie et al. [20] used parallel corpus as training data to learn translation models. The work by Lavrenko et al. [12] has adapted the relevance model in two different ways based on KL-divergence retrieval models to perform cross-lingual in-formation retrieval. The cluster-based query likelihood pro-posed in [10] can be regarded as a form of a translation model where the whole document is translated into the query. Re-cently, translation models have been applied in many appli-cations including question answering, sentence retrieval and tracking information flow [18, 19, 40]. For example, Xue et al [40] has applied translation model on question-answer archives where question and answer pairs are used to train the translation model. In Contrary to all these works, we studied statistical translation model in ad hoc retrieval con-text.

Vocabulary gap has also been studied in the past. Many studies have tried to bridge the vocabulary gap between documents and queries both based on co-occurrence the-saurus [1, 9, 14, 21, 24, 31, 32, 38] and hand-crafted the-saurus [15, 35]. Some other works have considered to com-bine both approaches [4, 17]. In this paper, we considered word co-occurrence relationship based on mutual informa-tion and incorporated it into translation language model in a more principled way.
As a principled approach to capturing semantic relation of words in information retrieval, statistical translation mod-els have been shown to outperform simple language models which rely on exact matching of words in the query and doc-uments. In this paper, we propose a new simple way to esti-mate translation probabilities based on mutual information. Our experiment results indicate that the proposed mutual information estimation method is both more efficient and more effective than the existing synthetic query estimation method. We also proposed to regularize translation proba-bility to ensure sufficient self-translation probability mass, which has been shown to be effective for both estimation methods we experimented with. Our results also show that the translation language model is not so sensitive to the effect of smoothing, and it can be combined with pseudo-relevance feedback to further improve the performance.
For future, it would be interesting to propose some other efficient estimation methods. It would also be interesting to explore other ways of incorporating the translation probabil-ities into the retrieval formula. Another interesting direction is to study how to transfer the knowledge learned from one collection to another collection.
We thank the anonymous reviewers for their useful com-ments. This material is based upon work supported by a Sohaib and Sara Abbasi Fellowship, Yahoo! Key Scientific Challenge Award, the National Science Foundation under Grant Numbers IIS-0347933, IIS-0713581, IIS-0713571, and CNS-0834709, and by NIH/NLM grant 1 R01 LM009153-01. Any opinions, findings, conclusions, or recommendations ex-pressed in this material are the authors X  and do not neces-sarily reflect those of the sponsors.
