 Term dependency, or co-occurrence, has been studied in lan-guage modelling, for instance by Metzler &amp; Croft [3] who showed that retrieval performance could be significantly en -hanced using term dependency information. In this work, we show how term dependency can be modelled within the Di-vergence From Randomness (DFR) framework. We evaluate our term dependency model on the two adhoc retrieval tasks using the TREC .GOV2 Terabyte collection. Furthermore, we examine the effect of varying the term dependency win-dow size on the retrieval performance of the proposed model. Our experiments show that term dependency can indeed be successfully incorporated within the DFR framework. Categories and Subject Descriptors: H.3.3 [Informa-tion Storage &amp; Retrieval]: Information Search &amp; Retrieval General Terms: Performance, Experimentation Keywords: Term Dependency, DFR
Document weighting models, such as BM25 and language modelling, rank documents using the occurrences of sin-gle query terms in documents and assuming that the query terms are independent. However, previous studies have show n that taking the dependency of query terms in documents into account can improve retrieval performance [3, 4]. In particular, Metzler &amp; Croft have developed a formal frame-work for modelling term dependencies via Markov random fields [3]. They explored three possible relation variants b e-tween query terms: Full Independence, which assumes query terms are independent with each other; Sequential Depen-dence, which only assumes a dependence between neigh-bouring query terms; and Full Dependence which assumes all query terms are dependent with each other. Their ex-periments showed that their term dependency model could significantly improve retrieval performance.

In this paper, we show how term dependency can be nat-urally modelled within the Divergence From Randomness framework [1] (Section 2). We evaluate the proposed model in the context of the TREC 2005 and TREC 2006 Terabyte track adhoc tasks (Section 3). In particular, we observe com -parable conclusions to Metzler &amp; Croft X  X  [3], namely that th e incorporation of term dependencies into a DFR-based model can significantly enhance retrieval performance.

We use the DFR paradigm to capture the dependence of query terms in documents. The proposed model assigns scores to pairs of query terms, in addition to the single quer y terms. Hence the score of a document d for a query Q is given as follows: score ( d, Q ) =  X  1  X  X where score ( d, t ) is the score assigned to a query term t in the document d , p corresponds to a pair of query terms that appear within the query Q , score ( d, p ) is the score assigned to a pair of query terms p in the document d , and Q 2 is a set of pairs of query terms, as defined below. The two scores are combined linearly using  X  1 &amp;  X  2 as weights. For simplicity, we use only binary weights. In Equation (1), the score P t  X  Q score ( d, t ) can be estimated by any DFR weighting model. For example, we can use the DFR PL2 document weighting model [1].

We now introduce three possible variants in using term de-pendencies between query terms: For full independence (FI) , the introduced weighting model only computes the first com-ponent of Equation (1) as it ignores the term dependencies between query terms (  X  1 = 1,  X  2 = 0). This is equivalent to PL2 alone; For sequential dependence (SD), we compute both components of Equation (1) (  X  1 = 1,  X  2 = 1), and in this case, Q 2 is the set that contains ordered pairs of neigh-bouring query terms; For full dependence (FD), we compute both components of Equation (1) (  X  1 = 1,  X  2 = 1), and in this case, Q 2 is the set that contains unordered pairs of any two query terms. In this paper, we consider only pairs of query terms, even if we could easily extend the model to more than two terms. The weight score ( d, p ) of a pair of query terms in a document is computed as follows: where P p 1 corresponds to the probability that there is a doc-ument in which a pair of query terms p occurs a given num-ber of times. P p 1 can be computed with any Randomness model from the DFR framework. P p 2 corresponds to the probability of seeing the pair of query terms once more, afte r having seen it a given number of times. P p 2 can be computed using any of the After-effect models in the DFR framework. The difference between score ( d, p ) and score ( d, t ) is that the former depends on counts of occurrences of the pair of query terms p , while the latter depends on counts of occurrences of the query term t .

To compute the weight score ( d, p ), we use a Randomness model, which does not consider the collection frequency of the pair of query terms. It is based on the binomial Ran-domness model, given as follows [2]: score ( d, p ) = where l is the length of the document in tokens, p p = 1 l  X  1 = 1  X  p p , and pfn is the normalised frequency of the pair of query terms p using Normalisation 2 [1]: pf is the frequency of the pair of query terms p that appear within window size tokens in the document (for SD, these must appear in the same order as in pair p ), avg l is the average document length in the collection, and c p is a hyper-parameter that controls the normalisation applied to the pair of query terms frequency against document length.
We use the TREC .GOV2 Terabyte test collection, and its associated TREC 2005 and 2006 adhoc title-only topics and relevance assessment sets. For indexing and retrieval ing stopwords. For all our experiments, we set c = 6 and c p = 0 . 05 for the term frequency normalisation parameter of PL2 and the pair of query terms frequency normalisation respectively, as suggested by [2]. For the window size , we use 5  X  the default setting suggested by [2]. We report Mean Average Precision (MAP), binary preference (b-Pref), and Precision at 10 (P@10).

Firstly, in Table 1, we assess the extent to which the in-corporation of term dependency enhances retrieval perfor-mance over a full independence baseline (FI). We observe that the FD variant always outperforms the baseline, except for P@10 on the TREC 2006 queries (the improvements on the TREC 2006 queries are statistically significant). More-over, the SD variant outperforms the FI baseline (these im-provements are statistically significant for MAP and b-Pref on the TREC 2006 queries), except for MAP and b-Pref on the TREC 2005 queries, which are slightly (but not signifi-cantly) lower than the baseline.
 Secondly, we compare the SD and FD variants. From Table 1, we observe that while FD outperforms SD for MAP 1 URL: http://ir.dcs.gla.ac.uk/terrier/ Figure 1: MAP distribution for TREC 2006 for varying window size . and b-Pref (these improvements are significant on the TREC 2006 queries), P@10 is enhanced more by SD than by FD.
Moreover, we vary the window size parameter to inves-tigate its effect on retrieval effectiveness. For lack of spac e, we consider only the TREC 2006 queries and the MAP mea-sure. From Figure 1, we observe that both SD and FD, in most cases, outperform the FI baseline. The performance is stable for the SD variant as window size is varied. However, the improvement decreases as window size is increased for the FD variant. In general, a window size around 5 will pro-duce the best MAP scores for the FD variant. Furthermore, for 2  X  window size  X  24, the FD variant outperforms SD, while for window size &gt; 24, SD performs better.
Finally, we notice that the results observed in our ex-periments mirror those observed in [3], namely that FD can significantly outperform SD, and both FD and SD can signif-icantly outperform the FI baseline, even though, unlike [3] , we only consider pairs of query terms. Furthermore, our retrieval performance would likely be enhanced by suitable training of  X  1 &amp;  X  2 in Equation (1).
We have introduced a novel DFR-centric approach for in-corporating term dependencies. Our approach is shown to be robust as retrieval effectiveness is enhanced on a large-scale adhoc test collection, using a variety of window sizes . Further enhancement of retrieval performance is likely to b e achieved by an appropriate training of the model, similar to that in [3].
