 Dimensionality reduction (DR) through feature extraction (FE) is desirable for efficient and effective processing of text documents. Many of the techniques for text FE produce fea-tures that are not readily interpretable and require super-linear computation time. In this paper, we present a fast supervised DR/FE technique, named FEDIP, that is mo-tivated by the notion of rela tedness of terms to topics or contexts. This relatedness is quantified by using the dis-crimination information provided by a term for a topic in a labeled document collection. Features are constructed by pooling the discrimination information of highly related terms for each topic. FEDIP X  X  time complexity is linear in the size of the vocabulary and document collection. FEDIP is evaluated for document classification with SVM and naive Bayes classifiers on six text data sets. The results show that FEDIP produces low-dimension feature spaces that yield higher classification accuracy when compared with LDA and LSI. FEDIP is also found to be significantly faster than the other techniques on our evaluation data sets.
 I.7.m [ Document and Text Processing ]: Miscellaneous; H.2.8 [ Database Management ]: Database Applications X  Data Mining Algorithms, Theory
Dimensionality reduction (DR) via feature extraction (FE) is an important step in many textual information retrieval and text mining applications. It often produces more ef-ficient and effective solutions, and in certain applications, can ensure the practical feasibility of a solution because of its efficiency. A popular text mining application is that of document classification where labeled documents are used to learn a classifier for labeling new documents. Feature ex-traction for document classification can yield classifiers that are more robust to noise and shifts in distributions. An-other popular application is document understanding and visualization. A fast FE technique can enable interactive visualizations of documents and their features.

In this paper, we propose a fast and effective supervised feature extraction technique for textual information. Our technique, named FEDIP, is motivated by the notion of re-latedness of terms to topics or contexts in which they occur. This notion of relatedness has been shown to play a signif-icant role in human comprehension of text [3, 5]. For in-stance, humans can easily associate terms with a particular topic after reading a few documents discussing that topic. We use discriminative term weights, computed via the rela-tive risk of a term in a topic-labeled document collection, to quantify the relatedness of terms to topics. Features are con-structed by pooling the discrimination information of highly related terms for each topic. We evaluate FEDIP for docu-ment classification, comparing it with Latent Semantic In-dexing (LSI) [2] and Linear discriminant Analysis (LDA) [8] on six data sets. The results show that FEDIP produces low-dimension feature spaces in which document classifica-tion is more accurate and efficient. FEDIP represents a new semantically motivated term pooling approach for text FE that supports efficiency and effectiveness in text mining. The remainder of this paper is organized as follows. In Section 2, we outline the motivation for our feature extrac-tion technique. Section 3 presents our fast supervised tech-nique for feature extraction. We discuss the experimental evaluation of our technique in Section 4. Finally, we present our concluding remarks in Section 5.
Typically in text mining and information retrieval, the notion of relatedness refers to the semantic relatedness be-tween pairs of terms (e.g. words). Accordingly, two terms are said to be related when they are linked by semantic relationships. Usually these are the so-called classical lexi-cal relationships like synonymy, antonymy, and hypernymy. Numerous semantic relatedness measures of this type have been proposed and evaluated in the literature. However, these measures have been developed for and are used pri-marily for natural language processing tasks like word sense disambiguation [6, 7].

On the other hand, the notion of relatedness of terms to contexts or topics is less known. Nonetheless, this notion of relatedness is more powerful for some applications where contexts are pre-defined or known. Furthermore, this notion of relatedness has been linked to humans X  comprehension of text by association of terms with their contexts. In a study by [5], it has been argued that readers develop non-classical relationships between terms by grouping terms associated to common contexts. These groups of terms may then serve as units of understanding of the respective contexts [3].
These observations indicate that groups of terms that are related to a particular context convey meaning about that context or topic. Thus, if we can find such groups of terms then we can pool their information content to construct fea-tures. These features will better capture the meaning of the text and aid in document understanding and document clas-sification. Our FE technique, FEDIP, uses term discrimina-tion information as a measure o f its relatedness to a context in a labeled document collection, and constructs features by pooling the discrimination information of terms related to each context.
We describe the key steps of our feature extraction tech-nique, FEDIP (Feature Extraction by [Term] Discrimination Information Pooling), in the following subsections. Here, we define the problem setting and notations.
 Let D = { d 1 ,d 2 ,d 3 ,...,d N } be the set of documents and V = { t 1 ,t 2 ,t 3 ,...,t M } be the vocabulary of terms in these documents. The context or topic of a document d is identi-fied by the context label cont ( d )  X  X  c 1 ,c 2 ,c 3 ,...,c K is the total number of topics in D (usually K N ). The weight of term t j in document d i is identified by x tw ( t j ,d i ), which is always greater than or equal to zero. In practice, this term weight can be a 0/1 value (e.g. term occurrence), an integer value (e.g. term count), or a pos-itive real number (e.g. term frequency inverse document frequency or TFIDF).

Given the above setting, a document d i is represented by the vector x i = x i 1 ,x i 2 ,...,x iM in the input space X X  M . After dimensionality reduction, document d i is represented by the vector y i = y i 1 ,y i 2 ,...,y iR in the fea-ture space Y X  R . For our technique, the dimension R can range from K , the number of context labels, to M ,the number of dimensions in the input space (i.e. K  X  R  X  M ).
Measures of discrimination information can be used to quantify the discriminative power provided by a term for a given context over all other contexts. They can also be viewed as the strength of the evidence or opinion that a term provides for a given context. Measures of discrimina-tion and association have been studied for different purposes in the literature including feature selection, association rule mining, and text classification. The idea of discriminative term weights is introduced in [4] for quantifying the dis-crimination information provided by terms for classification purposes. Three measures (Kullbach-Leibler divergence, rel-ative risk, and log relative risk) are evaluated and it is re-ported that the relative risk of a term provides robust clas-sification performance.

In this work, we use the relative risk of a term to quantify its discrimination information for a given context over the others. Accordingly, the discriminative term weight of term t for context c k is defined as where p ( t j | c k ) denotes the probability of term t j ments belonging to context c k and  X  c k refers to documents in all contexts but c k .If dtw ( t j ,c k ) &gt; 1thenterm t provides positive discrimination information for context c with larger values signifying higher discriminative power.
The probabilities in Equation 1 are computed from the set of labeled document D via maximum likelihood estimation (MLE). We evaluate two document models in this work: (a) documents X  terms follow a Multinomial distribution and (b) each term follows a Bernoulli distribution.

Once the discriminative term weights are estimated, we can identify all the terms that provide significant positive discrimination information for a given context. Specifically, the set of terms V k providing significant positive discrimina-tion information for context c k is defined as where T  X  1 is a term selection parameter controlling the exclusion of insignificant terms. It is important to note that, in general, V k  X  X  l =  X  for all k and l . Also, depending on the value of T ,  X  k V k = V as some terms may not provide significant discrimination information for any context.
Cai and van Rijsbergen [1] define the relatedness of a term to a context/topic as the product of a weight of the term in the context and a discrimination information measure of the term for the context. Following their framework, we define the relatedness of term t j to context c k as follows: Thus, the weight of a term in the context c k is taken to be the probability of the term in documents belonging to context label c k . Intuitively, a term is more related to a context if its discriminative term weight is larger and if it occurs frequently in documents belonging to the context.
This choice of the weight of a term in a context leads to the interpretation that the relatedness of a term to a context (Equation 3) is the term X  X  contribution towards the expected discrimination information provided by all significant terms for that context. The expected discrimination information provided by all terms t  X  X  k for context c k over the other contexts can be written as In words, E k is the expectation of the discrimination infor-mation for context c k basedontermsinthelabeleddocu-ment collection. And, the relatedness of a term to this con-text represents its contribution to the expected value E k the stronger the relatedness, the larger the contribution to E .
In the previous subsections, we have defined the relat-edness of a term to a context (Equation 3) and identified all terms that are related to a given context (Equation 2). Given this setup, we can construct features by pooling the discrimination information provided by terms in V k ( k = 1 ,K ). Consider a document d i represented in the input space by the vector x i . The representation of this document in the feature space y i is defined as follows: This expression will create R = K features, where K is the total number of contexts in the document collection. Each feature represents the linear opinion pool or ensemble average of the discrimination information provided by terms in the document. If a term does not occur in a document, then the discrimination information or opinion of that term is not included. The larger the value of y ik the greater is the chance that document d i belongs to context c k .The extension for R&gt;K features is omitted from this shortened paper. Algorithm 1 FEDIP 1: Input: { d i } N i =1 (documents), V = { t j } M j =1 (term vo-2: Output: { y i } N i =1 (feature vectors of length R ) 3: 4: for k =1  X  K do 5: for j =1  X  M do 6: dtw ( t j ,c k )  X  discriminative term weight of term t 7: end for 8: V k  X  significant terms for context c k (Eq. 2) 9: end for 10: 11: for i =1  X  N do 12: for r =1  X  R do 13: y ir  X  linear opinion pool of terms in V r (Eq. 5) 14: end for 15: end for
The steps in FEDIP are given in Algorithm 1. There are two main processing blocks in FEDIP. The first code block (lines 4 X  9) finds the discriminative term weights and constructs the term pool for each context. The estimation of the discriminative term weight (line 6) for a given term and context requires one pass over the set of labeled documents. Hence, the time complexity of this block of processing is O ( KMN ).

The second block of processing (lines 11  X  15) computes the desired features by outputting a feature value for each context. The time complexity of this processing is O ( RMN ). The overall worst-time complexity of FEDIP is O ( KMN )+ O ( RMN ). This expression shows that FEDIP X  X  time com-plexity depends linearly upon the data parameters N and M , and since K = R is usually much smaller than both M and N , FEDIP is computationally very efficient in practice.
We evaluate FEDIP for document classification using six text data sets. Its performance is compared with Latent Table 1: Key characteristics of the evaluation data sets Semantic Indexing (LSI) and Linear Discriminant Analysis (LDA) under Support Vector Machine (SVM) and Naive Bayes (NB) classifiers. Our experiments are conducted in the MATLAB environment (LSI, NB). For SVM we use the LIBSVM 1 implementation, and for LDA we use the LDA/QR 2 implementation [8]. In all our experiments, the term selection parameter T is set equal to one.

The names and key characteristics of the selected data sets are given in Table 1. The first data set is taken from a Cornell University page 3 , while the remaining five data sets are available from Karypis Lab at University of Minnesota Brief descriptions of these data sets can be found on the respective Web sites.

FEDIP preserves the topic or context information in the reduced feature space. This characteristic is highly desir-able for visualization of document collections and document classification. We illustrate this in Figure 1. In this fig-ure, the left plot shows the Movie Review data set in the 2-dimensional feature space produced by FEDIP, while the right plot shows the same for LSI. The separation of docu-ments belonging to the two contexts is evident in the feature space produced by FEDIP. Furthermore, the feature values produced by FEDIP are readily interpretable as relevance of documents to the respective contexts. In general, the scatter plots of documents in the 2-dimensional feature space pro-duced by FEDIP have documents belonging to one context spread along one axis and documents belonging to the other context spread along the other axis with some overlap along the diagonal. This representation suggests that a linear dis-criminant passing through the origin can produce accurate classification.

Table 2 gives the classification performance (average per-cent accuracy and standard deviation obtained from five ran-dom train/test runs in which the size of the test set is 33% of the total data size) of SVM and NB classifiers in the fea-ture space. The number of features is equal to the number of contexts ( R = K ) of the data sets, except for LDA/QR, for which R = K  X  1. FEDIP-a is the variant based on the Multinomial model and FEDIP-b is the variant based on the Bernoulli model.

The following observations and interpretations can be made from these results. (1) FEDIP X  X  feature spaces yield higher classification accuracy for the majority of the data sets. FEDIP X  X  performance is much better for data sets with fewer contexts when compared to LDA/QR. (2) The performance gap between FEDIP and LDA/QR decreases as the number http://www.csie.ntu.edu.tw/ cjlin/libsvm/ http://sites.google.com/site/mydemossite/ http://www.cs.cornell.edu/people/pabo/movie-review-data/ http://glaros.dtc.umn.edu/gkhome/cluto/cluto/download classifiers 6 . 5 97 . 73  X  0 . 46 98 . 38  X  0 . 46 55 . 02  X  2 . 48 91 . 34 Figure 1: Scatter plot of Movie Review data set in 2-D feature space. Left plot is for FEDIP and right plot is for LSI. The two categories are identified by different color markers. of contexts increases. (3) LSI X  X  feature spaces produce poor classification accuracy, especially when paired with SVM. Since LSI is unsupervised, it is not able to preserve the cat-egory separation in the low-dimension feature space. More-over, linear SVM, which is discriminative in nature, does poorly when compared to NB, which is generative in na-ture, in LSI feature spaces. (4) FEDIP-a and FEDIP-b can produce slightly different classification accuracies, and no clear winner is observable from our evaluation.
 We now compare the computation times required by FEDIP, LSI, and LDA/QR on our evaluation data sets. Instead of providing absolute run-time values, which depend heavily upon the computing environment, we provide the relative run-times on our computing setup. We observed the run-times for all data sets and found that LDA/QR is at least 4 times slower than FEDIP and LSI is at least 15 times slower than FEDIP. Even though LDA/QR has a theoreti-cal worst-case time complexity identical to that of FEDIP [8], in practice we found it to be significantly slower than FEDIP.
Motivated by the notion of re latedness of terms to topics or contexts, we develop and evaluate a supervised feature ex-traction technique for text, named FEDIP, based on discrim-inative term weighting and term pooling. FEDIP produces features that are readily interpretable as the strength of the discrimination information provided by the term pool for a given context. The computational complexity of FEDIP is linear in M (number of terms) and N (number of docu-ments). These characteristics of FEDIP are evaluated on six text data sets and its performance compared with LSI and LDA/QR using naive Bayes and SVM text classification. FEDIP outperforms LSI and LDA/QR especially when the dimensions have been reduced significantly.

This work demonstrates that term pooling is a practi-cally effective technique for text dimensionality reduction. It also highlights the use of relatedness of terms to contexts. There is much potential for future research in this direction. Specifically, it is worth investigating the use of knowledge-based measures of relatedness (in addition to the corpus-based measure used in this work) for term pooling. We also feel that term selection, via the term selection parameter T , can improve the quality of the feature spaces produced by FEDIP. [1] D.CaiandC.J.vanRijsbergen.Learningsemantic [2] S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. [3] M.A.K.HalidayandR.Hassan. Cohesion in English . [4] K. Junejo and A. Karim. A robust discriminative term [5] J. Morris and G. Hirst. Non-classical lexical semantic [6] P. Resnik. Using information content to evaluate [7] G. Tsatsaronis, I. Varlamis, and M. Vazirgiannis. Text [8] J. Ye and Q. Li. A two-stage linear discriminant
