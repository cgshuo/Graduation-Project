 Search engine is a great tool for people to effectively access useful information from pages, which provides shortcuts to the endless Web content. Although quite helpful, it is still inconvenient when searching vertical information, such as spatial information, since it is designed for general purpose. For example, when finding the battlefields of about what happened in the battlefields and where are these locations. A categorized list along with a map indicating the locations would be much easier to read. 
Literally, searching spatial information is a conventional task in today X  X  cyber about where greenhouse effect and ozone depletion occur, or students working on leaders who must keep one eye on the oversea markets where their products sell best. All of them can save much time if there exist any spatial information search services. 
Pioneer researchers have already studied this kind of service on traditional data sources. For example, Smith detects events by hand with date and location informa-tion from historical documents to facilitate the review of past events [8, 9]. 
Unfortunately, there is no such service on the Web. Since  X  X he Web is a sensor of the real world X  [16], a mass of information, including news and thorough discussions actually a better and more useful source for spatial information search task. 
Given a query, there are three tough problems when fetching spatial information from the general Web. 1. How to effectively retrieve the geographic information, ranging from continents to specific locations, from Web content without human labeling? I.e. How to make computer automatically recognize locations from relevant texts? Some ad-hoc loca-tions are not known before the event ha ppens. The location names are also evolv-ing. Building a gazetteer (or loca tion dictionary) is not enough. 2. How to approximately describe events with Web texts? Browsing all the Web pages to find out the events is time-consuming. Several keywords describing the events would be a simple and quick way for the users to know the relevant events. 3. How to draw a clear and understandable spatial distribution of the relevant events? locations across the world. Instead of listi ng these locations, there should be a vis-ual map to show them for clarity. The key point is to locate them on the map. In this paper, we name the above problems as Location Identification Problem, Event Detection Problem and Spatial Presentation Problem, respectively. To solve the first two problems, we introduce a new algorithm, Spatial Event Miner (SEM), which is composed of two sub-algorithms, Event Location Retrieval (ELR) and Event Topic Mining (ETM). In ELR, a hybrid approach including gazetteer and pattern based query, and rank them according to the correl ation. For example, the successful extrac-tion of the locations range from  X  X merica X  to  X  X orld Trade Center X  for the query  X  X eptember 11 2001 X  demonstrates the achievements because World Trade Center is SEM to detect and sum up salient phrases as event topics from the contexts of these locations. The summary of  X  X errorist attacks X  for the same query shows the achieve-ment on Problem 2. Finally, to solve the last problem, we design an easy-to-use inter-face with retrieved locations classified by sp atial scope. With the help of illustration, users can understand the spatial distribution of the events completely. 
A prototype system based on SEM is implemented as shown in Figure 1. The four the selected location.  X  4 geographic information using an online map service. are collected and tested. Thousands of spatia l events are discovered. The results show that with the help of SEM, people can understand the spatial events more effectively. The rest of the paper is organized as follows. Section 2 discusses the related work. Section 3 generally describes the proposed method. Section 4 discusses the algorithms presented in Section 5, followed by the discussion on conclusion and future work. 2.1 Event Location Retrieval including scientific research, vertical search engine, personal annotation mining, etc. Most published algorithms in this category were based on various NLP heuristics. Improved algorithms were also proposed by Bilhaut et al. [2] and Smith et al. [10] on suggestion to apply such techniques to Web pages was first made by McCurley in [6]. His method, however, depends heavily on information such as postal tracts and phone directories that is much harder to come by in most parts of the world. 
More seriously, all the methods mentioned above can only identify locations that found for query  X  X eptember 11 2001 X  only because it was not in the gazetteer. In this paper, a hybrid approach involving gazetteer algorithm and pattern based extraction is introduced into SEM for not only improving the accuracy of the identification but also improving the recall, i.e., finding the locations not exist in the gazetteer. 2.2 Event Topic Mining place (by Allan et al. [1]). Since 1996, it has been well studied in the community of [1]. Yang et al. studied the problem of retrospective and on-line event detection [13], a two stage method was also proposed by them for automated detection of chrono-TDT systems do not directly take geographical location into account. More recently, a new approach of detecting event was put forward by Zhao et al. from the evolution of click-trough data [16]. Instead of their speci al event detection, we focus on detecting events from the general Web pages with respect to the users X  query. 
The summary of events has also been studied for a long history. The work we are concerned is event summarization over locations. Smith studied the subject on mining spatio-temporal events from historical documents [8, 9], which summarizes events popular photo sharing website. Similar subjects on mining spatio-temporal events automatically retrieved from Web pages as summaries. The purpose of SEM is to help users understand the spatial distribution and the detail data from the Web easily and widely. 
Given a query Q , SEM will run as the stream line in Table 1. In Stage 1, since few geographic names can be retrieved by directly querying search engine, we expend the query to collect more spatial information. The details of Stage 1 will be discussed in where some events actually happened. The details of Stage 2 will be discussed in phrases in the snippets as candidate event topics. To extract those events that are most details of Stage 3 will be discussed in Section 4.3. Finally, SEM outputs a list of clas-sified locations, together with their a ssociated event topics and descriptions. Algorithm SEM( Q) 4.1 Data Retrieving and Query Expansion such as  X  X eptember 11, 2001 attacks -Wikipedia, the free encyclopedia X  and  X  X he September 11 Digital Archive X  can be retrieved. 
However these snippets contain few location names. To retrieve more location names for a given query, we define a set of linguistic patterns for retrieving the pages which may contain more location information. In our common sense, geographic phrase often follows a preposition. Therefore, 19 frequently-used location preposi-tions, which are divided into 3 groups as follows, are used by us to expand the query in total. Some example snippets are also listed for each group. P1: such as in , on and at which express an accurate location. Snippet: the history of the September 11, 2001 attacks in New York. P2: such as near , beside and around which express an approximate location. Snippet: Located near the Afghan border. P3: such as above and through which express other location prepositions Snippet: Department records of 911 calls from the World Trade Center. 
We get top l snippets for each expanded query from search engine and put them together to form a snippet collection S . 4.2 Mining Locations for a Query The purpose of this step is to extract the location names from the collected snippets. 
To mine the useful locations from these Web page snippets which are unstructured, noisy and changeful, we employ a gazetteer to recognize the common locations, and a pattern-based approach to recognize the locati ons that are not listed in the gazetteers. 
Gazetteer is used as a dictionary of common geographic vocabulary, which can  X  X ew York X  can be easily extracted by gazetteer for query  X  X eptember 11 2001 X . 
However, it is not enough for a gazetteer to detect the whole geographic space since many location names are seldom known to the public or being created and we utilize 117 patterns divided into 2 groups as follows to give the unmatched noun for the same query mentioned above while gazetteer misses it. Q1: man-made pattern such as XX Building, XX Hospital, XX School etc. Q2: nature pattern such as XX Sea, XX Island, XX Falls etc. 
Now we have collected a set of candidate locations such as  X  X orld Trade Center X ,  X  X os Angeles X  and  X  X sia X . Apparently,  X  X sia X  is not strongly relevant to the query. It is extracted because some Asian media has reported the tragedy. Therefore, a ranking method should be employed. It should assign a higher rank to a more relevant location. I.e.  X  X orld Trade Center X , as where the tragedy happened, should be ranked first.  X  X os Angeles X , as the destination of the accident plane, should also be ranked high. tween the given query Q and the extracted location p . It can be expressed by: means the number for querying Q and p . We place a high weight on the intersection size between Q and p and take the consideration of p  X  X  size as compensation. 
Location Confidence , named as LC ( p ), is used to emphasize the location fre-quently appear after the preposition. For example, given the query  X  X eptember 11 2001 X ,  X  X sia X  and  X  X orld Trade Center X  have similar total appearances. However,  X  X orld Trade Center X  appears more frequently after the preposition, which indicates  X  X orld Trade Center X  connects with the query more closely. means the times that p appears after the preposition. We focus more on the TAP for its confidence and an exponential function is used for this purpose. 
We combine these two properties with multiplication for their both necessity. 
Finally we rank all the extracted locations by their score values and pick up the top m to form a location collection P . 4.3 Summarizing Topics for Query The purpose of this step is to mine the ev ent topics from the extracted locations. Due phrases, we need acquire a better understanding of nature language to find event top-ics. Yet, by our observations as follows, the event topics extraction can be solved by a salient phrase ranking method [15] based on existing data mining techniques. 1. The pages which contain both the given query and its locations often talk about the event happened in this location. For example, the pages containing "September 11 2001" and "World Trade Center" often talk about "attack" or "terrorism". set. For example, "attack" may have more frequency than other terms. 3. The meaningful topics are more likely to be nouns or noun phrases. For example,  X  X ational commission X  is a meaningful topic for "September 11 2001" .

We parse the snippets with an NLP tool and use nouns and noun phrases as our candidates for extracting topics. To demons trate meaningful event topics of a loca-following the statistics features. 
Topic Frequency / Inverted Snippet Frequency ( TFISF ) is defined in the same fashion as TFIDF and could be expressed by number of the snippets containing topic . 
Intra-Cluster Similarity (ICS) [15] is the average cosine similarity between topic  X  X  associated snippets and thei r centroids. It is defined as: Model.
 is the probability of term t occurring in the documents where topic also occurs Topic Independence ( IND ) is used to measure the independence of a topic in [4]. We confirm topic  X  X  independence when its left and right context is random. The fol-lowing is the equation for IND RorL which is the independence value for topic  X  X  left or right context, where 0 X log0 is defined to be 0: ence or absence of topic and variable P , the places contained in snippets. count of snippets containing p i but not topic . The equation for the SS statistics is: 
We use the linear combination of the above five properties as the salience score of topic t : place and select n most salient ones to form a topic collection T. 5.1 Experimental Steps To evaluate the effectiveness of SEM, a prototype system is implemented based on SEM. To step into the experiment, so me preparations are done as follows. 1. The test query set consists of 40 queries are distributed in different fields, such as  X  X Phone X ,  X  X ormula 1 X ,  X  X IDS X  and  X  X ao Ming X , which reflects varied aspects of pre-defined patterns. Each snippet is tagged by a NLP tool, LingPipe 2 . from Wikipedia 3 is used by our system which contains all of the world X  X  continents, contains states and provinces as well as many natural regions. 3. In Section 4.1, top half of the whole ra nked locations are pi cked up. For each loca-tion, top 10 topics are chosen in Section 4.2. To calculate the weights of the linear combination mentioned in Section 4.3, 5 manual labeled queries listed in Table 2 are used which contain total 21 training topics per query and is divided into 10, 5 37.933, -3.597, 0.195, 0.205, and 0.002, respectively. may happen while t 1  X  t 2 can describe the event more detailedly than t 1 . For exam-ple, we query  X  X eptember 11 2001 X  and both  X  X ttacks X  and  X  X errorist attacks X  will be found for place  X  X nited States X . Although the former topic has a higher score, it should be replaced for the detailed description of the latter one. standing of spatial distribution. 
More experiment data including the distribution of 40 queries, patterns for snippets are available in online 5 . 5.2 Results of Place Mining In order to evaluate how effectively each kind of patterns defined in Section 4.2 dis-covers the pages containing places with comparison to traditional Web searching, we take  X  X orld War II X  as an example to check out whether the returned pages contain more location names. The results are shown in the following Table 3. 
Through the experiment we can find that our approach increases the percentage of geographic information quantity in the returned snippets by 40%, especially with P1, the accurate-locations pattern and P2, the approximate locations-pattern. 
In Table 4, the experiment shows the effectiveness of pattern-based extraction of specific place names described in Section 4.2, which share a 4.58% rate in the tions which missed by gazetteer are usually more sensitive to the query. On the other hand, more man-made places are extracted with Q1 pattern than nature places with Q2 pattern. 
Table 6 demonstrates the results of location mining for 10 queries. For each query, query X  X  event locations effectively and accurately. 5.3 Results of Topic Mining Table 7 shows event topics summary for 4 input queries. Here presents top 3 locations event are meaningful. 5.4 Case Studies 5.4.1 Time and Domain Restriction in the Topic prove the result. For example, historical venues will be extracted when directly query-ing  X  X AKDD X . However, if we restrict the time of  X  X AKDD X  to  X 2008 X , we will get the more accurate location:  X  X saka X  and  X  X apan X . 5.4.2 Time Evaluation in Event Search As we know, the number of Web pages increases every minute especially when a topic becomes hot. Table 9 shows the location for query  X  X ormula 1 X  at September 6 and 11 respectively. In the former result,  X  X pain X  and  X  X aris X  become hot because of has come to an end with the winner of Alonso in September 9. In this paper, we studied the problem of event location retrieval and event topic sum-mary from the Web. The main contributions are: 1. The proposal to study the problem of spatial event mining with the general Web. 2. The proposal of SEM, for mining location information and summarizing event topics from the general Web in which data is unstructured, noisy and changeful. 3. The implementation of SEM and a friendly interface with geographic support which offer an easy understanding for spatial distribution. and disambiguously, based on which, more experiments will be done to evaluate SEM. 
