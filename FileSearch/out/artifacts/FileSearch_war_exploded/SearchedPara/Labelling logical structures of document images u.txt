 ORIGINAL PAPER Yves Rangoni  X  Abdel Bela X d  X  Szil X rd Vajda Abstract This paper proposes a new method for labelling the logical structures of document images. The system starts with digitised images of paper documents, performs a phys-ical layout analysis, runs an OCR and finally exploits the OCR X  X  outputs to find the meaning of each block of text (i.e. assigns labels like  X  X itle X ,  X  X uthor X , etc.). The method is an extension of our previous work where a classifier, the per-ceptive neural network, has been developed to be an analogy of the human perception. We introduce in this connection-ist model a temporal dimension by the use of a time-delay neural network with local representation. During the recog-nition stage, the system performs several recognition cycles and corrections, while keeping track and reusing the pre-vious outputs. This dynamic classifier allows then a better handling of noise and segmentation errors. The experiments have been carried out on two datasets: the public MARG con-taining more than 1,500 front pages of scientific papers with four zones of interest and another one composed of docu-ments from the Siggraph 2003 conference, where 21 logical structures have been identified. The error rate on MARG is less than 2.5% and 7.3% on the Siggraph dataset.
 Keywords Document image analysis and recognition  X  Layout analysis  X  Logical labelling  X  Perceptive neural network  X  Time-delay neural network 1 Introduction The role of a document image analysis and recognition (DIAR) system is to provide an electronic and editable ver-sion of a paper document. For example, a user wants to find quickly some interesting documents inside a corpus, based on some keywords. He could use a plain-text search while an Optical Character Recognition (OCR) would be able to extract the text from the pages. However, generally it is a waste of time for the user and also the content providers, dig-ital libraries or publishers (e.g. CiteSeer, European Library, Library of Congress, Springer, Elsevier, etc.). The raw results of an OCR appear insufficient when the user needs to focus on some structural metadata such as specific titles, list of authors, paragraphs, tables. Indeed, both users and content providers prefer working on a specific part of the docu-ment ( X  X he advanced search X ) to focus their search on more meaningful zones like  X  X itle X  or  X  X uthor X . For an advanced query, the amount of computations is reduced and it should return less but more interesting documents for the reader [ 9 , 29 ]. On top of that, if the document is fully zoned (i.e. each zone has a logical label), it can be easily transformed, reformatted or reorganised; process which is really impor-tant for all viewer devices, especially for handheld devices [ 19 ]. Thus, the automatic labelling of documents is highly desirable [ 2 ]. Several large scale digitisation initiatives such as the Million Book project, the efforts of the Open Con-tent Alliance, or the digitisation works of Google [ 13 , 15 ], want to make the logical structures available in their systems to provide richer browsing and searching experience for the public.

Getting the logical information is a task that can be done easily by a human, but actually it is still an open problem for a computer. More precisely, it is still widely done man-ually for documents where scanned or paper versions are only available. Indeed, the logical structure extraction is a challenging problem due to the inherent complexity of the documents. Starting at the pixel level, the gap between physi-cal observations and logical interpretations is huge. The goal is to find the best labelling function which maps a logical label to each block of the physical page layout. To deal with this issue, two types of approaches have been considered in the literature: model-driven and data-driven [ 36 ].
The model-driven approach is the most frequent one. It needs a representation of the knowledge, a model, to inter-pret the input data. The model contains all the information necessary to transform a physical structure into a logical one. Usually, these models are made up either by rules, or trees, or grammars. Syntactical analysis is often employed to perform the labelling [ 36 ]. Rule-based systems such as [ 22 , 24 , 30 ]are fast and human-understandable but are poorly flexible and cannot really handle difficult cases and varying layouts. To avoid writing huge lists of empirical rules, knowledge dat-abases or thesaurus can be considered as proposed for exam-ple by [ 14 , 25 , 50 ]. However, it requires on the other hand the reading and understanding of the text. This implies other issues.

Grammars are also very popular solutions [ 10 , 21 , 26 ]. The physical and logical layouts are described as a sentence of tokens while syntactic parsers do the labelling. They pro-duce deterministic models which are improper for process-ing noisy documents. Stochastic extensions [ 52 ] or extended formalisms [ 12 ] have been proposed in order to overcome this issue.

Although model-driven approaches seem to transcribe the structure hierarchy, some drawbacks still remain. They are not designed to handle complex and noisy document struc-tures. Moreover, a lot of parameters need to be tuned. The model building requires an expert and cannot deal with all the possible interpretations of a document.

The data-driven approaches make use of raw physical data to analyse the document and no knowledge or static rules are given. The underlying idea is to let the system find the labelling function by itself and stop relying on rules or heuristics of an expert. Few contributions using classical-machine-learning tools like Neural Networks (NNs) can be found in the literature [ 45 , 46 ]. There are chiefly extensions of model-driven systems where a training stage is introduced. In that case, grammars are still popular [ 8 , 18 ]. NNs are used in other steps of DIAR and are appreciated for their robust-ness faced to noisy data. Indeed, NNs are largely exploited in image preprocessing and physical layout analysis as related in the survey of [ 39 ]. However, NNs are deprecated because of the workload of the training process (the ground truth doc-uments are expensive to produce and the learning stage can be slow). Furthermore, they are not really designed to work on structured patterns and do not integrate domain-specific knowledge.

In this paper, we introduce an extension of our previous work [ 44 ] where we have proposed to combine capabilities of model-driven and data-driven approaches, respectively. It is based on a hybrid method using a special kind of NN with local representation, the so-called Percepto by [ 11 ] or Trans-parent Neural Network by other authors [ 34 ].

The architecture is with a local representation. Our model incorporates the two structures, both physical and logical, as concepts in the neurons. A training stage allows learning the relationships between the two structures from samples. The recognition is not only a classic forward propagation over the NN, but it performs many perceptive cycles as well. A perceptive cycle consists in forwarding the physical fea-tures, getting the logical output, and if an ambiguity occurs, correcting the input vector according to what it has been seen during the recognition. Considering that the system will deal with erroneous input features, it can refine the recogni-tion progressively thanks to the input correction. We called it PNN for Perceptive Neural Network. The new contribution consists in implanting into the previous PNN the time dimen-sion. As the network is working with different and corrected input features at eachcycle, weintroducetheusageof aTime-Delay Neural Network (TDNN) which takes into account the results of the previous perceptive cycles at times T  X  n while making a decision at time T . The extended system, called Dynamic Perceptive Neural Network (DPNN), as opposed to PNN which is static, is as fast as its predecessor (PNN), thanks to a better behaviour during the recognition step.
The paper is organised as follows: the next section describes the PNN X  X  running and analyses its drawbacks. Section 3 introduces the Dynamic PNN extension, based on a TDNN. Finally, Sect. 4 reports experimental results and dis-cussion on the MARG dataset and a new dataset we created. This contains scientific papers as well but with more logical labels to be identified. 2 Perceptive neural network This section describes our previous work before introduc-ing the extension in Sect. 3 . By outlining the most important points from it, we hope it will prevent the reader to refer to several other papers.

The initial Perceptive Neural Network itself borrowed someideasfromthePerceptosystemintroducedbyC X t X [ 11 ]. Percepto is a perceptual model designed for handwritten word recognition, based on the [ 40 ] reading mode. The main idea is to integrate knowledge as interpretable concept asso-ciated to each neuron. Contrary to a classical Multi-Layer Perceptron(MLP)[ 28 ],alltheneuronsaretransparent,which means each output is known. There are no hidden layers at all. The network has a  X  X ocal representation X  as opposed to a distributed representation like a MLP. The recognition is performed through several bottom-up and top-down pro-cesses (perceptive cycles) just like human vision operates.
The Percepto architecture is organised in layers of neurons. The activation function works with saturation. It accumulates only positive activation, and there is no compe-tition between the neurons. The activation function A is given by ( 1 ), where  X  i is a decreasing constant, r i is the activation threshold, E i ( t ) the neighbourhood contribution, M and m are respectively superior and lower activation bounds,  X  ij and  X  ij are the positive and negative stimulations from j to i a ( t ) is the activation of the node j .
 A ( t +  X  t ) = A E ( t ) = n i n ( t ) =
The main concepts of the Percepto system were retained for our PNN. In [ 5 , 43 , 44 ], it has been shown how this model for handwriting recognition can be adapted to logical docu-ment zoning. We have shown its utility for the logical struc-ture recognition. The input data corresponds to text blocks (bounding boxes). The extracted features are related to the text block descriptions (e.g. style, font, etc.), while the output designates the logical labels.

As reported in [ 41 ] concerning logical structure recogni-tion, a perceptive and knowledge guided solution seems to be more appropriate to cope with the gap between physi-cal observation and logical interpretation. That is the reason why a regular MLP is not adapted: knowledge is difficult to integrate and it behaves as a  X  X lack-box X , resulting in a complex understanding of its behaviour [ 17 ]. The PNN has  X  X rganised X  neurons and each of them corresponds to an interpretable concept and it is linked to an element of the logical structure. Excluding the first layer containing the physical inputs, the following layers unfold the logical layout by introducing fine concepts in the first layers and general/coarse concepts in the following layers. The Fig. 1 presents an instance of the PNN used for logical labelling of scientificarticles.Inputfeatures(geometrical,morphological and semantic) make up the first layer, the second layer con-tains logical labels while the third layer includes coarse con-cepts called context. The context is provided by the expert. It is during the construction of this context that the  X  X nowl-edge X  mentioned before is brought. For our application, we decided to follow the logical splitting of the text. As pro-posed by the Text Encoding Initiative 1 (TEI), we created five independent concepts (front, heading, body, closing, back) clustering all the logical labels.

In the former system [ 11 ] the connections between adja-cent layers were bidirectional and only stimulating (just positive activation values were forwarded). Moreover, the connection weights were determined manually according to some prior knowledge. This choice sounded inappropriate in the case of logical structure recognition as the relationships between the layers are not straightforward. Thus, we have chosen to perform a training phase for the PNN, similar to MLP, in order to compute all the weights w according to the input patterns x p . As opposed to Percepto, the PNN is fully connected and the connections can be inhibitive. The train-ing is done by a gradient descent algorithm. The error E p between the desired output d q and the computed output o l is minimised for each input pattern p ( 2 ) where L stands for the last layer.
 E o The weight between the unit i in layer l and j in layer l is modified according to ( 3 )[ 28 ]. w where f is an activation function (e.g. the sigmoid).
All the neurons carry interpretable concepts, so the desired output is known for all of them. The partial term is given by ( 4 ) and the PNN can be trained as a cascade of mono-layer Perceptrons (no hidden layers included).  X  l ,
During the recognition step, the PNN is employed such as a MLP, but after each propagation, the outputs are ana-lysed. It means that if the output vector is close to a canonical basis vector ( 5 ) and ( 6 ), the pattern is considered as classi-fied. Otherwise, the following layers (the context) are taken into account to inject additional information. We defined two rejection criteria: M ( O ) checks if the vector has at least one component with a high value (close to 1) and ( O ) checks if the greatest component has a value largely higher than all the other components. These rules decide when a block is accepted or some corrections are needed.
 M ( O ) = O  X  &gt; X  with 0  X &lt; 1(5) (
O ) =
The final layers contain global information and coarse concepts, but they are more robust and easier to find. They can be used to generate hypothesis on the pattern. This con-text information manages the correction of the input features. Once a label is supposed to be the good one, the input vector is corrected according to this hypothesis. Actually, during the training step, several representative samples, or proto-types, for each logical label are extracted from the training set. The correction consists in modifying the current input to make it closer to a representative sample. The correction is mainly focused on the block bounding boxes: merging blocks together or splitting them into smaller sub-blocks. The rules are straightforward. If a block contains several lines and the hypothesis indicates that the bounding box for this kind of label is smaller, the current box is split into a different num-ber of lines in such a way that its new dimensions better fit a correct prototype (Fig. 3 ).

More precisely, when extracting the representative sam-ples,ak-meansalgorithmisusedtostorethewidth,theheight and the number of contained lines. Three possible candidates are determined for each class. One of the most likely repre-sentative samples for the  X  X uthor X  label could be the vector ( 20 ; 0 . 2 ; 1 ) , which means that the candidate is 20% of the page width, 0.2% of the height and contains 1 line. If an ambiguous block comes to the PNN with the hypothesis of being an  X  X uthor X  and with the vector ( 18 ; 1 ; 3 ) , we look if it can be divided and if so, we try the best split. Here, it could be split after the first line which produces the vectors ( 18 ; 0 . 3 ; 1 ) and ( 18 ; 0 . 7 ; 2 ) . The corresponding bounding boxes have better chance now to be labelled as  X  X uthor X  and  X  X ffiliation X .
 Mergingblocksoccursrarely,becausethebehaviourofthe OCR [ 1 ] is mainly under-segmentation. It could be supposed that it uses a fast top-down approach which stops dividing the blocks, maybe a little bit too early when they are considered sufficiently homogeneous. In the rare case when two consec-utive blocks are ambiguous, we merge them. At the end, it amounts to correct the physical layout analysis where errors occur quite often [ 23 , 54 ]. Perceptive cycles are completed in a loop (Fig. 2 ) until no ambiguity persists (i.e. ( 5 ) and ( 6 ) are fulfilled).

The perceptive cycles (propagation-correction) allow a bottom-up and top-down resolution and refine the recogni-tion. However, if too many cycles must be performed, the process could be time consuming because it implies many physical extractions. In order to face this problem, the solu-tion could be to prune some unnecessary extractions. Instead of feeding the network with the whole amount of features at each cycle, they are introduced progressively, in groups, during the recognition and only if the pattern is considered to be too ambiguous. The groups are the result of a clus-tering of the full set of features (e.g. geometrical, morpho-logical and semantic). This simulates at the same time a global and local vision of the recognition. It is global when using the context information and hypothesis generation; and local when extracting or correcting specialised features. The input data clustering does not improve the recognition quality, but for the same recognition rates the speed-up is considerable.

Technically speaking, as the number of features is not con-stant, we create as many PNNs as clusters. In the implemen-tation, the number of clusters is set to three, so three PNNs are used. If the groups of variables can be defined arbitrary as suggested in Fig. 1 , the input feature space can also be divided automatically according to several criteria. We pro-posed in [ 44 ] a fast filter-based selection [ 7 ] to construct subsets of variables. It ranks the subsets by predictive power and in each of them the variables are the most independent as possible. It avoids redundant variables, and allows feeding the PNN with relevant information. 3 Dynamic perceptive neural network This section describes the contribution we propose in this work. First we show why the PNN is perfectible and secondly wepresenthowtoextendthePNNinadynamicmodel,which provides a better behaviour during the recognition stage. 3.1 Static recognition with dynamic data As mentioned in Sect. 2 , a PNN is based on a static model but is improved to manage knowledge and input data correc-tion. During the recognition, several forwards are performed with possibly corrected inputs. As the segmentation is often corrected, it snowballs most of the features in the input vec-tor. However, the network is trained only once, with a fixed training database. Indeed, the features until now called x are different for each cycle. The x i should be named x i where t is the number of the current perceptive cycle. Unfor-tunately, the weights w l i , j are always constant scalars and are not adapted to x i ( t ) because x i ( 0 ) =  X  X  X  = x i ( n
The contribution of this paper is to demonstrate how to integrate the data correction occurring between each percep-tive cycle within the training step. The goal is to modify the training schema in such a way as the recognition step has a more appropriate behaviour. 3.2 Considering temporal dimension with a time-delay The Time-Delay Neural Network (TDNN) can handle this kind of unsettled data. Contrary to a MLP, where the output o j depends on the outputs of the preceding layer, the out-put of a neuron o ( t ) at time t in a TDNN corresponds to a weighted sum of the past delayed values ( 7 ). o ( t ) =
There are two main methods to train such a network. The first one removes all time delays by unfolding the network into an equivalent static structure [ 32 ], but this method is not used in practice (time consuming). The second solution is an extension of the back-propagation algorithm called tempo-ral back-propagation. The idea is to consider the weights as constants when computing an approximation of the gradient ( 8 ) of the cost function Err ( 9 ).
 Err =  X 
Err  X  With a complete derivation of the terms [ 53 ], the weights are updated according to ( 10 ).
 W with X l i ( n ) =[ x l i ( n ), x l i ( n  X  1 ),..., x l defined by ( 10 ). ( k ) =
If W and X are considered as scalars, the algorithm is sim-ilar to the back-propagation for static networks. The Algo-rithm 1 summarises the main steps of the training.
This dynamic training is slower than the static back-propagation one, even if T = 1. This is due to the presence of vectorial data instead of scalars. The algorithm also suffers from the same drawbacks as those of the clas-sic back-propagation one [ 31 ], especially convergence prob-lems, which are amplified by the new T parameter [ 42 , 51 ]. These are some of the possible reasons why TDNN are not so common, and why other methods such as HMM are preferred when a problem requires the time dimension [ 33 ].
Fortunately, in the case of logical structure extraction, the T factor depends on the number of perceptive cycles. Some experiments have shown that T can be small for the Static PNN (SPNN). On top of that, as the weights are more suitable now to the current input X i , the number of cycles can be lower compared to the static version. Moreover, each X is given by the same OCR and the variation between the data ( X i ( t )  X  X i ( t  X  1 ) &lt; ) is rather small. We have chosen to set T = 2 for the Dynamic PNN, which means 3 perceptive cycles. It is a reasonable trade-off between accuracy and time consumption. 3.3 Training and recognition with the DPNN 3.3.1 Training Unlike the Static PNN, the training database for a Dynamic PNN has to be modified to integrate the time dimension. The raw (uncorrected) outputs of a commercial OCR [ 1 ]are collected to have the feature vectors at time t = 0. Then, a manual correction is performed on the segmentation: the erroneous bounding boxes are tuned to match with logical elements. It is sometimes necessary to merge or split some bounding boxes (Fig. 3 ). The OCR is run another time on the new segmentation and the outputs are kept to feed data at time t = 1. These data are also modified manually for the second time and provide the network inputs at time t = 2.
These manual corrections could be tedious, but not impos-sible to handle. The system needs some ground truth docu-ments as a first bootstrapping and the user has to correct and label manually several documents (assuming there is no other ready-to-use material to start a training). Then, it can continue the ground truth generating process by using a first trained DPNN, with a high rejection rate and tries to use it for a new semi-automatic labelling of another set of document in order to make the training/testing dataset growing. This manual effort is not more difficult than any other data-driven methods, and it is a very profitable contribution to large and homogeneous datasets. 3.3.2 Recognition The recognition step is similar to the static version one. The input data are extracted first, then passed in the DPNN with t = 0. The outputs are analysed and if the answer is ambig-uous ( 5 ) and ( 6 ), the input features are corrected by resizing the bounding box as it was already done in the static case. Another perceptive cycle follows with a new OCR extraction but on the DPNN with t = 1, where the information of t = 0 is taken into account. A last cycle is finally executed, using the current extraction results and the previous ones at times t = 1 and 0.

Additional perceptive cycles can be considered and two solutions can be considered. Planning more cycles during the training stage, even if it means to stop the correction of the input data after t &gt; 2. It is also possible and more appropriate to keep the same network, but shifting the data with t  X  t as the  X  X apped delay line X  [ 20 ] of the TDNN (Fig. 4 ). That would amount to reduce the memory capability by remem-bering only the latest events and discard the first extractions which were maybe too erroneous. 4 Experimentations 4.1 The MARG dataset There are just a few available datasets and few contribu-tions reporting results involving these data. We applied the DPNN on the publicly available dataset MARG (Ground Truth Data for Biomedical Journals) of [ 16 ] which is one the most used ones, even though it is not the best test scenario for our DPNN. MARG contains binarized, skew corrected images. They are title pages of medical journal articles and the corresponding ground truths are given. There are 1 , 553 images divided into 8 classes (named with letters A to H) depending on their layout type, plus an additional class  X  X thers X , where all the unusual article layouts belong. The images are logically labelled with four labels:  X  X itle X ,  X  X uthors X ,  X  X ffiliation X  and  X  X bstract X . The frequencies of each class and a visual aspect of the layouts are given in Table 1 .

We made 10 rounds of cross-validations by splitting the database every time in two equal parts between training and validation. The results are averaged over the rounds to reduce variability. The 10  X  2 sets were chosen with a controlled random seed, sothat theexperimentationis reproducible. The initial segmentation and all the physical features (Table 2 ) were obtained with the [ 1 ] OCR.

Ourfeaturesarethedirecttranscriptionsofthosedescribed in the complete schema [ 47 ]. What we called Geometri-cal features corresponds to the  X  X lockType X  of the schema. We added the Up/Bottom/left/Right space values which are the widths of the white margins between a block and the other blocks around it. Morphological features are the com-bination of  X  X ormatting type X  and  X  X aragraphType X  of the schema. As some features are only given at the word or char-acter level (e.g. boldness), we computed the global ratio at the block level by an elementary cross-multiplication rule. The Semantic features are mostly taken in the  X  X harParams-Type X  section of the schema. We added in it:  X  X ullet X  and  X  X num X  to describe if some bullet or enumeration symbols are found in the text. The Keywords feature describes if a predefined word is found in the text. The keyword set is { X  X bstract X ,  X  X ntroduction X ,  X  X eyword X ,  X  X able X ,  X  X igure X ,  X  X on-clusion X ,  X  X eferences X ,  X  X ppendix X  X . Except this last feature, all the others can be extracted by most of the commercial OCR (e.g. FineReader, Omnipage, ReadIris) and are also listed in the ALTO (Analyzed Layout and Text Object) XML Schema [ 3 ].

The Fig. 5 shows the box-and-whisker diagrams of the recognition rates obtained for each type of layout. In addi-tion to sample min/max, lower/upper quartile and median, we added the mean with a blue round dot.
It can be shown that whatever the layout type is, the results are always good. The easiest layout types were  X  X  X ,  X  X  X  and  X  X  X , while the hardest was the  X  X thers X  type. Com-pared to what can be found in the literature, the results are satisfactory [ 36 ], although the DPNN was designed to treat more logical labels (more than a dozen) and few layout clas-ses. The MARG dataset is somewhat the opposite. There are few labels and several layout classes.

A lot of methods exist in the literature, but most of them have been tested on confidential documents or on small data-sets. Furthermore, the wide range of input features, labels, training/testsets,etc.makesthecomparisonsalmostimpossi-ble. Recently, [ 6 ] published a work on example-based logical labelling of document title page images. Firstly, they reported the few other representative works where the MARG data-set was used: [ 24 ] with a rule-based system obtained 96.7%, [ 35 ] with also a rule-based system obtained 86% (due to a bad recognition of the affiliations) and [ 37 ] with a hid-den semi-Markov model obtained 91%. [ 6 ] pointed the fact that the MARG dataset was not considered in its totality and that only subsets of it were used. Secondly, they introduced a lightweight method with a similarity measure for layout combining structural layout and textual similarity. The fea-tures they employed are fast to extract and the matching step is also fast, flexible and efficient. They obtained on the full MARG dataset accuracy rates from 94.8 up to 99.6% with an average of 97.8%.

Our rates are ranging from 94.6 to 99.7%, with a global average of 97.5%. At first glance, [ 6 ] can obtain up to 99.6%, but we are also acting in different conditions. Indeed, to reach 99.6% on all the 1,553 images, they used a leav-ing-image-out cross validation, which means that the label-ling of one document is determined knowing the label-ling of all the 1,552 others documents. Analogously, the leaving-journal-out gives 98.9% by testing documents of the same journal (a dozen in average) knowing all the other doc-uments. Finally, the leaving-type-out gives 94.8%, meaning that the tests where done on one type of layout knowing all the other types which roughly means that 90% of the full dataset is used for training (exact proportions can be deduced from Table 1 ).

For the MARG dataset, we did not use the context layer because 4 labels are too few to have a helpful context. The first cycle gives roughly 80%, while the second one is around 95% and 97.5% for the last one. Most of the errors are due to the bad recognition of the affiliations, which are most of the time labelled as authors. However, we do not have poor result on the label  X  X ffiliation X  like in the work of [ 35 ]. The percep-tive cycles are able to correct most of the miss-segmentations when a big block includes both lines of  X  X uthors X  and  X  X ffil-iations X . The dynamic version of the PNN is better than the static one. Only the class  X  X  X  was requiring a lot of correction. This class  X  X  X  was also difficult because some documents were really different one from one another. There were also some pages with missing labels (e.g. layout122/14230829, layout122/14234603,...), complex layouts of affiliations and abstracts (e.g. layout122/15111832), and also, accord-ing to us, some errors in the ground truth (e.g. lay-out122/18447737 or layout122/18628210: Abstract is the full body of the document (Fig. 6 ), sometimes the keyword lines are included in the abstract for layout122/18445612, sometimes excluded for layout122/18447737, missing title in layout 122/18583868, etc.) 4.2 The siggraph dataset The DPNN was designed to deal with several labels in order to propose a complete document analysis, meaning that all the blocks must have a label. The MARG dataset is somewhat different: with few labels and several clas-ses of documents. In our best knowledge, there is no pub-licly available dataset containing a full physical and logical description of the documents. For this purpose, we have cre-ated a more detailed dataset. It is composed of 74 papers from the ACM Siggraph 2003 conference [ 48 ]. The docu-ments are scientific articles in Portable Document Format (PDF) having a considerable amount of logical structure ele-ments.
 The PDFs were printed at 600 dpi with a laser printed HP Color LaserJet 4650 PCL 2 and then digitised with a digi-tal copier-printer-scanner device Gestetner DSm745 3 at 600 dpi in black and white (Fig. 7 ). In these 74 documents, 21 logical structures have been identified (Table 2 ) for a total of more than 2,000 patterns. The input feature information is still coming from the commercial OCR [ 1 ]. The training stage uses 44 documents and the remaining 30 are consid-ered for testing. The results of the Dynamic PNN are shown in the last columns of the Table 3 . We also reported the results obtained with a Static PNN with details for each cycle and a regular MLP.

After three cycles, the Static PNN can already outperform almost 10 points of recognition rate than a simple MLP (from 81.7 to 90.2%), but the extraction time is multiplied by a fac-torof1 . 85. It has been shown, that three perceptive cycles are a good trade-off between quality and speed. A possible fourth cycledoesnotbringhighlybetterrecognitionandslowsdown the recognition (not in Table 3 : 91.7% for recognition and 2.1 speed factor for time extraction). Here, the Dynamic PNN is better than the SPNN with 3 and also with 4 cycles. It can reach 92.7% with a 1.8 time factor. Although the training of the DPNN is up to 10 times slower than for the SPNN, the propagation of the inputs inside the network during the recog-nition is neglectable compared to OCR extractions. Results show that the 3-cycle DPPN is more accurate and faster than a 4-cycle SPNN. For the Siggraph dataset, the DPNN clearly outperforms the static version.

The Table 4 gives a closer look at the recognition rates for each logical label. The DPNN never returns worse results than the SPNN. The fact of using results from preceding cycles is favourable for the DPNN. On the other hand, the DPNN cannot return tremendous results. It fails also on dif-ficult cases. For instance, the  X  X cknowledgment X  and  X  X on-clusion X  are still not very well recognised. With the exception of segmentation problems, to which we can find a solution with more appropriate algorithms [ 4 ]; we still have problems with these types of labels: the bounding boxes and phys-ical features are correct, but we think that more informa-tive features are missing to deal with this kind of logical labels.

The results we obtained are difficult to compare with other reported results in literature, for the reasons we described before. We did not find publications using as many labels as we did. For example, if we refer to the work of [ 26 ], which deals with a similar dataset of document images, they obtained a recognition rate of 94.4% for 9 labels (Title, Author, Page Number, Abstract, KeyWords, Copyright, Sec-tion, Algorithm, Float). With the same set of logical labels, our DPNN reaches 96.3%. 5 Conclusions We presented an extension of the Static Perceptive Neural Network to a dynamic version, called Dynamic Perceptive Neural Network, using a Time-Delay Neural Network. The new network architecture is designed to recognise the logical structures in document images with several cycles of recog-nition-correction.

The method uses all the concepts of the static version: introduction of knowledge in each neuron, network topol-ogy in hierarchy from fine (the labels to recognise) to coarse (the global context), analysis of the outputs and correction of the inputs (perceptive cycles), input feature clustering for speeding up the recognition.

We introduced the time dimension in the network allowing to take into account the inputs of the preceding cycles during the recognition step. The static version has been extended through the usage of a TDNN. As a consequence, the pro-posed DPNN is more flexible and more adapted to handle the variability of the input features between each cycle. The correction of these features is also much more efficiently supervised thanks to the weight adaptations provided by the TDNN architecture.

The previous SPNN was already giving encouraging resultsandtheDPNNimprovestheexistingrecognitionrates. The DPNN has been tested on the MARG dataset and has been compared with other methods in the literature. Although it was not specifically designed to deal with such a database, it is able to outperform most of the previous methods, espe-ciallythoseusingrule-basedsystemsandgivessimilarresults to the state-of-the-art on this dataset. As there are no publicly available datasets with many different labels to be recogni-sed, we tested the model on a set of documents where 21 log-ical structures have been considered. The experiments show that the DPNN outperforms the SPNN and gives roughly 93% of recognition rate versus 90% for the same processing time.

In a future work, we plan to integrate a partial or totally recurrent network in order to provide an architecture with a temporal and space recurrence [ 27 , 49 ]. A further step will be to identify and test more informative input features for dealing with highly difficult cases where it seems that  X  X ead-ing X  and  X  X nderstanding X  the content of a block of text is necessary to find the right label for it.
 References
 ORIGINAL PAPER Yves Rangoni  X  Abdel Bela X d  X  Szil X rd Vajda Abstract This paper proposes a new method for labelling the logical structures of document images. The system starts with digitised images of paper documents, performs a phys-ical layout analysis, runs an OCR and finally exploits the OCR X  X  outputs to find the meaning of each block of text (i.e. assigns labels like  X  X itle X ,  X  X uthor X , etc.). The method is an extension of our previous work where a classifier, the per-ceptive neural network, has been developed to be an analogy of the human perception. We introduce in this connection-ist model a temporal dimension by the use of a time-delay neural network with local representation. During the recog-nition stage, the system performs several recognition cycles and corrections, while keeping track and reusing the pre-vious outputs. This dynamic classifier allows then a better handling of noise and segmentation errors. The experiments have been carried out on two datasets: the public MARG con-taining more than 1,500 front pages of scientific papers with four zones of interest and another one composed of docu-ments from the Siggraph 2003 conference, where 21 logical structures have been identified. The error rate on MARG is less than 2.5% and 7.3% on the Siggraph dataset.
 Keywords Document image analysis and recognition  X  Layout analysis  X  Logical labelling  X  Perceptive neural network  X  Time-delay neural network 1 Introduction The role of a document image analysis and recognition (DIAR) system is to provide an electronic and editable ver-sion of a paper document. For example, a user wants to find quickly some interesting documents inside a corpus, based on some keywords. He could use a plain-text search while an Optical Character Recognition (OCR) would be able to extract the text from the pages. However, generally it is a waste of time for the user and also the content providers, dig-ital libraries or publishers (e.g. CiteSeer, European Library, Library of Congress, Springer, Elsevier, etc.). The raw results of an OCR appear insufficient when the user needs to focus on some structural metadata such as specific titles, list of authors, paragraphs, tables. Indeed, both users and content providers prefer working on a specific part of the docu-ment ( X  X he advanced search X ) to focus their search on more meaningful zones like  X  X itle X  or  X  X uthor X . For an advanced query, the amount of computations is reduced and it should return less but more interesting documents for the reader [ 9 , 29 ]. On top of that, if the document is fully zoned (i.e. each zone has a logical label), it can be easily transformed, reformatted or reorganised; process which is really impor-tant for all viewer devices, especially for handheld devices [ 19 ]. Thus, the automatic labelling of documents is highly desirable [ 2 ]. Several large scale digitisation initiatives such as the Million Book project, the efforts of the Open Con-tent Alliance, or the digitisation works of Google [ 13 , 15 ], want to make the logical structures available in their systems to provide richer browsing and searching experience for the public.

Getting the logical information is a task that can be done easily by a human, but actually it is still an open problem for a computer. More precisely, it is still widely done man-ually for documents where scanned or paper versions are only available. Indeed, the logical structure extraction is a challenging problem due to the inherent complexity of the documents. Starting at the pixel level, the gap between physi-cal observations and logical interpretations is huge. The goal is to find the best labelling function which maps a logical label to each block of the physical page layout. To deal with this issue, two types of approaches have been considered in the literature: model-driven and data-driven [ 36 ].
The model-driven approach is the most frequent one. It needs a representation of the knowledge, a model, to inter-pret the input data. The model contains all the information necessary to transform a physical structure into a logical one. Usually, these models are made up either by rules, or trees, or grammars. Syntactical analysis is often employed to perform the labelling [ 36 ]. Rule-based systems such as [ 22 , 24 , 30 ]are fast and human-understandable but are poorly flexible and cannot really handle difficult cases and varying layouts. To avoid writing huge lists of empirical rules, knowledge dat-abases or thesaurus can be considered as proposed for exam-ple by [ 14 , 25 , 50 ]. However, it requires on the other hand the reading and understanding of the text. This implies other issues.

Grammars are also very popular solutions [ 10 , 21 , 26 ]. The physical and logical layouts are described as a sentence of tokens while syntactic parsers do the labelling. They pro-duce deterministic models which are improper for process-ing noisy documents. Stochastic extensions [ 52 ] or extended formalisms [ 12 ] have been proposed in order to overcome this issue.

Although model-driven approaches seem to transcribe the structure hierarchy, some drawbacks still remain. They are not designed to handle complex and noisy document struc-tures. Moreover, a lot of parameters need to be tuned. The model building requires an expert and cannot deal with all the possible interpretations of a document.

The data-driven approaches make use of raw physical data to analyse the document and no knowledge or static rules are given. The underlying idea is to let the system find the labelling function by itself and stop relying on rules or heuristics of an expert. Few contributions using classical-machine-learning tools like Neural Networks (NNs) can be found in the literature [ 45 , 46 ]. There are chiefly extensions of model-driven systems where a training stage is introduced. In that case, grammars are still popular [ 8 , 18 ]. NNs are used in other steps of DIAR and are appreciated for their robust-ness faced to noisy data. Indeed, NNs are largely exploited in image preprocessing and physical layout analysis as related in the survey of [ 39 ]. However, NNs are deprecated because of the workload of the training process (the ground truth doc-uments are expensive to produce and the learning stage can be slow). Furthermore, they are not really designed to work on structured patterns and do not integrate domain-specific knowledge.

In this paper, we introduce an extension of our previous work [ 44 ] where we have proposed to combine capabilities of model-driven and data-driven approaches, respectively. It is based on a hybrid method using a special kind of NN with local representation, the so-called Percepto by [ 11 ] or Trans-parent Neural Network by other authors [ 34 ].

The architecture is with a local representation. Our model incorporates the two structures, both physical and logical, as concepts in the neurons. A training stage allows learning the relationships between the two structures from samples. The recognition is not only a classic forward propagation over the NN, but it performs many perceptive cycles as well. A perceptive cycle consists in forwarding the physical fea-tures, getting the logical output, and if an ambiguity occurs, correcting the input vector according to what it has been seen during the recognition. Considering that the system will deal with erroneous input features, it can refine the recogni-tion progressively thanks to the input correction. We called it PNN for Perceptive Neural Network. The new contribution consists in implanting into the previous PNN the time dimen-sion. As the network is working with different and corrected input features at eachcycle, weintroducetheusageof aTime-Delay Neural Network (TDNN) which takes into account the results of the previous perceptive cycles at times T  X  n while making a decision at time T . The extended system, called Dynamic Perceptive Neural Network (DPNN), as opposed to PNN which is static, is as fast as its predecessor (PNN), thanks to a better behaviour during the recognition step.
The paper is organised as follows: the next section describes the PNN X  X  running and analyses its drawbacks. Section 3 introduces the Dynamic PNN extension, based on a TDNN. Finally, Sect. 4 reports experimental results and dis-cussion on the MARG dataset and a new dataset we created. This contains scientific papers as well but with more logical labels to be identified. 2 Perceptive neural network This section describes our previous work before introduc-ing the extension in Sect. 3 . By outlining the most important points from it, we hope it will prevent the reader to refer to several other papers.

The initial Perceptive Neural Network itself borrowed someideasfromthePerceptosystemintroducedbyC X t X [ 11 ]. Percepto is a perceptual model designed for handwritten word recognition, based on the [ 40 ] reading mode. The main idea is to integrate knowledge as interpretable concept asso-ciated to each neuron. Contrary to a classical Multi-Layer Perceptron(MLP)[ 28 ],alltheneuronsaretransparent,which means each output is known. There are no hidden layers at all. The network has a  X  X ocal representation X  as opposed to a distributed representation like a MLP. The recognition is performed through several bottom-up and top-down pro-cesses (perceptive cycles) just like human vision operates.
The Percepto architecture is organised in layers of neurons. The activation function works with saturation. It accumulates only positive activation, and there is no compe-tition between the neurons. The activation function A is given by ( 1 ), where  X  i is a decreasing constant, r i is the activation threshold, E i ( t ) the neighbourhood contribution, M and m are respectively superior and lower activation bounds,  X  ij and  X  ij are the positive and negative stimulations from j to i a ( t ) is the activation of the node j .
 A ( t +  X  t ) = A E ( t ) = n i n ( t ) =
The main concepts of the Percepto system were retained for our PNN. In [ 5 , 43 , 44 ], it has been shown how this model for handwriting recognition can be adapted to logical docu-ment zoning. We have shown its utility for the logical struc-ture recognition. The input data corresponds to text blocks (bounding boxes). The extracted features are related to the text block descriptions (e.g. style, font, etc.), while the output designates the logical labels.

As reported in [ 41 ] concerning logical structure recogni-tion, a perceptive and knowledge guided solution seems to be more appropriate to cope with the gap between physi-cal observation and logical interpretation. That is the reason why a regular MLP is not adapted: knowledge is difficult to integrate and it behaves as a  X  X lack-box X , resulting in a complex understanding of its behaviour [ 17 ]. The PNN has  X  X rganised X  neurons and each of them corresponds to an interpretable concept and it is linked to an element of the logical structure. Excluding the first layer containing the physical inputs, the following layers unfold the logical layout by introducing fine concepts in the first layers and general/coarse concepts in the following layers. The Fig. 1 presents an instance of the PNN used for logical labelling of scientificarticles.Inputfeatures(geometrical,morphological and semantic) make up the first layer, the second layer con-tains logical labels while the third layer includes coarse con-cepts called context. The context is provided by the expert. It is during the construction of this context that the  X  X nowl-edge X  mentioned before is brought. For our application, we decided to follow the logical splitting of the text. As pro-posed by the Text Encoding Initiative 1 (TEI), we created five independent concepts (front, heading, body, closing, back) clustering all the logical labels.

In the former system [ 11 ] the connections between adja-cent layers were bidirectional and only stimulating (just positive activation values were forwarded). Moreover, the connection weights were determined manually according to some prior knowledge. This choice sounded inappropriate in the case of logical structure recognition as the relationships between the layers are not straightforward. Thus, we have chosen to perform a training phase for the PNN, similar to MLP, in order to compute all the weights w according to the input patterns x p . As opposed to Percepto, the PNN is fully connected and the connections can be inhibitive. The train-ing is done by a gradient descent algorithm. The error E p between the desired output d q and the computed output o l is minimised for each input pattern p ( 2 ) where L stands for the last layer.
 E o The weight between the unit i in layer l and j in layer l is modified according to ( 3 )[ 28 ]. w where f is an activation function (e.g. the sigmoid).
All the neurons carry interpretable concepts, so the desired output is known for all of them. The partial term is given by ( 4 ) and the PNN can be trained as a cascade of mono-layer Perceptrons (no hidden layers included).  X  l ,
During the recognition step, the PNN is employed such as a MLP, but after each propagation, the outputs are ana-lysed. It means that if the output vector is close to a canonical basis vector ( 5 ) and ( 6 ), the pattern is considered as classi-fied. Otherwise, the following layers (the context) are taken into account to inject additional information. We defined two rejection criteria: M ( O ) checks if the vector has at least one component with a high value (close to 1) and ( O ) checks if the greatest component has a value largely higher than all the other components. These rules decide when a block is accepted or some corrections are needed.
 M ( O ) = O  X  &gt; X  with 0  X &lt; 1(5) (
O ) =
The final layers contain global information and coarse concepts, but they are more robust and easier to find. They can be used to generate hypothesis on the pattern. This con-text information manages the correction of the input features. Once a label is supposed to be the good one, the input vector is corrected according to this hypothesis. Actually, during the training step, several representative samples, or proto-types, for each logical label are extracted from the training set. The correction consists in modifying the current input to make it closer to a representative sample. The correction is mainly focused on the block bounding boxes: merging blocks together or splitting them into smaller sub-blocks. The rules are straightforward. If a block contains several lines and the hypothesis indicates that the bounding box for this kind of label is smaller, the current box is split into a different num-ber of lines in such a way that its new dimensions better fit a correct prototype (Fig. 3 ).

More precisely, when extracting the representative sam-ples,ak-meansalgorithmisusedtostorethewidth,theheight and the number of contained lines. Three possible candidates are determined for each class. One of the most likely repre-sentative samples for the  X  X uthor X  label could be the vector ( 20 ; 0 . 2 ; 1 ) , which means that the candidate is 20% of the page width, 0.2% of the height and contains 1 line. If an ambiguous block comes to the PNN with the hypothesis of being an  X  X uthor X  and with the vector ( 18 ; 1 ; 3 ) , we look if it can be divided and if so, we try the best split. Here, it could be split after the first line which produces the vectors ( 18 ; 0 . 3 ; 1 ) and ( 18 ; 0 . 7 ; 2 ) . The corresponding bounding boxes have better chance now to be labelled as  X  X uthor X  and  X  X ffiliation X .
 Mergingblocksoccursrarely,becausethebehaviourofthe OCR [ 1 ] is mainly under-segmentation. It could be supposed that it uses a fast top-down approach which stops dividing the blocks, maybe a little bit too early when they are considered sufficiently homogeneous. In the rare case when two consec-utive blocks are ambiguous, we merge them. At the end, it amounts to correct the physical layout analysis where errors occur quite often [ 23 , 54 ]. Perceptive cycles are completed in a loop (Fig. 2 ) until no ambiguity persists (i.e. ( 5 ) and ( 6 ) are fulfilled).

The perceptive cycles (propagation-correction) allow a bottom-up and top-down resolution and refine the recogni-tion. However, if too many cycles must be performed, the process could be time consuming because it implies many physical extractions. In order to face this problem, the solu-tion could be to prune some unnecessary extractions. Instead of feeding the network with the whole amount of features at each cycle, they are introduced progressively, in groups, during the recognition and only if the pattern is considered to be too ambiguous. The groups are the result of a clus-tering of the full set of features (e.g. geometrical, morpho-logical and semantic). This simulates at the same time a global and local vision of the recognition. It is global when using the context information and hypothesis generation; and local when extracting or correcting specialised features. The input data clustering does not improve the recognition quality, but for the same recognition rates the speed-up is considerable.

Technically speaking, as the number of features is not con-stant, we create as many PNNs as clusters. In the implemen-tation, the number of clusters is set to three, so three PNNs are used. If the groups of variables can be defined arbitrary as suggested in Fig. 1 , the input feature space can also be divided automatically according to several criteria. We pro-posed in [ 44 ] a fast filter-based selection [ 7 ] to construct subsets of variables. It ranks the subsets by predictive power and in each of them the variables are the most independent as possible. It avoids redundant variables, and allows feeding the PNN with relevant information. 3 Dynamic perceptive neural network This section describes the contribution we propose in this work. First we show why the PNN is perfectible and secondly wepresenthowtoextendthePNNinadynamicmodel,which provides a better behaviour during the recognition stage. 3.1 Static recognition with dynamic data As mentioned in Sect. 2 , a PNN is based on a static model but is improved to manage knowledge and input data correc-tion. During the recognition, several forwards are performed with possibly corrected inputs. As the segmentation is often corrected, it snowballs most of the features in the input vec-tor. However, the network is trained only once, with a fixed training database. Indeed, the features until now called x are different for each cycle. The x i should be named x i where t is the number of the current perceptive cycle. Unfor-tunately, the weights w l i , j are always constant scalars and are not adapted to x i ( t ) because x i ( 0 ) =  X  X  X  = x i ( n
The contribution of this paper is to demonstrate how to integrate the data correction occurring between each percep-tive cycle within the training step. The goal is to modify the training schema in such a way as the recognition step has a more appropriate behaviour. 3.2 Considering temporal dimension with a time-delay The Time-Delay Neural Network (TDNN) can handle this kind of unsettled data. Contrary to a MLP, where the output o j depends on the outputs of the preceding layer, the out-put of a neuron o ( t ) at time t in a TDNN corresponds to a weighted sum of the past delayed values ( 7 ). o ( t ) =
There are two main methods to train such a network. The first one removes all time delays by unfolding the network into an equivalent static structure [ 32 ], but this method is not used in practice (time consuming). The second solution is an extension of the back-propagation algorithm called tempo-ral back-propagation. The idea is to consider the weights as constants when computing an approximation of the gradient ( 8 ) of the cost function Err ( 9 ).
 Err =  X 
Err  X  With a complete derivation of the terms [ 53 ], the weights are updated according to ( 10 ).
 W with X l i ( n ) =[ x l i ( n ), x l i ( n  X  1 ),..., x l defined by ( 10 ). ( k ) =
If W and X are considered as scalars, the algorithm is sim-ilar to the back-propagation for static networks. The Algo-rithm 1 summarises the main steps of the training.
This dynamic training is slower than the static back-propagation one, even if T = 1. This is due to the presence of vectorial data instead of scalars. The algorithm also suffers from the same drawbacks as those of the clas-sic back-propagation one [ 31 ], especially convergence prob-lems, which are amplified by the new T parameter [ 42 , 51 ]. These are some of the possible reasons why TDNN are not so common, and why other methods such as HMM are preferred when a problem requires the time dimension [ 33 ].
Fortunately, in the case of logical structure extraction, the T factor depends on the number of perceptive cycles. Some experiments have shown that T can be small for the Static PNN (SPNN). On top of that, as the weights are more suitable now to the current input X i , the number of cycles can be lower compared to the static version. Moreover, each X is given by the same OCR and the variation between the data ( X i ( t )  X  X i ( t  X  1 ) &lt; ) is rather small. We have chosen to set T = 2 for the Dynamic PNN, which means 3 perceptive cycles. It is a reasonable trade-off between accuracy and time consumption. 3.3 Training and recognition with the DPNN 3.3.1 Training Unlike the Static PNN, the training database for a Dynamic PNN has to be modified to integrate the time dimension. The raw (uncorrected) outputs of a commercial OCR [ 1 ]are collected to have the feature vectors at time t = 0. Then, a manual correction is performed on the segmentation: the erroneous bounding boxes are tuned to match with logical elements. It is sometimes necessary to merge or split some bounding boxes (Fig. 3 ). The OCR is run another time on the new segmentation and the outputs are kept to feed data at time t = 1. These data are also modified manually for the second time and provide the network inputs at time t = 2.
These manual corrections could be tedious, but not impos-sible to handle. The system needs some ground truth docu-ments as a first bootstrapping and the user has to correct and label manually several documents (assuming there is no other ready-to-use material to start a training). Then, it can continue the ground truth generating process by using a first trained DPNN, with a high rejection rate and tries to use it for a new semi-automatic labelling of another set of document in order to make the training/testing dataset growing. This manual effort is not more difficult than any other data-driven methods, and it is a very profitable contribution to large and homogeneous datasets. 3.3.2 Recognition The recognition step is similar to the static version one. The input data are extracted first, then passed in the DPNN with t = 0. The outputs are analysed and if the answer is ambig-uous ( 5 ) and ( 6 ), the input features are corrected by resizing the bounding box as it was already done in the static case. Another perceptive cycle follows with a new OCR extraction but on the DPNN with t = 1, where the information of t = 0 is taken into account. A last cycle is finally executed, using the current extraction results and the previous ones at times t = 1 and 0.

Additional perceptive cycles can be considered and two solutions can be considered. Planning more cycles during the training stage, even if it means to stop the correction of the input data after t &gt; 2. It is also possible and more appropriate to keep the same network, but shifting the data with t  X  t as the  X  X apped delay line X  [ 20 ] of the TDNN (Fig. 4 ). That would amount to reduce the memory capability by remem-bering only the latest events and discard the first extractions which were maybe too erroneous. 4 Experimentations 4.1 The MARG dataset There are just a few available datasets and few contribu-tions reporting results involving these data. We applied the DPNN on the publicly available dataset MARG (Ground Truth Data for Biomedical Journals) of [ 16 ] which is one the most used ones, even though it is not the best test scenario for our DPNN. MARG contains binarized, skew corrected images. They are title pages of medical journal articles and the corresponding ground truths are given. There are 1 , 553 images divided into 8 classes (named with letters A to H) depending on their layout type, plus an additional class  X  X thers X , where all the unusual article layouts belong. The images are logically labelled with four labels:  X  X itle X ,  X  X uthors X ,  X  X ffiliation X  and  X  X bstract X . The frequencies of each class and a visual aspect of the layouts are given in Table 1 .

We made 10 rounds of cross-validations by splitting the database every time in two equal parts between training and validation. The results are averaged over the rounds to reduce variability. The 10  X  2 sets were chosen with a controlled random seed, sothat theexperimentationis reproducible. The initial segmentation and all the physical features (Table 2 ) were obtained with the [ 1 ] OCR.

Ourfeaturesarethedirecttranscriptionsofthosedescribed in the complete schema [ 47 ]. What we called Geometri-cal features corresponds to the  X  X lockType X  of the schema. We added the Up/Bottom/left/Right space values which are the widths of the white margins between a block and the other blocks around it. Morphological features are the com-bination of  X  X ormatting type X  and  X  X aragraphType X  of the schema. As some features are only given at the word or char-acter level (e.g. boldness), we computed the global ratio at the block level by an elementary cross-multiplication rule. The Semantic features are mostly taken in the  X  X harParams-Type X  section of the schema. We added in it:  X  X ullet X  and  X  X num X  to describe if some bullet or enumeration symbols are found in the text. The Keywords feature describes if a predefined word is found in the text. The keyword set is { X  X bstract X ,  X  X ntroduction X ,  X  X eyword X ,  X  X able X ,  X  X igure X ,  X  X on-clusion X ,  X  X eferences X ,  X  X ppendix X  X . Except this last feature, all the others can be extracted by most of the commercial OCR (e.g. FineReader, Omnipage, ReadIris) and are also listed in the ALTO (Analyzed Layout and Text Object) XML Schema [ 3 ].

The Fig. 5 shows the box-and-whisker diagrams of the recognition rates obtained for each type of layout. In addi-tion to sample min/max, lower/upper quartile and median, we added the mean with a blue round dot.
It can be shown that whatever the layout type is, the results are always good. The easiest layout types were  X  X  X ,  X  X  X  and  X  X  X , while the hardest was the  X  X thers X  type. Com-pared to what can be found in the literature, the results are satisfactory [ 36 ], although the DPNN was designed to treat more logical labels (more than a dozen) and few layout clas-ses. The MARG dataset is somewhat the opposite. There are few labels and several layout classes.

A lot of methods exist in the literature, but most of them have been tested on confidential documents or on small data-sets. Furthermore, the wide range of input features, labels, training/testsets,etc.makesthecomparisonsalmostimpossi-ble. Recently, [ 6 ] published a work on example-based logical labelling of document title page images. Firstly, they reported the few other representative works where the MARG data-set was used: [ 24 ] with a rule-based system obtained 96.7%, [ 35 ] with also a rule-based system obtained 86% (due to a bad recognition of the affiliations) and [ 37 ] with a hid-den semi-Markov model obtained 91%. [ 6 ] pointed the fact that the MARG dataset was not considered in its totality and that only subsets of it were used. Secondly, they introduced a lightweight method with a similarity measure for layout combining structural layout and textual similarity. The fea-tures they employed are fast to extract and the matching step is also fast, flexible and efficient. They obtained on the full MARG dataset accuracy rates from 94.8 up to 99.6% with an average of 97.8%.

Our rates are ranging from 94.6 to 99.7%, with a global average of 97.5%. At first glance, [ 6 ] can obtain up to 99.6%, but we are also acting in different conditions. Indeed, to reach 99.6% on all the 1,553 images, they used a leav-ing-image-out cross validation, which means that the label-ling of one document is determined knowing the label-ling of all the 1,552 others documents. Analogously, the leaving-journal-out gives 98.9% by testing documents of the same journal (a dozen in average) knowing all the other doc-uments. Finally, the leaving-type-out gives 94.8%, meaning that the tests where done on one type of layout knowing all the other types which roughly means that 90% of the full dataset is used for training (exact proportions can be deduced from Table 1 ).

For the MARG dataset, we did not use the context layer because 4 labels are too few to have a helpful context. The first cycle gives roughly 80%, while the second one is around 95% and 97.5% for the last one. Most of the errors are due to the bad recognition of the affiliations, which are most of the time labelled as authors. However, we do not have poor result on the label  X  X ffiliation X  like in the work of [ 35 ]. The percep-tive cycles are able to correct most of the miss-segmentations when a big block includes both lines of  X  X uthors X  and  X  X ffil-iations X . The dynamic version of the PNN is better than the static one. Only the class  X  X  X  was requiring a lot of correction. This class  X  X  X  was also difficult because some documents were really different one from one another. There were also some pages with missing labels (e.g. layout122/14230829, layout122/14234603,...), complex layouts of affiliations and abstracts (e.g. layout122/15111832), and also, accord-ing to us, some errors in the ground truth (e.g. lay-out122/18447737 or layout122/18628210: Abstract is the full body of the document (Fig. 6 ), sometimes the keyword lines are included in the abstract for layout122/18445612, sometimes excluded for layout122/18447737, missing title in layout 122/18583868, etc.) 4.2 The siggraph dataset The DPNN was designed to deal with several labels in order to propose a complete document analysis, meaning that all the blocks must have a label. The MARG dataset is somewhat different: with few labels and several clas-ses of documents. In our best knowledge, there is no pub-licly available dataset containing a full physical and logical description of the documents. For this purpose, we have cre-ated a more detailed dataset. It is composed of 74 papers from the ACM Siggraph 2003 conference [ 48 ]. The docu-ments are scientific articles in Portable Document Format (PDF) having a considerable amount of logical structure ele-ments.
 The PDFs were printed at 600 dpi with a laser printed HP Color LaserJet 4650 PCL 2 and then digitised with a digi-tal copier-printer-scanner device Gestetner DSm745 3 at 600 dpi in black and white (Fig. 7 ). In these 74 documents, 21 logical structures have been identified (Table 2 ) for a total of more than 2,000 patterns. The input feature information is still coming from the commercial OCR [ 1 ]. The training stage uses 44 documents and the remaining 30 are consid-ered for testing. The results of the Dynamic PNN are shown in the last columns of the Table 3 . We also reported the results obtained with a Static PNN with details for each cycle and a regular MLP.

After three cycles, the Static PNN can already outperform almost 10 points of recognition rate than a simple MLP (from 81.7 to 90.2%), but the extraction time is multiplied by a fac-torof1 . 85. It has been shown, that three perceptive cycles are a good trade-off between quality and speed. A possible fourth cycledoesnotbringhighlybetterrecognitionandslowsdown the recognition (not in Table 3 : 91.7% for recognition and 2.1 speed factor for time extraction). Here, the Dynamic PNN is better than the SPNN with 3 and also with 4 cycles. It can reach 92.7% with a 1.8 time factor. Although the training of the DPNN is up to 10 times slower than for the SPNN, the propagation of the inputs inside the network during the recog-nition is neglectable compared to OCR extractions. Results show that the 3-cycle DPPN is more accurate and faster than a 4-cycle SPNN. For the Siggraph dataset, the DPNN clearly outperforms the static version.

The Table 4 gives a closer look at the recognition rates for each logical label. The DPNN never returns worse results than the SPNN. The fact of using results from preceding cycles is favourable for the DPNN. On the other hand, the DPNN cannot return tremendous results. It fails also on dif-ficult cases. For instance, the  X  X cknowledgment X  and  X  X on-clusion X  are still not very well recognised. With the exception of segmentation problems, to which we can find a solution with more appropriate algorithms [ 4 ]; we still have problems with these types of labels: the bounding boxes and phys-ical features are correct, but we think that more informa-tive features are missing to deal with this kind of logical labels.

The results we obtained are difficult to compare with other reported results in literature, for the reasons we described before. We did not find publications using as many labels as we did. For example, if we refer to the work of [ 26 ], which deals with a similar dataset of document images, they obtained a recognition rate of 94.4% for 9 labels (Title, Author, Page Number, Abstract, KeyWords, Copyright, Sec-tion, Algorithm, Float). With the same set of logical labels, our DPNN reaches 96.3%. 5 Conclusions We presented an extension of the Static Perceptive Neural Network to a dynamic version, called Dynamic Perceptive Neural Network, using a Time-Delay Neural Network. The new network architecture is designed to recognise the logical structures in document images with several cycles of recog-nition-correction.

The method uses all the concepts of the static version: introduction of knowledge in each neuron, network topol-ogy in hierarchy from fine (the labels to recognise) to coarse (the global context), analysis of the outputs and correction of the inputs (perceptive cycles), input feature clustering for speeding up the recognition.

We introduced the time dimension in the network allowing to take into account the inputs of the preceding cycles during the recognition step. The static version has been extended through the usage of a TDNN. As a consequence, the pro-posed DPNN is more flexible and more adapted to handle the variability of the input features between each cycle. The correction of these features is also much more efficiently supervised thanks to the weight adaptations provided by the TDNN architecture.

The previous SPNN was already giving encouraging resultsandtheDPNNimprovestheexistingrecognitionrates. The DPNN has been tested on the MARG dataset and has been compared with other methods in the literature. Although it was not specifically designed to deal with such a database, it is able to outperform most of the previous methods, espe-ciallythoseusingrule-basedsystemsandgivessimilarresults to the state-of-the-art on this dataset. As there are no publicly available datasets with many different labels to be recogni-sed, we tested the model on a set of documents where 21 log-ical structures have been considered. The experiments show that the DPNN outperforms the SPNN and gives roughly 93% of recognition rate versus 90% for the same processing time.

In a future work, we plan to integrate a partial or totally recurrent network in order to provide an architecture with a temporal and space recurrence [ 27 , 49 ]. A further step will be to identify and test more informative input features for dealing with highly difficult cases where it seems that  X  X ead-ing X  and  X  X nderstanding X  the content of a block of text is necessary to find the right label for it.
 References
