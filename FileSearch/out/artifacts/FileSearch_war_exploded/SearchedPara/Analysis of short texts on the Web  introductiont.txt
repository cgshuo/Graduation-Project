 1 Analysis of short texts on the Web Analysis of web and social media data is a rapidly growing area of research. Researchers seek to extract a wide variety of information from these texts in order to address specific user needs, profile attitudes and intentions, and target advertising, etc., which may require application of the full range of natural processing techniques. However, many of the texts in question X  X ncluding news feeds, document titles, FAQs, and tweets X  X xist as short, sometimes barely sentence-like snippets that do not always follow the lexical and syntactic conventions assumed by many language processing tools. Many NLP analyses rely on the repetition of specific lexical items throughout the text in order to identify topic, genre, and other features; without sufficient context to enable such analyses, and because of their often eccentric grammatical style, short texts pose a new kind of challenge for language processing research (Errecalde et al. 2008 ; Pinto et al. 2011 ).

With Web 2.0, the largest communication and collaborative platform, new short texts are created on daily basis in the form of on-line reviews of commercial products, blog posts, or opinions in social media (Liu 2012 ). Twitter is a new microblog technology of the Web 2.0 genre which is used by millions of people and thousands of companies to publish very short messages, with the purpose of sharing experiences and/or opinions. Due to the huge amount of information they contain about user attitudes and habits, there is a clear interest in mining information from these messages in order to discover knowledge about the collective thinking of the crowds. Tweet analysis is especially relevant because comments, opinions, suggestions and complaints can be used to define new marketing strategies or obtain up-to-the-minute information on a company X  X  reputation.

The growing interest in the efficient analysis of short texts is apparent in evaluation campaigns such as TREC, CLEF, NTCIR, FIRE, and ROMIP, to which blog and Web tracks as well as tasks on Web people search and reputation, opinion analysis, passage retrieval, news clustering, chats analysis, and retrieval from technical forums, mailing lists, and SMS-based FAQs have been added in recent years. This special issue also addresses the rising interest in processing short texts, by collecting a set of papers that address the special challenges they pose in order to further work in the field. 2 LRE special issue The call for papers for this special issue was published in November 2010. The six papers included in this volume (from among 24 submissions) cover a range of problems in the development and use of resources and techniques for the analysis of short texts on the Web, with special emphasis on short texts of the collaborative platform of the Web 2.0: blog posts, tweets, text messages, etc. (Ram X   X  rez-de-la-Rosa et al.)  X  X  X  document is known by the company it keeps: Neighborhood consensus for short text categorization X  X  proposes a neighborhood consensus method that classifies short texts by considering also the textual information of the category assigned to other similar texts from the same target collection. News titles with an average length of eight words were used to evaluate the proposed method. The obtained results indicate that leveraging information from similar texts helped to improve classification accuracy. The proposed method is especially useful when labelled training resources are limited. (Romero et al.)  X  X  X lassifying unlabeled short texts using a fuzzy declarative approach X  X  presents a fuzzy approach to text categorization which does not need a pre-classified set of training documents. In fact, the proposed method only requires the category names that are defined by means of an ontology of terms modelled by a set of proximity equations. The proposed classification approach has been tested on four news and Web snippets datasets. (Costa-jussa ` and Banchs)  X  X  X utomatic normalization of short texts by combining statistical and rule-based techniques X  X  proposes a combination of statistical and rule-based techniques to normalize short texts in order to reduce the noise and improve the quality of text for processing and analysis purposes. The normalization approach, which is particularly suited as text normalization method for SMS-and chat-like messages (or tweets), is based on a statistical machine translation system which translates noisy data containing abbreviations, spelling variants and typos into clean data. Experiments have been carried out on a SMS messages dataset. (Carter et al.)  X  X  X icroblog Language Identification: Overcoming the limitations of short, unedited and idiomatic text X  X  considers the problem of language identification on microblog posts when mixed language is used. The authors indentify helpful microblog characteristics taking into account the language profile of the blogger and other users mentioned together with the information about the language of the original post and the content of an attached hyperlink. Although most priors examined in this work are specific to microblogging, certain features could be employed also with a SMS dataset. (Culotta)  X  X  X ightweight methods to estimate influenza rates and alcohol sales volume from Twitter messages X  X  proposes a supervised learning approach to reduce the burden of false alarms in Twitter and filter out these misleading messages. Tracking a small number of keywords allowed to estimate influenza rates and alcohol sales volume with high accuracy.
 Finally, (Reyes et al.)  X  X  X  multidimensional approach for detecting irony in Twitter X  X  describes a set of textual features for detecting irony at a linguistic level in short texts of microblogs such as Twitter. The obtained results provide valuable insights for tasks such as opinion mining and online reputation. 3 Concluding remarks Knowledge obtained by analyzing short texts available on the Web will inevitably play a key role in decision making processes in the future. However, as the articles in this special issue show, low frequencies of words, noisy and changing content, the lack of labeled training documents and the need for efficient methods to analyze huge amounts of information pose significant challenges. This special issue includes several articles that characterize ongoing research areas in short text analysis, for example, the search for efficient categorization approaches that can produce good results even with little o no training data [(Ram X   X  rez-de-la-Rosa et al.) and (Romero et al.)]; means to deal with  X  X  X oisy X  X  language in Web 2.0 content [(Costa-jussa ` and Banchs) and (Carter et al.)]; and the special considerations for treating the language of Twitter, which is perhaps the most influential microblogging platform today [(Culotta) and (Reyes et al.)]. Obviously, these selected works do not provide an exhaustive list of all the topics that have been covered so far in the field. Nevertheless, they allow to identify a variety of lines of research that will surely prompt further investigation in the future.
 References
