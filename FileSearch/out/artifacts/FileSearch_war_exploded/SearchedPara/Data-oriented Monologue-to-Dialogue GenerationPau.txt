 Several empirical studies show that delivering in-formation in the form of a dialogue, as opposed to monologue, can be particularly effective for educa-tion (Craig et al., 2000; Lee et al., 1998) and per-suasion (Suzuki and Yamada, 2004). Information-delivering or expository dialogue was already em-ployed by Plato to communicate his philosophy. It is used primarily to convey information and possibly also make an argument; this in contrast with dra-matic dialogue which focuses on character develop-ment and narrative.

Expository dialogue lends itself well for presenta-tion through computer-animated agents (Prendinger and Ishizuka, 2004). Most information is however locked up as text in leaflets, books, newspapers, etc. Automatic generation of dialogue from text in monologue makes it possible to convert information into dialogue as and when needed.

This paper describes the first data-oriented monologue-to-dialogue generation system which re-lies on the automatic mapping of the discourse relations underlying monologue to appropriate se-quences of dialogue acts. The approach is data-oriented in that the mapping rules have been auto-matically derived from an annotated parallel mono-logue/dialogue corpus, rather than being hand-crafted.

The paper proceeds as follows. Section 2 reviews existing approaches to dialogue generation. Section 3 describes the current approach. We provide an evaluation in Section 4. Finally, Section 5 describes our conclusions and plans for further research. For the past decade, generation of information-delivering dialogues has been approached primarily as an AI planning task. Andr  X  e et al. (2000) describe a system, based on a centralised dialogue planner, that creates dialogues between a virtual car buyer and seller from a database; this approach has been extended by van Deemter et al. (2008). Others have used (semi-) autonomous agents for dialogue gener-ation (Cavazza and Charles, 2005; Mateas and Stern, 2005).

More recently, first steps have been taken towards treating dialogue generation as an instance of Text-to-Text generation (Rus et al., 2007). In particu-lar, the T 2 D system (Piwek et al., 2007) employs rules that map text annotated with discourse struc-tures, along the lines of Rhetorical Structure Theory (Mann and Thompson, 1988), to specific dialogue sequences. Common to all the approaches discussed so far has been the manual creation of generation resources, whether it be mappings from knowledge representations or discourse to dialogue structure. With the creation of the publicly available 1 CODA parallel corpus of monologue and dialogue (Stoy-anchev and Piwek, 2010a), it has, however, become possible to adopt a data-oriented approach. This cor-pus consists of approximately 700 turns of dialogue, by acclaimed authors such as Mark Twain, that are aligned with monologue that was written on the ba-sis of the dialogue, with the specific aim to express the same information as the dialogue. 2 The mono-logue side has been annotated with discourse rela-tions, using an adaptation of the annotation guide-lines of Carlson and Marcu (2001), whereas the di-alogue side has been marked up with dialogue acts, using tags inspired by the schemes of Bunt (2000), Carletta et al. (1997) and Core and Allen (1997). As we will describe in the next section, our ap-proach uses the CODA corpus to extract mappings from monologue to dialogue. Our approach is based on five principal steps:
I Discourse parsing : analysis of the input mono-
II Relation conversion : mapping of text annotated
III Verbalisation : verbal realisation of dialogue
IV Combination Putting the verbalised dialogues
V Presentation : Rendering of the dialogue (this
For step I we rely on human annotation or existing discourse parsers such as DAS (Le and Abeysinghe, 2003) and HILDA (duVerle and Prendinger, 2009). For the current study, the final step, V, consists sim-ply of verbatim presentation of the dialogue text. The focus of the current paper is with steps II and III (with combination, step IV, beyond the scope of the current paper). Step II is data-oriented in that we have extracted mappings from discourse relation occurrences in the corpus to corresponding dialogue act sequences, following the approach described in Piwek and Stoyanchev (2010). Stoyanchev and Pi-wek (2010b) observed in the CODA corpus a great variety of Dialogue Act (DA) sequences that could be used in step II, however in the current version of the system we selected a representative set of the most frequent DA sequences for the five most com-mon discourse relations in the corpus. Table 1 shows the mapping from text with a discourse relations to dialogue act sequences (i indicates implemented mappings).
 DA sequence A C C E M TR YNQ; Expl i i d YNQ; Yes; Expl i i i d Expl; CmplQ; Expl i d ComplQ; Expl i/t i/t i i c Expl; YNQ;Yes i d Expl; Contrad. i d FactQ; FactA; Expl i c Expl; Agr; Expl i d Expl; Fact; Expl t c
For comparison, the table also shows the much less varied mappings implemented by the T 2 D sys-tem (indicated with t). Note that the actual mappings of the T 2 D system are directly from discourse rela-tion to dialogue text. The dialogue acts are not ex-plicitly represented by the system, in contrast with the current two stage approach which distinguishes between relation conversion and verbalisation.
Verbalisation, step III, takes a dialogue act type and the specification of its semantic content as given by the input monologue text. Mapping this to the appropriate dialogue act requires mappings that vary in complexity.

For example, Expl(ain) can be generated by sim-ply copying a monologue segment to dialogue utter-ance. The dialogue acts Yes and Agreement can be generated using canned text, such as  X  X hat is true X  and  X  X  agree with you X .

In contrast, ComplQ (Complex Question), FactQ (Factoid Question), FactA (Factiod Answer) and YNQ (Yes/No Question) all require syntactic ma-nipulation. To generate YNQ and FactQ , we use the CMU Question Generation tool (Heilman and Smith, 2010) which is based on a combination of syntactic transformation rules implemented with tregex (Levy and Andrew, 2006) and statistical methods. To generate the Compl(ex) Q(uestion) in the ComplQ;Expl Dialogue Act (DA) sequence, we use a combination of the CMU tool and lexical trans-formation rules. 3 The G EN example in Table 2 il-lustrates this: The input monologue has a Manner-Means relations between the nucleus  X  X n September, Ashland settled the long-simmering dispute X  and the satellite  X  X y agreeing to pay Iran 325 million USD X . The satellite is copied without alteration to the Ex-plain dialogue act. The nucleus is processed by ap-plying the following template-based rule: In words, the input consisting of a declarative sen-tence is mapped to a sequence consisting of the word  X  X ow X  followed by a Yes/No-question (in this case  X  X id Ashland settle the long-simmering dispute in December? X ) that is obtained with the CMU QG tool from the declarative input sentence. A similar ap-proach is applied for the other relations (Attribution, Condition and Explanation-Reason) that can lead to a ComplQ; Expl dialogue act sequence (see Table 1).
Generally, sequences requiring only copying or canned text are labelled d(irect) in Table 1, whereas those requiring syntactic transformation are labelled c(omplex) . We evaluate the output generated with both complex and direct rules for the relations of Table 1. 4.1 Materials, Judges and Procedure The input monologues were text excerpts from the Wall Street Journal as annotated in the RST Dis-course Treebank 4 . They consisted of a single sen-tence with one internal relation, or two sentences (with no internal relations) connected by a single relation. To factor out the quality of the discourse annotations, we used the gold standard annotations of the Discourse Treebank and checked these for correctness, discarding a small number of incorrect annotations. 5 We included text fragments with a variety of clause length, ordering of nucleus and satellite, and syntactic structure of clauses. Table 2 shows examples of monologue/dialogue pairs: one with a generated dialogue and the other from the cor-pus.

Our study involved a panel of four judges, each fluent speakers of English (three native) and ex-perts in Natural Language Generation. We collected judgements on 53 pairs of monologue and corre-sponding dialogue. 19 pairs were judged by all four judges to obtain inter-annotator agreement statistics, the remainder was parcelled out. 38 pairs consisted of WSJ monologue and generated dialogue, hence-forth G EN , and 15 pairs of CODA corpus monologue and human-authored dialogue, henceforth C ORPUS (instances of generated and corpus dialogue were randomly interleaved)  X  see Table 2 for examples.
The two standard evaluation measures for lan-guage generation, accuracy and fluency (Mellish and Dale, 1998), were used: a) accuracy : whether a dialogue (from G EN or C ORPUS ) preserves the in-formation of the corresponding monologue (judge-ment:  X  X es X  or  X  X o X ) and b) monologue and dialogue fluency : how well written a piece of monologue or dialogue from G EN or C ORPUS is. Fluency judge-ments were on a scale from 1  X  X ncomprehensible X  to 5  X  X omprehensible, grammatically correct and nat-urally sounding X . 4.2 Results Accuracy Three of the four judges marked 90% of monologue-dialogue pairs as presenting the same information (with pairwise  X  of .64, .45 and .31). One judge interpreted the question differently and marked only 39% of pairs as containing the same information. We treated this as an outlier, and ex-cluded the accuracy data of this judge. For the in-stances marked by more than one judge, we took the majority vote. We found that 12 out of 13 instances (or 92%) of dialogue and monologue pairs from the C
ORPUS benchmark sample were judged to contain the same information. For the G EN monologue-dialogue pairs, 28 out of 31 (90%) were judged to contain the same information.
 Fluency Although absolute agreement between judges was low, 6 pairwise agreement in terms of Spearman rank correlation (  X  ) is reasonable (aver-age: .69, best: .91, worst: .56). For the subset of in-stances with multiple annotations, we used the data from the judge with the highest average pair-wise agreement (  X  = . 86 ) The fluency ratings are summarised in Figure 1. Judges ranked both monologues and dialogues for the G EN sample higher than for the C ORPUS sam-ple (possibly as a result of slightly greater length of the C ORPUS fragments and some use of archaic lan-guage). However, the drop in fluency, see Figure 2, from monologue to dialogue is greater for G EN sam-ple (average: .89 points on the rating scale) than the C
ORPUS sample (average: .33) (T-test p &lt; .05), sug-gesting that there is scope for improving the genera-tion algorithm.
 Direct versus Complex rules We examined the difference in fluency drop between direct and com-plex rules. Figure 3 shows that the drop in fluency for dialogues generated with complex rules is higher than for the dialogues generated using direct rules (T-test p &lt; .05). This suggests that use of direct rules is more likely to result in high quality dialogue. This is encouraging, given that Stoyanchev and Piwek (2010a) report higher frequencies in professionally authored dialogues of dialogue acts ( YNQ, Expl ) that can be dealt with using direct verbalisation (in con-trast with low frequency of, e.g., FactQ ).
 With information presentation in dialogue form be-ing particularly suited for education and persua-sion, the presented system is a step towards mak-ing information from text automatically available as dialogue. The system relies on discourse-to-dialogue structure rules that were automatically ex-tracted from a parallel monologue/dialogue corpus. An evaluation against a benchmark sample from the human-written corpus shows that both accuracy and fluency of generated dialogues are not worse than that of human-written dialogues. However, drop in fluency between input monologue and output dia-logue is slightly worse for generated dialogues than for the benchmark sample. We also established a dif-ference in quality of output generated with complex versus direct discourse-to-dialogue rules, which can be exploited to improve overall output quality.
In future research, we aim to evaluate the accu-racy and fluency of longer stretches of generated di-alogue. Additionally, we are currently carrying out a task-related evaluation of monologue versus dia-logue to determine the utility of each.
 We would like to thank the three anonymous reviewers for their helpful comments and sug-gestions. We are also grateful to our col-leagues in the Open University X  X  Natural Lan-guage Generation group for stimulating discussions and feedback. The research reported in this pa-per was carried out as part of the CODA re-search project (http://computing.open.ac.uk/coda/) which was funded by the UK X  X  Engineering and Physical Sciences Research Council under Grant EP/G020981/1.

