 Lihong Li lihong@cs.rutgers.edu Michael L. Littman mlittman@cs.rutgers.edu Thomas J. Walsh thomaswa@cs.rutgers.edu At the core of recent reinforcement-learning algo-rithms that have polynomial sample complexity guar-antees (Kearns &amp; Singh, 2002; Kearns &amp; Koller, 1999; Kakade et al., 2003; Strehl et al., 2007) lies the idea of distinguishing between instances that have been learned with sufficient accuracy and those whose out-puts are still unknown.
 The Rmax algorithm (Brafman &amp; Tennenholtz, 2002), for example, estimates transition probabilities for each state X  X ction X  X ext-state triple of a Markov decision process (MDP). The estimates are made separately, as licensed by the Markov property, and the accuracy of the estimate is bounded using Hoeffding bounds. The algorithm explicitly distinguishes between proba-bilities that have been estimated accurately (known) and those for which more experience will be needed (unknown). By encouraging the agent to gather more experience in the unknown states, Rmax can guaran-tee a polynomial bound on the number of timesteps in which it has a non-near-optimal policy (Kakade, 2003). In this paper, we make explicit the properties that are sufficient for a learning algorithm to be used in efficient exploration algorithms like Rmax. Roughly, the learn-ing algorithm needs to make only accurate predictions, although it can opt out of predictions by saying  X  X  don X  X  know X  (  X  ). However, there must be a (polyno-mial) bound on the number of times the algorithm can respond  X  . We call such a learning algorithm KWIK ( X  X now what it knows X ).
 Section 2 provides a motivating example and sketches possible uses for KWIK algorithms. Section 3 defines the KWIK conditions more precisely and relates them to established models from learning theory. Sections 4 and 5 survey a set of hypothesis classes for which KWIK algorithms can be created. Consider the simple navigation task in Figure 1. There is a set of nodes connected by edges, with the node on the left as the source and the dark one on the right as the sink. Each edge in the graph is associated with a binary cost vector of dimension d = 3, indicated in the figure. The cost of traversing an edge is the dot product of its cost vector with a fixed weight vector w = [1 , 2 , 0]. Assume that w is not known to the agent, but the graph topology and all cost vectors are. In each episode, the agent starts from the source and moves along some path to the sink. Each time it crosses an edge, the agent observes its true cost. Once the sink is reached, the next episode begins. The learning task is to take a non-cheapest path in as few episodes as possible. There are 3 distinct paths in this example. Given the w above, the top has a cost of 12, the middle 13, and the bottom 15.
 A simple approach for this task is for the agent to assume edge costs are uniform and walk the shortest (middle) path to collect data. It would gather 4 exam-ples of [1 , 1 , 1]  X  3 and one of [1 , 0 , 0]  X  1. Standard regression algorithms could use this dataset to find a  X  w that fits this data. Here,  X  w = [1 , 1 , 1] is a natural choice. The learned weight vector could then be used to estimate costs for the three paths: 14 for the top, 13 for the middle, 14 for the bottom. Using these es-timates, an agent would continue to take the middle path forever, never realizing it is not optimal. In contrast, consider a learning algorithm that  X  X nows what it knows X . Instead of creating an approximate weight vector  X  w , it reasons about whether the costs for each edge can be obtained from the available data. The middle path, since we X  X e seen all its edge costs, is definitely 13. The last edge of the bottom path has cost vector [0 , 0 , 0], so its cost must be zero, but the penultimate edge of this path has cost vector [0 , 1 , 1]. This vector is a linear combination of the two observed cost vectors, so, regardless of w , which is just 3  X  1 = 2 . Thus, we know the bottom path X  X  cost is 14 X  X orse than the middle path. The vector [0 , 0 , 1] on the top path is linearly inde-pendent of the cost vectors we X  X e seen, so its cost is unconstrained. We know we don X  X  know. A safe thing to assume provisionally is that it X  X  zero, encouraging the agent to try the top path in the second episode. Now, it observes [0 , 0 , 1]  X  0, allowing it to solve for w and accurately predict the cost for any vector (the training data spans &lt; d ). It now knows that it knows all the costs, and can confidently take the optimal (top) path.
 In general, any algorithm that guesses a weight vec-tor may never find the optimal path. An algorithm that uses linear algebra to distinguish known from un-known costs will either take an optimal route or dis-cover the cost of a linearly independent cost vector on each episode. Thus, it can never choose suboptimal paths more than d times.
 The motivation for studying KWIK learning grew out of its use in multi-state sequential decision mak-ing problems like this one. However, other machine-learning problems could benefit from this perspective and from the development of efficient algorithms. For instance, action selection in bandit problems (Fong, 1995) and associative bandit problems (Strehl et al., 2006) (bandit problems with inputs) can both be ad-dressed in the KWIK setting by choosing the better arm when both payoffs are known and an unknown arm otherwise.
 KWIK could also be a useful framework for study-ing active learning (Cohn et al., 1994) and anomaly detection (Lane &amp; Brodley, 2003), both of which are machine-learning problems that require some degree of reasoning about whether a recently presented input is predictable from previous examples. When mistakes are costly, as in utility-based data mining (Weiss &amp; Tian, 2006) or learning robust control (Bagnell et al., 2001), having explicit predictions of certainty can be very useful for decision making. This section provides a formal definition of KWIK learning and its relationship to existing frameworks. 3.1. KWIK Definition KWIK is an objective for supervised learning algo-rithms. In particular, we begin with an input set X and output set Y . The hypothesis class H consists of a set of functions from X to Y : H  X  ( X  X  Y ). The target function h  X   X  H is the source of training ex-amples and is unknown to the learner. Note that the setting is  X  X ealizable X , meaning we assume the target function is in the hypothesis class.
 The protocol for a  X  X un X  is:  X  The hypothesis class H and accuracy parameters  X  The environment selects a target function h  X   X  H  X  Repeat: 3.2. Connection to PAC and MB Figure 2 illustrates the relationship of KWIK to the similar PAC (probably approximately cor-rect) (Valiant, 1984) and MB (mistake bound) (Lit-tlestone, 1987) frameworks. In all three cases, a series of inputs (instances) is presented to the learner. Each input is depicted in the figure by a rectangular box. In the PAC model, the learner is provided with labels (correct outputs) for an initial sequence of inputs, de-picted by cross-hatched boxes. After that point, the learner is responsible for producing accurate outputs (empty boxes) for all new inputs. Inputs are drawn from a fixed distribution.
 In the MB model, the learner is expected to produce an output for every input. Labels are provided to the learner whenever it makes a mistake (filled boxes). In-puts are selected adversarially, so there is no bound on when the last mistake might be made. However, MB algorithms guarantee that the total number of mistakes is small, so the ratio of incorrect to correct outputs must go to zero asymptotically. Any MB al-gorithm for a hypothesis class can be used to provide a PAC algorithm for the same class, but not necessarily vice versa (Blum, 1994).
 The KWIK model has elements of both PAC and MB. Like PAC, a KWIK algorithm is not allowed to make mistakes. Like MB, inputs to a KWIK algorithm are selected adversarially. Instead of bounding mistakes, a KWIK algorithm must have a bound on the num-ber of label requests (  X  ) it can make. By requiring performance to be independent of the distribution, a KWIK algorithm can be used in cases in which the in-put distribution is dependent in complex ways on the KWIK algorithm X  X  behavior, as can happen in on-line or active learning settings. And, like PAC and MB, the definition of KWIK algorithms can be naturally extended to enforce low computational complexity. Note that any KWIK algorithm can be turned into a MB algorithm with the same bound by simply hav-ing the algorithm guess an output each time it is not certain. However, some hypothesis classes are expo-nentially harder to learn in the KWIK setting than in the MB setting. An example is conjunctions of n Boolean variables, in which MB algorithms can guess  X  X alse X  when uncertain and learn with n + 1 mistakes, but a KWIK algorithm may need  X (2 n/ 2 )  X  s to ac-quire the negative examples required to capture the target hypothesis. 3.3. Other Online Learning Models The notion of allowing the learner to opt out of some inputs by returning  X  is not unique to KWIK. Several other authors have considered related models. For in-stance, sleeping experts (Freund et al., 1997) can re-spond  X  for some inputs, although they need not learn from these experiences. Learners in the settings of Se-lective Sampling (SS) (Cesa-Bianchi et al., 2006) and Label Efficient Prediction (Cesa-Bianchi et al., 2005) request labels randomly with a changing probability and achieve bounds on the expected number of mis-takes and the expected number of label requests for a finite number of interactions. These algorithms cannot be used unmodified in the KWIK setting because, with high probability, KWIK algorithms must not make mistakes at any time. In the MB-like Apple-Tasting setting (Helmbold et al., 2000), the learner receives feedback asymmetrically only when it predicts a par-ticular label (a positive example, say), which conflates the request for a sample with the prediction of a par-ticular outcome.
 Open Problem 1 Is there a way of modifying SS al-gorithms to satisfy the KWIK criteria? This section describes some hypothesis classes for which KWIK algorithms are available. It is not meant to be an exhaustive survey, but simply to provide a flavor for the properties of hypothesis classes KWIK algorithms can exploit. The complexity of many learn-ing problems has been characterized by defining the di-mensionality of hypothesis classes (Angluin, 2004). No such definition has been found for the KWIK model, so we resort to enumerating examples of learnable classes. Open Problem 2 Is there a way of characterizing the  X  X imension X  of a hypothesis class in a way that can be used to derive KWIK bounds? 4.1. Memorization and Enumeration We begin by describing the simplest and most general KWIK algorithms.
 Algorithm 1 The memorization algorithm can learn any hypothesis class with input space X with a KWIK bound of | X | . This algorithm can be used when the input space X is finite and observations are noise free. To achieve this bound, the algorithm simply keeps a mapping  X  h initialized to  X  h ( x ) =  X  for all x  X  X . When the environment chooses an input x , the algorithm re-ports  X  h ( x ). If  X  h ( x ) =  X  , the environment will provide a label y and the algorithm will assign  X  h ( x ) := y . It will only report  X  once for each input, so the KWIK bound is | X | .
 Algorithm 2 The enumeration algorithm can learn any hypothesis class H with a KWIK bound of | H | X  1 . This algorithm can be used when the hypothesis class H is finite and observations are noise free.
 The algorithm keeps track of  X  H , the version space, and initially  X  H = H . Each time the environment provides input x  X  X , the algorithm computes  X  L = { h ( x ) | h  X   X  H } . That is, it builds the set of all outputs for x for all hypotheses that have not yet been ruled out. If |  X 
L | = 0, the version space has been exhausted and the target hypothesis is not in the hypothesis class ( h  X  6 X  H ).
 If |  X  L | = 1, it means that all hypotheses left in  X  H agree on the output for this input, and therefore the algo-rithm knows what the proper output must be. It re-turns  X  y  X   X  L . On the other hand, if |  X  L | &gt; 1, two hypotheses in the version space disagree. In this case, the algorithm returns  X  and receives the true label y . It then computes an updated version space Because |  X  L | &gt; 1, there must be some h  X   X  H such that h ( x ) 6 = y . Therefore, the new version space must be smaller |  X  H 0 | X |  X  H | X  1. Before the next input is received, the version space is updated  X  H :=  X  H 0 . If |  X  H | = 1 at any point, |  X  L | = 1, and the algorithm will no longer return  X  . Therefore, | H | X  1 is the maximum number of  X  s the algorithm can return.
 Example 1 You own a bar that is frequented by a group of n patrons P . There is one patron f  X  P who is an instigator X  X henever a group of patrons is in the bar G  X  P , if f  X  G , a fight will break out. However, there is another patron p  X  P , who is a peacemaker. If p is in the group, it will prevent a fight, even if f is present.
 You want to predict whether a fight will break out among a subset of patrons, initially without knowing the identities of f and p . The input space is X = 2 P and the output space is Y = { fight, no fight } . The memorization algorithm achieves a KWIK bound of 2 n for this problem, since it may have to see each possible subset of patrons. However, the enumeration algorithm can KWIK learn this hypothesis class with a bound of n ( n  X  1) since there is one hypothesis for each possible assignment of a patron to f and p . Each time it reports  X  , it is able to rule out at least one possible instigator X  X eacemaker combination. 4.2. Real-valued Functions The previous two examples exploited the finiteness of the hypothesis class and input space. KWIK bounds can also be achieved when these sets are infinite. Algorithm 3 Define X = &lt; 2 , Y = &lt; , and This is, there is an unknown point and the target func-tion maps input points to the distance from the un-known point. The planar-distance algorithm can learn in this hypothesis class with a KWIK bound of 3. The algorithm proceeds as follows, illustrated in Fig-ure 3. First, given initial input x , the algorithm says  X  and receives output y . Since y is the distance be-tween x and some unknown point c , we know c must lie on the circle illustrated in Figure 3(a). (If y = 0, then c = x .) Let X  X  call this input X  X utput pair x 1 , y 1 The algorithm will return y 1 for any future input that matches x 1 . Otherwise, it will need to return  X  and will obtain a new input X  X utput pair x, y , as shown in Figure 3(b). They become x 2 and y 2 .
 Now, the algorithm can narrow down the location of c to the two hatch-marked points. In spite of this ambi-guity, for any input on the dark diagonal line the algo-rithm will be able to return the correct distance X  X ll these points are equidistant from the two possibilities. The two circles must intersect, assuming the target hypothesis is in H 1 .
 Once an input x is received that is not co-linear with x 1 and x 2 , the algorithm returns  X  and obtains an-other x, y pair, as illustrated in Figure 3(c). Finally, since three circles will intersect at at most one point, the algorithm can identify the location of c and use it to correctly answer any future query. Thus, three  X  s suffice for KWIK learning in this setting. The al-gorithm generalizes to d -dimensional versions of the setting with a KWIK bound of d + 1.
 Algorithm 3 illustrates a number of important points. First, since learners have no control over their inputs in the KWIK setting, they must be robust to degen-erate inputs such as inputs that lie precisely on a line. Second, they can often return valid answers for some inputs even before they have learned the target func-tion over the entire input space. 4.3. Noisy Observations Up to this point, observations have been noise free. Next, we consider the simplest noisy KWIK learning problem in the Bernoulli case.
 Algorithm 4 The coin-learning algorithm can accu-rately predict the probability that a biased coin will come up heads given Bernoulli observations with a KWIK bound of B ( ,  X  ) = 1 2 2 ln 2  X  = O 1 2 ln 1  X  . We have a biased coin whose unknown probability of heads is p . In the notation of this paper, | X | = 1, Y = [0 , 1], and Z = { 0 , 1 } . We want to learn an estimate  X  p that is accurate ( |  X  p  X  p | X  ) with high probability (1  X   X  ).
 If we could observe p , then this problem would be triv-ial: Say  X  once, observe p , and let  X  p = p . The KWIK bound is thus 1. Now, however, observations are noisy. Instead of observing p , we see either 1 (with probabil-ity p ) or 0 (with probability 1  X  p ).
 Each time the algorithm says  X  , it gets an independent trial that it can use to compute  X  p = 1 T P T t =1 z t , where z  X  Z is the t th observation in T trials. The number of trials needed before we are 1  X   X  certain our estimate is within can be computed using a Hoeffding bound: Algorithm 5 Define X = &lt; d , Y = &lt; , and That is, H is the linear functions on d variables. Given additive noise, the noisy linear-regression algorithm can learn in H with a KWIK bound of B ( ,  X  ) =  X  O ( d 3 / 4 ) , where  X  O (  X  ) suppresses log factors. The deterministic case was described in Section 2 with a bound of d . Here, the algorithm must be cautious to average over the noisy samples to make predictions accurately. This problem was solved by Strehl and Littman (2008). The algorithm uses the least squares estimate of the weight vector for inputs with high cer-tainty. Certainty is measured by two terms represent-ing (1) the number and proximity of previous samples to the current point and (2) the appropriateness of the previous samples for making a least squares estimate. When certainty is low for either measure, the algo-rithm reports  X  and observes a noisy sample of the linear function.
 Here, solving a noisy version of a problem resulted in an increased KWIK bound (from d to essentially d ). Note that the deterministic Algorithm 3 also has a bound of d , but no bound has been found for the stochastic case.
 Open Problem 3 Is there a general scheme for tak-ing a KWIK algorithm for a deterministic class and updating it to work in the presence of noise? This section provides examples of how KWIK learners can be combined to provide learning guarantees for more complex hypothesis classes.
 Algorithm 6 Let F : X  X  Y be the set of functions mapping input set X to output set Y . Let H 1 , . . . , H be a set of KWIK learnable hypothesis classes with bounds of B 1 ( ,  X  ) , . . . , B k ( ,  X  ) where H i  X  F for all 1  X  i  X  k . That is, all the hypothesis classes share the same input/output sets. The union algorithm can learn the joint hypothesis class H = S i H i with a KWIK bound of B ( ,  X  ) = (1  X  k ) + P i B i ( ,  X  ) . The union algorithm is like a higher-level version of the enumeration algorithm (Algorithm 2) and applies in the deterministic setting. It maintains a set of active algorithms  X  A , one for each hypothesis class:  X  A = { 1 , . . . , k } . Given an input x , the union algorithm queries each algorithm i  X   X  A to obtain a prediction  X  y from each active algorithm. Let  X  L = {  X  y i | i  X   X  A } . If  X  X  X   X  L , the union algorithm reports  X  and obtains the correct output y . Any algorithm i for which  X  y =  X  is then sent the correct output y to allow it to learn. If |  X 
L | &gt; 1, then there is disagreement among the subal-gorithms. The union algorithm reports  X  in this case because at least one of the algorithms has learned the wrong hypothesis and it needs to know which.
 Any algorithm that made a prediction other than y or  X  is  X  X illed X  X  X emoved from consideration. That is, On each input for which the union algorithm reports  X  , either one of the subalgorithms reported  X  (at most P i B i ( ,  X  ) times) or two algorithms disagreed and at least one was removed from  X  A (at most k  X  1 times). The KWIK bound follows from these facts.
 Example 2 Let X = Y = &lt; . Now, define H 1 = { f | f ( x ) = | x  X  c | , c  X &lt;} . That is, each function in H 1 maps x to its distance from some unknown point c . We can learn H 1 with a KWIK bound of 2 using a 1-dimensional version of Algorithm 3. Next, define H 2 = { f | f ( x ) = yx + b, m  X &lt; , b  X &lt;} . That is, H is the set of lines. We can learn H 2 with a KWIK bound of 2 using the regression algorithm in Section 2. Finally, define H = H 1  X  H 2 , the union of these two classes. We can use Algorithm 6 to KWIK learn H . Assume the first input is x 1 = 2 . The union algorithm asks the learners for H 1 and H 2 the output for x 1 and neither has any idea, so it returns  X  and receives the feedback y 1 = 2 , which it passes to the subalgorithms. The next input is x 2 = 8 . The learners for H 1 and H 2 still don X  X  have enough information, so it returns  X  and sees y 2 = 4 , which it passes to the subalgorithms. Next, x 3 = 1 . Now, the learner for H 1 unambiguously computes c = 4 , because that X  X  the only interpretation consistent with the first two examples ( | 2  X  4 | = 2 , | 8  X  4 | = 4 ), so it returns | 1  X  4 | = 3 . On the other hand, the learner for H 2 unambiguously computes m = 1 / 3 and b = 4 / 3 , because that X  X  the only interpretation consistent with the first two examples ( 2  X  1 / 3+4 / 3 = 2 , 8  X  1 / 3 + 4 / 3 = 4 ), so it returns 1  X  1 / 3 + 4 / 3 = 5 / 3 . Since the two subalgorithms disagree, the union algorithm returns  X  one last time and finds out that y 3 = 3 . It makes all future predictions (accurately) using the algorithm for H 1 .
 Next, we consider a variant of Algorithm 1 that com-bines learners across disjoint input spaces.
 Algorithm 7 Let X 1 , . . . , X k be a set of disjoint in-put spaces ( X i  X  X j =  X  if i 6 = j ) and Y be an out-put space. Let H 1 , . . . , H k be a set of KWIK learnable hypothesis classes with bounds of B 1 ( ,  X  ) , . . . , B where H i  X  ( X i  X  Y ) . The input-partition algorithm can learn the hypothesis class H  X  ( X 1  X  X  X  X  X  X k  X  Y ) with a KWIK bound of B ( ,  X  ) = P i B i ( ,  X /k ) . The input-partition algorithm runs the learning algo-rithm for each subclass H i . When it receives an input x  X  X i , it queries the learning algorithm for class H i and returns its response, which is accurate, by re-quest. To achieve 1  X   X  certainty, it insists on 1  X   X /k certainty from each of the subalgorithms. By the union bound, the overall failure probability must be less than the sum of the failure probabilities for the subalgo-rithms.
 Example 3 An MDP consists of n states and m ac-tions. For each combination of state and action and next state, the transition function returns a probability. As the reinforcement-learning agent moves around in the state space, it observes state X  X ction X  X tate transi-tions and must predict the probabilities for transitions it has not yet observed. In the model-based setting, an algorithm learns a mapping from the size n 2 m in-put space of state X  X ction X  X tate combinations to prob-abilities via Bernoulli observations. Thus, the prob-lem can be solved via the input-partition algorithm (Algorithm 7) over a set of individual probabilities learned via Algorithm 4. The resulting KWIK bound is B ( ,  X  ) = O n 2 m 2 ln nm  X  .
 Note that this approach is precisely what is found in most efficient RL algorithms in the literature (Kearns &amp; Singh, 2002; Brafman &amp; Tennenholtz, 2002). Algorithm 7 combines hypotheses by partitioning the input space. In contrast, the next example concerns combinations in input and output space.
 Algorithm 8 Let X 1 , . . . , X k and Y 1 , . . . , Y k be a set of input and output spaces and H 1 , . . . , H k be a set of KWIK learnable hypothesis classes with bounds of B 1 ( ,  X  ) , . . . , B k ( ,  X  ) on these spaces. That is, H ( X i  X  Y i ) . The cross-product algorithm can learn the hypothesis class H  X  (( X 1  X  X  X  X  X  X k )  X  ( Y 1  X  X  X  X  X  Y k with a KWIK bound of B ( ,  X  ) = P i B i ( ,  X /k ) . Here, each input consists of a vector of inputs from each of the spaces X 1 , . . . , X k and outputs are vectors of outputs from Y 1 , . . . , Y k . Like Algorithm 7, each component of this vector can be learned independently via the corresponding algorithm. Each is learned to within an accuracy of and confidence 1  X   X /k . Any time any component returns  X  , the cross-product algo-rithm returns  X  . Since each  X  returned can be traced to one of the subalgorithms, the total is bounded as described above. By the union bound, total failure probability is no more than k  X   X /k =  X  .
 Example 4 Transitions in factored-state MDP can be thought of as mappings from vectors to vectors. Given known dependencies, the cross-product algorithm can be used to learn each component of the transition func-tion. Each component is, itself, an instance of Algo-rithm 7 applied to the coin-learning algorithm. This three-level KWIK algorithm provides an approach to learn the transition function of a factored-state MDP with a polynomial KWIK bound. This insight can be used to derive the factored-state-MDP learning algo-rithm used by Kearns and Koller (1999).
 The previous two algorithms apply to both determin-istic and noisy observations. We next provide a pow-erful algorithm that generalizes the union algorithm (Algorithm 6) to work with noisy observations as well. Algorithm 9 Let F : X  X  Y be the set of functions mapping input set X to output set Y = [0 , 1] . Let Z = { 0 , 1 } be a binary observation set. Let H 1 , . . . , H set of KWIK learnable hypothesis classes with bounds k . That is, all the hypothesis classes share the same in-put/output sets. The noisy union algorithm can learn the joint hypothesis class H = S i H i with a KWIK For simplicity, we sketch the special case of k = 2. The general case will be briefly discussed at the end. The noisy union algorithm is similar to the union al-gorithm (Algorithm 6), except that it has to deal with noisy observations. The algorithm proceeds by run-ning the KWIK algorithms, using parameters ( 0 ,  X  0 ), as subalgorithms for each of the H i hypothesis classes, where 0 = 4 and  X  0 =  X  3 . Given an input x t in trial t , it queries each algorithm i to obtain a prediction  X  y ti Let  X  L t be the set of responses.
 If  X  X  X   X  L t , the noisy union algorithm reports  X  , ob-tains an observation z t  X  Z , and sends it to all subal-gorithms i with  X  y ti =  X  to allow them to learn. In the following, we focus on the other case where  X  /  X   X  L t . ficiently consistent, and we claim that, with high prob-y t = Pr( z t = 1). This claim follows because, by as-sumption, one of the predictions, say  X  y t 1 , deviates from y by at most 0 with probability at least 1  X   X / 3, and hence |  X  p t  X  y t | = |  X  p t  X   X  y t 1 +  X  y t 1  X  y t |  X  y t 1  X   X  y t | = |  X  y t 1  X   X  y t 2 | / 2 + |  X  y t 1  X   X  y not consistent enough for the noisy union algorithm to make an -accurate prediction. Thus, the noisy union algorithm reports  X  and needs to know which subal-gorithm provided an inaccurate response. But, since the observations are noisy in this problem, it cannot eliminate h i on the basis of a single observation. In-stead, it maintains the total squared prediction error for every subalgorithm i : ` i = P t  X  I ( X  y ti  X  z t ) 2 the subalgorithms gave inconsistent predictions. We observe that | I | is the number of  X  s returned by the noisy union algorithm alone (not counting those re-turned by the subalgorithms). Our last step is to show ` i provides a robust measure for eliminating invalid predictors when | I | is sufficiently large.
 Applying the Hoeffding bound and some algebra, we find Pr ( ` 1 &gt; ` 2 )  X  Setting the righthand side to be  X / 3 and solving for | I | , we have | I | = 1 Since each h i succeeds with probability 1  X   X  3 , and the comparison of ` 1 and ` 2 also succeeds with probability 1  X   X  3 , a union bound implies that the noisy union algo-rithm succeeds with probability at least 1  X   X  . All  X  s are either from a subalgorithm (at most P i B i ( 0 ,  X  0 or from the noisy union algorithm ( O 1 2 ln 1  X  ). The general case where k &gt; 2 can be reduced to the k = 2 case by pairing the k learners and running the noisy union algorithm described above on each pair. Here, each subalgorithm is run with parameter 4 and k +1 . Although there are improved reduction and analysis can reduce the de-pendence of | I | on k from quadratic to linearithmic, leading to the bound given in the statement.
 Example 5 Without known dependencies, learning a factored-state MDP is more challenging. Strehl et al. (2007) showed that each possible dependence structure can be viewed as a separate hypothesis and provided an algorithm for learning the dependencies in a factored-state MDP while learning the transition probabilities. The algorithm can be viewed as a four-level KWIK algorithm with a noisy union algorithm at the top (to discover the dependence structure), a cross-product algorithm beneath it (to decompose the transitions for the separate components of the factored-state representation), an input-partition algorithm be-low that (to handle the different combinations of state component and action), and a coin-learning algorithm at the very bottom (to learn the transition probabili-ties themselves). Note that Algorithm 9 is conceptu-ally simpler, significantly more efficient ( k log k vs. k dependence on k ), and more generally applicable than the one due to Strehl et al. (2007). We described the KWIK ( X  X nows what it knows X ) model of supervised learning, which identifies and gen-eralizes a key step common to a class of algorithms for efficient exploration. We provided algorithms for a set of basic hypothesis classes given deterministic and noisy observations as well as methods for composing hypothesis classes to create more complex algorithms. One example algorithm consisted of a four-level de-composition of an existing learning algorithm from the reinforcement-learning literature.
 By providing a set of example algorithms and compo-sition rules, we hope to encourage the use of KWIK algorithms as a component in machine-learning appli-cations as well as spur the development of novel algo-rithms. One concern of particular interest in applying the KWIK framework to real-life data we leave as an open problem.
 Open Problem 4 How can KWIK be adapted to ap-ply in the unrealizable setting in which the target hy-pothesis can be chosen from outside the hypothesis class H ?
