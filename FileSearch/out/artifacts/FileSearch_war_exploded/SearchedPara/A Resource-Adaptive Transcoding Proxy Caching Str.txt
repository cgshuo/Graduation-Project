 With the emergence of pervasive computing, many of today X  X  client end devices (for example, laptops, PDAs and mobile phones) have incorporated the Internet access features [1]. These devices X  capabilities vary in many aspects, such as connection bandwidth, processing power, storage capability and screen display size, etc. Because may be presented in several versions to different clients devices. These versions differ in modality, fidelity or resource requirements for storage, transferring and representation. The process of transforming a media object from an existing version to another is called transcoding. In general, media transcoding is a computation-intensive task. To reduce the service overhead on the original server, a proxy is commonly used to perform transcoding operations on the fly [2,3,4]. However, providing transcoding service at the proxies has introduced new challenges on the scalability of media systems. With transcoding, considerable amount of CPU resource at the proxy is required to complete a session. Thus, in addition to the communication links between the original server and the proxy, the CPU capacity of transcoding proxy is another potential bottleneck resource. In traditional media systems, caching media objects in the proxy is the widely used approach to reduce the network traffic effectively. In this paper, we explore a transcoding proxy caching scheme to improve streaming media delivery in a pervasive environment. In particular, we focus on its potential in reducing the demands of bottleneck resources. We propose a resource-adaptive caching (RAC) algorithm, whic h adjusts the caching merit function dynamically based on the current workload of CPU and network. Experimental results show that, under various resource constraints, RAC shows desirable performance, resulting in lower request blocking ratio. 
The rest of the paper is organized as follows. Section 2 gives an overview of related works. Section 3 describes the system environment and service model we considered, and the formal description of the problem. The detailed description of RAC algorithm is presented in section 4. The simulation modal and experimental results are discussed in section 5. Finally, section 6 concludes the paper. Proxy caching of streaming objects has been well investigated [8,9]. Which object would be replicated in the cache, and which one would be evicted from the cache to make room for the new object when the cache space has been fully occupied, are the two key design issues [8-11]. While the transcoding proxy is attracting more and more attention, its role in the functionality of caching is becoming a hot research topic caching strategies, i.e. single-version caching and multiple-version caching. With the single-version caching strategy, at most one version of an object is allowed to be cached in the proxy at any time. The algor ithms that adopt this strategy are TeC-11[12],TeC-12[12] and FVO[7] , etc. In the caching algorithms that using the multiple-version caching strategy, multiple versions of the same object are cached at the same time. The caching algorithms that adopt this strategy include TeC-2[12], transcoding also introduces new challenges. When the multiple-version caching strategy is taken, the aggregated profit of caching multiple versions of the same media same object [14]. Thus, when computing the merit of caching an object version, the existence of other versions of the same object must be carefully considered. In [14], a weighted transcoding graph (WTG) is used to describe the transcoding relationships among the versions and the corresponding transcoding delay, with which the minimal aggregated transcoding delay of caching multiple versions in the transcoding proxy is devised. This work takes transcoding delays into account in cache replacement, and does not apply in the case of  X  X treamlined X  transcoding in pervasive media streaming delivery. In the Tec [12] system, the impact of transcoding relationships on the caching design is neglected, and the existing popular algorithms (e.g., LRU, LFU, LRU-k, or GD*) are used to make the cache replacement decision. Bo Shen et al [7] simplify the transcoding relationships by assuming that the lower versions can only be transcoded from the original objects. The cache replacement decision is easier due to the restriction they have made, however, the universality of the proposed merit function and the results is lost.

Among the existing transcoding caching schemes, the work in [7] has similar objective to ours. In [7], three caching algorithms are proposed, i.e. FVO (full version only), TVO (transcoded version only) and an adaptive caching algorithm. FVO tries to reduce the network demand by caching full object versions, while TVO reduces the computation demand by caching the transcoded versions. To minimize the blocking probability, an adaptive cachi ng algorithm is proposed that considers the dynamic resource demands. Particularly, the adaptive caching algorithm uses a threshold-based policy to switch its caching replacement al gorithm between FVO and TVO. However, value in the dynamic environment has not been well explored. Our approach differs from that of [7] in two aspects: gain of caching multiple versions at the same time are explored. By introducing a design the cache replacement algorithm. Thus, our approach is more flexible and universal than that presented in [7]. computed based on the current CPU and network demands. The object versions that contribute more to the saving of the dominated bottleneck resource have more chance to be cached. Therefore, the caching system performs with good resource-awareness. 3.1 System Model We consider a media streaming system consisting of a content server, a transcoding proxy and various client devices, as shown in Figure 1. At the proxy, the media original versions and the transcoded ones can be cached. Upon receiving a service request, the proxy searches its cache space for the appropriate object version. We define the following events in the proxy: the client directly; the useful versions, transcoding is necessary. The proxy selects the useful version starts up a transcoding thread accordingly; otherwise, the request is blocked (named as CPU block). If the request is accepted, the CPU resource is reserved until the end of the streaming session. the full version should be retrieved from the content server. The proxy determines the required network bandwidth to fetch the full object version and the CPU requirement of transcoding it to the requested one, and performs the procedure. If successful, the network, it is called network block; if the request is blocked by the proxy X  X  CPU, we name it as CPU block). 3.2 Transcoding Model The various versions of a media object and the transcoding relationships among them can be represented by a WTG (weighted transcoding graph) graph [13,14]. In the transcoded to version v , the transcoding cost is given by (,) i wuv which is the weight of edge (,) uv . An example of WTG is illustrated in Figure 2. Definition 1. In the WTG i G of object i , version u is the useful version of version v iff there exist a directed edge from u to v . Let () i v  X  be the useful version set of v : 3.3 Problem Formulation To facilitate our discussion, the following notations are defined: u to v
The analysis in section 3.1 suggests that, if the request is version hit or useful hit in the cache, the CPU and network resources required for serving the request are reduced. Under a given caching status, the bandwidth saving is denoted as the network gain of the cache, while the saved CPU resource is named as the CPU gain. 
We begin by exploring how to compute the network gain. Assume that, under the versions of , ix o in the cache, there is no need to fetch the original version of object i from the content server, thus the network bandwidth saving is i b . On the other hand, if cache miss occurs, the bandwidth saving is zero. Hence, under () HO , for the request of , ix o , the bandwidth saving can be computed as follows: 
In a realistic Internet environment, different objects may have very different popularities. So, the network gain of the cache can be computed as follows: 
Similarly, if the proxy has cached , ix o , there is no need of transcoding to serve the request. Compared with fetching original version from the content server and useful version with the lowest transcoding cost and transform it to the requested one, saving can be computed as follows: 
However, CPU and network are two different types of resources. To make them comparable, we generalize the CPU gain and network gain with B and C respectively: importance of the network gain in the aggregate resource gain. 
Since the cache space in the proxy is limited, the proxy should determine which object versions be cached to maximize the aggregate gain of the cache. Therefore, the transcoding caching problem can be formuli zed as an optimization problem, i.e. to find a cache status () HO , such that (8) is maximized subject to service capacity of media streaming system is also maximized. In this section, a resource-adaptive caching (RAC) algorithm is proposed. With RAC, much as possible, and the () HO convergences towards the global optimum gradually. The value of () t  X  is dynamically computed based on the current workload of CPU and network, and the optimization objective is tuned accordingly. 4.1 Merit Function GHO o t GHO t  X  X  + X  . Taking into account the impact of object size on the caching efficiency, the caching merit function is defined as follows: In a dynamic environment like Internet, () t  X  should be dynamically tuned to reflect the current demands and availability of CPU and network resource. Hence, we design an observation-based adaptive  X  controlling mechanism to compute () t  X  dynamically. As shown in Figure 3, the output sensor measures the current CPU blocking ratio pt and network blocking ratio () net pt , and feeds them back to the controller, where the new value of () t  X  is computed as follows: CPU blocking ratio () cpu pt is computed as a moving average as follows: 
In this computation, older values of CPU blocking ratio are exponentially attenuated with a factor  X  ( 01  X  &lt;&lt; ). 4.3 Description of RAC Algorithm When the cache space is fully occupied and there is a new object , ix o being evaluated as a candidate for caching, the RAC proced ure is implemented as follows. First, inserts , ix o into the caching queue. Then, computes the caching merits for all objects in the queue, and selects an object with the lowest caching merit and remove it from cache size, a new cycle of merits computing and evaluating is needed; otherwise, the iterative procedure stops. Figure 4 shows the pseudo code of RAC. In this section, we will evaluate the performance of RAC. In particular, we construct an event driven simulator to simulate the media streaming system as illustrated in Figure 1. 5.1 Simulation Model Client Model: Suppose that the client devices can be classified into five classes. Without loss of generality, the distribution of these five classes of clients is modeled as a device vector of &lt;0.15, 0.2, 0.3, 0.2, 0.15&gt;. Transcoding Model: The original media objects in the content server should be transcoded to satisfy the user X  X  need. Thus, there may exist five different versions for the same object, and the size of the five versions are assumed to be 100%, 80%, 60%, have the same WTG graph. In particular, the transcoding relationships among the five versions and the corresponding weight matrix w are denied as (12): Where in w, the elements denote the required CPU fraction relative to the CPU power of a well-known machine for transcoding a version to another. Workload Model: Supposed that there are 1000 media objects maintained in the rate of 350kbps. The reference frequencies of these objects follow a Zipf-like requests obeys the Poisson distribution, where the parameter of  X  is set to be 0.2. 5.2 Experimental Results The performance of RAC is compared to that of LAR and LFU. The overall blocking ratio is used as the main metric in the experiments. To get a closer look, other metrics are also examined, including CPU blocking ratio, network blocking ratio, version hit ratio, useful hit ratio, and total hit ratio. 
Let S be the sum of original object versions maintained in the content server. The amount of CPU and network required to accomm odate all the user requests if there is no cache at the proxy. The CPU coefficient is used to describe the CPU power of 5.2.1 Impact of Cache Capacity First, we investigate the performance of several caching algorithms by varying the cache capacity. The CPU coefficient and network coefficient are all set to 0.3. As can be seen from Figure 5(a), the overall bl ocking ratio decreases with the increasing cache size, and RAC consistently outperforms LRU and LFU. The advantage of RAC can be explained with the help of Figure 6. From Figure 6(a), it can be seen that RAC has the highest version hit ratio. It implies that under RAC, more requests are serviced directly by the proxy cache, thus much more CPU and network resources are saved, and the potential service capacity of the system is improved. This is the main reason why RAC has lower overall blocking ratio. Moreover, as shown in Figure 6(b) and 6(c), LRU and LFU have lower overall hit ratio than RAC, and most of the hits are useful hits. As a result, more transcoding activities take place at the proxy under LRU and LFU, leading to heavier CPU load . Thus the proxy becomes the dominant bottleneck, and most requests are blocked due to insufficient CPU resource, while the network load is reduced. 5.2.2 Resource Coordinating Capability To gain insight into the RAC X  X  coordinating capability in resource usage, we examine the change of blocking ratio during runtime. In the experiments, the blocking ratio are phase (0-t1), the CPU blocking ratio increas es sharply, while the network blocking ratio decreases. It is because, at the beginn ing time the cache is cold and the version hit ratio is very low, which leads to heavy CPU load at the proxy. During the period the network load increases accordingly. At t2, the system reaches the steady state. On steady state at t1, and the CPU blocking ratio is kept at a high level while the network are used in a much more balanced fashion under RAC. In RAC, the coordinating capability is realized by tuning the value of () t  X  dynamically (see Figure 7(d)). 5.2.3 Performance Under Different Resource Conditions In this section, we examine the performance of RAC under different resource conditions. Figure 8(a) shows the overall blocking ratio as a function of CPU 20%. As can be seen, RAC produces the lowest overall blocking ratio over a wide range of CPU coefficient. Figure 8(b) shows the overall blocking ratio as a function of network coefficient with the CPU coefficient fixed at 0.3 and relative cache size set to 20%. RAC also produces the lowest overall blocking ratio over a wide range of network coefficient. In pervasive environments, the media objects should be transcoded to make them accessible to various client devices. In a transcoding proxy-based media streaming system, CPU and network are two potential bottleneck resources. In this paper, a resource-adaptive transcoding proxy caching me chanism is explored to improve the streaming media delivery in pervasive envir onment. In particular, a resource-adaptive caching (RAC) algorithm is proposed. Th e caching merit function is adjusted dynamically based on current resource conditions. With RAC, the system deals with the CPU and network demands in a balanced fashion, and performs with good resource awareness. 
