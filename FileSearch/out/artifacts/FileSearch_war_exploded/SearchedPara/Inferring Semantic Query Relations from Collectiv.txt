 In this paper we describe how high quality transaction data comprising of online searching, product viewing, and product buying activity of a large online community can be used to infer semantic relationships between queries. We work with a large scale query log consisting of around 115 million queries from eBay. We discuss various techniques to infer semantic relationships among queries and show how the results from these methods can be combined to measure the strength and depict the kinds of relationships. Further, we show how this extraction of relations can be used to improve search relevance, related query recommendations, and recovery from null results in an eCommerce context. H.2.8 [ Information Systems ]: Database applications  X  Data mining ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Query formulation, In formation filtering. Algorithms, Design , Experimentation, Measurement. Semantic Query Networks, sema ntic relatedness, query log mining, graph mining. The problem of matching a query to relevant documents and that of determining similarity among documents has been extensively researched in the field of Information Retrieval[15][16][17]. Finding relatedness between a given pair of queries is a different problem. Because of the short length of queries and extreme sensitivity to context, standard text similarity measures can not be applied to effectively measure query-query similarity[1]. Determining similarity between short text segments like queries concepts that the queries represent. This requires domain knowledge and reasoning ability. Hence, pure statistical techniques or lexical repositories are not sufficient to tackle this problem. With the increasing growth in size and popularity of the World Wide Web, many human needs for information gathering, education and commerce have shifted from the offline to the online world. Hence, the need to understand query formulations in a semantic way, has become important. Also, with the evolution of the web, lot of new vocabularies have emerged and then evolved. For instance, instant messaging has its own lingo, online scrapping has its own vocabulary and internet commerce has its own language. The word  X  X ib X  as defined by the Merriam-Webster X  X  dictionary is a noun meaning  X  X  small pointed or projecting part X . However on a commerce site like eBay, the community uses it to mean a product that is sold  X  X ew in box X . Similarly  X  X wt X  could mean Northwest Territories in the context of Canada, or it could mean New World Translation in the context of the Bible. However it means New With Tag(s) in the context of online auctions. On eCommerce sites, a user might search for an author name with the intent of finding her book or search for some attribute or f acet and expect to find the correct item. In order to find semantic similarity between such usages and use that information for web applications, a dynamic system that evolves with user behavior and captures relations and nuances based on collective intelligence is needed. Actions of the eCommerce community is a rich data-source. eCommerce data is likely to be less noisy as compared to other data-sources because of the involvement of monetary transactions. Hence, it can be leveraged to infer semantic relationships among queries. There has been extensive research study of queries on web search engines over the past decade. One of the oldest such studies is from 1998 and describes the correlation analysis of the log entries, studying the interaction of terms within queries. [2] describes how the queries issued and the URLs clicked from the results can be viewed as a bipartite graph and how agglomerative clustering can be applied on the bipartite gr aph to discover clusters of similar queries and similar URLs. [5] describes a way to represent queries in a vector space based on a graph derived from the query-click bipartite graph and shows how the representation can be used to infer some semantic relationships. There has also been work around using search engines to retrieve documents from the web that satisfy search queries and then use the content of the retrieved documents to determine the similarity between the queries. [6] proposes a method that exploits page counts and document summary text snippets returned by a Web search engine in response to a query to compute the semantic similarity between queries using overlap measures and lexico-syntactic pattern extraction. [4] describes a method for measuring the similarity between short text snippets(even those without any overlapping terms) by leveraging web search results to provide greater context for the short texts. It describes a similarity kernel function for the same and how the kernel function scores well for related queries and scores low for unrelated queries. [1] shows that unigram language models can be built for queries based on the vocabulary determined by the matching documents that are returned by the search engine. Then the semantic relatedness between queries can be estimated by measuring a function based on KL-divergence of the unigram language models for the queries. [14] defines a distance called the Google Similarity Distance to determine the similarity between two keywords by using the number of hits returned by the Google search engine for those keywords. [19] describes how Latent Semantic Analysis could be used to measure similarity between word pairs. Studies have been conducted to extract semantic relations from logs of user sessions. Such studies have been described in [10] computed from it to identify concepts related to a user query. There have been studies leveraging external sources like WordNet[7] and Wikipedia[3] to determine semantic relationships among queries. [11] and [12] use the temporal frequency information of queries to infer semantic relationships among them. Although significant work has been done in finding related queries, most of it has revolved around finding related queries for web search engines. Not much work has been done around finding semantically related queries for product search in eCommerce environments. Product titles tend to be short and on sites like eBay are defined by the sellers selling the items. The buyers who might want to buy the items might use a different vocabulary to formulate the queries, and without appropriate recommendations or query expansions, an eCommerce system with a boolean search engine cannot efficiently connect the buyers to the sellers. An item listed as  X  X pod nano 4gb X  will not match the query mp3 player , an item listed as  X  X arnet X  will not match the query january birthstone , an item listed as  X  X artin guitar X  will not match the query acoustic guitar (although martin guitar is a specialization of acoustic guitar) and an item listed as  X  X ak table X  will not match the query wood table . Our work focuses on extracting semantic relationships among queries for eCommerce. We use eCommerce transaction data from eBay for our work. We not only look at how people query but also at how they behave after a query, what they look at, what they bid on and what they buy. Web data could be polluted by robots, but data associated with merchandise being bought is less likely to suffer from such pollu tion. We extract semantic relationships from eBay queries using multiple measures and combine them using a composite score. We also show how these relationships can be used in a recommendation system or an inventory browser to match the buyers vocabulary with that of the sellers, thus promoting efficient commerce. The rest of the paper is laid out as follows. In section 3 we describe the textual methods that we use to determine similarity among queries. In section 4 we describe how we leverage user sessions to extract some semantic similarity based on searching and buying behavior. In section 5 we show a kernel function based on the collective wisdom of users inferred from their transaction data, that is useful in determining semantic similarity among queries. In section 6 we show some properties of the semantic query network that we built. Section 7 describes interesting relations mined through our work and various applications based on our semantic query network. Finally we conclude with discussions of possible future work in section 8. We selected a substantial sample of queries from eBay, which consists of around 115 million queries. The frequency of the queries follows a power-law distribution as shown in Figure 1. We keep the surface representation of the queries other than lowercasing and replacing special characters with spaces, which leaves us with around 17 million unique queries. We try to discover textual similarity among queries and connect them. This gives us a graph where each node represents a unique query and every edge indicates a relationship connecting two queries. We refer to this graph as the Term Connection Graph. Figure 1 eBay queries follow a power-law distribution. X-axis shows the rank of the query in terms of popularity. Y axis shows the frequency of the query in the sample. Both X and Y We use a simple similarity measure to connect queries with textual similarity. We represent every query as a set comprising of terms found in the query. So a query Q can be represented as terms in the queries and n is the total number of unique terms in query Q .
 For every query Q we find all queries c Q such that These are all the queries that can be formed by adding new terms to query Q . Then we connect query Q and each query c Term Connection Graph with an edge. We also find all queries Q such that q q W W formed by dropping words from query Q . We connect all such queries l Q with the node Q in the Term Connection Graph. Queries formed by adding new terms to the original query are specializations of the original query, whereas queries formed by dropping words from original query generally tend to be generalizations of the original query. Every edge between any two pairs of nodes b a Q Q , also has meta-information indicating whether b a Q Q  X  or a b Q Q  X  which conveys whether the edge traversal would lead to a generalization or a specialization. All edges are bidirectional. Traversal in one direction will give us a generalization whereas in the other will give us a specialization. We also connect the nodes for queries that have the same terms in them but in different order. For a boolean search engine like eBay such queries are practically synonymous. In order to build this graph efficiently we first build an inverted index from the queries. The index provides fast lookup to find all queries which contain a particular term. It also provides fast lookups to find all queries that have a particular number of terms. This index is then used to find the connections for every query. The dissimilarity between queries increases as the number of differing terms in the queries increase. We define the term distance between two queries as D , which is the number of terms by which the two queries differ. We use a simple function to normalize the edge score between 0 and 1. The similarity between two queries a Q and b Q based on the Term Connection Graph is given by = T T otherwise, and we don X  X  connect those queries in the graph. So the similarity exponentially decreases as the number of differing terms in the queries increase. After making such connections we see that out of ~17 million queries(nodes), there are only about 500,000 nodes which don X  X  have any connections. These are the rare queries or misspelled queries or some nonsensical robot generated queries. Otherwise, the degree distribution for the nodes follows a power-law distribution as shown in Figure 2. The graph is not dense and has around 168 million edges. Figure 2 Power law distribution for Node Degree in the Term An interesting graph showing the relationship between node degree and frequency of query is shown in Figure 3. popularity of the query. X axis shows the frequency of the connections(node degree) for the query in the sample. Both X Interestingly eCommerce queries show similar characteristics as the Yahoo web queries connected based on click characteristics described in [5]. This is evident from Figure 1, Figure 2 and Figure 3. A sub-graph around the query persian rug obtained from the Term Connection Graph is shown in Figure 4. As is evident from the sub-graph, many useful query specializations and generalizations can be obtained by using this method. around the query persian rug . The sub-graph was formed by looking only at edges with 5 . 0 = s T and selecting a sub-set of We mine user sessions to find the queries done by the user in the same session. We build a state machine out of queries done by users in their sessions and use it to build a graph indicating semantic similarity among queries. We refer to this graph as the Session Relationship Graph. All the queries found in user sessions are in the Session Relationship Graph. We look at every possible combination of 2 consecutive states in the state machine to infer the semantic relationships. So, if a user performed a series of queries 4 , 3 , 2 , 1 Q Q Q Q then we connect Q and 3 Q to 4 Q . We did experiments wherein we looked at a longer sequence of consecutive states, for example 3 consecutive states in which case we would have connected 1 Q to 2 Q and Q to 3 Q and 4 Q and 3 Q to 4 Q where the similarities for Q would be considered weaker than that from 1 Q to However, we found that it gives very little added benefit and hence for all subsequent experiments we have looked only at 2 consecutive states. These connections are directional because it is possible that the probability of 1 Q following 2 Q is significantly higher than that of 2 Q following 1 Q . This usually happens when users follow up on misspelled versions of their queries with the correct version. We aggregate this information across millions of user sessions in our query log sample. We only look at user sessions in which some buying activity happened. This way we can get rid of noise and activity by robots which might have escaped robot filtering. Also, we only keep edges for relationships that were observed in at least 3 user sessions because we qualitatively observed that this gives us a good confidence level for the inferred relationships. The Session Relationship Graph is sparse as compared to the Term Connection Graph. It consists of only around 7 million edges as compared to the 168 million edges in the Term Connection Graph. Also, out of these 7 million connections, around 600, 000 connections overlap with the connections in the Term Connection Graph. Out of the total ~17 million unique queries only 1.62 million queries ha ve connections in the Session Relationship Graph. The degree distribution of those 1.62 million nodes is as indicated in Figure 5 below. Figure 5 Degree distribution for nodes with connections in 
Session Relationship Graph. X axis shows the degree of the node and Y axis shows the fraction of nodes with that degree. The strength of the relations is based on the amount of users whose sessions shared these search terms. For 2 queries Q if the relationships were observed in N sessions, then the session based similarity score s S between 1 Q and as, This function was determined heuristically and through qualitative experiments, to normalize the similarity score between 0 and 1 and slice the strength of the recommendations in 10 different buckets. Figure 6 shows a sub-graph around the query persian rug derived from the Session Relationship Graph. A comparison with Figure 4 shows how this method can capture more semantics than purely syntactic term distance based connections. Synonyms in the form of  X  X ug X  and  X  X arpet X  are captured. Also various specific type of rugs like  X  X sfahan X  and  X  X abriz X  are captured in this network. It is interesting to note the weak connection ( 2 . 0 = s watch X . It could be related to the change of intent in user sessions or due to other noise in data. For real-life use cases data mining algorithms which can deal with the noise in the data are needed. Section 5 describes how historical buying behavior of user can be used to remove such noise from semantic connections. 
Figure 6 A sub-graph around the query persian rug obtained from the Session Relationship Graph. Note that only a few As described in [4], applying traditional document similarity measures, such as the widely used cosine coefficient[15], to short queries would often produce inadequate results. For similarity between the queries arlington mayor and carmen gronquist , applying the cosine would yield a similarity of 0 since the two queries don X  X  contain any common terms. However in reality the semantic similarity of these queries is pretty high. Carmen Gronquist is the former mayor of Arlington who was ousted from her post on account of some objectionable public photographs. Users on eBay use these two queries synonymously to look for her posters. Even in cases where two queries may share common terms, the terms might be getting used in different contexts. Consider the queries apple ipod and apple dishes . The first uses apple in reference to a brand whereas the second uses the term apple as an attribute for dishes. Thus, while the cosine score between these two queries would be 0.5 due to the shared word apple , in reality they are not so closely semantically related. This problem can be partly addressed by looking at metadata which could qualify the concept and context of the query; rather than just looking only at the words in queries. We leverage user activity, the title and attributes of items that get viewed, or bought to help us achieve this goal. We mine the user sessions and track user activity following every unique query happening on eBay. The kind of activity that we are interested in is buying behavior. eBay is a marketplace of millions of sellers and buyers. Each seller describes her product for sale in various ways. These include the title associated with an item, the description of the item, the category the item was listed in, and other attributes which qualify the item. eBay search engine is inherently boolean. When a buyer searches for items, all items matching the search keywords are extracted and shown to the buyer. They might get shown in different orders depending on sorting options chosen by buyer which could be items ending soonest, items that are cheapest, items that are closer to buyer X  X  location or some other sorting option available from the user interface. We look at the items that a user ends up buying after issuing a search. We then map the features of the items bought to the particular search query that was issued before buying the item. The features of the items that we extract for association are words found in the title of the item[13], and some other attributes on the item which might identify the category on the item or an ISBN / UPC number if there was one associated with it. Whenever an item gets bought, we extract the features out of it and then increment the weights of these features for the query that was issued before buying the item. This leads to a rich data set which maps a query to different features with specific weights. As a simple example, if one user issued a query britney spears and bought an item described as  X  X ritney spears poster 8x10 new X  and another user issued the same query and bought an item described as  X  X ritney spears fantasy perfume new X , then we will have a mapping from the query britney spears to the terms  X  X oster X ,  X 8x10 X ,  X  X antasy X ,  X  X erfume X  and  X  X ew X  with the weights 1,1,1,1 and 2. Note that the query is not mapped to the terms present in itself as they would be found in all the items bought after issuing the query as the eBay search engine is boolean in nature. The scores for the terms are in the e nd normalized by the total activity for the query. Once the scores are normalized they are converted to a log domain and then scaled linearly into a 32 bit integral range. This whole process helps us map the short queries to a high dimensional space which could carry information a bout the context and concept related to the query. Table 1 below shows some queries and the features they get mapped to. 
Table 1 Table indicating mapping of queries to other features that identify the query intent, the query concept and the query context. The table shows only a top few features for the query. 
For our semantic similarity work we use the top 25 features As is evident from the table above apple ipod and apple dishes have significantly different top features. As a result, a function based on these features would correctly be able to indicate low semantic similarity between the two, however a function based on terms in the queries would wrongly determine a higher similarity because of the common word apple . Also from Table 1 we see that although halle berry and drew barrymore don X  X  have any common term in them, they do share some top features like photo, signed, sexy, 8x10 etc. which indicates some level of semantic similarity between the two (both of them are famous actresses and merchandise related to both sold and bought on eBay might be similar). The table also shows some commonality in features between j k rowling and stephen king although they have no terms in common, which is expected as both are popular authors. Another interesting thing to note from the table is the commonality in features between 1st sorcerer stone and the purely numeric query 9780807281956 . At first instance these queries don X  X  look similar however the features correctly indicate the semantic similarity between the ISBN for the book  X  X arry Potter and the Sorcerers Stone X  and the query 1st sorcerer stone . Thus, it is evident that a function that represents a query using all these features can be effective in evaluating the semantic similarity among queries. As shown in the previous section we have features and weights associated with queries. We consider query to be a vector in the feature space, with com ponents proportional to the weights. Every query i Q is represented by a vector i v which has the top n features for the query i Q and for our experiments 25  X  n . We observe that limiting the number of features to 25, makes the calculations faster without losing much accuracy in evaluation of semantic similarity. We finally represent the query i Q by the L2 norm of the vector v . Hence, Q = . We calculate the semantic similarity s K between queries 1 Q and 2 Q by taking the dot product. s = = . As we take the L2 norm of the query representations before taking the dot product to find the semantic similarity, the semantic similarity s K is an inner product with a bounded norm. As we only use positive components for the vectors, s K will always lie between 0 and 1. From our experiments we observe that values of 5 . 0 &gt; explainable semantic similarity. In the graph we only preserve edges with 5 . 0 &gt; s K and for all query pairs other than these, is considered to be zero. Some examples of query pairs and the value of the semantic similarity s K calculated in the above manner are described below in Table 2. Similarity s K for some representative query-query pairs. As is evident from the table above the semantics of buyer behavior on eBay are nicely captured by our similarity function. Although stereo system and wii system , apple dishes and apple player share common words, the function rightly determines their similarity to be almost zero. Also abbreviations mapped to full names, synonymous queries and generalization/specialization of queries rightly score high for the function. Figure 7 below shows a network around the query persian rug using this similarity function. Figure 7 A sub-graph around the query persian rug formed by connections using the similarity function described. Only selected edges with a value of 5 . 0 &gt; s K are shown. Font-size is Comparing this network with Figure 4 and Figure 6 shows that this network is much dense as compared to the Term Connection Graph or the Session Relationship Graph. This is because this network can capture the most interesting re lated queries, those submitted by different users which the session-based graph cannot discover. This function is able to capture relationships among queries which are separated by low term distances, as well as between queries which share no terms in common but still are semantically related. The only downside of this approach is that sufficient historical data on features. If data is not sufficient, then the semantic function may not work well. Also for new queries for which we have less data, it might take significant time to infer relations using this similarity function. So for new queries a fast term distance based connection approach is more effective. We combine the 3 approaches and build a graph out of eBay queries which has 3 kinds of edges. We refer to this combined graph as the Semantic Query Network. We build an index out of this graph and load it up in a high performance Semantic Relations Server written in C++ which runs on a cluster of 8 CPU SUN x86 boxes. The index is then queried by various applications. One instance of the server can serve 500+ graph based queries per second. All the 3 independent methods have a scoring function which scores the relationship between two queries with a score between 0 and 1. We combine the 3 methods linearly to get a composite similarity score where  X  ,  X  and  X  are coefficients which determine the weights for the different kinds of similarity methods. By enforcing between 0 and 1 for any arbitrary pair of queries. We could also use a committee based approach wherein a relationship due to more number of methods is ranked higher than a relationship discovered through fewer number of methods. Textual relationships don X  X  always capture synonyms and other interesting semantic relations. Session based relationships could sometimes have noise because of change in user intent during the session. Query mapping to higher dimensional space and a function over it is a useful similarity measure, but it is useful only when we have seen enough activity around the query to be able to map it to appropriate features. Thus every method has its own advantages and limitations. For applications which need to dete rmine relationships with some level of confidence, a combination of the three methods proves effective to get rid of noisy suggestions and get higher quality recommendations. For example when users search for apple on eBay if their usual intent is to buy apple notebooks or ipods, then although the textual similarity between apple and apple ipod, apple and apple dishes would be the same, the composite similarity score would be higher for the query pair apple , apple ipod as compared to the query pair apple , apple dishes . Textual term based relationships do have some advantages. They are simple to infer and are very helpful in real-time applications. When we use our network for real applications, we do encounter situations in which we see a new query and we may not have enough user activity data to pl ace the query at the proper place in the network. However as we also store inverted meta information in our query network index, we could connect new queries to possible textual neighbors quickly. If a new  X  X eal colored zune X  comes in the market, we may not initially have any session data to determine related queries semantically, however we could easily associate  X  X eal colored zune X  to other queries like  X  X une X ,  X  X lack zune X  etc. We use the connections based on Term Connection Graph, to mine interesting meta-data. As shown in section 4 many queries which are part of the same session, don X  X  have any common terms in them. For example a user might issue the query zune followed by the query ipod . We discover the concepts or the central theme connecting such queries by looking at the common extensions for those queries in the Term Connection Graph. Query relationships can be used for merchandising with better confidence, if the themes relating the queries are known. As shown in Figure 8, for two queries u and v with no terms in common, we extract the central theme  X  from the Term Connection Graph. The queries u and v and themes  X  can be as indicated in Table 3. 
Figure 8 Figure indicates how two queries with no terms in common could be connected by a central theme. Also various kinds of semantic relationships could exist between the queries Table 3 A table indicating how mining the Term Connection 
Graph can help in explaining semantic relationships between The theme  X  connecting u and v can be used to infer the relationship r between u and v , the relationship 1 and  X  and the relationship 2 r between v and  X  . In typical examples, as shown below, 2 1 r r = . These relationships can be classified and could be used for various purposes. Examples of some different kinds of relationships include: Each node in our graphs also carries information about the frequency of the query and the amount of inventory found for that query. This determines a measure for the strength of the node. This is useful when the graph is queried by applications, for example to recover from searches resulting in low number of results as described in 7.3. We build another meta-graph out of the node strengths, term connections, and extracted concepts(as shown in Table 3). These kind of meta-graphs convey a lot of information. An example is discussed below and is shown in Figure 9. Here jessica simpson , paris hilton , britney spears , lindsey lohan , jessica alba , tara reid , christina aguilera are connected in the Session Relationship Graph. These are connected by the common extensions  X  X hoto X  and  X  X oster X . This makes them a related concept of  X  X rtist X . jessica simpson and rocket dog are related by the common extension  X  X hoes X . These, in this case are brand names for shoes. The differing weights of edges also tell us how we can extend queries, merchandise, and provide relevant results based up on these. For example, jessica simpson has a stronger connection to  X  X hoes X  than  X  X osters X  whereas jessica alba has a strong connection to  X  X hoto X  and  X  X osters X . So a jessica simpson query can be extended to  X  X hoes X  whereas a jessica alba query to  X  X hoto X  or  X  X osters X . 
Relationship Graph and then finding connecting themes from Based on our Semantic Query Network, we built an inventory browser for eBay (http://labs.ebay.com/demos/qnet/). When a user issues a search, this inventory browser shows a network of queries to further change and refine the search, while at the same time exploring eBay inventory. This is very useful for users who have a vague idea of what they want, but may not know the correct vocabulary to find the items. Using this, users can search for phones or cameras with only a vague idea of the model numbers and then be able to discover those through the network of queries. This is also useful to look for one of a kind items on eBay, wherein a user can form a general query, and the network can help her discover the intended inventory by expanding the query network at every step to aid in query reformulation. Product searches can often return few results b ecause of the difference in vocabulary between sellers and buyers or because of over-specialization of queries by buyers. The Semantic Query Network could be leveraged in these cases to help the users reformulate their query or to recommend queries which are likely to return inventor y related to the user X  X  intent. The table below shows some real user queries on eBay which did not match any inventory at the time the query was issued. Some recommendations from the query network are also shown. A mix of items based on the query network would be a good way to show some related inventory. 
Table 4 Queries returning zero results and recommendations Providing the user with other sear ch terms related to her issued query is a common application in web, image, product or any other form of searching. These are shown to the user even when there are many matching documents satisfying users original query, and provide the user with an option to reformulate, refine, specialize, generalize her own query or get an idea about competing or complementary brands and products. Our Semantic Query Network can be leveraged to find semantically related searches for the user search terms. The mapping of user queries to higher dimensions as well as user session information provides an excellent way to determine related searches. Based on the composite score described recommendations for some query terms on eBay are discussed in Table 5 below. Table 5 Table indicating related searches recommendations for some eBay queries. Related Queries not containing the original query are shown in bold The contribution of our work is as follows: For our work we have mostly used surface representation of queries with minor cleaning and normalization. As part of future work, we would like to add syntactic measures like a Porter X  X  stemmer to both our queries and the feature space made of item features to aggregate syntactically similar queries. We would also like to build a classifier which can use features from external sources like WWW, Wikipedia, WordNet, ODP and Cyc, to classify the semantic relationships into various classes like hypernyms, hyponyms and synonyms. [1] Metzler D., Dumais S. and Meek C. Similarity measures for short [2] Beeferman D. and Berger A. Agglomerative clustering of a search [3] Gabrilovich E. and Markovitch S. Computing semantic relatedness [4] Sahami M. and Heilman T. A web-based kernel function for [5] Baeza Yates R. and Tiberi A. Extracting semantic relations from query [6] Bollegala D., Matsuo Y. and Ishizuka M. Measuring semantic [7] Carterette B., Jones R., Greiner W. and Barr C. N semantic classes are [8] Shi X. and Yang C. Mining related queries from search engine query [9] Silverstein R., Helzinger M., Marais H. and Moricz M. Analysis of a [10] Cucerzan S. and Brill E. Extracting semantically related queries by [11] Chien S. and Immorlica N. Semantic similarity between search engine [12] Vlachos M., Meek C., Vagena Z. and Gunupulos D. Identifying [13] Gupta R. Query representation in a space defined by item features. [14] Clibrasi R. and Vitanyi P. The Google similarity distance. IEEE [15] Salton G. and McGill M. Introduction to Modern Information [16] Frakes W. and Baeza-Yates R. Information Retrieval: Data Structures [17] Fang H., Tao T. and Zhai C. A formal study of information retrieval [18] Fonesca B., Golgher P., Possas B., Ribeiro-Neto B. and Ziviani N. [19] Landauer T., Foltz P. and Laham D. Introduction to Latent Semantic 
