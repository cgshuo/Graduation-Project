 The demand for automatic extraction of true information (i.e., truths) from conflicting multi-source data has soared recently. A variety of truth discovery methods have wit-nessed great successes via jointly estimating source reliabil-ity and truths. All existing truth discovery methods focus on providing a point estimator for each object X  X  truth, but in many real-world applications, confidence interval estima-tion of truths is more desirable, since confidence interval contains richer information. To address this challenge, in this paper, we propose a novel truth discovery method ( ET-CIBoot ) to construct confidence interval estimates as well as identify truths, where the bootstrapping techniques are nicely integrated into the truth discovery procedure. Due to the properties of bootstrapping, the estimators obtained by ETCIBoot are more accurate and robust compared with the state-of-the-art truth discovery approaches. Theoretical-ly, we prove the asymptotical consistency of the confidence interval obtained by ETCIBoot . Experimentally, we demon-strate that ETCIBoot is not only effective in constructing confidence intervals but also able to obtain better truth es-timates.
 H.2.8 [ Database Management ]: Database Applications X  Data mining Truth Discovery; Confidence Interval; Bootstrapping
Today, we are living in a data-rich world, and the infor-mation on an object (e.g., population/weather/air quality of a particular city) is usually provided by multiple sources. Inevitably, there exist conflicts among the multi-source da-ta due to a variety of reasons, such as background noise, hardware quality or malicious intent to manipulate data, etc. An important question is how to identify the true informa-tion (i.e., truths) among the multiple conflicting pieces of information. Because of the volume issue, we cannot expect people to detect truth for each object manually. Thus, the demand for automatic extraction of truths from conflicting multi-source data has soared recently.

A commonly used multi-source aggregation strategy is av-eraging or voting. The main drawback of these approaches is that they treat the reliability of each source as the same. In real-world applications, however, different sources may have different degrees of reliability and more importantly, their reliability degrees are usually unknown a priori . To address this problem, a variety of truth discovery method-s [2 X 5,7,11,12,15 X 18,20 X 25] have been proposed. Although these methods vary in many aspects, they share a common underlying principle: If a piece of information is provided by a reliable source, it is more likely to be trustworthy, and the source that more often provides trustworthy information is more reliable. Following this principle, existing methods are designed to jointly estimate source reliability and truths by assigning larger weights to the reliable sources which in return play more important roles in the data aggregation.
All existing truth discovery methods [2 X 5,7,11,12,15 X 19, 21,22] focus on providing a point estimator for each object X  X  truth, i.e., the estimate is a single value. However, impor-tant confidence information is missing in this single-value estimate. For example, two objects A and B receive the same truth estimate, e.g., 25. Even though the estimates are the same, the confidence in these estimates could dif-fer significantly X  A may receive 1000 claims around 25 while B only receives one claim of 25, and clearly the confidence in A  X  X  truth estimate is much higher. Therefore, instead of a point estimation, an estimated confidence interval of the truth is more desirable. An  X  -level confidence interval [8] is an interval ( a, b ) such that P (  X   X  ( a, b )) =  X  for a given  X   X  (0 , 1), where  X  denotes the truth in our scenario. The width of the interval reflects the confidence in the estimate X  X  smaller interval indicates the higher confidence in the esti-mate and a larger interval means that the estimate has more possible choices within the interval. In the example we just mentioned, suppose the 95% conference interval of A and B  X  X  estimates are (24.9,25.1) and (0,50) respectively. Although both truth estimates are 25, we are more certain that the truth of A is close to 25. With such confidence information, the decision makers can use the truth estimates more wisely. However, such important confidence information cannot be ob tained by the traditional point estimation strategy adopt-ed by existing truth discovery methods.

The estimation of confidence intervals for objects X  truths can benefit any truth discovery scenario by providing addi-tional information (i.e., confidence) in the output, but its advantage is more obvious on long-tail data. A multi-source data is said to be long-tail in the sense that most objects receive a few claims from a small number of sources and on-ly a few objects receive many claims from a large number of sources. As discussed in the aforementioned example, the difference in the confidence of the truth estimates is usually caused by the difference in the number of claims received by the objects. When an object receives more claims, a smaller confidence interval is obtained, and thus the estimate of this truth is more certain. It is essential to provide confidence intervals rather than points for the truth estimates on such long-tail data, which are ubiquitous. The Flight Status and Game applications used in our experiments are examples of such long-tail phenomena (The details are deferred in Sub-section 4.3). In Figure 1, we present the histograms in terms of the number of claims and fit them into an exponential dis-tribution, a typical long-tail distribution, respectively. (a ) Flight Status Dataset
To address the problem, in this paper, we propose a nov-el method, E stimating T ruth and C onfidence I nterval via Boot strapping ( ETCIBoot ) to construct confidence inter-val estimates for truth discovery tasks. We adopt the iter-ative two-step procedure used in traditional truth discovery methods: 1) Update truth estimates based on the current estimates of source weights (source reliability degrees), and 2) update source weights based on the current estimates of truths. At the truth computation step, instead of giving a point estimation, we now adopt the following procedure to obtain confidence interval estimates. ETCIBoot obtains multiple estimates of an object X  X  truth, using bootstrapping techniques. Each estimate is obtained by calculating the weighted averaging or voting on a new set of sources which are bootstrapped from available sources. A statistic T that involves the truths is constructed. Its distribution F is usu-ally unknown a priori . Based on these multiple estimates obtained via bootstrapping, we derive an estimator b T of T and further approximate F by b F (i.e., the distribution of The confidence intervals of the truths are naturally implied in the distribution of b T (i.e., b F ). Theoretically, we prove that b T is asymptotically consistent to T in distribution, and the end points of the confidence intervals converge to the true ones at O p ( n  X  3 2 ), where n is the number of claims.
Besides providing confidence intervals, ETCIBoot is also able to provide more accurate and robust truth estimates if we use the average of the multiple estimates as the point esti-mator. Existing truth discovery methods typically compute weighted mean in the truth computation step, and thus the truth estimates can be quite sensitive to some outlying claim-s. In contrast, ETCIBoot adopts bootstrapping procedure which improves the robustness of the estimation. The truth estimates are obtained by computing the mean of bootstrap samples. These samples capture the distribution of claims in which the outlying claims X  effect can be greatly reduced.
We conduct experiments on both simulated and real-world datasets. Experimental results show that the proposed ET-CIBoot can effectively construct confidence intervals for each objects and achieve better truth estimates compared with the state-of-the-art truth discovery methods.

To sum up, the paper makes the following contributions:
We first introduce terminologies and notations in this sec-tion. Then, the problem is formally defined.

Definition 1. An object is an item of interest. Its true information is de ned as a truth.

Definition 2. The reliability of a source measures the quality of its information. A source weight is proportional to its reliability, i.e., the higher the quality of a source's in-formation, the higher its reliability, and the higher its weight. Assume that there are S := { s } S 1 sources, providing claims on objects N := { n } N 1 , where an object may receive claims from only a subset of S . The truths of objects N are de-noted as { x  X  n } n  X  X  , which are unknown a priori . For the n -th object, S n represents the set of sources which provide claims for it. The multi-source data for the n -th object is denoted as X n := { x s n } s  X  X  n , where x s n represents the claim provided by the s -th source for the object n . The whole data collection on objects N is further denoted as X :=  X  N n =1
For the s -th source, we assume the difference  X  s between its claims and truths follows a normal distribution with mean 0 commonly used in existing truth discovery works [11,12,22].  X  captures the error of source s . As a small  X  s means that the claims are close to the truths,  X  2 s measures the quality of the claims provided by the s -th source. We further denote the weight of source s as  X  s . Definition 2 implies that the larger  X  2 s , the smaller  X  s .

Truth Discovery Task. Truth discovery task is formally defined as follows: Given the multi-source data X , the goal of a truth discovery approach is to obtain estimates  X  x n are as close to x  X  n as possible (  X  n  X  X  ). Besides, for any  X  (0 , 1), we can also provide an  X  -level two-sided confidence interval for each object.
 We summarize the notations in Table 1. No tation Definition
In this section, we first review some preliminaries about truth discovery and confidence interval in Subsection 3.1. We then introduce two main components of ETCIBoot : a novel strategy for data aggregation ( ETBoot ) and a method for confidence interval construction ( CIC ) in Subsections 3.2 and 3.3, respectively. The proposed ETCIBoot is further summarized in Subsection 3.4. Finally, we present the theo-retical analysis of the confidence interval estimates obtained by ETCIBoot in Subsection 3.5. The goal of a truth discovery task is to identify objects X  truth-s (i.e., true information) from conflicting multi-source data. Many truth discovery methods have been proposed to esti-mate truths and weights iteratively. Details can be found in Section 5. We briefly introduce two iterative steps as follows.
Weight Update. Source weights play important roles in truth discovery. The underlying principle is that: If a source more often provides reliable information, it has a larger weight, and consequently this source contributes more in the truth estimation step discussed below. Based on this prin-ciple, various weight update strategies have been proposed. In this paper, we adopt the weight estimation introduced in [11]. Specifically, a source weight is inversely proportional to its total difference from the estimated truth, namely, where  X  2 ( with |N s | degree. It is used to capture the effect of the number of claims so that small sources get their weights reduced.

Truth Estimation. A commonly used strategy is weighted averaging for continuous data or weighted voting for categor-ical data, namely,  X  x are obtained at the Weight Update step; the truth estimated at this step will be used to update weights based on (1). Providing proper initializations, Weight Update and Truth Estimation are iteratively executed until the convergence condition is satisfied.
 Assume that an experiment has a sample set X = { x 1 ,  X  X  X  , x n } from F ( x ), where F is an accumulative den-sity function (c.d.f.) with a parameter  X  . An  X  -level confi-dence interval for the parameter  X  is defined as follows:
Definition 3. For any  X   X  (0 , 1) , (  X  X ;L ,  X  X ;R ) is called an  X  -level two-sided con dence interval of a parameter  X  if it satis es the following condition: The immediately preceding probability statement (3) can be read: Prior to the repeated independent trails of the random experiment,  X  is the probability that the random interval (  X  X ;L ,  X  X ;R ) includes the unknown parameter  X  .
Given the distribution of the experiment sample set X , the exact end points of a confidence interval is defined as:
Definition 4. The exact end points of an  X  -level two-sided con dence interval of  X  with a known c.d.f. F are: where F  X  1 (  X  ) is the inverse function of c.d.f. F , V the variance of  X  , and n is the number of observed samples.
However, (4) is always unknown a prior because F is un-known. The major task in this paper is to construct a confi-dence interval estimate for each truth.
In this subsection, we introduce a novel bootstrapping-based strategy for the truth discovery task. We term this strategy as E stimating T ruth via Boot strapping ( ETBoot ). All existing truth discovery methods apply weighted aver-aging or voting using all sources X  information. In contrast, ETBoot first bootstraps multiple sets of sources and then on each set of the bootstrapped sources it obtains a truth estimate based on (2). The final truth estimator is defined as the mean of these estimates. Due to the properties of bootstrapping techniques which are nicely integrated into the truth discovery procedure, ETBoot is more robust to the outlying claims and then achieves a better estimate of the truth. Moreover, as shown in Subsection 3.3, ETBoot is able to construct an  X  -level two-sided confidence interval of the estimated truth for any  X   X  (0 , 1).

The detailed procedure of ETBoot is as follows: for the n -th object, it obtains B estimates of its truth, i.e., { where  X  x b n is obtained by the following two-step procedure: The final estimator ( X  x Boot n ) 1 for the n -th object X  X  truth is further defined as:
W e use  X  Boot to represent the estimator obtained by Boot-strapping throughout the paper. Co mpared with existing truth discovery methods which use (2), the proposed ETBoot combines results from multiple bootstrap samples instead of using all the sources at once. This enables ETBoot to obtain more robust estimates and confidence interval estimates as explained in Subsection 3.3.
The pseudo code of ETBoot for the n -th object is summa-rized in Algorithm 1.
 A lgorithm 1 ETBoot
In put: S n , X n , {  X  s } s  X  X  n , and B 1: for the b -th iteration ( b = 1 ,  X  X  X  , B ) do 2: Bootstrap S b n from S n ; 3: Extract X b n from X n ; 4: Calculate  X  x b n according to (2); 5: end for 6: Calculate  X  x Boot n according to (5);
Output:  X  x Boot n .
In this subsection, we introduce the procedure of con-structing an  X  -level two-sided confidence interval of an objec-t X  X  truth. We illustrate it for the n -th object. The procedure is similar for other objects.

We denote the estimator we are interested in as  X   X  ( X n responding to the dataset X n = { x s n } s  X  X  n . In our scenario,  X   X  ( X n ) denotes the truth estimate. For simplicity, we ignore the subscript  X  n for X n . In a truth discovery task, the truth estimate is calculated as  X   X  ( X ) =
E (  X   X  ( X )) = x  X  The corresponding estimate of V ar(  X   X  ( X )) is defined as d V ar(  X   X  ( X )) = an d  X  x Boot n is obtained by ETBoot . To obtain a confidence interval of the truth x  X  n , we first construct a statistic T which is related to x  X  n , and then estimate the accumulated density function of T  X  F ( t ). In our scenario, T is defined as follows: which measures the error between  X   X  ( X ) and x  X  n . The confi-dence interval of x  X  n is available once the distribution of T is determined. More precisely, let T ( ) indicate the (100  X  percentile of T , i.e.,  X  =
P ( Moreover, an  X  -level two-sided confidence interval of x  X  naturally implied in (8), that is, ( Thus, the width of the confidence interval is proportional to  X  |S n | . It implies that if an object is claimed by more sources then the width of its truth X  X  confidence level is smaller, and vice versa. Especially, when the long-tail multi-source data is involved, this phenomenon is clearer.

However, as the T -percentile is usually unknown a priori , estimation of T ( ) is required. One commonly used strategy is bootstrap sampling [1, 6, 8, 10, 14]. Note that at the b -th iteration of ETBoot (Algorithm 1), we have bootstrapped X n . Based on X b n , we are able to calculate both d V ar( X b n ), yielding an estimator  X  T b for the statistic T , that is, Moreover, the estimate of T ( ) is defined as follows: (12) provides estimates of (9) and (10). Thus, the estimate of an  X  -level two-sided confidence interval is defined as follows: ( We summarize the procedure of constructing confidence in-tervals as CIC , i.e., C onfidence I nterval C onstruction. Its pseudo is presented in Algorithm 2 for the n -th object. Al gorithm 2 CIC 1: Calculate  X   X  2 s for s  X  X  n ; 2: for the iteration b ( b = 1 ,  X  X  X  , B ) do 3: Calculate d V ar(  X   X  ( X b n )) and b T b according to (11); 4: end for 5: Choose b T (1  X   X / 2) and b T (  X / 2) according to (12);
Output: Endpoints calculated based on (13) and (14).
So far, we introduce the update for source weights (i.e., (1)), a new truth estimation strategy, ETBoot , and the con-struction of confidence intervals for truths via CIC . Com-bining them together, we propose a novel truth discovery approach, E stimating T ruth and C onfidence I nterval via Boot strapping ( ETCIBoot ), to automatically construct con-fidence intervals as well as identify objects X  truths. The main component of the proposed ETCIBoot consists of the follow-ing three steps: Th e above two steps are executed iteratively until no truth estimates change anymore. The pseudo code of the proposed ETCIBoot algorithm is shown in Algorithm 3.
 A lgorithm 3 ETCIBoot
In put: the whole data collection X , confidence level  X  , and 1: Initialize truths x  X  ; 0 1 ,  X  X  X  , x  X  ; 0 N as average; 2: while the convergence condition is not satisfied do 3: Compute  X  s for each source s according to (1); 4: for each object n ( n = 1 ,  X  X  X  , N ) do 5: Conduct ETBoot to obtain  X  x Boot n ; 6: Calculate the confidence interval CI n (  X  ) via CIC ; 7: end for 8: end while
Output: {  X  x Boot n } N 1 and confidence interval { CI n
In this subsection, we present the theoretical analysis on the confidence interval estimates, i.e., (13) and (14), ob-tained via ETCIBoot . We first prove that b T converges to T in distribution and present it in Proposition 1.
Proposition 1. Assume that x s n  X  N ( x  X  n ,  X  2 s ) , for any s  X  X  n . Let T and T  X  be de ned as (7) and (11) , respectively. Then, we have that where P  X  is the probability calculated based on the bootstrap-ping sample distribution, |S n | is the Cardinality of S n any real number, and a.s. means `almost surely'.
 Proof. See Appendix A for a detailed proof.
 Pro position 1 is a straightforward result from Theorem 1 in [14], where the author provides sufficient conditions to guarantee the convergence of the bootstrapping samples. Thus, the proof of Proposition 1 is to testify whether the ETCIBoot satisfies these sufficient conditions, as shown in Appendix A. Proposition 1 shows that the bootstrapping es-timator b T converges to T in distribution. It enables us to use the bootstrapping distribution to approximate the unknown distribution F for confidence interval construction.
Next, in Proposition 2, we show that the upper end point of an  X  -level one-sided confidence interval obtained via ET-CIBoot is close to that from the theoretical distribution.
Proposition 2. Given T  X  F ( x ) , dataset X , we have that where P  X  (  X  ( X )  X   X   X  b T ; X (  X  )) =  X  , P (  X  ( X ) n = | X | , and O p means the order holds in probability. Proof. See Appendix B for a detailed proof.
 Pro position 2 shows that the endpoint of an  X  -level one-sided confidence interval obtained by bootstrapping b T is close to that obtained by T , provided that there are enough samples. As any  X  -level two-sided confidence interval can be obtained by two one-sided confidence intervals, the results ((16)) also hold for (13) and (14). In truth discovery tasks, ETCIBoot is able to provide more accurate confidence intervals for the objects X  truths, if they receive more claims. This result is more obvious especially on long-tail data.
In this section, we evaluate the proposed ETCIBoot method on both simulated and real-world datasets. We first introduce the experimental setup in Subsection 4.1. Then, we test the ETCIBoot and baselines on simulated datasets generated in different scenarios and real-world datasets in Subsections 4.2 and 4.3, respectively. Experimental results show that: (1) ETCIBoot outperforms the state-of-the-art truth discovery methods in most cases, and (2) ETCIBoot can provide accurate confidence interval estimates.
In this part, we introduce the baseline methods and discuss the measurements for evaluation.

Baseline Methods. For all truth discovery methods, we conduct them on the same input data in an unsupervised manner. Although ground truths are available, we only use them for evaluation. For different data types, different base-lines are adopted, including both the naive conflict resolution methods and the state-of-the-art truth discovery methods. More precisely, for continuous data we use Median, Mean, CATD [11], CRH [12] and GTM [22]. Baselines used for categorical data include: Voting, Accusim [5], 3-estimate [7], CRH [12], Investment [18], CATD [11], ZenCrowd [3], Daw-id&amp;Skene [2], and TruthFinder [21]. Details of baselines are discussed in the related work (Section 5).

Measurements. As the experiments involve both con-tinuous and categorical data, we introduce different measure-ments. For data of continuous type, we adopt both the mean of absolute error ( MAE ) and the root of mean square error ( RMSE ); Error Rate is used for date of categorical type. The details of the measurements are: Note That: the smaller the measurement value, the closer to ground truths the methods' output. Therefore, for all mea-surements, the smaller the value, the better the method.
In this subsection, we test the proposed ETCIBoot on sev-eral simulated datasets, which capture different scenarios in-volving various distributions of source reliability. We first in-troduce the procedure of generating simulated datasets, and then test the effectiveness of ETCIBoot in identifying truths comparing with baselines on these datasets. Last but not least, we compare the confidence intervals obtained by ET-CIBoot with that by theoretical distribution and show the advantage of bootstrapping. ) (10  X  3 ) (10  X  1 ) (10  X  3 ) (10  X  1 )
D ata Generation. The procedure of generating simulat-ed data is shown as follows: (i) We first generate a vector of the number of claims C , (ii) For each c i  X  C , there are o i = e 7  X  c  X  1 : 5 i (iii) For each source, we randomly generate its reliabili-
Experiments. In the following experiments, we simulate different scenarios via different source reliability distribution-s F . We set C = 70 : 100; thus, there are 31 objects and 100 sources. Note that the number of objects is not large. This is used to better display the experimental results on the confidence interval estimates. To reduce the randomness, we repeat the experiment 100 times and report the average re-sults. As the simulated data is continuous, MAE and RMSE are used for evaluation. We simulate 4 scenarios and the de-tail of each scenario is discussed as follows. Note that  X  represents the source reliability degree. The larger value the  X  , the lower reliability degree the source.

Scenario 1 :  X  2 s  X  Uniform(0 , 1). In this scenario, all source reliability degrees are uniformly distributed in (0 , 5).
Scenario 2 :  X  2 s  X  Gamma(1 , 3). In this scenario, most of the sources are reliable with high reliability degrees. Howev-er, there are a few unreliable sources with very small relia-bility degrees.

Scenario 3 :  X  2 s  X  FoldedNormal(1 , 2). As Folded Normal is a long-tail distribution, in this scenarios, it generates a few unreliable sources. Compared with Scenarios 1 and 2, the reliable sources have higher reliability degrees.

Scenario 4 :  X  2 s  X  Beta(1 , 1 2 ). In this scenario, source re-liability degrees are within 0  X  1. Compared with other scenarios, there are much more reliable sources.

We show the histograms of the source variances in Fig-ure 2, which implies that the simulated data covers various scenarios with varying source reliability distributions. We report the results in terms of MAE and RMSE in Table 2.
Comparison with Baselines. Table 2 shows that the proposed ETCIBoot outperforms all baselines in all scenar-ios in terms of both MAE and RMSE . When estimating the truth for each object n , ETCIBoot obtains multiple truth estimates which are calculated according to (2) based on the bootstrapped claims. Then, the final truth estimator is de-fined as the average of these estimates. Experimentally, we generate 10  X  X S n | bootstrapping samples. Due to the prop-erties of bootstrapping, ETCIBoot is robust to the outlying claims provided by some sources. However, as existing truth discovery methods typically compute weighted mean to ob-tain one single point estimate, they are more sensitive to the outlying claims. So, the ETCIBoot performs better than baselines as confirmed in the experimental results. Moreover, as there are more reliable sources in Scenarios 3 and 4, the results are better compared with those in Scenarios 1 and 2. It confirms the underlying intuition of truth discovery: the more the reliable sources, the better the results.
Con dence Interval Comparison. For confidence in-terval comparison, we compare the results of ETCIBoot with that obtained by theoretical distribution, i.e., normal distri-bution. Note that  X  x n  X  Normal( x  X  n , (2)). As the true  X  2 s is known for each source, we know the theoretical distribution for  X  x n , based on which we can further obtain the 95%-level confidence interval. We term the confidence interval obtained in this way as CI-Normal . The confidence interval (i.e., (13) and (14)) for the truths X  estimators, which is obtained by the ETCIBoot using the bootstrapping technique, is referred to as CI-ETCIBoot .
We report the results in Scenarios 1  X  4 in Figures 3  X  6, respectively. From Figures 3  X  6, we can draw the fol-lowing conclusions: (1) The CI-ETCIBoot is much smaller than CI-Normal in all simulated scenarios. Note that the smaller the confidence interval, the more confident the es-timator. For example, in Scenario 1 the shaded area (i.e., the area between the lower and upper bound curves) of CI-Normal in Figure 3(a) is larger than that of CI -ETCIBoot in Figure 3(b). Similar conclusions can be drawn in other scenarios. Thus, the experimental results show the power of the ETCIBoot on constructing effective confidence inter-vals. (2) As most sources are reliable in Scenarios 2  X  4, comparing with Scenario 1, the width of CI-ETCIBoot or CI-Normal in other scenarios is smaller, which indicates the higher overall confidence in these scenarios.

Next we conduct experiments to illustrate the relationship between the width of confidence interval and the number of claims on long-tail data. We follow the same procedure to generate the simulated data, except that we choose the num-ber of claims as 2 to 30. If there is only one claim, it is impossible to construct the confidence interval. We present the width of CI-Normal and CI-ETCIBoot in all scenarios in Figures 7(a) and 7(b), respectively. Meanwhile, we also fit them into a polynomial function of N ( N  X  1 2 ), respective-ly. The red line with square marker represents the fitting line, averaging over all scenarios. From Figure 7, we can see that the width of the 95% confidence interval, obtained via either normal distribution or ETCIBoot , decreases with re-spect to the number of claims at an error rate N  X  1 2 , where N is the number of claims. It confirms the theoretical anal-ysis that if an object receives more claims then its estimator is more accurate. Moreover, the width of CI-ETCIBoot is much smaller than that of CI-Normal , which demonstrates that ETCIBoot is able to provide a more confident estimator. This advantage is achieved by incorporating bootstrapping techniques into truth discovery procedure in ETCIBoot .
In this subsection, we present the experimental results on two continuous datasets and two categorical datasets. Exper-iments show that the proposed ETCIBoot is able to obtain more accurate estimates of truths comparing with baselines. We first introduce the description of the datasets and then report the results.
 Dataset Description. The following datasets of continu-ous data type are used in experiments: Figure 7: Simulated data in all scenarios: Con dence Interval width w.r.t. the number of claims ( N )
R esults Analysis. We present the results of ETCIBoot and baselines with respect to MAE and RMSE on the con-tinuous datasets in Table 3. The experimental results show that the proposed ETCIBoot can achieve the best perfor-mance on both datasets.
 Fig ure 8: Indoor Floorplan dataset: CI-ETCIBoot
On Indoor Floorplan dataset, as the number of objects is small, we also present the confidence intervals obtained by ETCIBoot for each object in Figure 8. The figure shows that in most cases the confidence intervals provided by ETCIBoot contains the corresponding objects X  truths. However, there are some confidence intervals which do not contain truth-s. A possible reason is: These objects are claimed by a few sources and the information provided by these sources is far away from the truth. Take the 9-th object for example. There are only 4 sources which provide claims, among which the smallest value is 14 . 3 that is still very larger than the ground truth 10 . 8. As a result, it is impossible to correctly identify these objects X  truths for any truth discovery method. Therefore, the confidence interval estimates obtained by ET-CIBoot do not contain the truths for these objects.
On Flight Status dataset, the data on each day is treated as a single data collection. As there are many flights only claimed by a few sources, the performance of baselines is not satisfactory. We conduct a case study on Day 1 dataset. We count the statistics on how many claims of an object receives to show the long-tail phenomenon: (1) there are about 61 . 1% of flights which only receives claims from at most 5 out of 38 sources; (2) only 2 . 3% of flights have received claims from more than 25 sources. Similar phenomenon can be found on other days X  data. Consequently, we can see that the proposed ETCIBoot outperforms all baselines, as shown in Figure 9. We do not present the confidence interval for the flights due to the page limit and the large number of flights. Fig ure 9: Comparison on Flight data over 30 days Dataset Description. We introduce the details of two categorical datasets and their tasks as follows:
Results Analysis. For categorical data, we first encode the claims into probability vectors and then apply the meth-ods proposed for continuous data, such as ETCIBoot , CATD, etc. The detailed procedure is: For a question with 4 possi-ble choices, the first choice is encoded into a 4-element vector (1 , 0 , 0 , 0). In Tables 4 and 5, we present the experimental results of the proposed ETCIBoot as well as baselines on the SFV and Game datasets, respectively.

On SFV dataset, there are only 18 sources, so we have a limited number of sources to bootstrap at each iteration of ETCIBoot . Thus, the result of the proposed ETCIBoot ( . 0945) is not the best, but still comparable with the two best methods: AccuSim ( . 0701) and TruthFinder ( . 0793).
On Game dataset, the number of sources (37 , 029) is suf-ficient for bootstrapping. Although CATD performs best among all baselines, the proposed ETCIBoot achieves even better performance compared with CATD. Especially, on the Levels 8, 9, and 10, the proposed ETCIBoot improves the results by 33 . 28%, 50 . 00% and 33 . 30%, respectively, when h ttp://www.nist.gov/tac/2011/ Met hod Error Rate co mpared with the best baseline CATD. As ETCIBoot in-tegrates bootstrapping techniques into the truth discovery procedure, it is more robust to the wrong claims compared with baselines. Thus, ETCIBoot can obtain better results as the experiments show. Note that there are 81 objects on which no sources provide correct answers. Therefore, the lowest error rate for any truth discovery method is . 0380. ETCIBoot can achieve error rate at . 0385, which shows its effectiveness in identifying truths.
Truth discovery has become an eye-catching term recent-ly and many truth discovery methods have been proposed to identify true information (i.e., truths) from the conflict-ing multi-source data. The advantage of truth discovery over the naive aggregation methods such as averaging or voting is that it can capture the variance in sources X  reliability degrees. Therefore, truth discovery methods can estimate source reli-ability automatically from the data, which is integrated into truth computation as source weight. Consequently, the more reliable sources contribute more in the final aggregation step.
A large variety of truth discovery methods have been designed to jointly estimate truths and source reliability. In [12], the authors formulate the truth discovery task into an optimization framework (CRH). They propose to minimize the overall weighted distance between claims from sources and aggregated results. CATD [11] is a statistical method that has been proposed to deal with long-tail phenomenon in truth discovery tasks, where confidence interval is incorpo-rated in source weight estimation. However, CATD does not consider the long-tail phenomenon on objects, which can be solved by ETCIBoot . In [22], the authors propose a proba-bilistic model based truth discovery framework (GTM). Both AccuSim [5] and TruthFinder [21] adopt Bayesian analysis to estimate source reliability and update truths iteratively. In [18], the authors take the prior knowledge on truth and background information into consideration and propose a truth discovery method Investment. In [7], 3-Estimate con-siders the difficulty of getting the truth for each object when calculating source weights as well as complement vote. Daw-id&amp;Skene [2] and ZenCrowd [3] propose to use Expectation-Maximization technique to update source weights and truths simultaneously, based on a confusion matrix.

However, most existing truth discovery methods have the following limitations: (1) As most of them apply weighted averaging, they are sensitive to outlying claims, and (2) they focus on point estimation of the truth, where important con-fidence information is missing. To the best of our knowledge, this is the first paper to illustrate the importance of confi-dence interval estimation in truth discovery , and proposes an effective method ( ETCIBoot ) to address it. By integrating bootstrapping into truth discovery, ETCIBoot is robust com-pared with the state-of-the-art truth discovery methods.
In this paper, we first illustrate the importance of confi-dence interval estimation in truth discovery, which has never been discussed in existing work. To address the problem, we propose a novel truth discovery method ( ETCIBoot ) to con-struct confidence interval estimates as well as identify truths. The bootstrapping techniques are nicely integrated into the truth discovery procedure in ETCIBoot . Due to the proper-ties of bootstrapping, the estimators obtained by ETCIBoot are more accurate and robust compared with the state-of-the-art truth discovery approaches. Theoretically, we prove that the confidence interval obtained by ETCIBoot is asymp-totically consistent. Experimentally, we demonstrate that ETCIBoot is not only effective in constructing confidence intervals but also able to obtain better truth estimates. This work was sponsored in part by US National Science Foundation under grant IIS-1319973, IIS-1553411 and CNS-1566374. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agency. For the object n , we have S n with |S n | = n . Denote the dis-tribution of a sample x i n as G i (  X  ). Based on the assumption, x Proposition 1 we only need to prove the following conditions: where  X  i =  X  x  X  , and  X   X  = 1 n  X  . Next, we prove the sufficient conditions point by point. Proof of (a). As introduced in Section 2, x s  X  Normal( x  X  ,  X  2 s ), where  X  2 s &gt; 0. Let H be the standard nor-mal distribution, i.e., Normal(0 , 1). As any continuous distri-bution is non-lattice, H is a non-lattice distribution. More-over, let k n = n and G i = H ( x  X  i Proof of (b). For the normal distribution, we have that where  X (  X  ) is the gamma function, i.e.,  X ( n +1) = n  X ( n ). Let  X  = 1, we have that E
Proof of (c). (i)  X  s ,  X  2 s &gt; 0 and v 2 n = 1 n  X  i ,  X  i =  X   X  n .

Proof of (d). As shown in the proof of (a), H is a normal distribution which is continuous. Let  X  = 1 and combine with (17), yielding that E As shown above, all the conditions are satisfied. Thus,
Proofs of (b) and (c) also show that  X  K 3 ;n  X   X   X  3 ;n 1 has been proven.
 Note that P [  X  ( X )  X   X   X  ( X )  X  F 1 (1  X  )[ d V ar( ^  X . as P ( T  X  t ) =  X  . So,  X   X  T; X (  X  ) =  X   X  ( X )  X  F from [6], the proof of Proposition 2 is straightforward.
