 University of Copenhagen Nuance Communications, Inc.

This article describes an approach to Lexical-Functional Grammar (LFG) generation that is
LFG grammar and an arbitrary acyclic input f-structure a context-free grammar describing exactly the set of strings that the given LFG grammar associates with that f-structure. The individual sentences are then available through a standard context-free generator operating on that grammar. The context-free grammar is constructed by specializing the context-free backbone of the LFG grammar for the given f-structure and serves as a compact representation of all generation results that the LFG grammar assigns to the input. This approach extends to other grammatical formalisms with explicit context-free backbones, such as PATR, and also provides a general mathematical framework for understanding and improving the operation of a family of chart-based generation algorithms. 1. Introduction
Algorithms providing compact representations of alternative syntactic analyses have been the state-of-the-art in parsing for many years. For context-free grammars, for example, the well-known chart parsing algorithms have been used for more than four decades. These assign to a sentence not just one possible analysis but a chart that compactly represents all possible syntactic analyses. Algorithms have also been developed that extend packing to the functional specifications of unification grammars by producing compact representations of feature-structure ambiguities as well. One that is pertinent to (but not restricted to) Lexical-Functional Grammar (LFG) is the con-texted constraint satisfaction method developed by Maxwell and Kaplan (1991). These algorithms lead to better average time performance because they carefully manage the ambiguities that are rampant in natural language. They work by dividing the parsing problem into two phases, a recognition or satisfiability phase that creates the compact representation and determines whether there is at least one parse, and an enumeration phase in which the alternative parses are produced one by one. Parsing performance is typically identified with the complexity of the first phase (e.g., the cubic bound for context-free parsing), because the collection of all parses can be delivered to a client ap-plication merely by presenting the compact representation. A client may be able to select a limited number of particularly desirable parses, perhaps the smallest or the most prob-able, without doing a full enumeration (Johnson and Riezler 2002; Kaplan et al. 2004). free chart parsing. 1 He observes that the recognition problem consists of finding the intersection of the language of the grammar with the input string, and then testing to see whether that intersection is empty. Many language classes are closed under intersection with a regular set, and the result of the intersection of a language L ( G ) with a regular language  X  is describable as a specialization G  X  of G that assigns to all and only the strings in  X  effectively the same parse trees as G would assign. Lang argues that a chart for an input string s (a trivial regular language) and a context-free grammar G can be regarded as a specialization G s of G that derives either the empty language (if s does not belong to L ( G )) or a language consisting of just that input. In this view a parsing chart/grammar is a representation that makes it possible to enumerate all the derivation trees of the string, guaranteeing that each tree can be produced in a backtrack-free way in time proportional to its size. This guarantee holds even for an infinitely ambiguous string: It would take forever to enumerate all valid derivations, but any particular one can be read out in linear time. The procedure for tree enumeration follows directly from the standard context-free generation algorithm applied to the grammar G malisms can also be viewed from this perspective. Several algorithms have been pro-posed for generation that avoid redundant recomputation by storing intermediate processing results in a chart-like auxiliary data structure (e.g., Shieber 1988; Kay 1996; Shemtov 1997; Neumann 1998; Carroll et al. 1999; Moore 2002; Carroll and Oepen 2005;
Cahill and van Genabith 2006; White 2006; de Kok and van Noord 2010). Most of them can be construed as having a first phase that provides a compact representation for alternative results, in this case for the strings that the grammar provides for a given functional or semantic input. The individual generated strings are then produced by an enumeration procedure operating on this compact representation.
 rules of a specialized context-free grammar, just as in Lang X  X  (1994) characterization of parsing. We present a generation algorithm that specializes the context-free backbone of a given LFG grammar to a grammar that describes exactly the strings that the LFG gram-mar relates to a given acyclic f-structure. Derivations of the resulting grammar simulate all and only those derivations of the LFG grammar whose derived strings are assigned to that input. 2 Thus the generated string set is a context-free language compactly repre-sented by the specialized grammar, and the individual members of that language can be enumerated, just as for parsing, by using standard context-free generation algorithms. generation algorithms, producing all and only correct outputs for larger combinations of grammars and inputs. It extends to unification grammars with explicit context-free backbones, such as PATR (Shieber et al. 1983), and also to formalisms that permit a context-free skeleton to be extracted from richer specifications. But it does not extend 868 to cyclic input structures because, as we will show by example, an LFG grammar structures are normally assumed to be the only f-structures that are motivated for linguistic analysis (Kaplan and Bresnan 1982), this restriction does not seem to limit the applicability of our algorithm for natural language generation.
 more explicit. Along with many other description-based grammar formalisms, an LFG grammar G assigns to every string s in its language at least one f-structure. This situation can be characterized in terms of a derivation relation  X  G (1)  X  G ( s , F )iff G assigns to the string s the f-structure F
In the LFG approach a sentence s and its f-structure F are not directly related. Their relation is mediated by a valid c-structure for s (Kaplan 1995). The arrangement of the three components of an LFG representation is illustrated in Figure 1. This representation is derivable by a grammar that includes the annotated (nonterminal) rules in (2a X  X ) and lexical expansions in (2d X  X ). Annotated lexical c-structure rules are just notational variants of traditional LFG lexical entries. (2) a. S  X  NP VP
In accordance with the basic architecture of LFG, an LFG grammar provides a set of licensing conditions that determine grammatical representations by descriptive, model-based rather than procedural methods. The well-formedness of the representation in Figure 1 with respect to the grammar in (2) is thus characterized as follows. node a grammar rule that licenses or justifies the local mother X  X aughters configuration constituted by the node and its immediate daughters. If we assume that the c-structure as depicted in Figure 2, then the rule-mapping  X  that justifies the c-structure is given by (3). mapping is constructed by instantiating the annotations of all justifying rules in the following way. For each rule justifying a local mother X  X aughters configuration, all occurrences of the  X  symbol (called a metavariable ) in the functional annotations of the daughters are replaced by the mother node, and for each of the daughter cat-egories, all occurrences of the  X  metavariable in its annotations are replaced by the corresponding daughter node. 3 Thus, the  X  of the annotations on a daughter category of a rule and the  X  of the annotations of the rule that further expands that category are always instantiated with the same node. The complete f-description is the union of the instantiated descriptions of all the justifying rules. The f-description obtained from the c-structure in Figure 1 and the rules of the justifying mapping in (3) is given in (4). (4)
The f-structure in Figure 1 is associated with the given c-structure because it satisfies the f-description in (4), and furthermore, it is the unique minimal solution for this description. In general, LFG requires the f-description of a grammatical sentence to be satisfiable and thus to have at least one model. Each such satisfying model consists of a universe and an interpretation function that assigns unary (partial) functions to the attributes ( SUBJ , NUM , SPEC , etc.) and elements of the universe to the atomic feature values ( SG , INDEF , etc.), as well as to the nodes in the description. Among the models satisfying a given f-description there is an (up to isomorphism unique) minimal model, one that is not properly subsumed by other satisfying models. represents the f-description X  X  minimal solution, the one from which the f-structure for the sentence is obtained. Conventional attribute X  X alue matrices where the nodes (or node numbers) are attached to the left brackets are LFG-typical representations of 870 exactly such minimal models. The attribute X  X alue matrix representation of the minimal model of the f-description (4) is given in (5). (5) root removing the node labels that record the relation of the f-structure to the c-structure.
From a formal point of view, an f-structure is obtained from the minimal model of an f-description by restricting its interpretation function to the attributes and atomic fea-ture values of the grammar, thus disregarding the nodes and their interpretation. f-structure F the set of strings that are related to it by the grammar: (6) Gen G ( F ) = { s |  X  G ( s , F ) }
The algorithm presented in this article accomplishes the generation task by pro-ducing a context-free grammar for Gen G ( F ), for a given LFG grammar G and any acyclic input f-structure F .
 for G , since a parser produces for any given terminal string s the set of f-structures that are assigned to it by G : (7) Par G ( s ) = { F |  X  G ( s , F ) }
For parsing, the Kaplan and Bresnan (1982) proscription of nonbranching dominance condition does not ensure the finiteness of the set of strings Gen an f-structure F . This is illustrated by the simple grammar in (8): (8) S  X  aSb
This generates for the input (9) the infinite context-free language { a n b n | 1  X  n } .
 that a natural language grammar relates to an f-structure is infinite. As a minimum, there should be some relationship that bounds the size of the c-structure of a sentence by the size of the f-structures associated with it. Such a structural relationship would then force the related sentences to form a finite set. Studies to determine intuitively plausible restrictions are rather scarce, however, and proposals for such restrictions are not yet generally accepted. It is thus still an open question whether grammars of actual natural languages satisfy the particular resource-boundedness restrictions on which termination of some existing chart-based generators depends.
 still be very large. Experiments with a broad-coverage German LFG grammar (Dipper 2003; Rohrer and Forst 2006) have shown that, because of the scrambling that German allows, a given f-structure might be related to a huge set of long sentences. consequences at least for those approaches that assume the output of generation to be a word lattice (Langkilde and Knight 1998) or a finite-state machine representing the compactly only if they are characterized by independent sets of alternative substrings.
Scrambling languages, however, have alternative substrings that reappear in different positions with complex cooccurrence dependencies and therefore cannot be shared in a lattice representation (see Langkilde [2000] for discussion). Our context-free grammars (and also Langkilde X  X  [2000] and Knight and Langkilde X  X  [2000] forest representations) offer a much more compact encoding under these circumstances, and their structure and formal properties are as well understood as lattices and finite-state machines. for optimality-theoretic generation (Kuhn 2001, 2002, 2003). An optimality-theoretic
LFG system consists of two components: a universal LFG grammar and a language-specifically ordered set of violable constraints (Bresnan 2000). The universal LFG gram-mar is used to produce the candidate space of possible analyses (consisting of the c-structure/f-structure pairs that are derivable by the grammar). The optimal and thus grammatical analyses are those candidates that violate the fewest constraints. A tech-nical problem comes from the fact that the universal grammar by design may assign an infinite number of c-structures and string realizations to a given f-structure, and the optimal outputs can be identified only by evaluating all of these against the collection of constraints. Our context-free characterization provides a finite evaluation procedure even for an infinite candidate space. By virtue of the pumping lemma for context-free languages (Bar-Hillel, Perles, and Shamir 1961; see also Hopcroft and Ullman 1979) we can enumerate the c-structure trees assigned to an input f-structure one by one in order of increasing depth. Because the number of constraint violations increases beyond a certain number of recursive category expansions, the optimal results from the infinite space can be chosen after examining only a finite number of relatively small structures (see Kuhn [2003] for details).
 a general framework encompassing all forms of chart generation in a single formalism.
This is because existing chart-based generators can be understood as concrete but some-how restricted algorithm/datastructure implementations of our context-free grammar construction. These restrictions may lead them to produce incorrect outputs in some situations. Because we show the correctness of the output grammar for unrestricted 872
LFG grammars, our framework allows us to examine, compare, and improve on existing chart-based generation techniques.
 fundamental formal objects of LFG theory and the relevant relationships among them.
Section 3 is the technical core of the article. There we present and prove the correctness of the context-free grammar-construction algorithm for LFG grammars with arbitrary equational constraints and acyclic input f-structures. The grammar construction ab-stracts away from specific details of data structure and computational strategy not es-sential to the mathematical argument. Performance and computational strategy are then briefly considered in Section 4, and Section 5 compares our approach to other generation algorithms. In Section 6 we identify a fundamental limitation of our approach, demon-strating that the context-free property does not hold for elementary equational con-the basic context-free construction can be extended beyond simple equations to the additional descriptive devices proposed by Kaplan and Bresnan (1982) and still in common use. This is shown in Section 7. The last section highlights some additional consequences of this approach.

Wedekind (2000). In that paper we outlined a context-free grammar construction for a subclass of LFG grammars with restricted functional annotations and single-rooted input structures. Here we consider a more general class of grammars and inputs that requires a more rigorous mathematical analysis. 2. Preliminaries We start with a formal characterization of LFG grammars with equational statements.
Let V  X  denote the set of all finite strings over V . An LFG grammar G over a set  X  of attribute and value symbols is defined as follows: Definition 1
An LFG grammar G (over attribute X  X alue set  X  )isa4-tuple( N , T ,S, R ) where N is a finite set of nonterminal categories, T is a finite set of terminal symbols, S root category, and R is a finite set of annotated productions of the form with A  X  N and X 1 .. X m  X  ( N  X  T )  X  . (Note that R might contain -productions, al-though these do not appear in most current linguistic descriptions.) Each annotated sions of the form (  X   X  ), (  X   X  ), or v where v is a value of  X  and  X  is a possibly empty sequence of attributes of  X  . When  X  is empty, (  X   X  ), ( respectively. 7 stituting for the  X  and  X  metavariables elements drawn from a collection of terms.
C-structure nodes are included among the terms, but later on we also make use of addi-tional elements. We define a function Inst that assigns to each m-ary rule r , term t ,and term sequence t 1 .. t m the instantiated description that is obtained from the annotations daughters. In the following definition we use the (more compact) linear rule notation
A  X  ( X Definition 2
Let r be an m-ary LFG rule A  X  ( X 1 , D 1 ) .. ( X m , D of a term and a sequence of terms of length m . Then the instantiated description that results from r and  X  is given by occurrences of  X  in D j and substituting t j for all occurrences of informally in the previous section. This is based on context-free derivation trees. Let us assume that root is the root node of any c-structure c ,andthat dts is a function that Context-free derivations are then defined as follows: Definition 3
A labeled tree c and a rule-mapping  X  from the nonterminal nodes of c into the rules of context-free grammar G is a context-free derivation of string s from nonterminal B in
G iff (i) the label (category) of root is B , (ii) the yield is s , (iii) for each nonterminal node n with label A and dts ( n ) = n f-structure from the (up to isomorphism) unique minimal model of the f-description by restricting it to the attribute X  X alue set  X  . This is formalized in the following def-inition by requiring the f-structure to be isomorphic ( of a minimal model M of the derived f-description. The effect of the isomorphism is to abstract away from the particular properties of different f-structure models that have no linguistic significance. Moreover, because we operate on an arbitrary mem-ber of the class of isomorphic structures without regard to any of its accidental or nonsignificant properties, we know that our analysis applies to all members of the class. 874 Definition 4
A labeled tree c and a mapping  X  from the nonterminal nodes of c into R is an LFG deri-vation of string s with functional description FD and f-structure F in LFG grammar G iff (iii) for each nonterminal node n with label A and dts ( n ) = n (iv) FD = (vi) FD a = v if v is an atomic feature value and a is any other constant (vii) FD ( v  X  ) = ( v  X  )if v is an atomic feature value and  X  is a nonempty (viii) M |  X  stant/complex clash conditions that together capture LFG X  X  functional uniqueness condition (the denotations of an atomic feature value and any other distinct atomic feature value or node constant have to be distinct (vi); atomic feature values have no (
U , I ) consisting of a universe U and an interpretation function I . The interpretation function assigns to each constant occurring in the f-description an element of to each attribute a unary partial function on U .
 a given c-structure. Thus, we conceive of these terms as constants and will refer to them on the f-description level sometimes as node constants rather than nodes. Because the instantiating nodes are uniquely determined if we have a mapping  X  licensing a given c-structure, in the following we abbreviate Inst (  X  n ,( n , dts ( n ))) by Inst (  X  restrictions of their minimal models to  X  are isomorphic.
 Definition 5
Let D and D be two descriptions with minimal models M and M . Then D
M |  X   X  = M |  X  .
 From Definition 4 we obtain the derivability relation  X  as follows.
 Definition 6 A terminal string s is derivable with f-structure F in G (  X  of s with F (with some f-description FD )in G . In this context we repeat the definition of the set of strings Gen G relates to a given f-structure F : Definition 7 For any LFG grammar G and any f-structure F gorithm to construct for an arbitrary LFG grammar G and any acyclic f-structure F a particular context-free grammar that provides a formal representation for the language
Gen G ( F ). 3. Constructing the Specialized Grammar for Gen G G G ( F F F ) f-structure F are the unknowns that must be discovered to confirm that a given string a subset of the trees that are generated by the context-free backbone of G .Butthis subset might be infinite, as we have already seen with the input (9) and the grammar in (8), because there is in general no fixed finite upper bound on the length of the strings related to F or the size of their c-structures. Whether or not a given tree is a valid c-structure for F then depends on the properties of the f-description that arises by instantiating with the proper node constants the annotations on the individual rules that license the derivation of that tree. The valid c-structures are just those trees for which F is the f-structure of the resulting f-description.
 upper bound on the number of node constants that may occur in an f-description for
F . However, because the number of f-structure elements to which the node constants actually refer is bounded by the size of F , it must be possible to obtain for any derived f-description FD an equivalent description whose constants are drawn from a fixed finite set. For instance, if we introduce a distinct canonical constant for each element of F , we can create an equivalent description by substituting for each node constant in FD the canonical constant associated with the functional element corresponding to that node. This substitution typically reduces the number of distinct terms needed for instantiation, and its usual effect is to replace several different node constants with a single canonical term. But these replacements will provide an equivalent description because we substitute a given term for two node constants if and only if it logically follows from FD that those two nodes map to the same element of F .Thus,if FD discriminates between two elements of F , so will the description that results from such a reducing substitution.
 for every f-description of F (from every possible c-structure) an equivalent descrip-tion that involves only a finite number of distinct instantiation terms. This is what enables us to simulate all the conditions for correct LFG generation with a finite set of context-free category labels and a finite set of context-free productions, and thus to rely on the finite control of the rule-by-rule category matching process of context-free generation to produce the strings in Gen G ( F ). 876 to enforce all functional discriminations for an f-description associated with a com-plete c-structure, as we have suggested. But unfortunately that set may not be large enough to keep track of all necessary distinctions as an f-description is created in an incremental context-free derivation process. For some f-structures and some grammars it may not follow from the description associated with one portion of a derivation tree that two nodes map to the same functional element, even though that identity does follow when equations in the f-description for the entire tree are taken into account.
 tell whether n 1 and n 2 can map to the same element of the f-structure and therefore whether it is correct to substitute the same canonical constant for both of them. It depends on whether the larger description that incorporates the expansion of the third daughter implies the identity of the n 1 and n 2 structures. The same-constant substitution would preserve equivalence only if the larger description implies that ( n
We must have two distinct constants available until that implication is deduced in the course of the derivation, even if the input f-structure does not contain separate ele-ments for those constants to correspond to.
 derivation proceeds incrementally may be larger than the number of elements in the input f-structure and larger than what is required for an equivalent description for a complete derivation. However, for each acyclic F we show that there is always a finite set of canonical terms that can maintain all necessary functional discriminations as a derivation unfolds. We use this set to construct a reducing substitution that permits generation to be carried out under finite control. In contrast, we observe in Section 6 that the partial descriptions of cyclic structures cannot safely be reduced without an unbounded number of canonical terms.
 [ HV ], we can accomplish the reduction of the f-description space with only two terms, the canonical constant root and a separate canonical constant all nodes that do not occur in an f-description. Let us start with the shortest derivation for the given input. This consists of the c-structure in (10), which is licensed by the
If we pair the licensing rule with its instantiating nodes ( root , n ing to the instantiating nodes a substitution that replaces root by root and both n n 2 by original node-instantiated rule, because the  X  does not occur in the annotations. The reduction for all other derivations of [ HV ] is illustrated in Figure 3. The substitutions of the node constants of the schematically represented derivations by canonical terms are indicated by assigning the canonical term values to the nodes. If we consider the resulting instantiation of the applied rules at the bottom of column (b), we observe that the f-description of each derivation of the input in G reduces to the description (11a) rules depicted in (11b). (11) a. root = root , context-free grammar construction. The construction is accomplished in three steps. In the first step we identify (as illustrated earlier) a finite set of canonical terms that can serve in reducing the f-description space that G provides for F .
 of G . These instantiations are  X  X ppropriate X  in the sense (to be made precise later) that they maintain all necessary distinctions. They are formed by associating with the metavariables canonical terms that can legitimately be used to reduce the corre-sponding nodes of a local tree of a potential derivation of F . For the grammar (8) and the terms root and  X  , for example, there are only three appropriately instantiated rules, the two rules contained in (11b) and S  X  c (  X  H ) = V all collections of appropriately instantiated rules that together provide descriptions of F without mistakenly collapsing a functional discrimination. For our particular ex-ample there are just two collections of instantiated rules that provide a description of 878 from the power set of the appropriately instantiated rules, so there is only a finite number of them and each contains a finite number of instantiated rules. This ensures that we can determine the f-description space that G provides for F without knowing the details of the derivations for F and their reductions.
 those derivations in G whose strings are assigned the f-structure F . The categories of this new grammar consist of refinements of the categories of the context-free backbone of G together with a distinct root category S F . The original categories are augmented with two additional components, a canonical instantiation term as used in the first step, and a subset of one of the instantiated-rule collections determined in the second step.
The term component is used to encode the reducing substitution for the f-description of a simulated derivation, and the rule component is used to record the reduced in-stantiations of the licensing LFG rules whose application must still be simulated in order to complete that derivation. The productions of the new grammar are created from the rules contained in the instantiated-rule collections by replacing the original categories by a certain number of their refinements, and then adding a particular set of start rules. The start rules expand the root category of the new grammar to the original start symbol augmented by root and one of the instantiated-rule collections determined in the second step.
 many more rules than G . It is organized so that the normal matching of categories in a context-free derivation globally ensures that the refined rules simulate all derivations of F in G whose f-description is reducible to a description provided by one of the instantiated-rule collections determined in the second step. Because we have already indicated that every f-description of F must be reducible to a description provided by one of these instantiated-rule collections, the constructed grammar simulates exactly the set of derivations that G provides for F . The strings of Gen removing the additional components from the categories of the terminal strings. With r construction produces for the LFG grammar in (8) and the input [ HV ] a context-free grammar that contains the rules in (12).
These derive the set of terminal strings { a:  X  :  X  n b:  X  refinements we obtain { a n b n | 1  X  n } and thus exactly the set of strings that the gram-mar in (8) relates to [ HV ]. The rules (12b,e) simulate the derivation with the c-structure recursions of the S rule of (8) and an application of rule (12d) terminates a recursion because it consumes r 1 . An application of rule (12e) consumes r derivations.
 that can be used to reduce the f-description space for a given f-structure F derivable with an LFG grammar G . We then investigate in Section 3.2 the problem of reducing the f-description space for F and G . In Section 3.3 we give a precise recipe for constructing the context-free grammar for F and G , and in Section 3.4 we illustrate this with a few examples. 3.1 Identifying the Reducing Terms
Our reduction of the f-description space makes use of the fact that we can eliminate cer-tain node constants from an f-description FD without risk of producing a description not equivalent to the original. This is because some node constants can be defined in terms of others. We proceed rule-wise top X  X own based on the following definability relation. Definition 8 iff there is a (possibly empty)  X  such that Inst ( r ,( t , a eliminated in favor of the term ( t  X  ) from any description containing this instantiated description of r .
 among its rules the ones in (13). (13) a. S  X  NP VP
In this grammar fragment we use equational annotations in the adverbial phrase rules (13c) and (13d) instead of the more traditional set-membership statements (Kaplan and Bresnan 1982). This is another way of allowing for multi-valued attributes that was the original motivation for introducing set representations into LFG theory. We use the equational treatment here to illustrate the fact that undefinable and hence ineliminable constants can arise even when equality is the only formal device in an f-description. The adverbial rules also illustrate that undefinable constants can figure in the description of multiply rooted f-structures. The rules in (13) provide, for example, the derivation depicted in Figure 4. The figure shows the f-structure on the left-hand side and the instantiated descriptions of the licensing rules associated with the nodes of the c-structure on the right-hand side. This more conventional way of depicting derivations (Kaplan and Bresnan 1982) makes it easy to see the mother-definability relation and at the same time permits the licensing rule-mapping to be read from the annotated c-structure. The complete f-description is shown as a set in (14). (14) 880 constants, we can construct definitions rule-wise top X  X own in the following way. We begin with the start rule and derive from its instantiated description and n 2 . We then continue with the rules that expand n 1 rule that expands n 2 . For the m-definable n 2 we use the already constructed definition to replace n 2 by its defining term root in the instantiated description of the VP rule.
From Inst (VP  X  (V, { X  =  X  X  )(ADVP, { X  =  X  X  ), ( root , n n 4 = root and n 5 = root for its m-definable daughters, and so forth. If we run like this through the whole derivation, for all m-definable daughters we obtain defining terms that do not contain mother-definable node constants. For our example these are the ones in (15). then produce from the original f-description the equivalent description in (16). (16)
Notice that for each acyclic f-structure F the maximal length of the  X  in the defining terms is bounded by the depth of F .
 constant corresponding to a higher node and a sequence of attributes leading down it occurs in FD ) and all daughter constants that occur in FD but are not mother-definable.
At least for acyclic f-structures, however, we can show that there is an upper bound on the number of these remaining constants. This is because the remaining constants must each denote one of the elements of the given f-structure, but no two of them can denote the same element. This is a consequence of LFG X  X  instantiation procedure and functional uniqueness condition, and the acyclicity of the f-structure.
 node constants can be related in a single equation only if the nodes stand in a mother X  daughter relationship. Thus a daughter and a node external to the mother cannot be related directly by instantiation but only as a consequence of a deduction involving at least one instantiated annotation of some other licensing rule. Because of LFG X  X  functional uniqueness condition the equations involved in such a deduction cannot contain atomic feature values. The constant/complex clash condition (vii) of Defini-tion 4 prevents atomic values from being substituted for proper subterms and the constant/constant clash condition (vi) prevents them from being equated to nodes. Thus such a deduction can only involve equations relating a daughter to its mother (or a node to itself).
 deduction that relates them must involve an instantiated annotation of that daugh-ter that is (up to symmetric permutation) of the form (  X  (such as the adverbial annotations previously mentioned), and there must be deduc-tions from other equations that induce a cycle. This is demonstrated in the following lemma.
 Lemma 1
Let c and  X  be a derivation with f-description FD for an acyclic f-structure in G. If n of n and n j is not m-definable in Inst (  X  n ) then FD n and all (possibly empty) sequences of attributes  X  .
 Proof
Let n j be a daughter of n that is not m-definable in Inst (  X  would follow from FD for node n not dominated by n j . Assume further that FD and the instantiated descriptions of the licensing rules are closed under symmetry. Now recall that the rule of substituting equals for equals has the form where e is an equation containing subterm t and e is obtained from e by replacing one occurrence of t in e by t . Then we know that there is an equation t = t that is either in FD (or follows from FD by partial reflexivity 9 )suchthat n t = t by a left-branching substitution proof of the form 882 where t is rewritten to n j and t to ( n  X  ) by a sequence of substitutions all justified by of LFG X  X  instantiation procedure and the constant/constant and constant/complex relation between n j and the node occurring in t there are two possible cases. These are illustrated in Figure 5. (i) If the node occurring in t is dominated by n must be a premise ( n j  X  ) = ( n  X  )from Inst (  X  n )suchthat t is rewritten to ( n ( n j  X   X  )to( n  X  X  ). Because FD t = n j and hence FD n j = ( n the node occurring in t is not dominated by n j there must be a premise ( n  X  ) = ( n from Inst (  X  n ) such that either t is rewritten to ( n  X  X  ) and then to ( n
Since FD t = n j , we get in both cases |  X  | = 0 because of acyclicity and thus the same contradiction as in (i).
 The following corollary follows directly from Lemma 1.
 Corollary 1
Let c and  X  be a derivation with f-description FD for an acyclic f-structure in G. If n of n and n j is not m-definable in Inst (  X  n ) then (i) FD n j = root, and (ii) FD n j = n i for any distinct node n i that is not definable in terms of its node constants are biunique. So, their number must be less than or equal to the size of the universe of a minimal model M of FD . Suppose F is the f-structure for a derivation with f-description FD . Because F is isomorphic to M |  X  for any minimal model M of
FD ,and M |  X  and M share the same universe, we can use F  X  X  (finite) universe to define the constants that we require. Thus for each element a of the universe of F that is not denoted by an atomic value we introduce a constant a a . 10 Definition 9 Let F be an f-structure with F = ( U , I ). We define the set of constants
The set C F provides a sufficient number of constants to produce an equivalent reduced description by a biunique renaming of the node constants that remain after the m-definable ones are eliminated.
 example, if we map in the natural way each mother-undefinable daughter n correspond-ing to a in the isomorphic image F of M |  X  to the constant a such a mapping must be biunique. Hence it can be used to rename all undefinable daughters occurring in FD and will thus produce an equivalent description where all nodes except root are replaced by constants drawn from F .
 with the universe in (17a) and the interpretation function whose directed acyclic graph representation is given in (17b). 11
The constants we obtain from the structure (17) by Definition 9 are the ones in (18). 884 phism between M |  X  and our structure (17) must map the denotation of n the denotation of n 10 to g , we can rename n 7 by a f and n equivalent description (19). (19) daughters and the substitution that we used to rename the undefinable daughters.
This provides a substitution that allows us to produce from the original f-description an equivalent description in a single transformation. If we compose the two sub-stitutions of our example, that is, the one induced by the definitions in (15) and the renaming substitution { ( n 7 , a f ), ( n 10 , a g ) in (20). range of the reducing substitutions for all derivations of an f-structure F . This set is obtained from the constants in C F and the attributes of F in the following way. We first provide the constants C F with their intended interpretation by expanding F in the natural way to the canonical structure  X  F for  X   X  C F .
 Definition 10
Let F be an f-structure with F = ( U , I ). We define the canonical expansion
 X   X  C
In the canonical expansion  X  F , each element of the universe is denoted by exactly one constant. Each new constant a a is interpreted by a and each atomic feature value by its original denotation.
 for all possible derivations of F is a set that contains all terms of the form ( a are defined in  X  F but do not denote an element already designated by an atomic feature value. It also contains all terms that we obtain from those by substituting root for their constant symbols. This set includes all constants of C F (because  X  can be empty) and thus all possible constant values for the mother-undefinable daughters of a derivation for F . Because each element in the universe of  X  F is denoted by a constant, all possible defining terms for the mother-definable nodes of that derivation. Terms referring to the denotation of an atomic feature value are not required, since there are (because of the constant/constant clash condition) no node constants with the same denotation as any atomic feature value.
 for the fact that different derivations may associate different functional elements with the root of the c-structure. That would be the case, for example, if our grammar contains in addition the S and VP rules (21a,b) and alternatively derives the adverbials with the rules (21c,d). (21) a. S  X  SADVP
With such a grammar we can derive the f-structure of Figure 4 also with an f-description where root denotes the ADJ value and where the top of the f-structure is denoted by the mother-undefinable S node that is expanded by the original start rule. As this example indicates, a grammar might produce several f-descriptions for the same f-structure by anchoring the description at different f-structure elements and then moving along different paths through the structure. This is why the term set must contain the entire set of constants C F (and the terms containing them) and not just the ones for the f-structure roots.
 reducing substitutions to make all the distinctions that could arise from any c-structure and f-description for the given F . It is defined formally in the following way. Definition 11
Let F = ( U , I ) be an f-structure. On the basis of the canonical expansion
 X   X  C The set of terms T F that we will use for the grammar construction is then defined by
For mathematical convenience we add the dummy constant  X  as a value for those nodes of the c-structure that are not interpreted in a minimal model of the f-description. These are just the ones that do not occur in the f-description. The complete set of terms for the structure in (17) is given in (22).
We have illustrated that we can reduce the f-description of every derivation of an acyclic f-structure F to an equivalent description if we replace the node constants by terms of T
Our grammar construction requires us to simulate this reduction without knowing in advance the details of either the c-structure or a particular f-description. And that means only on the basis of the possible values of the reducing substitutions, namely T , and the rules of G . 3.2 Reducing the f-Description Space
We now shift our attention to the rules of G and their instantiating terms, that is, to the arguments of the Inst function. These are pairs consisting of an m-ary rule r of G and its 886 simply an instantiated rule . Let us further extend the reducing substitutions that we constructed for the derivations of F to total functions by assigning root to root and to each non-denoting node constant. Now recall that the f-description of a particular derivation for F consists of the union of the instantiated descriptions of the rules that together license that derivation. If we consider these licensing rules together with their node instantiation, that is, pairs of the form ( r ,( n , n substitution for that derivation to replace the node constants in the instantiations by canonical terms, then we obtain a collection of instantiated rules of the form ( r ,( t , t these rules is identical to the description that the reducing substitution produces from the original f-description. Because R and T F are finite, the set of all instantiated-rule collections that we obtain from the (possibly infinite) set of derivations of F by reducing their node-instantiated licensing rules must be finite too. This fact is crucial for our grammar construction.
 also appropriate in the following sense.
 Definition 12
Let r be an m-ary LFG rule in R of G ( m  X  0), F be an f-structure, ( t , t and a 1 .. a m be a sequence of length m of pair-wise distinct constants not in the instantiated rule ( r ,( t , t 1 .. t m )) is appropriately instantiated (by terms of following conditions are satisfied: (i) if t j =  X  then a j is not interpreted in a minimal model of Inst ( r ,( t , a (ii) if a j is m-definable in Inst ( r ,( t , a 1 .. a m )) then Inst ( r ,( t , a (iii) otherwise t j  X  C F , t j = t and t j = t i for all i = 1, .. , m with i = j . In the following the set of all appropriately instantiated rules is denoted by IR { ( r ,  X  )  X  R  X  ( T F  X  T  X  F ) | ( r ,  X  ) is appropriately instantiated
The constants a 1 .. a m in this definition provide the same discriminations as the daughter from eliminating node constants in favor of terms in the way that we have described.
Such term-instantiated rules satisfy condition (ii), because whenever the mother is instantiated by t and an m-definable daughter n j isreducedtoaterm( t  X  ) wise distinctness of the values for the mother-undefinable nodes, due to Corollary 1.
And condition (i) holds, because non-denoting node constants are mapped to set IR F of all possible appropriately instantiated rules is large but finite, because R and T F are finite.
 tiations in (23) are appropriate.
The rule ADVP  X  (ADV, { (  X  ADJ ) = (  X  ELE ) } )(ADVP, { X  many appropriate instantiations, among them the ones in (24).
Instantiations that are not appropriate for this rule are, for example, the ones in (25).
They are not properly discriminating, because the ADV node of any derived f-description must denote an entity distinct from the denotation of the mother and the other daughter node.

Figure 4 and the reducing substitution (20). Note that the appropriately instantiated rule (23b) that does not associate the S node with the root constant might result from derivations where the top of the f-structure is not denoted by the root node of the c-structure, as illustrated with the rules in (21).
 the licensing rules of a derivation for F by replacing the node constants as described by terms of T F . As a consequence of Corollary 1, we also observe that our reducing substitutions never replace undefinable daughters of two distinct node-instantiated licensing rules by one and the same constant. That is, the term-instantiated rules that result from two distinct node-instantiated licensing rules always satisfy the following compatibility relation.
 Definition 13
Two appropriately instantiated rules ( r ,( t , t 1 .. t m ble iff
Given appropriateness, the conditions t i  X  C F and t i = t imply that t in terms of t in the instantiated description of r . In essence, two instantiated rules are compatible only if there are no repetitions of daughter constants instantiating mother-undefinable daughters: All shared daughter constants instantiate mother-definable daughters. Incompatible instantiations do not respect the biuniqueness property given by Corollary 1 and therefore cannot appear together in the set of for any derivation of F . Note that this compatibility relation is symmetric, but reflexive 888 by a constant from C F is mother-definable. As a consequence of Corollary 1, only an in-stantiated rule that is compatible with itself can emerge from two separate applications of r in a derivation of F .
 are not. The latter rules mistakenly introduce an identity that, because of Corollary 1, can never be derived by the grammar. The rules in (26a) result from reducing the licensing rules of the derivation in Figure 4 with the reducing substitution (20). tirely in terms of the identified properties of the T F -instantiated rules and thus in a way that will permit us to simulate their construction by a refinement of the context-free backbone of G . In the following definition we use N structure c and  X  [  X  ] to indicate the expression that is obtained from an expression  X  (term, sequence of terms, formula, set of formulas, etc.) and a substitution  X  (mapping from constants to terms) by replacing all occurrences of constants a in  X  simultaneously by  X  ( a ).
 Definition 14 Let c and  X  be a derivation of f-structure F in G and  X  be a mapping from
Then  X  is a reducing substitution for the given derivation iff  X  ( root ) = root ,andforall n , n  X  Dom (  X  )with n = n (i) (  X  n ,( n , dts ( n ))[  X  ]) is appropriately instantiated, and (ii) (  X  n ,( n , dts ( n ))[  X  ]) is compatible with (  X  following lemma.
 Lemma 2
Let c and  X  be a derivation with f-description FD and f-structure F in G. If  X  is a reducing substitution for c and  X  ,thenFD  X  FD [  X  ] .
 Proof
We prove the lemma by induction on the number of nodes, according to a left-to-right, top X  X own traversal of the c-structure. Let c and  X  be a derivation with f-description FD and f-structure F in G , M = ( U , I ) a minimal model of FD ,and  X  a reducing substitution for c and  X  . We first define for each node n of c the set than n , all nodes of the same depth as n but preceding (on the left), and n .Nowfor each N n with | N n | = i let the function  X  i be the restriction of  X  to can show by induction for each i = 1, .. , | N c | that FD down. The equivalence is established by constructing a minimal model M universe U of M . Thus the isomorphism between M |  X  and M
The basis, i = 1, is trivial, because  X  1 = { ( root , root ) and M 1 = M is a minimal model of FD [  X  1 ]. Hence FD  X  FD [  X  let i &gt; 1. Then FD  X  FD [  X  i  X  1 ] by hypothesis. Let M of FD [  X  i  X  1 ], and suppose that node n j with mother n is the next node in the sequence (i.e., | N n j | = i ).

If n j is not interpreted in M , it does not occur in FD and hence not in FD [  X 
FD [  X  i ] = FD [  X  i  X  1 ], M i = M i  X  1 is a minimal model of FD [  X 
If n j is interpreted in M , there are two cases to consider. (a) If n j is m-definable in Inst (  X  n ,(  X  i  X  1 ( n ), dts ( n ))) and  X  ( n
Because n j does not occur in t j and hence not in FD [  X  to the definitional extension FD [  X  i ]  X  X  n j = t j } of FD [  X 
M = M i  X  1 | ( Dom ( I i  X  1 ) \{ n j } ) is a minimal model of FD [  X 
FD  X  FD [  X  (b) If n j is not m-definable in Inst (  X  n ,(  X  i  X  1 ( n ), dts ( n ))) then  X  ( n
Then a a cannot occur in FD [  X  i  X  1 ], because the instantiation is appropriate and pair-wise compatible and a a = root ( =  X  ( root )). 13 So the model M by renaming n j by a a must be a minimal model of FD [  X  i
FD  X  FD [  X  Hence, FD  X  FD [  X  | N c | ] = FD [  X  ].
 stants are distinct from the root. This case is covered, however, because we kept root for the root.
 can X  X ependent on a minimal model of its f-description X  X onstruct a substitution with range T F that satisfies the conditions of Definition 14. We now provide a rigorous proof of this assertion.
 Lemma 3 For every derivation of an acyclic f-structure F in G there exists a reducing substitution. Proof Suppose there is a derivation c and  X  with f-description FD and f-structure F in G ,that
FD has minimal model M = ( U , I ), and that h is an isomorphism between M
Suppose furthermore that c has depth k . For each i = 0, .. , k we define by induction a function  X  i : N c  X  T F as follows. For the root ( i = 0) we set  X  have defined  X  i  X  1 ,0 &lt; i  X  k . We then set  X  i ( n ) =  X  let n j be a node of depth i with mother n .If n j is not interpreted in M we set  X 
If n j is interpreted in M we set 890
Now, let  X  =  X  k . Then  X  trivially satisfies the appropriateness conditions (i) and (ii) by definition. Appropriateness condition (iii) and compatibility follow by Corollary 1. Thus  X  is a reducing substitution for c and  X  .
 an acyclic f-structure F in G . By Lemma 2 we know that such a substitution preserves equivalence. 14 Thus, the collections of instantiated rules that result from the derivations for F and their reducing substitutions must belong to the set consisting of all possible collections of appropriately instantiated and pair-wise compatible rules that together provide descriptions of F . If we extend the Inst function in the obvious way to sets of instantiated rules IR then this set is defined as follows.
 Definition 15
Let F be an f-structure. Then IRD F is the set of all sets IR (ii) M |  X  This is a finite set whose size is bounded by a function of the sizes of R and f-description of F , not only with the model-dependent substitutions used in the proof of Lemma 3, but in general with any mapping that satisfies the definition of a reducing substitution. This is important for our grammar construction, because it provides the conditions that we have to control to make sure that we simulate the derivations of f-descriptions for F together with equivalence-preserving substitutions. Under these conditions we can reduce the sets of node-instantiated licensing rules of the simulated derivations to collections that are also included in IRD F out knowing the details of the valid derivations for F ,justonthebasisof F and the LFG grammar G alone. 3.3 Producing the Context-free Grammar G F G F G F
The context-free grammar G F that simulates all valid derivations for F in G is specified in the following definition. From this we can produce all strings in Gen tional context-free generation algorithms.
 Definition 16
Let G = ( N , T ,S, R ) be an LFG grammar and F be an acyclic f-structure. For G and F we construct a context-free grammar G F = ( N F , T F ,S F collection of nonterminals N F is the (finite) set where S F is a new root category. Categories in N F other than S
R of G . We include all and only rules of the form: (i) S F  X  S: root : IR root , where IR root is any element of IRD (ii) A : t : IR  X  X 1 : t 1 : IR 1 .. X m : t m : IR m such that We define the projection Cat ( X : t : IR ) = X for every category in N extend this function in the natural way to strings of categories and sets of strings of categories. Note that the set is context-free, because the set of context-free languages is closed under homomor-phisms such as Cat . 16 for F in G are simulated by the context-free grammar G F .

S: root : IR root containing the root category S of G as their first component. A derivation with refinements of the categories of the original LFG grammar. By taking the Cat projection of every category, we obtain the c-structure of at least one derivation for F in
G that is simulated by the derivation from S: root : IR root augmented categories encodes a reducing substitution  X  for the simulated derivation with the given c-structure. That is, if a node n in the G then  X  ( n ) = t for the corresponding LFG c-structure tree.
 the subderivation in G that corresponds (under the Cat projection) to the subderivation from n in G F , except that the licensed nodes are replaced in the instantiated rules by their  X  values. 17 Thus, the additional components of the root label S: root : IR 892 that  X  ( root )issetto root (the initial condition for reducing substitutions) and that the node-instantiated licensing rules of the simulated derivation are reduced to IR
Each application of a rule A : t : IR  X  X 1 : t 1 : IR 1 .. X n of the derivation in G F simulates the application of an LFG rule with context-free back-bone A  X  X 1 .. X m whose instantiation with ( t , t 1 .. t components of all daughters to form the rule component IR of the mother. must be a reducing substitution for the simulated derivation, because all instantiated rules in IR root are appropriately instantiated and pair-wise compatible and because condition (iic) of Definition 16 ensures that rules that are not self-compatible can only be used once for licensing the Cat projection. Thus, because of Lemma 2, the derivation in G F simulates a derivation of an f-description in G that  X  reduces to the equivalent description provided by IR root .
 G . We know from Lemmas 2 and 3 that we can construct for every derivation of an f-description for F in G a reducing substitution  X  that produces a description equiv-alent to the original one. Based on  X  we can then augment the category labels of the c-structure of a derivation for F in G by term and rule components that record  X  and the licensing rules (with the node constants replaced by their  X  values). We thus obtain aderivationfromS: root : IR root where the instantiated description provided by IR equivalent to the original f-description. Because G F contains a start rule for every set of appropriately instantiated and pair-wise compatible rules that provides a description of F , there must also be a rule that expands S F to S: root : IR the derivation for F in G must be the Cat projection of a derivable string in G Theorem
For any LFG grammar G and any acyclic f-structure F, Gen G Proof terminal string s with f-description FD and f-structure F in G . By Lemma 3, there exists a reducing substitution  X  for c and  X  .Thus FD  X  FD [  X  ] by Lemma 2. We construct a deri-vation c and  X  of s from S: root : IR root with Cat ( s ) = s .Weobtain c by relabeling each node n with label X by X :  X  ( n ): { (  X   X  n ,(  X  n , dts (  X  n ))[  X  ])
That means that the c-structures of both derivations share the same tree skeleton. We de-fine  X  for each nonterminal node n with label A :  X  ( n ): IR and dts ( n ) = n
X :  X  ( n 1 ): IR 1 , .. , X m :  X  ( n m ): IR m by  X  n = A :  X  ( n ): IR
FD [  X  ] = Inst ( IR root ) by construction of IR root and because IR of Definition 15 hold by the properties of  X  , IR root must be an element of IRD S components are subsets of IR root , the rule components of the terminals are empty, and the rules satisfy (iia,b) of Definition 16 by construction and (iic) because  X  is a reducing substitution. Thus s  X  Cat ( L ( G F )).
  X  of s from S: root : IR root with Cat ( s ) = s and IR root
We then show that there is a mapping  X  into R licensing c with FD induction on the depth of the subtrees we first define for each nonterminal n afunction  X  from all nonterminal nodes dominated by n into R such that (a)  X  n licenses the subtree of c with root n , (b) IR = { (  X  n  X  n ,(  X  n , dts (  X  n ))[  X  ]) | n dominates nonterminal node  X  n (c) (  X  n  X  n ,(  X  n , dts (  X  n ))[  X  ]) is appropriately instantiated and (d) (  X  n  X  n ,(  X  n , dts (  X  n ))[  X  ]) is compatible with (  X 
Suppose n with dts ( n ) = n 1 .. n m is expanded by  X  n = A : t : IR c , then there is a rule r  X  R satisfying the conditions of Definition 16(ii). Thus, r ex-pands A to X 1 .. X m , IR = { ( r ,( t , t 1 .. t m )) } X  definition of  X  .If n is a preterminal node then IR j =  X  set  X  n = { ( n , r ) } and (a) X (d) hold trivially. If  X  n daughters n j we set  X  n = { ( n , r ) } X  {  X  n j | n j is a nonterminal daughter of n (c) by construction of  X  n and by the inductive hypothesis, and (d) by Definition 16(iic) and because IR  X  IR root by Definition 15(i). So,  X  =  X  root substitution for c and  X  ,and FD  X  FD [  X  ] by Lemma 2. Then FD [  X  ] = Inst ( IR and thus s is derivable in G with F .
 Corollary 2
For any LFG grammar G and any acyclic f-structure F, Gen G 3.4 A Few Examples
In the preceding sections we have shown how to construct a context-free grammar that generates exactly the set of strings that an LFG grammar assigns to a given f-structure. Those strings can be produced by running a context-free generator with that grammar. In this section we provide examples to illustrate the derivation space of the constructed context-free grammar and the correspondence between the derivations of the constructed grammar and the derivations of the original LFG grammar. the f-structure F in (27) and the LFG grammar with the rules (13) and the VP rule in (2). (27)
For this grammar there is only one derivation of a string with the given f-structure, the one that is depicted in the upper part of Figure 6. The figure shows the derivation with all its components, that is, the c-structure, the rule-mapping  X  together with the node instantiation of the licensing rules, and the f-description. This LFG derivation is 894 simulated in the constructed context-free grammar by the derivation that is shown in the lower part of the figure.
 to the original LFG derivation by the construction of the first half of our proof. That is,  X  is a reducing substitution and the context-free derivation specializes the category label of each node n of the original c-structure. The term component is n  X  X   X  value.
The rule component is the set of all instantiated rules that result from the licensing rules of the corresponding n -dominated LFG subderivation. These are instantiated by replacing the instantiating nodes of the LFG derivation by their  X  values. Thus, the instantiated description provided by the rule component of the start rule is equivalent to the original f-description and hence the context-free derivation tree at the bottom of Figure 6 is licensed completely by the rules of the constructed grammar. Note that the
Cat projection of the terminal string of the context-free derivation is the terminal string of the c-structure, the sentence John fell .
 are also related by the construction of the second half of the proof. The c-structure is the Cat projection of the constituent structure that S F  X  X  daughter derives. The reducing substitution maps each node of this c-structure to the term of its complex label in the corresponding context-free derivation. And the LFG rule that the licensing mapping maps to each node is the rule of the node label X  X  rule component that licenses the node and its daughters in the Cat projection. This is instantiated by the term components of the applied context-free rule and combines with the rule components of the daughters to form the rule component of the mother. These licensing LFG rules for the immediate daughters are shown in gray in the rule component of the node labels in the context-free derivation.
 grammar G F produced for the f-structure F given in (17) and the grammar compris-ing the rules in (13). This LFG grammar produces two terminal strings for the given input, John fell today quickly and John fell quickly today . A set of pair-wise compatible appropriately instantiated rules that yields a description of the input f-structure is, for example, the one contained in the start rule (28). This set arises from reducing the node-instantiated licensing rules of the derivation in Figure 4 with the reducing substitution (20) extended by mapping non-denoting nodes to (28) The only useful rule of G F for expanding the daughter of rule (28) is the rule (29).
All other admissible distributions of the members of the mother X  X  rule component also result in rules of G F . But these other rules cannot be used to produce a terminal 896 (29) (30) string. For instance, when the instantiated S rule S  X  NP VP distributed over the daughters, the derivation will not produce a terminal string because
S is not reachable from either NP or VP in the context-free skeleton of the grammar in (13). Similarly, the verbal and adverbial categories are not reachable from NP and NP is not reachable from VP.
 terminal symbol  X  X ohn:  X  :  X   X .
Now, for the right daughter of (29), only the expansion with (30) gives rise to a terminal string. By applying (32) to the left daughter of (30) we first derive the terminal symbol  X  X ell:  X  :  X   X .
Rule (33) then is the only possible rule of G F whose application (to the right daughter of (30)) will lead to a terminal string. (33) daughters also produce categories that fail to derive terminal strings. Some of these distributions will figure in derivations that fail, as we observed earlier, because the LFG rules predicted in the rule component of our categories collectively do not derive a terminal string (ADVP is not reachable from ADV in this particular case). This example illustrates that derivations can also fail to produce any sentence because of mismatches of the term component of an augmented daughter category and the terms instantiating the left-hand categories of the rules in the rule component that expand that daughter category. That is why the alternative rule in G F in which the adverbial daughter has string. Note moreover that condition (iic) of Definition 16 blocks recursions of ADVP producible by the context-free backbone of the original grammar, because the instan-over the daughters.
 of (33). (34) 898
With rules (35) and (36) then we obtain the terminal string  X  X ohn: today:  X  :  X  quickly:  X  :  X   X .
The Cat projection of this string is John fell today quickly , the only sentence whose derivation G F simulates by starting with rule (28).
 like (28) except that the ADVP rules are instantiated as in (37), that is, exactly the other way around.
If we begin with this alternative starting rule, we can derive the string  X  X ohn: and in that sense the grammar G F allows for spurious ambiguities. These derivations differ from the given ones in that the instantiating constants of renamed (e.g., a f by a a and a g by a d ) or some of the terminal daughters with no their annotation are biuniquely instantiated by otherwise unused constants of next section we consider some computational strategies for eliminating rules that fail to produce terminal strings or give rise to spurious ambiguities. 4. Computational Considerations So far we imposed only loose restrictions on the ingredients of the generation grammar G , and a faithful implementation of the grammar definition may create categories and rules that are either useless or redundant. Useless rules cannot participate in the simu-lation of any LFG derivation while redundant ones simulate only the same derivations as other rules and categories in the grammar. There are a number of techniques for avoiding the construction of these unnecessary and undesirable grammar elements. daughter, a naive implementation would produce distinct but equivalent daughter in-stantiations. Rule and category instantiations that express only uninformative variation can be eliminated by normalizing the rule annotations in advance of generation so that there is exactly one canonical function-assigning equation for each mother-definable daughter and by using that equation to construct its defining term. Normalization can be accomplished by exploiting symmetry and substitutivity to reduce the anno-tations of the rules to some normal form according to an appropriate complexity norm, as suggested by Johnson (1988). Another off-line computation can identify terminal daughters that are introduced with rules that do not contain interpreted. Without loss of generality we can disregard other instantiating constants that might be drawn from C F and systematically instantiate all of those terminals with the distinguished constant  X  .
 differ only by renaming of the instantiating constants of contains rule sets that are identical up to renaming of the instantiating canonical con-stants, as indicated in Section 3.4. We observed in conjunction with Lemma 3 that the f-description of every derivation for F can be reduced to an equivalent description that is satisfied in the canonical model  X  F expanded by some interpretation of root . Thus the generation grammar can be constructed by considering only the set IRD those elements of IRD F whose instantiated descriptions are modeled by some root expansion of  X  F .
 our recipe for constructing G F may produce other useless categories and expansion rules. These cannot play a role in any derivation either because they are unreachable from the root symbol S F or because they do not lead to a terminal string. We can borrow strategies from conventional context-free grammar processing to control the production of these useless items.
 ing categories and rules that are unreachable from the root symbol. It corresponds most directly to the specification of Definition 16. The algorithm maintains three data-structures, an agenda A of categories whose expansion rules have yet to be constructed, aset V of terminal categories and nonterminal categories that have already been consid-ered for expansion, and a set R of constructed context-free rules. All three structures are empty at the outset. The first step of the algorithm is to add the root category S Then at each subsequent step a category  X  is selected from  X   X   X  are added to the rule set R , and each of the nonterminals  X  the agenda. Because Definition 16 provides for a finite number of categories, the agenda eventually will become empty. At that point the algorithm terminates with asubsetof R F sufficient to simulate all and only the LFG derivations for F . As indicated, this algorithm has the desirable property of creating just those categories and rules of G that are accessible from the root symbol. It is guided incrementally by the c-structure skeleton of the LFG grammar. It is also guided by properties of the input f-structure as the rule component for each new category is a subset of some element IR
But this procedure has the disadvantage of typically producing many categories that derive no terminal string.

The bottom X  X p algorithm uses the same three sets, all empty at the outset. Here the first step is to add to the agenda A all of the elements in the set T In each subsequent step a category is selected from A and moved to down approach. In this case, however, we add to R all rules  X  conditions (i) and (ii) of Definition 16 and where the selected category is at least one of the daughters  X  j and all other daughter categories already exist in further require  X   X  X  rule component to be a subset of some IR also constrained at each step by the input f-structure. The category  X  is added to the agenda if it is not already present in V . This algorithm also terminates when the agenda is empty. It ensures that every category we construct can derive a terminal string, but it does not guarantee that every bottom X  X p sequence will reach the root symbol. computation of all elements of IRD  X  F , but neither specifies how to instantiate those rule sets in an efficient manner. A straightforward modification of the bottom X  X p algorithm can sidestep this difficulty. We can replace the subset test on the rule component of each  X  with a check to see whether the instantiated description of that component is satisfied in  X  F expanded by some interpretation of root . This test makes reference just 900 to the canonical model of the input, examining only those features that are relevant to each potential new category. We reject a category if it fails this test, knowing that its rule component cannot be a subset of any element of IRD to the step-by-step subsumption test of other bottom X  X p generation algorithms (e.g.,
Shieber 1988 and Kay 1996). A further restriction is needed to filter the creation of start rules. Rules of the form S F  X  S: root : IR are included in of  X 
F is not only a model for Inst ( IR ) but a minimal one at that. We know in that case that we have arrived at one of the elements of IRD  X  F . The minimality condition is an ana-logue of the completeness requirement of other algorithms.
 interpretation of the node constant root , and we saw in Section 3.2 that root may denote different elements of the universe in different derivations of F . Although its eventual denotation cannot be uniquely predicted at intermediate steps of the bottom X  X p process, we can avoid reconsideration of root denotations already determined to be unsatisfactory by carrying along the satisfying denotations in an auxiliary data structure associated with each category in A and V . For an LFG rule r that expands
A with the c-structure categories X 1 .. X m ,arule A : t : IR added to R if there is at least one root expansion of  X  F that satisfies Inst ( r ,( t , t and whose root denotation is shared across all daughters. The root denotations of all such  X  F expansions are then associated with A : t : IR . The complexity of this test is proportional to the complexity of the instantiated description of the LFG rule and not of the instantiated description of the entire rule component IR , because the rule components of the daughter categories do not need to be reevaluated.
 down and bottom X  X p information into account at the same time. For instance, we can simulate a left-corner enumeration of the search space, considering categories that are reachable from a current goal category and match the left corner of a possible rule. As another option, we can precompute a reachability table for the context-free backbone of G and use it as an additional filter on rule construction. In general, almost any of the traditional algorithms for parsing context-free grammars can be reformulated as a strategy for avoiding the creation of useless categories and rules. We can also use enumeration strategies that focus on the characteristics of the input f-structure. A head-first, finds the rules that expand to them, and then uses information associated with those heads, such as their grammatical function assignments, to pick other categories to expand. 5. Other Chart-based Approaches
A bottom X  X p strategy for grammar construction comes closest to the algorithms of previous chart-based generation proposals. There is a correspondence between the edges that are added incrementally to a generation chart and the context-free rules that we add to the grammar. But chart edges in these proposals typically collapse some of the distinctions that we have in our rules and categories, and therefore these algorithms cannot faithfully interpret the full set of grammatical dependencies. For some grammars and inputs they may produce strings that should not belong to the generated language.
In an attempt to guarantee termination these algorithms may also include grammar restrictions or processing limits that unduly narrow the set of legitimate results. We will illustrate some correspondences and differences with the modified ( algorithm sketched in the previous section by comparing its first few steps with the operations of Kay X  X  (1996) chart-generation algorithm.
 ples to an equivalent grammar in the LFG formalism. The LFG grammar is given in (38). (38) a. S  X  NP VP
This grammar with its particular lexical rules has the sentence The dog saw the cat in its language, and that sentence is assigned the f-structure in (39), a direct encoding of Kay X  X  semantic specification. 19 This shows the f-structure elements that are used to define the constants in C F . (39) s initialize the agenda with the terminal categories T F = { gories are sufficient to complete the right sides of the given lexical rules, and so in the next steps the terminal categories are moved to V and rules including those in (40) are constructed. These are the ones that can potentially contribute to the generation of the noun phrase the dog : The instantiated descriptions produced with these terms pass our satisfiability test on  X  F . 902
Rules (40a,b) correspond directly to the lexical edges that are added to the chart in the initialization step of Kay X  X  algorithm. A lexical edge includes the word (the Cat projec-tion of our right-hand complex category), a syntactic category (a left-hand c-structure category) paired with an instantiation term, and instantiated semantic propositions (an instantiated description collected from our rule annotations). parallel the first two rules are shown in (41). (41) Words Category Semantics
Note that the instantiating term that corresponds to Kay X  X  semantic index d is the canonical constant a d drawn from C F . It is a significant limitation that ground-level terms like these are the only ones available for instantiation. We observed at the be-ginning of Section 3 that the set C F is in general not large enough to equivalently reproduce the discriminations that are required for grammars that allow for undefinable daughters and path equations and for inputs that contain reentrancies. Thus, as origi-nally presented, Kay X  X  algorithm is correct only for a very restricted set of unification grammars.
 collection of path-terms that combine constants with sequences of attributes. Rules (40c,d) make use of the path-term ( root ARG 1), and it is not unreasonable to extend
Kay X  X  approach to create the corresponding edges shown in (42). This would allow his algorithm to be applied to a broader set of grammars and inputs. another NP rule will be created from the constant-instantiated rules in (40a,b), and both new categories will be placed on the agenda. 21 (43)
Our extended version of Kay X  X  algorithm also combines determiner and noun edges to make up the NP edges in (44).
These edges reveal another significant difference between Kay X  X  algorithm and our approach. The Words fields now consist of sequences of words, the ( Cat projections of the) terminal strings for the full noun phrases. These strings are constructed by concatenating the Words from the two component edges in the order specified by the grammar rule that justifies the combination. That is, an edge does not incorporate the justifying rule but instead records a single member of the yield of the subtree beneath the category of the edge. The effect is that the incremental construction of the chart is intermixed with the process of recursively assembling the terminal strings of longer and longer phrases. The advantage of Kay X  X  strategy is that after termination the generated strings can be read out as the Words of all the edges whose Category is the start category paired with the top-level index and whose Semantics exactly matches the original input: There is no need for a separate context-free generation phase.
 that only a finite number of edges will be created so that the chart-construction process does in fact terminate. Kay proposes a use-once restriction that bounds the size of the derivable constituents by the number of predicates in the input. For some grammars and inputs his algorithm will only produce a proper subset of the full set of generable strings. Another disadvantage in comparison to our approach and other approaches in the chart-based family is that Kay X  X  chart edges do not record intermediate generation results in a compact form that allows operations on the generated string set to be carried out in advance of enumerating the individual strings. 22 but have similar characteristics at an abstract level. A common thread is that each edge contains a semantic or feature-structure representation aggregated from all of the edges in the subtree that it dominates, and edge creation is filtered by testing whether these representations subsume the generation input. Each algorithm in the family also imposes one or more additional restrictions in an attempt to guarantee termination of the string generation process. Kay appeals to a use-once processing condition, as noted earlier, that ensures termination but may only produce a proper subset of the complete output set.
 they do not associate individual terminal strings with the edges of the chart. Each edge contains a semantic or feature-structure representation and a sequence of immediate daughter edges from which that representation can be assembled. The individual sub-strings consistent with that representation are obtained by a recursive traversal reaching down to the terminal edges. The chart-construction phase of these algorithms (and our grammar construction) will not terminate if the number of distinct edges is not bounded by the size of the input. This may be the case for cyclic inputs, because they have 904 infinitely many distinct unfoldings all of which subsume the input. A separate question, even with a bounded chart, is whether the string-production traversal is guaranteed to terminate with a finite set of strings. A grammar may give rise to infinitely many strings if it has recursive or iterative rules whose feature structures subsume the same portion of the input. Any finite set of output strings for such a grammar and input will necessarily be incomplete.
 a finite but complete set of output strings for a restricted class of semantically mono-tonic grammars. Shieber X  X  condition requires that the semantic representation of every mother phrase is subsumed by the semantic structure of each of its daughter phrases.
In LFG terms this condition amounts to the requirement that each daughter is mother-definable (with an annotation of the form (  X   X  ) =  X  for that strings can be generated only for single-rooted inputs. On deeper analysis, how-ever, we see that this restriction is not sufficient to ensure that the generation process will terminate with a finite output set. It does not by itself preclude grammars that assign cyclic feature structures and therefore the chart-construction process may be unbounded. And with an acyclic input and a finite chart the complete set of output strings may still be unbounded since several daughters in a recursive rule may subsume exactly the same portion of the mother X  X  semantic representation. A formal example of this is the monotonic grammar in (8) that produces the string set stronger restriction on the form of the annotations, namely, that  X  is never empty, will guarantee a finite chart and a finite and complete output set, but monotonic grammars in this sense cannot naturally identify the functional or semantic head-daughters that figure prominently in so many linguistic descriptions. It seems that monotonicity is not a particularly helpful restriction and that some other constraint, either on grammars or processing steps, is needed to guarantee an output set containing only a finite number of syntactic variants (cf., e.g., Neumann 1994; Moore 2002).
 their instantiations need only terms involving root and none of the constants in terms containing those constants. 23 This is because these algorithms are not set up to control subsumption accurately for multi-rooted inputs and grammars with mother-undefinable daughters, and in fact their result set may be incorrect in those cases. As we have demonstrated, maintaining all of the proper discriminations requires the larger term set and a mechanism with the same effect as our appropriateness and compatibility conditions.
 creating a generation grammar has brought out some similarities but also highlighted some important differences. Chart edges contain information that summarizes the syn-tactic and semantic contribution of their subtrees and also allows for the correlated terminal strings to be read out by a straightforward traversal. These algorithms cannot attain correctness, completeness, and termination without imposing limits on the kinds of grammatical dependencies that the generator can faithfully interpret, the range of structures that can be provided as input, or the size and number of output strings that can be produced. Our approach operates correctly on a larger class of grammars and inputs because we have more instantiating terms and therefore are able to maintain appropriate discriminations without special restrictions. The resulting grammar gives a finite encoding of the complete set of generated outputs in a well-understood formal system. These can be enumerated on demand in our separate context-free generation phase. 6. Cycles
We have established the context-free result only for acyclic f-structures; the result does not hold for cyclic inputs. This is because the f-structures that correspond to subderiva-tions of a derivation of a cyclic structure are not necessarily bounded by the size of the input. So we might need an infinite number of terms in order to reproduce correctly any discrimination made in the f-description for some subderivation of a cyclic input structure. The following example demonstrates that the set of strings that a grammar relates to a particular cyclic input might not be context-free.
R given in (45). (45) a. S  X  AC
Now, let F be the following input f-structure.
The set of terminal strings that are derivable with F is { is not context-free. Each top X  X own derivation for a terminal string that gets assigned the given input f-structure F starts with the S rule. Suppose a c-structure and an f-structure of the form depicted in Figure 7 where the C node is mapped to the leftmost G value. The f-structure corresponding to the subderivation 906 aabb ! ! forces the distinguished F , G ,and H attributes to collapse into the simple cycles. Because the rightmost G value is the only position where this structure can be folded up to
F using the annotations of (45e), (45c) has to be applied exactly i a b i c i  X  1 C. With one application of (45e) we obtain F and the sentence a Gen G ( F ) = { a n b n c n | 1  X  n } .
 set drawn from any finite unfolding of a cyclic input structure, but a complete char-acterization of the output strings would require an infinite term set. We have not yet investigated the formal properties of the languages that are related to cyclic structures.
It is an open research question whether a more expressive system (e.g., indexed gram-mars or other forms of controlled grammars) can give a finite characterization of the complete string set and whether our context-free grammar construction can be extended to produce such a formal encoding. 7. Other Descriptive Devices We have shown that the context-free grammar of Definition 16 produces the strings in
Gen G ( F ) for an LFG grammar G that characterizes f-structures by means of equality and function application, the most primitive descriptive devices of the LFG formalism. In this section we extend the grammar-construction procedure so that it produces context-free generation grammars that simulate the other formal devices that were originally proposed by Kaplan and Bresnan (1982). 25 account LFG X  X  devices for enforcing the subcategorization requirements of individual predicates, the completeness and coherence conditions. Both conditions are concerned with the semantic-form PRED icate values that consist of a predicate and a list of gov-ernable grammatical functions, as for example, ' FALL ( SUBJ ) ' with the list ( SUBJ ) and ' JOHN ' with the empty list. An f-structure is complete if each substructure (including the entire structure) that contains a PRED also contains all governable grammatical functions its semantic form subcategorizes for. And an f-structure is coherent if all its governable functions are subcategorized by a local semantic form. If an input f-structure F is not complete and coherent, the LFG derivation relation  X  G does not associate it with any strings, and the set Gen G ( F ) is empty. Thus, when we determine by inspection that an input f-structure fails to satisfy these conditions, we maintain the context-free result by assigning it a trivial grammar that generates the empty context-free language. struction in Section 3.3 produces context-free generation grammars for LFG grammars whose c-structure rules are of an elementary form: Their right-hand sides consist of concatenated sequences of annotated categories, and the equations in the annotation sets are interpreted as simple conjunctions of f-structure requirements. The full LFG notation is more expressive, allowing functional requirements to be stated as arbi-trary Boolean combinations of basic assertions. It also allows the right-hand sides of c-structure rules to denote arbitrary regular languages over annotated categories. Rules with the richer notation can be normalized to rules of the necessary elementary form by simple transformations. First, in the regular right-side of each rule every category
X with a Boolean combination of primitive annotations is replaced by a disjunction of X  X  X  each associated with one of the alternatives of the disjunctive normal form of the original annotation. Then the augmented regular right-sides are converted to a collection of right-linear rewriting rules by systematically introducing new nontermi-nals and their expansions, as described by Chomsky (1959) (see also Hopcroft and
Ullman 1979). The new nonterminals are annotated with  X  = to ensure that f-structure requirements are properly maintained. The result of these transformations is a set of productions all of which are in conventional context-free format and have no internal disjunctions and which together define the same string/ f-structure mapping as a grammar encoded in the original, linguistically more expres-sive, notation.
 are divided into two classes: defining and constraining statements. The constraining statements are evaluated once all defining statements have been processed and a mini-mal model (of the defining statements) has been constructed. The constraining devices introduced by Kaplan and Bresnan (1982) are constraining equations and inequali-ties, and existential and negative existential constraints. If a constraining statement is contained in an f-description FD , it is evaluated against a minimal model M of the defining statements of FD in the obvious way: M | = t = c equation), M | = t iff  X  t ( M | = t = t ) (existential constraint), M of a constraining or defining statement).
 ments by adjusting the definition of IRD F . We modify condition (ii) of Definition 15 so that M |  X  and additionally require M | =  X  for all constraints  X  of Inst ( IR ). Then a context-free grammar based on this revised definition will properly reflect the defining/constraining distinction.
 structions that we used in the proof of our main theorem yield in both proof directions
FD [  X  ] = Inst ( IR root ). As a consequence, the constraining statements in Inst ( IR exactly the ones that result from those in FD by substitution with  X  . Suppose that M and M root are minimal models of the defining part of FD and Inst ( IR
In order to establish also that M satisfies all constraints in FD iff M contained in Inst ( IR root ), it is sufficient to show that M holds for all denoting terms. This follows (with M as M root mapping of term denotations provided by Lemma 2 , a slightly stronger version of
Lemma 2. 908 Lemma 2
Let c and  X  be a derivation with f-description FD and f-structure F in G. If  X  is a reducing parts of FD and FD [  X  ] , respectively, then there is an isomorphism h between M such that h ( I ( t )) = I ( t [  X  ]) for each interpreted term t or t [  X  ] .
Membership in LFG is interpreted just as a binary relation between functional ele-ments, and a model satisfies a membership statement t  X  t iff the membership relation holds between the denotation of t and the denotation of t . Membership statements may introduce daughters that are undefinable in terms of their mother and therefore may be instantiated by C F constants as we illustrated earlier in our treatment of the (  X  ADJ ) = (  X  ELE ) annotation. Then, if we expand the isomorphism-based determina-tion of the equivalence of feature structures and feature descriptions in the usual way to sets and set descriptions, membership statements can be handled by our original construction without further modification. 27 quoted values of PRED attributes in terms of which the completeness and coherence conditions are defined. They are also instantiated, in the sense that for each occurrence of a semantic form in a derivation a new and distinct indexed form is chosen. Because of this special property, semantic forms occurring in annotated rules may be regarded as metavariables that are substituted by the instantiation procedure similar to the familiar  X  and  X  symbols. The distinguishing indices on semantic forms are usually only displayed in a graphical representation of an f-structure if this is necessary for clarity, but distinctively indexed semantic forms are always available for appropriately instantiating the LFG rules, just like the other constants that we draw from the input structure. We can extend the mechanism for controlling the correct instantiation of undefinable daughters to ensure that the semantic forms of all simulated derivations are correctly instantiated. As part of an appropriate instantiation of an LFG rule we also substitute for the prototypical semantic forms in the rule distinct indexed forms, drawn from F , and we expand the compatibility condition to this larger set of instantiations. 8. Consequences and Observations
We have shown that a given LFG grammar can be specialized to a context-free grammar
We can now understand different aspects of generation as pertaining either to the way the specialized grammar G F is constructed or to well-known properties of context-free grammars and context-free generation.

Gen G ( F ) is empty, contains a finite number of strings, or contains an infinite number of strings. This can be determined by inspecting G F with standard context-free tools, once it has been constructed. If the language is infinite, we can make use of the context-free pumping lemma to identify a finite number of short strings from which all other strings can be produced by repetition of subderivations. Wedekind (1995) first established the decidability of LFG generation and proved a pumping lemma for the generated string set; our theorem provides alternative and very direct proofs of these previously known results.
 and Bresnan (1982) showed that the Nonbranching Dominance Condition (sometimes called Off-line Parsability) is a sufficient condition to guarantee decidability of the membership problem. Wedekind noted, however, that this condition is not necessary to determine whether a given f-structure corresponds to any strings. We now see more clearly why this is the case: If there is a context-free derivation for a given string that involves a nonbranching dominance cycle, we know that there is another derivation for that same string that has no such cycle. Thus, the generated language is the same whether or not derivations with nonbranching dominance cycles are allowed. G can be provided to a client as a finite representation of the set of perhaps infinitely many strings that correspond to the given f-structure, and the client can then control the process of enumerating individual strings. The client may choose to produce the shortest ones just by avoiding recursive category expansions. Or the client may apply an n -gram model (Langkilde 2000), a stochastic context-free grammar model (Cahill and van Genabith 2006) or a more sophisticated statistical language model trained on a collection of derivations to identify the most probable derivation and thus the presumably most fluent sentence from the set of possibilities (Velldal and Oepen 2006; de Kok, Plank, and van Noord 2011; Zarrie X , Cahill, and Kuhn 2011).
 analyzed, full-form words. A more modular arrangement is to factor morphological generalizations into a separate formal specification with less expressive power than LFG rules can provide, namely, a regular relation (Karttunen, Kaplan, and Zaenen 1992;
Kaplan and Kay 1994). The analysis of a sentence then consists of mapping the string of words into a string of morphemes to which the LFG grammar is then applied. The full relation between strings of words and associated f-structures is then the compo-sition of the regular morphology with an LFG language over morpheme strings. To generate with such a combined system, we can produce the context-free morpheme strings corresponding to the input f-structure, and then pass those results through the morphology. Because the class of context-free languages is closed under composition with regular relations and regular relations are closed under inversion, the resulting set of word strings will remain context-free.
 that the set of possible instantiations is finite. Dymetman (1991), van Noord (1993), and Wedekind (1999, 2006) have shown that it is in general undecidable whether or not there are any strings associated with a structure that is an arbitrary extension of the f-structure provided as the input. Indeed, our proof of context-freeness does not go through if we allow new elements to be hypothesized arbitrarily, beyond the ones that appear in F ; if this is permitted, we cannot establish a finite bound on the number of possible categories. This is unfortunate, because there may be interesting practical situations in which it is convenient to leave unspecified the value of a particular feature.
If we know in advance that there can be only a finite number of possible values for an underspecified feature, however, the context-free result can still be established. We create from F a set of alternative structures { F 1 , .. , F 910 the unspecified features, and for each of them we produce the corresponding context-free grammar. Because a finite union of context-free languages is context-free, the set of strings generated from any of these structures must again remain in that class.
Of course, this is not a particularly efficient technique: It introduces and propagates features that the grammar may never actually interrogate, and it needlessly repeats the construction of common subgrammars that do not make reference to the alternative fea-ture specifications. The amount of computation may be reduced by adapting methods from the parsing literature that operate on conjunctive equivalents of disjunctive feature constraints (e.g., Karttunen 1984; Maxwell and Kaplan 1991).
 generation. We showed previously that the problem is undecidable in the general case (Wedekind and Kaplan 1996). But our generation result does enable us to make that decision under certain recognizable circumstances, namely, if the intersection of the sentence sets assigned to the different f-structures is computable. This is true if the sentences belong to some formally restricted subsets of the context-free languages, for example, finite sets or regular languages; this is the unstated presupposition of Knight and Langkilde X  X  (2000) parse-forest technique. For a set of f-structures construct the context-free grammars G F i and inspect them with standard context-free each of them meets this condition, we can compute the intersection sentences that are derived ambiguously with f-structures F descriptive devices as originally proposed by Kaplan and Bresnan (1982). In Wedekind and Kaplan (forthcoming) we broaden the grammar-construction procedure so that it produces context-free generation grammars that simulate the more sophisticated mechanisms that were introduced and adopted into later versions of the LFG formalism.
Among these are devices for the f-structure characterization of long-distance depen-dencies and coordination: functional uncertainty (Kaplan and Maxwell 1988a; Kaplan and Zaenen 1989), set distribution for coordination, and the interaction of uncertainty and set distribution (Kaplan and Maxwell 1988b). We also extend to devices whose evaluation depends on properties of the c-structure to f-structure correspondence, namely, functional categories and extended heads (Zaenen and Kaplan 1995; Kaplan and Maxwell 1996) and functional precedence (Bresnan 1995; Zaenen and Kaplan 1995). such as templates, lexical rules, and complex categories (Butt et al. 1996; Kaplan and
Maxwell 1996; Dalrymple, Kaplan, and Holloway King 2004; Crouch et al. 2008); these clearly help in expressing linguistic generalizations but can be formally treated in the obvious way by translating their occurrences into the more basic descriptions that they abbreviate. In contrast, the restriction operator (Kaplan and Wedekind 1993) requires more careful consideration. Restriction can cause the functional information associated with intermediate c-structure nodes not to be included in the f-structures of higher nodes. This is formally quite tractable if the restricted information is provided to the generator as a separately rooted f-structure. Otherwise, the f-structure input is essen-tially underspecified, and thus, as discussed earlier, a context-free generation grammar can be produced just in case restriction can eliminate only a finite amount of information (see also Wedekind 2006).
 formalisms. The PATR formalism also augments a context-free backbone with a set of feature-structure constraints, but it differs from LFG in that its metavariables allow constraints on one daughter to refer directly to sister feature structures that may not be mother-definable. It is relatively straightforward to extend our lemmas and theorem so that they apply to a more general notion of definability that encompasses sisters as well as mothers. We can thus establish the context-free result for a broader family of formalisms that share the property of being endowed with a context-free base. On the other hand, it is not clear whether the string set corresponding to an underlying
Head-driven Phrase Structure Grammar (HPSG) feature structure is context-free. HPSG (Pollard and Sag 1994) does not make direct use of a context-free skeleton, and op-erations other than concatenation may be used to assemble a collection of substrings into an entire sentence. We cannot extend our proof to HPSG unless the effect of these mechanisms can be reduced to an equivalent characterization with a context-free base. Grammars written for the ALE system X  X  logic of typed feature structures (Carpenter and
Penn 1994), however, do have a context-free component and therefore are amenable to the treatment we have outlined.
 for LFG and other higher-order grammatical formalisms with context-free backbones.
Distinguishing the grammar-specialization phase from a string-enumeration phase provides a mathematical framework for understanding the formal properties of the generated string sets. It also provides a framework for analyzing and understanding the computational behavior of existing approaches to generation. Existing algorithms oper-ate properly on restricted grammars and inputs and thus only approximate a complete solution to the problem. They typically implement particular techniques for optimizing the size of the search space and bounding the amount of computation required by the generation process. Our formulation can allow a larger and perhaps more attractive set of candidates to be safely considered, and it also makes available a collection of familiar tools that may suggest new ways of improving algorithmic performance.
 analysis of higher-order generation akin to the richness of our mathematical and com-putational understanding of parsing. The approach outlined in this article, we hope, will serve as a major step in redressing that imbalance.
 Acknowledgments References 912 914
