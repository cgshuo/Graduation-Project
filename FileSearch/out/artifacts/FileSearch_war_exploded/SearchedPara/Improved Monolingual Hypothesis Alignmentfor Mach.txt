 XIAODONG HE Microsoft Research MEI YANG University of Washington and JIANFENG GAO, PATRICK NGUYEN, and ROBERT MOORE Microsoft Research 1. INTRODUCTION System combination has been applied successfully to variou s machine transla-tion tasks. Recently, confusion-network-based system com bination algorithms have been developed to combine outputs of multiple machine t ranslation (MT) systems to form a consensus output [Bangalore et al. 2001; Ma tusov et al. 2006; Rosti et al. 2007a; Sim et al. 2007; Rosti et al. 2008]. A confu sion network com-prises a sequence of sets of alternative words, possibly inc luding empty words, with associated scores. The consensus output is then derive d by selecting one word from each set of alternatives, to produce the sequence w ith the best over-all score, which could be assigned in various ways such as by v oting, by using posterior probability estimates, or by using a combination of these measures and other features.
 as the backbone (also called  X  X keleton X  in the literature), and other hypotheses are aligned to it at the word level. High-quality hypothesis alignment is crucial to the performance of the resulting system combination. How ever, there are two challenging issues that make MT hypothesis alignment di fficult. First, different hypotheses may use different synonymous words to express the same meaning, and these synonyms need to be aligned to each other. Second, correct translations may have different word orderings in differen t hypotheses and these words need to be properly reordered in hypothesis alig nment. hypothesis alignment. The HMM provides a way to model both sy nonym matching and word ordering. Unlike traditional HMMs whose p arameters are trained via maximum likelihood estimation (MLE), the pa rameters of the IHMM are estimated indirectly from a variety of sources incl uding word se-mantic similarity, word surface similarity, and a distance -based distortion penalty, without using large amounts of monolingual parall el training data. Our combined SMT system using the proposed method gave the be st result on the Chinese-to-English test in the constrained training tr ack of the 2008 NIST Open MT Evaluation (MT08). 2. CONFUSION-NETWORK-BASED MT SYSTEM COMBINATION The current state-of-the-art is confusion-network-based MT system combina-tion as described by Rosti and colleagues [Rosti et al. 2007a ; 2007b; 2008]. As described in Rosti et al. [2007a], the major steps are illust rated in Figure 1. In Figure 1(a), hypotheses from different MT systems are firs t collected. Then in Figure 1(b), one of the hypotheses is selected as the backb one for hypoth-esis alignment. This can be done by a sentence-level minimum Bayes risk (MBR) method which selects a hypothesis that has the minimum average dis-tance compared to all hypotheses. The backbone determines t he word order of the combined output. Then as illustrated in Figure 1(c), all other hypotheses are aligned to the backbone. Note that in Figure 1(c) the symb ol  X  denotes an empty word null , which is inserted by the alignment normalization algo-rithm described in Section 3.4. Figure 1(c) also illustrate s the handling of synonym alignment (e.g., aligning  X  X ar X  to  X  X edan X ), and wo rd reordering of the hypothesis. Then in Figure 1(d), a confusion network is cons tructed based on the aligned hypotheses, which consists of a sequence of sets in which each word is aligned to a list of alternative words (including null) in the same set. Then, a set of global and local features are used to decode the confu sion network. 3. INDIRECT-HMM-BASED HYPOTHESIS ALIGNMENT In confusion-network-based system combination for SMT, a m ajor difficulty is aligning hypotheses to the backbone [Matusov et al. 2006; Ro sti et al. 2007a; Sim et al. 2007]. One possible statistical model for word ali gnment is the HMM, which has been widely used for bilingual word alignment [Vogel et al. 1996; Och and Ney 2003]. In this article, we propose an indire ct-HMM method for monolingual hypothesis alignment. 3.1 IHMM for Hypothesis Alignment the backbone word aligned to each hypothesis word. We treat e ach word in the backbone as an HMM state and the words in the hypothesis as the observation sequence. We use a first-order HMM, assuming that the emissio n probabil-ity p ( e  X  j | e a backbone. Treating the alignment as hidden variable, the co nditional proba-bility that the hypothesis is generated by the backbone is gi ven by sociate a null with each backbone word to allow generating hy pothesis words that do not align to any backbone word.
 ilarity between a backbone word and a hypothesis word and wil l be referred to as the similarity model. The transition probabilities mo del word reordering and will be called the distortion model. 3.2 Estimation of the Similarity Model The similarity model, which specifies the emission probabil ities of the HMM, models the similarity between a backbone word and a hypothes is word. Since both words are in the same language, the similarity model can be derived based on both semantic similarity and surface similarity, and the overall similarity model is a linear interpolation of the two: tween e  X  j and e i , respectively, and  X  is the interpolation factor. dependent, the semantic similarity model is derived by usin g the source word sequence as a hidden layer: where f K 1 = ( f 1 , . . . , f K ) is the source sentence. Moreover, in order to handle the case that two target words are synonyms but neither of the m has counter-part in the source sentence, a null is introduced on the sourc e side, which is represented by f 0 . The last step in Equation (3) assumes that first e i gener-ates all source words including null. Then e  X  j is generated by all source words including null.
 data is available, we can estimate the translation probabil ities from a source word to a target word and vice versa via conventional bilingu al word align-ment. Then both p ( f k | e i ) and p ( e  X  j | f k ) in Equation (3) can be derived: ment model, and p ( f k | e i ) , which need to enforce the sum-to-1 constraint over all words in the source sentence, takes the following form, p null , whose value is optimized on held-out data. 1 simple model could be based on exact match: the surface simil arity model, p sur ( e  X  j | e i ), would take the value 1.0 if e  X  = e , and 0 otherwise. 2 However, a smoothed surface similarity model is used in our method. If t he target lan-guage uses alphabetic orthography, as English does, we trea t words as letter sequences and the similarity measure can be the length of the longest matched prefix (LMP) or the length of the longest common subsequence ( LCS) between them. Then, this raw similarity measure is transformed to a s urface similarity score between 0 and 1 through an exponential mapping, where s ( e  X  j , e i ) is computed as LMP or LCS of e  X  j and e i . and  X  is a smoothing factor that characterizes the model. We found the smoothed similarity model of Equation (4 ) yields slightly better results than the exact match model. Both LMP-and LCS-based methods achieve similar performance but the computation of LMP is fa ster. Therefore, we only report results of the LMP-based smoothed similarity model. 3.3 Estimation of the Distortion Model The distortion model, which specifies the transition probab ilities of the HMM, models the first-order dependencies of word ordering. In bil ingual HMM-based word alignment, it is commonly assumed that transition prob abilities p ( a j = i | a j  X  1 = i  X  , I ) depend only on the jump distance ( i  X  i  X  ) [Vogel et al. 1996]: with jump distance larger than 6 and less than -4 is uniformly divided. By do-ing this, only a handful of c ( d ) parameters need to be estimated. Although it is possible to estimate them using the EM algorithm on a small de velopment set, we found that a particularly simple model, described below, works surprisingly well in our experiments.
 seems intuitive that the distortion model should favor mono tonic alignment and only allow nonmonotonic alignment with a certain penalt y. This leads us to use a distortion model of the following form, where K is a tuning factor optimized on held-out data. the monotonic alignment, and decays for nonmonotonic align ments depending on how far it diverges from the monotonic alignment.
 of jumping to a null state, which can be optimized on held-out data, and the overall distortion model becomes 3.4 Alignment Normalization Given an HMM, the Viterbi alignment algorithm can be applied to find the best alignment between the backbone and the hypothesis, to build a confusion network. There are two reasons for this. First, the align-ment produced may contain 1-N mappings between the backbone and the hypothesis whereas 1-1 mappings are required in order to bui ld a confusion network. Second, if hypothesis words are aligned to a null in the backbone or vice versa, we need to insert actual nulls into the right plac es in the hypothesis and the backbone, respectively. Therefore, we need to norma lize the alignment produced by Viterbi search.
 bone word, we keep the link which gives the highest occupatio n probability computed via the forward-backward algorithm. The other hyp othesis words originally aligned to the backbone word will be aligned to th e null associated with that backbone word.
 backbone side, a set of nulls are inserted around that backbo ne word associated with the null such that no links cross each other. As illustra ted in Figure 3(a), if a hypothesis word e  X  2 is aligned to the backbone word e 2 , a null is inserted in front of the backbone word e 2 linked to the hypothesis word e  X  1 that comes before the backbone word e 2 . If there is no hypothesis word aligned to that backbone word, all nulls are inserted after that backbone word. 3 on the hypothesis side, right after the hypothesis word whic h is aligned to the immediately preceding backbone word. An example is shown in Figure 3(b). 3.5 Construction of the Confusion Network After all hypotheses being aligned to the backbone, a confus ion network can be constructed. This is done in a left-to-right fashion. First , all deletions in the hypotheses are replaced with the empty word null such that al l deletions are converted to substitutions, that is, a real word in the backb one substituted by a null word in the hypothesis. Then a position point is assign ed to each hy-pothesis. For each hypothesis, the position that the point p oints to is called the  X  X urrent X  position and the word at the current position is ca lled the  X  X urrent X  word. Each of these points is initially assigned to the begin ning of the associ-ated hypothesis.
 a new column is formed consisting of either a null word for a hy pothesis that doesn X  X  have insertion at the current position, or the curre nt word for a hy-pothesis that does have insertion. Then for hypotheses that have the inser-tion, the position points will move forward one step; if ther e are no insertions, a new column is formed consisting of all the current words fro m all hypotheses and all position points move forward one step. This process g oes on until all position points reach the end of the corresponding hypothes es and at the end the confusion network is constructed. 4. RELATED WORK The two main hypothesis alignment methods for system combin ation in the previous literature are GIZA++ and TER-based methods. M atusov et al. [2006] proposed using GIZA++ to align words between differe nt MT hypothe-ses, where all hypotheses of the test corpus are collected to create hypothesis pairs for GIZA++ training. This approach uses the conventio nal HMM model bootstrapped from IBM Model-1 as implemented in GIZA++, and heuristically combines results from aligning in both directions. System c ombination based on this approach gives an improvement over the best single sy stem. However, the number of hypothesis pairs for training is limited by the size of the test cor-pus. Also, MT hypotheses from the same source sentence are co rrelated with each other and these hypothesis pairs are not i.i.d. data sam ples. Therefore, GIZA++ training on such a data set may be unreliable.
 Levenshtein edit distance, and later Sim et al. [2007] and Ro sti et al. [2007a] extended it to a TER-based method for hypothesis alignment. TER [Snover et al. 2006] measures the minimum number of edits, including substitution, insertion, deletion, and shift of blocks of words that are ne eded to modify a hy-pothesis so that it exactly matches the other hypothesis. Th e best alignment is the one that gives the minimum number of translation edits . TER-based confusion network construction and system combination has demonstrated su-perior performance on various large-scale MT tasks [Rosti e t al. 2007b]. How-ever, when searching for the optimal alignment, the TER-bas ed method uses a strict surface hard match for counting edits. Therefore, i t is not able to handle synonym matching well. Moreover, although TER-base d alignment al-lows phrase shifts to accommodate the nonmonotonic word ord ering, all non-monotonic shifts are penalized equally no matter how short o r how long the move is, and this penalty is set to be the same as that for subst itution, deletion, and insertion edits. Therefore, its modeling of nonmonoton ic word ordering is very coarse-grained.
 sis alignment. The surface similarity information is used t o initialize the GIZA++ models and then the models are trained on hypothesis-pairs. How-ever, it is not clear how much of that information is still kep t in the models after following unsupervised maximum likelihood training . In contrast to the GIZA++-based method, our IHMM-based method has a similarit y model es-timated using bilingual word alignment HMMs that are traine d on a large amount of bi-text data. Moreover, the surface similarity in formation is explic-itly incorporated in our model. On the other hand, the TER-ba sed alignment model is similar to a coarse-grained, non-normalized versi on of our IHMM, in which the similarity model assigns no penalty to an exact sur face match and a fixed penalty to all substitutions, insertions, and deletio ns, and the distortion model simply assigns no penalty to a monotonic jump, and a fixe d penalty to all other jumps, equal to the non-exact-match penalty in the similarity model. proposed using ITGs to find the optimal edit sequence under th e restric-tion that block moves must be properly nested, so as to align h ypothesis to the backbone. Rosti et al. [2008] proposed an incremental TE R alignment method which allows using a confusion network as the alignme nt reference. In Jayaraman and Lavie [2005], a heuristic-based matching a lgorithm was proposed. 5. EXPERIMENTAL RESULTS In this section, we evaluate our IHMM-based hypothesis alig nment method on the Chinese-to-English (C2E) test in the constrained tra ining track of the 2008 NIST Open MT Evaluation [NIST 2008]. We compare to the TE R-based method used by Rosti et al. [2007a]. In the following experim ents, the NIST BLEU score is used as the evaluation metric [Papineni et al. 2 002], which is reported as a percentage in the following sections. 5.1 Implementation Details In our implementation, the backbone is selected with MBR. On ly the top hy-pothesis from each single system is considered as a backbone . A uniform pos-teriori probability is assigned to all hypotheses. TER is us ed as loss function in the MBR computation.
 ated with a word posterior probability. Given a system S , each of its hypotheses is assigned with a rank-based score of 1/(1+r)  X  , where r is the rank of the hy-pothesis, and  X  is a rank smoothing parameter. The system specific rank-base d score of a word w for a given system S is the sum of all the rank-based scores of the hypotheses in system S that contain the word w at the given position (after hypothesis alignment). This score is then normalized by the sum of the scores of all the alternative words at the same position and from the same system S to generate the system specific word posterior. Then, the tot al word posterior of w over all systems is a sum of these system specific posteriors w eighted by system weights.
 as features for confusion network decoding.
 N +1 decoding parameters, including M -1 system weights, one rank smoothing factor, N language model weights, and one weight for the word count fea ture, are optimized using Powell X  X  method [Brent 1973] to maximiz e BLEU score on a development set. 4 estimated from the English side of the parallel training dat a, and the other is a 5-gram model trained on the English GigaWord corpus from LD C using the MSRLM toolkit [Nguyen et al. 2007].
 are from the word-dependent HMMs proposed by He [2007], whic h are trained on two million parallel sentence-pairs selected from the tr aining corpus al-lowed by the constrained training condition of MT08.
 translation output length, an unsupervised length adaptat ion method has been devised. We compute an expected length ratio between the MT o utput and the source sentences on the development set after maximum-BLEU training. Then during the test, we adapt the length of the translation outpu t by adjusting the weight of the word count feature such that the expected outpu t/source length ratio is met. In our experiments, we apply length adaptation to the system combination output at the level of the whole test corpus. 5.2 Development and Test Data The development (dev) set used for system combination param eter training contains 1,002 sentences sampled from the previous NIST MT C hinese-to-English test sets: 35% from MT04, 55% from MT05, and 10% from M T06-newswire. The test set is the MT08 Chinese-to-English curre nt test set, which includes 1,357 sentences from both newswire and Web-data ge nres. Both dev and test sets have four references per sentence.
 sentence in the dev and test sets are collected from each of th e eight single systems. All outputs on the MT08 test set were true-cased bef ore scoring using a log-linear conditional Markov model proposed by Toutanov a et al. [2008]. However, to save computation effort, the results on the dev s et are reported in case insensitive BLEU (ciBLEU) score instead. 5.3 Description of Individual Systems for System Combinati on There are eight individual systems incorporated in the syst em combination framework. They are named from Sys-1 to Sys-8, respectively . All systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. In the following subsections, we give a bri ef description of each system. and Menezes 2007], informed by a source language dependency parse (Chinese). The Chinese text is segmented using a Semi-CRF Ch inese word breaker trained on the Penn Chinese Treebank [Andrew 2006], then POS-tagged using a feature rich Maximum Entropy Markov Model, an d parsed using a dependency parser trained on the Chinese Treebank [C orston-Oliver et al. 2006]. The English side is segmented to match the inter nal tokeniza-tion of the reference BLEU script. Sentences are word aligne d using an HMM with word-based distortion [He 2007], and the alignments ar e combined us-ing the grow-diag-final method. Treelets, templates, and or der model training instances are extracted from this aligned set; treelets are annotated with rela-tive frequency probabilities and lexical weighting scores .
 target side of the training data, a medium-sized LM built on o nly the Xinhua portion of the English Gigaword corpus, and a large LM built o n the whole English Gigaword corpus using a scalable LM toolkit [Nguyen et al. 2007]. It also has treelet count, word count, order model logprob, and template logprob features. At decoding time, the 32 best parses for each sente nce are packed into a forest; packed forest transduction is used to find the b est translation. The decoder uses a beam search to produce translation candid ates left-to-right, incorporating future distortion penalty estimation and ea rly pruning to limit the search [Moore and Quirk 2007]. The data is segmented and a ligned in the same manner as above. Phrases are extracted and provided wit h conditional model probabilities of source given target and target given source (estimated with relative frequency), as well as lexical weights in both directions. In addi-tion, word count, phrase count, and a simple distortion pena lty are included as features. as Sys-2 except that we apply a syntactic reordering system a s a preprocessor to reorder Chinese sentences in training and test data in suc h a way that the reordered Chinese sentences are much closer to English in te rms of word order. For a Chinese sentence, we first parse it using the Stanford Ch inese Syntactic Parser [Levy and Manning 2003], and then reorder it by applyi ng a set of reordering rules, proposed by Wang et al. [2007a], to the par se tree of the sentence. ordering based MT system using a syntax-based preordering m odel as de-scribed in Li et al. [2007]. Given a source sentence and its pa rse tree, the method generates, by tree operations, an n -best list of reordered inputs, which are then fed to a standard phrase-based decoder to produce th e optimal trans-lation. In implementation, the Stanford parser [Levy and Ma nning 2003] is used to parse the input Chinese sentences.
 of MSRSeg tool [Gao et al. 2005] is used to perform Chinese seg mentation. Moreover, we recognize certain named entities such as numbe r, data, time, person/location names. For those named entity, translatio ns are generated by rules or lexicon look-up. These translations serve as part o f the hypotheses of the translation of the entire sentence. The decoder is a lexi calized maxent-based decoder. Note that nonmonotonic translation is used h ere since the distance-based model is needed for local reordering. A 5-gr am language model is used, which is trained on the Xinhua part of English Gigawo rd version 3. In order to obtain the translation table, GIZA++ is run over t he training data in both translation directions, and the two alignment matri ces are integrated by the grow-diag-final method into one matrix, from which phr ase translation probabilities and lexical weights of both directions are ob tained. Regarding to the distortion limit, our experiments show that the optimal distortion limit is 4, which was therefore selected for all our later experiment s. based system as described by Chiang [2007]. It uses a statist ical phrase-based translation model that uses hierarchical phrases. The mode l is a synchronous context-free grammar and it is learned from parallel data wi thout any syntac-tic information.
 described in Section 5.3.4 was adopted, as well as the langua ge models and the handling of named entities. model similar to the one described by Xiong et al. [2006]. It u ses a maximum entropy model to predicate reordering of neighbor blocks (p hrase pairs). The same word segmentation, word alignment, language model, an d the handling of named entities were adopted as described in Section 5.3.4 . system with adapted LM proposed by Foster and Kuhn [2007]. Th is system uses a standard two-pass phrase-based approach. Major feat ures in the first-pass log-linear model include phrase tables derived from sy mmetrized IBM2 and HMM word alignments, a static 5-gram LM trained on the Gig a-word cor-pus using the SRILM toolkit, and an adapted 5-gram LM derived from the parallel corpus using the technique of Foster and Kuhn [2007 ]. Other fea-tures are word count and phrase-displacement distortion. D ecoding uses the cube-pruning algorithm of Huang and Chiang [2007] and param eter tuning is performed using Och X  X  max-BLEU algorithm with a closest-match brevity penalty. The rescoring pass uses 5,000 best lists, with addi tional features in-cluding various HMM-and IBM-model probabilities; word, ph rase, and length posterior probabilities; Google ngrams; reversed and cach e LMs; and quote and parenthesis mismatch indicators. that uses a 4-gram language model in the first pass to generate n -best lists, which are rescored by three additional language models to ge nerate the final translations via re-ranking. The preprocessor performs ru le-based transla-tion for number, date and time expressions, as well as some cl eanup. The translation engine is a CKY-style decoder, which performs p arsing and genera-tion simultaneously guided by a language model and synchron ous context-free grammars (SCFGs). The SCFGs are extracted from parallel tex t with word alignments generated by GIZA++, in the similar manner descr ibed by Chiang [2007]. The three rescoring language models include a count -based LM from Google Tera-word corpus, an almost parsing class LM based on SARV tags, and an approximated parser based LM [Wang et al. 2007b].
 on different subsets of the previous NIST MT test data.
 5.4 Experimental Results smoothing factor for surface similarity model is set to  X  = 3, the interpolation factor of the overall similarity model is set to  X  = 0 . 3, and the controlling factor of the distance-based distortion parameters is set to K = 2. These settings are optimized on the dev set. Individual system results and syst em combination results using both IHMM and TER alignment, on both the dev and test sets, are presented in Table I. The TER-based hypothesis alignmen t tool used in our experiments is the publicly available TER Java program, TER COM [Snover et al. 2006]. Default settings of TERCOM are used in the follo wing experi-ments.
 way system combination output is about 5.8 points higher tha n that of the best single system. Compared to the TER-based method, the IHMM-b ased method is approximately 1.5 BLEU points better. On the MT08 test set , the IHMM-based system combination gave a case sensitive BLEU score of 30.89%. It outperformed the best single system by 4.7 BLEU points and th e TER-based system combination by 1.0 BLEU points. Note that the best sin gle system on the dev set and the test set are different. The different sing le systems are optimized on different tuning sets, so this discrepancy bet ween dev set and test set results is presumably due to differing degrees of mi smatch between the dev and test sets and the various tuning sets.
 systems, we collected MT outputs on MT08 from seven addition al single sys-tems as summarized in Table II. These systems belong to two gr oups. Sys-9 to Sys-12 are in the first group. They are syntax-augmented hier archical systems similar to those described by Shen et al. [2008] using differ ent Chinese word segmentation and language models. The second group has Sys-13 to Sys-15. Sys-13 is a phrasal system proposed by Koehn et al. [2003], Sy s-14 is a hierar-chical system proposed by Chiang [2007], and Sys-15 is a synt ax-based system proposed by Galley et al. [2006]. All seven systems were trai ned within the confines of the constrained training condition of NIST MT08 e valuation. extra systems. No MT outputs on our dev set are available from them at present. Therefore, we directly adopt system combination p arameters trained for the previous eight-way system combination, except the s ystem weights, which are reset by the following heuristics: First, the tota l system weight mass 1.0 is evenly divided among the three groups of single system s: { Sys-1  X  8 } , { Sys-9  X  12 } , and { Sys-13  X  15 } . Each group receives a total system weight mass of 1/3. Then the weight mass is further divided in each gr oup: in the first group, the original weights of systems 1  X  8 are multiplied by 1/3; in the sec-ond and third groups, the weight mass is evenly distributed w ithin the group, that is, 1/12 for each system in group 2, and 1/9 for each syste m in group 3. 5 Length adaptation is applied to control the final output leng th, where the same expected length ratio of the previous eight-way system comb ination is adopted. shows that the IHMM-based method is still about 1 BLEU point b etter than the TER-based method. Moreover, combining 15 single system s gives an out-put that has a NIST BLEU score of 34.82%, which is 3.9 points be tter than the best submission to the NIST MT08 constrained training track [NIST 2008]. To our knowledge, this is the best result reported on this task. of the semantic similarity model and the surface similarity model by varying the interpolation weight  X  of Equation (2). The results on both the dev and test sets are reported in Table IV. semantic similarity. This gives a case insensitive BLEU sco re of 41.70% and a case sensitive BLEU score of 28.92% on the dev and test set, re spectively. The accuracy is significantly improved to 43.62% on the dev set an d 30.89% on test set when  X  = 0 . 3. In another extreme case,  X  = 0, in which only the surface similarity model is used for the overall similarity model, t he performance de-grades by about 0.2 point. Therefore, the surface similarit y information seems more important for monolingual hypothesis alignment, but b oth submodels are useful. distance-based distortion model by varying the controllin g factor K in Equa-tion (6). For example, setting K = 1 . 0 gives a linear-decay distortion model, and setting K = 2 . 0 gives a quadratic smoothed distance-based distortion mod el. As shown in Table V, the optimal result can be achieved using a properly smoothed distance-based distortion model. adaptation is applied to system combination to reduce the flu ctuation of BLEU scores caused by the inconsistent translation output lengt h. In this section, we investigate the effect of length adaptation measured by the BLEU score. The IHMM-based method is used in the experiments in this section .
 dev/test mismatch condition, we collect a different dev set , called dev mix , for system combination model training. Unlike the previous dev set which con-tains only newswire data, this dev mix set contains 501 newswire sentences generated in a similar way as dev , plus 483 sentences of newsgroup/web data from NIST MT06 test set. Therefore, the dev mix is more consistent with the test data MT08, which also contains both newswire and web dat a.
 ported because that dev mix contains data different from dev so the results are not comparable. However, the results on the test set are c omparable and are presented.
 ment and test sets, the feature weights max-BLEU-trained on the development set may not be suitable for the test data and may lead to biased output length which causes heavy brevity penalty on the BLEU score on the te st set. After length adaptation, the system is encouraged to output a tran slation that has more consistent hyp/src ratio and achieve a better result. In this section two real examples from our eight-way IHMM bas ed system com-bination experiment are presented. As shown in the examples , in some cases the algorithm is able to pick the best translation among the m ultiple hypothe-ses, and sometimes it can compose a translation better than t he best hypothe-ses from any of the individual systems. Note that the best hyp otheses are not always from the same single system. For example, the best sin gle system in example 1 is SYS-5, while in the second example SYS-1 gets mos t of the trans-lation text right. 6. DISCUSSION Synonym matching and word ordering are two central issues fo r hypothesis alignment in confusion-network-based MT system combinati on. In this article, an IHMM-based method is proposed for hypothesis alignment. It uses a simi-larity model for synonym matching and a distortion model for word ordering. In contrast to previous methods, the similarity model expli citly incorporates both semantic and surface word similarity, which is critica l to monolingual word alignment, and a smoothed distance-based distortion m odel is used to model the first-order dependency of word ordering, which is s hown to be better than simpler approaches.
 method gave superior results on the NIST MT08 C2E test set com pared to the TER-based method. Moreover, we show that our system combina tion method can scale up to combine more systems and produce a better outp ut that has a case-sensitive BLEU score of 34.82, which is 3.9 BLEU points better than the best official submission of MT08.
 The authors are grateful to Chris Quirk, Arul Menezes, Krist ina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Neci p Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and d iscussions.
