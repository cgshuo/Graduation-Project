 Timeline generation is an important research task which can help users to have a quick understanding of the overall evolution of any given topic. It thus attracts much attention from research commu-nities in recent years. Nevertheless, existing work on timeline gen-eration often ignores an important factor, the attention attracted to topics of interest (hereafter termed  X  X ocial attention X ). Without tak-ing into consideration social attention, the generated timelines may not re fl ect users X  collective interests. In this paper, we study how to incorporate social attention in the generation of timeline sum-maries. In particular, for a given topic, we capture social attention by learning users X  collective interests in the form of word distri-butions from Twitter, which are subsequently incorporated into a uni fi ed framework for timeline summary generation. We construct four evaluation sets over six diverse topics. We demonstrate that our proposed approach is able to generate both informative and in-teresting timelines. Our work sheds light on the feasibility of in-corporating social attention into traditional text mining tasks. H.4 [ Information Systems Applications ]: Miscellaneous Algorithms, Performance, Evaluation Timeline, social media attention, user interest
Timelines [3, 1, 5] provide temporal summaries of the evolution of news stories related to a topic, which are often desirable for users who do not closely follow news and want to quickly gain an overall picture of the major events related to a topic. Typically, sentences which describe major events are extracted in chronological order to form timeline summaries. We show an example timeline presenta-
Recently, Yan et al. proposed a task of automatically generating evolutionary timeline summaries [5, 4]. They formally formulated the task as an optimization problem via iterative sentence substi-tution in order to maximize the objective function with four fac-tors: relevance, coverage, coherence and cross-date diversity [5]. In [4], Yan et al. further extended the work by modeling inter-date and intra-date dependencies between timestamped sentences, and incorporating these two kinds of dependencies into a sentence ranking function.

The timeline summaries generated in [5, 4] are mainly based on semantic information and do not necessarily re fl ect the public at-tention an event has attracted. In Table 1, we can observe that not all the events described by the summary sentences receive equal so-cial attention, as evidenced by the number of related tweets listed in the  X  X otness X  column. Since the timeline summaries are usually kept succinct, it is desirable to present sentences which are likely to attract the attention of the majority of users. With today X  X  social web, it is possible to obtain the social attention signals from social media content such as Twitter feeds.

In this paper, we study how to capture social attention and incor-porate it into the generation of timeline summaries. The  X  X otness X  column in Table 1 reveals that there is a very skewed social at-tention distribution over the events described by the summary sen-tences in the example timeline. Millions of users engage in a di-verse range of activities on the social web such as posting status messages and interacting with items generated by others, for exam-ple, forwarding messages. These activities are often interest driv-en. Thus learning from online social media could be a good way to capture social attention. In our proposed method, users X  collective interests are learned from the Twitter data, and are represented as pseudo sentences. We run a modi fi ed graph-based method to prop-agate collective interest biased scores, which represent a trade-off between informativeness and interestingness, i.e., users X  collective interests.

To the best of our knowledge, it is the fi rst study which utilizes social attention to improve both the informativeness and interest-ingness of timeline summaries. We evaluate our method on four datasets constructed from Twitter and compare it with a number of state-of-the-art timeline generation methods. Our experimen-tal results show that by considering social attention, the proposed method for timeline summary generation gives better performance in terms of both informativeness and interestingness.
For our timeline summarization problem, we assume the follow-ing input data are available.

Time span: A time span I =( t s ,t e ) is de fi nedbyastarttime t and an end time t e .
 Query: A user issues a query Q = { q 1 ,q 2 ,...,q |Q| } within I to the timeline summarization system, where q i denotes a query word in the vocabulary V .
 News articles: We assume that news articles related to Q within I have been retrieved. We represent these relevant news articles as a set of sentences C . Each sentence in C has a timestamp (e.g. Table 1: Timeline summaries between July and December 2009 on  X  X obel Prize" generated by professional editors.
 the publish date) and C t denotes a collection of sentences at the t th time point.

Tweets: We also assume that we can retrieve a set of tweets published within I and relevant to Q .Weuse C to represent these tweets. Similarly, each tweet in C also has a timestamp.
Given the input speci fi ed above, the system is expected to gen-erate the following output: for each time point t  X  I , the system generates a summary R t , which consists of a set of news sentences from C t . All the generated summaries are expected to capture the most important information and meanwhile attract considerable so-cial attention about the topic within I . It is worth noting that we do not select sentences from tweets since our aim here is to generate a timeline summary which has a good coverage of the most promi-nent events happened related to a speci fi c topic. We only use tweets to derive social attention signals.
We propose a novel approach to capture social attention from tweets through learning users X  collective interests by a generative mixture model. We then show how to incorporate the learned col-lective interests into a state-of-the-art timeline generation algorith-m.
Existing timeline generation methods only consider news stream-s. Hence, the timeline summaries generated do not re fl ect users X  collective interests in the real world. We propose to learn users X  collective interests from the Twitter. We assume that we can obtain a set of relevant tweets relating to users X  queries at each time point in a time span I . It is worth mentioning that we do not attempt to discover individual user X  X  interests, instead, we aim to identify the most prominent collective interests of the majority.

Formally, let C t denote all the tweets at time point t , our aim is to learn a collective interest model  X  U,t from C t . 2 We notice that tweets are often noisy and contain many background words ( home, good, time, lol, love, etc. ) which are not relating to users X  topical interest with respect to a given query . Thus, words in C can be clustered into two groups, words closely related to a spe-ci fi c query topic and general background words. We assume that words in C t are generated either from a model  X  U which represents users X  collective topical interest or from a general background mod-el  X  B . With this model, we can reduce the effects of background words and learn a model which better captures words concentrat-ing around users X  collective interests. We further assume that both  X 
U and  X  B are represented as multinomial distributions over the vocabulary. This kind of two-mixture model has been shown to be effective in pseudo relevance feedback for information retrieval [6]. With the two-mixture model, we have where  X  is the probability (weight) that a word w i in C t from the general background model. A large  X  tends to make the interest-related language model more discriminative because more general words are generated from the background model. In prac-tice, we can set  X  empirically and fi x it during the learning process. Let c ( w, C t ) be the count of word w in C t and V be the vocabulary of the corpus, we then have
Usually the background model  X  B can be estimated directly from the entire tweet collection using maximum likelihood estimation. After deriving  X  B and fi xing  X  , we can use the expectation max-imization (EM) algorithm to estimate the collective interest lan-guage model. The updating formulae of the E-step and the M-step are shown below:
After obtaining the interest-related model  X  U , we can easily trans-form it into a vector by simply setting the weight of each word dimension to the word X  X  corresponding probability in  X  U . Such a vector can be treated as a pseudo sentence which describes users X  collective interests at a time point t . 3
We will fi rst give a brief introduction of a timeline generation algorithm, denoted as ETTS, which was proposed in [4]. Then we will present how to incorporate the learnt collective interests into ETTS. It is noteworthy that our proposed method can be easily incorporated into any other graph based summarization algorithms.
Given a news collection C partitioned according to the start/end time speci fi ed in a time span I ,i.e. C = {C t } t  X  I , we split each news article into sentences for each C t . At a time point t , we refer to sentences with timestamp t as local sentences and sentences with other timestamps as global sentences. ETTS models the inter-date and intra-date dependencies between the timestamped sentences and incorporate these two types of correlations into a sentence rank-ing function.
 Specially, ETTS constructs two probability transition matrices. One is for modeling global af fi nity and the other is for modeling local af fi nity. For global af fi nity, it means that summary sentences should be correlative with sentences from neighboring dates to cap-ture the overall topic evolution patterns, i.e., inter-date dependency. To allow the modeling of global af fi nity, global sentences are tem-porally projected onto time point t such that links between local and global sentences can be built. For local af fi nity, it means intra-date dependency, i.e., the timeline summary at time point t should be informative within C t , and links are built between local sentences. With these two transition matrices, both the global and local af fi nity propagation can be run using the standard LexRank algorithm. At time point t , a set of global ranking R g = { r ( g ) i } and local rank-ing R l = { r ( l ) i } of sentences in C t are obtained. ETTS then uses an optimization algorithm to combine both the global and the local rankings, and the fi nal ranking of sentence s i  X  X  t is a weighted combination between its global ranking and local ranking where 0  X   X  , 0  X   X  .  X  and  X  can be tuned on different date sets to make a tradeoff between global scores and local scores. See [4] for a detailed description of ETTS.
 Now we study how to incorporate users X  collective interests into ETTS. Note that regardless of the modeling of either global af fi n-ity or local af fi nity, we can formulate both problems in a standard LexRank form where  X  is the saliency score vector of sentences, M is the transi-tion probability matrix and y is the restart probability vector usu-ally set to be uniform. The main idea is that instead of using a uniform restart distribution y , we use an interest biased restart dis-tribution. Recall that at each time point, we have modeled users X  collective interests as a pseudo sentence. We can add a new vertex which represents such a pseudo sentence at that time point. It can be naturally incorporated into the above LexRank algorithm. We build the similarity links between the interest-related pseudo sen-tence and all the local sentences using the cosine similarity mea-surement. At the beginning of each iteration of LexRank, this pseu-do sentence has a large restart probability to be visited. During the learning process, it gradually propagates the interest-related score to other similar vertices. Letting v 0 to denote the vertex represent-ing users X  collective interest, each entry of y =[ y 0 , y ] can be modi fi ed as follows where  X  is a positive factor and N is the number of candidate sen-tences. For v 0 , i.e., the pseudo sentence representing users X  collec-tive interest, it has a large restart probability of  X  , while any of the other vertices has a smaller restart probability of 1  X   X  controls the trade-off between informativeness and interestingness; the larger it is, the more emphasis we put on interestingness. We use  X  g and  X  l to denote the corresponding values of  X  for glob-al af fi nity ranking and local af fi nity ranking. In our experiments, we simply set  X  g =  X  l . In traditional LexRank, the ranking score only indicates informativeness, while our interest biased LexRank makes a trade-off between informativeness and interestingness. Data collection. Since our summarization algorithm is query de-pendent, we selected six topics to cover a few important news events according to the Rule of Interpretation (ROI) category (Table 2). We then constructed corpora of news articles and tweets for each of the topics. For news articles, we submitted the topic queries in-between July, 2009 and December, 2009. For tweets, we use the articles into sentences and fi ltered those news sentences and tweets with too many or too few word tokens. The statistics of the datasets is summarized in Table 2.
 Gold standard generation. We manually constructed the gold s-tandard for these six topics, including both the informativeness-oriented and the interestingness-oriented sets. Informativeness-ori-ented set , similar to the evaluation of timeline summaries [4] and Table 2: Statistics of the datasets. We used the topic words in the fi rst column as the queries to obtain relevant tweets and news sentences.
 traditional summarization [2], requires a system to return informa-tive and relevant news sentences to cover important aspects given a query topic. We select various authoritative sources to generate the gold standard timelines, including mainstream news media (Chi-For each topic, we fi rst extracted the timelines from the profession-al editors in at least two kinds of resources mentioned above. Then we invited a human judge to merge the information from different resources by removing redundant sentences. Finally, 25  X  35 sen-tences were kept for each topic as gold standard. We denote this set as D .

Since the informativeness-oriented set does not consider the so-cial attention of the generated timelines, it may not re fl ect users X  collective interests. We thus further constructed interestingness-oriented sets by removing less  X  X nteresting" sentences from D .A sentence is considered to be interesting if it attracts a considerable amount of social attention. We invited 6 graduate students major in journalism for evaluation. Every volunteer was asked to remove top K least interesting sentences from D for each topic query. For each sentence in D , a volunteer was required to refer to news portals (for report volume) and online social websites (for social attention) be-fore making the judgement. We merged the results from six judges and reordered the sentences according to their total votes. To eval-uate interestingness at different levels, we set K to 5, 10 and 15, for which we respectively removed the top 5, 10 and 15 sentences that the judges considered to be less interesting from D .Insuch a way we ended up with another three gold standard sets, D D  X  10 and D  X  15 . For each topic, we computed the average pair-wise agreement of six judges over the top 5/10/15 less interesting sentences, and obtained the values of 0.84/0.8/0.75 indicating good agreement.
 Evaluation metrics. Following [5], we used the F scores of unigram-based ROUGE-1 (R-1), bigram-based ROUGE-2 (R-2), and the weighted longest common subsequence based ROUGE-W (R-W,W=1.2) as metrics.
 Methods to compare. We used the following widely used multi-document summarization or timeline generation algorithms as the baseline systems. 1) CHIEU : Chieu et al. [1] presented a similar timeline system with a different methodology by utilizing burstiness ranking tex-t feature. 2) CENTROID : The method applies MEAD algorithm (Radev et al., 2004) to extract sentences according to the follow-ing parameters: centroid value, positional value, and fi rst-sentence overlap. 3) LexRank :LexRank[2] fi rst constructs a sentence con-nectivity graph based on cosine similarity and then selects impor-tant sentences based on the concept of eigenvector centrality. 4) LexRank + i : Since LexRank is a graph based method, we can al-so incorporate users X  collective interests similarly. 5) ETTS : ETTS proposed in [4] is an algorithm with optimized a combination of global and local biased summarization. 6) ETTS + i : our proposed algorithm, which incorporates users X  collective interests into ETTS. Setup details. For fairness of comparison, we performed the same preprocessing steps and adopted Maximal Marginal Relevance to reduce redundancy for all the aforementioned baselines. We par-titioned the entire sentence collection C into local sentence col-lections according to the timestamps of each sentence, i.e., C = with smaller rates indicating more emphasis on interestingness. =1 C i . Following [1], we applied a simple mechanism to select sentences by extracting more sentences for important dates while fewer sentences for others. The allocation rate on t i was set to  X  is set to the number of sentences in the gold standard.

The parameters of all the baselines and our proposed algorithm were tuned in a way similar to cross-validation. For each query, we fi rst found the parameters which lead to the optimal performance on this query, and then applied the model learned with these pa-rameters on the other fi ve queries. And fi nally, we averaged results over six such runs. For  X  in the two-mixture model (Eq. 1), we fi nd that a value in 0 . 8  X  0 . 95 usually gives good performance, which can effectively remove noisy and background words. For the restart probability of the interest-related pseudo sentence  X  , we found that avaluein 0 . 4  X  0 . 6 usually leads to an optimal performance for both LexRank and ETTS. A large value of  X  will hurt the diversity of summary sentences while a small value of  X  essentially ignores the effect of social attention.
We present the results of various methods on both the informa-tiveness and interestingness oriented evaluation sets in Table 3. To better check the improvement when incorporating social attention, we also present the relative improvement on R-1 for LexRank over LexRank and ETTS + i over ETTS .

Evaluation of informativeness. We fi rst examine the results on the informativeness oriented set D , which consists of summa-ry sentences obtained from professional editors. We notice that the incorporation of users X  collective interest yields improvement of in-formativeness, i.e. ETTS + i &gt; ETTS and LexRank + i &gt; LexRank. It indicates that users do read important sentences, and the incorpora-tion of user interests does not hurt informativeness. A noteworthy point that users X  collective interests may affect the diversity due to the fact that our method force the generated summaries to match collective users X  interests.

Evaluation of interestingness. For the results on the three in-terestingness oriented sets, D  X  5 , D  X  10 and D  X  15 , we can see the improvement LexRank + i over LexRank and ETTS + i over ETTS be-comes more signi fi cant with the decreasing number of summary sentences in the gold standards, D  X  5 &lt; D  X  10 &lt; D shows that taking into account of social attention, our proposed method is indeed able to generate timeline summaries more tailored to users X  collective interests. The advantage of our method is more prominent when generating more succinct summaries. Finally, we notice that our proposed method is able to close the performance gap between LexRank and ETTS. For example, when tested on the D  X  5 set, ETTS outperforms LexRank by 3% (  X =0 . 006 )inthe R-1 measure. But with our proposed method incorporated, the gap between ETTS + i and LexRank + i (  X =0 . 003 ) is reduced to 1%.
To get an intuitive idea of why our method works, we present an example timeline generated by ETTS + i in Table 4. We list the top words ranked by probabilities learnt from the two-mixture user interest-related model. Clearly, these words are very meaningful and broadly re fl ect the social attention at that period. With them as supervision, the graph based summarization methods tend to give higher weight to sentences closely matched public interest. Com-Table 4: Sample timeline generated by ETTS + i on  X  X obel Prize" from July 2009 to December 2009. Due to space limit, we only present summary sentences related to the news  X  X ba-ma won Nobel Peace Prize 2009". Top interest-related words are marked in Italic.
 pared to the results in Table 1, ETTS + i fi nds more news re fl ect-ing users X  collective interest about the topic  X  X resident Obama won Nobel Peace Prize".
We present a graph based approach to consider collective users X  interests in timeline generation. Experiment results show that the incorporation of users X  interests is helpful to improve both infor-mativeness and interestingness. The generated summaries become more user favoring compared to traditional timeline summaries. As future work, we will explore learning user interests by dynamical-ly adjusting the time span of a given topic instead of using a fi xed time interval.
 ACKNOWLEDGEMENTS. We thank Jing Jiang and Qiaoling Liu for helping to improve the work. We thank the anonymous reviewers for the constructive comments. The work was partially supported by NSFC Grant 61272340 and 60933004. Yulan He was partially supported by the EPSRC grant EP/J020427/1. Xin Zhao was supported by Microsoft Research Asia Fellowship. [1] H. L. Chieu and Y. K. Lee. Query based event extraction along [2] G. Erkan and D. Radev. Lexpagerank: Prestige in [3] R. Swan and J. Allan. Automatic generation of overview [4] R. Yan, L. Kong, C. Huang, X. Wan, X. Li, and Y. Zhang. [5] R. Yan, X. Wan, J. Otterbacher, L. Kong, X. Li, and Y. Zhang. [6] C. Zhai and J. Lafferty. Model-based feedback in the language
