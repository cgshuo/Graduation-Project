 Content-based image retrieval systems have to cope with two different regimes: understanding broadly the categories of interest to the user, and refining the search in this or these categories to converge to specific images among them. Here, in contrast with other types of retrieval systems, these two regimes are of great importance since the search initial-ization is hardly optimal (i.e. the page-zero problem) and the relevance feedback must tolerate the semantic gap of the image X  X  visual features.

We present a new approach that encompasses these two regimes, and infers from the user actions a seamless tran-sition between them. Starting from a query-free approach meant to solve the page-zero problem, we propose an adap-tive exploration/exploitation trade-off that transforms the original framework into a versatile retrieval framework with full searching capabilities. Our approach is compared to the state-of-the-art it extends by conducting user evaluations on a collection of 60,000 images from the ImageNet database. H.3.3 [ Information storage and retrieval ]: Information Search and Retrieval X  Search process, Relevance feedback algorithms, experimentation, performance query-free interactive image retrieval, iterative relevance feed-back, Bayesian framework, user-based evaluation
It is recognized the need for image retrieval systems able to deal with automatically extracted content-based features, and provide an intuitive and simple interaction with users. A decade ago, the largest image collections were stock pho-tograpy collections such as Getty Images and Corbis, con-taining hundreds of thousand images carefully annotated with keywords from a well specified vocabulary by experts with a homogeneous and professional knowledge. Nowadays, the on-line image collections such as Flickr or FaceBook are orders of magnitude larger. Although many images are an-notated, the keywords are less reliable due to the users sub-jectivity and less consistent due to the uncontrolled vocab-ulary.

Research started to tackle this challenge via automatic tagging based on annotation propagation [ 13, 10 , 18 ]. How-ever, formulating a query might not be the most efficient way of searching for images since the visual content is often diffi-cult to describe in terms of keywords. Relevance feedback is envisioned by many researchers as the only alternative that could cope properly with the challenges in image retrieval, and multimedia retrieval in general [ 12 , 19 ].
The interactive retrieval process involves two different re-gimes. The first one can be seen as an exploration phase, during which the user communicates to the system her cate-gories of interest in a broad way. This first regime transitions into the second one that can be seen as an exploitation phase, where the user specifies more detailed requirements on the visual properties of images, making the system intelligently explore the restricted subset specified during exploration.
We propose an extension of the retrieval approach devel-oped by Ferecatu and Geman [ 6, 7] which has the major advantage of being query-free. Starting from an heuristic sampling of the collection, this method does not require any explicit query, and it relies solely on an iterative relevance feedback mechanism. At each iteration, the system displays a small set of images and the user chooses the image that best matches what she is looking for. The system updates an internal state and displays a new set of images accord-ingly. After a few iterations, the sets of displayed images start to include images that satisfy the user.

Our core contribution is an adaptive modulation of the exploration/exploitation trade-off, which leads to a versatile retrieval system with full searching capabilities. Internally, our approach employs an estimator of the consistency be-tween the system internal state and the user retrieval objec-tive, and controls dynamically, at each iteration, the selec-tion of the displayed images accordingly.

We developed our system as a web-application, and we set it up for a collection of 60,000 images sampled uniformly from the ImageNet database [ 4], for which we took over the provided pre-computed SIFT features (Scale Invariant Fea-Figure 1: Relevance feedback loop. At iteration t the system displays D the new display set D t +1 . ture Transform) [11 ]. We set up four configurations with dif-ferent similarity metrics and we run user-based evaluations with 20 users. Evaluation gives evidence that our approach brings a significant improvement on the retrieval capabili-ties of the original system that remains sustainable when employing different similarity metrics.

This paper is structured as follows. In  X  2 we present ex-isting techniques related to the problem at hand, and sum-marize in  X  3 the notation and the essence of the technique we are extending. In  X  4 we elaborate our approach, and present in  X  5-6 our experiments. We conclude in  X  7.
Research proposed many alternative approaches to tackle with the two retrieval regimes. Traditionally, they are seen as separate operations and they are treated by separate al-gorithms. Most of the image retrieval approaches require an initial query before offering relevance feedback tools. The most generic meanings are query-by-visual-examples [14], and query-by-sketching [8]. Regarding the relevance feedback tools, there are early works like MARS[1 ] and MindReader[9 ] that develope mechanisms for rich feedback information ( e.g. rank-ing many images, tuning many parameters). Sharing the same line of thinking, a perception-based image retrieval system was developed by Chang et al. [2 ]. As reported in surveys [ 13 , 17 ], there are many content-based image re-trieval systems in research form but very few have been com-mercially developed.

The idea of searching images without any explicit query appeared distinctly in the work of Cox et al. [3 ]. The core of their work is a Bayesian framework for iterative rele-vance feedback. Ferecatu and Geman [6, 7] extended the framework and provided theoretically sound interpretations. Moreover, they conducted user evaluations that demonstrate the retrieval capabilities of such an approach. Their work focused on using a similarity metric based on low-level fea-tures extracted from the visual content ( i.e. global descrip-tors of color, texture and shape). Recently, the framework was adopted and extended for large-scale image collections of millions of images in the HEAT retrieval system of Suditu and Fleuret [ 15 ]. Motivated by the potential of this query-free retrieval approach, our research takes a complementary direction and improves on its searching capabilities. Figure 2: Abstract representation with a synthetic collection. (a): The images have as visual content one single point in the 2D Cartesian space, and the indexing features are the corresponding coordinates of that point. The similarity distances between im-ages are the Euclidean distances between their cor-responding points. (b): The duality between points and images is used to represent the entire collec-tion. Additionally, the grey-levels of the points tell the probabilities of relevance of their corresponding images.
This section presents briefly the retrieval framework pro-posed in [ 7]. Given a collection of images  X  = { 1 , 2 ,...k,... } , the retrieval objective is to identify the small subset S  X   X  containing all the images that the user is looking for.
The retrieval framework embodies an iterative relevance feedback mechanism that has two components. First, there Figure 3: The posterior probabilities p t ( k ) for all k  X   X  are updated iteratively. Here, the relevance feedback events are given by a user who is searching for a point located in the center of the square. One can see how the distribution of probabilities evolves towards matching the user retrieval objective. is a Bayesian framework that models the probabilities of rel-evance of the images in the collection as conditional proba-bilities depending on the relevance feedback events. Second, there is the strategy to select what images to show next given the estimates of the probabilities of relevance of all the images in the collection.

For an intuitive illustration of the system behavior, a syn-thetic image collection comes in handy, where the images have as visual content one single point in the 2D Carte-sian space, and the indexing features are the corresponding coordinates of that point. Figure 2 explains the abstract representation based on the synthetic collection.
Relevance feedback events are accumulated iteratively as shown in Figure 1. After the system displays a small set of images D t  X   X , k D t k = 8, the user chooses one single image x t  X  D t that she considers to be the most similar to S , and this event is denoted as { D t , x  X  t } . The cumulative event up to iteration t can be expressed as:
The conditional probabilities p t +1 ( k ) = P ( k  X  S | B estimated after each relevance feedback event. Initially, when Figure 4: The set of displayed images is generated via the Voronoi tessellation algorithm. To illustrate its intermediate steps, the images already selected are marked in black and their current Voronoi cells are indicated by colors. (a): The first image x 0 is selected, and the first Voronoi cell C 0 is grown. (b): The second image x 1 is selected. (c): The Voronoi cells C 0 and C 1 are grown in parallel. C 0 is shrunken by detaching the images closer to x 1 , and then re-grown by including other images that are still closer to x 0 . (d-f ): The algorithm proceeds in the same manner until the set of displayed images is complete. there is no relevance feedback yet, the probabilities p are initialized with 0 . 5 for all k  X   X . Subsequently, the con-ditional probabilities are estimated via an image similarity model defined over the metric space of the indexing features.
To simplify the analysis of our work, we use for that mat-ter the exact same model as in [ 6, 7], which puts higher probability on the images similar to the chosen ones and ac-counts for an effect of  X  X aturation X  that ignores the increase in the image dissimilarities beyond a certain threshold. Fig-ure 3 shows how the probabilities of relevance are gradually updated on successive iterations.
The displayed images, namely D t with k D t k = 8, are gen-erated via a Voronoi tessellation algorithm proposed by Fang and Geman [ 5]. Instead of simply selecting the images with the highest probabilities of relevance, this algorithm samples the image collection with the purpose of maximizing the in-Table 2: Both the baseline algorithm [ 7] and our mass-zoom method rely on the following procedures to compute a meaningful display set D t . Given the current estimate of probabilities p = { p t ( k )  X  k  X   X  } , the cardinality k D t k = Q , and a target mass m , the function ComputeDisplaySet returns a list of im-ages x 1 ,...,x Q such that each of them has a high individual p t , and they have disjoint neighborhoods c ,...,c Q of mass m . Given the probabilities p, a list of images and a mass m , the function ComputeCells returns the corresponding disjoint neighborhoods, all of the same mass m .
 formation entropy, minimizing the redundancy between the displayed images, and thus maximizing the efficiency of the relevance feedback events.

The procedure ComputeDisplaySet to build a display set is described in Table 2. Given a target mass m , it picks each image successively, each time selecting the one with the highest p t which does not belong to the neighborhoods of mass m centered on the images already selected. In the function ComputeCells , the neighborhoods are grown in parallel by including images one by one, as ordered by their similarity distances, until the probability mass of each neigh-borhood reaches the target mass m .

The original algorithm by Fang and Geman [ 5] uses at every iteration a target mass equal to a constant fraction of the total mass of the images
The first display set D 0 is generated by running the algo-rithm with the initial probabilities of relevance, p 0 ( k ) = 0 . 5 for all k  X   X . The algorithm is still growing the Voronoi cells but it is choosing the images randomly between the equally probable candidates.

Figure 4 shows the intermediate steps of the Voronoi tes-sellation algorithm. One can see how the Voronoi cells are grown and how the images to be displayed are selected. In-tuitively, the cells including regions with higher probabilities are smaller than the cells including regions with lower prob-abilities.
As argued by Ferecatu and Geman [6 , 7], the retrieval framework is well suited for image category search and that is, in our words, the first retrieval regime of exploring the im-age collection. They explicitly suggest that other retrieval Figure 5: Evolution of the distribution of probabil-ities of relevance. The plots have the probability bins on axis X, and the percentage of images in the collection on axis Y. Initially, all images have the same probability, p 0 ( k ) = 0 . 5  X  k  X   X  . The distri-bution evolves rapidly in the first iterations, and it evolves slowly after the very first iterations. techniques should be employed to retrieve specific images among these identified categories and that is, in our words, the second retrieval regime of exploiting the image collec-tion.

A useful insight is given by analysing the evolution of a retrieval for the synthetic collection, when searching for a point located in the center of the square. Figure 6 shows the evolution of the displayed images, and Figure 5 shows the distribution of the probabilities of relevance.
As shown in Figure 5, the distribution of the probabili-ties evolves quite rapidly in the first iterations. These early iterations correspond to the first retrieval regime when the system is in the process of understanding broadly the cat-egories of interest to the user. Later, after the system has achieved a good understanding of the user interest, the dis-tribution of the probabilities evolves quite slowly from one iteration to another. These later iterations correspond to the second retrieval regime when the system is meant to refine the search and to converge to specific images.
As shown in Figure 6, the sets of displayed images include an image that is closer and closer, with each iteration, to the user interest. After 3 iterations, the system succeeds to display an image that is clearly in the intended region. Still after 5 iterations, the displayed images concentrate only slightly in the intended region.

The system succeeds efficiently to display an image in the intended region, but it has a hard time to display more and more images in the intended region. The  X  X ampling X  algo-rithm insists to cover the entire collection even after the distribution of probabilities becomes rather stable. One can say that the original system has a big inertia to maintain an exploration regime and it goes very slowly into an exploita-tion regime. Figure 6: Evolution of the display set for the base-line algorithm with the synthetic collection, when searching for a point located in the center of the square. After 5 iterations, the displayed images con-centrates slightly in the intended region. Again, the selected images are marked in black and their cor-responding Voronoi cells are indicated by colors.
This section presents our solution to eliminate the limi-tations of the retrieval framework described in  X  3.3 . Intu-itively, the system should be aware of the degree of align-ment of the distribution of probabilities with the user intent. When the distribution of probabilities is in line with the user intent, the system should to concentrate the  X  X ampling X  in the regions with high probability.

First, we present the sound idea of an adaptive strategy to handle the trade-off between exploration and exploita-tion, by modulating the concentration of the display set on promising images. Second, we present a heuristics that in-fers dynamically, at each iteration, from the user actions a consistency score that achieve a seamless trade-off that suits the user intent.
Our mass-zoom algorithm handles the trade-off between exploration and exploitation by modulating how much the display set should be concentrated on the images assessed as the most relevant. This is achieved by estimating at ev-ery iteration the target mass m t for the displayed image Figure 7: Evolution of the display set for the mass-zoom system with the synthetic collection, when searching for a point located in the center of the square. After 5 iterations, the displayed images con-centrates mostly in the intended region. The dis-played images yet provide the freedom to escape the exploitation if necessary. The system continuously estimates the exploration/exploitation trade-off that suits the user. neighborhoods (see  X  3.2 ). While this value was a constant fraction of the total mass in the baseline (see Equation 2), we propose to link it to an estimate of the confidence of our current estimate of the image relevance. Making the value of this target mass smaller make the neighborhoods around the images of the display set smaller, which leads to a more compact display set, concentrated in the area of high prob-ability.

Our approach increases the concentration of the display set if the choice of the user is consistent with our current estimate, and to decrease it otherwise. We propose the fol-lowing update scheme: where z t  X  1 m our estimates of the p t and the user choice.
The consistency score estimates the alignment of the sys-tem and the user intent. Immediately after the relevance feedback event { D t , x  X  t } , the consistency score aims to esti-mate the alignment of the system and the user intent.
In the first iteration, the user intent is totally unknown and the consistency score c 0 is initialized to 1 . 0. Subse-quently, the consistency score is estimated based on the probability of relevance of the chosen image p t ( x the probabilities of relevance of the other displayed images, namely p t ( x t ), for all x  X  D t .

The consistency score is estimated based on the cumula-tive distribution function for the Gaussian distribution. The proposed heuristics is to scale up this value and to have a consistency score in the interval [0 . 5 , 2 . 0]: where  X  = 1 k D
This is motivated by the intuition that if the p t already among the highest probabilities it means that the system has a distribution of the probabilities that is in line with the user intent, and thus the system is consistent with the user intent. If p t ( x  X  t ) is relatively low, the system is less consistent with the user intent.

The zoom value that impacts the exploration/exploitation trade-off of the selection of the displayed images is derived from the consistency scores as follows:
For an intuitive illustration, we run the mass-zoom system with the synthetic collection described in  X  3, and we search for a point located in the center of the square. We saved the evolution of the displayed images for intermediate iterations and we show them in Figure 7.

After efficiently identifying the intended region, the mass-zoom system is able to display more and more images in the intended region. The  X  X ampling X  algorithm concentrates in the intended region after the distribution of probabilities becomes rather stable. Although the  X  X ampling X  algorithm does not cover the entire collection anymore, the system continuously estimates the exploration/exploitation trade-off that suits the user.

Note that while the synthetic collection is very handy for intuitive illustrations, it should not be mistaken for image collections, which are typically facing high-dimensional im-age indexing feature spaces. Besides the miss-alignment be-tween the image feature space and the user subjective per-ception of image similarities, the distribution of the image similarity distances impacts the Voronoi tesselation algo-rithm as well as the distribution of the probabilities of rele-vance. We argue that the exploration/exploitation trade-off has even higher impact than in the case of the synthetic collection.
The retrieval system was developed as a web-application ( http://imr.idiap.ch/ ). Besides the advantage of perma-nent availability for evaluations, this implementation en-Figure 8: Web interface of the retrieval system used for user tests. The searching sessions were presented in a random fashion. The users were only told to end the searching sessions when they were satisfied by four of the displayed images. courages the adherence to a realistic system architecture. The application software is distributed under the GPL v3.0 open-source license ( http://www.idiap.ch/software/imr/ ).
The system was set up for 60,000 images sampled uni-formly from the ImageNet database [ 4], that has the con-venience of being structured in 1000 semantic categories, each composed of 500 X 2500 images. We considered the se-mantic information as benchmark meta-data for setting up the evaluation scenario, and we used as indexing features the pre-computed bags of SIFT features of dimension 1000 (Scale Invariant Feature Transform) [11 ], as they are pro-vided along with the images. For evaluation purposes, we considered four different image similarity metrics defined over these histogram-like indexing feature vectors:
The relevance feedback framework was calibrated as de-scribed in [6 ], and the parameters of the image similarity model are adjusted to saturate only after including on av-erage 10% of the images in the collection. Therefore, each similarity metric would employ a different image similarity model, adapted to its statistical properties.

Computational effort required by the approach depends linearly on the collection size. Currently supporting multi-ple users, the web-application takes 1 second per iteration and uses 300KB cache memory per user with the data-set described in this article.
Evaluation was conducted with 20 users not familiar with the system, and it consisted of running user tests with three systems: our proposed zoom-mass system, the original base-line system and a random system displaying images ran-domly without replacement. The random system discards totally the relevance feedback and thus provides the lowest possible performance. Figure 9: The users were asked to search for seman-tic categories described in words and accompanied by image examples as shown here. In order to ensure a sufficiently reliable diversity, there were 6 seman-tic categories.
The aim of our experiments was to evaluate our mass-zoom system in terms of the retrieval capabilities, and to get evidence that our system is capable of providing capabilities beyond finding an image category, and is able to support refining the user interest in an efficient manner.
In order to isolate our contribution as much as possible, we employed four different similarity metrics on top of the im-age indexing features, as mentioned in  X  5. We did not aim to evaluate which similarity metric suits better the user subjec-tive perception of image similarity, but rather to gather ev-idence that our contribution remains sustainable when em-ploying different similarity metrics.

In order to ensure a reliable diversity, there were 6 se-mantic categories described in words and accompanied by the corresponding images in Figure 9:
In order to ensure comparable difficulty, these categories were chosen to be relevant for about 1% of our collection of 60,000 images based on the evidence given by the cardinal-ity and the associated keywords of the ImageNet categories. Here, we should mention that these keywords were consid-ered only as benchmark meta-data for assessing the retrieval difficulty, and our retrieval system does not make use of any textual information.

In order to avoid any bias, the searching sessions were presented in a random fashion. The semantic categories, the systems and the similarity metrics were randomized all together in one single user test. The users were not aware of which configuration was active in a certain session. In fact, they were not introduced to anything beyond the evaluation interface in Figure 8. The users were only told to end the searching sessions when they were satisfied by four displayed images.

We designed the evaluation scenario with the intent of pushing the evaluation beyond a simple image category search. We looked for evidence that the system is able to properly identify the user interest and then refine it more and more in an efficient way. This is the reason of asking the users to continue the searching sessions until four displayed images are relevant to what they search for. Evaluation shows that the mass-zoom approach is viable. Mass-zoom is consistently better than the baseline for all configurations. Figure 10 shows the cumulative percentage of successful sessions per number of iterations. For example, for L1 similarity metric, mass-zoom finishes successfully in less than 10 iterations in 70% of the cases, and baseline in 45% of the cases. The random system is far from achiev-ing the same performance even after 20 iterations. Table 3 contains a few discrete values read from Figure 10 .
We argue that the system performs very reasonable when thinking of the most ideal case. If the collection would be ar-ranged as a tree with 8 branches at each node, the perfectly-structured search will need around 3 iterations in average and log 8 N  X  5 iterations at maximum.

Table 4 tells about the statistical significance of the eval-uation. For each couple of configurations, we counted how many times one performed better than the other for the same user and the same semantic category.Then, we com-puted the binomial probabilities. In principle, a difference is statistically significant if the corresponding probability is smaller than 0 . 05.

Figure 11 shows the evolution of the zoom values z t from one iteration to the next. By decreasing in average, it shows that the system is consistent with the user interest. One should be aware that the rate by which the system tran-sitions from exploration phase into exploitation phase (see Equation 4) may affect the results. An optimal rate could be derived by a more extensive user evaluation.
 Table 3: Retrieval performance. Here are a few dis-crete values read from Figure 10.
 Table 4: Binomial-test for statistical significance of our experiments for all four similarity metrics. For example, for L1 similarity metric, mass-zoom per-formed better than baseline in 37 times out of 60, and the probability of this to occur by chance is 0.026. iterations in 65% of the cases, and baseline in 45% of the cases. Figure 11: Zoom average and standard deviation. z 0 and z 1 are always equal to 1 as c 0 is initialized with 1 since there is no relevance feedback history at iteration t = 0 , and c of relevance p 0 ( k ) are all equal to 0 . 5 .
Although we did not organize an appraisal questionnaire, we received favourable informal feedback regarding the user experience. The system is unconventional but intuitive and it becomes understood in very short time, even in the first searching session.

Suggestions have been made to improve the user experi-ence. In the first couple of iterations, it may happen that none of the displayed images cannot be even vaguely related to what the user is searching for. When the users cannot make reliable similarity judgments, they would rather give negative feedback ( i.e. none of the images resembles what they are searching for) or, at least, give no feedback and just ask for new images. Also, the users would appreci-ate the possibility to undo the last relevance feedback iter-ation. Such functionalities may be easily integrated in our approach, but they were intentionally not supported in the evaluation scenario.
We have presented a query-free retrieval approach with full searching capabilities. The adaptive mass-zoom system encompasses both retrieval regimes of exploration and ex-ploitation, and supports a seamless transition between them that increases the alignment between the system and the user. Evaluation shows that our proposed mass-zoom sys-tem extends considerably the retrieval capabilities of the original algorithm. Moreover, evaluation gives evidence that the approach is intuitive and the minimalist user interface is effortless and self-explanatory.

The evaluation results give motivation for further investi-gations on how the system could benefit from other indexing features and similarity metrics. Although evaluated for im-age retrieval, our mass-zoom system is suitable for any type of multimedia retrieval with only minor changes.
Nicolae Suditu was supported by the Hasler Foundation through the EMMA (Enhanced Medical Multimedia data Access) project. Fran  X cois Fleuret was supported in part by the European Community X  X  Seventh Framework Programme FP7 -Challenge 2 -Cognitive Systems, Interaction, Robotics -under grant agreement No 247022 -MASH. [1] C. Carson, M. Thomas, S. Belongie, J. M. Hellerstein, [2] E. Chang, K.-T. Cheng, W.-C. Lai, C.-T. Wu, [3] I. J. Cox, M. L. Miller, T. P. Minka, T. V.
 [4] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and [5] Y. Fang and D. Geman. Experiments in mental face [6] M. Ferecatu and D. Geman. Interactive search for [7] M. Ferecatu and D. Geman. A statistical framework [8] M. Flickner, H. Sawhney, W. Niblack, J. Ashley, [9] Y. Ishikawa, R. Subramanya, and C. Faloutsos. [10] J. Li and J. Z. Wang. Real-time computerized [11] D. G. Lowe. Distinctive image features from [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, [14] J. R. Smith and S.-F. Chang. VisualSEEk: a fully [15] N. Suditu and F. Fleuret. HEAT: Iterative relevance [16] J. Tenenbaum, V. de Silva, and J. Langford. A Global [17] R. C. Veltkamp and M. Tanase. Content-based image [18] J. Weston, S. Bengio, and N. Usunier. Large scale [19] X. S. Zhou and T. S. Huang. Relevance feedback for
