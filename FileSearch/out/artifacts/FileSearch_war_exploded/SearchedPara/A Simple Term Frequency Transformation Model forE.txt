 Pseudo Relevance Feedback is an effective technique to im-prove the performance of ad-hoc information retrieval. Tra-ditionally, the expansion terms are extracted either accord-ing to the term distributions in the feedback documents; or according to both the term distributions in the feedback documents and in the whole document collection. However, most of the existing models employ a single term frequency normalization mechanism or criteria that cannot take into account various aspects of a term X  X  saliency in the feedback documents. In this paper, we propose a simple and heuristic, but effective model, in which three term frequency transfor-mation techniques are integrated to capture the saliency of a candidate term associated with the original query terms in the feedback documents. Through evaluations and com-parisons on six TREC collections, we show that our pro-posed model is effective and generally superior to the recent progress of relevance feedback models.
 H.3.3 [ Information Search and Retrieval ]: Retrieval models, Relevance feedback Algorithms, Performance, Experimentation Term Frequency Transformation; Pseudo Relevance Feed-back
Users often issue very short queries to describe their infor-mation need, which leads to the absence of some important terms from the queries. Thus, users could get a poor cov-erage of relevant documents. To solve this problem, pseudo relevance feedback (PRF) via query expansion (QE) is an effective technique for boosting the overall performance in Information Retrieval (IR). It assumes that top-ranked doc-uments in the first-pass retrieval are relevant, and then used as feedback documents in order to refine the representation of original queries by adding potentially related terms or ad-justing the weights of query terms. PRF has been shown to be effective in improving IR performance [6, 10, 14, 17, 29, 32, 34, 35, 42, 44, 46] in a number of IR tasks.

In general, the expansion terms are weighted and extracted either according to the term distributions in the feedback documents (i.e. one tries to extract the most frequent terms); or according to both the term distributions in the feedback documents and in the whole document collection (i.e. to extract the most specific terms in the feedback documents). Normally, the term frequency in a document determines its importance in that document, while inverse document fre-quency in the whole collections is used to estimate its im-portance globally. The term frequency is always normalized according to the length of the document that contains it. However, most of the existing models employ a single term frequency normalization mechanism or criteria that cannot take into account various aspects of a term X  X  saliency in the feedback documents. When estimating the weight of a can-didate expansion term, how the other terms are distributed are largely unexplored. First, for example, the original query itself is usually ignored in the process of expansion term se-lection. In other words, the term associations between can-didate terms and the query terms have been ignored in most of traditional PRF models. Term proximity is an effective measure for term associations, which has been studied ex-tensively in the past few years. Most of these studies focus on the term proximity within the original query and adapt this in ranking documents [5, 9, 15, 20, 30, 38, 40], which has proven to be useful in discriminating between the rel-evant and non-relevant documents. So it is promising to take into account the distribution of candidate expansion terms in combination with that of the original query terms. Second, although document length-based normalization can balance the weight of a term in different feedback documents well, the importance of the documents are not well utilized. Third, when one estimates the importance of a term in differ-ent documents, normal term frequency normalization meth-ods only consider the frequency of itself and the document length. The distributions of other terms are always ignored, while we believe that it will affect the importance of the current term in a given document.

In this paper, we propose a uniform and heuristic model, in which three term frequency transformation techniques are used to capture the local saliency of a candidate term asso-ciated in the feedback documents. In particular, three kinds of term frequency transformation techniques are then inte-grated to capture the overall saliency. First, besides the traditional term frequency normalization to overcome the length difference of documents, we take into account the weights of feedback documents to get a weighted and nor-malized term frequency. Second, we propose to use a rela-tive term frequency transformation to capture the relative importance of a term in a given document. Third, we use a kernel-base term frequency transformation to capture the closeness to the original query.

The main contributions can be summarized as follows: 1) expansion terms are no longer selected merely based on term distributions regardless of original query and other terms in the same feedback documents. We can expect the se-lected terms to be more closely related to the original query, and thus have a higher impact on the effectiveness; 2) three different term frequency transformation techniques are com-bined in a heuristic way. 3) our model is simple, yet effective since we only have to transform the term frequency based on information in the feedback documents.

We evaluate our model on six TREC collections and com-pare it to the traditional PRF models. The experimental results show that the retrieval effectiveness can be improved significantly and empirical parameter settings are suggested while no training data is available.
 The remainder of this paper is organized as follows: in Section 2 we review the related work. In Section 3, three transformation methods for capturing different aspects of term frequency (TF) and our proposed model are presented in details. In Section 4, we introduce the settings of the experiments. In Section 5, the experimental results are pre-sented and discussed. Finally, we conclude our work briefly and present future research directions in Section 6.
PRF via query expansion is referred to as the techniques or algorithms that reformulate the original query by adding new terms and adjust their weights, in order to obtain a better query. With the refined query, usually better retrieval performance can be expected. PRF has been shown to be effective with various retrieval models [6, 10, 14, 17, 29, 32, 34, 35, 42, 44, 46, 43, 25]. There are a large number of studies on the topic of PRF. Here we mainly review the work about PRF which is the most related to our research.
The Rocchio X  X  model [34] is one of the earliest work of PRF models, which was developed in 1971 for the Smart retrieval system. It provides a framework for implementing (pseudo) relevance feedback via improving the query representation in vector space retrieval model. In the following decades, a number of PRF models were developed, mostly derived from Rocchio X  X  framework. For example, Carpineto et al. proposed an information-theoretic approach to automatic query expansion evaluated under the vector space model. Another popular and successful automatic PRF model was proposed by Robertson et al. [32, 31]. Amati et al. [3] pro-posed a query expansion algorithm in the divergence from randomness (DFR) retrieval framework.

In addition, with the development of language model [27] in IR, a number of PRF (e.g. [17, 39, 46]) have been de-veloped to fit in the language modeling framework. For ex-ample, the model based feedback approach [46] is not only theoretically sound, but also performs well empirically. The essence of model based feedback is to update the proba-bility of a term in the query language model by making use of the feedback information. Much like model-based feedback, relevance models [17] also estimate an improved query model. The difference between the two approaches is that relevance models do not explicitly model the rele-vant or pseudo-relevant document. Instead, they model a more generalized notion of relevance [22]. Lv et al. [19] have conducted a comparable study of five representative state-of-the-art methods for estimating improved query lan-guage models in ad hoc information retrieval, including RM3 (a variant of the relevance language model), RM4, DMM, SMM (a variant of model-based feedback approach), and RMM [17, 39, 46]. They found that SMM and RM3 are the most effective in their experiments, and RM3 is more robust to the setting of feedback parameters.

Most of these PRF approaches estimate a value of the importance (or probability) of a candidate expansion term based on its own distribution or statistics (e.g. term fre-quency, collection term frequency and document frequency). However, when estimating the value of a term, how the orig-inal query terms and other terms in the same document are distributed was not considered together. Unlike previous work, we not only use the raw term frequency to capture the saliency of a term, but also take advantage of the distri-bution information of other terms. One of the information to utilize is the distributions of original query terms in com-bination with that of expansion terms. In particular, we model the closeness in terms of term proximity. In the fol-lowing, we review related work of term proximity in IR.
Term proximity is the co-occurrences of terms within a specified distance, which could measure the closeness of terms. A large amount of work has been done to integrate term proximity into both probabilistic and language models, which are characterized by the distance of the original query terms in documents. For example, Allan and Ballesteros [1] pro-posed phrases indexing instead of terms, and obtained some improvements on TREC datasets. However, this approach cannot handle the scenario in which the query terms are not adjacent to each other. A more relaxed approach [15, 16, 8] attempted to introduce  X  X EAR X  operator to quantify the proximity of query terms. Hawking and Thistlewaite [12] proposed a similar one, which evaluated text segments con-taining all query terms. In addition, Song et al. [38] grouped query terms into phrases and the contribution of a term is determined by how many query terms appear in the context phrases. Under the language modeling framework, Zhao et al. [50] used a query term X  X  proximate centrality as a hyper parameter in the Dirichlet language model. Lv et al. [20] in-tegrated the positional and proximity information into the language model by a different way. They defined a posi-tional language model at each position in documents by cre-ating virtual documents based on term propagation. With probabilistic models, Zhao et al. [48, 49] introduced a pseudo term, called cross term, to measure the association of mul-tiple query terms.

Although there have been plenty of efforts in integrat-ing proximity heuristic into existing retrieval models, work on how to utilize this information for PRF is still limited. Lv et al. [21] presented two methods to estimate the joint probability of a term w with the query Q at every position in each feedback document, which extended the relevance model [17], and significant improvements were obtained on two large collections. Miao et al. [24] employed proximity heuristic in a formalistic framework which extensively dif-fers from the language modeling framework. Unlike previous work, we propose a TF transformation method to capture this feature, which is then integrated into the PRF proce-dure.

Another aspect that could affect the performance of PRF is the quality of feedback documents. In most of traditional PRF approaches, there is a very strong assumption that top ranked documents from the first-pass retrieval are all rele-vant. In fact, the top ranked documents are not necessarily to be good for PRF since they are not evaluated by real users. Therefore, the candidate expansion terms should be assigned different weights. Several studies ([13, 18]) have in-vestigated this problem by detecting the right documents for PRF, from which expansion terms are extracted. In ([13]), He et al. proposed to detect good feedback documents by classifying all feedback documents using a variety of fea-tures such as the distribution of query terms in the feedback document, the similarity between a single feedback docu-ment and all top-ranked documents, or the proximity be-tween the expansion terms and the original query terms in the feedback document. In addition, Lee et al. ([18]) pro-posed a re-sampling method using clusters to select better documents for PRF. The main idea is to use document clus-ters to find dominant documents for the initial retrieval set, and to repeatedly feed the documents to emphasize the core topics of a query. In this study, we model this problem by transforming the TF of the candidate terms to consider the importance of different feedback documents.
We first give the notations and conventions used in this paper. Then, a term frequency (TF) transformation model for PRF is proposed.
Given a query Q and a document collection C , a list of ranked documents in descending order, denoted as D , is re-turned by an information retrieval system. This step is al-ways call first-pass retrieval in the process of PRF. We use d to denote the i-th ranked document in D . After the first-pass retrieval, the top-k documents in D will be used as feedback documents in PRF, which is denoted as D f .
In traditional PRF models, each d i in D f will all be treated as relevant. The goal is to utilize these feedback documents to expand the original queries and adjust their weights in or-der to derive a refined query Q 1. With Q 1, we could expect better retrieval performance.
In this study, we explore the techniques of term frequency transformation in the classic Rocchio X  X  model. Although the Rocchio X  X  model has been introduced in the informa-tion retrieval field for many years, it is still very effective in obtaining relevant documents and most of the state-of-the-art PRF approaches are derived from Rocchio X  X  model. According to ([45]),  X  X M25 ([33]) term weighting coupled with Rocchio feedback remains a strong baseline which is at least as competitive as any language modeling approach for many tasks X . This observation is also supported in ([45, 24]) as well as in our preliminary experiments of this paper. In the following, we revisit the traditional Rocchio X  X  models and enhance it with three TF transformation techniques.
The Rocchio X  X  model provides a way of incorporating (pseudo) relevance feedback information into the retrieval process. In case of pseudo relevance feedback, Rocchio X  X  method has the following steps: 1. All documents are ranked for the given query using 2. An expansion weight w ( t,D f ) is assigned to each term 3. The vector of query terms weight is finally modified by where Q 0 and Q 1 represent the original and first iteration query vectors, r i is the expansion term weight vector for the i-th feedback document, and  X  and  X  are tuning constants controlling how much we rely on the original query and the feedback information. We enhance the Rocchio X  X  model by refining the estimation of r i described in the following sec-tion. In practice, we can always fix  X  to 1, and only study  X  in order to get better performance.
As we can see from the previous section, the most impor-tant part within this framework is to calculate the vector r for d i . Namely, how to weight the candidate terms in a feedback document. The traditional approach uses the so-called TF-IDF weighting function to address this problem. However, most of these approaches only normalize the term frequency according to the length of feedback documents. Other aspects failed to be captured in this simple, yet ef-fective framework as discussed in the introduction. So in this paper, we propose different transformation techniques and investigate how to integrate them to obtain a still sim-ple and efficient, but more performing PRF approach. The resulting weighting framework is as follows: where tf j ( t ) is the j-th transformation technique and  X  the importance of j-th transformation technique. IDF ( t ) is the inverse document frequency of term t in the collection. In this study, we mainly focus on term frequency transfor-mation techniques. So we simple use the IDF formula from BM25 as follows: where N is the total number of documents in the collection, and n ( t ) is the number of documents containing t . It is of note that other variants of IDF can also be here, and performance improvement may be expected.

In the following, we present three methods for term fre-quency transformation, which are used for pseudo relevance feedback.
In traditional TF-IDF model and its variants, the term frequency is always normalized according to the length of the document [37, 33, 4]. All these methods have shown to be simple, yet effective to make term frequency comparable in different documents for the first-pass retrieval.
However, feedback documents play different roles in the process of PRF. More specifically, some feedback document may be much more important that other ones. So it is nec-essary to take into account the quality or importance of a candidate feedback to PRF. In order to address this prob-lem, we define a weighted term frequency by integrating the importance of a candidate document and the normalized term frequency according to the length of this document. The resulting formula, denoted as TF 1, is as follows: where lntf ( t ) denotes the traditional length-based normal-ized term frequency, and imp ( d ) is the importance of docu-ment d . For lntf ( t ), we use the following formula proposed in [4]: where len ( d ) is the length of document d and avdl is the average document length in the collection. Other TF nor-malization functions, such as the Robertson TF [33], are also viable. Here, the reason we choose formula 5 is sim-ply because it is not only effective but also parameter-free such that we can focus on evaluating main framework of our proposed PRF model.

For imp ( d ), without extra knowledge about the candidate feedback document, the best bet is to believe scores of the documents returned in the first-pass retrieval. In particular, we use the normalized scores returned the BM25 model as follows: imp ( d ) = X where k 1 and k 3 are tuning constants which depend on the dataset used and possibly on the nature of the queries. K equals k 1  X  ((1  X  b ) + b  X  dl/avdl ), and dl is the length of the document. In our experiments, the values of k 1 , k 3 default to 1.2 and 8, respectively, which is the recommended setting in [32].
In the process of PRF, the raw frequency of a term or its length-based normalization variants could be used to es-timate its importance in a feedback document. However, it cannot capture the characteristic that whether a candi-date term occurs near or far away from the query, which may cause the selected expansion terms not relevant to the query topic. Thus, we propose a Kernel-based term fre-quency ( ktf ) transformation method, which models the fre-quency of a term as well as the closeness to the query in terms of proximity.

In [21, 48], a pseudo term, namely Cross Term, is in-troduced to model term proximity within original query for boosting retrieval performance. kernel-based method to count the term frequency in a document. There are a num-ber of kernel functions (e.g. Gaussian, Triangle, Cosine, and Circle [48]) which were used for measuring the proxim-ity. The Gaussian kernel has been shown to be effective in most cases. So, in this paper, we adapt the concept of Cross Term with the Gaussian kernel by proposing a kernel-based TF transformation method, which captures the saliency of a candidate term brought not only by its occurrences but also the closeness to the original query. The resulting kernel-based TF between a candidate expansion term t and a query term q is as follows: where p t and p q are respectively the positions of candidate term t and query term q in a document,  X  is a tuning pa-rameter which controls the scale of Gaussian distribution.
In this method, beside the average proximity to the query, we also take into account the importance of different query terms. Therefore, we build a representational vector for the query, in which each dimension is the weight of a query term by the inverse document frequency formula below, and then the kernel-based term frequency, denoted as TF 2, in the Kernel-based method is computed as follows: where q i is a query term, | Q | is the number of query terms, and IDF ( q i ) is the same as in Equation 6. N is the number of documents in the collection, and N t is the number of documents that contain q i .
When comparing the importance of a term in difference documents, normal term frequency methods only consider the frequency of a term itself and the document length. The distributions of other terms are always ignored, while we believe that it will affect the importance of the current term. Similar to [26], let d 1 and d 2 be two documents of equal lengths, the frequency values of t in d 1 and d 2 are the same; but d 2 has more distinct terms and even some other terms have higher frequency that t . One could imagine an extreme case that all other terms in d i occur only once. So should the weight values of t in these two documents be the same?
With traditional TF normalization techniques, these two documents will be assigned with the same weights, which makes the ranking infeasible in this case. Intuitively, how-ever, d 2 mentions the query term t more frequently than d so t in d 2 is more likely to be most important term than in d . In other words, for d 1 it is possible that it talks about a topic not related to the query term t since other terms occur more frequently, while d 2 has a higher chance to talk about the query term t .

In order to capture the saliency of a term in this aspect, we use a relative TF transformation method, denoted as TF 3 as follows: where tf ( t,d ) is the raw term frequency of term t in docu-ment d , and atf ( d ) is the average term frequency of docu-ment d . This formula was also used in [37, 26] to normalize the tf values. Defferent from previous work, here we use it to transform the raw TF in the scenario of PRF.
As we can see from Equation 2, the three different TF transformation methods are linearly combined in our pro-posed model. In order to make the tuning of parameter sim-ple, we need to normalize these three aspects, and the nor-malization method f ( x ) is suggested to meet the following property: 1) when the TF = 0, f ( TF ) = 0; 2) f ( TF + 1) &gt; f ( TF ), but f ( TF + 2)  X  f ( TF + 1) &gt; f ( TF + 1)  X  f ( TF ); it means the weight of a term increases as the increase of TF , but the improvement has a diminishing effect; 3) f ( x ) maps TF into a specified scale.

One of the possible functions that satisfy the above re-quirements is as follows: This popular sub-linear TF normalization method has an upper-bound of 1, and puts TF into a range of 0 to 1. It also has the effect of reducing the influence of extreme values or outliers in the data without removing them from the data set. Other normalization methods may also be viable, and we leave this issue for further study in future work.
In this section, we describe six representative test collec-tions used in our experiments: Disk1&amp;2, Disk4&amp;5, WT2G, WT10G, GOV2 and Robust04, which are different in size and genre. The Disk1&amp;2, Disk4&amp;5 collection contains newswire articles from various sources, such as Association Press (AP), Wall Street Journal (WSJ), Financial Times (FT), etc., which are usually considered as high-quality text data with little noise. The WT2G collection is a general Web crawl of Web documents, which has 2 Gigabytes of uncompressed data. This collection was used in the TREC 8 Web track. The WT10G collection is a medium size crawl of Web documents, which was used in the TREC 9 and 10 Web tracks. It con-tains 10 Gigabytes of uncompressed data. GOV2 is a very large crawl of the .gov domain, which has more than 25 mil-lion documents with an uncompressed size of 423 Gigabytes. This collection has been employed in the TREC 2004, 2005 and 2006 Terabyte tracks. There are 150 ad-hoc query top-ics, from TREC 2004 -2006 Terabyte tracks, associated to GOV2. In our experiments, we use 100 topics in TREC 2005 -2006. The TREC tasks and topic numbers associated with each collection are presented in Table 1.
 In all the experiments, we only use the title field of the TREC queries for retrieval. It is closer to the actual queries used in the real application and feedback is expected to be the most useful for short queries [46].

In the process of indexing and querying, each term is stemmed using Porter X  X  English stemmer [28], and stopwords Table 1: the TREC tasks and topic numbers associ-ated with each collection.
 from InQuery X  X  standard stoplist [2] with 418 stopwords are removed. The MAP (Mean Average Precision) performance measure for the top 1000 documents is used as evaluation metric, as is commonly done in TREC evaluations. The MAP metric reflects the overall accuracy and the detailed descriptions for MAP can be found in [41]. We take this metric as the primary single summary performance for the experiments, which is also the main official metric in the corresponding TREC evaluations. To emphasize on the top retrieved documents, we also include P@k in the evaluation measures, which measures precision at fixed low levels of re-trieved results, such as 10 or 20 documents. This is referred to as  X  X recision at k X , for example  X  X recision at 20 X . It has the advantage of not requiring any estimate of the size of the set of relevant documents but the disadvantages that it is the least stable of the commonly used evaluation measures and that it does not average well, since the total number of relevant documents for a query has a strong influence on precision at k.
In our experiments, we compare our model with a information-theoretic approach [7] (denoted as Rocchio KL ) developed under the Rocchio X  X  framework in combination with the ba-sic model BM25 as shown in Equation 6 and Rocchio X  X  feed-back model. According to ([45]),  X  X M25 term weighting coupled with Rocchio feedback remains a strong baseline which is at least as competitive as any language modeling approach for many tasks X . In addition, we also compare the proposed models with the state-of-the-art feedback models in language modeling (LM) retrieval framework. In partic-ular, for the basic language model, we use a Dirichlet prior (with a hyperparameter of  X  ) for smoothing the document language model, which can achieve good performance gen-erally [47].

For PRF in language modeling framework, we first com-pare our proposed model with the relevance language model [17, 19], which is a representative and state-of-the-art approach for re-estimating query language models for PRF [19]. Rel-evance language models do not explicitly model the relevant or pseudo-relevant document. Instead, they model a more generalized notion of relevance R . The formula of RM1 is: The relevance model p ( w | R ) is often used to estimate the feedback language model  X  F , and then interpolated with the original query model  X  Q in order to improve its estimation as follows:  X  Q 0 = (1  X   X  )  X   X  Q +  X   X   X  F . This interpolated version of relevance model is called RM3 . Lv et al. [19] systemati-cally compared five state-of-the-art approaches for estimat-ing query language models in ad-hoc retrieval, in which RM3 not only yields impressive retrieval performance in both pre-cision and recall metric, but also performs steadily. In par-ticular, we apply Dirichlet prior for smoothing document language models [46].
As we can see from all the PRF retrieval models in our ex-periments, there are several controlling parameters to tune. In order to build strong baseline, the parameter b in BM25 and  X  in LM are optimized as follows. For the smoothing parameter  X  in LM with Dirichlet prior, we sweep over val-ues from 500 to 2000 with an interval of 50. Meanwhile, we sweep the values of b for BM25 from 0 to 1.0 with an inter-val of 0.05. In order to find the optimal parameter setting for fair comparisons, we use the training method presented in [11] for all the PRF baselines and our models, which is popular in the IR domain for building strong baselines. To evaluate the baselines and our proposed approach, we use 2-fold cross-validation, in which the TREC queries are par-titioned into two sets by the parity of their numbers on each collection. Then, the parameters learned on the training set are applied to the test set for evaluation purpose as in [23].
Specifically, for parameters in PRF models, we evaluate all PRF models with different settings of feedback document size ( | D f | X  X  5 , 10 , 15 , 20 , 30 , 50 } ). We sweep the number of expansion terms over ( k  X  { 10, 15, 20, 25, 30, 35, 50 } ), and
As we mentioned in the previous section, the results of both basic models are optimized using the same method. Therefore, it is fair to compare them on these six collections. As we can see from Table 2, BM25 slightly outperforms LM with Dirichlet prior on the Disk1&amp;2, WT10G and WT2G collections, while LM is superior on the other three collec-tions. The performance of these two basic models are gen-erally comparative, and no significant difference is observed. So it is reasonable to use them as the basic models of the PRF baselines and our proposed model.
In Table 3, we present the results of the baseline PRF models and our proposed PRF model with different settings of feedback documents. We denote our PRF model as TF-PRF . The last row in each of these tables is the average per-formance of each PRF model with different settings. We calculate the average MAP scores of each query with dif-ferent number of D f , and then conduct significant test. In particular, a  X * X  and a  X + X  indicate a statistically signifi-cant improvement over Rocchio KL and RM3 respectively, according to the Wilcoxon matched-pairs signed-ranks test at the 0.05 level. The bold phase style in a row means that it is the best result. As we mentioned in Section 4.2, the basic retrieval models of Rocchio KL is using BM25 for fair comparison.

First, both of Rocchio KL and RM3 have proven effective and been considered as strong baselines in previous stud-ies. The Rocchio KL model outperforms the RM3 model on the disk4&amp;5, Robust04, WT2G, GOV2 and Robust04 collec-tions, but defeated by the latter on the WT10G collection in terms of average MAP. In terms of average MAP and P@20, our proposed TF-PRF model is generally better than the two baseline PRF models on all collections, and achieve significant better results in most cases. The maximum av-erage improvement is as high as 8.00% and 8.25 in terms of MAP and P@20, respectively. Thus it is fair to conclude that our proposed models can outperform Rocchio KL and RM3 generally.

Second, with the increase of feedback document size | D f the performance of our proposed TF-PRF model is much sta-bler than the Rocchio KL model and the RM3 model. When | D f | is 50, both the baseline models obtain the worst results while our proposed TF-PRF model can still get very good per-formance on all the six collections. Besides, the optimal | D for our proposed TF-PRF model is always larger than that for the baseline models. To some extent, this phenomenon proves the effectiveness of the the weighted term frequency transformation method. Usually, when | D f | is very small, the top-k documents are more likely to be relevant, and it is reasonable to treat them equally and obtain good perfor-mance. However, when | D f | increases, the ratio of relevant documents will decrease. Since we have already taken this factor into account, the weights of feedback documents will be adjusted so that we can still obtain satisfying results. On the contrary, the baseline models which still treat the feedback documents equally may fail in this case.

Third, it is also interesting to note on Disk1&amp;2 that as the increase of | D f | , the performance of all the PRF models increases. When | D f | increases to 50, there is only a slight decrease. It means most of the feedback documents are at least not harmful to PRF, which differs from all other collec-tions. This is the only case that our TF-PRF model is slightly inferior to Rocchio KL , though it still performs significantly better that RM3. The main reason is that the TF 1 trans-formation method down-weight the term frequency of terms in lower-ranked documents.

To summarize, all the PRF models generally outperform the basic models (BM25 and LM). Meanwhile, the perfor-mance of the baseline PRF models, namely the Rocchio KL model and the RM3 model, is generally comparable on all the five collections, except Disk1&amp;2. Moreover, our pro-posed model, TF-PRF , makes significant improvements over the baseline models and extensive experiments have shown the effectiveness of TF-PRF especially when a relatively larger value of | D f | is used.
As we can see from the above experiments, the number of feedback documents | D f | can greatly impact the perfor-mance of PRF models, and the choice of | D f | turns out to be a challenge problem since it is hard to determine the optimal number of feedback documents. In this section, we further analyze their robustness of our proposed PRF models with respect to | D f | .

From Figure 5.3, it is clear to have a picture about the robustness of each method. Generally, the performance of all methods increases at the beginning when the number of feedback documents | D f | grows up. However, there is no unique optimal value of | D f | for all of them. The perfor-mance of each method starts to continuously drop after a peak. For example, TF-PRF obtains the best value when | D f | is 30 while RM3 performs the best when | D f | is 5 on the disk4&amp;5 collection. Meanwhile, the best performance of TF-PRF is much better than that of RM3 on this collection. the average performance of each PRF model with different | D phase style means that it is the best result.

In addition, the best values of | D f | of TF-PRF are larger than those for Rocchio KL and RM3 in most cases. This indicates that our proposed methods can make better use of feedback documents. Furthermore, after the peak point, the curve of TF-PRF falls down much smoother than those of the baselines. When | D f | is 50, which means 50 feedback documents are selected, the performance of our proposed methods are much better than Rocchio KL and RM3 on all most collections. Thus, it is clear that our proposed method performs more robustly with respect to | D f | . We also ob-serve that our proposed model can obtain the best perfor-mance on all the six collections which are of different sizes and quality. This is a solid evidence that the TF-PRF model can make better use of the feedback documents to improve the overall performance and constantly get good results.
In addition, it is also interesting to note that the per-formance of TF-PRF first increases with the increase of | D (this is especially obvious on the disk4&amp;5, WT2G and GOV2 collections), and then after the peak point it stays relatively stable on all collections. The reasons are two-fold. First, the increase in the first phase is due to the utilization of more useful feedback documents, though the optimal values of | D f | are different on different collections. In other words, the performance of PRF models can be increased by using more useful feedback documents. Second, since TF-PRF uses a weighted term frequency of candidate feedback documents, it is possible to reduce the negative impact of feedback docu-ments with lower qualities. This leads to the stability of our proposed models after the peak points. So it is always safe to choose a relatively larger value of | D f | . This feature of our proposed models makes it viable to address the problem of the selection of the number of feedback documents, while still keep good performance. Table 4: Comparison with PRM1, PRM2 and PRoc on Tera06 dataset. The bold phase style means that it is the best result.

MAP 0.3283 0.3322 0.3319 0.3371
P@10 0.5800 0.5306 0.5490 0.6248
P@30 0.5260 0.4884 0.4871 0.5678
P@100 0.3756 0.3671 0.3741 0.4326
In summary, the proposed model can utilize sufficient num-ber of useful feedback documents, and can also reduce the negative impact of feedback documents with lower qualities. Generally, TF-PRF can reach their best performance when | D f | is in the range of [20 , 30]. These values can be used as empirical optimal when no training data is available, al-though even larger values of | D f | do not necessarily harm the retrieval performance in terms of MAP and P@20. We also evaluate our proposed model on other data sets and similar results are observed. Due to the limit of space, we did not include all the results here.
In this section, we compare our model with the recent progress related to this paper, namely the proximity-based Rocchio X  X  model (PRoc) [24] and the position relevance model (PRM) [21]. PRoc extends the classic Rocchio X  X  model by integrating proximity information between expansion term and original query such that terms that occur closer to the original query will be given more weight in the process of relevance feedback. Unlike PRoc, PRM is developed under the language modeling framework. It extends the relevance model, which takes into account term positions and prox-imity with the similar intuition that words closer to query words are more likely to be related to the query topic, and assigns more weights to candidate expansion terms closer to the query.

To make the comparison fair, we train our parameters on the Terabyte05 topics and use Terabyte06 1 topics on the GOV2 collection for testing as Lv. et al. did in [21]. Since we do not give results for the Million Query Track so far, we do not compare our method with PRM on the ClueWeb collection with the topics of this track. In [21], parameter  X  in the Dirichlet smoothing is set to an optimal value of 1500, and b in our basic model, BM25, is set to 0.3 as PRoc in [24]. As we mentioned previously, the performance of BM25 and LM with Dirichlet smoothing does not differ significantly on the GOV2 collection. Therefore, this setting will not affect the comparison. Since PRoc3 is the most robust and per-forms the best generally among PRoc X  X  three variants, it is selected to make this comparison. There are two versions of PRM, PRM1 and PRM2, which behave differently with different evaluation measures. So the results of both PRM1 and PRM2 are obtained directly from [21] for fair compari-son. http://trec.nist.gov/data/terabyte.html
First, as we can see from Table 4, the TF-PRF model out-performs PRoc3 and PRM1 in terms of all metrics, which indicates the general effectiveness of our model. Second, it is also interesting to notice that TF-PRF is markedly superior to PRoc3, PRM2 and PRM1 by up to 17.8% improvement in terms of P@10, P@30 and P@100 which is more significant than on MAP. It shows that our model has more advantages in applications that emphasize the top results. In summary, our model is at least comparable to the recent progress in both probabilistic model and language model framework in MAP, and significantly better in P@10, P@30 and P@100.
In this paper, a new feedback model, TF-PRF , is proposed by incorporating three different term frequency transforma-tion methods into the classic Rocchio X  X  model. Specifically, we present three term frequency transformation methods to capture the saliency of an expansion terms from differ-ent local aspects. Then, three frequency measures, namely weighted term frequency, relative term frequency and kernel-based term frequency, are integrated for capturing the over-all saliency of expansion terms.

Experiment results on six standard TREC data sets show that the proposed TF-PRF model is very effective and robust, and significantly outperforms strong baseline PRF models in different retrieval frameworks. Meanwhile, our proposed TF-PRF is at least competitive to the most recent work, the PRoc model and the PRM model. Compared to the Rocchio KL model, the proposed model is also less sensitive to the setting of parameter | D f | , the number of feedback documents. Ad-ditionally, we carefully analyze the robustness of our model with respect to the number of feedback documents, and an empirical rule to set this parameter is suggested.

There are several interesting future research directions to further explore. We would like to study more term frequency transformation techniques and try to use machine learning models to further optimize the PRF procedure. Another possible research direction is to study how the parameters in our model can be set automatically. It is also interesting to study different normalization and combination methods for integrating the three TF transformation techniques pro-posed in this paper, and to evaluate our models on more collections (e.g. ClueWeb). This research is supported by the research grant from the Natural Sciences &amp; Engineering Research Council (NSERC) of Canada and the Early Researcher Award/ Premier X  X  Re-search Excellence Award. We thank five anonymous review-ers for their thorough review comments on this paper.
