
Hiroshi Fujimoto 1 ,MinoruEtoh 2 , Akira Kinno 1 , and Yoshikazu Akinaga 1 Web access user behavior analysis is, in ge neral, the first cruci al step of person-alized web applications such as advertizing, recommendation, and web search. A survey by Guandong Xu et al. [10] indicated that those applications include personalization and recommendation systems [13,19,7,3], web site modification or redesign [17] and business intelligence and e-commerce [1].

To realize the analysis needed, the a pplication system monitors web access behavior at sites, which are categorized into clients, servers and proxies. De-pending on the application, the monitoring site category and modeling of user web access may differ. This paper focuses on  X  X opic modeling X  which means that documents (i.e., users) are represented as mixtures of topics (i.e., abstracted user profile components), where a topic is a probability distribution over words (i.e., user web access actions). There h ave been comprehensive contributions regarding the topic modeling of user web access behavior.

Most successful topic modeling techni ques target domain-specific and application-oriented web analysis. By narrowing user actions to viewed contents, it offers excellent performance for recommendation and targeted advertisement [2,5,9,14,22,23]. The extracted topics, in other words, abstracted user intentions, enable the system to infer the user X  X  nex t action. Please note that they used SVD (singular value decomposition) [8], LSI (Latent Semantic Indexing) [18] or pLSA (probabilistic Latent Semantic Analysis) [20] as the probabilistic models, since their contributions appeared in the early 2000 X  X . As an update, LDA (Latent Dirichlet Allocation) [6] or more sophisticated models could be used instead.
The motivation for this paper lies in the authors X  belief that proxy data with a better topic and action model will yiel d deeper user analysis, whose results are not domain-specific nor application-oriented, but rather broadened to represent social group description s. The research scope of this paper seems to be similar to [11], which compared LDA to pLSA for probabilistic modeling, and associ-ated user sessions with multiple topic s to describe the user sessions in terms of viewed web pages. This paper, however, focuses on the association between words (i.e., user web accesses) and the observed click streams rather than proba-bilistic modeling. We also use an LDA model for topic modeling though, simply taking viewed pages as words doesn X  X  work, since a click stream contains many meaningless pages. Given a lot of proxy data, the key issue is how to select the appropriate words so as to symbolize sessions.

Our original contributions consist of 1. a word association scheme: we call it the  X  cross-hierarchical directory match-2. an empirical study at Osaka University of proxy log analysis. The log con-1.1 LDA Formulation We assume topic modeling where the user accesses Web pages under certain topics (i.e., abstracted user intentions or tasks). For example, the user accesses a certain SNS site under his latent topic  X  X NS-addict X , or accesses a certain job site under her latent topic  X  X ob Hunting X . In this case, by applying the concepts of LDA, a Web user should correspond to a document, accessed web contents correspond to words, and their latent topics correspond to topics of documents. The observed accesses of each user are input to the LDA model, which then outputs the association between users and topics.
 1.2 Cross-Hierarchical Directory Matching Given a session with time duration t, the task is to label the session with mul-tiple words. In the text mining domain, dictionaries and abstraction are being used with promising results [15,25]. A dictionary should cover a broad set of comprehensive concepts and words.

We use Yahoo! Directory [26] for the dictionary as it has a simple ontology structure, a category hierarchy containing paths of abstraction. For example, we extract a specific site  X  X he New York Times X  from a session from web accesses it contains.

We may have more specific sites such as  X  X hina -The New York Times X  as a sub-category of Newspapers. In this ex ample, we abstract those specific sub-categories to the uppermost sites that appear in the session. The results mirror breadth-first search (BFS) with multiple outputs. Our underlying assump-tion is that the most abstract URL that appears in the session best represents the user X  X  intention. Those abstracted URLs are identified from bookmarks and the landing URLs of search results. Thus, along with the direc-tory structure, we can apply automatically adjusted abstraction to the found URLs. We call our proposal  X  X ross-Hierarchical Directory matching. User topic modeling is the action of identifying topics that web users are inter-ested in based on their web actions. To realize it, we employ the LDA model, which was originally proposed as a probabilistic document-topic model in the document categorization domain. LDA assumes a  X  X ag of words X , i.e. each doc-ument is thought of as a vector of word co unts. Each document is represented as a probability distribution of some topics, while each topic is represented as a probability distribution over a number of words. More formally, by assuming the Dirichlet distribution for per-topic word multinomial as shown in [21], the document-topic distribution p ( z | d ) is denoted as  X  and the topic-word distribu-tion p ( v | z ) is denoted as  X  ,where z represents a topic, d represents a document, v represents a word,  X  and  X  represent hyper-parameters , N d is the total number of words in document d under the graphical model shown in Figure 1.

We assume topic modeling where the user accesses Web pages under certain topics (i.e., abstracted user intentions or tasks). For example, the user accesses a certain SNS site under his latent topic  X  X NS-addict X , or accesses a certain job site under her latent topic  X  X ob Hunting X . In this case, by applying concepts of LDA, a Web user should correspond to a document, accessed web pages corre-spond to words, and their latent topics correspond to topics of documents. The observed accesses of each user are input to the LDA model, which then outputs the association between users and topics. In detail, under the notation shown in Table 1, the input and the outputs are as follows:
Inputs: matrix N where each line denotes the counts of words each user accessed.
 Output1: matrix  X  where each line denotes the topic distribution of each user. Output2: matrix  X  where each line denotes word distributions of each topic. The goal of topic modeling is to derive the optimal outputs  X  and  X  ,wherethe topics of each user are represented by  X  and each topic is represented by  X  .To realize this, optimal input N is needed. The simplest approach, which takes all the accessed URLs as words (i.e. the approach of [11]) doesn X  X  work, since many URLs are not related to the users X  intention. Moreover, it is said in the text mining domain that word sets should be abstracted by dictionaries if a proper model is desired. Our goal is to model user-topic association. This can be realized by deriving the optimal input matrix N for the LDA model by using dictionaries in the abstraction of the original web accesses. In this section, we will show an approach based on the use of proxy logs.
 3.1 Description of Proxy log To reach our goals, we require that the proxy log for each user d m satisfies the following conditions; each record has, at least, acces s time and accessed URL. The records are sorted in chronologica l order. A user session is also defined as a series of continuous records for each us er. Each session has a time out interval  X  , so the session ends when the user does not access any web page in interval  X  . Formally, under the notation shown in Table 2, for each user d m , each session S i consists of a series of r ecords and each record s t ij and accessed URL l 3.2 Basic Idea of Labeling Words to User Session We define word set V ( m ) i is the abstraction of URLs from L ( m ) i ,aseriesofURLs in session S ( m ) i . For example, when user d m accesses a certain SNS community site, the abstracted URL is v w ,soword v w is assigned as the session label. Details of the abstraction process are explained in the next subsection.
 An example of the relationships between sessions and words is shown in Figure 2. Each session is labeled by one or more words. For example in Session1, both URLs are abstracted to v 1 and v 1 is assigned to the session. Note that we allow multiple words to be labeled to a single session shown by Session 2 and 3 in the figure.

After all sessions of all users are labeled, a set of words V can be derived as the union of words in all sessions of all users, while the number of words accessed by each user  X  ( u m ,c w ) can be derived as the number of sessions labeled v w for each user u m . This is formally represented as follows: 3.3 Cross-Hierarchical Directory matching Cross-Hierarchical Directory matching (CHDM) [12] is a method that uses a hi-erarchical dictionary to get a set of abstracted URLs that are broader in concept than the originally accessed URLs. We apply CHDM to each user session to get a set of abstracted UR Ls in the session.

Simple examples are shown in Figure 3. The figure places a user session on the left, and the hierarchical dictionary on the right. The dictionary should have an ontology structure and a category hierarchy among URLs (To distinguish these URLs from proxy log entries, we call the former SURL.) that supports path abstraction. 6 URLs are accessed in t he session, and there are 5 categories (c1-c5) and 4 SURLs are found in the dictionary.

At the matching step, URLs accessed at t1, t2, t3, t4, and t5 belong to the respective SURLs in the dictionary as in the column  X  X atched SURL X . Corresponding categories of the matched SURLs are also obtained straightfor-wardly in the column  X  X atched Category X . This yields pairs (c2,  X  X ttp://x2.y.z/ X ), (c3,  X  X ttp://x.z.y/ X ), (c4, http://x4.y.z/), and (c5,  X  X ttp://x.y.z/w/ X ) which are assigned to the session.
In the abstraction step, both  X  X ttp://x4.y.z/ X  and  X  X ttp://x.y.z/w/ X  are abstracted to  X  X ttp://x.y.z/ X  since corresponding categories (c4 and c5) are subordinate concepts of c3.

As a result, the set of remaining SURLS, i.e. ( X  X ttp://x.y.z/ X , and  X  X ttp://x2.y.z X ) is the abstracted se t of accessed web URLs in the session, and so is assigned as the word set. In this section, we show two results of an experiment on a real proxy log. The first result shows the optimality of CHDM, and the second shows the 24 topics derived for students in Osaka University. 4.1 Data Sets and Evaluation Settings We captured a set of proxy log recorded accesses from over 7500 students in Osaka University. The log, which occupied 40 GB, covered the four month period from April to July 2010. We divided the records into sessions for each user where session timeout  X  was set to 1800 [sec]. This yielded 175831 sessions for 7537 users. We prepared a dictionary by crawling Yahoo! JAPAN Directory [26] in July 2010. This yielded a hierarchical dictionary with about 570 thousand distinct SURLs.
 We matched the log entries against the dictionary in the manner of CHDM. This yielded, as the first result, over 20 thousand distinct words including many very minor words. We eliminated minor words (those with fewer than 4 users) to obtain 1150 test words.
 We ran LDA following [24] which describes the parallel implementation of LDA and used Gibbs sampling as the inference algorithm. We set hyper-parameters  X  and  X  to | Z | / 50 and 0.01 respectively as recommended by the authors. 4.2 Evaluation Metrics To evaluate the optimality of the LDA model, we introduce perplexity [6], a common evaluation metric of clustering quality. Perplexity is a measure of the ability of a model to generalize documents. The better the generalization per-formance of a model is, the lower is the perplexity score of its output. More formally, perplexity is: where N m is the total number of observed words for each user d m . Perplexity is derived as cross-validated value such that  X  ( z k ,v w ) is derived from training set, users in the test set are denoted as  X  m .) We prepared a proxy log of the data gathered over the first 3 months as the training set and the last 1 month as the test set. 4.3 Optimality Analysis of LDA Model We first show the perplexity versus the number of topics | Z | from 4 to 100; the parameter is session timeout  X  with input matrix N . The plots are shown in Figure 4. Since the results show that 1800 [sec] is a good choice and yields a better LDA model than the other values, we empirically set  X  to 1800 [sec].
Next we examine the optimality analysis of Cross-Hierarchical Directory matching in a comparison against other three word sets. The first is non-abstraction; that is, the word set is simply the URLs accessed in the session, i.e. L ( m ) i . This is the same approach as [11]. The second is directory-matching; the word set is the set of matched SURLs in the dictionary, i.e. L ( m ) i .Thethird is rough abstraction; that is, all the URLs that contains  X  X saka-u X  (a part of the domain name of Osaka University) are abstracted to the one word  X  X saka University X  after processed the Cross-Hi erarchical Directory matching. This is, the abstraction does not follow the conceptual hierarchy.

The results are shown in Figure 4(right). Our method yields the lowest per-plexity. In particular, its perplexity is about 10% lower than that of directory-matching (the number of topics is 24), so the abstraction ability of our approach is quite good even when the same dictionar y is used. Moreover rough-abstraction suffers from the performance degradation imposed by Cross-Hierarchical Di-rectory matching. Our clear finding is that abstraction without following the conceptual hierarchy does not work.

Please note that our approach is based on the heuristic assumption that the most abstracted URLs that appear in the se ssion represents the users X  intensions. Although the assumption is proved to be correct by the empirical evaluation conducted on our data sets, there is no assurance the same will be achieved with other data or other dictionaries. 4.4 Visualizing 24 Topics and Student Characterization Finally we describe below the 24 interesting topics output by LDA. (We chose the number of topics as 24 such that all the topics involve more than 1 % students.) All the topics (named by authors) and their major words (or their description) are shown in Table 3. Each topic has distinctive words and they imply the interests or tasks of the corresponding users.

Another interesting finding is that some topics are strongly biased by the students X  attributes such as grades or majors. To visualize this, we defined the pair of attribute values  X  X cience degree ( x m ) X  and  X  X igher grades degree ( y m ) X  as implicit attributes of each user derived from the latent topics. We then modeled the associations between the latent topics and the implicit attributes for each user as a regression formula as follows: Input: {  X  ( d m ,z k ) ,a k } 24 k =1
Output: a m ,where a k is the pair of attribute values ( x k , y k ) of each topic, and a m is the pair of implicit attribute values ( x m , y m )ofuser d m The attribute value of each topic a k was derived as follows. We can know which topics each student focused on by choosing the topic with maximum probability on matrix  X  . We also prepared two real attribute values, i.e.  X  X ajor X  and  X  X rade X  for each user. The major was taken from the students X  major (science major set 1 and non-science major set -1), while the grade was taken from their grade (1st grade set 1,..., 4th grade set 4). Finally we determined a k as follows where x k is the average  X  X ajor X  and y k is the average  X  X rade X  among the students focusing on the topic. We placed a group of students into a learning set for the formula. In the learning phase, output a m was set to a  X  k where  X  k was the topic of interest of each user. We trained the formula by Relevance Vector Regression using RVM [16], which yielded a pair of implicit attributes a m for each student. The results are shown in Figure 5. The implicit attribute values of all 7537 users are plotted where the x-axis represents  X  X cience de gree X  and the y-axis represents  X  X igher grade degree X . Each point is color-coded b y the user X  X  topic of interest. The figure also plots the distribution of the number of students interested in each topic at the lower left of the figure where each topic number (from 1 to 24) mirrors the number in Table 3.
 The figure shows that points with the same topic tend to cluster together. This indicates the fact that there is a strong relationship between the topics of interest and the attributes of students. Of particular interest topics points that are strongly attribute-biased tend to form clearly distinct vectors. Examples of attribute-biased topics are  X  X ull-Time Job Hunting X  (#3),  X  X ajor in Bioscience X  (#8),  X  X ikipedia User X (#19) or  X  X riting Report X  (#21). We investigated the corresponding Web accesses in the proxy log and the summarization is as shown in the figure. On the other hand,  X  X NS Addict X (#4) or  X  X witterer X (#23) are not biased, i.e. students use these community sites regardless of their attributes. Profiling Web users by their interests is a key technique for many Web appli-cations such as recommendation, site optimization, and collaborative filtering. In this paper, we proposed a user profiling method that uses the LDA model to assess Web access patterns and their laten t topics. To derive an optimal model, our method employs a hierarchical URL dictionary to abstract Web accesses into broader concept words. Experimen ts on real proxy log data showed the op-timality of our method, and also visualized 24 interesting topics. In future, we intend to apply our model to a recommendation of Web contents and evaluate the effectiveness on real application.

