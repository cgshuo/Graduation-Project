 Discounted cumulative gain (DCG) is widely used for eval-uating ranking functions. It is therefore natural to learn a ranking function that directly optimizes DCG. However, DCG is non-smooth, rendering gradient-based optimization algorithms inapplicable. To remedy this, smoothed versions of DCG have been proposed but with only partial success. In this paper, we first present analysis that shows it is inef-fective using the gradient of the smoothed DCG to drive the optimization algorithm. We then propose a novel approach, SHF-SDCG, for smoothing DCG by using smoothed hinge functions (SHF). It has the advantage of seamlessly transi-tion from driving the optimization mimicking pairwise learn-ing when the ranking function does not fit the data well, to driving the optimization using DCG when the ranking func-tion becomes more accurate. SHF-SDCG is then extended to REG-SHF-SDCG, an algorithm which gradually transits from pointwise and pairwise to listwise learning. Finally ex-perimental results are provided to validate the effectiveness of SHF-SDCG and REG-SHF-SDCG.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval X  Retrieval functions Algorithms, Experiments ranking function, learning to rank, machine learning, opti-mization, gradient descent, gradient boosting
Search engines are widely used tools for effectively explor-ing the information on the web. The core of a search engine is its ranking function: When a search engine receives a user query, this function assigns a real valued score to each of a given set of documents (or web URLs). The search engine then returns the list of documents according to the decreas-ing order of scores, which means the the larger the score of a document, the more relevant this document is to the user query.

Many approaches have been proposed for constructing the ranking function due to its important role in search en-gines. In particular, adopting the machine learning meth-ods to learn the ranking function, or learning to rank, has recently attracted more and more efforts. In these meth-ods, the training data contains a set of queries, a set of documents for each query and a label or grade for each doc-ument indicating the degree of relevance of this document to its corresponding query. For example, each grade can be one element in the ordinal set: which is generally assigned by human editors.

The Discounted Cumulative Gain (DCG) has been widely used as a main measurement to assess relevance in the con-text of search engines [2]. Therefore, when constructing a learning to rank approach, it is important to consider how to optimize model parameters with respect to the DCG value. Many machine learning algorithms apply the gradient based techniques for parameter optimization. Unfortunately, the DCG metric is not smooth. This makes it difficult to directly optimize it with gradient based approaches. Consequently many current ranking algorithms turn to optimize other ob-jectives, such as regression error and pairwise preferences.
To solve this problem, recently the SoftRank approach [4] treats the deterministic output values of a ranking function as Gaussian random variables, based on which a smooth approximation of DCG is derived.

In this paper, we also start from the idea of constructing a smooth DCG objective function. Similar as SoftRank, it is a smooth approximation of DCG. However, our approx-imation is deterministic and random distributions are not involved. More importantly, our main contribution is to show the problems of this approach and elucidate that di-rectly optimizing this approximation of DCG is still not a good way to learn the ranking function, even it is smooth. We then provide solutions to overcome these problems to construct our algorithms for the learning to rank problem. Specifically, we propose a SHF-SDCG algorithm, which uses smooth hinge functions (SHF). This algorithm has the ad-vantage of seamlessly transition from driving the optimiza-tion mimicking pairwise learning when the ranking function does not fit the data well, to driving the optimization us-ing DCG when the ranking function becomes more accu-rate. Then SHF-SDCG is further improved and extended to REG-SHF-SDCG, which firstly reaches a reasonably well solution by regression.

The remaining of this paper is organized as follows. In section 2, we formulate a smooth DCG objective, which is the start of our approach. Section 3 is the main part, which explains the problems of learning a ranking function by directly optimizing this approximation of DCG, even it is smooth. And we provide our solutions to these problems which lead to two ranking algorithms SHF-SDCG and REG-SHF-SDCG. Experimental results are provided in section 4 and we conclude the paper in the last section.
For one query, and a list of n documents, suppose the relevance grade of the i -th document with respect to this query is y i , then the DCG is defined as In equation (2), r i is the rank of the i -th document, k is a positive integer, while the weight function W k ( r i ) equals 1 if r  X  k , and 0 otherwise. Another widely used DCG metric is the Normalized DCG (NDCG) [2], which is defined as where Z is the normalization factor such that the perfect ranking of the list gives an NDCG value of 1.

In the following, we will focus on DCG@k metric to derive our ranking algorithm. But our approach can be straight-forwardly applied to NDCG@k.
In (2), the rank value r i can be approximated as r i  X  1 + for document i and j of the ranking function, and H (  X  ) is the step function,
The sigmoid function G  X  (  X  ) can be adopted as a smooth approximation of the step function H (  X  ): where  X  &gt; 0 is a parameter. Based on G  X  (  X  ), we can build smooth approximations for r i and W k (  X  ): Now we can define a smooth approximation of DCG@k: where  X  r i and  X  W k are defined in (6) and (7) respectively. Clearly SDCG@k is smooth and can be readily optimized by gradient based algorithms. In particular, we adopt the Gradient Boosting Tree [1] GBT approach to optimize it.
In this section, We will carry out a careful analysis of the gradient of the SDCG objective to pinpoint some of its problems, which result in our proposed ranking algorithms.
To facilitate the discussion, we consider a simple situation where there are only two documents x 1 and x 2 for a query, with relevance grades y 1 and y 2 respectively.

Let o i denote the output value of the ranking function for document x i ( i = 1 , 2). First we investigate the gradient of the SDCG objective with respect to o i : where  X  = 1 if j = 1 , and -1 otherwise.

From Figure 1, we can see that the curve of G  X  ( x ) is flat, i.e. the gradient value of close to 0, when the absolute value of x is large, and it has relatively larger values when x is close to 0. Suppose y 2 &lt; y 1 and at a certain Gradient Descent GD iteration, the ranking function gives the wrong order for this two documents, i.e. o 2 &gt; o 1 . Based on (10) and Figure 1, we can see that the a larger value of o 2  X  o 1 can lead order of these two documents is difficult since o 2  X  o 1 changed very little by the current GD iteration. This is not desirable since we hope in each iteration we can focus more on those incorrectly ranked pairs and correct them quickly.
Even worse, from (10) we can see that, Therefore the two terms on the right hand side of (9) give op-posite updating directions for o i , i = 1 , 2, which means that the optimization procedure is quite inefficient. By investi-gating the above simple case, we can see that even though the SDCG objective is smooth, directly optimizing this objective is not effective since correcting wrongly ranked pairs requires many optimization iterations. To overcome this problem, we propose to modify the calculation of  X  r 1 and  X  r 2 as follows: where and It is interesting to note that A  X  ( x ) and B  X  ( x ) can be con-sidered as a smoothed version of the hinge functions. The figure of the three functions G  X  (  X  ) with A  X  (  X  ) and B  X  (  X  ) are displayed in Figure 1. Based on (14) and (15), we can see that when o 2 &gt; o 1 , we have: where 1  X  i, j  X  2. This way, whenever the ranking order of these two documents is wrong, the GD iterations can effectively update them towards the right direction.
Thus, by replacing G  X  (  X  ) with A  X  (  X  ) and B  X  (  X  ) for  X  r (12) and  X  r 2 in (13), we can overcome the problems described above. By replacing the sigmoid function with SHFs, we obtain anthoer objective, which will be called SHF-SDCG in the following. In (8), there is a weight function  X  W k (  X  ) calculated as (7). Suppose at a certain GD iteration, a perfectly relevant doc-ument for a query is not well ranked at position, say, k + n . The weight value of this document is G  X  ( n ), which decreases very fast as n increases. This means this wrongly ranked documents tend to be ignored and hence improving their ranks is difficult. Let s m denote the largest rank value of the top k documents, i.e. the k most relevant documents, for a query at the m -th GD iteration, we modify the weight function in (7) as, This way, we can make sure that all the top k documents of each query can get enough weights. The width s m becomes smaller and smaller as GD iterations keep improving the ranking result. When s m is close to k ,  X  W m (  X  ) is also close to the original weight function W k (  X  ) in DCG metric (2). This is similar as the idea of the Deterministic Annealing (DA) algorithm. In order to solve a difficult optimization problem, DA optimizes a series of objective functions, which are easier to optimize and gradually approach the original objective.
Our objective function is not convex. Therefore a good starting point is helpful for obtaining a good result. We pro-pose to smoothly mix SHF-SDCG with regression by mini-mizing the following objective function: where R is the regression error, 0  X   X  m  X  1 decreases when the number of iterations m increases, giving SHF-SDCG more and more weights. In our algorithm,  X  m is calculated as: where M is the total number of the iterations, and  X  is chosen such that  X  1 = 0 . 999999 . According to (19),  X  m when m = M/ 2. Namely, regression error and SHF-SDCG have the same weight when half of the iterations have been finished. This is just a heuristic choice, and in practice we found it usually leads to good results.

In the following, we use REG-SHF-SDCG to denote ob-jective defined based on (18) and (19).
In REG-SHF-SDCG, at the beginning, minimizing the re-gression error, which is pointwise, is the focus of optimiza-tion such that a reasonably good ranking solution can be reached. As the number of iterations increases, the second term in (18), i.e. SHF-SDCG has more and more impor-tance. At this time, for a query, when there are many in-correctly ranked pairs, SHF-SDCG is not an accurate ap-proximation of the true DCG value. For this query, the optimization procedure is mainly to correct those wrongly ranked pairs, which is more like a pairwise approach. As the number of iterations increases more and the ranking result is further improved, for the queries whose most documents are correctly ranked, and SHF-SDCG is a good smooth approxi-mation of DCG metric, optimizing SHF-SDCG can lead to a good DCG value. Namely, at this stage, a listwise objective is being optimized. Hence we can see that in REG-SHF-SDCG and SHF-SDCG, we actually transit from pointwise and pairwise to listwise learning.
For this search engine data set, we extracted about 400 features. The queries are sampled from the search engine query logs and a certain number of query-document pairs are labeled according to their relevance judged by human editors. The five levels of grades shown in (1) is adopted. For experiment, we used a training, a validation and a test set, which contain 8179, 3755 and 916 queries respectively. The number of query-url pairs constrained in these three data sets are 322763, 111561 and 32008.

In [5], a pairwise ranking algorithm called GBRank, is pre-sented which shows the state of art ranking results. It also adopts the GBT framework for training and optimization. We will include GBRank for comparison. As a baseline, we also show the results of a simple regression approach, de-noted by Regression in the following, which uses the GBT method to train a regression model.

In the experiment, 600 trees were used for all these five algorithms. Figure 2 gives the results. It can be seen that REG-SHF-SDCG compares favorably to all the other algo-rithms. In particular, REG-SHF-SDCG outperforms SHF-SDCG, which indicates that the mixture with regression (18) can improve the ranking results, since a better staring point can be reached. And it can be observed that both REG-SHF-SDCG and SHF-SDCG can beat the SDCG algorithm. In fact, SDCG has even lower NDCG values than Regres-sion. All these support our analysis in section 3. The OHSUMED data set we used is contained in the LETOR 3.0 package [3], which is derived from the exist-ing data sets widely used in IR. The OHSUMED data set is a subset of the MEDLINE database, which is popular in IR community. This data set contains 106 queries. The doc-uments are manually labeled with three levels of relevance grades: definitely relevant, possibly relevant and not rele-vant. Three metrics are adopted here: NDCG, Precision and Mean Average Precision (MAP), which have been used in literature of ranking.
 For OHSUMED, 250 trees were used for SDCG, SHF-SDCG and REG-SHF-SDCG. These three algorithms are compared with other six state of art learning to rank al-gorithms reported in the LETOR package. The results are listed in Table 2.

It can be observed that REG-SHF-SDCG has the high-est NDCG@1, NDCG@2 values, and it has the second best NDCG@3, NDCG@4 and NDCG@5 values. This indicates that REG-SHF-SDCG is an effective algorithm for optimiz-ing the DCG metric. The precision values of REG-SHF-SDCG are not strong compared with other algorithms, since it aims to optimize DCG metric. However, it is interest-ing to see that it has the highest MAP value, also SDCG and SHF-SDCG have better MAP values than the six al-gorithms. Also, comparing REG-SHF-SDCG, SHF-SDCG and SDCG, we can see the similar results as in the last sub-section. All these again support our proposed approaches.
We have proposed a smooth DCG approach for learning ranking functions for web search. Starting from a  X  X aithful X  smooth approximation of the DCG metric, we have eluci-dated some of its problems and pointed out that optimizing an accurate approximation of DCG metric is not effective. Then we have provided solutions to these problems and for-mulated REG-SHF-SDCG and SHF-SDCG, which can be readily optimized by the gradient descent. The proposed approaches illustrate properties of pointwise, pairwise and listwise ranking approaches in different optimization stages, and the objective functions being optimized gradually ap-proach an accurate smooth approximation of the true DCG metric. Experimental results on both a commercial search engine data set and a publicly available benchmark data set have shown encouraging results. [1] J. Friedman. Greedy function approximation: a [2] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [3] T.-Y. Liu, T. Qin, J. Xu, W. Xiong, and H. Li. Letor: [4] M. Taylor, J. Guiver, S. Robertson, and T. Minka. [5] Z. Zheng, H. Zha, K. Chen, and G. Sun. A regression
