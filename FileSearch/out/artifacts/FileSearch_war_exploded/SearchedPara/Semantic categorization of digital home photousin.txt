 1. Introduction
Semantic categorization of arbitrary image has been a challenge in recent years. The goal of the semantic categorization is to discover image semantics in pre-defined concept domain. It generally requires the effective association and interaction of high-level semantic concepts and low-level features. The main focus of many recent researches has been on detecting of multiple categories in image since an image often has multi-seman-tics ( Lim, Tian, &amp; Mulhem, 2003; Loui &amp; Savakis, 2003; Smith, Naphade, &amp; Natsev, 2002 ).
The need for semantic categorization is rightly raised in digital home photos area as well. Recently, with the proliferation of digital cameras, an enormous number of personal photos are created in digital.
Especially at home, the digital camera has been a convenient means for people to easily take photos and share them efficiently and effectively. However, the problem is that people do not frequently arrange their photos in semantically meaningful groups, choosing to rather leave them in the digital camera or in per-sonal storage. Unless people are equipped with an automatic  X  X lbuming X  tool, the albuming of photos would often mean extra works, such as sorting, selecting, annotating, and moving pictures. Therefore, classifying photos into several meaningful categories in an automatic manner is one of the most essential albuming functions, and is necessary for photo album applications as well as for general image search and retrieval systems.

Classifying photos into several meaningful categories in automatic manner is one of the most essential album functions. Image retrieval and categorization have been recently advanced by content-based analysis ( Djeraba, 2002; Lim et al., 2003; Loui &amp; Savakis, 2003; Newsam, Sumengen, &amp; Manjunath, 2003; Smith et al., 2002 ). In the content-based image categorization, an important issue has been to reduce the semantic gap between low-level visual features and high-level semantics that is close to human visual perception. In
Smith et al. (2002), Loui and Savakis (2003), Lim et al. (2003) , multiple features have been used, where color, shape, and texture features are combined to describe images and to measure similarity between images. Further, more reliable algorithms have been developed by weighted feature selection ( Lim et al., 2003; Loui &amp; Savakis, 2003 ). As mentioned above, an image often shows multiple semantic concepts. So, it is important to catch multiple category concepts in the semantic categorization. In order to do so, concept learning with segmented region has been reported in recent works ( Carson et al., 2002; Fuh, Cho, &amp; Essig, 2000 ).

In this paper, we propose a semantic categorization method in generic home photos. Our approach is to classify a collection of photos into several meaningful categories. Like generic image classification, the pro-posed method is composed of two parts: concept learning to model concept detectors and category decision by the concept detectors. The proposed categorization method incorporates an intermediate level of con-cepts, referred to as local concept, so that it catches semantic meanings of local regions of image as bridging the semantic gap of low-level features and high-level image semantics. To detect the local concepts, region segmentation by photographic region template and concept merging is also proposed. In this paper, the two levels of concepts are trained with support vector machine (SVM) ( Joachims, 1999; Muller, 2001; Scho  X  lkopf &amp; Smola, 2002 ). This paper consists of four sections. Section 2 includes the proposed semantic categoriza-tion method. The experiments and results are described in Section 3 . Finally, we conclude the paper in
Section 4 . 2. Method
This section covers the details regarding the proposed home photo categorization method. It starts from overviewing the proposed method, and then embodies it. 2.1. Overall procedure of the proposed method
Fig. 1 shows the overall procedure of the proposed categorization method. If a photo is input, its entire image region is divided into 10 sub-regions in terms of the photographic region template, which is composed of one center, four corners, two horizontals, two verticals, and one entire image regions. Multiple visual fea-tures are extracted from the sub-regions, and then they are fed into the local concept detectors. The local con-cept detector outputs a numeric confidence value for each sub-region. In order to discover more likelihood concepts on the overlapping sub-regions, concept merging is performed toward keeping the most confident concepts for the five basis sub-regions that consist of one center and four corner regions. The concept merging aims to compensate classification error due to image localization with a fixed block size.

The merged confidence values compose a new feature representing local photo semantics. The local photo semantic features are fed into the global concept detectors. A global concept is a composite of one or more local concepts, meaning that it represents higher level of semantics than the local semantics. Each global con-cept detector outputs a confidence value for each basis sub-region. The confidence value numerically repre-sents the semantic link of a region with the local concept. Finally, the input image is categorized into multiple semantic categories based on the confidence values. 2.2. Regional division for local semantics
To detect local semantics of image, an image is often factorized into several sub-regions. The popular method for image localization can be divided into object-based segmentation and block-based segmentation ( Carson et al., 2002 ). An object can be a fundamental unit to represent image semantics. The union of several objects usually represents high-level semantics. Although elaborated object segmentation is the best represen-tation of object semantics, it is time-consuming and costly in computational work to achieve reliable segmen-tation performance.

On the other hand, the block-based region segmentation is much simpler as well as faster than the object-based one. In the block-based method, a whole image region is tessellated with a fixed or variable block in order to capture potential object semantics well, i.e., the smaller block size could lead time-consuming seg-mentation work as generating many blocks while the larger block size be difficult to detect small object semantics.

To overcome the aforementioned problem, in this paper, we propose region segmentation in terms of the photographic region template that is suitably designed for general home photos. In a simple way, a photo can be considered as composed of foreground and background. There are often some foreground objects with background scenery. Without any prior information for object detection, the location and contour of fore-ground objects are unpredictable. As such, it is assumed that foreground objects could be located in any sub-region of image. In other words, semantic objects or scenes in home photo could be located in center, cor-ner, horizontal, vertical or an entire region.

In order to build meaningful region templates, three conditions are considered: the region template should be large enough to detect semantics in the local photo region, simultaneously be small enough not to be time-consuming in both of feature extraction and similarity measure, and support spatial scalability to detect photo semantics over various scale subjects.

From this observation, we proposed a photographic region template shown in Fig. 2 . The region template consists of 10 sub-regions; they are one center region ( T
Fig. 2 ), two horizontal regions ( T 6 and T 7 in Fig. 2 ), two vertical regions ( T this paper, one center and four corner regions are referred to as basis sub-regions. The center region overlaps partially with the corner, vertical and horizontal regions, and entirely with the whole photo region.
Fig. 3 shows some example photos with different photographic composition decomposed by the proposed region templates. Fig. 3 (a) describes five examples decomposed with center, corner, horizontal, vertical, and whole region templates, respectively, e.g., the second example on the left side would be decomposed well by four corner regions containing sky on the top-left, building on the top-right, river on the bottom-left, and road on the bottom-right, respectively. Fig. 3 (b) shows five examples decomposed with different combination of the region templates. The second example on the left side could be semantically decomposed well by top-left corner, bottom-left corner, and vertical-left regions showing sky, river, and field/road, respectively.
 2.3. Semantic concept learning
The concept learning is composed of two parts: local concept learning and global concept learning. The detailed learning procedure is as follows:
For local concept learning, a set of local concept is defined. Let us denote a local concept as L than global concepts. Multiple low-level features are extracted from the sub-region images that are patched from original training images. For low-level feature extraction, MPEG-7 visual descriptors are considered ( Manjun-ath, 2002 ); color structure (CS), color layout (CL), dominant color (DC), and scalable color (SC) are used for color feature and homogeneous texture (HT) and edge histogram (EH) are used for texture feature. The CS rep-
The CL represents spatial distribution of colors and it is useful to image-to-image matching. The SC represents using Haar transform. The DC provides a compact description of the representative colors in an image. Unlike a fixed-length descriptor. For this, we make the new DC feature have a fixed cardinality, which is limited to a maximum number of dominant colors. If an image has less number of dominant colors, its features for remain-ing dominant colors was padded with zero. In summary, the CS and CL are useful to represent the local color characteristics while the DC and SC represent better global color characteristics than the CS and CL do. The HT vertical, horizontal, 45  X  diagonal, 135  X  diagonal, and non-directional edges.
 important families of local concepts that would be frequently appeared in local regions of general home pho-tos. Fig. 4 shows examples of photos for the 34 local concepts. The concept families first consists of  X  X round X , of local concept, all the concept families are sub-categorized into 34 local concepts as follows: seven  X  X round X  concepts:  X  X ravel X ,  X  X ark X ,  X  X avement X ,  X  X oad X ,  X  X ock X ,  X  X and X , and  X  X idewalk X ; two  X  X uman X  concepts:  X  X ace X  and  X  X eople X ; two  X  X ndoor X  concepts:  X  X ndoor X  and  X  X ndoor-light X ; three  X  X ountain X  concepts:  X  X ield X ,  X  X eak X , and four  X  X ky X  concepts:  X  X loudy X ,  X  X unny X ,  X  X unset X , and  X  X unset-on-mountain X ; five  X  X tructure X  concepts:  X  X rick X ,  X  X rch X ,  X  X uildings X ,  X  X all X , and  X  X indows X ; and six  X  X ater X  concepts:  X  X each X ,  X  X igh-wave X ,  X  X ow-wave X ,  X  X till water X ,  X  X irrored water X , and  X  X ce (snow) X .
 To learn the local concepts, training images are patched from the original training images. In this paper,
SVM is employed as a concept detector. The SVM is a binary classifier ( Muller, 2001; Scho  X  lkopf &amp; Smola, 2002 ) used to find the decision function of optimal linear hyper-plane given a labeled data, which is linearly separable in the feature space h . In the SVM, the input feature in the space x is mapped onto a feature space h via a nonlinear mapping / (  X  ): x ! h that allows ones to perform nonlinear analysis of the input data using a linear method. In general SVM, a kernel is designed to map the input data space x to the feature space. With measures between two feature vectors without explicit computation of the map / (  X  ). The kernel k is considered as a simple dot product similarity measure between two feature vectors as follows: where / (  X  ) maps the input feature vector x into the feature space h .
 Using the kernel function, the SVM for each concept is trained with low-level features x of training data.
For this, an optimal hyper-plane is found to correctly classify the training data, i.e., it is optimized toward satisfying the following condition: w is a weight vector and b is a threshold such that z i { K ( x to the hyper-plane equals 1/ i w i .

By solving the optimization problem ( Scho  X  lkopf &amp; Smola, 2002; Muller, 2001 ), the optimal hyper-plane f to predict the L k concept of unseen low-level feature vector x is formed as follows: where x i k is support vector of the hyper-plane for the local concept L of the support vector, the z i k is corresponding class vector of the support vector, and b mized for the local concept L k .

For global concept learning, a set of global concept is also defined. Let us denote the global concept lexicon as G m , where m =1,2,3, ... , M and M is the number of global concepts. The global concept should have relatively higher level of semantics than the local concepts. Fig. 5 shows an example of the relationship between local concept and global concepts. There are two global concepts of architecture and terrain, and strong semantic link with brick, wall, windows, and road concepts while have loose semantic link with tree, leaves, grass, and flowers concepts, On the contrary, terrain would be often strongly linked with tree, leaves, grass, and flowers concepts, while be loosely linked with brick, wall, windows, and road concepts.
From this observation, we consider to express the strength of the connection in numerical based on the con-fidence values of the local concepts. The bigger confidence value means the stronger connection between the concepts. The strength of the connection could bridge the gap between low-level features and high-level image semantics. So the global concepts are trained based on the confidence vectors of the local SVM. The kernel for the global SVM is the same as that for the local SVM. Likewise, as solving the optimization problem, the opti-mal hyper-plane f m to predict the global concept G k of unseen confidence vector y is formed as follows: where y i k is support vector of the hyper-plane for the global concept G vector of the support vector, the z i m is corresponding class vector of the support vector, and b optimized for the global concept G m . 2.4. Category classification As we mentioned above, an input image is divided into 10 sub-regions by photographic region template.
Multiple low-level visual features are extracted from each sub-region and then are fed into the local concept detectors. Given an input of feature vector x to the local concept detector D value that is considered as distance of the input feature vector from the trained hyper-plane f confidence values for every concept detector forms a confidence vector c where c k is confidence value of the concept detector D k
In this paper, in order to find out more likelihood concepts on overlapping sub-regions, a concept merging is performed as keeping the most confident concepts for the basis sub-region set T ter and four corner regions, i.e., the region set { T 1 , T local concept merging. Given the five basis regions, ten region templates are grouped into five overlapping regions. The region T 1 overlaps with the region T 10 . The region T
T . The region T 3 overlaps with the region T 6 , T 9 , and T and T 10 . The region T 5 overlaps with the region T 7 , T is updated as follows: where y t cept L k on the basis region t b . It is denoted that the five overlapping regions set T { T 1 , T 2 },{ T 2 , T 6 , T 8 , T 10 },{ T 3 , T 6 , T 9 , T
Given an input of the merged confidence values y to the global concept detector D confidence value which is considered as distance of the input feature vector from the trained hyper-plane f series of the confidence values for every concept detector forms a confidence vector c where c m is confidence value of the concept detector D m following condition: where the normalization factors, c min m and c max m , is the minimum and maximum value of the confidence values for the concept G m , respectively. And the c th m is the decision threshold for the concept G can be adaptive according to the range of the confidence values for each concept. 3. Experiment and results
To demonstrate the efficacy of the proposed semantic categorization, the experiment was performed with 3828 photos that are from MPEG-7 Visual Core Experiment 2 (VCE-2) data set ( MPEG-7, 2005 ) for category-based photo clustering. The ground truth set of the test images was officially determined and cross-verified by several participants of MPEG-7 visual group. Note that the ground truth set was designed for detecting of multiple concepts; one important rule for building the ground truth set was to include all concepts of an image as its ground truth categories. So, although a semantic concept is discovered in very small region of image, it would be a ground truth of the image.

In the experiment, 1597 image were used for training sample. They are also from MPEG-7 VCE-2 official training data set that is totally different from the 3828 photos for the testing. Of the training images, 800 images were from general home photos and 797 images were from Corel image collection. The training data was localized to sub-images and then positive samples for each concept were selected from the sub-images by human visual perception. The negative samples for a concept were randomly selected from the positive sam-ples of other concepts. We also bring ground truth (GT) categories for the MPEG-7 VCE-2. The GT category are composed of seven global concepts:  X  X rchitecture X ,  X  X errain X ,  X  X ndoor X ,  X  X aterside X ,  X  X ight-scene X ,  X  X now-scape X , and  X  X unset X . They would be popular in generic home photos.

For SVM learning, we utilized a verified SVM software developed in Joachims (1999) . Experiment was per-formed with two local concept set: one contains 20 local concepts and the other contains 34 local concepts. The two experiments have the same condition except for the number of the local concept detectors.
Table 1 shows training data description of the 20 local concepts. The number of positive and negative sam-ative. Average number of training images is about 803. In human visual perception, each global concept could be coupled with some local concepts. For example,  X  X rchitecture X  would have strong semantic link with  X  X uild-ing X ,  X  X ridge X ,  X  X kyscraper X ,  X  X treet X , and  X  X indow X .

Table 2 represents global concepts defined in the experiment, and the number of positive and negative sam-ples for each global concept. Average number of training images is about 995 for positive samples and 831 for negative samples. Fig. 7 shows categorization performance of recall and precision for the seven global con-ers. The main problem of low-performed categories might be caused by semantically-biased local concept structure; i.e., currently, most of the local concepts would have strongly link with only a few global concepts. than the other categories like  X  X nowscape X  or  X  X unset X .

To solve the aforementioned problem, we increased the number of the local concepts and subdivided the local concepts in more detail. In addition, we patched the training image for the local concepts being more homogeneous, i.e., having only single semantics. Table 3 shows the description of the 34 local concepts and the number of corresponding training data. The average number of the training images is about 130, and it is much smaller than that for the above 20 local concept case. In SVM training, smaller number of support vectors often present better classifier. In this experiment, the total number of support vectors for all global concepts was 463 (125 for architecture, 96 for indoor, 45 for night-scene, 80 for snowscape, 18 for sunset, 99 for terrain, and 149 for waterside). It is less than 10% of the number of positive training samples.
Fig. 8 shows the classification performance of recall and precision in case of using the 34 local concepts. In result, the categorization performance was improved over all categories. Even though some of the categories, such as  X  X ndoor X ,  X  X nowscape X  and  X  X aterside X , showed still low performance, the average performance of recall and precision was higher than that of above 20 local concept case. It means that the 34 local concepts were better structured to catch the global concepts than the 20 local concepts. The main problem that leads to low performance in some categories is that the GT set would be very strictly designed. And also, in particular, the  X  X ndoor X ,  X  X nowscape X  and  X  X aterside X  categories have relatively small number of the GT images. So, the pre-cision of the categories would usually be very low compared with the recall. 4. Conclusions
In this paper, a semantic categorization method in generic home photos is proposed. Our approach is to detect semantically meaningful concepts contained in a photo. The main purpose of the proposed method is to incorporate an intermediate level of concepts, called local concept, so that it catches the semantic mean-ing of local regions of image as bridging the semantic gap of the low-level features and high-level category concepts. To detect the local concepts from the home photo, region segmentation by photographic region tem-plate and concept merging is also proposed. The proposed method was demonstrated with 3828 general home photos in MPEG-7 VCE-2 official data set. Experiment results showed that the proposed method would be useful to detect semantic categories of generic home photos. Although the proposed photo categorization method would be useful to detect some photo semantics, it would be not so in some others. The main problem quite needed to design a systematic ontology of local and global concepts, which should be semantically-balanced, to achieve more reliable performance. There should be also feature optimization for each concept detector.
 References
