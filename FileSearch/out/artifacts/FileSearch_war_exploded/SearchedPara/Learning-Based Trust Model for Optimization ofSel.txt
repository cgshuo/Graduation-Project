 Web services standards and technologi es are expected to contribute in reduc-ing the cost and complexity of application integration within an enterprise and across enterprise boundaries. As the deployment of Web services increases in complex business application integration , it becomes inevitable that several Web services may have the same or similar functionalities each holds different Qual-ity of Services(QoS) [2],[7],[3],[4],[8],[5]. Due to the increasing number of Web services with the same or similar functionalities, it is getting difficult for web services consumers to find most pertin ent services for their businesses. When selecting services in either dynamic or sta tic environment, there are some issues Web service clients have to consider such as input-output dependency, semantics of services and QoS requirements of serv ices. Among these issues the last one, QoS requirements of clients, is essential for clients to select their providers wisely [10], [11]. Since the nature of web services is very dynamic, it is hard to predict providers X  QoS without testing. It leads Web services clients to face a question of how to select provider web service amon g the same or similar providers which can able to provide required services that satisfying QoS requirements of client. Moreover, clients, which request the sam e services may have different perspective on each required QoS of provider Web servi ces. For instance, for the time-critical applications response time of provider is critical for clients regardless of cost of service. On the other hand, in some cases, response time is not so important but cost of service is essential. In other words, clients requiring the same type of service may request different requirements for QoS factos such as response time, availability, cost,...etc. Many researches on selecting services based on QoS met-rics have been performed either in static or in dynamic environments[2],[7],[6]. However, most of the works are still in their immature state. Three approaches such as QoS broker approach, UDDIe and QoS-model are main trends so for. But none of the approaches are able to handle problem of selecting services in dynamic environment where dynamic na ture of web services are fully exposed. Proposed approaches for selection of services up to today are lack of follow-ing points: Using reliable historical data, incorporating reliable feedbacks from other services, a technique for motivati ng client Web services to give feedbacks to their providers and user-preference-aw areness feature. Fur thermore, there is no universally accepted method for speci fying QoS of Web services fully taking into account of dynamic nature of Web services. It incurs additional coding and cost for specifying QoS of Web services wi th current suggested ways. Currently, QoS can be specified by WSDL file of Web services with additional coding of providers. Specifying QoS in WSDL file has several disadvantages: Firstly, in dy-namic selection of provider Web services , it requires additional WSDL parser for extracting QoS. Secondly, providers n eeded to update the QoS of their services frequently in order to provide reliable QoS for their consumers.

In this paper, we suggest a mechanism for specifying QoS value of Web ser-vices. The mechanism is based on a model called Trust Model and implemented as QoS Broker Web services. Proposed Trust Model is based on learning expe-riences of past actions of individual Web services and reliable feedbacks from other services to this certain provider Web service. Feedbacks from other clients are checked in order to gather only honest and useful information for later use. In this way, we can collect up to date information about QoS values of provider Web services in reliable manner. In prop osed model, each client Web service supposed to give feedback to its providers by our QoS Broker Web services. If client gives really honest and useful feedback its reputation increases otherwise decreases. This technique can be a way to motivate client Web services to give reliable feedbacks to their providers. The usage of QoS Broker Web service is up to clients either to use or not to use. Since our model is independent from other applications it will be easy to use our model with existing approaches as suggested [6]. This paper is organized as follows:
The next section addresses t hree trends of researches related to proposed ap-proach. Section 3 describes proposed Trust Model in detail. Section 4 illustrates validation method, case study and result of validation. Finally, Section 5 and Section 6 concludes our work and proposes some discussions. QoS Broker based approaches: Yutu et al.,[2] introduced open, fair and dy-namic QoS computation model by means o f central QoS registery. Their Broker architecture is human-oriented which means every time a consumer Web ser-vices should give feedback to provider we b services which leads to not collecting reliable feedback data. Gao et al.,[7] used ANN to predict dynamic performance of web services using histo rically collected data. How ever, they collected data for evaluating performance of providers which makes the data unreliable. This paper can be good solution only performance evaluation, but still there are holes like customers don X  X  given a chance to contribute their providers performance. UDDIe based approaches: Ali et al.,[12] introduced UDDIe, extension of UDDI, which has ability to express QoS information by means of blue pages in UDDI. This information allows othe r Web services to discover Web services based on QoS values. Although, it solves limitation of UDDI their work is missing two points: updating QoS values in blue page and guaranteeing the reliability of QoS values in blue page.
 QoS-Model based approaches: Mou et al.,[14] defined extensible QoS model in which authors suggested multifaceted, fuzzy, dynamic and configurable QoS metrics for Web services. They tried to incorporate above characteristics of QoS of Web services with the description lang uage. However, their model requires extra parser for dynamic Web service s election or dynamic web service coor-dination for extracting QoS metrics. Le et al.,[15] presented Quality of Service based service selection and ranking method with reputation management. Al-though they present the idea of discovering dishonest provider which is similar to our idea in come sense, their method is obscure in presenting detailed framework and identifying honest clients from dishonest ones. Our Trust Model, T(x) , is a combination of three sub function such as QTM(), MTM() and DH() . T(x,y) = { QTM(x,y), MTM(x,y).  X  DH(x) }  X  QTM( S1 , S2 ) is the function for evaluating S1 Web services abilities in order  X  MTM( S1 , S2 ) is the function which evaluates how S1 is suitable for the  X  DH( S1 ) is the function for evaluating reputation of service S1. Basically, In general, our Trust Model is defined by following equation 1.

When using T() , users can give weights for requested QoS values from provi-ders. In this way, our framework can provide user-preference-aware feature. 3.1 QoS Trust Matrix: QTM Construction of QTM matrix is composed of three steps: In first step, Web services that have similar or same functionalities are grouped. In second step, the quality of service factors for each gr oup are identified. The last step is to construct QTM matrix for each group of Web services. let X  X  make following two assumptions: First, there are three groups of web services such as A, B and C . Second, Web service group A has two QoS factors, B group has four QoS factors, C group has three QoS factors. If we construct QTM Matrix for Web services group B it looks like in figure 1 (a) . Values of QTM matrix is collected periodically by automatic QoS Broker from provider Web services. Thus, we can make QoS repository for QoS of Web ser vices which is collected historically. For instance, let X  X  assume S1 is provider Web service and S2 is requester Web service. Then QTM function value is calculated as in equation 2.

QT M ( S 1 ,S 2 )= time, cost, availability and reliability of requester service S 2. Meanwhile, RT n r C n r , A quester service S2 and RT n p C n p ,A n p ,R n p are normalized response time, cost, avail-ability and reliability of service S1 in QTM matrix. 3.2 Mutual Trust Matrix: MTM Each Web service has MTM ma trix which is constructed by feedbacks from its client Web services. MTM construction has two steps: In first step, all Web services connected to that specific Web s ervices is identified. In second step, based on client Web services feedback an d QoS factors of that Web service MTM matrix is constructed. In general, we collect feedbacks for each provider Web service from its clients. Collected feedba cks are stored in feedback repository or in MTM database. After a some time, our Feedback Manager module which we implemented in QoS Broker, updates MT M matrix with only honest feedbacks. For example, let X  X  assume that we have identified Sb1 has four client Web services such as Sa1, Sa2, Sc1 and Sc2. .

Then, all feedbacks given to Sb1 are checked by Feedback Manager module and only honest feedbacks are used to construct MTM matrix or update MTM matrix of Sb1 . The MTM matrix for above example is shown in figure 1 (b) . Following equation evaluates data in MTM matrix for provider Web service S1 for the sake of requester service S2 .
MTM ( S 1 ,S 2 )= 3.3 DH: Degree of Honesty Degree of Honesty DH() is used for evaluating client Web services feedback when constructing MTM Matrix or updating MTM Matrix. DH() function in this work was proposed to identify reputation of Web services based on their honesty de-gree. Identifying reputation and truthful ness in distributed environment is vital research on its own [9], [13]. To simplify our research, we used a normal distri-bution with historically gathered data for identifying truthfulness of feedbacks. DH() can be (+) or (-) which means DH() can be a function encouraging client Web services to give only honest feedbacks. The DH() function for service S1 is given in equation 4.
 where N f is the number of feedbacks given by service S1 to other services, and N availability, reliability and cost of other services. 3.4 QoS Broker Architecture The proposed architecture in figure 2 has three different phases. In phase one, constructing QTM matrices is the vital task. The first task in phase 1 is to get all available Web services information from UDDI and making WSGs based on their QoS metrics values and func tional similarities. The second task in phase 1 is to construct QTM matrices for each group. The third task in phase 1 is to gather QoS values for available Web services by automated Web services monitoring tool. In phase two, there are also three tasks: First, Web services Manager module identifies all interactions between any t wo Web services. Secondly, Mutual Trust Evaluation module gathers feedbacks from clients for each provider Web services and constructs MTM matrix for each provi der Web services. Finally, Trust check module identifies truthfulness of feedback gathered by Mutual Trust Evaluation Module. According to feedbacks from c lients the MTM matrix updated by only honest feedbacks. At the same time, the clients giving honest feedbacks are rewarded by increasing their value of DH() function. In phase three, there are two tasks: In first task, client Web service X  X  required QoS is evaluated and most pertinent provider Web services is returned based on Trust Model. Secondly, any requests from clients (give feedback or to calculate T()) should be handled in phase three. All the functions in our architecture are implemented as Web services. In this way, our approach can be easily used by Web services developer. In order to show applicability of our method in real life case we have taken a four groups of Web services such as Tour, Ticketing, Banking and Delivering for a case study. Each group may or may not have ten or more than ten member Web services each holding different response time, availability, reliability and cost. Following sequences of tasks perfo rmed for each Web services selected from each Web services group(WSG) 1 .
 Client  X  Tour  X  Ticket ; Tour  X  Bank  X  Ticket  X  Delivery  X  Tour.
 Validation method: Validation was done by comparing two cases: when us-ing our Trust model and when not using our Trust model. Conventionally, provider Web services is selected among c andidate provider Web services based on promised QoS of providers. In our Trust Model, provider Web services is selected based on value calculated by T(x) function. We have applied both con-ventional way and our Trust Model for the case study and identified satisfaction of client Web services by following satisfaction degree equation.

Satisfaction Degree(SD(n)) = where QoS i required is the i th required QoS factor and QoS i provided is provided QoS value for i th required QoS. If QoS i provided approaches to QoS i required SD(n) converges to n .
 Validation results: We had obtained average satisfaction degree for conven-tional way is 0.61 and the average satisfaction rate when using our Trust Model is 0.701. Although, there are pros and cons in our validation, the initial result is good enough to motivate us to move next step. We consider 0.701 is reasonable result for initial step.
 In this work, we considered dynamic nature of Web services and tried to suggest a novel method for selecting Web services which we consider more trustable than other methods. However, still our work is in its infancy and there are several issues should be discussed in this research.

First issue is the dynamic nature of Web services. Web services may be newly be published or disappeared from UDDI or entirely from the net. Some re-searchers suggested to use Web services mo nitoring and testing tool for handling this issue. However, if the number of Web services increases to be monitored it decreases the reliability of the tool. Our work suggests to use historically gath-ered data by Web services moni toring tool, feedback and DH() .Inthisway,we can gather more reliable data and more up to date information.

Secondly, validation was done in local machine with self implemented Web services and artificially generated QoS values. Our result was obtained by taking average result of 400 experiments under different cases (increasing/decreasing overhead of machine) .

Thirdly, we used only response time for the validation. Although response time is critical factor, there is also need to consider other QoS factors for our validation. However, our initial validation motivates us to do next validation with multiple QoS factors. Finally, honest feedbacks are identified by historically gathered data which is not wise way. However, for initial research our way to identify honest feedbacks supports our approach.
 In this paper, we suggested a mechanism fo r specifying QoS(Quality of Services) for Web services based on so-called Trust Model. Trust Model is a function T(x) where it consists of three sub functions such as QTM(), MTM() and DH() . QTM() , which is a function for evaluating history of certain Web services by using data gathered by Web services monitoring tool. MTM() is a function for evaluating other services referen ces to certain provid er Web services. DH() is a function for encouraging and forcing client Web services to give honest feed-backs to their providers. Automatic, learning, dynamic QoS Broker Web services framework is suggested in detail and implemented with some essential functions. Our suggested model is implemented as a Web service and validated with ini-tial result which is showing and supporting our approach. Also, a method for identifying client Web services satisfac tion degree in Web services environment is suggested. Finally, proposed approach was validated using client Web services satisfaction degree function with initial feasible result.

