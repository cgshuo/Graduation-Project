 As pro duct prices become increasingly available on the World Wide Web, consumers attempt to understand how corp orations vary these prices over time. However, corp ora-tions change prices based on proprietary algorithms and hid-den variables (e.g., the num ber of unsold seats on a igh t). Is it possible to dev elop data mining techniques that will enable consumers to predict price changes under these con-ditions?
This pap er rep orts on a pilot study in the domain of air-line ticket prices where we recorded over 12,000 price obser-vations over a 41 day perio d. When trained on this data, Hamlet | our multi-strategy data mining algorithm | gen-erated a predictiv e mo del that saved 341 sim ulated passen-gers $198,074 by advising them when to buy and when to postp one ticket purc hases. Remark ably , a clairv oyant algo-rithm with complete kno wledge of future prices could save at most $320,572 in our sim ulation, thus Hamlet 's savings were 61.8% of optimal. The algorithm's savings of $198,074 represen ts an average savings of 23.8% for the 341 passen-gers for whom savings are possible. Overall, Hamlet saved 4.4% of the ticket price averaged over the entire set of 4,488 sim ulated passengers. Our pilot study suggests that mining of price data available over the web has the poten tial to save consumers substan tial sums of money per ann um.
 I.2.6 [ Arti cial Intelligence ]: Learning price mining, Internet, web mining, airline price prediction
Corp orations often use complex policies to vary pro duct prices over time. The airline industry is one of the most sophisticated in its use of dynamic pricing strategies in an attempt to maximize its rev enue. Airlines have man y fare classes for seats on the same igh t, use di eren t sales chan-nels (e.g., travel agen ts, priceline.com, consolidators), and frequen tly vary the price per seat over time based on a slew of factors including seasonalit y, availabilit y of seats, comp et-itiv e moves by other airlines, and more. The airlines are said to use proprietary soft ware to compute ticket prices on any given day, but the algorithms used are jealously guarded trade secrets [19]. Hotels, ren tal car agencies, and other vendors with a \standing" inventory are increasingly using similar techniques.
 As pro duct prices become increasingly available on the World Wide Web, consumers have the opp ortunit y to be-come more sophisticated shopp ers. They are able to com-parison shop ecien tly and to trac k prices over time; they can attempt to iden tify pricing patterns and rush or dela y purc hases based on anticipated price changes (e.g., \I'll wait to buy because they alw ays have a big sale in the spring..."). In this pap er we describ e the use of data mining metho ds to help consumers with this task. We rep ort on a pilot study in the domain of airfares where an automatically learned mo del, based on price information available on the Web, was able to save consumers a substan tial sum of money in sim ulation.
 The pap er addresses the follo wing cen tral questions:
The remainder of this pap er is organized as follo ws. Sec-tion 2 describ es our data collection mec hanism and analyzes the basic characteristics of airline pricing in our data. Sec-tion 3 considers related work in the areas of computational nance and time series analysis. Section 4 introduces our data mining metho ds and describ es how eac h metho d was tailored to our domain. We investigated rule learning [8], Q-learning [25], moving average mo dels [13], and the com bina-tion of these metho ds via stac ked generalization [28]. Next, Section 5 describ es our sim ulation and the performance of eac h of the metho ds on our test data. The section also re-ports on a sensitivit y analysis to assess the robustness of our results to changes in the sim ulation. We conclude with a discussion of future work and a summary of the pap er's con tributions.
We collected airfare data directly from a ma jor travel web site. In order to extract the large amoun t of data required for our mac hine learning algorithms, we built a igh t data collection agen t that runs at a scheduled interv al, extracts the pricing data, and stores the result in a database. We built our igh t data collection agen t using Agen t-Builder 1 for wrapping web sites and Theseus for executing the agen t [3]. Agen tBuilder exploits mac hine learning tech-nology [15] that enables the system to automatically learn extraction rules that reliably con vert information presen ted on web pages into XML. Once the system has learned the extraction rules, Agen tBuilder compiles this into a Theseus plan. Theseus is a streaming data o w execution system that supp orts highly optimized execution of a plan in a net work environmen t. The system maximizes the parallelism across di eren t operators and streams data between operations to supp ort the ecien t execution of plans with complex navi-gation paths and extraction from multiple pages.

For the purp ose of our pilot study , we restricted our-selv es to collecting data on non-stop, round-trip igh ts for two routes: Los Angeles (LAX) to Boston (BOS) and Seat-tle (SEA) to Washington, DC (IAD). Our departure dates spanned Jan uary 2003 with the return igh t 7 days after de-parture. For eac h departure date, we began collecting pric-ing data 21 days in adv ance at three-hour interv als; data www.fetch.com for eac h departure date was collected 8 times a day. 2 Over-all, we collected over 12,000 fare observ ations over a 41 day perio d for six di eren t airlines including American, United, etc. We used three-hour interv als to limit the num ber of http requests to the web site. For eac h igh t, we recorded the lowest fare available for an economy ticket. We also recorded when econom y tickets were no longer available; we refer to suc h igh ts as sold out .
We found that the price of tickets on a particular igh t can change as often as sev en times in a single day. We cate-gorize price change into two types: dep enden t price changes and indep enden t price changes. Dep enden t changes occur when prices of similar igh ts (i.e. having the same origin and destination) from the same airline change at the same time. This type of change can happ en as often as once or twice a day when airlines adjust their prices to maximize their overall rev enue or \yield". Indep enden t changes occur when the price of a particular igh t changes indep enden tly of similar igh ts from the same airline. We speculate that this type of change results from the change in the seat avail-abilit y of the particular igh t. Table 1 sho ws the average num ber of changes per igh t aggregated over all airlines for eac h route. Overall, 762 price changes occurred across all the igh ts in our data. 63% of the changes can be classi ed as dep enden t changes based on the beha vior of other igh ts by the same airline.
 Table 1: Average num ber of price changes per route.
We found that the round-trip ticket price for igh ts can vary signi can tly over time. Table 2 sho ws the minim um price, maxim um price, and the maxim um di erence in prices that can occur for igh ts on eac h route.
 Table 2: Minim um price, maxim um price, and max-imum change in ticket price per route. All prices in this pap er refer to the lowest econom y airfare avail-able for purc hase.

For man y igh ts there are easily discernible price tiers where ticket prices fall into a relativ ely small price range. The num ber of tiers typically varies from two to four, de-pending on the airline and the particular igh t. Even igh ts from the same airline with the same schedule (but with dif-feren t departure dates) can have di eren t num bers of tiers. For example, there are two price tiers for the igh t in Figure 1, four price tiers in Figure 4 and three price tiers in Figure 2 and Figure 3. 2 We exp ected to record 168 (21 8) price observ ations for eac h igh t. In fact, we found that on average eac h igh t was missing 25 observ ations due to problems during data collec-tion including remote serv er failures, site changes, wrapp er bugs, etc. Figure 1: Price change over time for United Air-lines roundtrip igh t#168:169 LAX-BOS departing on Jan 12. This gure is an example of two price tiers and how consumers migh t bene t from the price drop. Figure 2: Price change over time for American Air-lines roundtrip igh t#192:223, LAX-BOS departing on Jan 2. This gure sho ws an example of rapid price uctuation in the days priori to the New Year.
Price matc hing plays an imp ortan t role in airline pricing structure. Airlines use sophisticated soft ware to trac k their comp etitors' pricing history and prop ose adjustmen ts that optimize their overall rev enue. To change the price, airlines Figure 3: Price change over time for American Air-lines roundtrip igh t#192:223, LAX-BOS departing on Jan 7. This gure sho ws an example of three price tiers and low price uctuation Figure 4: Price change over time for Alask a Airlines roundtrip igh t#6:3, SEA-IAD departing on Jan 4.
 This gure sho ws an example of four price tiers. need to submit the change to the Airline Tari Publish-ing Compan y(A TPCO), 3 the organization formed by leading airlines around the world that collects and distributes airline pricing data. The whole pro cess of detecting comp etitors' fare changes, deciding whether or not to matc h comp etitors' prices, and submitting the price update at ATPCO can tak e up to one day [19].

Price changes app ear to be fairly orderly on some igh ts (e.g., Figure 3), and we see evidence of the well-kno wn 7 and 14 day \adv ance purc hase" fares. However, we also see plen ty of surprising price changes. For example, igh ts that depart around holida ys app ear to uctuate more (e.g., Figure 2. Figure 2 and Figure 3 sho w how pricing strategies di er between two igh ts from American Airlines that have the same schedule but y on di eren t dates. Figure 2 sho ws a igh t that departs around the new year, while Figure 3 sho ws the igh t that departs one week after the rst igh t. Both igh ts have the tier structure that we describ ed earlier in this section, but ticket prices in the rst igh t uctuate more often.

In terms of pricing strategy , we can divide the airlines into two categories. The rst category covers airlines that are big players in the industry , suc h as United Airlines, and American Airlines. The second category covers smaller air-lines that concen trate on selling low-price tickets, suc h as Air Trans and South west. We have found that pricing poli-cies tend to be similar for airlines that belong to the same category . Fares for airlines in the rst category are exp en-sive and uctuate often, while fares for airlines in the second category are mo derate and app ear relativ ely stable. How-ever, there are some policies that every airline seems to use. For example, airlines usually increase ticket prices two weeks before departure dates and ticket prices are at a maxim um on departure dates.
Previous work in the AI comm unit y on the problem of predicting pro duct prices over time has been limited to the Trading Agen t Comp etition (TAC) [27]. In 2002, TAC fo-cused on the travel domain. TAC relies on a sim ulator of airline, hotel, and ticket prices and the comp etitors build agen ts to bid on these. The problem is di eren t from ours since the comp etition works as an auction (similar to Price-3 see http://www.atpco.net . line.com). Whereas we gathered actual igh t price data from the web, TAC sim ulates igh t prices using a stochastic pro-cess that follo ws a random walk with an increasingly upward bias. Also, the TAC auction of airline tickets assumes that the supply of airline tickets is unlimited. Sev eral TAC com-petitors have explored a range of metho ds for price predic-tion including historical averaging, neural nets, and boost-ing. It is dicult to kno w how these metho ds would perform if recon gured for our price mining task.

There has been some recen t interest in temp oral data min-ing (see [23] for a surv ey). However, the problems studied under this heading are often quite di eren t from our own (e.g., [1]). There has also been algorithmic work on time se-ries metho ds within the data mining comm unit y (e.g., [4]). We discuss time series metho ds below.

Problems that are closely related to price prediction over time have been studied in statistics under the heading of \time series analysis" [7, 13, 9] and in computational -nance [20, 22, 21] under the heading of \optimal stopping problems". However, these techniques have not been used to predict price changes for consumer goods based on data available over the web. Moreo ver, we com bine these tech-niques with rule learning techniques to impro ve their per-formance.

Computational nance is concerned with predicting prices and making buying decisions in mark ets for stock, options, and commo dities. Prices in suc h mark ets are not determined by a hidden algorithm, as in the pro duct pricing case, but rather by supply and demand as determined by the actions of a large num ber of buy ers and sellers. Thus, for example, stock prices tend to move in small incremen tal steps rather than in the large, tiered jumps observ ed in the airline data.
Nev ertheless, there are well kno wn problems in options trading that are related to ours. First, there is the early ex-ercise of American Calls on stocks that pay dividends. The second problem is the exercise of American Puts on stocks that don't pay dividends. These problems are describ ed in sections 11.12 and 7.6 resp ectiv ely of [14]. In both cases, there may be a time before the expiration of an option at whic h its exercise is optimal. Reinforcemen t learning meth-ods have been applied to both problems, and that is one reason we consider reinforcemen t learning for our problem.
Time series analysis is a large body of statistical tech-niques that apply to a sequence of values of a variable that varies over time due to some underlying pro cess or structure [7, 13, 9]. The observ ations of pro duct prices over time are naturally view ed as time series data. Standard data mining techniques are \trained" on a set of data to pro duce a pre-dictiv e mo del based on that data, whic h is then tested on a separate set of test data. In con trast, time series techniques would attempt to predict the value of a variable based on its own history . For example, our moving average mo del at-tempts to predict the future changes in the price of a ticket on a igh t from that igh t's own price history .
There is also signi can t interest in bidding and pricing strategies for online auctions. For example, in [24] Harshit et al. use cluster analysis techniques to categorize the bidding strategies being used by the bidders. And in [17], Luc king-Reiley et al. explore the various factors that determine the nal price paid in an online auction, suc h as the length of the auction, whether there is a reserv e price, and the reputa-tion of the seller. However, these techniques are not readily applicable to our price mining problem.

Comparison shopping \bots" gather price data available on the web for a wide range of pro ducts. 4 These are de-scendan ts of the Shopb ot [11] whic h automatically learned to extract pro duct and price information from online mer-chan ts' web sites. None of these services attempts to analyze and predict the beha vior of pro duct prices over time. Thus, the data mining metho ds in this pap er complemen t the body of work on shopb ots.
In this section we explain how we generated training data, and then describ e the various data mining metho ds we in-vestigated: Ripp er [8], Q-learning [25], and time series [13, 9]. We then explain how our data mining algorithm, Ham-let , com bines the results of these metho ds using a varian t of stac ked generalization [26, 28].

Our data consists of price observ ations recorded every 3 hours over a 41 day perio d. Our goal is to learn whether to buy a ticket or wait at a particular time point, for a particu-lar igh t, given the price history that we have recorded. All of our exp erimen ts enforce the follo wing essen tial temp oral constrain t: all the information used to mak e a decision at particular time point was recorded befor e that time point. In this way, we ensure that we rely on the past to predict the future, but not vice versa.
Our rst step was to run the popular Ripp er rule learning system [8] on our training data. Ripp er is an ecien t sep-arate and conquer rule learner. We represen ted eac h price observ ation to Ripp er as a vector of the follo wing features: The class lab els on eac h training instance were `buy' or `wait'.

We considered a host of additional features deriv ed from the data, but they did not impro ve Ripp er's performance. We did not represen t key variables like the num ber of unsold seats on a igh t, whether an airline is running a promotion, or seasonal variables because Hamlet did not have access to this information. However, see Section 6 for a discussion of how Hamlet migh t be able to obtain this information in the future.

Some sample rules generated by Ripp er are sho wn in Fig-ure 5.

In our domain, classi cation accuracy is not the best met-ric to optimize because the cost of misclassi ed examples is highly variable. For example, misclassifying a single ex-ample can cost from nothing to upwards of $2,000. Meta-Cost [10] is a well-kno wn general metho d for training cost-sensitiv e classi ers. In our domain, MetaCost will mak e a learned classi er either more conserv ativ e or more aggres-sive about waiting for a better price, dep ending on the cost 4 See, for example, froogle.google.com and mysimon.com . IF hours-b efore-tak eo &gt; = 252 AND price &gt; = 2223 AND route = LAX-BOS THEN wait IF airline = United AND price &gt; = 360 AND hours-b efore-tak eo &gt; = 438 THEN wait of misclassifying a `buy' as a `wait' compared with the cost of misclassifying a `wait' as a `buy'. We implemen ted Meta-Cost with mixed results.

We found that MetaCost impro ves Ripp er's performance by 14 percen t, but that MetaCost hurts Hamlet 's overall performance by 29 percen t. As a result, we did not use MetaCost in Hamlet .
As our next step we considered Q-learning, a species of reinforcemen t learning [25]. Reinforcemen t learning seems like a natural t because after making eac h new price ob-serv ation Hamlet has to decide whether to buy or to wait. Yet the rew ard (or penalt y) asso ciated with the decision is only determined later, when Hamlet determines whether it saved or lost money through its buying policy . Reinforce-men t learning is also a popular technique in computational nance [20, 22, 21].
 The standard Q-learning form ula is: Here, R ( s; a ) is the immediate rew ard, is the discoun t factor for future rew ards, and s 0 is the state resulting from taking action a in state s . We use the notion of state to mo del the state of the world after eac h price observ ation (represen ted by the price, igh t num ber, departure date, and num ber of hours prior to tak eo ). Thus, there are two possible actions in eac h state: b for `buy' and w for `wait'.
Of course, the particular rew ard function used is critical to the success (or failure) of Q-learning. In our study , the rew ard asso ciated with b is the negativ e of the ticket price at that state, and the state resulting from b is a terminal state so there is no future rew ard. The immediate rew ard asso ciated with w is zero as long as econom y tickets on the igh t do not sell out in the next time step. We set = 1, so we do not discoun t future rew ards.

To discourage the algorithm from learning a mo del that waits until igh ts sell out, we introduce a \penalt y" for suc h igh ts in the rew ard function. Speci cally , in the case where the igh t does sell out at the next time point, we mak e the immediate rew ard for waiting a negativ e constan t whose absolute value is substan tially greater than the price for any igh t. We set the rew ard for reac hing a sold-out state to be 300 ; 000. This setting can best be explained below, after we introduce a notion of equiv alence classes among states. In short, we de ne the Q function by Q ( b; s ) = price ( s )
To generalize from the training data we used a varian t of the averaging step describ ed in [18]. More speci cally , we de ned an equiv alence class over states, whic h enabled the algorithm to train on a limited set of observ ations of the class and then use the learned mo del to generate predictions for other states in the class.

To de ne our equiv alence class we need to introduce some notation. Airlines typically use the same igh t num ber (e.g., UA 168) to refer to multiple igh ts with the same route that depart at the same time on di eren t dates. Thus, United igh t 168 departs once daily from LAX to Boston at 10:15pm. We refer to a particular igh t by a com bination of its igh t num ber and date. For example, UA168-Jan7 refers to igh t 168 whic h departs on Jan uary 7th, 2003. Since we observ e the price of eac h igh t eigh t times in every 24 hour perio d, there are man y price observ ations for eac h igh t. We distinguish among them by recording the time (num ber of hours) until the igh t departs. Thus, UA168-Jan7-120 is the price observ ation for igh t UA168, departing on Jan uary 7, whic h was recorded on Jan uary 2nd (120 hours before the igh t departs on the 7th). Our equiv alence class is the set of states with the same igh t num ber and the same hours be-fore tak eo , but di eren t departure dates. Thus, the states denoted UA168-Jan7-120 and UA168-Jan10-120 are in the same equiv alence class, but the state UA168-Jan7-117 is not. We denote that s and s are in the same equiv alence class by s s .
 Thus, our revised Q-learning form ula is:
The reason for choosing -300,000 is now more apparen t: the large penalt y can tilt the average toward a low value, even when man y Q values are being averaged together. Sup-pose, for example, that there are ten training examples in the same equiv alence class, and eac h has a curren t price of $2,500. Supp ose now that in nine of the ten examples the price drops to $2,000 at some point in the future, but the igh t in the ten th example sells out in the next state. The Q value for waiting in any state in this equiv alence class will be ( 300 ; 000 2 ; 000 9) = 10 = 31 ; 800, or still much less then the Q value for any equiv alence class where no igh t sells out in the next state. Thus the choice of rew ard for a igh t that sells out will determine how willing the Q-Learning al-gorithm will be to risk waiting when there's a chance a igh t may sell out. Using a hill clim bing searc h in the space of penalties, we found -300,000 to be locally optimal.
Q-learning can be very slow, but we were able to ex-ploit the structure of the problem and the close relationship between dynamic programming and reinforcemen t learning (see [25]) to complete the learning in one pass over the train-ing set. Speci cally , the reinforcemen t learning problem we face has a particularly nice structure, in whic h the value of Q ( b; s ) dep ends only on the price in state s , and the value of Q ( w; s ) dep ends only on the Q values of exactly one other state: the state con taining the same igh t num-ber and departure date but with three hours less time left until departure. Applying dynamic programming is thus straigh tforw ard, and the initial training step requires only a single pass over the data. In order to compute averages over states in the same equiv alence class, we keep a running total and a coun t of the Q values in eac h equiv alence class. Thus, the reinforcemen t learning algorithm just mak es a sin-gle pass over the training data, whic h bodes well for scaling the algorithm to much larger data sets.

The output of Q-learning is the learned policy , whic h de-termines whether to buy or wait in unseen states by mapping them to the appropriate equiv alence class and choosing the action with the lowest learned cost.
Time series analysis is a large and div erse sub eld of statistics whose goal is to detect and predict trends. In this pap er, we investigated a rst order moving average mo del. At time step t , the mo del predicts the price one step into the future, p t +1 , based on a weigh ted average of prices already seen. Thus, whereas Q-learning and Ripp er attempt to gen-eralize from the beha vior of a set of igh ts in the training data to the beha vior of future igh ts, the moving average mo del attempts to predict the price beha vior of a igh t in the test data based on its own history .

At time t , we predict the next price using a xed windo w of price observ ations, p t k +1 ; : : : ; p t . (In Hamlet , we found that setting k to one week's worth of price observ ations was locally optimal.) We tak e a weigh ted average of these prices, weigh ting the more recen t prices more and more hea vily . Formally , we predict that p t +1 will be where ( i ) is some increasing function of i . We exp eri-men ted with di eren t functions and chose a simple linearly increasing function.

Giv en the time series prediction, Hamlet relies on the follo wing simple decision rule: if the mo del predicts that p t +1 &gt; p t , then buy , otherwise wait . Thus, our time series mo del mak es its decisions based on a one-step prediction of the ticket price change. The decision rule ignores the magnitude of the di erence between p t +1 and p t , whic h is overly simplistic, and indeed the time series prediction does not do very well on its own (see Table 3). However, Hamlet uses the time series predictions extensiv ely in its rules. In e ect, the time series prediction pro vides information about how the curren t price compares to a local average, and that turns out to be valuable information for Hamlet .
Ensem ble-based learning techniques suc h as bagging [5], boosting [12], and stac king [26, 28], whic h com bine the re-sults of multiple generalizers, have been sho wn to impro ve generalizer accuracy on man y data sets. In our study , we investigated multiple data mining metho ds with very di er-ent characteristics (Ripp er, Q-learning, and time series) so it mak es sense to com bine their outputs.

We preferred stac king to voting algorithms suc h as weigh ted ma jorit y [16] or bagging [5] because we believ ed that there were iden ti able conditions under whic h one metho d's mo del would be more successful than another. See, for example, the sample rule in Figure 6.

Standard stac king metho ds separate the original vec-tor represen tation of training examples ( level-0 data in Wolp ert's terminology), and use the class lab els from eac h level-0 generalizer, along with the example's true classi -cation as input to a meta-lev el (or level-1 ) generalizer. To avoid over-tting, \care is tak en to ensure that the mo d-els are formed from a batc h of training data that does not include the instance in question" [26].

In our implemen tation of stac king, we collapsed level-0 and level-1 features. Speci cally , we used the feature repre-sen tation describ ed in Section 4.1 but added three additional features corresp onding to the class lab els (buy or wait) com-Let T S be the output of the Time Series algorithm, and let QL be the output of Q-Learning.
 IF hours-b efore-tak eo &gt; = 480 AND air line = U nited AND price &gt; = 360 AND T S = buy AND QL = wait THEN wait
Figure 6: A sample rule generated by Hamlet. puted for eac h training example by our level-0 generalizers. To add our three level-1 features to the data, we applied the mo del pro duced by eac h base-lev el generalizer (Ripp er, Q-learning, and time series) to eac h instance in the training data and lab eled it with `buy' or `wait'. Thus, we added features of the form TS = buy (time series says to buy) and QL = wait (Q-learning says to wait).

We then used Ripp er as our level-1 generalizer, running it over this augmen ted training data. We omitted leave-one-out cross validation because of the temp oral nature of our data. Although a form of cross validation is possible on temp oral data, it was not necessary because eac h of our base learners did not app ear to over t the training data.
Our stac ked generalizer was our most successful data min-ing metho d as sho wn in Table 3 and we refer to it as Ham-let .
After we studied the data in depth and consulted with travel agen ts, we were able to come up with a fairly simple policy \by hand". We describ e it below, and include it in our results as a baseline for comparison with the more complex mo dels pro duced by our data mining algorithms.

The intuition underlying the hand-crafted rules is as fol-lows. First, to avoid sell outs we do not want to wait too long. By insp ection of the data, we decided to buy if the price has not dropp ed within 7 days of the departure date. We can compute an exp ectation for the lowest price of the igh t in the future based on similar igh ts in the training data. 5 If the curren t price is higher than the exp ected min-imum then it is best to wait. Otherwise, we buy .

More formally , let M inP rice ( s; t ) of a igh t in the train-ing set denote the minim um price of that igh t over the interv al starting from s days before departure up until time t (or until the igh t sells out). Let ExpP rice ( s; t ) for a particular igh t num ber denote the average over all M inP rice ( s; t ) for igh ts in the training set with that igh t num ber. Supp ose a passenger asks at time t 0 to buy a ticket that leaves in s 0 days, and whose curren t price is CurP rice . The hand-crafted rule is sho wn in Figure 7.
 IF ExpP rice ( s 0 ; t 0 ) &lt; CurP rice AND s 0 &gt; 7 days THEN wait ELSE buy Figure 7: Hand-crafted rule for deciding whether to wait or buy .

We also considered simpler decision rules of the form \if the curren t time is less than K days before the igh t's de-parture then buy ." In our sim ulation (describ ed below) we 5 For \similar" igh ts we used igh ts with the same airline and igh t num ber. tested suc h rules for K ranging from 1 to 22, but none of these rules resulted in savings and some resulted in sub-stan tial losses.
In this section we describ e the sim ulation we used to as-sess the savings due to eac h of the data mining metho ds describ ed earlier. We then compare the metho ds in Table 3, perform a sensitivit y analysis of the comparison along sev-eral dimensions, and consider the implications of our pilot study .
The most natural way to assess the qualit y of the predic-tive mo dels generated by the data mining metho ds describ ed in Section 4 is to quan tify the savings that eac h mo del would generate for a population of passengers. For us, a passenger is a person wanting to buy a ticket on a particular igh t at a particular date and time. It is easy to imagine that an online travel agen t suc h as Exp edia or Travelocity could o er discoun ted fares to passengers on its web site, and use Hamlet to appropriately time ticket purc hases behind the scenes. For example, if Hamlet anticipates that a fare will drop by $500, the agen t could o er a $300 discoun t and keep $200 as comp ensation and to o set losses due prediction er-rors by Hamlet .

Since Hamlet is not yet ready for use by real passengers, we sim ulated passengers by generating a uniform distribu-tion of passengers wanting to purc hase tickets on various igh ts as a function of time. Speci cally , the sim ulation generated one passenger for eac h fare observ ation in our set of test data. The total num ber of passengers was 4,488. Thus, eac h sim ulated passenger has a particular igh t for whic h they need to buy a ticket and an earliest time point at whic h they could purc hase that ticket (called the \earliest purc hase point"). The earliest purc hase points, for di eren t sim ulated passengers, varied from 21 days before the igh t to the day of the igh t.

At eac h subsequen t time point, Hamlet decides whether to buy a ticket immediately or to wait. This pro cess con-tinues until either the passenger buys a ticket or econom y seats on the igh t sell out, in whic h case Hamlet will buy a higher priced business-class ticket for the igh t. 6 We de-ned upgrade costs as the di erence between the cost of a business class ticket and the cost of an econom y ticket at the earliest purc hase point. In our sim ulation, Hamlet was forced to \upgrade" passengers to business class only 0.42% of the time, but the total cost of these upgrades was quite high ($38,743 in Table 3). 7
We recorded for eac h sim ulated passenger, and for eac h predictiv e mo del considered, the price of the ticket pur-chased and the optimal price for that passenger given their earliest time point and the subsequen t price beha vior for that igh t. The savings (or loss) that a predictiv e mo del yields for a sim ulated passenger is the di erence between the price of a ticket at the earliest purc hase point and the price 6 It's possible, of course, for business class to sell out as well, in whic h case Hamlet would have to buy a rst-class ticket or re-b ook the passenger on a di eren t igh t. However, busi-ness class did not sell out in our sim ulation. 7 Since we did not collect upgrade costs for all igh ts, our upgrade costs are appro ximate but alw ays positiv e and often as high as $1,000 or more. of the ticket at the point when the predictiv e mo del recom-mends buying. Net savings is savings net of both losses and upgrade costs.
Table 3 sho ws the savings, losses, upgrade costs, and net savings achiev ed in our sim ulation by eac h predictiv e mo del we generated. We also rep ort on the frequency of upgrades as a percen tage of the total passenger population, the net savings as a percen t of the total ticket price, and the perfor-mance of eac h mo del as a percen t of the maximal possible savings.
 The mo dels we used are the follo wing:
Table 3 sho ws a comparison of the di eren t metho ds. Note that the savings measure we focus on is savings net of losses and upgrade costs. We see that Hamlet outp erformed eac h of the learning metho ds as well as the hand-crafted mo del to achiev e a net savings of $198,074. Furthermore, despite the fact that Hamlet had access to a very limited price history and no information about the num ber of unsold seats on the igh t, its net savings were a remark able 61.8% of optimal. Finally , while an average net savings of 4.4% may not seem like much, passengers spend billions of dollars on air travel eac h year so 4.4% amoun ts to a substan tial num ber of dollars.

We believ e that our sim ulation understates the savings that Hamlet would achiev e in practice. For close to 75% of the passengers in our test set, savings were not possible be-cause prices nev er dropp ed from the earliest purc hase point until the igh t departed. We rep ort the percen t savings in ticket prices over the set of igh ts where savings was possible (\feasible igh ts") in Table 4. These savings gures are of interest because of the unrealistic distribution of passengers in our sim ulation. Because we only gathered data for 21 days before eac h igh t in our test set, passengers \arriv ed" at most 21 days before a igh t. Furthermore, due to the uniform distribution of passengers, 33% of the passengers arriv ed at most 7 days before the igh t's departure, when savings are hard to come by. In fact, on our test data, Ham-let lost money for passengers who \arriv ed" in the last 7 days prior to the igh t. We believ e that in practice we would nd additional opp ortunities to save money for the bulk of passengers who buy their tickets more than 7 days before the igh t date. Optimal $320,572 $0 $0 0% $320,572 7.0% 100% By hand $228,318 $35,329 $22,472 0.36% $170,517 3.8% 53.2% Ripp er $211,031 $4,689 $33,340 0.45% $173,002 3.8% 54.0% Time Series $269,879 $6,138 $693,105 33.0% -$429,364 -9.5% -134% Q-learning $228,663 $46,873 $29,444 0.49% $152,364 3.4% 47.5% Hamlet $244,868 $8,051 $38,743 0.42% $198,074 4.4% 61.8% Metho d Net Savings Optimal 30.6% By hand 21.8% Ripp er 20.1% Time Series 25.8% Q-learning 21.8% Hamlet 23.8% Table 4: Comparison of Net Savings (as a percen t of total ticket price) on Feasible Fligh ts.
To test the robustness of our results to changes in our sim-ulation, we varied two key parameters. First, we changed the distribution of passengers requesting igh t tickets. Sec-ond, we changed the mo del of a passenger from one where a passenger wants to purc hase a ticket on a particular igh t to one where a passenger wants to y at any time during a three hour interv al. The interv al mo del is similar to the interface o ered at man y travel web sites where a poten tial buy er speci es if they want to y in the morning, afterno on, or evening.

We used the follo wing distributions to mo del the earliest purc hase point (i.e., the rst time point at whic h passengers \arriv e" and need to decide whether to buy a ticket or to wait):
Table 6 rep orts the net savings, as a percen tage of the to-tal ticket price, under the di eren t distributions. Hamlet saved more than 2.5% of the ticket price in all cases, and it saved more than any other metho d on all distributions except the Quadratic Decrease distribution, where it per-formed sligh tly worse than the hand-crafted decision rule. Hamlet 's savings were above 38% of optimal in all cases.
Table 5 rep orts on the performance of the di eren t meth-ods under the mo di ed mo del where a passenger requests a ticket on a non-stop igh t that departs at any time during a particular three hour interv al (e.g., morning). This di eren t mo del does not change our results qualitativ ely. Hamlet still achiev es a substan tial percen tage of the optimal sav-ings (59.2%) and its percen tage of upgrades drops to only 0.1%. Finally , Hamlet still substan tially outp erforms the other data mining metho ds.
 Metho d Net Savings % of Optimal % upgrades Optimal $323,802 100% 0% By hand $163,523 55.5% 0% Ripp er $173,234 53.5% 0% Time Series -$262,749 -81.1% 6.3% Q-Learning $149,587 46.2% 0.2% Hamlet $191,647 59.2% 0.1%
Table 5: Performance of algorithms on multiple igh ts over three hour interv al.

Overall, our analysis con rms that Hamlet 's perfor-mance on the test data is robust to the parameters we varied.
There are sev eral promising directions for future work on price mining. We plan to perform a more comprehensiv e study on airline pricing with data collected over a longer perio d of time and over more routes. We plan to include multi-leg igh ts in this new data set. The pricing beha vior of multi-leg igh ts is di eren t than that of non-stop igh ts because eac h leg in the igh t can cause a change in the price, and because pricing through airline hubs app ears to beha ve di eren tly as well.

We also plan to exploit other sources of information to further impro ve Hamlet 's predictions. We do not curren tly have access to a key variable | the num ber of unsold seats on a igh t. However, on-line travel agen ts and cen tralized reserv ation systems suc h as Sabre or Galileo do have this information. If we had access to the num ber of unsold seats on a igh t, Hamlet could all but eliminate the need to upgrade passengers, whic h is a ma jor cost.

To use the metho ds in this pap er on the full set of domes-tic and international igh ts on any given day would require collecting vast amoun ts of data. One possible way to address this problem is to build agen ts on demand that collect the required data to mak e price predictions for on a particular future igh t on a particular day. The agen ts would still need Distribution By hand Q-Learn Time Series Ripp er Hamlet Quadratic Decrease 4.07% 3.77% -24.96% 2.46% 3.96% Linear Decrease 4.70% 4.30% -26.76% 4.13% 5.17% Sqrt Decrease 4.47% 4.04% -29.05% 4.23% 5.03% Uniform 3.77% 3.37% -32.55% 3.83% 4.38% Sqrt Increase 3.66% 3.24% -34.63% 4.05% 4.39% Linear Increase 3.13% 2.72% -36.55% 3.62% 3.85% Quadratic Increase 2.10% 1.74% -39.90% 2.48% 2.60% to collect data for multiple igh ts, but the amoun t of data would be much smaller. This type of agen t would t well within the Electric Elv es system [6, 2], whic h deplo ys a set of personalized agen ts to monitor various asp ects of a trip. For example, Elv es can notify you if your igh t is dela yed or canceled or let you kno w if there is an earlier connecting igh t to your destination.

Bey ond airline pricing, we believ e that the techniques de-scrib ed in this pap er will apply to other pro duct categories. In the travel industry , hotels and car ren tal agencies emplo y man y of the same pricing strategies as the airlines and it would be interesting to see how much Hamlet can save in these pro duct categories. Similarly , online shopping sites suc h as Amazon and Wal-mart are beginning to explore more sophisticated pricing strategies and Hamlet will al-low consumers to mak e more informed decisions. Finally , rev erse auction sites, suc h as half.com, also pro vide an op-portunit y for Hamlet to learn about pricing over time and mak e recommendations about purc hasing an item righ t away or waiting to buy it. In general, price mining over time pro-vides a new dimension for comparison shopping engines to exploit.

We recognize that if a progen y of Hamlet would achiev e wide spread use it could start to impact the airlines' (already slim) pro t margins. Could the airlines introduce noise into their pricing patterns in an attempt to fool a price miner? While we have not studied this question in depth, the ob-vious problem is that changing fares on a igh t in order to fool a price miner would impact all consumers considering buying tickets on that igh t. If the price of a ticket moves up substan tially , then consumers are likely to buy tickets on di eren t igh ts resulting in a rev enue loss for the airline. Similarly , if the price moves down substan tially , consumers will be buying tickets at a discoun t resulting in a rev enue loss again. Thus, to avoid these distortions, the airlines are forced to sho w the prices that they actually want to charge for tickets. Of course, there are more prosaic metho ds of trying to blo ck a price miner suc h as placing prices inside GIF les or blo cking the IP address of the price miner. How-ever, an \industrial strength" price miner would not rely on \scraping" information from web sites, but would access a fare database directly .
This pap er rep orted on a pilot study in \price mining" over the web. We gathered airfare data from the web and sho wed that it is feasible to predict price changes for igh ts based on historical fare data. Despite the complex algo-rithms used by the airlines, and the absence of informa-tion on key variables suc h as the num ber of seats available on a igh t, our data mining algorithms performed surpris-ingly well. Most notably , our Hamlet data mining metho d achiev ed 61.8% of the possible savings by appropriately tim-ing ticket purc hases.

Our algorithms were dra wn from statistics (time series metho ds), computational nance (reinforcemen t learning) and classical mac hine learning (Ripp er rule learning). Eac h algorithm was tailored to the problem at hand (e.g., we devised an appropriate rew ard function for reinforcemen t learning), and the algorithms were com bined using a vari-ant of stac king to impro ve their predictiv e accuracy .
Additional exp erimen ts on larger airfare data sets and in other domains (e.g., hotels, rev erse auctions) are essen tial, but this initial pilot study pro vides the rst demonstration of the poten tial of price mining algorithms to save consumers substan tial amoun ts of money using data available on the Internet. We believ e that price mining of this sort is a fertile area for future researc h.
We thank Haym Hirsh, John Mo ody, and Pedro Domingos for helpful suggestions. This pap er is based upon work sup-ported in part by the Air Force Oce of Scien ti c Researc h under gran t num ber F49620-01-1-0053 to USC. The views and conclusions con tained herein are those of the authors and should not be interpreted as necessarily represen ting the ocial policies or endorsemen ts, either expressed or implied, of any of the above organizations or any person connected with them. [1] R. Agra wal and R. Srik ant. Mining sequen tial [2] J. L. Am bite, G. Barish, C. A. Knoblo ck, M. Muslea, [3] G. Barish and C. A. Knoblo ck. An ecien t and [4] D. Berndt and J. Cli ord. Finding patterns in time [5] L. Breiman. Bagging predictors. Machine Learning , [6] H. Chalupsky , Y. Gil, C. A. Knoblo ck, K. Lerman, [7] C. Chat eld. The Analysis of Time Series: An [8] W. W. Cohen. Fast e ectiv e rule induction. In [9] F. Dieb old. Elements of Forecasting . South-W estern [10] P. Domingos. MetaCost: A general metho d for making [11] R. Dooren bos, O. Etzioni, and D. Weld. A scalable [12] Y. Freund and R. E. Schapire. Exp erimen ts with a [13] C. W. J. Granger. Forecasting in Business and [14] J. C. Hull. Options, Futur es, and Other Derivatives . [15] C. A. Knoblo ck, K. Lerman, S. Min ton, and I. Muslea. [16] N. Littlestone and M. K. Warm uth. The weigh ted [17] D. Luc king-Reiley , D. Bry an, N. Prasad, and [18] S. Mahadev an. Average rew ard reinforcemen t [19] S. McCartney . Airlines Rely on Tec hnology To [20] J. Mo ody and M. Sa ell. Reinforcemen t learning for [21] J. Mo ody and M. Sa ell. Minimizing downside risk via [22] J. Mo ody and M. Sa ell. Learning to trade via direct [23] J. F. Roddic k and M. Spiliop oulou. A bibliograph y of [24] H. S. Shah, N. R. Joshi, A. Surek a, and P. R. Wurman. [25] R. S. Sutton and A. Barto. Reinfor cement Learning: [26] K. M. Ting and I. H. Witten. Issues in stac ked [27] M. P. Wellman, D. M. Reev es, K. M. Lochner, and [28] D. Wolp ert. Stac ked generalization. Neur al Networks ,
