 In 24 hours an electrocardiogram (ECG) can record over 100,000 heartbeats for a single patient. Of course, a physician is not likely to look at all of them. Automated analysis of long-term ECG recordings can help physicians understand a patient X  X  physiological state and his/her risk for adverse cardiovascular outcomes [1] [2]. Often, an important step in such analysis is labeling the different types of heartbeats. This labeling reduces an ECG to a set of symbols transferable across patients. Trained clinicians can successfully identify over a dozen different types of heartbeats in ECG record-ings. However, researchers have had limited success using supervised machine learning techniques to do the same. The problem is made challenging by the inter-patient differences present in the mor-phology and timing characteristics of the ECGs produced by compromised cardiovascular systems. The variation in the physiological systems that produce the data means that a classifier trained on even a large set of patients will yield unpredictable results when applied to a new cardiac patient. For this reason, global classifiers are highly unreliable and therefore not widely used in practice [3]. Hu et al was one of the first to describe an automatic patient-adaptive ECG beat classifier [4]. It distinguished ventricular ectopic beats (VEBs), from non-VEBs. This work employed a mixture of experts approach, combining a global classifier with a local classifier trained on the first 5 minutes of the test patient X  X  record. Similarly, de Chazal et al augmented the performance of a global heartbeat classifier by including patient-specific expert knowledge for each test patient. Their local classifier was trained on the first 500 labeled beats of each record [3]. More recently, Ince et al developed a patient-adaptive classification scheme using artificial neural networks by incorporating the first 5 minutes of each test recording in the training set [5] .
 increased classification accuracy. Unfortunately, patient-adaptive classifiers are not used in practice because they require an unrealistic amount of labor to produce a cardiologist-labeled patient-specific training set. Furthermore, by sampling all of the patient-specific training data from one portion of the ECG, one is at risk for over-fitting to that patient X  X  physiological state in time. Given a long-term record, which is likely to contain high intra-patient differences, it is likely that constructing the training set in this manner will not yield a good representation of the patient X  X  ECG.
 There has been some success with hand-coded rule-based algorithms for heartbeat classification. Hamilton et al developed a rule-based algorithm for detecting one type of particularly dangerous ectopic heartbeat, the premature ventricular contraction (PVC) [6]. While reasonably accurate, rule-based algorithms are inflexible, since they can only be used for a single classification task. And to be useful in practice, a classifier should not only be capable of adapting to new patients, but also to new classification problems, since the classification task in question can change depending on the patient or even the clinician. Since the field of ECG research is continuously evolving, tools to analyze the signal should be capable of adapting.
 In this paper, we show how active learning can be successfully applied to the problems of both patient-adaptive and task-adaptive heartbeat classification. We developed our method with a clin-ical setting in mind: initially it requires no labeled data, it has no user-specified parameters, and achieves good performance on an imbalanced data set. Applied to data from the MIT-BIH Arrhyth-mia Database our method outperforms current state-of-the-art machine learning heartbeat classifi-cation techniques and uses less training data. Moreover, our approach outperforms a rule-based algorithm designed to detect an important class of abnormal beat. Finally, we discuss how the clas-sification method performed when used in a prospective experiment with two cardiologists. We begin with a brief background on the signal of interest, the ECG. Since we will consider dif-ferent heartbeat classification tasks we first present a few examples of heartbeat classes and ECG abnormalities. 2.1 The ECG and ECG Abnormalities An ECG records a patient X  X  cardiac electrical activity by measuring the potential differences at the surface of the patient X  X  body. In most healthy patients, the ECG, measured from Lead II, begins with a P-wave, is followed by a QRS complex and ends with a T-wave. Figure 1(a) shows an example of the ECG of a normal sinus rhythm beat (N). The exact morphology and timing of the different portions of the wave depend on the patient and lead placement. Figure 1: Normal sinus rhythm beats like the ones shown in (a) originate from the pacemaker cells of the sinoatrial node. Premature ventricular contractions (b) and atrial premature beats (c) are two examples of ectopic beats.
 Cardiac abnormalities can disrupt the heart X  X  normal sinus rhythm, and, depending on their type and frequency, can vary from benign to life threatening. Examples of ectopic beats (beats that do not originate in the sinoatrial node) are shown in Figures 1(b) and 1(c). Premature ventricular contractions (PVCs), originate in the ventricles instead of in the pacemaker cells of the sinoatrial node. They are common in patients who have suffered an acute myocardial infarction [7] and may indicate that a patient is at increased risk for more serious ventricular arrhythmias and sudden cardiac death [8]. When the electrical impulse originates from the atria, an atrial premature beat is recorded by the ECG as shown in Figure 1(c). Atrial premature beats tend not to be life threatening. Because of their specific timing and morphology characteristics these two types of abnormal beats are generally distinguishable by trained cardiologists, but there are many exceptions. Not only can abnormalities vary from patient to patient, but the same recording may contain beats that belong to the same class but all look quite different. Figure 2 shows an example of an ECG containing multiform PVCs.
 Figure 2: Each PVC is marked by a  X  X  X  and each normal sinus rhythm beat is marked by a  X   X   X . The PVC morphology varies greatly among patients and even within recordings from a single patient. In this section we describe the two main components of our heartbeat classification scheme. We begin, with the process of feature extraction and then present the classification method. 3.1 Feature Extraction Before extracting feature vectors, we pre-process and segment the ECG. We used PhysioNet X  X  au-tomated R-peak detector to detect the R-peaks of each heartbeat [9]. Next, we removed baseline wander from the signals using the method described in [10]. Once pre-processed, the data was seg-mented into individual heartbeats based on fixed intervals before and after the R-peak, so that each beat contained the same number of samples.
 Our goal was to develop a feature vector that worked well not only across patients but also across dif-ferent heartbeat classification tasks. This led us to use a combination of the ECG features proposed in [10],[11], and [12]. The elements of the feature vector, x , are described in Table 1. The last, and most novel, feature in Table 1 is a measure of the morphological distance between the represented beat and the median beat for a patient (recalculated every 500 beats). The feature is based on the dynamic time warping algorithm used in [12] to measure the morphological distance between a fixed interval that contains a portion of the Q-T intervals of two beats. 3.2 Classification Our goal was to develop a clinically useful patient-adaptive heartbeat classification method for solv-ing different binary heartbeat classification problems. We designed the classifier for use in a clinical setting, where physicians have little time to label beats, let alone tune classifier parameters. Thus, it was important that the method should require few cardiologist-labeled heartbeats, and have no user-defined parameters. Based on these goals we developed the algorithm presented below, which combines different ideas from the literature [13-16]. Many proposed techniques for SVM active learning assume one starts with some set of labeled data or, as in [13], the initial training examples are randomly selected. In our application, we start with a pool of completely unlabeled data. Furthermore, since there is often a severe class imbalance ( e.g. , some multi-thousand beat recordings contain less than a handful of PVCs), choosing a small or even moderate number of random samples is unlikely to be an effective approach to finding representative samples of a record. The choice of initial queries is crucial. If beats from only one class are queried the algorithm could stop prematurely. More generally, the selection of the first set of queries is independent of the binary task, and therefore the first query should contain at least one example from each of the beat classes contained in the record. We use clustering in an effort to quickly identify representative samples from each class.
 We experimented with different clustering techniques before choosing hierarchical clustering. On average hierarchical clustering outperformed other popular clustering techniques like k -means. We variety of different clusters by modifying the linkage criterion. We chose to use two complementary linkage criteria in attempt to address the intra-patient variation present in ECG records. The first metric is average linkage. Average linkage defines the distance between two clusters, q and r , as the average distance between all pairs of objects in q and r . This linkage is biased toward producing clusters with similar variances, and has the tendency to merge clusters with small variances. The second linkage criterion is Ward X  X  linkage [17], defined in Equation 1. where ss ( qr ) is the within-cluster sum of squares for the resulting cluster when q and r are com-bined. The within-cluster sum of squares, ss ( x ) , is defined as the sum of squares of the distances between all objects in the cluster and the centroid of the cluster: Using Ward X  X  linkage tends to join clusters with a small number of points, and is biased towards producing clusters with approximately the same number of samples. If presented with an outlier, Ward X  X  method tends to assign it to the cluster with the closest centroid, whereas the average linkage tends to assign it to the densest cluster, where it will have the smallest impact on the maximum variance [18].
 Once the initial queries are labeled, we train a linear SVM, and apply this SVM to all of the data. We use linear SVMs because most heartbeat classification tasks are close to linearly separable and because linear SVMs require few tuning parameters. Next, we re-cluster the data on or within the margin of the SVM, incrementing the max number of clusters with each iteration. We then query a beat from each cluster that is closest to the SVM decision boundary.
 As described above, our algorithm would halt when no unlabeled data lay on or within the margin. For some records, however, e.g. , those with fusion beats -a fusion of normal and abnormal beats -many beats can lie within the margin of the SVM and thus a clinician might end up labeling hundreds of beats that add little useful information. Intuitively, one should stop querying when additional training data has little to no effect on the solution. The algorithm, therefore, terminates when the change in the margin between iterations is within . We implemented our algorithm in MATLAB, and used SV M light [19] to train the linear SVM at each iteration. We held the cost parameter of the linear SVM constant, at C = 100 , throughout all experiments. This value was selected based on previous cross-validation experiments. The stopping precision was held constant at = 10  X  3 . Typical ECG recordings contain beats from 2 to 5 classes but can contain more; based on this a priori knowledge, we conservatively set k = 10 . This value was held constant throughout all experiments.
 To test the utility of our proposed approach for heartbeat classification we ran a series of experi-ments on data from different patients, and for different classification tasks. First, we compare the performance of a classifier obtained using our approach to two classifiers recently presented in the literature. Next, we directly measure the impact active learning has on the classification of heart-beats by creating our own passive learning classifier using the same pre-processing and features as our proposed active learning method. Finally, we test our method using actual cardiologists. In our experiments we report the classification performance in terms of sensitivity (SE), specificity (SP), and positive predictive value (PPV). As an overall measure of performance we use the F-score: The F-score is a commonly-accepted performance evaluation measure in medicine and information retrieval where one data class (often the positive class) is more important than the other [20]. We use this measure since the problem of heartbeat classification suffers from severe class imbalance, and thus the SE (aka recall) and the PPV (aka precision) are more important than SP. 4.1 Classification Performance We tested performance on the MIT-BIH Arrhythmia Database (MITDB) [9], a widely used bench-mark database that contains 48 half-hour ECG recordings, sampled at 360Hz, from 47 different patients. Twenty-three of these records, labeled 100 to 124 were selected at random from a source of 4000 recordings. The remaining 25 records, labeled 200 to 234 were selected because they con-tain rare clinical activity that might not have been represented had all 48 records been chosen at random. The database contains approximately 109,000 cardiologist labeled heartbeats. Each beat is labeled as belonging to one of 16 different classes. In some sense, the data in the MITDB is too good. It was collected at 360Hz, which is a higher sampling rate than is typical for the Holter monitors used to gather most long term clinical data. To simulate this kind of data, we resampled the pre-processed ECG signal at 128Hz.
 We consider the two main classification tasks proposed by the Association for the Advancement of Medical Instrumentation (AAMI): detecting ventricular ectopic beats (VEBs), and detecting supra-ventricular ectopic beats (SVEBs). These two tasks have been the focus of other researchers in-vestigating patient-adaptive heartbeat classification. Recently, Ince et al [5] and de Chazal et al [3] described methods that combine global information with patient-specific information. Ince et al trained a global classifier on 245 hand chosen beats from the MITDB, and then adapted the global classifier by training on labeled data from the first five minutes of each test record. Their reported results of testing on 44 of the 48 records -all records with paced beats were excluded -from the MITDB are reported in Table 2. De Chazal et al trained their global classifier on all of the data from 22 patients in the MITDB, and then adapted the global classifier by training on labeled data for the first 500 beats of each test record. Their reported results of testing on 22 records -different from the ones used in the global training set-from the MITDB are also reported in Table 2.
 For the same two classification tasks we tested our proposed approach and we report the results when tested on the records reported on in [5] and [3]. In these experiments we exclude the queried beats from the test set, testing only on data the expert hasn X  X  seen. This was also done in [5] and [3]. Since we query far fewer beats that the other methods, we end up testing on many more beats. Table 2: Our proposed method outperforms other classifiers for two common classification tasks. As Table 2 shows, the method proposed here does considerably better than the methods proposed in [5] and [3] for each task. For the task of classifying VEBs vs. non-VEBs, our method on average used 45 labeled beats (compared to roughly 350 beats for [5] and 500 beats for [3]) per record. For the task of detecting SVEBs, our method used even fewer labeled beats. Recognizing SVEBs is considerably more difficult than detecting VEBs since the class imbalance problem is even more severe and supra-ventricular beats are harder to distinguish from normal sinus rhythm beats. Table 3: Our algorithm outperforms a rule-based classifier designed specifically for the task of detecting PVCs.
 Hamilton et al proposed a rule-based classifier for classifying PVCs vs. non-PVCs. Their software is freely available online, from eplimited.com . We applied their software to all of the records, see Table 3. Their method does particularly poorly on the four records containing paced beats. Omitting these four records the F-Score increases to 91.4%, still worse than our method. One advantage of the rule-based algorithm is that it does not require a labeled training set, whereas on average we require 45 labeled beats per record. However, unlike our method the rule-based algorithm can only be used for one task. 4.2 The Impact of Active Learning We hypothesize that the difference in performance between our method and the other learning-based methods discussed above is attributable partly to the design of our feature vector and partly to the method of choosing training data. In order to test this hypothesis we ran an experiment that directly compares the effect of actively vs. passively selecting the training set, with all other parameters kept the same (e.g., identical pre-processing, identical feature vectors, etc.).
 For each of the 48 records in the MITDB we compare a VEB vs. non-VEB classifier using our approach, to a linear SVM classifier trained on the first 500 beats of each record. For each patient we record the number of queries made, as well as the performance of each classifier. Table 4 shows the classification results for each method across all patients. The column headed  X #Q X  gives the number of beats used for training each classifier, while the column headed  X  X P X  for true positives, gives the number of correctly labeled VEBs. The last row gives the totals across all records for each classification method.
 Overall, our classification approach achieves an F-score over 99%, and the passive technique achieves an F-score of 94%. Compared to the passive approach, active learning used over 90% less training data, and resulted in over 85% fewer misclassified heartbeats. These results empha-size that fact that active learning can be used to dramatically reduce the labor cost of producing highly accurate classifiers. That the passive technique performed better than [5] and almost as well as [3], despite not having any global training data, suggests that our feature vector provides some advantage. Table 4: Active versus passive learning. Active learning outperforms a passive approach, and uses over 90% less data.
 4.3 Experiments with Clinicians To get a sense of the feasibility of using our approach in an actual clinical setting, we ran an ex-periment with two cardiologists and data from another cohort of patients admitted with NSTEACS. The ECG tracings in this database, unlike those in the MITDB, are not particularly clean, i.e., they contain a considerable amount of noise and many artifacts. This makes them more representative of the data with which an algorithm in clinical use is likely to have to deal. We considered 4 randomly chosen records, from a subset of patients who had experienced at least one episode of ventricular tachycardia in the 7 day period following randomization. For each record, we consider the first half-hour, giving us a test set of 8230 heartbeats.
 In these experiments we used a slightly different stopping criterion developed earlier. As our algo-rithm chose beats to be labeled, each cardiologist was presented with an ECG plot of the heartbeat to be labeled and the beats surrounding it, like the one shown in Figure 3. The cardiologist was then asked to label it according to the following key: 1=clearly non-PVC , 2 = ambiguous non-PVC, 3=ambiguous PVC, 4=clearly PVC. Because the cardiologists made different choices about how some beats should be labeled, one was asked to label an average of 15 beats/record and the other roughly 20 beats/record. The whole process took each cardiologist about 90 seconds per record. Since the records had not been previously labeled (and it seemed unreasonable to ask our experts to label all of them), we used the PVC classification software from [6] to provide a label to which Figure 3: The classifiers trained using active learning both labeled the delineated beat delineated as a PVC, Table 5: Comparison of active earning using two different experts and Hamilton et al. Results are the sum we could compare the labels generated by our method. This gave us three independently generated labels for each beat. When all three classifiers agreed, we assumed that the beat was correctly classified. Out of a possible 8230 disagreements there were only 6. We asked a third expert to adjudicate all 6 disagreements, and used this as the gold standard to calculate the results for the three classifiers shown in Table 5. The goal of this work was to produce a clinically useful technique for automatically classifying activity in ECG recordings. The problem is made challenging by the intra-and inter-patient differ-ences present in the morphology and timing characteristics of the ECG produced by compromised cardiovascular systems and by the variability in the classification tasks that a clinician might want to perform. We propose to address these difficulties with a method for using active learning to perform patient-adaptive and task-adaptive heartbeat classification.
 When tested on the most widely used benchmark database of cardiologist annotated ECG record-ings, our method had better performance than other recently proposed methods on the two primary classification tasks recommended by AAMI. Additionally, our method required over 90% less train-ing data than the methods to which it was compared. We also showed that our method compares favorably to a state-of-the-art hand coded algorithm for a third common classification task. To test out the practical applicability of our method, we conducted a small study with two cardiol-ogists. Both cardiologists were able to use our tool with minimal training, and achieved excellent classification results with a small amount of labor per record.
 These preliminary results are highly encouraging, and suggest that active learning can be used prac-tically in a clinical setting to not only reduce the labor cost but also garner additional improvements in performance. Of course, there is still room for improvement. In all experiments we used identical input parameters; further tuning of these parameters may improve results. However, in a clinical set-ting parameter tuning is impractical, and thus more work to investigate automated parameter tuning is needed. Based on preliminary experiments we believe that by first learning the optimal number of initial clusters for each record one can improve performance while decreasing the total number of required labels. It may also be possible to further reduce the amount of required expert labor by starting with a global classifier and then adapting it using active learning.
 Acknowledgments We would like to thank Benjamin Scirica, Collin Stultz, and Zeeshan Syed for sharing their expert knowledge in cardiology and for their participation in our experiments. This work was supported in part by the NSERC and by Quanta Computer Inc.
