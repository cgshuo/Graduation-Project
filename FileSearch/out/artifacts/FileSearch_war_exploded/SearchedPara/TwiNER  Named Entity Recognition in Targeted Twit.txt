 Many private and / or public organizations have been reported to cre-ate and monitor targeted Twitter streams to collect and understand users X  opinions about the organizations. Targeted Twitter stream is usually constructed by fi ltering tweets with user-de fi ned selec-tion criteria ( e.g., tweets published by users from a selected region, or tweets that match one or more prede fi ned keywords). Targeted Twitter stream is then monitored to collect and understand users X  opinions about the organizations. There is an emerging need for early crisis detection and response with such target stream. Such applications require a good named entity recognition (NER) sys-tem for Twitter , which is able to automatically discover emerging named entities that is potentially linked to the crisis. In this paper, we present a novel 2-step unsupervised NER system for targeted Twitter stream, called TwiNER .Inthe fi rst step, it leverages on the global context obtained from Wikipedia and Web N-Gram corpus to partition tweets into valid segments (phrases) using a dynamic programming algorithm. Each such tweet segment is a candidate named entity. It is observed that the named entities in the targeted stream usually exhibit a gregarious property, due to the way the tar-geted stream is constructed. In the second step, TwiNER constructs a random walk model to exploit the gregarious property in the lo-cal context derived from the Twitter stream. The highly-ranked segments have a higher chance of being true named entities. We evaluated TwiNER on two sets of real-life tweets simulating two targeted streams. Evaluated using labeled ground truth, TwiNER achieves comparable performance as with conventional approaches in both streams. Various settings of TwiNER have also been exam-ined to verify our global context + local context combo idea.  X  The work was partially done when Chenliang Li was an intern at HP Labs Singapore.
 H.3.4 [ Information Systems ]: Content Analysis and Indexing X  Linguistic processing Twitter, Tweets, Named Entity Recognition, Wikipedia, Web N-Gram
Twitter , as a new type of social media, has seen tremendous growth in recent years. It has attracted great interests from both industry and academia. Many private and / or public organizations have been reported to monitor Twitter stream to collect and under-stand users X  opinions about the organizations. Nevertheless, due is practically infeasible and unnecessary to listen and monitor the whole Twitter stream. Therefore, targeted Twitter streams are usu-ally monitored instead; each such stream contains tweets that po-tentially satisfy some information needs of the monitoring organi-zation. Targeted Twitter stream is usually constructed by fi ltering tweets with user-de fi ned selection criteria depends on the informa-tion needs. For example, the criterion could be a region so that users X  opinions from that particular region are collected and mon-itored; it could also be one or more prede fi ned keywords so that opinions about some particular events / topics / products / services can be monitored.

There is also an emerging need for early crisis detection and re-sponse with such target stream. For example, a cosmetic company is interested in automatically discovering any new named entities (e.g. person names, competitor names, or location names) in a tar-geted stream it creates for the company and its products, which may link to a potential PR crisis. By doing this, the company is able to acquire fi rst-hand information about the crisis and make early re-sponse. Such applications require a good named entity recognition (NER) system for Twitter , which is the focus of this paper.
Nevertheless, the nature of tweets brings new challenges. Tra-ditional NER methods on well-formatted documents heavily de-pend on a phrase X  X  local linguistic features [14], such as capitaliza-tion, part-of-speech (POS) tags of previous words, etc. However, tweets are usually informal in nature and short (up to 140 charac-day, according to http://blog.twitter.com/2011/06/ 200-million-tweets-per-day.html . ters). They often contain grammatical errors, misspellings, and un-reliable capitalizations. These unreliable linguistic features cause traditional methods to perform poorly on tweets. We use the real examples below to illustrate the challenges when applying tradi-tional NER on tweets.
 1 PAP POSTERS ARE EVERYWHERE! AND FOR 2 ya la!! some of them gg to potong pasir . I X  X  gg to yio Table 1 shows two real tweets collected during a political event. A POS tagger would fail due to the tweets X  abnormal capitalization and grammatical errors. For example, in the fi rst tweet, all words (except  X  X AP X  and  X  X SP X ) 2 are mislabeled as NNP (singular noun). Similarly, in the second tweet,  X  X otong X  and  X  X io X  are mislabeled as JJ (adjective) and VB (verb) respectively, although both are a part of location names ( X  X otong pasir X  and  X  X io chu kang X ). This kind of noisy POS labels would make NER tagger fail to recognize named entities.

To address the above challenges caused by tweets X  error-prone and short nature, this paper presents a novel unsupervised NER sys-tem for targeted tweet streams, called TwiNER . Based on the gre-garious property of named entities in targeted tweet stream, TwiNER recognizes named e ntities collectively from a batch of tweets in un-supervised manner. More formally, let T be the collection of tweets in question. TwiNER receives tweets from T in a batch manner. A batch is the set of tweets posted in the targeted Twitter stream within one fi xed time interval (e.g. a second). So, T = { T and T i is the batch of tweets posted in the i th interval. TwiNER then recognizes all possi ble named entities in T i regardless of their types.
It is noted that currently TwiNER does not categorize the type of named entity ( e.g., person, location). As conventional NER meth-ods fail to address the new challenges posed by emerging social media like Twitter , it is more pressing to be able to discover the presence of named entities in targeted Twitter stream before we could categorize their types. Furthermore, even without catego-rizing the types of named entities, TwiNER already enable us to make early crisis response. For example, a cosmetic company may be interested in discovering any new named entity which may di-rectly / indirectly link to the company and subsequently causes a PR crisis, be it a person name, product name, or company name. More-over, as a targeted Twitter stream is constructed for a particular in-formation need, we assume that the user who constructs the stream has the background knowledge in interpreting the named entities detected. In the following subsections, we give an overview of TwiNER .

Figure 1 shows the general system architecture of TwiNER ,which has two main components, namely tweet segmentation and segment ranking .
As shown in Table 1, traditional linguistic features (e.g., capital-ization) are unreliable in tweets. Is there any other feature in tweets we can utilize for the task of NER?
In the same examples in Table 1, people spell  X  X io chu kang X  rather than  X  X hu kang yio X  or  X  X ang chu yio X . In other words, the correct collocation of a named entity is still preserved in tweets. tags such as  X #whathappentosavingtheearth X  are not considered in this paper.
 This observation holds stronger if a larger set of tweets are aggre-gated together. This motivates us to learn a weak phrase segmenter for tweets fi rst.
The idea is to segment an individual tweet into a sequence of 18]. Figure 2 gives an example. In this example, after removing the stop words, a tweet  X  My shoes are gg to compete in the youth olympic games sailing competition. It just needs a mast and a rud-der  X  is segmented into seven parts.

More formally, given a tweet of four words w 1 w 2 w 3 w 4 ment it as w 1 w 2 w 3 w 4 rather than w 1 w 2 w 3 w 4 ,if C ( w being a valid phrase of a segment.

A straightforward idea of computing Pr (  X  ) is to count a segment X  X  appearance in a very large corpus. The ideal case is that we use the entire collection of tweets published in Twitter to compute the Pr (  X  ) for all possible segments. Unfortunately, to the best of our knowledge, such corpus never exists. Instead, we turn to Microsoft documents in the World Wide Web indexed by Microsoft Bing in the EN-US market; it provides a good estimate of the statistics of commonly used phrases in English.

Another idea of computing Pr (  X  ) is to look up the segments in a knowledge base where valid segments are more easily recognized. We exploit Wikipedia for this purpose, which is by far the largest online encyclopedia in the World Wide Web. We take a snapshot of English Wikipedia 5 , and build a dictionary by extracting all the article titles, disambiguation pages, redirect pages (synonyms), and wikilinks [8]. If a segment matches any entry in the dictionary, it has a higher prior probability of being a true named entity.
TwiNER combines both ideas in a dynamic programming algo-rithm to e ffi ciently test various segmentation combinations. Note that in this step, we do not use any local linguistic features of a seg-ment, such as its capitalization. Instead, we leverage on the World Wide Web to derive the segmentation. For ease of presentation, in-formation captured from the World Wide Web for a given segment is called its global context .
Each segment extracted in Step (1) is a candidate named entity, e.g.  X  X outh olympic games X  and  X  X ast rudder X . We now have a huge pool of candidate named e ntities. U ndoubtedly, this pool has a high recall but a very poor precision in identifying the true named entities. For example, among the seven segments extracted in Figure 1, only  X  X outh olympic games X  can be considered as a true named entity.

Can we automatically identify t he true entities from non-entities in the pool? To address this problem, we learn a function that as- X  X egment X  and  X  X hrase X  are used interchangeably. http://web-ngram.research.microsoft.com/info/ http://dumps.wikimedia.org/enwiki/ signs a con fi dence score of being a true named entity to each can-didate named entity. Candidate named entities are then ranked ac-cording to this score. By setting a threshold, we can easily remove the long tails of non-entities with low scores.

Recall there are two types of global context for a given seg-ment in TwiNER : Web N-Gram and Wikipedia . The former ap-parently has no clear clue about such score because many common word combinations with high frequency are not named entities, like  X  X here is X  and  X  X uch a X . The latter, on the other hand, provides some hints because many named entities either have corresponding Wikipedia pages or have been referenced in Wikipedia .However, Wikipedia is not as real-time as Twitter . It usually takes a while for a new named entity appeared in tweets to be captured by Wikipedia . For example, in the tweets we use in the experiments,  X  X incent Wijeysingha X  is the name of a political fi gure, which appeared in tweets in the early April 2011. Before end of April 2011, there was no mention about this person at all in Wikipedia .Furthermore, there is also no guarantee that all named entities in tweets would appear in Wikipedia later.

Since the global context is insu ffi cient to identify the true named entity, is there any local feature in tweets themselves that we can utilize? It is observed that there exists a gregarious property among the named entities in the targeted tweet stream, since the tweets in the targeted tweet stream are normally about similar or related top-ics / events. Formally, gregarious refers to the interaction of named entities with each other and to their collective co-existence in the targeted tweet stream. For example,  X  X arack Obama X  is a named entity. It often co-occurs with other named entities like  X  X nited States X  and  X  X ichelle Obama X  in a targeted stream about United States , but seldom co-occurs with  X  X lease look X , a valid segment extracted from tweets but a non-entity. It is also uncommon that same set of non-entities appear together often.

This gregarious property of named entities in Twitter motivates us to design a  X  X ecursive X  algorithm to compute the score of a seg-ment being a named entity. The idea is: an undirected segment graph using all the segments extracted in Step (1) is built fi rst, in which nodes are segments and edges are weighed proportional to the co-occurrence similarity; then, a random walk model is applied on this graph to derive the probability of a segment being a named entity. Because a segment X  X  con fi dence is a ff ected by its neighbors in the graph, which only depends on the tweets themselves, we call the segment graph as the local context of a segment in the tweets. Note that, not only has the local context been considered in this model, but also the global context is integrated to overcome the limitation of random walk model. Finally, the output of the model is used as the score of a segment being a named entity.
One may wonder that building local context (i.e. the segment graph ) defeats the real-time nature of Twitter . Indeed, a bu ff er of tweets is necessary to construct the local segment graph ,making TwiNER not completely real time (response in a  X  X weet by tweet X  manner). Nevertheless, there are more than 2,000 tweets generated every second 6 in Twitter , which is already a big enough bu ff er to build the local context in Step (2). Therefore, TwiNER is able to give  X  X ear real-time X  response practically (in a  X  X econd by second X  manner).
To sum up, we made the following contributions in the paper: 1. We proposed an unsupervised NER system without explicit 2. To the best of our knowledge, our TwiNER system is the fi rst 3. The proposed system has been successfully evaluated on two
The rest of this paper is organized as follows. A review of related work is given in Section 2. Sections 3 and 4 present the design of TwiNER in detail. Following that, experimental results are pre-sented in Section 5 to evaluate the correctness and e ff ectiveness of TwiNER . Finally, Section 6 concludes this paper with discussion of future work.
Tweets are infamous for their error-prone and short nature. This leads to failure of many conventional NLP techniques, which heav-ily depend on local linguistic features, such as capitalization, POS tags of previous words, etc. Also acknowledging the error-prone nature of tweets, Han and Baldwin [6] proposed to normalize ill-formed words in tweets to make the contents more formal. How-ever, this work does not address the problem of NER. NER has attracted renewed interests recently, due to the challenges posed by tweets. Conventionally, NER studies are mainly conducted in a supervised manner. In most of the cases, they depend on the Part-of-Speech (POS) tags, which again need a tagger to be trained with supervised approach based on linguistic features[14, 20, 21].
There are attempts that design linguistic features to capture tweets X  unique characteristics and train tweet-speci fi c models. Gimpel et. al trained a POS tagger with the help of a new labeling scheme and a feature set that captures the unique characteristics of tweets [5]. It was reported to outperform the state-of-the-art Stanford 6 200 million Tweets per day : http://blog.twitter.com/ 2011/06/200-million-tweets-per-day.html . POS tagger on tweets. In [16], Ritter et. al presented an tweet-based NLP framework which contains tweet-speci fi c NLP tools: POS tagger ( T-POS ), shallow parsing ( T-CHUNK ), capitalization classi fi er ( T-CAP ), and named entity recognition ( T-NER ). T-POS and T-CHUNK are trained by using condtional random fi eld (CRF) model with conventional and tweet-speci fi c features. These tweet-speci fi c features include retweets, @usernames, hashtags, URLs, and Brown clustering results. Both T-POS and T-CHUNK were reported with better performance compared to the state-of-the-art methods. T-NER is separated into two task: named entity segment-ing ( T-SEG ) and named entity classi fi cation ( T-CLASS ). T-SEG is trained with a CRF model. The features include orthographic, con-textual, dictionary features, and the output by T-POS , T-CHUNK , and T-CAP . T-CLASS is implemented by applying Labled-LDA [13] a KNN-based classi fi er to conduct word-level classi fi cation, lever-aging the similar and recently labeled tweets. Those pre-labeled re-sults, together with other conventional features (e.g. orthographic and lexical features), were then fed into a CRF model to conduct fi ner-grained NER.

Due to their supervised nature, those approaches require the avail-ability of labeled data, which is usually expensive to come by. Finin et. al. presented a crowd-sour cing way (using services like Me-chanical Turk and CrowdFlower) of preparing labeled data for NER studies in Twitter [3]. However, it did not propose a solution for NER.

Similar to TwiNER , Downey et. al also proposed a collocation -based approach, called LEX to detect the boundaries of named en-tities [2]. Nevertheless, it is not designed for tweet-like informal text. It assumes that named entitie s are either continuous capital-ized words or mixed case phrases beginning and ending with cap-italized words, which is apparently too strong to hold in tweets. Silva et. al. [1] studied fi ve di ff erent types of collocation mea-surements and their variations for phrase extraction task. Besides SCP measurement used in both TwiNER and LEX , there are an-other four types of collocation measure . And SCP performs the best among others.
 Wikipedia is exploited as a source of global context in this paper. Wikipedia has been utilized in many text mining and NLP tasks, such as text categorization, topic detection, etc. For NER task, Wikipedia is mainly used to derive the category label for phrases, including [7] and [15]. [7] only looks for phrases of no more than eight words that start with a word containing at least one capital-ized letter in a sentence, and treats phrases with corresponding Wikipedia page as named e ntities. The head noun of the noun phrase just after be in the fi rst sentence of the Wikipedia page is picked as the phrase X  X  category. This method is not suitable for in-formal texts such as tweets due to its heavy dependence on local linguistic features. [15] focuse d on multilingual NER . It depended on the Category information in each English Wikipedia page to cat-egorize an English named entity. For a non-English phrase, the Category information in its corresponding English Wikipedia page, if any, is used for categorization. Nevertheless, it is not clear how named entity candidates are identi fi ed in this paper [15].
Existing attempts that exploit Wikipedia usually assume that named entities should hav e corresponding Wikipedia pages. This assump-tion makes them unable to identify emerging named entities which are frequently observed in tweets. However, there are many new named entity mentioned in tweets. In TwiNER , information in tweets X  local context and global context are aggregated to calcu-late the probability that a phrase is a named entity. By doing so, http://www.freebase.com/ TwiNER is able to recognize new n amed entities w hich may not appear in Wikipedia yet. To the best of our knowledge, it is the fi rst to exploit both the local context (in tweets )andthe global context (from World Wide Web) together for NER task in Twitter. In this section, we detail our solution for tweet segmentation. Given an individual tweet t  X  T i , the problem of tweet segmentation is to split t into m consecutive segments, t = s 1 s 2 ... s contains one or more words. To obtain the optimal segmentation, we use the following objective function, where C is the function that measures the stickiness of a segment or a tweet de fi ned based on word collocation: Ahigh stickiness score of segment s indicates that it is not suitable to further split segment s , as it breaks the correct word collocation . In other words, a high stickiness value indicates that a segment can-not be further split at any internal position.

If the word length of tweet t is l , there exists 2 l  X  1 mentations. It is ine ffi cient to iterate all of them and compute their stickiness. We therefore design a dynamic programming algorithm to tackle the problem, which is presented in the following.
Algorithm 1 outlines our dynamic programming algorithm for tweet segmentation. The basic idea is to recursively conduct bi-nary segmentations and then evaluate the stickiness of the resultant segments. More formally, given any segment s from t ( s can be t itself or a part of t ) and suppose s = w 1 w 2 ... w n to conduct a binary segmentation b y splitting i t into two adjacent segments s 1 = w 1 ... w j and s 2 = w j + 1 ... w n by satisfying:
The complexity of Algorithm 1 is O( lue log( ue )), where l is the average tweet length, u is the upper bound of segment length, and e bounds top sub-segments of a segment. Long segments are rare in tweets because each tweet is limited to 140 characters. We ob-served that in our data, u = 5 is a proper bound as the maximum length of a segment, which largely reduces the number of possible segmentations. We also set e = 5 so that the segmentation only focuses on top-quality segments and are not stuck by trivial ones, which leads to a complexity of O( l ).
In Algorithm 1, one key factor is the stickiness function C .A high stickiness score of segment s indicates that further splitting segment s would break the correct word collocation .Therearea number of collocation measurements [10, 12]. However, all these measures were de fi ned for two arguments. That is, they were de-signed to measure the collocation of the bigram or the n-grams with the particular binary partition. A variety of studies have been con-ducted to extend these binary collocation measures to the n-grams case (where n is greater than 2) [1, 2, 17]. We de fi ne the stickiness functions by using the generalization framework proposed in [1]. Speci fi cally, the generalized collocation measures of Point Mutual Information (PMI) and Symmetric Conditional Probability (SCP) are studied here.
Algorithm 1: Tweet Segmentation
PMI measures the degree that two words occur together more often than by chance. Mathematically, PMI for bigram w 1 w de fi ned as follows: Given a segment, s = w 1 ... w n , PMI is then extended by averaging all binary partitions as follows: If segment s only contains one word w ,wehave PMI ( s ) = log Pr( w ). Note that PMI de fi ned above falls into the range of (  X  X  X  , +  X  ). The stickiness of segment s is then de fi ned by mapping the value of Equation 4 to the range of [0 , 1] as follows:
Symmetrical Conditional Probability (SCP) was proposed in [1] to measure the  X  X ohesiveness X  of bigram w 1 w 2 by considering both conditional probabilities for the bigram given each single term: Given a segment, s = w 1 ... w n ,SCPof s is de fi ned similarly as follows: Here, we smooth SCP value by taking logarithm calculation, Equa-tion 7 is then updated as follows: SCP ( s ) = log Similarly, we de fi ne SCP for any segment s of unit length as SCP ( s ) = 2logPr( w ). We then de fi ne the stickiness of s by using the sigmoid function as follows:
By now, the calculation of the stickiness is reduced to estimat-ing Pr( s ), Pr( s 1 ), and Pr( s 2 ) for any segment s  X  t , which are prior probabilities of segments. To accurately estimate these prior prob-abilities, we n eed a large enough corpus as the global context of each segment. The ideal global context is the entire collection of tweets published in Twitter . But unfortunately, to the best of our knowledge, such corpus is not available.
 Instead, we exploit the one provided by Microsoft Web N-Gram Services [19] as approximation. This corpus is based on the web documents indexed by Microsoft Bing search engine in the EN-US market. The spam and other low quality documents are excluded. Each indexed document is parsed, tokenized, and the text is lower-cased with the punctuations removed. No stemming, spelling cor-rection or in fl ections are performed [19], which provides a large enough English corpus to estimate p rior proba bilities of segments.
One problem of segmentation based on the lexical statistics de-rived from such corpus is its preference towards frequent patterns. Figure 3 illustrates such an example, with a portion of tweet and three possible segmentations.
If only Web documents are used as a priori knowledge, then  X  youth olympic games sailing competition  X  would be segmented into  X  youth  X  X nd X  olympic games sailing competition  X ( i.e., the possible segmentation 3 in the fi gure), because both  X  youth  X  X nd  X  olympic games sailing competition  X  are frequent in Web docu-ments. Nevertheless, this tweet is in fact referring to  X  X outh Olympic Games X  held in Singapore in 2010.
 We therefore leverage a knowledge base in the World Wide Web, Wikipedia , as another source of global context to tackle this prob-lem. There are several reasons for the choice of Wikipedia .Itpro-vides rich a priori knowledge about entity information and is pub-licly available. Article titles, references to other Wikipedia pages, and the disambiguation pages, have often been used as named en-tity candidates [7, 15]. In detail, we build a large Wikipedia dic-tionary by extracting from a snapshot of Wikipedia on January 30, 2010 all the English article titles, disambiguation pages, redirect pages as well as hyperlinks [8]. Articles isolated from the rest are removed. Finally, we have a Wikipedia dictionary of 4,342,732 en-tries as well as their polysemes, synonyms.

Let Q ( s ) be the probability that s appears as anchor text in its mentioning Wikipedia article, which is the number of Wikipedia ar-ticles containing s as anchor text divided by the number of Wikipedia articles s appears in. A segment appearing as anchor text with a high probability in Wikipedia is a strong indication that it is a valid name entity[8]. The stickiness function is now de fi ned as follows: C ( s ) is measured by exploiting the global context captured in Mi-crosoft Web N-Gram. The second component of Equation 10 is introduced so that segments appearing in Wikipedia as anchor texts are attributed with higher stickiness .
So far, we treat segments of various lengths equally. However, in Twitter NER task, there are only a few long named entities. And it is observed that longer valid segments have higher chances of being named entities than shorter ones. Note that the Web N-gram data has already had a strong preference for short segments. Given this, we introduce length normalization L ( s )toEquation10tofa-vor moderately long segments in both Web N-gram and Wikipedia . Finally, we have the following stickiness function: The length normalization factor L ( s ) is empirically de fi ned as:
Section 3 extracts a large number of segments which are valid in the sense of word collocation by leveraging segments X  global con-text in the World Wide Web. However, not all segments extracted are named entities. For e xample,  X  X lease look X  is a valid segment but not a named entity. In this section, a set of strategies have been developed to rank segments according to their likelihood of being named entities.
We fi rst remove three types of segments which are obviously not named entities. 1. Segments containing well-known slang words, e.g.  X  X ol X  and 2. Segments containing words with consecutive repeating char-3. Segments containing words with  X # X  as pre fi x. Those words
The global context alone is insu ffi cient to recognize a named en-tity. We therefore utilize the local context of a segment in tweets to tackle this problem. One intuitive solution is to weigh a seg-ment using its frequency in tweets. However, this method would wrongly favor phrases like  X  X lease look X , which is not only fre-quent in World Wide Web, but also frequent in Twitter.

As we discussed in Section 1, there exists a gregarious property among named entities in targeted tweet streams. A good exam-ple is  X  X arack Obama X . It is a true named entity, and it often co-occurs with other named entities like  X  X nited States X  or  X  X ichelle Obama X  in tweets, but seldom co-occurs with  X  X lease look X , a valid segment but non-entity. It is also uncommon that same set of non-entities would appear together often.

Based on this property, we propose a  X  X egment graph X . At the i th interval (recall that TwiNER recognizes named e ntities in a batch mode), we build an undirected segment graph G ( V , E )usingallseg-ments V extracted from the tweet set T i on the fl y. In this graph, each node is a valid segment after noise fi ltering, and the edge e ab  X  E between two nodes (segments) s a and s b is weighed by the Jaccard Index : where M ( s )isthesetoftweetsin T i containing segment s .
The segment graph G ( V , E ) provides a good local context for each segment in T i . It does not use the unreliable local linguistics features of tweets but relies on the relations among segments. Be-cause all segments have been parsed once by their global context and then fi ltered with heuristic rules, these relations are relatively more reliable than local linguistics features.
A random walk model is then applied on graph G ( V , E )tocom-pute the stationary probability of each segment being a true named entity, by considering the graph bidirectional. While random walk-ing, the proba bility of transiting from node s a to node s as P ab )isgivenby All transition probabilities are th en aggregated to form a nonnega-tive transition matrix P for the whole graph.

To overcome the  X  X angling links X  while conducting a random walk on graph G ( V , E ), a teleportation vector e is also introduced to make the random walker jump from a node to any other node in the segment graph with a small probability [11]. We observe that Q ( s ), the probability that s appears as anchor text in Wikipedia ,isa good teleportation a priori. In other words, we favor those segments that are valid hyperlinks in Wikipedia , i.e. those segments are more likely to be named entities. Accordingly, we de fi ne the following teleportation probab ility for node (segment) s : The exponential function is used here to avoid the situation that the segment is new to Wikipedia so that its Q ( s ) = 0 and will never be teleported to.

The Wikipedia -based teleportation can be considered as an in-jection of global context into the random walk model of the local context. With the transition matrix P and the Wikipedia -based tele-portation vector e , the stationary eigenvector  X  T of P is calculated iteratively using power method as below: where  X  controls the probability of teleportation. The lower  X  is, the higher probability th e random walk will teleport according to e Then,  X  T is used as probabilities of segments being named entities in the local context.

Finally, for balancing the advantages of global context and local context , given an input segment s , TwiNER multiples its stationary probability  X  ( s )inthe segment graph mainly learned from the local context with its teleportation probability learned from Wikipedia: Equation 17 is used to rank all segments, and only the top K seg-ments are retained as named entities. In this section, we conduct extensive experiments to evaluate TwiNER . In Section 5.1, datasets simulating two targeted twitter streams are described, and performance metrics are introduced. Section 5.2 compares TwiNER with existing methods. We then present a performance analysis of TwiNER in di ff erent settings in Section 5.3. Tweets collections . Two collections of tweets are used in the ex-periments to simulate targeted twitter streams.

The fi rst collection ( SIN ) was collected to simulate targeted twit-ter stream of one particular geolocation by monitoring a number of users to be monitored was populated by fi rst getting the top-1000 Singapore-based Twitter users with the most number of followers from http://twitaholic.com , and then expanding the list by including the top users X  followers and friends in Twitter within two hops. There are a number of real-life events in the data collection period, such as the fl ash fl ood in Orchard Road (a premium shop-ping belt in Singapore), FIFA World Cup 2010 and WWDC 2010, etc. Collection SIN contains 4 , 331 , 937 tweets.

The second collection ( SGE ) was collected to simulate targeted twitter stream of one particular event by monitoring a set of pre-de fi ned keywords related to Singapore General Election 2011. Sim-ilar to collection SIN , only tweets published by Singapore-based users were collected. The data collection started on April 13, 2011 and ended on May 13, 2011, which covered the duration of Singa-pore General Election 2011 (nomination day on April 27, 2011, and polling day on May 7, 2011). Collection SGE contains 226 , 744 tweets.

It is observed that, by collecting tweets based on users, topics covered in collection SIN are diverse in nature. Topics covered in collection SGE , on the other hand, are more concentrated since most of the discussions are about the general election. Another observation is that, twitter users are more formal in political dis-cussions than casual discussions. In other words, tweets in SGE are more formal than those in SIN .
 Manual Annotation . For both collections, 5 , 000 tweets are ran-domly sampled from the tweets published on one random day. Each tweet is then labeled by two human annotators, who have strong background knowledge about Singapore-related named entities. The BILOU schema is used [9, 14]. After discarding retweets and tweets with inconsistent annotations, we get 4 , 422 tweets for SIN and 3 , 328 tweets for SGE . We denote these two randomly sampled tweets collections with groundtruth labeling as SIN_g and SGE_g respectively. Observe that the annotating agreement is relatively 8 A user is considered Singapore-based if she speci fi es Singapore in the location fi eld of her pro fi le. low for collection SGE . This is mainly due to the disagreement be-tween the human annotators about the way how to handle the con-cept GRC 9 and SMC 10 , which refer to di ff erent types of electoral divisions in Singapore. Annotators did not have an agreement on whether a GRC / SMC should be labeled as part of a location name. Performance Metric . Performance metrics used throughout the experiments include: Precision( Prec ), Recall( Recall ), and F1 . Prec quanti fi es the percentage of the extracted phrases that are true named entities. Recall quanti fi es the percentage of the true named entities that are correctly recognized. F1 is the harmonic mean of Prec and
Note that di ff erent values of K (the parameter in the segment ranking step) would result in di ff erent performance of TwiNER : larger K will increase Recall but decrease Prec , and vice versa. TwiNER  X  X  performance reported in the following sections are the ones with the highest F1 score TwiNER can achieve using SCP-based stickiness function, and various values of K . For a fair com-parison, K is set to be larger than 50 ( i.e., K &gt; 50). The maximum iteration for the random walk is fi xed at 500.
In this section, we compare TwiNER with two conventional NER systems trained on tweets. Speci fi cally, we train Stanford-NER and LBJ-NER with the labeled tweet data and evaluate their perfor-mance 11 . Moreover, we also compare with a tweet-speci fi cNER
Note that, other than the proposed TwiNER , the three methods listed above ( i.e., LBJ-NER, Stanford-NER and T-NER) are su-pervised methods and require labeled examples. For performance comparison, we randomly split both SIN_g and SGE_g in the ratio of 6 : 4 as training and evaluation sets. Stanford-NER and LBJ-requires development set for the parameter tuning, we further split the training set in the ratio of 5 : 1 for training and development. All the methods are evaluated on the same evaluation set. http://en.wikipedia.org/wiki/Group_ Representation_Constituency http://en.wikipedia.org/wiki/Single_Member_ Constituency 11 Note that as the entity type classi fi cation is not the focus of this paper, we do not di ff erentiate the entity types when both LBJ-NER and Stanford-NER are trained. https://github.com/aritter/twitter_nlp shared task. http://www.cnts.ua.ac.be/conll2003/ner/
Table 2 shows the evaluation results of di ff erent NER systems. It can be observed from Table 2 that: 1. As observed in Table 2, the overall performance on SGE_g 2. T-NER performs consistently across the two evaluation sets. 3. No system outperforms the others on both collections. Stanford-4. TwiNER , an unsupervised approach, achieves comparable As this set of experiments show, performance of LBJ-NER and Stanford-NER deteriorate signi fi cantly when they are applied on tweets, due to tweets X  error-prone context. To further illustrate the adverse impacts of tweets X  error-prone context, we trained LBJ-NER and Stanford-NER with formal text corpus using the CoNLL-2003 shared task data, and then directly apply the trained models on the evaluation sets of SIN_g and SGE_g . To distinguish the meth-ods trained using tweet data, we denote the two methods trained on Table 3: Conventional NER systems X  performance on tweets
The results of LBJ-NER F , Stanford-NER F and TwiNER are sum-marized in Table 3. It is observed that the performance of LBJ-NER F and Stanford-NER F deteriorate signi fi cantly with F1-measure of lower than 0 . 5 on both SIN_g and SGE_g .
In this section, we investigate the impact of di ff erent TwiNER components on its performance.
Tweet segmentation is used to extract the named entity candi-dates from tweets, or in other words, to identify the correct bound-ary of potential named entities in tweets. It is a critical component because the performance of TwiNER is heavily a ff ected by the ef-fectiveness of tweet segmentation.

Two stickiness functions are de fi ned by using two collocation measures, PMI and SCP, for tweet segmentation. The tweet seg-mentation algorithm described in Section 3 also incorporates an external knowledge base Wikipedia . Further, we normalize the seg-ment length to favor long named entities. In this section, we study the impact of the collocation measures ( PMI or SCP ), the Wikipedia dictionary ( Wiki ), and the length normalization ( Norm ), based on the ground truth in SIN_g and SGE_g . We use tweet segmentation with only PMI or SCP measures as the baseline (Equation 5 and 9). We measure the percentage of named entities that are correctly ex-tracted (i.e. split as a segment) as the performance metric, which is denoted as Prec as well. The experimental results are listed in Table 4. From Table 4, we observe that: 1. SCP signi fi cantly outperforms PMI for tweet segmentation. 2. Length normalization ( Norm )ise ff ective and improves the 3. Wikipedia  X  X  broad coverage and high quality knowledge help 4. The combination of Wikipedia dictionary and length normal-
A random walk model is applied to exploit the gregarious prop-erty of named entities in tweets. The fi nal segment ranking output is an aggregation from the stationary probability of the random walk model ( local context ) and the segment X  X  Wikipedia -based teleporta-tion Wiki probability ( global context ). We analyze their impact on the performance of segment ranking in this section. Speci fi cally, we investigate the following schemes for segment ranking:
Table 5 lists the experimental results based on the ground truth in SIN_g and SGE_g . From Table 5, it can be seen that: 1. While MFS works considerably well on SGE_g , its perfor-Table 5: Impacts of localcontext , globalcontext and random walk on segment ranking RWW + Wiki 0.576 0.335 0.423
RWW + Wiki 0.929 0.646 0.762 2. RW outperforms MFS signi fi cantly on SGE_g in terms of F 1. 3. An impressive performance is achieved by Wiki . It obtains
TwiNER  X  X  performance is related to the choice of K .Larger K will increase Recall and decrease Prec , and vice versa. In reality, what matters is rather how many real named entities are in the top list, so that the user can gain direct understanding on what the tar-geted tweets / Twitter users are concerning about. Thus, we calculate Prec@K for each K value from 1 to 200 14 . Here, Prec@K is the percentage of top K segments returned by TwiNER that are real named entities. Figure 4 shows Prec@K curves of TwiNER on SGE_g and SIN_g . Major proportion of segments returned when K &lt; 50 are true named entities. TwiNER achieves a stable Prec performance when K is in the range of [50 , 100]. After 100, Prec@K starts to degrade slowly on SGE_g , while Prec@K is still stable at 14 We believe K &lt; = 200 is a good range for the tweet collections we studied here. around 0 . 5on SIN_g . A good strategy of choosing the suitable K value in various scenarios is planned for future work. Neverthe-less, it is observed that the choice of K value depends on the nature of targeted tweet streams, such as topic cohesiveness, gregarious property, and size of the tweet collections.

Based on the extensive experiments conducted above, we see that by incorporating the encoded intelligence of World Wide Web and local context of tweets, TwiNER shows a promising performance. It provides an unsupervised approach for named entity recognition for Twitter, especially for targeted tweet streams with high gregar-ious property.
Twitter , as a new type of social media, has attracted great inter-ests from both industry and academia. Many private and / or public organizations have been reported to monitor Twitter stream to col-lect and understand users X  opinions about the organizations. Nev-ertheless, it is practically infeasible and unnecessary to listen and monitor the whole Twitter stream, due to it extremely large volume. Therefore, targeted Twitter streams are usually monitored instead. Targeted Twitter stream is usually constructed by fi ltering tweets with user-de fi ned selection criteria. There is also an emerging need for early crisis detection and response with such target stream.
Nevertheless, the error-prone and short nature of Twitter has brought new challenges to named entity recognition. In this paper, we present a NER system for targeted Twitter stream, called TwiNER , to address this challenge. Unlike traditional methods, TwiNER is unsupervised. It does not depend on the unreliable local linguis-tics features. Instead, it aggregates information garnered from the World Wide Web to build robust local context and global con-text for tweets. Experimental results show promising results of TwiNER . It is also shown to achieve comparable performance with the state-of-the-art NER systems in real-life targeted tweet streams.
Despite its promising results, there is still space for improve-ment. First of all, we plan to study TwiNER  X  X  performance in a larger scale. Second, we plan to study the strategy to identify suit-able K value. Last but not least, this paper does not address the problem of entity type classi fi cation. As discussed earlier, this is because we feel this problem is not as pressing as the problem to correctly locate and recognize pres ence of named en tities in tweets, which existing methods largely fail. Extension of TwiNER for en-tity type classi fi cation is also planed for future work. [1] J. F. da Silva and G. P. Lopes. A local maxima method and a [2] D. Downey, M. Broadhead, and O. Etzioni. Locating [3] T. Finin, W. Murnane, A. Karandikar, N. Keller, [4] J. R. Finkel, T. Grenager, and C. Manning. Incorporating [5] K. Gimpel, N. Schneider, B. O X  X onnor, D. Das, D. Mills, [6] B. Han and T. Baldwin. Lexical normalisation of short text [7] J. Kazama and K. Torisawa. Exploiting wikipedia as external [8] C. Li, A. Sun, and A. Datta. A generalized method for word [9] X. Liu, S. Zhang, F. Wei, and M. Zhou. Recognizing named [10] C. D. Manning and H. Sch X tze. Foundations of statistical [11] L. Page, S. Brin, R. Motwani, and T. Winograd. The [12] P. Pecina and P. Schlesinger. Combining association [13] D. Ramage, D. Hall, R. Nallapati, and C. D. Manning. [14] L. Ratinov and D. Roth. Design challenges and [15] A. E. Richman and P. Schone. Mining wiki resources for [16] A. Ritter, S. Clark, Mausam, and O. Etzioni. Named entity [17] P. Schone and D. Jurafsky. Is knowledge-free induction of [18] J. Silva, Z. Kozareva, V. Noncheva, and G. Lopes. Extracting [19] K. Wang, C. Thrasher, E. Viegas, X. Li, and P. Hsu. An [20] Y. Wang. Annotating and recognising name d entities in [21] G. Zhou and J. Su. Named entity recognition using an
