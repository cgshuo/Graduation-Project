 1. Introduction
Multi-document summarization aims to generate a compressed summary by extracting the major information in a col-ument data (e.g., news, blogs, web pages) on the Internet, multi-document summarization provides a useful solution for understanding documents and reducing information overload. Thus, multi-document summarization has attracted much attention in recent years, and many applications have been developed. For example, summarized informative snippets in
A variety of multi-document summarization methods have been developed in the literature. The most commonly used by selecting semantically and probabilistically important sentences in the documents ( Gong &amp; Liu, 2001 ).
Different multi-document summarization methods base on different strategies and usually produce diverse outputs. A natural question arises: can we perform ensemble or consensus summarization by combining different summarization methods to improve summarization performance? In general, the terms of  X  X  X onsensus methods X  X  or  X  X  X nsemble methods X  X  are commonly reserved for the aggregation of a number of different (input) systems. Previous research has shown that ensemble methods, by combining multiple input systems, are a popular way to overcome instability and increase  X  our knowledge, so far there are only limited attempts on using ensemble methods in multi-document summarization ( Wang &amp; Li, 2010 ).
 median aggregation, round-robin scheme, correlation based weighting method, and graph based combination) for obtaining a consensus summarizer to improve the summarization performance. We also propose a novel weighted consensus scheme answer. However, each of the summarization systems has shown its effectiveness individually, so the agreement measure can be used in the consensus summarization. Experiments on DUC2002 and DUC2004 data sets demonstrate the perfor-mance improvement using various consensus multi-document summarization methods, and our proposed weighted consen-sus scheme outperforms the other baseline combination methods.
 consensus ranking methods. Our proposed weighted consensus summarization is studied in Section 3 . The summarization are shown and discussed in Section 5 . Finally Section 6 concludes. 2. Related work 2.1. Multi-document summarization
Multi-document summarization has been widely studied recently. In general, document summarization can be divided and has become the standard in document summarization. In this paper we focus on extractive multi-document summari-zation. There are several most widely used extractive summarization methods as follows.

Centroid-based methods : This type of methods ranks sentences by computing their salience using a set of features. For example, MEAD ( Radev et al., 2004 ) is a typical centroid-based algorithm which extracts sentences according to three tence, where n is the number of sentences in these documents. The overlap value is computed as the cosine similarity between a sentence and the first sentence in the same document. Then the three values are linearly combined with equal weights.

Graph-based methods : This type of methods constructs a sentence graph, in which each node is a sentence in the docu-document, there is an edge between the pair of sentences. The sentences are selected to form the summaries by voting from their neighbors. Erkan and Radev (2004) propose an algorithm called LexPageRank to compute the sentence impor-tance based on the concept of eigenvector centrality (prestige) which has been successfully used in Google PageRank. Other graph-based summarization have been proposed in Mihalcea and Tarau (2005) and Wan and Yang (2008) . ranked sentences for summarization. The method first creates a term X  X entence matrix, where each column represents the weighted term-frequency vector of a sentence in the set of documents. Then singular value decomposition (SVD) is used on the matrix to derive the latent semantic structure. The sentences with the greatest combined weights across all the important topics are included in the summary.
 tences with the highest probability in each topic. NMF can also be viewed as a clustering method, which has many nice most representative ones from each cluster to form the summary.
 model (HMM) based method ( Conroy &amp; O X  X eary, 2001 ). Some query-based summarization systems are also proposed (LCC) ( LCC, xxxx ), a DUC participant, that proposes a system combining the question-answering and summarization sys-tem and using k -nearest neighbor clustering based on cosine similarity for the sentence selection.
Although various summarization approaches have been developed in literature, few efforts have been reported on aggre-gating document summarization methods. One work related to ensemble summarization is described in Thapar, Mohamed, and Rajasekaran (2006) , where a graph-based meta-summarization approach by comparing the document graph of individ-systematically evaluate different baseline combination methods for ensemble summarization and propose a novel weighted consensus scheme to aggregate the results from individual summarization methods. 2.2. Rank aggregation from each system can be viewed as a ranking of the sentences. The problem of combining multiple ranking results into a Feng, 2001 ).

There are two types of rank aggregation: unsupervised and supervised. Most of the unsupervised rank aggregation ap-weighted Borda count. They also develop an EM-based algorithm which uses each ranking as an observation to estimate the parameters for combining the ranking lists ( Klementiev &amp; Roth, 2008 ). 2.3. Consensus document summarization
In this paper, we propose a weighted consensus scheme to aggregate diverse summaries from different summarization systems and compare the results with both individual methods and other base aggregation methods. 3. Weighted consensus summarization (WCS) 3.1. Notations
Suppose there are K single summarization methods, each of which produces a ranking for the sentences containing in the document collection. Then we have K ranking lists { r 1 , r tences in the documents. The task is to find a weighted consensus ranking of the sentences r  X  with a set of weights { w , w 2 , ... , w K } assigning to each of the individual summarization methods. 3.2. Optimization-based weighted consensus summarization
Our goal is to minimize the weighted distance between r  X  and all the r be formulated as follows. tance and the smoothness enforced by w . In our experiments, k is set to 0.3 empirically. distance to measure the discordance of the consensus ranking r  X  and each of individual sentence rankings r of the weights. We initialize w i  X  1 K , and this optimization problem can be solved by iterating the following two steps:
Step 1: Solve for r  X  while fixing w . The optimal solution is the weighted average
Step 2: Solve for w while fixing r  X  . Let
Note that
For fixing r  X  , the optimization problem becomes Shwartz, Singer, and Chandra (2008) .
 sensus ranking.
 simplicity, denote Eq. (1) as D and denote the initial w and r  X  as w step procedure: r i  X  arg minD w i 1 ; r i 1 and w i  X  arg minD w can often be established for this procedure. 4. Implemented systems
In the section, we describe four typical multi-document summarization methods and eight aggregation methods imple-mented in our experimental study. 4.1. Individual summarization methods tence overlap as features.
 LexPageRank : a graph-based summarization method recommending sentences by the voting of their neighbors ( Erkan &amp; Radev, 2004 ).
 LSA : conducts latent semantic analysis on terms by sentences matrix as proposed in Gong and Liu (2001) . wepickthetop-rankedsentenceinthemostimportantcluster/topicandthenthetop-rankedsentenceinthesecondimportant cluster-based summarization methods on selecting sentences with different summary lengths. 4.2. Aggregation methods Here we list the aggregations methods used in our experimental study.

Average score (Ave _ Score) : normalizes the raw scores from different summarization systems between 0 and 1, and then averages the scores as follows: where K is the number of summarization systems, and Score _ k ( S nally the sentences are re-ranked based on their average scores.
 Average rank (Ave _ Rank) : averages the individual rankings from different summarizers as follows: where Rank _ k ( S i ) is the ranking by the k th system. Then the sentences are sorted by their average ranking. Median rank (Med _ Rank) : instead of using average rank, median rank is also often used to aggregate ranking lists. reached.
 sentences are ranked based on their points obtained.

Correlation-based weighting (CW): uses Kendall X  X  Tau correlation ( Abdi, 2007 ) to measure the agreement between two sentence rankings. The average correlation between a ranking list and all the other lists is computed as the weight of the system. The Kendall X  X  Tau correlation is defined below: where N is the number of sentences, N c is the number of concordant pairs of sentences, and N pairs of sentences. A pair of sentences (e.g., S i and S j ranking lists (e.g., Rank _ m and Rank _ n ), i.e. if Rank _ m ( S the consistency of the two ranking lists. Finally, the weights are normalized between 0 and 1. marization systems are calculated by optimizing the weighted Borda count, which aims to find a consensus ranking with the minimum average Spearman X  X  distance ( Spearman, 1904 ) to all the individual ranking lists. An online algorithm is derived using iterative gradient descent ( Klementiev et al., 2007 ).

Graph-based combination (graph) : constructs a sentence graph for each of the summary produced by the summarization sentences is above a predefined threshold. Then a consensus summary is generated by selecting sentences most similar similarity to generate the sentence graph without natural language processing so that we can compare this method with other combination methods fairly.

Weighted consensus summarization (WCS) : our proposed weighted consensus document summarization algorithm as described in Section 3 .

In the experiments, we examine the summarization performance of the implemented individual and combination sys-tems, and compare our proposed weighted consensus summarization algorithm with the other combination methods. 5. Experiments
In this section, we conduct experiments on DUC benchmark data to compare and evaluate individual and consensus sum-marization performance. 5.1. Data set
To evaluate the summarization results empirically, we use the DUC2002 and DUC2004 data sets, both of which are open benchmarkdata sets from DocumentUnderstanding Conference(DUC) for genericautomatic summarization evaluation. Table (TDT) research. 5.2. Evaluation methods applied by DUC for performance evaluation. It measures the quality of a summary by counting the unit overlaps between the candidate summary and a set of reference summaries. Several automatic evaluation methods are implemented in ROUGE, such as ROUGE-N, ROUGE-L, ROUGE-W and ROUGE-SU. ROUGE-N is an n -gram recall computed as follows: where n is the length of the n -gram, and ref stands for the reference summaries. Count of n -grams co-occurring in a candidate summary and the reference summaries, and Count (gram in the reference summaries. ROUGE-L uses the longest common subsequence (LCS) statistics, while ROUGE-W is based on weighted LCS and ROUGE-SU is based on skip-bigram plus unigram. Each of these evaluation methods in ROUGE can gen-for simplicity, in this paper, we only report the average F -measure scores generated by ROUGE-1, ROUGE-2, ROUGE-L,
ROUGE-W and ROUGE-SU to compare the implemented systems. 5.3. Experimental results 5.3.1. Overall performance
First of all, we compare the implemented consensus summarization methods with individual summarization systems to examine the effectiveness of consensus methods for summarization performance improvement. We also compare the per-formance of our proposed WCS method with other implemented combination methods.

Tables 2 and 3 show the ROUGE scores of different individual and combination methods using DUC2002 and DUC2004 statistics). From the results, we have the following observations. 1. Most of the combination summarization systems outperform all the individual systems except the round robin combina-tion. The poor performance of the round robin combination may come from the inaccuracy or overlap of the very top ranking sentences of the single summarization results. The results demonstrate that in general consensus methods can improve the summarization performance. 2. Our proposed weighted consensus summarization (WCS) method outperforms other combination methods. For simple average combination schemes (such as Ave_Score, Ave_Rank, Med_Rank, RR, BC, and CW), they treat each individual sum-marization system equally. However, individual summarization methods may have different performance results on dif-ferent data sets, thus introducing weights to form weighted combination is necessary. From the results we observe that the weighted combination methods are more effective than average combination methods. Among different weighted combination methods (e.g. CW, ULARA, and WCS), our WCS method optimizes the weighted distance between the con-ser to the nature of consensus summarization than other approximation based weighted methods such as CW and ULARA the graph-based method only considers the subset of sentences selected by individual summarization systems. summarization method is not as good as the best team, many of the consensus summarization solutions outperform the best team of the DUC participants (especially on DUC2004 data set). Note that the good performance of the best team in mented systems.
 served more clearly. We show ROUGE-1 results in these figures. 5.3.2. Diversity of individual summarization methods
In this paper, we use four individual summarization methods as the baselines. These individual summarization methods are selected as the representatives of the most widely used types of summarization methods, and they are fundamentally different in both algorithm design and implementation, which makes them diverse and complimentary with each other. ROUGE X 1 senting each topic as the summary. However, with nonnegative constrains, NMF provides more natural interpretations of document data. In this set of experiments, we further examine if the four individual summarization methods are comple-mentary to each other. We use our WCS method to aggregate any three of the four summarization methods and compare From the results, we observe that adding any of the four individual methods improves the summarization performance.
This is because these individual summarization methods are diverse and their performance is data dependant, i.e., some methods may work well on certain data. Thus the four methods are complementary to each other, and combining them do improve the overall summarization performance.
 5.3.3. Parameter tuning
In Figs. 5 and 6 , we gradually tune the parameter k in our WCS method to adjust the weights between the weighed sen-to the four methods are 0.2085, 0.5025, 0.0982, and 0.1908, respectively. 6. Conclusion
In this paper, we study four most widely used multi-document summarization systems (i.e. the centroid-based method, the graph-based method, LSA, and NMF) and propose a weighted consensus summarization method to combine the results from single summarization systems. We evaluate and compare our proposed weighted consensus method with various com-weighting method, and graph-based combination), and experimental results on DUC2002 and DUC2004 data sets demon-strate the performance improvement by aggregating multiple summarization systems, and our proposed weighted consen-sus summarization method outperforms other combination methods.
 Acknowledgement The work is partially supported by US NSF Grants IIS-0546280 and DMS-0915110.

References
