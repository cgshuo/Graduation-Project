 Daisuke Kimura daisuke kimura@mist.i.u-tokyo.ac.jp Hisashi Kashima kashima@mist.i.u-tokyo.ac.jp Tokyo, 113-8656, JAPAN 1.1. Kernels for structured data Numerous studies on the research in machine learning are concerned with real-valued vectors. However, a considerable part of real world data is represented not as vectors, but as sequences, trees, and graphs. For ex-ample, we can represent biological sequences and natu-ral language texts as sequences, parsed texts and semi-structured data, such as HTML and XML, as trees, and chemical compounds as graphs. Extensive stud-ies have been conducted to analyze structured data such as sequences, trees, and graphs, owing to their widespread use in recent years. Among the various existing approaches, a popular approach to such anal-ysis is the kernel method ( Sch X olkopf &amp; Smola , 2002 ) because it can eciently work with high-dimensional (possibly, in nite-dimensional) feature vectors if ap-propriate kernel functions are provided to access data. A framework called the convolution kernel ( Haussler , 1999 ) is widely used for designing kernel functions for structured data, where the structured data are (im-plicitly) decomposed into substructures, and a ker-nel function is de ned as the sum of kernel functions among the substructures. It is important to design a good kernel function to balance the expressive power of the substructures with ecient algorithms for com-puting the kernel. In the framework of the convolution kernel, various kernel functions have been proposed for sequences ( Lodhi et al. , 2002 ; Leslie et al. , 2002 ), trees ( Collins &amp; Du y , 2001 ; Kashima &amp; Koyanagi , 2002 ; Aiolli et al. , 2009 ), and graphs ( Kashima et al. , 2003 ; G X artner et al. , 2003 ). 1.2. Tree kernels In this paper, we focus on tree kernels. The rst tree kernel was proposed by Collins and Du y ( 2001 ) for parse trees, and it was then extended to general or-dered trees ( Kashima &amp; Koyanagi , 2002 ). More re-cently, various kernels for ordered trees have been proposed ( Moschitti , 2006 ; Kuboyama et al. , 2006 ; Aiolli et al. , 2009 ; Sun et al. , 2011 ).
 Among the existing tree kernels, only a few kernels can handle unordered trees (Fig. 1 (a)). In their sem-inal work, Vishwanathan and Smola ( 2003 ) proposed an ecient kernel for unordered trees. Their work is pioneering in two ways: computation can be performed in linear time with respect to the size of two trees by converting the trees into strings. Moreover, in the pre-diction phase, prediction for a newly coming tree can be made in linear time with respect to the size of the tree. Their kernel employs complete subtrees as fea-tures. Figure 1 (b) shows all the complete subtrees in the tree shown in Fig. 1 (a). More ecient implementa-tion using the enhanced sux array (ESA) for strings was proposed by Teo and Vishwanathan ( 2006 ). More recently, Kimura et al. ( 2011 ) proposed another tree kernel using vertical substructures called sub-paths. Figure 1 (c) shows all the subpaths in the tree shown in Fig. 1 (a). Their kernel is useful for captur-ing vertical substructures responsible for hierarchical information in trees. Note that neither of the complete subtree features and the subpath feature is a superset of the other. Figure 2 shows the experimental com-parison of the predictive accuracy of their kernel with that of four other tree kernels using three datasets, including one XML dataset ( Zaki &amp; Aggarwal , 2006 ) and two glycan datasets ( Hashimoto et al. , 2003 ; Doubet &amp; Albersheim , 1992 ) 1 . Note that three kernels were designed by Kashima &amp; Koyanagi ( 2002 ), Mos-chitti ( 2006 ) and Aiolli et al. ( 2009 ) for ordered trees; hence, we used the order information appearing in the datasets as it is. The results show that the subpath kernel proposed by Kimura et al. ( 2011 ) is competi-tive with the other kernels. Interestingly, the subpath kernel and the kernel proposed by Vishwanathan and Smola ( 2003 ) work complementarily.
 Kimura et al. ( 2011 ) also showed that their subpath kernel is practically fast and that it is competitive with the linear-time kernel ( Teo &amp; Vishwanathan , 2006 ). However, despite its practical usefulness, the time complexity of the subpath kernel is theoretically O( n log n ) on average, and it is O( n 2 ) in the worst case, where n is the sum of the sizes of the input trees, because their algorithm for computing the kernel uses the multi-key quick sort ( Bentley &amp; Sedgewick , 1997 ). Moreover, in contrast to the linear-time kernel ( Vishwanathan &amp; Smola , 2003 ; Teo &amp; Vishwanathan , 2006 ), we need to evaluate the subpath kernel between a given tree and all the support vectors in the prediction phase, which is a serious drawback with large-scale data. 1.3. Proposed methods By improving the result of Kimura et al. ( 2011 ), we aim to develop (i) a theoretically guaranteed linear-time kernel computation algorithm that is practically fast, and (ii) an ecient prediction algorithm whose running time depends only on the size of the input tree.
 The key to achieving these two objectives is an ecient data structure that accesses vertical substructures in trees. The sux tree (ST) of trees ( Shibuya , 2003 ) is a potential candidate. However, despite its theoretical merits, its performance (especially its memory usage) is not sucient for practical use, as pointed out in lit-erature (e.g., Abouelhoda et al. ( 2004 )). In order to overcome this challenge, we use a more space-ecient data structure called the enhanced sux array (ESA) for unordered trees, and we develop its linear-time con-struction algorithm. To the best our knowledge, this is the rst algorithm that constructs the ESA for trees in linear time.
 Using the ESA for trees, we devise a linear-time com-putation algorithm for the subpath tree kernel by sim-ulating bottom-up traversal in the ST. Note that Vish-wanathan et al. calculated their kernel by simulat-ing top-down traversal in the ST, using the ESA for strings .
 We also devise a fast algorithm for prediction, whose complexity is independent of the number of support vectors. This algorithm can be considered as a gener-alization of that of Teo &amp; Vishwanathan ( 2006 ), which simulates top-down traversal in the ST. Our algorithm guarantees quadratic time with respect to the size of an input tree in the worst case. Note that a naive implementation using the ESA results in cubic time complexity. Experimental results show the proposed algorithms are also quite ecient in practice. 1.4. Contributions Our study makes the following three contributions: 1. We propose a linear-time algorithm for construct-2. We propose a linear-time algorithm for computing 3. We present a fast algorithm for making predic-Kimura et al. ( 2011 ) proposed a tree kernel on the basis subpaths to capture vertical substructures responsible for hierarchical information in trees. Formally, a sub-path is a substring of a path from the root to one of the leaves (Fig 1 (c)). By using subpaths, they proposed a kernel function between two trees T 1 and T 2 as where P is the set of all subpaths in T 1 and T 2 , and num( T 1 p ) and num( T 2 p ) are the number of times a subpath p 2 P appears in T 1 and T 2 , respectively. (0 &lt; 1) is a constant giving an exponentially decaying weight to each subpath p , according to its length j p j .
 Kimura et al. pointed out that there is a one-to-one correspondence between a subpath and a pre x of a sux of a tree. Intuitively, a pre x of a sux of a tree is a reversed subpath (whose formal de nition is given in Section 3 ). They utilized this fact, and computed by extending the idea of multi-key quicksort instead of computing Eq. ( 1 ) directly, where S is the set of all pre xes of suxes in T 1 and T 2 . The time complexity of their algorithm is O(( j T 1 j + j T 2 j )log( j T 1 j average, and O(( j T 1 j + j T 2 j ) 2 ) in the worst case. In Section 4 , we will improve this result to O( j T 1 j + j
T trees proposed in Section 3 . First, we review the sux tree and ESA for a tree. Both of them are essential for constructing fast algo-rithms for the subpath kernel in Section 4 . Then, we propose a novel algorithm for constructing the ESA in linear time.
 3.1. Sux Trees and Enhaced Sux Arrays Let T be a rooted tree consisting of n nodes, whose node labels are drawn from alphabet of size = j j . The i -th sux of T (denoted by S i ) is the string associ-ated with the path from the i -th node to the root of T . For a string s , each substring beginning with the rst character is called a pre x . The sux tree (ST) of a tree T is a patricia trie for all suxes of T (Fig. 3 (a)), where a common pre x of suxes is associated with a pass from the root to an internal node. Although ST provides fast access to any sux of the tree, it is known that it requires a large amount of mem-ory, and hence, it is inecient for practical purposes. The ESA ( Abouelhoda et al. , 2004 ) is a more space-ecient data structure that allows many of the oper-ations provided by the ST, and therefore, it is often used in many practical applications instead of the ST. The ESA of a tree T consists of two data structures, a sux array (SA) and an lcp array (LCP). The sux array SA[1 ; j T j ] is an array of integers that maintains the starting positions of lexicographically ordered suf-xes. The lcp array LCP[1 ; j T j ] is an array of inte-gers that stores the lengths of the longest common pre xes of the adjacent suxes in the SA, that is, LCP[ i ] lcp( S SA[ i ] ; S SA[i+1] ) for 1 i &lt; j T j LCP[ j T j ] 1, where lcp( s; t ) denotes the longest common pre x of two strings s and t . The LCP pro-vides information about the depth of internal nodes of the ST. We present an example of the SA and LCP in Fig 3 (b). 3.2. Linear-time construction algorithm of an There exists a linear-time algorithm that constructs an ESA for a string ( K X arkk X ainen &amp; Sanders , 2003 ). However, to the best of our knowledge, there is no algo-rithm for constructing an ESA for a tree in linear time. Therefore, we propose an O( j T j ) algorithm for con-structing an ESA for a tree T , which is described as Al-gorithm 1 . Our algorithm is designed by carefully com-bining two algorithms, namely, the skew algorithm for ESA construction of strings ( K X arkk X ainen &amp; Sanders , 2003 ) and the linear-time construction algorithm of an SA for a tree ( Ferragina et al. , 2005 ). The following theorem guarantees that this algorithm constructs an ESA of a tree in linear time.
 Theorem 1 Algorithm 1 constructs the ESA for a tree T in O( j T j ) time.
 Algorithm 1 Constructing the ESA for a tree T in O( j T j ) time Input: Tree T
Output: SA[1 ; j T j ] and LCP[1 ; j T j ] for T 1. Apply Algorithm 1 recursively to a tree T 0 obtain some of the nodes in T whose depth is not equal to d in modulo 3 2. Construct SA 2 [1 ; j T j j T 0 j ] for nodes whose depth is equal to d in modulo 3 by using SA 1 [1 ; j T 0 j ] 3. Construct SA[1 ; j T j ] by merging SA 1 [1 ; j T 0 j ] and
SA 2 [1 ; j T j j T 0 j ] 4. Construct LCP[1 ; j T j ] by using LCP 1 [1 ; j T 0 j
SA 1 [1 ; j T 0 j ], and SA[1 ; j T j ] return SA[1 ; j T j ] and LCP[1 ; j T j ] In what follows, we give how the algorithm works and a skech of the proof of Thorem 1 by construction. Algorithm 1 works recursively; it calls itself to con-struct an ESA for tree T 0 , whose size is at most 2 j T j (in Step 1). We focus only on the suxes starting at nodes whose depths are not equal to d 2f 0 ; 1 ; 2 g in modulo 3, and apply the radix sorting to them using only the rst three labels in each sux. The param-eter d is appropriately chosen so that the number of nodes staring at depth d (in modulo 3) is at least j T j = 3. Next, we rename the label of each node with the rank of the sux starting at the node in the sorting result, and construct T 0 whose size is at most 2 j T j = 3. If the all of the renamed node labels are di erent, their order directly gives the order of suxes (SA 1 [1 ; j T 0 j ]). Oth-erwise, the algorithm calls itself to construct an ESA for tree T 0 .
 In Step 2, it constructs an SA for the nodes not in-cluded in the ESA of T 0 . This can be done in O( j T j ) time by the radix sort using the rst two node labels. (Note that we already know the order of the second node label from SA 1 [1 ; j T 0 j ].) In Step 3, it constructs an SA for T by merging the (E)SA obtained in Step 1 and the SA obtained in Step 2. This can be done in O( j T j ) time ( Ferragina et al. , 2005 ).
 The key to the linear-time construction is in Step 4, which is originated from the algorithm of K X arkk X ainen and Sanders ( 2003 ) for updating the LCP for strings. Let k and l be k SA[ i ] and l SA[ i + 1] for T , respectively. There are two possible cases: (i) neither of the depths of k and l is equal to d in modulo 3, or (ii) either of them is equal to d in modulo 3. In the rst case, k and l are both included in T 0 . Let k 0 and l 0 be the nodes in T 0 corresponding to k and l , respectively. We can know the positions of k 0 and l 0 in SA 1 [1 ; j T 0 j ] by using a reversed suf-x array (RSA), which is de ned as RSA[SA[ i ]] i . Note that the RSA can also be constructed in lin-ear time. Without loss of generality, we assume that RSA[ k 0 ] &lt; RSA[ l 0 ]. Since k and l are ad-jacent in SA[1 ; j T j ], k 0 and l 0 are also adjacent in SA 1 [1 ; j T 0 j ]. Since we already have LCP 1 [1 ; j T obtain m = lcp( k 0 ; l 0 ) = LCP 1 [RSA[ k 0 ]] with a con-stant time by accessing LCP 1 [1 ; j T 0 j ]. Then, we can calculate LCP[ i ] = 3 m + lcp(anc( k; 3 m ) ; anc( l; 3 m )), where anc( v i ; j ) returns the j -th ancestor of node v Note that three successive node labels in T is renamed with one character in T 0 . In the case with trees, we need preprocessing for all nodes T to achieve O(1)-access to their arbitrary ancestor nodes (whereas this is trivial in strings by using the indices). This problem is called the level ancestor problem . It can be solved by O( j T j ) preprocessing ( Bender &amp; Farach-Colton , 2004 ). Since the lcp(anc( k; 3 m ) ; anc( l; 3 m )) is at most 2, we can obtain the value in constant time. Consequently, we can compute LCP[ i ] in O(1) time after O( j T j ) pre-processing.
 In the latter case, while at least one of k and l is not included in T 0 , anc( k; z ) and anc( l; z ) ( z 2 f 1 ; 2 g ) are both included in T 0 . In contrast with the previous case, k 0 and l 0 are not necessarily ad-jacent in SA 1 [1 ; j T 0 j ]. However, we can obtain m = lcp( k 0 ; l 0 ) = RMQ(LCP 1 [1 ; j T 0 j ] ; RSA[ k 0 ] ; RSA[ l where RMQ(Array ; x ; y ) returns the minimum value of Array[ i ] ( x i y ). This problem is called the range minimum query , and it can be solved in O(1) time after O( j T j ) preprocessing. Consequently, we can compute LCP[ i ] in O(1) time after O( j T j ) preprocessing. In conclusion, we can compute LCP[1 ; j T j ] in O( j T j time, and hence the total running time of the algo-rithm represented as f ( T ) = f (2 j T j = 3) + O( j T j O( j T j ). We propose a linear-time algorithm for computing the subpath kernel ( 2 ) by using the ESA for the trees intro-duced in Section 3 . The proposed algorithm consists of the following three steps. 1. Add special terminal characters $ 1 and $ 2 ($ 1 &lt; 2. Construct an ESA for the merged tree by using 3. Calculate Eq. ( 2 ) by simulating bottom-up traver-First, the algorithm merges the input trees T 1 and T 2 in Step 1, in which the special terminal characters are added to ensure that no sux can be a pre x of any other sux. Next, it constructs the ESA for the merged tree using Algorithm 1 in linear time. Finally, it calculates Eq. ( 2 ) with the ESA. Since Eq. ( 2 ) can be calculated by enumerating all the common pre xes of suxes in T 1 and T 2 , it can be computed as K ( T 1 ; T 2 ) = by a bottom-up traversal of the ST for the merged tree. In the above equation, ST in denotes the set of inner nodes in ST, depth( v ) denotes the depth of node v , parent( v ) denotes the parent node of v , and lvs( T 1 v denotes the number of leaves belonging to T 1 among the leaves of the subtree rooted at v . W is an ar-ray whose elements are de ned as W[ n ] where is the decaying rate in Eq. ( 2 ). Since we con-structed an ESA instead of a ST, we use the ESA to simulate bottom-up traversals in the ST ( Kasai et al. , 2001 ). Algorithm 2 shows the pseudocode of a bottom-up traversal in the ST and calculation of Eq. ( 2 ) with the ESA. Since the number of nodes in the ST for a T is 2 j T j at most, Algorithm 2 runs in O( j T 1 j + j T time. Figure 4 shows an example of (a) the merged tree obtained in Step 1, (b) the ST for the merged tree, and (c) the ESA for the merged tree.
 The following theorem shows that the three steps listed above compute the subpath kernel ( 2 ) in linear time. Theorem 2 The proposed algorithm computes the subpath kernel ( 2 ) for T 1 and T 2 in O( j T 1 j + j T 2 Proof 1 We can merge T 1 and T 2 in O(1) time in Step 1. In Step 2, Algorithm 1 constructs the ESA in O( j T 1 j + j T 2 j ) time. Finally, Algorithm 2 computes complexity of the proposed algorithm is O( j T 1 j + j T 2 Algorithm 2 Algorithm for computing Eq. ( 2 ) inO( j T 1 j + j T 2 j ) A serious drawback in applying kernel methods to large-scale data sets is that we need to evaluate a ker-nel function between an input data T and all the sup-port vectors T i ( i = 1 ; :::; m ) in the prediction phase. For the subpath kernel, prediction for a tree T needs to evaluate f ( T ) = where P S i and P S are the set of all pre xes of suf-xes in T i and T , respectively. Note that Eq. ( 3 ) is identical to the one of Teo and Vishwanathan ( 2006 ) when f T i g i and T are strings. They proposed a so-phisticated O( j T j )-time algorithm whose running time does not depend on the number of support vectors. We brie y describe the algorithm. The computation of Eq. ( 3 ) comes down to nding the longest common pre x (lcp) between S i and the \master string", which is the concatenation of all the strings corresponding to the support vectors. First, the algorithm constructs an ESA of the master string, Then, when an input string T comes, the algorithm simulates a top-down traver-sal of a ST with the ESA to nd the lcp between S i and the master string. The algorithm utilizes the fact that l i l i 1 1, where l i is the length of the lcp be-tween S i and the master string. This implies that we can skip the rst l i 1 characters and start comparison from the next character when we nd l i .
 We extend their algorithm to trees. First, we construct an ESA for the \master tree" obtained by concatenat-ing all the support vector trees. Then, when an in-put tree T comes, the algorithm simulates a top-down traversal of a ST with the ESA to nd the lcp be-tween S i and the master tree. The di erence from the previous algorithm is in its skipping strategy. Since node i may have more than one children in trees, l i max l Ch ( i ) 1 holds, where Ch ( i ) is the set of children of node i . Thus, we can skip max l Ch ( i ) 1 nodes when we nd l i . The following theorem guaran-tees that the prediction for a newly coming tree T is computed in O( j T j 2 ) time in the worst case. Theorem 3 The time complexity of prediction for a tree T is O( j T j 2 ) .
 Proof 2 We evaluate the total length which we tra-verse the ST to nd all the lcp between S i and the master tree. X For any node i satisfying max l Ch ( i ) = 0 , we cannot skip any node; hence, we have to walk down the ST of the master tree (corresponding to the rst term in the rst line). For any node i satisfying max l Ch ( i ) 6 = 0 , we can skip max l Ch ( i ) 1 nodes (the second term in the rst line). Sib ( i ) in the right term in the sec-ond line denotes the siblings of node i . Since the number of nodes in this term is L 1 (where L is the number of leaves in T ) and l i is upper bounded by H(= max depth( T )) , the time complexity is upper bounded by O( j T j 2 ) .
 Note that the time complexity of the algorithm be-comes O( j T j ) for some trees (for example, when either L or H is bounded by a constant). Finally, we point out that the algorithms in Section 4 and this section can also be applied to the route kernel ( Aiolli et al. , 2009 ) for ordered trees. We demonstrate the performance of the linear time algorithm for the subpath kernel and the fast compu-tation algorithm in the prediction phase.
 First, we compare the execution time of the pro-posed linear-time algorithm (denoted by `Proposed') with that of the existing algorithm of Kimura et al. ( 2011 ) (`Multikey') for the subpath kernel. We also compare them with the the linear-time tree ker-nel ( Teo &amp; Vishwanathan , 2006 ) (`Vishwanathan') im-plemented by Teo and Vishwanathan 2 .
 Next, we examine the execution time of the algo-rithm in the prediction phase (denoted by `Predic-tion'). We study the e ect of the size of an input tree and the number of support vectors. We also compare the execution time with the direct compu-tation of Eq. ( 3 ) (`Direct') and the linear-time tree kernel ( Teo &amp; Vishwanathan , 2006 ) (`Vishwanathan'). We run all the experiments on an Intel Core2 Duo 2.40GHz system with 4GB of main memory under Windows Vista. For all the kernels we use in the ex-periments, we set = 1 in Eq. ( 2 ) since the choice does not a ect the computation time. 6.1. Experiment 1: Fast kernel evaluation We compare the execution times using three real data sets, including one XML data set ( Zaki &amp; Aggarwal , 2006 ) and two glycan data sets ( Hashimoto et al. , 2003 ; Doubet &amp; Albersheim , 1992 ). Table 1 lists the statistics of these datasets.
 We measured the average computation time needed for a single evaluation of each kernel function. Fig-ure 5 (a) shows the average times of `Proposed', `Mul-tikey', and `Vishwanathan' for the three datasets. The results show that our proposed linear-time algorithm is consistently the fastest, which shows that our kernel is quite ecient in practice as well as in theory. Next, we examine the scalability of the algorithms with arti cial datasets. We xed the label size at 5, and we varied the tree size. Figure 5 (b) shows the average times of the three algorithms. Again, our proposed linear-time algorithm outperforms the others. 6.2. Experiment 2: Fast prediction We compare the execution times in the prediction phase with the XML dataset. We give all support vectors a uniform weight of i = 1.
 First, we study the e ect of the number of support vectors. We merge the rst 100 XML data to make an input tree. We use the other XML data as sup-port vectors, and vary the number of support vectors. Figure 6 (a) shows the average times of `Prediction', `Direct', and `Vishwanathan'. The results show that the execution times of Prediction and Vishwanathan are not dependent on the number of support vectors, whereas that of Direct scales linearly.
 Next, we study the e ect of the size of an input tree on the 'Prediction' algorithm. We x the number of sup-port vectors at 100, and we vary the size of an input tree. Figure 6 (b) shows the average times of Predic-tion. Although the time complexity of the algorithm is theoretically quadratic with respect to the size of an input tree in the worst case, the execution time scales linearly in practice. Since Haussler ( 1999 ) introduced the framework of the convolution kernel, various kernel functions for trees have been proposed. The rst tree kernel was proposed for parse trees by Collins and Du y ( Collins &amp; Du y , 2001 ), and then, it was generalized for labeled ordered trees ( Kashima &amp; Koyanagi , 2002 ; Kuboyama et al. , 2006 ), syntactic trees ( Daume III &amp; Marcu , 2004 ), and positional trees ( Aiolli et al. , 2009 ). However, all these kernels (explicitly or implicitly) exploit edge or-der information at each node in their de nitions or algorithms, and therefore, they cannot be directly applied to unordered trees. For unordered trees, a hardness result for tree kernels using general tree-structured features was shown by Kashima ( 2007 ). Vishwanathan et al. ( 2003 ) proposed an ecient linear-time kernel based on subtrees. While this kernel can be computed eciently with the ESA for strings , it is pointed out that its predictive performance is usu-ally worse than that of the other tree kernels in the pre-vious work of Aiolli et al. ( 2009 ). Kimura et al. ( 2011 ) proposed another tree kernel for unordered trees using vertical substructures called subpaths. In this paper, we focused on the subpath kernel for un-ordered trees proposed by Kimura et al. ( 2011 ), and we proposed a linear-time algorithm for computing it with an enhanced sux array for trees. To achieve the desired time complexity, we proposed, for the rst time, a linear-time algorithm for constructing an en-hanced sux array for trees. In addition, we presented a fast algorithm for prediction, which is independent of the number of support vectors because it exploits the algorithm of ( Teo &amp; Vishwanathan , 2006 ). Exper-imental results showed that the proposed algorithm is faster than the existing algorithm, and its practi-cal running time scales linearly in practice. Moreover, the running time in prediction is independent of the number of support vectors. A possible future devel-opment is to combine the subpath kernel with a fast training framework of SVM with kernels. Recently, Severyn and Moschitti ( 2011 ) proposed a fast training algorithm for structured kernels with a cutting plane method, which might be applied for the subpath ker-nel.
 This work was supported by MEXT KAKENHI 80545583.

