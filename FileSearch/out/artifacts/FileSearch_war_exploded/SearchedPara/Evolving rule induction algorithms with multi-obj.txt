 Gisele L. Pappa  X  Alex A. Freitas Abstract Multi-objective optimization has played a major role in solving problems where two or more conflicting objectives need to be simultaneously optimized. This paper presents a Multi-Objective grammar-based genetic programming (MOGGP) system that automatically evolves complete rule induction algorithms, which in turn produce both accurate and com-pact rule models. The system was compared with a single objective GGP and three other rule induction algorithms. In total, 20 UCI data sets were used to generate and test generic rule induction algorithms, which can be now applied to any classification data set. Experiments showed that, in general, the proposed MOGGP finds rule induction algorithms with compe-titive predictive accuracies and more compact models than the algorithms it was compared with.
 Keywords Grammar-based genetic programming  X  Pareto optimization  X  Rule induction algorithms  X  Data mining  X  Classification 1 Introduction Evolutionary algorithms (EAs) have been used to solve classification (supervised learning) problems for many years, and they became particularly popular in the data mining community for producing sets of classification rules [ 15 , 18 , 59 ]. In the context of EAs for rule induction, the individuals being evolved are designed to represent a single rule or a set of rules which best classifies instances in a specific data set.

Apart from EAs, rule models can be also produced by algorithms following the sequential-covering approach [ 20 ] or they can be extracted from other representation models, like decision trees [ 46 , 47 ]orneuralnetworks[ 28 ]. Although there is a large variety of methods available to produce rule models, there is still a great interest in studying new algorithms capable of producing them. The motivation for this is twofold. First, the accuracy of rule models produced by existing rule induction algorithms can still be improved. Second, there are currently many powerful classifiers which can learn a variety of other types of classifi-cation models from data sets and very often obtain higher classification accuracies than rule models. Nevertheless, most of these very accurate classification models are black-boxes [ 52 ], lacking interpretability. Interpretability has proved to be a key feature in many domains of current interest, such as bioinformatics or medical domains [ 5 , 17 , 35 , 45 ]. In these domains, in particular, a model is not very useful if it cannot be understood, because the model is typically used to support a decision to be made by a domain expert.

This necessity of creating better rule induction algorithms has led to a human-driven  X  X vo-lution X  in their design. For instance, Ripper X  X  popular sequential-covering algorithm X  X as created by following the evolution line presented in Fig. 1 . An analysis of the algorithms illustrated in Fig. 1 shows that each of them identifies and preserves the best components of its predecessors, and at the same time adds new or modifies components that will improve its performance. If evolution is a natural phenomenon in human-designed rule induction algo-rithms, and there is still room for research in the area of design of rule induction algorithms, why not to do it automatically? That is what we proposed in [ 42 ].

More precisely, in [ 42 ] we presented a grammar-based genetic programming (GGP) method that makes use of the background knowledge about how humans design sequential-covering rule induction algorithms to automatically evolve new sequential-covering rule induction algorithms. It should be emphasized that, unlike conventional EAs that evolve a rule set for a single given data set , the GGP proposed in [ 42 ]evolvesa generic rule induction algorithm which can be applied to any classification data set. In order to generate a generic classifier, the individuals (rule induction algorithms) evolved by the GGP are evaluated using a fitness function based on their accuracy on a set of data sets named meta-training set. At the end of the evolutionary process, the individuals are then validated in a new set of data sets (unseen during the evolution) named meta-test set.

Note that it is well known in the data mining literature that no classification algorithm will present the best possible performance in all kinds of data [ 32 , 34 ]. However, in the same way as human-designed rule induction algorithms are conceived to be robust, this work also aims to create rule induction algorithms as generic and robust as possible. Later, rule induction algorithms parameters X  X uch as the number of candidate rules preserved during the search process, the amount of rule pruning, etc. X  X an be tuned to improve the performance of the algorithm in more specific types of data. The algorithms evolved by the MOGGP also present this set of parameters and, more importantly, some parameters of the MOGGP itself (e.g., its meta-training set) can be set to generate rule induction algorithms tailored to a single data set.

The system presented in [ 42 ] had one disadvantage: the rule induction algorithms gene-rated could not deal with continuous attributes. In [ 43 ] we introduced a new version of the system which solved this problem, and presented more extensive results involving a set of 20 data sets.
However, one of the main advantages of using rule induction algorithms is related to the comprehensibility of the knowledge models generated. In both [ 42 ]and[ 43 ], comprehensi-bility was not taken into account when automatically evolving the rule induction algorithms, since the fitness function was based only on the accuracy of the generated rule induction algorithms in the meta-training set. In this paper, however, we propose an extended version of the GGP, which uses the principle of multi-objective Pareto optimization to evolve rule induction algorithms that produce both high accuracy and compact rule models.

This extended GGP system was obtained by changing the fitness function, tournament selection and elitist mechanisms of the original system to consider both accuracy and the size of the models generated by the evolved rule induction algorithms, as will be explained later. The modifications introduced were inspired by a multi-objective genetic algorithm proposed in [ 44 ].

The remainder of this paper is organized as follows. Section 2 introduces the basic concepts of GGP and reviews some works which used this kind of EA to solve problems in rule induc-tion. Section 3 gives a brief introduction to sequential-covering rule induction algorithms and the problems which we aim to solve with the proposed system. Section 4 presents some related work, whist Sect. 5 gives an overview of the system proposed in [ 42 ], and describes the extensions made to produce the proposed multi-objective GGP (MOGGP). Section 6 describes experiments performed, and shows comparisons between the single and multi-objective EAs and well-known human-designed rule induction algorithms. At last, Sect. 7 draws some conclusions and proposes some future work. 2 Grammar-based genetic programming This section introduces GGP. As the name suggests, the main difference between the classical GP approach and a grammar-based one is the presence of a grammar. In GGP systems, the set of terminals and functions is replaced by a grammar. The grammar guarantees that all the individuals are syntactically correct. Note that in GGP we do not use the terms functions and terminals, but rather terminals and non-terminals, where terminals and non-terminals refer to the symbols of the grammar.

The motivation for combining grammars and GP is twofold [ 38 ]. First, it allows the user to incorporate prior knowledge about the problem domain to help guide the GP search. Second, it guarantees the closure property through the definition of grammar production rules. Grammar-based genetic programming has been used in a variety of application domains. One of its first domains of application was to develop the topology of neural networks dimension of variables when evolving physical laws [ 48 , 49 ], to perform the clustering task and decision trees [ 63 ].

GGPs (as original) or Grammar-based genetic programming algorithms can be divided into different classes according to two different criteria: (1) the representation used by the GGP individuals; (2) the type of grammar they are based on.

Considering the representation of the GGP individuals, grammar-based systems follow two different approaches, which we named solution-encoding individual and production-rule-sequence-encoding individual, and are represented in Figs. 2 and 3 , respectively. In the first approach (Fig. 2 ), there is no difference between the individuals X  genotype and phenotype. An individual is represented by a tree, which corresponds to a derivation tree produced when following the production rules of the grammar.
The second GGP approach (Fig. 3 ) differs from the first because it uses a mapping between the individual X  X  genotype and phenotype (the search and solution space). In this approach, the individuals are represented by a linear genome (usually a binary string or an array of integers), which is generated independently from the grammar. When evaluating the individuals, a genotype/phenotype mapping is made, and the genetic material is used to select appropriate production rules from the grammar.

Regarding the types of grammar used to guide the GP, the most popular are the context-free grammars (CFG) [ 1 ]. A CFG is represented by a four-tuple { N , T , P , S } ,where N is a set of non-terminals, T is a set of terminals, P is a set of production rules, and S (a member of N ) is the start symbol. The production rules have the form x ::= y ,where x  X  N and y  X  X  T  X  N } .

Regardless of the representation used by the GGP systems based on CFGs, either the individuals X  genotype or phenotype will be represented by a grammar derivation tree Fig. 4 shows a derivation tree containing the pseudo-code of an individual which represents a rule induction algorithm. This derivation tree is the product of a set of derivation steps. A derivation step is the application of a production rule p  X  P to some non-terminal n  X  N ,and it is represented by the symbol  X  . In order to exemplify, consider the two production rules: where non-terminals are wrapped into  X  &lt;&gt;  X  symbols and  X  |  X  represents a choice. A derivation step starting in the non-terminal &lt; RefineRule &gt; would be represented as &lt; RefineRule &gt;  X  &lt;
AddCond &gt;  X  X eaning that a rule is refined by adding one or more conditions to it, and could be followed by a second step &lt; AddCond &gt;  X  Add1, meaning that exactly one condition is added to the rule. These two derivation steps are illustrated in the subtree indicated by the gray rectangle in Fig. 4 .

In the same way the derivation steps just described create the subtree shown in the gray whole tree presented in Fig. 4 . The pseudo-code for the algorithm this individual represents can be extracted by reading the leaf nodes of the tree, which are always represented by a grammar X  X  terminal symbol.

Although CFGs are the most popular type of grammars used with GGP systems, after the popularization of these systems, works have been done using logic grammars [ 59 ], attribute grammars [ 7 ], tree-adjunct and tree-adjoining grammars [ 26 ] and, more recently, Christiansen grammars [ 39 ]. While context-free grammars are used to restrict the syntax of the programs generated, logic grammars, attribute grammars and tree-adjoining/tree-adjunct grammars also consider context-information while generating trees (programs), and can express more com-plex representations. Christiansen grammars, in contrast, are particularly useful to account for semantic restrictions.

In this work, we are particularly interested in GGPs following the solution-encoding individual approach using a CFG, and how these algorithms were previously used in order to solve rule induction problems, as will be detailed in Sect. 2.1 . 2.1 GGP with solution-encoding individual This section briefly reviews the main ideas of GGP systems following the approach described in Fig. 2 , named solution-encoding individual. In these systems, a GGP individual directly encodes the solution for the target problem, and does not require any mapping from the search (genotype) to the solution (phenotype) space. This type of individual representation requires a special procedure to initialize the first population of individuals, and to control crossover and mutation operations.

Figure 4 shows an example of a solution-encoding individual for the problem of evolving production rules are applied to the tree until all the leaf nodes are represented by terminals. As explained before, the solution represented by the GGP individual shown in Fig. 4 is obtained by reading the leaf nodes of the tree, from left to right. This same procedure is used to generate all the individuals in the population.
Note that, when choosing a production rule from the grammar to form the individual X  X  derivation tree, the initialization algorithm needs to check whether that particular production rule will be able to reach a terminal symbol in a number of derivation steps smaller than the maximum tree depth permitted.

Crossover and mutation operations are restricted to non-terminals, and different non-terminals might be assigned different crossover/mutation rates. In the case of crossover, a non-terminal N x is randomly selected from the tree of the first individual I 1 . After that, the system searches for the same non-terminal N x in the tree of individual I 2 .If N x is present in I 2 , the subtrees rooted at N x in individuals I 1 and I 2 are swapped (respecting the maximum individual size parameter). If N x is not present in I 2 , the operation is not performed.

Regarding the mutation operator, a random non-terminal N x is selected from the derivation tree of the individual, the subtree rooted at N x is deleted, and a new subtree is created by following the productions of the grammar (starting from N x ). The population initialization, individual representation and crossover and mutation operations just described were first introduced by [ 56 ]. 2.2 GGPs as rule induction algorithms Evolutionary algorithms, including GGPs, have been widely used as a tool to evolve a set of if X  X hen rules to a specific data set [ 18 ]. This section briefly describes just a few of these GGP systems which automatically evolve rule sets for a specific data set.

Whigham [ 57 ], for instance, described a set of grammars to solve a classification problem named  X  X reater glider density X . This set of grammars supported if X  X hen X  X lse statements and built programs, which can be read as a set of rules. In this same context, [ 60 ] combined GGP with inductive logic programming (ILP) to produce a data mining classification system called the logical grammar based genetic programming system (LOGENPRO). However, instead of a CFG, they worked with a logic grammar to create individuals. LOGENPRO can produce both decision trees and rule sets.

When evolving rule sets, LOGENPRO individuals (derivation trees extracted from a logic grammar) represent classification rules. The trees representing individuals might present some  X  X rozen X  nodes, which cannot be swapped during crossover operations. Crossover swaps subtrees rooted at two non-terminals to produce a single individual, and mutation recreates a subtree rooted at a random non-terminal according to the grammar. Reproduction is not used, but a third operator called the drop condition (which generalizes rules) was implemented. LOGENPRO also has a mechanism called token competition, which aims to maintain population diversity.

In a similar manner, [ 55 ] proposed to evolve rule sets for medical domains using steady-state GPs and CFGs. They proposed two systems: one to evolve crisp rules and another to evolve fuzzy rules. Again, the population initialization and evolutionary operators are the conventional ones in GGPs with solution-encoding individual, as proposed by Whigham. In this system, each GGP individual is a rule list for a specific class. Hence, in a system with C classes, the GGP is executed C times, in each of them trying to find a rule list which separates the i th class ( i = 1,..., C ) from the other C  X  1 classes.

Also with the purpose of evolving prediction rules (although not classification rules), [ 51 ] proposed a GGP system which uses both a single and a multi-objective approach to create a set of prediction rules to provide feedback for courseware authors. The system was compared with both sequential-covering algorithms and multi-objective algorithms when producing rules, showing promising results.
All the systems described so far were used to evolve rule sets for a specific data set. Going on step further, Wong [ 59 ] used a GGP to automatically evolve the evaluation function (or scoring function) of the FOIL algorithm (an inductive logic programming algorithm). The GGP proposed by Wong creates a population of evaluation functions by following the production rules of a logic grammar, which uses terminals like the current information gain of the rule being evaluated, the number of positive and negative examples covered by the rule being evaluated, and random numbers. The individuals (evaluation functions) generated by the GGP are then incorporated into a generic version of a top X  X own first-order logic learning algorithm based on FOIL, and the learning algorithm as a whole is evaluated.
 Out of the GGPs previously mentioned, the most related one to our GGP system is the GGP proposed by Wong [ 59 ], because it is the only one of the above mentioned systems that evolves a component of a generic rule induction algorithm, rather than just evolving a set of rules specific to the dataset being mined as usual. Wong [ 59 ] proposes to evolve a component of a learning system, i.e., the evaluation function of a first-order rule induction algorithm named FOIL.

The work proposed in this paper aims to evolve a generic and complete rule induction algorithm. Hence, while [ 51 , 55 , 57 , 59 , 60 ] trained the GGP with a single data set, this work proposes that the GGP is trained with several data sets (from different application domains) in the  X  X eta-training set X  in the same run of the GGP, in order to evolve a truly generic and robust rule induction algorithm.

Moreover, when comparing the proposed method with Wong X  X  work, whilst the search space for Wong X  X  GGP is just the space of evaluation functions for FOIL, our grammar is much more elaborate, and includes in its search space all the major components found in sequential-covering rule induction algorithms. To put it simply, our work consists of evolving a complete rule induction algorithm, whilst Wong X  X  work consists of evolving just one component (the evaluation function) of just one existing algorithm. 3 Sequential-covering rule induction algorithms This section briefly describes one of the strategies most explored and most used to induce classification rules from data: the sequential-covering (also known as separate and conquer) strategy [ 20 , 58 ]. It learns a rule from a training set, removes from it the examples covered by the rule, and recursively learns another rule which covers the remaining examples in the training set. A rule is said to cover an example e when all the conditions in the antecedent of the rule are satisfied by the example e . For instance, the rule  X  X F (salary &gt;  X 100,000) THEN rich X  covers all the examples in the training set in which the value of salary is greater than  X 100,000, regardless of the current value of the class attribute of an example. The learning process goes on until a pre-defined criterion is satisfied. This criterion usually requires that all or almost all examples in the training set are covered by a rule.

This basic algorithm used to learn rules from data is composed of four main elements: the representation of the candidate rules, the search mechanisms used to explore the space of candidate rules, the way the candidate rules are evaluated and the pruning method, although the last one can be absent [ 20 , 58 ]. These four main components, in turn, can be represented at a lower level of abstraction by a set of operations, which we call building blocks. In the last 30 years, researchers in the rule induction area experimented with the combination of various building blocks in order to create better rule induction algorithms.

Consider for example the algorithms which appear in Fig. 1 . Grove [ 40 ] was created to produce decision lists (ordered rule sets) using a top X  X own approach to search for rules (i.e., it started the search with an empty rule X  X hich covered all the examples in the training set X  and iteratively specialized it). The produced rules are evaluated using the entropy measure. More importantly, Grove introduced a new idea of building a set of rules from a data sample, and later pruning the built rule set in a different data sample. Subsequently, REP [ 4 ]was created based on this latter idea of growing and pruning a rule in different data samples but, by contrast with Grove, it uses a bottom-up search mechanism (i.e., it randomly selected an example from the training set to represent the initial rule and then iteratively generalized it), and evaluates the rules using their accuracy. Following this same line of reasoning, GROW [ 10 ] combined REP with a top X  X own search (now using information gain to evaluate rules) to produce unordered rule sets. However, the application of this new algorithm in large domains was impracticable. Hence, GROW modified REP so that it simplifies every produced rule in the training set, and then re-grows the rule set, by adding the simplified rules to a new(empty) set of rules. Following GROW, IREP [ 21 ] used the basic ideas of REP but it prunes each rule right after they are generated. As an improvement to IREP, RIPPER [ 11 ] added an optimization process to it, and changed the heuristic functions/methods used to prune the rules.

These examples illustrate the fact that many sequential-covering rule induction algorithms were designed by experimenting with the current building blocks present in successful algo-rithms and inserting some new features to them.

The idea of this work is conceptually similar. By defining a grammar with a large number of building blocks and adding to it some new features which might work in a rule induction algorithm, a GGP is able to automatically generate new sequential-covering rule induction algorithms. 4 Related work on multi-objective genetic programming The success of multi-objective evolutionary algorithms (MOEA) in solving a variety of specificity, precision and recall, etc.

However, regardless of the domain of application, MOEAs are commonly used to optimize the efficacy and the complexity of the solutions produced. In the case of genetic programming, for instance, multi-objective genetic programming (MOGP) has been successfully applied to solve one of the most well-known GP problems: bloating.

Bloating [ 2 , 53 ] is the uncontrolled growth of genetic programming code. There are many possible reasons to explain this phenomenon, being the non-homologous nature of crossover one of them [ 3 ]. Controlling bloating means saving resources which otherwise would be wasted evaluating long individuals whose additional code does not lead to better fitness, and that have a weaker generalization power than smaller individuals.

Two types of techniques are commonly applied to reduce or remove the effects of bloating in GP: the first ones change the structure of the programs or the evolutionary operators, by using techniques such as automatically defined functions (ADF) and explicitly defined introns; the second ones implicitly consider the size of the individuals, such as by defining their maximum size or inserting a penalty term to their fitness (parsimony pressure).
Nevertheless, MOGPs have also proved to be an effective technique to control bloa-ting by optimizing simultaneously the individual X  X  size and fitness. For instance, by using different types of MOGPs both Bleuler et al. [ 3 ] and De Jong et al. [ 12 ] showed that they can outperform four conventional methods used to prevent bloating. While Bleuler et al. [ 3 ] optimized programs X  size and fitness, De Jong et al. [ 12 ] also took into account the diversity of the individuals generated.

It is important to point out that, in this work, it is not the size of the individuals which is being optimized, but the size of the rule sets generated by the individuals, which are rule induction algorithms. Bloating is tackled by setting a maximum size to the individuals, based on the depth of the derivation trees which can be generated by the grammar. However, using the size of the individuals themselves as a way to prevent bloating is one of the tasks proposed for future work. 5 Grammar-based genetic programming for automatically evolving rule induction algorithms In Sect. 2 , two types of GGP were introduced, and some systems used to evolve a rule set speci-fic to a single data set were described. This section presents a multi-objective grammar-based genetic programming algorithm which evolves generic rule induction algorithms following the sequential-covering approach, introduced in Sect. 3 . This system is an extension of the GGP system proposed in [ 42 ], and is based on the solution-encoding individual approach, where the grammar is used to create the individuals in the GGP initial population, instead of taking part in a genotype/phenotype mapping process (production-rule-sequence-encoding individual approach). To the best of our knowledge, there is no significant research which indi-cates that either the solution-encoding individual approach or the production-rule-sequence-encoding individual approach is superior to the other. Hence, in the absence of significant evidence in favor of any of these two approaches with respect to their effectiveness, we chose to use the solution-encoding-individual approach. This choice was based on the fact that, as this approach lacks a genotype-phenotype mapping process, there is no need to worry about how effective the mapping is, how large is the degree of epistasis (interaction among genes) at the genotype level, or how exactly the genotype should be defined.

However, we make no claim that the solution-encoding individual approach is superior for our problem domain. Running computational experiments comparing the relative effective-ness of this approach and the production-rule-sequence-encoding approach is a topic left for further research. The next two sub-sections describe the single-objective version of the GGP introduced in [ 42 ], and the extensions added to it to deal with multi-objective optimization. 5.1 The single-objective GGP (SGGP) As explained before, in the SGGP first proposed in [ 42 ] each individual represents a new rule induction algorithm, potentially as complex as well-known algorithms, such as CN2 [ 6 ], and is represented by a derivation tree such as the one illustrated in Fig. 4 . In order to extract from the tree the pseudo-code of the corresponding rule induction algorithm, we read all the terminals (leaf-nodes) in the tree from left to right. The tree in Fig. 4 , for example, represents the pseudo-code of the  X  X rdered version X  of the CN2 algorithm (where the induced rules are used in a specific order when applied to the test set).

As the individuals are represented by derivation trees, both the crossover and mutation operators have to be adapted, so that only individuals which are valid according to the production rules of the grammar are generated, as described in Sect. 2.1 .

The grammar used to generate the first population of individuals and guide the genetic operations contains knowledge about how humans design sequential-covering rule induction algorithms, and was created after an extensive survey of the rule induction literature. It also includes knowledge that we thought would be worth testing in the context of rule induction but, to the best of our knowledge, was not used in this context before (for instance, the concept of typical instance [ 62 ] was borrowed from the instance-based learning literature in order to create a first rule to be refined by a candidate rule induction algorithm). At last, it also contains a set of traditional programming statements, such as conditional statements and while loops, which enrich the way rules are refined or pruned. The grammar is shown in Table 1 ,and is composed of 83 production rules, creating a search space of over a billion candidate rule induction algorithms [ 41 ]. For a detailed explanation of the grammar the reader is referred to [ 42 ].

This same grammar and individual representation are used in this paper, but combined with a multi-objective approach, as described in the next subsection. 5.2 The multi-objective GGP This section introduces an extended version of the single objective-GGP proposed in [ 41 ]. The main modifications were introduced in the fitness calculation process and the selection and elitism procedures, besides the mechanism which selects the best individual to be returned to the user. Before describing these modifications, we introduce the multi-objective concept followed by the algorithm.

According to the multi-objective optimization concept, when many objectives are simultaneously optimized, there is no single optimal solution. Rather, there is a set of optimal solutions, each one considering a certain trade-off among the objectives [ 8 , 9 ]. Hence, a system developed to solve this kind of problem returns a set of optimal solutions, and can be left to the user to choose the one that best solves his/her specific problem. This means that the user has the opportunity for choosing the solution that represents the best trade-off among the conflicting objectives after examining several high-quality solutions. Intuitively, this is better than forcing the user to define a single trade-off before the search is performed. This is what happens when the multi-objective problem is transformed into a single-objective one by assigning weights to each objective and combining all objectives into a single weighted formula.
 The Pareto multi-objective optimization concept is used to find the set of optimal solutions. According to this concept, a solution S 1 dominates a solution S 2 if and only if [ 13 ]:  X  Solution S 1 is not worse than solution S 2 in any of the objectives.  X  Solution S 1 is strictly better than solution S 2 in at least one of the objectives.
Using these concepts, the solutions which are not dominated by any other in an EA population are said to form the estimated Pareto front. Note that the Pareto front returned by the GGP is just an estimation of the true, unknown Pareto front. The best estimated Pareto front found by the GGP is the set of solutions returned to the user, who can then select the best one according to his/her preference. 5.2.1 The system X  X  fitness evaluation process When developing a new rule induction algorithm, there are two objectives which should be simultaneously optimized: the predictive accuracy obtained when classifying a set of test examples (unseen during training), and the size (complexity) of the model (rule set) used to classify these new examples. These objectives are often conflicting, since many very accurate models are also very complex.

In this work, the values of these two objectives are obtained through the process of com-putation of each individual X  X  fitness showed in Fig. 5 . As illustrated, during this process the GGP individuals are converted into rule induction algorithms through a GGP/Java interface. The resulting rule induction algorithm is then trained and evaluated in a set of data sets named the meta-training set. It is important to note that during the evolution of the rule induction algorithm by the GGP, for each data set in the meta-training set, each candidate rule induction algorithm (i.e., each GGP individual) is trained with 70% of the examples, and then valida-ted in the remaining 30%. For each data set, a rule model is produced from the training set, and a classification accuracy in the validation set is computed. To avoid overfitting, at each generation the train and test sets in which the algorithms are trained change.

In the first, single-objective version of our system [ 42 ], only the predictive accuracy was used to calculate a measure of fitness. However, in the new multi-objective version presented in this paper, we aim at optimizing two objectives: 2. The number of rule conditions in the produced rule model should be minimized.
According to the definition of norm_acc i , if the accuracy obtained by the classifier is better than the default accuracy, the improvement over the default accuracy is normalized, by dividing the absolute value of the improvement by the maximum possible improvement. In the case of a drop in the accuracy with respect to the default accuracy, this difference is normalized by dividing the negative value of the difference by the maximum possible drop (the value of DefAcc i ). The default accuracy is obtained when using the trivial strategy of assigning to each test example the most frequent class among the training examples. Hence, normacc i returns a value between  X  1 (when Acc i = 0) and 1 (when Acc i =1). The motivation for Eq. ( 1 ) is that the degree of difficulty of the classification task depends strongly on the value of DefAcc i (the default accuracy associated with the i -th data set). The above fitness function recognizes this and returns a positive value of norm_acc i when Acc i &gt; DefAcc i . For instance, if DefAcc i = 0 . 95, then Acc i = 0 . 90 would lead to a negative value of fit i , as it should.

Note that, in this case, we have to be able to treat one special case: individuals whose rule induction algorithms produce models consisting of only one empty rule, i.e., individuals predicting the most frequent (default) class among the training examples for all the new examples in the validation set. For these individuals, the number of conditions in the produced model will always be 0. As we are dealing with a minimization problem, 0 represents the minimum possible value, but in this case the results obtained by the candidate rule induction algorithm is not a good result, representing only a trivial  X  X ajority classifier X . To avoid this situation, the number of rule conditions of a model with 0 conditions is set to 100,000.
Observe that the MOGGP used in this work does not set a single aggregated value for the fitness of the individuals, like NSGA-2 [ 14 ] (which assigns fitness values based on ran-kings) or SPEA-2 [ 64 ] (which assigns fitness values based on the strength of the individuals X  dominators). The individuals selected for tournament are simply compared among them-selves using the two objectives to be optimized, and the tie-breaking criteria which will be introduced in the next subsection. 5.2.2 Selection scheme and elitism Apart from the fitness evaluation of the individuals, three other major modifications were introduced to the single-objective GGP. First, in the GGP selection process, the individuals have to be selected according to a relationship of Pareto dominance instead of a simple fitness value. In a tournament selection of size 2, for instance, which is the method used in this system, the winner of the tournament is the individual that dominates the other. In the case that neither of the individuals dominates the other, a tie-breaking criterion decides the winner.

This tie-breaking criterion considers the difference between the number of individuals in the entire population which are dominated by an individual and the number of individuals in the population which dominate that individual [ 44 ]. This function is named ftb. If neither Ind 1 dominates Ind 2 nor vice-versa with respect to accuracy and rule set size, the winner of the tournament is the individual with the largest value of ftb (if the ftb values for both individuals are equal, one of them is selected at random).

While the MOGGP used in this paper uses the ftb as tie-braking criteria for tournament ties, other multi-objective algorithms X  X uch as NSGA-2 and SPEA-2, give preference to solutions found in the less crowded regions of the solution space. Although our MOGGP does not implement any mechanisms which enforce the distribution of the solutions in different areas of the search space, its results in previous data mining applications [ 44 ] showed a good diversity of solutions in the Pareto front. However, a comparative study between the MOGGP presented in this paper, NSGA-2 and SPEA-2 is left for future research.

The second modification concerns the elitism scheme used by the algorithm. The single-objective version of the GGP preserves the best individual found by the GGP during the evolution process. This individual is the one returned to the user.

In the case of the multi-objective GGP, at each generation, all the solutions in the current estimated Pareto front (individuals not dominated by any other individual in the population) are passed to the next generation by elitism, as long as their number does not exceed half of the size of the population. If they do, then the individuals with the highest value of ftb are preserved. If after applying ftb the number of individuals is still higher than half of the population size, the individuals with better norm_acc [function defined in Eq. ( 1 )] are given priority. When selecting the best individual to be returned to the user, at the last generation, this same logic is applied. The returned individual is then tested in a meta-test set. 5.2.3 The evolution process Based on the grammar and individual representation just explained, the proposed GGP works as a classical GP. After the first population is created, the two objectives to be optimized are calculated, and the estimated Pareto front formed. The individuals in that Pareto front are passed through the next generation by elitism, as long as the number of individuals in the front is not greater than half of the number of individuals in the population. The two objectives are then used to selected a subset of individuals through a tournament selection of size two to breed and undergo reproduction, crossover and mutation operations. Recall that the individuals generated by the latter two operators have also to be valid according to the grammar. The number of individuals selected to undergo these operations is given by the population size minus the number of individuals selected by elitism. The individuals generated by these operations are inserted into a new population, representing a new generation of evolved individuals. The evolution process is carried out until a maximum number of generations is reached. 6 Experiments and results This section describes the experiments performed and the results obtained in order to evaluate the effectiveness of the MOGGP system to automatically evolve rule induction algorithms. 6.1 Methodology As this paper presents an extended version of a single-objective GGP (from now on referred as SGGP) introduced in [ 42 ], we first compare the proposed system with its single objective version. Next, we compare the results obtained by the MOGGP-RIs (rule induction algorithms generated by the MOGGP) with three well-known human-designed rule induction algorithms. The MOGGP system presented in Sect. 5 requires two sets of parameters: a set of standard EA parameters, such as population size and number of generations; and the meta-training and meta-test set parameters, which include the number of data sets in each of the meta-data sets and which data sets will be included in each of the meta-data sets. In order to make the comparison between the MOGGP and the SGGP fair, the two sets of parameters used in these experiments are the same for both versions of the GGP: population size of 100, evolved over 30 generations, tournament size of 2, crossover rate of 0.7, mutation rate of 0.25 and reproduction rate of 0.05.

Note that these parameter values were chosen after some initial experimentation, but cannot be considered optimal. A population composed of 200 individuals was previously tested, but the results obtained were not considered statistically better than the ones obtained with a population of 100 individuals. Considering this result and the time necessary to evaluate each individual, a population of 100 was used. Although this population size might seem small when compared to conventional GP values, we cannot forget that the GGP X  X  search space is guided by the grammar. Hence, a smaller population might obtain the same results as a bigger population with no guiding mechanism. Ratle and Sebag [ 49 ], for example, noticed that their Stochastic Grammar-based Genetic Programming (SG-GP) obtained better results when run with smaller populations and more generations than conventional GP systems.
Regarding the second set of parameters, i.e., the distribution of data sets in meta-training and meta-test sets, the 20 data sets used are presented in Tables 2 and 3 . While Table 2 shows the data sets inserted in the meta-training set, Table 3 shows the data set used in the meta-test set. All the data sets were obtained from the well-known University of California at Irvine (UCI) data set repository [ 36 ], which is often used to benchmark rule induction algorithms. In both Tables 2 and 3 , the figures in the column Examples indicate the number of examples present in the training and validation data sets X  X umbers before and after the  X /  X , respectively, followed by the number of attributes and classes. Note that both data sets in the meta-training and meta-test sets are divided into training and validation sets. In the case of the meta-training set X  X hich is used to evaluate individuals in all generations X  X he training set is used by the evolved rule induction algorithm (individual) to build a model, while the validation data set is used to test the model and generate accuracy rates. These accuracy rates are then used to calculate the individuals X  fitness. In the case of the data sets in the meta-test set, which are only used to test the best individual at the end of the evolutionary process, the numbers in the column Examples represent an estimation of the size of the training and validation sets, since a cross-validation procedure is executed. The last column shows the default accuracy. As explained before, it is the accuracy obtained when using the trivial strategy of assigning to each test example the most frequent class among the training examples.

We selected the data sets which compose the meta-training set based on the execution time of the rule induction algorithms, so that we included in the meta-training set the data sets leading to faster runs of the rule induction algorithms.

After the MOGGP returns the best evolved rule induction algorithm, that algorithm is applied to each data set in the meta-test set, using a well-known cross-validation procedure [ 58 ]. Hence, the measures of accuracy of the best evolved rule induction algorithm to be reported later refer to predictive accuracy on a test set unseen during the training of the algorithm, as usual. However, analyzing the results obtained for accuracy and number of conditions present in the rule model separately when analyzing the results of the MOGGP is not the best approach. This is because, as explained before, the main objective of using a multi-objective approach is to find the best trade-off between predictive accuracy and the simplicity of the models obtained. Therefore, taking into account both the predictive accuracy and the number of conditions in the rule model when evaluating the MOGGP-RIs is essential. The next subsections describe the results obtained by the MOGGP-RIs and show two of the algorithms evolved. 6.2 MOGGP-RIs performance As explained before, analyzing the results obtained for accuracy and number of conditions present in the rule model separately when analyzing the results of the MOGGP is not the best approach. Table 4 makes an analysis using both these objectives simultaneously, and uses a special terminology. When evaluating the MOGGP-RIs regarding accuracy and number of conditions in the rule model (two objectives), we based our analysis of results on the Pareto dominance concept X  X dapted to consider statistically significant differences. This adapted Pareto dominance concept states that a solution S 1 dominates a solution S 2 if two conditions are satisfied. First, if every objective value of S 1 is not statistically significantly worse than the corresponding objective value in S 2 . Secondly, if at least one of the objective values of S is statistically significantly better than the corresponding objective value of S 2 (statistical significance is determined by the results of a Student X  X  t test with significance level 0.05).
Hence, Table 4 presents the number of classification models produced by the MOGGP-RIs which neither dominate nor are dominated by the classification models produced by the SGGP-RIs or the baseline algorithms ( Neutral column), the number of models produced by the SGGP-RIs or the baseline algorithms which the MOGGP-RIs dominate ( Dominate column), and finally the number of models produced by the MOGGP-RIs which are domina-ted by a model produced by the SGGP-RIs or a baseline algorithm ( Dominated column). This table was built by applying the statistical significance-adapted Pareto dominance concept to the results presented in Tables 5 and 6 .

It is important to emphasize that the results in Tables 5 and 6 are reported here only for the sake of completeness, as the objective of this paper is to generate rule induction algorithms where both accuracy and rule model comprehensibility are equally important. This approach is suitable particularly for applications where, in practice, the classification model will not be directly used to predict the class of individual data instances, but will rather be interpreted by a user expert in the application domain and the data, in order to try to provide the user with new insights about the domain or the data. There are several applications where classification models are induced mainly to be interpreted by users, such as biomedical applications and bioinformatics [ 5 , 17 , 35 , 45 ]. In such applications, discovering comprehensible knowledge is desirable for several reasons [ 54 ], such as increasing the confidence of the user in the system X  X  results, leading to new insights about the data and the formulation of new hypothesis, and detecting errors in the data. For instance, several new insights about the application domain provided by a comprehensible classification model are discussed in [ 29 ], in the context of protein function prediction. As another example of the usefulness of comprehensible models, even if the predictive accuracy is not very good, [ 60 ] discovered classification rules with a relatively low or moderate degree of accuracy (around 40 X 60%) that were considered, by senior medical doctors, novel and more accurate than the knowledge of some junior doctors.
Ta b l e s 5 and 6 present the predictive accuracies and the number of conditions per rule model obtained by the MOGGP-RIs, respectively. In both tables, the results obtained by the MOGGP-RIs (second column) are followed by the results obtained by the rule induction algorithms produced by the single-objective GGP (SGGP-RIs) and three baseline well-known rule induction algorithms, namely ordered-CN2, unordered-CN2 and C4.5Rules. Observe that the C4.5Rules algorithm is out of the search space of the MOGGP, as it does not follow the sequential-covering approach. Instead, it first generates a decision tree and later extracts rules from it [ 47 ]. However, as C4.5Rules is a baseline of comparison for many studies involving rule induction algorithms, it is also considered here.

As pointed out before, all the results were obtained using a fivefold cross-validation procedure, and the numbers after the symbol  X   X   X  are standard deviations. Results were compared using a two-tailed statistical Student X  X  t test with significance level 0.05, performed over five independent runs of the GGP for each data fold. Cells with figures in boldface represent statistically significant wins of the MOGGP-RIs against the other algorithms,while cells with figures in italics represent MOGGP-RIs X  statistically significant losses. Note that, although the MOGGP finds a set of non-dominated solutions, in practice we want to select a single solution (rule induction algorithm) to compare it with the baseline algorithms. Instead of manually choosing a single rule induction algorithm among the non-dominated ones, to keep the experiments as automated and unbiased as possible we have also automated that selection. That is, the MOGGP returns the non-dominated rule induction algorithm (in the last generation) having the largest value of the ftb function. The selected rule induction algorithm is then called MOGGP-RI.

To illustrate the logic behind the results presented at Table 4 , let us consider the cases of ionosphere and mushroom with OrdCN2. In both cases the accuracies of the MOGGP-RIs and OrdCN2 are competitive X  X .e, the difference in these two accuracies is not statistically signi-ficant. However, in ionosphere the model generated by the MOGGP-RIs has a significantly smaller number of rule conditions than the model generated by the OrdCN2, and so we say that the MOGGP-RIs dominates OrdCN2. A different situation occurs for mushroom ,where the size of the models generated by both the MOGGP-RIs and CN2Ord are also competitive, and so we say that the MOGGP-RIs and CN2Ord have a neutral relationship. Finally, the MOGGP-RIs are said to be dominated by another algorithm if they are significantly worse in one objective (accuracy or model size) and not significantly better in another. In other words, if the MOGGP-RIs obtain a significantly smaller accuracy (or larger rule set) than the algorithm in question and at the same time does not discover a significantly smaller rule set (larger accuracy), then it is said to be dominated by the respective algorithm.

An analysis of statistical significance-based Pareto dominance taking into account both the accuracy and the size of the models produced shows that in four out of ten cases the MOGGP-RIs and the SGGP-RIs present a neutral relationship, while in the other six cases the MOGGP-RIs X  models dominate the SGGP-RIs X  models. In contrast, when comparing the MOGGP-RIs with the baseline algorithms, in 23 out of 30 cases (3 algorithms  X  10 data sets) the MOGGP-RIs X  models dominate the baseline algorithms X  models, and the former are never dominated by the latter.

As stated before, the objective of this paper is to generate rule induction algorithms which are both accurate and generate comprehensible rule models. Hence, Appendix 1 shows the rule lists obtained by both the MOGGP, the SGGP and the C4.5 algorithms for the data set crx (Tables 7 , 8 , 9 ). The major problem in many data mining studies is that there is no specialist who can evaluate the interpretability and interestingness of the rules. That is the main reason most studies consider simplicity, measured in terms of rule set size, as a proxy for interpretability X  X lthough we understand this is not a perfect metric. However, just looking at the rules listed in Appendix 1 we realize that the rule lists generated by the MOGGP are simpler than the ones obtained by both the SGGP and the C4.5 algorithms. Importantly, the significant reduction in rule set size obtained by the MOGGP was achieved without any significant reduction in classification accuracy, by comparison with the rule set sizes and classification accuracies obtained by SGGP and C4.5 in this data set.

Figure 6 shows a graph representing the objective values for the last population of indi-viduals evolved by a run of the MOGGP. The x -axis shows the average number of rule conditions in the models built from data sets of the meta-training set, and the y -axis shows the value of norm_acc as defined in Eq. ( 1 ). Each point in the graph represents an indivi-dual (a rule induction algorithm). The greater the accuracy (and consequently the value of norm_acc) and the smaller the number of rule conditions, the better. The graph also shows the estimated Pareto front found by the MOGGP, which is formed by the set of individuals which are not dominated by any other individual in the population of the last generation. The circle indicates the individual in the Pareto front which was returned as the best single solution for the problem. The rule induction algorithm represented by this individual was the one evaluated in the meta-test set (unseen during the evolution of the MOGGP).

All the experiments were performed on pentium 4 duo processor machines with 1GB RAM and running Linux. Each run of the GGP (including the execution of the evolved algorithms of operations the rule induction algorithms (individuals) could perform. A few of these operation, such as inserting two conditions at a time to new candidate rules, had non-linear time-complexities.

In summary, when comparing the MOGGP-RIs with the SGGP-RIs, in more than half of the cases the MOGGP-RIs are able to obtain statistically similar accuracies as the ones obtained by the SGGP-RIs but using much simpler rule models. The same is true when com-paring the MOGGP-RIs with the three human-designed rule induction algorithms. However, it is also important to mention that, if we had chosen to perform an analysis which would give more weight to accuracy than to model simplicity, in two out of ten cases the SGGP would produce better accuracies than the MOGGP. At the same time, in 4 out of 30 cases the other three rule induction algorithms would produce better accuracies than the MOGGP. The MOGGP, on contrast, would be better than Unordered-CN2 in two cases, and better than C4.5Rules in one case.

Although in terms of accuracy the SGGP and the other three rule induction algorithms would be better than the MOGGP in two and four cases, respectively, the models produced by the MOGGP in 34 out of 40 cases are significantly simpler when compared with the SGGP and the human-designed rule induction algorithms. However, if accuracy is to be considered as a more important objective, a different type of MOGGP, such as the ones following a lexicographic approach [ 19 ], should be used.

After presenting the results in terms of accuracy and rule model size, one question is left to answer: how different are the evolved MOGGP-RIs from the evolved SGGP-RIs and the baseline human-designed algorithms? This is the subject of the next subsection. Algorithm 1 Example of a MOGGP-RI (Rule Induction Algorithm evolved by the Multi-objective GGP) 6.3 An insight about the MOGGP-RIs The most interesting fact to notice about the MOGGP-RIs is the impact that the inclusion of a measure of rule model size in the fitness function had in their design.

For instance, the five rule induction algorithms produced by the MOGGP (in five runs with different random seeds) use both a pre-and a post-pruning method. In contrast, none of the algorithms produced by the single-objective GGP used post-pruning, and only one out of the five algorithms pre-pruned rules by changing the final produced rule. Of course other forms of pre-pruning were used by these algorithms, such as considering as candidate rules only statistically significant rules, or rules with an accuracy greater than a predefined threshold.

Algorithm 1 shows an example of a MOGGP-RI. The first feature to notice in this algorithm is that it works with three different sets of data. It first divides the training set into build and post-prune sets, and subsequently divides the build set into grow and pre-prune sets. We recognize that this data division might be problematic if few examples are available from the training set. However, this algorithm obtained accuracies statistically competitive with the ones obtained by the well-known human-designed algorithms, together with much simpler rule models. Algorithm 2 Example of a SGGP-RI (Rule Induction Algorithm evolved by the Single-objective GGP)
Algorithm 1 works in three phases. First, it greedily builds rules and evaluates them using the Laplace estimation criterion in the grow set. It also tests the statistical significance of the rules before considering them as possible candidate rules, and only selects the best candidate rule to undergo further refinements. Once the best rule is found, it is pre-pruned. In this second phase, the algorithm pre-prunes a rule by removing only the last condition added to it. The new generated rules are again evaluated using the Laplace estimation criterion in the pre-prune set.
 Rules are produced until the number of examples in the grow set is reduced to 20 or less. Once the rule list is complete, the third phase starts. The rule list is post-pruned by trying to remove, from the last to the first inserted rule, one rule at-a-time. Rules are removed from the rule list while the accuracy of the system in the post-prune data set is not reduced.
The dynamics of Algorithm 1 can be compared to Ripper X  X  [ 11 ]. Both algorithms produce, prune and  X  X ptimize X  the entire rule list, with the following differences. Ripper works with rules ordered per class, produces only rules which do not cover any negative examples and uses the minimum description length (MDL) criterion when optimizing the set of discovered rules. Algorithm 1 produces rule lists, evaluates rules using the Laplace estimation and  X  X ptimizes X  rules by removing one condition-at-a-time from them. We do not know any algorithm in the literature which works in this way, so Algorithm 1 is X  X o the best of our knowledge X  X onsidered a novel rule induction algorithm.

Algorithm 2 shows an SGGP-RI produced by the SGGP when using the same random seed used by the MOGGP which produced Algorithm 1 . As observed, Algorithm 2 is much simpler than Algorithm 1 . It does not use any advanced pruning technique, and simply stops producing rules when their predictive accuracy is lower than 70%. Note that Algorithm 2 is also an innovative algorithm, since there is no rule induction algorithm in the literature which refines a rule according to the number of conditions already present on it.

The comparison between Algorithms 1 and 2 shows how the addition of a measure of rule set complexity to the fitness of the GGP changed the evolved MOGGP-RIs in order to find a good balance of the accuracy/complexity trade-off. These results also show that the MOGGP is flexible enough to produce very different kinds of algorithms. 7 Conclusion and future work This work presented a multi-objective version of a GGP system which automatically evolves generic rule induction algorithms X  X ather than just rule sets to a specific application domain. Comparisons between the single-objective version (SGGP) and the proposed multi-objective version of the system (MOGGP) showed that the MOGGP produces rule induction algo-rithms with competitive accuracies and much more compact models. Considering application domains where model size (as an approximation to interpretability) is as important as predic-tive accuracy, these are positive results. When comparing the MOGGP with three well-known human-designed conventional (non-evolutionary) rule induction algorithms, similar conclu-sions were drawn, as in general the solutions produced by the MOGGP had competitive accuracies and significantly smaller models than the ones produced by Unordered-CN2, Ordered-CN2 and C45Rules.

As future steps in this research, other objectives could be optimized by the MOGGP, such as the complexity of the generated algorithm, and/or the time necessary to evaluate a data set with the evolved algorithms.

Moreover, as many works in the literature [ 23 ], this paper considers the accuracy of a model to be as important as the size of the generated rule models. However, in cases where the user chooses to give more weight to optimizing accuracy than the simplicity of the model, a lexicographic approach could be more appropriate [ 19 ].

It would be interesting to implement a version of the system using a GGP following the production-rule-sequence-encoding individual, and compare its results with the ones obtained in this study. Finally, the current version of the grammar could be extended, so that the MOGGP will be able to build even more innovative rule induction algorithms.
 Appendix 1 In this Appendix, we show the rule lists produced by the MOGGP, the C4.5 and the SGGP algorithm for the data set crx . The rule lists produced by the Ordered-CN2 and the Unordered-CN2 algorithms are not reported due to space limitations, as they are always much longer than the ones produced by the MOGGP, with 99 and 102 conditions, respecti-vely. Although the C4.5 algorithm is not in the search space of the MOGGP, we use it as a baseline to show that the rules generated by the MOGGP are actually more compact and sim-pler than the ones produced by the other algorithms, as the numbers reported in Table 6 show. Observe that this more compact rule list is obtained by the MOGGP-RIs while preserving the values of predictive accuracy, as showed in Table 5 .
The crx data set has information about credit card applications, described by 15 attri-would be difficult to be interpreted, as the data was coded to preserve confidentiality. Tables 7 , 8 and 9 show the rule lists for the data set crx . As we can observe, the rules in Table 7 look considerably simpler than the other two, as they are even visually much smaller. While the MOGGP produces a rule list with 9 rule conditions in total (considering all rules), the C4.5 and the SGGP produce 32 and 97 rule conditions, respectively. Short rules have the advantages of requiring short time for the actually testing/prediction process. Note that the C4.5 generates a rule list for each class, while the rule lists created by both versions of the GGP generate a single rule list.
 References Author Biographies
