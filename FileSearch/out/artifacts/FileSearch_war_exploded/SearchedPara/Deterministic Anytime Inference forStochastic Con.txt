 E. Busra Celikkaya CELIKKAE @ CS . UCR . EDU University of California, Riverside Christian R. Shelton CSHELTON @ CS . UCR . EDU University of California, Riverside Continuous-time discrete-state stochastic models describe systems in which event times are not synchronized with a global clock. Examples include web searches (Gunawar-dana et al., 2012), computer networks (Xu &amp; Shelton, 2010), social networks (Fan &amp; Shelton, 2009), robotics (Ng et al., 2005), system verification (Baier et al., 2003), and phylogenetic trees (Cohn et al., 2009), among others. Discretizing time can be computationally expensive. The  X  X ime-slice X  width must be much smaller than the short-est time between events. This can lead to inefficient com-putations during times in which events or expected events are less frequent. Much as the abstraction of real-valued numbers (and their implementation in floating-point rather than fixed-point representations) is helpful in the develop-ment of numeric algorithms, continuous-time is useful for stochastic dynamics systems.
 This paper focuses on Markovian models. In a discrete-time Markov process, given a row-stochastic matrix M and a distribution v (as a row-vector), the computation of v n = vM n propagates v forward n time steps. In a continuous-time Markov process (CTMP), given a rate (in-tensity) matrix Q , v t = ve Qt propagates v forward t time units in the same fashion. This is the critical computation step in filtering, smoothing, and parameter estimation. We focus on how to compute this matrix exponential when the size of v is very large and both v and Q have structure (al-lowing their efficient representation).
 Except for the most trivial of cases, v t has no internal struc-ture. In particular, assume that the state space is factored, that is composed of joint assignments to state variables. Even if v is completely independent, v t no longer has any structure (unless Q also represents a completely indepen-dent system). This is the same problem that arises in dy-namic Bayesian networks (DBNs) in which forward propa-gation causes all variables in the system to be coupled. We assume that a full distribution over the state space is too large to be stored, and therefore seek an approximation. 1.1. Previous work This problem has received attention in the verification lit-erature for decision-diagram-based representations of the intensity matrix Q . However, the assumption behind this literature is that while Q may have structure to keep it rep-resentable, an exact answer is desired and therefore v t represented as a full vector. The shuffle algorithm is one such example (Fernandes et al., 1998).
 By contrast, we assume that representing v t explicitly is not possible. We would like to calculate expectations with respect to the distribution v t . In our approach, we con-centrate on continuous-time Bayesian networks (Nodelman et al., 2002) (CTBNs), but the method is general to any Q that is the sum of Kronecker products. Even the simplest expectations (like marginals) are NP-hard to compute (the proof is a straightforward extension of the proof for general Bayesian networks), so we focus on approximations. In the literature on CTBNs, there are a number of such methods that fall roughly into two groups. The first are variational approaches such as expectation propagation (El-Hay et al., 2010) and mean field (Cohn et al., 2009). These methods are deterministic. However, they do not converge to the true value as computation time increases and generally can only compute marginals or similar expectations. The sec-ond group are sampling approaches including importance sampling (Fan et al., 2010) and Gibbs sampling (Rao &amp; Teh, 2011). These approaches converge to the true value and can estimate any expectation of v t . However, they are random and this can cause problems when used inside other algorithms (like expectation-maximization). 1.2. Our approach Our proposed method is deterministic and converges in the limit of infinite computational time. It can be viewed as a bridge between sampling and deterministic methods. We decompose the system into two pieces: a system ( A ) of completely independent components, and a correction ( B ). We reason exactly about the system A and add increasing number of correction terms derived from B . We generate a computation tree and traverse it using a priority queue, to select the larger correction terms earlier.
 We first present our approach assuming that Q and proba-bility vectors can be stored exactly. Then, we demonstrate how the calculations can be carried out efficiently when Q is structured. In section 2.4, we present a simple example to ground the derivation. Finally we demonstrate results comparing the computational efficiency of our method to other anytime convergent methods. Consider a CTMP with discrete states which is described by an initial state distribution row-vector v of size n and a rate matrix Q of size n -by-n . The rate matrix represents the rates by which the system transitions between states. The rate of transitioning from state i to j is q ij  X  0 and the rate of transitioning out of state i is q i = P j q ij diagonal elements of the rate matrix are the negative row sums: q ii =  X  q i .
 As stated above, the distribution at time t , for t  X  0 , is calculated by v t = ve Qt where e Qt is the matrix expo-nential with Taylor expansion e Qt = P  X  k =0 1 k ! ( Qt ) matrix exponential calculation is very widely used in ap-plied mathematics and there are many numerical methods to solve it (Moler &amp; Loan, 2003).
 If the state-space is structured as joint assignments to m variables, its size, n , grows exponentially with the number of variables, m . This makes the e Qt calculation intractable for large systems. Using the structure of Q for this calcula-tion is not straightforward because it is not preserved by the matrix exponential. Additionally, the commutative prop-erty does not hold for matrix exponential in general: For any same-sized matrices A and B , e ( A + B ) t 6 = e At e e
Bt e At , unless the commutator [ A,B ] = AB  X  BA van-ishes. One possible decomposition comes from the Kro-necker sum property: e ( A  X  B ) = e A  X  e B . Yet, Kronecker sums alone can only describe rate matrices for systems in which all variables are independent.
 For the general case, e ( A + B ) t can be seen as a perturbation of e At in the direction of Bt (Najfeld &amp; Havel, 1995) and can be represented as e which is a sum of recursive functions. This series, was first explored in quantum field theory (Dyson, 1949) and is called a series of time-ordered products (TOP), or some-times a path-ordered exponential. In stochastic processes, Mjolsness &amp; Yosiphon (2006) called it a time-ordered product expansion and used it to guide a sampling algo-rithm. We will employ the expansion to derive our deter-ministic method, Tree of Time-Ordered Products (TTOP). 2.1. TOP computation tree We make two assumptions: Q can be split into Q = A + B , where ve At is relatively simple to compute, and B is bro-ken into J manageable terms B = P J j =1 B j . We will show how to realize these assumptions in the following sections. We use the TOP expansion of Equation 1 and apply the dis-tributive property of matrix multiplication to move the sum outside the integral: ve + Let F l ( t ) represent the l th term of the expansion. Then the equation can be rewritten as where By construction, the first term, ve At , is simple to solve (as will be explained in Section 2.2). We calculate each integral with the following expansion in which we treat a polynomial portion exactly and use adaptive quadrature to estimate the non-polynomial por-tion. Let g ( t ) be a general function of time, g 0 be a con-stant, and q ( t ) be a piece-wise polynomial. Further denote  X  q ( t ) = R t 0 q ( s ) ds and q [ r (both also piece-wise polynomials), where I [  X  ] is the indi-cator function. Then we can write an integral of the form h ( t ; q,g,g 0 ) = R t 0 q ( s )( g ( s )  X  g 0 ) ds as h ( t ; q,g,g 0 ) =  X  q ( t )( g ( s 0 )  X  g 0 ) =  X  q ( t )( g ( s 0 )  X  g 0 ) for any chosen g 0 , approximating g as the constant g ( s and adding 2 correction terms (of the same form) for sub-parts of the interval. Here, [ a,b ] is the support range of q , and s 0 = a + b 2 . For convenience, we divide this range into following sections as well, but generalization to more than two sub-intervals is straightforward.
 Recursive expansion Equation 5 will generate infinitely many terms in the form of  X  q ( t )( g ( s 0 )  X  g 0 ) : where q k ( t ) is  X  q ( t ) for a particular q , and u k for a particular g and g 0 . Assume level l of Equation 3 can be expressed as s 0 = ( a + b ) / 2 [ a,b ] = q  X  X  support (as is certainly true for l = 0 : q 0 0 ( t ) = 1 , u 0 0 show how to construct level l + 1 similarly: In last two lines, we have replaced the integral with the expansion of Equation 6. In particular, the inte-gration of interest is h ( t ; q l k 0 ,u l k 0 e At B the set { q k ,u k } k generated for this h be denoted as n q In Equation 8, k 0 represents a node at level l in the compu-tation tree. So, for every k 0 , we generate J nodes in level l + 1 , each of which are the roots of trees for expansion of corresponding integrals. The result is an expansion for F l +1 of the same form as Equation 7.
 We denote a term in this expansion as a compute node N ( q,u,u 0 ,j ) . It and its descendants in the same level l + 1 represent new terms in F l +1 . Node N ( q,u,u contributes the term to the total sum. Its two children on the same level are N Algorithm 1 TTOP Filter
Initialize priority queue PQ with N (1 ,v, 0 , 0) while PQ not empty and compute time left do On the next level, it generates a node N (  X  q,w  X  u 0 , 0 ,j for all 1  X  j 0  X  J . Figure 1 shows this expansion. For reasons that will be clear in the next section, we can-not form w  X  u 0 (even though we can form each individu-ally). Thus, node N (  X  q,w  X  u 0 , 0 ,j 0 ) could be described by two nodes: N (  X  q,w, 0 ,j 0 ) and N (  X  q,  X  u 0 , 0 ,j 0 the second node will essentially  X  X ndo X  calculations done elsewhere. We address this in the next section.
 These recursively generated nodes represent an infinite tree whose sum is ve Qt . Nodes have a single value, plus  X  X ame-level X  children who represent finer approximations of the integral, and  X  X ext-level X  children who represent one com-ponent of F l for the next level l . The sum of all nodes at level l describes a system that evolves according to A (instead of Q ), but for which at l time points (positioned anywhere), the correction B = Q  X  A is applied. If A = 0 , then each level is one term in the Taylor expansion of Q . The traditional 1 i ! coefficients in such an expansion are cap-tured by our piece-wise polynomial integrations.
 If we explore the tree such that every node will be visited in the limit of infinite computational time, then we can add each node X  X  evaluation at time t to a running sum and com-pute ve Qt . Algorithm 1 outlines this method using a pri-ority queue to concentrate computation on portions of the tree with large contributions. 2.2. Structured TOP calculations For the scenarios of interest, the vector v and matrix Q are too large to explicitly represent because the state space con-sists of one state for every assignment to a set of m vari-ables, X 1 through X m . We will assume that v is an inde-pendent distribution (although we can extend this work to dependencies in v , but this eases the exposition). In Kro-necker algebra this means v = N m i =1 v i , where each v small row-vector of the marginal distribution over X i . We now show how to keep each quantity in the computa-tion tree representable exactly as a similarly factored dis-tribution: a Kronecker product with one term for each vari-able. If A = L m i =1 A i , then e At = N m i =1 e A i t . We assume that each A i (which is only over the state space of X i ) is small enough so that calculation of e A i t can be performed efficiently. If we also require that each B j = N m i =1 then all vectors and matrices to be multiplied in the com-putation tree are such Kronecker products. In particular, at node N ( q,u,u 0 ,j ) , we need to compute w (Equation 9) for its contribution to the sum. Because u , B j , and e As 0 are all Kronecker products and ( A  X  B )( C  X  D ) = ( AC )  X  ( BD ) , all of the matrix products can be performed efficiently by just operating on the subspaces over each variable indepen-dently. Thus w (and by extension the node X  X  contribution to the sum) is a completely factored vector represented as a Kronecker product (that is, a distribution in which all vari-ables are independent).
 The generation of new nodes does not require any other operations, except for manipulation of one-dimensional piece-wise polynomials. Thus, our answer is a weighted sum of independent distributions (Kronecker products). It is not representable as a Kronecker product because it is a full distribution. However, any expectation of this distribu-tion can be computed by summing up the contribution of each of these independent terms.
 As we mentioned earlier, N (  X  q,w  X  u 0 , 0 ,j 0 ) has the expres-sion w  X  u 0 which is not a Kronecker product (despite that both w and u 0 are). To handle this, we note that where Because of how we select B j (see below), x i 0  X  y i 0 is only non-zero for a few i 0 (the family of variable j ). Further-more, this allows us to split up the nodes by how much the deviation ( w  X  u 0 ) contributes by variable, which concen-trates computation on those variables whose approxima-tions are most difficult. Thus, we use this decomposition and divide the node N (  X  q,w  X  u 0 , 0 ,j 0 ) (see Figure 1) into nodes N (  X  q,d i 0 ( w,u 0 ) , 0 ,j 0 ) for all i 0 for which w is always possible, although it might result in one B j for each element of Q (which would in general be exponen-tial in the number of state variables). Binary decision diagrams are often used to encode Q . In stochastic logic applications a disjunctive partitioning leads very naturally to this structure (Burch et al., 1991; Ciardo &amp; Yu, 2005). However, they are encoded in a form where A = 0 . Tech-niques similar to those we describe next can be applied to pull intensity from the B j matrices into A , but we will fo-cus on a different representation. 2.3. Continuous time Bayesian networks A continuous time Bayesian network (CTBN) (Nodelman et al., 2002) is a graphical model which provides a struc-tured representation of a CTMP. The initial distribution is described by a Bayesian network which we assume has no edges (but this work can be extended to dependencies in the initial distribution). The transition model is specified as a directed and possibly cyclic graph, in which the nodes in the model represent variables of the Markov process, and the dynamics of each node depend on the state of its par-ents in the graph. Each node X i , for i = 1 ,...,m , has a set of parents U i . The rate matrix Q is factored into condi-tional rate matrices, Q i | u Each conditional intensity matrix gives the rates at which variable X i transitions at instants when U i = u i . No two variables can transition at exactly the same instant so any element in the global Q matrix describing a change of mul-tiple variables is 0 .
 The global Q matrix for a CTBN can be represented with Kronecker algebra. Let R i | u necker product of one matrix for each variable where R where  X  k,k is a matrix of all zeros except a single one at location k,k . In this way, R i | u to the proper locations in Q . The full Q for the CTBN is therefore This corresponds to our TOP representation of Q where A is 0 and there is one B j for each variable and instantiation of its parents. We can pull intensity into the A matrix by defining B Then The algebra is long, but straight-forward. It holds because A i is constant with respect to u i and the sum over u i rep-resents each possible instantiation exactly once. The result is that A i represents an independent, approximate process for X i . A is the joint process of each of these independent approximations. The differences between the independent process and the CTBN are given by one B i | u able and its parents X  instantiation. Note that  X  ( i | u if i 0 is not a parent of i . Thus, most of the components of any B j are the identity and computing ue As Be  X  As for these components is trivial (they are the same as u ). Thus, the calculations for N ( q,u,u 0 ,j ) are local to the variable j and its parents.
 2.4. CTBN example Figure 2 shows a simple 2-variable CTBN and one possible decomposition into A and B . Here the local A i matrices are chosen to be the minimal rates. Because X 1 has no parents, A 1 is exact and there are no B terms. X 2 generates 2 B terms. If we let v = v 1  X  v 2 (that is, v 1 and v 2 are the independent marginals of X 1 and X 2 ), then Figure 3 shows a small portion of the computation tree.
 This method essentially computes the effect of A exactly and incorporates the effects of B as a Taylor expansion, adding increasing numbers of terms. Note that in Figure 2, A 1 and A 2 are proper intensity matrices (their rows sum to 0 ). This means that B 2 | 0 and B 2 | 1 have negative diag-onal elements. This results in a computation that corre-sponds to a Taylor expansion with alternating signs. This can cause computational problems. One alternative is to arrange for B to have no negative elements. For instance A B to less than 1 . The non-root nodes add probability to the answer (instead of moving it within the answer).
 Finally, for a CTBN, multiplication by a B j is particularly simple. The j value indexes a variable ( X i ) and an instan-tiation to its parents ( u i ). To multiply a factored vector by B , multiply the X i component by Q i | u component associated with a parent, zero out all elements of the vector except for the one consistent with u i . Vectors for non-parent nodes are unchanged. 2.5. Smoothing and computational considerations The discussion so far has focused on filtering. We would also like to perform smoothing. We will limit ourselves to the case in which the initial distribution at time 0 , v , is known and there is evidence at a later time T for which the vector v T represents the probability of the evidence for each possible state of the system. We assume that both vectors factor as previously discussed.
 The goal is to compute (an expectation of) the distribu-tion at time t conditioned on the evidence at time T . This consists of computing the Hadamard (point-wise) product sult). First, consider computing each exponential sepa-rately. Let the result of the  X  X orward X  direction be P j where the forward calculation X  X  j th node had contribution  X  j = N represented as P k  X  k with  X  k = N m i =1  X  k,i . It can easily be shown that
X Thus, we must consider every pair of nodes, one from the forward expansion and one from the backward expansion. For each pair, the components of the factored representa-tion are point-wise multiplied together to obtain the pair X  X  contribution to the answer.
 We want to include these terms judiciously to best use a finite computational budget. We do this by keeping a fron-tier set of pairs of computation nodes, one from the forward tree and one from the backward tree. If we have explored (added to the smoothing result)  X  j  X  k , we add to our fron-tier set  X  j paired with all of  X  k  X  X  children and  X  j  X  X  children paired with  X  k . We use a closed list to ensure no pair is considered twice.
 The question then is how to prioritize members of the fron-tier. We need to have an estimate of the total contribution of this pair and all subsequent pairs in the graph. We select the sum of this node X  X  contribution to the query value (absolu-tion value of the change) and the product of the maximum value in each node. We implemented our method, TTOP (Tree of Time-Ordered Products), as part of the CTBN-RLE code base (Shelton et al., 2010), and it will be included in the next version. We evaluated our method on a synthetic network of Ising model dynamics. The Ising model is a well-known interaction model with applications in many fields includ-ing statistical mechanics, genetics, and neuroscience (Zhou &amp; Schmidler, 2009). The experimental results focus on in-ference accuracy given a known network. The Ising model was chosen so that we could compute the true answer in a reasonable time and scale the problem size.
 Using this model, we generated a directed toroid net-work structure with cycles following (El-Hay et al., 2010). Nodes follow their parents X  states according to a coupling strength parameter (  X  ). A rate parameter (  X  ) determines how fast nodes toggle between states. We scale the num-ber of nodes in the network but limit it to 21 to be able to compare the results to exact inference. We use three net-works of respectively m = 9 , 15 , and 21 binary variables. We could not include networks with more than 21 binary variables because we cannot do exact exponentiation on a matrix of size bigger than 2 21  X  2 21 in a reasonable time. We scale the network by adding rows of nodes. For these networks we fix the  X  parameter and vary  X  . Nodes can take on values  X  1 and +1 .
 We compare TTOP to two efficient anytime algorithms: auxiliary Gibbs sampling (AuxGibbs) (Rao &amp; Teh, 2011) and importance sampling (IS) (Fan et al., 2010). We also compared to a mean field variational approach (MF) (Cohn et al., 2009); however, error for MF is above the error range of other methods for all computation times. For this reason, we omit the MF results in the plots. We analyze the error in marginals computed by each method relative to exact in-ference. We focus on the computation time because in our experiments memory was not an issue and whole computa-tion tree occupied only a few GBs.
 For TTOP, we set the number of splits for the quadrature (see Equation 5) to 10 because it produces a good compu-tation time versus error performance. We vary the compu-tation time budget to observe the trade-off between compu-tation time and the error.
 For AuxGibbs, we vary the sample size between 50 and 5000 , and set the burn-in period to be 10% of this value. For IS, the sample size varies between 500 to 50000 . We ran the experiments 100 times for each test for both sam-pling methods. The computation time shown in the plots is the average of these runs for a given number of sam-ples. The error is the sum of the KL-divergences of all the marginals from their true values.
 Our experiments focus on smoothing. The networks start from a deterministic state, for m = 9 : at t = 0 variables 1  X  5 are +1 and 6  X  9 are  X  1 . At t = 1 , variables 1  X  3 have switched to  X  1 , 4  X  5 remain +1 , and 6  X  9 have switched to +1 . For m = 15 and 21 we use a similar pattern of evi-dence for comparison reasons. For m = 15 , the variables 1  X  5 , 7  X  8 , 10  X  11 start at +1 and the remaining variables start at  X  1 . The variables 1  X  3 switch to  X  1 , while 4  X  5 , 7  X  8 , and 10  X  11 stay at +1 , and 6 , 9 and 12  X  15 switch to +1 . The evidence for m = 21 also follows the same pattern scaled to 21 nodes.
 The nodes are not observed between t = 0 and t = 1 . We query the marginal distributions of nodes at t = 0 . 5 . Figures 4 and 5 show computation time versus sum of KL-divergence of marginals. We focus on the first 20 seconds of computation time because usually a few seconds are enough for our inference tasks. The lines in the plots con-tinue their trend and cross at some point except for Figure 4-b. A KL-divergence sum of 10  X  2 is generally accurate for these networks.
 Figure 4 shows the results for  X  = 2 ,  X  = 0 . 5 . For most of these experiments, TTOP performs better than sampling methods. When the coupling strength of the network is increased to  X  = 1 as shown in Figure 5, TTOP has more variations in the error as the computation time increases but still has better performance overall. The occasional peaks in the error happen because sometimes a part of the com-putation tree is expanded and added to the sum, without the part that balances it since the time budget expired. This can be seen as more computation time is given to the algorithm, the errors decrease with the addition of the balancing part. As the number of nodes in the network increase, our method keeps the computation time versus error advantage. Additionally, the gap between our method and others in-creases with the network size. Especially when  X  = 1 , it performs better for the larger networks. While we can-not perform exact inference for larger networks, we expect these trends would continue as the problem size scales. TTOP is also much better for short computation times, be-cause it solves e ( At ) directly by integration while the sam-pling methods can generate only a few samples. Although the derivatives are smaller for the TTOP lines, this could potentially be fixed with better node prioritization. The best node prioritization would be one that looked at the contri-bution of the whole subtree rooted at a node rather than only the contribution of that node. Our heuristic is good for the first few levels of the tree, but it does not do as well as we go deeper in the tree.
 The fluctuations in the error of TTOP are expected. The error from a single run of sampling would fluctuate as well. The plotted results of our method are from a single run compared to the averaged results of sampling methods which are 100 runs. We have demonstrated an anytime algorithm for structured CTMP filtering and smoothing. Unlike prior work, it is de-terministic, which can be of benefit when used inside learn-ing methods. In the experiments, it has better computation time versus error performance than prior anytime conver-gent methods, especially for loosely coupled systems. Also as network size increases and coupling strength stays the same, our method X  X  advantage increases as well.
 This work was funded by The Laura P. and Leland K. Whittier Virtual PICU at Children X  X  Hospital Los Angeles (awards UCR-12101024 and 8220-SGNZZ0777-00) and DARPA (award FA8750-14-2-0010).
 Baier, Christel, Haverkort, Boudewijn, Hermanns, Holger, and Katoen, Joost-Pieter. Model checking algorithms for continuous-time Markov chains. IEEE Transactions on Software Engineering , 29(6):524 X 541, June 2003.
 Burch, Jerry R., Clarke, Edmund M., and Long, David E.
Symbolic model checking with partitioned transition re-lations. In International Conference on Very Large Scale Integration , pp. 49 X 58, August 1991.
 Ciardo, Gianfranco and Yu, Andy Jinqing. Saturation-based symbolic reachability analysis using conjunctive and disjunctive partitioning. In Proceedings of Correct
Hardware Design and Verification Methods , pp. 146 X  161, 2005.
 Cohn, Ido, El-Hay, Tal, Kupferman, Raz, and Fried-man, Nir. Mean field variational approximation for continuous-time Bayesian networks. In Proceedings of the Twenty-Fifth International Conference on Uncer-tainty in Artificial Intelligence , 2009.
 Dyson, F. J. The radiation theories of Tomonaga,
Schwinger, and Feynman. Physical Review , 75(3):486 X  502, 1949.
 El-Hay, Tal, Cohn, Ido, Friedman, Nir, and Kupferman,
Raz. Continuous-time belief propagation. In Proceed-ings of the 27th International Conference on Machine Learning , pp. 343 X 350, Haifa, Israel, June 2010. Fan, Yu and Shelton, Christian R. Learning continuous-time social network dynamics. In Proceedings of the Twenty-Fifth International Conference on Uncertainty in Artificial Intelligence , 2009.
 Fan, Yu, Xu, Jing, and Shelton, Christian R. Impor-tance sampling for continuous time Bayesian networks.
Journal of Machine Learning Research , 11(Aug):2115 X  2140, 2010.
 Fernandes, Paulo, Plateau, Brigitte, and Stewart, William J.
Efficient descriptor-vector multiplication in stochastic automata networks. Journal of the ACM , 45(3):381 X 414, 1998.
 Gunawardana, Asela, Meek, Christopher, and Xu, Puyang. A model for temporal dependencies in event streams.
In Advances in Neural Information Processing Systems , volume 24, 2012.
 Mjolsness, Eric and Yosiphon, Guy. Stochastic process se-mantics for dynamical grammars. Annals of Mathemat-ics and Artificial Intelligence , 47(3 X 4):329 X 395, August 2006.
 Moler, Cleve and Loan, Charles Van. Nineteen dubious ways to compute the exponential of a matrix, twenty-five years later. SIAM Review , 45(1):3 X 49, 2003.
 Najfeld, Igor and Havel, Timothy F. Derivatives of the ma-trix exponential and their computation. Advances in Ap-plied Mathematics , 16:321 X 375, 1995.
 Ng, Brenda, Pfeffer, Avi, and Dearden, Richard. Continu-ous time particle filtering. In Proceedings of the Nine-teenth International Joint Conference on Artificial Intel-ligence , pp. 1360 X 1365, 2005.
 Nodelman, Uri, Shelton, Christian R., and Koller, Daphne.
Continuous time Bayesian networks. In Proceedings of the Eighteenth International Conference on Uncertainty in Artificial Intelligence , pp. 378 X 387, 2002.
 Rao, Vinayak and Teh, Yee Whye. Fast MCMC sam-pling for Markov jump processes and continuous time Bayesian networks. In Proceedings of the Twenty-
Seventh International Conference on Uncertainty in Ar-tificial Intelligence , 2011.
 Shelton, Christian R., Fan, Yu, Lam, William, Lee, Joon, and Xu, Jing. Continuous time Bayesian network rea-soning and learning engine. Journal of Machine Learn-ing Research , 11(Mar):1137 X 1140, 2010.
 Xu, Jing and Shelton, Christian R. Intrusion detection us-ing continuous time Bayesian networks. Journal of Arti-ficial Intelligence Research , 39:745 X 774, 2010.
 Zhou, Xiang and Schmidler, Scott C. Bayesian parame-ter estimation in Ising and Potts models: A comparative study with applications to protein modeling. Technical
