 Link prediction on social media is an important problem for recommendation systems. Understanding the interplay of users X  sentiments and social relationships can be potentially valuable. Specifically, we study how to exploit sentiment homophily for link prediction. We evaluate our approach on a dataset gathered from Twitter that consists of tweets sent in one month during U.S. 2012 political campaign along with the  X  X ollows X  relationship between users. Our first con-tribution is defining a set of sentiment-based features that help predict the likelihood of two users becoming  X  X riends X  (i.e., mutually mentioning or following each other) based on their sentiments toward topics of mutual interest. Our eval-uation in a supervised learning framework demonstrates the benefits of sentiment-based features in link prediction. We find that Adamic-Adar and Euclidean distance measures are the best predictors. Our second contribution is proposing a factor graph model that incorporates a sentiment-based variant of cognitive balance theory. Our evaluation shows that, when tie strength is not too weak, our model is more effective in link prediction than traditional machine learning techniques.
 H.2.8 [ Information Systems ]: Database Applications X  Data mining ; J.4 [ Computer Applications ]: Social and Behavioral Sciences X  Sociology Algorithms, Experimentation Social media; Social networks; Link prediction; Sentiment analysis; Topic affiliation
Link prediction refers to inferring potential relationships from a snapshot of a social network. A common intuition be-hind link prediction approaches is the presence of homophily in networks X  X imilarity breeds connections [25]. Existing works derive similarities among users from network topol-ogy [21] (structural similarity), and users X  interests [30] and geography [29] (semantic similarity).

However, structurally or semantically similar users may express different sentiments toward a common characteris-tic. Thelwall [33] found some evidence of both positive and negative sentiment homophily among MySpace friends. We posit that there exists a sentiment homophily in networks X  similarity in users X  sentiments breeds connection. Sentiment can be an important trait for link prediction because of its application in different domains such as political election prediction [9], location recommendation [37], and event de-tection [34].

Romero et al. [28] found that topics of interest to users can predict social relationships. For example, two users in-terested in the topic  X  X bama for President X  are likely to be friends. However, the two users may exhibit the same (both support or oppose Obama) or contradictory sentiments (one supports and the other opposes Obama) toward the topic. Motivated by sentiment homophily, we imagine that the two users are more likely to become friends in the former case than in the latter. Based on the above intuition, we ask two questions:  X  How may we exploit sentiments for link prediction?  X  Can sentiment homophily help in link prediction? Two challenges arise when answering the first question. First, how can we design sentiment-based features between two users in order to quantify sentiment homophily? Unlike features such as number of common friends, age, number of common places, designing sentiment features is much more complex because interpreting the sentiment of a tweet de-pends upon its domain and topic.

Second, employing traditional machine learning techniques (e.g., logistic regression) for link prediction assumes inde-pendence among pairs of nodes in a network, i.e., whether A X  X  is connected is independent of other connected pairs. However, such a case seldom exists in the real world. Hei-der [16] proposed cognitive balance theory in social psychol-ogy suggesting that if strong ties A X  X  and A X  X  exist, the likelihood of B X  X  becoming a tie (whether weak or strong) increases because of the  X  X sychological strain X : C will want to maintain his or her own feelings to agree with A and A X  X  friend, B. Granovetter claimed that the B X  X  tie is always present in this case. The strength of a tie can be  X  X  com-bination of the amount of time, the emotional intensity, the intimacy, and the reciprocal services X  [11]. Therefore, we hypothesize that it is nontrivial to capture dependence be-tween pairs of nodes (e.g., A X  X  and A X  X  ties predicting the B X  X  tie) via a machine learning technique. If sentiment ho-mophily exists, can we leverage such homophily to quantify the strength of a tie? Will the sentiment-based cognitive balance theory help in link prediction? How to build such a model and how to define the strength of a tie through sentiments are our second challenge.

We employ a dataset of political tweets (and associated users) to address the second question. We extract users X  sentiments toward different topics from their tweets, where sentiments are modeled as numeric scores and categorical values. Further, we design several sentiment-based features, and evaluate the effect of sentiment homophily in a su-pervised setting on two social networks: the mutual-follow graph and the graph formed by users referring to each other using  X  X  X  mentions (Section 4). We find that sentiment-based features improve the performance of link prediction in terms of the F 1 score on both networks. We also inves-tigate each sentiment-based feature and find that sentiment features based on the Adamic-Adar and Euclidean distance measures are the best predictors (Section 6.1).

We further propose a factor graph model based on Dong et al. [10], incorporating Heider X  X  cognitive balance theory, where the strength of ties is defined based on sentiment-based features (Section 5). Our model outperforms the other two well-known classifiers (logistic regression and random forest) in the mutual-follow graph and in mention graphs where the strength of ties is not too weak (number of men-tions exceeds three) (Section 6.2).

Although our analyses focus on Twitter, we conjecture that our approach can extend to a broad setting involving online information sharing, e.g., for restaurant or movie rec-ommendations.
 Sentiment-based features. We define features that quan-tify the likelihood of two users becoming friends based on their sentiments toward topics of mutual interest. We evaluate the potential benefits of each feature.
 Graphical model. We propose a model that incorporates the sentiment-based cognitive balance theory for link pre-diction. Our evaluation suggests that our model yields improved the performance (F 1 score) of link prediction when compared to traditional machine learning models. To obtain a dataset involving strong sentiments, we crawled Twitter during U.S. 2012 political campaign (from March 23 to April 23 in 2012) using the keywords  X  X bama X  and  X  X om-ney. X  We preprocessed the dataset by first removing tweets that contain more than 10 hashtags. Because Twitter limits 140 characters in one tweet, a tweet containing too many hashtags is likely to be spam [18]. In addition, we treat users with less than five tweets as  X  X nactive X  and exclude them. The resulting dataset contains 3 , 970 , 974 tweets from 123 , 073 distinct user accounts.

Topics. A Twitter hashtag [35] is a string beginning with  X # X , which is viewed as a topic marker in the tweet. Typ-ically, users adopt the same hashtag to discuss a particular topic. Thus, we use hashtags to represent different topics.
Graphs. We investigate two kinds of undirected graphs: the mention graph and the mutual-follow graph. The men-tion graph is based on  X  X  X  mentions: whether a retweet, a reply, or direct reference to a user. If two users mention each other more often than a certain threshold, we create an edge in their mention graph (we experiment with multiple thresholds). In the mutual-follow graph, we create an edge between two users if they follow each other.
We use an established sentiment lexicon, SentiWordNet [3], to obtain the sentiment scores of all tweets. SentiWord-Net contains three real-valued scores for each word in its lexicon indicating positivity , negativity , and objectivity ; the sum of the three scores is one. In addition, we extract emoti-cons from tweets and estimate the three sentiment scores of each emoticon. Agarwal et al. [2] provide a list of emoticons and categorize them into five categories: extremely positive , positive , neutral , negative , and extremely negative . We assign the sentiment scores to each category as triples of positiv-ity, objectivity, and negativity scores, respectively,  X  1 , 0 , 0  X  ,
We adapt the major methods described by Bakliwal [5] to compute the sentiment score of a tweet. First, we choose only the adjectives in the lexicon and extract their stems [27] to build a pairwise stem-score mapping dictionary. We con-sider only adjectives because adjectives are strong indicators of sentiment [15] and can improve sentiment prediction ac-curacy [5]. Second, we use the Twitter part-of-speech tagger to extract the adjectives and emoticons in a tweet. Third, we handle the negation pattern through the Stanford parser [8], which contains a dependency schema ( neg ) to indicate negation. We reverse the sentiment polarity for each word marked in a neg schema. Finally, we obtain the positivity and negativity scores of a tweet by averaging the two scores for each adjective and emoticon; The objectivity score of the tweet is one minus the two polar scores.
As a sanity check on our intuition about sentiment ho-mophily in the graphs we consider, we first determine the probability of two users sharing a same sentiment toward a topic of mutual interest, conditioned on whether they are connected.

We construct a mention graph choosing the threshold of mentions as three. That is, two users are connected if they mention each other at least three times. From the mutual-follow graph, we randomly choose a subgraph with 175 users and their friends. A pair of users is connected if there is an edge between them. For each graph, we construct pairs of unconnected users, whose number is identical to the number of connected pairs in the same graph. We choose the six most frequent topics (hashtags) in our dataset, and we want to compare the probability of two connected users sharing a sentiment with that of two unconnected users.

As Figure 1 shows, the probability of sharing a senti-ment is 6% higher, on average, for connected users than unconnected users in the mention graph. In the mutual-follow graph (Figure 2), the mean difference in probability between connected and unconnected users is 4%, but the difference varies across topics. The probability difference is Figure 1: Probability of two users in the mention graph sharing a sentiment toward the six most frequent topics. Figure 2: Probability of two users in the mutual-follow graph sharing a sentiment toward the six most frequent topics. pronounced for  X #romney X  and  X #santorum X  (8%), whereas the difference is  X  1% for  X #teaparty X . These observations support our intuition that sentiments and connections are correlated.
Let G ( V,E ) be a social network, where V is the set of users and E is the social relationship between the users. For a given node v s and a candidate set C = { v 1 ,v 2 ,...,v our goal is to predict whether there is a link between v s v ( v i  X  C ). Specifically, the task is to find a predictive func-tion for v s such that: Y = f ( G,v s ,C ), where Y = { y C } is a vector of inferred results; i.e., y si = p (1 | G,v represents the probability that v s will create a link with v
To do so, we take two steps. First we generate a can-didate set for a source node v s as described next. Second, we learn a predictive function by defining prediction features (Section 4) and applying a factor graph model incorporating cognitive balance theory (Section 5).
For each source node v s , we choose its two-hop neighbor-hood as its candidate set: friends and friends of friends. We choose the two-hop neighborhood as the candidate set be-cause (1) the number of candidates increases exponentially with the number of hops [22]; (2) the number formed friend-ships decays exponentially with the number of hops [20].
We model our problem as a classification problem, where friends are positive instances and friends of friends are neg-ative instances. We assign half of the source nodes into a training set and half into a test set. We measure F 1 scores to validate our recommendations with respect to the existing friends of v s in the test set.

We can derive the potential friends of v s from its friends of friends and then make recommendations based on ranked probabilities of links between v s and its friends of friends. However, measuring the validity of such recommendations requires that we train a model from candidates at one time instance and test for candidates at a future time instance. Since our dataset does not have information about when the links were formed, such an evaluation is out of our scope.
With the development of online information sharing, the coevolution of social and affiliation networks is gaining at-tention, e.g., [38]. We consider a user as affiliating with a topic if the user evinces interest in it, and we call the af-filiation topical affiliation . On Twitter, topical affiliation happens when a user includes a hashtag in his or her tweet.
Combining sentiment analysis of users X  messages and top-ical affiliation, we call such an affiliation the topic-sentiment affiliation . That is, a user affiliates with a set of topics, and associates a sentiment with each topic. We now describe how a user X  X  topic-sentiment affiliation can help link prediction by describing our prediction features.

We consider three kinds of features: sentiment, structural, and topical. Sentiment features are extracted from topic-sentiment affiliation; structural features are based on the graph-based similarity between two users; topical features are based on the topical affiliation of two users, measuring the similarity in their usage of topics. The sentiment fea-tures are our contribution whereas the other two categories serve as baseline predictors.
We compute each tweet X  X  positivity, negativity, and ob-jectivity scores using the methods of Section 2.1. If a user mentions a hashtag in one of his or her tweets, we affili-ate him with the topic-sentiment pair; if a user mentions the same hashtag in several tweets, we take the mean of the three scores of these tweets. We further adopt the sentiment-volume-objectivity (SVO) function [13] to measure the aggre-gate effect of a user X  X  level of interest and his or her sentiment scores toward a topic. The SVO score is a real value between 0 and 1 that incorporates three elements: polar sentiment (positivity or negativity), number of times a user mentions a topic, and objectivity. Therefore, the sentiment in the af-filiation system consists of four numeric scores: positivity, negativity, objectivity, and the SVO score. In this way, we obtain a topic-sentiment affiliation for each user from his or her tweets.
We use the difference between the positivity and negativ-ity scores to decide a user X  X  categorical sentiment toward a hashtag. The opinion is positive (negative) if the difference is greater (less) than zero; otherwise, the opinion is objec-tive. In addition, the size of a hashtag is the number of users who have adopted it. We adopt the following notation:  X  Let v 1 , v 2 , . . . , v N be N users.  X  Let h 1 , h 2 , . . . , h M be M hashtags.  X  Let P i , N i , O i be user v i  X  X  adopted hashtags set with  X  Let P j , N j , O j be the set of users who expressed pos- X  Let H i = P i  X  N i  X  O i  X  Let U ( h j ) = P j  X  N j  X  O j  X  Let s i ( h j ) be user v i  X  X  SVO score toward hashtag h
Given two users v s and v t , we divide sentiment features into the following seven categories: 1. The number of hashtags for which they have the 2. Sentiment alignment coefficient : among the com-3. Size of the rarest common hashtags : among the 4. Adamic-Adar : sum of the Adamic-Adar distances for 5. Sum of inverse size . 6. Mean size of common hashtags for which they 7. Topic-SVO distance .
These features are based on graph structure without con-sidering semantic information. We choose four predictors introduced by Liben-Nowell et al. [21]. 1. Number of common neighbors (CN) between two users. 2. Jaccard X  X  coefficient (JC): CN divided by the total num-3. Adamic-Adar ( Structural-AA ) [1]: weighting the im-4. Preferential attachment (PA): the product of two users X 
These features, introduced by Romero et al. [28], are base-line predictors in our study. 1. The number of common hashtags ( common ): | H s  X  H t 2. Size of the smallest common hashtag ( smallest ): 3. Adamic-Adar distance ( Topical-AA ): 4. Sum of inverse sizes ( inverse ): P h 5. Mean size of common hashtags ( mean ):
To investigate how to better exploit sentiments for link prediction, we propose a topic-sentiment affiliation based graphical model (TSAM). The motivation underlying TSAM arises from cognitive balance theory: if A X  X  and A X  X  are strong ties, then these two links are not independent because B X  X  is likely to be present. We seek (1) a way of building such relationships where the strength of a tie incorporates sentiment and (2) to study whether this sentiment-based cognitive balance theory could improve link prediction.
A TSAM model is an undirected graph G ( V , E ), where V represents the set of variables and E is the set of edges in the graphical model. Below, variables and edges refer to entities in TSAM, and nodes and links refer to entities in the social network.

We now describe how we build a TSAM model G ( V , E ) by representing links and their relationships in a social network G ( V,E ). Given the social network G ( V,E ), a source node v and its candidate set C = { v 1 ,v 2 ,...,v | C | } , link prediction seeks to infer the probability y si that v s will create a link with v i . Thus, we treat y si as a variable (hidden) and the relationships between such variables as edges E in the TSAM model.

There is an edge between any two hidden variables if they contain the same source node v s . Thus, for each source node, there is a clique in the TSAM model. For each hidden vari-able, an observed variable is connected with it, representing a vector of features associated with the hidden variable.
For example, suppose v s has five candidates: { v 1 ,v 2 } , its one-hop friends, and { v 3 ,v 4 ,v 5 } , its friends of friends. The resulting TSAM model of Figure 3 has five hidden variables { y s 1 ,  X  X  X  ,y s 5 } and five observed variables { x s 1 ,  X  X  X  ,x
Even though the figure only shows the factor graph for one source node, our model captures a scenario with mul-tiple source nodes. Correspondingly, a TSAM model with multiple source nodes is composed of multiple disconnected components, where all the hidden variables in one compo-nent form a clique.
Let T represent the set of indices for any link between a source node and one of its candidates. Then Y = { y t | t  X  T } and X = { x t | t  X  T } denote the set of hidden and observed variables in the TSAM model, respectively.

The graph can be modeled as a conditional random field [19] that defines a distribution over the graph: where Z is a constant that ensures P Y P ( Y | X ) = 1.
The model incorporates two factor functions, which we instantiate by the Hammersley-Clifford theorem [14]. We follow the presentation of Dong et al. [10]: the attribute factor models the influence of different features on the hid-den variable (link). where  X  m is a weight constant and d is the number of fea-tures associated with y t . We include all the features in Section 4 to build the attribute factor. Second, the edge factor encodes the relationships between connected hidden variables. where  X  n is a weight constant and k is the number of features associated with the edge ( y t ,y t 0 ) in the TSAM model.
We define g n ( y t ,y t 0 ) as a binary function. For any two hidden variables y t and y t 0 , a triad is potentially involved because y t and y t 0 contain the same source node. The triad would be cognitively balanced if both y t and y t 0 are strong ties. We can use any sentiment feature that satisfies the axioms of Gupte and Eliassi-Rad [12] to define tie strength. Let X  X  take the feature sentiment-AA as an example. Fol-lowing Hopcroft et al. X  X  [17] definition of the importance of an user, we select the top 1% edges in the social network G ( V,E ) in terms of sentiment-AA features as strong ties. Therefore, g n ( y t ,y t 0 ) is one when both y t and y t ties; otherwise, it is zero.
 Accordingly, the log-likelihood objective function is Here  X  = (  X , X  ) is the model (parameter configuration) that we seek to learn to maximize the log-likelihood objective function:  X  ? = arg max  X  O (  X ,Y | X ).

We adapt the methods in [32] to learn the model except that we conduct experiments in a supervised setting; we use gradient descent to optimize the objective function, where the gradient is approximated by loopy belief propagation [26]. With the estimated model  X  ? , the goal of link pre-diction is to determine the probabilities of hidden variables that maximize the joint probability P ( Y | X, X  ? ):
We seek to answer two questions:  X  Do sentiment features help in link prediction?  X  Does our proposed graphical model incorporating the
Evaluation Strategy. We conduct our experiments us-ing the mention and mutual-follow graphs. For the mention graphs, the number of  X  X  X  references between users can be viewed as the strength of a tie. We therefore define several mention graphs by setting different strengths of ties. Ta-ble 1 shows the statistics of mention graphs with different thresholds and of the mutual-follow graph.

For each mention graph, we choose all users whose degree is less than 50 as v s . For the mutual-follow graph, we select users who adopt at least 50 hashtags; additionally, we only select  X  X ctive X  users, with the degree falling within range [50 , 100]. Then we generate the two-hop candidate set for each source node. A pair is constructed between each source node and any one of its candidates. Doing so leads to the class imbalance being extremely high, a common problem in link prediction [22]. Because we first want to investigate the effect of sentiment features in link prediction, we under-sample the negative instances to obtain a balanced dataset. Table 2 shows the number of instances of all the learning datasets after preprocessing.

We normalize all the features to [0 , 1]. We apply logistic regression and random forest models from the WEKA frame-work, and we conduct a 10-fold cross-validation with default parameters. The F 1 score and the Area under the Receiver-Operating-Characteristic Curve (AUC) are two widely used metrics in evaluating performance of classifiers [7]. In our setting, we are more interested in the true positive than the true negative metric for two reasons. First, positive in-stances (links between source nodes and their existing friends) are ground truth, and ensuring high recall of positive in-stances is nontrivial. Second, false positive with zero, in-dicating no new friends to recommend, is not necessarily desirable. Because AUC incorporates both positive and neg-ative instances equally whereas F 1 ignores the true negative metric, we adopt F 1 as our performance metric.

Results. Table 3 shows F 1 scores on different combina-tions of features for logistic regression and random forest classifiers. In general, sentiment features yield better per-formance in terms of F 1 scores, no matter whether they are combined with structural features to build the model. To investigate whether sentiment features indeed help improve the F 1 score, we conduct a paired t-test: each value in sam-ple one is the F 1 score with sentiment or sentiment plus structural features; each value in sample two is the F 1 score with topical or topical plus structural features. The p-value is 0 . 0012, indicating the difference is statistically significant. In addition, structural features perform much better than both sentiment and topical features, but adding sentiment features can generally improve performance. Thus, senti-ment features can indeed help in link prediction, but as ad-juncts to the structural features.

Individual Feature Evaluation. We show the perfor-mance of each sentiment feature for random forest since it outperforms logistic regression in Table 3. Table 4 shows the F 1 score for individual sentiment feature. We highlight the top three ranked features in each graph. We find that in the mention graphs, the features Euclidean , sentiment-mean , and sentiment-AA perform best. We find that in the mutual-follow graph, the feature sentiment-agreement performs best, but Euclidean and sentiment-AA are good indicators. And, sentiment-rarest is not as informative as smallest (topical features). In addition, sentiment-aligned outperforms sentiment-misaligned in general in all graphs, indicating the existence of sentiment homophily. Therefore, our evaluation suggests that sentiment homophily exists and can benefit link prediction.
Following the preprocessing strategy proposed by Back-strom and Leskovec, we choose  X  X ctive X  source nodes in all graphs. That is, active nodes are those whose degree is within the range [lower, upper]. After constructing pairs consisting of each source node and each of its candidates, we remove those whose number of common friends is less than a threshold, because users with only a few common friends are unlikely to form friendships. Table 5 shows the criteria we used. The criteria differ for graphs with differing statistics. As the ties become stronger, the mention graph becomes smaller. Thus an overfitting problem may arise if the dataset is too small. We therefore limit our evaluation to graphs with more than 100 source nodes left after prepro-cessing.
 Table 5: Preprocessing parameters for evaluating TSAM.
Because the feature sentiment-AA ranks in the top three features for each graph in Table 4, we choose it to define the strength of a tie in the edge-factor function. For each graph, we assign half of the source nodes into a training and half into a test set. In the training phase, we set the learning rate  X  = 0 . 001 and the number of iterations as 500. We split each graph five times and report the mean precision, recall, and F 1 scores of the TSAM model as well as for lo-gistic regression and random forest, and identify the best performing model in terms of F 1 . TSAM outperforms the other two models in the mutual-follow graph. In the men-tion graphs, TSAM performs best when the ties are strong (@  X  3 and @  X  5), but not for weak ties (@  X  1 and @  X  2). This suggests that when the ties are weak, sentiment-based cognitive balance theory does not help because the links be-tween users are somewhat random; hence, a balanced cog-nitive structure does not necessarily mean any relationship between two pairs.

Overall, our results indicate that performance of link pre-diction could be improved when we incorporate sentiment-based cognitive balance theory, especially on graphs where the strength of relationship is not too weak (mutual-follow graph or mention graphs where the number of mentions ex-ceeds three).
Link Prediction. Existing work on link prediction can be classified into two categories. For the unsupervised meth-ods, Liben-Nowell and Kleinberg evaluated different  X  X rox-imity X  features extracted from network topology. They found that the Adamic-Adar metric performs best in predicting links. Most recent works are based on supervised methods. Lichtenwalter et al. [22] provided a detailed analysis of chal-lenges, such as class imbalance, of using supervised methods in link prediction. Dong et al. [10] proposed a probabilistic graphical model to predict links. Backstrom and Leskovec [4] developed a supervised random walk algorithm for friend recommendation on Facebook. Scellato et al. [29] exploited place features in predicting links on location-based social networks. Whereas we adopt a supervised approach, we ad-ditionally consider sentiment features and investigate how they improve link prediction.

Collaborative Tagging Systems. These are based on a tripartite structure: users, tags, and resources, enabling users to share their tags for particular resources. Combined with social structure, collaborative tagging systems provide new modalities of link prediction. Marlow et al. [24] found that users tend to have a larger similarity of tag vocabularies with their friends compared with random users. Markines et al. [23] built a foundation for the folksonomy-based sim-ilarity measures, such as matching, overlap, Jaccard, and cosine similarity. Romero et al. [28] studied the relationship between topical affiliations and social network on Twitter. They found that the adoption of hashtags can predict users X  social relationships. We design sentiment features based on Romero et al. X  X  findings. Further, we propose a graphical model based on sentiment features.

Sentiment Analysis. With the popularity of social me-dia, sentiment analysis brings us deeper understanding of so-cial network analysis. Twitter enables researchers to access huge amounts of data to discover collective sentiments [6, 34], predict political elections [9, 36], and so on. In other ap-plications, Yang et al. [37] extracted sentiments from users X  reviews on venues to improve location recommendation ser-vices; Tan et al. [31] used the social relationship to improve user-level sentiment prediction. We conduct our work with a different purpose: using sentiment homophily to predict links.
We study how to exploit sentiments for link prediction, and evaluate the extent to which sentiment homophily can help improve link prediction. By extracting users X  senti-ments from their tweets on different topics, we describe a set of sentiment features to quantify the likelihood of two users becoming friends. The evaluation results sug-gest that sentiment features improve the performance of link prediction in terms of F 1 in both mutual-follow and mention graphs. Upon investigating the predictive power of each sentiment feature, we find that Adamic-Adar and Euclidean distance based measures perform best. We pro-pose a factor graph model considering the sentiment-based cognitive balance theory. The results show that our model outperforms the other two well-known classifiers (logistic re-gression and random forest) in the mutual-follow graph and mention graphs where the strength of ties is not too weak (@  X  3). In future work, we plan to evaluate our work in a friend recommendation framework by exploiting temporal information regarding how links form.
 We thank the Laboratory for Analytic Sciences at NC State University, the National Science Foundation (grant 0910868), and IBM (for a Ph.D. fellowship to Zhang) for support. We also thank Tong Sun for sharing her dataset. [1] L. A. Adamic and E. Adar. Friends and neighbors on [2] A. Agarwal, B. Xie, I. Vovsha, O. Rambow, and [3] S. Baccianella, A. Esuli, and F. Sebastiani.
 [4] L. Backstrom and J. Leskovec. Supervised random [5] A. Bakliwal, J. Foster, J. van der Puil, R. O X  X rien, [6] J. Bollen, H. Mao, and A. Pepe. Modeling public [7] S. Daskalaki, I. Kopanas, and N. Avouris. Evaluation [8] M.-C. de Marneffe, B. MacCartney, and C. D.
 [9] N. A. Diakopoulos and D. A. Shamma. Characterizing [10] Y. Dong, J. Tang, S. Wu, J. Tian, N. V. Chawla, [11] M. S. Granovetter. The strength of weak ties. [12] M. Gupte and T. Eliassi-Rad. Measuring tie strength [13] D. F. Gurini, F. Gasparetti, A. Micarelli, and [14] J. M. Hammersley and P. E. Clifford. Markov random [15] V. Hatzivassiloglou and J. M. Wiebe. Effects of [16] F. Heider. The Psychology of Interpersonal Relations . [17] J. Hopcroft, T. Lou, and J. Tang. Who will follow you [18] H. Kwak, C. Lee, H. Park, and S. Moon. What is [19] J. D. Lafferty, A. McCallum, and F. C. N. Pereira. [20] J. Leskovec, L. Backstrom, R. Kumar, and [21] D. Liben-Nowell and J. Kleinberg. The link prediction [22] R. N. Lichtenwalter, J. T. Lussier, and N. V. Chawla. [23] B. Markines, C. Cattuto, F. Menczer, D. Benz, [24] C. Marlow, M. Naaman, D. Boyd, and M. Davis.
 [25] M. McPherson, L. Smith-Lovin, and J. M. Cook. [26] K. P. Murphy, Y. Weiss, and M. I. Jordan. Loopy [27] M. F. Porter. An algorithm for suffix stripping. [28] D. M. Romero, C. Tan, and J. Ugander. On the [29] S. Scellato, A. Noulas, and C. Mascolo. Exploiting [30] P. Singla and M. Richardson. Yes, there is a [31] C. Tan, L. Lee, J. Tang, L. Jiang, M. Zhou, and P. Li. [32] W. Tang, H. Zhuang, and J. Tang. Learning to infer [33] M. Thelwall. Emotion homophily in social network [34] M. Thelwall, K. Buckley, and G. Paltoglou. Sentiment [35] O. Tsur and A. Rappoport. What X  X  in a hashtag?: [36] A. Tumasjan, T. O. Sprenger, P. G. Sandner, and [37] D. Yang, D. Zhang, Z. Yu, and Z. Wang. A [38] E. Zheleva, H. Sharara, and L. Getoor. Co-evolution
