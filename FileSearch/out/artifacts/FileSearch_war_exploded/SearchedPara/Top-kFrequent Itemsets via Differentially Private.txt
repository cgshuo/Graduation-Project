 Frequent itemset mining is a core data mining task and has been studied extensively. Although by their nature, frequent itemsets are aggregates over many individuals and would not seem to pose a privacy threat, an attacker with strong back-ground information can learn private individual information from frequent itemsets. This has lead to differentially pri-vate frequent itemset mining, which protects privacy by giv-ing inexact answers. We give an approach that first identifies top-k frequent itemsets, then uses them to construct a com-pact, differentially private FP-tree. Once the noisy FP-tree is built, the (privatized) support of all frequent itemsets can be derived from it without access to the original data. Ex-perimental results show that the proposed algorithm gives substantially better results than prior approaches, especially for high levels of privacy.
 H.2.0 [ Information Systems ]: Database Management Algorithms, Security, Theory Frequent itemset, Differential privacy, FP-tree
As volumes of personal data collected by many organiza-tions increase, the problem of preserving privacy is increas-ingly important. In this paper, we investigate the problem of releasing top k frequent itemsets in a differentially private way. The problem of frequent itemset mining (FIM) has been extensively studied in the data mining community[2, 9] and it serves as an important building block for many ex-ploratory data mining algorithms. Although frequent item-sets are inherently aggregated information common to many individuals, na  X   X ve release of frequent itemsets can reveal sen-sitive information about individuals in the dataset[3].
Differential privacy[7, 8] is a recent notion of privacy that guarantees the output of an algorithm is insensitive to the change of one individual X  X  data. Differential privacy adds noise to the output (in our case, the frequent itemsets and their supports) such that the impact of any individual (trans-action) on the outcome is small relative to the added noise -ensuring that even an adversary with extensive background knowledge cannot use the result to determine an individual X  X  value. The main advantage of differential privacy is that it provides protection against a strong adversary without re-quiring a model of the adversary X  X  knowledge, or defining what information is sensitive.
 The main challenge in developing a differentially private FIM algorithm is that the sensitivity of an itemset query (the maximum impact a single individual can have on the set of frequent itemsets) is dependent on the dimensionality of itemsets in the dataset. Recently two works on differen-tially private FIM, PrivBasis[15] and SmartTruncation[19], were introduced. They reduce the dimensionality by pro-jecting the data into a lower dimensional space and by trun-cating the transactions, respectively. While these methods guarantee differential privacy, they come at a substantial cost in the quality of the results.

In this paper, we propose a novel approach that integrates the low sensitivity of a threshold query set and the com-pactness of the FP-tree data structure[9]. The proposed al-gorithm uses a modified version of the general sparse vector technique introduced in [11, 10]. The sparse vector tech-nique was originally used to release a small number of count queries whose count is greater than or equal to the given threshold. A variation of it appears in [17]. A big advan-tage of this technique is that information disclosure affect-ing differential privacy occurs only for count queries above the threshold; negative answers do not count against the  X  X rivacy budget X . Intuitively, the itemsets whose supports are far above (below) the threshold remain frequent (infre-quent) even after adding or removing one transaction. Only those itemsets whose supports are near the threshold can be switched from frequent to infrequent or vice versa by the change of single transaction. Based upon this obser-vation, we modify the sparse vector technique to privately answer exponentially many threshold queries (with a con-stant number of non-null results) given a fixed threshold. The proposed algorithm is composed of two phases: (i) fre-quent itemset discovery and (ii) noisy support derivation. In the first phase, all frequent itemsets are identified. At this stage, the algorithm does not know their supports, but o nly that their supports are above the threshold. Using this information, the second phase builds a differentially private FP-tree with privatized supports of the frequent itemsets. The proposed algorithm injects noise in the data structure at the intermediate (FP-tree) step. The final output (Frequent Itemsets, or any other output derivable from an FP-tree) can be further refined through an optional post-processing step.

The rest of this paper is organized as follows: In Section 2, related works are discussed. Section 3 defines the notations used throughout the paper and introduces the background knowledge about differential privacy. In Section 4, given the threshold, how the proposed algorithm identifies the set of frequent itemsets and derives their supports via differen-tially private FP-tree are described. In Section 5, the per-formance of the proposed algorithm is evaluated on a variety of datasets. Finally, Section 6 concludes our work.
There has been concern for some time that data mining results could lead to privacy violations [13]. In [1], Aggarwal et al. claimed that in practice it is possible for an adversary to predict sensitive fields in records by using association rules learned from the dataset. Therefore, it is insufficient to sim-ply hide sensitive values in the dataset. They introduced a technique for hiding minimal set of association rules to prevent disclosure of sensitive entries in the dataset. In or-der to hide sensitive association rules, the input dataset is anonymized so that sensitive rules cannot be learned.
Atzori et al. applied the concept of k -anonymity to the mining result instead of input dataset. To prevent inference on sensitive information, frequent patterns are distorted by changing their support values [3]. A collection of frequent patterns is called k anonymous if and only if the support of each pattern in the collection is greater than or equal to k .
The common problems from which both approaches de-scribed above suffer are difficulty on determining sensitive information and on modeling an adversary X  X  background knowl-edge. Differential privacy, proposed in [8], has emerged as a promising solution for privacy protection and received con-siderable attention because of its privacy guarantee against an adversary with arbitrary background knowledge.
Bahaskar et al. studied the problem of differentially pri-vately releasing top k frequent itemsets of length m [4]. Given the mining result of a non-private algorithm, it first selects top k itemsets to release using either the Laplace or exponential mechanism and then adds noise to each item-set X  X  support value.

Li et al. proposed a method called PrivBasis [15], that finds top k frequent itemsets in a differentially private way. PrivBasis tries to reduce the search space by finding minimal sets of items in an initialization stage, that covers the top k frequent itemsets. Each such set is called a basis. The item-sets in transactional data are viewed as tabular data and projected onto each basis. The supports of all subsets of a basis are derived by using binary itemset support count-ing[5]. To find a basis set, PrivBasis employed the tech-nique used in MaxClique[18]. However, basis finding based on frequent 2-itemsets may be very inaccurate and tends to generate many more bases than actually required.

Zeng et al. built a differentially private FIM algorithm[19] on apriori. Inspired by the observation that the sensitivity of D = { t 1 ,  X   X  X  , t n } A database of transactions
I = { I 1 ,  X  X  X  , I p } Set of items a counting query set used for support verification is depen-dent on the maximal length of transactions in the dataset, they introduced the idea of truncating transactions to reduce the amount of noise to inject. However, truncating transac-tions in their algorithm is heuristic and its performance is quite sensitive to parameter settings. Let I = { I 1 ,  X  X  X  , I p } be a set of items. An  X  -itemset X = { x 1 ,  X  X  X  , x  X  } is a subset of I whose length is  X  where x  X  I (1  X  i  X   X  ). The support of itemset X , denoted by  X  ( X ), is the number of transactions in D that includes X as a subset. An itemset X is frequent if and only if its support is greater than or equal to minimum support  X  (i.e.,if  X  ( X )  X   X  ). We use b Y to denote the noisy version of Y , i.e., b Y + Lap (  X  ) where Lap (  X  ) is a random sample (i.i.d) drawn from a Laplace distribution whose scale factor is  X  .
Two databases D 1 and D 2 are referred to as neighboring if one can be obtained by adding or removing one tuple from differential privacy ensures that any changes in the proba-bility of any outcome due to a single change in the input database is bounded by a constant ratio.

Definition 1 (  X  -differential privacy). A random-ized mechanism K is  X  -differentially private if for all neigh-boring databases D 1 and D 2 ,  X  S  X  Range ( K ) One way to achieve differential privacy is to perturb the output with random noise. The magnitude of noise should be large enough to hide the change that can be made by one individual in the universe. This is captured by the concept of sensitivity [8].

Definition 2 (Sensitivity). The sensitivity of a query function q is defined as where D 1 and D 2 are neighboring databases.
 It is known that Laplace mechanism achieves  X  -differential privacy [7].
Definition 3 (Laplace mechanism). Gi ven a query function q , a mechanism K that adds a random noise drawn from Lap  X  q  X  t o the output value of q is referred to as Laplace mechanism.
 One nice property of differential privacy is that it is compos-able. The privacy guarantee provided by differential privacy gracefully degrades under sequential composition: any se-quential composition of differentially private sub-routines, each of which satisfies  X  i -differential privacy, satisfies differential privacy. This is useful when designing a differ-entially private algorithm since the entire algorithm will be  X  -differentially private as long as the privacy budget allo-cated to each sub-routine sums to  X  .
The sparse vector algorithm was developed to release  X  count queries that are above the given threshold  X  . The algorithm starts by calculating the noisy threshold  X   X  using part of the privacy budget. Given a count query q , it calcu-lates the noisy count and compares it with  X   X  . Let K denote the algorithm and q be a count query.
 The algorithm uses another half of the privacy budget to answer above threshold queries. Notice that the remain-ing privacy budget  X  2 i s divided into  X  count queries. Af-ter answering  X  count queries it halts. The nice property of this algorithm is that it only pays privacy budget for above threshold queries and all below threshold queries are answered without wasting the privacy budget. Hence, any number of below threshold queries can be answered with-out compromising privacy. In essence, although the noisy count is calculated for each query and it is compared to the noisy threshold  X   X  , the algorithm does not release it but  X  for all below threshold queries hence not paying the privacy budget. The privacy guarantee of above threshold queries privacy of below threshold queries comes from the fact that it is compared to the noisy threshold. The formal privacy proof appears in [10].
We now describe each step of the proposed algorithm, called NoisyCut . The algorithm takes an integer k and out-put the top k most frequent itemsets. The algorithm first learns the support of the k th most frequent itemset  X  k and uses it as a threshold. This can be done by running any non-private FIM algorithm. Since the only output of this stage is the  X  k , using only the noisy threshold  X   X  =  X  k + Lap (  X  ) ensures differential privacy.

For each itemset in the itemset lattice, the algorithm tests if its noisy support is above the noisy threshold. If it is, the algorithm regards it as frequent. This can be viewed as cut-ting the itemset lattice into two groups, frequent L and infre-quent L  X  , and hence the name of algorithm. We will show that this can be done with high accuracy and with small privacy budget while guaranteeing differential privacy. Af-ter identifying all frequent itemsets, to derive the support of each frequent itemset, the algorithm builds a noisy FP-tree. The supports of itemsets can be derived from the FP-tree Algorithm 1 F indFreqItemsets Input: T ransactional database D , set of items I , Top k , Output: a set of frequent itemsets L 1: function FindFreqItemsets ( D, I , k,  X  1 ) 2:  X   X   X   X  k + Lap 4  X  3 : L 1  X  GetFrequent ( I ,  X   X  , 3  X  1 4 ,  X  ) 4 :  X   X  2, L X  X  1 5: while L  X   X  1 6 =  X  and |L| &lt; k do 6: C  X   X  X  a  X  b | a, b  X  X  i  X  1  X  a &lt; b } 7: L  X   X  GetFrequent ( C  X  ,  X   X  , 3  X  1 4 , L ) 8 : L X  X  X  X   X  ,  X   X   X  + 1 9: return L 10: function GetFrequent ( C ,  X   X  ,  X , L ) 11: S  X  X  X  12: for each itemset X  X  X  do 13: b  X  ( X )  X   X  ( X ) + Lap 1  X  1 4: if b  X  ( X )  X   X   X  and | L  X  S | &lt; k then 15: S  X  S  X  X  X } 16: return S in a recursive manner. Generating noisy counts for frequent i temsets can also be done using the binary itemset support counting method proposed in [5].

The privacy budget  X  is allocated between two phases. Let  X  =  X  X  and  X  2 = (1  X   X  )  X  be the privacy budget allocated to the first and second phase, respectively (i.e.,  X  =  X  1  X  ), where  X   X  (0 , 1) is the parameter that controls privacy budget allocation between two phases. The larger  X  is, the more accurately the proposed algorithm can find frequent itemsets in the first phase while it would increase the amount of noise added to the support of each itemset in the second phase. We empirically settled on  X  = 1 3 a nd use this value in the experiments.
The algorithm for finding a set of frequent itemsets L is described in Algorithm 1. The algorithm is Apriori-based. The candidate (  X  + 1)-itemsets are generated by joining two previously found frequent  X  -itemsets that share a frequent (  X   X  1)-itemset as a prefix. While the proposed algorithm follows the intuition of Apriori algorithm, the biggest differ-ence is that Algorithm 1 finds frequent itemsets by asking a set of threshold queries, each of which asks if the noisy support of itemset in question is above the noisy threshold or not and receives a boolean answer.

This threshold query based approach has a significant ad-vantage over the count query based one in terms of noise addition. Let X  X  consider the case where count queries are used instead of threshold queries.

Definition 4 (  X  -count query set). Given a set of can-didate  X  -itemsets, C  X  , an  X  -count query set CQ  X  is defined as where each query q i asks for the count of i th itemset in C At each iteration, the algorithm throws CQ  X  to the privacy mechanism to verify the supports of candidate itemsets.
Theorem 1. The sensitivity of an  X  -count query set  X  CQ  X  is the size of candidate set, C  X  .
Proof. A ssume there is a transaction t that contributes to every q i (1  X  i  X  n ). Adding or removing t from D will change the answer of each q i by one. Therefore, the global sensitivity of CQ  X  is the size of candidate set (i.e.,  X  q = |C| ).
 application of the Laplace mechanism to the Apriori method will add unacceptable noise to each itemset.

Definition 5 (  X  -threshold query set). An  X  -threshold query set is a set of threshold queries for candidate  X  -itemsets. where each q i returns 1 if  X  ( X )  X   X  , and 0 otherwise.
In a differentially private algorithm, all information dis-closures must be performed in a differentially private way. Based on the sparse vector method, the noise in the result comes from the noise in the threshold, resulting in either near-frequent itemsets being treated as frequent, or vice-versa. This ensures that the effect of a single transaction on an itemset appearing in the result is low relative to the noise causing an itemset to appear in the result.
There would appear to be one issue: we don X  X  ask if all itemsets are frequent, only candidates. However, the first round considers all possible items, and subsequent round candidates are generated from the (differentially private) output of the previous round without access to the database, satisfying differential privacy.

Given an integer k &gt; 0, the algorithm starts from calcu-lating the noisy threshold by adding noise to the support of the k th most frequent itemset,  X  ( k ) (line 2). Observe that adding or removing a transaction can only change the sup-port of the k th most frequent itemset,  X  ( k ), by at most one. Hence, adding a random noise drawn from Lap 4  X  satisfies  X  1 4 -differential privacy. Let  X   X  1 and  X   X  thresholds for two neighboring database D 1 and D 2 , respec-tively. For  X  x  X  R , After computing  X   X  , for each itemset X  X  X  , the algorithm in-ternally computes the noisy support b  X  ( X ) by adding Lapla-cian random noise to its true support  X  ( X ). If the calculated noisy support is greater than or equal to the noisy threshold, the itemset is regarded frequent. Otherwise, it is regarded infrequent. Notice that in either case what is released by this phase of the algorithm is not the noisy support but whether the itemset is frequent or not . Let C be the set of all candidate itemsets and X i be the i th element in C . We can model the set of answers the algorithm receives from the privacy mechanism as a vector v = h v 1 ,  X  X  X  , v t i where v = 1 if b  X  ( X i )  X   X   X  , otherwise v i = 0. Therefore, to prove the privacy of Algorithm 1, it is suffi-cient to show that the privacy loss for all possible v  X  Z is bounded by exp (  X  ) where Z is the set of all possible binary vectors. In Theorem 2, we prove that vector v released by the Algorithm 1 satisfies  X  1 -differential privacy regardless of its length.
 Theorem 2. Algorithm 1 is  X  1 -differentially private.
Proof. Given any two neighboring databases D 1 and D 2 , let V 1 and V 2 denote the output distribution on v when D 1 and D 2 are the input databases, respectively. We use v &lt;t to denote ( t  X  1) previous answers from the mechanism probability, the privacy loss due to v = h v 1 ,  X  X  X  , v t a  X  X  0 , 1 } is V 1 ( v )
V 2 ( v ) Once v &lt;i is fixed, the conditional distributions of  X   X  and b  X  ( X ) are just a Laplace distribution. Let H 1 i ( x ) be the probability that the itemset X i is frequent ( i.e., v i = 1) in D 1 when the threshold is x .
 R ecall that  X   X  = 1. If we make a substitution u = y + 1, from d u = d y , the above yields There are two possible cases: Let the set of indices of answers for itemsets whose supports are the same in both D 1 and D 2 and for itemsets whose supports increase by one be S = { i | a i =1  X   X  1 ( X i )=  X 
Y = = A  X  B (3) where A = A =  X  exp  X  1 = exp  X  1
Probability B = =  X  exp  X  1 = exp  X  1 = exp  X  1 From (4) and (5), it is seen that
Y By the same argument as in the preceding, we can prove
Y Therefore, for all v of any length t , V 1 ( v ) V
A s shown in Figure 1, the farther an itemset is from the threshold, the lower chance of being a false negative it has, which means that, except for itemsets that are close to the  X  X orderline X , the algorithm is highly likely to find all frequent itemsets.

Theorem 3. Given an itemset X whose support is  X  +  X  , the probability that this itemset will become a false negative is
Proof. The mechanism will answer correctly if the fol-lowing condition is satisfied: Observe that  X   X   X   X  and b  X  ( X )  X   X  ( X ) are two independent random variables whose distribution is Lap  X  = 2  X  . Let V and W be random variables corresponding to  X   X   X   X  and b  X  ( X )  X   X  ( X ), respectively. Let Z = V  X  W denote the difference between two random variables. Since Laplace dis-tribution is symmetric, Z = V  X  W = V + W . To denote the probability density function of Z , we use the notation f T he probability of not satisfying (6) is 1  X  False positives may also occur (again, most likely if close to t he top k ), but are less critical as they may later be filtered by having a low (noisy) support.
Given a set of frequent itemsets L , it is easy to find the set of maximal frequent itemsets M . This can be done on the fly by checking if the newly added frequent itemset is subsumed by any existing itemsets.
 Algorithm 3 derives noisy supports of all itemsets in L . The algorithm employs an FP-tree data structure and the FPGrowth algorithm [9]. As the algorithm follows the usual procedure of the FPGrowth algorithm, we only remark on the differences. Algorithm 2 B uildFPTree Input: s et of dimensions for projection M Output: FP-tree T 1: function BuildFPTree ( M,  X  ) 2:  X   X  create a root node 3: for each itemset l  X  2 M do 4: v  X   X  5: for each item i  X  l do 6: if 6 X  w s.t. w  X  v.children  X  w.item = i then 7: create a new node w under v 8: w.item  X  i ; w.count  X  Lap 1  X  9 : v  X  w 10: return  X  11: function UpdateCount ( D, M, T ) 12: for each transaction t  X  D do 13: t  X  t  X  M ; v  X  T 14: for each item i  X  t do 15: if v has a child w s.t. w.item = i then 16: v  X  w 17: v.count  X  v.count + 1 Given an itemset X , its noisy support b  X  ( X ) is an unbi-ased estimator of the true support and we measure the er-ror of noisy support of X as its variance, i.e., Error ( X ) = E ( b  X  ( X )  X   X  ( X )) 2 . If an itemset X is a subset of mul-tiple maximal frequent itemsets, say M 1 , M 2 ,  X  X  X  , M m support is counted by m FP-trees and they need to be ag-gregated in a way that minimize Error ( X ). To aggregate multiple noisy supports, each noisy support is weighted pro-portional to the inverse of its variance as in Lemma 1.
Lemma 1. Given m noisy supports, b  X  1 ( X ) ,  X  X  X  , b  X  m and their respective variances v 1 ,  X  X  X  , v m , the variance of weighted mean Var w Wh ile Algorithm 3 looks like a (non-noisy) query to the database, which would appear to violate differential privacy, the output is equivalent to constructing a tree from the (dif-ferentially private) set of maximal frequent itemsets, then filling in supports using a noisy count query for each node. The algorithm as written does this with a single pass through the database.
 Theorem 4. Algorithm 3 achieves  X  2 differential privacy.
Proof. Given an input database D , the process of build-ing the FP-tree can be viewed as a query function g ( D ) which returns an FP-tree built upon D . An FP-tree is a set of nodes each of which contains the count of the correspond-ing itemset. Hence, using an arbitrary traversal order, it can be modeled as a vector u D = ( u 1 ,  X  X  X  , u i ,  X  X  X  , u u (1  X  i  X  q ) represents a node count and q is the number of nodes in the tree. For the proof, it suffices to show that the function UpdateCount satisfies differential privacy since this is the only place in the algorithm that requires access Algorithm 3 Ge tNoisySupport Input: d atabase D , set of maximal frequent itemsets M , Output: Top k frequent itemsets in L and their support 1: function GetNoisySupport ( D, M ,  X  2 ) 2: L X   X  3: for each maximal itemset M  X  X  do 4: T  X  BuildFPTree ( M,  X  2 |M| ) 5 : UpdateCount ( D, M, T ) 6: for each node v  X  T do 7: v.count = v.count + 8: FPGrowth ( T, M,  X , L ) 9: return top k itemsets and their supports in L 10: function FPGrowth ( T, M,  X , L ) 11: if T has a single path P then 12: for each combination  X   X  P do 13: L (  X   X   X  ) .count  X  min. support of nodes in  X  14: else 15: for each b i  X  M do 16:  X   X  b i  X   X  17: L (  X  ) .count  X  support of b i 18: construct  X  -conditional FP-tree T  X  19: FPGrowth ( T  X  , M,  X  ) to D . Other steps, such as noise propagation and support derivation, can be done purely based on the output of the function. Notice that changing a transaction in D can only change the value of one entry by at most 1. This is because the algorithm is designed to update the count of only one node per transaction. Suppose the itemset X corresponding to u i is removed from D . It will only decrease u i by exactly 1 and other entries will remain the same. The resulting vector will be u for all D and its neighboring database D  X  , According to the Laplace mechanism adding independent Laplace noise drawn from Lap |M|  X  g  X  fies  X  2 |M| -differential privacy, and by the composition theorem of differential privacy [16] constructing |M| noisy FP-trees satisfies  X  2 -differential privacy.

Figure 2 gives an example of building a noisy version of a n FP-tree. Let the input database be Figure 2(a) and, for simplicity, assume each transaction is lexicographically ordered after removing infrequent items. Given the mini-mum support  X  =2, there are two maximal frequent item-sets, M 1 = { a, c, d } and M 2 = { b, e } . The proposed algo-rithm will construct two FP-trees, one for M 1 and the other for M 2 . We now explain how the algorithm constructs the noisy FP-tree for M 1 = { a, c, d } . First, the algorithm starts by creating a root node and inserts all the subsets of M 1 created node is initialized with Laplace noise (line 8 in Al-gorithm 2). After creating nodes, the algorithm takes each transaction and filters out any item that does not appear in M 1 . The item e is removed from the first transaction since it is not a part of M 1 . The count of the node corresponding to (c) the tree built this filtered transaction is updated. Unlike the original FP-tree, only the count of the last node in the matching path is increased by 1 to reflect the occurrence of the transaction. In Figure 2(c), those nodes whose counts are updated to reflect the occurrence of transactions are marked as shaded. The first transaction causes to increase the count of node d , on transaction also increases the count of the same node since they become the same after the filtering step. The third transaction updates the count of node d on the first level. fifth transaction is ignored since it has no common item with M 1 . All the items are removed from the transaction and the resulting transaction becomes an empty set. After building the tree, from the leaf toward the root, the count of each node is added to its parent. The FP-tree after the count propagation is shown in Figure 2(d).
Given a node v in a non-perturbed FP-tree, according to the construction of the tree, the count of v cannot be smaller than the sum of counts of its children. Formally, However, the constraint (7) may be violated in the noisy tree created by Algorithm 3 due to the noise injected to each node. The accuracy of randomized output can be improved though post-processing to impose consistency on the tree-like data structure [12, 6]. This is done without reference to the original data, only the already differentially-private structure, so the result is still differentially private.
In this section, we formulate the problem of imposing con-sistency on the noisy FP-tree as a constrained least squares problem and provide the formulation to find the solution. in an FP-tree, i.e., the i th element of  X  x i corresponds to the noisy count of the i th node v i in the tree. Note that the ordering of nodes can be arbitrarily chosen. We impose con-sistency constraints on the noisy FP-tree by constructing a consistent vector  X  x such that the distance between  X  x and  X  x is minimized. In other words, given a noisy FP-tree b T , our algorithm tries to find another tree that is closest to b also satisfying the constraint.

Constraint (7) can be represented by a system of linear inequalities C  X  x  X   X  x where Let c T i denote the i th row of C and W i be the set of indices of v i  X  X  children, i.e., w i = { j | v j  X  v i .children } . The i c T i represents the constraint  X  x i  X  problem can be formulated as follows: We can reformulate the problem as a least distance program-ming (LDP) by substituting  X  x  X   X  x with  X  x  X  . where G = I  X  C and g =  X  G  X  x .

Theorem 5. Let u be the solution to the nonnegative least squares problem and r = ( r 1 ,  X  X  X  , r n +1 ) = Eu  X  f where . The unique solution to the problem (8) is Proof. See [14].
 The impact of constraint enforcement on the accuracy is e valuated in Section 5.2.
In this section, we evaluate the performance of the pro-posed algorithm (NC) on a variety of datasets and com-pare it with two state-of-the-art algorithms: PrivBasis (PB) and SmartTruncation (ST). The datasets used in the ex-periments are described in Table 2. All experiments are conducted on an Intel Xeon 2.4GHz machine with 24GB of physical memory. To obtain an average performance esti-mate, each algorithm was run 10 times. PrivBasis finds top k frequent itemsets while SmartTruncation reports all fre-quent itemsets with respect to the given threshold. For com-parison, the minimum support for SmartTruncation was set to the frequency of the k th most frequent itemset. To com-pare the performance of algorithms, we employ F score and Relative error (RE) as measures of utility.

Definition 6 (F score). Let F and  X  F be the set of correct and published frequent itemsets, respectively. The F score is defined as follows p umsb star (PUMSB) 49,046 2,088 63 50.5 BMS-WebView1 (WV1) 59,602 497 267 2.5 BMS-WebView2 (WV2) 77,512 3,340 161 5.0 w here precision = |{ F N otice that for top k FIM algorithms |F| = b F = k , hence precision = recall = F score = 1  X  FNR where FNR, used in [15] for utility measure, is the fraction of false negatives in the released frequent itemsets.

Definition 7 (Relative Error). The relative error of published frequent itemset  X  F is defined as B efore discussing the results, we note that the ST algorithm has maximal cardinality parameter  X  that controls the trade-off between information loss and sensitivity reduction due to the transaction truncation. Its performance heavily relies on the proper setting of this parameter. However, there X  X  no systematic way to set the parameter and the choice is merely heuristic. We fine-tuned this parameter until reasonable ac-curacy is obtained.
Figure 3 shows the F scores of each algorithm by different values of  X  . Observe that the proposed algorithm consis-tently outperforms both PB and ST algorithms and shows stable performance for different privacy budget and k . The F scores of PB and ST rapidly decrease at higher privacy levels (smaller  X  ). As the value of  X  is decreased  X  higher privacy level is imposed X , the performance gap between the proposed algorithm and other two algorithms becomes more noticeable. Especially, in Figure 3(f) and 3(i) only the pro-posed algorithm shows a good performance when  X  = 0 . 1; both PB and ST have unacceptably low F scores.

One interesting observation is that PB shows better per-formance on POS dataset than ST while on the WV1 and WV2 dataset ST outperforms PB. One reason for this is that the maximal length of FIs in WV1 and WV2 dataset is 2, hence transaction truncation effectively reduces noise with relatively small cost of information loss. In contrast, PB tends to generate long and many bases because of abun-dance of frequent 2-itemsets. In addition, PB shows low performance when k is large. The best F scores of ST we were able to get for the PUMSB, retail and aol datasets were under 0.6 even after substantial parameter tuning. As shown in Figure 3, PB and ST algorithms are only useful when the low privacy level is required (large  X  ). Figure 4 describes the change of RE on different values of  X  . Since ST algorithm doesn X  X  report the support values of frequent itemsets, the RE of proposed algorithm is only compared with that of PB. The proposed algorithm shows similar or better performance on all tested datasets. Observe that in Figure 4(b) and 4(c) relative errors of PB are extremely high, which make the released FIs almost useless in practice.
Figure 5 illustrates how optional consistency enforcement described in Section 4.3 affects performance. This experi-ment used the PUMSB dataset. As shown in Figure 5(a), imposing consistency on the FP-tree data structure not only produces consistent results but also improves utility. Al-though more improvement on accuracy is obtained when k = 200, this post-processing step increases processing time. The bigger FP-tree is, the longer it takes to find the con-sistent result. This is because that the size of constraint matrix is the number of nodes in the FP-tree, and solving least distance for a huge matrix is computationally expen-sive. Therefore, this post-processing step can be optionally executed when the consistency is essential to the problem or when there is enough computational power since the perfor-mance of the proposed algorithm without the optimization step is in general better than those of others. Although it is unfair to compare the processing time of each algorithm since the implementation of each algorithm is not written in the same language, we present it to show that the proposed algorithm is comparable to others.
We have proposed an algorithm for finding top-k frequent itemsets in a differentially private way. Our algorithm first discovers frequent itemsets (without their support values) using a small portion of the privacy budget. This enables the algorithm to use the remaining privacy budget to efficiently and effectively build a differentially private FP-tree. Once the tree is built, the supports of all frequent itemsets can be derived from the tree without access to the database.
We believe that the sparse vector mechanism demonstrated in this paper may also be applicable to other types of differ-entially private data mining, as it allows a potentially large amount of access to the data with the noise dependent only on the data that affects the output, rather than all data accessed.
 This material is based upon work supported by the National Science Foundation under Grant No. CNS-1012208. [1] C. C. Aggarwal, J. Pei, and B. Zhang. On privacy [2] R. Agrawal and R. Srikant. Fast algorithms for mining [3] M. Atzori, F. Bonchi, F. Giannotti, and D. Pedreschi. [4] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta. [5] J. Chen and K. Xiao. Bisc: A bitmap itemset support [6] B. Ding, M. Winslett, J. Han, and Z. Li. Differentially [7] C. Dwork. Differential privacy. In ICALP 2006 , pages [8] C. Dwork, F. McSherry, K. Nissim, and A. Smith. [9] J. Han, J. Pei, and Y. Yin. Mining frequent patterns [10] M. Hardt. A Study of Privacy and Fairness in [11] M. Hardt and G. N. Rothblum. A multiplicative [12] M. Hay, V. Rastogi, G. Miklau, and D. Suciu. [13] M. Kantarcio X glu, J. Jin, and C. Clifton. When do data [14] C. L. Lawson and R. J. Hanson. Solving least squares [15] N. Li, W. Qardaji, D. Su, and J. Cao. Privbasis: [16] F. D. McSherry. Privacy integrated queries: An [ 17] A. Roth and T. Roughgarden. Interactive privacy via [18] M. J. Zaki. Scalable algorithms for association mining. [19] C. Zeng, J. F. Naughton, and J.-Y. Cai. On
