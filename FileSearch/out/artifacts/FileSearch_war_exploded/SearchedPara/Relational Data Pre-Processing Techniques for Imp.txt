 Commercial datasets are often larg e, relational, and dynamic. They contain many records of people, places, things, events and their interactions over time. Such datasets are rarely structured appropriately for knowledge discovery, and they often contain variables whose meanings change ac ross different subsets of the data. We describe how these challenges were addressed in a collaborative analysis project undertaken by the University of Massachusetts Amherst and the National Association of Securities Dealers (NASD). We describe several m ethods for data pre -processing that we applied to transform a large, dynamic, and relational dataset describing nearly the entirety of the U.S. securities industry, and we show how these methods made the dataset suitable for learning statistical relational models. To better utilize social structure, we first applied known consolidation and link formation techniques to associate individuals with branch office locations. In addition, we developed an innovative technique to infer professional associations by exploiting dynamic employment histories. Finally, we applied normalization techniques to create a suitable class label that adjusts for spatial, temporal, and other heterogeneity within the data. We show how these pre -processing techniques combine to pro vide the necessary foundation for learning high -performing statistical models of fraudulent activity.
 H.2.8 [ Database Management ]: Database Applications  X  Data Mining; I.2.6 [ Artificial Intelligence]: Learning Algorithms, Measurement, Design, Experimentation.
 Fraud detection, data pre -processing, statistical relational learning, normalization, relational probability trees. The National Association of Securities Dealers (NASD) is charged with overseeing and regulating over 5,000 securities firms in the United States. One primary aim of NASD is to prevent and discover securities fraud and other forms of misconduct by member firms and their employees, called registered representa tives, or reps . With over 659,000 reps currently employed, it is imperative for NASD to direct its limited regulatory resources towards the parties most likely to engage in risky behavior in the future. It is generally believed by experts at NASD and other s that fraud happens among small, interconnected groups of individuals [2] . Due to the large number of potential interactions between reps, timely identification of persons and groups of interest is a sizeable challenge for NASD re gulators. This work is a joint effort between researchers at the University of Massachusetts Amherst (UMass) and staff at NASD to identify effective, automated methods for detecting these high -risk entities to aid NASD in their regulatory efforts. The se curities fraud domain, along with other similar domains, presents many challenges to knowledge discovery practitioners. The NASD dataset is large, containing historical records on over 3.4 million reps, 360,000 branches and over 25,000 firms. These entiti es also have many rich interactions over time as reps change jobs, as they move among branches and firms, and as branches and firms change ownership. In addition, the background rate of misconduct varies over time and geography. In this paper, we describ e our techniques to address each of the challenges presented by the NASD dataset. These techniques allow the transformation from raw data to high -performing models that are useful for detecting high -risk individuals. First, we utilized standard consolida tion and link formation techniques as described by Goldberg and Senator [4] to infer branch entities from rep employment records. Using the inferred branch entities, we created a new technique for identifying groups of reps, which we call tribes . Tribes are groups of reps that move from branch to branch together over time. Finally, we addressed the variability in background rate by creating a normalized class label. A graphical representation of this process is shown in Figu re 1 .
 While the results of the data pre -processing techniques (e.g., tribes) are frequently interesting and useful in their own right, we believe their true utility lies in the integration of these technologies to form a foundatio n for learning understandable and effective models for detection of securities fraud. Without this foundation of data pre -processing techniques, any analyses of large, dynamic datasets such as the NASD data run the risk of being ineffective and potentially impossible. The models we present can be used by NASD examiners to rank the risk of future misconduct by reps and branches, and these models have the added benefit of providing a means to evaluate the efficacy of our data pre -processing techniques. NASD is the primary private -sector regulator of the securities industry in the United States. It is currently responsible for overseeing the activities of more than 5,000 brokerage firms, 170,000 branch offices and 659,000 re gistered individuals. Since 1939, NASD has worked under the oversight of the U.S. Securities and Exchange Commission (SEC) to regulate all securities firms (called broker -dealers) that conduct business with the public. Currently, NASD employs a staff of o ver 2,500 employees situated in offices across the country and has an annual operating budget of more than $500 million. NASD is responsible for maintaining rules that guide all phases of the business for each member, starting with the testing, registrati on, and licensing of prospective broker -dealers and individuals. NASD is also responsible for the surveillance, examination, and enforcement of regulatory compliance among firms. Broker -dealers that are not in compliance with NASD regulations are subject to discipline in the form of a bar or suspension from the industry, a fine, or possibly other enforcement action. In addition, NASD offers opportunities for both professional training and investor education. In order to ensure compliance among its member s, NASD utilizes two types of examinations. The first, called a cycle examination , happens on a routine basis. The second type of examination, called examination for cause , is performed in response to complaints or for other specific reasons. Examinations require significant time and personnel resources and are critical for ensuring the integrity of the markets and safeguarding investors. Using both types of examinations, NASD strives for the early discovery of securities violations in order to prevent seri ous harm, punish offenders in a timely manner, and swiftly recover misappropriated funds. In addition, examinations can serve to prevent future violations by emphasizing the presence of regulatory oversight. It is imperative for NASD to identify the high est -risk branches and reps so that examiner resources can be appropriately allocated. NASD examiners currently utilize a number of different methods to identify these high -risk entities. Often these approaches involve examining the history of regulatory o r financial problems for an individual rep or branch. Due to dynamics of the marketplace and the inherent difficulty of predicting future violations, NASD is continually seeking new methods for focusing resources and identifying high -risk entities. The Central Registration Depository  X  (CRD) is a collection of records regarding all federally registered firms and individuals , including those registered by the SEC, NASD, the states, and other authorized regulators such as the New York Stock Exchange. This depository includes key pieces of regulatory data such as ownership and business location for firms, and employment histor ies for individuals. Although the information in the CRD is entirely self -reported, errors, inaccuracies or missing reports can trigger regulatory action by NASD. Since 1981, when the CRD was first created, records on around 3.4 million individuals, 360, 000 branches and 25,000 firms have been added to the database. Some of the critical pieces of information for NASD X  X  regulatory mission are records of any disciplinary actions, typically called disclosures , filed on particular individuals. These disclosu res can encompass any non -compliant actions including regulatory, criminal, or other civil judicial action. In addition, disclosures can also be in regards to customer complaints or termination agreements between firms and individual reps. Additional disc losures cover any past financial hazards an individual rep might have had such as bankruptcies, bond denials, and liens. The disclosure information found in the CRD is one of the primary sources of data on past behavior that NASD uses to assess future risk and focus their regulatory examinations to greatest effect. Disclosure information for individual brokers is freely available to the public through NASD X  X  BrokerCheck system 1 . In addition to disclosures filed by NASD, the BrokerCheck system also contains disciplinary information from the SEC, state regulators, New York Stock Exchange, the FBI, and any self -reported disclosures from the firms themselves. Our final analysis utilized data from the CRD for firms, branches, reps, and disclosures. An entity -re lation diagram is shown in Figure 2 along with counts for each entity appearing in our view of the database. The primary goal of this work is to develop statistical models that combine patt erns of past behavior, social structure among reps and firms, and the current risk environment to identify branches and reps that are at high -risk for future misconduct. To account for the dynamic nature of this process our models are designed to predict risk for the near future, given past information. This closely matches the scenario faced by NASD. Risk is broadly construed and encompasses any behavior that is potentially harmful to a member firm or to NASD as a whole. www.nasdbrokercheck.com The best available indicators of risk are the disclosure histories for reps and branches. NASD experts provided us with a weighting scheme for different disclosure types. Serious disclosures such as regul atory actions were assigned high weight while less serious disclosures such as customer complaints are given less weight. Since many disclosures with low weight may be as indicative of future misconduct as one disclosure with high weight, we combine all t he disclosure types into a risk score In a previous collaboration between UMass and NASD, it was shown that the social structure among reps was useful for detecting serious misconduct [8] . To better assess the strength of this inf luence among reps, this earlier work was limited to firms with fewer than 15 reps. In our current work, we seek to model firms of all sizes. Since the largest firms can employ hundreds if not thousands of reps, it is necessary to identify the meaningful sm all -scale social relations among many other incidental connections within firms. To provide the small -scale social structure we are seeking, we target two particular relations: (1) branch office affiliations and (2) tribes. Each firm typically spreads its business across many different branch locations. The branch locations must be reported to NASD; however, until recently firms were not required to report detailed branch affiliations for their reps. To identify branch affiliations, we utilized a standard consolidation and link formation technique [4] to link reps based on address es reported in their employment records (see Section 4 ). Since standard data pre -processing techniq ues are not well suited for detecting dynamic patterns , we developed a novel technique to find tribes by assessing the significance of overlap in job histories between two reps. (see Section 5 ).
 Because market conditi ons and corporate cultures vary widely across time and geography, it is imperative to adjust our risk measures to accurately reflect the risk environment in a particular branch or for a particular rep. For example, when the market is tight, firms may be u nder greater pressure to meet or surpass their goals. This pressure may manifest itself in an increased willingness to push the limits of misconduct. We show in Section 6 how normalization utilizing demographic and historical infor mation can be used to account for variations in the risk environment. To be of use to NASD, the risk dimensions of past behavior, social structure, and risk environment must be combined into an interpretable statistical model that captures the interaction s between these effects. We utilize a relational probability tree (RPT) for this purpose [7] . Along with identifying high -risk entities, we can use these models to evaluate the efficacy of our data -preprocessing techniques. The d etails of the RPT and results of our evaluation are described in Section 7. Since firms are often too large to develop an accurate view of the social relationships between brokers, we sought to link reps though employment at bra nch offices within each firm. Each employment record for a rep contained a self -reported address of employment. Unfortunately, since the addresses are self -reported, there were very few exact matches to known branch addresses necessitating the approach de scribed below. NASD recently began requiring firms to provide additional detailed information about branch affiliations and demographics , and we look forward to incorporating this information into future analyses.
 To get a  X  X uzzy X  match between reps and branches, we used an algorithm based o n string edit distance to determine the similarity between two addresses [6] . This algorithm assigns one point for each addition, subtraction, or substitution of a letter between the text strings. Since there are many ways to score points (e.g., a subtraction may look like many substitution s ), the string edit distance is the minimum possible score between two strings. We considered addresses in two p arts: (1) the street address and (2) city, state, zip. T here are a variety of ways to express standard street address components.  X  X orth X  may become  X  X  X ,  X  X . X  or even  X  X O X . A branch that is located on  X  X irst Street X  may have employ ees that report their address as  X 1st Street X ,  X  X irst St., X   X 1st St. X  etc. To account for these variations in street address, we started with the basic string edit distance and subtracted the difference in length for the two strings, effectively discounti ng the effect of abbreviations. We then divided the score by the minimum string length. The resulting score measured the percentage of characters that varied from one string to the second. Because the city -state -zip strings have fewer common abbreviatio ns, we chose not to subtract the difference in string length in this case. The intuition behind this is that any error in city, state, or zip code is probably a significant mismatch and should count for more. However, if the street address is identical b ut the city, state and zip are only slightly different then we would also like to match these addresses. To determine a final score we added the street score to the city score. If the final score was below our threshold of 0.28, then the addresses were a match. The threshold was chosen to minimize the number of false positives, i.e., distinct branches that are incorrectly grouped by the algorithm. Examples of this approach are shown in Table 1 .
 Using a threshold of 0.28, we were able to successfully match 70% (~3 .35 million) of the employment records to recorded branches. The remaining 30% (~1 .43 million) of employment records could not be matched to existing branches. A few possible causes for this i nclude branches that have moved locations over time, reps that report a home address or other non -branch address, data entry errors, or multiple addresses for the same location. In many cases there were many records with the same unmatched address. Using these unique addresses (as identified by our string matching algorithm), we inferred the existence of a branch at that address. We call these branches inferred branches . We then used our matching algorithm to match the remaining 30% of the records. Ther e were 431,895 branches recorded in the original data. To those we added 315,761 inferred branches, for a total of 747,656 branches. Of the 315,761 inferred branches, 158,438 have a single employee.

Table 1 : Example branch address matches produced by our 
Successful Matches From Algorithm (True Positives) 201 E. Main St., Washington, IN, 47501 201 E. Main St. Ste. 305, Washington, IN, 47501 201 E Main Street Suite 305, Washington, IN, 47501
Incorrect Non -Matches (False Negatives) 110 Wall Street , NEW YORK, NY, 10005 110 Wall Street , NEW YORK CITY, NY, 10005 110 Wall Street , 22ND FLOOR NEW YORK, NY, 10005
Correct Non -Matches (True Negatives) 110 Wall Street , MANHATTAN, NY 10005 110 Wa ll Street , BROOKLYN, NY, 10005 110 Wall Street , BOCA RATON, FL, 33432 In addition to the social structure provided by branch associations, we can utilize the dynamic nature of the data to identify other relations between reps. NASD e xperts have long suspected the existence of a pattern of behavior among reps where a group of high -risk reps, called tribes , will move together from branch office to branch office seeking  X  X reener pastures X  to continue their joint activities, which may inc lude perpetrating fraud. We developed a method to discover such tribes by identifying small groups that move together anomalously across multiple jobs.
 Reps can share multiple jobs by chance, due to firm acquisitions, and movement between firms and branch es in the same geographic region. We wish to factor out these trends to identify groups that stay together intentionally, sharing sequences of jobs that are unlikely to arise by chance alone. Of course, low -risk reps can also move together in groups; a gro up of friends might recruit one another as they move across the industry. To estimate the risk of the tribes we identify, we will use the risk scores on reps described in Section 6 . We expect a high -quality set of identified tr ibes to be homogeneous with respect to their risk scores, containing either mostly high -risk reps or mostly low -risk reps. For our purposes, a tribe is a group of reps that have significantly similar job sequences within the industry. The tribe -finding al gorithm is described in more detail in a separate paper [3] , but an overview follows. We enumerate all pairs of reps in the database that have ever worked together, and for each pair we record the jobs where they have intersecte d. Our task is to decide which pairs are interesting  X  ideally, to distinguish which reps are choosing to be at the same jobs, versus which reps just happen to intersect in their careers. Once we determine these significant pairs, we connect them to form tr ibes. The reps in a significant pair, plus any other reps connected to them through such pairs, are considered a tribe.
 We use a probabilistic model to decide which pairs are interesting (i.e., significant) under a null hypothesis of reps moving independe ntly. The key idea of the model is this: Some industry patterns are common, whether because they reflect typical career sequences, or else because whole branches may open, close, merge, or be bought. From the data, we estimate a model describing this backg round pattern of normal movement. For each pair of branches, it computes the percentage of reps that worked at one branch that eventually worked at the other branch as well. The employment data confirms that there are strong such trends among branches: Mo st small branches (90%), and many large ones (30%), are associated with some destination at which a majority of their employees later work. To score a pair of reps, we look at the sequence of jobs they share and calculate the likelihood of that sequence a ccording to the model. We set a threshold, depending on how many tribes we want to produce, and all pairs with scores beyond the threshold are rated significant.
 Since the real -world employment data has many instances of reps holding multiple jobs simultan eously, as well as gaps in employment records, the model was designed to handle these situations. It allows for situations where reps in a pair take any number of different jobs, then come back together. The model ignores employment durations and dates. Note that in computing probabilities, all that matters is the ordered sequence of jobs. We validated the tribes we identified using risk scores of reps and zip codes of branches. We found that the set of reps that are in tribes is strongly enriched for hig h -risk scores: For a set of tribes containing 1600 reps, the average risk score is 8.0, compared to a global average of 0.7. Pairs of reps that are rated significant are more likely to move geographically together than other pairs that overlap by chance: They work in jobs in an average of 2.85 different zip codes, whereas the average among all candidate pairs is 1.90. Finally, the tribes are homogenous for disclosure scores. The variance within each tribe is low (i.e., each tribe is homogenous), and the variance among (average) tribe scores is high (i.e., some tribes have high scores, while some have low). We established this by permuting the assignment of the reps within tribes, estimating p&lt; 0.001 for both measures above. Figure 3 displays the career histories of two potential tribes. Each of these tribes consists of a single pair of reps. The tribe in F igure 3 (a ) was scored as highly significant, while the tribe in F igure 3 ( b), even though it has a long history together, appears unremarkable and was scored as not significant. It is fortuitous that the brokers' start dates match, since the model does not take timing information into account. In the signifi cant case, we interpret the synchronized movements as evidence that the brokers are coordinating their job changes. However, for the case rated insignificant, it is more likely that these transitions are sudden mass movements. The brokers from the signif icant pair have disclosure scores of 18 and 24, respectively, primarily since in April 1996 they were both fired (disclosures show an Internal Review and a Termination for each). One of the brokers from the non -significant pair has no disclosures, while t he other was fired in 1997 for  X  X iversion of profitable trades to personal X  and received a score of 12 for this. In this figure, the names of the firms have been anonymized.
 Tribes can be useful for improving fraud detection in two ways. First, the tribes themselves, along with the corresponding risk scores, can direct NASD examiners towards groups of reps that merit investigation. It may also be possible to identify similarities among the tribes and identify possible tribes before branch movement is initi ated. Second, due to the homogeneity of the risk scores within a tribe, we would like to incorporate these tribe relations into a combined model of risk as described in Section 7 . We conducted a preliminary experiment to assess the value of using tribes to predict the risk scores of reps. First, we generated a large set of tribes, containing over 33,000 reps, by adjusting the significance threshold to be quite liberal. We converted the tribes into an attribute on reps by computi ng, for each rep, the average risk score of the other members of its tribe including past history up to but not including the current year. Then we constructed two training sets of reps. The first contained a mixture of reps with and without tribe attribut es and the second contained only reps with defined tribe attributes. Both training sets were constructed such that half of the reps were labeled  X  X igh -risk X  and the other half were labeled  X  X ow -risk X . The scores of simple predictive rules using only the tr ibe attribute are shown in Table 2 . T hese scores confirm that the tribes contain predictive information. Section 7 contains more information about the modeling process.

Figure 3 : Two examples of overlapping job histories indicative of tribes. (a) An example of a significant overlap in job histories (low background probability). (b) Example of non -significant overlap (high background probability). 
Names of fir ms have been anonymized. Firm sizes are in parentheses. Edge labels display transition percentages and start dates. Bold edges indicate both reps changing employment at the same time.
 In order to derive a measure of risk for reps and branches, we rely heavily on disclosure information. Disclosures are a useful indicator of risk since the y document and encapsulate past questionable behavior of reps. Individuals that have engaged in fraudulent activity in the past are more likely to exhibit similar behavior in the future than are those with a clean history. Similarly, branches that employ r eps with high risk should be deemed risky themselves. In other words, if many high -risk reps work at the same branch, then that branch might be more likely to be a source of fraudulent activity in the future. We developed a strategy to aggregate this inf ormation into a useful statistic and used this statistic to assign an appropriate normalized class label to reps and branches. Disclosures rates are highly variable among reps. Disclosures are never filed on the vast majority of reps while some reps have many disclosures. Additionally, the frequency with which disclosures occur varies across time, geography, and types of branches. We partitioned the set of reps and branches into categories based on these three attributes and computed a risk score on reps and branches normalized by their respective category. The first normalization category is temporal  X  by year. We limited the period under consideration to the years 1995 to 2005. This range was selected bec ause we are mostly concerned with the immediate past, and because NASD has initiated much more comprehensive oversight and data collection procedures over that time. Note that 2006 is not considered since we only have partial data for that year. Figure 4 illustrates the variability of disclosures by year and justifies the need for temporal normalization. The distribution is bimodal with peaks during 1996 -1997 and 2002. The second category for normalization is geographical location. We partitioned branches into ten geographical regions based on postal code. The first digit of a postal code represents a group of U.S. states that desi gnates a population region. In the event that a branch lacks this information, we assign the branch to a geographical location by taking the majority vote from the branch X  X  employees X  addresses. Figure 5 depicts a map of t he United States color -coded by our geographical categories. These location boundaries provide relatively equal numbers of branches within each geographical category. Note that since reps can work for multiple branches simultaneously, it is possible for a rep to appear in more than one locatio n.
 The third and final normalization category identifies types of branches. We considered two distinguishing features of branches: the size of the branch and the size of the branch X  X  firm (where size denotes the number of employed reps). The size of a branch/firm is the total number of unique individuals employed at the branch/firm within the period 1995 -2005. We construc ted partitions on these two dimensions that group branches according to size. Table 3 presents the branch typology along with the density of each class. Type 1 branches have a single rep associated with firms that employ no more than five thousand individu als. Type 2 comprises branches with a single rep for larger firms (more than five thousand reps). Types 3 and 4 contain medium -sized branches (two to one hundred employed reps), and type 5 encompasses all remaining large branches (employing more than one hundred reps). We have data on a total of 449,781 branches (both actual and inferred) that were open during our time frame, and the number of branches within each type varies. Additionally, for all branch types, we have a total of 2,329,113 distinct indi viduals that were employed in our time frame (see Table 3). Since reps can work for multiple branches simultaneously, it is possible for the same individual to appear under multiple branch types. This accounts for the larger number appearing in Table 3. W e found that roughly 28% of the employee count between 1995 -2005 is attributable to multiple employments. We address the problem of attributing disclosures of reps that work several jobs simultaneously below. Table 3 : Description of demographic categories for branches Branch Type We utilized a weighted disclosure score as a measure of risk for reps and branches. Based on input from experts at NASD, we assigned a weight to each disclosure type based on its relative severity. Regulatory action and termination disclosures are deemed the worst type of disclosure while a judgment lien is ignored entirely. To compute a risk score for a rep in a given year, we sum the weights of each disclosure attributed to the rep in that year. Branch scores are determined from the scores of all reps working at that branch.
 We assigned each branch to its appropriate normalization bin based on its branch type and location. Then, for each bin, we computed the disclosure scor e of each branch and rep as described above. This gives us distributions of rep disclosure scores and branch disclosure scores (averaged over employed reps) for each of our normalized categories of individual entities. Because an individual rep can work f or multiple branches concurrently, it is important to describe how we handle multi -branch employment of reps. For reps, we assign the score in its entirety, unless multiple branches are categorized into the same bin. For branches, we designate fractional d isclosure scores to each branch. This prevents reps from concealing their activity by working for many branches. Finally, we constructed a binary class label identifying entities as  X  X igh risk X  based on the normalized disclosure score. We compared the sco re of each entity to its expected distribution based on its normalization bin. Reps or branches were identified as being high risk (positive class label) if they satisfied the following two criteria simultaneously: These two criteria ensure that the rep or branch is among the worst of all similar entities, but in order to lim it the number, we required that they be worse than half of those entities with a non -zero score. However, if fewer than 5% of the reps in a category have scores above the median, we assign all the reps with scores above the median to the high -risk group. T he remaining reps and branches were assigned a  X  X ow risk X  label (negative class label). We present data for the normalized results for reps in 2005 in Figure 6. When looking at this figure, each number represents one of the normalized bins. The value of t he number indicates the bin X  X  geographical location, the shading of the number represents the branch type associated with the bin, and the size of the number is indicative of the median non -zero disclosure score for the bin. The position of each number is the log of the total number of reps in the bin against the percent of reps with the disclosure score. As an example, the 8 in the upper -left corner of Figure 6 r epresents the bin of small branches  X  small firms within the 8th geographical region. This num ber X  X  size is roughly average amongst the other numbers indicating that the median of the disclosure score for this bin is roughly average overall. This bin also has the highest percentage of reps with a disclosure score. The purpose of the evaluation described in this section is two -fold. We would li ke to demonstrate that we can automatically learn interpretable models of high -risk entities and we would like to demonstrate the effectiveness of our data processing approaches. We demonstrate the former by showing models automatically learned from data a nd demonstrate the latter by comparing our models to models learned for non -normalized class labels. This analysis was performed using P ROXIMITY source system for relational knowledge discovery designed and implemented by the Knowledge Discovery Laboratory in the Department of Computer Science at the University of Massachusetts Amherst . We u tilized the relational probability tree (RPT) algorithm to learn models of high -risk reps and branches [7] . The RPT is designed to automatically construct and search over possible aggregations of heterogeneous training data. In ge neral, instances drawn from relational data violate the independent and identically distributed (i.i.d) assumption common to most non -relational knowledge discovery techniques. The RPT applies standard aggregations COUNT, AVERAGE, MODE, etc. to effectively  X  X ropositionalize X  data before selecting features to be included in the model. To find the best feature, the RPT searches over values and thresholds for each aggregator. For example, if we are aggregating over disclosures filed on reps then we might co nsider a feature such as COUNT(Disclosure.type=Bankruptcy) &gt; 1 where the type and number of disclosures is determined by the algorithm.
 The RPT is a type of probability estimation tree for relational data [9] . A probability estimati on tree is similar to a classification tree, however the leaves contain a probability distribution rather than a class label assignment. Tree -based representations are often chosen for ease of interpretation and the ability to extract meaningful rules for future use. During the training phase, the RPT algorithm learns the probability distributions for each leaf and the features for each node in the tree. These tree models can then be applied to unseen test data to determine the performance of the algorithm . The class label we chose for our evaluation was the normalized class label described in Section 6 . As inputs, we use the attributes and structure of related entities in the network along with the intrinsic attributes on the rep or branch being evaluated. Since we are interested in predicting future behavior, our model uses information up to the present year to predict normalized class labels for the next year. Our training collection consists of reps and branches that were active in 2003 and 2004. We include past information up to and including 2003 as input to our model to predict high -risk status in 2004. The testing collection follows a similar protocol but for the years 2004 and 2005. The past information include s the class label from previous years.
 To generate the pool of instances from which to draw our training and test sets, we utilized the QG RAPH language implemented in P
ROXIMITY . QG RAPH is a graphical query language designed especially for querying large ne twork datasets [1] . The queries http://kdl.cs.umass.edu/proximity used to gather instances from the database for both reps and branches are shown in Figure 7 and Figure 8 , respectively. Each query re turns a portion of the entire data graph called a subgraph. These subgraphs define the related entities that are considered by the RPT for feature creation. For reps, we queried for only the reps themselves, their current branch affiliation, past branch a ffiliations (if any), and any disclosure history. For branches, we queried for the branch itself and all reps currently working at that branch and their work history (past branches and disclosures). By definition, our normalized class label can only occur on at most 5% of the reps or branches in a given bin. To avoid any floor effects due to such a high default accuracy, we created samples that contained all of the positive instances returned by our query and undersampled the negative class so that the sa mple contained an equal number of positive and negative instances. Provost and Fawcett show that this procedure does not significantly affect the rankings produced by the learned model [1] . We will evaluate our models primarily usin g the area under the ROC curve (AUC) metric. To maintain disjoint training and test sets, we removed any positive instances from the test set that also appeared in the training set. Negatives were also sampled to avoid overlap between training and test.

Figure 7 : QGraph query for reps. This query returns all reps their branch affiliation in the year t , any past branches they have also worked at, and any past disclosures filed on the rep. Figure 8 : QG raph query for branches. This query returns all branches active in the given year t , all reps working at that branch during that time, any past branches those reps have In order to assess the effect of normalization on our models, we considered two different class labels. The first class label is the normalized class label described in Section 6 . The second is a non -normalized class label that was based on t he top 5% of high -risk reps or branches without considering branch type and region. In addition, for each class label we considered two types of training sets for a total of four experiments each for branches and reps. We learned a single model trained on the combination of all the bins for both the normalized and non -normalized class label. We also learned a set of stratified models that were trained on each bin individually. Each of the RPTs was given attributes on reps (e.g., age, sex), branches, and disclosures (e.g., disclosure_type) as input. As described in Section 5, reps that were a part of a tribe had an additional attribute describing the average disclosure score of the other reps in the tribe. Although the tribe attributes are predictive of risk, none of these attributes were chosen in any of the models. We attribute this to the relative sparseness of tribes in the entire data. Tribes are definitely useful as a local pattern, but are not sufficiently strong to contribute to global models. An example of a learned tree model for reps using a normalized class label is shown in Figure 9 . The features selected in these trees include the past values of the class label and attributes on related entities such as disclosures and past branches. Specific thresholds and values have been removed to avoid revealing sensitive information. An example model for branches is not shown here, however the structure of the models and the features selected are similar to the rep model.
 ROC curves for our learned models are shown in Figure 10 . The performance of each of the models is summarized in Table 4 . The stratified models were combined from models learned on each bin individually. The stratified models perform worse than either of the mo dels learned across the entire data. The lack of calibration between the predicted probabilities of models learned on different bins would account for the poor showing on AUC when compared to models learned on the entire data set. Unfortunately, accuracy (ACC) scores also suffer with models learned on individual bins. We attribute this effect to the reduction in sample size resulting from the stratification. Most bins have only a few positive instances, making it difficult to learn a model that generali zes well to the test sample. The highest -risk branches according to the non -normalized class labels are single person branches with a small number of disclosures. This means that some branches with relatively minor disclosure problems are ranked very hig hly by the non -normalized disclosure score. Other branches, perhaps with a larger number of serious disclosures but also with a larger number of reps, are pushed further down the list due the average disclosure score being low. This is the ideal situatio n for normalization and our normalized class label is designed to capture this concept. The branches with serious disclosures should fall near the top of their respective bin and branches with only minor disclosures should fall near the bottom of their bin s. Assuming there are clear differences between the high -risk and low -risk branches, the normalized class label allows for a higher performing model. In contrast, modeling the non -normalized class label for reps produces models that perform as well the mo dels for the normalized class label. Since each rep is responsible for their disclosures, there is no need to average over multiple entities. Under these conditions, the high -risk reps, regardless of bin, should have high disclosure scores and be the mos t probable to have future serious disclosures. The effect of normalization in this case was to exclude reps that should have been high -risk based on raw disclosure score but did not receive a positive normalized class label because they were below the 95t h percentile in their bin.
 An interesting normalization approach to consider in the future would be to have a dynamic threshold for each bin. Rather than taking the top 5% of each bin, it would be possible to set a threshold based on the overall number of disclosures appearing in that bin. For example, since disclosures are more prevalent in the smaller branches we should consider a larger percentage of small branches as high risk when creating normalized class labels. By varying thresholds in this way, e ach bin receives the same weight in the normalized class label as it carries in the original data. This may lead to improvements in modeling high -risk individuals and branches.
 AUC ACC
Figure 10 : ROC curves for branches and reps. R esults are As our results from the previous section showed, past behavior, social structure, and normalized risk assessments can be used as a foundation from which to learn high -performing models from data automatically. As our learned models show, past behavior is a strong indicator of future risk. Features aggregating past normalized disclosure scores, past disclosures, and past branch history are prominent in the learned models.
 The identification of social structure was also useful in the modeling process. The branch entities created using consolidation and link formation techniques were foundational components in each aspect of our work. Despite not being chosen as a feature in our learned models, the groups of reps we identified as tribes intrigued the experts at NASD.
 Based on the results of our experiments, normalization should be used with care. Normalized class labels aided in the identification of high -risk branches and should be considered as a data pre -proces sing technique in the future. As we saw with the rep models, creating a normalized class label did not always improve the performance of the models. There is also the potential to increase the variance of the model when sample size is small, as we saw with our stratified models. In the future, we would like to develop additional methods to better utilize the temporal structure present in the data. It may be possible to improve tribe detection with a deeper understanding of the pa tterns of mergers and acquisitions among firms . An additional consideration for future research is performing collective inference with branch and rep models to better utilize the current estimates of risk to improve model performance. Fr om UMass, we thank Agustin Schapira for his technical assistance, Cynthia Loiselle for her writing and editing tips, and Jennifer Neville for advice on modeling. From NASD, we thank George Walz, Dipak Thakker, Lowell Cooper, and many others for their avail ability, insight, and subject matter expertise. This effort is supported by the National Association of Securities Dealers, through a research contract with the University of Massachusetts. It is also supported by the Central Intelligence Agency, the Natio nal Security Agency and National Science Foundation under NSF grant #IIS -0326249 . The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation hereon. The views and conclusions cont ained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements either expressed or implied, of the National Association of Securities Dealers, the Central Intelligence Agency, the Natio nal Security Agency, National Science Foundation, or the U.S. Government.
 Portions of this analysis were conducted using Proximity, an open -source software environment developed by the Knowledge Discovery Laboratory at the University of Massachusetts Amher st ( http://kdl.cs.umass.edu/proximity/ ). [1] Blau, H., Immerman, N., and Jensen, D. A Visual Language [2] Co rtes, C., Pregibon, D., and Volinsky, C. Communities of [3] Friedland, L., and Jensen, D. Finding tribes: Identifying [4] Goldberg, H. G. and Senator, T. E. Restructuring databases [5] Jensen, D. and Neville, J. Autocorrelation and linkage cause [6] Levenshtein, V. Binary Codes Capable of Corr ecting [7] Neville, J., Jensen, D., Friedland, L., and Hay, M. Learning [8] Neville, J., Simsek, O., Jensen, D., Komoroske, J., Palmer, [9] Provost, F. and Domingos, P. Tree induction of probability -[10] Provost, F. and Fawcett, T. Analysis and visualization of 
