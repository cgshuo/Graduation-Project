 In the past couple of decades, multidimensi onal index structures play a key role in modern database applications such as content based retrieval systems, sequence data retrievals, location based services, and so on. The applications are commonly required to manipulate multidimensional data. For example, content based retrieval systems store and retrieve multidimensional feature vector extracted by image and video. Also, location based services provide clients with the current locations of moving objects such as mobile phones. The locations of moving objects are represented as points in the two-dimensional space. To satisfy the requirements of the modern data-base applications, various multidimensional index structures have been proposed. There are space partitioning methods that divide the data space along predefined or predetermined lines regardless of data distributions[1, 3, 9]. On the other hand, data partitioning index structures divide the data space according to the distribution of data objects inserted or loaded into the tree[2, 4, 5, 6, 7]. Besides, Hybrid-tree[8] is a hy-brid approach of data partitioning and space partitioning methods, VA-file[10] uses flat file structure, and [11] uses hashing techniques. 
As mentioned above, many researchers have studied multidimensional index struc-tures to improve retrieval performance in various ways. However, there are bounds in improving retrieval performance with a single index structure. Also, for large amount data, a single index structure may show insufficient retrieval performance. To solve these problems, several index methods using parallelism of processors or disk I/Os have been proposed[12, 13, 14, 15, 16]. These parallel multidimensional index struc-tures can be classified into 1P-nD and nP-mD, where P and D are processor and disk, respectively. In 1P-nD architecture, multiple disks are connected to one processor so as to improve performance through parallel disk I/Os. However, there is only one channel between a processor and multiple disks so loading data to memory is proc-essed in serial. On the other hand, in nP-mD architectures, multiple disks are con-nected to multiple processors. Therefore, the index structures using this architecture exploit parallelism of processors and disk I/Os. 
In this paper, we propose a parallel multidimensional index structure that exploits the parallelism of the parallel computing environment. The proposed index structure is nP-n X mD architecture which is the hybrid type of nP-nD and 1P-nD. That is, there are multiple processors and each processor have multiple disks. Our node structures increase fan-out and reduce the height of an index tree. Also, range search algorithm that maximizes I/O parallelism is presented. To our knowledge, existing parallel mul-tidimensional index structures hardly consider k-NN(k Nearest Neighbor) queries. We propose new k-NN search methods suitable to our index structures. Through various experiments, it is shown that the proposed method outperforms other parallel index structures. 
The rest of this paper is organized as follows. In section 2, we describe existing parallel index structures. In section 3, we present the detailed description of our paral-lel high-dimensional index structure. In section 4, the results of performance evalua-tion are presented. Finally, we conclude in section 5. Existing parallel multidimensional index structures are classified into 1P-nD and nP-mD types. In 1P-nD architecture, multiple disks are connected to 1 processor so as to improve performance through parallel disk I/Os. MXR-tree[12] and PML-tree[14] are 1P-nD parallel index structures. These improve the performance of multidimensional index structures using the parallelism of disk I/O. MXR-tree proposed in [12] have one master server that contains all internal nodes of the parallel R-tree. The leaf level id) tuples for each global leaf level node. The leaf nodes of the global tree are distrib-uted across the other servers. The (site-id, page-id) is used to locate a page and server that contains the page. Once a query is sent to the master, the master searches the internal nodes of the MR-tree and produces a list of all (site-id, page-id) pairs needed. The constructed list and the query are sent to sites containing required pages. Each site then retrieves the page from disk and sends qualifying rectangles back to the master. In [12], the requirements for improving range searches are presented. The one is minLoad . When the load of processing queries is light, searchers should access as few nodes as possible. Consequently, queries with small selectivity should activate as few disks as possible. The other is uniSpread . Nodes that accessed by a query should be distributed over the disks as uniformly as possible. Consequently, queries with large selectivity should activate as many di sks as possible. Three approaches are pro-posed to distribute an R-tree over multiple disks. First approach construct d independ-ent R-trees. Second approach stripes super-node which consists of d pages on the d disks by striping pages. The last approach is MXR-tree (MultipleXed R-tree). In this approach, a single R-tree is constructed. Each node is spanned one disk page. Nodes are distributed over the d disks, with pointers across disks. 
PML-tree proposed in [14] uses native space indexing with a disjoint space de-composition method. The disjoint space decomposition method does not allow over-lapping intermediate MBR(Minimum Bounding Region)s. The PML-tree eliminates the extra search paths of the R-tree and the leaf node redundancy of the R+-tree by distributing data objects into multiple data spaces. Two data distribution heuristics, which distribute data over the multiple disks evenly, are proposed and implemented. 
These index structures improve search performance with exploiting disk I/O paral-lelism. However, there is only one channel between a processor and disks so loading data to memory is processed in serial. In the nP-mD architecture, multiple disks are connected to multiple processors. nP-mD parallel index structures are constructed based on special environments such as NOW(Network of Workstation). Therefore, nP-mD index structures can use parallelism of processors and disk I/Os. MR-Tree, MCR-Tree and parallel R-tree based on DSVM(Distributed Shared Virtual Mem-ory)[18], GPR-Tree and Parallel VA-file[17] are nP-mD parallel index structures. 
MCR-tree(Master-Client R-tree) proposed in [15] reduces communication mes-sages of MR-tree. One master and multiple clients are connected through computer network. The data structure of the master server is almost same to that of MR-tree, (MBR, site-id) pairs are needed at the leaf level of the master server. Each client there is redundant information stored comp ared to the MR-tree. This redundant in-formation reduces the overhead at the master and global communication costs. A query is sent to the master and is processed locally as in the sequential case. When a node. As soon as a client receives a request, it starts processing the query autono-mously. All data are retrieved and returned back to the master. The master adds the client site id to a list that keeps track of which clients are working on the query. Since the clients work autonomously, a maximum of one request is sent to each client. The master continues searching until either all clients are notified of the query or no more MBRs intersecting the query are found. The master then waits for answers and col-lects the qualifying data items sent back by the clients. In this section, we propose an index structure for the parallel processing of multidi-mensional data. The proposed index structure is nP-n X mD architecture which is the hybrid type of nP-nD and 1P-nD. That is, there are multiple processors and each proc-essor have multiple disks. Figure 1 shows the architecture of the proposed parallel index structure. Disks are grouped into the number of servers evenly. The groups are assigned to servers. One primary server coordinates search process and others are nor-mal servers that process index operations. R-trees are distributed to servers and each server including primary server has an independent R-tree. The R-tree of each server is distributed to multiple disks. We call this architecture as nP-n X mD type. We exploit the parallelism of CPUs and each CPU uses the parallelism of multiple disk I/Os. 
Each server manages a disk group and the disk group contains an independent R-tree. Figure 2 shows the R-tree of a disk group. As shown in the figure, a node in the index structure is distributed to disks in the group, i.e., a node consists of the pages of disks. An entry in the node contains child node X  X  MBR and the pointers of those pages that consist of the node. In the figure, the first entry of the root node points the node 1 . The node 1 consists of the first pages of disk A, B and C, so the entry must have the pointers of these pages and the MBR of the node 1 . 
The benefits of our architecture are as follows. First, similar data are declustered across multiple disks in the group. Since the entries in a node are distributed to multi-ple disks, declustering effects are maximized . Second, the height of index tree is re-duced. The size of a node is determined by the page size and the number of disks in the group. As the node size increases, it takes more time to load a node into memory. However, because the index structure can load the node in parallel, the loading time is not a problem. In R-tree family, overlaps between nodes reduce the retrieval perform-ance. The height of a tree is one of the factors to increase overlaps. As the height of a tree becomes higher, more overlaps may be caused. Finally, in multidimensional index structures, as the dimension increases the number of nodes to be accessed in-creases. That is, the number of node accesses is large when processing range search or k-NN search. Subsequently, in parallel multidimensional index structure, uniS-pread is much more important than minLoad . The proposed index structure read all pages that consist of a node, so it maximizes the uniSpread . 3.1 Insertion Figure 3 shows the process of entry insertion. Assume that we insert entries a, b, c, d, e, f, g and h sequentially. The entries are declustered across disk-groups in round robin fashion, i.e., a is inserted into disk-group 1, b is inserted into disk-group 2 and so on. Various declustering techniques have been proposed, but in high-dimensional data sets, the performance gap among them is not so large. Also, round-robin tech-nique is easy and cheap to implement. In that reason, we choose round-robin tech-nique as the declustering method. Entries a ssigned to each group are inserted into the index structure of the group. In the first phase, we find a proper node to insert a new entry. When a node is located, we check whether the node has enough space to ac-commodate the entry. Then, if overflow occurs, we start split process. 
When processing node split, we need to carefully allocate pages for newly created node. In general, nodes in multidimensional index structures are not always full. Con-sequently, we cannot fully obtain disk I/O parallelism when accessing index nodes. To relieve this problem, we place the pages of two nodes (old node and new node) in different disks as much as possible so as to increase disk I/O parallelism when proc-essing range search. We will describe our range search algorithm in the next section. smallest number of allocated pages. In the lower figure, disk D and E have the small-est number of allocated pages, so pages for node 2 and node 3 are allocated from these two disks. First, we allocate three pages from D, E and A sequentially, and then allocate three pages from B, C, and D sequentially. 3.2 Search 3.2.1 Range Search Range search algorithms for multidimensional index structures have been mentioned in several researches [3, 6]. Searchers take multiple paths when processing range search. That is, multiple nodes may be selected as next nodes to visit. Existing range search algorithms visit the selected child nodes sequentially. Figure 5 shows the proc-ess of existing range search algorithms. A searcher chooses entries 2, 4 and 7 from root node that are overlapped with the sear cher X  X  predicate. The searcher visit child nodes that are pointed by 2, 4 and 7 sequentially. To read node 2, the searcher must access disk A, D and E since the pages of node 2 are distributed disk A, D and E. In the sum of the number of disk accesses to read root node and leaf nodes. The number of disk accesses to read root node is 1 and that of leaf nodes is 3. Therefore, the total number of disk accesses to process the range query is 4. Our new range search algorithms use diff erent approaches to load child nodes. Once child nodes to visit are determined, we make a page loading plan according to which disks are involved to load child nodes. Figure 5 describes how to make the page loading plan. In the figure, A3 means third page of disk A . There are 8 pages to be read. We cluster these pages into groups consists of pages from different disks. For that those pages can be read at one I/O time. Also, A5, D4 and E2 in GRP2 are from only two disk I/Os are needed to load leaf nodes. One disk I/O is saved compared to the previously mentioned method. 3.2.2 k-NN Search Existing parallel multidimensional index structures hardly consider k-NN search. However, k-NN queries are important in modern database applications. In this paper, we propose three k-NN algorithms and through experiments we show which one is the best. In the first method, the primary server distributes a k-NN query to servers and each server processes the k-NN query independently. Then, the servers return the k results to the primary server. The primary server filters the results from servers and makes final k results. The response time is the sum of the longest time among servers X  response time and the time to filter servers X  results. This method is simple and easy to implement. However, we may not use disk I/O parallelism like our range search algo-rithm because of the properties of the k-NN algorithm. When processing range search, a searcher chooses all child nodes to visit next that are overlapped with query predi-cates before going down to next level. Therefore, we can make a page loading plan and save disk I/Os. However, in the existing k-NN search algorithm, all child nodes to visit next are not determined definitely but just one child node is determined. Conse-quently, we cannot make a page loading plan as in our range search algorithm. 
In the second method, the primary server transforms k-NN queries to range que-ries. Once a k-NN query is arrived from client, the primary server processes k-NN query partially. When the primary server gets first k results, it calculates the distance between k X  X h element and query point of the given k-NN query. It makes a range query with the distance. The range query is distributed to servers and the servers process the range query and return results. The primary server gathers the results from servers and makes k results. The time to process k-NN query partially is quite short. Since servers can process the transformed range query, this method can get parallel-ism of range search algorithm. However, the transformed range query may become larger and reduce the overall performance. 
In the third method, once the primary server receives a k-NN query from clients, it sends the query to all servers. The servers execute partial k-NN queries with the re-ceived query, transform the k-NN query to range query similar to the primary server of type 2 and return the transformed range query to the primary server. Then, the primary server redistributed the transformed query to servers. The servers process the range query and return their results to the primary server. Finally, the primary server makes k results from server X  X  results. 4.1 Experimental Setup The simulation platform is Sun Enterprise 250 with 1GB main memory and Solaris 2.7. Simulation programs are developed with gcc 2.8 compiler. We use uniformly distributed 100,000 data with 10 ~ 80 dimensions. N da means that the total number of disk accesses to perform a query. Assume that the number of disk accesses to read pages in parallel from different disks is 1. The response time to process a range query and type 1 k-NN query is calculated by the equation, max(RT i ) + filtering time + total from server and make final results and total message size is the size of total commu-nication messages between the primary server and each server. The response time of type 2 and 3 k-NN queries is calculated by the following equation, query transform time + response time of a range query . The query transform time of type 2 is calcu-query. The query transform time of type 3 is calculated by the equation, max(RT i for partial k-NN query) + filtering time + total message size X  T comm , where i = 0~ N server . We assume the value of T comm and T diskIO as in Table 1 according to [18]. 
We measure response time and total number of disk accesses of a query to compare the retrieval performance of our index structure with existing parallel multidimen-sional index structures. We perform several experiments in various environments. We present the results of experiments with varying dimension, the number of disks and page size. We compare our proposed index structure with MCR-tree. To our knowl-edge, the MCR-tree is the most recently proposed nP-mD parallel index structure and shows best performance among existing parallel multidimensional index structures. Table 1 shows simulation parameters. 4.2 Performance Evaluation Results We perform experiments to measure the response time and the disk accesses of k-NN queries and range queries with varying dimensions from 10 to 80, page sizes from 4k ~ 48k and disks from 3 ~ 15. Figure 6 to 8 show the response time and disk accesses of range searches and three types of k-NN searches. The graph of k-NN type 1 is omitted from the following charts since the performance gap of k-NN type 1 and others is too large to present in the charts with others. We carefully observe the per-formance of three k-NN queries. From the performance evaluation, we could con-clude that our proposed k-NN search algorithms outperform the existing k-NN search algorithm (k-NN type 1). Also, as shown in the figures, the k-NN type 2 out performs slightly the k-NN type 1. The reason is that even though the selectivity of transformed range query in the k-NN type 3 may be smaller than that in the k-NN type 2, k-NN type 3 requires more communication messages and more CPU time to gather and filter results from the servers. 
We perform various experiments to measure disk accesses and response time of the range search operations of MCR-tree and the PR-tree with varying the number of disks from 3 to 15. As shown in Figure 9, the PR-tree outperforms MCR-tree in all cases. In the MCR-tree, each server and client construct R-trees on one disk. How-ever, we present an architecture that servers builds R-trees on multiple disks. Also, our new range search algorithms improve the disk I/O parallelism. 
The Table 2 shows the results of performance comparisons between k-NN search algorithms of PR-trees and MCR-trees. As shown in the figures, PR-trees outperform MCR-trees about 3 times when comparing only k-NN search algorithms. In MCR-trees, there is only one global R-tree that contains only internal nodes and leaf nodes of the global R-tree are organized as R-trees in multiple clients. k-NN search algo-rithms require searchers to take paths down ward and backward repeatedly. Therefore, communication messages between master and clients increase. Also, since our k-NN algorithms is to transform k-NN queries to range-queries, searchers get improved disk I/O parallelism as described in the previous section. We proposed an efficient parallel multidimensional index structure. The proposed index structure is nP-n  X  mD structure that combines 1P-nD structure with nP-nD structure. We present new range search algorithms that more efficiently use disk I/O parallelism. Even though the k-NN search are one of the important query type in mul-tidimensional index structures, researches on improving k-NN search performance in parallel multidimensional index structures are hardly noticed. We present a new k-NN search algorithm that improves the disk I/O parallelism. Through various experi-ments, we prove that our proposed index structure outperforms exiting parallel multi-dimensional index structures. This work was supported by the Regional Research Centers Program of the Ministry of Education &amp; Human Resources Development in Korea. 
