 Despite the widespread use of BM25, there have been few studies examining its effectiveness on a document descrip-tion over single and multiple field combinations. We deter-mine the effectiveness of BM25 on various document fields. We find that BM25 models relevance on popularity fields such as anchor text and query click information no better than a linear function of the field attributes. We also find query click information to be the single most important field for retrieval. In response, we develop a machine learning approach to BM25-style retrieval that learns, using Lamb-daRank, from the input attributes of BM25. Our model significantly improves retrieval effectiveness over BM25 an d BM25F. Our data-driven approach is fast, effective, avoids the problem of parameter tuning, and can directly opti-mize for several common information retrieval measures. We demonstrate the advantages of our model on a very large real-world Web data collection.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval I.2.6 [Artifical Intelligence]: Learning General Terms: Algorithms, Experimentation, Theory. Keywords: Web Search, Retrieval Models, Learning to Rank, BM25.
BM25 [15] is arguably one of the most important and widely used information retrieval functions. BM25F [16] is an extension of BM25 that prescribes how to compute BM25 across a document description over several fields. A chal-lenge to using BM25 and BM25F is the necessity of tuning 2 K +1 parameters for a document description over K fields. Tuning can be accomplished using grid-search or gradient descent [21]. Each method has its drawbacks; grid-search can be prohibitively slow when the data collection is large, while gradient descent [21] is much faster but does not op-timize parameters directly for a target measure.

Recently, it has been shown that LambdaRank [2] is em-pirically optimal [7, 25] for NDCG and other IR measures. We could extend the approach in [21] to use LambdaRank to optimize the BM25 parameters for a chosen IR measure, but the function is still restricted to the BM25 model. Instead, we build upon LambdaRank to develop a machine learning approach to BM25-style retrieval. Our model can be used as a framework for learning other functions and offers value in the design of future information retreival systems. Our primary contributions are threefold (see [20] for details) : (1) We empirically determine the effectiveness of BM25 for dif-ferent fields. Although BM25 is effective on the title and URL fields, we find that on popularity fields it does not per-form as well as a linear model. (2) We develop a data-driven machine learning model called LambdaBM25 that is based on the attributes of BM25 [15] and the training method of LambdaRank [2]. Our model is both fast and simple; it does not require parameter tuning and is an extension of a state-of-the-art ranking approach. It also directly optimizes fo r several IR measures [7, 25]. (3) We extend our empirical analysis to a document description over various field combi-nations. We confirm that BM25F [16] is better than a linear function of BM25 scores. We extend our model to document descriptions over field combinations and find it consistentl y outperforms BM25F with statistical significance.
There have been a number of approaches to document re-trieval ranging from simple to complex models [12, 13, 22]. BM25 [15] is based on a probabilistic information retrieval model [19] which incorporates attributes of documents, suc h as term frequencies, document frequencies, and document length. BM25F is a simple extension of BM25 for combining attributes across multiple fields [16]. A drawback of BM25 and BM25F is the difficulty in optimizing the function pa-rameters for a given information retrieval measure. There have been extensive studies on how to set term frequency saturation and length normalization parameters [17, 9, 21] .
Recent studies demonstrate the effectiveness of query click data for ranking [1, 6, 8, 24]. However, to our knowledge, there is no detailed study of the effectiveness of BM25 on single document fields or on subsets of document fields, in-cluding anchor text and query click logs. In addition, we are unaware of efforts to develop a directly analagous re-trieval model based on the same attributes as BM25. Our work provides both an extensive study of the contributions of different document fields to information retrieval and a framework for improving BM25-style retrieval.
A Web document description is composed of several fields of information. Field information is preprocessed by remov -ing punctuation, converting to lowercase, and removing htm l markup. We consider a query q to be composed of at most 10 terms. The document frequency for term t is the number of documents in the collection that contain term t in their document descriptions. Term frequency is calculated per term and per field by counting the number of occurrences of term t in field F of the document. Field length is the number of terms in the field.

Content fields include the body text (the html content of the page), the document X  X  title (indicated through html &lt; TITLE &gt; tags), and the word-broken URL text. Popular-ity fields include anchor text and query click information. Unlike content fields, popularity fields are not written or controlled by the document X  X  owner, but rather are an ag-gregation over information about the page from many au-thors. The anchor text field is composed of the text of all incoming links to the page. We denote the field as a set of unique anchor text strings and the corresponding num-bers of incoming links with that string. The query click field is built from query session data [1, 8, 11] (see [8] for details) extracted from one year of a commercial search en-gine X  X  query log files and is represented by a set of query-score pairs ( q, Score ( d, q )), where q is a unique query string and Score ( d, q ) is derived from raw session click data as Score ( d, q ) = C ( d, q, click ) +  X   X  C ( d, q, last click ) where C ( d, q ) is the number of times d is shown to the user when q is issued, C ( d, q, click ) is the number of times d is clicked for q , and C ( d, q, last click ) is the number of times d is the temporally last click of q .  X  is a scaling factor and can be tuned. The term frequency of term t for the query click field is calculated as P p | t  X  p Score ( d, q ), where p is the set of query-score pairs.
BM25 [15, 19] is a function of term frequencies, document frequencies, and the field length for a single field. BM25F [16] is an extension of BM25 to a document description over multiple fields and reduces to BM25 when calculated over a single field; we refer to both functions as BM25 F , where F is a specification of the fields contained in the document description.

BM25 F is computed for document d with description over fields F and query q as: S = P t  X  q T F t  X  I t . The sum is over all terms t in query q . I t is the Robertson-Sparck-Jones inverse document frequency of term t : where N is the number of documents in the collection, df is the document frequency of term t . We calculate document frequency over the body field for all document frequency attributes 1 . T F t is a term frequency saturation formula:
We also used the whole document description, but found little difference in accuracy over using only the body field. T F t = f k + f , where f is calculated as tf
F is the term frequency attribute of term t in field F , k is the saturation parameter, and w F is a field weight parameter.  X  F accounts for varying field lengths:  X  F = (1  X  b F ) + b F (  X  F /avg X  F ), where b F is a parameter between 0 and 1,  X  F is the length of the field, and avg X  F is the average length of the field in the document collection.

BM25 F requires the tuning of 2 K + 1 parameters, when calculated across K fields, namely k , b F , and w F . Tuning can be done using grid-search or gradient descent [21]. In our experiments, we tuned the parameters of BM25 F using grid search over 10K queries and for K &gt; 3, it took over 2 weeks to complete on an Intel Xeon 2.93GHz processor with 127GB of RAM.
We now describe our simple machine learning ranking model that uses the input attributes of BM25 F and the training method of LambdaRank. LambdaRank [2] is a state-of-the-art ranking algorithm that optimizes for IR m ea-sures. For complete details, see [2]. LambdaRank is both a list-based and a pair-based neural network learning algo-rithm and is an extension of RankNet [3]; it is trained on pairs of documents per query, where documents in a pair have different relevance labels. In most machine learning tasks, a target evaluation measure is used for evaluation and an optimization measure, generally a smooth approx-imation to the target measure, is used to train the system. Typical IR target costs are either flat or non-differentiable everywhere, thus direct optimization of the target measure is quite challenging. LambdaRank [2] leverages the fact tha t neural net training only needs the gradients of the measure with respect to the model scores, and not the function itself , thus avoiding the problem of direct optimization. The gra-dients are defined by specifying rules about how swapping two documents, after sorting them by score for a given query, changes the measure. The gradient definition is general and can work with any target evaluation measure.

There are several challenges to using BM25 despite its strong retrieval capacity, including the requirement of pa -rameter tuning, the inability to directly optimize for an IR measure, and the restrictions of the underlying probabilis tic model. We directly address these challenges by introducing a new machine learning approach to BM25-like retrieval calle d LambdaBM25, which is trained over a large data collection using LambdaRank due to its flexibility, ease of training, and state-of-the-art ranking accuracy. BM25 can be pro-hibitively expensive when trained on a document descrip-tion over many fields, especially with the growing use of anchor text, click information, and other metadata. Lambd-aBM25 does not require parameter tuning since the function is learned directly from the train collection and can optimi ze for several IR measures [7, 25].

LambdaBM25 has the flexibility to learn complex relation-ships between attributes directly from the data, for exampl e if documents tend to be verbose or elaborative, while BM25 is limited to a predefined probabilistic model. Our model has the additional advantage that it does not require that the attributes be statistically independent, as in [19].
We recognize that in learning our model directly from a large data collection, we lose the probabilistic interpret ation inherent to BM25. However, our model has an additional advantage in that it is very flexible, and can be extended to include other fields in the document description as new fields become available.

We develop our model as follows. We train our model us-ing LambdaRank and the same input attributes as BM25, namely term frequency, document frequency, and field length , for each field included in the document description. Al-though we could include additional attributes, we would lik e to maintain a fair comparison to the BM25 retrieval function because it is so widely used. We train single-and two-layer LambdaRank neural nets to optimize for NDCG with vary-ing numbers of hidden nodes chosen using the validation set.
We evaluate our method on a real-world Web-scale data collection containing English queries sampled from query log files of a commercial search engine and corresponding URLs. We perform stopword removal and some stemming on queries. Our train/validation/test data contains 67683 /11911/12185 queries, respectively. Each query is associa ted with on average 150-200 documents (URLs) together with a vector of feature attributes extracted for the query-URL pair. Each query-URL pair has a human-generated label between 0, meaning d is not relevant to q , and 4, meaning document d is the most relevant to query q and 0.
We evaluate using Normalized Discounted Cumulative Gain (NDCG) [10] at truncation levels 1, 3, and 10. Mean NDCG is defined for query q as where N is the number of queries, l ( r )  X  X  0 , . . . , 4 } is the rel-evance label of the document at rank position r and L is the truncation level to which NDCG is computed. Z is chosen such that the perfect ranking would result in NDCG@ L q = 100. A significant difference should be read as significant at the 95% level using a t-test.
In all experiments, the parameters of BM25 F are tuned to optimize NDCG@1 on our validation set (it was pro-hibitively slow to tune on the train set) using a 2 K -D grid search as in [21]; we consider 1000 epochs or convergence of NDCG@1 as the stopping criterion. Parameters found are listed in the extended technical report [20]. We also tried an approach similar to the gradient-based approach in [21] and found results to be almost identical.

We first determine which single field is the most effective in terms of ranking using BM25 F . In the upper first three columns of Table 1, we report results for BM25 F on a doc-ument description restricted to a single field. We find Title (T), URL (U), and Body (B) are equally effective and pop-ularity fields achieve higher NDCG. In particular, the query click field achieves the highest NDCG accuracy.

We next compare BM25 F to single-layer LambdaBM25 F on a single field F . Since BM25 F is highly nonlinear, we expect it to outperform a simple linear combination of in-put attributes. Our linear model cannot, for example, divid e term frequency by document frequency or field length; these two operations have been shown to give improved retrieval accuracy [19]. In all experiments, we choose the best train-ing epoch and learning rate based on the validation data which is a learning rate of 10  X  5 and 500 epochs. Table 1 contains results for single-layer LambdaBM25 F . For content fields, we find that BM25 F is significantly better than a linear combination of input attributes since BM25 F was designed for improved accuracy over a linear term fre-quency function when using content fields. For popularity fields, on the other hand, our single-layer LambdaBM25 F model performs similar to or better than BM25 F . Such re-sults were hypothesized in [21]; since popularity fields dra w content from authors other than the document X  X  owner, it seems reasonable that the BM25 function, which was built for content fields, may not model the data much better than a linear function of input attributes.

Finally, we train our two-layer LambdaBM25 F model and determine if it can outperform BM25 F . Results are shown in Table 1. We find the following numbers of hidden nodes to be best: Title (10), URL (15), Body (15), Anchor (15), Click (5). We find that for the Body, Anchor, and Click fields, LambdaBM25 F outperforms significantly BM25 F ; BM25 F appears to model short, succinct, non-repeatable fields wel l, but fails to model longer fields with similar accuracy. As the length of the field grows, it is beneficial to learn richer relationships between term frequency, document frequency , and field length, which LambdaBM25 F is able to do.
We next seek to determine the most effective combination of fields to include in the document description for BM25 The first three lower columns of Table 1 list the results of BM25 F on various field combinations. We find that using multiple fields in the document description is superior to us -ing a single field, unless that single field is the query click field; the only combination of fields to outperform BM25 C are combinations that include the query click field. Note that the addition of anchor text to the C,U,T,B combina-tion yields an insignificant improvement in accuracy, but when query click information is not available, the anchor field yields significant accuracy improvement between the U,T,B and A,U,T,B field combinations.

To determine if BM25 F is better that a linear function of input attributes, we learn single-layer LambdaBM25 F mod-els for each combination of fields. As shown in the lower middle columns of Table 1, we find that BM25 F performs as well or better than single-layer LambdaBM25 F for all field combinations; our results confirm that a linear combination of fields is insufficient for good retrieval accuracy [16].
Finally, we train our two-layer LambdaBM25 F models us-ing 15 hidden nodes. For every field combination, as shown in Table 1, LambdaBM25 F achieves gains with statistical significance over the corresponding BM25 F model. For com-binations that include popularity fields, we see even more substantial gains over BM25 F .
Our main contribution is a new information retrieval model trained using LambdaRank and the input attributes of BM25 called LambdaBM25 F , which significantly improves retrieval effectiveness over BM25 F for most single-field, in particu-lar popularity fields, and all multiple-field document de-scriptions . LambdaBM25 F optimizes directly for the cho-sen target IR evaluation measure and avoids the necessity Table 1: Mean NDCG accuracy results on the test set for BM25 model. Parentheses indicate no statistically significant d ifference. of parameter tuning, yielding a significantly faster approa ch. Our model is general and can potentially act as a framework for modelling other retrieval functions.

In the future we would like to perform more extensive studies to determine the relative importance of attributes in our model. We would also like to determine the effectiveness of LambdaBM25 as a scoring function, where the scores can be used as inputs to a more complex ranking system, for example as a single feature in recent TREC retrieval sys-tems [5, 4]. Finally, we plan to expand our model to learn proximity relationships and determine if incorporating su ch features can learn a better function than, for example, the proximity models given in [14, 18].
