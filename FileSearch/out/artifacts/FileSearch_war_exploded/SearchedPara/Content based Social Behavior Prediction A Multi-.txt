 The study of information flow analyzes the principles and mechanisms of social information distribution. It is becom-ing an extremely important research topic in social network research. Traditional approaches are primarily based on the social network graph topology. However, topology itself can not accurately reflect user interests or behavior. In this pa-per, we adopt a  X  X icroeconomics X  approach to study social information diffusion. In particular, we aim to answer the question that how social information flow and socialization behaviors are related to content similarities and user inter-ests. We study content-based social activity prediction, i.e., to predict a user X  X  response (e.g. comment or like) to their friends X  postings (e.g. blogs) w.r.t. message content. In our solution, we cast the social behavior prediction problem as a multi-task learning problem, in which each task corresponds to a user. We have designed a novel multi-task learning al-gorithm for predicting information flow in social networks. In our model, we apply l 1 and Tikhonov regularization to obtain a sparse and smooth model in a linear multi-task learning framework. With comprehensive experiments, we have demonstrated the effectiveness of the proposed learning method.
 H.2.8 [ Database Management ]: Database Applications-Data Mining Algorithms, Experimentation Multi-task Learning, Social Networks, Heterogenous Struc-tured Tasks, Regularization
The study of information flow is to analyze the principles and mechanisms of social information distribution, which is an essential research topic in social networks [14, 26]. Full understanding and control of information flow in social net-works is essential for a number of tasks, including efficient emergency notifications (e.g. [30]), personalized advertis-ing/recommnadation and stopping rumor dissemination.
Most of the existing approaches on network information flow are based on the social network graph topology [16, 24]. For instance, maximum flow and betweenness central-ity are the basic measurements employed to assess overall information flow and nodes X  specific contributions to it [28]. However, topology itself can not accurately reflect the user interests or activities. It has been widely observed that it is more likely for a message to propagate between users that are mutually interested in the message.

Recently [22] performs a large scale trace on information diffusion in Twitter, and discovers that there are fundamen-tal differences of diffusion behaviors across different topics. The phenomena discovered in [22] further confirms that in-formation content plays a major role in social information flow. However, [22] did not provide a solution of how to quantitatively model or predict social information diffusion process with regard to information content.

In this paper, we adopt a  X  X icroeconomics X  approach to study social information diffusion and aim to answer the question that how social information flow and socialization behaviors are related to content similarity and user inter-ests. In particular, we study content-based social activity prediction, i.e., to predict a user X  X  response (e.g., comment or like) to their friends X  postings (e.g., blogs, tweets). In our solution, we cast the social behavior prediction problem as a multi-task learning problem, in which each task corre-sponds to a user. Similar to traditional supervised learning algorithm, the information content (i.e. sample) is repre-sented as a high dimensional feature vector and its labels indicate the users X  responses towards the information. We choose multi-task learning as the starting point of our inves-tigation since MTL boosts the generalization performance by learning several related tasks simultaneously [3, 10, 15, 23].

Our contributions in this paper are multifaced. At the conceptual level, we take the first step to model social net-work information flow w.r.t. information content in social networks. For modeling algorithms, we formalize the related modeling problem as a multi-task learning problem and pro-vide a novel algorithm specifically designed for learning with information flow in social networks. To our best knowledge, we present the first case of developing and applying multi-task learning to the social behavior prediction. Finally we have derived a practical solution based on an advanced op-timization technique. Experiment results show that our ap-proach significantly improves prediction accuracy using real world data sets.

The rest of the paper is organized as following: we first introduce related works in Section 2. We formalize the prob-lem, and describe the details of our model in Section 3. We present the experimental results in Section 4, and finally conclude the paper.
There are tremendous studies on how information is dis-tributed in social networks through user socialization activ-ities [1, 16, 17, 24, 31]. In particular, [16] provides an algo-rithm to select a subset of nodes whose information adoption activities can trigger a large cascade of information flow. [17] studies Internet chain-letter data, and finds that the letters spread in a  X  X arrow but very deep tree-like pattern X , instead of spreading widely. [24] models social information flow with a diffusion-rate based model and continuous-time Markov chain. While most existing approaches model in-formation diffusion using graph topology (i.e. information follows the links to propagate from nodes to neighbors), [31] takes a different route that models information flow based on observed infection history. Last but not least, from the social science perspective, different types of social relation-ships (e.g. strong ties vs. weak ties) [13] have been used to study information flow.

On the other hand, multi-task learning (MTL) has been widely investigated from different researchers and aspects, hence it is impossible to cover all the related works in depth and we only discuss these works that are related to our method. Multi-task feature learning [2, 18, 19] assumes all the tasks are uniformly related, and aim to learn a common low dimensional representation without actually learning the task relationships. MTL with known task relationships [10, 15] utilizes the prior knowledge on task relationships to learn model parameters so that simila r tasks share similar param-eters. They use all the features to build MTL model, hence they are not suitable for high dimensional data. Besides, the task relationship is homogenous.

Though information flow analysis and MTL have been studied for a long time, none of the existing method consid-ers formalizing the content based information flow analysis as MTL problem while considering the heterogenous social relationships. The objective of this paper is to incorporate the heterogenous relationships on tasks into MTL and build a more accurate and interpretable prediction model.
We formalize the user behavior prediction problem with the following model. Considering a social network with mil-lions of users, we focus on one user, i.e. the  X  X eed X  user. We represent each article published by the seed user using a bag-of-words model, where features are terms extracted from all the articles the seed has published and the value of a feature is the TF-IDF weight. There are a group of users who actively receive articles published by the seed (i.e. the  X  X ollowers X  of the seed). We treat each follower as a learn-ing task. If the follower performed an action on an article (e.g. writing comments about the article), we record the user response as positive (1). Otherwise, the user response is negative (-1). Figure 1 illustrate this data representation approach.
In adopting MTL for social behavior prediction, the major challenge is to group tasks (followers) with similar charac-teristics. We have three possible strategies: (1) group all tasks in a single group and totally ignore the possible differ-ence of tasks [7, 9, 18]; (2) use social network topology to model tasks relationships; (3) use previous history of tasks to estimate the possible structure of tasks.

In our experimental study, we have implemented all three strategies and done a case study as shown in Table 2. Our results show that the third strategy is the best over all, which demonstrates that the social network topology itself cannot accurately reflect user interests or behavior. For example, in Figure 1, we show three users. Clearly F 1 and F 2 are somehow related since they are follower of each other. Af-ter a careful investigation, we conclude that F 1 and F 2 following each other is due to the fact that both of the users are active in reading and posting entertainment related ar-ticles. Following this observation in our multitask learning practice, if our objective is to model the information flow for entertainment related articles, F 1 and F 2 should be group together due to the common interest. However, if our objec-tive is to model the information flow for technology related articles, F 1 and F 2 have quite different interest. Learning F 1 and F 2 together will confuse any learning algorithm. Figure 1: Data Representation of the frmaework. Five
In summary, we observe that the relationship between tasks in social networks is multilayered in the sense that the relationship may change based on the information con-tent. Based on the observation, we have designed a multi-graph representation of task relationship. With the multi-graph representation, we have modified an existing MTL algorithm by incorporating additional constraint based on the multigraph representation of task relationships and in-vestigated the related optimization techniques. In the fol-lowing subsections we elaborate the description by focusing on four important problems: (i) content based task simi-larity definition, (ii) multigraph representation of task sim-ilarity, (iii) MTL with multigraph constraints, and (iv) ef-ficient optimization. Before we present our model, we list Figure 2: Heterogenous social relationships between F 1 , notations in this paper. We use lowercase letters to repre-sent scalar values, lower-case bold letters to represent vec-tors (e.g. a ), uppercase bold letters to represent matrices (e.g. A ), Greek letters {  X ,  X  1 ,  X  X  X } to represent Lagrange multipliers, and uppercase calligraphic letters to represent sets. We use A 1 = p i,j | a ij | to denote the l 1 norm of A , &lt; A , B &gt; = tr ( A T B ) to represent the inner product be-tween two matrices where tr ( . ) is the trace of matrix. Fur-thermore, given matrix A  X  R p  X  k , A i, : is the i th row and A : ,j is the j th column. Unless state otherwise, all vectors in this paper are column vectors.
Formally, suppose we are given k users (tasks) { T i } k i =1 For the i th user T i , the training set D i consists of n articles (samples) ( x i j ,y i j ), j =1 ,  X  X  X  ,n i ,where x i j  X  X  p y j  X  X  X  1 , 1 } for the user X  X  response T i on article x i j simplicity, we assume all the tasks have the same number of training samples. The goal of the modeling practice is to learn a function f i ( x ) to map the content of the article to the user response, where f i ( x )= w T i x . The learning task is to seek W =[ w 1 , w 2 ,  X  X  X  , w k ]with w i corresponding to the i th user by solving min W k i =1 n j =1 ( y i j ,f i paper, we use linear regression with least square loss function ( y i j ,f i ( x i j )) = 1 / 2( y i j  X  f i ( x i j )) 2 which is equivalent to a linear discriminant analysis (LDA) for binary classification [12]. Such a procedure is also widely used in other MTL algorithms for classification [6, 18, 32].
The above objective is ill-posed for high dimension low sample size problems. To remedy the problem, we add l 1 regularization [25] on W to stabilize it and obtain a sparse solution. However, the resulting model neglects the het-erogenous structural relationship among tasks, which we will address in the following sections.
With the heterogeneity of social networks, we cannot rely on network topology as we discussed in the introduction sec-tion, but have to consider the information content. Addi-tionally, in order to build a more interpretable model, we expect the users that share the same interest will have sim-ilar prediction models when seeing the articles from their favorite information categories.

We collect followers X  actions to quantify the similarity be-tween two users. More specifically, for each follower, we build an activity profile for each content category and cal-culate pair-wise user similarity as:
Definition 3.1. Suppose that the data set contains k users and covers t categories with q possible actions in the social network (excluding no action), the user profile P ( l ) for the l th user is a q  X  t matrix with entries p ( l ) ij representing the number of action i on category j ,where 1  X  k  X  n , 1  X  i and 1  X  j  X  t . Furthermore, the similarity a ( l ) ij between user i and j for the l th category is the cosine value between vector P where &lt;.,.&gt; denotes the inner product, . represents the vector l 2 norm and P ( i ) : ,l is the l th column of profile matrix of user i .
 matrix for a weighted graph G ( l ) capturing the structure of users for category l . Since the categories are often diverse in social network, the relationship among users is heterogenous. In the following section, we detail how to incorporate the heterogenous relationship into learning framework.
We capture the structure relationships among tasks for t categories as an undirected multi-graph G = { G ( l ) } t whose nodes correspond to the set of k tasks. Edges in the graph G are multi-edges and weighted, with a ij  X  X  t defined in Equation (1) representing the similarity vector between user i and j . In Figure 2, we have shown a multi-graph with two categories on three users.

Given n articles (training samples) and the multi-graph collected from the whole social network for k users, we fur-ther assume all the tasks share the same training data since our goal is to predict the user activities towards these n sam-ples. We incorporate the heterogenous structure information by adding a Tikhonov regularization factor n l =1 k i,j =1 a ij w i  X  w j 2 2 to enforce that the task parameters vary smoothly for neighboring users, where I t  X  n is the indica-tor matrix with I jk =1ifthe k th article belongs to the j th category and 0 otherwise.

The Tikhonov regularization factor can be conveniently written in matrix format in terms of graph Laplacian ma-trix for individual graph G ( l ) , (1  X  l  X  t ) defined on each category of information content t i =1 r i tr ( WL i W T ), where r = j I ij , (1  X  i  X  t ) is the sum of the i th row in matrix I to summarize the number of posts belonging to the i th category. Note that we also allow overlapping categories, which means that each column of I may have multiple 1s.
Combining with l 1 penalty, the composite regularization function is: where  X  1 &gt; 0 , X  2 &gt; 0 are the regularization parameters, L is the Laplacian matrix of G ( i ) given by L ( i ) = D ( i )  X  A ( i ) is the k by k adjacency matrix for category i and D is the density matrix of A ( i ) , defined as D ( i ) =( d (task) or category dominate (2), we use normalized graph laplacian defined in [8] and normalized category vector r = [ r ,  X  X  X  ,r t ] T by dividing max { r i | 1  X  i  X  t } .
By combining (2) with loss function, we have the follow-all tasks share the same design matrix, it can be further simplified as: where Y n  X  k =[ y 1 ,  X  X  X  , y k ] is the response matrix with i th with the i th row  X  x i  X  X  p .

Equation (3) treats all samples equally, which is only suit-able for balanced data sets. Due to the unbalanced class ratio (a user only responses to a limited number of mes-sages), we introduce a weighting scheme based on positive and negative sample ratio for each task to guarantee that the misclassification cost is more on rare samples. Consider the following optimization problem: min where  X  is the element-wise product and B n  X  k is the weight matrix. For the i th task, let P = { j | y i j =1 } denotes the in-dices of positive samples, then the weights for positive sam-ples in i th task are given by B P ,i =1  X  X P| /n and negative sample weights are B [1 ,k ] \P ,i = |P| /n ,where |P| is the car-dinality of the set P . The major challenge in fitting the model described in Equation(4)todataistoestimatetheparameters W ef-ficiently and accurately. We propose an efficient algorithm to solve (4) based on accelerated gradient decent [21] and projected gradient [4]. The convergence rate of ordinary first order gradient method is O (1 / ) [21] for smooth prob-lems, where is the desired accuracy. To have a better convergence rate, we use Nestrerov accelerated gradient de-scent method [21] with O (1 / the generalized gradient update step for each gradient up-date step. Due to the space constrain, we do not show de-tailed algorithm. Refer to the longer version of this paper at http://people.eecs.ku.edu/~hfei/cikm2011longer.pdf .
We have conducted experiments with four real world data sets crawled from digg.com. To evaluate the performance of our MTL algorithm (MTLTLap), we compared our method with: (1) single task learning algorithm linear kernel SVM [27] with feature selection method SVMRFE [11]; (2) Multi-task feature learning with l 1 /l 2 regularization (MTLF) [19] without considering task relationship; and (3) MTL with homogenous networked task relationship (MTLALap) [15]. We have carefully implemented our method MTLTLap, MT-LALap and used LIBSVM [5] integrated with spider toolbox [29] for SVM and SLEP package [20] for MTLF.
We have crawled four data sets from digg.com, in which there are 10 categories of articles. Due to the tremendous number of users in digg.com, it is impossible to perform anal-ysis for every user. Instead we randomly select four users as  X  X eeds X  and collect their article contents as well as their followers X  activities towards these articles. The activities are comment, digg, comment &amp; digg and no action. For a seed user, we treat each article as a sample with bag-of-words rep-resentation, where the words (features) are extracted from all the articles the seed user submitted. We remove stop words, normalize words and calculate their TF-IDF values with porter stemmer available at http://sourceforge.net/ projects/wvtool/ . Each follower corresponds to a task, where the action of comment or digg are treated as 1 and no action as -1. We eliminate these followers whose total number of comments and diggs on the seed is less than 5. Table 1: Data set: the symbol of the data set. # T : To build the multigraph for capturing the heterogenous rela-tionships among the followers, we also collect the number of submissions, diggs and comments of these followers on each category. Each follower has a 3 by 10 user profile matrix. In Table 1, we summarize the characteristics of the five data sets.
Model Construction: We partition each data set into 5 folds to perform 5-fold cross-validation (CV). For MTL methods, we use another 5-fold CV on the training data set to select the regularization parameters  X  1 and/or  X  2 with asimplegridsearchintherangeof[2 10 , 2 9 ,  X  X  X  , 2  X  10 ]. For SVM, we first use 5-fold CV to select the number features in the rage of { 25 , 50 , 75 ,  X  X  X  , 300 } , then another 5-fold CV to select parameter C in the range of [2 10 , 2 9 ,  X  X  X  , 2
Model Evaluation: We collect the following metrics: precision = TP/ ( TP + FP ) recall = TP/ ( TP + FN )
F 1 =2  X  precision  X  recall/ ( precision + recall ) where TP stands for true positive, FP stands for false pos-itive, TN stands for true negative, FN stands for false neg-ative. All the values reported are collected from the test-ing data set only and are averaged across 5-fold CV with 6 replicates. Note that since there is even no positive samples available in testing data during cross validation due to the imbalanced class ratio, we skip such folds when averaging the final F 1 score.
F1 Score
F1 Score We compare our method with SVM, MTLF and MT-LALap in terms of the average F 1 score for four different data sets in Figure 3. The standard deviation for each task is around 8%-15% for all the methods and we do not report them for simplicity. From Figure 3, we observe that the performance of single task SVM is very unstable compared with MTL approaches. For example, the average F 1 score is 0 for the 5th task of nichewp ( S 1 ) because SVM predicts all the samples as negative (no comment or digg action) when the class ratio is unbalanced. However for the 2nd task, the performance is comparable to MTLF because the class ratio is balanced. Such an observation demonstrates the ad-vantages of MTL vs STL for improving the generalization performance especially when training samples are limited and imbalanced.
 Among the MTL methods, MTLALap and our method MTLTLap outperform MTLF for most tasks for four data sets, which confirms that considering the relationship among tasks will boost the learning performance. Finally, compared with MTLALap without differentiating the heterogenous so-cial connections, our approach MTLTLap performs better, although the difference is subtle for some tasks. The reason is that when the training samples are dominated by only one or two categories (i.e. S 2 ), our method may not per-form very well compared with MTLALap especially when the true topology actually reflects the user interests.
To further explore why our approach provides a reason-able performance compared with the other methods, we se-lect three followers 2, 4 and 10 from S 2 , which corresponds to the example shown in Figure 1. The data set of S 2 cov-ers 5 categories dominated by technology and game and the result is shown in Table 2. We see that MTLTLap and MTLALap outperforms MTLF for two out of three tasks, which confirms the importance of task relationship incorpo-ration. Meanwhile, the F 1 score and recall of the third strat-egy MTLTLap is consistently better than MTLALap, which demonstrates that our approach can more effectively identify positive samples in an unbalanced classification task.
To explain this phenomenon, we recall the similarities of the three followers as shown in Figure 2: F 1 , F 2 and F all like technology but with different levels; Meanwhile, F and F 2 share interests in entertainment. Disregarding the information content category in the training data, the het-erogenous relationship among followers will be either mixed (i.e. MTLALap) or ignored (i.e. MTLF). However in our approach, by introducing heterogenous task relationship in-duced by different categories and the weight of each category in the training data, we enforce similar tasks to have similar parameters based on the categories specified in the training data. Hence our prediction result is more stable and the resulting model is more interpretable.
In this paper, we tackle the problem of predicting user behavior to friends X  postings in social networks. We argue that social information flow and socialization behaviors are not only related to social relationships (i.e. graph topology), but also information contents and user interests. Therefore, we should integrate all these factors to construct a better model. Towards that end, we presented a multi-task learn-Precision Recall F 1 Precision Recall ing algorithm with heterogenous task relationships, in which we capture the heterogenous relationships induced by dif-ferent information categories among users as an undirected multigraph and incorporate such information by introducing a trace norm regularized graph Laplacian to standard MTL formalization. Using a comprehensive experimental study with social network data collected from digg.com and com-paring with current state-of-the-art, we demonstrate that the new algorithm achieves better prediction performance. The work is partially supported by the NSF award IIS (0845951) and University of Kansas General Research Fund (GRF: 2301420).
