 While it is has often been observed that the product of translation is somehow different than non -translated text, scholars have emph a-sized two distinct bases for such differences. Some have noted interference from the source l anguage spilling over into translation in a source -language -specific way, while others have noted general effects of the process of translation that are independent of source la n-guage. Using a series of text categorization experiments, we show that both th ese effects exist and that, moreover, there is a continuum between them . There are many effects of translation that are consistent among texts translated from a given source language, some of which are consistent even among texts translated from families o f source languages. Significantly, we find that even for widely unrelated source languages and multiple g e-nres , differences between translated texts and non -translated texts are sufficient for a learned classifier to accurately determine if a given text is translated or original. T he products of translation (written or oral) are generally assumed to be ontologically different from non -translated texts. Researchers have e m-phasized two aspects of this difference. Some (Baker 1993) have emphasized general effects of the process of translation that are independent of source language and regard the collective product of this process in a given target language as a n  X  X  n-terlanguage X  (Selinker, 1972),  X  X hird code X  (Fra w-ley, 1984) or  X  X ranslationese X  (Ge llerstam, 1986) . Others (Toury , 1995) have emphasized the effects of interference , the process by which a specific source language leave s distinct marks or finge r-prints in the target language , so that translations from different source languages into the same ta r-get language may be regarded as distinct dialects of translationese . 
We wish to use text categorization methods to set both of these claims on a firm empirical fou n-dation. We will begin by bringing evidence for two claims: (1) T ranslations from di fferent source languages into the same target language are sufficiently di f-ferent from each other for a learned classifier to accurately identify the source language of a given translated text ; (2) T ranslations from a mix of source languages are sufficien tly distinct from texts originally wri t-ten in the target language for a learned classifier to accurately determine if a given text is translated or original .

Each of these claims has been made before, but our results will strengthen them in a number of way s. Furthermore, we will show that the degree of difference between translations from two source languages reflect s the degree of difference between the source languages themselves. Translations from cognate languages differ from non -translated texts in sim ilar ways, while translations from unr e-lated languages differ from non -translated texts in distinct ways. The same result holds for families of languages.

The outline of the paper is as follows. In the fo l-lowing section, we show that translations from di f-ferent source languages can be distinguished from each other and that closely related source langua g-es manifest similar forms of interference. In se c-tion 3, we show that , in a corpus involving five European languages, we can distinguish translati o-nese from non -translated text and we consider some salient markers of translationese. In section 4, we consider the extent to which markers of translationese cross over into non -European la n-guages as well as into different genres. Finally, we consider possible appl ications and implications for future studies. In this section, we perform several text categoriz a-tion experiments designed to show the extent to which interference affects (both positively and n e-gatively) our ability to classify documents. 2 . 1 The Europarl Corpus The main corpus we will use throughout this paper is Europarl (Koehn, 2005), which consists of tra n-scripts of addresses given in the European P arli a-ment. The full corpus consists of texts translated into English from 11 different languages (and vice versa) , as well as texts originally produced in En g-lish. For our purposes, it will be sufficient to use translations from five languages ( Finnish, French, German, Italian and Spanish ), as well as original English. We n ote that this corpus constitutes a comparable corpus (Laviosa, 1997), since it co n-tains (1) texts written originally in a certain la n-guage (English), as well as (2) texts translated into that same language, matched for genre, domain, publication timeframe, etc. Each of the five tran s-lated components is a text file containing just u n-der 500,000 words ; the original English component is a file of the same size as the aggre gate of the other five .

T he five source languages we use were selected by first eliminating several source languages for which the available text was limited and then choosing from among the remaining languages, those of varying degrees of pairwise similarity. Thus, we select three cognate (Romance) langua g-es (French, Italian and Span ish), a fourth less r e-lated language (German), and a fifth even further removed (Finnish). As will become clear, t he m o-tivation is to see whether the distance between the languages impacts the distinctiveness of the tran s-lation product.

We divide each of the translated corpora into 250 equal chunks, paying no attention to natural units within the corpus. Similarly, we divide the original English corpus into 1250 equal chunks. We set aside 50 chunks from each of the translated corpora and 250 chunks from th e original English corpus for development purposes (as will be e x-plained below). The experiments described below use the remaining 1000 translated chunks and 1000 original English chunks. 2 . 2 Identifying source language Our objective in this section is to me asure the e x-tent to which translations are affected by source language. Our first experiment will be to use text categorization methods to learn a classifier that categorizes translations according to source la n-guage. We will check the accuracy of such cla s-sifiers on out -of -sample texts. High accuracy would reflect that there are exploitable differences among translations of otherwise comparable texts that differ only in terms of source language.

The details of the experiment are as follows. We use the 200 chunks from each translated corpus, as described above . We use as our feature set a list of 300 function words taken from LIWC (Penneba k-er , 2001 ) and rep resent each chunk as a vector of size 300 in which each entry represents the fr e-quency of the correspon ding feature in the chunk. The restriction to function words is crucial; we wish to rely only on stylistic differences rather than content differences that might be artifacts of the corpus.

We use Bayesian logistic regression (Madigan , 2005) as our learnin g method in order to learn a classifier that classifies a given text into one of five classes representing the different source lan guages. We use 10 -fold cross -validation as our testing m e-thod.

We find that 92.7% of documents are correctly classified. 
In Table 1 we show the confusion matrix for the five languages. As can be seen, there are more mi s-takes across the three cognate languages than b e-tween those three languages a nd German and still fewer mistakes involving the more distant Finnish language.

This result strengthens that of van Halteren (2008) in a similar experiment. Van Halteren, also using Europarl ( but with Dutch as the fifth source language , rather than Finnish ) , obtained accuracy of 87.2% -96.7% for a two -way decision on source language , a nd 81.5% -87.4% for a six -way decision (including the original which has no source la n-guage) . Significantly , though, van Halteren X  s fe a-ture set included content words and he notes that many of the most salient differences reflected di f-ferences in thematic e mphasis. By restricting our feature set to function words, we neutralize such effects.

In Table 2 , we show the two words most over -represented and the two words most under -represented in translations from each source la n-guage (ranked according to an unpair ed T -test) . For each of these, the difference between freque n-cy of use in the indicated language and frequency of use in the other languages in aggregate is signi f-ican t at p&lt;0.0 1. Fr of, finally here, also It upon, moreover also, here Es with, therefore too, then De here, then of, moreover Fi be, example me, which The two most underrepresented words for French and Italian, respectively, are in fact id enti c-al. Furthermore, the word too which is underrepr e-sented for Spanish is a near synonym of also which appears in both French and Spanish. This suggests the possibility that interference effects in cognate languages such as French, Italian and Spanish might be similar. We will see presently that this is in fact the case. 
When a less related language is involved we see the opposite picture. For German, both underrepr e-sented items appear as overrepresented in the Romance languages, and , conversely, underrepr e-sented items in the Romance languages appear as overrepresented items for German. This may cast doubt on the idea that all translations share unive r-sal properties a nd that at best we may claim that particular properties are shar e d by closely related languages but not others. In the experiment s pr e-sented in the next subsection, we  X  X l find that tran s-lationese is gradable : closely related languages share more features, yet even further removed la n-guages share enough properties to hold the general translationese hypothesis as valid. 2 . 3 Identifying translationese per source l a n-We now wish to measure in a subtle r manner the extent to which interference affects translation. In this experiment, the challenge is to lear n a classif i-er that classifies a text as belonging to one of only two classes: original English (O) or translated -into -English (T). The catch is that all our training texts for the class T will be translations from some fixed source language, while all our test documents in T will be translations from a different source la n-guage. What accuracy can be achieved in such an experiment? The answer to this qu estion will tell us a great deal about how much of translationese is general and how much of it is language dependent. If accuracy is close to 100%, translationese is pur e-ly general ( Baker, 1993) . (We already know from the previous experiment that that's n ot the case.). If accuracy is near 50%, there are no general effects, just language -dependent ones. Note that, whereas in our first experiment above pair -specific interf e-rence facilitated good classification, in this exp e-riment pair -specific interference i s an impediment to good classification.

The details of the experiment are as follows. We create , for example, a  X  X rench X  corpus consisting of the 200 chunks of text translated from French and 200 original English texts. We similarly create a corpus for eac h of the other source languages, taking care that each of the 1000 original English texts appears in exactly one of the corpora. As above, w e represent each chunk in terms of fr e-quencies of function words. Now, using Bayesian logistic regression, we learn a classifier that disti n-guishes T from O in the French corpus . We then ap ply this learned classifier to the texts in , for e x-ample, the equivalent  X  Italian  X  corpus to see if we can classify them as translated or original. We r e-peat this for each of the 25  X  train_corpus, test_corpus  X  pairs.

In Table 3 , we show the accuracy obtained for each such pair. (For the case where the training corpus and testing corpus are identical  X  the d i-agonal of the matrix  X  we show results for ten -fold cross -validation.) 
We note several interesting facts. First, results of cross -validation within each corpus are very strong. For any given source language, it is quite easy to distinguish translations from original En g-lish. This corroborates results obtained by Baroni and Bernardin i (2006), Ilisei et al. (20 10 ), Kur o-kawa et al. (2009) and van Halteren (2008), which we will discuss below. 
We note further, that for the cases where we train on one source language and test on another, results are far worse. This clearly indicates that interference effects from one source language might be misleading when used to identify transl a-tions from a different language. Thus, for example , in the Finnish corpus, the word me is a strong ind i-cator of original English (constituting 0.0003 of tokens i n texts translated from Finnish as opposed to 0.0015 of tokens in original English texts), but in the German corpus, me is an indicator of tran s-lated text (constituting 0.0020 of tokens in text translated from German).

The most interesting result that can be seen in this table is that the accuracy obtained when t rai n-ing using language x and test ing using language y depends precisely on the degree of similarity b e-tween x and y. Thus , for training and testing within the three cognate languages, results are fa irly strong, ranging between 8 4 . 5 % and 91.5 %. For training/testing on German and testing/training on one of the other European languages, results are worse, ranging from 68.5 % to 83.3%. Finally, for training/testing on Finnish and testing/training on any o f the European languages, results are still worse , hovering near 60% (with the single une x-plained outlier for training on German and testing on Finnish) .

Finally, we note that even in the case of training or testing on Finnish, results are considerabl y be t-ter than random, suggesting that despite the co n-founding effects of interference, some general properties of translationese are being picked up in each case. We explore these in the following se c-tion. Having establis hed that there are source -language -dependent effects on translations, let X  X  now co n-sider source -language -independent effects on tran s lation . 3 . 1 Identifying translationese In order to identify general effects on translation, we now consider the same two -class classification problem as above, distinguishing T from O, except that now the translated texts in both our train and test data will be drawn from multiple source la n-guages. If we succeed at this task, it must be b e-cause of features of translationese that c ross source -languages. 
The details of our experiment are as follows . We use as our translated corpus, the 1000 translated chunks (200 from each of five source languages) and as our original English corpus all 1000 original English chunks. As above, we represent each chunk in terms of function words frequencies. We use Bayesian logistic regression to learn a two -class classifier and test its accuracy using ten -fold cross -validation. Remarkably, we o btain accuracy of 9 6 .7%. 
This result extends and strengthens results r e-ported in some earlier studies. Ilisei et al. ( 2010 ), Kurokawa (2009) and van Halteren (2008) each obtained above 90% accuracy in distinguishing translation from original. However, in each case the translations were from a single source la n-guage. ( V an Halteren considered multiple source languages , but each learned classifier used only one of them. ) Thus, those results do not prove that translationese has distinctive source -language -independent features. To our knowledge, the only earlier work that used a learned classifier to ident i-fy translations in which both test and train sets i n-volved multiple source languages is Baroni and Bernardini (2006), in which the target language was Italian and the source languages were known to be varied. The actual distribution of source la n-guages was, however, not known to the researc h-ers. They obtained accuracy of 86.7 % . Th eir result was obtained using combinations of lexical and syntactic features.
 3 . 2 Some distinguishing features Let us now consider some of the most salient fun c-tion words for which frequency of usage in T di f-fers significantly from that in O. While t here are many such features, we focus on two categories of words that are most prominent among those with the most significant differences. 
First, we consider animate pronouns . In Table 4 , we show the frequencies of animate pronouns in O and T, respect ively (the possessive pronouns, mine , yours and hers , not shown, are extremely rare in the corpus) . As can be seen, all pronouns are u n-der -represented in T ; for most (bolded), the diffe r-ence is significant at p&lt;0.01.
 By contrast, the word the is significantly overr e-presented in T (15.32% in T vs. 13.73% in O; si g-nificant at p&lt;0.01). 
I n Table 5 , we consider cohesive markers, tagged as adverbs ( Schmid , 2004) . (These are a d-verbs that can appear at the beginning of a se n-tence followed immediately by a comma.)
We note that the preponderance of such cohesive markers are significantly more frequent in transl a-tions. In fact, we also find that a variety of phrases that serve the same purpose as cohesive adverbs, such as in fact and as a result are significantly more frequent in translationese.

The general principle underlying these phen o-mena is subject to specul ation. Previous researc h-ers have noted the phenomenon of explicitation , according to which translators tend to render i m-plicit utterances in the source text into explicit u t-terances in the target text (Blum -Kulka, 1986, Laviosa -Braithwaite, 1998), for exam ple by filling out elliptical expressions or adding connectives to increase cohesion of the text (Laviosa -Braithwaite, 1998). It is plausible that the use of cohesive a d-verbs is an instantiation of this phenomenon.

With regard to the under -representation o f pr o-nouns and the over -representation of the , there are a number of possible interpretations. It may be that this too is the result of explicitation , in which an a-phora is resolved by replacing pronouns with noun phrases (e.g., the man instead of he ). But it also might be that this is an example of simplification (Laviosa -Braithwaite 1998, Laviosa 2002), a c-cording to which the translator simplifies the me s-sage, the language, or both. Related results confirming the simplification hypothesis were found by Il isei et al. (2010) on Spanish texts. In particular, they found that type -to -token ratio ( lex i-cal variety / richness ), mean sentence length and proportion of grammatical words ( lexical dens i-ty / readability ) are all smaller in translated texts. 
We note that Van Halteren (2008) and Kurokawa et al. (2009) , who considered lexical features , found cultural differences, like over -representation of ladies and gentlemen in translated speeches . Such differences, while of general interest, are o r-thogonal to our purpose s in this paper. 3 . 3 Overriding language -specific effects We found in Section 2.3 that when we trained in one language and tested in another , classification succeeded to the extent that the source languages used in training and testing, respectively, are r e-lated to each other. In effect, general differences between translationese and original English were partially overwhelmed by language -specific diffe r-ences that held for the training language but not the test language. We thus now revisit that earlier e x-pe riment, but restrict ourselves to features that di s-tinguish translationese from original English generally. 
To do this, we use the small development corpus described in Section 2.1. We use Bayesian logistic regression to learn a classifier to distinguish b e-tween translationese and original English. We s e-lect the 10 highest -weighted function -word markers for T and the 10 highest -weighted fun c-tion -word markers for O in the development co r-pus . We then rerun our train -on -source -language -x, test -on -source -lang uage -y experiment using this r e stricted set as our feature set. We now find that even in the difficult case where we train on Finnish and test on another language (or vice versa), we succeed at distinguishing translationese from ori g-inal English with accuracy above 80 %. This cons i-derably improves the earlier results shown in Table 3. Thus, a bit of feature engineering facilitates learning a good classifier for T vs. O even across source languages. W e have found both general and language -specific differences between translationese and original English in one large corpus. It might be wondered whether the phenomena we have found hold in other genres and for a completely different set of source language s. To test this, we consider a second corpus. 4 . 1 The IHT corpus Our second corpus includes three translated corp o-ra, each of which is an on -line local sup plement to the International Herald Tribune (IHT) : Kathim e-rini (translated from Greek), Ha X  X retz (transl ated from Hebrew), and the JoongAng Daily (translated from Korean). In addition, the corpus includes original English articles from the IHT. Each of the four components contains four different domains balanced roughly equally: news (80,000 words), arts and leisure (50,000), business and finance (50,000), and opinion (50,000) and each covers the period from April -September 2004. Each comp o-nent consists of about 230,000 tokens. (Unlike for our Europarl corpus, the amount of English text available is not equal to the aggregate of the tran s-lated corpora, but rather equal to each of the ind i-vidual corpora.)
It should be noted that t he IHT corpus belongs to the writing modality while the Europarl corpus belongs to the speaking modality (although poss i-bly post -edited) . Furthermore, t he source langua g-es (Hebrew, Greek and Korean) in the IHT corpus are more disparate than those in the Europarl co r-pus .

Our first objective is to confirm that the results we obtained earli er on the Europarl corpus hold for the I HT corpus as well. 
P erhaps more interestingly, our second objective is to see if the gradability phenomenon observed earlier (Table 3) generalizes to families of la n-guages. Our first hypothesis is that a classifier for identifying transla tionese that is t rained on Eur o-parl will succeed only weakly to identify transl a-tionese in IHT. But our second hypothesis is that there are sufficient general properties of translati o-nese that cross language families and genres that a learned classifier can accurately iden tify transl a-tionese even on a test corpus that includes both corpora, spanning eight disparate languages across two distinct genres. 4 . 2 Results on IHT corpus Running essentially the same experiments as d e-scribed for the Europarl corpus, we obtain the fo l-lowin g results. 
First of all, we can determine source language with accuracy of 86. 5 %. This is a somewhat wea k-er result than the 92.7% result obtained on Eur o-parl , especially considering that there are only three classes instead of five . The difference is most likely due to the fact that the IHT corpus is about half the size of the Europarl corpus. Nevertheless, it is clear that source language strongly affects translationese in this corpus.

Second, as can be seen in Table 6, we find tha t the gradability phenomenon occurs in this corpus as well . Results are strongest when the train and test corpora involve the same source language and trials involving Korean, the most distant language, are somewhat weaker than those across Greek and Hebre w.

Third, we find in ten -fold cross -validation exp e-riments that we can distinguish translationese from original English in the IHT corpus with accuracy of 86.3 %. Thus, despite the great distance between the three source languages in this corpus, general differences between translatione se and original English are sufficient to facilitate reasonably acc u-rate identification of translationese. 4 . 3 Combining the corpora First, we consider whether a classifier learned on the Europarl corpus can be used to identify tran s-lationese in the IHT corpus, and vice versa. It would be consistent with our findings in Sec tion 2.3, that we would achieve better than random results but not high accuracy, since there are no doubt features common to translations from the five European languages of Europarl that are di s-tinct from those of translations from the very di f-ferent lan guages in IHT. 
In fact, we find that training on Europarl and testing on IHT yields a ccuracy of 64.8%, while training on IHT and testing on Europarl yields accuracy of 58.8 %. The weak results reflect both differences between the families of source la n-g uages involved in the respective corpora, as well as genre differences. Thus, for example, we find that of the pronouns shown in Table 4 above, only he and his are significantly under -represented in translationese in the IHT corpus. Thus, that effect is sp ecific either to the genre of Europarl or to the European languages considered there. 
Now, we combine the two corpora and check if we can identify translationese across two genres and eight languages. We run the same experi ments as described above, using 200 texts from each of the eight source languages and 1600 non -translated English texts, 1000 from Europarl and 600 from IHT. 
In 10 -fold cross -validation, we find that we can distinguish translationese from non -translate d En g-lish with accuracy of 90.5%.

This shows that there are features of translati o-nese that cross genres and widely disparate la n-guages. Thus, for one prominent example, we find that, as in Europarl, the word the is over -represented in translationese in IHT ( 15.3 6 % in T vs. 13. 31 % in O; significant at p&lt;0.01 ). In fact, the frequencies across corpora are astonishingly co n-sistent.

To further appreciate this point, let X  X  look at the frequencies of cohesive adverbs in the IHT corpus.
We find essentially, the same pattern in IHT as we did in Europar l . The preponderance of cohesive adverbs are over -represented in translationese, most of them with differences significant at p&lt;0.01. Curiously, the word actually is a counter -example in both corpora. We have found that we can learn classifiers that determine source language given a translated text, as well as classifiers that distinguish translated text from non -translated text in the source language. These text categorization exp eriments suggest that both source lan guage and the mere fact of being tran slated play a crucial role in the makeup of a translated text . 
It is important to note that our learned classifiers are based solely on function words, so that, unlike earlier s tudies, the differences we find are unlikely to include cultural or thematic differences that might be artifacts of corpus construction.

In addition, we find that the exploitability of di f-ferences between translated texts and non -translated texts are relat ed to the difference b e-tween source languages: translations from similar source languages are different from non -translated texts in similar ways.

Linguists use a variety of methods to quantify the extent of d ifferences and similarities between languages . For example, Fusco ( 1990 ) studies translations between Spanish and Italian and co n-siders the impact of structural differences between the two languages on translation quality . Studying the differences and distance between languages by comparing translation s into the same language may serve as another way to deepen our typological knowledge. As we have seen, training on source language x and testing on source language y pr o-vides us with a good estimation of the distance b e-tween languages, in accordance with what we find in standard works on typology ( cf. Katzner , 2002 ). 
In addition to its intrinsic interest, t he finding that the distance between languages is directly co r-related with our ability to distinguish translations from a given source language from n on -translated text is of great importance for several comput a-tional tasks. First, translations can be studied in order to shed new light on the differences between languages and can bear on attested techniques for using cognates to improve machine translat ion ( Kondrak &amp; Sherif, 2006 ). Additionally , given the results of our experiments, it stands to reason that using translated texts, especially from related source languages, will prove beneficial for co n-structing language model s and will outperform results obtained from non -translated texts. This, too, bears on the quality of machine translation.
Finally, we find that there are general properties of translationese sufficiently strong that we can identify translationese even in a combined corpus that is compr ised of eight very disparate languages across two distinct genres, one spoken and the ot h-er written. Prominent among these properties is the word the , as well as a number of cohesive adverbs, each of which is significantly over -represented in translated te xts.

