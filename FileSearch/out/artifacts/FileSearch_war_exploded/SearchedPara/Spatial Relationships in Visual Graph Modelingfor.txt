 In this paper, a language model adapted to graph-based rep-resentation of image content is proposed and assessed. The full indexing and retrieval processes are evaluated on two different image corpora. We show that using the spatial re-lationships with graph model has a positive impact on the results of standard Language Model (LM) and outperforms the baseline built upon the current state-of-the-art Support Vector Machine (SVM) classification method.
 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms, Experimentation Graph theory, language model, image categorization
Our goal here is to automatically induce, from a given im-age, a graph that represents the image content. This graph will contain concepts directly associated with the visual el-ements in the image, as well as relations which express how concepts are related spatially in the image. To do so, our procedure is based on four main steps: (1) Identify regions within the image that will form the basic blocks for concept identification; (2) Index each region with a predefined set of features; (3) Cluster all the regions found in the collection in k classes, where each class represents one concept. Each region in the image is then associated to one concept. We obtain for each type of region a set of concepts C ; (4) Finally, extract spatial relations between visual concepts.

Based on this representation, our contributions are two-fold. First, a directed graph model is constructed to rep-resent the image content based on concepts. Second, we apply a simple and effective method for the graph match-ing based on the language model [2]. Unlike the previous approach [3] based on a sequence of n -gram concepts, our framework embeds smoothly different types of spatial rela-tions. The experiments carried out on two image collections confirm the significative impact of our method.

We assume that each image i is represented by a set of weighted concept sets S i W C = { W i C } and a set of weighted relation sets S i W E = { W i E } , forming a graph: Each concept of one set W i C corresponds to a visual concept used to represent the image according to the feature associ-ated with. Denoting C a set of concepts for one feature over the whole collection, W i C is a set of pairs ( c, #( c,i )), where c is an element of C and #( c,i ) is the number of times c occurs in the document image i : Any labeled relation between any pair of concepts ( c,c 0 C X C 0 is represented by a triple (( c,c 0 ) ,l, #( c,c 0 ,l,i )), where l is an element of L , the set of possible labels for the relation, and #( c,c 0 ,l,i ) is the number of times c and c 0 are related with label l in image i . W i E is then defined as:
W i E = { (( c,c 0 ) ,l, #( c,c 0 ,l,i )) | ( c,c 0 )  X  X  X C If a pair of concepts ( c,c 0 ) come from the same concept set, we refer this relation as intra-relation set. Otherwise, we refer it as inter-relation set. Inspired by [1], the probability for a graph query G q = &lt; S is computed as: This probability composed of two parts: a probability to generate the concept sets P ( S q W C | G d ) and a probability to generate the relation sets P ( S q W E | S q W C ,G d ). The proba-bility of generating query concept sets from the document model P ( S q W C | G d ) uses a concept set independence hypoth-esis: Assuming concept independence, standard in information retrieval and the number of occurrences of the concepts (i.e., the weights considered previously) are integrated through the use of a multinomial model, we compute P ( W q C | G d where #( c,q ) denotes the number of times concept c occurs in the graph representation of the query. This contribu-tion corresponds to the concept probability. The quantity P ( c | G d ) can be estimated through maximum likelihood us-ing Jelinek-Mercer smoothing: where #( c,d ) represents the number of occurrences of c in the graph representation of the image d , and where #(  X  ,d ) is equal to P c #( c,d ). The quantities #( c,D ) are similar, but defined over the whole collection (i.e., over the union of all images in the collection). Based on the relation set independence hypothesis, we follow a similar process for the relation sets, leading to: For the probability of generating query relation from the document, we assume that a relation depends only on the two linked sets. Assuming that the relations are independent and following a multinomial model, we compute: P ( W q E | S q W C ,G d )  X  (6) where c  X  C , c 0  X  C 0 and L ( c,c 0 ) is a variable with values in L reflects the possible relation labels between c and c this relation set. The parameters of the model P ( L ( c,c l | W q C ,W q C 0 ,G d ) are estimated by the maximum likelihood with Jelinek-Mercer smoothing. Images are ranked based on their relevance status value.
In order to assess the validity of our methods, we have ex-perimented on 2 image collections and compared the results with other state-of-the-art approach in image categorization such as SVM classification method (implemented thanks to the libsvm 1 ). We applied the same visual features used for our experiment. Each class was trained with a correspond-ing SVM classifier using RBF kernel.
 STOIC-101 collection The STOIC-101 collection contains 3849 photos of 101 tourist landmarks in Singapore. For experimental purposes, the col-lection has been divided into a training set of 3189 images and a test set of 660 images. We extracted from each block of 10  X  10 pixels a center pixel as a representative for the region. From this pixel, a vector of HSV color (8 bins for each chan-nel) was extracted and clustered into 500 concepts. Based on this representation, we built 2 graph models: (1) with only concept set, referred as simple Language Model (LM); (2) with integrating of intra-relation set { left of,top of } to concept set, referred as Visual Graph Model (VGM). As a comparison, we present in table 1 the best results obtained using SVM classifiers.
 RobotVision X 09 collection The RobotVision X 09 collection was used for ImageCLEF com-petition aiming to address the problem of localization of a robot using only the visual information. This collection con-tains a sequence of 1034 images for training and a sequence http://www.csie.ntu.edu.tw/cjlin/libsvm/ Table 1: Results on categorizing STOIC-101 and RobotVision X 09 collections STOIC-101 101 0.789 0.809 (+2.5%) 0.744 RobotVision of 909 images for validation. The official test is carried out on a set of 1690 images. Image sequences were cap-tured within an indoor laboratory environment consisting of 5 rooms. For this collection, we have applied 2 types of image representations: (1) regular division of 5  X  5 patches; (2) extraction of SIFT (Scale Invariant Feature Transform) features from local key-points. From these image represen-tations, we defined an inter-relation set { inside } between patches and key-points representation if one key-point is lo-cated inside the region of one patch. Similar to above, we referred the model without relation as LM (simply the pro-duction of probability generated by different concept sets) and graph model with the spatial relation as VGM (with the contributing of relation probability to graph model). The SVM model was trained based on the fusion of concepts come from both patches and SIFT key-point features.
Table 1 summarizes the results obtained from both col-lection STOIC-101 and RobotVision X 09. We can see that in all cases our VGMs outperformed other methods. More precisely, with the integration of spatial relation into VGM helped improving the accuracy of classical approaches of LM by at least 2.5%. Especially with the RobotVision collec-tion, VGMs have increased roughly the accuracies of 7.9% to 16.6% comparing to LMs respectively for both test and validation set. Lastly, the VGMs have retained medium to large improvements over the state-of-the-art SVM classifiers in both image collections.
In this work, we have presented a novel graph-based frame-work for integrating smoothly the spatial relationships of visual concepts. Our contributions are two-folds: (1) a well-foundeness graph model for representation of image content (2) a simpler and more effective graph matching process based on the language model. Our experimental results con-firmed the stability of our visual graph models, as well as, enhanced the results obtained with other approaches such as standard LM and SVM classification method.
 This work was supported by AVEIR (ANR-06-MDCA-002) and Merlion PhD. programme from Singapore. [1] L. Maisonnasse, E. Gaussier, and J. Chevalet. Model [2] J. M. Ponte and W. B. Croft. A language modeling [3] P. Tirilly, V. Claveau, and P. Gros. Language modeling
