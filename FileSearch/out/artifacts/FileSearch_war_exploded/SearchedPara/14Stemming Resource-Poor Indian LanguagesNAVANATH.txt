 NAVANATH SAHARIA and UTPAL SHARMA ,TezpurUniversity An information retrieval (IR) system attempts to identify and retrieve relevant infor-mation from a database, usually containing a large number of documents. A document in IR is usually represented as a set of words. The efficiency of an IR system is ad-versely affected by the abundance of words appearing in various morphological forms, either as a result of inflection or derivation. To reduce this adverse effect of morpho-logical variation, one common method is to represent the words in a normalized repre-sentative form. One approach to do so is by finding the root word from an inflected or a derivational form; this is known as stemming . It is an initial step in analyzing the morphology of words. Thus, instead of keeping all the variants in the database, if we store or index only the base word, it reduces the size of the index. Thus, our problem is to find the base form(s) of a given word or a set of words.

Methods for finding the base form 1 include affix stripping, co-occurrence compu-tation, dictionary look-up and probabilistic approaches. Most approaches are first developed for English, and later adapted for other languages (see Section 2). These approaches may not work properly for highly inflectional languages, including Indian languages which are our focus. These languages are morphologically rich and rela-tively free word order. Studies by McFadden [2004, Chapter 5] and M  X  uller [2002] analyze the relationship between morphology and word order freedom of natural lan-guages. A number of approaches for stemming have been used by researchers for In-dian languages. Reported approaches can be classified into three broad categories: rule-based techniques [Porter 1980; Sarkar and Bandyopadhyay 2008], supervised techniques [Wicentowski 2004; Yarowsky and Wicentowski 2000], and unsupervised techniques [Majumder et al. 2007; Paik and Parui 2011; Sharma et al. 2008]. The rule-based approach develops rules based on linguistic analysis without training. Usu-ally, the rule-based approach produces the best results for either relatively fixed word order or languages with a limited amount of inflection. However, highly inflectional languages need more in-depth linguistic knowledge of the formation of words to han-dle more complex derivational and inflectional morphology. In highly inflectional lan-guages, it is very common to see compound formation, partial and full combination of two words, and abundant conflation of tense, aspect and mood markers to the root. Our objective is to reverse the effect of inflection or derivation on a stem. In other words, given a  X  X omplex X  word, we want to find its morphological constituents, in particular identify its stem. A machine learning approach, whether supervised, unsupervised or rule-based, needs linguistic resources including substantial corpora, which are sorely lacking in resource-poor languages. Thus, a machine learning approach may not pro-duce better results compared to hand-crafted rules for resource-poor languages like most Indian languages. The two main contributions of our article are the following.  X  In this study, we take into consideration the problem of stemming Assamese (a resource-poor language from Northeast India) texts for which stemming is hard due to the morphological richness of the language. We use three different techniques to find the stem, explained step by step in the following sections. Our experiments reveal that approximately 50% of the inflections in Assamese appear as single let-ter suffixes. Such single letter morphological inflections cause ambiguity when one predicts the underlying root word.  X  After obtaining encouraging result in Assamese (  X  16.5 million native speakers), we use the approaches to stem text in several other Indian languages, viz, Ben-gali (  X  181 million native speakers), 3 Bishnupriya Manipuri ( speakers) 4 and Bodo (  X  1.54 million native speaker) 5 to show the level of generality in our method. Bishnupriya Manipuri and Bodo are vulnerable language according to UNESCO. 6
The rest of the article is organized as follows. We give a brief description of prior work related to stemming in Section 2, followed by the linguistic characteristics of Assamese. The next three sections describe the approach used for stemming. Each section contains results and discussion. Section 7 describes results obtained for the three additional Indian languages. Section 8 gives the concluding remarks. For transliteration of given examples, we use an in-house transliteration scheme and also provide representation using International Phonetics Alphabets (IPA). In most well-studied languages, morphological inflections usually take place at the right-hand end of a word-form and this has influenced the affix stripping approaches to extract the root from a given word. The Porter stemmer [Porter 1980], an itera-tive rule-based approach, has found the most success and is used widely in applica-tions such as spell-checking and morphological analysis. This simple approach was first developed for English and later adapted to Germanic (German, Dutch), Romance (Italian, French, Spanish, and Portuguese), and Scandinavian languages (Swedish, Finnish, Danish, and Norwegian), Irish, Czech, Armenian, Basque, Catalan and Rus-sian [Porter 2012]. [Lovins 1968] introduced a suffix dictionary to assist in finding stems of words. The right-hand end of a word is checked for the presence of any of the suffixes in the dictionary. These two algorithms pre-date the development of many other algorithms such as [Harman 1991; Hull 1996; Lennon et al. 1981; Oard et al. 2001] discover suffixes statistically using a four-stage backoff technique from a text collection and eliminate dependence on word ending. They count the frequency of ev-ery one, two, three and four character suffixes (in decreasing order) that would result in a stem of three or more characters for the first 500,000 words of the collection. A probabilistic stemming approach is described by Diner and Karaoglan [2003] for Turk-ish. String distance-based stemming, an alternative to language-specific stemming is proposed by [  X  Snajder and Ba  X  sic 2009], where stems are classified using a string distance measure called the dice coefficient-based on character bigrams from a cor-pus. McNamee et al. [2001] develop a system which combines word-based and 6-gram based retrieval, performing remarkably well for several languages (English, French, German and Italian). One major pitfall with the n-gram approach is the increase in the size of the inverted index. A series of experiments were conducted by Kraaij and Pohlmann [1996] to enhance the recall of stemming at the cost of precision. They find that stemming of derivational words reduces precision by a considerably higher amount than inflectional words for Dutch.

European languages including English have a number of stemmers available, and their performance has been extensively examined [Harman 1991; Hull 1996]. Some other reported stemmers include French [Majumder et al. 2007; Savoy 1999], Span-ish [Majumder et al. 2007], Finnish [Korenius et al. 2004], Czech [Dolamic and Savoy 2009], and Hungarian [Paik and Parui 2011]. Arabic [Al-Shammari and Lin 2008; Larkey et al. 2002; Rogati et al. 2003; Taghva et al. 2005], Japanese [Kudo et al. 2004; Uchimoto et al. 2001], German [Braschler and Ripplinger 2003; McNamee et al. 2001], and Dutch [Kraaij and Pohlmann 1996] are also well studied in the literature. For language-specific stemming, additional resources (like dictionary) are also often used [Krovetz 2000] to group morphologically related words.

In the Indian language context, a few stemmers have been reported. Among these, Ramanathan and Rao [2003] use a hand crafted suffix list and strip off the longest suffixes for Hindi and report 88% accuracy using a dictionary of size 35,997. The work reported by [Majumder et al. 2007] learns suffix stripping rules from a cor-pus and uses a clustering-based method to find equivalent categories of root words. They show that their results are comparable to Porter X  X  and Lovin X  X  stemmers for Ben-gali and French. The work of Pandey and Siddiqui [2008] focuses on heuristic rules for Hindi and report 89% accuracy. Aswani and Gaizauskas [2010] propose a hybrid form of Majumder et al. [2007] and Pandey and Siddiqui [2008] for Hindi and Gujarati with precisions of 78% and 83%, respectively. Their approach takes both prefixes as well as suffixes into account. They use a dictionary and suffix replacement rules and claim that the approach is portable and fast. Sharma et al. [2008] describe an unsuper-vised approach that learns morphology from an unannotated corpus and report 85% precision. They discuss salient issues in Assamese morphology where the presence of a large number of suffixal determiners, sandhi, samas and the propensity to use suffix sequences make more than 50% of the words used in written and spoken text inflected. Paik and Parui [2011] report a generic unsupervised stemming algorithm for Bengali and Marathi as well as Hungarian and English. Their approach is entirely corpus-based and does not employ language-specific rules. A graph-based stemming algorithm is proposed by Paik et al. [2011] for information retrieval. They report their experiment with two Indian (Marathi and Bengali) and five European (Hungarian, Czech, English, French, and Bulgarian) languages. Reported work of Kumar and Rana [2010] for Punjabi uses a dictionary of size 52,000 and obtain 81.27% accuracy using a brute-force approach. Majgaonker and Siddiqui [2010] describe a hybrid method (rule-based + suffix stripping + statistical) for Marathi and claim 82.50% precision for their system. Work in Malayalam [Ram and Devi 2010] uses a dictionary of size 3,000 and reports 90.5% accuracy using finite state machines. Among the reported work on In-dian languages, the result may vary widely as each author may have individual rules and corpus for the same reported language. As the languages considered in this article except Bengali, are among the most resource-poor languages in the world, we work with a rule-based and a supervised approach, rather than following the current trends towards corpus-based unsupervised stemming [Korenius et al. 2004; Oard et al. 2001; Paik and Parui 2011; Paik et al. 2011; Rogati et al. 2003]. In the languages we work with, large labelled corpora simply do not exist. Most Indian languages are studied infrequently in the global context. Among Indian languages Hindi, Bengali, Tamil, and Telugu are studied more often. Other languages still lack even a single good corpus or basic language processing modules like stem-mers and morphological analysers that are freely available. In this work, we focus on Assamese, Bengali, Bishnupriya Manipuri, and Bodo. The first three languages share the same writing convention and fall in the Eastern Indo-Iranian language group. Bodo, an important language of North-east India, is a member of the Tibeto-Burman language family, but uses Devanagari script for writing. There is no published work on morphological analysis of Bodo and Bishnupriya Manipuri. Some common properties of the languages under consideration are given as follow.  X  All are relatively free word order. This means that the position of occurrence of a word within a sentence may change without changing the overall meaning. For com-plex sentences, phrases can change their position of occurrence within the sentence.
Inside a phrasal/clausal boundary the sequence of word occurrence is normally fixed.  X  The predominant word order is subject-object-verb (SOV) and more than one suffix can be attached to a root word sequentially. In comparison to suffixes, the number of prefixes is very small.  X  They share a small common vocabulary, although we are not interested in measur-ing the number of common vocabulary items among the languages.  X  All are classifier-based verb final languages, that is, verb changes with person and TAM (tense, aspect and modality) markers, not with gender and number.

The manner in which morphology is expressed varies from language to language. For example, among Indian languages, for Hindi, Oriya, Manipuri, and Nepali, most of the English DP X  N X OG  X  DZLJQLJ Assamese DP X   X  LVL X PD O  X  DELJQLJN Bengali DP X  P  X  X  X   X  LOR N X DELJQ X  Bishnupriya Manipuri DP X  Y  X   X  X PD  X  L O  X  D E  X LJLJQ  X  Bodo DP X  D PRQ X  X  X G X EXW X D  X   X N X  X DEDQ Hindi Q DP X   X  D X PD  X  DZLJQNR Manipuri Q DP X   X  KDWODPL DZLJQEX X  Nepali DP O X  X  DNRW X LR X PD  X  DZLJQODL
Oriya DP X  LW X PD  X  LO X   X  DZLJQNX time morphological attributes are separate tokens whereas in the case of Assamese, Bishnupriya Manipuri, Bodo, and Bengali, the morphological attributes are always part of the words and thus need separate methods to handle. We present some com-mon patterns of adding morphological inflection in Table I. In the case of Assamese, Bodo and other similar languages, stemming is the process of finding sub-string(s) in a token. In the context of stemming, the most common property of languages like As-samese is that, they take a sequence of suffixes after the root words. We give some examples in the following. (1) Assamese (2) Bengali (3) Bishnupriya Manipuri (4) Bodo
During literature survey we found that an Assamese noun root word may have 3,500 X 6,000 inflectional forms, although the maximum number of suffixes attached in sequence after the root seems to be limited to five. Among Indo-Aryan languages, Assamese has the largest number of relational nouns to denote relations between two persons [Goswami 2001]. A relational noun root in Assamese may have 10,000 X 15,000 inflectional forms depending on nominal attributes like number, gender, animacy and emphasis. In Appendix A, we list 45 inflectional forms of the noun root ZdU g a (manuh : man ). Likewise, an Assamese verb may also have 300 X 1,500 different inflectional forms depending on person, tense, aspect, honor, mood and emphasis. In Appendix B, we tabulate some inflectional forms of the root 7H ( DV  X  : to be ). Indian languages, including Assamese, have two types of vowels: one is the full vowel and another is the vowel  X  X atra. X  During clubbing suffix sequences into a word, morpho-phonemic changes occur depending on the ending of the base word and the starting of the suffix to be appended. For example, the word 78 (ai : mother ) ends with the full vowel 8 (i). Adding the nominative suffix &gt; (je) at the end of the root word 78 (ai) results a new word 7 kt (aije). Although phonetically (see the sequence of IPA symbols) there is no change after addition of the new suffix, there is a change in the orthography. That is, after clubbing, the vowels 8 (i) and &gt; (je) are changed to  X t (je), semi-vowel + vowel matra. The next section discusses a rule-based approach to stemming, focusing on Assamese. As mentioned earlier, an Assamese root can take a series of suffixes sequentially. So, our first aim is to find the probable sequence of suffixes that a word contains. We manually collected all possible suffixes and categorized them into six basic groups, viz., case marker (CM) (nominative, accusative, locative, genitive, instrumental and dative), plural marker (PM), definiteness marker (DM), emphatic marker (EM), verb markers (VM) and others. The other categories contain kinship noun markers, adver-bial makers and derivational suffixes. Table II shows some suffixes with their counts.
The rule engine generates a list of suffixes. It is a module that generates all probable suffix sequences that may be attached to a root, based on the affixation rules incor-porated in the engine. The rule engine uses a collection of rules that produces a valid list of suffixes in sequence. The rule engine is responsible for generating the proper sequencing of suffix(es). By proper sequencing, we mean that the suffixes must abide by morphotactic rules for Assamese. For example, the addition of a plural marker after a case marker will generate an invalid sequence for Assamese. We have observed that no inflections are attached to the verb root or noun root after the emphatic marker. The following examples illustrate such affixation rules that the rule engine uses to generate the suffix list. The first eleven, Examples (5 X 15), illustrate nominal suffixa-tion. The word Z d U g a (manuh : man ) is the root in Examples 5 through 15 and the word B X  (  X NLJ : to do ) is the root in Examples 16 and 17. (5) root + PM (6) root + CM (7) root + DM (8) root + EM (9) root + PM + CM (10) root + PM + EM (11) root + CM + EM (12) root + DM + CM (13) root + DM + EM (14) root + PM + CM + EM (15) root + DM + CM + EM (16) root + VM (17) root + VM + EM (18) root + others
We confirmed 14 (Examples 5 X 18) such rules and generated 18,194 suffix sequences for Assamese. These rules are implemented using Java RE package. Ex-amples 9 through 15 and Examples 17 and 18 have sequences of two or more suffixes whereas Examples 5 through 8 and 16 have only one suffix each, attached to the root. IU B k a U  X LJQLJNLJK V in Examples 5, 6 and 15, respectively. The rule engine works with all grammatical categories. It generates a list of suffix sequences. The list is arranged in nonincreasing order of the length of the sequence, so that in the next phase the longest possible suffix sequence in an input word can be identified using a sequen-tial look-up of the list. For instance, let us consider the word U QDWLQLM X NN X L X LJQLPDQ X K X  V (Example 1) and assume the suffix sequence list has the and  X  tB k B 8IUfZdkUka U M X NN X L X LJQLPDQ X K X  V in that order. A sequential look-up will yield the segmentation U QDWLQLM X NN X L X LJQLPDQ X K X  V , whereas the segmentation ( U QDWLQ L +
M  X NN X L X LJQLPDQ X K X  ) is more appropriate. Hence the list is arranged in nonincreasing or-der of length of the suffix sequences. The input words are passed through the suffix look-up process. For an input word of length L w , matching is attempted only with the suffix sequences whose length is less than L w  X  1. Any match found in the list, will separate the word matched part as a component. In this experiment, we use a part of the EMILLE 8 Assamese corpus of size 123,753 words. Among these, 25,111 words are unique (including inflected and root words). man ) are considered separate words, although the second and the third words are inflected forms of the first word. We found that 5.85 is the mean word length for the corpus. We manually evaluate the output. One highly educated and native speakers is employed as manual evaluator and found 57% of the words are correctly stemmed by Approach 1. Some observations from these experiments that explain the low accuracy are enumerated as follows. (A) Suffixes such as  X  X d  X  U  X ER V , ZdU U PDQ V and IU U  X LJQ V (B) The error rate for inflected words with suffix length greater than 4 is less than It is clear from this experiment that the error rate decreases with increasing suffix length. As the error rate of single character suffixes is the highest, one possible solu-tion to increase the accuracy of stem identification is to add a root word list, which is discussed in Section 5. It is clear that using the rule set developed in the previous section, we were not able to extract all stems from the input words. On looking closely at the Type-I and Type-II errors, we find that the inputs are root words, but the end letter(s) unfortunately match some valid suffixes from the suffix list. In Table III, we see that the input word  X  U  X  V is the genitive case marker and is in the suffix list. Hence, the stemmer separates  X  U  X  V from B dk V d  X  , producing a wrong stem B d k V d as a suffix from all words that end in  X  even though many such words are indivisible. A Type-II error is similar to a Type-I error, except the number of letters present in the B dk V d  X  U N D S  X R V B dk V d U N D S R V B dk V d  X  U N D S  X R V
LJMR X LJQ X S V  X  k t d U LJ X S M R V
LJMR X LJQLJW X S V  X  k t d U LJ X S M R V H X LJ X GDH X LJ X GD V suffix. The number of words that cause Type-II errors is fewer but such words occur frequently in the text. To handle these two types of exceptions, one way is to maintain a word list (henceforth, called dictionary ) where most frequent stems or roots are kept. For example, words ending with any character listed in Table IV, such as rice ), Z dQ ( PD W : voice ), 6Z  X  ( U  X LJPLJ )) and exceptional root words (such as some ), word per line. Thus in this approach, first each word is checked against the dictionary (that is, words stored in the text file) to be stemmed. After that we apply Approach 1. The main advantage of the approach is that it minimizes over-stemming (removing too many letters as suffix) and under-stemming (removing fewer letters as suffix) errors (c.f. Table XI). We develop a frequent root word list from the entire EMILLE Assamese corpus (ap-proximately 2.6 million words). Alternatively, the dictionary may comprise only those words that clash with the suffixes, thus may improve the search efficiency. Using a Python program, we extract the unique words (including inflected and root words) and their frequencies from the corpus in lexicographic order to ease the identification of the roots. We manually extract and arrange the root words based on frequency. Figure 1 illustrates our experiment to visualize the impact of the size of dictionary coverage in stemming. We choose 5000, 10000, 15000, 20000 and 25000 most frequent root words and test with the corpus described in Section 4.1. We found accuracies of 66, 73, 77, 80 and 81% respectively, when merged with Approach 1. This shows stemming accuracy increases as the size of the dictionary increases, although as expected the increase starts to level off. We also examine the accuracy (i.e., the number of root words) of stemming without combining with Approach 1. For this approach we use a word list of size 25,000 root words. As obvious, the obtained results in Table V are an improvement over the first approach. We use a set of hand-crafted rules as discussed earlier and a dictionary as discussed in this section to stem and obtain an accuracy of nearly 81%. Nearly 19% of the words are still not stemmed properly. Among the incorrectly stemmed words, 23% of the words are marked root words although they possess inflection. That is, the rules fail to extract inflection from such words. On looking closely at the incorrectly stemmed words that are marked as no inflection, we find these are mostly single character inflections attached to the root word. Of the words that are incorrectly stemmed, 57% are incorrectly stemmed as single character inflection. Digging deeper, we find that these words are not in the dictionary and most of them are proper nouns whose end letters are unfortunately the same as some single letter suffix. The common appearance of single letter suffixes as morphological inflections causes the rapid downfall of the accuracy in Approach 2. We find that, among the generated suffixes, 11 suffixes are single letter suffixes and more than 50% of the inflections in Assamese are single letter suffixes. Such single letter morphological inflections cause ambiguity while predicting the underlying root words. This approach eliminates the Type-II errors to a great extent and a fraction of the Type-I errors. A fraction of the Type-I errors still exists, particularly when the stemmer finds an unseen word that ends with a member of the single letter suffix set. Keeping this in mind our goal next is to further improve proper stemming of unseen words and increase accuracy. We describe a Hidden Markov Model in Section 6 to handle single letter inflections left out by the previous two approaches. Table VI makes an important observation when we look at randomly picked news articles in English, Assamese, Bengali and Hindi. Each collection is approximately 2,000 words. Among major Indian languages, Bengali is closest to Assamese in terms of spoken and written forms. Hindi is a closely related language as well, but written using a different script, the Devanagari Script. The fourth column gives the number of unique inflected words.

We observe that among these languages, Assamese has the highest frequency of single letter inflectional suffixes. This behooves us to develop an algorithm to im-prove the accuracy of detecting single letter suffixes to build a better stemmer for Assamese. [Melucci and Orio 2003] use HMMs for stemming five different languages, viz., Dutch, English, French, Italian and Spanish. They design their approach to stem-ming in terms of an HMM with states for two sub-processes or disjoint sets: states in the prefix-set that are considered to be the stems and states in the suffix-set that possi-bly generate the suffix sequence if the word has one. Our problem is a bit different. We intend to devise a model to learn to classify single letter suffixes only. Our work is first of its kind for some of the considered languages. Use of suffix is governed by syntactic principles of a language that may spread over an entire sentence. Since HMM is well known for sequence labelling, it is a suitable candidate for experiments like ours.
Our concept is very simple. We drop the single occurrence of the single letter suffix set from the suffix list generated by the rule engine. We collect all the words, whose end character matches a member of the single letter suffix set, independent of inflectional information. This collection contains only those words, which are not in the dictionary and words that are not covered by the rule engine. This word list is sent as input to the HMM training model to classify. The task described here is an extension of our previous work [Saharia et al. 2013]. Suppose w 0 , w 1 ,  X  X  X  , w n  X  1 are the words of a corpus. Each word w where p i is a root word; s i an inflectional or derivational suffix; and operation between two strings. Let S be the set of inflectional suffixes in the language under consideration including the empty string . For any word, w , we say that word w is a root word , otherwise we say that word w ends with an inflectional or derivational suffix. Using this notation, the word 7Z (am : mango ) can be decomposed as 7Z (am : mango )  X  , as the end letter Z / (  X PDQXK X  : of man ) can be represented as p  X  s with p = ZdU g a 6 Z X  (  X  X P X  : immortal )has p = 6 Z (  X P )and s =  X  (  X  X  ). Although s : immortal ) is a root word. Thus, if there is an inflection s w = p  X  s ,wesay w is morphologically inflected whether the generation is meaningful or not. Therefore, we define two states of the generator, G at the time of generating the word, viz. , inflected word ( M ) and root words or noninflectional words ( N ). We can associate with a corpus of some length : w 0 , w 1 ,  X  X  X  w series of states for the sentence given in Example 19.

Example 19 .
Therefore, for a corpus generated by G , the problem of deciding if a word is mor-phologically inflected boils down to determining the state of G ( N or M ) at the exact moment of generating the word. We construct an HMM-based algorithm to predict the states of G corresponding to the words of any given corpus. Therefore, the problem has two main aspects: ( a ) estimating the HMM parameters with a training corpus and ( b ) applying the calibrated algorithm on a test corpus to detect morphologically inflected words. Our HMM for the generator G can be defined as follows. (i) S is the alphabet that consists of the set of inflections that generator G can gener-(ii) Q ={ N , M } is the set of possible states of G . (iii) A = ( a k ) is the | Q | X | Q | matrix of state transition probabilities of G . In order to compute the optimal path, we use the Viterbi algorithm [Viterbi 1967]. The goal of the algorithm is to compute the probability f ending in state k at w i for every possible state k . In our case, the states are either N or M .

We know that the inaccuracy of the previous method comes mostly from single letter inflections. For multiple letter inflections, the ambiguity of being a true inflection ver-sus a coincidental match of the word with the set of inflections is significantly low. We denote by S 1 and S m the set of single letter and multi-letter inflections, respectively. In order to simplify our analysis, we partition the set of inflections S as Therefore, the appearance of a multi-inflection suffix on a word definitely generates the presence of morphological inflection. Hence, we can safely assume that if s foraword w i , q i = M . We can state the same notion as for q Since we are essentially trying to predict the correct state of G for only single letter inflections (i.e., S 1 ) we assume all inflections in S 1 inflections in S m are equivalent to each other. So we assume that our alphabet S in the Hidden Markov Model is S ={ , s 1 , s m } , where s 1 multi-letter morphological inflections, respectively. For this experiment, we used a random text from the EMILLE Assamese corpus. We labelled approximately 3,082 words with 4 tags.  X  Words with multi-letter inflection ( M sm ) . For example: e]eCXl] (  X  Words with single character inflection ( M s 1 ) . For example: Xt` X  (  X  Words with no inflection, that is, root words ( N e ) . For example:  X  Words that have no inflection but end with a member of the single letter suffix set Table VIII gives details of suffixes present in the training set. It is clear from Table VIII that the number of words with single letter inflection (30.37% in the training data) is more than the number of words with multi-letter inflection (15.06% in the training data). Interestingly as mentioned earlier, words with single letter suffix ( M and words that unfortunately end with any member of the single letter suffix set ( N ) create problems. In the training set, we have 1,686 (936+750) such words, which is more than 50% (54.67%) of the training data and 1,682 words ( N + N noninflected words. In addition to 1,686 (936+750) words that possess any one member of the single letter suffix set at the end, we have 210 more words in the training file, with multiple suffixes that end with any one member of the single letter suffix set. Using Approach 1 and Approach 2, we can handle multiple character inflection well. The statistics of single character inflection in the training set is given in Table IX. From the statistics, it is clear that the genitive case marker (19.33%) is the most frequent among the single letter suffixes. In Assamese, we have 11 suffixes in the single letter suffix set. The last four suffix pairs in Table IX show the vowel matra and the full vowel . Depending on use, they change their form from full vowel to matra or matra to full vowel. As shown in Table IX, among the 11 characters, B (k), 8e X  (i) and &gt;  X   X  (e) are ambiguous, that is the same symbol/letter is used to inflect nouns as well as verbs. The stemming accuracy found using Approach 1 is 57% and using Approach 2 is 82% and using the hybrid approach is 94%. The complete statistics for our experiments are given in Table X. [Sharma et al. 2008] reported 69% F-measure for suffix acquisition, when they tested their unsupervised approach with 300,000 Assamese words. In com-parison with [Sharma et al. 2008], the result produced by Approach 2 with a root word list of only 25,000 entries is considerably better. With the same test data, we found 85% correct stems using Morfessor [Creutz and Lagus 2005]. Morfessor is an unsupervised language independent tool of four morphology learning models based on recursive min-imum description length [Creutz and Lagus 2002]. It takes an unannotated corpus as input and generates morpheme-like units of the words observed in the corpus. The remaining errors in our combined approach are due to irregular use of some verbs. As mentioned earlier, Assamese verb morphology is complex. Finding the root form from with this stemmer. It needs a lemmatizer to extract the root, as the whole form of the irregular verb changes after inflection. However, with our hybrid approach we mini-mize the error rate to &lt; 10%. Embedding more linguistic knowledge using quantitative restrictions like Porter [1980] and Lovins [1968] and by proper handling of compound words and hyphenated words, we may be able to further reduce the error rate. In or-der to give a glimpse of the output difference among approaches, we tabulate the stem extracted by the various stemmers in Table XI for some words containing the noun root Ud L B ( QDWLJN : drama ). We consider the word Ud L B member of single letter suffix set. As obvious, in Approach 1, B is extracted from the end of the root word Ud L B U QDWLJN V producing a wrong stem tracted stem UdL is a valid meaningful word in Assamese. After introducing the word list in Approach 2, the stemmer recognizes UdL B U QDWLJN V as a root word. Morfessor, an unsupervised model, reports UdL B U QDWLJN V and UdL B CU ( QDWLJNN X LJQ : the darma ) as root words. In the second example, the extracted output Ud L B CU ( QDWLJNN X LJQ ) is not a root word, whereas in the first example it is a root word. The authors of Morfessor state their approach as - X  X he general idea behind the Morfessor model is to discover as com-pact a description of the data as possible. Sub-strings occurring frequently enough in several different word forms are proposed as morphs and the words are then repre-sented as a concatenation of morphs X  [Creutz and Lagus 2005]. Morfessor does not use language-specific rules. Based on evidence and probability, it learns to segment words into valid meaning bearing units. Therefore, in case of Examples (iv) through (vii) (Ta-word in the corpus. Due to the controlled rule sequence, our Approach 2 and Approach 3 produce the correct stem. Likewise, we compare the output of the stemmers in the same Table XI for some words containing the verb root B X  (  X NLJ : to do ). After obtaining excellent results in Assamese, we extend our approach to three other languages from Eastern India. Being spoken in the same region they share a small amount of common vocabulary. For each language, we have generated the suffix list using the rule engine and manually developed root word lists. We manually tagged 3,212, 2,540 and 2,621 words using the four tags mentioned earlier for Bengali, Bish-nupriya Manipuri, and Bodo respectively and trained them for the hybrid model. (1) Like Assamese, the Bengali verb is a complex category in terms of inflection. Fi-(2) Bishnupriya Manipuri is an Indo-Aryan language spoken in Assam, Tripura and (3) Bodo , a tonal language with two tones belongs to the Tibeto-Burman language
The obtained results for all the languages are shown in Table XII. The languages used in the study, except Bengali, still lack good balanced corpora. Using our rule en-gine we produce 12,456, 8,694 and 6,344 suffix sequences for Bengali, Bishnupriya Ma-nipuri and Bodo, respectively. Being verb final languages, the investigated languages have a complex morphology for the verb. The small size of the root word list may be the reason behind the low accuracy in Bishnupriya Manipuri and Bodo. We may be able to improve the accuracy by increasing the dictionary size and with more insights to the languages in designing the rules used by the rule engine. These two languages are vulnerable as mentioned earlier and linguistic expertise is difficult to find. For man-ual evaluation, we employ one evaluator for each language; the evaluators are highly educated and native speaker of the language. We compare our result with unsuper-vised approaches such as Dasgupta and Ng [2007], [Das and Bandyopadhyay 2010] and [Sharma et al. 2008] and the comparisons are given in Table XIII. From the ta-ble, it is clear that our approach work well with low resource languages, particularly ones from India. We also compare our results with these obtained by Morfessor. The obtained results are shown in Table XIII with 123,753, 130,512, 42,580 and 40,103 words for Assamese, Bengali, Bishnupriya Manipuri, and Bodo, respectively. We have to mention here that the corpora used for Bishnupriya Manipuri and Bodo are not balanced. For Bishnupriya Manipuri, texts are collected from blogs and Wikipedia, whereas for Bodo we have manually typed 40,103 words for our work. In Table XIII, the results obtained in our experiments with Morfessor and the hybrid approach are presented. Other three results shown are from the respective reports. Since the data sets (and languages) for the different approaches are not the same, small variations in the quality of the output may be ignored. In this work, we have presented stemmers for texts in Assamese, Bengali, Bishnupriya Manipuri, and Bodo. All are morphologically rich, agglutinating and relatively free word order Indian languages. First we use a rule-based approach and obtain 57%, 56%, 53% and 45% stemming accuracy, respectively. Next, we add a frequent word list to the rule-based approach and increase the accuracy substantially to 81%, 84%, 77%, and 71% for the same languages, respectively. We found that for the language set, a dominant fraction of suffixes are single letter and words ending such single let-ters create problems during suffix stripping. Therefore, we propose a new method that combines the rule-based algorithm for predicting multiple letter suffixes and an HMM-based algorithm for predicting the single letter suffixes. The resulting algorithm uses the strengths of both algorithms leading to a much higher accuracy of 94% compared to just 82% for Assamese and 94%, 87% and 82% for Bengali, Bishnupriya Manipuri and Bodo, respectively. It is possible that named entity recognition, prior to stemming or in parallel may help. This is because many errors occur with OOV words, a lot of which are named entities. However, since languages considered (except Bengali; even Bengali researchers complain of lack of corpora and tools) are resource-poor languages, named entity recognizers are not readily available although there is some published research [Ekbal and Bandyopadhyay 2008; Sharma et al. 2012]. As future work, it would be interesting to explore the possibility of modelling all morphological phenom-ena using other successful techniques such as Optimality Theory [Prince and Smolen-sky 1993], Maximum Entropy Models [Ratnaparkhi 1997] and Conditional Random Fields [Lafferty et al. 2001] and comparing the results with those of our approaches. We found 5,260 inflectional forms for the Assamese noun root ZdU Table XIV lists a few of the inflectional forms. The second column is the inflected word, the third column represents the transcribed form in IPA and the fourth column shows the break-up of the word into valid morphological units.
 2. Z dU g aka PDQX KK  X  ZdU g a X a 4. ZdU g kakUd d PDQ XK X  Q R ZdU g a X   X   X U d 6. Z dU g ka8kQ d PDQXK X LW R ZdU g a X   X  8kQd 8. Z dU g ka@kU PDQXK X RQ X  ZdU g a X   X  @ X U 10. Z dU g aIU PDQX K X  LJQ ZdU g aIU 19. ZdU g aIUf Q PDQX K X  LJQL W K X  ZdU g aIUfQ d 23. ZdU g akLd  X X d PD Q X K WRLJ  X  ED ZdU g a X Ld  X  X d 24. Z dU g aZCd  X  ka PDQXKPLJN  X  K X  X DLJ ZdU g aZCd  X   X a 25. Z d U g aZ Cd  X  kakU PDQXKPLJN  X  K X Q X  X DLJ ZdU g aZCd  X   X a X U 26. ZdU g ae X ]d B l] @ PDQXKELODNORLR ZdU g ae X ]d B  X ]@ 27. Z dU g ae X ]d B l]@kGdU PDQXKELODNORLRVRQ ZdU g ae X ]d B  X ]@ X GdU We found 380 inflectional forms for the Assamese verb root 7 H ( DV LJ : to be ). Table XV lists a few of the inflectional forms. The second column is the inflected word, the third column represents the transcribed form in IPA, and the fourth column shows the break-up of the word into valid morphological units.
 Table XVI shows single-letter suffixes in Bengali. Table XV shows suffix information in the training corpora.

