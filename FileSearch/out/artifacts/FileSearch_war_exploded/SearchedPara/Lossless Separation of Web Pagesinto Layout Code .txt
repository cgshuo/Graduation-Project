 A modern web page is often served by running layout code on data, producing an HTML document that enhances the data with front/back matters and layout/style operations. In this paper, we consider the opposite task: separating a given web page into a data component and a layout program. This separation has various important applications: page encoding may be significantly more compact (reducing web traffic), data representation is normalized across web designs (facilitating wrapping, retrieval and extraction), and repetitions are diminished (expediting updates and redesign).
We present a framework for defining the separation task, and de-vise an algorithm for synthesizing layout code from a web page while distilling its data in a lossless manner. The main idea is to synthesize layout code hierarchically for parts of the page, and use a combined program-data representation cost to decide whether to align intermediate programs. When intermediate programs are aligned, they are transformed into a single program, possibly with loops and conditionals. At the same time, differences between the aligned programs are captured by the data component such that ex-ecuting the layout code on the data results in the original page.
We have implemented our approach and conducted a thorough experimental study of its effectiveness. Our experiments show that our approach features state of the art (and higher) performance in both size compression and record extraction. Many modern webpages are served by applying layout code to structured data, producing an HTML page that is presented to the user. The resulting HTML page contains both formatting elements inserted by the layout code, and values that are obtained from the structured data. The page is therefore a blend of formatting ele-ments, and actual data.
 Goal Our goal is to separate a given HTML page into a layout code component and a data component such that: (i) the separation is lossless , running the extracted layout code on the extracted data reproduces the original page, and (ii) the separation is efficient such that common elements become part of the layout code, and varying values are represented as data.

This separation has various important applications: page encod-ing may be significantly more compact (reducing traffic), data rep-resentation is normalized across different Web designs (facilitating wrapping, retrieval and extraction), and repetitions are diminished (expediting updates and redesign). Many of these applications are not limited to static web pages but can also be applied to dynami-cally generated pages (e.g., by using a headless browser to obtain a static HTML page).
 Existing Techniques There has been a lot of past work on data extraction from web pages [1, 3, 6, 8, 18, 19, 24 X 28, 32 X 35, 37, 42]. Techniques have also been presented for wrapper induction , using the template structure of a page to produce a wrapper that extracts particular data elements [7, 10, 22]. While the use of templates is essential for improving uniformity, readability, and maintainabil-ity of web-pages, templates are considered harmful for many au-tomated tasks like semantic-clustering, classification and indexing by search engines. Therefore, a lot of past work tackled the chal-lenges of template identification [2, 21, 24, 29, 42] and template-extraction [4, 9, 13 X 15, 20, 36]. Typically, the goal of these works is to identify or extract the template so it can be ignored/discarded, and the data could be passed to further processing.

Separation combines, and generalizes, two aspects of the ex-traction problem that are typically considered separately X  X ecord extraction, and template extraction X  X nd seeks to balance them. Rather than treating the template as noise when extracting data, or eliminating data when extracting a template, separation seeks to extract both at the same time. The separation algorithm we present extracts layout code and not a static template. Furthermore, it at-tempts to maintain a balance between the quality of extracted layout code, and the structure of the extracted data.
 Our Approach We present, implement, and evaluate a method for automatically separating a static template-generated HTML page into a template layout-code and data. The main idea of the separa-tion algorithm is to synthesize layout code hierarchically for parts of the page, and use a combined program-data representation cost to decide whether to align intermediate programs. When inter-mediate programs are aligned, they are transformed into a single program, possibly with loops and conditionals. At the same time, differences between the aligned programs are captured by the data component.

In contrast to previous work on template extraction, which iden-tifies template-chunks to remove or extract as features, we syn-thesize fully working template-code which when invoked on the extracted data reproduces the original static HTML page. There are many possible ways to represent a page as a layout-code and data. We guide our choice of separation by attempting to min-imize the joint representation size of the page, according to the MDL [31] principle. Our approach could be applied to any form of tree-structured data, and can be used for applications such as tree retrieval [23].

We have implemented our approach in a tool called S YNTHIA conducted a thorough experimental study of its effectiveness. Our experiments show that S YNTHIA features state of the art (and higher) performance in both size compression and record extraction. There has been a considerable amount of work on page-level data extraction (e.g., [1, 5, 12, 19, 33, 34, 40]) and record-level extrac-tion (e.g., [3, 6, 11, 24, 26, 27, 32, 35, 37, 42]). In the following, we focus on closely related work.

A lot of related work has dealt with the problem of template ex-traction or wrapper induction , for record extraction . As such, the focus has been on templates that are based on regular expressions, and more importantly, the resulting separation into templates and records is lossy; that is, we cannot recover the original HTML doc-ument from the output records and template. We focus on lossless separations into data and code, where the code involves (nested) loops and conditions. The notion of wrappers and patterns is dif-ferent from our notion of code , since the former describes how to access the DOM tree to extract data, whereas the latter states how data is processed to generate the DOM tree. Moreover, we aim at finding separations of a short description; traditionally there has not been much focus on the complexity of the template, but rather mainly on its ability to perform high-quality record extraction. An-other distinction between our solution and many existing ones is that those require multiple different pages (of the same template) as input, whereas our solution already works on a single page. Next, we describe some of these systems.

FiVaTech [19] works on a set of pages to automatically detect their shared schema and extract the data. Their solution applies several techniques such as alignment and pattern mining to con-struct a structure called  X  X ixed/variant pattern tree, X  which can be used to identify the template and detect the schema. TEX [34] ex-tracts data, but does not extract the template or the schema of the data. Trinity [33] builds on TEX and improves it by using the tem-plate tokens to partition the document into prefixes, separators and suffixes. They recursively analyze the results to discover patterns and build a  X  X rinity tree, X  which is later transformed into a regu-lar expression for data extraction. RoadRunner [7] uses a matching algorithm to identify differences between the input documents and build a common regular expression. It starts by considering one page as a wrapper, and matches it with another page. It then re-fines it using generalization rules to compensate for mismatches. EXALG [1] uses the concept of equivalence classes and  X  X ifferen-tiating roles X  to discover a template, which is a regular expression. TPC [28] considers a web document as a string of HTML tag paths. It detects the repeated patterns of tags paths called  X  X isual signals X  within a page, clusters them based on a similarity measure that cap-tures how closely the visual signals appear in the document. For each one of the clusters the method uses the paths of its visual sig-nal to extract records from the page. RSP [35] takes as an input a web page and a sample subject string which is used to help identify subject nodes. The method uses the repetitive pattern of subject items in a page to identify the boundary of data records. It aligns data records to find a generalized pattern, which is used to generate a wrapper. The method generates a template wrapper that describes the location of data records and can be used to extract them. MDR [24] and DEPTA [42] use tag strings representation of DOM nodes to compare individual nodes and combinations of adja-cent nodes. Similar individual nodes or node combinations are con-sidered as generalized nodes, and sequences of generalized nodes Figure 2: A sample static html snippet that we would like to sepa-rate into code and data. are considered as a data region. DEPTA [42] uses partial tree align-ment to align generalized nodes and extract their data. DeLa [37] automatically generate regular expression wrappers based on the page HTML-tag structures to extract data objects from the result pages. IEPAD [6] discovers repeated patterns in a document by coding it into a binary sequence and mining maximal repeated pat-terns. These patterns are then used for data extraction.
In contrast to alignment algorithms used in other works (e.g., [19, 28, 35, 42]), our tree-alignment algorithm operates on layout code trees with their data, and updates both the code and the data com-ponents. In addition, as opposed to classical alignment algorithms, which define a fixed cost per alignment operation, the costs in our algorithm are context dependent.

To the best of our knowledge, none of the related works are able to produce runnable layout code and provide lossless separation into layout code and data. In this section, we give an informal overview of the problem we formulate in this paper, and of our solution S YNTHIA . We provide a formal treatment in the following sections. 3.1 Motivating Example Fig. 1 shows part of a navigation web page taken from www. viewpoints.com/explore (we focus on a part of a page for illustrative purposes; the solution of this paper works on full pages). Given this page, our goal is to separate it to a layout-code component, and a data component. Technically, a layout tree is a tree representation Figure 3: (a) The DOM tree of the original HTML document, and (b) the layout tree produced by our approach from this DOM tree. of a program that formats data into a web page. We formally define layout trees in Section 4.

Fig. 2 shows the HTML document of Fig. 1. This HTML con-tains repeated formatting elements for the listed items. For exam-ple, the items Medicine , Diet Pills , Diets , Toothbrushes , and Multivitamins are formatted in a similar HTML structure.
The HTML document can be viewed as a DOM tree [39]. Fig. 3(a) shows the DOM tree for the HTML document of Fig. 2. In this tree, the subtrees of the div elements share a similar structure, and so do the subtrees under the ul elements. S YNTHIA is able to detect these common structures, synthesize the corresponding layout trees, and extract hierarchical data that captures the different contents that are laid in the common structures.
 Synthesized layout tree Fig. 4 shows the code synthesized by our technique for the page of Fig. 2. The code can also be viewed in tree form as the layout tree shown in Fig. 3(b).

This code uses two iteration ( for ) instructions to create a nested loop structure that is used to format the data. Our layout tree uses standard control constructs common in any layout language, and uses a syntax similar to JSP. The tree refers to variables , such as f1 and v1 , that are assigned actual values in the extracted data. Extracted data Fig. 5 shows the data extracted by our technique. Data is extracted as a hierarchical structure, where data elements are labeled by their corresponding loop or variable. For example, the data elements under the label f1 are the elements that are iter-ated over by the for operation in line 1 of the extracted code. The data elements under the label f2 (in lines 3 and 7 of Fig. 5) are the elements that are iterated over by the for operation in line 4 of the code. As our data is viewed as an assignment of values to variables that are used in the layout tree, we refer to a data instance as an environment . An important feature of our approach is the fact that the separation is lossless X  X xecuting the synthesized layout tree on the extracted environment reproduces an exact copy of the original HTML document. This should be contrasted with common lossy techniques for wrapper induction and record extraction. 3.2 Our Approach From a high-level perspective, S YNTHIA works by folding adjacent subtrees of a layout tree. Initially, the layout tree is simply the DOM tree representing the web page. As subtrees are being folded, we synthesize unified code that represents their common structure, and create separate data elements to represent their different values. There are two trivial solutions to this problem. The first is where all subtrees are folded, forcing a single layout tree and effectively pushing all differences into the data. The other trivial solution ap-plies no folding at all, and then the layout tree effectively dumps the entire web page. Naturally, we are not interested in the trivial solutions, but rather in a solution that minimizes the representation cost . Intuitively, this means that we should only fold subtrees when they share a sufficiently common structure.

To find a folding that minimizes the representation cost, we have to answer two technical questions:
We address both of these questions using a novel alignment al-gorithm. We use the alignment algorithm as a building block for deciding when to fold subtrees, and also for computing the separa-tion into layout tree and data when subtrees are folded. Subtree folding In a bottom-up manner, we analyze adjacent lay-out subtrees by evaluating their structural similarity. This is done by calculating the representation cost for representing the subtrees using a shared single layout tree and two data components. That is, we estimate the benefit of forcing the subtrees into using the same layout tree with separate data.

To that end, we use our alignment algorithm to compute an align-ment that attempts to minimize the resulting representation cost, and also returns the cost. We fold together adjacent subtrees which are found to be similar (based on the calculated shared representa-tion cost). Folding is done by (i) applying the calculated alignment. The result may include conditional instructions and variable refer-ences in text nodes and attributes to overcome differences; (ii) in-troducing a for instruction whose body is the resulting shared lay-out tree while verifying losslessness (i.e., when invoked on the data, the result is the same as that of the sequence of folded subtrees). Alignment We present a novel tree-alignment algorithm, that is tai-lored to handling layout trees, enabling it to handle loops, condi-tions and variables in the template. In addition, we enable it to perform data extraction and modifications to the data representa-tion, in order to fit changes in the layout trees, so that invoking the layout trees on the data will result in the original HTML.
E XAMPLE 1. Fig. 6 shows a few steps of our algorithm applied to the (partial) tree of Fig. 3. Initially, the layout tree is the orig-inal DOM tree (L1), with no folding, and no extracted data (D1). The algorithm works in a bottom-up manner, looking for folding opportunities. The algorithm detects that the subtrees rooted at list items ( &lt;li&gt; ) for Medicine , Diet Pills , Diets , Toothbrushes , and Multivitamins could be folded with common structure and extracting the varying data. The algorithm folds the subtrees cor-responding to the following items:
By introducing new layout trees and extracted data. The layout tree is as follows:
This synthesized layout tree uses variables v1 and v2 to refer to data elements in the extracted data. The synthesized code is shown in Fig. 6 (L2) as the subtree rooted at FOR:f1 . The extracted data is shown at the bottom part of the figure (D2). The data is struc-tured and is labeled by names corresponding to the variables in the layout tree. For example, the data maps the variable f1 , used at FOR:f1 , to a sequence of four possible values, each providing the data for one invocation of the loop body, resulting in one of the four aligned subtrees. The inner data values provide the interpretation of variables v1 and v2 .

This folding reduces the original combined description length of the code and data, as the template part that repeats in all four items is described only once, in the code, and only the differentiating details are described for each item (in the data).

The subtrees rooted at list items for Bottles , ... , Strollers are folded in a similar manner, resulting with the layout subtree rooted at FOR:f2 (this is also depicted in L2 in Fig. 6).
After creating the layout trees rooted at FOR:f1 and FOR:f2 , the algorithm proceeds by identifying that these subtrees could be folded together. This folding renames variables of the two subtrees to match each other (e.g., f1 is renamed to f2 , unifying it with the existing f2 variable of the subtree on the right). Folding also introduces new variables, v1 and v2 , to account for differences (note that these are fresh variables, as the previously used v1 and v2 were renamed). Finally, folding introduces an additional ex-ternal for loop with variable f1 (recall that the previous f1 was renamed). The produced layout tree is shown in Fig. 4. A graphical representation is shown in Fig. 6 (L3). The corresponding extracted data is shown in (D3). Note that folding also adds another layer to the data, corresponding to the nested loop structure.

In this simple example folding does not introduce conditional constructs. However, if, for example, all items in the first list had an additional attribute, the folding of the two for subtrees depicted in L2 would introduce a conditional construct guarded by a boolean variable, with  X  X rue X  in the first loop and  X  X alse X  in the second. 3.3 Key Aspects The example of the previous section highlights a few key aspects of our approach: In this section we formally define the notions of a webpage, data and template code which is used to generate webpages by invoking it on a given data.
 DOM Trees We model an HTML document as a DOM tree , which is a tree of elements and textual values. Formally, a DOM tree is a rooted and ordered tree with two types of nodes. An element node has a name , and an attribute set , which is a mapping from a finite set of attribute names to values (strings). The children of an element node form an (ordered) sequence of nodes. A text node is associated with a textual value. We require all text nodes to be leaves (i.e., childless).
 Environment As we explain later, we model the construction of DOM trees by executing programs over data. We model data by means of an environment , which is a hierarchy of assignments to variables. Formally, we assume an infinite set Var of variables . An environment is inductively defined as follows. It is a mapping from a finite set of variables to values, where a value is either (i) a text item, or (ii) a list of environments.
 Layout Trees We now define our model of a program, namely the layout tree , that executes over an environment to produce a DOM tree. This model is very simple, and is straightforward to translate into common languages that embed code with HTML/XML (e.g., server side like ASP and JSP, or client side like Javascript, Angu-larJS and XSLT).

Recall that a DOM tree has two types of nodes: element and text nodes. A layout tree is similar to a DOM tree, except that it has a third type of nodes, namely instruction nodes . An instruction node v is associated with a type and a variable. The type of an instruction node can be one of three: condition , iteration , and reference . The variable of an instruction node is a member of Var . We refer to an instruction node with the variable x and the type condition, iteration a layout tree is either an element node or a text node. 1 Semantics of a Layout Tree The result of executing a layout pro-gram  X  over an environment E is a DOM tree that we denote by  X  ( E ) . To define  X  ( E ) formally, we need some notation.
A DOM hedge is a sequence of DOM trees. Similarly, a lay-out hedge is a sequence of layout trees, except that we allow each layout tree to be rooted at an instruction node. For hedges h = t ,...,t k and g = u 1 ,...,u m , we denote by h  X  g the hedge that is obtained by concatenating g to h (i.e., t 1 ,...,t k ,u If v is a node and h is a hedge, then we denote by v [ h ] the tree that is obtained by adding v to h as the root (with the roots of h being the children of v ). If t is a tree with the root v , then we denote by t  X  v the hedge that is obtained from t by removing v .

To define  X  ( E ) , we give a more general (inductive) definition of the semantics of executing a layout hedge  X  over E , again denoted by  X ( E ) , and is generally a DOM hedge.
Finally, recall that a layout tree has a non-instruction root. Then the above definition implies that the result of executing a layout tree over an environment is always a single DOM tree.
Our approach creates layout trees by folding subtrees of a DOM tree. As the root is never folded, it remains a non-instruction node. In this section we formally define the space of separation solutions, and the desirable separation solutions in that space. 5.1 Separation and Solution Space Our goal is to describe a given DOM tree by a layout tree and an environment. Formally, a separation of a DOM tree t is a pair (  X , E ) , where  X  is a layout tree and E is an environment, such that  X  ( E ) = t . Separating t is the process of constructing a separation (  X , E ) of t . Note that a DOM tree may have many separations (in fact, infinitely many separations). We denote by Sep ( t ) the set of all separations of t .
 A special case of a separation in Sep ( t ) is the trivial one (  X , E ) where  X  is identical to t and E is empty. 5.2 Separation Quality Since there are many possible ways to separate a given DOM tree, it is important to define what makes one separation better than an-other. In this work, we define a quality metric that is inspired by the principle of Minimal Description Length (MDL) [31]. Accord-ing to MDL, one should favor the model that gives the shortest description of the observed data [17]. MDL is well-suited for deal-ing with model selection, estimation, and prediction problems in situations where the models under consideration can be arbitrarily complex, and overfitting the data is a serious concern [16]. In par-ticular, S YNTHIA aims at synthesizing a separation that minimizes the length of the representation of the separation. To define the length of the separation, we define a size measure for a given sepa-ration (  X , E ) . The description length of (  X , E ) is defined based on the size in characters of the string representations of  X  and E , de-noted sizeof (  X  ) and sizeof ( E ) , respectively. Hence, we define the following: cost (  X , E ) def = sizeof (  X  ) + sizeof ( E ) .
Our algorithm (defined in the next section) does not guarantee a separation of minimal cost. Instead, it applies a heuristic approach that uses the above cost for guiding intermediate decisions along the way. We leave for future work the challenge of obtaining opti-mality and analyzing the associated computational complexity. In this section we describe our algorithm for folding a DOM tree into a layout tree and an associated environment. 6.1 The General Separation Algorithm Given a DOM tree t , our algorithm constructs the separation (  X , E ) recursively, as we describe below. We denote the input DOM tree t as v [ t 1 ,...,t n ] (that is, the root is v and it has n children, each is the root of a subtree t i ). The separation algorithm goes as follows. 1. Recursively separate each t i into a separation s i = (  X  2. Split s 1 ,...,s n into m chunks ( s 1 ,...,s j 1  X  1 ) , 3. Fold each chunk ( s j l ,...,s j l +1  X  1 ) into a single separation 4. Return the separation (  X , E ) where  X  = v [  X  0 1  X  X  X   X 
Note that in step 4, the different E 0 l use pairwise-disjoint sets of variables; hence, their union E is a legal environment.

We denote by fold ( s 1 ,...,s k ) the procedure used in step 3 for folding a sequence s 1 ,...,s k of separations s i = (  X  i new separation s = (  X , E ) . Next, we explain how splitting and folding are implemented (In practice, they are weaved together). 6.2 Splitting To split a sequence s 1 ,...,s n of separations into chunks, we de-fine a pairwise similarity function  X  that assigns a score to each pair of separations. We define a chunk to be a maximal continuous sub-sequence s j l ,...,s j l + q l of s 1 ,...,s n where  X  ( s than some fixed threshold for every i = j l ,...,j l + q l the chunks are broken where similarity is below the threshold. The similarity function  X  is based on the fold procedure, as follows. For two separations s and s 0 , let s f = fold ( s,s 0 ) . Recall the definition of cost ( s ) in . Then  X  ( s,s 0 ) is the relative reduction of cost gained by replacing s and s 0 with s f ; that is, 6.3 Folding In the rest of the section, we describe the procedure fold . Recall that the input is a sequence s 1 ,...,s k of separations s and the output is a single separation (  X , E ) with the property that  X  ( E ) is the hedge  X  1 ( E 1 )  X  X  X   X  k ( E k ) . fold ( s 1 ,...,s k ) is performed by introducing a new for ( x ) node with a single child  X  c . The single child  X  c captures the common layout of  X  1 ,..., X  k . The differences between them are captured by conditional and reference nodes in  X  c , along with an environ-ment, E c i , that is generated for each  X  i . The environment E based on E i (the environment that  X  i was accompanied with), but also includes the values of the new conditional and reference vari-ables that are introduced in  X  c i . Finally, the output environment E that accompanies  X  is constructed by
R EMARK 1. Splitting is aimed at identifying separations that will be unified by fold into a new for root with a single child that generates all of them (with proper environments). If the number of chunks exceeds some threshold (above 30% of the number of children number), we consider folding into a for node with d &gt; 1 children. To do so, S YNTHIA looks for chunks in which separations in distance d from each other are similar. Folding is adapted ac-cordingly to collapse separations in distance d from each other to one child of the for node (rather than collapsing all separations in the chunk to a single child). This enables S YNTHIA to deal with data items that correspond to a sequence of adjacent nodes in the tree.
The crux of folding is the construction of  X  c (the child of the for node), along with the environments E c 1 ,..., E c k . This construction is done by applying on the input trees  X  1 ,..., X  k and their envi-ronments E 1 ,..., E k an alignment algorithm, which we describe next. Alignment operations may introduce conditional and refer-ence nodes, and may align trees (or hedges) with for nodes, but they never introduce new for nodes. for nodes are introduced by folding (the procedure fold ). 6.4 Alignment We consider alignment of two layout trees with their environments. To handle a larger number of layout trees, we apply alignment incrementally: we first align two layout trees (and their environ-ments), then align the result with another and so on, until all are aligned.

Intuitively, when given two separations (  X  1 , E 1 ) and (  X  alignment unifies their layout trees by establishing a common lay-out tree and updating the environments. The result is a triple (  X  , E 0 1 , E 0 2 ) such that  X  0 ( E 0 1 ) =  X  1 ( E 1 ) and  X  order to allow an incremental alignment (as needed for the align-ment of more than two layout trees), where we apply alignment on the result of a previous alignment which consists of two environ-ments, we work with environment series E = ( E 1 ,..., E k of environments E . Alignment is defined inductively, and for that another generalization is required. Namely, instead of two layout trees  X  we work with two layout hedges  X  . The need for this gener-alization will later become apparent. We denote by  X ( E ) the series ( X ( E 1 ) ,...,  X ( E k )) of DOM hedges.
 D EFINITION 1. Let  X  1 and  X  2 be layout hedges and E 1 and E 2 be two environment series. An alignment of ( X  1 , E ( X  2 , E 2 ) is a triple ( X  0 , E 0 1 , E 0 2 ) such that  X  and  X  0 ( E 0 2 ) =  X  2 ( E 2 ) .

The objective of our alignment is to minimize the combined de-scription length of the unified layout tree and the corresponding environments. We therefore define an alignment cost, similarly to the notion of separation cost: cost ( X  0 , E 0 1 , E 0 2 ) = X 6.4.1 Scope Environments The most tricky part of the alignment is the update of the environ-ments. To explain this update we need the following definitions. Scope. Given a layout tree  X  , each iteration node in  X  defines a scope. The scope of a node v in  X  is determined by its lowest ancestor v s which is an iteration node for ( x ) (or by the root if no such ancestor exists). In the former case, we say that v scope node and x is the scope variable of v . To simplify matters and prevent ambiguity, we do not allow two iteration nodes to have the same variable. We define the scope node and variable of a hedge similarly by considering the lowest common ancestor.
 Scope environments. Given a layout tree  X  and an environment E , the scope environments of a node v in  X  , denoted S ( v ) , are defined inductively based on the scope of v . If the scope of v is the root, then S ( v ) = {E} . Otherwise, let v s and x be the scope node and scope variable of v , respectively (i.e., v resides in the subtree of v = for ( x ) ). Then S ( v ) = S E That is, that scope environments of v are all the environments in the lists that x is mapped to.

E XAMPLE 2. Consider the layout tree L3 in Fig. 6 and the en-vironment depicted in D3. The node &lt;li&gt; resides in the subtree of the node FOR:f2 . Therefore, its scope environments are the nine environments consisting of the five environments in the first list of environments associated with variable f2 : E  X  Medcicine 00 , v4 :  X 176 00 } ,..., E 15 = { v3 :  X  Multivitamins v4 :  X 109 00 } , along with the four additional environments in the second list, E 21 = { v3 :  X  Bottles 00 , v4 :  X 54 00 } ,..., E  X  Strollers 00 , v4 :  X 264 00 } . 6.4.2 Alignment Operations Alignment of two hedges  X  1 and  X  2 , (usually these are children hedges of two nodes that are being aligned) with environment se-ries E 1 and E 2 respectively, is performed using a dynamic pro-gramming algorithm. The algorithm advances along the two given hedges simultaneously and aligns their trees. The operations considered by our alignment algorithm are: Align , Skip and AlignFor , which we describe next. Align and Skip are conventional operations in alignment algorithms (unlike traditional alignments, in our case special care is taken to ensure that the align-ment is lossless). The AlignFor operation enables for -rooted trees to be aligned with a hedge rather than a single tree.
 Align . aligns (  X  1 , E 1 ) with (  X  2 , E 2 ) where  X  1 gle trees with matching roots, which means that they have the same name and type. In this case, we introduce a new root node v which unifies the roots v 1 and v 2 of  X  1 and  X  2 (as demonstrated below). The children of the new root are the result of recursively aligning the children hedges  X  1 and  X  2 into a hedge  X  . In particular, the recursive operation might update E 1 and E 2 .

For example, if v 1 and v 2 are both text nodes (meaning that  X  and  X  2 are empty) and text ( v 1 ) = text ( v 2 ) , then the unified root v is identical to (both of) them and E 1 and E 2 remain unchanged. However, if text ( v 1 ) 6 = text ( v 2 ) , then v is a reference node of the form ref ( x ) , where x is a fresh variable. For i = 1 , 2 , we add to each scope environment of v i in E i the mapping x 7 X  text ( v
If v 1 and v 2 are for ( x 1 ) and for ( x 2 ) , then v is for ( x ) , where x is a fresh variable, and we update all the scope environments of v and v 2 in E 1 and E 2 respectively by renaming every occurrence of x with x .
 Skip . aligns ( X  1 , E 1 ) with (  X  2 , E 2 ) where  X  1 is an empty hedge and  X  2 is a tree by introducing a conditional node v of the form if ( x ) , where x is a fresh variable. The alignment result is then the tree  X  0 = v [  X  2 ] , with E 1 updated by adding the mapping x 7 X  0 to each scope environment of  X  1 , and E 2 updated by adding the mapping x 7 X  1 to each scope environment of  X  2 . Technically, in this case, we also receive the scope node (and variable) of  X  empty hedge) as input (in other cases this input is not needed since it is uniquely defined given the tree or hedge).
 AlignFor . aligns (  X  1 , E 1 ) and (  X  2 , E 2 ) where  X  tree (which is possibly the result of alignment with previous trees from  X  2 ). Intuitively, the result of the alignment will be a for -rooted tree that in addition to the trees captured by  X  1  X  . Repeated applications of AlignFor enable aligning a for tree with a hedge. This operation has some resemblance to fold , yet it utilizes an existing for node (from  X  1 ), rather than introducing a new one. The tricky part in this operation is that it breaks up existing scopes in  X  2 due to the import of the for -node from  X  a result, a new hierarchical level is also created in the environments in E 2 . Due to space constraints we omit the detailed description. 6.4.3 Alignment Algorithm Given ( X  1 , E 1 ) and ( X  2 , E 2 ) our algorithm computes an align-ment while trying to minimize its cost. It also calculates the re-sulting cost. It uses dynamic programming to find the sequence of alignment operations which minimizes the alignment cost.
The algorithm gradually fills a two dimensional matrix B of size n  X  m , where n = |  X  1 | and m = |  X  2 | . For each 1  X  i  X  n and 1  X  j  X  m B [ i,j ] . cost contains the minimal alignment cost of the prefix hedge  X  i 1 of  X  1 of length i , and the prefix hedge  X   X  2 of length j . B [ i,j ] .op contains the operation for  X  resulted in the minimal cost.

The algorithm calculates B [ i,j ] . cost and B [ i,j ] .op by calculat-ing the cost of all possible alignment operations for  X  i by using the costs calculated in B for i 0 &lt; i and j 0 rithm picks the option with the minimal cost. Finally, B [ n,m ] .cost is the alignment cost of ( X  1 , E 1 ) and ( X  2 , E 2 ) . The cost of operations The cost of an operation reflects the change in both the layout tree and environment costs. As the following example demonstrates, the latter is not fixed per operation, but de-pends on E 1 and E 2 .

E XAMPLE 3. Consider the alignment of two subtrees,  X  l and  X  , where  X  l is a subtree residing under a loop node for ( x ) which has 10 scope environments and  X  r is an element subtree with a single scope environment. A conditional subtree insertion during the alignment will introduce a new conditional value in these 11 environments (one of  X  r and 10 of  X  l ). As such, its effect on the cost depends on the number of scope environments.
 We demonstrate the cost calculation on some of the operations. Align (aligning single trees). The algorithm recursively calcu-lates the minimal alignment cost for (  X  i 1 , E 1 ) and (  X   X  is rooted at v 1 and  X  j 2 is rooted at v 2 . Skip (aligning an empty hedge with a tree (to left)). We calculate the code cost of wrapping  X  i 1 with a conditional node v data cost of updating every scope environment in E 1 and E denote the cost of adding the conditional subtree and updating the environments as cost left c . Then the cost of applying the skip align-ment operation is cost left c + B [ i  X  1 ,j ] . cost .

E XAMPLE 4. Consider the folding of the left-most sequence of &lt;li&gt; nodes in the layout tree L1 from Fig. 6. Each of these nodes is accompanied by an environment capturing the mapping of the variables in its subtree. In our case these environments are initially empty, as the &lt;li&gt; subtrees have no variables (yet). The fold op-eration first aligns these subtrees. Alignment recursively aligns the respective text nodes under the &lt;a&gt; nodes from different subtrees. These text nodes have different values (e.g., Medicine vs. Multi-vitamins). Therefore alignment introduces a reference node with variable name v1 and updates the scope environments of the dif-ferent subtrees to include a mapping of v1 to the respective value. Similarly, v2 is introduced. Therefore, each of the environments includes a mapping of both v1 and v2 . The fold operation then wraps the resulting aligned subtree with a for node FOR:f1 (intro-duced in layout tree L2) and adds a mapping of the variable f1 in the main environment to a list containing the updated environments (as reflected in the environment D2).

R EMARK 2. As a post-processing phase, S YNTHIA identifies vari-ables that always have the same value whenever they appear to-gether in the same environment. Such variables are renamed to the same variable to avoid duplications in the data. In this section, we evaluate our approach across multiple dimen-sions. First, we show that our technique is good for data extrac-tion by evaluating it on standard datasets, and comparing it to three other state of the art data extraction techniques. Then, we show that our technique is good for separation of code and data by computing the combined representation size (MDL). 7.1 Evaluation of Data Extraction 7.1.1 Methodology To evaluate the effectiveness of our approach for data extraction, we have used the common testbeds TBDW [41] and RISE [30]. We compare our approach to DEPTA [42], a technique that works on single pages, as well as to techniques that handle multiple pages: MDR [24], TPC [28], FivaTech, and Trinity (as reported by [33]). Testbed 1: TBDW The TBDW testbed contains 253 web pages from 51 sites. Each web page in the testbed is manually labeled with the correct number of records, and the content of the first record. We use TBDW to compare the performance of our algo-rithm with that of DEPTA [42], MDR [24], and TPC [28]. For DEPTA, where the code is available, we reproduce the results by running the DEPTA tool. For MDR and TPC, we compare our re-sults to those reported in [24, 28].
 Testbed 2: RISE The RISE testbed contains 663 pages from 5 dif-ferent site. We use it to compare the performance of S YNTHIA FivaTech and Trinity as reported by [33]. RISE checks the perfor-mance of page-level record extractors. It contains pages with single records, something that S YNTHIA is not meant to handle, but is able to handle if pages are merged into a single page. To enable our tool to deal with single record pages, we put all the DOM trees of these different pages as children subtrees under a shared  X  X oot X  node, and apply S YNTHIA on the resulting tree. DEPTA is excluded from the comparison on RISE, because it was not designed to handle multi-ple pages, and applying it to our single merged page produces very poor results (which we consider unfair comparison).
 Experiment We run S YNTHIA on the 253 pages from TBDW and 663 pages from RISE, and collect the records extracted from each page. For each page, our approach extracts a hierarchical represen-tation (json) of the data on the page. We consider the list of envi-ronments in the data corresponding to a  X  X or X  variable as a table of records. If the relevant data was separated to two or more different tables, we only consider the table containing the biggest number of relevant records as the table of records identified by S YNTHIA Ground Truth As suggested in TBDW, the first record on a page, together with the page itself, defines the ground truth of the set of data records of the page. The ground truth for each site is obtained by the union of all ground truth sets of its pages.
 Comparing Results We ran both our algorithm and DEPTA [42] on the 253 webpages from the 51 websites in the testbed. We com-pare the set of records extracted by each approach to the ground truth. For the comparison, we consider the ground truth over all websites, as well as the set of true positives , which consists of data records correctly extracted by the algorithms, and the set of false positives , which consists of items that are wrongfully identified as data records. We report the precision and recall of each approach:
In addition, to compare our results with TPC [28] and MDR [24], we use the same partial set of 43 websites containing 213 web pages from TBDW used in [28]. In this case, the ground truth, true posi-tives and false positives, are computed per website. The results are the average recall and precision aggregated for all sites.
To compare to FivaTech and Trinity, we ran our tool on RISE dataset and compared its results to those reported by Trinity in [33]. 7.1.2 Results The results of S YNTHIA when compared to DEPTA on the whole TBDW dataset are reported in Table 1. As seen from the table, many cases DEPTA fails to find the boundaries of the data records, frequently merging several records into one.
 Table 1: Accuracy comparison with DEPTA on the TBDW dataset Table 2 shows the results of our tool when compared to DEPTA, MDR and TPC on a partial set of 43 websites containing 213 web pages from TBDW (we denote it TBDW-P). The TBDW-P is sug-gested by TPC [28] and it excludes pages from TBDW containing nested structures, in order to provide a fair comparison with the MDR algorithm, which is designed for flat data records. The As can be seen from the results, MDR suffers from similar recall is-sues as DEPTA, while having a lower recall. Generally speaking, our algorithm has the best performance, both in precision and recall compared to the three other algorithms.

The TBDW dataset contains a few pages with a single result record. Our algorithm fails to extract such records since it works on a single page and not on a group of pages generated using a similar template. This contributes to the small loss of recall (95.6% and 96.2% on the partial and full sets respectively) of our algorithm. The results for running our tool on RISE dataset are reported in Table 3. Our tool outperforms both Trinity and FivaTech in most of the sites of this dataset. Trinity is the closest among the two in terms of performance. Our tool has low recall when extracting the records from IAF. We reviewed the web pages, and found that different data records are not of the same length. While our tool is capable of dealing with data records of length&gt;1 (not wrapped by a single html tag, which is not so common), our tool does not deal with records of varying lengths.
 Table 3: Record extraction performance comparison between 7.2 Evaluation of Code and Data Separation 7.2.1 Methodology The TBDW dataset contains the search results generated by search-able databases, also called search result records (SRRs). These pages are always of a common format of list of results. In this dataset, our approach recognizes that the format does not vary be-tween records, and that formatting is part of the template. To eval-uate the quality of the resulting code/data on general websites, we consider benchmarks with more significant page structure. We cre-ated our own dataset(available at: https://goo.gl/PKY0VI) by col-lecting 200 pages from 40 popular websites in 8 categories, with 5 different pages from each site. In all of our experiments we also verify that the separation computed by S YNTHIA is indeed lossless by running the extracted code on the extracted data and comparing the result to the original page.
 Quality of Separation Inspired by the MDL principle [9], we con-sider the length of the combined code/data representation as an in-dicator for the quality of separation. On the one hand, considering similar code subtrees as separate subtrees will prevent potential re-duction in representation size due to the code representation. On the other hand, folding together different subtrees and represent-ing them using a single code tree will introduce many conditional constructs and dynamic references, resulting in a more complicated and bigger data. A good solution will know when to fold two sub-trees and when to keep them separate, in a way that keeps the rep-resentation length minimal.

For each page we compute the size in bytes of the data and code representation produced by our approach, denoted | data ( page ) | and | code ( page ) | respectively. We use these to compute
When the entire page is considered code (this is one of the triv-ial solutions for separation), the reduction-ratio is 1. The reduction in representation size results from deduplication of the shared tem-plate repeating in a code-generated page. The reduction is bigger in pages having more regularity. Previous work on template ex-traction [15] reported that the template size is around 40%-50% of the page size. If this template is regular, we can expect to obtain significant savings in representation from this part of the page. Comparing Results Since we are not aware of any other approach that separates a single page into data and code, we compute the reduction-ratio of our approach and compare it to 2 other simpli-fied implementations with different features (referred to as basic and w/nesting in the table). The first implementation is inspired by RTDM [29, 36] and is based on a traditional tree edit distance metric both for the decision which subtrees to fold and for folding them. The second algorithm is based on a bottom-up tree edit dis-tance computation. The main difference between the two is that the latter can deal with nested data regions by first running on a node X  X  children before trying to fold them. In contrast, our algorithm cal-culates the minimal shared representation size of two subtrees, and uses it as the basis for deciding which subtrees to fold. In addition, folding minimizes the shared representation of the folded subtrees. 7.2.2 Results The results in Table 4 show that using a bottom-up algorithm, which enables dealing with nested data-regions, improves the reduction-ratio compared to the simpler approach based on tree edit distance. Furthermore, the results show that our algorithm significantly out-performs both of the algorithms that are based on tree edit distance in terms of representation size.
 Table 4: Ratio of reduced size to original size (reduction ratio). Lower numbers represent better reduction. Figure 7: Running times as a function of the nodes count for the different documents in the two datasets 7.3 Running Time We recorded the running time of our algorithm on the 453 different web pages from both TBDW and our dataset. All experiments were run in a single thread on a Macbook Pro with Core i7 CPU and 16GB memory. The running time is reported in Fig. 7. We found that our tool has an average run-time of 53 ms on pages from the two datasets. It processes 95 . 9% of the pages in the two datasets in less than 150 ms and 99 . 5% of the documents in less than 1 sec . We presented a technique for separating a webpage into layout code and structured data . Our technique computes a separation that is lossless , which means that running the extracted code on the ex-tracted data reproduces the original page. Because there are many ways to separate a webpage into layout code and data, we make sure that our separation is efficient by aiming to minimize the joint description length of code and data. What this means intuitively, is that our technique attempts to find a separation such that common elements become part of the layout code, and varying values are represented as data. The ability to separate webpages has various important applications: page encoding may be significantly more compact (reducing Web traffic), data representation is normalized across different Web designs (facilitating wrapping, retrieval and extraction), and repetitions are diminished (expediting site updates and redesign). We show the effectiveness of our approach by evalu-ating its performance both for size compression and record extrac-tion. Despite the fact that our approach is not specifically tailored to these applications, it outperforms state of the art data extraction tools, and achieves impressive compression ratios.

As code becomes increasingly important in producing the con-tent of a page [38], we believe that layout code (more generally, page code) and the problem of code extraction should receive more attention. In future work, we plan to address the separation problem with primitives for data generalization.
 The research leading to these results has received funding from the European Union X  X  Seventh Framework Programme (FP7) un-der grant agreement no. 615688 -ERC-COG-PRIME and the Is-rael Ministry of Science and Technology, grant no. 3-9779. The research of Benny Kimelfeld is supported by the Israeli Science Foundation, grant no. 1295/15 and grant no. 1308/15. [1] A RASU , A., AND G ARCIA -M OLINA , H. Extracting [2] B AR -Y OSSEF , Z., AND R AJAGOPALAN , S. Template [3] C AI , D., Y U , S., W EN , J.-R., AND M A , W.-Y. Vips: a [4] C HAKRABARTI , D., K UMAR , R., AND P UNERA , K.
 [5] C HANG , C. H., K AYED , M., G IRGIS , M., AND S HAALAN [6] C HANG , C.-H., AND L UI , S.-C. IEPAD: information [7] C RESCENZI , V., M ECCA , G., AND M ERIALDO , P.
 [8] D ALVI , N., B OHANNON , P., AND S HA , F. Robust web [9] D HOLI , M. P. R., AND C HAUDHARI , K. Template [10] F AZZINGA , B., F LESCA , S., AND T AGARELLI , A. Learning [11] F UMAROLA , F., W ENINGER , T., B ARBER , R., M ALERBA [12] F UMAROLA , F., W ENINGER , T., B ARBER , R., M ALERBA [13] G AO , B., AND F AN , Q. Multiple template detection based [14] G ERACI , F., AND M AGGINI , M. A fast method for web [15] G IBSON , D., P UNERA , K., AND T OMKINS , A. The volume [16] G R X NWALD , P. D. The minimum description length [17] H ANSEN , M. H., AND Y U , B. Model selection and the [18] H AO , Q., C AI , R., P ANG , Y., AND Z HANG , L. From one [19] K AYED , M., AND C HANG , C.-H. Fivatech: Page-level web [20] K IM , C., AND S HIM , K. Text: Automatic template [22] K USHMERICK , N., W ELD , D. S., AND D OORENBOS , R. B. [23] L I , J., L IU , C., Y U , J. X., AND Z HOU , R. Efficient top-k [24] L IU , B., G ROSSMAN , R., AND Z HAI , Y. Mining data [25] L IU , D., W ANG , X., L I , H., AND Y AN , Z. Robust web [26] L IU , W., M ENG , X., AND M ENG , W. Vision-based web [27] L IU , W., M ENG , X., AND M ENG , W. Vide: A vision-based [28] M IAO , G., T ATEMURA , J., H SIUNG , W.-P., S AWIRES [29] R EIS , D. D. C., G OLGHER , P. B., S ILVA , A. S., [30] RISE. Rise: A repository of online information sources used [31] R ISSANEN , J. Modeling by shortest data description. [32] S IMON , K., AND L AUSEN , G. Viper: augmenting automatic [33] S LEIMAN , H., C ORCHUELO , R., ET AL . Trinity: on using [34] S LEIMAN , H. A., AND C ORCHUELO , R. Tex: An efficient [35] T HAMVISET , W., AND W ONGTHANAVASU , S. Information [36] V IEIRA , K., DA S ILVA , A. S., P INTO , N., DE M OURA [37] W ANG , J., AND L OCHOVSKY , F. H. Data extraction and [38] W ENINGER , T., P AL X CIOS , R., C RESCENZI , V., [39] W OOD , L., ET AL . Document object model (dom) level 1 [40] W U , S., L IU , J., AND F AN , J. Automatic web content [41] Y AMADA , Y., C RASWELL , N., N AKATOH , T., AND [42] Z HAI , Y., AND L IU , B. Web data extraction based on partial
