 In this demo we present AMETHYST, a system for explor-ing and analyzing a topical hierarchy constructed from a heterogeneous information network (HIN). HINs, composed of multiple types of entities and links are very common in the real world. Many have a text component, and thus can benefit from a high quality hierarchical organization of the topics in the network dataset. By organizing the topics into a hierarchy, AMETHYST helps understand search results in the context of an ontology, and explain entity relatedness at different granularities. The automatically constructed top-ical hierarchy reflects a domain-specific ontology, interacts with multiple types of linked entities, and can be tailored for both free text and OLAP queries.
 I.7 [ Computing Methodologies ]: Document and Text Processing; H.2.8 [ Database Applications ]: Data Mining Topic Modeling, Network Analysis, Heterogeneous Network, Entity Mining
Heterogeneous Information Networks (HINs), composed of multiple types of entities and links are very common in the real world, and have become increasingly more impor-tant to analyze and understand [3]. Many of them have a text component, inviting many interesting recent applica-tions of topic mining techniques [2, 5, 4, 1]. One such impor-tant application is constructing a high quality hierarchical organization of the concepts in a dataset at different levels of granularity [6], which heralds a more nuanced understanding of topics and subtopics in the dataset as a whole.
In order to apply the automatically constructed hierar-chy to browsing, search, and summarization tasks on the HIN dataset, we present AMETHYST (Analyzing, Mining, and Exploring a Topical HierarchY SysTem). Compared with other systems that support topical analysis and multi-dimensional mining tasks, such as Arnetminer [5], Topic the following key features:  X  The topics are organized in a hierarchy where more gen-eral topics are parent of more specific topics. The hierarchy helps understand search results in the context of an ontology, and explain entity relatedness at different granularities.  X  The topical hierarchy is automatically constructed from the data and therefore reflects the domain-specific ontology and accommodates user preference.  X  The topical hierarchy interacts with multiple types of linked entities, and can be tailored for both free text and OLAP queries.
There are many examples of HIN X  X  with text components, such as a bibliographic network, a collection of user reviews. For example, Figure 1a shows the schema of the DBLP pub-lication network consisting of a paper and its related entities: authors, publication venue, publication year, and some key terms. Figure 1b shows the schema of another HIN, con-structed from news articles, consisting of an article and its related entities: people, locations, and organizations men-tioned in the article, the publication date, and keywords.
Throughout this paper we will use a publication network dataset consisting of papers published in DBLP to illustrate the functionality of our system. However, AMETHYST can work with any HIN which can be used to successfully build a topical hierarchy. Furthermore, if multiple topical hier-archies are generated for the same dataset, exploring them with our system can provide a deeper understanding of the implications of the different ways of organizing information.
Figure 2 illustrates the offline (red) and online (blue) ar-chitecture components of AMETHYST: a cademic.research.microsoft.com  X  Topical Hierarchy Construction: Construct a top-ical hierarchy given an HIN dataset, representing the top-ics present in the dataset, with each topic represented by a ranked list of mixed-length topical phrases.  X  Entity-Topic Relationships: Precompute the rela-tionship between every entity present in the HIN and every topic in the hierarchy, to facilitate browsing and searching.  X  Topical Hierarchy Browsing: Users can choose an available dataset, and browse the topical hierarchy via a web interface. For each entity type, the most relevant entities are listed for each topic in the hierarchy.  X  Topical Hierarchy Search: Users can perform free-text queries, and/or explore just the slice of the hierarchy that represents the topics of an OLAP query, with related phrases and entities re-ranked accordingly for each topic.
For a given dataset, we first precompute the topical hier-archy (or possibly several topical hierarchies), as well as the entity-topic relationships between the entities in the dataset and the topics in the hierarchy. The input to the construction of a topical hierarchy is an HIN with a text attribute, as described in Section 1, and the output is a hierarchical tree of topics. The basic unit of a topical hierarchy is a phrase. The output is a tree of topics, where each topic is represented by a ranked list of mixed-length topical phrases, such that a child topic is a subset of its parent topic. Every non-root topic t in a topical hierarchy is represented by a ranked list of phrases {P t , r t ( P P t is the set of phrases for topic t , and r t ( P t ) is the ranking score for the phrases in topic t . For every non-leaf topic t in the tree, its children C t are its subtopics. For example, in a topical hierarchy based on the DBLP dataset, the topic of query processing and optimization may be described by the phrases {  X  X uery processing X ,  X  X uery optimization X ,... } , while its parent topic of general problems in databases may be de-scribed by {  X  X uery processing X ,  X  X atabase systems X ,  X  X oncur-rency control X ,... } . A phrase can appear in multiple topics, though it will have a different ranking score in each topic (e.g.  X  X uery processing X  in the above example).

Topical phrases that would be regarded as high quality by human users are likely to vary in length. Unlike exist-ing phrase extraction and ranking methods which are term-centric, our approach is phrase-centric and is able to nat-urally compare mixed length phrases with each other. Re-gardless of length, a phrase is ranked highly within a topic if it has good coverage, is discriminative, has high phraseness (it is a true phrase, e.g.  X  X ctive learning X  in a topic about machine learning, and not simple a combination of frequent unigrams, e.g.  X  X earning classification X ), and is complete (e.g.  X  X ector machines X  is incomplete, since it is nearly always a subset of the longer phrase  X  X upport vector machines X ).
The process of constructing the topical hierarchy results in every phrase in the hierarchy having a topical frequency value for every topic in the hierarchy.

Definition 1 (Topical Frequency). The topical fre-quency f t ( P ) of a phrase is the count of the number of times the phrase is attributed to topic t . For the root node o , f ( P ) = f ( P ) . For each topic node in the hierarchy, with quency is equal to the sum of the sub-topical frequencies.
Table 1 illustrates an example of estimated topical fre-quency of phrases for a computer science topic that has 4 subtopics. For instance, the phrase  X  X upport vector ma-chines X  is estimated to belong entirely to the machine learn-ing (ML) topic with high frequency, while  X  X ocial networks X  is fairly evenly distributed among three of the topics. Each phrase X  X  topical frequency is recursively estimated for subtopics, in order to perform hierarchical topic construction. Table 1: E xample of estimating phrase topical frequencies
AMETHYST also uses the phrase topical frequency values to define the relationships between entities in the original HIN and topics in the hierarchy.
In order to browse the heterogeneous entities associated with each topic node, as well as run user queries, we calculate the entity-topic relationships offline. We use the link data from the original network, as well as the topical frequency of every phrase present in the hierarchy. We also keep a persistent index of the document-phrase relationships for the dataset. We estimate the topical score of each document based on the topical frequencies of the phrases contained in the document. A document containing phrases ranked highly in topic t will therefore have a high topical score in that topic. We then estimate the topical score of each entity based on the topical scores of the documents which link to it in the HIN. This offline computation of the entity-topic relationships is then used in the online tasks of browsing and searching.
We first present the web interface of AMETHYST and demonstrate how a user might explore a topical hierarchy constructed from an HIN dataset. We then describe the different search functionalities.
Figure 3 demonstrates the interface of AMETHYST for browsing. The main menu is in the top right corner, allowing users to choose a dataset to load, browse the resulting topi-cal hierarchy, or search the topical hierarchy (search details are discussed in Section 4.2) To illustrate the interface, we assume that the user has loaded the aforementioned DBLP dataset, and is exploring the topical hierarchy.  X  Structure View: leftmost panel, visualizing the struc-ture of the entire topical hierarchy. Clicking a node zooms in on that area of the topical hierarchy. In Figure 3, the user has selected the third child of the root node.  X  Zoom View: central panel, which zooms in on the selected node (highlighted). Each node represents a topic in the hierarchy, and displays its top ranked topical phrases. The user may click other nodes or use the mouse to move around in this view. The rectangle in the Structure View will shift accordingly, as a constant reference for the user X  X  current location in the hierarchy.  X  Topic Detail View: the rightmost panel, below the main menu, which provides detailed information about the selected topic. The  X  X hrases X  tab shows a significantly longer list of the topical phrases. Other entity types present in the HIN dataset are also represented by tabs (authors and con-ferences, in the case of the DBLP dataset). Each tab shows a ranked list of the most relevant entities to the selected topic. In Figure 3, the user has selected a topic that is generally about data mining, and so the Authors tab of the Topic Detail View displays well-known data mining authors.  X  Topic Temporal View: the histogram below the Topic Detail View, showing the relative temporal distribution of documents which are associated with this topic (if the cur-rently loaded HIN dataset has a temporal attribute). In Figure 3, the temporal distribution is generally growing, most likely because the number of publications in the DBLP dataset increases with each year. In Section 3.2 we described how we calculate the topical score of each document offline. Therefore, the histogram value for a given topic t and a given time period y can be estimated from the topical scores of all documents, s t ( d ) where T ime ( d ) = y .
The other online components of AMETHYST enable the user to perform different search tasks. By clicking on the Search option in the menu bar, users can choose to perform a topical search using entities or free text as input, using an input area that appears beneath the menu bar.
A user may be interested in focusing on a subset of the topical hierarchy. For instance, which topics discovered from the DBLP dataset reflect the work of a particular author, or a group of authors? Or, which news topics have cropped up in a particular location? Our topical search functionality makes it easy to slice and dice the topical hierarchy via an OLAP implementation.

Given a query consisting of a specific set of criteria (e.g. an author, a conference, or a year range for the DBLP dataset), we do not construct a new topical hierarchy. Rather, we filter the existing hierarchy so that only topics relevant to the query are highlighted, and we re-rank the phrases and entities within each topic. For a given query we can filter the original HIN and select only those central document objects whose entities satisfy the criteria given in the query (e.g., all papers published in a queried year). For each topic, we are now able to use the precomputed relationships described in Section 3.2 to re-rank its phrases and entities based on the strength of their links with the selected documents.
For example, the user may be interested in the topics that the author Jiawei Han has worked in since the year 2000. Figure 4 demonstrates the result of the user issuing this query. The query itself is visible in the input area below the menu bar. The Structure View now reflects the impor-tance of various topics from the original hierarchy, relative to the query. The phrases within each topic, as well as the entities connected to each topic are reordered. Notice how in the example result, the selected node in the Zoom View shows only those phrases that are closely related to asso-ciation rule mining to be ranked highly (compare with the top-ranked phrases for this same node visible in Figure 3 which mention gene expression data, a phrase that is not very relevant to the query, and which has therefore been downranked in the topic.) The Topic Detail View shows that the top ranked phrases for this topic continue to be fairly closely related to association rule mining. Finally, the Topic Temporal View reflects the fact that Dr. Han X  X  publication rate on this topic peaked in the mid-2000s.
A user may be interested in examining the contexts in which a phrase, or a set of phrases appears in the topical hierarchy. The topical hierarchy search interface shown in Figure 4 allows the user to query using free text. All topi-cal hierarchy phrases which exist in the free text query are identified. The topics containing these phrases are then vi-sualized, accentuating the topics in which the phrases are highly ranked, and thus providing the user with the topical context of their query. The free text search may also be combined with an OLAP query, as indicated in Figure 2. Our system can work with a variety of datasets such as DBLP, news articles, and other data collections with similar schema. Other applications of mining HINs with text com-ponents may also be explored with AMETHYST, such as related entity search, expert finding, and ontologies which incorporate user guidance.
This work was supported in part by the U.S. National Sci-ence Foundation grants IIS X 0905215, CNS-0931975, and IIS-1017362; U.S. Army Research Laboratory under Coopera-tive Agreement No. W911NF-09-2-0053 (NS-CTA); and IIS-1017362, U.S. Air Force Office of Scientific Research MURI award FA9550-08-1-0265, and MIAS, a DHS-IDS Center for Multimodal Information Access and Synthesis at UIUC. Chi Wang was supported by a Microsoft Research PhD Fellow-ship. Marina Danilevsky was supported by a National Sci-ence Foundation Graduate Research Fellowship grant NSF DGE 07-15088.
