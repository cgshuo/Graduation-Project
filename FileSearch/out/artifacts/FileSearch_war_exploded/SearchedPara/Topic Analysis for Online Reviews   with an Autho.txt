 Dirichlet Allocation (LDA) model has become popular due to its solid theoretical foundation and promising performance, and several strategies have been proposed to extend the model in order to simulate the contexts for different purposes [3, 4, 5, 8]. 
On the other hand, social data available in the internet has drawn attention to improve traditional topic analysis. For instances, the Topic-Perspective model [9] simulates the generation process of social annotations by modeling the tag generation the process. The Author-Topic Model (AT) [3] extends the basic topical model to include author information in which topics and authors are jointly modeled. Each distribution over words. The Author-Recipient-Topic model (ART) [4] is proposed sensitive messages sent between entities. 
The online reviews, free text generated by the authors to comment on target objects (i.e. services or products), is one popular type of social media in the current internet. The authors, target objects as well as the reviews form a heterogeneous network, which we refer to as social review network. Although much work has been done for review network [7, 12]. The AT model adds an author layer to LDA, and the ART reviews. Previous work in recommendation systems and collaborative filtering has exist on those links [10, 11]. In order to utilize the social network information of online reviews, we propose an Author-Experience-Object-Topic Model (AEOT), a new probabilistic generative social review network, including the authors, objects and content of reviews. topic modeling and various models for social media proposed in previous research. Section 3 presents the proposed AEOT Model for online reviews and introduces the parameter estimation process. In section 4, we evaluate the performance of the proposed model based on an online movie dataset. In section 5, we conclude the paper and present the future work. For social media, several strategies extending LDA have been proposed, which For instance, the APT model assumes that each author write under one or more matching papers with reviewers [6]. The Pairwise-Link-LDA and the Link-PLSA-LDA models jointly model both text and link for Academic Social Networks [5]. The author-topic model [3] uses the authorship information together with the text to learn topics. Among these models only the authorship information is incorporated into the model. 
In recommendation system and collaborative filtering domain, the users, items and the links between them form a heterogeneous network. Generally the user and the item are modeled together [17]. The Topic-Perspective model [9] simulates the documents, words, and tags) as well as latent variables (topics, user perspectives) in a unified model. FolkRank [11] is proposed to exploit the structure of the users, resources, and tags, and the user-based assignment of tags to resources called folksonomies for social bookmark. To our knowledge, few of work utilize the social review network for topic analysis. In this section, we introduce the proposed Author-Experience-Object-Topic Model for and the generation process of content terms in a unified framework. This model is to represent and connect all the observed and hi dden variables of social review network in a unified framework. By estimating this model, we can learn the topical structures of the reviews relevant with the authors and objects. 3.1 Motivation In web communities for online reviews, one author may write multiple reviews towards different objects and one object may be commented by multiple authors. Thus the authors, objects and reviews form a heterogeneous social review network. 
In social review network, we assume that the content of each review entails the commenting. For the same target object and the nearly same experience, different authors may give different review. Secondly, each object has multiple aspects which see a film because he had a nice seat. As shown in Table 1, the snippet 1 is about the author, the snippet 2 discusses the experience, and the snippet 3 talks about the movie. 1: they recently sent me a vhs copy of their down with america trilogy and i decided to spend an hour of my day watching it. 2: sure , the risky use of vhs instead of super 8mm or 16mm was a pain , and the natural light was one of the most annoying things about public access films, 3: but the movie itself was fairly enjoyable. down with america concerns a government agent , needless murder , and a book containing everything from the unabomber's manifesto to the 1995 apple computer profit report . 3.2 The Author-Experience-Object-Topic Model The model is designed based on the real social commenting process, in which a term may be generated from the author, the object or the experience. In order to reflect this control the influence of the author, the object and the experience. The proposed model vocabulary, U denotes the number of authors and O denotes the number of objects in distributions. 
As shown in Fig. 1, the generative process of review in the model can be described as follows:  X  For each document d , sample  X  (e) d ~Dir(  X  e )  X  For each author u , sample  X  (u) u ~Dir(  X  u )  X  For each object o , sample  X  (o) o ~Dir(  X  o )  X  For each document d , sample  X  d ~Dir(  X  )  X  For each of the K topics k , sample  X  k ~Dir(  X  )  X  For each of the N d word tokens w i in document d : As shown in Fig. 1 (c), our model adds an author layer, an object layer based on LDA. Dir(  X  ) is the prior Dirichlet distribution for choosing x among experience, author and which term is associated with the author, which term is associated with the object and which term is associated with the experience, as shown in Table 1. In fact our model is very similar to author-topic model [3] except the generation of variable x as shown in Section 3.4. 3.3 Gibbs Sampling Algorithms Several methods have been developed for estimating the latent parameters in LDA [13], and Gibbs sampling [2]. Compared to the other two methods, Gibbs sampling often yields relatively simple algorithms for approximate inference in high-dimensional models such as LDA. Therefore we select this approach for parameter estimation. For our model, we derive the sampling equations for our model. terms: We draw each ( z i ; x i ) pair as a block, conditioned on all other variables. When x=exp , the sampling equation is: where e d n is the number of times that words are generated from experience in review review d ; k n . is the number of times that words are assigned topic k . k w number of terms in the vocabulary. 
When x=user , the equation is: times that words are generated from author u in the review d ;. 
When x=obj , the equation is: times that words are generated from object o in the review d ;. 
After a set of sampling processes based on the posterior distributions calculated with above equations, we can estimate the parameters for any single sample using the following equations:  X  3.4 Generation of Variable x word, where x is to control the generation of z and w . In AT [3] for each word w , an author, x is chosen at uniform from a d , all authors of the documents. And in ART [4] The ACT model in [14] is similar to AT model for the generation of latent author x d . generation of x in this paper is more reasonable than in AT and ART. For comparison, another model is proposed which we refer to as AEOT-R. In AEOT-R model, the x is model is better than AEOT-R for online reviews. 3.5 Variants of AEOT Model the words with  X  exp =1 are completely generated from the experience and not affected LDA. Contrarily, the words with  X  user = 1 are totally generated from the author. Thus totally generated from the object. 
Especially if only  X  user is set to 0, the words are generated from the experience or the generated from the author or the object. Summarily our model can be transformed to six simpler models, as listed below. with the AT model in [3]. And each review has only one author. In this section, we investigate the performance of the proposed AEOT model based on for online reviews. 4.1 Dataset ids. And the information of the left 29 html pages is incomplete. For the experiments, we selected 17657 reviews as the dataset. To further clean the dataset, stop words and dataset used for experimentation contains 17657 reviews, 155 authors, 1540 movies, 46661 unique words and 4,970,358 word tokens. Then we randomly selected 1601, around 9% of the reviews as a held-out test data and trained the model on the remaining 90%. The data is available online 2 . 4.2 Experimental Setup The AEOT model has five Dirichlet prior parameters. Previous research also found that these parameters only affect the convergence of Gibbs sampling but not much the experiments. For the number of topics K, we set to 50, 100, 150 and 200 respectively sampler is set to 1000, and the iteration number is set to 400 for the held-out test data in all experiments empirically. 4.3 Document Modeling In the experiments, we use perplexity as the criterion for model evaluation. Perplexity data. 
Fig. 2 plots the perplexities of eight models being compared, introduced in the section III-E on the test data for topic number set to 50, 100, 150 and 200 respectively. The ULM is the abbreviation of smoothed unigram language model, where the smoothing parameter is set to 0.05. similarly, and are the best of all the eight models. It X  X  very strange that the performance of EAT is so good. Further studies uncover the secret that the most of words are assigned model. That is to say, the EAT is degraded and similar to the LDA. 
However the AT performs very badly, just better than the ULM. But OT and EOT perform similarly and better than AT. It seams that the object plays a more important role in social review network. In fact the most of words in the movie review are related with the target movie, and the results are consistent with our intuitive. 
The AEOT works better than AOT slightly. At the same time, we note that the result can improve the performance and plays an important role in the AEOT model for AT Model [3], which could improve the performance of AT. However the role of experience is limited for the AOT and AEOT perform similarly. 
However the performances of AOT and AEOT are worse than the results of EAT and LDA, but the AOT and AEOT can produce the distributions over topic of authors and objects simultaneously from the social review network. 4.4 Two Strategies about the Generation of x ART [4] and ACT [14]. We implemented the AEOT-R and AOT-R, where the x is drawn uniformly. For perplexity, the AEOT-R is a little worse than AEOT except for K=50 and AOT-R is much worse than AOT, as shown in Fig. 3. Especially the performance of AOT-R is much worse than other models. The experimental results suggest that the drawing strategy of variable x in this paper is more efficient than that in AT, ART and ACT for online reviews. The results provide a good suggestion for design of the switch variable in probabilistic generative model. 4.5 Discovered Topics Table 2 shows 9 topics discovered by LDA and AEOT respectively in the training obtained by LDA (as shown in the left of Table 2). In machine learning there has been standard measure for it yet. We leave the problem as future work. 
In our experiments, we remained the words "the, their, them, then" in the vocabulary, not contained in the stop word list. In most of topics discovered by LDA, the word "the" is the top 1 word out of the top 50 words. As shown in the left column of Table 2, there are 8 topics in which the word "the" takes the first place. But in the topics discovered by AEOT, there is only one topic, in which the list of top 50 words contains the word "the", as shown as topic No. 9 in Table 2. It seems that the AEOT model could produce more coherent topics than LDA intuitively. This is a very interesting result that we will explore how to evaluate in the future work. 
No. Topics by LDA Topics by AEOT In this paper, we presented a social review network, and proposed the Author-Experience-Object-Topic Model for topic analysis of online reviews. This model The proposed AEOT is general and can be transformed to simpler models including LDA. Experiments on the movie review dataset that we extracted from the original social recommendation, review classification, author X  X  community analysis, target object clustering, information retrieval for reviews, review sentiment analysis and other review X  X  text mining tasks. 
How to evaluate the coherence of topics pr oduced by topic models is intractable. In future work, we will focus on the evaluation of coherence of topics and study how to apply the model to recommendation system. Recommender systems are usually classified into three categories based on th eir approach: content-based, collaborative, and hybrid approaches combining content-based and collaborative methods [18]. Recommendation system based on social review network may be another promising for experimentation to test our model's applicability in the future. Acknowledgments. We thank anonymous reviewers for their useful comments. The paper is supported in part by the National Nature Science Foundation of China (Grant No. 90820005 and 61070082). Ying Su is the corresponding author. 
