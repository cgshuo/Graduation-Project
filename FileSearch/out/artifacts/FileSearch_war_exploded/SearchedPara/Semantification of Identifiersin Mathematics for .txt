 Mathematical formulae are essential in science, but face chal-lenges of ambiguity, due to the use of a small number of iden-tifiers to represent an immense number of concepts. Corre-sponding to word sense disambiguation in Natural Language Processing, we disambiguate mathematical identifiers. By regarding formulae and natural text as one monolithic infor-mation source, we are able to extract the semantics of identi-fiers in a process we term Mathematical Language Processing (MLP). As scientific communities tend to establish standard (identifier) notations, we use the document domain to infer the actual meaning of an identifier. Therefore, we adapt the software development concept of namespaces to mathemati-cal notation. Thus, we learn namespace definitions by clus-tering the MLP results and mapping those clusters to subject classification schemata. In addition, this gives fundamental insights into the usage of mathematical notations in science, technology, engineering and mathematics. Our gold standard based evaluation shows that MLP extracts relevant identifier-definitions. Moreover, we discover that identifier namespaces improve the performance of automated identifier-definition extraction, and elevate it to a level that cannot be achieved within the document context alone.
Mathematical formulae are essential in Science, Technol-ogy, Engineering, and Mathematics (STEM). Consequently, Mathematical Information Retrieval (MIR) continues to re-ceive increasing research attention [13]. Current MIR ap-proaches perform well in identifying formulae that contain the same set of identifiers or have a similar layout tree struc-ture [2].

However, the ambiguity of mathematical notation decreases the retrieval effectiveness of current MIR approaches. Since the number of mathematical concepts by far exceeds the num-ber of established mathematical identifiers, the same identi-fier often denotes various concepts [16]. For instance,  X  E  X  may refer to  X  X nergy X  in physics,  X  X xpected value X  in statis-tics or  X  X limination matrix X  in linear algebra. Analyzing the identifier-based and structural similarity of formulae without considering the context of a formula can therefore lead to the retrieval of non-relevant results.

Ambiguity is a problem that mathematical notation and natural language have in common. Since words are also often ambiguous [6, 9, 16], Word Sense Disambiguation [15], i.e., identifying the meaning of an ambiguous word in a specific context [15], is an integral part of Natural Language Pro-cessing. Typical approaches for Word Sense Disambiguation replace a word by its meaning [34] or append the meaning to the word. For example, if the ambiguous word man has the meaning human species in a specific context, one can replace it by man species to contrast it from the meaning male adult , replaced by man adult. We transfer this idea to ambiguous mathematical identifiers. If the identifier E has the mean-ing energy in the context of physics, one could replace E by E energy given one can determine that E is indeed used as energy in this context.

In this paper, we propose a method to semantically en-rich mathematical identifiers by determining and assigning the context (namespace) in which the identifier is used, e.g., mathematics or physics. We determine the namespace of an identifier by analyzing the text surrounding mathemati-cal formulae using Natural Language Processing (NLP) tech-niques. In software development, a namespace refers to a collection of terms that is grouped, because it shares func-tionality or purpose. Typically, namespaces are used to pro-vide modularity and to resolve name conflicts [7]. We extend the concept of namespaces to mathematical identifiers and present an automated method to learn the namespaces that occur in a document collection.

Employing an analysis of natural language to enrich the in-formation content of formulae is a new approach, which Pagel and Schubotz termed Mathematical Language Process-ing (MLP) [26]. Today X  X  MIR systems treat formulae and natural language as separate information sources [2]. While current systems offer retrieval from both sources (formulae and text), they typically do not link them. For example, math-aware search systems allow to search in formulae by specifying a query using mathematical notation or special-ized query languages. To search in the text, MIR systems support traditional keyword search [2].
 We deem the MLP approach promising for two reasons. First, a large-scale corpus study showed that around 70 per-cent of the symbolic elements in scientific papers are explicitly denoted in the text [35]. Second, although almost all iden-m c m d ... ... ... tifiers have multiple meanings, mathematical notation obeys conventions for choosing identifiers [5, 16]. Therefore, we pro-pose that identifying the namespace of identifiers can improve their disambiguation and the capabilities for machine process-ing mathematics in general. Improved machine processing of mathematics can benefit recommender [31] and plagiarism de-tection systems [8, 21] for STEM literature. Likewise, formula search engines, and assistance tools for authors and students could benefit.

In summary, the contributions we make in this paper are: (1) a method to extract the semantic meaning of mathemat-(2) a method to learn the set of mathematical namespaces (3) a method that utilizes identified mathematical name-(4) a large scale analysis of identifier use as part of the math-Several approaches extract information from the surrounding text to retrieve information about mathematical formulae [17, 36, 24, 26, 19, 11]. Quoc et al. [24] extract entire formulae and link them to natural language descriptions from the surround-ing text. Yokoi et al. [36] train a support vector machine to extract mathematical expressions and their natural language phrase. Note, that this phrase also includes function words, etc. In [26], we suggest a Mathematical Language Processing framework -a statistical approach for relating identifiers to definientia, in which they compare a pattern based approach and the MLP approach with part-of-speech tag based dis-tances. They find the MLP approach to be more effective. The findings of Kristianto et al. [17] confirm these findings.
Our approach is the first that uses the concept of name-spaces to improve the extraction of semantics regarding math-ematical identifiers. While other approaches only use one document at a time to extract the description of a specific formulae [17, 36, 19], we use a large scale corpus and combine information from different documents to extract the meaning of a specific identifier. In contrast, our task is more specific. We limit the extraction of mathematical expressions to iden-tifiers and extract semantic concepts instead of descriptions.
The goal of Mathematical Language Processing is to ex-tract identifier-definitions from a text that uses mathematics. Formally, a definition consists of three parts: definiendum , definiens and definitor . Definiendum is the expression to be defined. Definiens is the phrase that defines the definiendum. Definitor is the verb that links definiendum and definiens. An identifier-definition is a definition where the definiendum is an identifier.
According to ISO/IEC 40314:  X  X ontent identifiers repre-sent  X  X athematical variables X  which have properties, but no fixed value. X  Identifiers have to be differentiated from sym-bols , that refer to  X  X pecific, mathematically-defined concepts X  such as the operator + or the sin function. Identifier-definiens pairs are candidates for identifier-definitions. Since we do not use the definitor, we only extract the definiendum (identi-fier) and the definiens (natural language term), and extract in the following, identifier-definiens pairs as candidates for identifier-definitions. To illustrate, we introduce the follow-ing running example: Th i s d es cri p t io n in c l u d es t h e fo rm u l a E = mc en erg y ), ( m , ma s s) , a n d ( c , sp e ed o f li gh t ) . in t o th e fo ll o wi n g st ep s : ( 1 ) De tec t fo rm u la e; ( 2 ) E xt ra c t id en t i fi ers; ( 3 ) F i n d i d en t ifi ers ; ( 4 ) F i n d d efi n i en s c a n d id a t es; a n d ( 5 ) S c o re a ll i d en ti fi er-d efi n i en s p a irs . c a l fo rm u l a e. I n so m e ca s es u n ma rk ed tex t l ik e t h is i s o u t si d e of t h e s co p e i f t h is res ea rc h . J sin s ym b o l , wh ere sin 2 : x 7 X  (sin( x )) 2 vs . sin l ist of fo u r v a ria b l es h , e , a , t .
 t h e re al l in e c a n b e d en o t ed e it h er b y R o r R .  X  X b ec o m es X , w b ec o me s w a n d R b ec o me s R . Th e d i sa d -a nd c i s th e s p e e d o f l i ght . X  We are not only interested in the identifier, but also in its definiens. Therefore, we extract identifier-definiens pairs (iden-tifier, definiens) as candidates for identifier-definitions. For example, ( E , energy) is an identifier-definition, where E is an identifier, and  X  X nergy X  is the definiens. In this step, we de-scribe the methods for extracting and scoring the identifier-definitions in three sub-steps: (1) Math-Aware Part-of-Speech Tagging; (2) Part-of-Speech based distances; and (3) Scoring of definiens candidates.
 Pagel and Schubotz [26] found the MLP method with a Part-of-Speech based distance measure in a probabilistic ap-proach to outclass a pattern based method. Thus, we use the Part-of-Speech based distances methods here to extract identifier-definitions. First, we define definiens candidates: (1) noun (singular or plural); (2) noun phrases (noun-noun, adjective-noun); and (3) special tokens such as inner-wiki links.
 We assume that successive nouns (both singular and plurals), possibly modified by an adjective, are candidates for defini-entia. Thus, we include noun phrases that either consist of two successive nouns (e.g.,  X  X ean value X  or  X  X peed of light X ) or an adjective and a noun (e.g.,  X  X ravitational force X ).
Authors often use special markup to highlight semantic concepts in written language. For example in Wikipedia ar-ticles, Wiki markup, a special markup language for speci-fying document layout elements such as headers, lists, text formatting and tables, is used. In the Wikipedia markup pro-cessing, we retain inner Wikipedia links that link to another article that describes the semantic concept, which eliminates the ambiguity in the definiens itself. This link is an exam-ple for a definiens candidate of type special token. Part-of-Speech Tagging (POS Tagging) assigns a tag to each word in a given text [15]. Although the POS Tagging task is mainly a tool for text processing, it can be adjusted to scientific documents with mathematical expressions [29, 26]. There-fore, we tag math-related tokens of the text with math spe-cific tags [29]. If a math token is only one identifier, an identifier tag is assigned rather that a formula tag. We in-troduce another tag for inner-wiki-links. For the extrac-tion of definiens candidates, we use common natural lan-guage POS tags as well as the following three task specific tags: (1) identifiers; (2) formulae; and (3) special tokens.
 Generally, the Cartesian product of identifiers and definiens might serve as identifier-definition candidate. To extract the definiens candidates, we make three assump-tions, according to [26]: (1) definiens are noun phrases or a special token; (2) definiens appear close to the identifier; and (3) if an identifier appears in several formulae, the definiens
The next step is to select the most probable identifier-definition by ranking identifier-definition candidates by prob-ability [26]. The assumption behind this approach is that definientia occur closely to their related identifiers, and thus the closeness can be exploited to model the probability distri-bution over identifier-definition candidates. Thus, the score depends on (1) the distance to the identifier of interest and (2) the distance to the closest formula that contains this iden-tifier. The output of this step is a list of identifier-definiens pairs along with the score. Only the pairs with scores above the user specified threshold are retained.
 The candidates are ranked by the following formula: In this formula  X  is the number of tokens between identi-fier and definiens candidate, R  X  d ( X ) is a zero-mean Gaussian that models this distance, parametrized with the variance  X  and n is the number of sentences between the definiens can-didate and the sentence in which the identifier occurs for the first time. Moreover, R  X  s ( n ) denotes a zero-mean Gaussian, parameterized with  X  s , and tf( t ) is the frequency of term t in a sentence, and the weights  X , X , X  combine these quanti-ties. Therefore, we reuse the values suggested in [26], namely  X  =  X  = 1 and  X  = 0 . 1.

We also tested a refined strategy, which takes into account that the same definition might be explained multiple times in a document and calculated a refined weighting R  X  = (  X   X  1) within one document that lead to one definition. However, this did not lead to a significant performance increase for the task at hand, so we dropped this approach. Note that the idea is revived in the Namespace Discovery section, where multiple documents are considered at the same time.
In this section, we describe the adaptation of the idea of namespaces to identifier disambiguation and the process of namespace discovery to extract identifier-definitions in the following steps: (1) Automatic Namespace Discovery; (2) Document Clustering; (3) Building Namespaces; and (4) Building Namespace Hierarchy.
 Namespaces in well-defined software exhibit low coupling and high cohesion [18]. Coupling describes the degree of depen-dence between namespaces. Low coupling means that the de-pendencies between classes of different namespaces are mini-mized. Cohesion refers to the dependence within the classes of the same namespace. High cohesion principle means that the related classes should be put together in the same names-pace. We define a notation N as a set of pairs { ( i,s ) } , where i is an identifier and s is its semantic meaning or definiens, such that for any pair ( i,s )  X  X  there is no other pair ( i 0 with i = i 0 . Two notations N 1 and N 2 conflict if there exists a pair ( i 1 ,s 1 )  X  X  1 and a pair ( i 2 ,s 2 )  X  X  2 such that i s 6 = s 2 .

Thus, we can define a namespace as a named notation. For example, N physics can refer to the notation used in physics. For convenience, we use the Java syntax to refer to specific entries of a namespace [10]. If N is a namespace and i is an identifier such that ( i,s )  X  X  for some s , then N . i is a fully qualified name of the identifier i that relates i to the definiens s . For example, given a namespace N physics = { ( E,  X  X nergy X ) , ( m,  X  X ass X ) , ( c,  X  X peed of light X ) } , N physics . E refers to  X  X nergy X   X  the definiens of E in the namespace  X  X hysics X . Analogous to definitions in programming language namespaces, one can expect that (a) definiens in a given mathematical namespace come from the same area of mathematics, and (b) definiens from different namespaces do not intersect heavily. In other words, one can expect namespaces of mathematical notation to have the same properties as well-designed software pack-ages, namely low coupling and high cohesion.

To precisely define these concepts for mathematical name-spaces, we represent them via a document-centric model. Suppose we have a collection of n documents D = { d 1 ,...,d and a set of K namespaces {N 1 ,..., N K } . A document d use a namespace N k by implicitly importing identifiers from it. Note that real-life scientific documents rarely explicitly use import statements. However, we assume that these implicit namespace imports exist. In this document-centric model, a namespace exhibits low coupling, if only a small subset of documents uses it and high cohesion if all documents in this subset are related to the same domain.

We use the extracted identifier-definitions (see Section 2.1) to discover the namespaces. Since manual discovery of math-ematical namespaces is time consuming and error prone, we use Machine Learning techniques to discover namespaces au-tomatically.

We utilize clustering methods to find homogeneous groups of documents within a collection. Comparable to NLP identi-fiers can be regarded as  X  X ords X  in the mathematical language and entire formulae as  X  X entences X . We use cluster analysis techniques developed for text documents represented via the  X  X ag-of-words X  model for documents with math formulae that are represented by  X  X ag-of-identifiers X . Some definientia are used only once. Since they do not have any discriminative power, they are not very useful and are excluded. Once the identifiers are extracted, we discard the rest of the formula. As a result, we have a  X  X ag-of-identifiers X . Analogoe to the bag-of-word approach, we only retain the counts of occurrences of identifiers, but do not preserve any structural information. For clustering, documents are usually represented using the Vector Space Models [1, 25]. We apply the same model, but use identifiers instead of words to represent documents. As the vocabulary, we use a set of identifier-definiens pairs V = I  X  F which is an element of the vector product space of the identifier space I and the the definiens space F . We rep-resent documents as m -dimensional vectors d j = ( w 1 ,...,w where w k is the weight of an identifier-definiens pair i document d j and m = dim( I )dim( F ). We define an identifier-document matrix D as a matrix where columns represent document vectors and rows represent identifier-document co-occurrences. We evaluate three ways to incorporate the ex-tracted definientia into the model: (1) we use only identi-fiers without definientia, which reduces the vocabulary to V 1 = P I V , where the projection operator P I : I  X  F  X  I reduces the dimensions dim V 1 = dim I ; (2) we use  X  X eak X  identifier-definiens associations that include identifiers and definientia as separate dimensions, formally V 2 = P I  X  F where the projector P I  X  F : I  X  F  X  I  X  F reduces the di-mension to dim V 2 = dim I + dim F ; and (3) we use  X  X trong X   X   X   X   X  Figure 2: Illustration of the identifier-document matrix D for the analyzed methods to create features from the identifiers and definientia, for the mass-energy equivalence example and three hypothetical documents d = { E,m,c } , d 2 = { m,c } , d 3 = { E } . identifier-definiens associations that append a definiens to each identifier and thus V 3 = V .

There is some variability in the definientia: for example, the same identifier  X  in one document can be assigned to  X  X auchy stress tensor X  and in another to  X  X tress tensor X , which is almost the same thing. To reduce this variability we perform the fol-lowing preprocessing steps: we tokenize the definiens and use individual tokens to index dimensions of the space. For ex-ample, suppose we have two pairs (  X  ,  X  X auchy stress tensor X ) and (  X  ,  X  X tress tensor X ). In the  X  X eak X  association case, we will have dimensions (  X ,  X  X auchy X  ,  X  X tress X  ,  X  X ensor X ), while for the  X  X trong X  association we only use the last term, i.e., (  X  tensor) as additional features. At this stage, we aim to find clusters of documents that are reasonable namespace candidates. We vectorize each doc-ument using the following weighting function log(tf) / ( z df), where tf denotes the term frequency , df the document fre-quency and z the normalization parameter, such that the length of each document vector is 1. In addition, we discard all identifiers with DF &lt; 2. We further reduce the dimensionality of the resulting dataset via Latent Semantic Analysis (LSA) [6], which is implemented using randomized Singular Value Decomposition (SVD) [14], see [12]. After the dimension-ality reduction, we apply Mini-Batch K -Means with cosine distance, since this algorithm showed the best performance in our preliminary experiments (refere to [12] for further de-tails). Once a cluster analysis algorithm assigns documents from our collection to clusters, we need to find namespaces among these clusters. We assume that clusters are namespace-defining, meaning that they are not only homogeneous in the cluster analysis sense (e.g., in the case of K -Means it means that the within-cluster sum of squares is minimal), but also contain topically similar documents.

To assess the purity of the clusters, we use the Wikipedia category information, which was not used for clustering in the first place. Since each Wikipedia article might have an arbitrary number of categories, we find the most frequent cat-egory of the cluster, and thus define its purity C as where the c i  X  X  are cluster categories . Thus, we can select all clusters with purity above a certain threshold and refer to them as namespace-defining clusters. In our experiments we achieved best results with a threshold of 0.6.

Afterwards, we convert these clusters into namespaces by collecting all identifiers and their definiens in the documents of each cluster. Therefore, we first collect all identifier-definiens pairs, and then group them by identifiers. During the extrac-tion, each definiens candidate is scored. This score is used to determine which definiens will be assigned to an identifier in the namespace. We group the pairs by identifier. If an identifier has two or more identical definiens, we merge them into one. Thus, the score of an identifier-definiens pair is the sum of scores. There is some lexical variance in the definiens. For example,  X  X ariance X  and  X  X opulation variance X  or  X  X ean X  and  X  X rue mean X  are closely related definiens. Thus, it is ben-eficial to group them to form one definiens. This can be done by fuzzy string matching (or approximate matching) [23]. We group related identifiers and calculate the sum of their scores. Intuitively, the closer a relation is, the higher is the score. A high score increases the confidence that a definiens is correct.
In the last step of our pipeline, we label our namespace defining clusters with categories from well known classifica-tions, effectively naming the namespaces we identified. We thus achieve two goals. First, we indirectly evaluate our dataset. Second, we ease the use of our dataset to improve MIR. We use the following official classifications: (1) Mathematics Subject Classification (MSC2010) [3] [Amer-(2) Physics and Astronomy Classification Scheme (PACS) (3) ACM Computing Classification System [28] available We processed the SKOS ontology graph with RDFLib. All categories can be found on our website [30]. After obtaining and processing the data, the three classifications are merged into one. We map namespaces to second-level categories by keyword matching. First, we extract all keywords from the category. The keywords include the top level category name, the subcategory name and all third level category names. From each namespace, we extract the namespace category and names of the articles that form the namespace. Finally, we perform a keyword matching, and compute the cosine sim-ilarity between the cluster and each category. The namespace is assigned to the category with the largest cosine score. If the cosine score is below 0 . 2 or only one keyword is matched, the cluster is assigned to the category  X  X thers X .
 We used POS Tagging based distance measures (see Sec-tion 2.1) to extract identifier-definiens pairs from the text surrounding the formula. In a second step, we build name-spaces of identifiers. This namespaces allows us to study the usage of identifiers in different scientific fields. Many, but not all definientia can be found in the text surrounding the formulae. Thus, the namespaces can additionally be used to identify the definiens in cases where the definiens is not mentioned in the text.
We use the Big Data framework Apache Flink , which is capa-ble of processing our datasets in a distributed shared nothing environment, leading to short processing times. Our source-code, training, and testing data is openly available from our website [30].

For the MLP part, our implementation follows the open source implementation of the Mathematical Language Pro-cessing Project [26], with the following improvements: rather than converting the Wikipedia formulae via L A T E xml , we now directly extract the identifiers from the L A T E X parse tree via Mathoid [32]. Second, we include a link to Wikidata, so that Wikipedia links can be replaced by unique and language in-dependent Wikidata identifiers (ids). These ids are associ-ated with semantic concepts, which include a title, and in many cases a short description that simplifies disambigua-tion. For the POS Tagging, we use the Stanford Core NLP library ( StanfordNLP ) [20] for POS Tagging of natural lan-guage as well as additional math-aware tags (see Section 2.1). In summary, we use the following tags: (1) identifiers ( X  ID  X ); (2) formulae ( X  MATH  X ); (3) inner-wiki link ( X  LINK  X ); (4) singular noun ( X  NN  X ); (5) plural noun ( X  NNS  X ); (6) adjective ( X  JJ  X ); and (7) noun phrase ( X  NOUN_PHRASE  X ).

For the Namespace Discovery step in our pipeline (Section 2.2), we use the following implementation to discover clusters that are suitable namespace candidates. Using  X  X fidfVector-izer X  from scikit-learn [27], we vectorize each document. The experiments are performed with (log TF)  X  IDF weighting. Therefore, we use the following parameters:  X  X se idf=False X ,  X  X ublinear tf=True X . Additionally, we discard identifiers that occur only once by setting  X  X in df=2 X . The output of  X  X fid-fVectorizer X  is row-normalized, i.e., all rows have unit length.
The implementation of randomized SVD is taken from [27]  X  method  X  X andomized svd X . After dimensionality reduction, we apply Mini-Batch K -Means (class  X  X iniBatchKMeans X ) from [27] with cosine distance. In our preliminary experi-ments, this algorithm showed the best performance. To im-plement it, we use the Python library FuzzyWuzzy. Using fuzzy matching we group related identifiers and then sum over their scores.
As our test collection, we use the collection of Wikipedia articles from the NTCIR-11 Math Wikipedia task [33] in 2014. We choose this collection instead of the latest version of Wikipedia to be able to compare our results to previous experiments.

After completing the MLP pipeline, we exclude all docu-ments containing less than two identifiers. This procedure re-sults in 22 515 documents with 12 771 distinct identifiers that occur about 2 million times. Figure 3 shows that identifiers follow a power law distribution, with about 3 700 identifiers occurring only once and 1 950 identifiers occurring only twice. Figure 3: Distribution of identifier counts. The most frequent identifiers are x (125k), p (110k), m (105k), and n (83k).
The amount of identifiers per document also appears to fol-low a long tail power law distribution ( p&lt; 0 . 001 for KS test) as only a few articles contain a lot of identifiers, while most of the articles do not. The largest number of identifiers in a sin-gle document is an article with 22 766 identifiers, the second largest has only 6 500 identifiers. The mean number of iden-tifiers per document is 33. The distribution of the number of distinct identifiers per document is less skewed than the distribution of all identifiers. The largest number of distinct identifiers in a single document is 287 followed by 194. The median of identifiers per document is 10. For 12 771 identi-fiers, the algorithm extracted 115 300 definientia. The num-ber of found definientia follows a long tail distribution as well, with the median of definientia per page being 4. Moreover, we list the most common identifier-definiens pairs in Figure 3.
We created a gold standard from the 100 formulae patterns included in the NTCIR-11 Wikipedia task [33] and the fol-lowing information: (1) identifiers within the formula; (2) definiens of each identifier; and (3) links to semantic concepts on Wikidata.
 We compared our results with that gold standard and cal-culated the three measures: precision, recall, and F1-score, to evaluate the quality of our identifier-definitions. In a first step, we evaluated the results acquired with the POS Tag-ging based distance measures (see Section 2.1). In a second step, we evaluated the results acquired by combining the POS Tagging based distance measures and the results of the name-spaces (see Section 2.2)
The gold standard (cf. Figure 4) consists of 310 identifiers, with a maximum of 14 identifiers per formula. For 174 of those identifiers, we could assign the corresponding semantic con-cept in Wikidata. For 97, we assigned an individual phrase that we could not relate to a Wikidata concept. For an ad-ditional 27, we assigned two phrases. For example, for Topic 32 (cf. Figure 4), we assigned critical temperature in addition to the semantic concept of the critical point, since the critical temperature is more specific. The full list of assignments is available from our website [30]. Note, that the identification of the correct identifier-definition, was very time consuming. For several cases, the process took more than 30 minutes per (1) Van der Waerden X  X  theorem: W (2 ,k ) &gt; 2 k /k  X   X  X  X  (31) Modigliani-Miller theorem: T c (32) Proximity effect (superconductivity): T c  X  X  X  (69) Engine efficiency:  X  = work done  X  X  X  (86) Lagrangian mechanics:  X  X  Figure 4: Selected entries from the gold standard. Bold font indicates that the entry is linked to a language independent semantic concept in Wikidata. The descriptions in brackets originate from the English Wikidata label and have been cropped to optimize the layout of this figure. formulae, since multiple Wikipedia pages and tertiary liter-ature had to be consumed. The gold standard was checked by a mathematician from the Applied and Computational Mathematics Division, National Institute of Standards and Technology, Gaithersburg, Maryland, USA. In this section, we describe the results of our evaluation. First, we describe the quality of the MLP process in Sec-tion 4.1. Afterwards, we describe the dataset statistics and the results of the namespace evaluation in Section 4.2.
Our gold standard consists of 310 identifiers to be extracted from the aforementioned 100 reference formulae. We were able to extract 294 identifiers (recall 94.8%) from the gold standard correctly. We obtained only 16 false negatives, but overall 57 false positives (precision 83.7%, F 1 89.0%). Falsely detected identifiers affect 22% of the reference formulae, show-ing that often several falsely extracted identifiers belong to one formula. In the following, we explain why the errors can be attributed to the shortcomings of the heuristics explained in Section 2.1. C lassical mechanics of discrete systems 45.00 (PACS) Categories: Physics, Mechanics, Classical mechanics
Purity: 61%, matching score: 31%, identifiers 103, semantic concepts 50, 5 8, 4 , 4 2, 1
I dentifier-definitions: m mass (quantitative measure of a physical object X  X 
F force (influence that causes an object to change) [ s  X  25]
E e nergy (physical
V v elocity [ s  X  9] u flow velocity [ s  X  8]
E electric field (. . . representing St ochastic analysis 60Hxx (MSC) Categories: Stochastic processes, Probability theory
Purity: 92%, matching score: 62%, identifiers 54, semantic concepts 32, 1 8, 0 , 3 0, 0
I dentifier-definitions: a stochastic process (. . . random variables) [ s  X  12]
X s tochastic process (. . . random variables) [ s  X  10]  X  X  X 
E expected value [ s  X  2]  X  X  X 
E e xpected value s&lt; 1 v function s&lt; 1 The ory of data 68Pxx (MSC) Categories: Information theory, Theoretical computer science
Purity: 86%, matching score: 35%, identifiers 58, semantic concepts 10 Identifier-definitions: R rate [ s  X  12]
X p osterior probability [ s  X  10] n l ength [ s  X  8]
H In formation entropy (expected value of the amount
I m utal information [ s  X  5] a p rogram [ s  X  5] a c odeword s&lt; 1 E X expected value s&lt; 1 table, we manually shortened some long description texts. Incorrect markup. Errors relating to 8 formulae (33 false positive and 8 false negative identifiers), were caused by the incorrect use of L A T E X, especially the use of math mode for text or the missing usage of math mode for part of the for-mula. An identifier Q 1 that is falsely marked as Q 1 (cf. Fig-ure 4, Topic 69) in a formula, can easily be identified correctly by a human since it looks very similar in the output. As obvi-ously Q 1 is meant in the formula, we took Q 1 as gold standard for this identifier. But in the MLP process it is impossible to extract the identifier correctly, as Q 1 implies Q times 1. Symbols. For 8 formulae (9 false positive identifiers), Math-oid [32] misclassified symbols as identifiers, such as d in dx . Two formulae (2 false positive identifiers) are substitu-tions (abbreviations that improve the readability of formulae without specific meaning).
 Sub-super-script. Two formulae (3 false positive, 2 false negative identifiers), used sub-super-script such as  X  2 y Special notation. For 2 formulae (10 false positive, 2 false negative identifiers), use special notation like the Einstein sum convention.
 We excluded incorrectly extracted identifiers from the follow-ing processing steps. Thus the upper bound for recall and precision are set by the identifier extraction step.
In a first step, we only assess the definitions that matched exactly the semantic concepts materialized as Wikidata item in the gold standard. Thus, we found 88 exact matches (recall 28.4%), but also obtained 337 false negatives, which results in a precision of 20.7% ( F 1 23.9%).

In addition, we evaluated the performance of partially rele-vant matches by manually deciding the relevance for each en-try. For example, integer (number that can be written with-out a fractional or decimal component) would be classified as highly relevant, but the string integers was classified as rel-evant. Although this classification is mathematically incor-rect, it provides valuable information for a human regarding the formulae. With this evaluation, we obtain 208 matches (recall 67.1%) and 217 false negatives (precision 48.9%, F 56.6%). To interprete these results, we differentiate between definitions that have not been extracted, although all nec-essary information is present in the information source, and definitions that do not completely exist in the information source. Wolska and Grigore [35] found that around 70% of objects denoting symbolic expressions are explicitly denoted in scientific papers. Since in our data source only 73% of the identifiers are explained in the text, 73% represents the highest achievable recall for systems that do not use world knowledge to deduce the most likely meaning of the remain-ing identifiers. Considering this upper limit, we view a recall of 67.1% that was achieved when including partly relevant re-sults, as a good result. These results also confirm the findings of Kristianto et al. [17]. Although these overall results match with the results of Wolska and Grigore [35], we found major differences between different scientific fields. In pure mathe-matics, the identifiers usually do not link to a specific concept and the formulae do not relate to specific real-life-scenarios. In contrast, in physics the definientia of the identifiers are usually mentioned in the surrounding text, like in the mass-energy-equivalence example.
The evaluation of the namespace discovery performance is twofold. First, we apply the same procedure as in the eval-uation of the MLP process. In a second step, we perform a manual quality assessment of the final namespaces.

We obtain the following results with regard to the extrac-tion performance. For the strict relevance criterion, the recall improved by 18% (0.048) to 33.2% (103 exactly correct def-initions), and the precision declined only slightly with 420 false positives to 19.7% ( F 1 24.7%). In the end, 30 identi-fiers (9.6%) reached the ultimate goal and were identified as a semantic concept on Wikidata. For the non strict relevant cri-terion, we could measure a recall performance gain of 19.4%, while maintaining the precision level. This exceeds the upper limit for recall achievable by exclusively analyzing the text of a single document of (73%) and extracts 250 definitions cor-rectly (recall 80.6%) with only 273 false positives (precision 47.8%, F 1 60.0%).

The second part of the evaluation assesses the quality of the discovered namespaces. While a detailed performance eval-uation of the clustering methods was already carried out in [12], we focus on the contents of the discovered namespaces here. For evaluating the Namespace Discovery, we evaluated 6 randomly sampled subject classes. Two independent judges rated the categorized identifier-definiens pairs regarding their assignment to subject classes using the four categories:  X  X on-firmed X  ( ),  X  X artly confirmed X  ( ),  X  X ot sure X  ( ) and  X  X ncor-rect X  ( ), regarding their assignment to the subject class by two independent raters. All cases of disagreement (mostly vs. ) could be resolved in consensus.

With strong coupling and a minimal purity of 0.6, 250 clus-ters were obtained of which 167 could be mapped to name-spaces in the official classification schemes (MSC 135, PACS 22, ACM 8). The purity distribution is as follows: 0.6-0.7: 98, 0.7-0.8: 57, 0.8-0.9: 44, 0.9-1.0: 51.

Those namespaces contain 5 618 definitions with an overall score &gt; 1, of which 2 124 (37.8%) link to semantic concepts. We evaluated the recall of 6 discovered namespaces exem-plary. The purity of the selected namespaces ranged from 0.6 to 1. with an average of 0.8. They contained between 14 and 103 identifiers (with a score &gt; 1). Here, relevance means that the definition is commonly used in that field. This was de-cided by domain experts. However, since this question is not always trivial to judge, we introduced an unknown response ( ). In total, 129 (43%) of the 278 discovered definitions matched the expectation ( ) of the implicit namespaces ex-pected by the domain experts. For 7 definitions (3%), they were clearly wrong ( ), for 8 (3%), the definitor was not spe-cific enough and for the remaining 144 (52%), the reviewers could not assess the relevance ( ). Note that the quality of namespaces varied. For example cluster (33Cxx, Hypergeo-metric functions) had significantly more clearly wrong results, because symbols were classified as identifiers, compared to the investigated clusters in physics where the definition of specific symbols is less common.

In general, this result was expected, since it is hard to as-sess the namespaces that have not been spelled out explicitly before. Especially, the recall could not be evaluated, since to the best of our knowledge, there is no reference list with typical identifiers in a specific mathematical field. For details regarding implementation choices, visit our website [30], and contribute to our open source software mathosphere.
We investigated the semantification of identifiers in math-ematics based on the NTCIR-11 Math Wikipedia test collec-tion using Mathematical Language Processing and Names-pace Discovery. Previous approaches have already shown good performance in extracting descriptions for mathemat-ical formulae from the surrounding text in individual docu-ments.

We achieved even better performance (80% recall, while maintaining the same level of precision) in the extraction of relevant identifier-definitions. In cases where identifier-definitions were absent in the document, we used our fall back mechanism of identifier-definitions from the namespace that we learned from the collection at large. This way, we could break the theoretical limit for systems (about 70% recall cf. Section 4) that take into account only one document at a time. Moreover, the descriptions extracted by other systems are language dependent and do not have a specific data structure.
In contrast, we organized our extracted identifier-definitions in a hierarchical data structure (i.e., namespaces) which sim-plifies subsequent data processing tasks such as exploitative data analysis.

For about 10% of the identifiers, we were able to assign the correct semantic concept on the collaborative knowledge base Wikidata. Note, that this allowed extracting even more se-mantics beside a natural language description as spelled out in Table 1. Namely, one can find labels and descriptions in multi-ple languages, links to relevant Wikipedia articles in different languages, as well as statements. For example, for the iden-tifier speed of light , 100 translations exist. As statements one can, for example, retrieve the numeric value (3  X  10 8 and the fact that the speed of light is a unit of measurement. We observed that identifier clusters in physics and computer science are more useful in the sense that they more often link to real-world semantic objects than identifier clusters in pure mathematics, which often solely specify the type of the vari-able.

During the construction of the gold standard, we noticed that even experienced mathematicians often require much time to manually gather this kind of semantic information for identifiers. We assume that a significant percentage of the 500 million visitors to Wikipedia every day face similar problems. Our approach is a first step to facilitate this task for users.
The largest obstacle for obtaining semantic information for identifiers from Wikidata is the quality of the Wikidata re-source itself. For 44% of the identifiers in the gold standard, Wikidata contains only rather unspecific hypernyms for the semantic concept expressed by the identifier. We see two op-tions to remedy this problem in future research. The first option is to use a different semantic net containing more fine-grained semantic concepts. The second option is to identify unspecific semantic concepts in Wikidata and to split them into more specific Wikidata items related to mathematics and science.

Our identifier extraction has been rolled out to the Wikime-dia production environment. However, at the time of writing, incorrect markup is still a major source of errors. To overcome this problem, the implementation of procedures that recog-nize and highlight incorrect markup for Wikipedia editors is scheduled and will encourage editors to improve the markup quality. In addition, symbols falsely classified as identifiers have a noticeable negative impact on the quality of the clus-tering step. Improving the recognition of symbols is therefore an issue that future research should address. Moreover, in the future our method should be expanded to other datasets be-side Wikipedia.

With regard to math information retrieval applications i.e., math search, we have shown that the discovered namespaces can be used to disambiguate identifiers. Exposing name-spaces to users is one application of identifier namespaces. Using them as internal data structure for math information retrieval applications, such as math search, math understand-ing or academic plagiarism detection is another. Regarding MIR tasks, identifier namespaces allow for quiz like topics such as  X  X t constant temperature, is volume directly or in-versely related to pressure? X . This simplifies comparing tradi-tional word based question and answering systems with math aware methods.

In conclusion, we regard our namespace concept as a signif-icant innovation, which will allow users to better express their mathematical information needs, and search engines to dis-ambiguate identifiers according to their semantics. However, more research needs to be done to better understand the in-fluence of each individual augmentation step of our presented pipeline for MIR applications. [1] C. C. Aggarwal [2] A. Aizawa, M. Kohlhase, I. Ounis, [3] American Mathematical Society.
 [4] American [5] F. Cajori. A history of mathematical [6] S. C. Deerwester, S. T. Dumais, T. K. Landauer, [7] E. Duval, W. Hodgins, [8] B. Gipp. Citation-based Plagiarism Detection -Detecting [9] A. Gliozzo and [10] J. Gosling, B. Joy, G. Steele, G. Bracha, [11] M. Grigore, M. Wolska, and M. Kohlhase. Towards [12] A. Grigorev. Identifier namespaces in mathematical [13] F. Guidi and C. Sacerdoti Coen. A survey [14] N. Halko, P. Martinsson, and A. Tropp. Finding [15] D. Jurafsky and J. H. Martin. Speech [16] M. Kohlhase and I. Sucan. A Search Engine [17] G. Y. Kristianto, A. Aizawa, and Others. Extracting [18] C. Larman. Applying UML and patterns: an [19] K. Ma, S. C. Hui, and K. Chang.
 [20] C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. [21] N. Meuschke and B. Gipp. Reducing Computational [22] A. Miles, B. Matthews, M. Wilson, and D. Brickley. [23] G. Navarro. A guided tour to approximate string [24] M.-Q. Nghiem, K. Yokoi, Y. Matsubayashi, and [25] N. Oikonomakou and M. Vazirgiannis. A review [26] R. Pagel and M. Schubotz. Mathematical language [27] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, [28] B. Rous. Major [29] U. Sch  X  oneberg and W. Sperber. POS Tagging [30] M. Schubotz. mlp.formulasearchengine.com . [31] M. Schubotz, M. Leich, and V. Markl. Querying [32] M. Schubotz and G. Wicke.
 [33] M. Schubotz, A. Youssef, V. Markl, and H. S. Cohl. [34] C. Stokoe, [35] M. Wolska and M. Grigore. Symbol declarations in math-[36] K. Yokoi, M. Nghiem, Y. Matsubayashi, and A. Aizawa.
