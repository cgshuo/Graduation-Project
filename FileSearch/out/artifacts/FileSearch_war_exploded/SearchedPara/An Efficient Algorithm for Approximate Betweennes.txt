 Betweenness centrality is an important centrality measure widely used in social network analysis, route planning etc. However, even for mid-size networks, it is practically intractable to compute ex-act betweenness scores. In this paper, we propose a generic ran-domized framework for unbiased approximation of betweenness centrality. The proposed framework can be adapted with different sampling techniques and give diverse methods. We discuss the con-ditions a promising sampling technique should satisfy to minimize the approximation error and present a sampling method partially satisfying the conditions. We perform extensive experiments and show the high ef fi ciency and accuracy of the proposed method. G.2.2 [ Discrete Mathematics ]: Graph Theory X  Graph algorithms, Path and circuit problems ;E.1[ Data ]: Data structures X  Graphs and networks Theory Centrality, betweenness centrality, social network analysis, approx-imate algorithms.
Betweenness centrality of a vertex, introduced by Linton Free-man [6], is de fi ned as the number of shortest paths (geodesic paths) from all (source) vertices to all others that pass through that vertex. He used it as a measure for quantifying the control of a human on the communication between other humans in a social network [6]. Betweenness centrality is also used in some well-known algorithms for clustering and community detection in social and information networks [8].

Although betweenness centrality co mputation is tractable in the-ory in the sense that there exist polynomial time and space algo-Since it might be computationally expensive to fi nd such a sam-pling, we propose a sampling technique which partially satis fi es the condition. While the algorithm of [1] is intuitively presented for high centrality vertices, in our method, the sampling technique can be revised to optimize itself for both high centrality vertices and low centrality vertices. The proposed method can be used to com-pute similar centrality notions like stress centrality , which is also based on counting shortest paths. We perform extensive experi-ments on real-world networks from different domains, and show that compared to existing exact and inexact algorithms, our method works with higher accuracy or it gives signi fi cant speedups.
The rest of this paper is organized as follows. In Section 2, pre-liminaries and de fi nitions related to betweenness centrality com-putation are given. In Section 3, we present a generic random-ized algorithm for betweenness centrality computation. In Section 4, we discuss the sampling methods. We empirically evaluate the proposed method in Section 5 and show its ef fi ciency and high ac-curacy. Finally, the paper is concluded in Section 6.
Throughout the paper, G refers to a graph (network). For sim-plicity, we suppose G is a connected and loop-free graph without multi-edges. Th roughout the paper, we assume G is an unweighted graph, unless it is explicitly mentioned that G is weighted. V ( G ) and E ( G ) refer to the set of vertices and the set of edges of G ,re-spectively. Throughout the paper, n points to | V ( G ) | and m points to |
E ( G ) | . For an edge e =( u, v )  X  E ( G ) , u and v are two end-points of e .A shortest path (also called a geodesic path ) between two vertices u, v  X  V ( G ) is a path whose size is minimum, among all paths between u and v . For two vertices u, v  X  V ( G ) ,we use d ( u, v ) , to denote the size (the number of edges) of a short-est path connecting u and v .Byde fi nition, d ( u, v )=0 and d ( u, v )= d ( v,u ) .For s, t  X  V ( G ) ,  X  st denotes the number of shortest paths between s and t ,and  X  st ( v ) denotes the number of shortest paths between s and t that also pass through v .We have  X  s ( v )= vertex v is de fi ned as: A notion which is widely used for counting the number of shortest paths in a graph is the directed acyclic graph (DAG) containing all shortest paths starting from a vertex s (see e.g. [3]). In this paper, we refer to it as the shortest-path-DAG ,or SPD in short, rooted at s . For every vertex s in a graph G ,the SPD rooted at s is unique, and it can be computed in O ( m ) time for unweighted graphs and in O ( m + n log n ) time for weighted graphs [3]. In [3], the authors introduced the notion of the dependency score of a vertex s  X  V ( G ) on a vertex x  X  V ( G ) \{ s } , which is de fi ned as: We have: BC ( v )= given the SPD rooted at s , dependency scores of s on all other vertices can be computed in O ( m ) time.
Algorithm 1 shows the high level pseudo code of the algorithm proposed for approximate betweenness centrality computation. First note that instead of taking T samples, we can de fi neacriteriafor the termination of the loop in Lines 8-15 of Algorithm 1. For ex-ample, similar to the algorithm of [1], we can stop when B [ v ]  X  cn for some constant c .
Suppose that we want to approximate betweenness centrality of avertex v . The following Lemma de fi nes the probabilities mini-mizing the approximation error.

L EMMA 2. If in Algorithm 1 source vertices i are selected with probabilities the approximation error (i.e. variance of B [ v ] ) is minimized. In this case, variance of B [ v ] will be 0 1 .
 P ROOF . Omitted due to lack of space.

Therefore, using probabilities p i de fi ned in Equation 7, gives an exact method in the sense that it makes the approximation error 0 . However, time complexity of computing optimal p i  X  X  is the same as exact betweenness centrality computation. Although it is not they can help us to de fi ne properties of a good sampling. From Equation 7, we can conclude that in a good sampling, for every two vertices i and i , the following must hold: which means vertices with higher dependency scores on v ,mustbe selected with a higher probability.

However, fi nding probabilities p 1 ,p 2 ,...,p n which satisfy Equa-tion 8 might be computationally expensive, since it needs to com-pute dependency scores of all vertices on v which is as bad as com-puting dependency scores of every source vertex on all vertices. In order to design practically ef fi cient sampling techniques, we con-sider relaxations of Equation 8. Consider two vertices i and i such ancestor-descendant relationship between i and i and i is the only ancestor of i at the level d ( i, v ) , then, it can be shown that for k  X  X  i, i } , probability p k de fi ned as satis fi es Equation 8.

The positive aspect of the sampling technique presented in Equa-tion 9 is that it only needs to compute the distance between vertex v and every vertex in the graph: the single-source shortest path, or SSSP in short, problem. For unweighted graphs, this problem can be solved in O ( m ) time and for weighted graphs, using Fibonacci heap, it is solvable in O ( m + n log n ) time[5].Itmeansthatthe sampling method presented in Equation 9 is practically ef fi cient. tex selection procedure presented in [7]. In the method of [7] the scheme for aggregating dependency scores changes so that vertices do not pro fi t from being near the selected source vertices. How-ever, Lemma 2 says it is better to select source vertices based on their dependency scores on v , and as we will see later, it might result in preferring source vertices which are closer to v . The reason of this contradiction is that while here we aim at pre-cisely approximating betweenness centrality of some speci fi c ver-tex v , the method of [7] aims to rank all vertices based on their betweenness scores.
 exact method, for single vertices in different datasets. Database Wiki Vote 76056 . 85 515 . 09 37 . 0 % &lt; 1 41 . 13 % 46 . 05 10% dblp0305 564246 . 41 19149 . 8 7 . 59 % &lt; 2 64 . 73 % 1747 . 15 10% dblp0507 798125 . 00 35140 7 . 19 % &lt; 2 50 . 17 % 2863 . 82 10%
CA-CondMat 691667 3026 . 9 10 . 8 % &lt; 1 20 . 81 % 315 . 3 10% dataset, it is always smaller than 1 second. The next dataset is Email-Enron. Compared to Wiki-Vote, it is less dense (but still dense) and larger. Over this dataset, the approximation error of distance-based sampling is better than the uniform sampling.
Dblp0305 and dblp0507 are large and relatively sparse datasets.
 As re fl ected in Table 2, over these datasets, distance-based sampling works much better than uniform sampling. This means that on sparse datasets, the difference between the ap-proximation quality of two meth-ods is more considerable. It has several reasons. The fi rst reason is that in very dense datasets, many vertices have the same (and small) distance from v ( v is the vertex whose be-tweenness centrality is approx-imated). Therefore, distance-based sampling becomes closer to the uniform sampling. The second reason is that in sparse networks, in the SPD rooted at v , the probability that a vertex i has only one ancestor at some level k is lower than this probability in dense graphs. Figure 1 compares these two situations. It means that in sparse networks, distance-based sampling is closer to the optimal sampling, because by distance-based sampling, a larger number of vertices will satisfy the condition expressed in Equation 7. As a result, on sparse net-works, distance-based sampling becomes much more effective than uniform sampling.

Finally, the methods were compared on the CA-CondMat dataset which contains scienti fi c collaborations between authors of papers submitted to Condense Matter category [11]. The average degree in this dataset is 8 . 08 which means it is denser than dblp0305 and dblp0507, but less dense than Wiki-Vote and Email-Enron. Over this dataset, the approximation error of uniform sampling is almost twice of the approximation error of distance-based sampling.
In this paper, we presented a generic randomized framework for unbiased approximation o f betweenness centrality. In the proposed framework, a source vertex i is selected by some strategy, single-source betweenness scores of all vertices on i are computed, and the scores are scaled as estimations of betweenness centralities. Our proposed framework can be adapted with different sampling
