 There are too many products in an on-line shopping website. Take eBay for example, their platform sells more than 75 million kinds of products at any time [8]. We need to help buyers to find products they want in an efficient way. The two common methods are searching and browsing by categories. A keyword-based IR system seems suitable for searching products. Figure 1 shows a snapshot example of shopping.com 1 issuing a query  X  X phone X  on June 2010.

An efficient retrieval system that can provide the most relevant ranking list of prod-ucts to meet buyer X  X  query is very important. If the retrieval system cannot provide suit-able ranking list corresponding to buyers X  query in an efficient way, buyers may change to other shopping platforms which therefore declines shopping platform provider X  X  profit. Unfortunately, we observe from real world query logs and find that queries for product search are usually very short. A query for product search consists of only 1.28 English words or 3.22 Chinese characters in average. So, it is hard to realize buyer X  X  intention. What is worse, a document describing a product may contain lots of words associating with related products. It is hard for an IR system to distinguish represen-tative terms from other noisy terms. The retrieved products often match the keywords from query issued by buyers, but have poor relevance.
For example, when a buyer issued a query  X  X phone X , we assume that the buyer was interested in the iphone cellphones, inst ead of iphone accessories such as iphone com-patible batteries, leathers, or screen protect ors. Unfortunately, from Fig. 1, we can see that the top two retrieved results when i ssuing query  X  X phone X  are iphone accessories: black case and transmitter, instead of iphone ce llphones. Accordingly, the IR system for product search needs more sophisticated methods in the hope of understanding buyers X  and sellers X  intentions.

We make an assumption that a buyer specifies keywords to describe products that he or she wants to buy. The buyer is interested in main products, instead of accessories. Ravi Chandra et al. also make similar assumption [3]. In this work, we observe that each term in a product document title has different semantic types in different circum-stances. Hence, we propose an approach which considers not only the string of the term but also the semantic type of the term in each product document title. We apply a super-vised learning method to labeling the sema ntic type for each term in product document title and modify the conventional Language M odel to improve the relevance of search results.

The rest of this paper is organized as the f ollowing. Section 2 introduces many re-lated works and existing approaches. Sec tion 3 formulates this problem and defines notations in this paper. In section 4, our methods are described in detail. And in section 5, we introduce our dataset and report experime nt results to verify our methods. Finally, section 6 is our conclusions and future works. Some existing works are based on logs, which are knowledge from previous buyers. On-line shopping platforms record users X  browsing history, keywords for search, click-ing behavior on products, or transaction records to purchase products. Methods using the history data are known as log-based solutions. Nish Parikh and Neel Sundaresan make a detailed study of eBay logs. They try to find semantic query relations and build graphs for searching or recommendation applications [7]. Also, they try to find burst events from queries [8]. Ravi Chandra et al. directly explore rules from logs for product search [3]. An association-rule-mining-liked method is proposed by them and has good performance.

Logs can also be used by collaborative filtering or recommendation systems. Using collaborative filtering techniques in e-commerce platforms has been discussed for years [9,2,10]. Raz Lin et al. integrate both information retrieval and collaborative filtering techniques for search in on-line shopping platforms. Their solution considers not only buyers X  but also their neighbors X  browsing history and preference profiles [5,6]. Another research group, Y.S. Kim et al., considers navigational and behavior patterns as well [4]. They also give more considerations to the products that are clicked but not purchased.
Log-based solutions may have good performance, but they also have many disadvan-tages. First of all, they cannot response to the market immediately. Time and adequate users are required to shape up rules from the logs. Second, log data is usually difficult to obtain due to privacy issues. Most of large scale websites have their own privacy poli-cies. Last, using log data to change search ing behavior will influence future log data. Log-based methods can only be applied once in some circumstance. For these reasons, we would like to solve this problem using only contents. To formalize this problem, we define a term in the first place. A term t can be a separate word in English, a single symbol such as punctuation marks, or characters in Chinese. Each term t has its own part of speech, denoted as POS ( t ) . We regard a product as a document with one or more terms. A product document d i representing a product to D ( d i )= { t j } . A tuple consists of two parts: a term and a semantic type of the term. semantic type for term t j . We will describe how to determine the semantic type for a term in our methodologies later. Also, a product query q consists of a set of tuples: { v 1 ,v 2 , ..., v n
The problem to be focused in this paper can be formulated. Given a product doc-ument collection C = { d 1 ,d 2 , ..., d k } with k product documents and a query q , our objective is to rank all product documents d i  X  C ordered by a scoring function Score ( q, T ( d i )) in a decreasing order. Figure 2 is our system architecture. As de fined above, given a data collection C ,we have to pre-process the product documents, including storage, indexing, and Chinese word segmentation. Our methods have three main phases to solve the problem. The first phase of our method is named  X  X erm type prediction X . In this phase, we aim to predict the semantic type of each term fro m product document titles. Using this type information, the second phase is a type-based retrieval model which retrieves relevant product documents from product document collection. And the final phase is a filter to remove irrelevant product documents in th e final ranking list. The three main phases will describe in detail in the following subsections. 4.1 Term Type Prediction Term Type Prediction in Product Document Title. In our observation for mismatched product documents, the crux of the problem we find is that the retrieval system does not understand the semantic type of each term in the product document. For instance, con-sider these two product document titles:  X  USB Desktop Battery Charger Cradle For Nokia N97 Mini Cellphone  X  Nokia N97 Mini Unlocked Cellphone Plus Free Battery When a buyer issues a query  X  X ellphone X  and intents to buy a cellphone, these two prod-uct documents may be retrieved because of matched keywords. However, we humans can easily distinguish that the second product document is the real cellphone, but the first product document is only an accesso ry of cellphones. Even though both product document titles contain the same term  X  X ell phone X , the semantic type of this term are different. In the second product document, the term  X  X ellphone X  is a product, but in the first product document is not. The main produc t of the first product document is battery, whereas the main product of the second product document is cellphone.

Hence, our idea is to let the retrieval system to understand the semantic type of each term for each product document title. By observation from query collection in our experiments, high frequency query term s have three main kinds of types: product, brand, and model. To simplify, we aim to categorize each term into one of the four types:  X  Product (P): the major sale goods.  X  Brand (B): production companies or retailers.  X  Model (M): the design model, usually appears in electric products. E.g.  X  X 97 X ,  X  None (N): none of above.
 The objective categorizing results for the above examples are:  X  USB N Desktop N Battery P Charger P Cradle P For N Nokia B N98 M Mini M  X  Nokia B N97 M Mini M Unlocked N Cellphone P Plus N Free N Battery N We apply a well-known supervised machine learning approach named support vector machine (SVM). We train three binary cla ssifiers to determine each term in title:  X  X s features for each term in product document title. For a product document title T ( d i )= { u 1 ,u 2 , ...u m  X  Part of speech features. ( t j  X  1 ,t j ,t j +1 ) We observe that a term with Product type  X  Is parentheses ( t j  X  1 ,t j ,t j +1 ). Chinese sellers like to put Brand terms into paren- X  Length of term ( t j  X  1 ,t j ,t j +1 ). In multi-byte encoded langua ges like Chinese, this  X  Is alphabets and/or digits only ( t j  X  1 ,t j ,t j +1 ). Brand or Model type terms usually  X  Term frequency features ( t j ). We find that Brand terms sometimes occur twice in a  X  Document frequency features ( t j ). A term with very high document frequency may  X  Location-based features ( t j ). Term occurrence position is very useful. Brand terms Term Type Prediction in Query. After giving a type for each term in each product document title, we also have to give a type for each term in the query. For a query v as the most likely semantic type accordin g to the whole corpus. This method is good for some terms that have ambiguous semantic types. For example, the term  X  X pple X  is not only a famous computer company but also a kind of fruit. But in the whole corpus, the term  X  X pple X  is more likely to be a brand of Apple Computer Inc., instead of a fruit U  X  X  P roduct, Brand, M odel } .Otherwise,  X  ( t 4.2 Retrieval Model To find relevant product documents, we modify Language Model with Bayesian smooth-ing using Dirichlet Priors. Given a query q , we have to estimate the probability of gen-scoring function Score ( q, T ( d )) for retrieval ranking. With Bayesian smoothing using Dirichlet Priors, we assume pseudo counts  X  1 P ( t i | T ( C )) for unseen terms in product document title T ( d ) .
 For a query term t q and another term t d from product document title, we define two matching: t q = t d . Note that the two conditions are not disjoint, a term satisfies ex-actly matching also satisfies partial matching. We give some pseudo count  X  2 P ( t | T ( d )) for terms satisfying partial matching for smoothing propose, instead of restricting the exactly matching for all terms. Hence, we have: where t is a term and e can be a product document d or the whole product document collection C . To observe the effect of this approach, take the logarithm of equation 1 and place equation 2 into it, we have: Part (3b) is like the term frequency -inverse document frequency (TF-IDF) weighting and part (3c) can be regard as document length normalization. We can also find that a product document title with a term exactly matching another term in query will have more likelihood to be retrieved than only partial matching. 4.3 Irrelevant Removal In the previous phases, many smoothing strategies are adopted to improve the search recall. But this also causes noises. To have a better ranking precision, we try a naive method to eliminate irrelevant product documents from the retrieved set. We make an assumption that most of top retrieved product documents are relevant. Hence, this phase aims to eliminate product documents that are not similar to the top retrieved product documents. The elimination method simply calculates an average vector from top ten retrieved product document titles, and remove s product documents with cosine similar-ity to the average vector less than or equal to 0.5. In the experiments of term type prediction, we will show our prediction result. In the other phases, the type-based retrieval model and the irrelevant removal, we will evaluate our methods by common information retrieval evaluation criteria. 5.1 Data Collection Our experimental datasets have two parts: the product document collection and the query collection.
 Product Document Collection. The product document collection contained 984,096 product documents and was crawled from Yahoo! Taiwan Shopping platform on Oc-tober, 2009. Yahoo! Taiwan Shopping is a famous shopping website in Taiwan. Each product document has about 10 columns incl uding id, category, title, subtitle, thumbnail image, description and timestamps. In our observation, the average number of terms in all product document titles i s 11.4703 and the average unique number of terms in all product documen t titles i s 11.2823.
 Query Collection. The query collection was a set of query keywords issued to Yahoo! Taiwan Shopping and Ruten Auction Platform 2 on April 25, 26 and 27 in 2010. Ruten Auction Platform is another shopping website in Taiwan funded by PChome Online and eBay Inc. Different from Yahoo! Taiwan Shopping, products in Ruten Auction Platform were decided by various sellers like eBay, yet products in Yahoo! Taiwan Shopping were decided by inner salesmen. The query collection was collected from the logs of Web Reputation Service provided by Trend Micro Inc. A simple observation is shown in Table 1. 5.2 Term Type Prediction Evaluation To produce training data for supervised learning, we have to sample some product to be labeled by human. We reference to the categories of the product document collec-tion. The three main categories of products in amount are clothing accessories (17%), clothes(17%), and 3C (Computer, Communication, and Consumer Electronic) (13%). Therefore, we sample 400 product documen ts for each category from the three main categories. The total 1,200 product docum ent titles are labeled by humans. We have three volunteers. A volunteer has to lab el one of the four types for each term in each product document title. We choose the labels with at least two agreements on type from the volunteers.
 We use LibSVM [1] for SVM training. To find the best parameters  X  and C for the C-Support Vector Classification and the Gaussian radial basis function, we try different parameters using a grid tool to reach the best accuracy. Using the parameters for the best accuracy, the performances including accuracy , recall, precision and F-score are shown in the left side in Table 2 (Mi cro View). In this classification problem, recall means the percentage of correct prediction from all tr ue positive examples. Precision means the percentage of correct prediction from all examples which are predicted as positive. The F-score is a measurement considering both r ecall and precision. Note that F-score does not consider true negative examples, which are very common in this training method. This report is a micro view since we evaluate in term level. We find out that type Brand is the easiest one to predict, yet type Product and Model are good for precision but poor in terms of recall.

To avoid the problem of Chinese word segmentation, we also evaluate in a macro view. We concatenate terms by human and restr ict the correct prediction to only exactly matching the concatenated section. For example, we can consider a title with four tuples and u 3 , a prediction  X  ( u 1 )= N,  X  ( u 2 )= P,  X  ( u 3 )= P,  X  ( u 4 )= N is correct and otherwise conditions like  X  ( u 1 )= P,  X  ( u 2 )= P,  X  ( u 3 )= P,  X  ( u 4 )= N or  X  ( u 1 )= N,  X  ( u 2 )= P,  X  ( u 3 )= N,  X  ( u 4 )= N are incorrect. The performances including recall, precision and F-score are available in the right side in Table 2 (Macro View). We do not report the accuracy because it is hard to define true negative conditions in macro view. In this report, the recall of Product type and Model type is very low, similar to the micro view performance.
 Feature Contribution Analysis. We are curious about which feature is useful dur-ing training. Accordingly, we decide to re move some features and check whether the performance is affected or not.
 The percentage of change in accuracy, reca ll, precision, and F-score are shown in Table 3. Negative value indicates that the p erformance has decreased after the removal of feature or group of features and vice versa. Values that contribute the highest per-formance in a row are marked in bold. In th is result, we can find that location-based features (LOC) have significant contributions when predicting Product or Brand. A pos-sible reason is that sellers tend to put Product or Brand terms in the first place or the last place in a product document title. Another discovery is that term length (LEN) or  X  X s not a word X  (PNW) features contribute a lot when predicting Model because sellers usually use one character symbols to decorate model strings.
 Category of Products Prediction Performance Analysis. Finally, we observe the prediction performance in each category of p roducts. Figure 3 shows the three main categories labeled by human in advance. Clothes products are easier to predict than 3C products in terms of accuracy. We specula te that 3C products have the poorest recall due to the diversity of 3C products. 3C products contain various products and their accessories. Like the cellphone examples in section 4.1, a cellphone can have lots of possible related accessories terms together in title. So, it is hard to distinguish Product terms in 3C product titles. After applying the p rediction model to all categories of prod-ucts, the average number of terms in the prediction result is reported in Fig. 4. Clothes products tend to have more Brand type terms because a Chinese brand is often split into many separated terms. 3C products have more Model terms, since models usually appear in 3C products. For example,  X  X 800i X ,  X 3310 X ,  X  X 61 X , or  X  X 5F X  are models for cellphones and laptops. 5.3 Retrieval Model Evaluation We split the query collection into two parts: 1) High frequency queries (HFQ). The most frequent queries to be issued. 2) Random queries (RQ). Randomly sampled queries from the original list of queries. We sampl e 30 queries from each part for evaluation.
We compare our methods with different parameter  X  2 and some existing methods or implementations, including Vector Space Model (Apache Lucene 3 ), conventional Lan-guage Model, and search results from on-line product search services for well-known Chinese shopping platforms in Taiwan. We compare with on-line product search ser-vices including Yahoo! Taiwan Shopping (YTS), Yahoo! Taiwan Portal Product Search (YPS) 4 , and PChome Shopping 5 on May 2010. It is important to note that the on-line product search services have different product corpora from our methods currently used. Hence, the comparisons of on-line product search services are for reference only. Figure 5 is an average evaluation result o f HFQ and RQ dataset from query collection Ruten Auction and Yahoo Taiwan Shopping because each separated result is almost the same. LM means conventional Language Model. M 0, M 1andM 1 F are our methods with parameter  X  2 =0 ,  X  2 =1 ,and  X  2 =1 with irrelevant removal. Our methods M 1andM 1 F are significantly different from baseline methods LM and Lucene from Student X  X  t-test with p  X  value &lt; 0 . 01 in precision at one. Compared only with baseline Lucene, M 1andM 1 F also have significant different with p  X  value &lt; 0 . 05 when measuring P@1, P@2, P@3, P@5, P@10 and P@20. In this Fig., we can see that our method with  X  2 =1 plus irrelevant removal has the best performance. Our method with  X  2 =0 causes very bad performance. Therefore, giving some pseudo counts for terms with type mismatch is necessary. Figure 5 also shows that conventional methods without considering semantic types of each term, such as Language Model and Vector Space Model (Lucene), may have worse performance.

We also try to figure out the effect of our parameter  X  2 . In fig. 6, we can see that allowing only exactly matching (  X  2 =0 ) results in very bad performance.  X  2 =1 is much better. When  X  2 is closed to the average number of terms in product document titles | T ( d ) | =11 . 47 03 , the performance costs down again. 5.4 An Example Consider a query  X  X aptop X . Obviously, a buyer issuing this query tends to buy a laptop. The top ten retrieved product document title s (translated from Chinese to English by human) by Lucene are shown in the left side of Table 4. Without considering each se-mantic type of each term in title, even though all these ten titles have the term  X  X aptop X , they are obviously not laptops.

On the other hand, the right side of Table 4 are product document titles retrieved by our methods. The top eight results are truly laptops and highly related to the buyer X  X  query. In the term type prediction phase, we have predicted the term  X  X SI X  as a Brand and  X  X aptop X  as a Product in the first retrieved product document. The query term  X  X aptop X  is predicted as a Product type becau se 71.13 percent of pr oduct docum ent titles having this term are predicted this term as Product type in the whole corpus. Therefore, the first product document gets high score because of not only ter m  X  X aptop X  matching but also type Product matching.
 In this work, we firstly point out the problem of product search in current on-line shop-ping platforms. Next, we describe our key i dea to find the semantic types of each term in product document titles and propose a supervised learning method to learn a prediction model. To find relevant products, we modify Language Model to improve the relevance of search results using the prediction model.

In the future, we can try to use the type prediction model in other applications like recommendations or user interfaces in browsing products. Also, our method may be applied to other vertical search domains such as movie search, news search, or blog search.

