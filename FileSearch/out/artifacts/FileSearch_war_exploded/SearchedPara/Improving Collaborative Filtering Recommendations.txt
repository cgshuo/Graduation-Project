
This paper describes an approach for incorporating ex-ternally specified aggregate ratings information into certain types of collaborative filtering (CF) methods. For a statis-tical model-based CF approach, we formally showed that this additional aggregated information provides more ac-curate recommendations of individual items to individual users. Furthermore, theoretical insights gained from the analysis of this model-based method suggested a way to incorporate aggregate information into the heuristic item-based CF method. Both the model-based and the heuristic item-based CF methods were empirically tested on several datasets, and the experiments uniformly confirmed that the aggregate rating information indeed improves CF recom-mendations. These results also show the power of theory by demonstrating how the insights gained from theoretical developments can shed light on proper selection of good heuristic methods. We also showed the way to introduce scalability and parallelization into the estimation procedure and reported the running time for steps of the estimation procedure for large datasets.
Consider a Netflix recommender system [7] and assume that it is augmented with the aggregate ratings from the IMDB database [13], such as the one specifying that fe-malesintheagecategoryof18to29gaveanaveragerating of 6.9 (out of 10) to the movie  X  X adagascar. X  Can such additional aggregate rating information, provided from the external sources, improve the quality of individual ratings? More generally, a traditional recommender system provid-ing individual ratings to individual users can be supple-mented with an externally provided OLAP-based [1] sys-tem of aggregate ratings, such as the aggregate ratings for  X  X adagascar X  provided by females vs. provided by females in the age category of 18 to 29 years. [20] studied this question for the special type of a sta-tistical model reported in the marketing literature [5] and showed that these externally obtained aggregate ratings can be converted into additional constraints on the model esti-mating individual ratings. [20 ] also theoretically demon-strated that these additional constraints provide for better estimation of unknown ratings.

Although useful and having nice statistical properties, the model from [5] is not widely used in the field of rec-ommender systems. Therefore, in this paper, we study how the aggregate ratings information can be used in the collab-orative filtering (CF) systems constituting the  X  X read-and-butter X  of recommender systems. To this end, we show in this paper that these external aggregate ratings can be used for providing better recommendationsof individual items to individual users for a certain class of collaborative filtering systems.

More specifically, we consider two types of CF sys-tems: model-based and classical item-to-item based CF [17]. We selected the model-based CF approach because it was grounded in fundamental statistical theory, and, there-fore, we wanted to gain some insights on how to handle aggregate ratings based on that theory. We also selected the classical heuristic based [17] item-to-item CF method because of its popularity in the recommender systems com-munity and because it is used in some popular systems, in-cluding Amazon X  X  recommender system [15]. We also show how to expand the theoretical insights obtained from the model-based approach to developing better recommenda-tion methods for the heuristic-based CF approach.
We made the following contributions in the paper: for the model-based and the CF models approaches we  X  showed how to apply the aggregate rating information  X  theoretically and experimentally showed that the ag- X  applied the insights gained from our studies of the  X  experimentally showed that these insights indeed lead  X  showed how to scale the proposed methods to large
The usage of aggregate ratings has been previously stud-ied in the recommender systems literature. An idea of us-ing an OLAP-based multidimensional approach to recom-mender systems was proposed by [2]. This approach was subsequently extended by [1] by incorporating additional contextual information on ratings, such as when, how and with whom the movie was watched. Also, [16] presents a method for providing recommendations to a group of users. [14] discusses new issues that arise when one considers web-based personalization involving groups for a certain subclass of group recommender systems. Both methods deal with the bottom-up approach to recommendations that used aggregate ratings as a basis for recommendations to groups of users. In contrast to this, [9] presents a top-down method for using aggregate information about traversal of hypertext pages by a group of users in order to provide bet-ter recommendations of hypertext pages to individual mem-bers of the group. [6] presents a two-level rating estimation method where at the lower level ratings are estimated using collaborative filtering deploying local scale neighborhood information. At the upper level, [6] uses SVD-style factor-ization based on global scale information to improve pre-dictions. However, this work does not use any information on prespecified taxonomy of users or items, nor does it use externally specified aggregate ratings. [4] uses pre-existing taxonomy of webpages and advertisements in order to bet-ter estimate the click-through rate and combat the sparsity of the data. However, this work is only tangentially related to recommender systems, also does not use any externally specified aggregate information and does not deal with ag-gregate ratings. [20] presents the preliminary work on ag-gregate ratings model based on [5] and analyses it at the theoretical level. However, none of this prior work focused on using aggregate ratings information to improve the CF methods considered in this paper.

The rest of the paper is organized as follows. In Sec-tion 2 we describe a model-based approach to collabora-tive filtering from [19] and the estimation procedure that we implemented in order to estimate unknown parameters of the model. In Section 3 we describe our new method of adding aggregate information into this model, get theo-retical insights on how this information is introduced and prove theoretically that the aggregate information improves performance. In Section 4 we use these theoretical insights obtained from the model-based approach in order to intro-duce the aggregate information into classical heuristic item-based collaborative filtering. In Sections 5 and 6, we show empirically on several dataset s that the significant improve-ment is achieved for both model-based CF and item-based CF when the aggregate information is introduced using the suggested method. In Section 7, we address scalability is-sues for our method.
First, we present a model-based approach to CF that is grounded in the fundamentals of statistical theory. In par-ticular, we follow [19] in this section when describing such an approach. Then the insights from this theoretical devel-opment are applied to handle the classical item-based CF in Section 4.

Assume we have a set of N users and M items. De-note r ij an observed or unobserved rating by user i for item j . Moreover, for a specific item j , denote the vector r j =( r 1 j ,r 2 j ,...,r Nj ) a vector of ratings of all N for item j . We assume that all vectors r j are i.i.d draws from a multivariate normal distribution with some unknown mean vector  X  and unknown covariance matrix  X  : We also assume that for each j , we do not observe the vec-tor r j completely, but only observe some subset of ratings explicitly provided by some subset of users K ( j ) .
The goal of this recommender system is to estimate an unobserved rating r ij from the set of observed ratings { r and parameters of the model  X  ,  X  . According to [8], the least mean squared error unbiased estimator for (1) is:
For item j , consider the vector of observed ratings r Kj where K = K ( j ) is a set of users whose ratings we have ob-served for item j , and the vector of unobserved ratings r where U = U ( j ) is a set of users whose ratings we have not observed. From the assumption that r j is drawn from mul-tivariate normal distribution, we conclude that ( r Uj , r is also drawn from the following multivariate normal distri-bution:
As it is shown in [11], the conditional expected value has the following form:  X 
We call the estimator  X  r Uj unconstrained rating estima-tor (URE) for the reasons that will become clear below when we introduce aggregate information as a constraint.
Equation (3) provides us a direct method for computing the estimator of unobserved ratings r Uj .However,wemust take into account that the parameters  X  and  X  of the model (1) are unobserved as well. Following [19] and [12], they can be estimated using our prior beliefs about the parame-ters and the observed ratings as follows.

We follow the standard assumption in Bayesian statistics [12] that our prior beliefs are conjugate priors on  X  and  X  : where  X  0 ,  X  0 ,  X  0 , k 0 are hyper-parameters of the model, that is, parameters specifying our prior belief about param-eters  X  and  X  before observing the data. The scalar hyper-parameter  X  0 describes the degrees of freedom and the ma-trix  X  0 describes the scale of inverse-Wishart distribution. The vector hyper-parameter  X  0 is the prior mean and the scalar k 0 is the scaling of prior variance.

In order to find the point estimates of unobserved param-eters  X  and  X  , we find the values  X   X  and  X   X  that maximize the posterior probability P (  X  ,  X  | observed { r kl } ) : P (  X  ,  X  | observed { r kl } )
In [19], the parameters were estimated using expectation-maximization algorithm. However, that approach did not work well on our data, since their algorithm converged very slowly to a local optimum for us.
Therefore, in this paper we developed the following al-ternative method for estimating parameters  X  and  X  for model (1) by following the ideas from [12] and taking into account our likelihood function (1). After some algebra, we find that the negative logarithm of posterior distribution corresponds to the following expression (up to a constant term):  X  log P (  X  ,  X  | observed { r kl } )= + where K = K ( j ) is the ordered set of users whose ratings we observed for item j ,  X  K is a subvector of  X  correspond-ing to mean ratings of the users from the set K ( j ) ,  X  a submatrix of  X  corresponding to rating covariance matrix of the users from the set K ( j ) .

Therefore, the point estimates for unobservedparameters  X  and  X  that are required for our analysis can be found by minimizing the expression (4) with respect to  X  and  X  , thus maximizing their posterior probability.

The minimization can be done using the following gradi-ent descent iterative procedure. First, we compute the gra-dient of the negative log posterior (4) as follows. Let us de-note elements of some index set K as ( k 1 ,...,k | K | ) .Then we introduce the matrix L K of size N  X | K | as follows: Intuitively, if we multiply any matrix A by the matrix L
K , then we just swap and arrange columns of A according to ordered set K and remove from A the columns corre-sponding to numbers that are not in K . For example,
Then the gradient of (4) w.r.t. parameter  X  is  X  (  X  log P )
The gradient of (4) w.r.t. parameter  X  is
Second, after defining this gradient, we estimate param-eters  X  and  X  using the line search gradient descent proce-dure [10] that guaranteed to converge to a local minimum.
The estimates  X   X  and  X   X  that are obtained after conver-gence of this algorithm are substituted into equation (3) for computing ratings predictions.
In this section we describe a method of adding aggre-gate information to the unconstrained (URE) collaborative filtering model presented in Section 2. We assume that we have some external source of information from which we also observe an aggregate rating r a = 1 N N i =1 r ij for a particular item j . 1 In particular, assume that: where a j is the observed noisy average rating for item j is the unobserved true value of the average rating,  X  j is a noise component,  X  j is a known item-specific parameter of the noise.

For example, assume we are using the Netflix Prize movie rating dataset [7] to predict the rating of  X  X adagas-car X  for a particular user and we also know from IMDB [13] that the average rating r a for  X  X adagascar X  is a j =6 . 5 with unobserved noise  X  j having the aggregate noise uncertainty  X  j =0 . 15 for this movie. Note that, in general, the external aggregate ratings may come from a sample that is different from the sample of the given individual ratings , including having different distribution properties. However, the noise term  X  allows us to handle such occasions by choosing  X  ac-cordingly. More specifically, if the sample for the aggregate information is quite different in their characteristics from the sample of individual information, then specifying high  X  will allow to accommodate for the inappropriateness of the aggregate rating for the particular sample and force the estimation procedure not to treat this information as precise.
In this model, the joint distribution of the observed, the unobserved and the aggregate ratings is a multivariate nor-mal:  X   X  where  X  11 ,  X  12 ,  X  21 and  X  22 are as in (2). Since the matrix  X  31 is just an average of all rows of  X  11 and  X  21 . Similar analysis applies to  X  32 whichisanaverage of all rows of  X  12 and  X  22 . To compute  X  33 ,weusethe following cov ( r a ,r a )= cov That is,  X  33 is the average of all the elements of  X  11 ,  X  12 ,  X  21 and  X  22 and the variance of the aggregate noise .

Therefore, following the id eas from [11], as in the case of equation (3), the least mean squared error unbiased esti-mator that takes into account the observed aggregate infor-mation (5) is
We call the estimator (9) the constrained rating estima-tor (CRE) , since besides using the observed ratings r Kj also incorporates the additional constraint of the type (5). Theorem 1. The expected mean squared error of the con-strained rating estimator (CRE) is smaller than the expected mean squared error of the unconstrained rating estimator (URE).
 Proof. From (6), (9) and the properties of multivariate nor-mal distribution, we conclude that the conditional distribu-tion of ( r Uj ,r a ) , given that r Kj = a , is also a multivariate normal distribution with the covariance matrix:
Therefore, the variance of the estimator without aggre-gate ratings is However, as it follows from (10) and the properties of mul-tivariate normal distribution [11], the variance of the esti-mator with aggregate information is Since S 22 is a non-negative definite matrix, S 12 S  X  1 22 is also a non-negative definite matrix. Therefore,
That is, in terms of comparison of non-negative definite matrices, the covariance matrix of CRE is  X  X maller X  than the covariance matrix of URE. This implies that the standard errors of CRE are also smaller.

Since both estimators  X  r  X  ij and  X  r ij are unbiased, then lower standard error of the estimator implies lower mean squared error of predictions [8].

Define an aggregate correction term T ij using expres-sion where  X  r ij is the unconstrained estimator from (3) and  X  the constrained estimator from (9). Subtracting (3) from (9), we get the following expression for the vector of correction terms T Uj : where T Uj is a vector of individual correction terms for all unobserved ratings U = U ( j ) for item j .

From this definition of T ij , we may consider the process of introducing external aggregate information as an addition of aggregate correction term T ij to the standard model (3). As Theorem 1 shows, adding the correction term to the URE estimator (3) must improve the performance of the model. Moreover, this result holds not only in theory, but it is also confirmed on the real-life rating data as shown in Section 6.
The case of observing multiple aggregate ratings r a 1 , ... , r al for a particular item j is a simple generaliza-tion from the described case of observing just a single rat-ing r a for item j . Moreover, these aggregate ratings can be specified over specific segments of users and groups of items, such as an aggregate rating taken over females living in New York and over Woody Allen X  X  comedies, thus, im-plicitly introducing user segmentations and item groupings into the model.

In the next section, we apply this correction term ap-proach (11) when we incorporate the aggregate rating infor-mation into the classical item-based collaborative filtering.
We follow the standard approach of [17] to the item-based CF in this section and show how it can be improved using the aggregate information and some of the ideas from Section 3.

Item-based collaborative filtering is one of the most pop-ular recommendations techniques used widely in industry by such companies as Amazon [15, 18]. The item-based approach attempts to determine a user X  X  rating for an item based on the ratings of similar items this user rated in the past, where the similarity between two items is established based on the correlation between the ratings for these two items. More specifically, for user i and item j , item-based CF estimates the rating r ij as: where I ( i ) is the set of the items for which ratings by user i are observed and s jk is a measure of  X  X imilarity X  between item j and item k .

A common measure of similarity between two items j and k is a Pearson correlation coefficient: where r .j is a sample average rating for j -th item.
The item-based approach described above falls into the heuristic-based category [3], unlike the model-based URE and CRE estimators described in Sections 2 and 3. There-fore, formal statistical analysis to improving rating estima-tions presented in Section 3 cannot be directly applied to the item-based approach.

However, we decided to use the theoretical insights ob-tained from the model-based approach from Section 3 and applied them to the item-based approach as follows. Since the rating estimator  X  r  X  ij that uses aggregate information has the form defined by equation (11) having the additive cor-rection term T ij , we conjecture that the same correction term may help to improve the item-based CF. In particu-lar, we defined a new item-based rating estimator for the item-based CF method as where T ij is calculated as in (12). In Section 6, we empir-ically show that this new rating estimator indeed improves performance of the item-based CF.
To empirically validate the theoretical results from Sec-tion 3 and to see if estimator (13) indeed improves the item-based collaborative filtering, we conducted the experiments on the following  X  X eal-world X  datasets. The first one was the Netflix Competition dataset [7], from which we took three subsamples for validation purposes. The other one pertains to recommending movies and was used in [1]. We also took the external aggregate ratings from the IMDB dataset and applied them to both datasets. In the rest of Section 5 we describe these datasets, and in Section 6 we present the ex-perimental results.
For our experiments we used three random subsamples of the Netflix Prize dataset [7]. Specifically, the first sub-sample of the Netflix dataset was produced by selecting 100 users from the set of all the Netflix users ranked be-tween 2000 to 2100 based on the total number of ratings they gave. Then we selected 100 random movies that these selected users watched and 3000 random ratings that they provided for those 100 movies 2 . The second and third sub-samples of the Netflix dataset were produced in a similar manner, except that we selected 100 random users for each subsample from the group of users ranked between 10,000 and 300,000 based on the total number of ratings they gave. Finally, each dataset was randomly split into ten subsets for the 10-fold cross validation.

For each of the three aforementioned datasets, we in-troduced external aggregate information from the IMDB database exactly as for the movie database in Section 5.2 with the aggregate rating variance of  X  2 =0 . 02 for movies that received more than 1000 votes. Both IMDB ratings and Netflix Prize dataset ratings were normalized to the [0 , terval.

The original Netflix Prize dataset [7] contains no de-mographic or other information about users except their id number. For movies, Netflix Prize dataset [7] provides the movie title and movie release year. For users X  ratings, the time when the rating appeared on the website is also pro-vided by the original dataset.
In order to diversify our sample, we used the data from the study [1] on 61 users that provided 1110 ratings for 62 movies. The dataset was also randomly split into 10 subsets for 10-fold cross validation.

In order to introduce external aggregate information into the data, the average rating from the IMDB database [13] for each movie was used. For each movie in the dataset from [1], we found the average movie rating contained in the IMDB database and used this average rating as the ex-ternal aggregate rating for that movie.

The dataset from [1] contains demographic information about users such as user X  X  age, gender, home ZIP code and preferences about the context behind the movie watching experience, such as the preferred time and venues for watch-ing movies. For movies, the dataset from [1] provides the movie title and movie release year. For users X  ratings, this dataset provides complete description of the context of the movie watching experience, such as when, where and with whom the movie was seen.
The graphs in Figures 1, 2 and 3 represent the mean squared error (MSE) performance of the model-based CF and item-based CF as a function of the number of additional aggregate ratings introduced for the movies dataset from several subsets of Netflix Prize Dataset [7]. More specifi-cally, Figures 1, 2 and 3 plot on the x -axis the cumulative number of additional aggregate ratings introduced into the model. The 0 -th tick corresponds to the plain basic recom-mendation model without any aggregate ratings. The 1 st tick corresponds to just one aggregate rating of type (5) for the first item as described in Section 3. The 2 nd tick adds one more aggregate rating of type (5) for the second item, and so on. On the y -axis we plot the MSE performance of the model based on 10-fold cross-validations described in Section 5.2.

Although the MSE error rates are not monotone, as Fig-ures 1, 2 and 3 demonstrate, the overall drift taken across multiple average ratings is definitely downward, as Figures 1, 2 and 3 clearly show. This experimental finding is in line with Theorem 1 and empirically supports the theory.
Therefore, all the three graphs confirm the theoretical re-sult from Theorem 1 that the predictive rating errors de-crease on average, as the number of aggregate ratings in-creases. The MSE in Figure 1 decreased by 1.25% for model-based CF and by 2% for item-based CF from the case of no aggregate to 96-99 additional aggregate ratings. The MSE in Figure 2 decreased by 1.1% for model-based CF and by 2.14% for item-based CF. The MSE in Figure 3 decreased by 1.5% for model-based CF and by 1.5% for item-based CF.

Despite relatively small numbers, we would like to em-phasize that 1% and 2% constitute solid performance im-provements, given that they are based on less than 100 ad-ditional aggregate ratings. For comparison, the $1,000,000 Grand Prize of the Netflix Prize Competition required per-formance improvement of 10% for the RMSE. Moreover, if the leading competitor of the Netflix Competition could achieve an MSE performance improvement of 1.7% today (as of July 06, 2008), that competitor would have won the $1,000,000 Netflix Grand Prize.

Furthermore, all these performanceimprovementsdo not happen by chance alone. To see this, assume that the re-ported performance improvements simply constitute ran-dom white noise. This assumption would imply that the MSE graphs on Figures 1, 2 and 3 are the results of a ran-dom process with zero drift with MSE improvements jump-
Figure 1. MSE decreases both for model-based CF (top) and item-based CF (bottom) on a Netflix-1 data as more aggregate infor-mation is introduced. ing arbitrarily up and down as additional aggregate ratings are introduced (and plotted along the x-axis). However, it is clear from the graphs that the process has a drift down for all the datasets that we used. The same drift down is observed for other datasets that are not reported in this paper because of the space limitations. There is no single case of the MSE of the constrained estimator with 15-20 aggregate ratings or more being bigger or equal to the MSE of the unconstrained estimator. Therefore, we conclude from these observations that this downward drift would have been unlikely under the assumption that the performance improvement is a random white noise, which is in line with the result of Theorem 1.
The graph in Figure 4 represents the mean squared error (MSE) performance of the model-based CF and item-based CF as a function of the number of additional aggregate rat-
Figure 2. MSE decreases both for model-based CF (top) and item-based CF (bottom) onaNetflix-2dataasmoreaggregateinfor-mation is introduced. ings introduced for the movies dataset from [1].
As before, since the graph in Figure 4 is not aver-aged across multiple datasets, there are occasional non-monotonic jumps in it. This happens because adding one aggregate rating to a training sample does not always im-prove MSE on the test set. For example, the aggregate rating of 6.5 given to movie  X  X adagascar X  may not reflect biases of the particular segment of users who gave the ratings, and this aggregate rating may not fit well with the particular in-dividual ratings given to movie  X  X adagascar X  by the users in our dataset. This explains the big jumps observed in Fig-ure 4 for the model-based CF, where inaccurate aggregate rating information was used for some of the movies (such as movie #25). This happened for this particular movie be-cause all the users who gave good rating for the movie hap-pened to be excluded from the subsample since they pro-vided only few overall ratings.

Furthermore, note that the MSE decreased in Figure 4
Figure 3. MSE decreases both for model-based CF (top) and item-based CF (bottom) on a Netflix-3 data as more aggregate infor-mation is introduced. by about 0.7% from the case of no aggregate to 62 ad-ditional aggregate ratings for the model-based CF and by about 2.1% for the item-based CF.
 As in the case of the samples from Netflix dataset from Section 6.1, this case constitutes a solid performance im-provement, given that they are based on less than 62 addi-tional aggregate ratings. Again, for comparison, the Netflix Prize competitors try to achieve performance improvements of 10% over the Netflix baseline, and the key competitors would have won the $1,000,000 Grand Prize today if they could achieve such performance improvements now.
The computational performance of our method was rea-sonable on the datasets used in our experiments. In particu-lar, the estimation of unknown parameters  X  and complete
Figure 4. MSE decreases both for model-based CF (top) and item-based CF (bottom) on a movie rating dataset as more aggregate information is introduced. matrix  X  using the iterative gradient descent algorithm pre-sented in Section 3 and implemented in MATLAB on Intel Xeon CPU 3.73GHz took about 6 hours, depending on the particular dataset used in the experiments. Once the param-eters were estimated, the solution of (9) took on the order of 1 second for each of the datasets.

However, the method described so far requires estima-tion of the N  X  N covariance matrix  X  in (1) where N is the number of users. Therefore, it works well with cer-tain optimizations only for small-to medium-size datasets, such as the ones described in Section 5. In this section, we present enhancements to our basic method that make it more scalable and allow it to work on large datasets.
In particular, we propose the following estimation method of unknown ratings. Consider the ratings estimator from (9). If we estimate all the required unknown ratings r
Uj simultaneously using this equation, then the estimation of the full N  X  N covariance matrix  X  is required. How-ever, note that if we could estimate the unobserved ratings one-by-one using the same equation (9) and if we have only | K j | observed ratings for item j , then we would require ap-proximately a | K j | X | K j | submatrix of matrix  X  in (9) to estimate these ratings. More specifically, as it is written in equation (9), we would only need to estimate the corre-sponding covariance submatrix instead of the whole matrix  X  ,where r uj is the unknown scalar rating for item j that we are attempting to estimate.
If the number of observed ratings | K j | for item j is small, then this method is clearly better than the original one. For example, if there are 10,000 users and every item has only 5 ratings, then it is clearly much faster to estimate 9,995 times the matrix of size 7  X  7 than to do it once but on a matrix of size 10 , 002  X  10 , 002 .

Moreover, the external aggregate information is meant to be especially helpful for items with small amount of known ratings . The items with very sparse known ratings are the ones targeted by us for prediction improvement, since for heavily rated items the external aggregate rating informa-tion is almost revealed in the dataset itself.

Therefore, we suggest the following scalable estimation procedure: 1. Choose items with small number of given ratings . 2. For every such item, estimate the matrices  X  22 ,  X  23 3. Then, for every rating that is to be predicted for such 4. For every rating , use equation (9) to calculate the pre-
Assuming that the required parameters of  X  are already estimated, the complexity of the estimator of one rating (9) is O ( | K j | 3 ) ,where | K j | is the number of observed rating for item j . Note that, as explained above, the un-known ratings can be estimated independently from each other. Therefore, the computational time for estimating n unknown ratings is linear in the number of unknown rat-ings n , i.e., is O ( n | K j | 3 ) .

The estimation step involves iterative optimization pro-cedure, which makes it difficult to determine the theoretical complexity of the method. In order to examine scalabil-ity on practice, we selected 10 , 000 users and 10 , 000 items subsample from the Netflix Prize dataset 3 . In Figure 5 we present the average time it takes to complete Step 1 for one arbitrary item as a function of the number of already ob-served ratings for the item. The Figure 5 clearly demon-strates that, even without special optimization, the MAT-LAB code solves the problem in reasonable time, since the most time-consuming optimization in Step 2 needs to be done only once for an item. Step 3 of the estimation proce-dure takes on the order of seconds for estimating one rating for the example provided above.

Speeding up the estimation procedure is one of the di-rections for the future research. Fortunately, there is a large number of Bayesian estimation methods substituting or complementing the optimization methods with sampling techniques.

We should also note that, for the scalable method, we es-timate the matrices  X  31 ,  X  32 and  X  33 directly from the data as if we treat the aggregate rating r a as a rating provided by some pseudo-user and estimate the covariance matrix from the observed vectors r uj r Kj r a using the same Bayesian approach as we described above in Equation (4).
Note also that the rating prediction task is highly par-allelizable . If we have 10,000 items to predict ratings for, we may predict ratings for each item as separate indepen-dent tasks. For example, the estimation of parameters for one item with 10 known ratings will take 150 seconds as shown in the Figure 5. However, if we have 10,000 items with 10 known ratings for each item and if we have 100 CPUs, then the estimation of parameters of all items will
In addition, the results of running the described meth-ods for several datasets containing 10 , 000 users and 10 items are presented in our technical report [21]. Therefore, we conclude from all these discussions that the proposed method is scalable when used on modern computational ar-chitectures. We should also note that not only are the items with small number of given ratings the easiest to estimate from the computational point of view, but also that they are the ones targeted for the best improvement from the aggre-gate information.
In this paper we presented an approach for incorporating externally specified aggregate ratings information into cer-tain types of collaborative filtering (CF) methods. This was
Figure 5. Parameter estimation time for 1 item in 10 , 000  X  10 , 000 dataset done by introducing a statistical model of aggregate ratings and incorporating it into the CF methods. For a statisti-cal model-based CF method, we formally showed that this additional aggregated information provides more accurate recommendations of individual items to individual users. Furthermore, theoretical insi ghts gained from the analysis of this model-based method suggested a way to incorpo-rate aggregate information into the heuristic item-based CF method. We empirically tested the model-based and the heuristic item-based CF methods on several datasets; the experiments uniformly confirmed that the aggregate rating information significantly improves CF recommendations.
Among other things, this work shows the power of the-ory by demonstrating how the insights gained from theoreti-cal developments can shed light on proper selection of good heuristic methods.

We also demonstrated that the method can be scaled to large datasets and is inherently easy to parallelize. More-over, scalability is achieved easiest for the items that have only few known ratings. As explained in the paper, these items stand the most to benefit from the aggregate informa-tion, thus making scalability and sparsity  X  X ork X  together.
As a future research, we plan to combine the top-down aggregate rating method presented in this paper with the bottom-up method of computing aggregate ratings for the groups of users. The solution to this problem will help us to fill-in the entire OLAP-based hierarchy of aggregate ratings and provide for even better predictions of individual ratings as well as group ratings. We also plan to develop a wider theoretical framework by identifying a class of recommen-dation methods for which we can formally show that the aggregate ratings can help to provide better recommenda-tions. Another direction for future research constitutes the study of other methods of introducing this type of aggregate information into heuristic-based recommendation models.
