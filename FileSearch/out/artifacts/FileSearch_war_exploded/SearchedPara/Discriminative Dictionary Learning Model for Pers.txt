 Transferred knowledge and visual knowledge [31, 22, 6] such as appearance, shape and context of the target objects are important ingredient to enable learning and recognition object classes. In sparse coding approaches, dictionary is a type of transferred knowl-edge that may express the visual features of images. Images from different camera can be coded by learned dictionary to person re-identification. Person re-identification (re-id) between non-overlapping camera views is important in video surveillance [23] for its significant application on threat detection, human retrieval and cross-camera tracking. Person re-id aims at finding a pedestrian from a gallery set who has the same iden-tity as the probe set. The challenge problem of person re-identification is that a person observed from different camera views with significant variations on viewpoint, pose, illumination, image blurring, background clutters and occlusions, all of which make identification difficult.Traditional methods that sought to solve this problem focused on obtaining more distinct and reliable feature representations from people X  X  appearances, since feature extraction was the most important component in the success of person re-id. They even developed machine-learning methods that classified different persons, but it was too complicated to find features that could be applied to all the different images, just as it is currently too difficult to find a common metric model that is suitable for all scenarios. Unlike the traditional methods that did not concentrate on finding features or developed descriptors via distance or through machine-learning methods, the Sparse Representation based Classification (SRC) recently achieved the most impressive re-sults on record for person re-id.
 Classification with the learned dictionary. Images can be coded on a dictionary trained with various constraints, then classified using reconstruction error. Sparse coding tech-niques is based on the fact that a nature image can be represented by a small number of atoms parsimoniously chosen out of an over-complete dictionary. Dictionary Learning achieved impressive results in several classification and recognition problems [12]. Its aim is to learn from the training images and to develop a strong representational power, and the constraints placed on it in the training process ensure that it is sparse and dis-criminative. Previously, the dictionary was obtained by merely adding constraints to the training process, yet there is still some room for improvement by taking the representa-tion space of the dictionary into consideration.
 which produces a more discriminative dictionary. In order to learn that dictionary, we focused on three aspects: (1) We analyse distribution of the training set and try to find the statistical curve that (2) We introduce a piecewise function with parameters derived from the curve above (3) The representation space of the dictionary is transformed in each iteration with the transformation: the more informative data that contribute most to the dictionary X  X  rep-resentation ability and the less informative ones which make a small contribution. We stretch the representation space that contains the more informative data and shrink the remaining space. The concrete solving process is shown in Section 4.2. Existing methods for person re-id mainly focus on two aspects: appearance modeling and distance learning. Recently, sparse representation based classification [24] (SRC) has been successfully applied to person re-identification. Dictionary learning has been shown to provide promising results in face recognition and object classication. features. In supervised methods, training samples with the identity labels. Many re-id model use global color and texture histograms [25, 8, 5]. Several approaches focused on finding a descriptor that was robust to background and view point variation. Li and Wang [14] learned a mixture of cross view transforms and projected features into dif-ferent locally-aligned common feature spaces. Bazzani et al. Li et al. [15] suggested a deep learning network that reduced the impact of multi-view variations, so when new cameras were added into the system, a laborious annotation was required. Distance learning-based person Re-ID focuses on the optimal similarity measure in pairs of per-son images. Li et al. [16] proposed to learn a decision function jointly distance metric and a locally adaptive thresholding rule for matching. Zheng et al. [29] suggested the Probabilistic Relative Distance Comparision(PRDC) was a novel way to maximize the probability of a pair of correctly matched images with a smaller distance than that of an incorrectly matched pair. Learning decision tree ensembles and salient regions [27, 28], have also been explored. However, none of the aforementioned approaches avoided treating the features indiscriminately and did not assume the existence of universally distinctive and reliable features. Instead, distance learning methods were based on the subtraction of misaligned feature vectors, which caused information loss and errors. that represent different people and the dictionary learning method is vital to sparse cod-ing. Dictionary learned from the training sample achieved impressive results in several classification and recognition problems[19, 18, 13]. Zhang and Li extended K-SVD al-gorithm[11] by learning an over-complete dictionary from a training dataset of nature image patches. Liu et al. [17] proposed semi-supervised coupled dictionary learning to bridge the human appearance variations across cameras, and also introduced a new ap-proach to address the person re-identification problem in cameras with non-overlapping fields of view [13]. However, the above DL methods changed the constrains to get the dictionary and treated all the features in the dictionary as identical.
 Dictionary Learning Model (DDLM) in this paper. Inspired by the statistical results of training data, we introduce piecewise function to change the dictionarys information space in training process. Dictionary with strong presentation is learned from DDLM. Our experiments in bench-mark databases show that DDLM achieves better perfor-mance than existing dictionary learning methods. The SRC method models the sparse coding as sparsity constrained regression problem. The test sample is expressed by an overcomplete dictionary. Dictionary learning try to D should be able to accurately represent the person by X , subject to A  X  DX . D i is the sub-dictionary, X i is the coding coefficients of A i over D , and there is A i  X  DX i = D 1 X 1 i + D 2 X 2 i + ... + D n X n i ,i = 1 , 2 ,...,n .
 constraints in the training process led to dictionaries with different discriminative power. One of the minimization problems researchers often use to formulate the dictionary learning process is: will be got by solving: In this section, we introduce the overall framework of our model, then present our ap-proach to learn a discriminative dictionary and the classification scheme for re-id. To improve the classification performance, we learned a discriminative dictionary. Dictio-nary learning in our method can be divided into two sub-problems: updating X with D fixed; updating D with X fixed. Our DL algorithm is summarized in Algorithm 1, and the symbol  X  in the algorithm represents a constant, which is the convergence condition for the iteration.
 ages from the gallery and probe set (Fig.3(a)). During the training process, the first step was initialization D and X . We randomly initialized all atoms of each D i as vectors, and then initialized coding coefficients X as zero in our model. Lastly, we changed D i and X to get the optimal value by using optimization methods in each iteration. In the testing phase, we encode the feature of a given probe image by the dictionary, and then use both the reconstruction error and coding coefficient for image classification. There are two modalities for performance evaluation: the multi-versus-single (MvsS) modality and the multi-versus-multi (MvsM) modality (Fig.3(g)). 4.1 Optimization Of Coefficients In our model, we change the representation of different characteristics in the dictionary of space to increase the represent ability of the dictionary. The statistical curve of the training data fit into the chi-square curve, piecewise function for dictionary space trans-formation. When updating the coefficients X i , D is fixed and all X j , i 6 = j , are fixed . Thus Eq.(1) can be reduced to: that the input signal A i can be well represented by dictionary D , so its value is small. || A i  X  D i X i it is expected that the images can be well represented by the images belong the same class, which implies that there are some significant coefficients in X i small. different classes. For A i , X j tion function of different intervals was different, so the mapping was a piecewise func-tion. The statistical curve of the training set agree with the three-degree-of-freedom chi-square distribution. The conversion interval is a confidence interval of 80% confi-dence.
 of the piecewise function that includes three parts: f 1 , f 2 , and f 3 . Poly-line p 1 passes through the origin of coordinates and is symmetrical to the coordinate origin, while p 2 does not pass through the coordinate origin. Mapping intervals are [ min,a ) , [ a,b ) , [ b,max ] , and the breakpoints of piecewise function are ( a,c ) , ( b,d ) : convex optimization techniques. In our model, we use the algorithm in (Kim et al., 2007). 4.2 Optimization Of Dictionary The second important optimization problem of dictionary learning(DL) is updating D with the coefficient X fixed. We update D class by class and when updating D i , all D j , j 6 = i , are fixed. Eq.(1) is reduced to as follow: concrete calculation and deduction and Eq.(7) is be reduced to as follow: , abbreviated to Y 1 , Y 2 and Y 3 , respectively, are fixed. In our model, each metaface d l (l=1,2,...,p) is required to be a unit column vector, i.e. d l T d l = 1 . The shorthand for Eq.(8) is as follow: Langrage multiplier, it is equivalent as follow: where 4.3 The Classification Strategy approaches [24, 26, 20] for classification do not take reconstruction error and coding coefficient into account. In our model, the different is dictionary learning combine the reconstruction error and coefficient sparsity.
 compute the reconstruction error , then the reconstruction error associated with each class is computed for classification.
 where  X  is a constant. Serial number of the class which the testing sample A belongs to is the index of D i and X i that minimize || A  X  D i  X  X i || 2 . This section evaluates our approach on three public available datasets, i.e. CAVIAR4REID , ETHZ , and i-LIDS . We compared DDLM with several state-of-the-art person re-identification methods, and reported the quantitative results in standard Cumulated Matching Char-acteristics (CMC) curves. 5.1 Experimental Setup There were tree modalities for person re-identification: single-shot versus single-shot (SvsS), that there was only one image for each person in both the probe and gallery set; multiple-shot versus single-shot (MvsS), that there were a group of images in the gallery set but a single image in probe set; and multiple-shot versus multiple-shot (MvsM), which was when both the gallery and probe set contained multiple images for each person. In our model, images were linearly expressed by the dictionary, so dictionary learning required more than one image of each person in the gallery set. Considering that, the modality of SvsS was unfit for our method, so we only used MvsS and MvsM in our experiments.
 and represented as a vector with the dimensions 3  X  30  X  75 = 6750 . We randomly chose N images from individuals as the training sets (the total number of images in a training set was N  X  number of individuals), and the remaining images were for the testing set. There were seven parameters in DDLM including  X  1 ,  X  2 , a , b , c , d , and maximum number of iterations I . We set the regularization parameters  X  1 =  X  2 = 1 . For the convenience of expression, we set r=(MAX-MIN), then set a=0.4*r, b=0.6*r ,c=0.2*r, d=0.8*r in CAVIAR4REID , where MAX and MIN is the max value and min value in the dictionary. We set a=0.38*r, b=0.62*r ,c=0.2*r, d=0.8*r in iLIDS . We set a=0.35*r, b=0.7*r ,c=0.25*r, d=0.85*r in ETHZ . Our results showed that most of the DL function value J and the objective function value converged when the number of abtained and different curve led to different parameters for transformation, as shown in Table 2. We repeated all of the experiments 10 times, and with each repetition, the labeled training data was randomly chosen. Finally, we compared the average results to state-of-the-art methods. 5.2 Datasets CAVIAR4REID is made by processing 26 sequences captured from two cameras in a shopping center for person tracking and detection evaluations. There are 72 unique in-dividuals in total, which contains people meeting with others, window shopping, exist-ing shops, entering and walking along. The main complexity of the dataset arises from the very severe resolution and lighting changes between the two camera views. image sequences of 300 different pedestrians that from two non-overlapping camera views. Images in i-LIDS dataset with significant occlusions, viewpoint and illumination variations.
 image sequences captured from a moving camera in a busy street scene. The images are extracted from the ground truth location of people in the video with original resolution. It contains three sub-datasets ETHZ1 , ETHZ2 and ETHZ3 contains 83 people (4,875 images), 35 people (1,936 images), and 28 people(1,762 images), respectively. 5.3 Comparison with the state-of-the-art We compared our method with 15 approaches including HPE[2], AHPE [3],PLS [21], SDALF [5], CPS[4], NSC[7], RWSC[30], MRCG [1], EIML [9], RPLM [10] and RSR [7] .
 approaches on CAVIAR4REID dataset, including AHPE, SDALF, CPS, NSC, RWSC .
 In Fig.5, we reported the CMC curves of DDLM and the state-of-the-art for MvsM on CAVIAR4REID . From this figure we seen that we slightly outperform other approaches, while we significantly outperform competing methods by nearly 17% for MvsM (N = 3) and by 4% for MvsM (N = 5). For MvsS , only RWSC made experiments in CAVIAR4REID , our method achieved 73.5% (N=3) and 80.1%(N=5) at rank-1. We compared our results with WSC in Fig.4 and Fig.5.
 methods. HPE, AHPE, SDALF, CPS, MRCG, SCR, RWSC for MvsM (N = 2) modal-ities and SDALF, RWSC for MvsS (N = 2) modalities. We improved on the state-of-the-art at rank-1 by nearly 5% for MvsM and by 4% for MvsS, the CMC curves are reported in Fig.6. As can be seen, our method achieved 85.8% (MvsM) and achieved 83% (MvsS) at rank-1.
 with nine state-of-the-art methods. The performances at rank-1 on ETHZ are summa-rized in Table 1. Our method outperformed other methods on ETHZ1. DDLM reached to a high recognition rate, and it was comparative with RWSC.
 In this paper, we proposed a discriminative dictionary learning model for person re-identication. We conducted probability statistics of training set to divide the data into two categories, which led to the different contribution to the representation ability. A piecewise function is introduced to transform the representation space of dictionary in training process. With the dictionary transformation, the learned dictionary enhanced the more informative space whereas downgraded the less one. Thus the discrimination of dictionay was increased. Experimental results on three public datasets demonstrate the effectiveness of our model for person re-identication problem.

