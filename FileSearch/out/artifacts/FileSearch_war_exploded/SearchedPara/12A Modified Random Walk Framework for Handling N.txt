 YU-CHIH CHEN, YU-SHI LIN, YU-CHUN SHEN, and SHOU-DE LIN , National Taiwan The goal of a recommendation system is to provide a (usually ranked) list of items that has a good chance of being accepted by the user. The more the users believe the items are relevant to their interests, the better their perception of the recommendation system will be. Such systems have been widely applied in different domains, such as music, books and movies. Even a search engine can be regarded as a recommendation system for documents.

A recommendation system must consider the following elements. (1) Users: U ={ u 1  X  u m } . (2) Items: I ={ i 1  X  i n } . (3) Ratings: R ={ r 11  X  r ij } , where r ij is the rating of user u for item j. Thus, R is an
The goal of a recommendation system is twofold. (1) Predict ratings. Given a data pair comprised of a user i and an item j ,andsome (2) Predict rankings. Sort items based on the inferred preference of the user.
Most recommendation systems are based on the concept of similarity. They exploit the similarity between users, the similarity between items, or the similarity between an item and a user.

Content-based recommendation systems try to analyze the characteristics of users and items to determine their relevance or similarity, and then recommend highly relevant items to the users. For example, knowing a user X  X  preferred movie genre, a content-based recommendation system can recommend another movie of the same genre. The main problem with this type of recommendation system is that it is not always easy to infer the user X  X  preference. Also, understanding the content of a movie is by no means a trivial task for machines.

Another popular approach is collaborative filtering (CF) [Resnick et al. 1994] [Sarwar et al. 2001] which exploits the idea that similar users will give similar items similar ratings. The assumption allows CF methods to obtain the ratings between all items and users given only a subset of them. CF methods have following potential drawbacks. (1) Cold start. The prediction becomes unreliable for users with few rated items. (2) It is not clear how extra relational information or knowledge can be incorporated (3) In a sparse dataset, users with disjoint sets of ratings are not correlated. For
Other than CF-based methods, researchers have proposed using graph-based recom-mendations which transform ratings data into graphs. The graphical model considers the long-distance relationships between users and items. In practice, users not linked by common items directly, such as user1 and user2 in the previous example, can now be connected indirectly through another user on the graph. Another advantage of graph-based methods is that they naturally facilitate the usage of additional relationship information among users and items (e.g., the social relationship between users, or the same-authorship relation between items).

Among graph-based recommendation algorithms, random walk (RW) [Fouss 2007] is probably the most appealing and the most widely used. The algorithm simulates the user X  X  random selection from some source nodes to other nodes. The rationale is that if an item node can be reached easily from a user node, then it is more likely to be relevant to the user. The graphs are usually bipartite, containing user nodes and item nodes. The probability of moving from a user node to an item node (or vice versa) is proportional to the rating of the item given by the user.

The main drawback of traditional RW-based approaches is that they cannot deal with negative ratings. Commonly used datasets, like Netflix and MovieLens, contain both positive and negative opinions (usually using rating scales range from 1 to 5 where 1 stands for  X  X islike X ). Generally, a negative rating indicates that the user is not impressed by an item. For recommendation systems, negative opinions are just as important as positive ones. Recommending something that users hate could dam-age the reputation of the system more than recommending something they may not like. Technically, negative ratings create another problem as traditional RW-based ap-proaches require positive weights (or transition probabilities) on the graph to guarantee convergence to the stationary probabilities.

A popular strategy for dealing with negative impressions involves shifting the rating from negative to positive (e.g., from [  X  2 ,  X  1 , 0 , 1 , 2] to [1,2,3,4,5]), but it can cause other problems such as limiting the propagation of negative information. For example, in Figure 1, u 1 is similar to u 2 because they like the same items, and u 1 is also somewhat similartou 3 because they dislike the same items. Now, item i 5 is disliked by u 2 ,but item i 6 is liked by u 3 . Intuitively, i 6 should be a better candidate for recommendation to u 1 than i 5 , which is disliked by a user similar to u 1 . However, running a random walk algorithm on a weight-shifted graph (see the left part of Figure 1) shows that the upper part of the graph attracts most of the flow, which results in an unwanted higher stationary probability for i 5 than i 6 . This is a serious problem because the system gives a higher preference rating to an item ( i 5 )that u 1 dislikes.
 We attempt to solve the given problem in this article. Our contribution is twofold. First, we propose a modified random-walk method that can handle both positive and negative opinions. In our model, each node can store two types of values, one for positive information and another for negative information. During the random walk process, a node will propagate the same type of information to its neighbors if there is a positive weight between them, and the opposite information if there is a negative weight. We also provide a propagation mechanism to implement the process efficiently with a mathematical proof of its convergence.

Here we would like to emphasize that the main contribution for this article is to advance the state of the art in RW-based method, rather than designing a RW-based model to compete with other recommendation models such as the Matrix-Factorization (MF) based models or KNN-based models. In the recent years, thanks to several worldwide competitions such as NetFlix Prize and KDD Cup 2011, researchers have realized that the best strategy for recommendation requires a blending of diverse types of models [Toscher and Jahrer 2009; Chen et al. 2011; McKenzie et al. 2011]. The models that have been shown useful includes MF-based models [Koren et al. 2009]. Probabilistic latent semantic analysis models [Hofmann 2004], KNN-based models [Piotte and Chabbert 2009], supervised models, models using features created by Restricted Boltzmann Machines (RBM) [Ackley et al. 1985], and random-walk-based models [McKenzie et al. 2011]. The advance of these models will eventually have an impact on the overall quality of recommendation results. Such  X  X nsemble recommen-dation X  idea changes the mindset of researchers in this area since different kinds of recommendation systems are not being viewed as  X  X ompetitors X  rather as  X  X ollabora-tors. X  The RW-based models are therefore useful due to the diversity they bring in to blend with other recommendation models, since their underlying mechanism is very different from that of the MF-based methods, RBM-based method, or even PLSA-based methods. Therefore, we believe our model, which significantly advances the state of the art in random-walk-based method, can be very useful for blending-based recom-mendation system. To verify such claim, we did additional experiments in section 5 to show that our model plays a critical role in the ensemble of different kinds of models.
Second, we believe that showing explanations of the system X  X  ranking decisions im-proves users X  acceptance of recommendations. Research in psychology suggests that people usually have difficulty accepting recommendations without knowing the rea-soning behind the selections [Haynes 2001]. Therefore we propose a mechanism that automatically generates explanations for recommendations made by our RW-based system by identifying the dominant paths or subgraphs of information flow.
The remainder of this article is organized as follows. Section 2 contains a review of related works. We present our modified random walk approach in Section 3, and describe our explanation framework in Section 4. We report the results of experiments in Section 5, and summarize our conclusions in Section 6. First, we define some notations used throughout this section. We denote a set of users as U ,asetofitemsas I, and the extra knowledge related to the items as K ,with | U |= m , | I |= n , | K |= o . The rating given by a user u to an item i is denoted by r ui . Some works [Cheng et al. 2007; Zhang 2010] exploit extra knowledge such as the relatedness of item i to a knowledge item k is c ik , 1 if they are related and 0 otherwise.
 the vectors comprised of user u X  X  ratings for all items and ratings of all users for item i , respectively. In same way, c i  X  and c  X  k represent, the relations of all knowledge to an item i and the relations of all items to knowledge k , respectively. I u is the set of items rated by user u ,and U i is the set of users who rated item i. Similarly, K i is the set of all knowledge related to item i ,and I k is the set of all items related to knowledge k . The concept of random walk bases on the PageRank [Brin and Page 1998] algorithm. The PageRank model computes the scores for web pages by simulating a user X  X  surfing behavior. Similarly, random walk simulates the behavior of moving from a node to its neighbors on a graph by taking random steps. If a node X can be reached easily by a given source node Y ,then X is deemed to be relevant to Y . As will be discussed in details later, several recommendation systems based on random walk have become popular in recent years [Craswell and Szummer 2007; Fouss 2007; Gori and Pucci 2007; Yildirim and Krishnamoorthy 2008; Liu and Yang 2009; Clements et al. 2009]. 2.2.1. Random Walk on a Bipartite Graph with Rating Relations. Figure 2(a) shows a graph constructed based on the ratings that users give to items. G ={ V , E } V ={ V user , V item } E ={ e assigns either 1 or 0 as the weight of each link. Despite this, in practice, the weights are usually assigned as integers or real values that better describe the ratings.
Like the PageRank algorithm, prior to processing, the random-walk algorithm with a certain starting point requires the weights, the transition probability between nodes, to be updated. The transition probability between node pairs is derived as follows:
It has been shown that with nonnegative weights, the algorithm is guaranteed to converge [Athreya et al. 1996]. 2.2.2. Random Walk with Extra Information. Cheng et al. [2007] posited that extra informa-tion about items could be exploited to improve the recommendation performance. The relationships can be seamlessly incorporated into graphical models by adding edges to the graph. Figure 2(b) shows an example of a tripartite graph: G ={ V , E } , V ={ V user , V
Let P ( x ) be the probability of staying at node x , then the initial probability distribu-tion is P 0 (source user) = 1, P 0 (others) = 0. The transition probability then becomes: Then, the update of the probability distribution will be: Let  X  M be the transition matrix corresponding to the transition probability
To give a penalty for longer path from the source and to let the process cope with personalized preferences, the parameter  X  is introduced.

The value of  X  ranges from 0.15 to 0.2 will work for most cases [Craswell and Szummer 2007; Yildirim and Krishnamoorthy 2008; Liu and Yang 2009; Clements et al. 2009].
Cheng et al. demonstrated that the accuracy of recommendations improves with extra information. Several extensions of the traditional random walk approach have been proposed, such as Itemrank [Gori and Pucci 2007], similarity random walk [Yildirim and Krishnamoorthy 2008], Eigenrank [Liu and Yang 2009], and positive/negative rele-vance random walk [Clements et al. 2009]. We will describe them one by one in this section and compare them with our approach in Section 5. 2.3.1. Itemrank. Gori and Pucci [2007] propose this model to improve the efficiency when there are many more users than items. The graph is projected from the { user -item } space to { item-item } space. The weights of the edges between the items are proportional to the correlations of the items, while the correlation is modeled as the number of common users that have rated the items. If an item is highly correlated to the items that received high ratings from a user, then the item is a good candidate for recommendation. Given a correlation graph, it is possible to use random walk to identify items for recommendation. Mathematically, item correlations are decided by the set of common users of the items.
 The initial probability distribution for a specific user u is defined as and the probability update rule is defined as
The major concern with Itemrank is that information can be lost when summarizing a bipartite graph into a unipartite graph. Furthermore, the user X  X  rating information is not exploited, as only the binary information about whether the user rated the item is used; therefore, Itemrank does not provide a good solution to negative feedbacks since the ratings will be treated equally as the positive ones. Moreover, the item-item correlation network is a nearly fully connected graph, which affects the algorithm X  X  efficiency. 2.3.2. Similarity Random Walk. Yildirim and Krishnamoorthy [2008] propose a model similar to Itemrank which constructs a graph based on the similarity of items. If an item is similar to those rated highly by a specific user, it is considered suitable for recommendation . The model exploits the random walk method to capture transitive associations.

Given an adjusted cosine similarity S ij = u the transition probability becomes P ( i j | i k ) = ( 1  X   X  ) S jk The initial probability distribution for a specific user u is The updated rule for the probability is P t + 1 ( i k ) = ( 1  X   X  )
Similar to Itemrank, reducing a bipartite graph to a unipartite graph can cause in-formation loss. Furthermore, the meaning of negative ratings cannot be fully exploited by this framework since the same problem stated in Figure 1 can still occur. 2.3.3. Eigenrank. Liu and Yang [2009] propose the Eigenrank model to generate the rankings of all item pairs. The rankings for unknown pairs are obtained from similar users. If an unseen item is ranked as high as or even higher than those that have already been given high ratings by a user, it can be a good candidate for recommendation to that user. To achieve this, a graph of asymmetric ranking order relations is constructed, with transition probability determined by the rankings, and the random walk approach is used to aggregate partial and incomplete rankings. The simulation of random walk algorithm on this graph would favor higher ranking neighbors.
 We now list the key equations under this framework: The initial probability distribution for a specific user u is The probability update rule is
One potential issue with this model is that the rankings are only obtained from similar users. The nondirect neighbor information in the graph is not exploited. Also negative ratings are used for only similarity measures, thus similar issues introduced in Figure 1 can also happen. 2.3.4. Positive and Negative Relevance Random Walks. Clements et al. [2009] observe that the traditional random walk method cannot deal with negative relevance assessments. To handle such problem, they propose to split the original graph into two graphs, one for positive-preference information and the other for negative-preference information. If a user can reach an item in the positive graph easily, the item is deemed more relevant to the user. In contrast, if a user can reach an item in the negative graph easily, the user may not prefer it. Eventually, they combine the results of the two graphs to provide a single ranking value for recommendation.

In this model, positive and negative preference information is used separately. There-fore, nodes on the graph might not be fully connected, which would halt the information flow. For example, the connected graph shown in Figure 1 would be decomposed into disconnected components shown in Figure 4. Guha et al. [2004] propose a way to measure the propagation of trust and distrust. They observe that including negative opinions will not improve the performance unless they are being propagated through positive relations. Our model mainly emphasizes on the like/dislike information, which is different from trust/distrust, as our experiment shows that our model allows dislike information to be propagated through negative links to enhance the quality of results.

Tong et al. [2008] try to measure proximity with side information. However, their model cannot handle multiple sets of could-be-conflicting side information, which hap-pens a lot in a recommendation system.
 As will be discussed later, a subgraph is extracted as part of the explanation. Therefore we include some subgraph extraction algorithms as reference. Faloutsos et al. [2004] propose a way to quickly find a subgraph containing source vertex and target vertex with maximum flow from source to target. They later extend the algorithm to multiple sources and different logic conditions (AND, OR, SOFT-AND) [Tong and Faloutsas 2006]. In this article, we improve the random walk model in two ways. (1) As mentioned before, existing RW-based methods do not pay special attention (2) We propose a graph-based mechanism that generates explanations for the
Figure 5 shows the flowchart of our framework. The center node of the system is a modified random walk that deals with bidirectional opinions. The input is a graph constructed based on the ratings that users give to the items. Finally, we trace the information flow path to produce visualized explanations for the recommended items. Without losing of generality, we assume that the ratings are discrete values distributed over the range { X  2 , + 2 } , where + 2 means  X  X ike it very much, X  0 stands for a neutral opinion, and  X  2 represents  X  X trongly dislike. X  In the conventional random walk model, the strength of connections between users and items is proportional to the ratings, normalized to the positive side (See Figure 6(a)). However, as mentioned previously, the drawback of this model is that it tends to downplay the importance of negative ratings. Figure 6(b) shows the original graph in which both positive and negative ratings are weighted. Unfortunately, negative weights can cause convergence problem in random walk models. The transition probability P ( i / u ) = r ij / r ij will not remain bounded from [0,1] if some r ij are negative. In the worse case, r ij can be zero which results in infinite probability.

To deal with this problem, our modified RW model first assumes that each node stores two kinds of information (or probabilities). The first, denoted as P ( X + ), is the positive information and the second, denoted as P ( X  X  ), is the negative information of the node. The information from P ( X + )and P ( X  X  ) propagate in different ways. Given a positive weight, P ( X + ) will propagate to its neighbors X  P ( X + ) just like the normal RW would, while P ( X  X  ) will propagate to its neighbors X  P ( X  X  ) similar to multiplication, negative  X  positive = negative. Given a negative weight between nodes, P ( X  X  ) should be propagated to its neighbors X  P ( X + ) (i.e., negative  X  negative = positive), while P ( X + ) should be propagated to the neighbors X  P ( X  X  ). The rationale is that if two people have similar preferences for items, they like or dislike similar things, their ratings should be propagated to each other. On the other hand, if two people have very different tastes, then their ratings should also be propagated to each other, but in a negative manner.
These conditions control the sign and direction of the propagation. Thus, we can focus on the amount of information being propagated by using the absolute strength as follows:
To sum up, the model splits a node into two nodes, one containing positive informa-tion, P(X + ), and the other containing negative information, P(X  X  ) . Whether there is a link between the positive or negative node to the neighbors X  positive/negative nodes will depend on the sign of the weight:
Because we are interested in the items that a user likes, we set the initial probability that P will propagate as P(source user + ) = 1 and P(others) = 0.
 In addition, the updated probability in each iteration of RW is
In (3.3), the positive value of a node is determined by the positive values of its neighbor nodes when the weight is poistive, and the negative values of its neighbors when the weight is negative (see parts (A) and (C) in Figure 7). The negative value of a node is determined by the negative values of its positive neighbors, and the positive values of its negative neighbors.
 score to determine its ranking for recommendation. That is, an item that has more chance of being liked and less chance of being disliked by a user will be recommended.
In our modified random walk model, all values in the transition matrix are nonneg-ative; therefore, the model is guaranteed to converge. Figure 8 shows how the example in Figure 1 can be modeled under the modified random walk framework. Note that the main difference between our model and Clements et al. X  X  model is that we do not separate the positive and negative information. Figure 8 shows that the positive and negative planes of our model actually interact with each other to exchange information. One limitation of the proposed model is that the number of nodes and edges in the graph doubles, which can significantly affect the efficiency. To address this problem, we propose an equivalent model that has the same complexity as the original RW model. In fact, for recommendation systems, eventually we only need to derive the R ( X ) = P ( X + )  X  P ( X  X  ) values of the nodes. That is, the individual values of P(X + ) and P(X  X  ) are not important as long as we know the difference between them. As result, we find that, for each node, we only need to store its R values and propagate it based on a certain strategy. Thus, it is possible to apply the RW model to the original graph without replicating the nodes and edges. The updated rule for R(X) is formulated in Equation (3.4), where sign(W ik ) denotes the sign of the given weight.
 P ROOF . R ( X k ) = P ( X + k )  X  P ( X  X  k ) = R ( X k ) = = = =
This proof shows that, instead of running RW on a larger graph G(2n,2e) ,our equalivent model implemented on R X  can be executed on the original graph G(n,e) without incurring any additional computational burden. We believe that providing the reasons behind recommendations will improve the prob-ability of users accepting the recommended items. In this section, we describe our explanation mechanism on a graph-based RW model. The explanation for RW-based recommendations can be obtained by tracing the infor-mation flow of the graph. Based on this idea, we try to identify the paths that have the most influential flows (or the highest probability of being selected) from the source (the user) to the target (the recommended item) during the random walk process. In our model, the influence of a node B on its neighbor A can be defined as
Starting from the item being recommended, it is possible to apply a greedy method to trace back and find the neighbor nodes X that contributed the most to the final score. Then, from X , we can keep tracing to another node Y with the most influence on X in a greedy manner. The process continues until the original user node is reached. Figure 10 shows an example of such a path, which can be described as: An item, B, is recommended to the user who likes item A because another person, who also likes item A, likes B .
 Generally, it is possible to search the top-k influencial paths using the greedy method. Eventually, we can obtain a set of paths that describe the dominant routes for passing the information from the source user to the recommended item. The paths can some-times be merged. For example, Figure 11 shows three dominant paths from the user to the item. Based on his information, we can assume that because other users who like movie A also like movie B , the system will recommend movie B .

We also found that with additional knowledge in the network, it is possible to create more reasonable and inetresting explanations. The dominant paths in Figure 12 reveal that movie B is recommended to the user because it has similar actors and writers, and it is of the same genre as movie A, which is one of the user X  X  favorite movies.
It is sometimes better to use a subgraph instead of a path or a set of paths to explain the recommendation. Figure 13 exemplifies the method we propose for this purpose. Simiarily, we first generate the influence scores of each node on its neighbors as Influence B  X  A = P ( A | B ) P ( B ). Again, a greedy method is used for backtracing until the starting user node is found. However, this time the greedy method keeps several of the top nodes that, as a whole, account for more than k% of the influence score on the node. For example, in Figure 13(c), assuming k = 51%, nodes E and F are kept in the subgraph because they sum up to more than 51% of the contribution to node B .In the end, given k, it is possible to obtain a subgraph that contributes most significantly to the recommendation of an item. We use two popular datasets, the MovieLens and the Netflix Prize datasets, for evaluation. The MovieLens dataset consists of 943 users and 1682 movies, with a total of 100,000 ratings. We randomly sample data for five-fold cross validation and repeat the process three times. The reported results are the average of the outcomes of three trials. Two similar experiments were performed on the sized-down Netflix prize dataset. We selected the 2,000 DVDs rated by most users and randomly selected 1,000 users who rated those DVDs at least 40 times.

We also tested on a more sparse dataset where we select the same DVDs but a different set of 1,000 users who rate those DVDs only 20 to 100 times. We did not make it even sparser because by doing so the graph will not be connected (there will be several small islands).
 Following other random-walk recommendation methods, we use NDCG (Normalized Discounted Cumulative Gain) to measure the performance since RW-based systems produce a rank for each item. The NDCG is used because, comparing with other mea-surements such as RMSE, it is more suitable for ranking-based alrogithm such as RW. This is also a very common measure that has been widely used by other models such as CF-based and classifiction-based ones [Abbassi el al. 2009, Parra and Brusilovsky 2009, Zheng et al. 2010, Chapelle and Keerthi 2009].
 NDCG measures how close the ranked results are to a perfect ranking.
 i is the ranking order, rate i is the corresponding rate of the item ranked at i position, p stands for the top p ranking items, and IDCG p is the discounted cumulative gain with a perfectly ranked list.
The closer the NDCG is to 1, the closer the ranking is to the gold standard. We compare our models mainly with other state-of-the-art RW-based models, and we also include the CF-based model and the supervised model as reference. Note that the parameters for the competitive models are chosen according to the suggestions in the corresponding papers. (1) Collaborative filtering (CF(user), CF(item)). This method predicts ratings based on (2) Original Random walk method (RW). We compare our approach with the original (3) Positive and negative relevance random walks [Clements et al. 2009]. We also com-(4) ItemRank (IR) [Gori and Pucci 2007]. Use random walk model to capture the item (5) Similarity Random Walk (SR) [Yildirim and Krishnamoorthy 2008]. Use random (6) EigenRank(ER) [Liu and Yang 2007]. Use random walk to aggregate the ranking (7) Supervised classifier. Using the ratings of the targets as labels, and the ratings (8) Modified Random Walk (MW). For our methods, we also set the transition penalty Table I shows the NDCG results of the given algorithms. We show CF-based methods first, and then supervised methods. The rest are all RW-based methods. The results reveal the following interesting phenomena.
 Being able to handle negative information does improve the results significantly (see RW vs. MW, we obtain &gt;10% improvement in NDCG for Netflix dataset). It basically confirms several things. First, treating negative ratings as truly negative (rather than less-positive) is critical. Second, our hypotheses to treat people who dislike similar movies as similar, and to use negative opinions of dissimilar persons as positive rein-forcement are proper. Eventually it confirms that our overall model to handle negative examples is effective.

Our model also outperforms the state-of-the-art RW-based models by a significant margin, which confirms our advance of the RW-based methods in recommendation.
We also compare the best RW-model to the other types of methods. The results show that our model obtains similar quality of results comparing to CF-based method and supervised based method.

However, we would like to point out that the comparison among different types of models is only for reference, and we do not regard outperforming different types of algorithms as a research goal in this article. As it has been shown that in order to build a high-quality recommendation system, a blending method that combines different types of models is required. Therefore, we believe the goal for designing a recommendation system has to evolve from  X  X utperforming other types of models X  to  X  X dvancing state of the art in one type of model, X  as an inferior model with diversity might be even more helpful than a superior model with less diversity in improving the final outcome of blending [Toscher and Jahrer 2009; Chen P.-L. et al. 2011; McKenzie et al. 2011].
To verify such claim, we did a simple ensemble experiment to combine three diverse models (CF, SVM, and our MR model) to show the effectiveness of our model. We chose the MovieLens dataset. in which our model ranks 2 nd in performance, better than CF but worse than the SVM model. Table II shows the results. First, we simply combine the predictions from the two better models (SVM and MR), and realize that even with equal weight, we can achieve 0.44% inprovement on performance. With slightly higher weight for SVM, the improvement can reach 0.82%. After adding the worse model (CF), the performance can further improve 0.23% to reach 1.05% total. Note that 1% difference is considered significant as the top teams in Netflix or KDD Cup 2011 are only seperated by one tenth of such scale. This experiment shows that even a relatively small portion of our model can contribute significantly to the overall results. Even better results can be expected with more sophisticated ensemble methods. To provide more readable explanations and to demonstrate that our recommendation framework can easily incorporate external information or knowledge, we provide an explanation on a heterogeneous graph whose relational schema is shown in Figure 14.
We collect extra information about movies from IMDB, including the directors, writ-ers, genres, plots and the actors of each movie. Our model treats all of these relations as positive relations.

An online demomonstration system is available. 1 Given the user X  X  id, the system will display a list of recommended movies to the user. Users then can check the explanations and visualization graph by clicking on the names of the movies.

Figures 15 to 17 are snapshots of the system. They are generated using the  X  X ubgraph-based X  explanation technique discussed at the end of Section 4.1. The dif-ferent colored edges and nodes represent different relations and node types. The two nodes with red outline and text color are the source user and the item to be recom-mended. Figure 14 displays the meanings of each kind of relation (in different colors). Figure 15 captures the major information flow from user 1 to the movie Star Wars: VI . Focsuing on the high-degree nodes and their neighbors, we can see that the node with the highest degree is Star Wars: V (isolated in Figure 16). Thus, the user can conclude that  X  X he system believes that Star Wars: Episode V is worth recommending because one of the user X  X  favorite movies, Start Wars VI , is highly correlated with Star Wars: Episode V (i.e., they have the same director, producer and actor) X . Figure 17 illustrates another example where Apollo 13 is recommended to user 505. The graph shows that the system recommends this movie for three reasons. 1) People who like the movies that are rated favorably by the user also like Apollo 13 (note that CF can also capture this); 2) Apollo 13  X  X  director, Ron Howard, also directed the movie Ransom ,whichis liked by the user; and 3) Several actors in Apollo 13, such as Tom Hanks, Bill Paxton, and Gray Sinise, also performed in some of the user X  X  other favorite movies. We conducted a human study to evaluate the effectiveness of our explanation system. We first identify 100 popular movies (top 50 movies in moviemeter and top 50 movies in US box office) each year from 2005 to 2009 and 10 subjects. Out of these 500 movies, for each subject, we randomly select 50 movies and ask them to rate (the label  X  X nseen X  shall be given for unseen movies). We then construct a graph of all movies from 2005 to 2009. Then for each subjec t, we connect him/her to the rated movies to perform our RW model. For evaluation, we first display the top 10 recommended movies by the system to the subjects and ask them to check whether they want to watch those movies. The results show an average of 5.7, which means 57% of the recommended movies are accepted by the subjects. Then we show again the same movies recommended by our system with explanations to the same set of users, and ask them to mark again whether they want to watch the movies after viewing the explanations. The accepted rate then raised to 66%, which means the user changed their mind for one out of the four recommendations that were not accepted in the first place. In this article, we have proposed a modified random walk model that allows the propagation of both positive and negative information simultaneously. We show that our model is guaranteed to converge, and there is no additional computation overhead. Furthermore, we demonstrate the advantages of the RW-based model by presenting a simple, efficient, yet intuitive explanation framework. We believe the major contribu-tion of this article does not necessarily lie in the improvement of the recommendation results; rather, it highlights two issues that have not received much attention thus far: handling bidirectional opinions and providing explanations for the ranking of recommendations. Furthermore, we have demonstrated that by combining our system with other recommendation engines, it is possible to achieve even better performance.
Future work will include the investigation of how to deal with cold start and sparse data issues, as well as how explanations for other types of recommendation systems (such as CF and MF) can be produced.

