 A recommender system has to collect users X  preference data. To collect such data, rating or scoring methods that use rating scales, such as good-fair-poor or a fi ve-point-scale, have been employed. We replaced such collection methods with a ranking method, in which objects are sorted according to the degree of a user X  X  prefer-ence. We developed a technique to convert the rankings to scores based on order statistics theory. This technique successfully im-proved the accuracy of ranking recommended items. However, we targeted only memory-based recommendation algorithms. To test whether or not the use of ranking methods and our conversion tech-nique are effective for wide variety of recommenders, we apply our conversion technique to model-based algorithms.
 H.3.3 [ Information Search and Retrieval ]: Information fi ltering Measurement Recommender System, Ranking Method, Order Statistics, Sensory Test A recommender system suggests items that a user would prefer. Collaborative fi ltering (CF) is an algorithm that implements this recommender system by automating the word-of-mouth paradigm. CF requires data that represent the degrees of a user X  X  preferences in items, and a scoring or a rating method is widely used for collecting such data. In both methods, the system shows an item to a user and records the degree of the user X  X  preference to the item on a scale. While a scoring method uses a numerical scale, e.g., a scale of 1 to 5, a rating method adopts ratings with ordered labels, e.g., { good , fair , poor }. The use of these measurement methods has been successful in performing CF. However, these methods have a few properties that are inappropriate when measuring a user X  X  preferences, as we point out in the next section.

We have therefore advocated a framework called Nantonac Col-laborative Filtering 1 [8, 9], which is a CF framework that adopts a ranking method to capture users X  preference patterns. In a ranking method, a set of items is shown to a user, who ranks these items according to the degree of his/her preference.

In our previous work, we advocated a technique to convert rank-ing data to preference scores. Further, our experimental results showed that the relative degree of preference could be more ac-curately predicted from the converted scores. However, because we adopted only memory-based algorithms for recommendation, it was not clear whether the use of a ranking method and our con-version technique were useful for the other types of recommenda-tion algorithms, namely model-based methods. Both memory-and model-based methods have their own pros and cons, and sophisti-cated model-based methods were developed and used in commer-cial systems [3]. We therefore tested whether or not the use of a ranking method is also bene fi cial to two model-based methods: pLSA [6] and matrix decomposition [12].

Our motivation in employing a ranking method is discussed in section 2. In sections 3 and 4, we present our model-based nan-tonac CF methods and experimental results, respectively. Section 5 summarizes our conclusions.
To accurately predict items that a user prefers, the precise mea-surement of a user X  X  preference patterns is very important. For this measurement, a scoring or rating method has been adopted in al-most all CF systems. To our knowledge, no other measurement methods, such as pairwise comparison, choice, or ranking meth-ods, have been tested in CF.

We here show a weak point of a scoring method. In Figure 1(a), we intuitively show how scores are captured by a scoring method. The unobserved true preferences and observed scores are shown in the upper and lower panels of the fi gure, respectively. In the fi gure, because the true preference of item X is in user A X  X  interval 2, user A will respond with a score of 2. If we are measuring a physical quantity, such as length or weight, the mapping from quantities to observed values can be de fi ned based on an objective and invari-ant criterion, such as the speed of light or the kilogram prototype. However, when we measure a preference, it is dif fi cult to share such an invariant and objective mapping between true preference and ob-served score, because each user uses his/her own mapping based on
The word  X  X antonac X  originates from a Japanese word,  X  X anton-aku, X  which means  X  X ust somehow. X  For example, in Japanese, if I say  X  X  nantonaku understand something, X  I am saying that I cannot speci fi cally explain why I understand it, but that I somehow do. X YZ a subjective and variable criterion in his/her own mind. The map-pings therefore tend to be inconsistent between users A and B. Fur-ther, when mapping back from the observed scores to the induced preference as in Figure 1(b), the system uses a common scale, and thus the induced degrees of preference might shift from the orig-inal. For example, item X lies in interval 3 of user B X  X  mapping scale as in Figure 1(a). However, in Figure 1(b), B X  X  true prefer-ence lies in interval 4 of the common mapping, while the induced preference (depicted by X X  in the fi gure) deviates from the origi-nal degree. To avoid these defects, we advocated nantonac CF [8], in which a user X  X  preference is measured by a ranking method. In this ranking method, a user responds by ordering objects according to his/her preference (Figure 1(c)). Mapping from true preference to observed order is simple: the more preferred items are ranked higher, and these mappings are common for all users.

One might think that these shifts in scores can be canceled by using calibration techniques. In [4], instead of the Pearson corre-lation, rank correlation is used to evaluate the similarity between two users. Further, rating scores are normalized by subtracting the mean of scores. According to our previous work [9], the adop-tion of a ranking method is advantageous even if these techniques are employed. This can be explained as follows. As pointed out in [13], only trained experts, e.g., wine tasters, can maintain a con-sistent mapping throughout a given session, and untrained users X  mappings generally change for each response. It is known that users X  responses are roughly correlated, but can drift slightly [5]. In a ranking method, this is not problematic, because only the si-multaneously evaluated items are considered.

However, this ranking method has a few limitations. It is gener-ally dif fi cult to sort so many items at the same time. This limitation can be alleviated by sorting small multiple sets of items separately as in [9]. A scheme to collect ordered pairs was proposed in [7]. Another restriction is the lack of absolute information about pref-erence. Because ranking methods merely provide a user X  X  relative preferences, the system can predict which items are more preferred than compared items, but it cannot determine whether an item is absolutely preferred among all items. Therefore, a ranking method is inappropriate for a system displaying absolute ratings, e.g., fi ve stars, but it is useful for estimating which choice is better to support users X  decision making.
Collaborative fi ltering is a task to predict the preferences of a par-ticular user (an active user) based on the preference data collected on other users (sample users). We fi rst formalize a standard CF task using preferences captured by a scoring method. x  X  X  1 ,...,n and y  X  X  1 ,...,m } denote a user and an item, respectively. s denotes the score given by a user x to an item y . The score takes one of the values on a rating scale, such as a fi ve-point scale, and represents the degree of preference. A training set consists of tu-ples, D = { ( x k ,y k ,s x k y k ) } ,k =1 ,...,N . A set of items rated by user x is denoted by Y x = { y | ( x = x, y, s )  X  X } .Giventhe set D , we want to derive a function,  X  s xy = f ( x, y ) , that predicts a preference score for any pairs of a user x and an item y . We move on to a nantonac CF incorporating a ranking method. In the case of nantonac CF, the system shows a set of items, Y ,touser x , who sorts them according to the degree of his/her preference. The sorted order is denoted by O x = y  X  X  X  y l O . The order y 1 y 2 means that  X  y 1 is preferred to y 2 . X  The j -th item, y l j , is an element of Y x .

We proposed a technique to extend CF methods that targeted scores in order to enable to deal with preference orders. In this technique, each preference order is converted into a set of scores based on the following theorem. We assume the existence of the unobserved complete preference order, O  X  , which is generated by sorting all the items { 1 ,...,m } according to the user X  X  preference. Then, a portion of the items are sampled uniformly at random from this order, and these items are sorted so as to be concordant with this complete order. This resultant order is treated as the user X  X  re-sponse order, O . We here denote the rank of an item y in an order O by r ( y, O ) , which indicates that y appears at the r ( y, O ) -th po-sition in the order O . According to [1], the conditional expectation of the rank of an item y in an order O  X  given O is Because | O  X  | is constant for any observed order O , E[ r ( y, O is proportional to r ( y, O ) / ( | O | +1) . Based on this theorem, we convert a response order, into a set of tuples, n Standard CF methods targeting scores can be applied to this con-verted set of scores. The only difference from standard scores is that items with smaller converted scores indicates a stronger prefer-ence in items, whereas a larger value implies a stronger preference on a standard score scale. This conversion technique might seem rather brute-force, but it has worked well even in tasks other than CF, such as clustering [10] or object ranking [11].

We previously applied this conversion technique to a memory-based CF method developed for Grouplens [14] and its extensions [4]. We here introduce this technique to two model-based CF meth-ods: pLSA [6] and matrix decomposition [12]. pLSA was originally proposed to derive a compact representa-tion of words and documents, but it was applied to a CF task [6] and was used in a commercial system, GoogleNews [3]. The three-way model in [6] was slightly modi fi ed so as to deal with real value scores. Formally, z is a latent discrete random variable, whose do-main is { 1 ,...,K } , and follows a categorical distribution, which is a K -way generalization of a Bernoulli distribution. Discrete ran-dom variables for a user and an item are denoted by x and y ,re-spectively. Each of them conditionally follows a categorical distri-bution given z . In addition, a real random variable for scores, s , conditionally follows a normal distribution given z . Consequently, a log-likelihood function for a training set D is
L ( D ; X ) = Parameters maximizing this function can be easily derived by using an EM algorithm. Once model parameters are learned, a preference score for an item y by a user x can be inferred by calculating a conditional expectation,  X  s xy =E[ s | x, y ]=
We further introduced a bias cancellation technique in [2], which was shown to alleviate the in fl uences of various biases in scores collected by a scoring method. First, to alleviate a global effect, we computed b , which is the mean score over all scores in each score, and we get modi fi ed scores s xy = s xy  X  b .From each modi fi ed score, the mean of all scores s of an item y , d is subtracted, and we get s xy = s xy  X  d y . We further subtract the mean score over all scores s rated by a user x , c x , and get s xy = s xy  X  c x . Scores in a training set D are replaced with these modi fi ed scores, and the above pLSA model is learned. After a modi fi ed score,  X  s xy , is estimated, the score is corrected by adding biases, i.e.,  X  s xy = X  s xy + b + c x + d y .

The second model-based method is based on matrix decomposi-tion (MD for short) in equation (4) in [12]. In this model, a prefer-ence score is predicted by where b , c x ,and d y are parameters for canceling global, per-user, and per-item biases, respectively. u y , v x ,and w y are parameters with K -dimensional vectors. A dot product of u y and v x sents the cross effect between items and users, and the term is intended to take into account the information about which items each user rates. These parameters are tuned so as to minimize the following loss function: where R is the sum of L 2 -regularization terms for all parameters except global bias, b ,and  X  is a regularization hyperparameter. The parameters are optimized so as to minimize this loss function. Once the parameters are learned, preference scores for any user and item pairs can be predicted by equation (2).
We next applied the model-based methods to our data set col-lected by using both ranking and scoring methods.
To test the effectiveness of adopting a ranking method, we ap-plied the methods in the previous section to our sushi data sets These data sets were collected by the same procedure as in [8], but the number of users was increased to 5000 .

The preference data were collected through the following pro-cedure. Before collecting the data, we surveyed menu data from 25 sushi restaurants found on the Web. For each type of sushi, we counted the number of restaurants that listed the sushi on their menu. From these counts, we derived the probability that each item would be supplied. Note that using this distribution violates the uni-form assumption of equation (1), but even in such a case, the later experimental results show the effectiveness of our score conversion technique. By eliminating unfamiliar or low-frequency items, we compiled a list of 100 items.

We generated two item sets, which were presented as Y x to each user. The type A set ( Y A ) was common for all users and composed of ten items: shrimp, sea eel, tuna, squid, sea urchin, salmon roe, egg, fatty tuna, tuna roll, and cucumber roll. This set was used for testing. The other type B sets ( Y B x ) were different for each user. Ten items were randomly sampled according to the above probability distribution of items. The orders in this item set were treated as user responses. Note that Y A and Y B x hadanoverlapof 2 . 58 items per order on average.
 We collected the responses via a commercial Web survey service. The following queries were presented for each user x : 1) We asked the user to sort items in the Y A set according to his/her preference and get a response order O A x . 2) We asked the user to rate the items in the Y B x set by a scoring method using a fi ve-point scale. The set of response scores was denoted by S B x . 3, 4) Next two questions were irrespective to preferences. These two questions lessened the in fl uence of query 2 on query 5. 5) We asked the user to sort the items in the Y B x set according to his/her preference and thus obtained a response order O B 6) The users were asked some demographic questions.

We screened users whose demographic features were rare or whose response times were either too short or too long, and the data set consequently included 5000 tuples: ( O A x ,O B x ,S B x ) . We checked the ratio of responses that contained a contradiction between S and O B x . Here, a contradiction means that, although the item y precedes y b in O B x , the score of y b in S B x is rated higher than that of y a , and vice versa. Only 31 . 7% of users rated all items without such a contradiction. This fact at least shows that different aspects of preference can be captured by ranking and scoring methods.
Two model-based methods, pLSA and MD, were applied to the above sushi data set. Response orders, O B x , of all users were merged and converted, and we obtained a data set D O . Similarly, response scores, S B x , of all users were merged, forming another data set Hyperparameters of model-based methods were tuned by minimiz-
Sushi is a Japanese food. Data sets can be obtained from the site: http://www.kamishima.net/sushi/ . Figure 2: Changes in rank correlations between true and pre-dicted orders ing the squared errors derived by fi ve-fold cross validation for each data set. We set the hyperparameters as follows: Using these hyperparameters and and entire data set, D O or the models were trained. For each user x , the scores of all items in
Y A were predicted by each of these models. By sorting these items according to this user X  X  predicted scores, we obtained a pre-dicted preference order,  X  O A x . The concordance between the true order, O A x , and the predicted order,  X  O A x , was measured by Spear-man X  X  rank correlation,  X  , a widely used metric of the concordance between two orders. Note that MAE or squared error were widely used, but such absolute evaluation metrics are meaningless for data captured by a ranking method, as described in section 2.
We changed the number of rated items per user, i.e., |Y B subsampling, and corresponding changes in Spearman X  X   X  are shown in Figure 2. MD or PLSA indicate the types of methods, and suf-fi xes O and S indicate that these results were obtained from training sets, D O and D S , respectively. If the number of items per user was three or more, adoption of a ranking method improved the accuracy of prediction. However, when |Y B x | was two, a scoring method is superior, as was also observed in our previous work [8]. In the case of a scoring method, two items are rated by using a fi ve-point scale, and thus there are 10 possible choices in total. In the case of a ranking method, one can choose which of two items is preferred. Clearly, less information is provided from users with a ranking method. However, we can conclude that adopting a rank-ing method is generally fruitful for obtaining the recommendations performed by model-based methods.
We previously developed memory-based CF methods to deal with preference orders collected by using a ranking method. Here, the same technique is embedded into two model-based methods, pLSA and MD, which were applied to our sushi data set. Experimental results showed that it was effective for adopting a ranking method for collecting preference data.

Unfortunately, compared to memory-based methods, these model-based methods were inferior. We therefore plan to improve these model-based methods for orders.
This work is supported by the grants-in-aid 14658106, 16700157, and 21500154 of the Japan society for the promotion of science. [1] B. C. Arnold, N. Balakrishnan, and H. N. Nagaraja. AFirst [2] R. M. Bell and Y. Koren. Scalable collaborative fi ltering with [3] A. Das, M. Datar, A. Garg, and S. Rajaram. Google News [4] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An [5] W. Hill, L. Stead, M. Rosenstein, and G. Furnas.
 [6] T. Hofmann and J. Puzicha. Latent class models for [7] T. Joachims. Optimizing search engines using clickthrough [8] T. Kamishima. Nantonac collaborative fi ltering: [9] T. Kamishima and S. Akaho. Nantonac collaborative fi ltering [10] T. Kamishima and S. Akaho. Ef fi cient clustering for orders. [11] T. Kamishima, H. Kazawa, and S. Akaho. A survey and [12] Y. Koren. Collaborative fi ltering with temporal dynamics. In [13] O. Luaces, G. F. Bay X n, J. R. Quevedo, J. D X ez, J. J. del Coz, [14] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and
