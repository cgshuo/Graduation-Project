 Mugizi Robert Rwebangira RWEBA @ CS . CMU . EDU Rajashekar Reddy RREDDY @ CS . CMU . EDU Learning algorithms often face a shortage of labeled train-ing data. In many situations we would like a learning algo-rithm to do well with only a few labeled training examples. Fortunately, in many cases large numbers of unlabeled ex-amples are often available. As a result, there has been a good deal of work in recent years on how unlabeled data can be usefully employed in order to produce better predic-tions.
 If one believes that  X  X imilar examples ought to have similar labels, X  then a natural approach to using unlabeled data is to combine nearest-neighbor prediction X  X redict a given test example based on its nearest labeled example X  X ith some sort of self-consistency criteria, e.g., that similar unlabeled examples should, in general, be given the same classifi-cation. The graph mincut approach of Blum and Chawla (2001) is a natural way of realizing this intuition in a trans-ductive learning algorithm. Specifically, the idea of this algorithm is to build a graph on all the data (labeled and un-labeled) with edges between examples that are sufficiently similar, and then to partition the graph into a positive set and a negative set in a way that (a) agrees with the labeled data, and (b) cuts as few edges as possible. (An edge is  X  X ut X  if its endpoints are on different sides of the partition.) Zhu et al. (2003) propose an alternative  X  X oft-partitioning X  method that assigns fractional classifications to the unla-beled data so as to minimize a quadratic cost function, and Joachims (2003) gives a method based on spectral parti-tioning, that produces an approximate minimum ratio cut in the graph.
 The graph mincut approach has a number of attractive properties. It can be found in polynomial time using net-work flow; it can be viewed as giving the most probable configuration of labels in the associated Markov Random Field (see Section 2); and, it can also be motivated from sample-complexity considerations, as we discuss further in Section 4. However, it also suffers from several draw-backs. First, from a practical perspective, a graph may have many minimum cuts and the mincut algorithm pro-duces just one, typically the  X  X eftmost X  one using standard network flow algorithms. For instance, a line of vertices between two labeled points and has cuts of size 1, and the leftmost cut will be especially unbalanced. Sec-ond, from an MRF perspective, the mincut approach pro-duces the most probable joint labeling (the MAP hypothe-sis), but we really would rather label nodes based on their per-node probabilities (the Bayes-optimal prediction). Fi-nally, from a sample-complexity perspective, if we could average over many small cuts, we could improve our con-fidence via PAC-Bayes style arguments.
 In this paper, we propose a simple method for addressing a number of these drawbacks using randomization. Specif-ically, we repeatedly add artificial random noise to the edge weights, 1 solve for the minimum cut in the resulting graphs, and finally output a fractional label for each exam-ple corresponding to the fraction of the time it was on one side or the other in this experiment. This is not the same as sampling directly from the MRF distribution, and is also not the same as picking truly random minimum cuts in the original graph, but those problems appear to be much more difficult computationally on general graphs (see Section 2). A nice property of the randomized mincut approach is that it easily leads to a measure of confidence on the predic-tions; this is lacking in the deterministic mincut algorithm, which produces a single partition of the data. The confi-dences allow us to compute accuracy-coverage curves, and we see that on many datasets the randomized mincut algo-rithm exhibits good accuracy-coverage performance. We also discuss design criteria for constructing graphs likely to be amenable to our algorithm. Note that some graphs simply do not have small cuts that match any low-error solution; in such graphs, the mincut approach will likely fail even with randomization. However, constructing the graph in a way that is very conservative in producing edges can alleviate many of these problems. For instance, we find that a very simple minimum spanning tree graph does quite well across a range of datasets.
 PAC-Bayes sample complexity analysis (McAllester, 2003) suggests that when the graph has many small cuts consis-tent with the labeling, randomization should improve gen-eralization performance. This analysis is supported in ex-periments with data sets such as handwritten digit recogni-tion, where the algorithm results in a highly accurate classi-fier. In cases where the graph does not have small cuts for a given classification problem, the theory also suggests, and our experiments confirm, that randomization may not help. We present experiments on several different data sets that indicate both the strengths and weaknesses of randomized mincuts, and also how this approach compares with the semi-supervised learning schemes of Zhu et al. (2003) and Joachims (2003). For the case of MST-graphs, in which the Markov random field probabilities can be efficiently calcu-lated exactly, we compare to that method as well. In the following sections we give some background on Markov random fields, describe our algorithm more pre-cisely as well as our design criteria for graph construc-tion, provide sample-complexity analysis motivating some of our design decisions, and finally give our experimental results. Markov random field models originated in statistical physics, and have been extensively used in image process-ing. In the context of machine learning, what we can do is create a graph with a node for each example, and with edges between examples that are similar to each other. A natural energy function to consider is where are binary labels and is the weight on edge , which is a measure of the similarity between the examples. To assign a probability distribution to labelings of the graph, we form a random field where the partition function normalizes over all label-ings. Solving for the lowest energy configuration in this Markov random field will produce a partition of the entire (labeled and unlabeled) dataset that maximally optimizes self-consistency, subject to the constraint that the configu-ration must agree with the labeled data.
 As noticed over a decade ago in the vision literature (Greig et al., 1989), this is equivalent to solving for a minimum cut in the graph, which can be done via a number of stan-dard algorithms. Blum and Chawla (2001) introduced this approach to machine learning, carried out experiments on several data sets, and explored generative models that sup-port this notion of self-consistency.
 The minimum cut corresponds, in essence, to the MAP hy-pothesis in this MRF model. To produce Bayes-optimal predictions, however, we would like instead to sample di-rectly from the MRF distribution. Unfortunately, that prob-lem appears to be much more difficult computationally on general graphs. Specifically, while random labelings can be efficiently sampled before any labels are observed, us-ing the well-known Jerrum-Sinclair procedure for the Ising model (Jerrum &amp; Sinclair, 1993), after we observe the la-bels on some examples, there is no known efficient algo-rithm for sampling from the conditional probability distri-bution; see (Dyer et al., 2000) for a discussion of related combinatorial problems. This leads to two approaches: (1) try to approximate this procedure by adding random noise into the graph, or (2) make sure the graph is a tree, for which the MRF probabilities can be calculated exactly us-ing dynamic programming. In this paper, we consider both. The randomized mincut procedure we consider is the fol-lowing. Given a graph constructed from the dataset, we produce a collection of cuts by repeatedly adding random noise to the edge weights and then solving for the mini-mum cut in the perturbed graph. In addition, now that we have a collection of cuts, we remove those that are highly unbalanced. This step is justified using a simple -cover argument (see Section 4), and in our experiments, any cut with less than 5% of the vertices on one side is considered unbalanced. 2 Finally, we predict based on a majority vote over the remaining cuts in our sample, outputting a con-fidence based on the margin of the vote. We call this al-gorithm  X  X andomized mincut with sanity check X  since we use randomization to produce a distribution over cuts, and then throw out the ones that are obviously far from the true target function.
 In many cases this randomization can overcome some of the limitations of the plain mincut algorithm. Consider a graph which simply consists of a line, with a positively la-beled node at one end and a negatively labeled node at the other end with the rest being unlabeled. Plain mincut may choose from any of a number of cuts, and in fact the cut pro-duced by running network flow will be either the leftmost or rightmost one depending on how it is implemented. Our algorithm will take a vote among all the mincuts and thus we will end up using the middle of the line as a decision boundary, with confidence that increases linearly out to the endpoints.
 It is interesting to consider for which graphs our algorithm produces a true uniform distribution over minimum cuts and for which it does not. To think about this, it is helpful to imagine we collapse all labeled positive examples into a single node and we collapse all labeled negative exam-ples into a single node . We can now make a few simple observations. First, a class of graphs for which our algo-rithm does produce a true uniform distribution are those for which all the -minimum cuts are disjoint, such as the case of the line above. Furthermore, if the graph can be decomposed into several such graphs running in par-allel between and ( X  X eneralized theta graphs X  (Brown et al., 2001)), then we get a true uniform distribution as well. That is because any minimum -cut must look like a tuple of minimum cuts, one from each graph, and the ran-domized mincut algorithm will end up choosing at random from each one.
 On the other hand, if the graph has the property that some minimum cuts overlap with many others and some do not, then the distribution may not be uniform. For example, Figure 1 shows a case in which the randomized procedure gives a much higher weight to one of the cuts than it should ( rather than ). 4.1. The basic mincut approach From a sample-complexity perspective, we have a trans-ductive learning problem, or (roughly) equivalently, a prob-lem of learning from a known distribution. Let us model the learning scenario as one in which first the graph is con-structed from data without any labels (as is done in our ex-periments) and then a few examples at random are labeled. Our goal is to perform well on the rest of the points. This means we can view our setting as a standard PAC-learning problem over the uniform distribution on the vertices of the graph. We can now think of the mincut algorithm as mo-tivated by standard Occam bounds: if we describe a hy-pothesis by listing the edges cut using bits each, then a cut of size can be described in bits. 3 This means we need only labeled examples to be confident in a consistent cut of edges (ignoring depen-dence on and  X  ).
 In fact, we can push this bound further: Kleinberg (2000), studying the problem of detecting failures in networks, shows that the VC-dimension of the class of cuts of size is . Thus, only labeled examples are needed to be confident in a consistent cut of edges. Kleinberg et al. (2004) reduce this further to where is the size of the global minimum cut in the graph (the minimum number of edges that must be removed in order to separate the graph into two nonempty pieces, without the require-ment that the labeled data be partitioned correctly). One implication of this analysis is that if we imagine data is being labeled for us one at a time, we can plot the size of the minimum cut found (which can only increase as we see more labeled data) and compare it to the global minimum cut in the graph. If this ratio grows slowly with the number of labeled examples, then we can be confident in the mincut predictions. 4.2. Randomized mincut with  X  X anity check X  As pointed out by Joachims (2003), minimum cuts can at times be very unbalanced. From a sample-complexity per-spective we can interpret this as a situation in which the cut produced is simply not small enough for the above bounds to apply given the number of labeled examples available. From this point of view, we can think of our mincut exten-sion as being motivated by two lines of research on ways of achieving rules of higher confidence. The first of these are PAC-Bayes bounds (McAllester, 2003; Langford &amp; Shawe-Taylor, 2002). The idea here is that even if no single con-sistent hypothesis is small enough to inspire confidence, if many of them are  X  X retty small X  (that is, they together have a large prior if we convert our description language into a probability distribution) then we can get a better confi-dence bound by randomizing over them. Even though our algorithm does not necessarily produce a true uniform dis-tribution over all consistent minimum cuts, our goal is sim-ply to produce as wide a distribution as we can to take as much advantage of this as possible. Results of Freund et al. (2003) show furthermore that if we weight the rules appro-priately, then we can expect a lower error rate on examples for which their vote is highly biased. Again, while our pro-cedure is at best only an approximation to their weighting scheme, this motivates our use of the bias of the vote in producing accuracy/coverage curves.
 The second line of research motivating aspects of our al-gorithm is work on bounds based on -cover size, e.g., (Benedek &amp; Itai, 1991). The idea here is that suppose we have a known distribution and we identify some hypoth-esis that has many similar hypotheses in our class with respect to . Then if has a high error rate over a labeled sample, it is likely that all of these similar hypotheses have a high true error rate, even if some happen to be consistent with the labeled sample . In our case, two specific hypothe-ses we can easily identify of this form are the  X  X ll posi-tive X  and  X  X ll negative X  rules. If our labeled sample is even reasonably close to balanced  X  e.g., 3 positive examples out of 10  X  then we can confidently conclude that these two hypotheses have a high error rate, and throw out all highly unbalanced cuts , even if they happen to be consis-tent with the labeled data. For instance, the cut that simply separates the three positive examples from the rest of the graph is consistent with the data, but can be ruled out by this method.
 This analysis then motivates the second part of our algo-rithm in which we discard all highly unbalanced cuts found before taking majority vote. The important issue here is that we can confidently do this even if we have only a very small labeled sample. Of course, it is possible that by do-ing so, our algorithm is never able to find a cut it is willing to use. In that case our algorithm halts with failure, con-cluding that the dataset is not one that is a good fit to the biases of our algorithm. In that case, perhaps a different approach such as the methods of Joachims (2003) or Zhu et al. (2003) or a different graph construction procedure is needed. For a given distance metric, there are a number of ways of constructing a graph. In this section, we briefly discuss de-sign principles for producing graphs amenable to the graph mincut algorithm. These then motivate the graph construc-tion methods we use in our experiments.
 First of all, the graph produced should either be connected or at least have the property that a small number of con-nected components cover nearly all the examples. If com-ponents are needed to cover a fraction of the points, then clearly any graph-based method will need labeled examples to do well. 4 Secondly, for a mincut-based approach we would like a graph that at least has some small balanced cuts. While these may or may not correspond to cuts consistent with the labeled data, we at least do not want to be dead in the water at the start. This suggests conservative methods that only produce edges between very similar examples. Based on these criteria, we chose the following two graph construction methods for our experiments.
 MST: Here we simply construct a minimum spanning tree  X  -MST: For this method, we connect two points with an Another natural method to consider would be a -NN graph, say connected up via a minimum spanning tree as in
 X  -MST. However, experimentally, we find that on many of our datasets this produces graphs where the mincut algo-rithm is simply not able to find even moderately balanced cuts (so it ends up rejecting them all in its internal  X  X anity-check X  procedure). Thus, even with a small labeled dataset, the mincut-based procedure would tell us to choose an al-ternative graph-creation method. We compare the randomized mincut algorithm on a number of datasets with the following approaches: P LAIN MINCUT : Mincut without randomization.
 G AUSSIAN FIELDS : The algorithm of Zhu et al. (2003). SGT : The spectral algorithm of Joachims (2003). EXACT : The exact Bayes-optimal prediction in the MRF model, which can be computed efficiently in trees (so we only run it on the MST graphs).
 Below we present results on handwritten digits, portions of the 20 newsgroups text collection, and various UCI datasets. 6.1. Handwritten Digits We evaluated randomized mincut on a dataset of handwrit-ten digits originally from the Cedar Buffalo binary digits database (Hull, 1994). Each digit is represented by a 16 X 16 grid with pixel values ranging from 0 to 255. Hence, each image is represented by a 256-dimensional vector. For each size of the labeled set, we perform 10 trials, ran-domly sampling the labeled points from the entire dataset. If any class is not represented in the labeled set, we redo the sample.
 One vs. Two: We consider the problem of classifying dig-Odd vs. Even: Here we classify 4000 digits into Odd In both datasets, the randomized mincut algorithm tracks the exact MRF Bayes-optimal predictions extremely closely. Perhaps what is most surprising, however, is how good performance is on the simple MST graph. On the Odd vs. Even problem, for instance, Zhu et al. (2003) report for their graphs an accuracy of 73% at 22 labeled examples, 77% at 32 labeled examples, and do not exceed 80% until 62 labeled examples. 6.2. 20 newsgroups We performed experiments on classifying text data from the 20-newsgroup datasets, specifically PC versus MAC (see Figure 4). Here we find that on the MST graph, all the methods perform similarly, with SGT edging out the others on the smaller labeled set sizes. On the  X  -MST graph, SGT performs best across the range of labeled set sizes. On this dataset, randomization has much less of an effect on the mincut algorithm. 6.3. UCI Datasets We conducted experiments on various UC Irvine datasets; see Table 1. Here we find all the algorithm perform com-parably. 6.4. Accuracy Coverage Tradeoff As mentioned earlier, one motivation for adding random-ness to the mincut procedure is that we can use it to set a confidence level based on the number of cuts that agree on the classification of a particular example. To see how con-fidence affects prediction accuracy, we sorted the examples by confidence and plotted the cumulative accuracy. Figure 5 shows accuracy-coverage tradeoffs for Odd-vs-Even and PC-vs-MAC. We see an especially smooth tradeoff for the digits data, and we observe on both datasets that the algo-rithm obtains a substantially lower error rate on examples on which it has high confidence. 6.5. Examining the graphs To get a feel for why the performance of the algorithms is so good on the MST graph for the digits dataset, we examined the following question. Suppose for some you remove all vertices that are not digit . What is the size of the largest component in the graph remaining? This gives a sense of how well one could possibly hope to do on the MST graph if one had only one labeled example of each digit. The result is shown in Figure 6. Interestingly, we see that most digits have a substantial fraction of their examples in a single component. This partly explains the good performance of the various algorithms on the MST graph. We introduce a new semi-supervised learning algorithm based on adding artificial random noise to the edge weights of a graph and averaging over the minimum cuts produced. Our algorithm addresses several shortcomings of the basic mincut approach, improving performance especially when the number of labeled examples is small, as well as pro-viding a confidence score for accuracy-coverage curves. We provide theoretical motivation for our approach from a sample complexity and Markov Random Field perspective. We present experimental results supporting the applicabil-ity of the randomized mincut algorithm to various settings. In the experiments done so far, our method allows mincut to approach, though it tends not to beat, the Gaussian field method of Zhu et al. (2003). However, mincuts have the nice property that we can apply sample-complexity anal-ysis, and furthermore the algorithm can often easily tell when it is or is not appropriate for a dataset based on how large and how unbalanced the cuts happen to be.
 The exact MRF per-node likelihoods can be computed ef-ficiently on trees. It would be especially interesting if this can be extended to larger classes of graphs.
 Acknowledgements This work was supported in part by NSF grants CCR-0105488, NSF-ITR CCR-0122581, and NSF-ITR IIS-0312814.

