 Flash-based solid state drives (SSDs), as a new type of non-volatile storage, are grad-ually replacing the central role of traditional magnetic hard disk drives (HDDs). More and more portable devices are equipped with SSDs to get excellent performance such as MacBook Air, Play Station and so on. Compared to HDDs, SSDs provide faster access speed, lower power consumption, lighter weight, smaller size and better shock consumption, SSDs are expected to gradua lly substitute HDDs as mass storage media in large data centers. 
The development of flash-based SSDs is also attracting researchers X  interests to re-design various aspects of DBMS internals for SSDs such as storage management, query processing and so on. Traditional query processing algorithms are mainly analysis workloads in database [3]. Thus it is necessary to redesign the query processing algorithms to take full advantages of SSDs. 
Scan and join are two important operators in DBMS. Scan operators are basic physical operations in database system and they can mainly divide into two catego-ries: table scan and index scan [4]. Table scan reads data block one by one sequential-role in determining the overall performance of the DBMS. There are three classic ad and hash join [4]. In this paper, we mainly explore the optimization of table scan and hash join. I/O requests at the same time on SSDs, that may offer us excellent IOPS (In-put/Output Operations Per Second). However, the outstanding random I/O perfor-mance of SSDs will remain only a potential performance specification, unless DBMSs take advantage of internal parallelism and fully utilize the high IOPS. 
In this paper, we investigate query processing methods that are better suited for the characteristics of SSDs, especially SSDs X  internal parallelism. In particular, we focus goal, we make the following contributions.  X 
We detect and examine internal architecture of different kinds of SSDs and then propose a novel parallel table scan operator called ParaScan to take full advantage of internal parallelism of SSDs.  X 
Based on ParaScan, we present ParaHashJoin, an efficient parallel hash join opera-tor which makes full use of internal parallelism of SSDs to accelerate join processing in a query plan.  X  Experiment evaluation results on TPC-H datasets demonstrate that the proposed 
ParaScan and ParaHashJoin operators reduce the execution time of scan and join effectively. of SSDs at first and then discusses how to utilize this internal parallelism and why we should detect SSD internals. After that, we propose a parallel table scan operator and experimental results on TPC-H datasets, and we conclude in Section 7. In order to achieve high bandwidth and better IOPS, most modern SSDs adopt multi-channel and multi-way architecture and flash memory controller can access flash chips in parallel [5]. Therefore, we need to understand the impact of this parallelism inside SSDs to improve data processing performance. Chen et al. [2] studied on how to uncover internal parallelism features of SSDs and revealed that exploiting internal parallelism can significantly improve I/O performance. In the study of [6], researchers method and design a new B+-tree variant called PIO B-tree to exploit internal paral-lelism of SSDs. Other studies [7, 8] tried to improve SSD internal architecture design in order to provide more I/O parallelism inside SSDs. 
There are several works that investigate in database query processing techniques join operations in query processing. They explore the impact of new page layouts on SSDs and propose FlashScan, FlashJoin and RARE-join algorithms. Another typical work is DigestJoin [12] which focuses on exploring the possibility of further improv-dom reads of SSDs. Different from previous studies, we try to optimize scan and join performance by exploiting internal parallelism of flash-based SSDs. internals. 3.1 Internal Parallel Architecture used to connect with the host and its common interface type is SATA. SSD controller mands to flash memory packages via the flash controller . Inside SSD, there is a RAM memory packages. Each channel can be operated independently and simultaneously interleaved, so the bus utilization can be optimized [5, 13]. By examining the internal architecture of SSDs, we can find that there are two typical levels of parallelism which lelism provides us an opportunity to improve the performance of applications on SSDs. 3.2 How to Utilize Internal Parallelism I/O requests designated to different flash memory packages spanning several channels should be submitted to SSDs at the same time whenever possible. In this way, native command queuing (NCQ) mechanisms of the host interface can generate favorable I/O patterns to the internal architecture [14]. In this paper, we mainly use multi-thread processing technique to produce multiple parallel I/Os at the same moment. 3.3 Detecting SSD Internals To make better use of internal parallelism of SSDs, it is necessary to know some key architectural features of an SSD. For example, knowing the number of channels in an SSD, we can set a proper concurrency level and avoid over-parallelization. However, it is hard to obtain such key architectural information because these details are often regarded as critical intellectual property of SSD manufacturers. Therefore, we have to do some detecting work to know about the SSD internals. 
We select two representative and state-of-the-art SSDs for research. One is built on multi-level cell (MLC) flash memories, which is designed for the mass storage mar-ket, while the other is a high-end product built on faster and more durable single-level cell (SLC) flash memories. For simplicity, we refer to these two SSDs as SSD-S and SSD-M respectively. More details about these two SSDs are shown in Table 1. 
Despite various implementations, most designers of SSDs try to optimize perfor-mance essentially in a similar way that is evenly distributing data accesses to maxim-ize resource usage. Base on some open documents, Chen et al. [2] define an abstract set of flash memories that share a specific set of resources (e.g. channels). A domain can be further partitioned into sub-domains (e.g. packages). A chunk is a unit of data that is continuously allocated within one domain. Chunks are interleavingly placed over a number of domains. Guided by the model and the detecting method introduced in [2], we detected the chunk size and the number of domains on SSD-S and SSD-M respectively. The detecting results are shown in Table 2. In this section, we first give an overview of ParaScan, a parallel table scan operator, which is designed guided by internal parallelism of flash-based SSDs and then de-scribe its main components including domain scan and multi-domain parallel scan in the following subsections. 4.1 ParaScan Overview Despite various implementations, most SSDs adopt a RAID-0 like striping data sto-rage mechanism as is shown in Fig. 2. The striped chunks of the domains are mostly placed in consecutive LBA (Logical Block Address) regions. In the striped domains, the write interleaving technique enhances the write performance by avoiding the shared data-bus channel competition and by interleaving data transfers while other domains are writing the already transferred da ta. This data storage policy provides us accesses to different domains. Therefore based on that good nature, we propose a parallel table scan called ParaScan to improve the efficiency of table scan. 
As shown in Fig. 2, the basic operation of ParaScan is domain scan . Domain scan read data chunks one by one from a single domain and then put them into the buffer. To reduce the potential performance loss caused by sharing resources, each domain multiple ScanBuffers compose the multi-domain parallel scan . As domain is a paral-lel unit of solid state drive, when we want to write data to SSDs, we should consider that all data pages of a relational table should be distributed into different domains as much as possible to make full use of internal parallelism of SSDs. 4.2 Domain Scan and Multi-domain Parallel Scan scan read data blocks of a relational table one by one, and then put them into a buffer domain scan read data chunks one by one which all come from the same domain, and usually exceed ScanBuffer size, the processed contents need to be replaced in order to cover the processed contents dir ectly to read unprocessed data. 
We implement multi-domain parallel scan by multi-thread processing. ParaScan operator generates multiple threads to do scan operation and each of them is in charge Buffers so that each scan thread can use one ScanBuffer. The performance of multi-domain parallel scan depends on the concurrency level which is not only related to the number of domains but also the maximal number of physical threads supported by the processor and the maximal queue depth supported by the SSD. Based on ParaScan operator, we present ParaHashJoin in this section. We first give an including ParaHash, MiniJoin and Fetch in the following subsections. 5.1 ParaHashJoin Overview ParaHashJoin is a parallel hash join operator tuned for solid state drives. First, it par-of SSDs. Moreover, ParaHashJoin also learns some important ideas from previous researches to take advantage of the fast random reads of SSDs. It uses late materiali-zation strategy to avoid processing unneeded attributes and postpone retrieving two-way equi-join implement of ParaHashJoin, and the multi-way join implement will continue to be researched in the future. Each ParaHashJoin in two-way equi-join consists of three phases, ParaHash phase, hash table in parallel on the join attributes and the row-ids (RIDs) of the participating rows from input relational table. A RID specifies the page and offset within the page phase retrieves the needed attributes using the RIDs specified in join results produced by MiniJoin. This approach offers some important benefits over traditional joins which use an early materialization strategy. 
First, based on ParaScan, ParaHashJoin can hash table records belong to different domains in parallel which not only make full use of internal parallelism of SSDs but also the ability of multi-core processor. Second, ParaHashJoin is more memory effi-cient. By using late materialization strategy, ParaHashJoin greatly reduces the amount of data needed to be read to compute the join result. Moreover, when multiple passes are needed, it incurs lower partitioning cost than traditional joins. processing and more cost of random reads for retrieving the other projected attributes in the fetch phase. But we show that this tradeoff is worthwhile to do a join on SSDs in the experimental section. 5.2 ParaHash In ParaHash phase, we use the same technique as ParaScan to implement parallel processing. Fig. 4 is a sketch of ParaHash in which buffer is divided into two regions, Each hash thread is in charge of one ScanBuffer. To mitigate the cost of calculations, here we use a simple hash function which applies a fast bit operator, as shown in Eq. hashed and B is the number of hash buckets which should be the power of 2. As we implement ParaHash by multi-thread processing, some threads may hash dif-ferent records into the same bucket at the same time. Thus, each bucket should main-each bucket to quickly judge whether hash in dex records with speci fied join attribute exist in the bucket. 5.3 MiniJoin Then, in the MiniJoin phase, we read each hash bucket into memory and generate the written to the SSD sequentially if it is larger than the memory size. 
In the case memtioned above, we need two pass to generate the MiniJoin results, hold the hash table of table R, the smaller table, we only need one simple pass. It first ParaScan and ParaHash table R, then it ParaScan table S. After that, in the MiniJoin phase, it can directly probe the hash table and produce MiniJoin results. 5.4 Fetch However, the outputs of the MiniJoin phase are the incomplete join results which only the necessary attributes using the RIDs specified in the join index to generate the final join results. 
In this phase, an efficient fetching strategy is very important for ParaHashJoin as it minimizes the number of page accesses when fetching the needed attributes from the them from peripheral storage, and then generate the final join result. This approach is reasonable when all data pages needed to generate the result can fit in memory. How-ever, when available memory is insufficient, this approach may result in reading some pages multiple times because the RIDs in the join index are usually unordered. Thus, the larger the join result, the higher is the cost of reloading pages. TID hash joins [15] use this approach which is their biggest weakness. 
We adopt a sort-based fetching strategy inspired by DigestJoin [11] to avoid reloading pages as much as possible. Befo re fetching the matching pages according to RIDs in MiniJoin results, we sort MiniJoin results based on the RIDs of outer table at the sorted MiniJoin results. In this strategy, we need to pay more cost to execute this sort, but we show that this payment is worthwhile in the experimental section. In this section, we present experimental evaluations of ParaScan and ParaHashJoin. We first describe the experimental setup in Section 6.1. Then we present experimental 6.3 respectively. 6.1 Experimental Setup Our experiments all run on a HP PC with Ubuntu 12.10 operating system. This plat-form is equipped with Intel Core i5-2400 @ 3.10GHz processor which is of four cores and supports four physical threads. In addition, it is equipped with 8G DDR3 memo-ry, a 500G 7400rpm SATA3 Seagate magnetic disk and two kinds of SSDs as shown in Table 1. In order to make use of SSDs X  rich internal parallelism, we need to enable AHCI (Advanced Host Controller Interface) mode by setting the BIOS. 
For our experiments, we implement two operators, ParaScan and ParaHashJoin, by multi-thread C programming. To avoid the interference from the buffer of file system, we read/write files in DirectIO mode and align the memory manually. The test dataset is taken from the TPC-H benchmark. In particular, we use CUSTOMER table and ORDERS table to do scan and join. CUSTOMER table has 1.5 million rows in total size of about 256MB, while ORDERS table has 150 million rows in total size of about 2GB. In following subsections, we have executed scan operations on ORDERS table and join operations between CUSTOMER table and ORDERS table. 6.2 ParaScan Evaluation We executed a table scan on ORDERS table by using ParaScan in our HDD, and two kinds of SSDs respectively. Fig. 5 compares the performance of scans as we vary the number of parallel scan threads. For simplicity, we define the symbol ParaScan-N to data block one by one sequentially in a single-thread mode, it is equal to ParaScan-1. As our CPU is of 4 physical threads and we have known that SSD-S and SSD-M both parallel threads. HDD due to its magnetic characteristics. However, the scan time of ParaScan on two kinds of SSDs both decrease apparently with the increasing number of parallel threads. When the number increases to 30, the performance of ParaScan on SSDs still switch among parallel threads also increases. Fig. 5 shows that, in best case, the scan only a quarter of time of the traditional table scan on HDD. 6.3 ParaHashJoin Evaluation In our experiments, we compare the performance of ParaHashJoin with two kinds of join algorithms. One is TradHashJoin which refers to traditional hash join using table ParaScan. We mainly consider the equi-join of two relations CUSTOMER and results size. The number of parallel threads in ParaScan and ParaHashJoin is set to be SSD-S but we also conducted experiments on SSD-M and got consistent results. 
In the first experiment, we vary the selectivity of the join result from 0.01% (1500 8MB so that all of the joins are executed in two pass. As shown in Fig. 6, the execu-tion times of all algorithms increase with the growth of the selectivity. That is because higher selectivity can lead to larger intermediate results and hence higher partitioning SSD at the same time. the amount of memory allocated per join form 2MB to 256MB. Fig. 7 presents our results. We can see that both TradHashJoin and NewHashJoin require 256MB to ex-ecute the join between CUSTOMER and ORDERS in one pass while ParaHashJoin NewHashJoin and 1.5X faster than TradHashJoin. From these results, we can see that random reads for retrieving projected attributes in the fetch phase. In this paper, we detect and examine internal architecture of different kinds of SSDs and then based on rich internal parallelism of SSDs, we propose ParaScan and Para-HashJoin operators to accelerate scan and join processing on SSDs. ParaScan takes full advantage of internal parallelism of SSDs through multi-thread processing tech-niques. Based on ParaScan, ParaHashJoin not only parallels the join operation as take advantage of the fast random reads of SSDs. The experimental results show that traditional table scan on HDD in best case. And the execution of traditional hash join superiority of ParaScan and ParaHashJoin. Acknowledgements. This research was partially supported by the grants from the Natural Science Foundation of China (No. 60833005, 61070055, 91024032, 2013AA013204); the Fundam ental Research Funds for the Central Universities, and the Research Funds of Renmin University( No. 11XNL010). 
