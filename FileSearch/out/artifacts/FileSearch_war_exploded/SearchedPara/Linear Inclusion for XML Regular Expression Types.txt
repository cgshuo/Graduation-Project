 Type inclusion is a fundamental operation in every type-checking compiler, but it is quite expensive for XML ma-nipulation languages. We recently presented an inclusion checking algorithm for an expressive family of XML type languages which is polynomial, but runs in quadratic time both in the best and in the worst cases. We present here an algorithm that has a linear-time backbone, and resorts to the quadratic approach for some specific parts of the com-pared types. Our experiments show that the new algorithm typically runs in linear time, hence can be used as a building block for a practical type-checking compiler.
 H.2 [ Database Management ]: Miscellaneous Theory XML, type inclusion
Regular Expressions extended with counting and inter-leaving (Extended REs, or EREs) are an abstract model of the basic mechanism of typical type systems for XML manipulation languages, such as XML Schema Definition, DTDs, Relax NG [11, 3, 4, 5]. Such ERE-based languages are expressive and natural, but type inclusion is intractab le, being EXPTIME-complete for basic REs, and EXPSPACE-complete once counting and interleaving are added [8].  X 
Dario Colazzo has been partially funded by Agence Na-tionale de la Recherche , decision ANR-08-DEFIS-004.
Type inclusion is the basic operation of any type-checking compiler, and is typically invoked for every variable assig n-ment, function definition, and function call, hence it must be extremely fast. We offered a first solution in [9, 6]. In these papers we introduced conflict-free EREs, which are a restricted form of EREs that closely correspond to the kind of EREs that schema designers actually use, and that admit a quadratic-time inclusion algorithm.

Unfortunately, that algorithm is quadratic both in the best and in the worst case, which is hardly acceptable, since in the most common situations a linear test is quite obviousl y sufficient. We present here a new algorithm that is linear-time in the common situations and resorts to the quadratic approach only for those specific portions of the two types where it seems to be necessary. Our experiments show that the new algorithm typically runs in linear time.

The algorithm we presented in [6] extracts a set of  X  X on-straints X  X rom the candidate supertype and verifies that eac h constraint is satisfied by the subtype, which involves a quad ratic amount of work, even in cases when the two types are very similar, or equal. Our new algorithm has a more tradi-tional  X  X tructural X  approach: it visits both types in paral lel from the top, matching the topmost operator and recurring on the children. This approach is not complete, since EREs may be included in cases when the topmost operators are permuted in quite complex ways, hence the structural ap-proach should be combined with the quadratic approach to yield a complete algorithm. A na  X   X ve algorithm could just apply an incomplete set of structural rules and, when these fail, go back to the original types and apply the quadratic algorithm. Hence the algorithm would be better than the quadratic one in those cases when the structural rules suffice , but would impose an overhead otherwise. Unfortunately, choosing the optimal set of structural rules is impossible under this approach. A simple set of rules would be very ef-fective in only a small set of cases. A richer set of rules woul d enlarge the set of cases where the algorithm is effective, but would impose a higher overhead in those cases where the structural work is useless. Our understanding of the  X  X ypi-cal X  workload of a type-checking compiler is too limited for a reasoned choice of an optimal set of rules.

We overcome this problem by designing a set of no-back tracking structural rules: whenever these rules rewrite a comparison into a set of simpler comparisons, the new set is not just a sufficient condition for the previous comparison, but it is equivalent. In this way, once a comparison that matches no rule is found, we do not need to go back to the initial types, but we can apply the quadratic algorithm to the smaller type fragments, so that the algorithm is always convenient over the baseline. These no-backtracking rules for EREs are the main contribution of this work, together with a technique to select the applicable rule in constant time.
 The paper is structured as follows. In Section 2 we describe the ERE type language we are using here. In Section 3 we describe the algorithm and prove its correctness. In Sectio n 4 we validate our approach with an experimental evalua-tion. In Sections 5 and 6 we revise some related works and conclude.
We describe here the specific syntax that we use for our extended REs, or  X  X ypes X .

We adopt the usual definitions for words concatenation w 1 w , and for the concatenation of two languages L 1 L 2 . The shuffle , or interleaving , operator w 1 &amp; w 2 is also standard, and is defined as follows.
 v, w  X   X   X  , or two languages L 1 , L 2  X   X   X  , is defined as fol-lows; notice that each v i or w i may be the empty word  X  .
When v  X  w 1 &amp; w 2 , we say that v is a shuffle of w 1 for example, w 1 w 2 and w 2 w 1 are shuffles of w 1 and w
We consider the following type language for words over an alphabet  X :
T ::=  X  | a | T [ m..n ] | T + T | T T | T &amp; T | T ! where: a  X   X , m  X  ( N \{ 0 } ), n  X  ( N  X  \{ 0 } ), n  X  m , and, for any T !, at least one of the subterms of T has shape a . Here, N  X  is N  X  X  X  X  , where  X  behaves as +  X  , i.e., for any n  X  N  X  ,  X  X  X  n .

Note that expressions like T [0 ..n ] are not allowed, due to the domain ( N \{ 0 } ) of m , but the type T [0 ..n ] can be equivalently represented by T [1 ..n ]+  X  . The type T ! denotes J T K \{  X  } , where J T K denotes type semantics (it is formalized shortly). The mandatory presence of an a subterm in T ! guarantees that T contains at least one word that is different from  X  , hence T ! is never empty, which, in turn, implies that we have no empty types.
 Definition 2.2 ( S ( w ) , S ( T ) ) For any word w , S ( w ) is the set of all symbols appearing in w . For any type T , S ( T ) is the set of all symbols appearing in T .
The semantics of types is inductively defined by the fol-lowing equations.

We will use to range over product operators and &amp; when we need to specify common properties, such as, for example: J T  X  K = J  X  T K = J T K . We will use to range over , &amp;, and +.
 We use N( T ) to indicate that T is nullable , that is  X   X  J T K . N( T ) has the following definition (observe that N( T [ m..n ]) = N( T ) because m cannot be 0).
 Definition 2.3 (N ( T ) ) N ( T ) is a predicate on types, de-fined as follows:
From this definition, it easily follows that N( T ) can be computed in O ( | T | ).
In [6] we proved that inclusion for the above language, which is EXPSPACE-complete in general, can be verified in quadratic time when the right hand-side of the comparison (the supertype ) is conflict-free . Conflict-free types are de-fined as those types that respect the following restrictions (hereafter we will use the meta-variable U for conflict-free types):
The symbol-counting restriction means that, for exam-ple, types like ( a b )  X  cannot be expressed. However, it has been found that DTDs and XSD (XML Schema Defi-nition) schemas use repetition almost exclusively as a op as ( a + . . . + z ) op (where op  X  { + ,  X  X  , see [2]), which can be immediately translated to types that only count sym-bols, thank to the U 1 &amp; U 2 and U ! operators. For instance, as ( a  X  &amp; . . . &amp; z  X  )!.

It should be observed that the quadratic algorithm im-poses no restriction on the left hand-side of the comparison (the subtype ), hence it can be safely applied in any context where the subtype is automatically inferred and the super-type is human-designed or human-declared. This situation is very common during the semantic analysis of programs being compiled: indeed, the compiler infers types for any expression in the language and compares those types with a supertype declared in the program code in the three funda-mental situations where subtype-checking is used: variabl e assignment, function definition, function call.

Our algorithm will adopt the same conflict-free restriction for the supertype, and will revert to the algorithm in [6] in those cases when it is not able to proceed.
Our algorithm is based on the assumption that subtyping would typically be applied to types that are very similar, a ? abbreviates a +  X  . Most of these cases may be proved by combining transitivity, associativity and commutativi ty with some obvious structural rules, such as:
Our algorithm is defined, as usual, by a set of deduction rules which are meant to be used to deterministically reduce the consequence to the premises. For example, one may encode monotonicity of  X   X  by the following rule.

Unfortunately, this rule requires backtracking: if we appl y it to ( a b ) c  X  a ( b c ), it would reduce it to a b  X  a, c  X  b c ; the second set does not hold, but still the original judgemen t was true. Our basic observation is that backtracking is not needed if the symbols of U 1 and U 2 are disjoint, as always happens since U is conflict-free, and if the symbols of T T 2 are respectively included in those of U 1 and U 2 . In this case, the rule needs no backtracking: the judgement in the conclusion holds if, and only if, all those in the premises do hold, as expressed by the following property.

The situation is slightly more complex for union types: if we substitute with + in the above property, the double implication does not hold, as in the following example: a ?+ b  X  a + b ? holds, symbol inclusion holds, but still a ?  X  a does not hold. This problem can be solved by separating empty words from non-empty words, as follows. We first define a kernel-subtyping relation T  X  k U , as follows. Definition 3.1 ( T  X  k U ) Now, we have the following double implication.

S ( T 1 )  X  S ( U 1 )  X  S ( T 2 )  X  S ( U 2 )  X  T 1 + T 2  X  U 1 + U 2
While it is quite natural to define  X  and  X  k by mutual recursion, our algorithm recursively computes the kernel-subtyping relation T  X  k U only, since the standard subtyp-ing relation T  X  U , defined as J T K  X  J U K , can be easily derived by adding a linear-time test (N( T )  X  N( U ))) to T  X  U , as specified by the following, obvious, property. Property 3.2 T  X  U  X  ( T  X  k U  X  ( N ( T )  X  N ( U )))
Symbol inclusion tests and use of T  X  k U give us the abil-ity to write rules that require no backtrack. Our algorithm uses these rules to reduce the problem as far as possible and, once no rule can be applied, it resorts to the quadratic al-gorithm. We need now to define a good set of rules, rich enough to deal with a good set of cases, but still with the property that looking for the next rule to apply should be extremely fast, so that the algorithm is linear on the size of the types.

We now introduce the rules, and will then formalize the algorithm, and discuss its correctness and its cost.
As previously discussed, our structural rules have the fol-lowing shape.

The premise is formed by a condition Cond ( T , U ), and a finite number of predicates T r i  X  k U r i , with T r i sub-terms of, respectively, T and U . The rule means that, if Cond R ( T, U ) holds, then T  X  k U is equivalent to T U 1 , . . . , T R n  X  k U R n . The algorithm selects a rule whose Cond R ( T, U ) holds, and uses it to rewrite the conclusion to the premises.

The condition Cond r ( T, U ) of every rule is composed by a pattern-matching part and a part that depends, among other things, on symbol inclusion. The pattern-matching part is usually written in the rule conclusion, hence we will follow this habit, and write instead of: T = T 1 + T 2  X  U = U 1 + U 2  X  S ( T 1 )  X  S ( U 1 )  X  S ( T The structural subtyping rules are collected in Table 1. All of these rules are  X  X idirectional X , meaning that, when a ll the conditions hold, the premises are equivalent to the con-clusion. As previously discussed, bidirectionality is a co nse-quence of the fact that S ( U 1 ) and S ( U 2 ) are disjoint, of the symbol inclusion conditions, and of the use of  X  k in the ++ case.

Most of the rules are self explicative, and their bidirec-tionality is proved in Theorem 3.7. The only non-trivial detail is the use of nullability in the premises. In the three (DIVIDE ) rules the nullability condition is needed for the direct implication to be sound. If the first nullability con-dition were violated, we would have  X   X  J T 1 K , a non empty word w 2 in J T 2 K and  X  /  X  J U 1 K . Hence, w 2 would belong to T 1 T 2 and w 2 would not contain any symbol from U 1 , hence it could not belong to U 1 U 2 , which only contains words that contain some symbol from U 1 . Observe that this com-plication derives from the use of  X  k , since T 1  X  U 1 would imply N( T 1 )  X  N( U 1 ), and similarly for T 2 .
Nullability of U 2 in the (NFOCUS ) rules is not related to  X  k , but it is the kernel of the rule itself, which is based on the observation that, if  X   X  J U 2 K , then J U 1 K  X  J U The same observation, applied to both factors, justifies the (NDIVIDE) rules.
 Observe that this set of rules is by no means complete. For example, one may add the following rule, to take com-mutativity of  X + X  into account.
 Unfortunately, associativity is at least as important as co m-mutativity, but is far more difficult to deal with. We hence present here just a minimal set of rules, to illustrate the ba -sic ideas, and we discuss our approach to associativity and commutativity later, in Section 3.4.
The algorithm is described below. It first calls the auxil-iary algorithm preprocess (T , U), which prepares the types for efficient subtype checking, and which we describe later on. The algorithm then verifies whether a rule r exists such that Cond r ( T, U ) holds. If the rule exists, it is applied, and the problem is split in simpler problems, to be solved in subsequent iterations of the while-loop. When we find a sub-problem where no rule is applicable, the algorithm resorts to the quadratic algorithm Oracle ( T, U ) [6].
 Check ( T, U ) 1 preprocess ( T , U ) 2 push ( T, U ) in todo 3 while ( todo 6 =  X  ) 4 do 5 pick ( T, U ) from todo 6 if (  X  r such that Cond r ( T, U )) 7 then push T r 1  X  U r 1 , . . . , T r n  X  U r n in todo 8 else if (not Oracle ( T, U )) 9 then return false 10 return true
The following theorems specify some sufficient conditions about Cond r ( T, U ) which guarantee that the algorithm is correct and is linear Oracle , meaning that it runs in linear time, apart from the time spent by Oracle .
 Theorem 3.3 (Correctness) The structural algorithm is correct if, for any rule r and any pair of types T and U , the following holds.

Cond r ( T, U )  X  ( T  X  U  X  T r 1  X  U r 1  X  . . .  X  T r n Theorem 3.4 (Linearity Oracle ) The structural algorithm is linear Oracle provided that:
We have now to show that the rules are correct, meaning that each rule corresponds to a double implication. Finally we show that the algorithm is linear, by showing that rule selection can be performed in constant time. Linearity Oracle follows by Theorem 3.4, since every rule consumes one sym-bol, i.e., k r = 1 for every rule r .
In the following, we will use the notation S 1 # S 2 to indi-cate that the two symbol sets are disjoint.
 Lemma 3.5 Let U be a conflict-free type. The following 4 properties hold: w  X  ( w 1 &amp; w 2 )  X  w  X  J T 1 T 2 K  X  Lemma 3.6 For each type T we have that J T K 6 =  X 
We can now present our main technical result, the bidi-rectionality of all the rules. The result we present here is slightly stronger than needed, since we group the nullabil-ity conditions together with the  X  k premises, instead of the symbol inclusion precondition. In practice, this means tha t the algorithm may just use symbol inclusion to choose the rule, and, after the choice has been performed, if the nulla-bility test went wrong the algorithm may return an inclusion failure. We do not elaborate more on this point, but it may represent an important optimization.
 Theorem 3.7 (decomposition) If both S ( T 1 )  X  S ( U 1 ) and S ( T 2 )  X  S ( U 2 ) hold, then (divide ++ ) (divide &amp; )
T 1 T 2  X  U 1 &amp; U 2  X  T 1  X  U 1  X  T 2  X  U 2 (divide ) (divide &amp;&amp; )
T 1 &amp; T 2  X  k U 1 &amp; U 2  X  T 1  X  k U 1  X  T 2  X  k U
T 1 &amp; T 2  X  U 1 &amp; U 2  X  T 1  X  U 1  X  T 2  X  U 2 (ndivide +&amp; )
T 1 + T 2  X  U 1 &amp; U 2  X  T 1  X  U 1  X  T 2  X  U 2 (ndivide + )
T 1 + T 2  X  U 1 U 2  X  T 1  X  U 1  X  T 2  X  U 2 Also, if S ( T )  X  S ( U 1 ) then (focus + ) T  X  k U 1 + U 2  X  T  X  k U 1
T  X  U 1 + U 2  X  T  X  k U 1  X  ( N ( T )  X  N ( U 1 + U 2 )) (nfocus &amp; ) T  X  k U 1 &amp; U 2  X  T  X  k U 1  X  N ( U 2 )
T  X  U 1 &amp; U 2  X  T  X  U 1  X  N ( U 2 ) (nfocus ): T  X  k U 1 U 2  X  T  X  k U 1  X  N ( U 2 ) T  X  U 1 U 2  X  T  X  U 1  X  N ( U 2 )
Proof. For lack of space, we only report here the proof of main cases; the omitted cases are similar to those here reported. divide ++:
Assumed S ( T 1 )  X  S ( U 1 )  X  S ( T 2 )  X  S ( U 2 ), we want to prove that:
Let w 6 =  X   X  J T 1 K , hence w  X  J T 1 + T 2 K . By T 1 + T U 1 + U 2 , w  X  J U 1 + U 2 K . From S ( T 1 )  X  S ( U 1 ) we deduce that w 6 X  J U 2 K , hence w  X  J U 1 K .
 Now we want to prove that:
Assume w 6 =  X   X  J T 1 + T 2 K ; without loss of generality, assume that w  X  J T 1 K ; by hypothesis w  X  J U 1 K , hence w  X  J U 1 + U 2 K .
 Finally we want to prove that:
It follows by T 1 + T 2  X  k U 1 + U 2  X  T 1  X  k U 1  X  T 2 and by Property 3.2. divide &amp;:
Assumed S ( T 1 )  X  S ( U 1 )  X  S ( T 2 )  X  S ( U 2 ), we want to prove that:
T
Let w 6 =  X   X  J T 1 K , and consider any w  X   X  J T 2 K ; such a w  X  exists by Lemma 3.6. Since w w  X   X  J T 1 T 2 K , and ( w w  X  ) 6 =  X  , we have that w w  X   X  J U 1 &amp; U 2 K , hence, by S ( U 1 ) and S ( w )# S ( U 2 ), hence, by Lemma 3.5(1), we have we prove that T 2  X  k U 2 .

We want now to prove that N( T 1 )  X  ( S ( T 2 ) 6 =  X  )  X  N( U Assume  X   X  J T 1 K , and consider a non empty word w  X   X  J T that exists, by the hypothesis S ( T 2 ) 6 =  X  . By T 1 T U &amp; U 2 , since  X  w  X  is not empty,  X  w  X   X  J U 1 &amp; U prove that N( T 2 )  X  ( S ( T 1 ) 6 =  X  )  X  N( U 2 ). Now we want to prove that:
T
Assume w  X  J T 1 T 2 K and w 6 =  X  ; hence, exist w 1  X  J T and w 2  X  J T 2 K such that w = w 1 w 2 . If both w 1 and w are different from  X  we have that w 1  X  J U 1 K and w 2  X  J U hence w = w 1 w 2  X  J U 1 &amp; U 2 K . If w 1 =  X  , then w hence we have that N( T 1 )  X  ( S ( T 2 ) 6 =  X  ), hence N( U w 1  X  J U 1 K , hence we still have that w 1  X  J U 1 K and w The same reasoning applies when w 2 =  X  .
 Now we want to prove that:
Let w  X  J T 1 K , and choose one w  X   X  J T 2 K ; such a w  X  exists by Lemma 3.6. Since w w  X   X  J T 1 T 2 K , we have that w w  X   X  J U 1 &amp; U 2 K , hence, by Lemma 3.5(2), ( w w  X  ) | J U 1 K . By S ( T 1 )  X  S ( U 1 )  X  S ( T 2 )  X  S ( U 2 ) and S ( U we deduce that S ( w )  X  S ( U 1 ) and S ( w )# S ( U 2 ), hence, by Lemma 3.5(1), we have that ( w w  X  ) | S ( U J U 1 K .
 Finally we want to prove that:
Assume w  X  J T 1 T 2 K ; hence, exist w 1  X  J T 1 K and w such that w = w 1 w 2 , hence w 1  X  J U 1 K and w 2  X  J U w = w 1 w 2  X  J U 1 &amp; U 2 K . ndivide +&amp;:
Assumed S ( T 1 )  X  S ( U 1 )  X  S ( T 2 )  X  S ( U 2 ), we want to prove that:
Consider any w 6 =  X   X  J T 1 K ; by T 1 + T 2  X  k U 1 &amp; U have w  X  J U 1 &amp; U 2 K . By S ( w )  X  S ( T 1 )  X  S ( U Lemma 3.5(4) we have w  X  J U 1 K , hence T 1  X  k U 1 . By Lemma 3.5(3), we also know that w | S ( U w |
S ( U 2 ) =  X  , we deduce that N( U 2 ). By considering any w 6 =  X   X  J T 2 K we prove that T 2  X  k U 2 and that N( U Now we want to prove that:
Assume w 6 =  X   X  J T 1 + T 2 K , hence w  X  J T 1 K or w  X  J T Without loss of generality assume w  X  J T 1 K . By hypothesis w  X  J U 1 K and  X   X  J U 2 K , hence w &amp;  X   X  J U 1 &amp; U Now we want to prove that: Consider any w  X  J T 1 K ; by T 1 + T 2  X  U 1 &amp; U 2 we have w  X  J U we have w  X  J U 1 K , hence T 1  X  U 1 . By Lemma 3.5(3), we also know that w | S ( U that N( U 2 ). By considering any w 6 =  X   X  J T 2 K we prove that T 2  X  U 2 and that N( U 1 ).
 Finally we want to prove that: Assume w  X  J T 1 + T 2 K , hence w  X  J T 1 K or w  X  J T 2 Without loss of generality assume w  X  J T 1 K . By hypothesis w  X  J U 1 K and  X   X  J U 2 K , hence w &amp;  X   X  J U 1 &amp; U focus +: Assumed S ( T )  X  S ( U 1 ), we want to prove that:
Let w 6 =  X   X  J T K ; by T  X  k U 1 + U 2 we have w  X  J U 1 we have that w 6 X  J U 2 K , hence w  X  J U 1 K . Observe that the proof depends on the hypothesis that w 6 =  X  , hence cannot be trivially transposed to the  X  case.
 Now we want to prove that: Trivial by definition of +.
 Finally we want to prove that:
It follows by T  X  k U 1 + U 2  X  T  X  k U 1 and by Property 3.2. focus &amp;: Assumed S ( T )  X  S ( U 1 ), we want to prove that:
Let w 6 =  X   X  J T K ; by T  X  k U 1 &amp; U 2 we have w  X  J U hence, by Lemma 3.5(3), w | S ( U S ( T )  X  S ( U 1 ) we deduce that S ( w )  X  S ( U 1 ), hence, by Lemma 3.5(4), we have that w  X  J U 1 K . By Lemma 3.5(3), we also know that w | S ( U deduce that N( U 2 ).
 Now we want to prove that: Assume w 6 =  X   X  J T K , by hypothesis w  X  J U 1 K and  X   X  J U 2 K , hence w &amp;  X   X  J U 1 &amp; U 2 K .
 Now we want to prove that:
Let w  X  J T K ; by T  X  U 1 &amp; U 2 we have w  X  J U 1 &amp; U hence, by Lemma 3.5(3), w | S ( U S ( T )  X  S ( U 1 ) we deduce that S ( w )  X  S ( U 1 ), hence, by Lemma 3.5(4), we have that w  X  J U 1 K . By Lemma 3.5(3), we also know that w | S ( U deduce that N( U 2 ).
 Finally we want to prove that: Assume w  X  J T K , by hypothesis w  X  J U 1 K and  X   X  J U 2 hence w &amp;  X   X  J U 1 &amp; U 2 K .
Since every rule consumes a bit of input, by Theorem 3.4, it suffices to prove that, after a linear-time preprocessing, the applicable rule can be selected in constant time. Since we have a finite number of rules, it suffices to show that the applicability of each rule can be tested in constant time . Applicability conditions are a combination of the followin g components: 1. pattern matching, such as T = T 1 T 2 2. boolean combination of nullability and symbol empti-3. symbol set inclusion, such as S ( T 1 )  X  S ( U 1 ) Component (1) is obviously in O (1). A linear time bottom-up traversal can be used to decorate each node of T and U with attributes recording its nullability and the emptines s of symbol set, hence solving component (2). Component (3) requires a bit more of work, which we describe now.
Given a type T , represented by its syntax tree, we intro-duce the following definitions. Lemma 3.8 Given two types T and U , with S ( T )  X  S ( U ) , and where U is conflict free: 1. for any node n of T whose children are n 1 and n 2 , if 2. for any node n of T with S ( n ) 6 =  X  , cap U ( n ) is well
Proof. (1) Any common ancestor m of cap U ( n 1 ) and S ( LCA U [ cap U ( n 1 ) , cap U ( n 2 )]). Now consider any node m in U such that S ( n )  X  S ( m ), hence S ( n 1 )  X  S ( m ) and S ( n 2 )  X  S ( m ), hence m is an ancestor of both cap U and cap U ( n 2 ). (2) We reason by induction on the size of the subtree rooted in n . We have three cases: either n corresponds to a symbol a , or it is a unary operator applied to a node n  X  with S ( n  X  ) 6 =  X  , or it is a binary operator applied to n and n 2 . In the first case, since U is conflict-free, cap nodeOfSymbol U ( a ). In the second case, S ( n ) = S ( n  X  ), hence cap U ( n ) = cap U ( n  X  ), which is well defined by induction. In the third case we have to distinguish whether both n 1 and n 2 enjoy S ( n i ) 6 =  X  , or not. In the first case, we apply in-duction plus property (1). In the second case, let us assume that S ( n 1 ) =  X  , hence S ( n 2 ) 6 =  X  and S ( n ) = S ( n and cap U ( n ) = cap U ( n 2 ), which is well defined by induction.
Lemma 3.8 suggests a way to implement a constant-time We first build, in time O ( | U | ), the data structures needed to compute LCA U [ m 1 , m 2 ] and nodeOfSymbol U ( a ) in constant time [1]. We then decorate each node n of T such that S ( n ) 6 =  X  with a pointer to cap U ( n ) through a bottom-up visit of T , as follows: each leaf a of T is decorated with a pointer to nodeOfSymbol U ( a ), each node of T with only one child n 1 with S ( n 1 ) 6 =  X  is decorated with cap U and each node of T with two children n 1 and n 2 with n i  X  is decorated with LCA U [ cap U ( n 1 ) , cap U ( n 2 )]. Each step of the decoration phase takes constant time, hence T can be decorated in time O ( | T | ). Now, a test S T ( n )  X  S can be reduced to Desc ( cap U ( n ) , m ), and Desc ( m  X  , m ) is equivalent to LCA U [ m  X  , m ] = m .
The algorithm as presented embodies our main ideas, but it is too rigid, because it ignores basic commutativity and associativity properties of our type operators. For exampl e, it would fail on all of the following examples. a + b  X  b + a a + b + a  X  b + a + c a ( b c )  X  ( a b ) c a &amp;( b &amp; c )  X  ( c &amp; b )&amp; a a + ( b + c )  X  b ?&amp;(( a ? + d ) + c ) The first example shows that commutativity should be taken care of, and the second one elaborates a bit on this. The third example illustrates associativity. The fourth examp le shows that the simple approach of normalizing how oper-ators are associated is not sufficient, because associativit y and commutativity should be treated together. We solve this issue by adopting a flat version of all type operators, where every operator has an arbitrary number of arguments. This approach solves associativity, but leaves commutativ -ity open; we may solve this by reordering all addends al-phabetically, but that would require more than linear time. Moreover, the last example shows that flattening and then reordering is not enough: since the product of nullable fac-tors is a supertype of union, one would need to consider some pairs of operators together.

The approach we implemented in the algorithm is a bit more elaborated. First of all, we generalize all binary op-erators to their n-ary version, and we preprocess the types, in linear time, to collapse all consecutive application of t he same binary operator into one application of an n-ary oper-ator. Second, when applying a divide/ndivide rule to a pair of types T 1 . . . T n and U 1 . . . U m , we find, for each T , the minimum subterm U  X  ( i ) of some U j that contains all of its symbols, so that we may recur on the pair ( T i , U U  X  ( i ) does not need to coincide with a U j , provided that some conditions (specified later) hold on its path to U j this solves the issue presented in the fifth example.
To formalize this algorithm, we first define the notions of +-child and +-descendant. The intuition is that, when a subterm U  X  of U is a +-descendant of U , then J U  X  K  X  J U K . Definition 3.9 PlusChild ( U i , U ) holds if one of the follow-ing conditions hold: 1. U = U 1 + . . . + U i + . . . + U n 2. U = U 1 . . . U i . . . U n , and  X  j  X  X  1 , . . . , i  X  1 , i + The relation PlusDesc ( , ) is the reflexive and transitive clo-sure of PlusChild ( , ) .

The flat algorithm starts by first building the same data structures that we described for the binary algorithm, and then finding the node m = cap U ( n ), where n is the root of T , and starting its work on the pair n, m . In this way, the algorithm always operates on a pair of nodes n , m such that m = cap U ( n ), meaning that it never needs a focus rule. The algorithm, instead, repeatedly applies the following f our rules which, guided by the topmost operators of n and m , combine the tasks of divide and focus together.

With a slight abuse of notation, in the rules we write cap U ( T i ) rather then cap m ( n ), by identifying each node with the type that is rooted in that node. We remove all  X  types from the encoding, but we carry the corresponding infor-mation through an N( T ) mark at every node; in this way, the expression cap U ( T i ) is always well-defined, since S ( T never empty, and S ( T i )  X  S ( U ). The final case (SYMBOL) is not completely trivial, but is derived from the approach described in [6], and only requires a linear-time bottom-up visit of T .

The linearity of the algorithm follows from the fact that each rule has a cost that is proportional to the amount of symbols that it removes. We already described how to com-pute cap U ( T i ) in constant time, and the test PlusDesc ( , ) can also be run in constant time, provided that one builds the relevant data structures during preprocessing, in line ar time. The same is true for all the N( ) tests.
 U = a [ m..n ] S ( T )  X  X  a } cardinality a ( T )  X  X  m..n }
The rules differ because, when the subtype operator is +, we only have to check that every addend of the subtype cor-responds to a +-descendant of the supertype. In the ( &amp;) case, each factor of T must correspond to a +-descendant of a factor of U , but, moreover, no factor in the subtype must be duplicated, and the missing factors in the supertype must be nullable. The condition N( T i )  X  N( U  X  ( i ) ) that is found in the product rules corresponds to the  X  -inclusion condi-tion that is found in the binary product rules. Finally, in the ( ) case, the factors of T must also respect the order of the corresponding factors of U .
In this paper we describe an improved algorithm for asym-metric inclusion between regular expression types. The new algorithm exploits a linear structural comparison techniq ue whenever is possible, and reverts to the quadratic approach of [6] when the linear comparison is no longer applicable.
As for any improvement, we must show that the  X  X pti-mized X  algorithm is more efficient than the original one and that its applicability conditions can be easily satisfied, s o to justify its implementation.

To this purpose, starting from the observation in [8] that most human designed XML types are in conjunctive normal form , where each factor has the form ( a 1 + . . . + a k . . . + a k )?, ( a 1 + . . . + a k )  X  , or ( a 1 + . . . + a experiments on CNF types and compare the performance of our algorithm with that of the quadratic algorithm on the four main kinds of factors.

To make these experiments more significant, the conflict-freedom restriction has been enforced on the supertype only , hence the subtype contains repeated labels.
Both the structural linear algorithm and the quadratic one [6] have been tested in Java 1.5, and all experiments were performed on a 2.16 Ghz Intel Core 2 Duo machine (3 GB main memory) running Mac OSX 10.5.7. To avoid issues related to independent system activities, we ran eac h experiments ten times, discarded both the highest (worst) and the lowest (best) processing times, and reported the average processing time of the remaining runs.
As already stated, in our experiments we evaluate the per-formance of our algorithm on CNF types, with four main categories of factors: ( a 1 + . . . + a k ), ( a 1 + . . . + a ness, we also evaluate our algorithm on a DNF types sce-nario, where types are in disjunctive normal form (e.g., the subtype and the supertype are a union of products).
In the supertype we impose the conflict freedom constraint, hence terminal symbols are unique and counting is applied only to terminal symbols, while these restrictions are rela xed in the subtype, which can be any legal type.

In our experiments we compared the performance of the structural algorithm with that of the plain mixed algorithm of [6]; in particular, we evaluate the scalability of the alg o-rithms by increasing the number of addenda in each factor of both the supertype and the subtype from 10 to 100. To make the experiments even more realistic and test the flat algorithm, the supertype contains a 20% of randomly dis-tributed labels. We only generated pairs of types which sat-isfy the subtype test, since this is the dominating situatio n when the algorithm is run by a compiler.

The results of our experiments on CNF types are shown Figure 1: Structural vs quadratic algorithm: CNF types.
 Figure 2: Structural vs quadratic algorithm: op-tional types. in Figures 1, 2, 3, 4, and 5. As it can be seen, except for the case for ( a 1 + . . . + a k ) + (see Figure 4), the structural algorithm definitely outperforms the plain algorithm, that exposes its quadratic behaviour, while the structural algo -rithm is able to perform most of the work without resorting to the quadratic fallback. Hence, the structural algorithm is a definite improvement over the previous one.

In the case for ( a 1 + . . . + a k ) + the two algorithms show essentially the same performance. The problem is related to this encoding is based on the use of a bang operator !, which is currently not covered by any applicability condition for the structural algorithm. Adding the relevant condition is a trivial task, which we plan to complete very shortly, in orde r to make this case uniform with the others.

In Figure 5 we illustrate a variation of the case for ( a . . . + a k ), where ordered products have been replaced by com-mutative products. As for the base case, the performance is satisfactory and the speed gain is significant.

For the sake of completeness, in Figure 6 we report the re-sults of an experiment with disjunctive normal form types: in both the subtype and the supertype each addendum is a product of factors, whose number ranges from 20 to 200. As Figure 3: Structural vs quadratic algorithm: star types.
 Figure 4: Structural vs quadratic algorithm: plus types.
 Figure 5: Structural vs quadratic algorithm: com-mutative CNF types. it can be seen, the structural algorithm significantly outpe r-forms the plain one also in this case.
 Figure 6: Structural vs quadratic algorithm: DNF types.
The inclusion of regular expressions with interleaving has been studied in many papers. In particular, in [10] the com-plexity of membership, inclusion, and inequality was studi ed for several classes of regular expressions with interleavi ng and intersection, and authors proved that inclusion, in the presence of interleaving, is EXPSPACE-complete.

Starting from the results of [10], Gelade et al. [8] studied the complexity of decision problems for DTDs, single-type EDTDs, and EDTDs with interleaving and counting. By considering several classes of regular expressions with in ter-leaving and counting, they showed that their inclusion is al -most invariably EXPSPACE-complete, even when counting is restricted to terminal symbols only.

In [9] we defined a quadratic algorithm for inclusion of conflict-free types, while in [6] we presented a new algorith m that can be applied when the subtype is not constrained (asymmetrical inclusion). This algorithm forms the basis for the present work.

Asymmetric inclusion of XML types has been studied in [7] too. Here, Colazzo and Sartiani showed that complexity of inclusion can be lowered from EXPSPACE to EXPTIME when a weaker form of conflict-freedom is satisfied by the supertype. In [6] we proposed an algorithm to check subtyping among EREs types with the only restriction that the supertype must be conflict-free, as it commonly happens while type-checking XML programs. This algorithm has quadratic com-plexity, both in the best and worst cases, it strongly exploi ts the conflict-free restriction over the supertype, but does n ot exploit any structural similarities between the subtype an d the supertype to further accelerate inclusion checking.
In this paper we have provided a more efficient algorithm, still dealing with the kind of mixed comparisons of [6], but which also exploits possible structural similarities betw een the types being compared. The new algorithm proceeds in a top-down fashion, and is based on a set of structural subtyp-ing rules, that are applied whenever a structural similarit y is detected; when these similarity conditions are not satisfie d, the algorithm just resorts to the quadratic algorithm.
We have proved that the new algorithm is correct, and that it runs in linear time whenever the quadratic algorithm is not invoked. In order to ensure linearity we have defined a specific pre-processing technique, and a set of structural subtyping rules whose application can be decided in constan t time, and that need no backtracking; in particular, to this end we have defined each subtyping rule so that its premises are equivalent to the conclusion. To verify the effectivenes s of the new algorithm, we have performed several tests com-paring an implementation of the new structural algorithm with respect to the one we proposed in [6]. As illustrated by our experiments, in most of the considered cases the new algorithm exhibits a linear behavior, while the other one is clearly quadratic. [1] M. A. Bender and M. Farach-Colton. The LCA [2] G. J. Bex, F. Neven, T. Schwentick, and K. Tuyls. [3] P. V. Biron and A. Malhotra. XML Schema Part 2: [4] T. Bray, J. Paoli, C. M. Sperberg-McQueen, E. Maler, [5] J. Clark and M. Murata. Relax NG specification. [6] D. Colazzo, G. Ghelli, and C. Sartiani. Efficient [7] D. Colazzo and C. Sartiani. Efficient subtyping for [8] W. Gelade, W. Martens, and F. Neven. Optimizing [9] G. Ghelli, D. Colazzo, and C. Sartiani. Efficient [10] A. J. Mayer and L. J. Stockmeyer. Word problems  X  [11] H. S. Thompson, D. Beech, M. Maloney, and
