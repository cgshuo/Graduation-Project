 An intuitive framework for spoken dialogue system (SDS) can be regarded as a chain process. Specifi-cally, the automatic speech recognition (ASR) mod-ule accepts the user X  X  utterance U string of words W standing (SLU) module converts W representation of the user X  X  dialogue act (DA). The dialogue management (DM) module determines the user X  X  dialogue act A  X  current act of the system. The system DA is con-verted to a surface representation by natural lan-guage generation in the textual form, which is passed to a text-to-speech synthesizer for speech waveform generation. The cycle repeats when the user responds with a new utterance. Clearly, one can see that the inference of the user X  X  overall intention via DA detection is an important task in SDS.
Figure 1 depicts the training and test phases of the SLU module and the DM module in our system. The dataflow for training and testing are indicated by blue arrows and red arrows, respectively. The input word sequences are converted to partial sen-tence trees (PST) (Wu and Chen, 2004) in the PST Construction block. The derivation rule (DR) Gen-eration block extracts derivation rules from the train-ing text. The DR-DA matrix is created after cluster-ing the sentences into different dialogue acts (DAs), counting the occurrences the DRs in DA, and intro-ducing an entropy-based weighting scheme (Belle-garda, 2000). This matrix is pivotal in the computa-tion of the lexical score. Finally, the lexical, the his-tory, and the ASR scores are combined to decide the optimal dialogue act, and a proper action by the sys-tem is taken. In our system, not only the clean text data but also the noisy ASR output data are used in order to take the error-proneness of ASR output into account. Furthermore, a predefined keyword list is used and the keyword tokens are replaced by the cor-responding named entity classes (NEC) in order to obtain a compact feature set. Referring to the SDS depicted in Figure 1, the DA detection can be formulated as follows. At turn t , the most likely DA is determined by where U historical information, and  X  = { A set of DAs. Using the maximum approximation for summation, (1) can be written as A  X  t = arg max where W is the ASR output. Since the ASR output is independent of H term in (2) can be re-written as
P r ( W | U t , H t ) = P r ( W | U t )  X  f ( W , U t ) , where the function f ( W , U ASR score function. In addition, assuming that the information provided by U in
W , we can approximate the second term in (3) by the product of two functions where g ( A, W ) is introduced as the lexical score function, and h ( A, H score function. Thus, (3) can be re-written as A  X  t  X  arg max In Sections 3 and 4, we specify and explain how the scores in (5) are computed.
 For the ASR score, we use the conventional recog-nition probability of the ASR recognition model. For the history score, similar to the schemes used in (Hori et al., 2009c; Hori et al., 2009b; Hori et al., 2009a), a back-off bi-gram model for DA sequence is estimated from the data collected by the SDS. The estimated bi-gram model is used to calculate the his-tory score. That is, Essentially, (6) is based on a Markov model assump-tion for the chain of the dialogue acts. Figure 2 shows an example of dialogue controlling model of an SDS. In this example, each state represents a DA. A dialogue begins with the greeting state and ends with the ending state. During a session, a user can inquire the system about the provided services and then choose one service to continue (e.g., the loop-back connection in Figure 2). The main challenge of this system is the computa-tion of the lexical score g ( A, W ) . In this paper, we propose a novel data-driven scheme incorporating many techniques. 4.1 Construction of Partial Sentence Tree keywords K , and a set of non-keywords N . Each word w  X  K should be indicative of the DA of the sentence. The set of sentences S containing at least one keyword in K , can be represented as or more words in K . Given a sentence s  X  S , a par-tial sentence is formed by keeping all the keywords in s and some of the non-keywords in s . These partial sentences can be compiled in a tree, called the partial sentence tree (PST) and denoted as T ( s ) . The motivation for using PST is to achieve robust DA detection as the ASR module could be error-prone in adverse environments. In addition, words that are not confidently recognized are replaced by a special non-keyword token called Filler . Specif-ically, we compute the z -score (Larsen and Marx, 2000) of each word w in the ASR output. Figure 3 illustrates the PST for the sentence s : Where is the Anping-Fort . There are two keywords Where and Anping-Fort and two non-keywords is and the . Note that with 2 non-keywords in the original sentence s , we have 2 2 = 4 partial sentences in the PST T ( s ) . 4.2 Extraction of the Derivation Rules After text processing, a sentence s is parsed by the statistical Stanford parser (S-parser) (Levy and Man-ning, 2003). Let the grammar of the S-parser be denoted as a 5 -tuple G = ( V ,  X  , P , S, D ) where V is the variable (non-terminal) set,  X  is the termi-nal symbol set, P is the production rule set, S is the sentence symbol, and D is a function defined on P for rule probability (Jurafsky and Martin, 2009). A form A  X  B  X  w where A, B  X  V and w  X   X  .
 The parsing result of the exemplar sentence s repre-sented in the parenthesized expression is shown in Figure 4. From the parsing result, four DRs are ex-tracted. Essentially, we have one DR for each lexical word in the sentence. Totally, given a corpus, l rules are extracted and defined as D = { R
Based on PST T ( s ) and DR set D , a vector rep-resentation v ( s ) for sentence s can be constructed according to the DRs used in T ( s ) . That is For example, v ( s ) = [1 0 1 0] T means that there are four derivation rules, of which R in T ( s ) . The motivation for using DRs instead of the lexical words is to incorporate the part-of-speech (POS) tags information. POS tags are helpful in the disambiguation of noun-and-verb homonyms in Chinese. Moreover, the probabilistic nature of the S-parser renders the DRs extracted from the pars-ing results quite robust and consistent, even for the error-prone ASR output sentences. 4.3 Generation of Dialogue Acts The basic idea of data-driven DA is to cluster sen-tences in the set and identify the clusters as formed by the sentences of the same DA. In this work, the spectral clustering algorithm (von Luxburg, 2007) is employed for sentence clustering. Specifically, sup-pose we have n vectors represented as C = { v v ( s k ) , k = 1 , . . . , n } converted from sentences ac-cording to (7). From C , we construct an n  X  n sim-ilarity matrix M , in which each element M a symmetric nonnegative distance measure between v The matrix M can be regarded as the adjacency ma-trix of a graph G with node set N and edge set E , where N is 1 -to-1 correspondent to the set C , and E corresponds to the non-zero entries in M . The nor-malized Laplacian matrix of M is where D is a diagonal matrix with entries It has been shown (von Luxburg, 2007) that the mul-tiplicity of the eigenvalue 0 for L equals the num-ber of disjoint connected components in G . In our implementation, we find the q eigenvectors of the normalized Laplacian matrix of M of the smallest eigenvalues. We put these eigenvectors in an n  X  q orthogonal matrix Q , and cluster the row vectors to q clusters. Each cluster correspond to a data-driven DA A to the cluster they belong to.

In order to use the DRs in a PST as a knowl-edge source for DA detection, we essentially need to model the relationship between the random DA and the random DR. Denote the random DA by X and the random DR by Y . Given a text corpus, let n the accumulated count that R labeled as A of
Y = A j given X = R i can be defined as where j = 1 , . . . , q . The normalized entropy for the conditional probability function (10) is From (10) and (11), a matrix  X  can be constructed by  X  rule dialogue-act (DR-DA) matrix, in which each row corresponds to a derivation rule and each col-umn corresponds to a dialogue act. 4.4 Distance Measure In our system, the lexical score g ( A, W ) in (5) is further broken into two terms where g g
N ( A, W ) that s denotes the sentence after text processing. The cosine distance measure is employed for the deriva-tion rule score, where b T ordinates of the DRs) of a partial sentence  X  in T ( s ) , and a  X  . For the named entity score, we use the approxi-mation where  X   X  ( A,  X  ) is estimated from a training corpus by rela-tive frequencies. To evaluate the proposed method of dialogue act de-tection for robust spoken dialogue system, we adopt the commonly-used Wizard-of-Oz approach (Fraser and Gilbert, 1991) to harvest the Tainan-city tour-guiding dialogue corpus in a lab environment and experiment with simulated noisy ASR results. The details are given in this section. Two types of data from different sources are collected for this work. The first type of data, called A-data, is a travel infor-mation data set harvested from the databases avail-able on the web, e.g., Wikipedia and Google Map. A-data consists of 1 , 603 sentences with 317 word types. The second type of data, called Q-data, is the edited transcription of a speech data set simulating human-computer dialogues in a lab environment. Q-data is intended for the system to learn to handle the various situations, e.g., misunderstanding the user X  X  intention. It consists of 144 dialogues with 1 , 586 ut-terances. From the Q-data, 28 named entity classes and 796 derivation rules were obtained from the S-parser. Table 1 gives some examples of the selected NECs and semantic classes. 5.1 Experimental Conditions A Mandarin speech recognition engine was real-ized using the HTK (Young et al., 2006), which is commonly used in research and development. For speech features, 39 dimensions were used, includ-ing 12 dimensions of mel-frequency cepstral coeffi-cients (MFCCs), one dimension of log energy, and their delta and acceleration features. In total, the acoustic models are composed of 153 subsyllable and 37 particle models (e.g., EN, MA, OU) based on Hidden Markov Model (HMM) with 32 Gaus-sian mixture components per state. For the lan-guage model, SRILM toolkit (Stolcke, 2002) was employed to estimate a bi-gram model with the Q-data. The average word accuracy of the ASR module is 86.1% with a lexicon of 297 words. Note that the vocabulary size is small due to a limited domain. 5 -fold cross validation method was utilized for system evaluation.

As shown in Table 2, one can see that 38 DA types achieve the best performance for the proposed detec-tion model. Therefore, we use 38 DA types ( q = 38 ) in our system. Note that some exemplar DAs are shown in Figure 2. 5.2 Incremental Evaluation We incrementally add techniques in our SDS un-til the complete proposed overall system is imple-mented, to observe the effect of these techniques. The detection accuracies are shown in Table 3. In this table, the third column (ASR) represents the re-sults of the experiment using the ASR transcripts directly. The fourth column (REF) uses the refer-ence transcripts, so it represents the case with per-fect ASR. The first (40%-sim) and second (60%-sim) column represents the simulation where 40% and 60% of the words in the reference transcripts are retained, respectively. There are five sets of ex-periments summarized in this table. For the base-line, each keyword corresponds to a coordinate in the vector representation for a sentence. The results are shown in the first row (baseline). In the second set of experiments (NEC), the keywords are replaced by their NEC. In the third set of experiments (PST), the PST representation for a sentence is used. In the fourth set of experiments (DR), the derivation rule representation of a sentence is used. Finally, the entropy-normalized DR-DA matrix is used to repre-sent sentences, and the results are shown in the last row (DR-DA). There are strong improvements when NEC (from 49.6% to 56.8%) and PST (from 56.8% to 76.2%) representations are introduced. Moreover, baseline 17.2 32.6 49.6 60.9 the DR and DR-DA representations also lead to sig-nificant improvements, achieving 81.6% to 82.9%, respectively. For the other conditions of 40%-sim, 60%-sim, and REF, similar improvements of using NEC and PST are observed. Using DR-DA, how-ever, suffers from performance degradation when the keywords are randomly discarded. 5.3 Evaluation on the Weighting Scheme We examine the effect of different weighted product fusion and rewrite the formulation in (5) as A t  X  arg max where  X  lexical score,  X  and  X  history information will effect on the DA detection, because it was estimated by the dialogue turns that captured the user behaviors. In this paper, a noise-robust dialogue act detection using named entity classes, partial sentence trees, derivation rules, and entropy-based dialogue act-derivation rule matrix is investigated. Data-driven dialogue acts are created by the spectral cluster-ing algorithm, which is applied on the vectors of sentences represented by the derivation rules. Our spoken dialogue system benefits when the proposed components are integrated incrementally. For the fully integrated system, we find that the proposed approach achieves 84.3% detection accuracy.
