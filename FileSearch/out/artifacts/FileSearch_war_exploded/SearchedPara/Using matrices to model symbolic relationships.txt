 It is sometimes possible to find a way of mapping objects in a  X  X  ata X  domain into objects in a  X  X arget X  domain so that operations in the data domain can be modelled b y operations in the target domain. If, for example, we map each positive number to its logarithm , multiplication in the data domain can be modelled by addition in the target domain. When the objects in the data and target domains are more complicated than single numbers, it may be difficult to fi nd good mappings using inspiration alone. If we consider a continuous space of possible mapping s and if we define a smooth measure of how well any particular mapping works, it is possible to use g radient search to find good mappings between the data and target domains.
 Paccanaro and Hinton [10] introduced a method called  X  X inea r Relational Embedding X  (LRE) that uses multiplication of vectors by matrices in the target dom ain to model pairwise relations between objects in the data domain. LRE applies to a finite set of objec ts  X  and a finite set of relations R where every relation R  X  X  is a set of pairs of objects, so R  X   X   X   X  . Given the objects and relations, LRE finds a column-vector representation A of each object A  X   X  , and a matrix representation R of each relation R  X  X  , such that the product RA is close to B for all pairs ( A, B ) that are members of the relation R , and far from C for all pairs ( A, C ) that are not members of
R . LRE learns the vectors and matrices by performing gradient descent in a cost function C that measures the similarities between RA and all B such that ( A, B )  X  R relative to the similarities between RA and the vector representations of all the objects in the set o f known objects  X  : The cost function in Eq. 1 is  X  X iscriminative X  because it com pares the distance from RA to each correct answer with the distances from RA to all possible answers. This prevents trivial solutions in which RA and B are always zero, but it also causes the cost function to be non convex, making it hard to optimize. We can view exp(  X  X  RA  X  B k 2 ) as the unnormalized probability density of B under a spherical Gaussian centered at RA . The cost function then represents the sum of the negative log probabilities of picking the correct answers t o questions of the form ( A, ? )  X  R if we pick answers stochastically in proportion to their probabi lity densities under the spherical Gaussian centered at RA .
 We say that LRE accurately models a set of objects and relatio ns if its answers to queries of the form ( A, ?)  X  R are correct, which means that for each object A and relation R such that there are k objects X satisfying ( A, X )  X  R , each vector representation X of each such object X must be among the k closest vector representations to RA . The definition of correctness implies that LRE X  X  answer to a query ( A, ?)  X  R that has no solutions is always trivially correct. More refin ed versions of LRE handle such unsatisfiable queries more explicitly [9] .
 It may not be obvious how to determine if the representation f ound by LRE is good. One way is to check if LRE X  X  representation generalizes to test data. M ore specifically, if LRE has not been informed that B is an answer to the query ( A, ?)  X  R that has k correct answers (that is, ( A, B ) was removed from R during LRE X  X  learning), yet LRE answers the query ( A, ?)  X  R correctly by placing B among the k closest object representations to RA , then we can claim that LRE X  X  representation generalizes. Such generalization can occur only if LRE lear ned the  X  X ight X  representations A , B , and R from the other propositions, which can happen only if the tru e relation is plausible according to LRE X  X  inductive bias that determines the subjective plau sibility of every possible set of objects and relations (see, e.g., [6]). If the representation is hig h-dimensional, then LRE can easily represent any set of relations that is not too large, so its inductive bi as finds all sets of relations plausible, which prevents generalization from being good. However, if the re presentation is low-dimensional, then LRE must make use of regularities in the training set in order to accurately model the data, but if it succeeds in doing so, generalization will be good. Paccan aro and Hinton [10] show that low-dimensional LRE exhibits excellent generalization on data sets such as the family relations task. In general, the dimensionality of the representation should g row with the total numbers of objects and relations, because when there are few objects and relations , a high-dimensional representation easily overfits, but if the number of objects and relations is large t hen the dimensionality can be higher, without overfitting. The best dimensionality depends on the  X  X it X  between LRE and the data, and is mainly an empirical question.
 A drawback of LRE is that the square matrices it uses to repres ent relations are quadratically more cumbersome than the vectors it uses to represent objects. Th is causes the number of free parameters to grow rapidly when the dimensionality of the representati ons is increased. More importantly, it also means that relations cannot themselves be treated as ob jects. Paccanaro and Hinton [10], for example, describe a system that learns propositions of the f orm: (2 , 5)  X  +3 where +3 is a relation that is represented by a learned matrix, but their system doe s not understand that the learned matrix for +3 has anything in common with the learned vector that is used to model the number 3 in propositions like (5 , 3)  X  X  X  2 .
 In this paper we describe  X  X atrix Relational Embedding X  (MR E), which is a version of LRE that uses matrices as the representation for objects as well as fo r relations. 1 MRE optimizes the same cost function as LRE (equation 1), with the difference that RA  X  C is now a matrix rather than a vector and k RA  X  C k 2 denotes the sum of the squares of the entries of the matrix. Th is choice of matrix norm makes MRE a direct generalization of LRE. All d istances between matrices will be computed using this norm.
 Although MRE is a simple variation of LRE, it has two importan t advantages.
 The first advantage of MRE is that when using an N  X  N matrix to represent each object it is possible to make N much smaller than when using an N -dimensional vector, so MRE can use about the same number of parameters as LRE for each object but many f ewer parameters than LRE for each relation, which is useful for  X  X imple X  relations. The second advantage of MRE, which is also the main novelty of this paper, is that MRE is capable of representing higher-order relations, instance s of which are (+3 ,  X  3)  X  inverse or ( has husband, has wif e )  X  higher oppsex . It can also represent relations involving an object and a relation, for instance (3 , +3)  X  plus . Formally, we are given a finite set of higher-order rela-tions  X  R , where a higher-order relation  X  R  X   X  R is a relation whose arguments can be relations as well as objects, which we formalize as  X  R  X  X  X R or  X  R  X   X   X R ( R is the set of the basic relations). The matrix representation of MRE allows it to treat relation s in (almost) the same way it treats basic objects, so there is no difficulty representing relations wh ose arguments are also relations. We show that MRE can answer questions of the form (4 , ? )  X  +3 even though the training set contains no examples of the basic relation +3 . It can do this because it is told what +3 means by being given higher-order information about +3 . It is told that (3 , +3)  X  plus and it figures out what plus means from higher-order examples of the form (2 , +2)  X  plus and basic examples of the form (3 , 5)  X  +2 . This enables MRE to understand a relation from an  X  X nalogic al definition X : if it is told that has f ather to has mother is like has brother to has sister , etc., then MRE can answer queries involving has f ather based on this analogical information alone. Finally, we sho w that MRE can learn new relations after an initial set of objects an d relations has already been learned and the learned matrices have been fixed. This shows that MRE can a dd new knowledge to previously acquired propositions without the need to relearn the origi nal propositions. We believe that MRE is the first gradient-descent learning system that can learn new relations from definitions, including learning the meanings of the terms used in the definitions. Th is significantly extends the symbolic learning abilities of connectionist-type learning algori thms.
 Some of the existing connectionist models for representing and learning relations and analogies [2, 4] are able to detect new relations and to represent hiera rchical relations of high complexity. They differ by using temporal synchrony for explicitly repr esenting the binding of the relations to object, and, more importantly, do not use distributed repre sentations for representing the relations themselves. Paccanaro and Hinton [10] describe a very simple modular ari thmetic task in which the 10 objects are the numbers from 0 to 9 and the 9 relations are +0 to +4 and  X  1 to  X  4 . Linear Relational Embedding easily learns this task using two-dimensional ve ctors for the numbers and 2  X  2 matrices for the relations. It arranges the numbers in a circle center ed at the origin and uses rotation matrices to implement the relations. We used base 12 modular arithmetic, thus there are 12 objects, and made the task much more difficult by using both the twelve relation s +0 to +11 and the twelve relations  X  0 to  X  11 . We did not include subtraction and division because in modu lar arithmetic every proposition involving subtraction or division is equivalent to one invo lving addition or multiplication. There are 288 propositions in the modular arithmetic ntask. We tried matr ices of various sizes and discovered that 4  X  4 matrices gave the best generalization when some of the cases are held-out. We held-out 30 , 60 , or 90 test cases chosen at random and used the remaining cases to le arn the real-valued entries of the 12 matrices that represent numbers and the 24 matrices that represent relations. The learning was performed by gradient descent in the cost fu nction in Eq. 1. We repeated this five times with a different random selection of held-out cases ea ch time. Table 1 shows the number of errors on the held-out test cases. To learn the parameters, we used the conjugate gradient opti mization algorithm available in the  X  X cipy X  library of the Python programming language with the default optimization parameters. We computed the gradient of the cost function on all of the train ing cases before updating the parameters, and initialized the parameters by a random sample from a sphe rical Gaussian with unit variance on each dimension. We also included  X  X eight-decay X  by addin g 0 . 01 results is due to the nonconvexity of the objective function . The implementation is available in [www.cs.utoronto.ca/  X  ilya/code/2008/mre.tar.gz].
 Table 1: Test results on the basic modular arithmetic task. E ach entry shows the number of errors on the randomly held-out cases. There were no errors on the tr aining set. Each test query has 12 possible answers of which 1 is correct, so random guessing sh ould be incorrect on at least 90% of the test cases. The number of held-out cases of each run is wri tten in brackets.
 Figure 1: (a) Two isomorphic family trees (b) An example of a s ituation in which the discriminative cost function in Eq. 1 causes the matrix RA produced by MRE to be far from the correct answer, B (see section 5).
 In an attempt to improve generalization, we tried constrain ing all of the 4  X  4 matrices by setting half of the elements of each matrix to zero so that they were ea ch equivalent to two independent 2  X  2 matrices. Separate experiments showed that 2  X  2 matrices were sufficient for learning either the mod 3 or the mod 4 version of our modular arithmetic task, s o the mod 12 version can clearly be done using a pair of 2  X  2 matrices for each number or relation. However, the gradient optimization gets stuck in poor local minima. 1(a) where the relations are { has husband, has wife, has son, has daughter, has father, has mother, has brother, has sister, has nephew, has niece, has uncle, has aunt } . Notice that for the last four relations there are people in the families in figure 1(a) for w hom there are two different correct answers to the question ( A, ? )  X  R . When there are N correct answers, the best way to maximize the sum of the log probabilities of picking the correct answe r on each of the N cases is to produce an output matrix that is equidistant from the N correct answers and far from all other answers. If the designated correct answer on such a case is not among the N closest, we treat that case as an error. If we count cases with two correct answers as two diffe rent cases the family trees task has 112 cases.
 We used precisely the same learning procedure and weight-de cay as for the modular arithmetic task. We held-out 10, 20, or 30 randomly selected cases as tes t cases, and we repeated the random selection of the test cases five times. Table 2 shows the numbe r of errors on the test cases when 4  X  4 matrices are learned for each person and for each relation. M RE generalizes much better than the Table 2: Test results on the basic family trees task. Each ent ry shows the number of errors on the randomly held-out cases. There were no errors on the trainin g set. The same randomly selected test sets were used for the 4  X  4 matrices. Each test query has 24 possible answers, of which a t most 2 objects are considered correct. As there are 24 objects, ran dom guessing is incorrect on at least 90% of the cases. feedforward neural network used by [3] which typically gets one or two test cases wrong even when only four test cases are held-out. It also generalizes much b etter than all of the many variations of the learning algorithms used by [8] for the family trees ta sk. These variations cannot achieve zero test errors even when only four test cases are held-out a nd the cases are chosen to facilitate generalization. We used a version of the modular arithmetic task in which the o nly basic relations were ing of 36 propositions, examples of which are (3 , +3)  X  plus ; (3 , +9)  X  minus ; (+3 , +9)  X  inverse . We then held-out all of the examples of one of the basic relati ons and trained 4  X  4 matrices on all of the other basic relations plus all of the higher-order rel ations.
 Our first attempt to demonstrate that MRE could generalize fr om higher-order relations to basic relations failed: the generalization was only slightly bet ter than chance. The failure was caused by a counter-intuitive property of the discriminative object ive function in Eq. 1 [9]. When learning the higher-order training case (3 , +3)  X  plus it is not necessary for the product of the matrix representin g 3 and the matrix representing plus to be exactly equal to the matrix representing +3 . The product only needs to be closer to +3 than to any of the other matrices. In cases like the one shown i n figure 1(b), the relative probability of the point B under a Gaussian centered at RA is increased by moving RA up, because this lowers the unnormalized probabilities of C and D by a greater proportion than it lowers the unnormalized probability of B . The discriminative objective function prevents all of the representations collapsing to the same point, but it does no t force the matrix products to be exactly equal to the correct answer. As a result, the representation of +3 produced by the product of 3 and plus does not work properly when it is applied to a number.
 To overcome this problem, we modified the cost function for tr aining the higher-order relations so that it is minimized when  X  RA is exactly equal to B where  X  R ranges over  X  R , the set of all higher-order relations, and A and B can be either relations or basic objects, depending on  X  R  X  X  domain.
 Even when using this non-discriminative cost function for t raining the higher-order relations, the matrices could not all collapse to zero because the discrimi native cost function was still being used for training the basic relations. With this modification, th e training caused the product of 3 and plus to be very close to +3 and, as a result, there was often good generalization to basi c relations even when all of the basic relations involving +3 were removed from MRE X  X  training data and all it was told about +3 was that (3 , +3)  X  plus , (9 , +3)  X  minus , and (+9 , +3)  X  inverse (see table 3). Table 3: Test results on the higher-order arithmetic task. E ach row shows the number of incorrectly answered queries involving a relation (i.e., +1 , +4 , +6 , or +10 ) all of whose basic examples were removed from MRE X  X  training data, so MRE X  X  knowledge of this relation was entirely from the other higher-order relations. Learning was performed 5 tim es starting from different initial random parameters. There were no errors on the training set for any o f the runs. The number of test cases is written in brackets.
 involving a relation are held-out (i.e., has father , has aunt , has sister , or has nephew ). Each row shows the number of errors MRE makes on these held-out propos itions on 5 different learning runs from different initial random parameters. The only informa tion MRE has on these relations is in the form of a single higher-order relation, higher oppsex . There were no errors on the training sets for any of the runs. The number of held-out cases is written in bra ckets. To demonstrate that similar performance is obtained on fami ly trees task when higher-order relations are used, we included in addition to the 112 basic relations t he higher-order relation higher oppsex . To define higher oppsex we observe that many relations have natural male and natural female versions, as in: mother-father, nephew-niece, uncle-aunt , brother-sister, husband-wife, and son-daughter. We say that ( A, B )  X  higher oppsex for relations A and B if A and B can be seen as natural counterparts in this sense. Four of the twelve examp les of higher oppsex are given below: We performed an analogous test to that in the previous sectio n on the higher order modular arithmetic task, using exactly the same learning procedure and learnin g parameters. For the results, see table 4.
 The family trees task and its higher-order variant may appea r difficult for systems such as MRE or LRE because of the logical nature of the task, which is made ap parent by hard rules such as ( A, B )  X  has father , ( A, C )  X  has brother  X  ( C, B )  X  has father . However, MRE does not perform any ex-plicit logical deduction based on explicitly inferred rule s, as would be done in an Inductive Logic Programming system (e.g., [7]). Instead, it  X  X recomputes t he answers X  to all queries during training, by finding the matrix representation that models its trainin g set. Once the representation is found, many correct facts become  X  X elf-evident X  and do not require explicit derivation. Humans may be using a somewhat analogous mechanism (thought not necessar ily one with matrix multiplications), since when mastering a new and complicated set of concepts, s ome humans start by relying heavily on relatively explicit reasoning using the definitions. Wit h experience, however, many nontrivial correct facts may become intuitive to such an extent that exp erts can make true conjectures whose explicit derivation would be long and difficult. New theorem s are easily discovered when the repre-sentations of all the concepts make the new theorem intuitiv e and self-evident.
 Table 5: Test results for the higher-order arithmetic task ( top) and the higher-order family trees task (bottom) when a held-out basic relation is learned from high er-order propositions after the rest of the objects and relations have been learned and fixed. There were no errors on the training propositions. Each entry shows the number of test errors, and the number of t est cases is written in brackets. Figure 2: A neural network that is equivalent to Matrix Relat ional Embedding (see text for details). This is analogous to the idea that humans can avoid a lot of exp licit search when playing chess by  X  X ompiling X  the results of previous searches into a more c omplex evaluation function that uses features which make the value of a position immediately obvi ous.
 This does not mean that MRE can deal with general logical data of this kind, because MRE will fail when there are many relations that have many special cases. T he special cases will prevent MRE from finding low dimensional matrices that fit the data well an d cause it to generalize much more poorly. The previous section shows that MRE can learn to apply a basic relation correctly even though the training set only contains higher-order propositions abou t the relation. We now show that this can be achieved incrementally. After learning some objects, basi c relations, and higher-order relations, we freeze the weights in all of the matrices and learn the matrix for a new relation from a few higher-order propositions. Table 5 shows that this works about as we ll as learning all of the propositions at the same time. Consider the neural network shown in Figure 2. The input vect ors R and A represent a relation and an object using a one-of-N encoding. If the outgoing weights from the two active input units are set to R and A , these localist representations are converted into activi ty patterns in the first hidden layer that represent the matrices R and A . The central part of the network consists of  X  X igma-pi X  units [12], all of whose incoming and outgoing connections h ave fixed weights of 1 . The sigma-pi units perform a matrix multiplication by first taking the pro ducts of pairs of activities in the first hidden layer and then summing the appropriate subsets of the se products. As a result, the activities in the next layer represent the matrix RA . The output layer uses a  X  X oftmax X  function to compute the probability of each possible answer and we now show that i f the weights and biases of the output units are set correctly, this is equivalent to picking answe rs with a probability that is proportional to their probability density under a spherical Gaussian cente red at RA . Consider a particular output unit that represents the answer B . If the weights into this unit are set to 2 B and its bias is set to The probability that the softmax assigns to B will therefore be: Maximizing the log probability of p ( B | R, A ) is therefore equivalent to minimizing the cost function given in Eq. 1.
 The fact that MRE generalizes much better than a standard fee dforward neural network on the family trees task is due to two features. First, it uses the same repr esentational scheme (i.e., the same matrices) for the inputs and the outputs, which the standard net does not; a similar representational scheme was used in [1] to accurately model natural language. Second, it uses  X  X igma-pi X  units that facilitate multiplicative interactions between represen tations. It is always possible to approximate such interactions in a standard feedforward network, but it is often much better to build them into the model [13, 5, 11].
 Acknowledgments We would like to thank Alberto Paccanaro and Dafna Shahaf for helpful discussions. This research was supported by NSERC and CFI. GEH holds a Canada Research Ch air in Machine Learning and is a fellow of the Canadian Institute for Advanced Research.

