 Fl X via Linhalis  X  Renata Pontin de Mattos Fortes  X  Dilvan de Abreu Moreira Abstract This paper is about the use of natural language to communicate with computers. Most researches that have pursued this goal consider only requests expressed in English. A way to facilitate the use of several languages in natural language systems is by using an interlingua. An interlingua is an intermediary representation for natural language information that can be processed by machines. We propose to convert natural language requests into an interlingua [universal networking language (UNL)] and to execute these requests using software components. In order to achieve this goal, we propose OntoMap, an ontology-based architecture to perform the semantic mapping between UNL sentences and software compo-nents. OntoMap also performs component search and retrieval based on semantic information formalized in ontologies and rules.
 Keywords Ontologies  X  Interlingua  X  Software components  X  Natural language applications 1 Introduction The desire of human beings to communicate with machines is evidenced by several research works that have been carried out since the late 1970s. Much of this research has been focused on the goal of executing user requests expressed in restricted natural language. Despite of the intuitive appeal of natural language for interaction, a language like English has too many ambiguities to be useful for communicating with computers. A limited solution to this prob-lem is to restrict the input to simple algorithmic representations, as a way to reduce ambiguity [ 1 , 18 ]. More recently, however, some researchers have used software components or software agents, related to a specific application domain, to get a higher level of semantic abstraction [ 4 , 10 , 11 , 15 , 24 ]. For example, high level semantic abstraction requests could be: (a)  X  X dd student John Smith to the Hypermedia course X .
 (b)  X  X end an e-mail to the students of Operating Systems course saying that the test will be
In order to use natural language to interact with computers, most functionality of nat-ural language-based applications can be implemented by software components or agents. Requests can be expressed in natural language and executed by a suitable component/agent, which is related to a specific application domain [ 4 , 15 ].

Other problem that is faced by natural language-based applications is that, most of them, accept only one language in their interfaces X  X sually English. The difficulty to work with more than one natural language exists because each language has its own particularities, which complicates the adaptation of natural language-based applications.

A way to avoid ambiguity and to bring flexibility, allowing the use of several natural languages, is by using an interlingua. An interlingua is an intermediary representation for natural language information that can be processed by machines [ 28 ].

Using an interlingua, the same sentence, expressed in several natural languages, will have the same representation. Thus, if you have a sentence written in English and the same sentence written in Spanish, both of them will have the same representation because the interlingua represents only the meaning of the sentences [ 26 , 28 ].

One example of interlingua is the universal networking language (UNL). The UNL project aims to embody, in the cyber world, the functions of natural languages used in human com-munication. But, different from natural languages, UNL expressions can be unambiguous. Using UNL, people can express knowledge conveyed in several natural languages (English, French, Spanish, Portuguese, and so on). It also enables computers to intercommunicate, pro-viding a linguistic infrastructure for distributing, receiving and understanding multilingual information [ 28 ].

Universal networking language suffers from the same drawback of other interlinguas: to be unambiguous it restricts what can be said (for instance, UNL represents only the three basic verbal tenses: past, present and future). This is a big disadvantage for translation sys-tems but not so much for computer interfaces, as this form of interaction is far simpler than normal human interaction.
 Using software components and UNL, we propose a new architecture, the OntoMap Architecture, to process natural language requests based on UNL and to search for suitable software components to execute them. In the literature, there are some proposed systems that execute natural language requests [ 2 , 4 , 15 ]. OntoMap X  X  differential and main contribution is that natural language requests are first converted into UNL, enabling support for several natural languages.
 In order to be able to search for components that can execute natural language requests, OntoMap infers semantic information about components using the UNL representation of requests, and uses this inferred semantic information to search for one or more suitable com-ponents (to execute the request). To achieve this goal, OntoMap relates UNL constructs with software components, what is being called here the Semantic Mapping between UNL and components.

In order to enable computers to intercommunicate and efficiently  X  X nderstand X  multilin-gual information, it is necessary to provide semantics to natural language-based applications. This can be achieved by using ontologies. An ontology [ 8 ] is commonly used as a struc-ture to represent knowledge about a certain area, providing relevant concepts and relations between them. Ontologies have received special attention of researchers from computer sci-ence academic and industrial communities. The reason is that ontologies have been used to provide meaning for applications concerning several areas of computer science. According to Richards [ 19 ], knowledge acquisition is a difficult task and it is often referred to as the bot-tleneck in the development of knowledge-based systems. In acquiring knowledge, we are seeking to capture the conceptual model of domain experts and build a system that can solve problems. To capture the experts X  conceptual model, we need a means of communication at the semantic level. Ontologies are seen to offer such a channel by allowing concepts within a domain of interest to be defined and structured.

Ontologies have an important role in the OntoMap Architecture. We use an ontology (named InterComp), together with rules, to define the relationships between an interlingua and software components. We also use ontologies to perform the search and retrieval of software components to execute the natural language requests.

This paper is organized as follows: next section presents related work. To better under-stand OntoMap Architecture, it is necessary to provide a brief background about the UNL interlingua and project. Section 3 provides this background. Section 4 presents the OntoMap Architecture and its three main modules (UNL Conversion, Semantic Mapping and Compo-nents Search and Retrieval), described in Sects. 4.1  X  4.3 . Section 5 presents an application of OntoMap in the course management domain. Section 6 concludes the paper and emphasizes the main contributions of this work. Finally, Sect. 7 presents some remarks on future work. 2 Related work The literature has evidenced that restricted natural language can be used to describe user requests to be processed by machines. Some of the published work in this area use input requests in algorithm like form, which is not our objective. Like in our work, some research-ers use software agents or components to get a high semantic abstraction level for the natural language requests. If components or agents are going to be used to execute requests, it is also necessary to search for the suitable ones, which is generally done by using semantic information about the components or about the application domain. According to this expla-nation, the works related to this one can be divided into two groups: components to execute natural language requests expressed in an interlingua, and component search and retrieval using ontology semantics. 2.1 Components to execute natural language requests expressed in an interlingua In the literature, there are several systems that use natural language to communicate with applications and software agents or components to execute actions related to the natural lan-the requests in many natural languages. In this section, we are going to describe works that also translates natural language requests into an interlingua, which makes them very close to our purposes.

Open agent architecture (OAA) [ 4 , 31 ] is a framework for constructing agent-based sys-tems that makes it possible for software services to be provided through the cooperative efforts of distributed collections of agents. OAA provides an interface that accepts natural language requests as input. The requests are converted into interagent communication lan-guage (ICL), a prolog-based language. ICL is used, by the agents, to communicate with each matching ICL requests to choose the most suitable agents to execute the requests. It is clear that ICL works like an interlingua, but different from our approach, OAA does not use an explicit ontology. Thus, it does not take advantage of the semantic structuring that ontologies can bring to natural language applications.
The Semantic Agent platform [ 15 ] uses agents, implemented as software components, to execute actions. Users can express their requests in natural language. First, the request is converted into universal communication language (UCL) interlingua, which is a UNL-based language that is represented in XML. Then, the UCL request is processed by the agents to satisfy the request. All the agents can communicate and there is a facilitator agent, which knows the address of all agents registered in the system. The Semantic Agent knowledge base is an upper ontology. It is possible to link the software components of the platform with concepts in this ontology.

The Semantic Agent platform has some common aspects with OntoMap. For example, it uses an interlingua and software components to execute requests expressed in natural language. However, OntoMap is more flexible when working with different domains. The limitation of the Semantic Agent platform, which evidences this fact, is that it uses an upper ontology to convert requests into UCL. To use a particular word in the natural language request, this word has to be a concept in this upper ontology. This fact limits the possibility to work with different domains, because the natural language requests are dependable on the concepts in the upper ontology. 2.2 Component search and retrieval using ontologies Ontologies have been used to help the component search and retrieval using semantic descrip-tions about their functionality.

Sugumaran and Storey [ 22 ] use a semantic-based approach to component retrieval. Their system makes use of domain models containing the objectives, processes, actions, actors, and an ontology of domain terms, their definitions, and relationships with other domain-specific terms. A reuse repository was developed containing relevant components for the creation of new applications, along with their attributes and methods. Using natural language, a user can specify the requirements of a component he/she wishes to use. The natural language query is mapped into a SQL-like language. The domain ontology is used to refine and enhance the query, which is decomposed into processes and actions (methods). The decomposed query is then compared with the capacities of the components in the repository. The percentage of actions supported by a particular component or object indicates how relevant it is to that requirement.

In Sugumaran and Storey system an ontology is used to provide a way to  X  X nderstand X  what a software component can do. The ontology provides additional information about a component, and this information can lead a search engine to consider that component suit-able according to the requirements specified by the user. In this way, the ontology is used to increase the meaning of the terms to provide a complete and relevant answer to user queries. OntoMap has some related points with Sugumaran and Storey system, like the use of natural language and ontologies. Their system takes into account some measures to classify compo-nent relevance, which is not addressed in OntoMap yet. However, in their system, the search requirements are specified in English, while in ours they are extracted from an interlingua, which allows the search requirements specification in many natural languages.

Yao and Etzkorn [ 30 ] use a semantic-based approach to improve component reuse. Their work extends reusable software libraries to the web and allows users to specify queries in natural language. In their work, a component is treated as a service, described by a seman-tic service representation format. In order to perform the search and retrieval, they use an ontology to perform the matching between the user query semantic representation and the semantic description of the components. They propose methods to improve software search and retrieval in two cases: software component libraries and the WWW. Like in OntoMap, they also use ontologies to describe component semantics and natural language to specify user queries. But their main objective is to improve component reuse, while ours is to search for suitable components to execute users X  natural language requests. In our case, the use of an interlingua is an important differential.

Like in OntoMap, Khemakhem et al. [ 12 ] define an ontology to perform the search and retrieval of software components. According to Khemakhem et al., the ontologies can be used to describe component semantics related with three aspects: internal structure and rela-tionship, functional aspects provided by the component interface, and non functional aspects like performance, security and so on. These aspects represent different and complementary views of a component. Their formalization in ontologies depends on the kind of information one needs to obtain.

Khemakhem et al. defined two ontologies that meet the three aspects described above: (1) discovery ontology: describes the functional and non functional aspects of a component to organize repositories; (2) integration ontology: specifies structural aspects necessary to integrate a component in an application. The first ontology is used by a tool, named search engine for components (SEC), to search for components according to requisites specified by a developer.

The component ontology developed in OntoMap describes the functional aspects of com-ponents, which is the only relevant aspect when we want to consider the search to satisfy natural language requests. So, the differential between our work and Khemakhem et al. is that their objective is to search for components to compose an application, and our objective is to search for components to satisfy a natural language request. Different from our work, theirs do not specify queries in natural language.

The systems presented in this session are the most related to ours because they use ontologies to improve software component search and retrieval, and some of them also use natural language to specify queries. But, there are many other works that use ontolo-gies to describe objects or components. Some examples are: component service model with semantics (CoSMoS) [ 6 ], SOTA [ 3 , 13 , 17 , 24 , 29 ].

Ta b l e 1 presents a summarized comparison between the OntoMap Architecture and other relevant systems in the literature, considering aspects related to natural language requests execution, to the use of interlingua, and to component search and retrieval. 3 The UNL project The UNL project [ 26 , 27 ] was created in 1996 by the Institute of Advanced Studies of the United Nations University (IAS/UNU), in Tokio. The project proposed an interlingua, named UNL, which has sufficient expressive power to represent relevant information conveyed by natural languages in a machine processable manner.

For each language, two systems should be developed: an EnConverter (EnCo) to convert natural language texts into UNL, and a DeConverter (DeCo) capable of translating texts from UNL to a target language. The enconverting and deconverting processes use a dictionary and grammar rules for each natural language. The DeCo and EnCo for each language form a language server residing somewhere in the Internet. All language servers will be connected to allow any Internet user to deconvert an UNL document found on the web into his/her native language, as well as to produce UNL representations of the texts he/she wishes to make available to the whole Internet community.

The project embraces several universities and research institutions that have been devel-oped language servers to 16 languages. Brazilian Portuguese is one of these languages and an UNL partner since 1997, through Interinstitutional Center for Computational Linguistics (NILC), a research group and laboratory from our institute. In OntoMap, we used a UNL EnCo, named Hermeto [ 16 ], which was developed by the NILC laboratory group.

Universal networking language is not the first language created to translate texts using an intermediary representation (interlingua). Another examples of this same idea can be found in academic and commercial translators, like ATLAS [ 25 ], SYSTRAN 1 [ 7 ], and Ergane. 2 This last one uses Esperanto 3 as interlingua.

We chose UNL to our work not only because we have a neighbor group that worked on it, but also because UNL has a noble objective. Its goal is not simply to create an interlingua to perform text translation, but to reduce the language barriers in the Internet community, which is still segregated by language boundaries. Theoretically, this seems to be the major obstacle standing in the way of international and interpersonal communication in the infor-mation society. The United Nations initiated the UNL project aiming to solve or to reduce this problem [ 27 ].
 The rest of this section in about the UNL language. It is important to understand how UNL works to understand how the semantic mapping proposed in the OntoMap Architecture is performed.

UNL represents natural language sentences using three elements [ 28 ]:  X  Universal Words (UWs): each UW is a concept that is represented by an English word.  X  Relation Labels (RLs): RLs express semantic relations between UWs. There are cur- X  Attribute Labels (ALs): ALs express additional information about UWs, such as verb
The following shows an example of UNL expression for the sentence I can hear a dog barking outside [ 28 ]: an attribute of the UW hear. a dog barking outside is expressed by a scope, and 01 is given as the Scope-ID. :01 appears in the position of a UW to refer to the scope. The scopes can be seen as links between the parts of a sentence.

The concepts are grouped into categories to provide semantics to UWs. There are four categories: nominal concept, verbal concept, adjective concept and adverbial concept. Each category has a hierarchical structure of concepts that defines how each concept can be used to represent knowledge in natural language sentences. Such hierarchical structure is named UWs System and it is the basis of the UNL knowledge base (UNL KB) [ 28 ]. In the UNL KB, all the UWs are linked to each other by subclass-of (icl), instance-of (iof) and equivalence (equ) relations, giving rise to an implicit ontology. In the UWs System, all the feasible relations that an UW can have with others, such as agent (agt), object (obj), etc., are defined using upper concepts. Using the inheritance property of the UWs System, feasible relations with lower concepts can be inferred.

A complete description of UNL can be found at UNL specification [ 28 ] and at UNDL foundation web site. 4 4 OntoMap general view The basic OntoMap goal is to process natural language requests and find software components to execute them. To achieve that, it makes the Semantic Mapping between UNL interlingua requests and software component concepts, and uses these concepts to search for and to activate suitable components (to execute the requests).

OntoMap main modules are illustrated in Fig. 1 : UNL Conversion , Semantic Mapping between UNL and Components (or simply semantic mapping), and Component Search and Retrieval .

The UNL Conversion Module converts natural language requests into UNL. The Seman-tic Mapping Module uses the UNL representation of a request to infer semantic information about possible components to execute it. The Component Search and Retrieval Module uses the inferred semantic information to search for possible components to execute the request. The three modules of the OntoMap Architecture are detailed in the following Sects. 4.1  X  4.3 . 4.1 UNL conversion The UNL Conversion Module is illustrated in Fig. 2 . It provides a service (EnCo) to convert natural language requests into UNL. The service uses a dictionary and a grammar of the target language to perform the conversion.

The UNL conversion module goal is to serve as an interface between natural language applications and an UNL EnCo. With this module, natural language based applications can use an EnCo to perform the conversion of natural language into UNL. An EnCo, named Her-meto [ 16 ], developed at Interinstitutional Center for Computational Linguistics (NILC), were used in the OntoMap architecture to perform UNL EnConversion.
 Tables 2 and 3 show parts of a dictionary and of a grammar developed to serve as input to Hermeto EnCo. We do not intend to detail the EnCo grammar and dictionary syntax, which can be obtained at Martins et al. [ 16 ]. These examples are included in this paper to show some particularities of UNL grammars and dictionaries as explained below.

In the dictionary, synonyms, instances, super and subclasses relations can be defined. In the dictionary example of Table 2 , the verbs add , include and insert are considered synonyms, because they are represented by the same concept (the verb add ). It means that, if the input sentence is  X  Insert student Mary...  X , the EnCo will use the concept add in the output sen-tence. Another important aspect of the dictionary is that it contains an implicit ontology. It can be observed, e.g., that for the entries student and user , the EnCo generates the outputs subclasses of person .

Table 3 shows grammar rules defined for two imperative sentences. The first one ( IMP[1] ) starts with a verb, followed by two nouns; and the second one starts with a verb followed by two nouns, a preposition and two nouns. Valid sentence examples to IMP[1] and IMP[2] could be  X  Create student Mary  X  X nd X  Add student Mary to Java course  X . It is important to observe that the grammar contains the UNL relations that are going to be used in the output sentences. For example, in IMP[1] , these relations are obj(:01,:02) and nam(:02,:03) . Thus, to write a UNL grammar, it is necessary to know the target language and the UNL language.

The EnCo uses the grammar rules and the dictionary entries to generate the UNL output. For example, to the input sentence  X  X reate student Mary X , the EnCo generates the output obj(cre-ate,student (icl &gt; person)) , nam(student icl &gt; person),Mary) . To generate this output, it firstly matches the input sentence with the grammar rule defined in IMP[1] . Then, it searches for the first word of the sentence ( create ) in the dictionary and puts its representation in the UW 1 position of obj relation. The same is done for the second word of the sentence ( student ), which representation in the dictionary is student(icl &gt; person) . This representation is placed in the UW 2 position of obj relation and in the UW 1 position of nam relation. All the words in the input sentence are precessed this way. If a noun is not defined in the dictionary, the EnCo assumes that it is a proper name ( ppn ) and puts it in the corresponding place in the output sentence. It happens, for example, to the noun Mary .

In OntoMap, the dictionary has to contain words (concepts) related to the functionalities implemented by a component set developed to work in a particular domain. The concepts in the dictionary should also be in the Domain Ontology, as detailed in Sect. 5.4 . In the dic-tionary example of Table 2 , only the concepts add , course , delete , person , student and teacher must be considered as concepts in the ontology, because the other dictionary words are synonyms, prepositions or articles and will not be part of the UNL output sentence. 4.2 The semantic mapping between UNL and components Before starting the semantic mapping, it is necessary to have software components that imple-ment a functionality set specific for an application domain. The semantic mapping is performed by indicating, for a set of UNL sentences, what is the semantic information that can be related to the software components. Such semantic information is compiled using UNL UWs (con-cepts) and UNL relations. UNL attributes are not used because they do not carry relevant semantic information to the search and retrieval of software components.

To clarify what is the semantic mapping and how it is performed, the imperative sentence  X  X elete student Mary from Java course X  will be considered as an example. A UNL EnCo can generate the following UNL representation of the sentence (attributes are not considered):
The first task to perform the semantic mapping is to analyze each UNL relation in the requests and relate their UWs with semantic information about the application software com-ponents. To the example given in (1), the relations object (obj), name (nam) and final state (gol) must be analyzed.

The analysis result is summarized in Table 4 , which shows the UNL relation, its generic meaning (according to the specifications), its meaning considering the sentence (1) and pos-sible information that can be inferred about components.

An analysis, like the one presented in Table 4 , must be done for all UNL relations that are part of the natural language requests for a specific natural language-based application. The analysis must consider the meaning of the relations and the functionality of the components developed for a particular application. Using this information it is possible to conclude how the UWs of the relations can be mapped to semantic information about the components. Such information must indicate if an UW is:  X  a concept related to a component;  X  a concept related to an argument;  X  a concept related to the return value of a method;  X  an action related to a method or
Figure 3 illustrates a possible semantic mapping between UWs and components, consid-ering the relations analyzed in Table 4 .
 In order to make the Semantic Mapping an automated process we developed the Semantic Mapping Module for the OntoMap Architecture (see Fig. 1 ). This module is illustrated in Fig. 4 . It is composed by the Token Classifier , the InterComp ontology and a set of rules . The InterComp ontology relates UNL interlingua with semantic information about software components. The Token Classifier classifies the tokens of a UNL sentence in InterComp. After the tokens are classified in the ontology, specific rules are fired to infer semantic information about components.

The rules depend on the specific functionality set implemented by the software compo-nents developed for an application domain. They have to be written by a human expert, which must consider how the UWs of UNL relations are related to semantic information about the components. In the following sections, the InterComp ontology, the Token Classifier and the rules are described. 4.2.1 The InterComp ontology Interlingua-Components (InterComp), illustrated in the class diagram of Fig. 5 , is an ontology that relates the UNL interlingua UWs and relations with semantic information about software components. This semantic information is inferred using specific rules and is used to help search engines to find suitable components to execute requests, which can be expressed in different natural languages.

It is important to notice that requests can be expressed in several natural languages because the InterComp ontology deals with them at the UNL interlingua level. This ontology does not contain language specific information, but interlingual information to represent the semantics of natural languages. The concepts in this ontology are expressed as English words because UNL uses mainly English to represent UWs (see Sect. 3 ).

In order to create this ontology, all relations in the UNL specifications were used [ 28 ]. Each relation has two or more relationships with generic concepts of the UWs System (UWs hierar-chical tree). Thus, InterComp ontology formalizes the relationships between the UNL relations and their generic concepts (UWs). The ontology also formalizes relationships between the generic UWs and software components to help the semantic mapping between UNL and com-ponents. The right side of Fig. 5 shows the main concepts of the UWs System hierarchy. The left side shows the relation hierarchy represented by their labels, with the super class relation (the super class of all UNL relations) on top. Each UNL relation has relationships with generic concepts of the UWs System. For example, according to the UNL specifications, the generic concepts (UWs) of relation object ( obj ) are the following: The UW 1 of relation object ( obj ) is always an event or a verbal concept ( be , do or occur ). UW 2 is always a subclass of the generic concept thing . The relationships between obj and its generic UWs are defined as objUW1 and objUW2 . The same pattern was followed for the relationships of the other UNL relations and their generic UWs. The InterComp ontology for-malizes such relationships to all UNL relations, but due to the great number of relationships, Fig. 5 shows only the object ( obj ) relation to make the diagram cleaner.

The class ComponentInfo has relations to associate component semantic information with UNL generic UWs, as shown in Fig. 5 . This relationships are about component interface information, i.e., concepts related to arguments, return values, methods, and argument values.
The relationships hasMainComponent and hasOtherComponents relate a UNL con-cept with a component. The former relationship is used when there is more than one possible component to be called. The UNL concept that these relationships are related to has always to be a noun, derived from the class thing in the ontology. For example, the UWs  X  X tudent X ,  X  X ourse X  and  X  X eacher X  could be related to components in a course management application. So, if these UWs appear in an UNL sentence, they will be classified according to hasMa-inComponent and hasOtherComponents relationships. In a similar way, the hasReturn relationship relates a noun (UNL concept) with the return value of a method.

The relationships hasParams and hasConcept are concerned about argument values and about concepts associated to these values. The argument values are classified under the UNL concept name in the ontology. For example, UWs like  X  X ohn X ,  X  X perating Systems X  and  X 3042890 X  are arguments values and should be classified according to hasParams relation-ship. These argument values are related to concepts. For example,  X  X perating Systems X  is the name of a course. The concept to which a parameter is related to is classified according to hasConcept relationship.

Finally, the hasAction relationship relates an action (verbal concept in the ontology) to a component method. For example, the UWs  X  X elete X ,  X  X ist X  and  X  X dd X  will be classified according to hasAction relationship.

All this information about components will be classified (stored) in the InterComp ontol-ogy after the rules are fired. So, the first step is to classify the UNL sentence tokens, which is performed by the Token Classifier (explained in the next section). The second step is to fire the rules, which will use the classified tokens (represented as instances or facts in the ontology) to infer how these tokens are related to components, i.e., if the token is an argument value, an action related to a method, and so on. The result of this inference is the creation of new facts in the ontology, which are going to be stored as relationship values (what we call slots) of class ComponentInfo instance, as explained in Sect. 4.2.3 . 4.2.2 The token classifier The Token Classifier receives a UNL sentence as input. Its task is to separate each sentence token and classify it in the InterComp ontology. This classification generates instances (facts) of the ontology classes. For the example given in (1), the Token Classifier creates the instances shown as colored boxes in Fig. 6 .

In order to create the instances shown in Fig. 6 , the Token Classifier first separates the token  X  X bj X , searches for the class  X  X bj X  in the ontology and creates instance obj-1. Then, the classifier separates the token  X  X elete X , follows the relationship objUW1 and creates the instance  X  X elete X  under class  X  X erbal concept X . The same is done to token  X  X tudent X , which instance belongs to class  X  X hing X , according to the relationship objUW2. This classification is performed for each UNL relation in sentence (1).

After the instances creation, the Token Classifier loads the rule file and an inference engine to run the rules, as explained in the next section. 4.2.3 The rules The semantic mapping must be formalized in rules by a human expert, i.e., it is necessary to write rules to relate UNL UWs to semantic information about a specific set of software components.
 The rules will be executed considering the facts (instances) of the InterComp ontology. The rules goal is to infer information about components, considering the semantics of UNL relations and their UWs, represented as instances. Table 5 shows four examples of Java expert system shell (JESS) 5 rules written for the relations name ( nam ) and object ( obj ).
The rules shown in Table 5 are production rules. The JESS rule engine uses a forward-chaining algorithm [ 5 ] to process them. The rules must be located in a file, separated from the ontology, because they can change according to the application domain component set.
The first rule in Table 5 can be interpreted as follows:  X  if there is any instance of class obj as an ontology fact, then store the value of its UW 1 ( objUW1 ) in the slot hasAction of instance ComponentInfo _ 1 X . If this rule fires, the action related to the component method is going to be inferred and stored in the slot hasAction . Considering that the ontology facts are the slot hasAction . Similarly, the instance student is going to be stored in the slot hasMain-Component , the instances Mary and Java are going to be stored in the slots hasParams ,and the instances student and course are going to be stored in the slot hasConcept to indicate that Mary and Java are related to the concepts student and course , respectively.
The rules execution result is the generation (through inference) of new facts in the ontology, more specifically, in the slots of class ComponentInfo and in the slot hasConcept . Figure 7 shows a RDF graph representing the inferred information, considering the instances shown in Fig. 6 and the rules in Table 5 . The inferred information is passed to a search engine, which searches for a suitable component method to execute the request.
 Discussion about the rules
The rules bring flexibility to the semantic mapping, but they limit the architecture indepen-dence. They bring flexibility because if the component set changes the InterComp ontology does not need adaptation, because the semantic mapping between UNL and components is formalized by the rules.

On the other hand, the rules limit the architecture independence because they must be rewritten by a human expert if the component set changes. For example, consider a com-ponent named  X  X tudent X , which has the method Vector getStudents() . The request  X  X ist students. X  is going to activate the mentioned method because the concept  X  X tudent X  (UW 2 of obj relation) would be related to the component  X  X tudent X  by the following rule: (defrule obj2 (object (is-a obj) (objUW2 ?y)) =&gt; (slot-set ComponentInfo_1 hasMainComponent ?y))
But, if the component set changes, the functionality of the component  X  X tudent X  may be substituted by a component named  X  X ser X , that contains the method Vector getUsers(String role) , where role can assume the values  X  X tudent X ,  X  X eacher X  and so on. In this case, the concept  X  X tudent X  would be related to the concept  X  X ole X , which is an argument. The aforementioned rule must change because the concept  X  X tudent X  is no more related to a component, but to an argument. The new rule would be the following: (defrule obj2 (object (is-a obj) (objUW2 ?y)) =&gt; (slot-insert$ ComponentInfo_1 hasParams 1 ?y)) 4.3 Component search and retrieval Figure 8 illustrates the Search and Retrieval Module. This module works with the Compo-nent Ontology ,a Domain Ontology and the Search Engine . The Component Ontology was developed to relate component interfaces with semantic information about their functionality. This information depends on the application domain each component belongs to. The appli-cation domain concepts are defined in the Domain Ontology. Using the ontologies, the Search Engine searches for suitable components and provides specific information about component execution to a component loader, which executes the methods to satisfy the natural language request. 4.3.1 The component ontology The Component Ontology holds semantic information related to component interface. Figure 9 shows the class diagram of this ontology.

The class Action contains imperative verbs related to component methods. The verbs defined in this class are in the dictionary. The class DomainConcept holds concepts from the application domain (that components belong to) that are also in the dictionary. The presence of the verbs and concepts in the dictionary is important because they are part of the UNL output that is going to be classified in the InterComp Ontology. The concepts held by the Doma-inConcept class may have relationships with each other, giving rise to a Domain Ontology. Thus, the DomainConcept class is the meeting point between the Component Ontology and a Domain Ontology.

The classes Component , Method and Parameter describe component interfaces, while the classes Action and DomainConcept hold semantic information about component functionality. The relationships between the first three classes and the last two ones relate component interfaces with semantic information.

The Component Ontology should be instantiated for each component set used. The Com-ponent Ontology is always the same, but its instances change according to each component functionality set. 4.3.2 The domain ontology The Domain Ontology describes the semantics of a particular application domain. Its concepts (application domain concepts) are identified using to the dictionary entries. Due to this fact, this ontology can change according to the domain vocabulary, which is related to component functionality. The Domain Ontology is linked to the Component Ontology through the DomainConcept class (see Fig. 9 ).

A Domain Ontology was developed to the course management domain to show an instan-tiation of OntoMap, as presented in Sect. 5.4 . 4.3.3 The search engine The Search Engine goal is to search for suitable components to execute requests. It receives as input, from the Semantic Mapping Module, the following information inferred based on the facts (instances) in the InterComp Ontology: an action, a concept(s) related to possible components to be called, arguments, concepts related to each argument and a concept related to the return value of a method. For example, considering the rules presented in Table 5 ,and the inferred information illustrated in Fig. 6 , the Search Engine receives the information pre-sented in Table 6 as input and uses it in conjunction with the information on the Component and Domain ontologies.

The following steps are performed by the Search Engine after receiving an input like the one showed in Table 6 : 1. It searches the Component Ontology for methods that are related to an action and to a 2. It checks the return type of the method. 3. It checks the concepts related to the method arguments. 4. It goes back to step 1, using another possible concept.

It is important to notice that, for the example given in (1), the semantic mapping extracts the student and the course names (Mary and Java). So, the Search Engine will initially search for methods that receive the names as arguments. But, suppose that there are no methods that receive names as arguments, but only IDs (which is often the case in components). In such cases, the search engine will consider not only the concept student, but also its properties in the Domain Ontology. The ontology represents, for example, the student concept, which has the properties name, ID, and so on. If no method that receives a name as argument is found, the search engine performs another search considering other properties of the concept.
If more than one suitable method is found, it shows all of them to the user and he chooses one. The information to execute the method is passed to a component loader. 5 OntoMap application in the course management domain The OntoMap Architecture was instantiated for an application in the course management domain, using imperative sentences. In order to implement this instantiation, we developed components related to the following concepts in the course management domain: Student, Teacher, Candidate, Administrator, Monitor, Course and Team. Each component has a well defined functionality related to the concept it is associated to. For example, the component that is related to the concept Teacher is  X  X esponsible X  for the execution of all actions related to a teacher, like create a teacher, delete a teacher, associate a course to a teacher, and so on.
The activities shown in Fig. 10 must be performed to instantiate the OntoMap Architec-ture. These activities were properly formalized as a software engineering process in Linhalis [ 14 ]. In the following sessions, we describe each process activity considering specifically the course management domain application. Readers who are interested in the general process definition, which can be used in several application domains with different component sets, should refer to Linhalis [ 14 ]. 5.1 Domain analysis In order to perform the domain analysis, we used the components developed to the course management application domain. A good documentation of the component interfaces was very important to understand their functionality and, consequently, to perform the domain analysis. The domain analysis comprised the following activities:  X  Component functionality analysis : in this activity, we analyzed the component  X  Domain vocabulary analysis : in this activity, a set of imperative natural language requests 5.2 Dictionary and grammar development This activity is about the development of dictionaries and grammars for the target languages. domain analysis (Table 7 ) and their synonyms. The grammars must consider all the imperative natural language structures identified in the domain analysis (some examples of these sen-tences structures are shown in Table 8 ). Tables 2 and 3 showed part of an English dictionary and grammar.
 After the development of the dictionaries and grammars we used an UNL EnCo, named Hermeto [ 16 ], to generate the UNL representation for all the sentences structures identified in the domain analysis. The UNL representation of the sentences was used to perform the semantic mapping, as explained in the next section. 5.3 Semantic mapping definition In this activity, we identified the semantic information about components in the UNL repre-sentation of the requests and we wrote rules to formalize this information.

The first step was to get each UNL relation in the UNL representation of each request and to indicate the information about components their UWs were related to. An example was demonstrated in Sect. 4.2 .

Afterward, rules were written in a separate file to formalize the semantic mapping. The rules and InterComp ontology instances (UNL relations and UWs) were used to infer semantic information about components to execute a particular natural language request.
 Figure 11 a shows the UNL representation of some sentences structures defined in Table 8 . Figure 11 b shows the information about components that the UNL sentences are related to (semantic mapping). Figure 11 c shows JESS rules, written according to the semantic mapping identified in Fig. 11 b. 5.4 Search engine adequacy The search engine works with semantic information about the target components inferred in the semantic mapping phase.

It uses two ontologies to perform the search and retrieval of the proper component (or components) to execute a request: the Domain Ontology and the Component Ontology. The Domain Ontology has concepts (nouns) identified in the domain analysis. The Com-ponent Ontology relates the component interfaces (components, methods, arguments and return values) with concepts in the Domain Ontology and with actions (imperative verbs), also identified in the domain analysis. The Domain Ontology, developed for this OntoMap Architecture instantiation, is illustrated in the class diagram of Fig. 12 . The Component Ontol-ogy, presented in Fig. 9 , was instantiated according to the component set developed for this application. This solution brings flexibility to the search engine, which can be easily adapted to different application domains. 5.5 Evaluation In the evaluation phase, we verified if the semantic mapping and the search engine were work-ing properly. To perform the evaluation we submitted each request, defined in the domain analysis, as input to our instantiation of the OntoMap Architecture and verified if the search engine was indicating the proper component method to execute the request. We evaluated 94 requests (defined in the Domain Analysis) and generated an evaluation report. Table 9 shows the evaluation report for the requests in Table 8 .
We verified that, with the proper set of rules, the correct semantic information about components was inferred and passed to the search engine. The methods to execute all the 94 requests defined in the Domain Analysis were properly discovered. However, there are some factors that can influence the quality of OntoMap results. These factors are the follow-ing:  X  The semantic mapping currently performed is dependent of the information given in the  X  Each component has to be associated to a concept with a well-defined role in the appli- X  The Domain Ontology has to be in accordance to component functionality. For example,  X  Before writing the rules, it is important to associate each component, method, argument
Most of the problems related to these factors can be avoided if the software engineering process defined to use OntoMap [ 14 ] is properly followed (see Fig. 10 ). But, even to a correct OntoMap instantiation, the natural language application users have to know the available func-tionalities. This is evidenced by the examples in Table 10 . This table shows a simple variation of two requests presented in Table 9 . These two requests were not addressed in the Domain Analysis, but they are apparently valid requests from the users X  point of view. 6 Conclusions and contributions The OntoMap Architecture project was undertaken to address the lack of mechanisms to exe-cute natural language requests that considered semantic information extracted of an interlingua. The advantage of using an interlingua is that it allows the creation of systems that are more independent from particular natural languages, allowing users to express natural language requests in their native language. As the UNL project matures, systems based on the OntoMap Architecture will be able to leverage UNL technologies to provide its services to a wider set of languages, not usually targeted by such systems, without having to be extensively rewritten. This natural language  X  X ndependence X  is one of the key contributions of OntoMap. The architecture presented in this paper proposes to infer semantic information, from the UNL interlingua representation of a request, which is used to search and retrieve software components to execute this request. The main contributions of the work described in this paper are:  X  The semantic mapping that relates an interlingua to software components to enable users  X  Several publications have evidenced that ontologies have been used in several areas of 7 Future work The OntoMap Architeture described in this paper can originate some interesting future work, such as the following:  X  The Tokens Classifier can be extended to consider restricted UWs. This can enrich the UNL  X  The OntoMap Architecture instantiation, described in Sect. 5 , was performed considering  X  Many of the steps described in Sect. 5 , about the OntoMap instantiation, can be performed  X  The OntoMap Architecture instantiation in the course management domain was considered References
