 Identifying user intention has always been one of the most challenging issues of search engines. What makes the problem even harder is that most Web users provide only short queries. Recent analysis of search engine logs has revealed that the average length of Web queries is only about 2.3 words [Silverstein et al. 1998]. This is a major obstacle in information retrieval X  X hat keywords should I put in the search box to get the information I really want? In other words, a decisive factor of the user search experience is the quality of query terms.

Search engines commonly employ term suggestion mechanisms to formulate and recommend related terms for users. In contrast to query expansion techniques, which modify queries automatically, term suggestion techniques provide less active but more comprehensive aid.

One conventional approach for term suggestion involves the extraction of cooccur-ring key terms from retrieved documents that are highly ranked. Such approaches are referred to as document-based approaches. To extract high-ranking terms, these approaches must ensure that the extracted terms are representative with correct com-pound word boundaries [Vectomova et al. 2006]. Another problem is that the retrieved documents might not be relevant to the queries. Furthermore, document-based ap-proaches cannot identify key terms that are highly semantically related, but that do not frequently cooccur in documents [Xu 1996]. A variation of the document-based approach is to consider the hyperlink graphs of terms [Gracia et al. 2008].
The second approach is log-based term suggestion, where the stored logs of previous users X  queries are investigated. Beeferman and Berge [2000] proposed a query cluster-ing method based on  X  X lick-through X  data. Each click-through record consists of a user X  X  query to the search engine and those URLs that the user actually visited within the list provided by the search engine. One can cluster queries with similar clicked URLs by treating click-through data set as a bipartite graph and identifying the mapping between queries and clicked URLs [Ma et al. 2008]. The main problem with log-based approaches is that a user normally browses only the most highly-ranked search re-sults, regardless of how long the result list might be. As a result, most queries are associated with only a few URLs that are already limited to the top list of the search engine, and many URLs are not associated with any queries. Thus,  X  X lustering queries submitted to search engines X  appears to be a rather under-explored problem. Although we could use the click history of a given user to improve his or her current search re-sults, this clicked set of documents is likely to be different from the documents relevant to the current query. Some differences also arise because we are aggregating clicks across users, who may simply disagree about which documents are relevant. Clearly, log-based approaches deserve further investigation.

Similar to the click-through approaches, [Zhao et al. 2010] proposed a method to ex-tract paraphrases from search engine query logs. The method first extracts paraphrase query-title pairs with the assumption that a search query and its corresponding clicked document titles stand for the same thing. It then extracts paraphrase query-query and title-title pairs from the query-title paraphrases with a pivot approach. This approach differs from [Ma et al. 2008] in that the paraphrases are extracted in each step using a binary classifier. The authors extracted more than 3.5 million pairs of paraphrases and showed they can be used to generate high-quality paraphrase patterns.

The third approach for term suggestion is to rely on ontologies inferred from lexical reference systems such as WordNet [WordNet; Budanitsky et al. 2006]. However, Word-Net is a manually constructed system based on individual words, using it to compute semantic relatedness on the basis of bigram or multigram words is of only limited bene-fit; moreover, the system is not easily updated. Given these difficulties, search term sug-gestions for most web search engines are generated primarily based on word completion rather than on semantically relevant keywords. That is, given the user query  X  X lobal warming, X  it could be valuable to be able to show additional search results like the related word  X  X reen energy X  rather than only phrases starting with  X  X lobal warming. X 
We propose enhancing the quality of search term suggestions by utilizing the collective intelligent embedded in user-intensive social media such as Wikipedia [Watts 1999; Jin et al. 2001]. We propose modeling the contributor expertise, and fusing this with multipartite graphs of five different types of pairs X  X ontributor-term, contributor-category, term-category, contributor-contributor and term-term. The hid-den networks that link Wikipedia X  X  contributors (i.e., article editors) to key terms on each Wikipedia page help us to estimate the semantic distance between any two terms. We calculate not only the relatedness of two terms through hyperlinks of the Wiki page or related links section on each Wikipedia page [Gracia et al. 2008], but also take the expertise knowledge inference and the hidden implicit linkage of terms, through the overall knowledge of contributors, into account. We find that modeling contributor expertise is crucial to constructing good term-relation graphs.

We implemented the proposed algorithms into a prototype system that shows a weighted suggested term-relation graph to users for a given search term. This allows users to easily visualize the semantic relationships between terms. These graphs can be used for search, regardless of the modality. In visualization, we can also change the center term of a graph to facilitate browsing based on the different semantic distances between the other terms. This complete implementation has made it possible for us to evaluate the performance of the algorithm and to compare it with the other approaches.
The rest of this article is organized as follows. We review related work in Section 2, and present the framework of our semantic graph-based term suggestion approach in Section 3. We provide details about how to construct the system in Section 4. In Section 5, we present a procedure for measuring the relative importance of suggested terms in the relational graph, to conduct interactive user-driven data retrieval. Section 6 reports the evaluation results of the proposed system based on a common dataset taken from TREC test data. In addition, since there are a large number of recent works on paraphrasing, such as Zhao et al. [2010]. We compare our approach with this approach as well to evaluate the effectiveness of our approach versus paraphrasing counterpart. Finally, we conclude this article and discuss our future research direction in Section 7. For cooccurrence-based term-to-term suggestion, the major factors affecting the perfor-mance of suggestion results are the term similarity measures and the selection criteria for additional search terms. We need to be very careful when we interpret and apply the results of this type of research because the obtained results may be influenced by the characteristics of the test collections. Many researchers have examined the cooccurrence based term-term characteristics of term similarity measures in various scenarios. Chung and Lee [2001] explored the characteristics of five similarity mea-sures in term clustering experiments and developed mutual information approaches for the task. Kim and Choi [2001] reported that, in their experiments, the search terms added by using Jaccard index, Dice, and Cosine similarity coefficients include more fre-quent terms with lower similarity values than the average conditional probability and normalized mutual information. It was also found that Jaccard, Dice, and Cosine mea-sures achieved better retrieval effectiveness than the other measures. However, with information retrieval techniques based on conventional cooccurrence modeling, terms are extracted using statistical approaches from the top documents that are returned in response to the original query. Whereas this approach has been shown to be effec-tive to some collections, results on large collections of Web data show that it does not reflect real user needs. Indeed, the rapid growth and change of the Web pages has in-troduced new challenges for Web queries. Our proposed term suggestion approach uses a sophisticated probabilistic algorithm derived from probabilistic information retrieval techniques. For instance, we extend the concept of Jaccard index similarity coefficient to our soft clustering algorithm to model the human collective intelligence embedded in Wikipedia. In this work, we address two important issues with term suggestion: the selection and the weighting of additional suggestion terms. In contrast to earlier approaches, our term suggestions are expanded by adding those terms that are most semantically related to the user X  X  query term, rather than merely selecting terms that typically follow the query. A major challenge of suggesting effective terms is how to ferret out the meaningful se-mantic relationships among terms [Salton and Buckley 1998]. Repository-based query expansion, which is highly dependent on the quality and relevance of the thesaurus, has been attempted using lexical reference systems such as WordNet, as stated in the intro-duction. However, WordNet-yielded term suggestion results are of limited value since WordNet is a manually-constructed system that focuses primarily on single words. The limitation lies in its inability to easily compute or update the semantic relatedness of bigram or multigram words. That is, a general-purpose repository is not specific enough to offer synonyms for words used in the corresponding document collection. Researchers have therefore attempted to use Wikipedia to replace WordNet as a more effective ontology. However, they tend to treat Wikipedia merely as an online dictio-nary and utilize it only as a structured knowledge database: they exploit the Wikipedia structure with text processing techniques [Gabrilovich and Markovitch 2005, 2006] or its associated hyperlinks [Milne et al. 2007; Wang and Domeniconi 2008], all the while ignoring the important role that Wikipedia has played in the rise of Web 2.0 appli-cations, which promote information sharing, interoperability and Web collaboration, and have underpinned the role of Web-based communities and contributor expertise in Wikipedia social networks [Shieh et al. 2009]. Recently, [Brandes et al. 2009] analyzed and visualized the networks representing the collaborative social process of Wikipedia editing. This kind of works focus on identifying the characteristics inherent to the structure and the community of Wikipedia. Wang et al. [2008] also introduced the feature-based transfer learning model, which incorporates a semantic kernel trained on the basis of Wikipedia categories. Xiang [2010] proposed a solution to incorporate background knowledge efficiently using the instance-based transfer perspective, which establishes a connection between transfer learning problems and traditional semisu-pervised learning problems. The primary contribution of our work is to show how to design a powerful algorithm that uses social network-derived weighting approaches to incorporate each contributor X  X  expertise in the output term suggestion relational graphs. Notably, in the approaches presented here, we have attempted to leverage this role that other term suggestion systems have so far ignored. One of the differences in search behavior between experts and common users is the way they formulate query statements. In general, experts need thorough information to form long and specific query term statements. Therefore, proper modeling of expert knowledge might make it possible for us to formulate useful concept-based term sugges-tions rather than probabilistic term frequency or click count-based term suggestions. However, the question becomes  X  How and where can we find these experts ? X 
A number of automatic expert-finding prototypes reported in the literature have used traditional information retrieval techniques. In their approaches, expertise is de-scribed in terms of a vector and does not include any relational information. NASA X  X  Expert Finder [Becerra-Fernandez 2001; Staab 2001] uses named-entity extraction to process employee resumes and documents as well as corporate newsletters, thus iden-tifying keywords to create expertise profiles. I-Help [Bull et al. 2001] models a user X  X  characteristics so that it can assist the user in identifying a peer who can help. To select the most appropriate peer for a particular request, it uses a matchmaking agent that communicates with the personal agents of other users by accessing various kinds of vector-based user information. Link analysis has long been studied as a way to capture relationships between entities [Wasserman and Faust 1995], For instance, both Google search engine [Page et al. 1998] and Kleinberg X  X  HITS algorithm [1998] use link analy-sis on the web to find  X  X ubs X  and  X  X uthorities X . Although both PageRank and HITS have topic drift problem, which makes the most in-links in the network tend to dominate. However, the success of these approaches has led to a flurry of research introducing link analysis into the traditional information retrieval area [Henzinger 2001]. In other works, researchers have proposed approaches to expert finding in social networks that take into consideration not only the information about which topic a person has edited but also the interpersonal relationships among experts [Lappas et al. 2009; Dmitriev et al. 2010]. However, information about a single topic is inadequate, as it does not include editing behavior for other terms related to the key term. Moreover, although based on the propagation theory it may make use of interpersonal relationships to improve the accuracy of  X  X mportant contributor X  finding, it is still unable to identify a person X  X   X  X xpertise. X  We leverage the social network structure of Wikipedia by using multimodal link analysis to mine and estimate contributors X  expertise. Our approach includes two major parts: personal specialization weights obtained via link analysis of contributor and categories, and the combination of relationships between contribu-tors with common interests and their personal specialization weights to improve the accuracy of expert finding. The corresponding expertise information for contributors is calculated based on the list of changes in his or her  X  expertise fields  X  that the contributor has made, which can be found in the history section of each Wikipedia topic. Information retrieval systems should not only provide efficient retrieval, but should also support the user in describing a question that he or she does not understand well. A good term-suggestion process could not only provide good query terms, but also support iterative dialog interaction between users and the system. That is, users are engaged in the problem solving process, such as finding relevant information, and the result refinement process, through continuous responding to the intermediate query results. Unfortunately, choosing an appropriate set of terms to a user as suggestions for query refinement remains a difficult task. Thesauri may not exist for public access and statistical approaches, such as relevance feedback, require users to validate the relevance of articles in a candidate list, which is a task believed to be difficult. More-over, there are typically hundreds of terms that are potentially relevant to a specific query; without some structure imposed upon the terms, it would be nearly impossi-ble for a user to inspect more than a handful. This is the reason why we try to build up relational graph incorporating expertise with term suggestion. Meanwhile, using paraphrase can also assist search. Paraphrases are alternative ways of expressing the same information. Being able to extract or generate paraphrases automatically is use-ful in a wide range of natural language applications. The recent work Zhao et al [2010] have shown how paraphrases can improve question answering (QA) through query expansion, automatic evaluation of translation and summarization by modeling alter-native lexicalization, and machine translation both by dealing with out of vocabulary words and phrases and by expanding the set of reference translations for minimum error rate training. While all applications require preserving the meaning when a phrase is replaced by its paraphrase, some additionally require the resulting sen-tence to be grammatical. Existing approaches to paraphrase evaluation include human evaluation, automatic evaluation, and application-driven evaluation. Large scale eval-uation is still an open issue. The proposed framework includes eight components, as illustrated in Figure 1. Given a search term, we perform a form of data sampling on the Wikipedia networks. We crawled thousands of Wikipedia articles to obtain hyperlinks and author information from topic histories in which nodes are contributors and terms, and edges are between contributors and each of the terms to which they have contributed.

Data sampling starts from the query keyword. First, the system collects all the terms that exist as concept links within the page of the query keyword. We then identify the contributors for these terms to construct the previously mentioned  X  X irtual X  social net-work and continue to identify even more terms on the basis of these contributors. We repeat this process iteratively to glean a large set of related terms and contributors. After data sampling, we construct a multipartite network composed of layers of con-tributors and terms like that shown in Figure 2. We also go on to construct multipartite term-category networks and hyperlink-based term-term single-partite networks.
We then apply a soft clustering technique to fold these networks into a term relation-ship graph called the related-term graph. In this graph, terms are expressed as nodes and edge weights correspond to the degree of semantic relatedness among terms.
Furthermore, we crawl the contributor histories in Wikipedia to construct the contributor-category networks based on their editing histories to infer the expertise of individual contributors. The expertise distributions help us to determine the edge weights of the related-term graph.

Cosine similarity is effective for divergence measurements in several scenarios [Zhang et al. 2002]. We first use it to analyze term-category relationships in Wikipedia to calculate the specialization level of each contributor to each term X  X he degree to which a given contributor is focused solely on a given term. Then, using ensemble fusion, we capture the relationship between different modalities in the Wikipedia and adjust the edge weights of the semantic relatedness graph accordingly. These finer edge weights are used to determine a form of semantic similarity between any two terms, which can be further used to calculate the relative importance and the resultant rank of a term with respect to another given term, in a similar fashion to PageRank with Priors.

We suggest additional search terms to the user by showing the related-term graph through the visualization interface, then the retrieval process can be user-driven and interactive.

Note that a limitation of the proposed system is that related-term graphs can only be generated if the terms already existed in Wikipedia. One helpful approach to resolve this problem is to combine the related-term graphs with other document-based and log-based approaches to make sure all terms have related graphs; however, this is beyond the scope of this article. We also want to point out that a thorough real-time use of this system would require periodic large-scale crawling of the Wikipedia to construct graphs beforehand. However, Large-scale Wikipedia crawling would require significant computing resources that are normally not affordable in academic settings. Therefore, during our prototype construction, we limited the number of involved terms and generated the related-term graphs off-line. For conducting experiments, we also developed a system that crawls Wikipedia from time to time so as to reflect the timely changes of semantic relationships that are caused by new events. In the experiments reported here, we use 200 query terms derived from the TREC-5 ad-hoc topics [TREC-5 1996] as testing targets. Our data sampling method differs from intuitive approaches that simply use Wikipedia hyperlinks to connect each term with the next term. We believe that such methods capture only the simplest relationships among terms. In contrast, we note that infor-mation obtained from Wikipedia contains not only hyperlinks among terms, but also contributors; that is, editors (or authors) who have created or modified the Wikipedia pages for these terms. This information, taken together, can be used to induce an expertise network that can be considered as a  X  X irtual social X  relationship network among contributors; thus, we are able not only to identify the contributors for query terms but also those who have contributed to related terms. We describe the associated mathematical models below.

Let T term be the set of terms that constitute the topics of Wikipedia, and let C ctr be the set of contributors to Wikipedia. Note that, in this notation, we treat as equivalent the contributors of the final and previous versions of a given Wikipedia page. We association between topic t term and contributor c ctb .
 We then define the set as the topics that appear within Wikipedia X  X  top topic page t 0 term with respect to the (t
For every c ctb  X  C ctb , there exists a t term  X  T term such that (t term , c ctb )  X  A which means that from the beginning search term t query term we can find the internal term links in the article of the query term and then find all of the contributors who have edited these terms.
 { t
In this fashion, given a term we can find the term X  X  contributors, and given a con-tributor we can find the terms associated with the contributor, layer by layer. Thus, in the k th layer we have and Figure 2 illustrates this multipartite network.

In graph theory, clustering coefficient is used to measure the degree to which nodes in a graph are clustered together (i.e., the probability that two nodes are linked given they are both linked to a third node). Evidence suggests that in social networks, nodes tend to create tightly knit groups characterized by a relatively high density clustering coefficient. We then study the cluster coefficient of the graph constructed at each crawl-ing layer k to learn which layer the idealist relational graph is on. After analysis, we construct a network (term-contributor) graph corresponding to the cluster coefficient related to each level k as well as the number of terms from each level respectively.
We observed that the resultant networks reflect that Wikipedia clearly exhibits the  X  X mall world X  property. Using 200 terms in our experiments, we see that by the fourth layer, both the quantities of the network cluster coefficient and the number of terms have already saturated, as illustrated in Figure 3. Thus we select k = 4 as an ideal number of layers.
 After sampling, we generate a related-term graph from a contributor and its associ-ated terms. We then construct a bipartite graph by partitioning the contributors C ctb and terms T term into two parts. We apply soft clustering on this graph to calculate the semantic relatedness of each term pair. Here we first define the graph and its corre-sponding probability descriptions, and then introduce the soft clustering technique [Yu et al. 2005] we adopted.
 are the two disjoint vertex sets and E CT denotes all of the edges that connect C ctr and T weight of the edge between c k ctr and t i term . The bipartite graph G induces a similarity C ctr . Equation (1) can be interpreted from the perspective of Markov random walks
Without loss of generality, we normalize the similarity to ensure that ij SRW(t links between vertices in T term and all the paths from t i term to t j term must go through vertices in C ctb . Thus d = p( t i t indicates the likelihood of c k ctb contributing to term t i term . This suggests that one can which each node t i term  X  T term represents an individual and each edge w ij term  X  W term denotes the presence of interactions between t i term and t j term .Since G is constructed using soft clustering, the corresponding graph S illustrates the affinity of the clusters.
In the following, we use a small example to describe how to model semantic relatedness weighting based on Wikipedia community structure, and how to compute the semantic relatedness between terms. We assume there are m contributors at time t and further assume that the interaction (similarity) SRW(t i term , t j term ) is a combined effect that reflects all contributors. We approximate SRW(t i term , t j term )usingasimple model, that is, actions of c k ctb involve term nodes t i term and t j term , respectively. Moreover, we assume filtering [Sarwar and Karypis 2001]. Written in matrix form, we have SRW  X  X X t ,
We use a simple example with six term nodes and two contributor nodes to illustrate the prescribed model of semantic relatedness weighing. The two contributor nodes are c only between a term node (t term ) and a contributor node (c ctb ). The term-term similarity SRW(t 3 term , t 4 term ) can be generated, in the mixture model, as the sum of the probabilities (p 4.3.1. Expertise Weight Estimation. In the Wikipedia social network, taking into account a contributor X  X  specialization helps greatly to improve recommendation quality, as some contributors are able to expertly formulate related terms, whereas other contributors are not experts in certain fields. Even though experts are rare, many of their opinions and suggestion terms have a profound influence on the development of semantic relat-edness. For instance, in many universities there are seminars offered apart from the regular academic curriculum. These seminars are comprised of lectures on specialized themes; thus, although they do not require much school time, these seminars often still uncover many unforeseen solutions and profound relationships due to their level of academic specialization. For instance, when we consider the example of  X  iPad , X  the general suggestive terms are  X  iPod , X   X  iTune , X  and  X  Apple Store  X ; however, since some experts believe the  X  iPad  X  may result in further development of the e-book market, their input may lead to the use of  X  Kindle  X  as a better suggestion term than for  X  iPod.  X 
Hence, we refine our semantic relatedness model by incorporating information about contributor specialization. In other words, the prescribed term-term relatedness model does not take a contributor X  X  specialization into account but considers only the prior probability that a contributor edits Wikipedia as well as trip-respective editing prob-abilities for t i term and t j term . In order to incorporate contributor expertise, we include which contributor c k ctb specializes in a given term t j term . To incorporate a contributor X  X  specialization with respect to a given term, we find the categories that the contributor is familiar with and then estimate the specialization factors between those categories and the categories related to each of the terms that the contributor has edited. We follow up by revising the term-term relatedness model as t term , Expertise (c As illustrated in Figure 5, the semantic relatedness of the terms  X  iPad  X  X nd X  Kindle  X  can be estimated based on the prescribed method. The remaining question is how to calculate the specialization capacity of contributor c k ctb to a specific term t i term ,thatis,
Again, the contributor X  X  specialization leads to a refined estimate of semantic related-ness. The corresponding specialization factor of contributors, that is, the contributor X  X  personal specialization factor, can be calculated from the list of changes in specific fields that the contributor has made. This information can be found in the history section of each Wikipedia topic or term page. We first list the terms that the contributor has edited and the categories related to those terms (for example, the term  X  X udwig von Beethoven X  falls into the categories  X  X erman composers, X   X  X eaf musicians, X  etc.). On the basis of a contributor X  X  specialization in the kind of categories he or she typically edits, a contributor X  X  specialization in a given term can be calculated as the similarity between the categories related to the term and the various categories to which he or she has contributed. For instance, if the contributor c k ctb edits only Beethoven-related pages, he would be considered highly specialized in Beethoven. Note that because specializa-tion is calculated according to related categories, c k ctb  X  X  specialization in Bach would also be high, because Bach and Beethoven share the category  X  X erman composers X  [Schonhofen 2006]. In Wikipedia, each term can belong to several different categories, for example, the term  X  X lliptic curve cryptography X  belongs to  X  X ryptography, X   X  X sym-metric key cryptosystem, X  and  X  X inite fields X  categories.

In addition, in Wikipedia, the page for a given term (here called the original term) generally contains references to other terms in the form of internal Wikipedia links; following these links to other terms yields even more terms. In keeping with the con-cept of reference link networks, when a contributor edits these referenced terms it also represents a contribution to the original term. The impact factor for those terms relative to the original term can, therefore, be weighted. Again, the contributor X  X  per-sonal specialization factor X  X  vector representing the categories that he or she has edited X  X an be estimated. Since the experiment conducted in Section 4.1 demonstrates Wikipedia X  X  remarkable social network property, our construction takes into account not only the contributor X  X  personal specialization factor but also weights derived from the contributor-to-contributor relationship network. 4.3.2. Cosine Similarity-Based Personal Specialization Weighting .

Weighting Based on Local Category Links. The algorithm for calculating contributor X  X  specialization is as follows. First, we use cosine distance to determine the similarity between the categories that a contributor is familiar with and the categories that the original term belongs to. As demonstrated in [Zhang et al. 2002], cosine similarity is effective for information detection and has been shown to outperform KL divergence in several scenarios; thus, we adopt Cosine distance as our similarity measure. We calculate contributor expertise by first deleting contributors who have contributed little, for Wikipedia, to ignore edits that have been marked  X  X inor. X  We also perform latent Dirichlet allocation (LDA) [Blei et al. 2003] to reduce data dimensionality. represented as a normalized inner product, is the vector representing the categories that contributor c k ctb is familiar with, and | V | denotes the length of the vector V .

Weighting Based on Category Concept. Second, the link structure can lead to related terms or phrases for the original term that elaborate on the original term X  X  concept. By proceeding layer-by-layer, we connect these internal links as cross references. There-fore, if contributors have edited such internal linked reference terms, they are also said to contribute in part to the original term, and are thus seen to be more specialized in this area.

We then find terms that are related to the original term one layer at a time by leveraging these links in every Wikipedia page. The following formulation clarifies this property: where r is the distance in links from the original term and x is the term linked from all of the terms linked directly from the original term page.

Likewise, the specialization level of a contributor can be measured using the following two quantities: the Cosine distance between the category vectors of the contributor c k ctb and the linked concept term t term , as well as the importance of the concept term t term with respect to the original term. That is, a contributor X  X  personal familiarity with respect to a given term can be computed as for contributor c k ctb ,W t and B(t term , n  X  1) to avoid duplicated terms.

In practice, due to the presence of dangling nodes (nodes that do not have any out-links) and cyclic paths in the network, W t
As in PageRank [Page et al. 1998], we apply the remedy of  X  X andom jumps X , where  X  is the probability that the random walk follows a link, (1  X   X  ) is the probability of a  X  X andom jump X , and 1 u is the probability that a particular random node is chosen to make this random jump. In Equation (9), e is a vector of all ones and a is the vector with components a i = 1ifthe i th row of W t a = 0 otherwise. We set on the basis of the reference link network. Contributor expertise is defined as the composition of the two functions f 0 and f 1 ,thatis, where  X  is the weighting factor between the key term and related concept terms. Thus, l = 1 corresponds to the initial stage of the contributor X  X  specialization score, which is used for further belief propagation as described in the next section. 4.3.3. Weighting Based on Contributor Relationship Network . Contributors for any given topic or term can be found in the history section of each Wikipedia topic. Thus, when a contributor cooccurs with another contributor in a term history, he or she is expected to possess some degree of expertise on the term. We construct a contributor relationship V ctb represent all of the neighbor contributor nodes and contributors. Based on the belief propagation theory, we can use the relationships between contributors to improve the accuracy of each contributor X  X  expertise weight [Song et al. 2007; Zhang 2007]. According to our observations, as shown in Figure 6, many contributors share the ideas and fundamental knowledge of leading experts, and therefore, these experts should be assigned correspondingly greater weights. Therefore, for each edge we assign a propagation weight based on cooccurrence frequency (that is, how often two contributors worked on the same term) to indicate how much the expertise score of a contributor propagates to its neighbors.

These propagation coefficients W bp (c k ctb , c m ctb ) are normalized to the range from 0 to 1 inclusively and can be computed using the approaches presented in Section 4.2. Using belief propagation the relationship weight can be incorporated as follows. Expertise (c k ctb , t i term ) l + 1 is computed from Expertise (c k ctb , t i term ) l in which After propagation in each iteration, all expertise weights are normalized, that is, di-vided by the maximal expertise score of the current iteration. For the propagation stop criterion, we set a threshold  X  for some l &gt; 0 or stop after ten iterations. The final for term t j term , Expertise (c k ctb , t j term ), can be calculated in a similar fashion. In practice, users are not really interested in suggestion terms per se; they are really only interested in one term X  X he one they are looking for but can X  X  seem to think of. So they are very interested in a more precise representation of the connections between the query and suggestion terms, as evidenced by the importance rankings in the semantic graph shown in Figure 7. Thus, a user may also click on any term in the graph to display a completely new semantic graph that shows that term X  X  relative importance with respect to the other terms. In this way, a user may find the query term he or she is looking for using a process of guided discovery by traversing the proposed semantic graph shown. In the following, we present a procedure to measure the relative importance of suggested terms in which a PageRank with priors [White and Smyth 2003] mechanism is used to make semantic relatedness recommendations. We define the target keywords as the root set R , and a vector of prior probabilities P importance (or  X  X rior bias X ) attached to node v st . In general, we have P v v to P R , we also define a  X  X ack probability X   X  ,with0  X   X   X  1, which determines how often we can jump back to the set of root nodes in R . Integrating these two extensions into the original PageRank formula yields the following probability equation: d are obtained by normalizing the weights of the outgoing edges of node u st . That is, nodes linked to node u st . After convergence, the ranking result that is biased toward the prior set R is reported. Equation (13) represents a Markov chain of a random surfer who transits  X  X ack X  to the root set R with probability  X  at each time step. Under this assumption, we evaluate the probability of landing on a node in a modified Markov chain, where the random surfer starts at any elements in the set R (associated with appropriate prior probabilities) and executes a random walk that ends stochastically with probabilities  X  (at which point the process restarts). This process defines an infinite set of walks of variable lengths starting at the root set. In fact, they will follow a geometric distribution with mean 1 / X  . The ranking equation, given in (13), estimates the relative probability of landing on any particular node during this set of walks. In order to evaluate the accuracy of the term suggested by our model we need some form of semantic relatedness evaluation. That is, how many suggestion terms from our system are relevant to the query? Evaluating the quality of semantic relatedness is difficult, in particular, for user-generated content, as there are no standard linguistic resources available. User studies of term suggestion evaluations involve asking if par-ticipants think the terms suggested for each query are relevant. We developed several approaches to avoid biased judgments, but the user studies have a tendency to overes-timate of the quality of the results. Therefore, we believe only the users who originally annotated the source can really judge whether a term is relevant. In this work, we con-ducted our performance evaluation by choosing 200 query terms according to TREC-5 ad-hoc topics. To ensure obtaining real practical evaluation results, we chose not to conduct user study approaches, and instead compared our term suggestion results with the original annotators of the sources. Hence we used four large databases: ODP [ODP 1998], BibSonomy [Benz 2010], Amazon Mechanical Turk [Amazon 2011], and the Wordsimilarity-353 test collection [Finkelstein 2002]. These databases are main-tained by large-scale communities of contributors. The contributors for the first three datasets organized terms, grouped them into categories, and identified relevant terms. The last dataset is composed of two sets of English word pairs with human-assigned similarity judgments. They serve as practical and real references with which we can automatically and probabilistically evaluate our term suggestion results. Such evalua-tion approaches have been used by Baeza-Yates and Tiberi [2007], Harvey [2010], Yeh [2009], and Milne [2007, 2008] to evaluate the quality of the suggested terms. We use the following metrics to evaluate the ability of our system to return a good ranked list of suggested terms:  X  P @ k . Precision at rank k . P @ k is the average of the hit rates of suggested term (i.e., how many terms are relevant) among the first k terms in the ranked list of suggested terms. We report P @ k for k = 1and k = 5.  X  S @ k . Success at rank k . S @ k is the average the hit rates in the first k terms of the ranked list of suggested terms. We report S @ k for k = 1, k = 5and k = 20. Note that the values of P @1 and S @1 are the same and thus we do not report them separately.  X  MRR . Mean Reciprocal Rank, MRR is the average of the inverses of the ranks of the first relevant terms obtained from the ranked list of suggested terms.
 For providing more detailed comparisons, we also use MAP (mean average precision) to illustrate the mean average precision scores for each query. BibSonomy [Benz 2010] is a large collective intelligent classification system derived from the practices of collaboratively creating and tagging term managements for anno-tating and categorizing documents and contents. In this database there are more than 305,000 terms provided by 20,000 users. As described in Section 6.1, such a real system is an ideal reference against which to evaluate our system. We use the metrics stated in Section 6.2 as our evaluation criteria. Since our approaches are based on multimodal graphs, we used two different types (LDA and tensor analysis) of representative query expansion approaches as the baseline term suggestion algorithms.

The following three methods are included in our baseline approaches: (i) the early version Bayesian network-based latent Dirichlet allocation (LDA) approach [Wei and Croft 2006], (ii) a recent LDA approach for query expansion (LDA + ) [Fan et al. 2010], (iii) and the tensor analysis-based tripartite hidden topic model (TMM) [Harvey et al. 2010].

LDA is a generative probabilistic model for collections of discrete data such as text corpora; it is a three-level hierarchical Bayesian model where each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is in turn modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. Viewed as a language model that clusters cooccurring terms into topics, LDA has attracted much interest from both the machine learning and language pro-cessing communities. It facilitates making inferences on new documents or terms and overcomes the overfitting problem.

TMMs are derived from LDA and are based on three-dimensional tensor analysis; a tensor can be represented as a multidimensional array of numerical values. The degree of a tensor is the number of relationship vectors needed to be represented. However, its ability to measure semantic relatedness is limited by the dimension of the relational vectors.

Table I shows the performance comparison results where the evaluation metrics mentioned in Section 6.2 are used. The superiority of our method to other approaches is clear from Table I.

In order to make the experiments more convincing, we also used the Amazon Me-chanical Turk as our test reference. This tool enables requesters to coordinate the use of human intelligence to perform tasks such as objective testing that computers are yet unable to do. Moreover, this system randomly chooses many participants to partici-pate in this objective test, which ensures very convincing experimental results. Again, Table II shows the performance comparison results where the evaluation metrics men-tioned in Section 6.2.1 are used. Our experiments clearly show the improvements yielded by our method.

In addition to the previous two experiments, in order to show that the multirela-tional graph approach performs better than tensor analysis based-approaches, we also included the tensor analysis-based query expansion (TQE) [Symond 2011] into com-parison. On the basis of MAP our approach yields 71.9 % while TQE yideelds only 62.7%.
 In order to ensure a fair comparison with other Wikipedia-based term suggestion systems, we performed the same experiments described in Section 6.1 based on the BibSonomy set. We first conducted searches on each of the 200 terms using our system and then obtained suggestion terms provided by Koru. Koru is a user friendly search interface that offers effective, domain-specific, knowledge-based information retrieval. It expands queries automatically and guides users as they evolve their queries inter-actively. In Milne et al. [2007] a user study conducted with 12 participants and 10 topics demonstrated that Koru offers significant advantages over traditional keyword search. For almost every query, the system was shown to be helpful. It streamlined the query submission process, improved the relevance of the returned documents, and thus narrowed the gap between expert and novice seekers. Nevertheless, our experiment results show that the proposed approach significantly outperforms Koru for all evalu-ation measures; for example, the search term  X  search engine  X  submitted to our system yields suggestion terms such as Google, Bing, Yahoo!, PageRank and Semantic Web, etc. Koru is not able to provide such suggestion terms. In addition, our system uses rela-tional graphs to visualize the relationships between suggestion terms. A user can click on any suggestion term in the graph to display a completely new semantic graph that shows that term X  X  relative importance with respect to the other terms. This amounts to a process of guided discovery, where the user traverses the proposed semantic graph to find query terms that better reflect what he or she is looking for.

Semantic relatedness experiments also show that our system X  X  suggestion terms are more relevant to the search query than the suggestion terms yielded by Koru. These results are shown in Table III.

We again used the Amazon Mechanical Turk as our objective test. Experiments show that our method outperforms Koru. The results are shown in Table IV. Zhao et al. [2010] proposed a method that extracts paraphrases from search engine query logs. Based on Baidu logs, the authors defined eight features to train an SVM classifier to determine whether a selected candidate is a paraphrase or not. They used human scoring to estimate the precision, which is shown in Table V. While their approach is limited to find paraphrases of a given query, our approach supports the following classes of term suggestions: synonyms, antonyms, and hyponym.

For the ease of comparison, we omitted those terms that do not belong to any of these three classes from our system for this evaluation.

Being a relational term suggestion system, our approach focuses not only on syn-onyms but also on antonyms and on hyponym. This was made possible by mining for expertise from Wikipedia contributors, because contributors focused not only on one topic but also on related topics. Accordingly, our results contain both synonyms and terms with other relationships. We conducted our evaluation using Mechanical Turk, a human intelligence-based crowd-sourcing service, Participants of our user study are asked to identify the relationship between two terms, or specify that they are not related. In our study, 82% of the suggested terms are reported as related, that is, syn-onyms (22%), hyponyms (37%) or antonyms (23%). The results are shown in Table V.
Synonymy and paraphrase are different in semantics. Paraphrases are sentences that have the same set of entailments: they mutually entail each other. Synonymy evokes the notion of sameness of meaning and is applied to individual predicates, while paraphrase evokes the same notion applied to the entire sentences or the propositions expressed by those sentences. Experimental results show that Zhao et al [2010] is a very effective method to extract paraphrases with precision close to 74%. In comparison, our approach provides high quality related term suggestion, including synonyms, hyponym and antonyms, with the overall precision being 82%. Both approaches do help users conducting their search much more effectively than before. In order to illustrate the benefits of our approach, we compared with two existing graph-based methods for term suggestion [Yeh et al. 2009] and [Milne 2008]. In order to ensure a fair comparison, we used the same reference set as the two papers. The WordSimilarity-353 [Finkelstein et al. 2002] test collection contains two sets of English word pairs along with human-assigned similarity judgments. This collection can be used to test algorithms implementing semantic similarity measures (i.e., algorithms that numerically estimate the similarity of natural language words). To conduct a fair comparison with other term suggestion systems, we calculated Spearman X  X  rank correlation coefficient between the terms X  similarity weights obtained by our system and those weights defined in WordSimilarity-353, following [Yeh et al. 2009] and [Milne 2008]. Spearman X  X  rank correlation coefficient is defined as where x i and y i are the ranked lists. This metric reflects the ranking characteristics more precisely than the traditional Pearson X  X  correlation measurement. Note that the weights defined in [Yeh et al. 2009] and [Milne et al. 2008] are positive scores; that is, a higher weight implies closer similarity. Our system calculates initial word similarity scores based on relational graph mining, and then outputs ranked lists of terms using these similarity scores. Thus, we can perform precision ranking comparison as de-scribed in Sections 6.3 and 6.4. The experimental results demonstrate that our system outperforms these two systems. This is because these two approaches use only simple type of linkage in their graphs. In contrast, our system is based on multipartite linkage networks of contributor-term, term-category, and term-term extracted from Wikipedia, as stated in Section 4. These networks are optimized with contributor expertise and then fused to form term relation graphs with very strong semantic relatedness. Also, our contributor-term and term-category linkage graphs ensure reliable data, because of the way we explicitly classify links as contributors, categories, or terms. This makes it possible to calculate accurate relationship graphs that are much less susceptible to noise, spam, and broken links.

The broken links problem has been addressed in the previous two works, but in our approach, since broken links mean missing contributors or categories, the resultant weight for the term in question is lower, and thus more accurately reflects the value of the information contained therein. The results of this experiment in Table VI show that our method outperforms the other methods. To further demonstrate the effectiveness of using contributor information based on our multimodal graph, we conducted an experiment to show how it complements exist-ing methods based on content, link, and category information. We first used a simple content-based graph (denoted as simple link in Table VII) and evaluated its perfor-mance, and then we added the contributor-term relation (denoted as + Contributor in Table VII) to build up our link-based term graph. Finally, we incorporated contributor expertise from category and contributor relationships (denoted as + Expertise in Ta-ble VII) to yield the complete system, based on the social network property embedded in the Wikipedia linkage network, as described in Section 4. This is thus a way to re-flect more latent relationships between terms  X  X elationships not reflected in previous approaches. We also analyzed our system performance on two different thesauri. There are two baselines: the traditional bag of words approach (BOW) and the WordNet based approaches. As information retrieval thesauri are organized to make explicit exist-ing relationships between concepts, they are more complex than static vocabular-ies, and heavily reflect the variety of domain knowledge. Thus, we use the ODP database to evaluate search precision. ODP, also known as DMOZ, is the largest and the most comprehensive human-edited directory on the Web. It uses a hierar-chical http://en.wikipedia.org/wiki/Ontology (information science)ontology scheme to organize site listings, which are grouped by topics into categories and can then in-clude smaller categories. We adopt the method used in Baeza-Yates and Tiberi [2007] to evaluate the quality of the suggested terms. When users submit queries to ODP, in addition to site matches, categories sorted by their relevance to the query, are also represented as directory paths. Hence, to measure how related two suggestion terms are, we use a notion of similarity between the corresponding categories (as provided by ODP). In particular, we measure the similarity between two categories D c and D c as the length of their longest common prefix O( D c , D c ), divided by the length of the longest path of D c or D c . More precisely, we denote the length of a path as | D c | and define the similarity as
We evaluated the similarity between two suggestion terms by measuring the sim-ilarity between the most similar categories of the two suggestion terms for the top five ODP results. As shown in Table VIII, the proposed algorithm yielded an average suggestion precision of 71.9%. This shows that the query suggestion algorithm is very effective in comparison with the two baselines. We also tested the system performance when the related-term graphs do not incorporate expertise, which yielded a relatively lower precision of 67.3%.

We can see from Table VIII that our algorithm performs better result in Science and Engineering (including Electrical &amp; Computer Engineering) domains. This is be-cause Science/Engineering experts are generally proficient in many topics in related domains. For example, Mathematics experts are usually good at Physics, Engineering and Computer Science. Therefore, we can find related terms generally mix-used in various topics of these domains precisely. However, our algorithm X  X  performances in Business and Law domains are not as well as those in Science/Engineering domains. This, again, comes from the fact that there are not so many mix-used terms in these domains. Besides, experts in Business/Law domains are usually expertized on a few specific topics. For example, a Finance expert is usually not so familiar with Market-ing; however, most universities include both of them into business schools. Thus, the numbers and the correlation of returned terms in these domains are less than those of the Science/Engineering domains are. Also, the means and the standard deviations shown in the Table VII also reflect this phenomenon. Medical domain presents the worst statistical results because Wikipedia is hard to deal with medicine nouns. Lots of medicine nouns have not been included in Wikipedia, yet. To the best of our knowledge, we are the first team to explicitly use Wikipedia X  X  mul-tipartite networks and contributor X  X  expertise to compute the semantic relatedness of keywords and to use the obtained semantic graphs to conduct term suggestions. Various experiments on the proposed approaches have shown promising results for providing effective search-term suggestions. We see a potential advantage in using such kind of semantic graphs for various search tasks in people X  X  daily search activities. Compared with WordNet, an information retrieval ontology, our approach leverages knowledge bases that are orders of magnitude larger and more comprehensive, and therefore yields much better performance. Compared with other term suggestion systems, our system results in better semantically related search suggestions. Moreover, our system does not require a pre-defined vocabulary (because the Wikipedia vocabulary is maintained by a large number of contributors) and does not require storing huge volumes of query logs (because richer relationships are embedded in the editorial history of Wikipedia); therefore, our visualized relational graph system is able to perform term suggestions more simply, efficiently, and semantically. Our future work will focus on enhancing the system X  X  search capabilities by adding personalization factors into the design. More-over, we hope to further understand the latent relationships in related semantic terms. For example, why are certain synonyms or antonyms closely connected? If we can better understand this hidden relatedness, we may extend the query expansions and suggestions of the system one step further.

