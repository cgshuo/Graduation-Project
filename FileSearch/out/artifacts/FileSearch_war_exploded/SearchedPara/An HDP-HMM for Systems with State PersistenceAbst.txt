 Emily B. Fox ebfox@mit.edu Erik B. Sudderth sudderth@eecs.berkeley.edu Department of EECS, University of California, Berkeley, CA 94720 Michael I. Jordan jordan@eecs.berkeley.edu Alan S. Willsky willsky@mit.edu Hidden Markov models (HMMs) have been a major success story in many applied fields; they provide core statistical inference procedures in areas as diverse as speech recognition, genomics, structural biology, ma-chine translation, cryptanalysis and finance. Even af-ter four decades of work on HMMs, however, signifi-cant problems remain. One lingering issue is the choice of the hidden state space X  X  cardinality. While standard parametric model selection methods can be adapted to the HMM, there is little understanding of the strengths and weaknesses of such methods in this setting. Recently, Teh et al. (2006) presented a nonparamet-ric Bayesian approach to HMMs in which a stochastic process, the hierarchical Dirichlet process (HDP), de-fines a prior distribution on transition matrices over countably infinite state spaces. The resulting HDP-HMM leads to data X  X riven learning algorithms which infer posterior distributions over the number of states. This posterior uncertainty can be integrated out when making predictions, effectively averaging over models of varying complexity. The HDP-HMM has shown promise in a variety of applications, including visual scene recognition (Kivinen et al., 2007) and the mod-eling of genetic recombination (Xing &amp; Sohn, 2007). One serious limitation of the standard HDP-HMM is that it inadequately models the temporal persis-tence of states. This problem arises in classical finite HMMs as well, where semi-Markovian models are of-ten proposed as solutions. However, the problem is exacerbated in the nonparametric setting, where the Bayesian bias towards simpler models is insufficient to prevent the HDP-HMM from learning models with un-realistically rapid dynamics, as demonstrated in Fig. 1. To illustrate the seriousness of this issue, let us con-sider a challenging application that we revisit in Sec. 5. The problem of speaker diarization involves segment-ing an audio recording into time intervals associated with individual speakers. This application seems like a natural fit for the HDP-HMM, as the number of true speakers is typically unknown, and may grow as more data is observed. However, this is not a setting in which model averaging is the goal; rather, it is critical to infer the number of speakers as well as the transi-tions among speakers. As we show in Sec. 5, the HDP-HMM X  X  tendency to rapidly switch among redundant states leads to poor speaker diarization performance. In contrast, the methods that we develop in this paper yield a state-of-the-art speaker diarization method, as well as a general solution to the problem of state persis-tence in HDP-HMMs. The approach is easily stated X  we simply augment the HDP-HMM to include a pa-rameter for self-transition bias, and place a separate prior on this parameter. The challenge is to consis-tently execute this idea in a nonparametric Bayesian framework. Earlier papers have also proposed self-transition parameters for HMMs with infinite state spaces (Beal et al., 2002; Xing &amp; Sohn, 2007), but did not formulate general solutions that integrate fully with nonparametric Bayesian inference.
 While the HDP-HMM treats the state transition dis-tribution nonparametrically, it is also desirable to al-low more flexible, nonparametric emission distribu-tions. In classical applications of HMMs, finite Gaus-sian mixtures are often used to model multimodal ob-servations. Dirichlet process (DP) mixtures provide an appealing alternative which avoids fixing the num-ber of observation modes. Such emission distribu-tions are not identifiable for the standard HDP-HMM, due to the tendency to rapidly switch between redun-dant states. With an additional self-transition bias, however, we show that a fully nonparametric HMM leads to effective learning algorithms. In particular, we develop a blocked Gibbs sampler which leverages forward X  X ackward recursions to jointly resample the state and emission assignments for all observations. In Sec. 2, we begin by presenting background material on the HDP. Sec. 3 then links these nonparametric methods with HMMs, and extends them to account for state persistence. We further augment the model with multimodal emission distributions in Sec. 4, and present results using synthetic data and the NIST speaker diarization database in Sec. 5. A Dirichlet process (DP), denoted by DP(  X ,H ), is a distribution over countably infinite random measures on a parameter space  X . The weights are sampled via a stick-breaking construction (Sethuraman, 1994): We denote this distribution by  X   X  GEM(  X  ).
 The DP is commonly used as a prior on the parameters of a mixture model of unknown complexity, resulting in a DPMM (see Fig. 2(a)). To generate observations, we choose  X   X  i  X  G 0 and y i  X  F (  X   X  i ). This sampling process is often described via a discrete variable z i  X   X  indicating which component generates y i  X  F (  X  z The hierarchical Dirichlet process (HDP) (Teh et al., 2006) extends the DP to cases in which groups of data are produced by related, yet unique, generative pro-cesses. Taking a hierarchical Bayesian approach, the HDP places a global Dirichlet process prior DP(  X ,G 0 ) on  X , and then draws group specific distributions G j  X  DP(  X ,G 0 ). Here, the base measure G 0 acts as an  X  X verage X  distribution ( E [ G j ] = G 0 ) encoding the frequency of each shared, global parameter: Because G 0 is discrete, multiple  X   X  jt  X  G 0 may take identical values  X  k . Eq. (4) aggregates these probabil-ities, allowing an observation y ji to be directly associ-ated with the unique global parameters via an indica-tor random variable z ji  X   X  j . See Fig. 2(b). We can alternatively represent this generative process via indicator variables t ji  X   X   X  j and k jt  X   X  , as in Fig. 2(c). The stick-breaking priors on these mix-ture weights can be analytically marginalized, yield-ing simple forms for the predictive distributions of as-signments. The resulting distribution on partitions is sometimes described using the metaphor of a Chinese restaurant franchise (CRF). There are J restaurants (groups), each with infinitely many tables (clusters) at which customers (observations) sit. Upon entering the j th restaurant, customer y ji sits at currently occupied tables t ji with probability proportional to the number of currently seated customers, or starts a new table  X  t with probability proportional to  X  . Each table chooses a dish (parameter)  X   X  jt =  X  k tional to the number of other tables in the franchise that ordered that dish, or orders a new dish  X   X  k with probability proportional to  X  . Observation y ji is then generated by global parameter  X  z An alternative, non X  X onstructive characterization of samples G 0  X  DP(  X ,H ) from a Dirichlet process states that for every finite partition { A 1 ,...,A K } of  X , ( G 0 ( A 1 ) ,...,G 0 ( A K )) Using this expression, it can be shown that the fol-lowing finite, hierarchical mixture model converges in distribution to the HDP as L  X  X  X  (Ishwaran &amp; Zare-pour, 2002; Teh et al., 2006): Later sections use this weak limit approximation to develop efficient, blocked sampling algorithms. The HDP can be used to develop an HMM with an unknown, potentially infinite state space (Teh et al., 2006). For this HDP-HMM, each HDP group-specific distribution,  X  j , is a state-specific transition distribu-tion and, due to the infinite state space, there are in-finitely many groups. Let z t denote the state of the Markov chain at time t . For Markov chains z t  X   X  z so that z t  X  1 indexes the group to which y t is assigned. The current HMM state z t then indexes the parameter  X  By sampling  X  j  X  DP(  X , X  ), the HDP prior encour-ages states to have similar transition distributions ( E [  X  jk ] =  X  k ). However, it does not differentiate self X  transitions from moves between states. When model-ing systems with state persistence, the flexible nature of the HDP-HMM prior allows for state sequences with unrealistically fast dynamics to have large posterior probability. For example, with Gaussian emissions, as in Fig. 1, a good explanation of the data is to divide an observation block into two small X  X ariance states with slightly different means, and then rapidly switch be-tween them (see Fig. 1). In such cases, many models with redundant states may have large posterior prob-ability, thus impeding our ability to identify a single dynamical model which best explains the observations. The problem is compounded by the fact that once this alternating pattern has been instantiated by the sam-pler, its persistence is then reinforced by the prop-erties of the Chinese restaurant franchise, thus slow-ing mixing rates. Furthermore, when observations are high-dimensional, this fragmentation of data into re-dundant states may reduce predictive performance. In many applications, one would thus like to be able to incorporate prior knowledge that slow, smoothly vary-ing dynamics are more likely.
 To address these issues, we propose to instead sample transition distributions  X  j as follows: Here, (  X  X  +  X  X  j ) indicates that an amount  X  &gt; 0 is added to the j th component of  X  X  . The measure of  X  j over a finite partition ( Z 1 ,...,Z K ) of the positive in-tegers Z + , as described by Eq. (5), adds an amount  X  only to the arbitrarily small partition containing j , cor-responding to a self-transition. When  X  = 0 the origi-nal HDP-HMM is recovered. Because positive  X  values increase the prior probability E [  X  jj ] of self X  X ransitions, we refer to this extension as the sticky HDP-HMM. In some ways, this  X  parameter is reminiscent of the infinite HMM X  X  self-transition bias (Beal et al., 2002). However, that paper relied on a heuristic, approximate Gibbs sampler. The full connection between the infi-nite HMM and an underlying nonparametric Bayesian prior, as well as the development of a globally con-sistent inference algorithm, was made in Teh et al. (2006), but without a treatment of a self-transition parameter. 3.1. A CRF with Loyal Customers We further abuse the Chinese restaurant metaphor by extending it to the sticky HDP-HMM, where our fran-chise now has restaurants with loyal customers. Each restaurant has a specialty dish with the same index as that of the restaurant. Although this dish is served elsewhere, it is more popular in the dish X  X  namesake restaurant. We see this increased popularity from the fact that a table X  X  dish is now drawn as We will refer to z t as the parent and z t +1 as the child. The parent enters a restaurant j determined by its parent (the grandparent), z t  X  1 = j . We assume there is a bijective mapping of indices f : t  X  ji . The parent then chooses a table t ji  X   X   X  j and that table is served a dish indexed by k jt the increased popularity of the house specialty dish implies that children are more likely to eat in the same restaurant as their parent and, in turn, more likely to eat the restaurant X  X  specialty dish. This develops family loyalty to a given restaurant in the franchise. However, if the parent chooses a dish other than the house specialty, the child will then go to the restaurant where this dish is the specialty and will in turn be more likely to eat this dish, too. One might say that for the sticky HDP-HMM, children have similar tastebuds to their parents and will always go the restaurant that prepares their parent X  X  dish best. Often, this keeps many generations eating in the same restaurant. The inference algorithm is simplified if we introduce a set of auxiliary random variables  X  k jt and w jt as follows: where Ber( p ) represents the Bernoulli distribution. The table first chooses a dish  X  k jt without taking the restaurant X  X  specialty into consideration (i.e., the orig i-nal CRF.) With some probability, this considered dish is overridden (perhaps by a waiter X  X  suggestion) and the table is served the specialty dish j . Thus, k jt rep-resents the served dish. We refer to w jt as the override variable. For the original HDP-HMM, when  X  = 0, the considered dish is always the served dish since w jt = 0 for all tables. See Fig. 2(c). 3.2. Sampling via Direct Assignments In this section we describe a modified version of the direct assignment Rao-Blackwellized Gibbs sampler of Teh et al. (2006) which circumvents the complicated bookkeeping of the CRF by sampling indicator random variables directly. Throughout this section, we refer to the variables in the graph of Fig. 3. For this sampler, a set of auxiliary variables m jk ,  X  m jk , and w jt must be added (as illustrated in Fig. 2(c)).
 Sampling z t The posterior distribution factors as: p ( z t = k | z \ t ,y 1: T , X , X , X , X  )  X  p ( z t = k | z \ t , X , X , X  ) p ( y t | y \ t ,z t = k,z \ t The properties of the Dirichlet process dictate that on the finite partition { 1 ,...,K,  X  k } we have the following form for the group-specific transition distributions: We use the above definition of  X  j and the Dirichlet dis-tribution X  X  conjugacy to the multinomial observations z t to marginalize  X  j and derive the following condi-tional distribution over the states assignments: p ( z t = k | z \ t , X , X , X  )  X  (  X  X  k + n  X  t z This formula is more complex than that of the stan-dard HDP sampler due to potential dependencies in the marginalization of  X  z derivation, see Fox et al. (2007). The notation n jk rep-resents the number of Markov chain transitions from state j to k , n j. = P k n jk , and n  X  t jk the number of transitions from state j to k not counting the transi-chooses a state k with probability depending on how many times we have seen other z t  X  1 to k and k to z t +1 transitions. Note that there is a dependency on whether either or both of these transitions correspond to a self-transition, which is strongest when  X  &gt; 0. As in Teh et al. (2006), by placing a conjugate prior on the parameter space, there is a closed analytic form for the likelihood component p ( y t | y \ t ,z t = k,z \ t Sampling  X  Assume there are currently  X  K unique dishes being considered and take a finite partition {  X  1 , X  2 ,..., X   X  K , X   X  k } of  X , where  X   X  k =  X  \ S Since  X   X  jt  X  G 0 and  X  m .k tables are considering dish  X  , the properties of the Dirichlet distribution dictate: p ((  X  1 ,..., X   X  K , X   X  k ) |  X  k , X  )  X  Dir(  X  m . 1 ficient statistics for resampling  X  on this partition. However, this requires sampling two additional vari-ables, m jk and w jt , corresponding to the number of tables in restaurant j served dish k and the corre-sponding overwrite variables. We jointly sample from p ( m , w ,  X  m | z 1: T , X , X , X  ) = p (  X  m | m , w ,z 1: T We start by examining p ( m | z 1: T , X , X , X  ). Having the state index assignments z 1: T effectively partitions the data (customers) into both restaurants and dishes, though the table assignments are unknown since mul-tiple tables can be served the same dish. Thus, sam-pling m jk is in effect equivalent to sampling table as-signments for each customer after knowing the dish assignment. This conditional distribution is given by: where  X  n  X  ji jt is the number of customers at table t in restaurant j , not counting y ji . The form of Eq. (15) implies that a customer X  X  table assignment conditioned on a dish assignment k follows a DP with concentra-tion parameter  X  X  k +  X  X  ( k,j ) and may be sampled by simulating the associated Chinese restaurant process. We now derive the conditional distribution for the override variables w jt . The table counts provide that m jk tables are serving dish k in restaurant j . If k 6 = j , we automatically have m jk tables with w jt = 0 since the served dish is not the house specialty. Otherwise, p ( w jt | k jt = j, X , X  )  X  where  X  =  X  Observing served dish k jt = j makes it more likely that the considered dish  X  k jt was overridden than the prior suggests. We draw m jj samples of w jt from Eq. (16). Given m jk for all j and k and w jt for each of these instantiated tables, we can now deterministically com-pute  X  m jk . Any table that was overridden is an unin-formative observation for the posterior of  X  m jk so that Sampling Hyperparameters Rather than fixing the sticky HDP-HMM X  X  hyperparameters, we place vague gamma priors on  X  and (  X  +  X  ), and a beta prior on  X / (  X  +  X  ). As detailed in Fox et al. (2007), the auxiliary variables introduced in the preceding section then allow tractable resampling of these hyperparam-eters. This allows the number of occupied states, and the degree of self X  X ransition bias, to be strongly influ-enced by the statistics of observed data, as desired. 3.3. Blocked Sampling of State Sequences The HDP-HMM direct assignment sampler can exhibit slow mixing rates since global state sequence changes are forced to occur coordinate by coordinate. This is explored in Scott (2002) for the finite HMM. Although the sticky HDP-HMM reduces the posterior uncer-tainty caused by fast state-switching explanations of the data, the self-transition bias can cause two con-tinuous and temporally separated sets of observations of a given state to be grouped into two states. If this occurs, the high probability of self-transition makes it challenging for the sequential sampler to group those two examples into a single state.
 A variant of the HMM forward-backward procedure (Rabiner, 1989) allows us to harness the Markov struc-ture and jointly sample the state sequence z 1: T given the observations y 1: T , transitions probabilities  X  j , and model parameters  X  k . To take advantage of this pro-cedure, we now must sample the previously marginal-ized transition distributions and model parameters. In practice, this requires approximating the theoretically countably infinite transition distributions. One ap-proach is the degree L weak limit approximation to the DP (Ishwaran &amp; Zarepour, 2002), where L is a number that exceeds the total number of expected HMM states. This approximation encour-ages the learning of models with fewer than L com-ponents while allowing the generation of new compo-nents, upper bounded by L , as new data are observed. The posterior distributions of  X  and  X  j are given by:  X   X  Dir(  X /L +  X  m . 1 ,..., X /L +  X  m .L ) (19)  X  j  X  Dir(  X  X  1 + n j 1 ,..., X  X  j +  X  + n jj ,..., X  X  L + n jL Depending on the form of the emission distribution and base measure on the parameter space  X , we sam-ple parameters for each of the currently instantiated states from the updated posterior distribution: Now that we are sampling  X  j directly, we can use a non-conjugate base measure.
 We block sample z 1: T by first computing backward recursively sampling each z t conditioned on z t  X  1 from A similar sampler has been used for learning HDP hid-den Markov trees (Kivinen et al., 2007). However, this work did not consider the complications introduced by multimodal emissions, as we explore next.
 For many application domains, the data associated with each hidden state may have a complex, multi-modal distribution. We propose to approximate such emission distributions nonparametrically, using an in-finite DP mixture of Gaussians. This formulation is related to the nested DP (Rodriguez et al., 2006). The bias towards self-transitions allow us to distin-guish between the underlying HDP-HMM states. If the model were free to both rapidly switch between HDP-HMM states and associate multiple Gaussians per state, there would be considerable posterior un-certainty. Thus, it is only with the sticky HDP-HMM that we can effectively learn such models.
 We augment the HDP-HMM state z t with a term s t indexing the mixture component of the z th t emission density. For each HDP-HMM state, there is a unique stick-breaking distribution  X  k  X  GEM(  X  ) defining the mixture weights of the k th emission density so that s  X   X  z sian component with parameter  X  z To implement blocked resampling of ( z 1: T ,s 1: T ), we use weak limit approximations to both the HDP-HMM and Dirichlet process emissions, approximated to lev-els L and L  X  , respectively. The posterior distributions of  X  and  X  k remain unchanged; that of  X  k is given by: where n  X  kl are the number of observations assigned to the l th mixture component of the k th HMM state. The posterior distribution for each Gaussian X  X  mean and covariance,  X  k,j , is determined by the observations as-signed to this component, namely, The augmented state ( z t ,s t ) is sampled from p ( z t ,s t | z t  X  1 ,y 1: T ,  X  ,  X  ,  X  )  X  Since the Markov structure is only on the z t compo-nent of the augmented state, the backward message m function of z t  X  1 . These messages are given by: Synthetic Data We generated test data from a three-state Gaussian emission HMM with: 0.97 proba-bility of self-transition; means 50, 0, and -50; and vari-ances 50, 10, and 50 (see Fig. 1(a).) For the blocked sampler, we used a truncation level of L = 15. Fig. 5 shows the clear advantage of considering a sticky HDP-HMM with blocked sampling. The Hamming distance error is calculated by greedily mapping the indices of the estimated state sequence to those max-imizing overlap with the true sequence. The appar-ent slow convergence of the sticky HDP-HMM direct assignment sampler (Fig. 5(b)) can be attributed to the sampler splitting temporally separated segments of a true state into multiple, redundant states. Al-though not depicted due to space constraints, both sticky HDP-HMM samplers result in estimated mod-els with significantly larger likelihoods of the true state sequence than those of the original HDP-HMM.
 To test the model of Sec. 4, we generated data from a two-state HMM, where each state had a two-Gaussian mixture emission distribution with equally weighted components defined by means (0 , 10) and (  X  7 , 7), and variances of 10. The probability of self-transition was set to 0.98. The resulting observation and true state sequences are shown in Fig. 6(a) and (b).
 Fig. 6(e)-(h) compares the performance of the sticky and original HDP-HMM with single and infinite Gaus-sian mixture emissions. All results are for the blocked sampler with truncation levels L = L  X  = 15. In-tuitively, when constrained to single Gaussian emis-sions, the best explanation of the data is to associate each true mixture component with a separate state and then quickly switch between these states, result-ing in the large Hamming distances of Fig. 6(g)-(h). Although not the desired effect in this scenario, this behavior, as depicted in Fig. 6(c), demonstrates the flexibility of the sticky HDP-HMM: if the best ex-planation of the data according to the model is fast state-switching, the sticky HDP-HMM still allows for this by learning a small bias towards self-transitions. The sticky HDP-HMM occasionally has more accu-rate state sequence estimates by grouping a true state X  X  Gaussian mixture components into a single Gaussian with large variance. By far the best performance is achieved by the sticky HDP-HMM with infinite Gaus-sian mixture emissions (see Fig. 6(e) and (d)); compar-ing to Fig. 6(f), we see that the gain can be attributed to modeling rather than just improved mixing rates. Speaker Diarization Data The speaker diariza-tion task involves segmenting an audio recording into speaker-homogeneous regions, while simultaneously identifying the number of speakers. We tested the util-ity of the sticky HDP-HMM for this task on the data distributed by NIST as part of the Rich Transcrip-tion 2004-2007 meeting recognition evaluations (NIST, 2007). We use the first 19 Mel Frequency Cepstral Coefficients (MFCCs), computed over a 30ms window every 10ms, as our feature vector. When working with this dataset, we discovered that: (1) the high frequency content of these features contained little discriminative information, and (2) without a mini-mum speaker duration, the sticky HDP-HMM learned within speaker dynamics in addition to global speaker changes. To jointly address these issues, we instead model feature averages computed over 250ms, non X  overlapping blocks. A minimum speaker duration of 500ms is set by associating two average features with each hidden state. We also tie the covariances of within X  X tate mixture components. We found single X  Gaussian emission distributions to be less effective. For each of 21 meetings, we compare 10 initializations of the original and sticky HDP-HMM blocked sam-plers. In Fig. 8(a), we report the official NIST di-arization error rate (DER) of the run with the largest observation sequence likelihood, given parameters esti-mated at the 1000th Gibbs iteration. The sticky HDP-HMM X  X  temporal smoothing provides substantial per-formance gains. Fig 8(b) plots the estimated versus true number of speakers who talk for more than 10% of the meeting time, and shows our model X  X  ability to adapt to a varying number of speakers. As a fur-ther comparison, the ICSI team X  X  algorithm (Wooters &amp; Huijbregts, 2007), by far the best performer at the
