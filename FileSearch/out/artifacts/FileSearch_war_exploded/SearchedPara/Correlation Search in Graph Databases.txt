 Correlation mining has gained great success in many ap-plication domains for its ability to capture the underlying dependency between objects. However, the research of cor-relation mining from graph databases is still lacking despite the fact that graph data, especially in various scientific do-mains, proliferate in recent years. In this paper, we propose a new problem of correlation mining from graph databases, called Correlated Graph Search (CGS). CGS adopts Pear-son X  X  correlation coefficient as a correlation measure to take into consideration the occurrence distributions of graphs. However, the problem poses significant challenges, since ev-ery subgraph of a graph in the database is a candidate but the number of subgraphs is exponential. We derive two nec-essary conditions which set bounds on the occurrence prob-ability of a candidate in the database. With this result, we design an efficient algorithm that operates on a much smaller projected database and thus we are able to obtain a signif-icantly smaller set of candidates. To further improve the efficiency, we develop three heuristic rules and apply them on the candidate set to further reduce the search space. Our extensive experiments demonstrate the effectiveness of our method on candidate reduction. The results also justify the efficiency of our algorithm in mining correlations from large real and synthetic datasets.
 Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications -Data Mining General Terms: Algorithms Keywords: Correlation, Graph Databases, Pearson X  X  Cor-relation Coefficient
Correlation mining is recognized as one of the most impor-tant data mining tasks for its capability of identifying the underlying dependency between objects. It has a wide range of application domains and has been studied extensively on market-basket databases [5, 13, 15, 24, 23, 29], quantita-Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00. tive databases [11], multimedia databases [16], data streams [20], and many more. However, little attention has been paid to mining correlations from graph databases, in spite of the popularity of graph data model pertaining to various domains, such as biology [4, 10], chemistry [2], social science [3], the Web [17] and XML [1].

In this paper, we study a new problem of mining cor-relations from graph databases. We propose to use Pear-son X  X  correlation coefficient [21] to measure the correlation between a query graph and an answer graph. We formu-late this mining problem, named Correlated Graph Search ( CGS ), as follows. Given a graph database D that consists of N graphs, a query graph q and a minimum correlation threshold  X  , the problem of CGS is to find all graphs whose Pearson X  X  correlation coefficient wrt q is no less than  X  .
Pearson X  X  correlation coefficient is shown to be one of the most desirable correlation measures in [21] for its ability to capture the departure of two variables from independence. It has been widely used to describe the strength of correla-tion among boolean variables in transaction databases [21, 23, 29]. This motivates us to apply the measure in the con-text of graph databases. However, graph mining is a much harder problem due to the high complexity of graph oper-ations (e.g., subgraph isomorphism testing is NP-complete [7]). The difficulty of the problem is further compounded by the fact that the search space of CGS is often large, since a graph consists of exponentially many subgraphs and each subgraph of a graph in D can be a candidate graph. Thus, it poses great challenges to tackle the problem of CGS.
How can we reduce the large search space of CGS and avoid as many expensive graph operations as possible? We investigate the property of Pearson X  X  correlation coefficient and derive two necessary conditions for the correlation con-dition to be satisfied. More specifically, we derive the lower bound and upper bound of the occurrence probability (also called support ), supp ( g ), of a candidate graph g .Thisef-fectively reduces the search space to be the set of Frequent subGraphs ( FGs ) [12] in D with the support values between the lower and upper bounds of supp ( g ).

However, mining FGs from D is still expensive when the lower bound of supp ( g )islowor D is large. Moreover, we still have a large number of candidates and the solution is not scalable. Thus, we need to further reduce the number of candidates as well as address the scalability problem. Our solution to this problem is as follows.

Let D q be the projected database of D on q ,whichisthe set of all graphs in D that are supergraphs of q .Weprove that, the set of FGs mined from D q using lowerbound ( supp as the minimum support threshold is complete wrt the an-swer set. Since D q is in general much smaller than D while finding not only saves the computational cost for generating the candidate set, but also significantly reduces the number of candidates. Furthermore, we develop three heuristic rules to be applied on the candidate set to identify the graphs that are guaranteed to be in the answer set, as well as to prune the graphs that are guaranteed to be false positives.
In addition to the formulation of the new CGS problem and its efficient solution, the significance of our work also lies in its close connection to graph similarity search, which is an important research area of graph querying. There are two types of similarity: structural similarity (i.e., two graphs are similar in structure) and statistical similarity (i.e., the occurrence distributions of two graphs are similar).
Existing work [8, 18, 27, 22] mainly focuses on struc-tural similarity search. However, in many applications, two graphs that are structurally dissimilar but always appear to-gether in a graph in D may be more interesting. For exam-ple, in chemistry, isomers refer to molecules with the same chemical formula and similar structures. The chemical prop-erties of isomers can be quite different due to different posi-tions of atoms and functional groups. Consider the case that the chemist needs to find some molecule that shares similar chemical properties of a given molecule. Structural similar-ity search is not relevant, since it mostly returns isomers of the given molecule that have similar structures but different chemical properties, which is undesirable. On the contrary, CGS is able to obtain the molecules that share similar chem-ical properties but may or may not have similar structures to the given molecule. Therefore, our proposed CGS solves an orthogonal problem of structural similarity search.
Our extensive experiments on both real and synthetic datasets show that our algorithm, called CGSearch , achieves short response time for various queries with relatively small memory consumption. Compared with the approach whose candidate set is generated from the whole database with a support range, CGSearch is orders of magnitude faster and consumes up to 41 times less memory. The effectiveness of the candidate generation from the projected database and three heuristic rules is also demonstrated.
 Contributions. The specific contributions of the paper are stated as follows. Organization. We give preliminaries in Section 2. We de-fine the CGS problem in Section 3. We propose the effective candidate generation from a projected database in Section 4. We present the algorithm, as well as the three heuristic rules, in Section 5. Then, we analyze the performance study in Section 6. Finally, we discuss related work in Section 7 and conclude our paper in Section 8.
In this paper, we restrict our discussion on undirected, la-belled connected graphs (or simply graphs hereinafter), since most of the interesting graphs in practice are connected graphs; while our method can be easily extended to process directed and unlabelled graphs.

Agraph g is defined as a 4-tuple ( V, E, L, l ), where V is the set of vertices, E is the set of edges, L is the set of labels and l is a labelling function that maps each vertex or edge to a label in L . We define the size of a graph g as size ( g )= | E ( g ) | .

Given two graphs, g =( V, E, L, l )and g =( V ,E ,L ,l ), a subgraph isomorphism from g to g is an injective func-tion f : V  X  V , such that  X  ( u, v )  X  E ,( f ( u ) ,f ( v )) The subgraph isomorphism testing is known to be an NP -complete problem [7].

Agraph g is called a subgraph of another graph g (or g is a supergraph of g ), denoted as g  X  g (or g  X  g ), if there exists a subgraph isomorphism from g to g .

Let D = { g 1 ,g 2 ,...,g N } be a graph database that consists of N graphs. Given D and a graph g , we denote the set of all graphs in D that are supergraphs of g as D g = { g : g D ,g  X  g } . We call D g the projected database of D on g .The frequency of g in D , denoted as freq ( g ; D ), is defined as The support of g in D , denoted as supp ( g ; D ), is defined as |D| . A graph g is called a Frequent subGraph ( FG )[9, 12, 25] in D if supp ( g ; D )  X   X  ,where  X  (0  X   X   X  1) is a user-specified minimum support threshold . For simplicity, we use freq ( g )and supp ( g ) to denote the frequency and support of g in D when there is no confusion. Given two graphs, g 1 and g , we define the joint frequency , denoted as freq ( g 1 ,g the number of graphs in D that are supergraphs of both g 1 the joint support of g 1 and g 2 as supp ( g 1 ,g 2 )= freq
The support measure is anti-monotone , i.e., if g 1  X  g 2 then supp ( g 1 )  X  supp ( g 2 ). Moreover, by the definition of joint support, we have the following property: supp ( g 1 supp ( g 1 )and supp ( g 1 ,g 2 )  X  supp ( g 2 ).

Example 1. Figure 1 shows a graph database, D ,that consists of 10 graphs, g 1 ,...,g 10 . For clarity of presentation, all the nodes are of the same label (not shown in the figure); while the characters a , b and c represent distinct edge labels.
The graph g 8 is a subgraph of g 2 . The projected database is computed as freq ( g 8 )= |D g 8 | = 5. The support of g is supp ( g 8 )= freq ( g 8 ) |D| =0 . 5. As for g 9 ,wehave { g 6 ,g 7 ,g 9 } . The joint frequency of g 8 and g 9 is computed as freq ( g 8 ,g 9 )= |D g 8  X  X  g 9 | = |{ g 6 ,g 7 }| = 2. The joint
We first define Pearson X  X  correlation coefficient [19] for two given graphs. Pearson X  X  correlation coefficient for boolean variablesisalsoknownas X   X  correlation coefficient  X  [28]. Definition 1. ( Pearson X  X  Correlation Coefficient ) Given two graphs g 1 and g 2 ,the Pearson X  X  Correlation Co-efficient of g 1 and g 2 , denoted as  X  ( g 1 ,g 2 ) ,isdefinedasfol-lows:  X  ( g 1 ,g 2 )= supp ( g 1 ,g 2 )
When supp ( g 1 ) or supp ( g 2 ) is equal to 0 or 1 ,  X  ( g defined to be 0 .

The range of  X  ( g 1 ,g 2 ) falls within [  X  1 , 1]. If  X  ( g positive, then g 1 and g 2 are positively correlated; otherwise, g and g 2 are negatively correlated. In this paper, we focus on positively correlated graphs defined as follows.
Definition 2. ( Correlated Graphs ) Two graphs g 1 and g 2 are correlated if and only if  X  ( g 1 ,g 2 )  X   X  ,where  X  ( 0 &lt; X   X  1 ) is a user-specified minimum correlation thresh-old .

We now define the correlation mining problem in graph databases as follows.

Definition 3. ( Correlated Graph Search ) Given a graph database D ,a correlation query graph q and a min-imum correlation threshold  X  , the problem of Correlated Graph Search (CGS) is to find the set of all graphs that are correlated with q . The answer set of the CGS problem is defined as A q = { ( g, D g ):  X  ( q, g )  X   X  } .
For each correlated graph g of q , we include D g in the answer set in order to indicate the distribution of g in D We also define the set of correlated graphs in the answer set as the base of the answer set, denoted as base ( A q )= { ( g, D g )  X  X  q } . In the subsequent discussions, a correlation query graph is simply called a query .
 Table 1 gives the notations used throughout the paper.
A crucial step for solving the problem of CGS is to ob-tain the set of candidate graphs. Obviously, it is infeasible to test all subgraphs of the graphs in D because there are exponentially many subgraphs. In this section, we discuss how to effectively select a small set of candidates for a given query.
We begin by investigating the bounds on the support of a candidate graph, g , with respect to the support of a query q . We state and prove the bounds in Lemma 1.

Lemma 1. If q and g are correlated, then the following bounds of supp ( g ) hold:
Proof. By the definition of the joint support, we have supp ( q, g )  X  supp ( g )and supp ( q, g )  X  supp ( q ).
Since q and g are correlated,  X  ( q, g )  X   X  . By replacing supp ( q, g )with supp ( g )in  X  ( q, g ), we have:
Similarly, by replacing supp ( q, g )with supp ( q )in  X  ( q, g ), we obtain the upper bound: For simplicity, we use lower ( g )and upper ( g )todenotethe respective lower and upper bounds of supp ( g )withrespect to q , as given in Lemma 1. The above lemma states a nec-essary condition for a correlated answer graph. Thus, a candidate graph should have support within the range of [ lower ( g ) , upper ( g )].

With the result of Lemma 1, we can obtain the candi-date set by mining the set of FGs from D using lower ( g )as the minimum support threshold and upper ( g )asthemax-imum support threshold. However, according to the anti-monotone property of the support measure, the graphs with higher support are always generated before those with lower support, no matter adopting a breadth-first or a depth-first strategy. As a result, the maximum threshold upper ( g )is not able to speed up the mining process. Therefore, generat-ing the candidates by mining the FGs from D with a support range is still not efficient enough, especially when lower ( g ) is small or D is large. This motivates us to devise a more efficient and effective approach to generate the candidates.
From Definition 1, it follows that if  X &gt; 0, then supp ( q, g ) &gt; 0. This means that q and g must appear together in at least one graph in D . This also implies that  X  g  X  base ( A q appears in at least one graph in the projected database of q ,
D q .Since D q is in general much smaller than D ,this gives rise to the following natural question: can we mine the candidate set more efficiently from D q instead of D ?
The challenge is that, however, we need to determine a minimum support threshold that can be used to mine the FGs from D q , so that no correlated answer graph is missed. Obviously, we cannot use a trivial threshold since it is too expensive. In this subsection, we derive a minimum support threshold which enables us to efficiently compute the can-didates from D q . Our solution is inspired by the following important observation as stated in Lemma 2.
 Lemma 2. Given a graph g ,supp ( g ; D q )= supp ( q, g ;
Proof. By the definition of the projected database, every graph in D q must contain q . Therefore, every graph in D that contains g must also contain q .Thus, supp ( g ; D q supp ( q, g ; D q ) holds. Since the number of graphs contain-ing both q and g in D is the same as that in D q ,thatis, freq ( q, g )= freq ( q, g ; D q ), we have supp ( q,g ) supp
Lemma 2 states that the support of a graph g in D is the same as the joint support of q and g in D q .This prompts us to derive the lower bound and upper bound for supp ( q, g ; D q ), given that g is correlated with q . Then, we can use the bounds as the minimum and maximum support thresholds to compute the candidates from D q .
 derive the bounds for supp ( q, g ).

First, by the definition of the joint support, we obtain the upper bound of supp ( q, g ) as follows:
Then, we construct a lower bound for supp ( q, g )fromDefi-nition 1. Given  X  ( q, g )  X   X  , we have the following inequality: where f ( supp ( g )) =  X  supp ( q ) supp ( g )(1  X  supp ( q ))(1
The lower bound of supp ( q, g ) stated in Inequality (2) can-not be directly used, since it is a function of supp ( g ), where g is exactly what we try to get using supp ( q, g ). However, since as stated in Lemma 1, we now show that this range can be used in Inequality (2) to obtain the lower bound of supp ( q, g ).
By investigating the property of the function f , we find that, f is monotonically increasing with supp ( g ) in the range of [ lower ( g ) , upper ( g )]. Therefore, by substituting supp ( g ) with lower ( g ) in Inequality (2), we obtain the lower bound of supp ( q, g ). We state and prove the bounds of supp ( q, g ) in the following lemma.

Lemma 3. If q and g are correlated, then the following bounds of supp ( q, g ) hold:
Proof. The upper bound follows by the definition of the joint support.

To show that the lower bound holds, we need to prove that the function f is monotonically increasing within the bounds of supp ( g ) given in Lemma 1. This can be done by applying differentiation to f with respect to supp ( g )as follows: f ( supp ( g )) =  X 
Thus, we need to prove that within [ lower ( g ) , upper ( g )], f ( supp ( g ))  X  0 or equivalently the following inequality:
First, if supp ( g )  X  upper ( g )  X  0 . 5, then (1  X  2  X  0 and hence f ( supp ( g ))  X  0.
 Now we consider the case when upper ( g )  X  supp ( g ) &gt; 0 . 5. Since the left hand side of Inequality (3) is less than 0, we take square on both sides of Inequality (3) and obtain:  X  a  X  ( supp ( g )) 2  X  a  X  supp ( g )+  X  2 (1  X  supp ( q )) where a =4  X  2 (1  X  supp ( q )) + 4 supp ( q ).

The left hand side of Inequality (4) is a quadratic func-tion, which is monotonically increasing within the range supp ( g )with upper ( g ) in this quadratic function: =  X  2 (1  X  supp ( q ))(  X  4  X  upper ( g )+1) &lt; X  2 (1  X  supp ( q ))(  X  4  X  0 . 5+1) (Since upper ( g ) &gt; 0 . 5) &lt; 0 .

Therefore, when 0 . 5 &lt; supp ( g )  X  upper ( g ), Inequality (4) holds and hence f ( supp ( g ))  X  0.

Thus, f is monotonically increasing within the range of in Inequality (2), the lower bound of supp ( q, g ) thus follows:
We use lower ( q, g )and upper ( q, g ) to denote the lower and upper bounds of supp ( q, g ) with respect to q ,asgiven in Lemma 3.

With the results of Lemmas 2 and 3, we propose to gener-ate the candidates by mining FGs from D q using lower ( q,g the minimum support threshold. A generated candidate set, C , is said to be complete with respect to q ,if  X  g  X  base ( g  X  X  . We establish the result of completeness by the fol-lowing theorem.

Theorem 1. Let C be the set of FGs mined from D q with plete with respect to q .

Proof. Let g  X  base ( A q ). Since  X  ( q, g )  X   X  , it follows that lower ( q, g )  X  supp ( q, g )  X  upper ( q, g ) by Lemma 3. By dividing the inequality by supp ( q ) on all the expressions, C is the set of FGs mined from D q using lower ( q,g ) supp minimum support threshold.

The result of Theorem 1 is significant, since it implies that we are now able to mine the set of candidate graphs from a much smaller projected database D q (compared with D ) with a greater minimum support threshold lower ( q,g ) supp pared with lower ( g ) which is equal to lower ( q, g ), as shown in Lemmas 1 and 3).
In this section, we present our solution to the CGS prob-lem. The framework of the solution consists of the following four steps. 1. Obtain the projected database D q of q . 2. Mine the set of candidate graphs C from D q ,using 3. Refine C by three heuristic rules. 4. For each candidate graph g  X  X  ,
Step 1 obtains the projected database of q .Thisstepcan be efficiently performed using any existing graph indexing technique [26, 6] that can be used to obtain the projected database of a given graph.
 Step 2 mines the set of FGs from D q using some existing FG mining algorithm [12, 25, 14]. The minimum support threshold is determined by Theorem 1. The set of FGs forms the candidate set, C . For each graph g  X  X  , the set of graphs in D q that contain g is also obtained by the FG mining process.

In Step 3, three heuristic rules are applied on C to further prune the graphs that are guaranteed to be false positives, as well as to identify the graphs that are guaranteed to be in the answer set.
 Finally, for each remaining graph g in C , Step 4(a) obtains D g using the same indexing technique as in Step 1. Then Step 4(b) checks the correlation condition of g with respect to q to produce the answer set. Note that, the joint sup-port of q and g , which is needed for computing  X  ( q, g ), is computed as ( supp ( g ; D q )  X  supp ( q )) by Lemma 2.
In the remainder of this section, we present three heuristic rules and our algorithm, CGSearch , to solve the problem of CGS.
To check whether each graph g in C is correlated with q , a query operation to obtain D g is needed for each candidate (Step 4(a)). The step can be expensive if the candidate set is large. Thus, we develop three heuristic rules to further refine the candidate set.

First, if we are able to identify the graphs that are guar-anteed to be correlated with q before processing Step 4, we can save the cost of verifying the result. We achieve this goal by Heuristic 1.

Heuristic 1. Given a graph g ,if g  X  X  and g  X  q ,then g  X  base ( A q ) .

Proof. Since g  X  q ,wehave supp ( q, g )= supp ( g ). More-over, since g  X  X  ,wehave supp ( g, q ; D q )  X  lower ( q,g Lemma 2, we further have supp ( q, g )  X  lower ( q, g ).
By replacing supp ( q, g )with supp ( g )in  X  ( q, g ), we have
Now,  X  is monotonically increasing with supp ( g ), and supp ( g )= supp ( q, g )  X  lower ( q, g ). We replace supp ( g ) with its lower bound of lower ( q, g )= supp ( q )  X   X  2 (1  X  in  X  ( q, g ). Then,wehavethefollowing: Therefore, g  X  base ( A q ).

Based on Heuristic 1, if we find that a graph g in the candidate set is a supergraph of q ,wecanadd( g, D g )into the answer set without checking the correlation condition. In addition, since g is a supergraph of q , D g can be obtained when g is mined from the projected database D q .

We next seek to save the cost of unrewarding query opera-tions by pruning those candidate graphs that are guaranteed to be uncorrelated with q . For this purpose, we develop the following two heuristic rules.

Before introducing Heuristic 2, we establish the following lemma, which describes a useful property of the function  X  .
Lemma 4. If both supp ( q ) and supp ( q, g ) are fixed, then  X  ( q, g ) is monotonically decreasing with supp ( g ) .
Proof. Since both supp ( q )and supp ( q, g )arefixed,we first simplify  X  for clarity of presentation. Let x = supp ( g ), a = supp ( q, g ), b = supp ( q ), and c = supp ( q )(1  X  Then we have
The derivative of  X  at x is given as follows:
Since 0  X  x  X  1, we have x (1  X  x )  X  0. Thus, the sign of  X  ( x ) depends on the sign of ((2 a  X  b ) x  X  a ). Since ((2 a b ) x  X  a ) is a linear function, we can derive its extreme values by replacing 0 and 1 of x into the function. The two extreme values of ((2 a  X  b ) x  X  a )are(  X  a )and( a  X  b ), both of which are non-positive, since a  X  0and a  X  b . Therefore, we have ((2 a  X  b ) x  X  a )  X  0and  X  ( x )  X  0. It follows that  X  ( q, g )is monotonically decreasing with supp ( g ).

Heuristic 2. Given two graphs g 1 and g 2 ,where g 1  X  g 2 and supp ( g 1 ,q )= supp ( g 2 ,q ) ,if g 1 /  X  base ( A base ( A q ) .
 Proof. Since g 1  X  g 2 ,wehave supp ( g 1 )  X  supp ( g 2 ). Since supp ( g 1 ,q )= supp ( g 2 ,q )and supp ( q ) is fixed, by Lemma 4, we have  X  ( q, g 1 )  X   X  ( q, g 2 ). Since g 1 /  X  base (  X  ( q, g 1 )  X   X  . Therefore,  X  ( q, g 2 )  X   X  ( q, g 1 ) have g 2 /  X  base ( A q ).

By Lemma 2, if supp ( g 1 ,q )= supp ( g 2 ,q ), then we have supp ( g 1 ; D q )= supp ( g 2 ; D q ). Thus, Heuristic 2 can be ap-plied as follows: if we find that a graph g is uncorrelated with q , we can prune all the subgraphs of g that have the same support as g in D q .

We now use the function f again to present the third heuristic: f ( supp ( g 1 )) =  X  supp ( q )(1  X  supp ( q )) supp ( g
Heuristic 3. Given two graphs g 1 and g 2 ,where g 1  X  g 2 if supp ( g 2 ,q ) &lt;f ( supp ( g 1 )) ,then g 2 /  X  base ( Proof. Since g 1  X  g 2 ,wehave supp ( g 1 )  X  supp ( g 2 ). By Lemma 1, the necessary condition for  X  ( q, g 2 )  X   X  is that, supp ( g 2 ) should fall within the range [ lower ( g 2 ) , upper ( g As shown in the proof of Lemma 3, the function f is mono-tonically increasing within the range [ lower ( g 2 ) , upper ( g Therefore, we have supp ( g 2 ,q ) &lt;f ( supp ( g 1 ))  X  By replacing supp ( g 2 ,q )with f ( supp ( g 2 )) in  X  ( q, g have the following derivations:  X  ( q, g 2 ) &lt; f ( supp ( g 2 )) Therefore, we have g 2 /  X  base ( A q ).

Note that, supp ( g 2 ,q ) &lt;f ( supp ( g 1 )) also implies g base ( A q ). This is because g 1  X  g 2 implies supp ( g supp ( g 2 ,q ). Therefore, we have supp ( g 1 ,q ) &lt;f ( supp ( g Similarly, by replacing supp ( g 1 ,q )with f ( supp ( g 1 we can have  X  ( q, g 1 ) &lt; X  and thus g 1 /  X  base ( A q
By Lemma 2, we have supp ( g 2 ,q )= supp ( g 2 ; D q )  X  Thus, if supp ( g 2 ,q ) &lt;f ( supp ( g 1 )), then supp ( g supp ( q ) . Thus, Heuristic 3 can be applied as follows: if we find that a graph g is uncorrelated with q , we can prune all the subgraphs of g that have support values less than Now, we present the CGSearch algorithm. As shown in Algorithm 1, after we obtain the candidate set C from the projected database D q (Lines 1-2), we process each candi-date graph in C according to the descending order of the graph sizes. Then, Lines 4-5 applies Heuristic 1 to include the supergraphs of q  X  X  directly into the answer set with-out performing the query operation (as in Line 7). For other graphs in C , if they are verified to be correlated with q ,wein-clude them in the answer set (Lines 8-9); otherwise, Heuris-tic 2 (Lines 11-12) and Heuristic 3 (Lines 13-14) are applied to further reduce the search space so that the unrewarding query costs for false-positives are saved.
 Algorithm 1 CGSearch Input: A graph database D ,aquerygraph q , and a corre-lation threshold  X  .
 Output: The answer set A q . 1. Obtain D q ; 3. for each graph g  X  X  in size-descending order do 4. if ( g  X  q ) 5. Add ( g, D g )to A q ; 6. else 7. Obtain D g ; 8. if (  X  ( q, g )  X   X  ) 9. Add ( g, D g )to A q ; 10. else 11. H 2  X  X  g  X  X  : g  X  g, supp ( g ; D q )= supp ( g ; D q 12. C X  X  X  H 2 ; 13. H 3  X  X  g  X  X  : g  X  g, supp ( g ; D q ) &lt; f ( supp ( 14. C X  X  X  H 3 ;
We now prove the soundness and completeness of the re-sult returned by CGSearch algorithm. In other words, we prove that CGSearch is able to precisely return A q with respect to a given q .

Theorem 2. The answer set, A q , returned by Algorithm 1, is sound and complete with respect to q .

Proof. We first prove the soundness.  X  ( g, D g )  X  X  q , ( g, D g )isaddedto A q in either Line 5 or Line 9. For the case of Line 5, we have proved in Heuristic 1 that g is cor-related with q ; while for the case of Line 9, the soundness is guaranteed in Line 8. Thus, the soundness of A q follows.
It remains to show the completeness. By Theorem 1, the candidate set, C , produced in Line 2 of Algorithm 1 is com-plete.  X  g  X  X  ,if g is not included in A q ,then  X  ( q, g )is checked to be less than  X  (Line 10) or g is pruned by Heuris-tics 2 or 3 (Lines 11-14). For all cases, g is proved to be uncorrelated with q andthusisnotin A q . Therefore, the completeness of A q follows.

Example 2. Consider the graph database in Figure 1 and the query q in Figure 2(a). Let  X  =0 . 6. CGSearch (Line1)firstobtains D q = { g 1 ,g 2 ,g 3 ,g 4 } .Thus,wehave supp ( q )=0 . 4and lower ( q, g )=0 . 19. Then, CGSearch (Line 2) mines FGs from D q using 0 . 19 0 . 4 =0 . 475 as the min-imum support threshold and obtains 9 candidates, which are shown in Figure 2(b). The number following  X : X  in the figure is the support of each candidate in D q .

Since the candidates are sorted in descending order of their size, CGSearch first processes c 1 .Since c 1 is a super-graph of q ,( c 1 , D c 1 ) is directly included into A q 1. Note that D c 1 = { g 1 ,g 2 } can be obtained in the process of mining the candidates from D q ,since c 1 is a supergraph of q .

Then, CGSearch processes c 2 to obtain D c 2 = { g 2 ,g 3  X  . Then, CGSearch computes H 2 = { c 6 } since c 6  X  c and supp ( c 6 ; D q )= supp ( c 2 ; D q )=0 . 5. CGSearch fur-ther computes H 3 = { c 4 ,c 9 } since c 4  X  c 2 , c 9  X  c supp ( c 4 ; D q )= supp ( c 9 ; D q )=0 . 75 &lt; 0 . 76 = as shown in Figure 2(b). Therefore, after processing c C = { c 3 ,c 5 ,c 7 ,c 8 } .

Similar to c 1 , CGSearch finds that c 3 is a supergraph of q and ( c 3 , D c 3 ) is directly included into A q by Heuristic 1. For c 5 , after obtaining D c 5 , CGSearch computes  X  ( c 0 . 61  X   X  ,so( c 5 , D c 5 ) is added into A q . Finally, by querying c and c 8 ,since  X  ( c 7 ,q )=0 . 4 &lt; X  and  X  ( c 8 ,q )=0 . 82 CGSearch adds ( c 8 , D c 8 )into A q .

Therefore, A q = { ( c 1 , D c 1 ) , ( c 3 , D c 3 ) , ( c Among the 9 candidates, 5 of them do not need to perform correlation verification by applying Heuristics 1 to 3.
When carrying out the exhaustive search, there are 40 subgraphs for such a small and simple graph database. If we generate the candidate set by mining FGs from D using lower ( g )=0 . 19 and upper ( g )=0 . 64 as support thresholds, there are still 16 graphs in the candidate set. This clearly illustrates that the candidate generation from the projected database indeed significantly reduces the search space. Figure 2: An Example Query and Its Candidate Set
To apply the three heuristic rules in our algorithm, we need to obtain supergraphs or subgraphs of a given graph (Lines 4, 11 and 13 of Algorithm 1) by testing subgraph isomorphism. However, subgraph isomorphism testing is an expensive operation and we want to avoid it as much as pos-sible. We find that the number of subgraph isomorphism testings can be effectively reduced by using a depth-first FG mining algorithm (such as gSpan [25]) for the candidate generation. For a depth-first mining process, the FGs gen-erated can be organized by a prefix tree, in which a child is a supergraph of its parent. Thus, by following the root-to-leaf paths (simply called path ) in the prefix tree, we are able to determine the subgraph-supergraph relationship without performing subgraph isomorphism testing.

If we only follow a path in the prefix tree and do not check the relationship of the graphs that appear in different paths, we are not able to identify all the graphs in H 2 and H , as well as all the supergraphs of q . However, we note that there is a trade-off here. On the one hand, if we fully apply the three heuristic rules by cross-checking the graphs in different paths to find all the subgraph-supergraph rela-tionships, more subgraph isomorphism testings have to be performed but less candidates are needed for verification of correlation condition. On the other hand, if we only par-tially apply the three heuristic rules by simply following the paths in the prefix tree, no subgraph isomorphism testing is needed but more candidates are required for verification. We demonstrate further this trade-off in our experiments.
We evaluate the performance of our solution to the CGS problem on both real and synthetic datasets.
The real dataset contains the compound structures of can-cer and AIDS data from the NCI Open Database Com-pounds 1 . The original dataset contains about 249K graphs. By preprocessing and removing the disconnected graphs, we randomly select 100K graphs for our experiments. On aver-age, each graph in the dataset has 21 nodes and 23 edges. The number of distinct labels for nodes and edges is 88.
To test the scalability of CGSearch on graph size, we de-sign a synthetic graph generator (see details in GraphGen We generate four synthetic datasets by varying the average number of edges in a graph from 40 to 100. Each synthetic dataset has 100K graphs. The number of distinct labels is 30 and the average graph density is 0.15.

We use FG-index [6] to obtain the projected database of a graph. In all experiments, we set the minimum support threshold and the frequency tolerance factor in FG-index to be 0 . 03 and 0 . 05, respectively. We use gSpan [25] to mine the FGs for generating the set of candidates. All experiments were run on a linux machine with an AMD Opteron 248 CPU and 1 GB RAM.

The efficiency of CGSearch is based on the effective candi-date generation from the projected database and the three heuristic rules. Since there is no existing work on mining correlations from graph databases, we mainly assess the ef-fects of the candidate generation method and the heuristic rules on the performance of our algorithm.

To justify the effect of the candidate generation from the projected database on speeding up the mining process and on reducing the search space, we implement the approach whose candidates are mined from the whole database with a support range. Furthermore, to show the effect of the heuristic rules on refining the candidate set, we make three variants of our algorithm: CGSearch P , CGSearch F and CGSearch N . Among them, CGSearch P and CGSearch F are implemented based on the different strategies of apply-http://cactus.nci.nih.gov/ncidb2/download.html http://www.cse.ust.hk/graphgen ing the heuristic rules as discussed in Section 5.3. Table 2 summarizes the algorithms tested in our experiments.
Since the complexity of the CGS problem mainly depends on the support of the query, we randomly generate four sets of queries, F 1 , F 2 , F 3 ,and F 4 , each of which contains 100 queries. The support ranges for the queries in F 1 to F 4
Figure 3 reports the performance of CGSearch P and Range on the real dataset when varying the support of the queries. Figures 3(a-b) show the running time and memory consump-tion per query. On average, CGSearch P is two orders of magnitude faster and consumes 10 times less memory than Range. For both CGSearch P and Range, the time taken by the candidate generation dominates. We observe that, CGSearch P is slightly slower for the query set F 1 and F This is because the time for generating the candidates not only depends on the size of the projected database (i.e., supp ( q )), but also depends on the minimum support thresh-old of F 4 is the highest among all the query sets, its pro-jected database is the largest, which increases the mining time slightly. While for F 1 , its low minimum support thresh-old results in slightly longer processing time. Compared with Range, the running time of CGSearch Pismuchmore stable. For all support ranges, CGSearch Ptakes2to4 seconds for each query, while the running time of Range is largely influenced by the support of the query. With the decrease in the support of the query, the running time of Range increases rapidly from 100 seconds to 400 seconds.
We show the size of the candidate sets of CGSearch P and Range in Figure 3(c). The size of the answer set is also shown as a reference. It is obvious that the size of the candidate set produced by CGSearch Pismuchcloserto that of the answer set. Compared with Range, the candidate set of CGSearch P is over an order of magnitude smaller.
Figure 4 reports the performance of CGSearch P and Range when varying the minimum correlation threshold  X  from 0 . 6 to 1. We test all query sets on the real dataset for both CGSearch P and Range. For clarity of presentation, we only present F 4 for Range. But we remark that Range performs the best on F 4 among all the query sets, which means that the performance of Range on F 4 is the lower bound.
As shown in Figure 4, for all values of  X  , CGSearch Pis over an order of magnitude faster and consumes 6.5 times less memory than Range on F 4 . Given a query, with the decrease in  X  , the minimum support threshold used to gen-erate the candidates also decreases for both CGSearch Pand
Figure 3: Performance on Varying Query Support Range. Hence, the processing time of both CGSearch Pand Range increases with the decrease in  X  . We find that, when varying  X  , the running time of CGSearch Pon F 1 and F 2 is less stable than that on F 3 and F 4 . We also observe similar phenomenon for Range on F 1 and F 2 (not reported in the figure). This is because the small minimum support thresh-old results in a large number of candidates. In this case, the time taken by candidate generation no longer dominates the total processing time. Instead, much more time is spent on querying the candidates by FG-index to verify the correla-tion condition. For example, for the query set F 1 ,when  X  = 1, only 3% of the total time is spent on querying the candidates; while when  X  =0 . 6, more than 60% of the total time is spent on querying the candidates. This explains the trend of the running time for queries of low support.
In order to show the effect of the heuristic rules clearly, we get rid of the time taken by the candidate generation and only present the time for querying candidates and checking the correlation condition.

Figure 5 shows the time on F 4 for the three variants of CGSearch at different values of  X  .When  X  =0 . 6, the number of candidates is large. Therefore, CGSearch Fper-forms the best, since the cost for querying the candidates is much larger than the cost for fully applying the heuristic rules. In this case, CGSearch P is slower than CGSearch F since partially applying the heuristic rules is not able to fur-ther reduce the number of candidates as effectively as does CGSearch F. However, with the increase in  X  , and hence the decrease in the size of candidate set, CGSearch Pout-performs CGSearch F. This is because, given the smaller number of candidates, the full application of the heuristic rules which involves subgraph isomorphism testings is more costly than querying the candidates by FG-index. This sug-gests a good strategy for applying the heuristic rules: when the number of candidates is large, we can use CGSearch F to reduce the search space as much as possible; when the number of candidates is relatively small, we can simply use CGSearch P.

In most of the cases, CGSearch N is the worst, since all the candidates need to go through the verification of correlation condition. However, if the number of candidates is small, it is possible that CGSearch F is even slower than CGSearch N due to too many subgraph isomorphism testings performed when fully applying the heuristic rules. Therefore, it can be seen from Figure 5 that the time of CGSearch Fisal-most the same as that of CGSearch N for high values of  X  . However, in general, CGSearch P outperforms CGSearch N, since the partial application of the heuristic rules requires no subgraph isomorphism testing due to the prefix tree, as discussed in Section 5.3.
Since the graphs in the real dataset are of small size (av-eragely 23 edges per graph), we use the synthetic datasets to test the scalability of CGSearch and Range on different graph sizes.

Similar to the experiments on the real dataset, we gener-ate four sets of queries, F 1 to F 4 , with the same setting of support ranges as in Section 6.2.

For clarity of presentation, we only show the results of F and F 4 , which are of the largest and the smallest support ranges, respectively. Figure 6 reports the performance of CGSearch P and Range. For F 1 ,CGSearch Pisuptofour orders of magnitude faster and consumes 41 times less mem-ory than Range. While for F 4 ,CGSearch P is still over an order of magnitude faster and consumes 6 times less memory than Range. The smaller improvement on the performance of CGSearch P over Range for F 4 is because the average number of candidates of Range for F 4 is over three orders of magnitude smaller than that of Range for F 1 (111 , 955 for F 1 and 795 for F 4 ). Figure 6 also shows that, CGSearch P is much more stable on resource usage than Range when varying graph sizes.
There have been a number of studies on mining corre-lations from various types of databases. Pearson X  X  correla-tion coefficient, as well as its computation form for binary variables,  X  correlation coefficient, are prevalently used as a correlation measure. Sakurai et al. [20] use Pearson X  X  correlation coefficient to define the lag correlation between two time sequences. Xiong et al. [23] apply  X  correlation coefficient to define the strongly correlated pairs in transac-tion databases. An upper bound of  X  , as well as monotone properties of the upper bound, are identified to facilitate the efficient mining process. Recently, Zhang and Feigenbaum [29] also adopt  X  correlation coefficient to measure the corre-lated pairs in transaction databases. An efficient algorithm that uses min-hash functions as the pruning method is de-veloped. To the best of our knowledge, our work is the first application of  X  correlation coefficient in the context of graph databases.

In literature, many other correlation measures are pro-posed for different applications. For market-basket data, correlation measures include  X  2 [5], interest [5], all-confidence [13, 15], bond [15], h-confidence [24], and so on. For multi-media data, Pan et al. [16] use random walk with restart to define the correlation between the nodes in the graph that is constructed from a multimedia database. For quantita-tive databases, Ke et al. [11] utilize mutual information and all-confidence to define the correlated patterns.

For similarity searching techniques developed for general graph models, Holder et al. [8] use the minimum descrip-tion length principle for inexact graph matching. Raymond et al. [18] propose an efficient algorithm, called MCES ,to perform similarity search measured by maximum common subgraphs. Yan et al. [27] develop a structural filtering al-gorithm, called Grafil , to filter graphs without performing similarity computations. Recently, Williams et al. [22] pro-pose an indexing technique that adopts graph decomposition methods to facilitate similarity search on graph databases. However, all of them focus on structural similarity search as indicated by their graph similarity measures, while our work captures statistical similarity defined by Pearson X  X  correla-tion coefficient.
We formulate the problem of correlated graph search, which takes into account the occurrence distributions of graphs us-ing Pearson X  X  correlation coefficient. By deriving the theo-retic bounds for the support of a candidate graph, we pro-pose to efficiently generate the candidate set by mining FGs from the projected database of the query graph. We de-velop three effective heuristic rules to further reduce the size of the candidate set. We propose an efficient algorithm, CGSearch, to solve the problem of CGS. The soundness and completeness of the query results returned by CGSearch are also formally proved. The experimental results justify the efficiency and effectiveness of the candidate generation and the heuristic rules. Compared with the approach that gen-erates the candidates directly from the database by a sup-port range, our solution is orders of magnitude faster and consumes much less memory. More importantly, CGSearch achieves very stable performance when varying the support of the queries, the minimum correlation threshold, as well as the graph size.
 Acknowledgement. This work is partially supported by RGC CERG under grant number HKUST6185/03E. We thank Dr. Xifeng Yan and Prof. Jiawei Han for providing us the executable of gSpan. We also thank the anonymous review-ers for their valuable comments.
