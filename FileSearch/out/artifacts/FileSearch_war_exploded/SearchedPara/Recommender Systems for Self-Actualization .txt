 Ever y day, we are confronted with an abundance of decisions that require us to choose from a seemingly endless number of choice options. Recommender systems are supposed to help us deal with this formidable task, but some scholars claim that these systems instead put us inside a  X  X ilter Bubble X  that severely limits our perspectives. This paper present s a new direction for recommender systems research with the main goal of supporting users in developing, exploring, and understanding their unique personal prefere nces.
  X  Information systems Recommender system s  X  Human -centered computing Interaction paradigms .
 Recommender Systems; Filter Bubble; Choice Overload; Self -Actualization . Recommender systems were invented in the 1990s to help users find useful and attractive items among the large assortments that came available with the growth of the Internet [31]. Such systems are now embedded in a wide range of online applicat ions that help us find desirable products, and increasingly permeate our online interactions. As Eric S chmidt , CEO of Google, has pointed out, recommendation techniques are now em ployed in virtually every online service, including search engines and socia l networks. As people experience most of the Web through these services, it becomes very hard for them to watch or consume something that has not in some sense been tailored to their needs [15].
 While the move to a personalized Web has been welcomed by most, some scholars have vo iced an interesting critique against recommender systems: they argue that recommen der systems put users inside a filter bubble that severely limits their perspectives and that may make them complacent consumers of easy -to-consume items [28].
 What c auses this pushback against recommender systems? Is the filter bubble simply a consequence of our psychology, or is there something wrong with the way recommenders operate? And if so, what are the consequences of this shortcoming? And how can we solve it? As part of the discussion about the past, pre sent, and future of recommender systems, this paper attempts to start a dia -logue surrounding these questions. Particularly, it acknowledges some of the shortcomings  X  in recommender sys tems as well as their use rs  X  that have led to the filter bubble, and suggests a new direction for recommender systems research to address these shortcomings. This leads us to propose the development of Recommender Systems of Self -Actualization : personalized systems that have the ex plicit goal to not just present users with the best possible items, but to support users in developing, exploring, and understanding their own unique tastes and preferences .
 Such deep understanding of one X  X  own tastes is a particularly im -portant goal in d ecisions that have a resounding impact on one X  X  life  X  e.g. choosing an education, a job, a health insurance plan, or a retirement fund. For these types of decisions, rather than have people choose the easiest option, we wish to have them develop a strong se nse of determination of having selected the right path. A deep understanding of one X  X  own tastes is also important for cul -tural diversity  X  we want people to make lifestyle choices (e.g., music, movies and fashion) based on carefully developed personal tast es, rather than blindly followed recom mendations .  X  X he algorithm accounts for only 5% of the commercial success of our recommender systems [...] The interactive components of a recommender account for about 50 % X   X  Francesco Martin [22] . Traditionally, the field of recommender systems focused on developing more accurate algorithms [20, 31] . This goal appears reasonable: the more accurate the algorithm, the better the system can pre dict the best recommendations for the user , which in turn should lead to a better user expe rience. R esearchers have come to realize , though , that recommender s should go well beyond making accurate predictions. McNee et al. [25] , for example, argued that  X  X eing accurate is not enough X  , and that recommender systems should be studied  X  from a user -centric perspective to m ake them not only accurate and helpful, but a lso a pleasure to use X  . T hey also [26] suggested that researchers should investigate the inter -active components of the recommender system, i.e., the mecha -nism through which users indicate their preferences ( X  X reference elicitation X ) , and the i nter face that displays the recommendations . Subsequent work has indeed demonstrated that the algorithms that test best offline are not always the most successful in real life [8, 24] , especially when focusing on users X  subjective evaluation of the system [35] . Inspired by these findings and the need to thoroughly evaluate recommender systems from a user -centric standpoint, researchers have developed conceptual frame works for the user -centric evaluation of recommender sys tems (cf. [19, 29] ), and are increasingly evaluating the effects of all aspects of a recommender system (not just the algorithm, but also the preference elicitation method and the presentation of the recom -mendation list) on all aspects of the user X  X  interaction experience (not just the accuracy of the algorithm, but also subjective aspects such as system satisfaction and choice satisfaction) [18] . This more inclusive perspective has uncovered several interesting problems that escape the attenti on of traditional recommender systems research. One of these problems is the inadequacy of existing preference elicitation methods [17]. Current recommend -ers rely on either implicit or ex plicit feedback for preferenc e elicitation. Implicit feedback is easy to gather, but can result in  X  X verspecialization X , because the system only recommends items that it thinks the user likes : Even if the users X  actual preferences are wider than the provided set of recommendations, th e system will end up targeting a very specific preference. Diversifying the recommendation can prevent this [30, 36] but the main downside of diversifications is that it depends on the sys tem X  X  interpretation of d iversity rather than the users X  . Explicit feedback fares slightly better, since users can rate items negatively , thereby preventing over specialization . However, research shows that users X  ratings are often inaccurate [2, 14] , arguably because consumers X  prefer -ences are often constructed on the spot [3]. If users are often una -ble to accurately express their preferences, then how much can be gained by accurately predicting said preferences? This conundrum demonstrates that the traditional recommender goal of accurately predicting these preferences may very well be a chimera . Another problem is choice o verload [4, 13] : Given that consumers construct their preference on the spot, it is no surprise that they encounter difficulties in selecting items from the Top -N recom-mendations. Overcoming choice overload is one of the challenges of research on the presentation of recommendations , and a good solution to this problem has yet to be devised.  X  X Computers ] are useless. They can only g ive you answers. X  As the pervasiveness of recommender systems increases, argu -ments have emerged that attack the very nature of recom mender systems. Spearheaded by Eli Pariser, these voices claim that by filtering all but the top predicted items, recommender systems provide a very myopic view of the world. Pariser argues that users get stuck in a filter bubble : recommenders isolate us f rom a diversity of viewpoints, content, and experiences, and thus make us less likely to discover and learn new things [28] A careful examination of the Filter Bubble phenomenon in recommender systems has validated the occurrence of this effect, albeit to a lesser extent than suggested by Pariser X  X  claims [27]. Regardless of the actuality of the effect, the idea of the Filter Bubble has gained a lot of traction in popular opinion and it is interesting to analyze why this may be the case. Psychologically, the Filter Bubble plays into our tendency for loss aversion and our fear of missing out . For recommender system users, it means that in certain situ ations the sum of the (presumed) missed opportunities presented by all the items that are ignored by the recommender, may loom larger than the bene fits of receiving a short -list of items tailo red to a specific subset of their pref -erences. In other words, the joy of getting rec ommendations may be spoiled by our worry of missing out on other enjoyable items that were not recommended. This looming loss may decrease their satisfactions with the system  X  and even their satisfaction with their choices  X  because de cision-making research shows that the mere thought of missed opportunities may reduce one X  X  decision confidence [7], and cause one to regret one X  X  decision [13]. The existence of the Filter Bubble may have a long -term conse -quence that is arguably worse than the fear of missing things : The possibility that users will eventually embrace it. This is not an unlikely scenario, because recommender systems have been shown to have persuasive qualities: users are prone to agree with a recommender X  X  predicted ratings [8] and to follow a recom -mender X  X  advice [12]. This creates what Lanier calls a  X  X ositive feedback loop X  [28] : users will unknowingly make themselves better  X  X it in X  with a system , i.e., make themselves more easily targetable by the algorithm. Rather than going through the trouble of developing our own unique taste, we take the default setting  X  something we are prone to do [33]  X  and simply consume whatever the recommender serves us.
 T he positive feedback loop leads to the very worrying concern that recommender algorithms may gradually replace human crea -tivity and understanding [21] : if we embrace the Filter Bubble, we run the risk of getting locked in by th e algorithm, which sub -sequently becomes a self -fulfilling prophecy. When this happens, recommenders do not just inhibit discovery and learning, they actively work against it. Pariser is afraid that personalization will create  X  X elf -fulfilling identities X : Your identity shapes your recommendations, and your recommendations then shape what you believe, and what you care about.
 If recommender algorithms indeed turn into self -fulfilling prophecies, then what will they recommend? Pariser argues that the items t hat tend to make it past the filter bubble are usually the kinds of things that are  X  X asy X  to like or consume [28] . Psycho -logically, this phenomenon is bas ed on a human tendency called temporal discounting [9] : We tend to discount future gains, and are thus likely to choose guilty pleasures that provide instant grati -fication (a funny Internet meme or a spectacular action movie) over substantive educational experiences of long -term value (a complex essay or an acclaimed period piece). This leads to what Boyd calls  X  X he psychological equivalent of obesity X , where all recommended content is the cerebral equivalent of junk fo od [5] .  X  X n order to find his own self, [a person] needs to live in a milieu where the possibility of many different value systems is explicitly recognized and honored X   X  Christopher Alexander et al. [1] . The Filter Bubble persists, despite the fact that recommender systems researchers have taken several steps in a more user -centric direction [20, 30] . One reason for this is that virtually all recommender systems are built with the goal of recommending good items to the user. If we are to solve the F ilter Bubble prob -lem, we will have to build recommender systems with a different goal in mind: a  X  X ecommender System for Self -Actualization X  (RSSA), which supports users in developing, exploring, and understanding their unique personal tastes. Below we ou tline how the operating principles of RSSAs differ from traditional recom -menders : RSSAs support rather than replace decision -making . Tradi -tional recommender s turn preferences into choice options, but research shows that user preferences are fleeting, con structed on the fly and vulnerable to distorting influences, rather than well -defined, fixed, and invariant [2, 3, 14] . RSSAs take the additional step to help u sers develop and express their preferences.
 RSSAs focus on expl oration rather than consumption. RSSAs do not focus on optimiz ing the probability that the user will like recommendations, but instead focus on exploring underdeveloped tastes. Consequently, th eir recommendations can be likened to  X  X amples X  or  X  X athways X , rather than  X  X lternatives X .
 RSSAs attempt to cover users X  tastes, plural. Research has shown that users X  preferences are not singular, but rather multi -faceted and only loosely connected [14] . Whereas traditional recommenders are targeted to fit any part of a user X  X  preferences, RSSAs endeavor to help the user discover all of these prefer ences. Implementing these operating principles will likely require a combination of new innovations in recommender system features, interfaces, and algorithms. In this paper we highlight the most straightforward innovation: Presenting recommendations that are not part of the Top -N. Existing research on critiquing [6] and diversi fication [36] already expand the notion of the Top -N to offer a better alternatives, but these techni ques still focus on providing  X  X ood X  recommendations. In contrast, we suggest four completely different recommendation lists , displayed alongside but separately from the Top -N. Each new list is next discussed in detail.  X  X hings we think you will hate  X  A r ecommender may mistaken ly predict a very low rating for some of the items that the user actually likes. T hose mistakes will be hard to correct , since the system never recommends them. We propose to present a list of things the sys tem predicts the user wil l hate . This allow s users to either confirm or correct these prediction s, thereby mitigating loss aversion . To resolve mistakes more quickly, corrections can be given a higher weight, which counter s the unwanted persuasive effect of the rec ommender.  X  X  hings we have no clue about  X  Another cause for  X  X aps X  in the recommender X  X  knowledge of users X  tastes is the fact that certain preferences simply remain unexpressed when the system hones in too quickly on a presumptive Top -N. We propose to show a list of har d-to-predict items that may be used identify unexpressed preferences. This involves modifying existing active learn ing approaches [16] to detect not just some but all of th e user X  X  preferences .  X  X hings y ou X  X l be among the first to try X  Solutions for the item cold -start problem are abound [32], but they ignore the fact that certain users may (at times) actually be excited to try out new items. We propose to present a list of yet -to-be-rated items to users that are identifie d (using a  X  X ipster measure X ) as having a high willingness to try out new items.  X  X hings that are polarizing  X  Nearest -neighbor recommender al -gorithms often give recommendations that the neighbors unani -mously like. It is possible that certain polarizing items divide these neighbors into rivaling camps; some of them may absolutely love a controversial item, while others absolutely hate it. Experi -encing controversial items could have an important value to the user thoug h, because such items would allow the user to develop unique tastes. We therefore propose to detect such items (e.g. by measuring the rat ing variability of items among the neighbors, or by sub -clustering the neighbors, and then selecting items that best discriminate between clusters) and to present them to the user. There are several reasons why displaying items that are unrelated to the Top -N can help overcome the Filter Bubble problem. Showing items outside the Top -N is arguably the only way to combat th e fear of missing things , and mitigating this fear may in-crease the users X  satisfaction with the system and overall choice satisfaction [4]. Furthermore, by getting more feedback on items outside the Top -N, recommender s can get a better idea of the users X  tastes. It can also help users to better understand their own tastes, because developing one X  X  tastes means trying new things, even if this includes things that one may not like [34]. That said, there are other, more interaction -related features that could also contribute to the support of self -actualization. One of these features is to connect people . An unfortunate side effect of recommender systems is that advice -giving has become passive and indirect : Users have no idea how exactly their tastes are being used to help other users, and they have no active say in the process. We therefore propose a feature for users to a ctively recommend items to other user s . This can contribute to a sense of fulfilment (helping others) and pride (being called upon for ex -pertise). An algorithm that uses advances in the field of people recommendation can be used to drive this process. This feature is expandable beyond simple one -to -one connections between users, to recommend groups of users to come together and develop  X  X aste -based communities X  that are based on shared pref erences , e.g. regarding certain controversial items . Another suggestion is to construct a human -readable taste profile to help users explore and understand their own tastes. The devel -opers of some commercial recommender systems (e.g. OkCupid, The EchoNest) have recently started to share fascinating insights into consumer tastes , us ing compe lling infographics to highlight surprising preference dynamics, sometimes broken down by state , gender, age or other demographic dimensions. Could such analyses be personalized? For example, a simple analysis could be condu cted to figure out which of your tastes are predictable (e.g. the fact that you like both Mozart and Bach), and which are unique (e.g. the fact that besides these two, you also like Nicki Minaj). This feature allow s users to explore the common and unique sides of their identity, and  X  if co mparable across users  X  provide a starting point for establishing sub -cultures of u niquely like -minded individuals.  X  X e need help overcoming our rationality sometimes, and allow This paper has unpacked the filter bubble critique of recom -mender systems, and proposed a new path for research: to support rather than replace human decision -making. By making us better understand our own preferences, R ecommender S ystems for Self -Actualization will improve our potential to have confidence in (and take ownership over) our life decisions . T h ey allow us to each develop a unique personal style, thereby supporting Maslow X  X  need for Esteem and Self -Actualization [23] , and prevent ing the erosion of our autonomy as consumers. This would usher the field of recommender systems in to a new er a of compu -ting, where systems move from serving our basic needs (e.g.  X  X ind item X X ) to supporting us to reach our full potential (e.g. helping us understand an d reflect upon our own desires) . We are actively pursuing the RSSA features presented in this p aper, and we en -courage others to join us in this exciting quest to pop the filter bubble. This research was supported in part by the NSF award IIS 1565809. [1] Alexander, C., Ishikawa, S. and Silverstein, M. 1977. A [2] Amatriain, X., Pujol, J.M., Tintarev, N. and Oliver, N. [3] Bettman, J.R., Luce, M.F. and Payne, J.W. 1998. [4] Bollen, D., Knijnenburg, B.P., Willemsen, M.C. and Graus, [5] Boyd, D. 2010. Streams of Content, Limited Attention: The [6] Chen, L. and Pu, P. 2011. Critiquing -based recommenders: [7] Chernev, A. 2003. When More Is Less and Less Is More: [8] Cosley, D., Lam, S.K., Albert, I., Konstan, J.A. and Riedl, [9] Doyle, J.R. 2013. Survey of time preference, delay [10] Fifield, W. 1964. P ablo Picasso: A Composite Interview. [11] Gelernter, D. 2010. Time to start taking the Internet [12] Gretzel, U. and Fesenmaier, D.R. 2006. Persuasion in [13] Iyengar, S.S. and Lepper, M.R. 2000. When choice is [14] Jameson, A., Willemsen, M.C., Felfernig, A., de Gemmis, [15] Jenkins, H.W. 2010. Google and the Search for the Future. [16] Karimi, R., Freudenthaler, C., Nanopoulos, A. and [17] Knijnenburg, B.P., Reijmer, N.J.M. and Willemsen, M.C. [18] Knijnenburg, B.P. and Willemsen, M.C. 2015. Evaluating [19] Knijnenburg, B.P., Willemsen, M.C., Gantner, Z., Soncu, [20] Konstan, J.A. and Riedl, J. 2012. Recommender systems: [21] Lanier, J. 2010. You Are Not a Gadget: A Manifesto . [22] Martin, F .J. 2009. Top 10 Lessons Learned Developing [23] Maslow, H.A. 1943. A theor y of human motivation. [24] McNee, S.M., Albert, I., Cosley, D., Gopalkrishnan, P., [25] McNee, S.M., Riedl, J. and Konstan, J.A. 2006. Being [26] McNee, S.M., Riedl, J. and Konstan, J.A. 2006. Making [27] Nguyen, T.T., Hui, P. -M., Harper, F.M., Terveen, L. and [28] Pariser, E. 2012. The filter bubble: how the new [29] Pu, P., Chen, L. and Hu, R. 2011. A User -centric [30] Resnick, P., Garrett, R.K., Kriplean, T., Munson, S.A. and [31] Resnick, P., Iacovou, N., Sushak, M., Bergstrom, P. and [32] Schein, A.I., Popescul, A., Ungar, L.H. and Pennock, D.M. [33] Thaler, R.H. and Sunstein, C. 2008. Nudge : improving [34] Tian, K.T., Bearden, W.O. and Hunter, G.L. 2001. [35] Torres, R., McNee, S.M., Abel, M., Konstan, J.A. and [36] Ziegler, C. -N., McNee, S.M., Konstan, J.A. and Lausen, G. 
