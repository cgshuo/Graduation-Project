 The VAR model is widely used for analyzing relations between variables in time series data since the pioneering works [Sims 1980]. This method infers the relations between variables by regressing the current observation on past observations, and interprets the autoregression coefficients as causal effects. There are two main drawbacks of this method. The first one is that the VAR method provides no information on contempora-neous causal order. The second one is that least square estimators become unreliable when the dimensions of time series are large and the number of samples are limited. To capture both temporal and contemporaneous causal relations, the SVAR model is proposed that estimates contemporaneous coefficient matrices by orthogonalizing the VAR residuals [Bernanke 1986; Blanchard and Watson 1987; Sims 1986]. However, this article shows that the SVAR model is incapable of deciding contemporaneous causal orders for Gaussian process. Recently, graphical models have been recognized useful on time series analysis, and Bayesian network learning algorithms have been used to identify the contemporaneous causal orders in SVARs [Chen and Chihying 2007; Demiralp and Hoover 2003]. The main idea of these works is using the least squares approach to estimate a VAR, and then applying Bayesian network learning algorithms to the VAR residuals to identify contemporaneous causal orders. This approach can solve the contemporaneous causal order problem but relies on the quality of the estimation of VARs. Therefore, the difficulty of unreliable least squares estimators involved by high-dimensional time series still exists in these works.
In this work, we provide a deep analysis on the reason that the SVAR model is inca-pable of identifying the contemporaneous causal orders for Gaussian process. We show that the incapability is because the SVAR model fails to discover the structure that is faithful to the underlying distribution. Because Bayesian network learning algorithms can be employed to identify the faithful structure to the underlying distribution, in the remaining part of the work we propose a solution of applying Bayesian network learn-ing algorithms to mine causal relations in time series. In our approach, the Bayesian network learning algorithm is applied to time series data instead of the VAR residu-als, and temporal and contemporaneous causal relations are considered in a unified way. The difficulty of doing this is determining how to find a robust Bayesian network learning algorithm to deal with large size Bayesian networks. The reason is as follows. To represent a VAR model by a Bayesian network, the number of the vertices in the Bayesian network is several times larger than that of i.i.d. data, because the past ob-servations need to be considered. For example, to represent a second order VAR with 10 variables, there are 30 vertices in the Bayesian network. To decide whether there exists an edge between two vertices, the Bayesian network learning algorithms need to search all subsets of the entire vertex set to find a set of vertices d-separating these two vertices, and the results of CI tests serve as indicators of d-separation. Large net-works pose a difficulty on Bayesian network learning algorithms because of unreliable high-order CI tests [Ramsey et al. 2006].

The key step of using Bayesian network learning algorithm for causal mining in time series is determining how to avoid high-order CI tests even when the sizes of the underlying Bayesian networks are large. This work shows that to infer the structures of Bayesian networks, it is sufficient to test conditional independence conditioned on all subsets of Markov blankets, so that the largest order of CI tests does not dependent on the size of the network, but on the sizes of Markov blankets. With this results, determining how to avoid high-order CI tests when learning Bayesian networks is equivalent to determining how to identify Markov blankets without involving high-order CI tests. In this work, we apply the Incremental Association Markov Blanket (IAMB) algorithm [Tsamardinos et al. 2003b] to learn Markov blankets from data. The heuristic we use in this work is partial correlation, and the IAMB algorithm in this case is equivalent to the forward-backward linear regression [Draper and Smith 1966; Hocking 1976]. The IAMB algorithm enables us to identify Markov blankets of each vertex in a Bayesian network without involving high-order CI tests.

The contributions of this work are summarized as follows: (i) this work formally shows that the reason of the SVAR model being incapable of identifying contempora-neous causal order for Gaussian process is that faithfulness condition is violated under the SVAR model; (ii) this work provides a graph-theoretic method estimating SVARs and VARs, which avoids high-order regressions; (iii) this work formally proves that in Bayesian network learning if there exists a set of vertices d-separating two vertices, such a set can always be found within a subset of the Markov blanket of either of the given two vertices. The rest of the article is organized as follows. Section 2 reviews previous works related to ours. Section 3 clarifies the problem definition and several technical preliminaries. Section 4 discusses the reason that the SVAR model is inca-pable of identifying contemporaneous causal order and the necessity of Bayesian net-work learning algorithms. Section 5 provides a theoretical analysis on using Markov blanket information to search conditioning sets, and explains how to use our heuris-tic Bayesian network learning algorithm to estimate SVARs and VARs. Section 6 presentes some empirical comparison of our algorithm and the existing algorithms. Section 7 concludes our article with a summary of our finds. est in economic time series analysis since [Sims 1980], followed by a series of varieties. One of the varieties related to causal relation mining is the SVAR model [Bernanke 1986; Blanchard and Watson 1987; Sims 1986]. In the SVAR model, contemporaneous correlations are assumed to be interpreted causally. One typical solution of this type of methods is to estimate a standard VAR model, and then orthogonalize the covari-ance matrix of the residuals using the Cholesky decomposition. However, this work will show that under the SVAR framework, all the contemporaneous causal orders are equivalent for Gaussian processes, and the faithfulness condition is violated. The method presented in Swanson and Granger [1994] requires prior knowledge of the contemporaneous causal orders to identify the true SVAR models.
 learning algorithms have been widely used for causal discovery since the pioneering works [Pearl and Verma 1991; Spirtes et al. 1990]. To reduce computational complex-ity, the Peter and Clark ( PC ) algorithm [Spirtes and Glymour 1991] is a represen-tative one that has polynomial time complexity when Bayesian networks are sparse, but not efficient when networks are relatively dense. Markov blanket information is used by Bayesian network learning algorithms to reduce computational complex-ity and avoid high-order CI tests. The algorithms using Markov blanket informa-tion are the Grow-Shrink (GS) algorithm, [Margaritis and Thrun 1999], the Max-Min Hill-Climbing (MMHC) algorithm [Tsamardinos et al. 2006], and the Total Condition-ing (TC) algorithm [Pellet and Elisseeff 2008]. The GS algorithm learns the Markov blankets of variables by a step-wise procedure, and uses the Markov blanket infor-mation obtained to limit the sizes of conditioning sets when inferring the structures of Bayesian networks. The Bayesian network learning algorithm in this work can be viewed as an enhanced version of the GS algorithm in the sense that we show that the search space of conditioning sets can be reduced to the subsets of the Markov blankets. The MMHC algorithm uses the Min-Max Parents and Children (MMPC) algorithm [Tsamardinos et al. 2003a] to identify the parents and the children of each variable from data. However, identifying the parents and the children of a variable is a more difficult task than identifying the Markov blanket, because identifying all the spouses of a variable requires an exponential number of CI tests. The TC algorithm uses high-order CI tests to obtain Markov blanket information. In addition, the TC algorithm does not use Markov blanket information explicitly. The Two-Phase algorithm [Wang and Chan 2010], an improved version of the Three-Phase Dependency Analysis (TPDA) algorithm [Cheng et al. 2002], is our first attempt to learn Bayesian networks from Markov random fields. In this work, we improve this basic version by using Markov blanket information.
 network learning algorithms are used for identifying the contemporaneous causal order of a SVAR [Chen and Chihying 2007; Demiralp and Hoover 2003]. Demiralp and Hoover [2003] apply the PC algorithm to search the contemporaneous causal order in the residual covariance matrix. In Time Series Causal Models (TSCMs) [Chen and Chihying 2007], a score-based Bayesian network learning algorithm is used to dis-cover the causal structures in SVARs. Besides Bayesian network learning algorithms, the Linear Non-Gaussian Acyclic Model (LiNGAM) algorithm [Shimizu et al. 2006], an causation mining algorithm based on independence component analysis, has been applied for deciding the causal orders in SVARs [Hyvarinen et al. 2008] and in that work the authors show that ignoring the contemporaneous causal effects can lead to wrong estimation of temporal causal relations. All these works need to estimate VAR models first and then apply causation mining algorithms to the residual covariance matrices. Therefore, these methods are incapable of overcoming the difficulty that least squares estimators are unreliable when the scales of the problems are large. causal inference is proposed by Mooij et al. [2009], named Hilbert-Schmidt Indepen-dence Criterion HSIC regression. This regression approach minimizes the statistical dependence between regressors and residuals, rather than minimizing squared errors as the standard linear regression does. The algorithm proposed by Henao and Winther [2009] learns factor models and directed acyclic graphs in a unified framework. We call the algorithm FactorDAG in this article. This algorithm is closely related to VAR and Bayesian network learning, because VARs can be view as factor model with time struc-ture, and Bayesian networks are directed acyclic graphs representing certain probabil-ity distributions. Another algorithm for identifying the causal direction of time series is proposed by Peters et al. [2009]. This algorithm models time series as causal au-toregressive moving average process, and the causal direction of the time series is determined by the dependence between regression residuals and the time series itself. However, this algorithm is incapable of dealing with contemporaneous causal orders. The algorithm proposed by [Lin et al. 2010; Lozano et al. 2009] extends the concept of Granger causality [Granger 1980] to learn temporal causal relations in time series data. Because the limitation of Granger causality, this algorithm can only deal with two univariate time series at one time, and for multivariate time series, it learns the causal relations among data pairwisely. Another disadvantage of this algorithm is the incapability of finding contemporaneous causal orders. ter G . Boldface capitals X , Y , Z denote sets of random variables or vertices in a net-work. V is the set of all variables in the analysis. Italicized capitals like X , Y , Z are designated either constant matrices or random variables or the vertices in V , depend-ing on the context. Vectors are set in boldface lowercase, as a , b ; scalars in italics, as the number of samples n or the order of a VAR k . An undirected edge between vertices X and Y is denoted by X  X  Y and directed edge by X  X  Y or X  X  Y , depending on the orientation of the edge. We denote an observed time series by X i ( t )= x i ( t )for1  X  i  X  n and 1  X  t  X  m , where X ( t ) denotes random variable, x i ( t ) is the corresponding observation, i is the index of random variables and t is the index of time. The collection of all the variables at time t is denoted by n  X  1 vector X ( t ) and the observations x ( t ). The dynamic of the time series under the VAR is defined as where k is the order of the VAR, A  X  ,0  X   X   X  k , are n  X  n coefficient matrices, E ( t ) are disturbances satisfying E ( t ) E ( s )for1  X  t , s  X  m , t = s and the covariance matrix of E is Cov [ E ]= E . A VAR with order k is denoted by VAR(k). The SVAR assumes that the covariance matrix of disturbances can be interpreted as the contemporaneous causal structure, and the SVARs can be identified from VARs by applying Cholesky decomposition to the covariance matrix of the disturbances as follows: where L is a lower triangular matrix with strictly positive diagonal entries and L denotes the transpose of L . And for each E ( t ), find W ( t ) satisfying Plugging Eq. (3) into Eq. (1) and rearranging the formula, we get where B 0 = I  X  L  X  1 and B  X  = L  X  1 A  X  . And from Eq. (2) and Eq. (3), we know that The VAR model identified by orthogonalizing the contemporaneous variables in Eq. (4) is known as a SVAR. The coefficient matrices of the VAR in Eq. (1) can be estimated from data by the least squares method as follows [Richard and Wichern 2002]. Denote the observations by concise matrix notations: The least squares estimators of the coefficient matrices are given by the following formula: and the regression residuals are calculated by the formula: The drawback of using the least squares approach to estimate the structures of VARs is that when the dimensions of VARs are large and sample sizes are limited, the estimate coefficient matrices become unreliable. Even worse, when the number of samples is smaller than the production of the dimension of the VAR and the order of the VAR, namely m &lt; n  X  k ,thematrix ZZ becomes a singular matrix, the inverse of ZZ does not exist, and the least squares approach fails. This is an important motivation for us to apply the Bayesian network learning algorithm directly to the time series data instead of the regression residuals. A Bayesian network G B ( V , E ) is a directed acyclic graph used to represent a joint distri-bution over vertex set V in which a single vertex is associated with a random variable in data set. In this work, we use vertex to denote the random variable in the domain and the corresponding vertex in the Bayesian network, and E denotes the edge set of the Bayesian network. An edge from V i to V j ,for V i , V j  X  V , indicates that V i is a di-rect cause of V j . The joint distribution p represented by a Bayesian network obeys the local Markov property that for any vertex V  X  V , V is conditional independent of its nondescendants given its parents, denoted by V Nd ( V ) | Pa ( V ). In the formula Nd ( V ) is the set that consists of all nondescendants of V and Pa ( V ) is the set that consists of all parents of V . If we ignore the direction of all edges in G B ( V , E ) we get an undirected graph called the skeleton of G B ( V , E ), denoted by skeleton ( G B ( V , E )).
Before proceeding, we provide standard definitions for adjacency path, collider, non-collider, d-separation and other important concepts related with dependency analysis Bayesian network learning.

Definition 1. In a graph G ( V , E ), an adjacency path connecting V 0 and V k is an V contained in the path are distinct.

Definition 2. In a Bayesian network G B ( V , E ), a vertex V is a collider on a simple adjacency path  X  if there are two distinct vertices adjacent to V on  X  , and both of vertices are parents of V in G B ( V , E ); otherwise, V is called noncollider on  X  .
Definition 3. In a Bayesian network G B ( V , E ), two vertices U and V are d-separated by a set of vertices C , denoted by Dsep ( U ; V | C ), if and only if every simple adjacency path connecting U to V is blocked by C . A simple adjacency path  X  is blocked by C if and only if at least one noncollider on  X  is in C or at least one collider and all of its descendants are not in C . Specifically, U and V can never be d-separated if there is an edge connecting U and V . In this article, we call the set C conditioning set . Adjacency paths in a Bayesian network are different from directed paths. Take the Bayesian network in Figure 1 as an example. From vertex A to vertex E , there is a directed path ( A , C , E ), which is also an adjacency path connecting vertex A and vertex E . From vertex E to vertex A , there is no directed paths but there is an adjacency path ( E , C , A ). Note that a collider is defined by not only a vertex but also by simple adjacency path containing the vertex. In Figure 1, vertex C is a collider on adjacency path ( A , C , B ) but a noncollider on adjacency path ( A , C , E ). Therefore, vertex A and vertex B are d-separated by  X  while vertex A and vertex E are d-separated by C .
Definition 4. A distribution p is a Markov distribution with respect to a Bayesian network if Dsep ( U ; V | C ) implies U V | C .
 Definition 5. A distribution p is faithful to a Bayesian network if U V | C implies Dsep ( U ; V | C ).

It has been proved that a distribution p is a Markov distribution if and only if p obeys local Markov property with respect to a Bayesian network [Lauritzen et al. 1990]. Thus, Markov property of Bayesian networks provides a connection between the structure of a Bayesian network and the independence implied. More specifically, the absence of an edge between two vertices guarantees a set of independence related with these two vertices. However, the reversed part, the existence of an edge, does not guarantees dependence between the endpoints of the edge given merely the Markov property. To guarantee the correctness, most Bayesian network learning algorithms assume that the distributions of data are not only Markov but also faithful. Faithful-ness assumption is not strong in the sense that a Markov distribution on a Bayesian network satisfies the faithfulness condition almost surely [Spirtes et al. 1993]. In the remainder of the article, we assume that all distributions are both Markovian and faithful with respect to the corresponding Bayesian networks, which implies the equiv-alence between Dsep ( U ; V | C )and U V | C . The faithfulness assumption also implies that every edge in a Bayesian network can be identified by the absence of indepen-dence between the corresponding endpoints given any conditioning set. To illustrate this idea, we take Figure 1 as an example. Suppose that the distribution over the ver-tex set of the Bayesian network in Figure 1(b) is faithful. To check whether there is an edge between vertices A and B , dependency analysis algorithms need to test inde-pendence between A and B conditioned on all subsets of the set { C , D , E } . If there is a conditioning set making A and B independent, there is no edge between these two vertices. There are 2 3 = 8 such sets to be checked, and the largest one contains three vertices. From this case, we can see that the maximum size of conditioning sets in-creases as the dimension of the underlying data set grows if we use brute-force search. When data sets are high-dimensional and samples are limited, large conditioning sets cause unstable CI tests and impair the accuracy of learning algorithms. In addition, the number of CI tests grows in an exponential rate with the dimension of data, which makes brute-force search infeasible but only on small size networks. The information of the contemporaneous causal order of a time series is implied in the contemporaneous coefficient matrix of the true SVAR. The true SVAR is distinguished from the other SVARs by the fact that the disturbances are independent rather than uncorrelated. The true SVAR is assumed corresponding to the data-generating pro-cess [Demiralp and Hoover 2003]. We show that the procedure of identifying the true SVAR is equivalent to identifying the structure equation model (SEM) generating the disturbances of the original VAR. We use the same notations here as in section 3, and suppose that there exists a permutation matrix P denoting the true contemporaneous causal order of the SVAR. The disturbances under the true contemporaneous causal order are given by Denote the diagonal matrix where  X  2 ii denotes the variance of the i th entry in E ( t ). The covariance matrix of distur-bances under the true contemporaneous causal order can be decomposed in accordance with Cholesky decomposition as follows where L
P is a lower triangular matrix got by applying Cholesky decomposition to E P . The main diagonal entries of L P are the corresponding standard deviations of E P . We re-strict the main diagonal entries of M by D  X  1 2 so that M is a lower triangular matrix with all the diagonal elements one. There exists a vector W P ( t ) satisfying where The coefficient matrix C 0 is a strictly lower triangular matrix, because M  X  1 is a lower triangular matrix with all diagonal entries one. For the permutation matrix P corre-sponding to the true contemporaneous causal order, disturbances U P satisfy U Pi U Pj for 1  X  i , j  X  n and i = j , and in this case, Eq. (15) is the SEM generating the distur-bances of the VAR in Eq. (1). Plugging Eq. (15) into Eq. (1), we have where Because the elements in U P are mutually independent, the SVAR in Eq. (16) is as-sumed corresponding to the data-generating procedure. The strictly lower triangular coefficient matrix C 0 captures the contemporaneous causal order in this case. The non-zero elements c 0 ij in C 0 denotes that x j is a contemporaneous cause of x i . The difficulty of analyzing contemporaneous causal order by identifying the data-generating process is that for a time series with dimension n , there are n ! possible orders, and under each of them we need to test independence of regression residuals. Even worse, when the given time series is a Gaussian process, the elements in residual U P are mutually independent for arbitrary permutation P , because uncorrelation is equivalent to inde-pendence for Gaussian variables. However, different P results in different contempo-raneous coefficient matrix C 0 and makes contemporaneous causal order analysis fail. In this case, prior knowledge is required to resolve the confusion.

The concepts related to Bayesian network learning provide a deep insight of the reason that the SVAR model is incapable of identifying contemporaneous causal or-der for Gaussian process. We have shown that the SVAR model cannot identify the contemporaneous causal order for Gaussian processes, because any order will give mutually independent residuals U P . The SVAR model cannot distinguish these orders under which the faithfulness condition is satisfied from those under which the faithful-ness condition is violated. The previous work shows that a distribution satisfying the Markov property of a Bayesian network is faithful to the network almost surely [Meek 1995], which means that with probability one the distribution of data is faithful to the Bayesian network corresponding to the true data-generating process. We illustrate the fact by an example in Figure 2. In Figure 2, the disturbance E =( E 1 , E 2 , E 3 ) is gener-ated by the SEM in the left, and all U i , i =1 , 2 , 3, are drawn from standard Gaussian distribution and mutually independent. There is no causal effect between disturbances E 1 and E 2 , and both E 1 and E 2 are the causes of E 3 . The distribution of E is faithful to the Bayesian network in Figure 2, because E 1 E 2 implies that E 1 and E 2 are d-separated by empty set, which means that E 1 and E 2 are not directly connected in the network. The true permutation matrix P and the corresponding parameters are Another permutation matrix Q and the corresponding parameters are given as follows: For both permutation P and Q , the elements in residual U are mutually independent, and the SVAR model cannot tell which one corresponds the true data-generating pro-cedure. It is obvious that the faithfulness condition is violated under permutation Q . The reason is as follows. There does not exist causal effect between E 1 and E 2 , because these two disturbances are independent of each other. However, the regression coeffi-cient between E 1 and E 2 under permutation Q , in this case c Q 032 , the entry in the third row and second column of C Q 0 , is not zero, which means that E 1 and E 2 are connected by an edge in the Bayesian network corresponding to permutation Q , and in this case E 1 and E 2 cannot be d-separated. The independence of E 1 and E 2 is the result of spe-cial regression coefficients. More specifically, for each pair of mutually independent disturbances E i and E j , i &lt; j , the SVAR model always finds the coefficient matrix C 0 making where Cov [ E i , E j ] is the covariance between E i and E j , m ik is the entry in the i th row and k th column of M . From Eq. (16), we know that m ik is a function of C 0 . For this rea-son, the SVAR model cannot tell the coefficient matrices corresponding to the faithful structures from the coefficient matrices satisfying dependency relations by choosing special regression coefficients. The Bayesian network learning algorithms always find the faithful structures by CI tests. Given the fact that E 1 and E 2 independent, the corresponding entry in the coefficient matrix is restricted to be zero, so that coefficient matrix C Q 0 is ruled out. In addition, Bayesian network learning algorithms identify the contemporaneous causal order by finding all the V-structures [Spirtes et al. 1993]. If the two parents of a collider are not connected by an edge, the collider and its two parents form a V-structure in a Bayesian network. In the Bayesian network in Figure 2, the vertices E 1 , E 2 and E 3 form a V-structure, and the Bayesian network learning algorithms identify it by the results that E 1 and E 2 are independent of each other conditioned on the empty set and dependent of each other conditioned on E 3 . In this section, a novel algorithm for discovering VARs and SVARs from data is pre-sented. The algorithm is sound under the following assumptions. (i) The coefficient matrices of SVARs are time-invariant. In other words, the VARs and SVARs in this work are stationary, which is a typical assumption for many VAR approaches and causal analysis [Chen and Chihying 2007; Dahlhaus 2000; Demiralp and Hoover 2003; Haufe et al. 2010; Hyvarinen et al. 2008; Moneta and Spirtes 2006]. (ii) The coefficient matrix C 0 corresponds to a directed acyclic graph. Namely, there exists a permutation matrix P ,sothat PC 0 P is a strictly lower triangular matrix, which is a necessary assumption if we use Bayesian network learning algorithm in causal analysis [Chen and Chihying 2007; Demiralp and Hoover 2003; Hyvarinen et al. 2008; Moneta and Spirtes 2006; Shimizu et al. 2006]. (iii) There exist reliable statistical tests of condi-tional independence. In practice, it require sufficient samples to conduct reliable CI tests. However, reliable CI tests are commonly assumed in the theoretical correctness analysis of Bayesian network learning [Cheng et al. 2002; Margaritis and Thrun 1999; Pellet and Elisseeff 2007; Tsamardinos et al. 2006]. One of the distinction between this work and previous works using Bayesian network learning algorithms to learn SVARs is that in this work, the Bayesian network learn-ing algorithm is applied to the time series data instead of regression residuals. To represent a SVAR(k) by a Bayesian network, the vertex set should contain the current observation and the previous k observations. Each vertex in the network corresponds a random variable X i ( t )for1  X  i  X  n and 0  X  t  X  k , where n denotes the dimension of time series and X i ( t ) denotes the i th element of X ( t ). To represent a n -dimensional SVAR(k), there are n  X  ( k +1) vertices in the corresponding Bayesian network. There is son is that the SVARs considered in this work have time-invariant coefficient matrices, which implies that the causal relations between variables are also time-invariant. The X ( t  X  s  X   X  ) is a cause of X i ( t  X  s ) for all s &gt; 0. Consider a SVAR(2) with following coefficient matrices:
The Bayesian network corresponding to this time series is given in Figure 3. The dimension of the time series is 3 and the order of the SVAR is 2. Therefore, there are 3  X  (2 + 1) = 9 vertices in the network. There is an edge from X 1 ( t )to X 2 ( t )since c (2 , 1) = 0 . 5, which also implies an edge from X 1 ( t  X  1) to X 2 ( t  X  1) and an edge from X 1 ( t because the sizes of the networks grow with both the dimensions and the orders of time series. The difficulty motives us to address a Bayesian network learning algorithm that has good performance on large networks. To avoid high-order CI tests, dependency analysis algorithms restrict the search space of conditioning sets. More specifically, suppose that in a Bayesian network G B , there is no edge between two vertices U and V . If it can be proved that we can always find a conditioning set d-separating U and V by choosing vertices only from a subset of the entire vertex set, the search space is narrowed down from the entire vertex set to this particular subset. One of such subsets commonly used consists of all the vertices on the simple adjacency paths connecting U and V in G B excluding U and V themselves, denoted by ADJ ( U , V , G B ). The reason is that according to the definition of d-separation, only the vertices on a simple adjacency paths can block that path. Notice that the set ADJ ( U , V , G B ) can be an empty set, and this happens when there is no simple adjacency path connecting U and V or the only simple adjacency path connecting U and V is an edge. Take Figure 4 as an example. In the Bayesian network in Figure4(b), to decide that there is no edge between vertices A and B , it is sufficient to show that either A B |{ C } or A B | X  is true, because ADJ ( A , B , G B )= { C } .We also have ADJ ( A , C , G B )=  X  , because the only simple adjacent path connecting A and C in the network is ( A , C ). The exact ADJ ( A , B , G B ) can be identified only when we know the structure of G B . Therefore, we need an estimation of the underlying network, say G B , based on which we figure out an estimated ADJ ( A , B , G B ) denoted by ADJ ( A , B , G B ). Correctness guarantee requires that ADJ ( A , B , G B ) is a subset of ADJ ( A , B , G B ), which implies that G B needs to contain all the true edges in G B . Existing algorithms employing ADJ information such as PC uses estimated skeletons satisfying this condition. Phase two of the TPDA algorithm adds edges into the skele-ton because the maximum spanning trees obtained in phase one do not satisfy this condition.

The Two-Phase algorithm, denoted by Basic2P in the remainder of the article, is an improved version of TPDA. In phase one of TPDA, the algorithm gets the initial skele-tons by constructing maximum spanning trees. Phase two of TPDA adds missing edges into the initial skeletons and phase three of TPDA removes redundant edges. The gen-eral idea of the Basic2P algorithm comes from the observation that the structures of Bayesian networks are similar to those of Markov random fields. A Markov random field G M ( V , E ) is an undirected graph used to represent a joint distribution over vertex set V , in which a single vertex is associated with a random variable in the data set. Moreover, E denotes the edge set of the Markov random field. The joint distribution p represented by a Markov random field obeys the local Markov property that for any vertices U , V  X  V , U and V are conditional independent of each other given a set of vertices C if C separates U and V in G M ( V , E ). With the concepts above, the Basic2P algorithm works as follows:  X  Phase One constructs a Markov random field G M ( V , E ) from data in accordance with the Markov property. That is, for each pair of vertices U and V in vertex set V ,
Basic2P does not add edge U  X  V into G M ( V , E )ifandonlyif U V | V \{ U , V } .  X  Phase Two removes redundant edges from G M ( V , E ). For each edge U  X  V in G removes U  X  V . After all edges in G M ( V , E ) have been checked, Basic2P orients the remaining edges.

Phase one of Basic2P obtains the initial estimations of the skeletons of Bayesian networks by learning Markov random fields from data. The advantage of using Markov random fields as initial skeletons is that Markov random fields theoretically contain all the correct edges in the corresponding Bayesian networks. Therefore, phase two of Basic2P can focus on how to remove those redundant edges by searching conditioning sets with ADJ information obtained from Markov random fields. In addition, Markov random fields contain much less redundant edges than the complete graphs used by PC as trivial estimations of underlying networks. An example is given by Figure 4. The Markov random field in (a) and the Bayesian network in (b) are defined on the same set of random variables, and the former contains all the edges in the latter. With the Markov random field obtained in phase one, phase two only needs to consider the set ADJ ( A , B ) to remove A  X  B , in this case { C } . That is, phase two only needs to test A B | X  and A B |{ C } .

However, when dealing with high-dimensional data sets, Basic2P suffers from the increase of the sizes of the networks. The reason is as follows. Phase one of Basic2P learns Markov random fields according to Markov property. To be specific, for each pair of vertices, Basic2P needs to test independence conditioning on the entire vertex set, excluding the two under testing, to decide if there is an edge. Take the Markov random field in Figure 4(a) as an example. To decide whether there is an edge between A and B , Basic2P tests if A B |{ C , D , E } is true. Such tests are unstable when the sizes of the conditioning sets are large and samples are limited. Another point can be improved is that phase two of Basic2P does not make use of Markov blanket information obtained in phase one, and that information shown in this work is useful for reducing the search space of conditioning sets. In this section, we address an improved Two-Phase Algorithm with Markov Blanket information, named Markov2P , in order to overcome the difficulties faced by Basic2P. To avoid independence tests conditioned on large sets of variables, we use the IAMB algorithm [Tsamardinos et al. 2003b] to replace the original phase one. In phase two we use Markov blanket information to reduce the search space of conditioning sets. These two modifications are based on the concept of Markov blanket. In a Bayesian network, Markov blanket of a vertex A is defined as the set of vertices composed of its parents, children and spouses, denoted by MB ( A ). The heuristic Markov random field learning algorithm is based on the fact that all and only vertices in MB ( A ) are adjacent to A in a Markov random field. An example of Markov blanket is given in Figure 5. In the Bayesian network (b), vertices from M 0 to M 6 are in MB ( A ), and in Markov random field (a), all these vertices are adjacent to A . Therefore, learning a Markov random field from data can be done by identifying Markov blanket for each vertex in the Markov random field by the IAMB algorithm. The heuristic we use for IAMB is partial correlation. We use  X  XY  X  Z to denote partial correlation between random vari-ables X and Y after eliminating the effect of the conditioning set Z . The intuition justification of the heuristic is that zero partial correlation indicates conditional inde-pendence in linear models [Baba et al. 2004; Spirtes et al. 1998]. The idea of IAMB is as follows. The vertices in MB ( X ) can never be independent of X conditioned on the other vertices in MB ( X ), and tend to have larger partial correlation coefficients with X than those vertices not in MB ( X ). Following this idea, the searching procedure initial-izes Candidate Markov Blanket of vertex X , abbreviated as CMB ( X ), according to the current edge set and keeps on adding vertex with largest partial correlation coefficient into CMB ( X ). The procedure IAMB is phase one of the Markov2P that learns Markov random fields from data. The IAMB with partial correlation heuristic is equivalent to the stepwise regression [Draper and Smith 1966; Hocking 1976].

After IAMB, phase two of Markov2P removes redundant edges from Markov random fields to recover the skeletons of Bayesian networks. For most dependency analysis approaches, removing redundant edges is the most difficult part. The reason is that, to remove an edge from a network, we need to find a set of vertices conditioned on which the two endpoints of the edge are independent and the search space is com-posed of all subsets of the entire vertex set. In Basic2P, the search space is restricted to the set of vertices on the simple adjacency paths connecting the endpoints. In Markov2P, we show that the search space of conditioning sets can be further reduced. To be more precise, we prove that for any two vertices X and Y , if there exists a set of vertices conditioned on which X and Y are independent, we are always capable to make the two vertices independent by choosing vertices only from either MB ( X ) or MB ( Y ) instead of the entire vertex set. In addition, Markov blanket information can be combined with ADJ information to further reduce the search space because, to d-separate two vertices, it never needs vertices off the simple adjacency paths connecting them. We illustrate this idea by Figure 5, and the formal proof is given by Theorem 1. Consider the redundant edge A  X  M 0 of the Markov random field in (a), which should be removed in phase two. Phase two of Basic2P searches conditioning sets from vertices in ADJ ( A , M 0 , G M ), which is composed of the three vertices under the colored rectangular: M 4 , M 6 and a grey vertex. Phase two of Markov2P reduces the search space to ADJ ( A , M 0 , G M ) MB ( A ), which contains only M 4 and M 6 .In this case, we exclude one vertex from the search space and cut the size of the searching space by half because the algorithm has to go through all possible subsets in it. On large networks this improvement can be significant. Another advantage is that by reducing the size of the search space, Markov2P has less chance to test independence conditioned on large sets, which makes estimation more stable. Through CI tests with Markov blanket information, phase two of Markov2P checks every edges in the Markov random fields and removes redundant ones. Finally, Markov2P orients edges in the skeleton by identifying all colliders in the network. For two vertices X and Y , if there exists an edge between X and Y in the Markov random field, and the edge is excluded from Bayesian network, X and Y must be spouses in the underlying Bayesian network and the children of both X and Y must be included in S = ADJ ( X , Y , G M ( V ,  X  E )) MB ( X ) MB ( Y ). In this case, if there exists a set C  X  S making X Y | C , which is indicated by  X  XY  X  C = 0, the children of both X and Y cannot be in C and are therefore in S \ C . After orienting edges in the skeleton by identifying all the V-structures in the network, Markov2P poses the directions of the undirected edges from lags to the current variables. For the remaining undirected edges, con-straint propagation rules used in the MMHC algorithm are applied, which orients edges by preserving acyclicity in a Bayesian network. Without other information, an edge-orienting algorithm cannot distinguish Bayesian networks in a Markov equiva-lent class, which contains Bayesian networks with same skeletons and V-structures. Therefore, Markov2P outputs the complete partial directed acyclic graph (PDAG) that represents the Markov equivalent class of the true Bayesian network as PC and MMHC did. The correctness of Markov2P is guaranteed by the following theorem.
T HEOREM 1. For any two vertices X and Y in a Bayesian network, if there is no edge between vertices X and Y, we can always construct a conditioning set d-separating X and Y by choosing vertices only from either MB ( X ) or MB ( Y ) .

P ROOF . Without loss of generality, we prove that there exits a subset of MB ( X )d-separating X and Y if edge X  X  Y and X  X  Y do not belong to G B . We first prove that the simple adjacency paths between X and Y unblocked, given initial conditioning set C = MB ( X ), are those containing only a collider, which is a child of both X and Y . For any simple adjacency path connecting X and Y in G B and containing only one vertex between X and Y , this vertex is in C . If this vertex is a collider on the path, the path is unblocked given C , otherwise blocked. For any simple adjacency path connecting X and Y and containing more than one vertices between X and Y ,ifthe vertex adjacent to X on the path is a noncollider, since the vertex is in C , C blocks the path. If the vertex adjacent to X is a collider, the successive vertex on the path must be a noncollider on that path and a spouse of X . Therefore, this spouse of X must be included in C , which makes C block the path. This proves that the only unblock paths are those containing only the children of both X and Y . Based on the result, we show that we can remove the children of both X and Y from C so that it d-separates X and Y . To this end, we need to prove that we can remove all the descendants of both X and Y from C and keep original blocked paths remained blocked. If removing a descendant of both X and Y ,say Z , unblocks certain simple adjacency path connecting X and Y , Z must be a noncollider on that path which implies that there must exist a minimum descendant of Z ,say W , on that path. W must be a collider on that path. Otherwise, there would be a cycle in the Bayesian network, which is a contradiction. In addition W is also a descendant of both X and Y , so after removing all the descendants of both X and Y , the path is still blocked by W . This completes the proof. The idea is illustrated in Figure 6.

C OROLLARY 2. For any two vertices X and Y in a Bayesian network, if there is no edge between vertices X and Y, we can always construct a conditioning set d-separating X and Y by choosing vertices only from either ADJ ( X , Y ) MB ( X ) or ADJ ( X , Y ) MB ( Y ) .

P ROOF . Corollary 2 is an immediate result of Theorem 1, since to block a path we never need the vertices off that path.
 TPDA and GS. It improves TPDA in the sense that Markov2P provides a concise step to learn the approximate skeletons of Bayesian networks from data. It improves GS because Markov2P employs both local and global features to reduce the search space of conditioning sets. More specifically, the GS algorithm restricts the search space within the Markov blankets and the Markov2P algorithm shows that it is sufficient ot consider the vertices in the intersection of the ADJ set and the Markov blankets. The the Markov blanket information is local because it is related with a vertex and its neighbors, whereas the ADJ information is global because it is obtained only when the whole network is taken into account. We have demonstrated how to model SVARs by Bayesian networks and provide a efficient algorithm to deal with the large size networks corresponding to the SVARs. However, some tasks may require to estimate the coefficient matrices rather than causal relations. In this section, we show that the coefficient matrices can be estimated based on the Bayesian networks obtained. More importantly, high-order CI tests are avoided by this approach, so the estimators are more reliable than those obtained by applying the least squares approach to the time series directly. The idea of our approach is as follows. The structures of Bayesian networks indicate which random variables should be taken as the independent variables when we use least squares approach to estimate the coefficient matrices of SVARs. The coefficient matrices of the VARs can be calculated based on those of the SVARs by the relations in Eq. (17). More specifically, to regress a variable in a SVAR(k), it is not necessary to take all the variable in past k time as independent variables, but only the parents of the dependent variable in the Bayesian network. The justification is an immediate result of the Markov property of Bayesian network: a variable in a Bayesian network is independent of its nondescendants given its parents. We present this idea formally in the procedure BayesVAR . In the BayesVAR algorithm, we first apply Markov2P to time series data to learn a Bayesian network that corresponds to the true SVAR. With the Bayesian network obtained, we regress every variable at the current time on its parents, and the regression coefficient is the estimator of the corresponding element in the coefficient matrix of the SVAR. The next step is finding the permutation matrix P that implies the contemporaneous causal order and calculating the coefficient ma-trices of the VAR according to the relation in Eq. (17). From the procedure, we can see that the algorithm has essential distinction from previous works [Chen and Chihying 2007; Demiralp and Hoover 2003; Hyvarinen et al. 2008]. In these works, the VAR is the necessary first step, and the Bayesian network algorithms are applied to the residuals of the VAR to identifying the contemporaneous causal order. In our work, the VARs and SVARs are identified in a reversed order. The SVARs are identified first by applying Markov2P to the time series data, and the VARs are figured out based on the SVARs. The advantage of solving the problem in this way is that high-order CI tests required by the VAR approach can be avoided by choosing efficient Bayesian network learning algorithms. With the Bayesian network information, the number of independent variables is | Pa ( X i ( t )) | for each X i ( t ), whereas in the VAR approach, the number is k  X  n for a n dimensional VAR(k) as Eq. (8) shows.

Taking the SVAR in Section 5.1 as an example, we explain how the BayesVAR al-gorithm works and why the algorithm performs better than the VAR approach. Given thedataset D generated by the SVAR in Section 5.1, we use BayesVAR to learn a SVAR(2) and a VAR(2). The first step is learning a Bayesian network from data by Markov2P, and we get a Bayesian network as shown in Figure 3. The next step is estimating coefficient matrices of SVAR(2) according to the structure of the Bayesian network. To this end, BayesVAR regresses each element in X ( t ) on its parents. For example, in the Bayesian network in Figure 3, the algorithm needs to regresses X 1 ( t ), X 2 ( t ), X 3 ( t ) on their parents. Without loss of generality, we take X 2 ( t ) as an example. Pa ( X 2 ( t )), and get regression coefficients 0.5, 0.5, 0.3 for the three regressors. From this result, we know that c 021 =0 . 5, c 221 =0 . 5, c 223 =0 . 3, and the other entries in the second row of each coefficient matrix of the SVAR(2) are all zero. After all the entries in the coefficient matrix of the SVAR(2) have been estimated, we find the C 0 is a strictly triangular matrix, so we have the permutation matrix P an identical matrix in this case. The last step is calculating the coefficient matrices of VAR(2) from the coefficient matrices of SVAR(2) in accordance with Eq. (17). In this case, we have the result In this section, we empirically evaluate the BayesVAR algorithm. We first compare BayesVAR with existing works those combine the VAR approach and Bayesian net-work learning algorithms to discovery causal relations on synthetic data, and then we apply the BayesVAR algorithm to some real world datasets. To investigate the performance of the BayesVAR algorithm, we conducted a series of simulations. We design the experiment to check if empirical results support our the-oretical analysis. To be specific, we are going to test (i) if the BayesVAR algorithm is capable to identify contemporaneous causal relations; (ii) if the Markov2P algorithm avoids high-order CI tests when dealing with large Bayesian networks. We also com-pare BayesVAR with the following algorithms.  X  The GS algorithm [Margaritis and Thrun 1999]. GS is a Bayesian network learning algorithm that infers the structures of Bayesian networks locally by identifying the
Markov blanket of each vertex. In this work, we apply GS to the Bayesian networks corresponding to time series.  X  The VAR+PC algorithm [Demiralp and Hoover 2003]. This approach applies VAR to time series first, and then uses PC to discover the contemporaneous causal order on regression residuals.  X  The TC algorithm [Pellet and Elisseeff 2008]. TC is a Bayesian network learning algorithm that identifies Markov blankets by linear regression. In this work, we apply TC to the Bayesian networks corresponding to time series.  X  The HSIC regression [Mooij et al. 2009]. This regression approach minimizes the statistical dependence between regressors and residuals, rather than minimizing squared errors as the standard linear regression does.  X  The FactorDAG algorithm [Henao and Winther 2009]. FactorDAG learns directed acyclic graphs from factor models, and uses the directed acyclic graphs to represent causal relations.
  X  The Basic2P algorithm [Wang and Chan 2010]. Basic2P is a dependency analysis
Bayesian network learning algorithm that learns Bayesian networks from Markov random field.  X  The BayesVAR algorithm. BayesVAR uses Markov2P to learn the Bayesian net-works corresponding to time series and estimates VARs based on the Bayesian net-works obtained.

We empirically evaluate the listed algorithms on Gaussian time series, and the data are generated according to some real world Bayesian networks. The networks used in the evaluation are listed in Table I, which are obtained from real decision support systems. Data are generated by SVARs corresponding to these networks by the fol-lowing way. Every coefficient matrix C  X  is constructed according the structures of the Bayesian networks. Namely, the ( i , j )-th entry of C  X  is nonzero if and only if there is an edge from variable j to variable i . And then, for a SVAR(k), we generate k +1 coefficient matrices and in this case, there are ( k +1)  X  n vertices in the Bayesian net-work corresponding to the SVAR if the original real world network contains n vertices. Weights are sampled from uniform distribution between 0.1 and 0.9 for nonzero en-tries in C  X  . After that, we normalize C  X  , so that SVARs are stable. Each variable in SVARs is evaluated according to the dynamic of the SVAR for t steps, where t is the sample size in the experiment. Disturbance terms are drawn from standard Gaussian distribution, so that all SVARs are Gaussian processes and zero partial correlation can be tested by Fisher X  X  Z transformation of partial correlation coefficients [Fisher 1915], and the significant level is set to be 0.05. The performances of the algorithms are qual-ified in terms of efficiency and accuracy. We use the number of CI tests and CPU time to evaluate efficiency. The advantage of using the number of CI tests as the metric of efficiency is that this metric is implement and platform independent, whereas the disadvantage is that it can only be applied for dependency analysis Bayesian network learning algorithms. The CPU time can be used to evaluate efficiency for all the al-gorithms in comparison. For accuracy, there are two metrics as well. The first one is F -measure that is defined based on the similarity between the output Bayesian net-work and the target one. We use adjacent matrix to represent a Bayesian network. Let  X  A denote the target adjacent matrix, and  X  A the output one, precision P and recall R are defined as follows: Given precision and recall, F 1 is defined as: The other is metric for accuracy is forecast error, which is a measurement of the dif-ference between the real value of the time series and the predicted value. More specif-ically, we use the Mean Squared Error (MSE) defined as follows In Eq. (23), s is the sample size and e t is the difference between the real and predicted value at time t .

We first check the accuracy of the BayesVAR identifying both temporal and con-temporaneous causal relations and how the performance varies with the scales of the problems and the number of available observations. In this experiment, we gener-ate SVAR(1) and SVAR(2) based on the networks and for each SVAR, the sample size varies from 128, 256, 512, 1024, 2048, 4096 to 8192. The results are summarized in Figure 7. From the results, we can see that BayesVAR outperforms the other algo-rithms in comparison on all SVARs. The BayesVAR outperforms the other algorithms for two reasons. The first one is that the BayesVAR uses partial correlation as heuris-tic when identifying Markov blankets. The second reason is that BayesVAR employs ADJ information to restrict the search space of conditioning sets to subsets of Markov blankets. More importantly, we can see that the performance of BayesVAR does not decrease as the scale of the problem increases. For example, BayesVAR has higher F 1 value on SVAR(1) corresponding to the Hailfinder network than that corresponding to the Insurance network. The reason is that BayesVAR searches the conditioning sets within Markov blankets, and uses a heuristic Markov blanket learning algorithm to avoid high-order CI tests when identifying Markov blankets from data. The VAR+PC, TC, and Basic2P perform worse for the reason that these algorithms rely on high-order CI tests when the scales of the problems are large. The VAR+PC algorithm applies the VAR approach to regresses each variable in the current time on all the variables in the past k time for a SVAR(k). Therefore, the maximum size of conditioning sets is n  X  k for a n -dimensional SVAR(k). The TC algorithm uses linear regression to identify the Markov blanket of each variable, and the size of the conditioning set in this case is n  X  ( k +1)  X  2. The Basic2P uses high-order CI tests to learn Markov random field from data.Therefore, the F 1 values of VAR+PC, TC, and Basic2P drop dramatically on large networks when samples are limited. For example, on SVAR(1) based on the Hailfinder network and 128 samples available, there is a sudden drop of the F 1 value of the TC algorithm. The HSIC regression performs worse than BayesVAR for the reason that the HSIC regression regresses by making regressor and residuals independent, and therefore, for Gaussian processes, it cannot identify contemporaneous causal orders. Table II provides a deep insight on the sizes of conditioning sets required by the algo-rithms in comparison when 8192 samples are available. From Table II, we can see that the maximum sizes of conditioning sets of VAR+PC, TC, and Basic2P are consist with the theoretical analysis, and the average sizes of conditioning sets of these algorithms tend to be larger than the other two. The BayesVAR has the smallest maximum size and average size of conditioning sets on every setting, which means that BayesVAR is more robust. In addition, the average size of conditioning sets of BayesVAR does not grow fast as the sizes of the underlying networks increase because it employs the Markov blanket information and the ADJ information to restrict the search space.
A summary of MSE and CPU time is presented in Figure 8. All algorithms were run on Intel Core 2 Duo, 2.4GHz, 2GB RAM running 32-bit Windows. We normalize the MSE reported by dividing by the MSE of BayesVAR on the same learning task. A normalized MSE more than one means more errors than BayesVAR. We calculate the normalized MSE and CPU time on first order SVARs and 8192 sample available. From Figure 8, we can see that BayesVAR provides the best prediction on the time series because the normalized MSEs of all the other algorithms are more than one. In addition, BayesVAR is the most efficient algorithm in the sense of CPU time con-sumed. The CPU time required by the dependency analysis algorithms is close re-lated with the numbers of CI tests: the more CI tests required by an algorithm, the longer CPU time consumed. For example, the VAR+PC algorithm needs more CI tests than others, so the CPU time required by VAR+PC is much longer than the other algorithms.

The error analysis of BayesVAR on 8192 samples is summarized in Table III. The errors are classified into two categories, temporal errors and contemporaneous errors. The temporal errors occur between two variables at time t and s , respectively, where t = s and contemporaneous errors occur between two variables both in time t . There are three types of errors in the contemporaneous category: (i) there should be a causal relation but missed; (ii) there should not be an causal relation but wrong added; (iii) the orientation of the causal relation is reversed. In the temporal category, there are only two types because the orientation is indicated by time. For a Bayesian network with d edges, the corresponding SVAR(1) contains d temporal causal relations and 2 d contemporaneous ones and the corresponding SVAR(2) contains 3 d temporal ones and 3 d contemporaneous ones. From Table III, we can see that the proportion of missing temporal causal relations to the contemporaneous one is around 0.5 on SVAR(1) and that proportion is around 1 on SVAR(2). This is also true for the extra causal relations. This fact indicates that the algorithm has almost the same change to make a mistake on temporal and contemporaneous relations. In addition, most orientation of the con-temporaneous causal relations can be correctly identified even though there is no time indicator and other prior knowledge. We use the BayesVAR algorithm to find the causal relations among several world stock indices. The chosen indices are DJI in USA, FTSE in UK, N 225 in Japan, HSI in Hong Kong, and the SSEC in China, and all the data are public available from Yahoo finance database. We use the daily dividend/split adjusted closing prices from 3rd January 2007 to 31st December 2010. We choose the DJI trading date as the date basis and there are 1008 observations during this period. For the prices of the other indies not available in some DJI trading dates, we simply estimate the prices by linear interpolation. The analysis is based on daily return calculated by the following formula where p ( t )and p ( t  X  1) denote the adjusted daily closing price of the current trading date and previous trading date respectively and r ( t ) denotes the daily return of the current trading date.
 A summary of MSE and CPU time on the stock index data is presented in Figure 9. In this experiment, we estimate the first order SVARs for each model. We can see that the BayesVAR algorithm gives the best prediction on the daily return of stock index data because the normalized MSE of all the other algorithms are larger than one. In addition, the BayesVAR algorithm is the most efficient one because it requires shortest CPU time among all the algorithms in comparison.

We give a deep insight of the SVAR(1) and VAR(1) on the stock index data set estimated by the BayesVAR algorithm. The structure of the SVAR(1) is illustrated in Figure 10. The numbers on the edges are regression coefficient denoting the strength of the causal effects. The SVAR(1) in Figure 10 indicates that DJI has significant tempo-ral causal effect on all the other indices, which is consistent with our knowledge. FSTE has a temporal causal effect on DJI , which indicates the close connection between the markets of USA and UK. An interesting fact is that all the autoregression coefficients for N 225, FTSE ,and DJI are negative. Although there are other paths implies positive causal effects from the previous observation to the current one, the overall effects are still negative. For example, there are three paths from N 225 t  X  1 to N 225 t , and the causal effect of each path equals to the production of the weights of the edges is 0 . 27  X  0 . 3  X  0 . 72  X  0 . 25  X  0 . 015. The summation of the weights of the three paths is  X  0 . 23. The contemporaneous causal orders identified by BayesVAR are consist with the time difference among the markets in comparison, although the time difference information is not provided to BayesVAR. In addition, all the contemporaneous causal effect are positive, which indicates that the markets tend to move to the same direction in one day. The estimated VAR(1) is illustrated in Figure 11. We can see that no information about the contemporaneous causal effect are explicitly illustrated by the VAR(1). In addition, the temporal causal effect in the VAR(1) are quite different from those in the SVAR(1). For example, there is no causal effect from FTSE t  X  1 to DJI t in the VAR(1). A more detailed discussion on the structures of VARs deviate from the true causal relation can be found in Hyvarinen et al. [2008]. In this work, we show that the VAR and the SVAR models are incapable of identify-ing contemporaneous causal order from Gaussian processes and provide a solution to the problem based on Bayesian network learning. The BayesVAR algorithm proposed in this work is distinct from the existing works that find contemporaneous causal or-der by applying Bayesian network learning algorithms to the residuals of VARs. The BayesVAR algorithm learns Bayesian networks directly from time series data and does not depend on the results of VAR models. By doing this, the algorithm avoids the high-order CI tests involved by estimating VARs from data. To overcome the difficulty that the sizes of the Bayesian networks corresponding to time series tend to be large, we propose the Markov2P algorithm to learn the Bayesian networks locally. By restrict-ing the search space of conditioning sets within a subset of Markov blanket, the orders of the CI tests do not grow fast with the scales of the problems.

