 In this paper, we propose SimCC-AT (similarity based on content and citations with automatic parameter tuning) to compute the similarity of scientific papers. As in SimCC, the state-of-the-art method, we exploit a notion of a contri-bution score in similarity computation. SimCC-AT utilizes an automatic weighting scheme based on SVM rank and thus requires only a smaller number of experiments for parame-ter tuning than SimCC. Furthermore, our experimental re-sults with a real-world dataset show that the accuracy of SimCC-AT is dramatically higher than that of other exist-ing methods and is comparable to that of SimCC.
 Automatic Weighting, Citations, Content, Contribution Score, Similarity
Scientific papers are one of primary sources to share infor-mation and knowledge among researchers. Recently, com-puting the similarity of scientific papers became an interest-ing topic in information retrieval and data mining [1][6][9]. SimCC [6] is state-of-the-art method that considers both content and citations in computing similarity of scientific papers. The philosophy of SimCC is that, when paper q cites paper p , it means p is a valuable paper on some topics discussed in q and contributes to q for improving the content of q . Based on this philosophy, SimCC introduces the notion of a contribution score as a key factor in similarity computa-tion. SimCC dramatically outperforms text-based similarity measures such as Cosine [5], Dice coefficient [5], BM25 [5], and Kullback-Leibler Distance (KLD) [5], link-based simi-larity measures such as SimRank [3], rvs-simRank [11], and P-Rank [11], and also hybrid methods such as CEBC [1], Keyword-Extension [8], and WCO [7].

In spite of high accuracy, the parameter tuning is per-formed manually in SimCC, which is a difficult and time-consuming task. Consequently, it is not easy to adopt SimCC f or practical applications. We cannot utilize automatic weight-ing schemes such as SVM rank [4] directly for parameter tun-ing because SimCC applies a weighted linear combination to two different feature scores obtained from single paper p to get a single score as a new feature for p , which is later utilized in similarity computation. These two combined fea-ture scores of a paper are not calculated in relating to other paper, thereby making SVM rank unable to be applied to SimCC for indicating the importance of each feature in com-bination.

In this paper, we propose a method, SimCC-AT (similar-ity based on content and citations with automatic parame-ter tuning), which performs parameter tuning automatically . In order to utilize automatic weighting schemes, we refor-mulate SimCC while preserving its philosophy in similarity computation. In SimCC-AT, only a small number of ex-periments are required for parameter tuning; therefore, it is easily adopted for practical applications. Our extensive experimental results show that the accuracy of SimCC-AT is dramatically higher than that of other existing methods and is comparable to that of SimCC.

The contributions of this paper are as follows. (1) We uti-lize automatic parameter tuning in similarity computation based on contribution scores; (2) we simplify the adoption of an accurate similarity computation based on contribution scores for any similarity measures applicable to vectors; (3) we evaluate the effectiveness of SimCC-AT extensively with a real-world dataset of scientific papers.
The contribution score measures how much a paper con-tributes to another single paper on a specific term via a specific citation path . Consider the sample citation graph in Figure 1 where nodes represent papers and edges do citation relationships among papers. As an example, p contributes to q directly (via citation path q  X  p where  X  denotes a di-rect citation) and indirectly (via citation paths q  X  r  X  p and q  X  u  X  p ) ; p contributes to u only directly via citation path u  X  p . Therefore, p has three contribution scores on a single term t to q via three distinct citation paths and has only one contribution score on t to u via a single citation path.
SimCC performs both feature extraction and similarity computation. For feature extraction, every paper p is rep-resented as an n -dimensional vector. The weight of a term t in the vector of p is calculated as follows [6]: where R t ( p ) is a relevance score of t to p calculated by apply-ing any weighting factors such as TF, TF-IDF, and BM25. A ( p ) is an authority score of p on t calculated by summing up all contribution scores of p on t to all other papers citing p .  X  (0  X   X   X  1) is a relative importance factor. For similar-ity computation, any similarity measures for vectors such as Cosine, Dice, BM25, and KLD can be employed.

The best value of  X  is found manually , which is difficult and time-consuming since we have to conduct lots of exper-iments as follows. For any employed similarity measure, at least 55 distinct experiments are required [6] as five different path lengths from 1 to 5 are considered for computing the contribution scores, and the value of  X  is set from 0.0 to 1.0 in steps of 0.1 for each path length. Consequently, it is not easy to adopt SimCC for practical applications.

We note that it is not possible to perform automatic pa-rameter tuning in SimCC for the following reason. Auto-matic weighting schemes such as SVM rank can be utilized to determine the importance (i.e., rank) of each feature in a set of features, each of which measures a relatedness between two objects based on its own criteria [4]. In SimCC, however, R ( p ) and A t ( p ) are two features of single paper p ; they do not measure any relatedness (e.g., similarity) between paper p and another paper.
Our proposed method, SimCC-AT , has the goal of per-forming automatic parameter tuning with preserving the phi-losophy of SimCC in similarity computation. As in SimCC, the contribution score is a key factor in SimCC-AT which performs both feature extraction and similarity computa-tion. However, there are two major differences between SimCC-AT and SimCC as follows.

In SimCC, R t ( p ) and A t ( p ) are combined into a single value, w t ( p ), for every paper p . The similarity score of a paper-pair ( p, q ), S ( p, q ), is computed by employing a simi-larity measure on their corresponding vectors. On the con-trary, in SimCC-AT, every paper p is represented by two separate vectors R-vector (relevance vector) and A-vector (authority vector) containing R t ( p ) and A t ( p ) for all terms t in p , respectively. For computing S ( p, q ), two distinct similarity scores are computed based on their correspond-ing R -vectors, SR ( p, q ), and their corresponding A -vectors, SA ( p, q ). Then, the two scores SR ( p, q ) and SA ( p, q ) are combined into a single score by applying a weighted linear combination as S ( p, q ). In this way, we reformulate SimCC while persevering its philosophy in similarity computation.
In SimCC, the parameter tuning is performed manually ; however, in our method, the importance of SR ( p, q ) and SA ( p, q ) in the combination is determined automatically by utilizing an automatic weighting scheme based on SVM rank [4]. We can utilize SVM rank since, 1) for every paper p , we consider R t ( p ) and A t ( p ) as two separate features in similar-ity computation; 2) for both p and q , SR ( p, q ) and SA ( p, q ) measure a relatedness (i.e., similarity) between a pair of pa-pers p and q . We only need to conduct 6 experiments as five different path lengths are considered for computing the con-tribution scores; then, SVM rank is utilized to automatically determine the importance of SR ( p, q ) and SA ( p, q ) in the combination to obtain S ( p, q ). Consequently, we can easily adopt SimCC-AT for any similarity measures applicable to vectors in practical applications. A t ( p ) is calculated by the following formula: where d denotes the maximum length of the path in the citation graph traversed to compute the contribution score, D ( p, i ) does a set of papers that cite p via paths with length i (1  X  i  X  d ), and q i  X  p does a set of citation paths with length i from q to p .  X  denotes a single citation path q  X  r 1  X  ...  X  r i  X  1  X  p with length i from q to p and C does the contribution score of p on t to q via  X  . For exam-ple, in Figure 1, D ( p, 1) = { q, r, u } and D ( p, 2) = { q, s } .
Only for simplicity of presentation, we assume that there is only one citation path q i  X  p with length i from q to p . Equation (2) is rewritten as follows: where C t ( q i  X  p ) denotes the contribution score of p on t to q via the single path q i  X  p and is computed as follows: where  X  t ( q i  X  p ) denotes the contribution ratio of p on t to q via q i  X  p . If q cites p directly (i.e., i = 1), the contribution ratio is calculated as follows: where citations ( q ) denotes a set of papers directly cited by q . If q cites p indirectly via other papers (i.e., i  X  2),  X  determined by contribution ratios between all directly con-nected papers in the citation path. Let q  X  r 1  X  ...  X  r be a citation path with length i from q to p . Then, we have  X  t ( q i  X  p ) =  X  t ( q In our SimCC-AT, S ( p, q ) is computed as follows: where w 1 and w 2 are weights for controlling the degree of im-portance of SR ( p, q ) and SA ( p, q ) in the combination since we do not consider them as equally significant in computing S ( p, q ). We use SVM rank [4] that is based on the support vector machine (SVM) to determine best values of w 1 a nd w 2 automatically .

SVM rank solves a maximum-margin optimization prob-lem by finding a hyperplane. In our case, the hyperplane is a vector of two weights represented as V = &lt;w 1 , w provides an ideal separation between relevant and irrelevant papers in a training set by finding the best values of w 1 w . The training set is used for the training process and con-tains training instances. The training instance represents a paper in regarding to a query paper as follows: where r is set as 1 when p is relevant to the query paper q , and is set as 0 otherwise as described in Section 5.2. qid denotes a query number. SVM rank indicates the hyperplane according to pairwise preference constraints, which are in-cluded for all pairs of training instances that have different r but the identical qid .
In this section, we compare the effectiveness of SimCC-AT with those of Cosine, Dice, BM25, and KLD as text-based similarity measures, SimRank, P-Rank, and SimRank* [10] as link-based similarity measures, and CEBC, WCO, and Keyword-Extension as hybrid methods. Also, we compare the effectiveness of SimCC-AT with that of original SimCC.
We employed a real-world dataset of scientific papers by crawling information of 1,071,793 papers from DBLP 1 and their abstract and citation information from Microsoft Aca-demic Search 2 . We do not have access to the body of papers due to the copyright issue. However, the combination of the title and abstract has been reported to show the better ac-curacy than the body in computing the similarity [8].
We constructed our ground truth sets based on a famous data mining textbook [2] where, as in user studies , relevant papers to research topics addressed in each chapter are cat-egorized by experts (i.e., the authors of the book) in the bibliographic section of the chapter. We selected eleven re-search topics as our ground truth sets, each of which contains its related papers. Also, we utilize MAP, precision at top 10 results (P@10), and recall at top 10 results (R@10) [5] as evaluation measures.

As in SimCC, we employ Cosine, Dice, BM25, and KLD as basic similarity measures to be employed with R -vectors and A -vectors. To employ Cosine and Dice, we utilize the TF-IDF value as the relevance score. For BM25 and KLD, we utilize the BM25 weight and the TF value, respectively.
As described in Section 4.1, A t ( p ) depends on d , the max-imum length of the path to compute contribution scores. Therefore, we investigate how the accuracy of a basic simi-larity measure changes with different values of d to find its best value for each measure. We set the value of d from 1 to 5 in Equation (2) and construct five distinct A -vectors for every paper in the dataset. Figure 2 represents the accuracy of Cosine, Dice, BM25, and KLD with different values of d in terms of MAP, P@10, and R@10. The baseline method h ttp://www.informatik.uni-trier.de http://academic.research.microsoft.com denotes the similarity computation based on R -vectors (i.e., relevance scores).

For all basic similarity measures, we observe the following common results. The similarity computation based on au-thority scores significantly outperforms the baseline method regardless of the value of d . As a surprising result, the best value of d is 2 regardless of similarity measures. The accu-racy decreases gradually for d  X  3 since, when we go farther from each paper in the citation graph, contribution scores of the paper to other papers tend to be noisier .
For every basic similarity measure, we perform the auto-matic parameter tuning to determine best values of w 1 and w 2 in Equation (7) as follows. We construct the A -vector of all papers in the dataset based on d =2. Then, we compute SR ( p, q ) and SA ( p, q ) for all paper-pairs ( p, q ) where p and q belong to the dataset and ground truth sets, respectively. Finally, we construct the training set by defining training in-stances according to Equation (8) for 60% of papers in our dataset. If both p and q belong to the same ground truth set, r is set as 1, otherwise 0. SVM rank is executed on the training set to determine values of w 1 and w 2 .
Now, we compare the effectiveness of SimCC-AT with those of other existing methods in Figure 3. For exam-ple, Figure 3(a) represents the accuracy of CEBC, Keyword-Extension, WCO, and SimCC-AT, each of which is equipped by Cosine; also, this figure shows the accuracy of the base-line method (Cosine only with R -vectors) and SimRank*. For link-based similarity measures, we only represent the result of SimRank* because it is shown to outperform both SimRank and P-Rank with our dataset. The reason is that it considers those possible paths between papers in a cita-tion graph, which are neglected by SimRank and P-Rank in similarity computation.

The following results are commonly observed with all the employed basic similarity measures. The baseline method and SimRank* show the worst accuracy since they consider only content and citations in similarity computation, re-spectively. However, the baseline method outperforms Sim-Rank*. Hybrid methods significantly outperform the base-line method and SimRank* since they consider both content and citations in similarity computation. SimCC-AT dramat-ically outperforms all other methods. The reason is that SimCC-AT not only considers both content and citations in similarity computation but also, in contrary to other hybrid F igure 3: Accuracy of SimCC-AT and other meth-ods. methods, it does not simply combine the content of papers involved in a direct citation relationship; instead, SimCC-AT measures the amount of contribution between papers involved in a direct or indirect citation relationship as con-tribution scores to utilize them in similarity computation. Now, we compare the accuracy of SimCC-AT with that of SimCC in terms of MAP, P@10, and R@10 in Figure 4. For all basic similarity measures, SimCC shows slightly (see Ta-ble 1) better accuracy than SimCC-AT. The reason is that, in SimCC, relevance and authority scores are combined into a single value as a unique feature for similarity computation. However, in SimCC-AT, these scores are considered as two separate features for similarity computation.
 Figure 4: Accuracy of SimCC-AT and SimCC.

D espite the fact that SimCC-AT shows lower accuracy than SimCC, we claim that it is a better method than SimCC for similarity computation by the following aspects: 1) there is no tangible difference between the accuracy of SimCC-AT and that of SimCC as shown in Table 1; 2) compared with SimCC, SimCC-AT requires a much smaller number of ex-periments (i.e., 6) for parameter tuning; therefore, SimCC-AT can be easily adopted for practical applications; 3) the best value of d in SimCC-AT (i.e, 2) is less than that in SimCC (i.e, 3 [6]). Therefore, SimCC-AT has a smaller com-putational overhead in large citation graphs.
In this paper, we proposed SimCC-AT to compute the similarity of scientific papers by considering both content and citations, which utilizes SVM rank for automatic param-eter tuning. As in SimCC, the state-of-the-art method, the Table 1: Relative accuracy (%) of SimCC-AT over SimCC.
 contribution score is a key factor in SimCC-AT. However, to u tilize SVM rank , we reformulated SimCC while preserving its philosophy (i.e., contribution score) in similarity com-putation. As a result, it is easy to adopt SimCC-AT for practical applications since it requires a smaller number of experiments (i.e., 6) than SimCC (i.e., 55) for parameter tuning. SimCC-AT dramatically outperforms other existing methods, and its accuracy is comparable to that of SimCC. This research was supported by (1) the Ministry of Science, ICT and Future Planning (MSIP), Korea, under the Infor-mation Technology Research Center (ITRC) support pro-gram (IITP-2016-H8501-16-1013) supervised by the Insti-tute for Information &amp; communication Technology Promo-tion (IITP) and (2) the National Research Foundation of Ko-rea (NRF) grant funded by the Korea government (MSIP) (NRF-2014R1A2A1A10054151). [1] N. Chiki, B. Rothenburger, and N. Gilles. Combining [2] J. Han, M. Kamber, and J. Pei. Data Mining: [3] J. Jeh and J. Widom. SimRank: A Measure of [4] T. Joachims. Optimizing Search Engines using [5] C. Manning, P. Raghavan, and H. Schutze.
 [6] M. Reyhani Hamedani, S. Kim, and D. Kim. SimCC: [7] K. Sugiyama and M. Kan. Scholarly Paper [8] S. Yoon, S. Kim, and J. Kim. On Computing [9] S. Yoon, S. Kim, and P. Sunju. C-Rank: A Link-based [10] W. Yu, X. Lin, W. Zhang, L. Chang, and J. Pei. More [11] P. Zhao, H. Han, and S. Yizhou. P-Rank: a
