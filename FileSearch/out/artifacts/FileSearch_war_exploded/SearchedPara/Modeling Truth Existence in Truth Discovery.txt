 When integrating information from multiple sources, it is common to encounter conflicting answers to the same question. Truth dis-covery is to infer the most accurate and complete integrated an-swers from conflicting sources. In some cases, there exist ques-tions for which the true answers are excluded from the candidate answers provided by all sources. Without any prior knowledge, these questions, named no-truth questions , are difficult to be dis-tinguished from the questions that have true answers, named has-truth questions . In particular, these no-truth questions degrade the precision of the answer integration system. We address such a chal-lenge by introducing source quality , which is made up of three fine-grained measures: silent rate, false spoken rate and true spoken rate. By incorporating these three measures, we propose a proba-bilistic graphical model, which simultaneously infers truth as well as source quality without any a priori training involving ground truth answers. Moreover, since inferring this graphical model re-quires parameter tuning of the prior of truth, we propose an initial-ization scheme based upon a quantity named truth existence score , which synthesizes two indicators, namely, participation rate and consistency rate . Compared with existing methods, our method can effectively filter out no-truth questions, which results in more accu-rate source quality estimation. Consequently, our method provides more accurate and complete answers to both has-truth and no-truth questions. Experiments on three real-world datasets illustrate the notable advantage of our method over existing state-of-the-art truth discovery methods.
The rapid growth of web data provides an overwhelming amount of information. Though information is available from more sources, sources often disagree with each other. For example, the location of the last confirmed case of Ebola patient in the US may be reported by multiple websites with different answers. Any false report of location leads to unnecessary panic. Hence, it is crucial to identify the most accurate and complete answer among conflicting answers. This problem is commonly known as truth discovery [19].

One straightforward approach to truth discovery problem is ma-jority voting . It collects all possible answers to one question from  X  multiple sources and treats the most frequent answer as the truth. However, majority voting ignores an important fact: the quality of each source is often heterogeneous. Consequently, it fails to dis-cover the truth in the setting where a majority of sources provide a wrong answer, while few high-quality sources provide the correct answer. In order to address such a challenge, one feasible approach is to incorporate source quality [5, 11, 19]. The rationale behind this approach is, if an answer comes from a more reliable source, it is more likely to be true; meanwhile, if a source is associated with a more trustworthy answer, it is likely to be more reliable. Naturally, one may infer the truth and source quality in an iterative way. It allows to find truth and estimate source quality in an unsupervised fashion. There exist several methods that leverage this intuition and additional heuristics [3, 15, 17, 20].

However, existing methods do not address a critical issue: there might be questions, named no-truth questions , whose true answers are not included in the candidate answers provided by all sources. Without careful treatment, this issue can severely degrade the per-formance of the truth discovery system. In the sequel, we motivate this truth existence problem with an example.
 Example Recently, automatic knowledge base construction is ex-plored to build a proliferation of knowledge bases [4]. In knowl-edge base construction, one crucial step is to build information ex-tracting systems to discover the answers from millions of docu-ments, named slot filling [6]. The true answers to the questions do not necessarily exist in the corpus and can be hard to detect. In Tables 1-2 we provide an example of the slot filling task: Table 1 gives the questions; in Table 2 each column represents the answers that come from 13 sources to a single question, while each row gives the answers provided by a single source to the 8 questions. Each blank item suggests that the corresponding source does not provide any answer to this question. We name the blank items to be an empty answer .

For the first four questions, correct answers exist among the can-didate answers. We define them as the has-truth questions . Mean-while, for the last four questions, the answers either do not exist, or are not discovered by all sources. We define the truth to these questions as empty , and the questions as no-truth questions .
Our task is to integrate the answers to all questions. Ideally, for questions whose true answers are among the candidate answers, we should identify them, while for those questions whose answers are not among the candidates, e.g., the province of death of Stuart Rose who is still alive, we should faithfully provide the empty answer. Based on this, we point out the drawbacks of some strategies. Strategy 1 (MajVot) Majority voting among non-empty answers easily fails in this example. As shown in Table 2, for the first four questions majority voting will have a correct answer. However, for the other questions majority voting would randomly choose a can-didate answer instead of refusing to answer it. Though majority voting answers all has-truth questions correctly, half of its answers, i.e., q 5 to q 8 , are wrong. Moreover, incorporating source quality in the same way as TruthFinder [19] cannot alleviate the issue, be-cause it will still provide answers to all questions regardless of truth existence. An alternative approach is to compute a confidence score based upon source quality and use a threshold to decide whether we want to give out an answer or not. However, it is hard to determine such a suitable threshold without any extra knowledge.
 Strategy 2 (MajVotEmp) Based on Strategy 1, a naive way to deal with the no-truth questions is to treat the empty answer as a can-didate answer and apply majority voting on both empty and non-empty answers. However, this strategy is likely to output empty answer as the true answer for many questions. Consider the exam-ple, for q 2 and q 3 , the most frequent answer is the empty answer. Recent work [11] treats the empty answer equally as other non-empty answers and consider source quality to estimate the truth. Even in this situation, the final output is severely degraded because the estimation of source quality will be severely affected by empty answers, which in turn affects the truth inference.

In summary, previous methods will fail when no-truth questions exist. They either suffer from low accuracy when they provide an-swers to all questions, or low coverage when they treat empty an-swer equally as the others. Truth existence estimation is crucial be-cause when a source fails to answer a has-truth question, it should be punished; when it keeps silent to a no-truth question, it should be rewarded. Source quality measures used in previous work [17, 19] cannot alleviate this issue even when they consider empty answers because using single quality measure cannot depict the complete performance of sources, which will hurt the truth estimation step.
Therefore, we propose a new model called T ruth E xistence M odel (TEM), which can leverage the correctness and the completeness of truth integrated from a mixture of correct answers, empty answers and erroneous answers. To the best of our knowledge, this is the first work modeling the existence of truth in truth discovery. For no-truth questions, the proposed unsupervised approach can confi-dently output an empty answer instead of randomly selecting a non-empty answer as the output. We define three source quality: silent rate, false spoken rate and true spoken rate to model a complete spectrum of source behavior. We propose a probabilistic model that can naturally incorporate the proposed source quality measures into the estimation of truth. Efficient inference and parameter set-ting strategies are derived. We also provide a novel cluster-based initialization scheme to help better estimate truth existence.
We evaluate TEM on three real-world datasets on both source quality and truth estimation. TEM can achieve 19.4% improvement in F1 on SF2013. Furthermore, the results on synthetic datasets with various proportion of no-truth questions demonstrate that TEM can perform consistently best on both high-quality and low-quality datasets. We also discuss different initialization schemes of truth existence and variations of TEM. The results show that TEM out-performs state-of-the-art truth discovery approaches in both accu-racy and robustness with comparable time complexity.

The rest of the paper is organized as follows. We first describe our data model and problem formulation in Section 2. In Section 3 we define three types of source quality. Section 4 introduces the probabilistic graphical model and inference algorithm. Section 5 presents our experimental results. We present the related work in Section 6 and conclude the paper in Section 7.
In this section we introduce important terms and the problem definition. We assume a single-value question typeThe truth to a single-valued question is unique. In this case, each source only provides a single answer to each question.

Let E denote an empty answer when a source keeps silent to a question. Let Q = { q 1 ,...,q M } be the set of questions where M is the total number of questions. Each question either has no truth or a single truth. Let S = { s 1 ,...,s N } be the set of sources where N is the total number of sources. Let D i = { d i 1 be the set of distinct non-empty candidate answers to question q where N i is the number of distinct candidate answers to question q . D i only contains the answers provided by sources in S . Let A = { a 11 ,...,a MN } be the set of observed answers provided by all sources to all questions. Each answer a ij is associated with q and s j . Each source s j will provide only one answer to one question q i . The answer can take an empty answer E or a non-empty answer in D i . Let T = { t 1 ,...,t M } be the set of truths where each t i associated with q i can either be a non-empty answer in D i or an empty answer E. We define a has-truth question as the question whose truth is in the non-empty candidate answer set D and a no-truth question as the question whose truth is not in D The truth of a no-truth questions is the empty answer E.

E XAMPLE 1. Considering the data given by Table 2, the ques-tion set is Q = { q 1 ,...,q 8 } . The source set is S = { s The non-empty candidate answer set to the first question q ={43,:59:11, 520627, Afghan, 7/25, 9} with 6 distinct non-empty answers. The input of this truth discovery problem is the set of observed answers A = { a 11 ,a 12 ,...,a MN } , where the answer provided by s 1 to q 1 is a non-empty answer a 11 = 43 , and the an-swer provided by s 1 to q 2 is E, i.e., a 21 = E . The output of this truth discovery problem is the truth set of the 8 questions T ={43, Afghanistan, Ghazni, 50, E, E, E, E}, where q 1 to q 4 are has-truth questions and q 5 to q 8 are no-truth questions.

Given a set of observed answers A for M questions in Q pro-vided by N sources in S , the goal is to infer the truth t question q i and estimate the quality of each source. Note that both truth and truth existence in the input are not known beforehand. Instead, we must infer the hidden truths by fitting the observed an-swers into our model.
In this section, we explore source quality measures in our truth discovery model and explain why quality measures in previous meth-ods fail in the scenarios involving truth existence problem.
As we discussed in Section 1,empty answers are very important inputs that need to be modeled together with non-empty answers. Based on the observed answers of one source s and truths of all questions, we generate the confusion matrix of source s in Table 4. Here t i is the variable to represent the truth of question q observed answer from s , and d i is the correct answer to question q . E is an empty answer.

In Table 4, True Non-Empty ( TNE ) is the number of cases when source s correctly answers a has-truth question. False Non-Empty ( FNE ) is the number of wrong answers provided by source s . It contains two parts: FNE 1 is the number of cases when source s provides a wrong answer to a has-truth question; FNE 2 is the number of cases when source s provides a non-empty answer to a no-truth question. False Empty ( FE ) is the number of cases when source s provides an empty answer to a has-truth question. True Empty ( TE ) is the number of cases when source s keeps silent to a no-truth question. The number of has-truth questions is TNE + FNE 1 + FE . The number of no-truth question is FNE 2 + TE and the total number of questions is TNE + FNE + FE + TE , where FNE = FNE 1 + FNE 2 .

E XAMPLE 2. Consider the source s 13 in the example of Ta-ble 2. s 13 gives correct answers to q 3 and q 4 , thus TNE = 2 ; wrong answer to one has-truth question q 1 , thus FNE 1 = 1 ; wrong answer to one no-truth question q 5 , thus FNE 2 = 1 ; empty answer to one has-truth question q 2 , thus FE = 1 ; empty answers to q q and q 8 , thus TE = 3 . The total number of questions is 8 with 4 has-truth questions and 4 no-truth questions.
For each source, we define different source quality measures to describe different behaviors. We first define three new measures on has-truth questions: Silent Rate , False Spoken Rate and True Spoken Rate . Silent rate and false spoken rate differentiate two types of errors: false empty cases and false non-empty cases.
Then for no-truth questions, two cases may happen: a source may provide a non-empty answer, which contributes to FNE 2 an empty answer, which contributes to TE . We can define an additional false spoken rate on no-truth questions, i.e. FR FNE 2 +TE . Then we can deduct that the quality measures on no-truth questions are:
However, it is not the best way to define an additional false spo-ken rate on no-truth questions. Instead, we propose an assumption on the consistency of false spoken rate.

A SSUMPTION 1. False spoken rate is consistent across has-truth part and no-truth part, i.e. FR = FR 0 .

Based on this assumption, by simple algebra we can compute we can define a new false spoken rate FR = FNE TNE+FE+FNE+TE In particular, the numerator of FR is the number of wrong answers a source provides to both has-truth questions and no-truth ques-tions. The denominator is the number of questions. FR is the probability of a source providing a wrong answer to any question. It represents an overall false spoken rate across all questions. We can see that FR = FR = FR 0 , which means that the overall false spoken rate is consistent on both has-truth part and no-truth part.
By making this assumption, we have a single false spoken rate across all questions instead of two independent ones on each part. This assumption is reasonable because: (1) When a source provides an answer to a question, it will not consider its truth existence, so the probability of providing a wrong answer is independent of truth existence, i.e consistent across all questions. (2) It reduces the num-ber of parameters to estimate, so it increases the effective sample size to make a more accurate estimation on overall false spoken rate. Later we will show it with experiments on real-world datasets.
Next, we re-define silent rate SR and true spoken rate TR based on this assumption and FR . Since FR is the overall false spoken rate across all questions, the definitions of SR and TR should also be on all questions. Keeping the ratio of silent rate to true spo-ken rate consistent across has-truth questions and all questions, i.e. stays true, we can get the following definitions.
The overall SR and TR can be interpreted as follows. (1) A no-truth question could be both valid and invalid. For example, in Table 1, q 5 is a valid question whose answer possibly exists in the document collection, while q 8 is invalid because Stuart Rose is still alive. Based on the confusion matrix in Table 4, TE is the number of cases when a source keeps silent to a no-truth question. Sources generate true empty cases may result from two reasons: failing to provide an answer to a valid question, which contributes to TE correctly keeping silent to an invalid question, which contributes to keeping the ratio of silent rate to true spoken rate consistent across has-truth questions and all questions, true empty cases contribute to SR and TR proportionally to FE and TNE , i.e. TE 1 TE (3) Keeping the ratio of silent rate to true spoken rate consistent is equivalent to making both silent rate and true spoken rate consistent across has-truth part and no-truth part, i.e. SR = SR 0 , TR = TR where SR 0 and TR 0 are the silent rate and true spoken rate of no-have SR = SR 0 = SR , TR = TR 0 = TR .

Actually in our model, we do not differentiate TE 1 from TE explicitly. By keeping the ratio of silent rate to true spoken rate con-sistent, the computation of SR and TR is dependent on the sum of TE 1 and TE 2 , i.e. TE , but not on each individual element.
Similarly, we can derive that 1  X  FR = TR + SR . It holds for both has-truth and no-truth questions. For has-truth part, when a source does not provide a wrong answer, it may either provide a correct answer or keep silent. For no-truth part, when a source gives no answer to a question, it may result from failing to provide the correct answer to a valid question, which is associated with silent rate, or by successfully predicting that there is no true answer to an invalid question, which corresponds to true spoken rate.
A commonly used measure of source quality is Precision . We can define it based on the confusion matrix as follows.
Revisit the example in Table 2. Table 5 represents the source quality measures of s 12 and s 13 . Previous work [11, 19], e.g. AverageLog and TruthFinder use precision to model the quality of sources. They only consider non-empty answers and ignore empty answers from sources. The integrating algorithms provide non-empty answers to all questions. Thus, they fail in all no-truth questions. In Table 2, the truth of q 5 will be predicted as Holland instead of E, because non-empty answer is only provided by s whose precision is 0.5.
Another alternative is to only use true spoken rate as the source quality measure. It is similar to the source quality used in proba-bilistic models such as LCA [12], LTM [21] and EM [17]. How-ever, existing work do not differentiate two types of errors, i.e. false non-empty ( FNE ) and false empty ( FE ). To illustrate the necessity of it, we use the following example.

In Table 5, source s 12 and s 13 have the same true spoken rate but different silent rate and false spoken rate. To simplify the prob-lem, we only consider the contribution made by s 12 and s With only true spoken rate as the quality measure, the probability of Afghanistan to be true is TR 12  X  (1  X  TR 13 ) = 0 . 25 . The probability of E to be true is (1  X  TR 12 )  X  TR 13 = 0 . 25 . These two answers get the same score because missing an answer counts to the same measure as a wrong answer does. Thus, both sources are treated as with the same quality.

However, we can conclude that s 13 is more likely to provide a wrong answer, which is reflected by its higher error rate. Thus, when s 13 provides an empty answer and s 12 gives non-empty an-swer, empty answer made by s 13 is more likely to be wrong while the non-empty one given by s 12 is more likely to be the truth.
Consequently, if we differentiate empty answer from wrong an-swer and recompute the probabilities again, we can get the proba-bility of Afghanistan to be true is TR 12  X  SR 13 = 0 . 5  X  0 . 25 = 0 . 125 , and the probability of an empty answer to be true is FR (1  X  FR 13 ) = 0  X  0 . 75 = 0 . We can conclude that the correct answer to q 2 is Afghanistan.
In this section we first describe our TEM model, a Bayesian net-work that naturally incorporates true spoken rate, silent rate and false spoken rate into truth estimation. We formulate it as a Max-imum Likelihood Estimation (MLE) problem and apply EM algo-rithm to jointly estimate source quality and truth. In each iteration, source quality and truth are iteratively computed. We also discuss an initialization scheme to set the prior of truth. We tackle the truth existence problem using Bayesian network. Figure 1 is the graphical structure of our probabilistic model. Each node represents a random variable. Each dot represents a prior pa-rameter. The shaded nodes indicate the corresponding variables are known, and lighter nodes mean the latent variables we are going to infer. The letter on the right corner of each plate is the number of replicates for each node, e.g. N is the number of sources, M is the number of questions. A directed edge from one node a to another node b means that b is generated from a distribution parameterized by values of a in addition to other related nodes.
 Three Source Quality Measures For each source s j  X  S , we can define silent rate, false spoken rate and true spoken rate by probabilities, denoted by  X  (1) j , X  (2) j , X  (3) j . According to the original definitions, silent rate is the probability that s j keeps silent when a
Based on the assumption that false spoken rate is consistent across has-truth and no-truth parts, false spoken rate is the probability it makes mistakes on either has-truth or no-truth questions, i.e.
True spoken rate is the probability to provide a trustworthy an-swer when a question has truth, i.e.  X  (3) j = P ( a ity measures is that silent rate, false spoken rate and true spoken Prior of Source Quality Measures For each source s j  X  S , a source quality vector, denoted by  X  j , i.e.  X  j = (  X  (1) We generate  X  j from a Dirichlet distribution with hyper-parameter
Later we will see that  X  serves as the pseudo counts of silent answers, wrong answers and correct answers when estimating the corresponding source quality. It controls the prior belief for three source quality measures. In practice, we can plug in our assump-tion on the overall quality of sources by using either symmetric or asymmetric Dirichlet distribution. It makes our model robust to both high-quality and low-quality data.
 Prior of Truth For each question q i  X  Q , we define the prior of probability of truth t i being one of the non-empty candidate answer d in .  X  i 0 is the probability of q i being a no-truth question, i.e.  X  P ( t i = E ) ,  X  in = P ( t i = d in ) ,n = 1 ,...,N i . The probability that the truth is empty or any non-empty candidate answer should add up to 1 ,i.e. P N i n =0  X  i 0 = 1 . We will discuss the initialization of truth distribution in depth in Section 4.4.
The observed answers to q i provided by N sources in S are de-noted by A i , where A i = { a i 1 ,a i 2 ,...,a iN } is a subset of A . Based on the dependencies of random variables in TEM, for each question q i we bring in a latent truth t i  X  X  and partition the like-lihood of observations of q i into N i + 1 parts. The probability to observe A i given source quality  X  S is: Eq. 1 is expanded by the law of total probability to the combina-tion of N i + 1 mixing components. The mixing weight for each component n is fixed to its corresponding prior of truth  X 
We assume sources are mutually independent . Thus, the prob-ability of A i conditioning on t i = d in is the multiplication of the conditional probability of observed answer from each source, i.e. a . Thus, each component in the first N i parts is computed by:
Given the latent truth t i , the observed answer a ij is generated from a categorical distribution parameterized by  X  j . The proba-bility of a ij given t i = d in is Eq. 3, where I { X } is an indicator function serving as a selector of corresponding source quality. Similarly, the last component is shown in Eq. 4.
 Source quality of each source follows a Dirichlet distribution pa-rameterized by  X  . Thus, the prior of source quality of S is: Then the complete likelihood of all observed answers and source quality given hyper-parameters  X  and  X  is: Eq. 6 is the objective function. Given the observed answers A , non-empty candidate answer set D i of each question q i , prior of truth  X  and hyper-parameter  X  , the objective is to infer the parameters  X  = {  X  S } and estimate the posterior of latent truths in T .
Expectation-maximization (EM) algorithm [2, 18] is an iterative approach to find the maximum likelihood estimate of the latent variables in graphical model. EM algorithm iteratively alternates between two steps, called the expectation step (E-step) and the maximization step (M-step). In E-step, it computes the expected log-likelihood of the complete data. In M-step, it estimates param-eters by maximizing the log-likelihood of the complete data. This process continues until it converges, i.e., reaching a local maxima. E-step : Given observed answers A and the estimated source qual-ity  X  ( k ) S of k-th round, for question q i , by Bayes X  rule we com-pute the posterior probability of truth being empty of k+1-th round,  X  i 0 . Based on the independence of sources, we derive that the posterior of truth is estimated by the multiplication of correspond-ing source quality and prior of truth.
Eq. 7 indicates if a question is answered by sources with high false spoken rate  X  (2) j , or not answered by sources with low false spoken rate, or with high prior of t i = E , this question is unlikely to have truth. The probability that the truth of q i being non-empty is:
Eq. 8 shows that if an answer d in is provided by sources with high true spoken rate  X  (3) j , or different from the answer provided by sources with high false spoken rate  X  (2) j , or not provided by sources with high silent rate  X  (1) j that keeps silent to this question, or with high prior of t i = d in , d in is prone to be the truth. M-step : For source j , we estimate the source quality  X  imizing the expectation of the log-likelihood of the complete data. Take derivatives of it with respect to  X  (1) j and  X  (2) j  X  j = 1  X   X  quality of k-th round with the estimation of posterior of truth of k-th round. The estimated source quality of s j is shown in Eq. 9 -11. Eq. 12 -15 are the empirical counts weighted by the posterior prob-ability of each case being true. Eq. 12 is the weighted count of cases when s j keeps silent to a has-truth question. a j is exactly the estimation of FE defined in Section 3. Eq. 13 is the weighted count of cases when a source provides the correct answer to a has-truth question, i.e. the estimate of TNE . Eq. 14 is the weighted count made of two parts: providing an an-swer when there is no truth and giving an incorrect answer to a has-truth question. The sum of these two parts is FNE . Eq. 15 is the weighted count of empty answers to no-truth cases.
The sum of these weighted count is the number of questions.
Note that these weighted counts are added by corresponding pseudo counts originated from prior of source quality. Thus, the prior of source quality serves as a smoothing factor for source quality.
We can interpret Eq. 9 -11 as follows. False spoken rate  X  is estimated by the number of wrong answers a source provides to all questions. The ratio of silent rate  X  (1) j and true spoken rate  X  is estimated by the ratio of the number of empty answers and the number of correct answers to has-truth questions. With constraint  X  j +  X  form solutions. We can see that Eq. 9 -11 exactly match the defi-nitions of SR , FR and TR in Section 3.
As mentioned in Section 4.1, for each question q i , we need to set the prior of truth  X  i . Two classical methods can be applied to set the prior truth distribution. (1) UNIFORM: Uniformly assign weight to each dimension of the prior truth distribution, i.e. 1 / ( N N i is the number of non-empty candidate answers. It indicates that we put the same initial guess on both empty and non-empty candidate answers. (2) VOTE: Assign weight to each dimension of prior truth distribution proportionally to the number of occurrences of each candidate answer.

Take q 2 in Table 2 as an example. The parameter setting of prior truth distribution is shown in Table 6.

As shown in the example of Table 2, empty answers play an im-portant role in estimating truths of questions. It is risky to treat empty answers same as the other empty ones, because a large pro-portion of empty answers may take the majority, making the es-timation of has-truth question be no-truth. Thus, it is important to develop a new scheme to initialize the prior of empty and non-empty answers separately.

Here, we propose an initialization scheme called EXISTENCE based upon a quantity named truth existence score , which syn-thesizes two indicators, namely, participation rate and consistency rate . We define two types of sources and two indicators.
E XAMPLE 3. In Table 2, the participating sources of q s ,s 4 ,s 7 ,s 8 ,s 9 ,s 12 , and the majority sources of q who provide answer Afghanistan, i.e. s 4 ,s 7 ,s 12 . So the participat-ing rate of q 2 is 6 / 13 and the consistency rate of q 2
These two rates can effectively reflect the truth existence of each question. High participating rate indicates that a large proportion of sources tend to provide answer to this question. High consis-tency rate indicates that a large proportion of sources agree on one answer. When a large proportion of sources provide an answer to a certain question and reach an agreement on one answer, the ques-tion is likely to have a correct answer within its candidate answers.
We define the truth existence score as the probability that a ques-tion has a correct answer in its candidate answers, i.e. P ( t We may treat participating rate and consistency rate as two features and the estimation of truth existence score can be conducted in ei-ther semi-supervised or supervised method.

However, in most real applications, the labeling information is not known in advance, or is expensive to obtain. Consequently, we introduce an unsupervised method to coarsely estimate the truth ex-istence score. By using a Gaussian Mixture model [1] (GMM), we can separate questions into two groups: has-truth cluster and no-truth cluster. We may use the posterior probability of each question belonging to the has-truth cluster as truth existence score. Each question is represented by PR and CR in the new features space. Intuitively, GMM tends to cluster questions into two groups cen-tered at two peaks of the density function of new features. Thus, we can consider it as a "relative grouping". It means that the clus-tering result of one question is affected by the other questions, i.e. compared to other questions, how likely it is to be has-truth. To know which cluster is the has-truth cluster, we simply assume that the question whose product of participating rate and consistency rate is the largest belongs to the has-truth cluster.

For the non-empty candidate answers, we use VOTE to initialize the prior truth of each dimension, i.e. set the prior truth of this can-didate answer proportionally to the number of occurrence. Table 6 shows the initialization of prior truth distribution by EXISTENCE, where p is the estimated truth existence score.

EXISTENCE provides us an alternative way to initialize prior of truth. When most of sources are credible, we may just trust ma-jority and use VOTE to initialize truth prior. When a large part of questions are no-truth, EXISTENCE can outperform other initial-ization schemes. Later we will see it with real-world datasets.
One problem of using the posterior probability of GMM clus-tering is that it may be very small, i.e. close to 0, or very large, i.e. close to 1. In this case, the judgment of truth existence may be too bold. So we introduce a smoothing factor  X  to compensate this judgment. We use P ( t i 6 = E ) +  X  as truth existence score if
Algorithm 1 presents the implementation of TEM.
In this section we demonstrate the effectiveness and efficiency of TEM on three real-world datasets. All the experiments are con-ducted on a laptop with 4 GB RAM, 1.4 GHz Intel Core i5 CPU, and OS X 10.9.4. Algorithms are implemented in Python 2.7.
We provide details on datasets and the experimental settings. SF2013  X  This dataset is from TAC Knowledge Base Population 2013 slot filling validation (SFV) track [14]. In this task, 18 slot-filling systems return the answers to a given set of questions about 100 entities. We select single-valued questions and manually map answers of different representations but the same semantic mean-ing into a single string. Note that this problem can be solved by synonym learning or co-reference algorithms and is independent of the truth discovery problem. After that, it consists of 774 ques-tions in total, where 329 are has-truth questions. There are 3,913 http://www.nist.gov/tac/2013/KBP/data.html Algorithm 1 EM Algorithm for TEM inference Input: Answers A for questions in Q provided by sources in S Output: Truths in T , source quality  X  S 1: {Initialization} 6: {EM Algorithm} 7: k  X  0 8: while not converge do 9: k  X  k + 1 14: {Compute answers} non-empty answers from 18 systems. Note that we generate empty answers to questions of a certain entity only when a source answers at least one question of it. It is a common practice used in truth dis-covery [21]. After generating 4,591 related empty answers, there are 8504 pieces of answers in all. Ground truths are evaluated by human accessors and provided by TAC.
 SF2014  X  This dataset is from TAC-KBP 2014 SFV track. After the same pre-processing, it consists of 406 questions in total with 160 has-truth questions. The 18 systems provides 2858 answers, in which 1590 are empty and 1268 are valid answers.
 Flight This dataset is crawled from 38 flight websites from Dec 1, 2011 to Jan 3, 2012 [9]. For each flight, it contains the scheduled and actual departure time, arrival time, and actual departure and ar-rival gate. The dataset provides ground truths for 100 flights every day which are used in our experiments. We removed those trivial questions to which none of the sources gives answers. Finally, the dataset contains 2,909 flights with 17310 questions, and 341,732 non-empty answers provided by the 38 sources. There are 1,596 no-truth questions with 80,949 empty answers.
We introduce the measures used in our experiments to evaluate the estimation of truth and source quality. We use precision, recall and F1 to measure the performance of truth discovery algorithms.
For source quality, we use Mean Root Square Error (MRSE) to measure the difference between the estimated and true source qual-ity. We compute the true source quality based on ground truth, with the estimation of source quality in Eq. 9-11 of Section 4.3. http://www.nist.gov/tac/2014/KBP/data.html
Most truth discovery methods adopt an iterative framework to compute the quality of sources and answer credibility. We briefly introduce them as follows.
 Vot For each question, we calculate the number of occurrences of each candidate answer provided by all sources and use the answer agreed by majority of sources as truth.
 TruthFinder (Find) [19] For each non-empty candidate answer, its credibility is the probability that at least one associated source is true. The quality of source is the average of credibility of answers provided by this source.
 AverageLog (Ave) [11] The credibility of an answer is the average quality of associated sources. Source quality is the average answer credibility weighted by the number of answers this source provides. Investment (Inv), PooledInvestment (PInv) [11]. Each source uni-formly invests its quality among the answers they provide, and its quality is a weighted sum of the credibility of those answers. 3Estimates (3Est) [5] They introduce a factor called difficulty of the question in answer credibility and source quality.
 GuessLCA (LCA) [12] Each source has a probability to tell the truth, and a probability to guess among all the candidate answers. They use an EM algorithm to compute the answer credibility and honest probability. We choose this LCA model among the four variants because it performs consistently well on reported datasets. LTM [21] They use a Bayesian model to incorporate two-sided source quality, i.e. sensitivity and specificity, and Gibbs Sampling to infer the truth. For a certain question, if no answer is considered true, then E is returned. If multiple answers are true, we select the most possible one as the true answer.
 EM [17] Each source has two quality measures similar to LTM. It adopts an EM algorithm to compute these measures and answer credibility. We choose truth in the same way as LTM.

LTM and EM naturally handle no-truth cases while other base-lines cannot, so we extend other baselines to run on both original and augmented datasets with empty answers. We append suffix E to the methods running on augmented datasets. To avoid randomness, we run LTM and EM 10 times and report the best results.

Served as pseudo counts of the number of questions, the prior of source quality in our new model TEM needs to be at the same scale as the size of data to affect source quality estimation. Based on empirical study, we set the sum of the elements of the prior about 20% of the total number of questions. For SF2013 dataset, we set the prior uniformly as (  X  1 , X  2 , X  3 ) = (50 , 50 , 50) because the quality of data is low and FR may be large. Similarly, the prior of SF2014 is (  X  1 , X  2 , X  3 ) = (27 , 27 , 27) . On flight dataset, the prior is (  X  1 , X  2 , X  3 ) = (2000 , 10 , 2000) to incorporate the as-sumption that the websites are generally reliable and the FR is rela-tively small. Recent empirical study [16] shows the baselines make the same assumption to perform well on reported datasets. Besides, the smoothing factor is  X  = 0 . 01 for EXISTENCE initialization. The convergence condition is that the sum of the absolute value of quality measures of all sources is less than 10  X  6 . For the base-lines, we set parameters, initializations and convergence conditions as suggested in the original papers.
In Section 4.4.1 we propose a novel method called EXISTENCE to initialize the prior of truth. Here, we run EXISTENCE on SF2013 dataset to see its effectiveness. Figure 2a shows the estimation on (a) Result of EXISTENCE truth existence of questions in SF2013 dataset. The red dots rep-resent no-truth questions, while the blue dots represent has-truth ones. Clustering centers and variance are shown by ellipsoids. From the result we can see that the dots around clustering cen-ters have high accuracy to be correctly labeled. Figure 2b shows the accuracy of EXISTENCE. The red dots suggest these no-truth questions are labeled correctly, denoted by TN. The blue dots sug-gest has-truth questions are labeled correctly, denoted by TP. The green dots represent has-truth questions are labeled as no-truth, de-noted by FN, while magenta ones show reversely, denoted by FP. The numbers of the four cases are shown in the legend in Figure 2b, and the overall accuracy is 0.80.

EXISTENCE provides us an effective way to initialize prior of truth. Later we will show that the combination of TEM and EXIS-TENCE will outperform significantly than other combinations.
We first examine the performance of truth inference. For the slot filling datasets, we use EXISTENCE to initialize the prior of truth, and for flight dataset, we use VOTE because of its high quality. Table 7 presents the inference results of all methods. It shows that our TEM model outperforms existing methods in terms of F1 score on all datasets. Baseline methods either return a small number of non-empty truths, which leads to high precision but low recall, e.g. FindE, AveE, or return non-empty truths to most of the questions, which results in high recall but low precision, e.g. Ave, Vot. On the contrary, our TEM model can better infer truth existence, so it can selectively provide non-empty truths to achieve both high precision, recall and the highest F1.

To further examine the effectiveness of TEM, we conduct Stu-dent X  X  paired t-test on TEM and PInv E whose average F1 is the highest among all baselines. We randomly split each dataset into 10 folds, leave out 1 fold each time to run TEM and PInv E and fi-nally obtain 30 pairs of F1 score. Then we conduct the two-tailed test on the F1 scores of two algorithms. The value of t is 2 . 0452 that is larger than that when p = 0 . 05 . Therefore, we conclude that TEM is better than other baselines with statistical significance.
We can see that the three real-world datasets have different pro-portion of no-truth questions. We define no-truth rate as the pro-portion of no-truth questions among all questions, which is an im-portant factor to affect the performance of all the methods. On slot filling datasets where no-truth questions are prevalent with 57% no-truth rate on SF2013 and 56% for SF2014, our TEM model per-forms significantly better than all the baselines. State-of-the-art algorithms perform better when considering empty answers. This is natural because simply ignoring the empty answers will result in many no-truth questions being mistakenly answered. On flight dataset, although there are a small number of no-truth questions with only 10% no-truth rate, our TEM still achieves the highest F1 among all the methods. On this dataset, baseline methods per-form better without considering empty answers due to lower no-truth rate. Note that none of the baselines perform consistently well on all datasets. This shows the strength and robustness of TEM on datasets with various no-truth rates.

To examine the effect of no-truth rate, we synthesize a set of datasets based on flight dataset. We randomly sample different number of has-truth questions and remove them to make the no-truth rate ranges from 0.1 to 0.5, and run all methods on these pro-cessed datasets. Figure 3 shows that the F1 score of all methods de-creases as the no-truth rate gets larger because the removal of has-truth questions is equivalent to degrading the quality of sources. Most baselines get worse than or close to Vot when no-truth rate is 0.5. However, TEM is stable and consistently better than baseline methods. Even when half of the questions have no true answers, the F1 score of TEM is 0.70. This also proves the robustness of TEM on datasets with different no-truth rates.
Then we show the effectiveness of TEM on source quality esti-mation of SF2013 dataset. The estimated source quality measures are shown in Table 8. We can see that sources are different in three quality measures. SFV2013_12 has the highest false spoken rate with low silent rate and true spoken rate. This means that this aggressive source tends to give answers as many as possible while most of them are wrong. Based on the intuition we derive from Eq. 7 and 8, if an answer is provided by this source, it increases the probability of this answer to be wrong for both has-truth and no-truth questions. SFV2013_14 has the highest true spoken rate and lowest false spoken rate. If it states an answer, it increases the prob-ability of it to be correct due to its high true spoken rate, and votes more to this question being has-truth because of its low false spo-ken rate. In all, our TEM model can represent the source quality in fine-grained measures, which helps to gain more accurate truth estimation than the state-of-the-arts methods.
When the algorithm converges, the final MRSE is 0.011, 0.013 and 0.021 on SF2013, SF2014 and flight dataset, respectively. It shows that TEM converges closely to the global optima.
In Section 4.4.1 we propose a novel initialization method to set the prior of truth. To demonstrate the effectiveness of the combi-nation of TEM and EXISTENCE, we run baseline methods in the following way. We first run EXISTENCE to have the estimation of has-truth questions. Then we run baseline methods on the esti-mated has-truth part. The evaluation metrics are the same. Table 9 shows the performance of our TEM model and the baselines. We can see that with the estimation of has-truth questions by EXISTENCE, the performance of baseline methods is significantly improved on slot filling datasets compared to that in Table 7, which shows the power of our EXISTENCE initialization. However, our TEM still outperforms the modified baselines. It is because the mis-clustered questions by EXISTENCE will definitely lead to wrong answers in the baseline methods, while they could be corrected in the later stage when we iteratively estimate truths and source qual-ity in TEM. On the other hand, the performance on flight dataset is degraded for all methods. It is because the no-truth rate of flight dataset is very low. In this situation, EXISTENCE will mistakenly label many has-truth questions as no-truth.

To investigate the effect of different initializations of truth prior, we compare the performance of TEM with different initializations, i.e. EXISTENCE, UNIFORM and VOTE. As shown in Table 10, TEM with EXISTENCE is much better than that with the other two initializations on slot filling datasets. Because the quality of fight dataset is high with only 10% no-truth rate, VOTE is a better way to initialize truth prior. In all, EXISTENCE provides an effective scheme to set the prior of truth, and the combination of suitable initialization and TEM outperforms other baselines on all datasets.
In Section 3 we make an assumption on the consistency of false spoken rate. Here we justify our assumption by experiments.
We first provide the false spoken rate on both has-truth and no-truth parts, i.e., FR and FR 0 defined in Section 3. Table 11 shows the false spoken rates of 18 sources in SF2013 dataset. The two
Table 11: False Spoken Rate on Has-Truth and No-Truth Part false spoken rates are quite similar for all the sources. The mini-mum difference is only 0.01, and the maximum difference is 0.21. The overall difference, defined by q P 18 i =1 (FR i  X  FR 0.089. It indicates that the false spoken rate on has-truth and no-truth part are consistent, and our assumption is reasonable.
In Table 12 we compare TEM model with the variation TEM2FR, which has two false spoken rate FR and FR 0 for has-truth questions and no-truth questions, respectively. On all datasets, TEM2FR has a higher precision because of better false spoken rate estimation on has-truth questions. However, it suffers from low recall due to inaccurate estimation of FR 0 on no-truth questions. The inaccu-rate FR 0 leads to a large number of truths estimated as empty, so TEM2FR has very low recall and hence low F1 score. This experi-ment shows that our TEM model is more robust than TEM2FR by reducing parameter size with the assumption of consistency.
We compare the running time of all methods to show the effi-ciency. All algorithms except Vot are iterative. Thus, we fix the number of iterations to 100 and run all iterative algorithms for 10 times. The average running time per iteration is in Table 13.
TEM works faster than 3Est, LCA and LTM, comparable to other baselines and adaptive on datasets with various no-truth rates. Sim-ple models like Find and Ave are faster, but they are not robust enough to consistently achieve good performance on all datasets. Other models, e.g, 3Est, LTM and LCA are much slower. 3Est and LTM consider negative claims, which increases the data size sig-nificantly. LCA is not efficient because it suffers from the SGD process to compute the source quality.

Figure 4 illustrates the F1 score change in each iteration for iter-ative models. LTM is a sampling-based algorithm whose number of iterations is user specified, so it is not considered here. We see that TEM converges within only 5 iterations. Find and Ave also converge fast, while 3Estimates needs about 30 iterations before convergence. Some baselines are not very stable. LCA does not converge linearly due to the randomness in SGD. Inv and PInv up-date the score of truth by an exponential function, thus they may converge to a local optima with low performance, i.e. PInv on SF2013. In summary, TEM converges fast with short running time per iteration, thus is efficient in terms of time complexity.
In truth discovery there exist some interesting studies handling different challenges. Yin et al. [19] are the first to formally intro-duce truth discovery and iteratively inferred truth and source qual-ity. Using integer programming, the framework proposed in [11] could incorporate common-sense constraints into iterations. How-ever, these iterative models do not consider truth existence, thus gain either low precision or recall. On the other hand, recent work [17] used probabilistic model to estimate quality measures by bringing latent truth. However, these models do not differentiate empty answers from wrong answers, thus cannot describe fine-grained source quality. To our best knowledge, TEM is the first to model truth existence in truth discovery problem.

Some interesting studies focused on other aspects of truth dis-covery. Li et al. [7, 8] proposed a framework to model multiple data types in a unified optimization model by defining different loss functions. Correlation between sources estimated by similar-ity between answers is considered in source quality to reduce the dependency problem [3]. Guo et al. [13] alleviated source depen-dency problem by revealing the latent group among sources in a probabilistic model. MTM [20] incorporated the credibility of ev-idence into truth discovery by discovering semantic rules. Vydis-waran et al. [15] used a retrieval-based approach to find relevant articles to the answers and propagated the trustworthiness between sources, evidences and answers. Recent work [10] discovered the trustworthiness of the authors of user-generated medical statements by exploiting linguistic cues and expert sources.
In this paper, we investigate the truth existence problem of truth discovery. We show that giving an answer to every question is not acceptable and the aggregation should be able to output empty as the final answer when truth does not exist. Moreover, when a source indeed gives empty as the answer to no-truth questions, we should reward this source, and vice versa. To model this important observation, we propose three source quality measures: silent rate, false spoken rate and true spoken rate. We propose a novel proba-bilistic model to incorporate these measures as sources generating the answer set given true answers. Also, we proposed effective initialization approaches to initialize the prior of truth. Extensive experiments on three real-world datasets clearly show the proposed model outperforms state-of-the-art truth discovery approaches.
Interesting future work includes solving the truth existence prob-lem when the independence assumption between sources does not hold. When two sources are dependent, the answers they agree with should be discounted. The source dependence will affect the initialization of truth prior as well.
Research was sponsored in part by the U.S. Army Research Lab. under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), NSF IIS-1017362, IIS-1320617, and IIS-1354329, HDTRA1-10-1-0120, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov), and MIAS, a DHS-IDS Center for Multimodal Information Access and Synthesis at UIUC.
