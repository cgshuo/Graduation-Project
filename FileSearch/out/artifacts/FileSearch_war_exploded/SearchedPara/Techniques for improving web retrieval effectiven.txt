 1. Introduction
A huge amount of information exists in the Internet web. The number of web pages is enormous. But has become an important technology. It will be more indispensable as the amount of information in the web gets larger.

To foster research on information retrieval (IR) technology the Text Retrieval Conference (TREC) has been held annually ( Harman, 1997 ). The web track in TREC is specialized for web IR. This track  X  s major goal was to develop technology for the ad hoc retrieval task. In this respect the goal has not been much different from that of the conventional IR systems. As web retrieval gets more commonly and widely used several retrieval modes have been proposed and studied in the web track. The home page finding task was documents relevant to the query. The named page finding task is to find the exact web pages or documents that actually contain the relevant information ( Craswell &amp; Hawking, 2003 ).
 search engine with the vector-space model that is popular in the conventional IR systems. On top of this basic model, several schemes are applied that can improve performance include:  X  using the title sections of web pages,  X  using the anchor texts of the incoming links,  X  using sentence X  X uery similarity,  X  stratifying and re-ranking the retrieval list,  X  cutting off the documents that have limited kinds of information.

To justify the validity of these techniques, we developed a web IR system, applied these techniques to the baseline system, and measured the system performance. Effectiveness of each technique was measured
Hawking, 2003; CSIRO, 2003 ). Deliberate consideration had to be exercised to make the system efficient in time and space for indexing and retrieval.

The test collection has 150 topics provided by NIST. The relevance judgments for the topics were pre-pared by NIST. Table 1 shows some of the topics and the corresponding relevance judgments. Before the announcement of the relevance judgments the participants to the TREC sent the result of runs of their sys-tem (called the official runs) to NIST and received the performance evaluation of those runs. The perform-This data is compared with performance measurements of our unofficial runs to assess the techniques pro-posed in this paper. Our experiment demonstrated that our techniques are useful for improving retrieval effectiveness.

This paper is organized as follows. Section 2 describes the related works. In Section 3 the basic model that forms the underlying foundation is explained. Section 4 provides the descriptions of the techniques proposed for improving retrieval effectiveness on the web. Experimental results and evaluations are given in Section 5. Finally Section 6 has the concluding remarks. 2. Related works
Web documents have hyperlinks connecting web pages. This is the feature which conventional informa-in the early years focused on developing techniques to make use of information obtainable from hyperlinks.
Kleinberg (1999) proposed a link-based algorithm which calculates and uses the authority and hub scores of documents. These scores are totally based upon the link connectivity of pages rather than semantic con-tents. A PageRank algorithm was suggested by Brin and Page (1998) which assigns a page rank (PR) value to a page based upon the PR values of the pages pointing to it. PR values depend on the connection topol-ogy as Kleinberg  X  s. Another scheme called spreading activation propagates the page X  X uery similarity through links to other documents. Thus the final retrieval score of a document depends on both link con-Picard, 2001 ).
 The early attempts to exploit anchor texts of incoming links can be seen in Brin and Page (1998) and
McBryan (1994) . More recently Fujita (2001) and Singhal and Kaszkiel (2001) also studied on the use of this data representative. However, they could not observe any reliable improvement in retrieval effective-ness. On the contrary, more recent works have reported that in-link anchor text is useful ( Craswell, in-link anchor text is helpful in web IR. However, there is no unified agreement on the scheme for making use of it.

Another characteristic of web documents is the document structure. They have the title section and sev-eral levels of H sections (where H stand for headlines). From early web IR research, systems attempted to utilize this structure. But their importance was not clear because using the structure did not result in
Picard, 2001 ). However, the systems in recent days tend to make use of the title as a major document port this approach.

Another source of information for web retrieval is URL. It was shown that this information could be it was not confirmed that it is helpful in the named page finding task ( Craswell &amp; Hawking, 2003 ). using sentence X  X uery similarity. A lot of research has been done on passage retrieval and revealed that it can improve the retrieval effectiveness significantly. However, the use of sentences in our sentence X  X uery similarity technique has some aspects different from the passage retrieval. A passage is not confined to a the scores of documents containing the passages. In contrast with this method no attempt is made to make query and a sentence.

There were attempts to use an interval of text in which all query terms occur for computing the docu-such intervals or spans are identified. The shorter the interval the better it is. The documents with good of all such intervals are computed and used as the major factor in computing the document score. However, an interval can lie across different sentences. There is no direct relationship between an interval and a sentence. 3. The baseline system
We have developed and implemented the whole system including the core search engine. the underlying model of our baseline system. Our system is based upon the vector-space model ument. The representation for document d j is
The element w i , j corresponds to index term k i and can be interpreted as the weight of k ument d j . It is computed as follows.
Similarly, query q is represented by a vector
The weight q i corresponding to index term k i is computed as model.
The numerator is the inner product of the two vectors and j d criterion for retrieval the retrieval status value, RSV. In the basic model alone just sim
When a query q is given to the system, the retrieval process first computes the RSV of all documents. The 4. Techniques for improving retrieval effectiveness
In this section we introduce several techniques adopted by our system to enhance its retrieval effective-ness. Some of them are based on the ideas introduced or suggested previously in other works. We describe
Furthermore this section includes some techniques that we propose for performance improvement. 4.1. Use of the title section
Most of web documents have the title section. Savoy and Picard (2001) said that according more impor-tance to keywords appearing in the title or H1 logical sections document than those in the text body. To apply this idea we use the following scheme: While each occur-the term in the title results in the increment of tf by h where h is greater than 1. in the title are given more importance than those in other sections of the document. 4.2. Using sentence X  X uery similarity
The vector-space model is actually a methodology to measure and use similarity between a document and a query. Vectors are used for representation and comparison. However, in the case of the named page finding task, similarity between a query and a sentence seems to be useful because the query describes the page by name ( Craswell &amp; Hawking, 2003 ). A name usually appears within a sentence rather than being spread across adjacent sentences. We hypothesize that the relevance of a document can be increased if it has a sentence that contains the whole or large part of the name given in the query. tween a sentence and a query for the named page finding task. This information seems to be important.
Let us take an example in Table 3 . Note that the query here uses a name to specify the pages to be re-trieved. Suppose that the document collection contains the two documents d ilarity to the query is almost equal. That is, sim 0 ( d i the index terms  X  X  X ield X  X  and  X  X  X useum X  X  that the query q has. However, humans can easily decide that d more relevant than d i to q . This decision is due to the first sentence of d and q is substantial and affects decision-making. This example provides a motivation to take into account sentence X  X uery similarity in the named page finding task.

Sentence X  X uery similarity can be most accurately computed when a system can understand meanings of systems will employ NLU technology to compare the meaning of a sentence with that of a query. Unfor-tunately, current NLU research is not mature enough to allow ideal IR systems. There have been a lot of research efforts on phrasal or semantic indexing to take advantage of NLU techniques. Unfortunately they were not successful enough ( Perez-Carballo &amp; Strzalkowski, 2000 ).

As illustrated in Table 1 , queries in the named page finding task have a form of a list of several words (especially nouns) like information requests in web search being done by people these days. Here we make
This idea is motivated by the consideration that, in a relevant document, query terms appear in concen-trated fashion in a sentence rather than distributed among multiple sentences.

To apply this idea we need to compute the degree of closeness between a sentence and a query. This value must be one of the factors determining the RSV. The best way to compute this degree is to compare the meanings of them. As mentioned above it is not practical at present. To circumvent this problem, we pro-s (1) = 2, s (2) = 1, s (3) = 2, s (4) = 2, s (5) = 2, and s ( i ) = 3 for i P 6.
 tence X  X uery similarity sim 1 ( d , q ) between d and q : basic model is computed as The coefficient a is used to control the weight of sentence X  X uery similarity in the overall RSV value.
C  X  s j ; q  X  is 1 while C  X  s bigger than sim 1 ( d i , q ). Therefore, d j is decided to be more relevant to the query than d have the same sim 0 values). The main reason for this result is that all index terms in q exist in d occur in different sentences. The observation so far related to this example leads to a heuristic. in a document, the bigger the relevance score of the document gets.

To be able to compute sentence X  X uery similarity we need to store in the index storage additional infor-mation, i.e., the sentence numbers of sentences (of a document) in which an index term occurs. We store this list as shown in Fig. 1 . This figure shows a node for document d d in which the term x occurs. The sentence number list is implemented as an array. So a sentence number fore, the system does not experience serious slowdown of speed. 4.3. Exploiting link information
Our system does not exploit link connectivity since web IR research so far could not show its effective-the important document representatives.
 4.3.1. Using anchor texts of incoming links approaches did not result in nontrivial improvement in performance ( Hawking, 2001 ). However, several tiveness enhancement ( Craswell et al., 2001; Kraaij et al., 2002 ).

To calculate the RSV of a document d , we make use of the anchor texts of the links coming into d (the in-link anchor texts of d ). For example, the link l in Fig. 2 is an in-link of d link seems to indicate the content of the document being pointed to. In particular an anchor text can be involved in the relevance computation of the destination document of the corresponding link. We take two approaches in using anchor texts.  X  Method 1: Similarity between an anchor text and a query is computed using the cosine coefficient. Let document d have m in-links whose anchor texts are L i ,1 6 i 6 m . Interpreting L representation,
Contribution by the anchor texts to relevance of d is represented by sim  X  Method 2: The degree of closeness between anchor texts and a query are used in this method as in sen-tence X  X uery similarity computation explained above. We use the function C introduced in Section 4.2.
The total contribution by using link information is obtained by adding the values from the two methods.
Incorporating link information to relevance computation leads to the next formula for the RSV. The coefficient b in this formula is used to control the weight of link information.
 4.3.2. An efficient procedure for using anchor texts attempt to use link information requires efficiency in computation. Otherwise, the system can experience much slow-down of speed. As explained before, the system considers only documents whose sim than 0 to save time. The documents that do not have any query terms are not even considered during the processing. Similarly time constraint does not allow the system to consider all documents in computing sim 2 . We need to develop a scheme that those documents whose sim or considered.

We take a similar approach to that shown in ( Lim, Oh, Maeng, &amp; Lee, 1999 ). Given a query, all doc-uments whose sim 0 is greater than 0 are identified. They constitute the set A : document can have relevance to the query via the anchor texts. In other words by having nonzero sim document can have the RSV greater than zero.

We emphasize that, in our system, anchor texts of outgoing links of a document are part of the document  X  X  X edical insurance X  X  is considered to be a part of the text body of d terms in this anchor text contribute to the tf  X  s of those terms related to d chor text makes some contribution to sim 0 of d i since it makes the corresponding tf nonzero. Thus sim is greater than 0. (In contrast, the terms in the anchor text do not contribute to sim if sim 2 of d j is nonzero because of this anchor text then it is certain that sim does not have any anchor text which can contribute to sim that every document holding an anchor text that contributes to sim set A .
 Here it holds that that F = A B is the set of documents which receive no contribution from anchor texts but only from the text bodies and D = B A has the documents that have nonzero score contributed to only by anchor texts but not by the text bodies.

We should be able to compute E in an efficient way. For this we use the basic idea (drawn above) that ument in A whether it has outgoing links whose anchor texts have some relevance to the query. If such case is found the destination document is given the appropriate sim there. The procedure for obtaining E is as follows: (1) Find and insert into A all documents whose sim 0 is bigger than 0 using the basic model. (2) Copy A into E . (3) For each document d in A , check every out-link anchor text L in d .If L share some index terms with (4) E is the final result and can be used for further processing.

The number of documents in A is much smaller than the whole document collection. Thus this procedure preprocessing (for each document) needs to record those documents pointed to by outgoing links in it and their anchor texts. 4.4. A stratifying and re-ranking stage
The RSV of a document is determined by using the techniques introduced so far. Then the documents whose RSV is bigger than 0 are sorted in descending order and ranked. The result is the RSV-based ranked list and is usually used as the final output.

However, before producing the final output we let the RSV-based ranked list undergo another stage, the stratifying and re-ranking stage. This additional stage is based on the maximum count / of index terms in common between the sentences and a query. For each document in the ranked list, / is computed as follows: both s i and q .

The main idea of having this stage is that if the / of d i the RSV. The documents with the same / belong to the same layer and they are ranked according to the is done in this stage can be defined precisely as follows: rank( d i ) 6 rank( d j ) if and only if 4.5. Cutting off documents based upon information sources
Finding the large number of documents including ones with small relevancy is not what the named page important. The system must do its best to find a small number of documents that the query really wants.
This characteristic of the task led us to cut off the documents that do not receive contribution from either sentence X  X uery similarity or anchor texts. The experiment showed that this scheme improves the performance. 5. Experimental results and evaluation Experiments were done for the named page finding task using the test collection for the web track of
TREC-2002. In the named page finding task one or two documents are given as the relevance judgment to each query. Because of the characteristics of the task the mean reciprocal rank (MRR) is used as the criterion for performance evaluation instead of recall and precision. The MRR is computed as follows. recorded. 9 After the reciprocals for all queries are computed, their mean is computed as the MRR. The ideal system  X  s MRR would be 1 since the first document in the output will be an answer for every query.
The worst system will have 0 as the MRR since no answer is found in the final output list for any query. 5.1. Determining the parameter values
The system has three parameters a , b and k . 10 We need to determine their values. This process can be meters are determined to be the values that result in the best performance for the training set. The MRR measure explained above is used as the criterion for performance comparison. The performance of the sys-tem to report is measured upon the queries in the test set by using the parameter values obtained from the corresponding training set.

Given the training set, the next procedure is used to determine the (optimal) parameter values. We hold k point (with the particular combination of a and b ) the MRR is measured using the queries in the training set. This is illustrated in Fig. 3 where the measured MRR value is shown at some of the grid points. The maximum MRR is identified. The a and b values at this point (along with the maximum MRR) are re-corded in association with the grid.

This process of creating a grid and finding the best a and b values is repeated for every k between 0 and
The a and b recorded for the grid of this best k determines their optimal values. Note that the optimal to a different optimal parameter values. 5.2. Performance data 5.2.1. Multiple sets of training and test data
Recent machine learning technology recommends us to have the training and test data be separated, use test data. In this way we prepared 10 sets of test and training data.

For each test and training data set we measured the performance of the system. Once training data is given, the optimal parameter values are determined by the procedure explained in Section 5.1. By using fore, we come up with 10 sets of performance measurements. 5.2.2. Performance measurement results
Table 4 shows the performance measurement result. Each number in this table is actually the average of 10 measurements for our multiple (training and test) data sets. Each row represents a combination of the proposed schemes. Column  X  X  X op 10 X  X  has the number of queries (and its ratio) for which an answer was found among the top 10 documents in the retrieval result list.  X  X  X ot found X  X  has the count of the queries
Row 1 (sim 0 ) shows performance of the system using the basic model alone. This is the base line per-formance of the system. Adding the title information improves the system a lot as shown in row 2 (sim rows represent the various combinations that incorporate some of the proposed techniques.
Exploiting sentence X  X uery similarity as stated in Eq. (5) results in the most significant performance improvement as demonstrated in sim 0 + title + sim 1 . This is a novel technique that we have suggested for the named page finding task of web information retrieval.

Utilizing hyperlinks results in performance shown in rows 4 X 7. The symbol sim both Method 1 and Method 2 for exploiting hyperlinks explained in Section 4.3. Rows 5 and 6 show that that Method 2 was found to be better than Method 1. Using both of them (sim better than using just one of them (sim 0 + title + sim 1 in the table that using both methods for anchor texts (sim anchor texts.

The documents are removed from the retrieval result when they do not receive any contribution from improvement in performance as observed in sim 0 + title + sim
Incorporating the stratifying and re-ranking stage was proven to be quite effective as shown in sim future. 5.2.3. Statistical tests for meaningful comparison
The MRR given in Table 4 is the average of the performance measurements for our 10 (training and test) data sets. To have a better grasp on the significance of any difference between schemes it is necessary to variations or not. For this purpose we adopted the t test that is widely used for performance comparison between a pair of systems ( Manning &amp; Schu  X  tze, 1999 ).

The performance of a system is represented by a sample having n values ( n = 10 in our case). Let us as-
The t score is computed as follows. where n is the sample size (the number of measurements), x and y are the averages, and s of t score calculation is shown in Table 5 . The columns C of schemes) under comparison. The next column has the t score. The last column gives the confidence level 18 degrees of freedom.)
They allow us to figure out the significance of performance difference between C t = 7.33 at row 2 indicates that C 2 , sim 0 + title + sim more than 99.9%. Thus it is quite certain (99.9%) that the sentence X  X uery similarity scheme (sim sim 0 + title leads to a better system. In row 7 the mediocre confidence of 65% says that one is not sure that the cutting off technique achieves performance improvement. The techniques sim ity), str (stratification and re-ranking), sim 2 (anchor texts), and sim found to be effective for system enhancement (in decreasing order of confidence).
 5.3. Comparison and evaluation
The performance data of other research works for the named page finding task using the same test col-black). However, the schemes, the components and implementation details of the systems vary. Therefore, simple comparison based on this data cannot be objective enough to evaluate usefulness of the techniques introduced in this paper. For example, some systems used the well-known search engines (as the basic com-search engines and used them for experimentation because special treatments are necessary. There are also propose look valuable.

Our system agrees with other top systems in the fact that titles and in-link anchor texts need to be is when compared with other information sources. Our experiment showed that the title section is an impor-vious findings that providing more importance to keywords in the title section did not result in of the title section.
 Usefulness of in-link anchor text was pointed out in many works ( McBryan, 1994; Brin &amp; Page, 1998; experiments have supported the idea. The value of in-link anchor text was also confirmed in our system.
Moreover we suggested two different schemes for using in-link anchor texts. They can be used in an inte-grated way to yield bigger improvement in retrieval effectiveness.
 Our research showed that sentence X  X uery similarity has a high potential in enhancing performance.
There have been no other research efforts to make use of this information like our approach. According to our experiment this information is most effective for retrieval among the techniques we use including in-link anchor texts. Using sentence X  X uery similarity can be viewed as an approximation to the use of
NLU in information retrieval. Realizing that NLU is not expected to be mature enough in the near future ered to be a good alternative to using NLU.

Another characteristic of our system is to have a stage of stratifying and re-ranking. Applying this stage ship with sentence X  X uery similarity but is in a different form.

The fact that both using sentence X  X uery similarity and having the stratifying and re-ranking stage improve performance significantly means that they works in some degree for computing similarity between a document and a query.
 contribution from either sentence X  X uery similarity or anchor texts. Its contribution to the performance improvement is rather weak compared to other proposed techniques. 6. Conclusion
This paper introduced several techniques for improving retrieval effectiveness of web information retrie-sections in web pages leads to performance improvement. We proposed to use a new technique that makes terms of a query occur the document  X  s relevance tends to get large. It was demonstrated that exploiting links in the form of in-link anchor texts could improve performance a lot. Another effective technique we introduced is to stratify and re-rank the documents in the result list according to the maximum number of index terms in common between a sentence and a query. The effectiveness of this technique was measured to be bigger than that of using in-link anchor texts. Combining these techniques enabled our system to the named page finding task. Whether they might work in other retrieval tasks such as the normal topic relevance task has to be explored.

The techniques we propose have a limitation. It do not work well for the short queries. Especially for one word query these techniques do not work well. The reason is that these techniques use the number of com-mon words between the query and the strings such as a sentence or anchor text.
 Acknowledgements
The authors would like to thank the anonymous reviewers for their detailed comments and suggestions that led to the significant improvement of the paper.
 References
