 As the world is moving into the Big Data era, it is becoming increasingly chal-lenging to integrate and combine records that correspond to the same real-world entities across multiple heterogeneous data sources for efficient and effective deci-sion making. The process of matching and aggregating records that relate to the same real-world entities from different data sources is known as  X  X ecord linkage X ,  X  X ata matching X  or  X  X ntity resolution X  [ 3 ].
 record linkage, it has become a common practice to use quasi-identifiers (QIDs) such as first and last name, address details, age, etc. [ 16 ] for accurate linkage of records. However, when linking personal or confidential data, organizations usually do not want their sensitive information to be revealed to other data sources due to privacy and confidentiality concerns [ 3 ]. This has led to a new research area known as  X  X rivacy-preserving record linkage X  (PPRL) [ 18 ]. Considering the large volume of data in many databases and increasing num-ber of participating parties, achieving scalability has become a challenging task in both classical record linkage and PPRL. Many blocking techniques have recently been developed [ 3 ] to overcome scalability issues. They reduce the comparison space by grouping similar record sets into blocks that likely corresponded to true matches, while excluding as many unlikely matching record sets as possible. As a result, expensive similarity comparisons are only required on a smaller number of candidate record sets. In the PPRL context, blocking techniques need to be performed with the additional requirement of preserving privacy [ 16 ]. In this paper, we propose a novel distributed blocking mechanism for multi-party PPRL which allows each database owner to generate their set of blocks by clustering their own databases independently without revealing any private information across parties, and identify the candidate cluster sets to be com-pared by hashing these blocks in a lower dimensional space. Besides an initial exchange of parameter settings and the final central clustering, our approach does not require any communication among the parties. This provides flexibility and control over the efficiency and privacy of blocking for the users on their datasets. Our approach also provides a mechanism to identify the most similar blocks that need to be compared in sub-groups of participating parties. To the best of our knowledge, no such distributed and independent multi-party private blocking technique has been developed in the literature so far.
 Our contributions in this paper are: (1) a novel scalable distributed and inde-pendent multi-party PPRL blocking protocol based on clustering and hashing, (2) a theoretical analysis of the proposed technique in terms of complexity, block-ing quality, and privacy, and (3) an empirical evaluation of our technique using large datasets. We compare our approach with two state-of-the-art multi-party private blocking techniques [ 12 , 13 ] which shows that our approach outperforms earlier approaches in terms of efficiency, effectiveness, and privacy. Blocking techniques have been employed in record linkage for decades [ 3 ]. Some of the developed techniques have been adapted for PPRL [ 1 , 5 , 12 , 13 ]. Al-Lawati et al. [ 1 ] were the first to introduce blocking for PPRL using standard block-ing [ 3 ]. Mapping-based blocking [ 14 ], clustering [ 13 ], locality sensitive hashing (LSH) [ 5 , 8 ], and reference values-based blocking [ 7 ] are some other techniques that have been adopted for PPRL. However, performing scalable record link-age that provides better linkage quality while preserving privacy is still an open research question that needs further investigation [ 16 ].
 The use of Bloom filters in PPRL [ 5 , 8 , 12 , 13 , 15 , 17 ] has become popular due to their capability of preserving the distances (similarities) between the original strings in the databases. Durham [ 5 ] was the first to suggest a private block-ing technique using Bloom filters in the three-party context. This approach uses Hamming-based LSH functions to efficiently generate candidate record pairs. Recently, Karapiperis and Verykios [ 8 ] have suggested a three-party PPRL block-ing framework which also uses LSH functions for blocking.
 Ranbaduge et al. [ 12 ] recently proposed a multi-party blocking approach based on Bloom filters. The suggested technique uses a single-bit tree [ 9 ] data struc-ture which requires all the parties to communicate to create each node in the tree. In this approach the blocks generated might miss some true matches due to the recursive splitting of Bloom filter sets. This has been addressed by the same authors using a clustering-based blocking approach [ 13 ], where the Bloom filters are first split into small mini-blocks, which are then merged into large blocks based on their similarity using a canopy clustering technique. However, these suggested approaches require all the participating parties to communicate frequently, and they lack flexibility and control over the block generation as all the parties need to agree on the same parameter settings. In contrast to these existing blocking protocols, our approach aims to provide users with control over the block generation process in terms of sizes and number of blocks, which leads to an efficient distributed blocking approach. The aim of our protocol is to allow each database owner to cluster their data-bases completely independently. Importantly, it allows users to block their data according to their computational resources and privacy requirements. of presentation we assume that the databases held by the parties have the same schema. If the databases have different schemas, a private schema matching approach can be used to align the different schemas [ 14 ]. The main steps of our protocol are: 1. Bloom Filter Generation: The parties agree on the parameter settings for 2. Local Cluster Generation: Each party performs a local clustering over their 3. Cluster Representative Generation: For each local cluster a Min-Hash based 4. Candidate Cluster Sets Generation: The LU uses a LSH-based blocking on to be compared from sets of local clusters generated by the different parties. A LU is commonly employed in PPRL [ 1 , 5 , 8 ] to conduct the linkage of the data sent to it by the database owners. An illustrative example of our protocol is shown in Fig. 1 and each step is discussed further in the following subsections. 3.1 Bloom Filter Generation As the first step in the protocol, each party independently encodes their database records into Bloom filters (BFs), where each BF is a bit vector of length m [ 15 ]. First, a set of quasi-identifier (QID) values is selected as blocking key attribute (BKA) values. These selected BKA values are then converted into a set S = { s ,s encoded into a given BF by using k independent hash functions h and all bits having index positions h j ( s i )for1  X  j  X  1. All P parties need to agree upon the parameters required for Bloom filter generation, including m , q (in characters), the k hash functions, and the BKAs. 3.2 Local Cluster Generation The second step is to perform clustering over the Bloom filters independently by each party to generate a set of blocks. The distributed nature of our protocol allows each party to select an appropriate clustering technique depending upon their computational resources. A key point is that the local cluster generation can be considered as a black box where the clustering technique does not need to be the same across the parties as long as the minimum ( s ( s ) size of a cluster can be controlled. Each party can set s independently without making any agreements with each other, which provides more control over the block generation for the database owners.
 The output of this local clustering step is a set of clusters each containing a set of Bloom filters. For our experimental study, we will use a threshold-based hierarchical clustering technique, which is explained in detail in Sect. 5 . 3.3 Cluster Representative Generation As the third step in the protocol, each party independently generates a cluster representative pair (CRP) for each local cluster. A CRP consists of a cluster ID ( CID ) and a Min-Hash signature ( MhS )[ 2 ]intheformof CID, MhS . that defines the densities of all m bit positions of the BFs in a cluster, which allows each party to select the most dense bit positions in a cluster for signa-ture generation, and hide information about less dense bit positions which can potentially reveal sensitive information to other parties [ 5 , 10 ]. The density of a bit position i is calculated as  X  i = o i n , 1  X  i  X  m , where o 1 X  X  in i and n is the number of BFs in a given cluster. Then, the bit positions in v R are ranked according to the density values in descending order and the top-most dense bit positions d&lt;m are selected. Each v R a bit vector v B , where all the selected d bits are set to 1 and the other ( m positions are set to 0. Finally, a v B is used to generate the MhS for its cluster. in v B by using a random seed value R seed , which defines l random permuta-tions [ 2 ]. Using a single pass over the set of v B , the corresponding l Min-Hash values g 1 ( v B ) ,  X  X  X  ,g l ( v B ) are determined for each v dom permutations. Finally, the generated MhS is used in the CRP for each cluster. Before generating the CRPs independently, all parties need to agree on the parameters d, l, and R seed , and the importance of each is described next. Number of Top-Most Dense Bit Positions in MhS Generation ( d ): In order to calculate a suitable value for d , the database owners can individually simulate a linkage attack on their databases to compute an interval of the min-imum and maximum d that can be selected [ 18 ], as will be described in Sect. 4 . All parties need to use the same d , since different values can generate differ-ent signatures for similar clusters in different parties. This would result in these clusters not being considered as candidates in step 4 of our protocol. The Length of the Min-Hash Signature ( l ): The length l provides a trade-off between accuracy and computational cost in candidate cluster generation. In general, the probability that two bit vectors v B and v B Hash for a hash function g i is computed as Pr [ g i ( v B where sim J ( v B ,v B ) is the Jaccard similarity between v l MhS s, the sim J ( v B ,v B ) can be estimated as sim J i  X  landg g probability that y =(1  X   X  )  X  sim J ( v B ,v B )  X  l Min-Hash values of v equal can be defined as: By applying the Chernoff Bound [ 11 ] to this equation, the probability that sim ( v B ,v B ) deviates from ( y/l )uptoanerrorbound  X  is given by: where 0 &lt; X   X  1. Equation ( 1 ) must satisfy l  X  (2 +  X  ) / X  with a probability  X &gt; 0[ 4 ]. To this end, for any constant l = O (1 / X  expected error of the similarity estimate is at most  X  . Based on this estimation the database owners can agree upon an appropriate value for l (with l&lt;m ). Random Seed Value for Permutation Generation ( R seed ): The value R seed needs to be shared among the parties to generate the same set of l per-mutations for the MhS generation using a pseudo-random generator. 3.4 Candidate Cluster Set Generation In order to identify the candidate cluster sets ( CCS s), as a naive approach the linkage unit (LU) can compute the similarities between all MhS s and based on these similarity values group the CID s into different CCS . This would require a complexity of O ( C P ), if each of the P parties generates C clusters, which can become infeasible in terms of the number of computations. To improve the effi-ciency of generating CCS s, a Locality Sensitive Hashing (LSH)-based blocking approach is used in step 4 of our protocol, as shown in Algorithm 1. LSH [ 6 ]is commonly used for searching nearest neighbors in high dimensional data. LSH involves the use of locality sensitive hash function families, which in our context can be defined as follows. The MhS s of each party are divided into b bands each consisting of  X  values where l = b  X   X  . If two signatures MhS and MhS have a Jaccard similarity s , then the probability that the signatures agree in all  X  Min-Hash values of one particular band is s  X  . Thus, the probability that MhS and MhS agree in all  X  hash values of at least one band to become a candidate pair is 1  X  (1  X  s  X  ) b (see also [ 2 ]). This defines the LSH family to be ( s 1 ,s 2 , 1 X (1 X  s  X  1 ) b , 1 X (1 X  s  X  2 ) b )-sensitive if,  X  sim J ( MhS ,MhS )  X  s 1 , then Pr i  X  1 ,...,b [ i | MhS = i  X  sim J ( MhS ,MhS )  X  s 2 , then Pr i  X  1 ,...,b [ i | MhS = i where p 1 and p 2 are two probabilities such that p 1 &gt;p and s 1 , s 2 (with s 1 &gt;s 2 ) are two Jaccard similarity thresholds. into a list of inverted indexes B (lines 2 to 10). For a given band i ,the  X  values of a MhS are used as the hashing key of a bucket u  X  B [ i ] by concatenating all  X  values and the corresponding CID is added to u (lines 7 to 10). If MhS sof different parties have the same  X  values for band i then the corresponding CID s are added to the same bucket in B [ i ] which become a CCS to be compared. In line 12, the LU can generate CCS s for different groups of parties by specifying the parameter s g in the function createCandidateSets() , which defines the sub-group size of participating parties. This allows the LU to identify the most similar clusters that need to be compared between sub-groups of parties. With a default value of s g = P , the algorithm provides the set of CCS s that need to be compared among all the parties, while 2  X  s g &lt;P produces sets of CCS sfor different group combinations of parties according to the specified size. cluster sets that need to be compared in the private comparison and classification step (lines 13 to 15). The parameter L can be calculated as an approximation of the reduction ratio (RR) based on the cluster comparisons by the protocol where C i clusters (each of the same size), where 1 of cluster comparisons for P parties is equal to P i =1 C can be considered as the fraction of cluster comparisons reduced from more likely to be similar among all the CCS s generated. In order to identify the L most similar CCS s, the CCS s are ranked based on how often a given CCS is generated for a bucket u  X  B (line 14), where a CCS generated for all u  X  B gets the highest rank. The top L CCS s are added to the set SCCS . Finally, SCCS is sent to the relevant parties (line 15) to be compared in the private comparison step [ 16 , 17 ] as shown in Fig. 1 -step 4. The time and space requirement for Algorithm 1 is proportional to b which has a trade-off between quality and efficiency as we discuss in more detail in the following section. In this section we analyze the steps of our protocol in terms of complexity, quality, and privacy. Complexity: By assuming there are N records in a dataset with each having an average of n q-grams in the attributes used for blocking, we analyze the computational and communication complexities in terms of a single party. In step 1 all records are encoded into m length Bloom filters using k hash functions. The Bloom filter generation for a single party is of O ( k step 2, the complexity depends on the clustering technique used by a party. We assume each party generates C = N/s max clusters and calculates the v each cluster in step 3. This requires a complexity of O ( m defines the maximum number of records in a block. Consequently, generating l length MhS s for all clusters requires a complexity of O ( l In step 4 of the protocol, the LU needs to hash MhS s of all the P parties into b bands, which requires O ( b  X  P  X  N/s max ) complexity. By excluding the initial parameter agreements in the protocol, which has a constant complexity, the parties communicate only with the LU in step 4 of our protocol. The LU receives P messages each containing C = N/s max CRPs which leads to an overall protocol communication complexity of O ( l  X  P  X  N/s max ).
 Quality: We analyze the quality of our protocol in terms of effectiveness and efficiency [ 3 ]. Since each party performs the clustering mechanism independently, the overall blocking quality depends on these clustering mechanisms used. The lower ( s min ) and upper ( s max ) size bound of the clusters generated by each party indirectly determine the number of candidate record set comparisons required in the private comparison step [ 16 ].
 In step 3 of our protocol, the length l of a MhS provides a trade-off between effectiveness and efficiency of the candidate cluster set generation in step 4. An increase of l decreases the error  X  of similarity estimation by  X  = O (1 / which would decrease the false negative rate [ 3 ], but would increase the number of false positives [ 3 ] in the candidate cluster generation, and vice versa. For a given signature length l , the running time and quality of the candidate cluster set generation in step 4 depend on the number of bands b considered by the LU. As b decreases the probability that MhS s are mapped to the same bucket decreases, which leads to the number of false positives to decrease, but would increase the number of false negatives, and vice versa. On the other hand, incrementing b requires more computational time as each MhS is hashed more often which leads to an increase in the number of candidate cluster sets.
 Privacy: We assume that each party follows the honest-but-curious adversary model [ 18 ] with no collusion between parties. In steps 1 to 3 of the protocol, each party performs their computations independently without any communication across the parties except for the parameter agreements. Step 2 allows each party to select the values of s min and s max according to their privacy requirements, where s min guarantees that every resulting cluster contains at least s which guarantees k -anonymous mapping ( k = s min ) privacy [ 16 , 18 ]. In step 3 of the protocol, before generating MhS s, each party can individually simulate a linkage attack, based on the probability of suspicion ( P databases to compute an interval [ d min ,d max ] for selecting the number of top-most dense bit positions d in BFs to be used for the signature generation. P is defined for a value in an encoded dataset as 1 /n g , where n of values in a global dataset ( G ) that match with the corresponding value in the encoded dataset D . Each party performs the attack by assuming the worst case scenario of D  X  G . d min and d max provide the minimum and maximum d required to avoid exact matching of a record in the database and a unique q -gram of a record, respectively. All parties agree upon an appropriate value for d by considering these intervals.
 only receives a set of CRPs from each party. The parameters used in the Bloom filter generation, the values for d , R seed , and the sizes of the clusters, all are unknown to the LU. Therefore, the LU cannot learn the frequency distribution of the clusters generated to conduct a frequency attack [ 18 ]. We evaluated our protocol, which we named DCH (for Distributed Cluster-ing and Hashing), using the datasets used in and provided by [ 12 ], which were extracted from a North Carolina Voter Registration (NCVR) database datasets contain 5 , 000 to 1 , 000 , 000 records for 3, 5, 7 and 10 parties, where in each of these sub-sets, 50 % of records were matches. Some of these datasets included corrupted records, where the corruption levels were set to 20 % and 40 %. Experiments with these corrupted datasets allowed us to evaluate how our approach works with  X  X irty X  data. We used Given name , Surname , Suburb ,and Postcode attributes as QIDs, as these are commonly used for record linkage. splits the Bloom filters into a set of mini-blocks, as adapted from [ 13 ], and merges these mini-blocks using hierarchical clustering until all clusters are at least of size s min . For comparative evaluation purposes we used two state-of-the-art multi-party private blocking techniques, the single-bit tree (SBT) multi-party PPRL blocking approach [ 12 ] and the hierarchical canopy clustering-based (HCC) multi-party PPRL blocking approach [ 13 ] by Ranbaduge et al. as to our knowledge there are no other blocking approaches for multi-party PPRL available. All experiments were run on a server with 64-bit Intel Xeon (2 . 4GHz) CPUs, 128 GBytes of main memory, and running Ubuntu 14 . 04. We implemented all the approaches using Python (version 2 . 7 . 3), and these programs and test datasets are available from the authors.
 filter parameters as m = 1000, k = 30, and q = 2. Based on a set of parameter evaluation experiments we set the parameters d = 500, l = 500, b = 100, and s min = 1 % of the dataset size. We set the parameters of the SBT and HCC approaches according to the settings provided by the authors [ 12 , 13 ]. Complexity is evaluated using the average total runtime for the protocol. We evaluate the blocking quality using the standard measures RR (as explained in Sect. 3.4 )and pairs completeness (PC), which is the fraction of true matching record sets that are included in the candidate record sets generated by a blocking technique [ 3 ]. To evaluate the privacy against frequency attacks we use the measure probability of suspicion ( P s )[ 18 ] for a single party by assuming all parties contain similar block structures.
 Figure 2 illustrates the scalability of our approach in terms of the average time required with different dataset sizes and the number of parties. Our approach shows a linear scalability with the size of the datasets and the number of parties. As shown in Fig. 2 (a), the runtime required for a given dataset depends mostly on the local clustering step, which suggests that the efficiency of the protocol improves with faster clustering algorithms. According to Fig. 2 (b), total blocking time increases with the number of parties because more hashing is required by the LU. For the dataset with 1,000,000 records, SBT and HCC require each party to send 2,010 and 16,128 messages with floating-point vectors, respectively. In our approach the parties require to communicate only once with the LU in step 3 which makes the protocol more communication efficient.
 Figure 3 (a) to (c) illustrate PC against RR for the dataset with 500,000 records for different number of parties and different corruption levels when all parties have the same block sizes. This shows our approach can produce better blocking quality with more cluster comparisons. According to the results illus-trated in Fig. 3 ( b ) and ( c ), our approach DCH can provide better blocking quality than SBT and HCC even with  X  X irty X  data. However, with the increment in the number of parties, a lower RR value would generate more candidate cluster sets which in-turn requires more candidate record sets to be compared in the private comparison and classification step in PPRL. Figure 3 (d) illustrates PC against RR for the dataset with 500,000 records with different block sizes for 3 parties. This shows our approach provides high blocking quality for lower block sizes and even when the parties use different block sizes.
 As shown in Fig. 4 (a), DCH provides significantly better privacy against frequency attacks compared to SBT and HCC. According to Fig. 4 (b), the variance between cluster sizes generated by DCH is lower compared to the other approaches. DCH provides clusters within the acceptable size limit of [ s min ,s max ]. This illustrates that our technique provides better privacy than the other approaches while achieving higher RR and PC for dirty data. We proposed a novel communication efficient distributed blocking protocol for multi-party PPRL based on local clustering followed by a global candidate clus-ter set identification. We evaluated our approach with large datasets which indi-cates our approach is scalable with both the size of the datasets and the number of parties. Our approach outperforms two existing state-of-the-art multi-party private blocking approaches in terms of blocking quality and privacy. As future work, we plan to extend the experiments with different techniques in the local clustering step to measure the impact of clustering on the blocking quality. We also plan to extend our protocol into a cloud-based framework, improve the privacy of the protocol, and investigate other adversary models.

