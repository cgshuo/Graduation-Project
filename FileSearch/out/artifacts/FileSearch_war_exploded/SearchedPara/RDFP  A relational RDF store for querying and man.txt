 1. Introduction
With recent advances in the development of Scienti fi c Work various domains are able to automate their experiments using scienti complex and distributed scienti fi c computations. As a result, scienti provenance metadata.
 [16,94] technologies have been increasingly used for provenance management due to their domain knowledge via domain-speci fi c provenance ontologies; therefore, an inference engine with support of user-de inference rules is needed as domain-speci fi c provenance ontologies can contain various inference rules (such as derived from a protein  X  ) that cannot be known in advance, and domain-speci different provenance models, domains, and organizations in collaborative scienti the Tupelo project [6] ).

In this paper, we propose an approach to provenance management that seamlessly integrates the interoperability, ex-query mapping, enabling us to develop a provenance metadata management system that is more ef that is simply based on an existing RDF store.  X 
As provenance metadata is generated incrementally, each time a scienti elimination optimization strategy, can be developed for provenance based on the property that work generated before work fl ow execution metadata.  X 
As the performance for provenance storage and that for provenance querying are often con provenance management system to trade data ingest performance for query performance. For example, for long-running scienti fi c work fl ows, trading data ingest performance for query performance might be a good strategy.  X  ef fi cient provenance browsing, visualization, and analysis.  X 
Update and delete are not the concern of provenance management since it works in an append fashion, similarly to log improved query performance.

These provenance-speci fi c metadata properties cannot be assumed by a general-purpose RDF store, hampering several study for a real-life scienti fi c work fl ow in the biological simulation completely satisfy the provenance management requirements of the work Therefore, by exploiting the above provenance characteristics, we design a relational RDF store, called RDFP optimized for scienti fi c work fl ow provenance querying and management. RDFP complies with the architectural requirements de fi ned for the reference architecture for scienti relational database management system that serves as an ef commercial native RDF stores, AllegroGraph [1] and BigOWLIM [2] , to show that our optimizations result in improved performance and scalability for Semantic Web enabled provenance metadata management. We also show how SPARQL can be but not least, we provide a case study for provenance management in the TangoInSilico [43] scienti production quality and capability of RDFP ROV for this real-life provenance application. 1.1. Organization RDFP ROV and introduces a sample provenance ontology. Sections 4, 5, and 6 present the model mapping layer of RDFP work fl ow from the biological simulations fi eld. Section 8 empirically compares RDFP stores. Finally, Section 9 concludes the paper and discusses possible future work directions. 2. Related work
In this section, we discuss related work on scienti fi c work and querying systems. At the end of the section, we discuss our research in the context of related work. 2.1. Storing and querying scienti fi c work fl ow provenance
Provenance management has become an important functionality for most scienti including the context, data derivation history, work fl ow de
Based on the provenance information, Kepler supports ef fi provenance recorder implements the Read-Write-State-Reset (RWS) provenance model proposed by Bowers et al. [21] for work fl ow run to support a wide range of scienti fi c provenance queries.
The CombeChem [48,104] , Mindswap [49,50] , and VIEW [29,69] systems also use a Semantic Web approach for provenance work fl ow provenance on the Semantic Web.
 product validation.

The Wings-Pegasus system [64] uses an OWL ontology for semantic representation [65] of provenance generated during execution. As a result, work fl ow instantiation provenance can be queried using SPARQL and work be queried using SQL.

The VisTrails system [27,46] is the fi rst one to support provenance tracking of work evolution provenance is represented as a rooted tree, in which each node corresponds to a version of a work corresponds to an update action that was applied to the parent work this way, VisTrails can support scientists to navigate through the space of work process. VisTrails uses XML and relational database technologies for provenance management.
The REDUX system [14] uses the Windows Work fl ow Foundation (WinWF) as a work provenance management.

The Karma system [97,98] records provenance at four dimensions: execution, location, time, and data provenance.
 and XML database, respectively, for provenance management.
 work fl ow provenance annotation that will enable interoperability among the systems. determines the source data that is used to produce a data item. However, in scienti existing approaches to the data lineage problem are not suf 2.2. Storing and querying RDF data using relational RDF stores its result is returned as a SPARQL query solution.
 Based on database schemas employed by existing relational RDF stores, we can classify them into four categories: RDF schema or ontology evolution, since it employs a generic database representation. (s,o 1 ,o 2 , ... ,o n ) , which stores subjects s and objects o
Representatives of schema-aware RDF stores are Jena [117  X  further improvements in query performance [7] .
 the vertically partitioned approach that is available in both schema-aware and data-driven approach, if supported, might be expensive.
 from schema-oblivious and schema-aware approaches) is presented in [105] , where a schema-oblivious database rep-hybrid and schema-aware approaches.
 important and has many previously unexplored optimization opportunities.
Inference support techniques employed by RDF stores can be classi supported on the data mapping stage. In backward-chaining, inferences are computed dynamically for each query, which mapping stage. Additional readings on inference for the Semantic Web include [4,11,66,74] .
SPARQL features and implement several query translation simpli database. Udrea et al. [106] propose an in-memory index structure to store RDF graph regions de elaborate on OWL/RDF data management in IBM DB2, presenting scalable storage schema, reasoning, indexing and query data management systems. 2.3. Our research in the context of related work backend. In this work, we present relational RDF store RDFP Sesame and Jena for provenance metadata (see our case study in Section 7 ). RDFP much similarity to OPM [3] , although they are developed in parallel and independently. Some of our novel fi ndings with respect to existing RDF data management work are described below. characteristics to satisfy varying data management needs. In particular, RDFP desired.
 speci fi cally, employing the fact that work fl ow de fi nitions are always inserted before work
At the query mapping stage, we propose a new schema-independent SPARQL-to-SQL query translation algorithm that is essential to support multiple schema mappings in the system. We propose two optimizations for the translation: Finally, we explore several performance characteristics of RDFP
Unlike in other experimental studies that benchmark speci support additional important provenance queries. 3. Provenance model management based inference to augment to-be-stored RDF datasets with new triples. RDFP mappings that are available for provenance metadata acquisition. The repository is currently represented by a
While OPM [3] may emerge as a provenance model standard in the future, in this paper, we use a simpli provenance model to provide an example. Note that the development of a full-paper; this task rather requires collaborative community effort. In our sample model, a work tasks, work fl ow inputs, work fl ow input parameters, work a computational or analytical step of a scienti fi c work interface to other tasks. Tasks are linked together into the work input parameters, which are used by an e-scientist to con
The provenance ontology, called PO , which can capture the semantic and structural description of work objects, as well as their execution instances, is shown in Fig. 2 . PO can support queries across work and data objects. Fig. 2 illustrates only an excerpt of PO which sketches concepts for work work fl ow evolution, and de fi nition  X  execution relationships:  X 
Work fl ow de fi nition (see Fig. 2 (a)). It includes classes Work a particular data channel, it can be either a work fl ow input (relates to Work
Work fl ow via property output ), work fl ow input parameter (relates to Work task output (relates to Task via output ), or task input parameter (relates to Task via inputParameter ).  X 
Work fl ow execution (see Fig. 2 (b)). It includes classes Work invocation dependency graph ( directTaskDependency and transitiveTaskDependency ), and data object runs other via computational tasks.  X 
Work fl ow evolution (see Fig. 2 (c)). A work fl ow that evolved from another work directWork fl owEvolution and transitiveWork fl owEvolution to model a work  X 
De classes via property instanceOf to model that each work fl task run.

Although the de fi nition and execution components look similar, their purposes are totally different. A work prospective, representing the plan for processing; a work work fl ow, which can be conditional or iterative. In addition, a work corresponds to a different work fl ow run, while the work different work fl ow de fi nition).

Consider a sample work fl ow in Fig. 3 (a). It consists of three tasks, two work work fl ow outputs. An RDF graph that describes this work may be present in only one model, such as work fl ow evolution in PO and agents (a catalyst of a process) in OPM. chaining , in which inferences are computed dynamically for each query, we adopt the updates and larger space consumption, however the former is not an issue for immutable provenance metadata. full-opportunity for a user to de fi ne additional inference rules for a speci rules, such that an antecedent and a consequent of a rule are speci graph. For example, our rule for deriving a data dependency graph is as follows. transitiveDataDependency property is de fi ned as owl:TransitiveProperty , such that
Task invocation dependency graph can be inferred based on a similar rule:
Finally, work fl ow evolution graph can be inferred using even a simpler rule, because the directWork between two different work fl ows is given in a provenance dataset. Then, shown in Fig. 3 (d). These RDF graphs, as well as the work be-stored into our provenance database via the model provenance layer.

In addition to a general provenance ontology like PO or OPM, experimental data can be annotated using a scienti vocabulary like Gene Ontology [5] to provide scienti fi c work on demand. For example, while the core functionality of a scienti complex  X  for the data object and  X  alignment  X  for the task. Furthermore, domain-speci kind of metadata. Both general and domain-speci fi c metadata constitute scienti equivalently in this work. 4. Provenance ontology to database schema mapping database schema mapping algorithms using our provenance ontology as a running example. 4.1. Schema mapping algorithms
Database schema design is of decisive importance to support ef an optimal schema for a given set of queries under certain time and space ef graph nodes of a given type, such as Work fl ow , Work fl and can be supported by a general-purpose relational RDF store, RDFP more ef fi cient query evaluation. In particular, since ef relations redundantly, such that query types (1), (2), and (3) can be supported via an ef joins of multiple relations.
 that stores all RDF triples in the database is created. This table can be used to ef the subject, predicate, and object positions. Second, for each $ c views are intended for query type (1), e.g., a user can retrieve all work $ cSubject(i,p,o) is created to capture all triples whose subjects are instances of class $ c . Fourth, for each $ c (3), e.g., all inputs used by a work fl ow can be retrieved from view input . contains a complete set of RDF triples, it is the largest table and should be accessed when there is no suf (see Fig. 2 ) are shown in Fig. 5 .
 alternative indexing strategies with B + -tree indexes, hash indexes, and combination of both B tables $ c(i) and $ p(s,o) , respectively. The set of B + 3 X | P | indexes for SchemaMapping-T.

Finally, the hybrid strategy can provide bene fi ts of performing hash-enables equality searches and B on subject and predicates that are represented by URIs. For example, we can use B that are known to relate instance of ontological classes (aka object properties) and B instance with a literal (aka datatype properties).
 Out of these three strategies, we choose the fi rst one to be used by RDFP this work; we leave the exploration of other strategies as our future work. node, such that it becomes a child of a node n 1 and a parent of another node n reusability can be found in [44,99,102] . 4.2. Schema mapping experiments operated by MS Windows XP Professional. All algorithms were implemented in C/C++ and MySQL 5.0 Community Edition was employed as the RDBMS. Our developed provenance server communicated with MySQL using the MySQL C API.
The datasets for schema mapping, data mapping, and query performance experiments included our provenance ontology, work fl ow de fi nition documents, 2000 work fl ow run provenance documents. All the work biology simulation work fl ow described in our case study (see Section 7 ) and are linked with each other via work relationships. Work fl ow execution provenance documents were obtained by executing the work
VIEW collected provenance for each work fl ow run in a persistent log discussed in corresponding sections.

The performance of our schema mapping algorithms on PO is presented in Table 4 . The reported times include the time around a hundred classes and properties, and minutes for complex ontologies with hundreds and thousands of entries. 5. Provenance metadata to relational data mapping In this section, we explore data ingest optimization strategies for the RDFP compare our strategies with two existing general-purpose RDF stores. 5.1. Data mapping algorithms Availability of the two alternative database schemas in RDFP the system. While the SchemaMapping-V schema requires to deal with only one table, SchemaMapping-T is much more work fl ows.

In the following, we present three data mapping algorithms that insert a new provenance dataset D , either of a work de
SchemaMapping-T, table Triple can be populated similarly, i.e., by simply inserting D into Triple . Let Triple storing the triples of D . New tuples for $c can be calculated by $c new tuples for $p can be calculated by $p  X  (s,o)  X  Select s,o From Triple tuples for tables $cSubject and $ cObject for each class $c
One strategy, called brute-force , is to calculate Triple
Then, delete contents of $cSubject and $cObject and rematerialize these two tables as follows: $cSubject(i,p,o) have to recompute joins of Triple and $c , whose sizes are growing over time. (i,p,o)  X  (Select s,p,o From Triple  X  ,$c  X  Where s=i) Union (Select s,p,o From Triple, $c $c Where s=i) and $cObject(s,p,i)  X  (Select s,p,o From Triple smaller tables.

Triple  X  $c  X  when populating $ cSubject and $cObject . This simpli such that a work fl ow de fi nition is stored at fi rst, its work result, a to-be-stored dataset D may have an instance X whose type ( X rdf:type class ) is not de set stored in the database; the other way around can never be true. Therefore, the join of Triple and $c
Triple  X   X  $c , we can replace them by Triple  X   X  ( $c  X   X  the database tables as follows. Let Triple  X  ,$ c  X  ,$ cSubject ,$ cObject , and $ p $ p a P in the ontology. For each triple t ( t . s , t . p , t . o )in D , (1) t is added to Triple (3) t is added to $ cSubject for each $ c a T [ t . s ], (4) t is added to $ cObject for $ c O(D) .

Figs. 6 and 7 de fi ne algorithms DataMapping-T and DataMapping-TM that implement the optimized incremental and dataset from Fig. 3 (b) and gives a good example of a database instance that we need to query.
Note that the following three properties regarding the cardinalities of relations always hold: (1) | Triple | the smallest relation for query optimization which we discuss later in this work. 5.2. Data mapping experiments
Before data mapping is performed, each RDF document that corresponds to a work performance of less than 0.1 s when evaluated on sample datasets of work produce different entailments.

First, we experimentally checked that the optimized incremental and optimized incremental in-memory strategies were 20 of the optimized incremental (DataMapping-T) and optimized incremental in-memory (DataMapping-TM) strategies for the SchemaMapping-T schema.

Second, algorithms DataMapping-V, DataMapping-T, and DataMapping-TM were evaluated to store sequences of work runs into the databases with the corresponding schemas. In particular, we stored measured the times to store sequences of 1, 20, 200, 2000, and 20,000 work be much faster than its two peers since it only populated one table. On the other hand, DataMapping-TM bene larger response time for the 10 times larger dataset.

Third, the algorithms were evaluated to store a single work already stored in the database. In particular, we stored fi runs with the MySQL server restarted before a trial and for
DataMapping-V was the fastest and Jena showed the second best performance. DataMapping-TM was the slowest for the trials, except for 20,001st work fl ow run when Sesame was slower, and Sesame was the slowest for the performance of all the approaches, except maybe for Sesame, showed to be ef about 0.1 s per work fl ow run, Jena  X  about 0.2  X  0.3 s per work
DataMapping-T  X  about 1.3  X  1.7 s per work fl ow run, and Sesame performed in the range of 1.7
Fourth, in Fig. 11 , we report disk space required to store 1, 20, 200, 2000, and 20,000 work schemas generated by SchemaMapping-V, SchemaMapping-T, Jena, and Sesame. In the space than SchemaMapping-V to store the same data. Jena and Sesame required less space than SchemaMapping-T and more than Jena and Sesame.
 achieve even faster data mapping of large provenance datasets, while the indexes can be created later for ef evaluation. SchemaMapping-V showed constant performance of 0.022 s and 0.16 s per work respectively. SchemaMapping-TM showed nearly constant performance of about 1.0 s and 2.5 s per work  X  performance greatly depended on the availability of indexes. 6. Translation of SPARQL provenance queries into equivalent SQL queries In this section, we present the last and most complex mapping from the model mapping layer of RDFP by the common provenance query patterns and provenance immutability.
 6.1. Query translation algorithm returns information that describes work fl ows that require user input (have input parameters):
In the Select clause, it speci fi es three variables ?w for the work design algorithms to translate a SPARQL query into an equivalent SQL query. questions are formulated in terms of two mapping functions, that may match tp , while  X  ( tp , s ),  X  ( tp , p ), and  X  instance.
 question is yes, let  X  ( X ) be the type of X , then which relation should be chosen for Triple ? Intuitively, we like to choose the relation with the smallest number of tuples.
PO,  X  ( X ) can be decided as follows: de fi ned; otherwise,  X  ( X ) is unde fi ned.

For our sample query,  X  (? w )= Work fl ow as stated in the inputParameter . The other instances and variables have unde range of inputParameter contains several classes.

The answer to the second question of choosing the best relation for used to compute  X  and  X  for each tp in a SPARQL query, such that decided by the relation schema of  X  ( tp ). The smallest relation is identi  X  ( tp . p ) is unde fi ned, we assign |  X  ( tp . s ) Subject |=+
For our sample query, we have  X  (?w rdf:type :Work fl ow)= Work because  X  ( p ) and  X  (? o ) are unde fi ned and | Work fl assuming that | inputParameter |  X  | Work fl owSubject |.
In particular, we eliminate tp of the form X rdf:type :c ,if X also appears in another triple pattern tp already in place when we match X over relational attribute
In our sample query, ?w rdf:type :Work fl ow should be eliminated, because  X  (?w ?p ?o)= Work fl owSubject .
 is schema-independent, it is parameterized with  X  and  X  , and the Calculate-to triple patterns in bgp , restricting (1) relational attributes that correspond (based on patterns to match the same values and (2) relational attributes that correspond (based on values of those instances or literals, respectively.
 contains two relations (lines 05  X  06 in the algorithm) Work
SQL Where clause should ensure their equality t 1. i = t 2. s (lines 10 its  X  value is unde fi ned (lines 13  X  14). The SQL Select clause projects each distinct variable in bgp (lines 15 translated query (line 17): Finally, the SQL query equivalent of our SPARQL query is their applicability (via RDF-to-Relational mappings  X  and stores, are available in [31] . 6.2. Provenance queries
The fi rst provenance challenge [76] de fi ned several provenance queries for a sample scienti of provenance queries that, besides basic graph patterns and its SQL counterpart using our translation algorithms. While queries Q1 use our extensions to SPARQL, denoted as SPARQL+, which are summarized in the following:  X  greatly improves the readability of a query.  X  can use the power of a relational database to implement them (see Q11).  X  containment, etc. In particular, Q12 implements the division operator.
 6.3. Query performance experiments since Sesame did not support SPARQL, we had to represent the queries in the SeRQL [22] query language. relations and relational joins in the queries. Both Sesame and SchemaMapping-T were approximately 2 and Q12, SchemaMapping-T was signi fi cantly faster than SchemaMapping-V. than SchemaMapping-T and Sesame; SchemaMapping-V was on-average faster than Jena. For all the SPARQL+ queries, SchemaMapping-T was signi fi cantly faster than SchemaMapping-V.

Queries Q10, Q11, and Q12 were only evaluated by RDFP ROV are known to be expensive [63] .

From these two experiments, we observed that SchemaMapping-V, Jena, and Sesame scaled worse than SchemaMapping-T, in a memory bound approach. When there is a huge number of URIs/literals in a dataset, ID-to-URI/literal mapping may SchemaMapping-T enables faster data mapping and better scalability for both data mapping and query processing. Figs. 9 and 10 ).

Finally, we dropped all the database indexes and redid the above experiments to get an idea of how the indexes and and two database size settings are reported in Fig. 15 . We observed that:  X  support scalable query processing in RDFP ROV .  X 
Therefore, partitioning and materialization showed to be bene 7. Case study for the TangoInSilico work fl ow
In this section, we present a case study for a real-life scienti as for Jena and Sesame.
 hypothesis that these behaviors elicited by low concentrations of pheromone can be used by males to hypothesis, a simulation scienti fi c work fl ow, called TangoInSilico [43] , was developed using the of different kinds of male and female worms based on the parameters speci results.
 conditions, resulting in 5 X 36 X 20=3, 600 work fl ow runs. Each work provenance of around 500 RDF triples (after inference). After each set of experiments (3600 work 50 replays of simulation visualization and asks a number of questions (provenance queries):  X  20 different parameters) for a particular work fl ow run?  X 
Did a male catch a female in a particular work fl ow run?  X 
In how many runs (aggregation) did a male catch a female for a particular environment setting?  X 
In how many runs (aggregation) did a male fail (negation) to catch a female for a particular environment setting?  X  Based on the above information and our experiments with RDFP how these systems can ful fi ll the requirements of provenance management for the TangoInSilico work requirements of data ingest, provenance query support, and query performance are fully supported only by RDFP COUNT and DIVIDE operations. Out of two database schemas supported by our system, RDFP candidate to manage provenance of TangoInSilico . An important advantage of RDFP schemas SchemaMapping-T and SchemaMapping-V. If later, for another scienti over one table of SchemaMapping-T, since the latter basically subsumes the former. 8. Comparison of RDFP ROV with commercial RDF stores as Jena and Sesame, since they are free to use and distribute with non-commercial scienti as Taverna [121,122] and VIEW [68,69] . However, we are also interested in exploring if RDFP commercial systems. In this section, we empirically compare RDFP as black boxes with de fi ned APIs.
 (1) RDFP ROV +MySQL 5.0 Community Edition (via MySQL C API), (2) RDFP ROV +Oracle Enterprise Edition 9.0.1 (via ODBC), (3) AllegroGraph 3.2, (4) BigOWLIM 3.1.0.
 indexing procedure (the indexNewTriples method) was called after data mapping of each work execution document. Since this strategy resulted in many small index 200, the new triples were automatically re-indexed into a new single uni TM, were used, resulting in six different combinations. RDFP
RDFP ROV with the MySQL backend (except for the single work peers since it only populated one table. DataMapping-TM bene signi fi cantly faster than DataMapping-T. Overall, RDFP ROV and 20, it was the slowest to load 200 and 2000 work fl ow runs. AllegroGraph could not load 20,000 work
DataMapping-TM approaches, but was slower than DataMapping-V. For example, BigOWLIM loaded 20,000 work 6318 s, which is approximately 3.3 times faster than RDFP
RDFP ROV /Oracle/DataMapping-V. We do not report the performance of the systems to store a single work this type of evaluation, nor it is clear how  X  cold  X  and
RDFP ROV showed better performance when coupled with Oracle rather than with MySQL, which could be due to more sophisticated query optimization techniques and join algorithms supported by Oracle. RDFP BigOWLIM were frequently very close and outperformed other competitors for most queries.
For 2000 work fl ow runs or one million triples, RDFP ROV better than RDFP ROV /MySQL for Q1, Q2, Q3, Q4, and Q6, this system performance was signi for Q5, Q7, and Q9.

For 20,000 work fl ow runs or 10 million triples, RDFP ROV insigni fi cant, except perhaps for query Q6, where BigOWLIM was outperformed by every other competitor. While, RDFP Oracle/SchemaMapping-V and RDFP ROV /MySQL/SchemaMapping-T were not very far from the two leaders, RDFP SchemaMapping-V was signi fi cantly slower for Q4, Q7, and Q9.

Queries Q10, Q11, and Q12 were only evaluated by RDFP ROV two database sizes, both RDFP ROV /Oracle/SchemaMapping-T and RDFP 16 ms.
 with respect to the commercial RDF stores AllegroGraph and BigOWLIM. In particular, its data mapping outperformed and Q7, and outperforming BigOWLIM on the larger dataset for queries Q6, Q7, and Q9 when SchemaMapping-T was used.
Furthermore, RDFP ROV with the Oracle backend showed signi for the majority of the test queries. 9. Conclusions and future work managing scienti fi c work fl ow provenance metadata. The architecture of RDFP
RDFP ROV system design provides the two alternative database representations, SchemaMapping-V and SchemaMapping-T, enabling the fl exibility to setup a provenance repository based on speci
SchemaMapping-V supports very fast schema and data mappings, while SchemaMapping-T supports very ef
AllegroGraph, and BigOWLIM showed that our optimizations provide improved ef management. Finally, our case study for provenance management in the TangoInSilico scienti quality and capability of the RDFP ROV system.

Our provenance storage and querying techniques are orthogonal to the scienti be a desirable feature for some scienti fi c work fl ow applications.
 with billions of triples.

References
