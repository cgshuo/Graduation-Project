
Even as the Internet is rapidly becoming an important source of information, little is known about how to retrieve information from the Internet efficiently. Often, Web agents  X  software applications or humans  X  searching for information are selfishly rational; each agent tries its best to retr ieve the information needed. One way to increase the chances of finding the infor mation sought is to send the query to multiple information sites. The practice of sending multiple queries, however, should be done in moderation. The information sites are a common resource that all agents on the
Internet share. Sending too many queries can create excess traffic that will decrease the efficiency of both the Internet as a whole and the individual agents.
The Internet Access Problems (Bicchie ri et al. 1998; Etzioni et al. 1996; Dent et al. 1992) investigate optimal strategies in deploying queries on the Internet. In particular, we study the Multiple Acces s Problem (MAP) (Bicchieri et al. 1998), which considers how resources on the Internet  X  e.g., information sites  X  can be shared in cooperative ways so that the information-seeking agents optimally achieve their goals.

To study the MAP, we need a theoretical model that captures the essence of such a problem. Bicchieri et al. (1998) presents a possibility of modeling the MAP in the traditional two-person iterated prisoner X  X  dilemma game (2-IPD). The MAP, how-ever, almost always (if not always) deals with more than two agents and numerous information sites.

Although the classical 2-IPD can give some insights into the problem at hand, it may not adequately describe the problem. There are many real-world problems that cannot be modeled by the 2-IPD; examples of such problems can be found in
Colman (1982), Hardin (1968), and others. Glance and Huberman (1994) indicate that the IPD game with n players (i.e., n -Person Iterated Prisoner X  X  Dilemma Game) is  X  X ualitatively different X  from the 2-IPD.

Oh (1999c) shows that the MAP is the n -Person Prisoner X  X  Dilemma Game ( n -IPD). Furthermore, given a number of information-seeking agents, the paper pres-ents the optimal range of available number of information sites for cooperation among the agents to be effective.

A corollary of the result is that when the number of available information sites is much larger than that of the information-seeking agents, cooperation may not be a good strategy. There is little incentive to cooperate since the resource is abundant.
On the other hand, when the resource is s carce, cooperation will help more agents attain the information sought. It is, however, generally not possible to know how many information sites are available and how many other agents may be seeking the same information sites.

Usually, groups of information-seeking a gents tend to form clusters by accessing similar information sites (Bicchieri et al. 1998). In this paper, we study the benefits approach. In addition, we discuss diffic ulties on promoting cooperation in the MAP. We will present reasons for these difficulties and discuss possible solutions. This paper is organized as follows. Section 2 explains the n -IPD and the MAP.
Section 3 discusses the equivalence of the MAP and the n -IPD and the optimal ratio of the number of agents to the number of ava ilable information sites for cooperation among agents to be effective. Section 4 presents theoretical lower and upper bounds for cooperation among agents to be efficient. It also introduces the notion of kinship .
Section 5 presents difficulties involving the MAP in promoting cooperation. Section 6 presents the n -IPD model for the MAP. Section 7 presents the experimental results and discusses the effects of clustering.
Hardin (1968) introduces the term tragedy of the commons (TOC). Traditionally, the  X  X ommons X  is any resource shared by a group of people: things like the air we breathe, the highways we share, and the land we live on are the commons. Here, the commons are the information sites that are available over the Internet. resource in the commons. To maximize its utility, the agent believes that it can use the resource as much as possible yet share the cost of accessing the resource.
For example, consider a farmer raising cattle. She believes that she can raise as many cows as she wants and discard the resulting waste far from her cattle in the commons. The fallacy of this logic is that every agent in the commons believes the same. Inevitably, if all the farmers follow the same practice, the common area will be overrun with pollutants that may sicken all the cattle as well as their owners. The logic of commons breaks down when the resource declines or is overused and the population of the group increases.
 commons face a dilemma  X  whether to cooperate or defect. From the individual everyone defects, the commons will break do wn. This situation recalls the classic prisoner X  X  dilemma game. Although the classic 2-IPD can give some insights to the problem at hand, it may not be suitable for the domain in which multiple agents participate in the same instance of the game. Hardin (1968), Colman (1982), and
Glance and Huberman (1993) discuss many real-world problems that cannot be ad-equately described by the 2-IPD. Furthermore, Dawes (1980) states that the 2-IPD games do not represent social dilemmas such as the tragedy of the commons .He gives three reasons: 2. In the real world, the behaviors of other players are essentially anonymous, with 3. In pairwise games such as 2-IPD,  X  X ach pl ayer has total reinforcement control pairwise. In the TOC with multiple player s, it is hard to  X  X unish X  or  X  X indicate X  defecting agents.
Unlike the 2-IPD game where pairwise games are played, the n -IPD is situated when there are n players playing the same instance of the game. There are several different ways of defining the n -IPD. We consider the one presented by Molander (1992). As in 2-IPD, each player faces a choice  X  either to cooperate (C) or to defect (D).
The payoff of an agent is a function of the number of existing cooperators, i .Let c (and d i ) be the payoff of the agent under consideration if it cooperates (and defects, respectively), where i = 0 , 1 ,... , n  X  1.

Figure 1 shows this concept. The agent in the middle is the agent under consid-eration. There are i cooperators and n  X  i  X  1 defectors in the world. The agent in the middle will receive c i or d i when it cooperates or defects, respectively. The agent need not know the number of cooperators and defectors in computing the payoff.
The payoff functions must satisfy the following conditions: 1. Monotonicity d i &gt; d i  X  1 where i = 1 , 2 ,... , n  X  1 . 2. Dominance of the D alternative d i &gt; c i where i = 0 , 1 ,... , n  X  1 . 3. Efficiency of cooperation 2 ( i + 1 ) c i + ( n  X  i  X  1 ) d i + 1 &gt; ic i  X  1 + ( n  X 
The monotonicity condition states that the more cooperators there are already in the commons, the greater the payoff will be for an additional cooperator; the same is true for an additional defector by the second inequality of the monotonicity condition.

The dominance of the D alternative condition states that a myopically rational player will choose defection.

The efficiency of cooperation states that the total payoff of the population will monotonically increase as the number of cooperators increases (or as the number of defectors decreases). The second inequality of the efficiency of cooperation states that if everyone chooses to defect, everyone will get d 0 to cooperate, every one will get c n  X  1 , which is better than d
The payoff matrix will look like Table 1. Table 2 shows an example of possible payoff values (Yao and Darwen 1994).
The Internet is rapidly becoming an important source of information. Yet little is known about how to retrieve information fro m the Internet efficiently. Recently there has been much interest in the creation of software agents for the Internet information search (Dent et al. 1992; Etzioni et al. 1992, 1996; Maes and Kozierok 1993; Shoham 1993; Bicchieri et al. 1998). Agents often look for a piece of information in too many different Internet sites and overload the queried sites, increasing the cost of access.
 mation-seeking agents accessing randomly di stributed information sites. In real life, however, agents sharing cer tain characteristics tend to query the same group of sites.
For example, agents looking for similar t opics will form clusters by accessing the information sites containing the topics being sought. Furthermore, more Internet in-dexing companies such as Inktomi, Alexa, etc. recognize the importance of content-based indexing, which sorts Web sites in terms of their context rather than alpha-dexing is done. Currently, in these early days of Web indexing, Web sites are in-dexed mostly in alphabetical order. As Web indexing becomes more sophisticated  X  by using manual indexing involving human labor or automatic indexers that are becoming smarter  X  more Web indexing companies will use content-based index-ing.

Web searches. In a keyword search, for example, a user looking for  X  X olphins X  may look for Nintendo Dolphin games or Miami Dolphins information. Depending on the user X  X  interests  X  inferred from informatio n collected in the past (from the user and other people)  X  the Web search engine can make intelligent suggestions. This will create user communities over the Internet.
 can be considered  X  X in X . (See Sect. 4.3.) We are interested in studying the emergent behavior of agents when agents tend to cluster based on the content matter of Internet information sites. In this paper, we consider a specific In ternet access problem (IAP) known as the Multiple Access Problem (MAP) defined in Bicchieri et al. (1998):
Definition 2.1. Multiple Access Problem: If an agent seeking a piece of informa-tion knows of several sites that have, or might have, that information, how many queries should it issue, and when?
For one information-seeking agent, the best strategy for maximizing its chances of obtaining the information quickly and successfully is to query every information source; however, if every agent adopts the same strategy, sources will be overloaded and the cost of access (i.e., network delays, f ailure to obtain wanted information, etc.) may increase. This phenomenon fits the TOC. Each agent has a dominant strategy, which is accessing every information source (i.e., abusing common facilities to max-imize individual utility). If an agent believe s that other agents will access every site, then it will also access every site, and there i s no other combination of actions that leads to a better outcome for one agent without other agents doing worse. Although the dominant strategy equilibrium is a Nash equilibrium, it is not Pareto-optimal for all agents.

As the number of information-seeking age nts increases, the load on each informa-tion site can increase dramatically and hence the cost of access as well. This suggests that agents will benefit if they cooperate by sending fewer queries to information sources.

Bicchieri et al. (1998) provide a theore tical analysis of a simplified case with n agents and m information sites to show that cooperation (i.e., sending fewer queries) is beneficial to every agent. The paper assumes that the queries are independent of each other and are sent to the sites in a random fashion so that, on average, queries response time. The theoretical analysis shows that being a defector pays only in very special cases in terms of the frequency of queries received by a site.
Oh (1999c) proves that the MAP[ n , m ], an instance of the MAP with n informa-tion-seeking agents and m information sites, satisfies the conditions of the n -IPD game when m is within the interval ( m min , m max ). We present the main results of the paper and sketches of the proofs here. Readers interested in the details of the proofs should refer to the paper.
 For theoretical analysis, we define cooperation and defection for the MAP as in Bicchieri et al. (1998).

Definition 3.1. Given n agents and m sites, where n , m choices: (1) sending only one query to one of the m sites or (2) sending the query to all m sites. The former is considered cooperation and the latter defection.
We assume that the delay of each site is the same exponential function of the number of queries. This is a reasonable assumption, as server performance deteri-orates faster when server loads linearly increase. (See Bicchieri et al. (1998) and others.)
Figure 2 shows this model X  X  reward function. When there are n agents, each sending a query to the site, the load of the site is n and the reward, r to each agent is  X  1 reward value 1 when there is only one query (i.e., the site load is 1). in our model,  X  = 1. Note that we assume that the value of information being sought is the same for each agent.
 between cooperation and defection. The age nts in the models can send any number of queries. Therefore, there are degrees of c ooperation and defection. Since theoretical analysis of this model would be very complicated, we study the model empirically.
Denote c i and d i by c ( n , m , i ) and d ( n , m , i )
We derive formulae for c ( n , m , i ) and d ( n , m , i Derivation of c ( n , m , i ) :
Consider the simplest case where there are no cooperators and n c ( n , m , 0 ) ). The load (i.e., number of queries received) of each site is n agent under consideration cooperates, the site the agent sent message to will have load n  X  1 + 1 = n . The cooperating agent will get the reward r the reward function of a site as discussed above.
 of the agent when it cooperates would be cooperator and one additional cooperator. The first term is for the case when the additional cooperator queries the site with n  X  2 load (i.e., the site with queries from n  X  2 defectors) and the second term is for the case when the additional cooperator queries the site with n  X  1 load (i.e., the site with queries from n one existing cooperator).

More specifically, for each information site, 1 m m  X  1 m additional cooperator and the existing coope rator query different information sites, and 1 m 1 m is the probability that the two coope rators query the same informa-tion site. Since there are m information sites, we have m disjoint cases like above; therefore, we multiply these probabilities by m .

Recall that i is the number of existing cooperators. Then n of existing defectors plus one. Using the same method as in the c the general closed form for the expected payoff value for an agent if it cooperates, where r ( n ) = 1 Derivation of d ( n , m , i ) :
In the case where the agent under consideration defects, the closed form for the expected payoff, d ( n , m , i ) , is more complicated than when it cooperates. However, we only need to know a lower bound of d ( n , m , following theorem.

Theorem 3.1. Effectiveness of c oordination of cooperators. Given i cooperators and n  X  i  X  1 defectors and for the given exponentially decreasing reward function ( ,where l is the site load), a defecting agent under consideration will have the lowest payoff if and only if each of the i cooperators accesses uniquely different sites.
 Proof. A detailed proof is found in Oh (1999c, 2000a).

Theorem 3.1 says that, given fixed numbers of cooperators and defectors, the sum of the defectors X  payoff will be the lowest when there is perfect coordination among cooperators (i.e., cooperators access uniquely different sites.) This theorem justifies the use of the lower bound d ( n , m , i ) if we prove that d ( n , m , i ) lo w erbound &gt; c ( d ( n , m , i )&gt; c ( n , m , i ) for all i in general.

We assume that when an additional cooperator is introduced, the existing coop-erators send queries to the same sites as in the case before the additional cooperator was introduced. This assumption will fre e us from unnecessary complications in proving the second condition of monotonicity, d ( n , a lower bound of d ( n , m , i + 1 ) and upper bound of d
Consider the simplest case where there are no cooperators and n
The defecting agent under consideration will get the reward mr for each site will be n and the agent sent m queries. In this cas e, all agents are defectors.
 One can argue that a defector should not get multiple rewards for identical queries. We have two reasons for allowing defectors to get such seemingly redundant rewards. 1. Many times two perfectly valid information items returned by a query can be 2. If we show that the model that gives defectors more leverage can promote co-the reward is set up, the optimal interval we are deriving in the next section can be narrow (see Sect. 4.2.1.) Our immediate future research effort will be to prove that the interval exists in the general model. In a preliminary mathematical analysis, the lower bound for the optimal interval is smaller in the general model. consideration defects, there will be a total of one cooperator and n
Then there will be one information site with load n and m load n  X  1. Therefore, the defecting agent under consideration (and other defectors as well) will get the lower bound reward
Similarly, we can find the general closed form for the lower bound to be we assume the queries are evenly distributed over m sites; we call this perfect coor-dination, when i &gt; m . For example, if cooperator i queries site i mod m , then this is perfect coordination.
 is the number of sites with load ( n  X  i + i m + 1 )
Theorem 3.2. The MAP model with the following four properties satisfies the three conditions of the n -IPD: 1. Cooperation and defection are defined as in definition 3.1. 2. For a given number of agents n , the number of information sites m is within the 3. Conflicts among the queries sent by the cooperators are possible. That is, there 4. n &gt; 2.

Outline of proof. The proof is purely mechanical. W e need to first derive the opti-mal interval ( m min , m max ) . Then we prove the three conditions of the n -IPD for the general equations for c ( n , m , i ) and d ( n , m , i ) for the conditions above.
We only consider the case where n &gt; 2 since we are interested in multiagent systems. Also, for n  X  2, the reward equations yield complex numbers.

In the following sections, we discuss efficiency of cooperation and derive the optimal interval ( m min , m max ) for a given number of agents n such that cooperation among agents is effective.
The monotonicity and dominance of D altern ative conditions are the natural condi-tions that come with the MAP. In other words, agents do not have any control over these conditions. The efficiency of cooperation depends on two things: (1) the ratio of n and m and (2) the coordination of queries among cooperators. We will look at these issues in the following sections.
Intuitively, when the number of available information sites is much larger than the number of information-seeking agents (i. e., the resource is abundant), cooperation may not be necessary (or may not pay off) since there is little incentive to cooperate.
On the other hand, if the number of agents is extremely large and the number of information sites relatively small, cooperation may not work either; no matter how much cooperation exists, the information site will be overloaded.

This is consistent with Hardin X  X  argument. If there are relatively few players, there is neither dilemma nor tragedy since a farmer X  X  payoff for adding a cow is more or less the same regardless of whether or not others add cows; this suggests the existence of an upper bound in resources for cooperation to be useful. If the commons has collapsed, adding a cow is poi ntless because it will starve to death; again there is no dilemma; this suggests the existence of a lower bound for usefulness of cooperation. The dilemma occurs only when the commons is in the gray area where it is in danger of being exploited beyond its capacity. When the dilemma exists, cooperation will pay off.

Therefore, there should be a lower bound and an upper bound on the number of information sites (resource) for a give n number of agents for cooperation to be useful. To find the optimal interval, we consider a simplified case for the MAP.
Figure 3 shows the payoff values for cooperation and defection for the simple case where n = m = 50 and i = 0 ,... , n  X  1. Notice that the maximum possible expected payoff for cooperation is 1 while that of de fection can reach 12. This is due to the way the reward is set up in our model. One can argue that defectors may have a better chance of getting the information needed, but the final reward would be no more than 1 since multiple copies of th e same information would not amount to multiple rewards.
 small  X  not quite zero but very close to zero. This suggests that cooperation would not pay unless most of the agents cooperate as well. The general case also exhibits the same phenomenon. This is one of the d ifficulties in promoting cooperation in the MAP domain. This reflects the real-world situation in that a small number of defectors can cause disadvantages for all existing cooperators.
 in Fig. 3 shows that when the number of cooperators is less than 45, i.e., i payoffs for the defection are not that high either (less than 2 in the figure). In other words, defectors need cooperators to achieve significant payoffs. If the cooperator-to-defector ratio is small, defectors suffer as well (Fig. 3b).
 more likely when groups are smaller and more homogeneous. When the groups are small, the behaviors of agents are more public than anonymous. Also, the impact of cooperation and defection is easily  X  X elt X  by each individual when the group is small.
 help cooperators survive. Consider the case where there are several disconnected habitats. Habitats with a greater number of cooperators will have higher reward values on average than habitats with a greater number of defectors. When two habi-tats compete indirectly for survival, th e habitats with higher cooperation levels will survive. This suggests that the kinship bias is important to sustaining cooperation in the MAP. The precise meaning of kinship is defined in Sect. 4.3.

Theorem 4.1. For the model described above, the optimal ratio of the number of agents to the number of available information sites for the efficiency of cooperation condition to be maximum is where
Proof. Detailed derivation is beyond the scope of this paper. The derivation can be found in Oh (1999c, 2000a).
To summarize, for a given n value, the optimal range of m for the efficiency of cooperation condition to hold for the mode l without any coordination among coop-erating agents is
The above inequality is simplified to
Notice that both lower and upper bounds are linear with respect to n . The lower bound is approximately . 6 n , and the upper bound is approximately
It should be noted that this range is sensitive to the site reward function, r
However, the important thing is that such an optimal range exists for most models with a reasonable reward function that reflects the real-world situation. We formally define a generic multidimensional kinship model for this paper.
Definition 4.1. Consider a domain D that contains n agents; n can be a fixed number or a dynamically changing number. An agent in the domain has i kinship genes and j action genes (a.k.a. strategy genes). Th e collection of the kinship genes and the action genes can be defined as an i-tuple and a j-tuple ,where i is the number of kinds of kinship genes in the domain and j the number of kinds of action genes available in the domain. i and j are usually finite and fixed but can be dynamic, infinite, or both.
 An i-tuple kinship gene is defined as and a j-tuple action gene is defined as
Each element of K can be considered an element t hat contributes to defining the kinship relationship between two agents. These elements can be combinations of tags, locational descriptors [as in t he space-based model (Oliphant 1994)], rules (as in rule-based systems), beliefs, opinions, length of arms, or anything that can be used to define  X  X loseness X  (i.e., the metric defined in definition 4.6) between two agents. The kinship tuple K defines the  X  X haract eristics X  of an agent. Each element or combination of elements in A defines a possible action (strategy) of a given agent.
These action genes define how the given agent interacts with and responds to other agents and the environment. Finally, K and A are not necessarily disjoint. Definition 4.2. We denote a kinship domain as D = ( satisfies four kinship constraints defined below as M = (i-kinship, j-strategy) model in general, where d is the metric defining kinship proximity for given two agents. Definition 4.3. Kinship compatible probabilistic distribution function (K-pdf):
A probabilistic distribution function is kinship compatible if and only if it has the tendency of yielding higher probability values (i.e., values of the dependent variable) for smaller values of input variables (i.e., smaller kinship metric values). distribution function, where  X  is the mean and  X  2 is the standard deviation.
Definition 4.4. Kinship compatible genetic operators: Genetic operators that pro-duce kin from two parents in a kinship relation are called kinship compatible ge-netic operators. The kinship compatible ge netic operators satisfy the schema theo-rem (Holland 1975). That is, the probability of the schema being destroyed by the kinship compatible genetic operators, P destroy , is reasonably small. are called  X  X ell-behaved X  genetic operators.

Definition 4.5. Kinship constraints: In a kinship domain, the following constraints exist: 1. Kinship metric: There exists a metric that defines distance between given two 2. Kinship relation: The degree of kinship relation between agent a 3. Kinship interaction: 4. Kinship reproduction: depends on the degree of kinship between both parents and the probability of the schema in parents being destroyed by gene tic operations. If there is only one parent, a , D k (( a i a o ) kin is a function of P destor y .

Definition 4.6. Given a kinship domain, two agents are  X  X in X  if 1. the two agents are more closely related in terms of a kinship metric compared 2. the two agents interact with each other m ore often in terms of some probabilistic distribution than with other agents (the kinship interaction constraint); 3. the offspring generated from the two a gents by some genetic operation satisfy the kinship reproduction constraint.

In a way, our kinship is very much like a  X  X eme X  as described in Heylighen (1992), where the concept of meme is described as replicating units of culture  X  cognitive or behavioral patterns  X  that can be transmitted from one individual to another by learning and imitation. Therefore, agents can be kin if there exists some common characteristic among them; the co mmon characteristic need not be genetic similarity.

The notion of the kinship is also closely related to speciation in evolutionary computation (Spears 1995). Darwen and Yao (1997) showed the importance of spe-ciation in promoting cooperation, a result supporting our kinship hypothesis.
Hypothesis 1. A kinship model M that satisfies the above kinship constraints pro-duces a higher level of cooperation than a nonkinship model M ,where M is the complement of model M , which does not satisfy the kinship constraints but is oth-erwise the same as model M .

Notice that arbitrary genetic similarity alone does not necessarily constitute a kin-ship relation between two agents. For two given agents to be kin, they must be similar to each other (i.e., close to each other) in terms of the metric mentioned above. For example, the metric in the tag-based model of IPD (Riolo 1997) is the tag distance between two players, while the metric in the space-based model of IPD (Oliphant 1994) is the spatial distance between two players.
 The closeness of two given agents is relative to the density of the population.
When the population density is high, the two agents need to be closer to be kin than when the population density is low. We should notice that more interactions among kin will produce more kin in the next generation.

The kinship hypothesis states that cooperation can emerge when players tend to of the agents as well as the genetic makeup of the agents. Therefore, the notion of kinship in this paper is broader than the one specifically used by biologists.
In a series of papers, Oh (1998, 1999a, 1999b, 2000b) shows the importance of the kinship bias in promoting coopera tion in a multiagent environment in which agents are caught in the IPD. It has been shown that the kinship bias produces positive effects on fostering cooperation in such environments.
We have shown that the MAP[m,n] satisfies the conditions of the n -IPD game for certain values of m and n . Before embarking on the empirical studies, we need to understand the complexity of the MAP.

The MAP presents a significant obstacle to promoting cooperation. There are several distinct difficulties:
D-1: As seen in the graphs of c i and d i in Fig. 3, cooperation does not pay off until
D-2: Unlike the pairwise two-person PD gam e, when an agent defects, it defects
D-3: Even in a world with all cooperators, without proper coordination there can
D-4: As the number of available sites increases relative to the number of agents, the D-5: It costs little to send additional queries (the bandwidth is the cost). n -IPD in general) faces overpopulation in cooperator clusters. In a homogeneous region with perfect coordination, the coope rators have higher p robabilities of being selected to produce offspring. Ironically, the kinship mechanism, the very mechanism that produces cooperator clusters, will over populate the region by placing offspring nearby.
 our theoretical model, overall the model intuitively reflects the real-world situation. the difficulties of D-1, D-2, and D-4 above can be alleviated. This is much the same as community identification. For D-1 and D-2, homogeneous kinship regions can benefit a pure cooperators X  region over a pure defectors X  region provided there is no interaction among the regions. For D-4, restricted region imposed by kinship bias will be affected less by the larger number of available sites in the entire domain. This is because the number of available sites, m , is restricted by the kinship region. The kinship region can support the optimal ratio and make the efficiency of cooperation effective. Also, no matter how many agents and information sites are available in the entire world, the kinship bias effectively reduces the group size. As has been discussed, smaller group sizes can encourage cooperation.
 ators within the region. The coordinatio n should not require direct communication among agents. In our experiments, we consider a simple coordination using the idea of kinship bias: each cooperator sends a query to its favorite site. When a coopera-tor receives a less-than-desir able reward, it sends the query to the next favorite site.
As Dietz and Rosa (1994) suggest, efficient utilization of resources can alleviate the dilemma.
This section presents the basic algorithm for the n -IPD model of the MAP and some important parameters of the experiments.
Figure 4 shows the basic algorithm, which consists of two major for loops (within the outermost for loop). In the first for loop, agents send queries to the information sites within the window region. Window size defines the magnitude of the kinship bias. Smaller window size means more kinship bias  X  smaller clusters.
FindAvailInfoSiteWithin(I.Window) returns the list of the informa-tion sites within I.Window . Then the agent decides how many queries it will send using the agent X  X  game-playing strategy, I.Strategy . The function
SendQuriesTo(ISList) sends the queries to the information sites within the
ISList  X  that will receive the queries using t he agent X  X  strategy and the model X  X  mechanisms.

The second loop implements the behaviors of the information sites. Each infor-mation site computes the reward to be ret urned, to each agent who had sent a query the information sites send the rewards to the agents. Note that the orders of the evaluation in the for loops are randomized to eliminate biased situations.
Table 3 presents some important parameters for the MAP model. There are other parameters that are not discussed here but are relevant to (1) evolutionary algorithms and (2) the kinship bias. These parameters are the same as in Oh (1998, 1999b).
We studied both one-dimensional and two-dimensional kinship space. We present the results from the two-dimensional experiments in this paper. We use the site load function used in the theory we developed (Oh 1999c). Some different site load func-tions and mechanisms will be studied empirically.
We begin with simple models and then gradually increase the complexity of the models while observing the effects of the kinship hypothesis on cooperation level. It may seem that some models exhibit obvious results on the experimental setup; how-ever, we intend to elucidate the mechanisms of the kinship hypothesis incrementally.
Each model is designed to show the effects of the kinship hypothesis under specific conditions. Whenever possible, we will relate the experimental results to the theor-etical results discussed in Sect. 4.
  X  Clustering: From randomly distributed populations of cooperators and defectors  X  Coordination: Once homogeneous clusters are formed, coordination among co-in evolutionary computation (Hoffmann and Warning 1996; Seo et al. 2000) and multiagent systems (Sandholm and Lesser 1995; Sims 2003). In Seo et al. (2000), a smaller neighborhood size tends to encourage evolution of cooperation. Further-more, the history length of a strategy is more important in promoting cooperation in a larger neighborhood. Hoffmann and Warning (1996) also show a strong correlation between the degree of localization and its effect on cooperation. This phenomenon is also verified in this study.
 sary, we use the Student X  X  t -test to find confidence intervals under the assumption that the population has a Gaussian distribution. We use the confidence intervals based on the Student X  X  t distribution with a confidence level of 0.95. Unless stated otherwise, all experiments are conducted with default parameter values.
 generations.
The model under consideration is a 2-kinship, 1-strategy model, where the kinship genes are real numbers that define the location of an agent in the two-dimensional world and the strategy gene defines the ag ent X  X  action. The distance between two agents in the two-dimensiona l world represents the preference of the agents accessing servers. Two agents that are close to each other may access a similar set of servers.
The idea is that after a certain number of generations, agents close to each other will have similar strategy genes. Therefore, c ooperators will cluster together and defectors will do the same. The clusters consisting o f defectors will perform poorly compared to cooperators X  clusters.

There are two kinds of models depending on the strategy gene. 1. Discrete Strategy Gene Model (DSM):  X  Number of queries to send: Query only one information site (i.e., cooperation)  X  Decision to cooperate/defect: If the strategy gene is 1, cooperate; if it is 0,  X  Query-sending order: Agents send queries from most-favored to least-favored 2. Continuous Strategy Gene Model (CSM):  X  Number of queries to send: There is no clear distinction between cooperation  X  Decision to cooperate/defect: The number of queries to send resolves this.  X  Query-sending order: Agents send queries from most-favored to least-favored
A similar idea to CSM is presented by Yao and Darwen (1999). Unlike previous studies, CSM and Yao X  X  model considers degree of cooperation rather than strict binary cooperation and defection strategies.

We study the effects of the following parameters empirically: 1. Window size: Agents send queries to the information sites within the window area. Oh (2000a) discusses the biased-selection and the bias-breeding mechanisms of the kinship bias. In particular, the window size is directly related to the biased-selection mechanism, which imposes bias in selecting opponents. In general, the window size and the magnitude of the kinship bias are inversely proportional. 2. The ratio of the number of agents and the number of available sites: We em-pirically study the effects of the optimal ratio of m and n on the efficiency of cooperation condition.
Each set of experiments is conducted with ten different random seeds. Figure 5 shows window size will give better global fitness values. Window sizes larger than 5 will yield to the all-defector state in the early st ages of the simulation. When a simulation reaches an all-defector state, the simula tion is stopped. This is why some plots stop Average Reward short in the figures. Yet among window sizes 2, 4, and 5, the experiments with window size 4 show the best average fitness value. The experiments with window size 5 converge to the all-defector state a round generation 1200. The runs with window sizes 2 and 4 show equilibrium states such that the defectors and cooperators are separated from each other and form communities of their own (Fig. 13). Notice that the window size directly limits the number of information sites an agent sends queries to. This means that an extremely small window size would not support the optimal effectiveness of cooperation. Recal l from the optimal interval theorem in
Sect. 4.1, page 34 that there exists a lower bound of the number of information sites available for a given number of agents. An extremely small window size will violate the lower bound.
This section studies a simple coordination scheme. First, we discuss the model with-out the coordination scheme that sends a query to random information sites within the window region.
 tively, without coordination for the experiments from Fig. 5. Here cooperators have rewards approximately 0.3 larger than defectors. Although cooperators have larger reward values, there is still room to improve. This lower performance among the co-operators is due to a problem mentioned previously: there is no coordination within communities of cooperators. Again, for both cooperators and defectors, a larger win-dow size tends to help defectors and produce an all-defector state. This is why the reward values quickly decrease in the cas es where window sizes are very large.
We use a simple self-coordination strategy among cooperators. The coordination scheme is very simple. A cooperator assumes that other agents are cooperating as well. Then the expected reward for a cooperator is 1 (i.e., 1 load of the queried information site is 1. If a cooperator gets 1 as the reward, it sends queries to the same site in the future. If the cooperator gets less than 1 as the reward, it assumes that there was conflict among que ries sent by cooperators (including its own). It will then switch to the next closest site among the known sites. This process works reasonably well, as shown below. T his is because rarely will any two agents of different window sizes when no coordination exists among cooperators; Fig. 8 shows the effects of different window sizes when coordination does exist among cooperators.

Figures 9a and b show the average reward for cooperators and defectors, respec-tively, using the same experiments as in Fig. 8. As shown, for window sizes 2, 3, and 4, the average reward for cooperators is about 30% higher than in the experi-ments without coordination. Also, the ave rage reward per query for cooperators is close to 1. This means that cooperators are rewarded with each query they send. On
This suggests that cooperators and defectors form their own communities through the kinship bias. The simple coordination among the cooperators works fairly well.
Figures 10 and 11 show the effects of window size on a per-query basis, with-out and with coordination, respectively. C ooperators receive rewards close to 1 (the perfect score), while defectors get around 0.5 regardless of the existence of coordi-nation.

Figure 12 shows the effects of different ratios of m and n . These are consistent with the theory; when the number of sites is 40, 60, 90, or 100, the average reward per query for cooperators is close to 1. Considering the window sizes, the ranges of 20  X  m  X  100 when n = 100 seem to be reasonably consistent with the theory.
When the number of sites is larger than 100 (i.e., NS efficiency of cooperation drops and the simulations converge to all-defector states.
Figure 13 shows a snapshot of the distribution of agents and information sites for the typical run, at generation 250. The two-dimensional space represents the kinship Average Reward Average Reward Average Reward space. The distance between a server and a c lient represents the preference of the around generation 77; the difference con tinues to grow. Runs with different random seeds exhibit similar results. Although the number of cooperators is reduced by more such that cooperators and defectors can coexist in the MAP domain, and the above is kinship regions). Since cooperators are separated from defectors and a reasonable coordination exists, the average reward pe r query for cooperators after generation 20 iscloseto1 X  X .e.,c ooperators receive the information sought with one query. On the other hand, the average reward per query for defectors decreases from 0.5 to worse. In fact, defectors need to do reasona bly well for the clustering to be helpful to cooperators. Consider the scenario in which defectors do very badly compared to cooperators. In this case, cooperators will flourish since more cooperators will be able to produce. This will introduce over population of cooperators within cooper-ator clusters. No matter how good the coordination scheme among cooperators is, overpopulation will make the scheme ineff ective and the information sites will be overloaded.
Figures 14a and b show average gene values with 60 information sites and 90 infor-mation sites, respectively, for the CSM. Recall that a higher gene value means the agent is more cooperative, sending a fewer number of queries.
 Average Reward Average Reward
Average Reward Average Reward Average Reward Average Reward Average Reward
As in the earlier models, smaller window sizes tend to promote higher average gene values. However, for the No . sites = 60 case, the WS higher average gene values than the WS = 30 case. Figures 15a and b show average rewards for the same experiments. The average rewards graphs also show that the
WS = 70 case has a higher average reward than the WS = 30 case. Finally, Figs. 16a and b show the same trend for the averag e site load values. We conclude that the
WS = 70 case when the number of sites is 60 satisfies the optimal ratio of m and n better than the WS = 30 case.

Figures 15a and b show average reward values for the same experiments. Both the 60-and 90-site cases show the same result pattern, differing only in the magnitude of the reward, with one exception; the WS = 2 case performs better for the 90-site case because more sites can be queried fo r a given window size. Again, the WS case is an exception to the general pattern  X  smaller window sizes tend to promote higher average reward values.

Finally, Figs. 16a and b show average site loads. The results are very similar in both the 60-and 90-site cases.

We summarize the relationships among aver age reward, average gene values, and average site loads for the 60-and 90-site cases below.  X 
Average gene values: The 60-site case has slightly higher average gene values than the 90-site case.  X 
Average reward values: The 60-site cas e has lower average reward values than the 90-site case.  X  Average site loads: The 60-and 90-site cases have very similar site load values.
From the above summary, we conclude that the 60-site case produces a higher cooperation level than the 90-site case. We say this because the average site loads are almost the same in each case des pite the 30-site difference. Furthermore, the average gene values are slightly higher in the 60-site case. This is yet more evidence of the existence of an optimal ratio of m and n . The 90-site case has relatively abundant resources so that cooperation is a less attractive option for agents. The higher average reward values in the 90-site cases are due to the abundance of resources. Recall that the number of agents is the same in both cases, i.e., 70 agents.
We embarked upon this research with a general question: What conditions promote cooperation among selfishly rational a gents in multiagent environments? maximize their own utilities, at the cost o f others if necessary. Social dilemmas occur when a group of agents share commo n resources. Benefits from using shared in the group. Therefore, agents are tempted to use resources as much as possible.
However, if every agent in the group thinks the same way, the collapse of shared resources will result. It is therefore in the interest of research communities to study the promotion of moderate usage (i.e., cooperation).

We hypothesized that when frequent interaction among similar agents is encour-aged, cooperation among agents emerges i n environments with such social dilem-mas. To study the effects of such similarity-based cooperation on multiagent systems, we formulated the kinship hypothesis. Informally, the kinship hypothesis states that a model in which similar agents are encouraged to interact frequently will have a higher cooperation level than the sam e model with no such encouragement. Average Site Load
Specifically, we studied an instance of IAP known as the Multiple Access Prob-lem (MAP). MAP solutions try to optimize utilization of the Internet information servers by finding optimal strategies for information-seeking agents.
 information-seeking agents and m information sites, is the n -IPD game when the value of m is within the optimal interval for a given value of n .
 imal, which means that the cooperation among agents is effective. The existence of such an optimal interval is intuitive. When relatively many information sites are available to information-seeking agents, there is no incentive to cooperate since the resource is abundant; this suggests the existence of an upper bound. On the other hand, when relatively few information sites are available, cooperation is not effect-ive since, no matter what, there are insuffi cient resources so that the commons has collapsed; this suggest existence of a lower bound.
 tive assumptions than the mathematical m odel of MAP[n,m]. In most cases, the ex-perimental results confirm the existence of an upper and a lower bound. They also support the kinship hypothesis to a degree.
We suggest the following directions for future research:  X  Various clustering measures: We have c onsidered abstract one-or two-dimen- X  Various game-playing strategies: To separate the effect of kinship bias, we inten- X  Coordination schemes in the IAP: In the IAP, we found out that cooperators  X  Computing  X  X eliefs X  of agents in the MAP: Using the payoff equations, agents  X  More relaxed theoretical models for IAP: In our theoretical model for the MAP,  X 
Collaboration among agents: In our MAP models, information-seeking agents and information sites are functionally different. We can consider a model in which agents can share information with other agents who are kin. This may give more leverage to cooperators.  X 
Cost of sending additional queries: We have not rigorously studied the cost of sending additional queries. Therefore, our models are quite a difficult environment for cooperators. This served our purpose well since we were able to isolate, to a reasonable extent, the effect of kinship bias. We can now study the cost function of sending additional queries. For example, for a given number of agents, n , number of information sites, m , and cost, c , what is the relationship among the three?  X 
Concept of reputation: If agents are awa re of reputation of others and the fact that others are aware of their reputations, cooperation tends to emerge as shown by
Yao and Darwen (1999). The origins of Internet requests can be easily traced, and the information about the requests can be used to build reputation on other agents.
It is worth studying how reputation of agents can affect sharing of common resource in the Internet and distributed systems.

