 Fault-tolerant frequent itemsets (FTFI) are variants of fre-quent itemsets for representing and discovering generalized knowledge. However, despite growing interest in this field, no previous approach mines proportional FTFIs with their exact support (FT-support).

This problem is difficult because of two concerns: (a) non anti-monotonic property of FT-support when relaxation is proportional, and (b) difficulty in computing FT-support. Previous efforts on this problem either simplify the general problem by adding constraints, or provide approximate so-lutions without any error guarantees.
 In this paper, we address these concerns in the general FTFI mining problem. We limit the search space by provid-ing provably correct anti monotone bounds for FT-support and develop practically efficient means of achieving them. Besides, we also provide an efficient and exact FT-support counting procedure.

Extensive experiments using real datasets validate that our solution is reasonably efficient for completely mining FTFIs. Implementations for the algorithms are available from www.cais.ntu.edu.sg/~vivek/pubs/ftfim09 .
 H.2.8 [ Database Management ]: Database Applications -Data Mining Algorithms frequent itemset, error toleran ce, proportional fault toler-ance, anti monotone bound
In transactional databases, the support of an itemset X is conventionally defined as the number of transactions con-taining all items in X . Recent research initiatives in gener-alized knowledge discovery have questioned the strict defini-tion of support, and led to the idea of relaxing it in various ways. The main purpose of introducing such flexibility is to attain generalized information, providing useful knowl-edge or patterns to analysts, which otherwise would remain undiscovered [16]. Such fault-tolerant itemsets have been shown to be extremely useful in various applications and domains, e.g., for initializing the seed of EM clustering [16], discovering fault-tolerant association rules [10], discovering interesting patterns [2, 14], reconstructing noisy databases [2, 9, 6, 7], and clustering/classification [9, 6, 7].
An itemset X is considered as a fault-tolerant frequent itemset (FTFI), if there exists a transaction-set Y whose size is at least as large as the minimum support threshold  X  ,such that pattern Y  X  X satisfies some given relaxation criteria. The FTFI mining problem is to list all such FTFIs with their FT-support. Depending on the mining requirements, the relaxation may be constant or proportional to the size of the items, transactions and pattern. This paper focuses on the proportional case which is considered more natural [9, 6, 7], however as yet no algorithm has been proposed that correctly solves this problem [16, 9, 13, 2], unlike for the case of constant relaxation [11].

This problem is difficult because, unlike conventional sup-port, the FT-support of X , sup FT ( X ), is not anti-monotone [16, 9]. One generic approach for mining itemsets in the ab-sence of an anti-monotone support function is to bound the search space based on a bounding function .Inotherwords, we define a function, f ( X ) which never underestimates the FT-support of X or any of its supersets, and then use it to limit the search space whenever we reach itemset X where f ( X ) &lt; X  .

Example 1. Figure 1 illustrates the idea of the bounding function . Here, the x-axis represents a prefix path of the itemset, such that A  X  B  X  C , sup FT ( X ) corresponds to the FT-support of itemset X and  X  is the minimum de-sired support. Figure 1(a) shows 3 candidate functions, f ( X ) ,f o ( X )and f ( X ), none of which underestimate sup Though f i ( X )isverycloseto sup FT ( X ), it would be an in-correct bounding function, since f i ( A ) &lt;sup FT ( B ). The consequence is that even though sup FT ( A ) &lt;f i ( A ) &lt; X  ,we cannot prune the search at A , since there are possibly other support (a) Incorrect, optimal, and loose bounding functions
Figure 1: Bounding non anti-monotone support itemsets B  X  A ,with sup FT ( B )  X   X  . The desired function would be f o , because whenever f o &lt; X  , we can directly prune the search space. In this example, we can directly prune at itemset C . f can also be used as a bounding function, but it is very loose, and results in a large search space.
While f o is desirable, it might not be efficient to com-pute, which is actually the case as explained later in Section 4.2. Hence, we might want to approximate (slightly over-estimate) f o with an approximated function that permits efficient computation, f a , as illustrated in Figure 1(b).
Following this discussion, we are faced with a challenging question: How can an optimal bounding function for mining FTFIs be derived? (Research Problem 1) .

An integral, but often expensive task in the mining pro-cess is to determine the support of a given itemset. While with conventional frequent itemsets, we can simply count the number of transactions containing that itemset, calculating the support of FTFIs (even with constant error tolerance) is known to be an NP-complete problem [11]. Previous ap-proaches either apply a greedy approximation heuristic [9] or impose additional constraints [2, 7], which again, leads to incorrect or incomplete results. This leads us to Research Problem 2: How can the true FT-support of itemsets be ef-ficiently calculated?
Assuming these two questions can be answered positively, we can mine all FTFIs using the standard two-phase frame-work. First, we generate a minimal number of candidate itemsets (Research Problem 1), and then quickly verify if they are frequent (Research Problem 2). These two phases do not need to be done consecutively, since the support of an itemset can be calculated directly after it has satisfied the bounding check.
For research problem 1 , we can derive the theoretical op-timal (lowest) bounding-function to define the boundary of the search space, given the assumption that no other knowl-edge is known. In other words, when calculating the bound for itemset X , we do not consider any other items outside X . However, this optimal bound is inefficient to compute. We then propose to approximate this optimal bound, which permits very fast computation (linear to the size of itemset).
For research problem 2 , we extend our previous work [11] on calculating FT-support with constant tolerance. The support counting problem (using either proportional or con-stant relaxation) can be modeled as an Integer Linear Pro-gramming (ILP) problem, which in general is NP-Complete. In this paper, we propose a heuristic which substantially im-proves the efficiency of the LP solution when the relaxation is constant. Then we propose an efficient method to de-rive FT-support with proportional relaxation, by iteratively computing FT-support with constant relaxation.

With these solutions, we can efficiently and accurately mine the complete set of FTFIs. Through extensive experi-mental evaluations we show that our techniques are reason-ably efficient in real-world datasets.
The rest of this paper is organized as follows. Section 2 discusses previous works on this topic. Preliminary infor-mation and the formal problem statement for completely mining FTFIs are stated in Section 3. Our framework and algorithms are presented in Section 4, and their efficiency is justified by empirical evaluations in Section 5. Finally, Section 6 concludes with several future research directions.
Yang et al. [16] pioneered fault-tolerant itemset mining in 2001. Since then, this field has witnessed significant re-search interests. Most of these efforts propose different ideal fault-tolerance criteria, which can be generalized using three parameters, each representing the maximum allowed errors in a transaction, in an item, and in the entire pattern respec-tively. To allow efficient computation, those works impose additional constraints for an itemset to be considered as an FTFI. For example, Besson et al. [2] propose the notion of consistent and relevant patterns to reduce the number of patterns, Cheng et al. [6] require FTFIs to meet some exact support (besides FT-support) criteria, and Sepp  X  anen and Mannila [14] force the resulting itemsets to be downward closed.

A major step towards mining complete FTFIs is presented by Liu et al. in [9]. Similar to ours, [9] proposes a bounding function to restrict the search space. However, the proposed bound is both loose and very sensitive to input parameters. We show that even with the best parameters, their func-tion is always lower bounded by our approximate bound (c.f. Section 4.2). Besides this limitation, there are sev-eral other issues that affect the feasibility of the algorithm. First, their proposed technique requires all candidate FT-FIs to store the transactions that possibly support them. This results in infeasible memory requirements, especially on large datasets. Second, the approach does not calculate the exact FT-support, but uses a greedy heuristic instead, resulting in approximate results.

Other works enumerate all interesting (dense) patterns in transactional databases [2, 15, 8]. Their problem is slightly different from ours, since their mining result is the matrix (transaction-set  X  itemset), instead of FTFI. While their approaches can be adjusted to address our problem, they are clearly inferior since large numbers of transaction-sets are associated with each itemset [11].

Recently, Gupta et al. [7] compared the quality of several constraints and corresponding approaches [9, 6, 16, 14] for several data mining applications. However, the results are not comprehensive since some of the algorithms do not mine complete FTFIs. While this paper does not consider the utility of frequent itemsets, our algorithmic development will help towards justifying and exploiting the utility of FTFIs. sup FT ( X, Fault-tolerant support (FT-support) of  X  t , X  i , X  p ) itemset X with the given tolerance. A transactional database consists of a set of transactions T over a set of items I . For clarity, each item is denoted as a lower-case character a, b, c, ... , and an itemset (set of items) is denoted by a sequence of characters, e.g., abc .A function I ( y ) ,y  X  T represents the itemset contained by transaction y . Similarly, a function T ( x ) ,x  X  I represents the transaction-set containing item x . The (exact) support of an itemset X  X  I , sup ( X ), is the number of transac-tions containing X . In this paper, we define a pattern to be a matrix formed by transaction-set and itemset. Without fault-tolerance, a pattern is considered interesting if all its transactions contain all its items, and the number of trans-actions is greater than the minimum support threshold  X  . With fault-tolerance, we relax t he requirement for all trans-actions to contain all items, by introducing some relaxation criteria.
 Definition 1. Transaction Relaxation. A pattern P = Y  X  X satisfies transaction relaxation if all its transactions contain most of its items. Mathematically,  X  y  X  Y , | X \  X   X | X | ,where  X  t is the maximum desired proportion of items missed by any transaction in P .

Definition 2. Item relaxation. A pattern P = Y  X  X satisfies item relaxation if all its items are contained by most of its transactions. Mathematically,  X  x  X  X , | Y \  X   X | Y | ,where  X  i is the maximum desired proportion of trans-actions missing any item in P .
 Definition 3. Pattern relaxation. A pattern P = Y  X  X satisfies pattern relaxation if the total number of missing items by all transactions is small. Mathematically, desired proportion of misses in P .

We require  X  = 0, since otherwise, the problem degrades into the one without fault-tolerance.When a relaxation cri-teria is imposed or considered , it means the corresponding error tolerance is less than 1, and vice versa. For example,  X  X ransaction relaxation is imposed X  means  X  t &lt; 1. When the relaxation is defined as a constant value instead of propor-tional, we add superscript  X  c  X  to the variables, e.g.,  X  and  X  c p . Some common notations are summarized in Table 1 for ease of reference.

Here, we consider a pattern to be interesting if it satisfies all relaxation criteria. Following all aforementioned defini-tions, our mining target is defined as: Definition 4. Fault-tolerant frequent pattern (FTFP). A pattern P = Y  X  X is considered as an FTFP if it satisfies the specified relaxation criteria, and if its size , | Y | X  Algorithm 1 : Framework
C  X  candidate 1-itemset; 1 while C is not empty do 2
Definition 5. FT-support. The FT-support of an item-set X is the maximum size of all FTFPs Y  X  X . FT-support of itemset X with respect to  X  t ,  X  i ,and  X  p is denoted as sup FT ( X,  X  t , X  i , X  p ). When the context is clear, the toler-ance parameters can be omitted, e.g., sup FT ( X ). Definition 6. Fault-tolerant frequent itemset (FTFI). An itemset X is an FTFI, if sup FT ( X )  X   X  .

The problem addressed in this paper can now be formally stated as follows.

Definition 7. FTFI mining (FTFIM) problem. Given a transactional database, the relaxation criteria, and the minimum support threshold, the FTFI mining problem is to enumerate all FTFIs along with their FT-support.
Our framework for FTFIM cons ists of three modules, viz., itemset enumeration, bound-checking, and support-counting. This framework is presented in Algorithm 1. Itemset enu-meration module can be treated as a process to generate candidates (line 8) and to choose which itemset to work on (line 3). Bound-checking procedure (line 4) checks whether any superset of X (including X ) is possibly frequent, and Support counting procedure (lin es 5 X 6) calculates the exact FT-support of X , and outputs X if its FT-support is greater than or equal to  X  .

We denote itemsets whose bound f ( X )iscalculatedas candidate border , and those whose bound is greater the mini-mum support as candidate frequent . To speedup the support calculation, prior to calculating f ( X )and sup FT ( X ), we ex-tract the equivalence classes of transactions with respect to X [11]. This module is denoted as equivalence classes ex-traction .

The purpose of the itemset enumeration procedure is to ef-ficiently generate all itemsets which are potentially frequent , without missing any. So the objective is to generate as few candidate borders, and consequently as few candidate item-sets, as possible. For this purpose, we can use any popular approach [1, 17, 4] for generating frequent itemsets.
This step was introduced in [11] to speedup the support counting procedure using an ILP formulation. The idea is to reduce the number of LP variables for support counting, from the number of transactions into the number of equiva-lence classes . Table 2: Impact of relaxation criteria on anti-monotone property of support, and complexity of support counting
Based on the equivalence criterion, there are two types of equivalence classes.

Definition 8. E X num . Two transactions are E X num equiva-lent if they contain the same number of items from itemset X . Mathematically, t 1  X  t 2  X  X  I ( t 1 )  X  X | = | I ( t Hence, for an itemset X , the number of equivalence classes is |
X | + 1. The equivalence class for transactions containing i items from X is denoted as E X i . In a general context, the superscript X may be omitted.
 Example 2. Consider following transactional database: Let X = bc . Here, we have three equivalence classes, viz, E 0 = {} , E X 1 = { 1 , 3 } ,and E X 2 = { 2 , 4 } .
Definition 9. E X iset . Two transactions are E X iset equivalent if they contain same set of items from itemset X .Mathe-matically, t 1  X  t 2  X  I ( t 1 )  X  X = I ( t 2 )  X  X . Hence, for an itemset X , the number of equivalence classes is 2 | X | .The equivalence class for transactions containing itemset Y but not X \ Y is denoted as E X Y .
 Example 3. Consider the database in Example 2. Let X = bc . Here, we have four equivalence classes, viz., E X {} , E X b = { 3 } , E X c = { 1 } ,and E X bc = { 2 , 4 } .
For enumeration purpose, we can ignore equivalence classes with zero cardinality. Hence, the number of variables is up-per bounded by the number of transactions. The current best algorithm for extracting E X num takes O ( | X | 2 + S ( X )) iterations [12], and that for extracting E X iset takes O ( 2 | X | + S ( X )) iterations [5], where S ( X )isthenumberof iterations to calculate the exact support of X .Hence,ex-tracting E X num is more efficient than extracting E X iset
The objective of this module is to derive a function which can bound the search space of FTFIs. Given an itemset X , this function f ( X ) must never underestimate the sup-port of X or any of its supersets. Mathematically, f ( X ) max Y  X  X sup FT ( Y ). In order to derive f ( X ), we first an-alyze the characteristics of sup FT ( X ) with individual re-laxation criterion. The fact that sup FT ( X )withanycon-stant error relaxation is anti-monotone has been proved in [11], while sup FT ( X ) with proportional pattern relaxation and transaction relaxation are not anti-monotone have been sketched in [16] and [9]. These findings are summarized in Table 2. We now show that sup FT ( X ) with only propor-tional item relaxation is also anti-monotone.

Lemma 1. sup FT ( X,  X  t =1 , 0 &lt; X  i &lt; 1 , X  p =1) is anti-monotone.

Proof. Consider P = Y  X  X satisfying the item relax-ation. In other words, all items in X are contained by at least  X  i  X | Y | transactions, and sup FT ( X )= | Y | .Sinceeach item is independent of the other, then  X  Z  X  X, sup FT ( Z ) |
Y | .

When several relaxation crite ria are combined, the anti-monotonic property of FT-support can be derived as follows.
Lemma 2. When 0 &lt; X  t &lt; 1 or 0 &lt; X  p &lt; 1 , sup FT anti-monotone.
 Proof. Suppose sup FT ( X ) &lt; X  .Thatis,thereisno P = Y  X  X ,with | Y | X   X  , which satisfies all relaxation cri-teria. Now, assume that there exists P 1 = Y 1  X  X ,where |
Y 1 | X   X  , such that Y 1  X  X satisfies item relaxation. In the pessimistic case, it is possible to extend X into X ,such that Y 1 contains all transactions in X \ X ,and | X | is large enough such that Y 1  X  X satisfies all relaxation criteria. Therefore, sup FT ( X )  X   X  , implying that it is not anti-monotone.

Lemma 2 states that we cannot construct an anti-monotone function by using either proportional transaction or pattern relaxations. So, consider a function f o ( X )= sup FT ( X,  X  1 , X  i , X  p =1). Itisclearthat f o ( X ) never underestimates sup FT ( X ) since it uses lesser constraints. Moreover, f is also less constraining compared to sup FT (  X  X ) for all X , since every pattern containing any superset of X im-poses the same item relaxation. Hence, f o can be used as a bounding-function. This function is indeed the best (low-est) possible, assuming we only have knowledge of itemset X , i.e., we ignore all items not within X .

Lemma 3. By considering only items x  X  X , f o ( X )= sup FT ( X,  X  t =1 , X  i , X  p =1) is an optimal upper bound for sup FT ( X ) .

Proof. Since we cannot use either transaction or pattern relaxation (Lemma 2), we can only use item relaxation.
However, the computation of f o ( X )isanNP-Complete problem, as we shall explain in Section 4.3. Therefore a natural approach is to design an approximate function that may be computed efficiently. One simple way to achieve this is by loosening item relaxation with pattern relaxation. It is clear that patterns satisfying item relaxation (  X  i will also satisfy pattern relaxation with the same tolerance (  X  p = e ). A similar technique was used in [16] to loosen transaction relaxation with pattern relaxation. Mathemati-cally, we define f a ( X )= sup FT ( X,  X  t =1 , X  i =1 , X 
Example 4. Let  X  t =0 . 3,  X  i =0 . 2, and  X  p =0 . 1. f a the FT-support of itemset X with parameters  X  t =1,  X  i =1, and  X  p =0 . 2. f a ( X ) is a valid bounding function since it never underes-timates f o ( X ), which is also a valid bounding function. We show in Section 4.3, that by having E X num (Section 4.1), we can calculate f a ( X )in O ( | X | ) time complexity. This weaker bound, indeed, is the best possible if we know only E X num
Lemma 4. Having only E X num , f a ( X ) is an optimal upper bound for f o ( X ) .
Proof. Based on the proof of Lemma 3, we can impose only item relaxation to form a bounding function. Since we know only the number of items contained by each transac-tion, the worst case is to assume that the missing items are distributed uniformly among the transactions. In this case, all items are missed by the same number of transactions, hence item relaxation is equivalent to pattern relaxation.
Liu et al. proposed another upper bound in [9]. Ana-lyzing the derivation, we find that their approach calculates the FT-support assuming all transactions either contain all items or contain k + 1 items, where k =  X  t  X | X | ,and the missing items are uniformly distributed. This bound is clearly weaker (higher) than f a .
Previously, we showed that f o ( X ) is optimal, having only the knowledge of itemset X . Here, we show that if we know m -the largest desired size of FTFIs, then we can further tighten the bound, as illustrated in Figure 1(b). When the largest desired FTFI is of size | X 2 | , the bound can be tight-ened (shown by dashed lines in the figure), and when we don X  X  need FTFIs bigger than | X 1 | , X 1  X  X 2 , the tight-ening can be potentially stronger. Note that our approach guarantees completeness of the results if the size of the true largest FTFI is no larger than m . In practice, even if we want to mine all FTFIs, we can safely set m to be as large as 30 to 40 (or much lower in sparse datasets).

The idea is to utilize transaction and pattern relaxation, which were omitted in f o ( X )and f a ( X ). We first discuss how to handle transaction relaxation. Since the largest FTFI is of size m , then the number of errors allowed in all FT-FIs is at most  X  t  X  m . Therefore, by setting the transaction relaxation as a constant value  X  c t =  X  t  X  m , we will never un-derestimate the support, which constitutes a valid bounding function.

Next, we discuss how to get ri d of proportional pattern relaxation. The idea is still the same as in transaction re-laxation, by calculating the maximum (constant) allowed errors of all FTFIs. However, the absolute value of pattern relaxation also depends upon the size of the transaction-set. The easiest way to achieve this is by using another upper bound for the maximum transaction-set size, e.g., |
T | . Hence, the whole matrix is allowed to have up to  X  p =  X  p  X | T | X  m errors. Despite being valid, this bound is very loose. A tighter bound is derived as follows. For a pattern Y  X  X , the maximum total number of errors is re-stricted to be at most  X  p  X | X | X | Y | .Since | X | X  m ,the total number of allowed errors in all FTFIs is less than (  X  p  X  m )  X | Y | .Let  X  p ( X ) be the pattern relaxation for an itemset X , then the number of errors allowed per pattern is at most  X  p ( X )  X | X | X | Y | =  X  p  X  m  X | Y | .Hence,wehave  X 
We can then define f o ( X )= sup FT ( X,  X  c t =  X  t , X  i  X  ( X )), where  X  t =  X  t  X  m and  X  p ( X )=  X  p  X  m | X | . As before, we can approximate item relaxation with pattern relaxation for faster computation. In this case,  X  i becomes 1 (unused), and  X  p becomes the minimum of  X  i and  X  p .

Example 5. Let  X  t =0 . 3,  X  i =0 . 2,  X  p =0 . 1, m =8and |
X | = 5. Here, we have  X  t = 0 . 3  X  8 =2,and  X  p ( X )=0 . 1 =0 . 16. In this case, f o ( X ) is the FT-support of itemset X with parameters  X  c t =2,  X  i =0 . 2, and  X  p =0 . 16. To approximate f o ( X ), we use  X  i =1and  X  p =min(0 . 2 , 0 . 16).
This section presents how to calculate the FT-support of an itemset efficiently. Prior to designing the algorithm, we analyze the impact of each constraint on the complexity of the support counting procedure. This result is summarized in Table 2. When only transaction relaxation is considered, the FT-support is simply the number of all transactions in the pattern that satisfies transaction relaxation. When only pattern relaxation is considered, we can use a greedy algo-rithm, by repeatedly taking transactions with least number of errors, until the constraint is violated [16, 11, 14]. Hav-ing E X num , these two functions can be calculated in O ( iterations. When item relaxation is imposed, E X num is not sufficient, since we need to know the errors contained by spe-cific items. This fact indicates the difficulty (NP-Complete) of this problem, which has formally been proved in [11] for the case with constant relaxation.

Though we analyze each relaxation criterion individually, it turns out that there is a very nice property for combining several criteria as follows:
Property 5. The complexity of computing FT-support using the combination of several relaxation criteria equals to the maximum complexity when using individual criterion.
Here, we discuss how to handle the difficult problem of support counting with item relaxation, and consequently the general support counting problem.
Poernomo and Gopalkrishnan [11] show that the support counting problem can be translated into an integer linear programming (ILP) problem, where the variables represent the equivalence classes ( | E X iset | ), and the number of con-straints equals the number of items ( | X | ).

The reduction is as follows. Let sup FT ( X ) correspond to the pattern P = Y  X  X satisfies all relaxation criteria, and | Y | = sup FT ( X ). Let V = { v X 1 ,v X 2 , ... } of variables, where v X i  X  V corresponds to the number of transactions in Y from equivalence class E X i (Section 4.1). For each item a  X  X , we add one constraint (inequality) ciated with class E X i do not contain item a ,and a X i =0 otherwise. The value of variables v X i must be between 0 and | E
X i | , and the objective function is to maximize the total number of transactions, which can be written as X i v X i
Example 6. Let the itemset be ab .Focusingonitem a , we see that the number of transactions not containing item a is at most  X  c i (c.f. Section 3). This number is specified by the sum of variables, associated with equivalence classes that do not contain item a , which in this case are E  X  and E . Hence, we have one inequality v  X  + v b  X   X  c i . Similarly, for item b ,wehave v  X  + v a  X   X  c i . Since the goal is to find the maximum sized transaction-sets, the objective function translates to maximizing the sum of all variables, which is v + v a + v b + v ab .

In the worst case, the size of this LP (number of con-straints  X  number of variables) is | X | X  min(2 | X | , | is quite large even for moderate sizes of X (around 20). How-ever, transactions lacking more than  X  c t (or  X  t  X | X | can be ignored, and hence the number of variables reduces number of variables equals 1,351, which is small for an ILP.
The ILP procedure was optimized in [11] based on a prop-erty of equivalence classes.

Property 6. For two equivalence classes E X X where X 1  X  X 2 , it is always better to choose X 2 instead of X . Mathematically, X 1  X  X 2  X  v X 2 = | E X X 2 | X  v X 1 =0 .
Here, we further exploit this property to reduce the num-ber of variables of ILP.

Lemma 7. When considering item relaxation, taking trans-actions that lack at most one item always leads to the max-imum size | Y | that satisfies all relaxation criteria.
Proof. The optimality is trivial for transactions that lack no item, since their coefficients in LP are always 0. Next, transactions lacking one item, say, item a , appear only in the inequality with respect to item a . Hence, this trans-action only constrains other transactions that lack itemset X  X  X  a } . Based on Property 6, it is always better to take transactions lacking one item.

Example 7. Let X = abc . Here, v bc presents only in in-equality with respect to item a . In that inequality, we also have v b , v c ,and v  X  , but all are subsets of bc .Hence,trans-actions that contain itemset bc are always preferable.
From Lemma 7, we can pre-process variables associated with transactions lacking at most one item, to reduce the number of variables for LP. Moreover, if the number of trans-actions containing such an item is greater than  X  i , the error tolerance with respect to the corresponding item is satu-rated. Hence, we can remove all variables corresponding to transactions that miss such an item. Observe that this property does not hold for transactions lacking two or more items.

Example 8. Continuing Example 6, let  X  c i =10and | E b | 20. We know from Lemma 7, taking these transactions leads to the optimal choice. Hence, we can take as many as pos-sible, by setting v b = 10. When v b = 10, the first inequality (w.r.t. item a ) is saturated. Hence, we cannot take any more transactions that lack item a , i.e., v X i =0 ,  X  a
When item relaxation is defined as proportional, the prob-lem can also be modeled as an ILP, by adding an extra fac-tor,  X  i , in the coefficients.
 Example 9. Continuing Example 6, we have:
However, this change affects the efficiency significantly, since no pre-processing can be done. In other words, we do not know how many transactions can we take for each itemset missing one item. Here, we propose to transform the constraint into a constant value, so that we can use the previous technique.

Let s be achievable if there is a transaction-set Y of size s which satisfies the relaxation criteria, and let h ( s )= sup ( X,  X  c t =  X  t  X | X | , X  c i =  X  i  X  s,  X  c p =  X  p  X | X
Algorithm 2 : Iterative method to compute support (prop. relaxation) using support (const. relaxation) Input :itemset X ,  X  t ,  X  i ,  X  p
Output : FT-support s  X  UB // set s as the upper bound 1 while true do 2 Lemma 8. s is achievable if and only if s  X  h ( s ) .
Proof. First, observe that h ( s ) is monotone to s ,since greater s allows more errors, implying greater h ( s ). Now let the absolute number of errors in a pattern P = Y  X  X ,when |
Y | = s (in any criteria) be e .If h ( s ) &lt;s ,itmeansthat the size of the largest transaction-set that allows e errors is lesser than s .Hence, s is not achievable .When h ( s )  X  we can use the respective transaction to form h ( s )asthe transaction-set Y .Hence, s is achievable .
 Lemma 9. sup FT ( X )=max( s | s = h ( s )) .

Proof. If h ( s ) &gt;s ,thereisalways s o  X  h ( s ), such that s = h ( s o ). Otherwise, we can set s 2 as h ( s ), and recalculate h ( s 2 ). This cannot be done indefinitely since the domain is finite (they represent support of itemset). Therefore, the largest achievable s is always when s = h ( s ).

One intuitive approach to find the largest s where s = h ( s ), is to perform binary search on s . However, even though h ( s ) is monotone to s , s  X  h ( s ) is neither monotone nor anti-monotone, hence ruling out binary search. Here we propose to use an iterative method as presented in Algorithm 2.
First, we initialize s as the upper bound of the FT-support (line 1). One easy and reasonably good approach is by re-laxing item relaxation with pattern relaxation, hence UB = sup FT ( X,  X  t , X  i =1 , min(  X  p , X  i )). Having obtained the up-per bound of s , we iteratively verify whether s is achievable (line 4). If it is, then we have obtained the result, other-wise, we lower down the estimation. The correctness of this algorithm is proved as follows.
 Lemma 10. Algorithm 2 produces a correct result.

Proof. Since s is the upper bound, if s = s ,then s is the largest value which is achievable , implying s is the FT-support (line 5). Otherwise, if s &lt;s , then the FT-support must be less than or equal to s ,since s is monotone to s .

Next, we analyze the number of iterations with respect to item relaxation. Let the initial s = a and h ( s )= b .Onaver-age, (constant) item relaxation is reduced by 1 whenever s is reduced by 1 / X  i . Also, whenever constant item relaxation is reduced by 1, h ( s ) is reduced by at most  X  = (1  X   X  t ) by removing one transaction per item. Let  X  / (1 / X  i )= X  be denoted as  X  . Since the amount of first reduction of s is a  X  b = d , then the second reduction would be at most d  X   X  , and the following reductions would geometrically progress as d  X   X  2 , d  X   X  3 , etc. Since the algorithm terminates when the reduction equals 0, the approximated upper bound of the number of iterations (ignoring floor and ceilings) is given as O (  X  log  X  ( d )), where d  X  UB  X  sup FT ( X ).

For example, when | X | =5, d =1 , 000,  X  t =1and  X  =0 . 1, we have  X  =0 . 5, implying that the number of iterations would be approximately  X  log 0 . 5 (1000)  X  10. In our experiments (Section 5), we show that in practice the number of iterations is very small, and more importantly the algorithm is efficient.
Let N cb and N cf be the number of candidates border and candidates frequent respectively; T ie be the overall time taken for iterating the itemsets; T num (or T iset ), T b the time taken for extracting the equivalence classes of each itemset, bound checking, and support counting respectively.
Then, with optimal bound-checking, or using E iset ,the overall time needed is given as:
As mentioned in Section 4.2, it might be better to use approximate bound-checking, in which case the complexity becomes: With optimal bound-checking, E iset is extracted N cb times. While with the approximate bound, E iset is calculated N cf times (lesser), but there X  X  an additional cost of extracting E num N cb times, and possibly larger N cb and N cf due to looser bounds. As both techniques have their own advan-tages and disadvantages, we compare their efficiency using empirical evaluation.
We evaluated the algorithms using three real-world datasets, viz., Retail [3], Mushroom, and Chess, available from the FIMI website 1 . Some characteristics of the datasets are pre-sented in Table 3. In brief, Retail is very sparse, Chess is very dense, and Mushroom is somewhere in the middle. Un-less stated otherwise, the experiments are run with default parameters as presented in Table 3. To solve the ILP prob-lem, we used the LPSolve package that is available from SourceForge 2 . All implementations are done using C++, andallexperimentsarerunonanIntelCore2,2.22GHz machine, with 3GB main memory. In several figures, some plots are missing, either because the execution fails to ter-minate, or takes longer than one hour.
As mentioned in Section 4.3, for support counting with constant relaxation, we propose to pre-process by taking itemsets lacking one item (or none) prior to solving the ILP. Figure 2 compares the efficiency of the algorithm with pre-processing ( PP )andwithout( noPP ) pre-processing. For evaluation, we calculate the time for support counting, for all frequent itemsets (not fault-tolerant) with the given min-imum support threshold. The value of  X  c p is set to | X | X  and  X  c t is infinity. http://fimi.cs.helsinki.fi/data/ http://lpsolve.sourceforge.net/5.5/
Figure 2: Effect of pre-processing on efficiency
We see that pre-processing is always faster, so for the re-maining procedures, we always use pre-processing. In the sparse dataset, the algorithm using pre-processing executes almost instantaneously, since the exact support can be de-termined directly after pre-processing. In the dense dataset, the efficiency is proportional to  X  i . A possible explanation is that, when  X  i is lower, the LP is more constrained, and hence the optimization becomes more efficient.

Next, we compare the efficiency of support counting with proportional relaxation, between directly converting the prob-lem to ILP and using the iterative approach which reduces to constant tolerance (Algorithm 2). The former is denoted as ILP-Prop and the latter as Iterative . Here,  X  p is fixed as half of  X  i ,and  X  t = 1, and the results are shown in Figure 3.
We again see a consistent pattern, with the numerical ap-proach always running faster. This is perhaps due to the small number of iterations. In the Chess dataset, the maxi-mum number of iterations is 5, with average of slightly above 1. In the Retail dataset, the maximum number of iterations reaches 30, but the average is still lesser than 2.
This section analyzes the efficiency and effectiveness of the bound-checking procedure, using the default values specified in Table 3. As mentioned in Section 4.2, we can either calcu-late the optimal bound or perform approximation. The re-sults are plotted in Figure 4, and a detailed snapshot for one particular minimum support is presented in Table 4, with notations as given in Section 4.4. It is clear from the table that by approximating the bound, the number of candidates only increases a little, but the time for bound-checking de-creases significantly. Hence, it is beneficial to use the relaxed bound, i.e., E num .

Regarding the effectiveness of the bound, we can see that the number of itemsets within borders is around 2.5 times, 1.6 times, and 1.5 times the numbers of FTFIs in Retail, Mushroom, and Chess datasets respectively. While ideally the number of candidates frequent should be similar to the number of FTFIs, these numbers are, in our opinion, quite reasonable.

Next,weanalyzetheimpactof m , the desired maximum size of FTFIs, as shown in Figure 5. Sizes of the actual largest FTFI s for Retail, Mushroom, and Chess datasets are 6, 13, and 14 respectively, and hence we mine complete results in all cases. We observe that the efficiency is insen-sitive to m .
Here we analyze the impact of each relaxation criteria, with respect to the number of FTFIs and time taken by the mining algorithm. Since some applications require only maximal itemsets, we also show the plots for maximal item-sets, which we mine using depth-first traversal. Because of space limitations, we only demonstrate using the Mushroom dataset, where the difference between all and maximal item-sets is most noticeable.

Figure 6 shows the scalability with respect to minimum support and error tolerances. Here, we can see a consis-tent pattern that the number of FTFIs is quite insensitive to  X  i and  X  t . This is good news for analysts since we can simply pick any natural value of  X  i and  X  t , and need only to tune  X  and  X  p . Nonetheless, the difference compared to min-ing without error tolerance is quite significant. This shows that FTFIs can capture interesting knowledge which remain undiscovered using strict frequent itemsets. This paper tackles the problem of completely mining FT-FIs with proportional relaxation. While this problem has been mentioned previously, we note that no decent solution has been proposed earlier. Our algorithmic contributions are mainly on the bound-checking and support-counting proce-dure. We empirically show that our algorithms are feasible for mining in real-world datasets within a reasonable time. This development can assist problems that analyze FTFIs, which have been struggling in the absence of efficient algo-rithms. One concern for applying FTFIs for data analysis is regarding the abundance of parameters. In our experi-ments, we show the sensitivity of results with respect to tol-erance parameters, which hopefully can guide data analysts to choose the proper value of tolerance.

For future work, we would like to further improve the effi-ciency of the algorithm. For the bound checking procedure, we restrict our bounding function with items in the current itemset. It would be better if we can exploit the knowledge of other items as well. For the support counting procedure, we would also like to design an efficient algorithm, instead of using the generic integer linear programming technique.
Though we have provided sensitivity analysis with respect to tolerance parameters, end-users would still be burdened for setting the parameters. It would be ideal if those param-eters can be intelligently and automatically set, given the database.

One limitation of frequent itemsets based techniques is that they generate abundant results, resulting in difficult analysis. While significant progress has been made on sum-marizing frequent itemsets, there is no work yet on summa-rizing fault-tolerant frequent itemsets. As FTFIs can dis-cover broader knowledge than frequent itemsets, we consider this problem as an interesting and important future direc-tion as well. [1] R. Agrawal and R. Srikant. Fast algorithms for mining [2] J. Besson, R. G. Pensa, C. Robardet, and J.-F.
FTFI optimal vs. approximate (c) | FTFI | w.r.t.  X  t (g) | FTFI | w.r.t.  X  p [3] T. Brijs, G. Swinnen, K. Vanhoof, and G. Wets. Using [4] T. Calders and B. Goethals. Depth-first non-derivable [5] T. Calders and B. Goethals. Quick inclusion-exclusion. [6] H. Cheng, P. S. Yu, and J. Han. Approximate frequent [7] R. Gupta, G. Fang, B. Field, M. Steinbach, and [8] J. Li, K. Sim, G. Liu, and L. Wong. Maximal [9] J. Liu, S. Paulsen, X. Sun, W. Wang, A. B. Nobel, [10] J. Pei, A. K. H. Tung, and J. Han. Fault-tolerant [11] A. K. Poernomo and V. Gopalkrishnan. Mining [12] A. K. Poernomo and V. Gopalkrishnan. Efficient [13] J. K. Sepp  X  anen. Using and Extending Itemsets in Data [14] J. K. Sepp  X  anen and H. Mannila. Dense itemsets. In [15] K. Sim, J. Li, V. Gopalkrishnan, and G. Liu. Mining [16] C.Yang,U.M.Fayyad,andP.S.Bradley.Efficient [17] M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li.
