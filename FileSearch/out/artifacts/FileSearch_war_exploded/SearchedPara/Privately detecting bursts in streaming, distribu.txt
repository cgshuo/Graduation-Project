 1. Introduction Streaming time series data is prevalent in many domains including financial, medical, network and military applications. We are interested in identifying peaks and valleys (bi-directional bursts) across data streams owned by independent parties.
We have two constraints: communication cost and privacy. Because the data is distributed and streaming, it is costly to com-municate all the raw data necessary to find bursts. Second, because of privacy concerns, the parties cannot share the raw data munication and as much privacy as possible.

Examples of distributed time series applications include customer sales, e.g. credit card transactions across independent entities, trade surveillance for security fraud across independent exchanges, network packet data of different companies, and military tactical surveillance of troops or equipment. These parties may be interested in finding bursts from a combined data set, but have privacy concerns or legal constraints that prevent the sharing of raw data. In order to find these  X  X ggregate bursts X , the data needs to be combined by sharing a perturbed version of the original data. We refer to this general problem as privacy-preserving aggregate burst detection [36].

Let X  X  look at a detailed example. Credit card companies maintain a network that their retail partners and banks have ac-cess to. Suppose multiple credit card companies wanted to identify peaks and valleys in credit card activity at the customer level, the merchant level, or even in a specific geographical region level. Questions of interest may include: Is there a large spike in customer purchases across different bank cards? Can we verify fraudulent behavior by identifying bursts across the credit, retail and banking network? Because each company maintains its data independently, the data must be merged to detect bursts across these independent entities. Then these companies will have insight into burst behavior of individual customers, individual merchants, individual banks, etc., during specific periods of time. It also allows these credit card com-panies to take the information and see how the burst behavior of their individual data compares to the aggregate burst behavior. However, because of legal privacy regulations, sharing the raw data stream may not be an option. In those cases, bursts need to be detected using an approximation of the raw data.

Fig. 1 shows a small example with three participants. Each participant (P1,P2,P3) has a time series containing nine time points of data. Without sharing their raw individual data, the participants are interested in determining whether or not a burst exists in the combined data. In Fig. 1 , the top time series is the combined sum or  X  X ggregated X  data. A burst can be seen in the aggregate time series beginning at time point 2 and ending at time point 5. In this figure, we show the data values of each participant and the aggregate time series so the summation of participant data is clear.

Privacy preservation in the context of streaming data has received limited attention [15]. Work by Li et al. uses random perturbations to hide raw data while maintaining correlation information. Our work differs in two critical ways. First, we are focusing on distributed streams that need to be merged. Second, random perturbation as presented in [15] is not an option because of the affect on burst detection accuracy and the associated overhead of communicating the entire perturbed data stream in a distributed environment. Instead, our goal is to find a condensed representation from which participants can identify the aggregate bursts without compromising any participant X  X  original data.

In this paper, we introduce a new approach that involves computing the wavelet transform of each data stream window and then calculating a summation vector that is then combined with data from other participants. The individual participant summation vector is a condensed approximation of a segment of the original stream from which the original stream values are difficult to reconstruct. After data is combined, bursts of varying width within a window are detected directly from an aggre-gated  X  X istance X  vector. Our online privacy-preserving burst detection algorithm obscures raw data values and the shape or envelope of the time series, hides bursts of individual participants, reduces communication costs to logarithmic with respect
The contributions of this paper are as follows. First, we consider burst detection in the context of a streaming environ-ment with limits on processing time, communication cost, and buffer space. Next, we formalize two types of privacy breaches, including a breach that has not been previously studied in this context (envelope breach), and quantify the discrep-ancy between the original stream, the adversary X  X  approximate stream, and the participants X  individual vectors (stream approximations). We also analyze privacy limits, bounding the level of privacy preserved at different points in the algorithm.
Third, we extend the analysis of our previous work for the streaming environment and an envelope breach. Fourth, we intro-duce a new algorithm that identifies bursts accurately using a small summation vector of potentially large segments of the data stream. Our data aggregation strategy is also a new contribution; here, we use bursty, self-eliminating noise to obscure the bursts of individual participants. Previous work on similar time series problems use a round robin protocol for secure summation  X  a costly operation in a streaming environment [31,36] .

The remainder of this paper is as follows. We begin by reviewing some related literature in Section 2. We then formalize the problem and notation in Section 3. Section 4 details the components of the algorithm for burst detection and studies privacy preservation within its context. In Section 5, we empirically demonstrate the approach using both real and synthetic data sets. Finally, conclusions and future directions are presented in Section 6.
 2. Related literature
We have separated the related literature into four sections: privacy preservation literature, extensions to previous work, statistical databases and burst detection. 2.1. Privacy preservation literature
Much work in the area of privacy-preserving data mining has surfaced. Some work has investigated privacy preservation within the context of traditional data mining problems, e.g. classification [2,41] , association rule mining [14,20] , sensitive pattern mining [45,43] , clustering [24,40,19] , and regression analysis [21]. Some of this work applies random noise to the data and releases the perturbed, noisy data. With this perturbed data, the distribution of the noise is also released. This al-lows the data user to determine the distribution of the original data without determining the actual individual data values.
The focus of our approach is using a compressed representation of linear transforms. While we do add bursty noise when aggregating the distributed data, this noise is self-eliminating. While random noise is a good option for some data mining tasks, its use has a large impact on the results of burst detection. k -Anonymity was introduced for privacy preservation of independent, unlinked data records. The idea is that each tuple should not be distinguishable from k 1 other tuples [37]. Two approaches for accomplishing this are generalization and suppression. This approach has been used in the context of clustering, classification, and association rule mining [6,16,29] . k -Anonymity is not applied to our burst detection problem because k -anonymity attempts to  X  X ide X  outliers. In con-trast, our goal is to identify bursts in the context of streaming time series data. Using generalization could have a large im-pact on accurately identifying a burst. For example, if a burst is an outlier, then k 1 other bursts need to be created to hide then a false negative will occur.

Some privacy preservation work exists on horizontally partitioned data sets [20,27,19] . However, none of those have been applied to the problem of burst detection. Liu et al. propose an adaptive perturbation model that lets the user select a desired privacy level [25]. For a survey of current approaches and tools for privacy preservation in data mining, we refer you to Clif-ton et al. [11] and Verykios et al. [42].

Li et al. investigate privacy preservation in the context of streaming data [15]. As previously mentioned, that paper fo-cuses on maintaining the correlation and auto-correlation statistics of the data stream while hiding the raw data stream.
They accomplish this by inserting random perturbations that mirror certain statistics of each window of data. While bursts could be detected from the final privacy-preserving stream, the size of the perturbed data is the same as the original stream.
When aggregating streaming data in a distributed environment, a compressed data format will reduce communication costs considerably. Moreover, for our problem, maintaining correlation and auto-correlation statistics would be extra information that we want to keep private. There is also work on trust based privacy preservation in peer to peer multimedia streaming systems [26]. 2.2. Statistical databases
A great deal of work in the area of statistical databases focuses on providing statistics about data without compromising individual data values. There have been a number of data perturbation strategies used including swapping values [13], add-ing noise [39], and data partitioning [32]. While all these ideas are relevant to burst detection, they differ because these works attempt to minimize the total error of the query result while blocking inference channels to sensitive data. In our case, we are only concerned with the error associated with bursts in the stream. As long as the remaining data does not indicate a false burst, we are not concerned about the total error of the data stream. Instead, we want to introduce as much bias or error as possible to improve the level of privacy without decreasing the accuracy of the burst detection procedure. For a more de-tailed analysis of statistical databases, we refer you to Adam and Worthmann [1]. 2.3. Extension of previous work
This paper is an extension of the work presented in [31,36] . First, neither of those papers formalize the privacy breaches or bound the level of privacy within the proposed algorithms. Further, both of those papers consider only data privacy breaches in a non-streaming environment. In [31], a heuristic that employs windowing and scaled binning is introduced for time series data. Scaled binning computes a representative value for each window, e.g. a mean or median, and replaces each representative value with a new scaled bin value based on the distance between the mean of the time series and each representative value. This approach has similarity to Li et al. X  s work that partitions the data using a kd-tree and then per-turbs each partition using the average value [23]. While the accuracy was reasonable, false positives could occur if each par-ticipant X  X  time series distribution varied significantly.

To reduce the false positive problem that sometimes occurred using scaled binning, we consider detecting bursts from linear transforms of the original stream. In [36], we securely sum individual participant coefficients of different linear detection accuracy with wavelets achieving the highest burst detection accuracy. (This is another reason we focus on using of the transmitted participant data equals the size of the participant X  X  time series. In a streaming environment, that may be a prohibitive cost. We need to find a representation of the data which is smaller than the original data and still leads to accu-rate burst detection results. Unfortunately, if the number of coefficients maintained for aggregation is reduced (referred to as percentage thresholding), the burst detection accuracy will decrease [36]. The algorithm proposed in this paper extends our previous work. It is more  X  X rivate X  than either of the previous off-line algorithms, it can be used without envelope breaches occurring, and it reduces the amount of data that needs to be communicated to logarithmic in the size of the data stream while maintaining a high burst detection accuracy.

Another extension in this paper involves the way data is communicated. Both Sayal and Singh [31] and Singh and Sayal [36] used secure summation [46] to privately combine each participant X  X  local data. This is a standard approach for many privacy preservation problems on horizontally partitioned data [20,27] . In this paper, we propose adding self-eliminating noise with a large number of bursts to the individual participant distance function values prior to aggregation. Because the noise cancels out once aggregation is complete, it serves as a data obscuring tool similar to secure multi-party compu-tation, but has a smaller communication overhead. The idea of self-eliminating noise has roots in that of private information retrieval. There, the user query is kept private by sending a string that contains more than the query result and using linear summations to answer the user X  X  query [10]. 2.4. Burst detection
While burst detection has been studied extensively [4,12,33,30,44,47] , our work differs from this traditional burst detec-tion literature since we make adjustments for maintaining privacy during data aggregation within a distributed environ-ment. Similar to some burst detection work, we will use wavelet transformations [4,47] . In both Bailey et al. [4] and Zhu and Shasha [47], the data is in one central location, not distributed. Our incorporation of summation vectors based on wave-let coefficients is also another important extension for the privacy constraint in the problem and is new to the best of our knowledge.

Burst detection can be viewed as a special type of anomaly detection or outlier detection. Anomalies and outliers are a set of points that are substantially different from remaining data. Anomalies and outliers can be associated with categorical or numeric data. With numeric data, a statistical test is applied to determine whether or not each point is an anomaly. In this work, we define a burst based on a statistical test similar to the anomaly detection literature. This paper does not focus on the statistical test. Rather, we focus on identifying these anomalies or more specifically,  X  X ursts X  in the context of keeping individual participant data private. We refer you to Tan et al. [38] for an overview of anomaly detection algorithms. 3. Problem formulation and notation
This section presents definitions, terminology, and notation. It concludes with a more formal statement of the problem investigated in the paper. Because there are a number of different notations that have been introduced for distributed and streaming time series data, we formally present notation we will use throughout this paper. For convenience, Table 1 also contains a summary of this notation. Our representation of streaming data is based on those presented in [15,28] . 3.1. Streaming data characteristics and notation
Each input stream contains items e 1 ; e 2 ; ... ; e N arriving sequentially and describing an underlying signal E that can be viewed as a vector E or as a one-dimensional function E :  X  1 ... N ! R . Here, each e
The distributed data can be horizontally or vertically partitioned. This paper focuses on a horizontal partitioning of the data, where each participant has the same time series variable for a disjoint set of data. For example, suppose two agencies have weather data at different locations in the country, e.g. minute by minute temperature data. Each agency records values for the same attribute or variable during a specified time period, but the actual data is distinct and non-overlapping.
In our distributed environment there are P participants each having an individual stream vector E . We denote the i th par-
Notice that in this formulation, each participant has a single stream. We can easily generalize this so that each participant has multiple streams that are locally combined prior to aggregation with other participants. Extensions for multiple, possibly correlated streams that are shared from each participant are described in future work.

Definition 1. We define the aggregate stream , A , to be a one-dimensional stream vector that represents the combined stream of all P participants, where the combined stream is the sum of the participant streams. Formally, A  X 
In the simplest case, creating the aggregate stream requires communicating each participant X  X  stream to a central loca-tion. The time needed to send a participant X  X  stream is the participant X  X  communication cost . While communicating each par-ticipant X  X  stream will make the burst detection straightforward, the data is not as private as sending a perturbed representation of the data and the communication cost is higher than sending a compressed representation of the data.
Therefore, in the next section, we will investigate approaches that consider perturbed, compressed representations of the original participant streams.

Because streams are long and continuous, we analyze them in equal size chunks or windows . A stream of length N con-tains x windows with n  X  N x elements in each window. The window size n is also the same for all participants and the time intervals are aligned across participant sites. 1 We denote the k th window of participant i as E aggregate stream as A k . From the aggregated stream we are interested in identifying periods of large fluctuations or bursts .
Definition 2. A burst, B , is a subset of a stream A having a magnitude that deviates significantly from the average magnitude of previous windows of a stream. Formally, Here, b i is the first item in the burst, b j is the last item in the burst, l deviation.

In this context, the number of items in B is defined as j i . It represents the width of the burst and is less than or equal to n , the size of each window. Also, observe that i and j can be equal, so a burst can contain a single item. We denote a burst in the k th window as B k . Typically, a burst is characterized by a small subset of the stream relative to the entire stream, but since different parties may be interested in different granularities of bursts, we want to consider approaches that detect bursts at multiple resolutions or varying widths when the maximum width of interest is pre-specified to be the size of the window. Notice that we do not constrain the length of the window. A longer window allows for a larger degree of varying burst widths to be detected. In fact, we will show that the communication cost savings of our algorithm increases signifi-cantly as the window length increases. Finally, if two participants have a shifted time series, our approach does not make adjustments for this phase mismatch. We assume that accurately mapping time and magnitude data is important. 3.2. Data privacy measurements
Similar to Li et al. [15], we define R i to be a random stream of noise. This noise is added to each element of a participant X  X  data stream, E i . The perturbed data stream then becomes E
However, for this paper we will consider two types of noise, noise following a Gaussian distribution and noise that combines a noise time series generated using a Gaussian distribution and one that contains a large number of bursts of random mag-nitude, duration and position. We refer to this second type of noise as bursty, Gaussian noise . For the bursty, Gaussian noise, the magnitude is based on a uniform distribution within a given range  X  x ; x  X  . The duration and position are determined using an exponential distribution. This distribution provides the interarrival time of each burst in the signal. We take the two signals and add the signals at each data point using simple vector addition. By doing this the resulting signal has both the burst and the Gaussian noise.

We also want to be able to measure the distance or discrepancy between any two data streams, X and Y . How far do the two streams deviate from each other? While a number of metrics could be used to calculate this distance, we use Euclidean distance. In one dimension, Euclidean distance and L1 distance reduce to j X Y j and j Y X j , respectively, which are equivalent in one dimension. Formally, we point average this distance to measure discrepancy, D  X  X ; Y  X  X  1 discrepancy is just the standard Euclidean distance between the two streams at every point divided by the number of points.
Given that our focus is on understanding if the distance between two magnitudes over time is small (indicating a strong sim-ilarity in the two streams) or large (indicating possible misidentified bursts), Euclidean distance or L1 distance is sufficient for one-dimensional discrepancy of two numeric streams. If we increase the number of streams in the discrepancy calcula-tion, other statistical discrepancy measures including Mahalanobus (used more with multiple different classes) and Kull-back X  X eibler discrepancy (used to approximate the relative similarity of underlying distributions of variables) may be more appropriate. We leave that extension for future work.

While measuring D  X  E ; E  X  , the discrepancy between the actual stream and the perturbed stream, is useful, it is also impor-tant to consider the approximate stream, e E , predicted by an adversary. Ultimately, our goal is to keep D  X  E ; sible while still accurately detecting bursts.

When considering adversaries, we assume that all participants are semi-honest, i.e. do not exhibit malicious behavior, but database literature [1]. We also assume that general external attacks can typically be handled using secure communication channels. Therefore, we focus on targeted attacks by informed adversaries and participants.

There are two privacy breaches we consider: a data breach and an envelope breach. A data breach occurs if for any par-ticipant i , the participant X  X  individual stream vector E will measure whether a data breach has occurred by considering the discrepancy between a participant X  X  event stream and an adversary X  X  estimated or predicted event stream, D  X  E ;
Definition 3. A data breach occurs when D  X  E ; e E  X  &lt; q
The privacy guarantee is based on the value for q d low . If the adversary can generate a stream that has a lower discrepancy than a noisy version of the original stream, we say a data breach has occurred. We also consider a stronger privacy guarantee based on discrepancies of the original stream and of different noise streams.

Definition 4. We define q d high to be the discrepancy between the data stream and a random noise stream. Formally, d high  X  D  X  E ; R  X  , where random noise vector R has a different mean and distribution than E .
 gaussian stream generated using a different mean and distribution than the original stream. This error is significant. If it oc-curs over a small number of points, then false bursts will be detected. If it occurs over a large number of points, then the overall burst characteristics of the time series will differ.

It can happen that the discrepancy between the original stream and the adversary X  X  reconstructed stream is high, but the shape of the two streams is similar. In other words, the error is distributed evenly across all the points in the stream. Fig. 2 shows an example of three time series with a similar shape. While a significant difference in magnitude may exist at every envelope breach occurs if for any participant i , the shape of the stream vector E envelope breach, which has not been previously studied in this context, is a breach because knowing the shape of a time series exposes trend information and potentially participant burst information.

One way to quantify the similarity between the two streams is to measure their covariance. The covariance will give in-sight about whether the two streams have a similar directional trend. A positive covariance means that the two streams move in the same direction and a negative one means that they move in opposite directions. However, two time series may have the same direction, but not the same shape. Therefore, we use the variance of the discrepancy or difference be-tween the streams to measure the envelope difference, V  X  E ; tween two streams will be some constant value and the variance will be zero. If the two streams do not have the same shape, the magnitudes of the differences will range in value and the variance will be much higher than zero.

Definition 5. An envelope breach occurs when V  X  E ; e E  X  &lt; q
If variance of the envelope difference between E i and e E i is less than q
According to this definition, detecting bursts in the correct window is important. While knowing the existence of a burst may be useful, for many applications, its value is limited if an adversary cannot relate the burst to a single time period or window. For example, a burst in purchasing activity during the holidays may be less unusual than a burst of purchasing activity during another time of the year. Also, recall that we do not constrain the window to be small. Therefore, for larger windows, misalignment will be more problematic because the context of the burst activity will be unclear.
For applications where knowing the correct window is less important, we define an elastic envelope breach to be a similar envelope that may have a small phase misalignment. Therefore, reconstructed streams with a similar envelope and a phase misalignment less than / can lead to a privacy breach.

Definition 6. An elastic envelope breach occurs when V  X  E ;
If an envelope breach occurs and the difference in time, D t is less than / , we say that an elastic envelope breach has taken place. The remainder of this paper will focus on a standard envelop breach, not the elastic envelope breach. We leave extensions for an elastic envelope breaches as future work. Typical techniques that may be useful for this extension include dynamic time warping [7] and longest common subsequence [17]. 3.3. Problem statement
In this paper, we investigate the problem of privacy-preserving aggregate burst detection. We attempt to accurately gen-erate bursts B from aggregated data stream A without adversaries, including P semi-honest participants, determining any participant i  X  X  raw data stream, E i or any participant i  X  X  data envelope. The adversarial attack under investigation occurs when a participant sends data for aggregation. The adversary is interested in determining any participant X  X  individual data stream. In order to measure the accuracy of an adversary X  X  approximate time series obtained during communication, we introduce the ideas of discrepancy and envelop difference. Our goal is to develop a perturbation strategy that maintains a high burst detection accuracy while keeping the discrepancy and envelop difference between the adversary X  X  predicted time series e E and any participant i  X  X  individual time series E more privacy breaches have occurred. 4. Overview of algorithms
At a high level, the proposed algorithm for privacy-preserving aggregate burst detection can be broken down into four major steps: preprocessing (Section 4.1), the participant data level sum calculation (Sections 4.2 and 4.3 ), distributed data aggregation (Section 4.4), and burst detection of aggregated data (Section 4.5). Table 2 presents our high level algorithm and maps the different steps to the subsections that follow. The subsections describe each of these steps in more detail and analyze the level of privacy maintained where appropriate. 4.1. Preprocessing steps
Prior to beginning, one of the participants is designated as the master location or the leader . All of the processes begin and end at that location. The leader begins by sending the participants a number of parameters across a secure channel: date range  X  d  X  , window size  X  n  X  , number of participants  X  P  X  , and number of noise generators  X  G  X  .
The date range identifies the time period of the analysis. This is used to ensure that the data streams are aligned along the time dimension. The window size defines the chunk of data processed at once and also specifies the maximum burst width detected. (Note, a large value is reasonable here since the communication cost is logarithmic in the size of the window.)
Noise generators create bursty random noise for all the participants. The number of participants is used to determine the number of bursty lists that need to be generated by the generators. Participants use the number of generators to ensure they receive the correct number of bursty lists. As a preprocessing step, the generators create the bursty lists and distribute these encrypted lists to each participant. We will describe this in more detail in Section 4.4.
 4.2. Participant linear transformation
A linear transformation uses a function to translate a vector into another vector that is a linear combination of the ori-ginal. When we use a linear transformation of a window containing n elements of the data stream, we are projecting the coordinates of the window into a new n -dimensional space using n orthogonal basis vectors. The new representation of the data gives us an opportunity to highlight different aspects of the time series that may be beneficial for certain applica-tions. Further, because the transforms are linear with orthogonal basis vectors, addition and scalar multiplication are pre-served. The original time series vector can be reconstructed without introducing error by multiplying the coefficients with the basis vectors and summing them up. Two well-known linear transformations are the Discrete Fourier Transform (DFT) and Discrete Wavelet Transforms (DWT).

A Fourier transform uses basis vectors that are defined by the trigonometric functions sine and cosine to generate Fourier coefficients for an arbitrary vector. One of the disadvantages of the DFT is that the transformation produced is a single res-olution. In other words, time localization is only captured at the window level. In [36], Fourier transforms were used. The authors found that using a windowed Fourier transform on time series containing varying width burst behavior resulted in a larger number of missed burst when compared to using a wavelet transform.

Wavelets are a tool for analyzing  X  X  X ransient, nonstationary, time-varying phenomenon X  [9]. Wavelets allow time series to be viewed in multiple resolutions. Informally, at each resolution, the size of the input data is halved. A time series of length 16 has four resolutions. Level 4 maintains the highest frequency coefficients and is represented using eight coefficients. Level referred to as the  X  X emainder X , is also a single coefficient. From this we see that wavelet transforms give gradually refined representations of a time series at different scales. While any linear transform can be used to generate coefficients, we focus on wavelets since they have been used successfully for different burst detection applications [36,47] .

Formally, the Discrete Wavelet Transformation (DWT) is obtained by calculating the set of coefficients,  X  c linear combination of a specified wavelet function [18]. The function s transforms each window of stream values  X  e ; e 2 ; ... ; e n  X  to wavelet coefficients  X  c 1 ; c 2 ; ... ; c
W ment the level for each resolution, where the maximum coefficient level is log  X  n  X  . Since the adversary will be attempting to reconstruct the wavelet coefficients, his predicted wavelet transform will be denoted
There are many different families of wavelet functions. In this paper, we consider the Haar and Daubechies wavelets. The difference between the Haar and Daubechies wavelets is the function used to generate the coefficients. Haar is the simplest wavelet. It has two wavelet and scaling coefficients. The scaling function is defined as the average of two data values and the wavelet function is defined as the difference between two data values. The original data set of n elements is replaced with an average (the scaling function value) followed by a set of wavelet coefficients obtained during the different iterations, i.e. at scaling function values and wavelet coefficients are calculated by shifting the scaling and wavelet vectors by two and cal-culating the inner products. The Haar wavelet is discontinuous, generates orthogonal basis, has one vanishing moment, and has compact support. The Haar wavelet functions are neither smooth, nor continuously differentiable. Therefore, any vector it approximates is done using a ladder like view. This may be undesirable for smooth functions. Therefore, we also consider the Daubechies wavelet. Daubechies wavelets are continuous, generate orthogonal basis, have multiple vanishing moments, and have compact support.

From a computational perspective, the difference between the Daubechies and Haar transforms is the way the scaling and wavelet functions are defined. The Daubechies transform uses more wavelet and scaling coefficients than the Haar trans-form. There is a family of Daubechies transforms that have different scaling functions. For the purposes of this paper, we focus on Daubechies D4. It has four wavelet and scaling coefficients and from a systems standpoint, it has the shortest filter in the Daubechies family of wavelets. Similar to the Haar example, each step of the wavelet transform applies the wavelet function and the scaling function to the input data. Unlike the Haar, at each iteration, overlap exists when calculating new scaling and wavelet function values. This enables the transformation to capture smoothing details missed by the Haar wave-let transformation, thereby avoiding the ladder like view. Efficient in-place algorithms that are linear with respect to n exist for calculating wavelet coefficients at resolutions that vary over a power of two. We refer you to Burrus and Gopinath [9] for a detailed discussion of different wavelet types.

Fig. 3 shows a simple data stream containing only a single burst at a single location. The x -axis represents i or the item arrival sequence, while the y -axis represents the magnitude of the items  X  e example is 32, n  X  32 and r  X  5. Table 3 shows x  X  3 windows. Each window contains 32 Daubechies-4 wavelet coefficients, with each coefficient. Window 2 contains higher coefficient values than the other windows. Specifically, the coefficients in level 1 and level 2 have the highest magnitude.

When the fluctuations or generalized differences of the weighted average is high at a particular resolution, one or more of the coefficients at that resolution are large. This results because the wavelet transform localizes time series in space (reso-lution) and frequency by using orthogonal basis functions that map a time series into trends and fluctuations. The trends are define this behavior using the ideas presented in [9].

Definition 7. The Haar and Daubechies-4 wavelet transforms decompose a sample variance of a time series window according to scale  X  r 1  X  .

In other words, small coefficient magnitudes indicate minimal change or variation at a particular resolution while larger ones indicate more significant variations. A large coefficient value results when the variance is high. Statement 1. Large coefficient magnitudes at coefficient level l indicate a burst.

Proof. Suppose that a large coefficient does not indicate a burst. Then by Definition 7 , the variance between the wavelet assumed that the coefficient is large, so this is a contradiction.
 This statement follows from Definition 7 . If the variance is high, then the change in magnitude is high, indicating a burst.
If the variance is small, then by definition, the coefficient is small and a burst has not occurred. h 4.3. Multi-resolution level sums Intuitively, one way to detect bursts is to keep track of the overall magnitude of the coefficients at different resolutions.
We accomplish this by creating level sums from the coefficients in each window. The summation vector is composed of level sum values for each coefficient level of the linearly transformed data. Each participant X  X  level sums will be perturbed, com-bined and used for burst detection.

Definition 8. We define vector S k to be the cumulative magnitude of the coefficients at different coefficient levels l . More precisely, we are interested in calculating this sum for all coefficient levels from 1 to r for window k , our result is the vector S contains elements f S k  X  1  X  ; ... ; S k  X  r  X g . The size of the S values for our burst example. Recall r  X  5 for each window of streaming data. In the table, S levels 1 to r in each window.

Notice that coefficient level 0 is not in S k . The level 0 coefficient maintains trend data. While this is very important for reconstruction of the original time series, we will show in Section 4.5 that we can calculate bursts without this information.
Further, eliminating coefficient level 0 means that a significant piece of the data that is necessary for reconstruction is not being transmitted to the leader.

Claim 1. If the adversary knows coefficient values c 2 ; c represents a possible range of coefficient values, and a is a small constant with a magnitude less than one.
Here we are attempting to quantify the probability of determining c is x , even though this is not known to the participants.

If the adversary has coefficient values c 2 ; c 3 ; ... ; c (1) Coefficient values c 2 ; c 3 ; ... ; c n are small when compared to x . (2) Coefficient values c 2 ; c 3 ; ... ; c n are large, approaching x . (3) Coefficient values c 2 ; c 3 ; ... ; c n vary, some approach x and some do not.

Case 3: If the coefficient values are a hybrid of Case 1 and Case 2, this implies that some approach x and some do not. Then
This claim establishes that knowing the other coefficients provides no additional insight into the level 0 coefficient in most cases and limited insight in Case 2. It then follows that knowing S c since it does not contain c 1 and the sum of the other coefficients does not decrease the range of possible values for c
We now consider what an adversary can determine using coefficients c sents the trend of the wavelet. For the Haar wavelet it represents the mean. Without the mean, the magnitude of the time series cannot be determined, but the shape of the time series can be determined for Haar wavelets and approximated for Daubechies wavelets if we know the coefficients for levels 1 through r .

Statement 2. While a data breach occurs if all the coefficients are known by the adversary, an envelope breach occurs if only the values of c 2 ; c 3 ; ... ; c n are known.

This follows from the definitions of the Haar and Daubechies wavelet transforms. In other words, if c
Haar wavelet transformation, then the envelope of the original time series can be computed exactly using the other coeffi-cients. Therefore, given S k , the probability of determining the actual coefficients is P  X  W range of values is sufficiently large and the mean or distribution of W ing W k is small and discrepancy D  X  W ; f W  X  will be large.

Using level sums decreases the likelihood of a data breach or an envelope breach by obscuring raw data values and raw coefficient values. It also reduces the amount of data that will be transmitted. Approximating actual coefficient values using the summation vector is not intuitive. One approach is to assign the average value to each coefficient for a particular reso-coefficient magnitude as the coefficient value at each resolution (distorted). We see that because coefficients are not raw data values, using the average value can lead to substantial changes when reconstructing the time series.
A participant may also consider using the underlying distribution of his own wavelet coefficients to approximate another participant X  X  coefficients. If two participants have the same underlying distribution and mean, using this approach to approx-imate the other participant X  X  wavelet coefficients can lead to a privacy breach. (We will show an example in Section 5.)
Therefore, as an additional layer of privacy, we perturb the level sum values prior to communication. 4.4. Secure summation vector communication
In this paper, we transmit summation vectors, S i k for each window k and each participant i . While we showed in the pre-vious section that determining the raw wavelet coefficient values can be difficult using the level sums, the leader can still determine the other participants X  individual bursts when collecting the individual level sum vectors. In order to hide each participant X  X  individual bursts, we need to communicate a perturbed summation vector S sions of this problem use the secure multi-party computation (SMPC) protocol for secure summation [46]. This protocol has the leader add random numbers to his data prior to transmission. As a participant receives data from a neighbor, the participant adds his data values to the received ones and sends the aggregated data values to the next participant. This con-tinues in a round robin fashion until the cumulative values return back to the leader. If we used this SMPC to communicate our level sums, the total size of data communicated would be  X  P 1  X  x log  X  n  X  . Each participant must transmit log  X  n  X  val-ues per window. There are x windows and  X  P 1  X  hops in the round robin data transmission.

Because this online communication cost increases linearly with P , we introduce a simple approach that involves insertion of  X  X elf-eliminating X  random bursty noise. It is important that the noise we insert contains a large number of bursts to hide the actual bursts found. We define self-eliminating noise to be a vector of values that cancels out after the elements in one dimension are summed together. The vector R  X  X  5 ; 1 ; 1 ; 3 is an example of a self-eliminating noise vector since  X  5  X  1  X  1  X  3  X  X  0. Self-eliminating noise removes the need to either aggregate summation vectors of different partic-ipants in a round robin fashion or remove the noise after aggregation. In a streaming environment, these savings are important.

Definition 9. We define a noise generator (or generator for short) to be a participant assigned to generate self-eliminating noise.

Recall from the algorithm presented in Table 2 , each generator j creates a random noise list R are G participants that serve as generators. The protocol requires G P 2. If there is only one generator, G  X  1, then the gen-erator could intercept any participant X  X  communication and remove the added noise to get the raw summation vector S
In order for the noise to be self-eliminating during aggregation of the level sum values, each generator must ensure that the sum of values across all generated, participant noise lists sum to zero at any index on the list:
By enforcing this constraint, the noise will cancel out once the individual level sums are aggregated. The noise prevents par-ticipants from potentially causing a privacy breach while also avoiding more costly aggregation using a round robin secure summation.

Recall that R i ; j is distributed to each participant as a preprocessing step. Once participant i receives the random number list from the generators, the participant adds the next random number from each list to the next level sum value as described in Table 2 . After the noise has been added for all the elements in S the leader. An example of this is illustrated in Table 5 . In this example, there are two noise generators and six participants.
Each participant receives a list of random numbers. Each participant will take the first number from the list and add it to his first level sum value. Then he will add the second number to the second level sum and so on. For example, if Participant 1 X  X  raw level sums are 2, 3, and 4, then using the generated values in Table 5 , the transmitted values would be 1, 12, and 10.
Once the level sum values are aggregated by the leader, the added noise cancels out and the actual aggregate level sum is obtained by the leader. We will refer to the aggregated summation vector for window k as S
Because the leader is not one of the noise generators, the leader does not see the actual level sums of the participants during aggregation. Another benefit of this approach is that each generator can use different means and variances for data generated for each participant as long as it is self-eliminating across all participants.

To ensure that data from participants with unusually large deviations compared to other participants is adequately hid-den, a maximum and minimum data value threshold can be enforced. Participants with values outside of those thresholds would replace the actual data value with the corresponding threshold value. The idea of thresholding is similar to the idea of transform thresholding presented in [36].

The time needed to get the data to the leader is x  X  log  X  n  X  X  . The amount of data communicated is the same, but the run-communication is a large cost. It is also a more straightforward coordination than one involving passing streaming data to all neighbors for aggregation.
 4.5. Burst detection Burst detection is a specific case of anomaly detection that incorporates change detection. In control theory, Statistical
Process Control (SPC) methods are used to detect changes or out-of control conditions in single resolution data. Methods pro-posed include: Shewhart, moving averages (MA), exponentially weighed moving averages (EWMA), and cumulative sum (CUSUM) control charts [5,8]. Because we are attempting to detect bursts directly from the summation vector, and not the raw data, we will use a Shewhart chart method for finding bursts. A Shewhart chart uses a threshold to identify when an observation or an event falls outside a desired control limit [34]. The idea is to identify a meaningful threshold on the original time series, e.g. l c r , where c is a small constant. If a value exceeds the threshold, it is considered a potential change point. In this paper, we will employ a variation of the Shewhart method because the linear transformation coeffi-cients are a different scale. We use a constant c to account for the variation in scaling between the coefficient level sums and the original data.

For our burst detection, we now flag any coefficient level sum that is above the Shewhart threshold. We use an exponen-tial decay function to calculate a moving mean and standard deviation. We chose the decay parameter to provide slow adap-window, each burst is flagged. The highest level coefficient that is flagged defines the width of the shortest burst detected.
The lowest coefficient level that is flagged defines the width of the longest burst. The leader then securely distributes the flagged windows and coefficient levels to the other participants. Any standard encryption technique can be used for commu-nication of these results.

If we consider the example level sums in Table 4 , we see that for window 2, coefficient levels 1 and 2 have magnitudes that exceed the Shewhart threshold. This tells us that a burst of width larger than 16 and smaller that 32 has been detected. The actual width of the burst is 18.

In our example, the burst fits neatly into a single window. This is not always the case. Even though the burst width may be less than n , it may be split across two windows. If the burst is split equally across the two windows, it will be identified in both windows. Simple distance functions that compare level sums across adjacent windows at each resolution can be used to determine if a burst is completely contained in a single window or if it is split relatively evenly between two windows. We now define two functions that compare adjacent windows k and k 1.

Definition 10. We define two adjacent window distance functions f
If the participants want to know whether or not a burst is completely contained in a single window, f evaluated using the aggregated level sums S A k and S A k 1 the burst is split across two windows k 1 and k . If both f and g are large, then the burst is in window k 1. 4.6. Overall costs
While we have discussed the individual component costs in earlier subsections of this section, we now consider the entire cost. The online costs can be broken down into three categories: compression, communication and burst detection. Compres-sion has two components: the transformation cost for each window of the original time series O  X  n  X  and the cost of computing the level sums for each window O  X  n  X  . Communication refers to the cost of transferring the perturbed individual participant vectors, computing the window comparison vectors and detecting bursts using the level sums and the window distance
O  X  X  P x  X  n  X  log  X  n  X  X  X  X  . In general, the number of elements in a window will be greater than the number of participants or the number of windows. However, one of the strengths of this algorithm is that the overall cost is linear with respect to all three of these components  X  the size of the data  X  n  X  , the number of participants  X  P  X  , and the number of windows  X  x  X  . This overall cost is also not dependent on the number of bursts or the width of a burst. The overall algorithm is more scalable than previously proposed algorithms. 5. Experiments and evaluation
We now present our experimental results. The first subsection begins with an analysis of privacy for a sensor data set. In this experiment we explore the discrepancy between the actual data stream and an adversary X  X  data stream predicted from a participant X  X  raw level sum values. In Section 5.2, we evaluate our multi-resolution summation strategy in the context of burst detection accuracy for different types of time series data sets and show that it performs as well or better than previ-rithm in terms of computation, memory and communication overhead. Our costs are also compared to those of the previously proposed methods and show significant savings across the different measures.
 5.1. Amount of privacy maintained
Here we empirically investigate whether or not privacy breaches occur on sensor data collected from sensors that mea-sure the temperature of a room housing a server cluster system. The data was collected during an experiment when individ-ual air conditioners were turned on and off to observe the change in temperature at different locations in the room. The sensor readings are recorded every 5 ms. While this data does not require privacy, it is a good data set for analyzing privacy data with similar burst behavior while the third has data with different burst features. Fig. 5 a X  X  show an example of time series data streams from three participants and the aggregated stream, respectively. The x -axis represents time and the y -axis represents temperature. Each subfigure shows 16 K data points of the stream.

To test whether or not a privacy breach occurs, we setup a scenario where Participant 2 (P2) and Participant 3 (P3) are independently trying to determine Participant 1 X  X  (P1) data stream. We chose this scenario because P2 X  X  stream trends ex-actly like P1 X  X  data stream. P3 X  X  data is bursty, but trends differently from P1 X  X  data.

We first determined the q d privacy breach threshold for P1 X  X  data. To do this, we generated five different types of noise: random, random with the same mean as Participant 1 X  X  data, bursty, bursty with the same mean as Participant 1 X  X  data, and bursty with the same mean and number of bursts as P1 X  X  data. We set q data and the different noise data (bursty, same mean, same number of bursts) and q discrepancy (random).

We then setup the  X  X orst case X  scenario for P1. We assume that the other participants are able to get P1 X  X  aggregate sum-mation vector. This scenario is highly unlikely since noise is added to P1 X  X  aggregate summation vector prior to communi-cation. However, for the purpose of analysis, it is useful. We then calculate naively splitting the level sum values equally across the appropriate coefficient level and splitting it based upon the adver-participant X  X  own mean. Data breach results are shown in Fig. 6 . The x -axis shows the two coefficient approximation strat-egies and the y -axis shows the discrepancy between each adversarial participant X  X  predicted time series and P3 X  X  time series.
The two lines highlight the lower and upper thresholds. The bars on the left use the equal splitting strategy and the bars on the right use the distribution strategy. We see that both strategies work poorly for P3 and do not lead to any breaches. In contrast, P2 does cause a data breach using its own mean and distribution information. This is not surprising since P1 and P2 X  X  means and distributions are very similar. The best signal predicted by P2 and P3 are shown in Fig. 8 . For an envelope breach, we generate a stream that has some similar properties to P1 X  X  data, but is not an envelope match.
We then calculate q e using the approach described in Section 3. Results are presented in Fig. 7 . When we reconstruct the stream using the summation vector, we find that P3 is not able to generate an envelope breach; however, because P1 and P2 have a very similar data stream, P2 can generate an envelope breach. These results confirm the importance of hiding the raw level sum values during aggregation. When the noise is added to the level sums, neither of the participants generate data or envelope breaches. This results because the variation in burst behavior between the original level sums and the noisy version is significant. Fig. 9 shows the level sums across windows for each participant on the left and the noisy versions of the level sums on the right. For all of our experiments, the number of noise generators  X  G  X  is two. Because the wavelets are multi-resolution, we show the level sum for each of the seven resolutions along the z -axis. Recall that for each window a set of level sums is generated. The x -axis represents the different windows and the y -axis shows the magnitude of the level sum value for each window at each resolution. 5.2. Burst detection accuracy
We now analyze burst detection accuracy on the aggregate stream. In information retrieval literature, recall is defined to be the number of actual bursts detected divided by the total number of actual bursts. Precision is defined to be the number of actual bursts divided by the total number of bursts obtained. F -measure combines both precision and recall into one value.
Bursts that exist but were not detected by a particular algorithm are considered false negatives (the number of actual bursts the number of actual bursts detected). Non-bursts that are considered bursts by a particular algorithm are referred to as false positives (number of bursts detected the number of actual bursts) [3].

The data sets we consider include stock ticker, network packet, sensor, random walk, and synthetic time series, e.g. peri-odic, random, monotonic, etc. The majority of the non-synthetic data sets were obtained from the UCR time series data repository [22]. Information about the other data sets, including the synthetic ones can be found at [35]. Again, while none of these data sets actually requires privacy, we consider these data sets because they serve as a representative set of time series data that has varying energy and noise characteristics.

Fig. 10 compares the number of actual bursts detected using multi-resolution summation vectors. Our multi-resolution summation comparison shows both the Haar (Haar Level Sums) and Daubechies-4 (Daubechies Level Sums) wavelets, the actual number of bursts found using the original time series (Raw Data), the number of bursts obtained using scaled binning with window means (Scaled Bin) [31], the number of bursts obtained using the wavelet coefficients directly (Haar and
Daubechies), and the number of bursts obtained using percentage thresholding (% Thresholding) [36]. For these experiments, we used a window size of 128 and an equivalent threshold to that of l 1 : 5 r for the bursts. The x -axis shows the different aggregate data set names and the y -axis shows the number of bursts detected for each data set. The first bar for each data set is the actual number of bursts and the last two bars are the Haar and Daubechies Level Sum results. We set the number of participants to be between three and eight and aggregated different time series combinations for each test. Because there was no change in burst detection accuracy as the number of participants increase, here we simply show the average results. Table 6 shows the precision, recall, and F -measure for Haar Level Sums (left) and Daubechies Level Sums (right).
These results highlight a number of interesting findings. First, the recall of the Haar Level Sums or Daubechies Level Sums approach is high. There are no more than two false negatives for any data set. That is less than 1%. False negatives will occur when coefficients at a particular resolution have high magnitudes, but have different signs. If the positive and negative coef-ficients are of a similar magnitude, the coefficient values will cancel each other out, resulting in a level sum value that will approach zero. For the data sets we tested, this behavior did not occur often.

Using this approach for burst detection, no false positives are generated. In other words, the precision is 1 for all these examples. This is an important distinction between this multi-resolution comparison approach and the scaled binning ap-proach [31]. We now discuss why this results.

Based on Statement 1, a large change at any position in the original time series, will yield a large coefficient value at cor-change is small, and the level sum is small. If coefficients are large, the change is large, and the level sum is large.
In order to avoid false positives or false alerts, it is only necessary to ensure that the burst threshold on level sums is set properly based on the burst threshold on actual data.
 Statement 3. Using level sums to detect bursts does not introduce additional bursts, i.e. false positives.
Proof by contradiction: Let T be the burst threshold on actual data stream E and f  X  T  X  be the burst threshold on level sum values where f is a linear function of T . For any data window w of size n , let e  X  0 be the first data value in the window, e the smallest data value within the window, and e max be the largest data value within the window. If there exists a burst in window w , then at least one of the following two conditions has to be true on actual data: (1) e max e  X  0 &gt; T ; (2) e  X  0 e min &gt; T .

In other words, there has to be at least one data value in window W that is large enough in magnitude (i.e., a large positive or negative value) to trigger a burst.

Now, let X  X  assume that a burst is reported, i.e., a level sum is large enough to report a burst, but an actual burst does not exist. This means that both condition 1 and condition 2 are false. If a burst does not exist in window W of actual data, then by are small values in magnitude, the level sum is also small and a burst does not exists. We assumed that a burst existed; therefore, we have a contradiction. h 5.3. Costs and overhead
In the previous section, we highlighted the costs associated with our aggregate burst detection algorithm. In this section, we measure the actual costs using different parameters. Fig. 11 shows the times (in milliseconds per window) associated with the compression, communication and burst detection steps of our algorithm. The x -axis shows the cost type and the window size for the raw data, half the wavelet coefficients (Daubechis/2 and Haar/2), and our new method (Daubechies
Sums and Haar Sums). The y -axis shows the time required per window for the mentioned steps. The time represents the median time per window over all the data sets. For the communication time, to evenly compare the cost across data sets, we measured the data transfer time from a machine in California to a machine in Washington, DC for all the data sets using the different methods. We ran the experiment ten times for each data set and used the average time per window over all the data sets. The communication costs do ignore the initial setup time. A more detailed comparison of just the communication time is shown in Fig. 12 . Here, the x -axis represents the method and the window size, while the y -axis shows the commu-nication time needed to transfer data using the different methods. Fig. 13 compares the amount of data stored and commu-nicated (in bytes per window) for the different data aggregation methods across three different window sizes: 32, 128, and the window size, while the y -axis shows the computation time for detecting bursts using the different methods.
Finally, we explore the increase in communication cost as the number of participants increases. For these experiments, we measured the communication time between two machines: one located in India, and the other located in the US. Each experiment measured the communication time for sending the level sums of Haar and Daubechies-4 coefficients for multiple participants. Each experiment has been repeated 10 times for every combination of wavelet method (Haar and Daubechies-4) and number of participants P (1, 2, 4, 8, 16, and 32). The minimum and maximum measurements out of 10 runs are elim-inated and the average of the remaining eight runs is calculated as the communication time. Fig. 15 shows the increasing communication costs as the number of participants increases. The x -axis represents the number of participants and the y -axis represents the communication time in milliseconds. While there is an increase in cost, it is sublinear as the number of participants increases for both types of wavelets.

Since we did not have multiple machines to act as different participants, we ran a multi-thread program on one machine in order to simulate multiple participants. The other machine acted as the collector and accepted connections from all par-ticipants. Because this set of experiments was not run on P machines, the results shown in this paper represent the upper limit for the communication cost. In a multiple machine environment, the participant machines would not experience the overhead of running multiple threads and sending data of multiple participants in parallel from the same machine. Instead, each participant machine would have sent the data for only one actual participant and the communication cost would have been smaller than those shown in Fig. 12 .

From the graphs, we observe the following: the dominant cost is the communication for all the approaches, in terms of memory space and time. Therefore, reducing that cost is critical to the success of any method. Our multi-resolution summa-tion approach reduces communication costs significantly when compared to sending the raw data or sending half the wave-let coefficients (Haar, Daubechies). Another interesting observation is that the computation of the Haar wavelet transform is significantly faster than the Daubechies wavelet transform. This results because more scaling coefficients are needed to accurately compute the Daubechies wavelets. Finally, the time needed to calculate the level sums and the aggregate bursts are insignificant compared to the time associated with communication and data transformation.

The other cost to consider in a streaming environment is memory overhead. Because the wavelet algorithm is in-place, there is no additional memory needed to compute the transform. Similarly, the coefficients can be directly replaced with an in-place vector summation calculation  X  again, no additional memory. Finally, the leader needs an additional O  X  log  X  n  X  X  amount of memory to detect bursts from the summation vectors. Since the summation vectors are small, the overhead is reasonable in a streaming environment.

We pause to discuss the choice of parameter values in these experiments. First, we consider the size of the windows. We have reported for 32, 128, and 1024, but have tested over a large range. A small n reduces time because it reduces delays due to waiting for data; whereas a large n reduces the amount of data being communicated and therefore, reduces the commu-nication cost. We found that for our environment, values below 32 and above a few thousand were not desirable because they either caused too much delay in processing or had very poor compression rates. Next, for the burst threshold we tested several different factors (or fractions) of stddev, including 0.5, 1, 1.5, 2, 2.5, and 3. Then, we checked the average number of bursts in each window and compared it to bursts based on manual inspection of the data stream. We chose 1.5 stddev be-cause it gave the best burst detection accuracy across all the data sets. This generally translated to between 1% and 10% of a window corresponding to bursts.
 6. Conclusions
While privacy-preserving data mining techniques are growing, limited attention has been paid to privacy in the context of streaming data. This paper presents an approach for burst detection of aggregated data streams in the context of privacy preservation. We use wavelets to highlight bursts of different resolutions and to compress windows of the original stream.
We also introduce the calculation of summation vectors to further compress the data and obscure raw data values. This indi-vidual participant information is aggregated using  X  X elf-eliminating X  bursty, random noise. Bursts are then calculated directly from the aggregated summation vectors using a Shewhart threshold.

There were a number of new contributions including: considering a new privacy breach, introducing summation vectors, using self-eliminating noise, and limiting memory overhead, communication costs, and processing time for the streaming environment constraint.

Without any prior knowledge about the participant stream, privacy breaches were avoided and burst detection accuracies of Daubechies.

Even though the cost of the algorithm is reasonable in terms of memory overhead, communication costs, and processing times on a range of data sets, both real and synthetic, if we compress the wavelet representation and only consider bursts at a single resolution, we can reduce the communication cost from logarithmic time to constant time. Because communication cost is the dominant cost, detecting a specific type of burst may suffice so that the communication cost can be further reduced.

In our formulation of the problem, we assume that each participant is sharing a single data stream. If multiple data streams are shared by parties, then similarities that exist across streams from a single participant can be exploited by an adversary that has access to part of the data. As future work, our technique could be extended to consider similarity between the streams based on the inner product of the streams. We would also need to devise efficient ways to determine which streams to aggregate.

While this is an important early contribution, we believe that exploring privacy preservation in the context of streaming data will continue to grow in importance as the complexity of the data and the need for privacy increase.
References
