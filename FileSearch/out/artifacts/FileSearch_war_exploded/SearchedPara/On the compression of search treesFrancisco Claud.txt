 1. Introduction become challenging.
 that provides a space X  X ime trade-off, these solutions are called parametric . logarithmic time, supports:  X  access  X  X ; i  X  : retrieve the value at position i in X . search  X  X ; t  X  : retrieve the position of the left-most stored value greater or equal than t . capabilities.
 sums problem we are given a sequence of n non-negative values, Y  X  y operations: sum  X  Y ; i  X  : retrieve the sum of all the values up to position i . search  X  Y ; t  X  : retrieve the smallest i such that sum  X  Y ; i  X  P t .

Note that X  X  x 1 ; x 2 ; ... ; x n can be defined as a sequence of partial sums of values in the sequence Y  X  y x  X  for example, to represent Rank / Select dictionaries ( Okanohara &amp; Sadakane, 2007 ). the paper with some brief remarks and avenues for future research. 2. Related work
As we mentioned above, common solutions to this problem encode the differences between consecutive values with metric solutions, whereas our method is non-parametric .
 Finally, we describe an approach for handling general trees, with the potential of becoming dynamic. improvement. 3. Differentially Encoded Search Tree (DEST) tion), one can determine whether the difference is positive or negative.
 suitable integer encoding techniques.
 note that the selection of a tree representation and encoding is entirely application dependent. 3.1. Operations senting X . We assume T has d n = k e nodes, each of arity k  X  1. The operations T supports are: root T : obtain the root of the tree. value, and that of the parent node. child T  X  v ; r  X  : find the r th child of node v in T . Unlike the previous case, r  X  0 ... k . paren T  X  v  X  : find the parent of node v in T . subtree size T  X  v  X  : count the number of values in the sub-tree rooted at node child rank T  X  v  X  : compute the rank of node v among its siblings. map T  X  v ; r  X  : map the r th value of node v to its position in the original sequence X . (not its difference with the parent). Therefore, any tree traversal will start by accessing the root ( embedding w  X  X  w 0 ; ... ; w k 1  X  is a vector (the binary embedding is a particular case w  X  X  w child also in constant time. To do this, we set v  X  child w  X  w r  X  fetch T  X  v ; j  X  otherwise. We can move to the parent of node on the fly the values in w that we need, thus we are not forced to pay O  X  k  X  every time we move.
This takes O  X  log k  X  time at each node, and thus the whole traversal takes d log shows the pseudocode for this operation.

Algorithm 1. access  X  X ; i  X  ; T is the DEST representation of X v root T { v is the current node} w 0{ w is the current value} pos 1{ pos is the position in X of the current value} rightMostChild true while pos &lt;&gt; i do
Algorithm 2. search  X  X ; t  X  ; T is the DEST representation of X v root T { v is the current node} w 0{ w is the current value} rightMostChild true while v is a node do return n{ The length of X , which indicates that t is greater than all the values of X } 3.2. Binary heap-like embedding only a contiguous prefix is filled with values.

It is well known that such a tree can be embedded in an array A  X  1 ... n , right children of a node at position v are at positions 2 that we need to address in order to give a complete description of the structure are how to compute subtree size map T  X  v ; r  X  , and how to build this structure efficiently.

Supporting subtree size T  X  v  X  The tree has depth h  X  log given node v by computing h  X  v  X  X  log 2  X  v  X  1  X  de . For each internal node h h  X  v  X  X  1or h h  X  v  X  . We know that the subtree contains at least 2 of nodes in the last level. In order to do that, we compute the positions p most descendants of node v , respectively. Since the subtree rooted at p  X  X  v  X  1  X  2 h h  X  v  X  1. By comparing p  X  with n , we can determine whether there are any nodes in level h h  X  stant time.
 Supporting map T  X  v ; r  X  . In the binary case, we can picture the map moving to another node and this can be done in constant time using the subtree size the root is simple if n  X  2 h 1, since it is exactly in the middle of the array at position 2 struction we need to handle the general case, when n is not a power of 2. Assume 2 scenarios that could arise. There are two cases: 3
Case n P 3 2 h 2 : This case is represented on the right side in Fig. 1 , and the root is at position 2 vation is that the root is at position max  X  2  X  ; n 2  X   X  1  X  , where  X   X  log these cases ( Fich, Munro, &amp; Poblete, 1995, Theorem 4 ).
 time. 3.3. Multiary heap-like embedding of k  X  1 for each node, thus every node stores k values. The root is at position 1 in the array. value, for example, for k  X  3 the 0th child of the root is the node jk and rightmost descendants of position v , which are placed in the last level of a subtree of height h h  X  h  X  v  X  X d log k  X  1  X  v  X  1  X e . If the leftmost child is at a position p subtree is that of a complete tree of height h h  X  v  X  . Otherwise, given the position of the rightmost node, p  X  p  X   X  k  X  k  X  1  X  h h  X  v  X  1, the subtree contains min  X  n ; p
We can compute map T  X  v ; r  X  in a similar way, but in this case we move to the leftmost descendant of node values stored in node v up to position r plus the r complete subtrees of height h h  X 
The construction is slightly more complicated than in the binary case. We can compute the height h  X d log height h 1 (see Fig. 2 ).

The number of values in a complete tree of height h 2is  X  k  X  1  X  level of the subtrees with height h 1, we can write n as n  X  X  k  X  1  X  of height h 1is k  X  k  X  1  X  h 2 . From the previous paragraph, we get that b  X  n  X  1  X  k  X  1  X  lue of j by computing j  X  b means that the j th subtree has height h 2, and all the subtrees to the left are complete trees of height h 1. values every  X  k  X  1  X  h 1 1 values apart, then we jump  X  k  X  1  X  remaining values, we jump  X  k  X  1  X  h 2 1 between each. This construction allows us to state the following lemma. linear time.
 disk that has block size B , then we just need to set k  X  B 1 and the search I/O complexity becomes O  X  log operations in O  X  log B n  X  I/Os.
 of the time, as it has been discussed in the past ( Ferragina, 2010 ). 3.4. General trees Note that we have not mentioned much about the operation fetch access. This is not the case for general trees.

Most succinct tree representations support subtree size T saves more than 2 n bits, then this approach outperforms the representation of the previous paragraph. 3.5. Encoding DEST encode different chunks (e.g. different encodings for each level).
 Our first proposal, named DEST-DAC, uses the Directly Addressable Codes (DACs) proposed by Brisaboa et al. (2013) . codes. This encoding achieves constant time access in the word-RAM model.
 both encodings, there may exist other encodings that achieve better space offering the same time complexities. 4. Applications and experiments sented here were performed in an Intel Xeon E5520@2.27 GHz, 72 GB RAM, running Ubuntu server (kernel 2.6.31-19). We compiled with gnu/g++ version 4.4.1 using -O3 directive.
 by Okanohara and Sadakane (2007) , which is available in LIBCDS 4.1. Performance overview For our structure, we tested the four encodings proposed in Section 3.5 , named DEST-DAC, DEST-LVL, DEST-HYB, and difference between them.
 larger values of k skew the distribution, thus increasing the probability of zeros. from the interpolative encoding (which does not support random access and efficient searches). around for exponentially distributed data.

Since we mainly focus on the search operation X  X e are compressing search trees X  X e emphasize that, for search, our shows the good scalability of our proposal. 4.2. Posting lists perform better when the lengths of the lists are unbalanced. We call this variant Set-vs-Set (SVS). constraining factor for inverted indexes.

P  X  p 1 ; p 2 p 1 ; ... ; p n p n 1 of d-gaps and stores each value in P array samples  X  1 ; d n = s e stores a sample every s values such that samples  X  i  X  p the offsets corresponding with the beginning of each sampled block have to be stored in d n = s ed log stored.

Lemma 4.1. Suppose we are given a sorted list L 1 of length m, and a second list L
Proof. Let T be the binary-heap-shaped tree representing L were visited.
 left-most leaf of the subtree induced by u .

We use E to denote the set of all leaf nodes reached while searching for the values in L are the only leaves accessed during the traversal.

We use LCA  X  e 1 ; e 2  X  to denote the lowest common ancestor of nodes e total cost of the traversal is at most 2  X  t 1  X  t 2  X  .

Consider a value s 2 S whose parent, s , is not in S . Let s 0 be the sibling of s . Let e t by at least 1, since we add at least the edge between s and s 0 .

S corresponds to a heap-shaped tree with m = 2 leaves covering the top of the tree representing L leaves. Each path has length log 2 n d log 2 m e X  O  X  1  X  log n a value in the tree is higher.
 out in the time comparison in exchange for a higher space consumption. 4.3. Sparse bitmaps porting rank  X  X ; v  X  (the number of values in X no greater than the most practical representation we are aware of is the sarray proposed by Okanohara and Sadakane (2007) . lemma: rank  X  B ; v  X  X  search  X  Y ; v  X  1 , and select  X  B ; i  X  X  sum  X  Y ; i  X  . mance when compared to SAMP-RICE, which is the only structure competing around that part of the trade-off. 4.4. Geographic data culty of the instance.
 petitive with the state-of-the-art.
 by representing each chain using an instance of our structure, yielding a more space-efficient data structure. lows us to embed both in the same tree/array. The navigation is quite similar to the one already presented. We implemented this structure and compared it with a practical variant of the chain structure presented in Claude, space. Results reported in Table 1 do not consider this space because is the same for both variants. space and time. 5. Concluding remarks space X  X ime trade-off. Non-parametric solutions have been recently introduced by Teuhola (2011) . tion is competitive in a broad range of applications (e.g. representing posting lists and sparse bitmaps). case? efficient spatial index and perform an extensive experimentation to test its performance. Acknowledgements paper.
 References
