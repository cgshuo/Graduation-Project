 We present a preference aggregation algorithm designed for situations in which a limited number of users each review a small subset of a large (but finite) set of candidates. This algorithm aggregates scores by using users X  relative prefe r-ences to search for a Kemeny-optimal ordering of items, and then uses this ordering to identify good and bad items, as well as those that are the subject of reviewer conflict. The algorithm uses variable-neighborhood local search, allow ing the efficient discovery of high-quality consensus orderings while remaining computationally feasible. It provides a si g-nificant increase in solution quality over existing systems . We discuss potential applications of this algorithm in grou p recommender systems for a variety of scenarios, including program committees and faculty searches.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Performance Preference aggregation, Local search algorithms
In situations such as conference program committees and faculty searches, a group of people is tasked with reviewing a large set of candidates, and then collaboratively identif y-ing which of these are suitable. This problem is within the domain of group recommender systems , which aggregate in-dividuals X  preferences to recommend the best items for the group as a whole. Such systems present challenges that do not face recommender systems designed for individuals [7]; in particular, they must both accurately and fairly aggrega te users X  individual preferences.

One of the simplest methods for aggregating user prefer-ences is eliciting numerical ratings, and then assigning ea ch item a score that is a function of all the individual scores it receives. While this is a viable technique for some sys-tems [11], it fails within the context of committee decision -making, for a number of reasons. First, different reviewers may have different perceptions of how good or bad an item should be to receive a particular score, obscuring each scor e X  X   X  X eaning X . Second, some reviewers are universally negativ e or universally positive. When every user does not express a preference on every item, items will be considered different ly on the basis of who happens to have reviewed them. Third, some reviewers may also, by chance or by inclination, re-view only high-quality items or only low-quality items. Thi s situation is very hard to distinguish from that of univer-sally positive or negative reviewers. Nonetheless, numeri cal scores are appealing from a user-interface perspective: us ers are accustomed to assigning numeric scores, or analogous indicators such as a number of  X  X tars X , as a means of pro-viding preference information. But how can we glean more dependable information from these numbers?
We propose a group recommender system that considers only the relative preferences of each reviewer. If a given reviewer gives a higher score to item A than to item B, we take it as axiomatic that that reviewer prefers A to B. Our system uses the preferences thus exposed to extract a partial ordering of items from each reviewer X  X  score data, and aggregates these orderings, in order to combine prefer-ences elicited through standard numerical comparisons wit h-out encountering any of the above problems.

To accomplish this, we use both a novel local-search al-gorithm for aggregating individuals X  orderings into a sing le consensus ordering, and a strategy for using these order-ings to assist groups tasked with reviewing large numbers of different items. Our algorithm produces better results, on average, than any existing heuristics, and it solves most smaller problems to optimality. We analyzed this recom-mender system using anonymized data from various real-world situations, such as academic conferences.

An extended version of this paper, with details of the algo-rithms, their implementation, and evaluation, is availabl e at www.cs.brown.edu/research/pubs/techreports/reports/ CS-09-07.html . Our generated data sets are available at www.cs.brown.edu/research/plt/dl/recsys2009/ .
In order to make use of reviewers X  relative preferences, we must find a way to combine the disparate preferences of reviewers together. Aggregating orderings X  X ombining the relative preferences of multiple people into a single  X  X ons en-sus ordering X  in as fair of a way as possible X  X s the very same problem addressed by voting theory [1]. Kemeny [8] proposed a rule whereby the consensus ordering should be chosen to minimize the number of violations : the number of triples ( C i , C j , R k ) such that reviewer R k prefers item C C , but the consensus ordering ranks C j above C i .
The Kemeny rule has a number of desirable properties as a preference aggregation function [15]. However, it has a number of less-desirable properties: 1. Finding the optimal Kemeny ordering is NP-hard. Ex-2. There are mutliple Kemeny-optimal orderings, and any 3. A consensus ordering presents only a relative picture of 4. Almost invariably, final decisions are produced within
In order to address these issues, we use a local search algorithm to quickly provide a near-optimal answer rather than an exact solution; furthermore, we do not use this con-sensus ordering directly, but rather use it as input to our categorization system, described in section 4, which aims t o provide simple, useful, and dependable information based on this ordering.

Using relative preferences allows us to provide robust in-formation from scores. While scores are a common method of eliciting preferences in group recommender systems [7, 11], they are not universal. Lorenzi et al. [10], for instanc e, concieve of user preferences as a set of constraints, and at-tempt to find recommendations that fit the constraints of all the users. However, such systems tend to eliminate items that would cause conflict, which is not the goal in scenar-ios such as program committees and employee searches. We should highlight conflict-causing items rather than penalizing or eliminating them. Our ranking provides the additional benefit of identifying conflict without ruling out conflict-causing items.
In this section, we present a local search algorithm that quickly determines optimal or near-optimal consensus rank -ings according to the Kemeny criterion from sparse rank-ing data. In our categorization algorithm below, we use these rankings in concert with original scores to determine whether items are good or bad, as well as to identify conflict.
We can use reviewers X  preference data to construct a weighte d directed graph G = ( V, E ), in which each vertex v  X  V rep-resents an item being reviewed, and the edge from v i to v has weight c ij equal to the number of reviewers who prefer i to j . Given this graph, finding the Kemeny-optimal or-dering becomes an instance of the Linear Ordering Problem (LOP), in which the goal is to find a total order &gt; o that
Our algorithm is a variable-neighborhood search algorithm , with the same structure as the algorithm described by Gar-cia et al. [5]. We begin with a random ordering, and pro-ceeds to a local maximum. At every iteration, we then try to improve on that maximum by performing a series of succes-sively larger  X  X iversification X  moves, followed by the findi ng of another local maximum. Each diversification move at-tempts to change the solution enough that the subsequent search for a local maximum will find a maximum that is distinct from the previously best-known order. If the best local maximum we have found so far is close to a better max-imum, it should take only a small change in our solution to move us towards this higher point; however, if this does not work, we try larger moves. This is the essence of variable neighborhood search [5]. As soon as we reach a local maxi-mum better than the one where we started, the series starts all over again, with the smallest diversification moves.
We improve on Garcia et al. X  X  variable neighborhood search algorithm in two places: we have a novel technique for find-ing local maxima, and we modify the diversification step to be more appropriate for sparse graphs. These techniques result in major improvements, especially on the particular problem instances encountered in rank aggregation.
Most attempts to find good local maxima for the linear ordering problem have used a BestFit search, in which the algorithm repeatedly examines each vertex, and inserts tha t vertex in the position that results in the most improvement of the objective function. This continues until no moves can be found that improve the result.

We improve upon BestFit with cascadeMoveUp (Fig-ure 1) and the analogous cascadeMoveDown , which we developed to exploit the structure found in sparse matrices . We combine these two moves into a heuristic for finding local optima: first, we go from vertex N  X  2 to vertex 1, performing cascadeMoveDown , and then from 2 to N  X  1 performing cascadeMoveUp . We repeat these two steps until we achieve no further improvement.

In practice, we have found that this procedure works much better than using simple BestFit . On the other hand, it also performs significantly more slowly. But if we re-member which vertices are  X  X tuck X  X  X lready unable to move further X  X nd use this information to terminate the recursio n early, we can achieve a substantial speedup: with this opti-mization, Cascade takes only 50-75% longer than BestFit , as opposed to over 200% longer without it.
Garcia et al. use a diversification step diversify k which per-forms k random moves in which a randomly-chosen vertex is procedure cascadeMoveUp ( p ) end procedure placed in a randomly chosen position other than its own. k begins at 1, and each time the algorithm fails to find a new local maximum, k increases until it reaches k m ax . We modify this move by identifying, for a vertex v , the vertices pred ( v ) and succ ( v ) X  X he closest vertices ordered lower than v and higher than v , respectively, to which v is directly connected. Our diversification step uses only random moves that switch relative order of v and either pred ( v ) or succ ( v ), which im-proves its effectiveness on the sparse matrices prevalent in preference aggregation.
We evaluated our algorithm against real-world data ob-tained from a departmental faculty search with roughly 350 applicants and 25 reviewers, against the instances in LOLIB [14], and against a set of instances randomly generated to be simi-lar to real-world rank aggregation instances. These instan ces were generated by simulating k reviewers each ranking p of n papers. Their rankings are each set initially to be identi-cal, but are then each perturbed by m random moves. For each of n = 300 and n = 400 we generated both  X  X parse X  instances ( k = n/ 10 , p = 30 , m = 15) and  X  X ense X  instances ( k = n/ 5 , p = 50 , m = 20). We generated 10 each of these 4 types, for 40 instances in total. The dense instances are called 300-D and 400-D and the sparse instances 300-S and 400-S . There are two data sets from the faculty search: one is called Potential , corresponding to reviewers X  ratings on a  X  X aculty Potential X  scale; the other Fit , corresponding to their ratings on a  X  X oodness of Fit X  scale.

On each of these instances, we ran two different algo-rithms. The first, VNS , comprised the variable-neighborhood search algorithm with none of our modifications, as decribed in [5]. The second, VNS-CD : was our variable neighbor-hood search algorithm with the Cascade heuristic and the modifications to the diversification step.

For these algorithms, we set k max = 20, while Garcia et al. set k max = 10; we found that using a high k max , allowing our search to diverge farther from previous local maxima, improved solutions for rank-aggregation problems in parti c-ular. We ran each algorithm for the same amount of proces-sor time, rather than performing a set number of iterations; this allowed us to determine whether the additional time taken by the Cascade heuristic is put to better use than it would be by simply adding more iterations.

All algorithms were executed for 5 seconds of processor time on an Intel Pentium M processor at 1.4GHz.

On LOLIB instances, each algorithm reached the optimal solution for every problem, with the exception of VNS-CD , which returned a solution 2 below optimal on one instance, be75np . We hypothesize that this was just a poor run caused by the effects of randomness.

For the random rank-aggregation instances, our algorithm produced significant improvements in most cases; however, it was marginally worse on the  X 300 sparse X  set. For the problems encountered from real-world faculty-search data , our algorithm provides a real improvement over  X  X tandard X  VNS. Thus, our VNS-CD algorithm is an improvement over the state of the art in the domain of rank aggregation.
While the VNS-CD algorithm yields a good ordering of the vertices, just finding a consensus ordering is not enough . To improve the quality and utility of our information, we use a categorization algorithm that incorporates both the original scores and the consensus ordering.

We first attempt to reduce variability by gaining infor-mation about unconstrained vertices. This is accomplished by using the succ ( p ) and pred ( p ) functions defined in sec-tion 3.3. Since moving a vertex to any position in the order between its predecessor X  X  position and its successor X  X  wou ld not affect the cost, a vertex X  X  position within that range is arbitrary. Thus, we create O h , an order sorted by succ ( p ) which we use to look for good vertices, and O l , an order sorted by pred ( p ), to use when looking for bad vertices.
The next step is anchoring the consensus ordering to the initial scores. We computing a moving average of items X  average scores, in order to figure out approximately which numerical score is equivalent to which position in the sorte d order without re-introducing the same biases we have set out to correct. Starting with the highest vertex in O h , we label all vertices as  X  X ood X  until the moving average of scores firs t falls below some user-supplied cutoff values c good ; similarly, we label vertices as  X  X ad X  in O l until the moving average of scores rises above some c bad .
 The final step is identifying vertices that are  X  X n conflict X . To accomplish this, we look at all  X  X ood X  vertices v  X  G , and calculate the percentage of preferences that compare v and some non- X  X ood X  vertex u in which u is ranked above v : If this value exceeds the cutoff value c conflict , v is labelled as  X  X ood but conflicted X . A similar technique is used to identif y  X  X ad but conflicted X  vertices. We evaluated our algorithm using data from a number of small conferences that used the  X  X dentify the Champion X  (ItC) system for scoring [12]. In this system, reviewers sco re papers from A to D, where A signifies that the reviewer will  X  X hampion X  the paper by arguing for its acceptance, and D signifies that the reviewer will argue for the paper X  X  reject ion. B and C are intermediate values signifying views not strong enough for the reviewer to actively argue for or against.
We found that our algorithm (which produced optimal consensus orderings within five seconds on commodity hard-ware for all conferences) was slightly worse at identifying which papers would be accepted than ItC. While we never identified an accepted paper as X  X ad X , we occasionally ident i-fied as  X  X ood X  papers that would go on to be rejected. How-ever, our algorithm labeled more papers as  X  X ood X  or  X  X ad X  than were given definitive recommendations by ItC, which is designed so that papers with all As but no Ds should be accepted, and all Ds but no As should be rejected. For papers with no As or Ds, our algorithm correctly identi-fied which papers would go on to be accepted 80% of the time, which provided an improvement over the minimal in-formation otherwise available. Moreover, it is worth notin g that these small conferences, each having between 10 and 36 submissions, do not represent the target environment for our recommender system.
Cook et al. have previously examined the problem of cre-ating a consensus ranking from those of individual review-ers; a branch-and-bound algorithm is proposed that results in very fast optimal solutions for low-noise instances with up to 60 elements [4]. By using a heuristic local-search algo -rithm, we sacrifice the ability to obtain an optimal solution for increased scalability. Our categorization system prov ides information about conflict, while addressing the problem of unreliable consensus rankings, allowing us to provide more complete and dependable information. Lastly, the proce-dure designed by Cook et al. is meant to be used in concert with their allocation scheme for peer reviews, which is not practicable in all domains.

Other local search algorithms for the Linear Ordering Prob-lem have been proposed, using various metaheuristics [2, 6, 9, 13]. However, most of these algorithms were designed for instances such as those encountered in the Triangulatio n Problem for Input-Output Matrices in economics; indeed, the popular LOLIB library of sample instances for the linear ordering problem are derived entirely from this source, and tend to be both smaller (60 elements or fewer) and denser than the problems encountered in our domain.
Much more empirical data is required to give a good as-sessment of the efficacy of this recommender system in com-parison to less-sophistocated methods; this data will be cr e-ated as the algorithm is implemented and used in various recommender systems. Additionally, finding better ways of reducing the variability of consensus rankings X  X erhaps identifying and extricating disconnected components of th e preference graph, for instance X  X ould result in algorithms that are much more robust against conflicting reviews. In general, using relative preference data to provide feedbac k that is richer than a  X  X ere X  consensus ranking may prove to be a fruitful direction for future group recommender sys-tems and may be the key to providing accurate, stable and unambiguous ways of separating good choices from bad. We thank Meinolf Sellman, Claire Mathieu, Warren Schudy, and David Laidlaw for their helpful comments on our sys-tem, Arjun Guha for his help testing and supporting it, and Pascal Van Hentenryck for his assistance optimizing the lo-cal search algorithm. This work is partially supported by th e NSF. Baskin X  X  work was conducted at Brown University. [1] K. J. Arrow. Social Choice and Individual Values . Yale [2] V. Campos, M. Laguna, and R. Mart  X  X . Scatter search [3] I. Charon and O. Hudry. A branch-and-bound [4] W. D. Cook, B. Golany, M. Penn, and T. Raviv. [5] C. G. Garcia, D. P  X erez-Brito, V. Campos, and [6] G. Huang and A. Lim. Designing a hybrid genetic [7] A. Jameson. More than the sum of its members: [8] J. Kemeny. Mathematics without numbers. Daedalus , [9] M. Laguna, R. Marti, and V. Campos. Intensification [10] F. Lorenzi, F. Santos, J. Paulo R. Ferreira, and A. L. [11] J. F. McCarthy and T. D. Anagnost. MusicFX: an [12] O. Nierstrasz. Identify the champion. Pattern [13] J. Petit. Experiments on the minimum linear [14] G. Reinelt. LOLIB, 1997. http://www.iwr.uni-[15] D. Saari and F. Valognes. Geometry, voting, and
