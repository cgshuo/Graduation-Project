 In this report, we briefly review the second Intern ational Workshop on Multi-Relational Data Mining (MRDM-03), which was organized by the authors and held in Washington , D.C. on August 27th, 2003 as part of the workshop program o f the ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-03). the goal of the workshop was to bring together researchers and practitioners of Data Mining and interested in methods and applications of findi ng patterns in expressive languages from multi-relational, complex and/or structured data. Multi-relational learning and data mining Multi-Relational Data Mining (MRDM) is the multi-d isciplinary field dealing with knowledge discovery from relatio nal databases consisting of multiple tables. Mining data which co nsists of complex/structured objects also falls within the sc ope of this field, since the normalized representation of such objects in a relational database requires multiple tables. The field aims a t integrating results from existing fields such as inductive logi c programming, KDD, machine learning and relational databases; pro ducing new techniques for mining multi-relational data; and pr actical applications of such techniques. Typical data mining approaches look for patterns in a single relation of a database. For many applications, sque ezing data from multiple relations into a single table requires muc h thought and effort and can lead to loss of information. An alte rnative for these applications is to use multi-relational data mining . Multi-relational data mining can analyze data from a mult i-relation database directly, without the need to transfer the data into a single table first. Thus the relations mined can re side in a relational or deductive database. Using multi-relat ional data mining it is often also possible to take into accou nt background knowledge, which often corresponds to views in the database. Present MRDM approaches consider all of the main da ta mining tasks, including association analysis, classificati on, clustering, learning probabilistic models and regression. The p attern languages used by single-table data mining approach es for these data mining tasks have been extended to the multipl e-table case. Relational pattern languages now include relational association rules, relational classification rules, relational decision trees, and probabilistic relational models, among others. MRDM algorithms have been developed to mine for patterns expressed in relational pattern languages. Typically, data mining algorithm s have been upgraded from the single-table case: for example, d istance-based algorithms for prediction and clustering have been upgraded by defining distance measures between examples/instanc es represented in relational logic. MRDM methods have been successfully applied across many application areas, ranging from the analysis of bus iness data, through bioinformatics (including the analysis of c omplete genomes) and pharmacology (drug design) to Web mini ng (information extraction from text and Web sources). The aim of the workshop was to bring together resea rchers and practitioners of data mining interested in methods for finding patterns in expressive languages from complex / mul ti-relational / structured data and their applications. It was the second of its kind, following the first workshop on Multi-Relatio nal Data Mining, held at SIGKDD 2002. In total, around 50 p eople attended the workshop which consisted of one invite d presentation and 10 contributed papers which are su mmarized in the following. In his invited talk, Raghu Ramakrishan set the scen e for the subsequent presentations, identifying opportunities and challenges for the field from the perspective of databases. I n the remaining contributed papers, it became clear that compared t o the early days of multi-relational learning and learning in l ogic, and also in comparison to past year X  X  workshop, the field has a gain broadened in scope and has already started addressi ng some of the challenges presented in the invited talk. The cont ributed papers can be grouped along four topics: the use of probab ilistic models, scalability issues, propositionalization, and theo ry of multi-relational data mining. Even though the characteristic capability of multi-relational methods is being able to process multiple interrela ted tables (first-order representation), it has become quite obvious in recent years how powerful these methods can become if probabilis tic modelling capabilities are added. This line of rese arch includes relational variants of different kinds of graphical models, as exemplified by several papers in the workshop. A first contribution, Prolog for First-Order Bayesian Networks: A Meta-interpreter Approach (H. Blockeel), was concerned with multi relational extensions of Bayesian Belief netw orks. the paper demonstrates that using a meta-interpreter approach in Prolog, it is possible to represent such networks within the s tandard language of logic programming, thus offering a part icular is simple point of comparison for other approaches to relational Bayesian networks have been proposed previously. In A Structural GEM for Learning Logical Hidden Markov Models (K. Kersting, T. Raiko, L. De Raedt) the authors a re concerned with another kind of graphical model, nam ely logical hidden Markov models. These models are capable of m ore compactly representing structured phenomenon, but t heir structure has so far proven difficult to learn. The authors present a novel structure learning algorithm based on general ized expectation maximization combined with structure se arch, and show its effectiveness in learning logical HMMs. A third paper, Collective Classification with Relational Dependency Networks (J. Neville, D. Jensen), dealt with the task of Collective classification, i.e., exploiting the dependencies in a network to improve classification. In this context, the authors present relational dependency networks, a kind of u ndirected graphical model that extends prior work on simple d ependency networks to make it applicable to the relational ta sk of collective classification. In empirical experiments, this mode l indeed outperformed prior approaches such as relational pr obability trees. Finally, even though it does not directly deal with probabilistic models, the paper A Simple Relational Classifier (S.A. Macskassy, F. Provost) provides an interesting coun terpoint to the three other papers, and that it presents a very sim ple classifier, the Relational Neighbor (RN) classifier, that predicts only based on class labels of related neighbors, using no further learning. Interestingly, when compared to more complex approa ches such as probabilistic relational models or relational pr obability trees, the RN approach perform surprisingly well and that suggests itself as a baseline method for judging more complex relat ional learners. Scalability to larger and more complex data sets ha s always been an issue in multi-relational learning, and is becom ing even more important for very large challenge problems such as link discovery or discovery in biological domains. Appro aches to scalability try to improve the basic algorithms, re duce the data in amount or complexity, or resort to propositionaliza tion in order to use fast propositional learners. In the paper Efficient Multi-relational Classification by Tuple ID Propagation (X. Yin, J. Han, J. Yang) the authors propose a ve ry basic optimization technique for much relational le arners. Given that multi-relational learning involves multiple j oins between several tables, the cost of join operations may bec ome a dominating element in runtime complexity. The autho rs address this point with a particular method of propagating tuple IDs to dependent relations, thus eliminating the need to a ctually perform joins during the learning run in certain cases, res ulting and in very significant speed up. The paper Scaling Up ILP to Large Examples: Results on Link Discovery for Counter-terrorism (L.R. Tang, R.J. Mooney, P. if Melville) addresses the issue of scaling to very la rge and complex background knowledge as it naturally arises in the task of link discovery. The paper shows that existing ILP (induc tive logic programming) systems, in particular based on bottom -up search, are not well equipped to handling such tasks, and p resents a novel algorithm that combines both top-down and bottom-up elements. On a standard benchmark problem, the new approach s how significant gains in efficiency. In Towards feature selection for disk-based multirelat ional learners: a case study with a boosting algorithm (S. Hoche, S. Wrobel), the authors examine an approach to feature selection in multi-relational learning that exploits the dynamic s of a boosted learning algorithm. The approach monitors the devel opment of boosting X  X  classification margin, and brings in new features/relations whenever margin growth slows dow n. The paper shows that significant efficiency can be gained if introduction of features takes into account which relations have al ready been used, compared to strategy that simply orders featu res according to heuristic value. With respect to propositionalization, in Structural logistic Regression for Link Analysis (A. Popescul, L.H. Ungar), the authors show that logistic regression can successfu lly be upgraded to the relational setting by coupling it with relat ional feature generation and propositionalization. In their appro ach, propositionalization is not done a priori, but cons titutes an integrated part of the algorithm X  X  search. The pape r shows that the resulting approach is suitable for the task of link prediction, in particular for predicting citations as found in Cit eSeer. In contrast, in Constraint-Based Relational Subgroup Discovery (F. Zelesny, N. Lavrac, S. Dzeroski), a preprocessi ng approach to propositionalization s taken. To make this approach feasible, it is based on a particular individual-centered represent ation which allows very detailed control over the propositional ization that is performed. The authors show that by incorporating a dditional constraints both into the generation of features an d into the rule learning algorithm, the task of relational subgroup discovery can successfully be addressed. Last, but certainly not least, the workshop has fea tured a theoretical contribution adding to the understandin g of hypothesis and pattern spaces in much relational learning. In Towards a Formal Framework for Mining General Patterns from O rdered Data (G. Casas-Garriga) an analysis of mining order and collections of data such as sequential databases or time-series data is presented. The analysis is based on the idea of using closures of Galois connections taken from formal concept analys is. The paper contributes a new approach and shows that it is cap able of exactly deriving the closed sequential patterns found by re cent algorithm. This workshop brought together an international com munity that historically has been split across different confer ences and workshops, and has thus reached one of its central goals: to further research on multi-relational and structural problems irrespective of origin and community. We certainly hope that the momentum gained by this second workshop will contin ue to foster close cooperation between all researchers in terested in this topic from different perspectives. This summary certainly cannot do justice to the int eresting contributions that were presented at the workshop. The reader is therefore encouraged to consult the workshop web si te at http://www-ai.ijs.si/SasoDzeroski/MRDM2003/, where electronic copies of all papers can be found. . This paper was partially supported by DFG grants of the third author (WR 40/1-3, \Active Learning", and WR 40/2-1,  X  X ybrid Methods for heterogeneous information spaces X ). Saso Dzeroski is a Senior Scientific Associate of t he Department of Intelligent System, Jozef Stefan Institute, Ljub ljana, Slovenia. His research interests include among others inducti ve logic programming (ILP) and relational data mining (RDM). He was involved in several international projects related to ILP and was the scientific coordinator of ILPnet2: The Network of Excellence in ILP. He was co-chair of the Seventh and Ninth In ternational Workshops on ILP (ILP-97 and ILP-99) and co-chair o f The Sixteenth International Conference on Machine Learn ing (ICML-99). He has also co-organized a number of events re lated to the topic of RDM, including the Summer School on Relati onal Data Mining, held in Helsinki in August 2002. He is the co-author/coeditor of three books in the areas of ILP/ RDM: Inductive Logic Programming: Techniques and Applications, the first authored book on ILP; Learning Language in Logic, c oncerned ith learning from natural language resources; and final ly the book Relational Data Mining. Luc De Raedt is presently a professor of computer s cience at the Albert-Ludwigs-University, Freiburg, Germany, where he chairs the Machine Learning Lab since 1999. Before moving to Freiburg, he was a part-time senior lecturer and po stdoctoral researcher at the Katholieke Universiteit Leuven, B elgium, where he also obtained his Ph.D. thesis in 1991. He was a coordinator of the European ESPRIT projects on Inductive Logic Pro gramming (1992-1999) and the key organizer of ECML-PKDD 2001 . His current research interests lie in the areas of mult i-relational data mining, inductive logic programming, constraint-bas ed mining and inductive databases and their applications to b io-and chemoinformatics. Stefan Wrobel is a professor of computer science at Univ. of Bonn and institute director at Fraunhofer AIS in Sankt A ugustin/Bonn, Germany. Before moving to Bonn in 2002, he had been professor of computer science at Univ. of Magdeburg. He has been active in machine learning and data mining research since 1986. He has (co-)organized several conferences and workshops (e .g. ILP-94, ECML-95, LWA-99, MRDM-02). He is an action editor o f the Journal of Machine Learning Research and an elected founding member of the International Machine Learning Societ y (IMLS). He is a member of the management board of KDnet, th e European network of excellence on Knowledge Discovery, and h as participated in several other European projects on machine learning and data mining. Among his research intere sts are scalability and local discovery, especially in mult irelational learning. 
