 Given a drug under development, what are other drugs or bioch em-ical compounds that it might interact with? Early answers to this question, by mining the literature, are valuable for pharma ceuti-cal companies, both monetarily and in avoiding public relat ions nightmares. Inferring drug-drug interactions is also impo rtant in designing combination therapies for complex diseases incl uding cancers. We study this problem as one of mining linguistic cu es for query expansion. By using (only) positive instances of d rug interactions, we show how we can extract linguistic cues whi ch can then be used to expand and reformulate queries to improve the effectiveness of drug interaction search. Our approach int egrates many learning paradigms: partially supervised classificat ion, asso-ciation measures for collocation mining, and feature selec tion in supervised learning. We demonstrate compelling results on using positive examples from the DrugBank database to seed MEDLIN E searches for drug interactions. In particular, we show that purely data-driven linguistic cues can be effectively mined and ap plied to realize a successful domain-specific query expansion frame work. H.3.1 [ Content Analysis and Indexing ]: Linguistic processing; H.3.3 [ Information Search and Retrieval ]: Query expansion Algorithms Text mining, domain-specific query expansion, partially su pervised classification, collocation, SVM, syntactic parsing Given a drug under development, what are other drugs or bioch em-ical compounds that it might interact with? History abounds with instances where this question had been investigated incomp letely, causing severe personal, monetary, and professional losse s. Two recent examples serve to illustrate this aspect well. In Sep 2004, drug maker Merck voluntarily recalled their anti-inflammatory drug Vioxx because they discovered that patients taking Vioxx faced he i-ghtened risk of heart attacks. In May 2009, it was discovered that older men using the Flomax drug (to address their urinary tract problems) are twice as likely to experience  X  X loppy iris synd rome, X  a condition that can cause inflammation around the eye, retin al de-tachment, and other serious side effects [2]. Thus there is g reat in-terest in mining for drug interactions before product devel opment, clinical trials, and market releases.

Formally, a drug interaction can be defined as  X  X he pharmaco-logical or clinical response to the administration or co-ex posure of a drug with another substance that modifies the patient X  X  res ponse to the drug X  [38]. While the intent of inferring drug interac tions is often to avoid them, sometimes it is actually desirable to en courage such interactions. For instance, in treating complex disea ses such as cancers [35], multiple, or multi-component, drugs are us ually ad-ministered in order to enhance combinatorial selectivity [ 12]. Here the different components work cooperatively to inhibit (or activate) a protein or protein network of interest in a diseased tissue , but are not particularly toxic for normal tissues.

Many computer-aided systems for exploring drug interactio ns have been established for clinical decision making. One suc h sys-tem [20] uses the CYP3A cytochrome (a key component of many drug metabolism pathways) as the focal pont to rank potentia l drug interactions. Another interesting system exploits the inh erent net-work structure of drug interactions [28]. The key issue in th ese systems (and all others) is the completeness of their drug interac-tion information and ensuring that they stay current with pu blished literature. On one hand, it is inconvenient for a clinician t o search the scattered literature for information about a specific dr ug. On the other, database maintainers are concerned with issues of so undness, coverage, and trustworthiness.

The aim of our work is, hence, to design a framework for au-tomatically identifying drug interaction sentences from l arge on-line corpora. Given a specific drug name such as darbepoetin alfa , a naive search for darbepoetin alfa in public corpora often gives a poor starting point, yielding hits such as the usage of darbepo-etin alfa in the treatment of anaemia . By using state-of-the-art query expansion algorithms [30, 31, 44, 45], darbepoetin alfa gets expanded to darbepoetin alfa anemia or darbepoetin alfa cancer , which still leads to results of usage and is unsuitable for dr ug inter-action identification. Even a manually formulated query, li ke dar-bepoetin alfa interaction or darbepoetin alfa use together , gives the result such as  X  X ecombinant human epoetin beta in the treatm ent of renal anemia X  1  X  they still do not cover drug interactions very well. In this paper, we turn to designing a domain-specific qu ery http://www.ncbi.nlm.nih.gov/pubmed/18488073 expansion capability (similar in spirit to [13, 24, 32]) by m ining linguistic cues to combat this lack of specificity.

There are several research issues to be considered. Admitte dly, one way to expand queries is to  X  X earn to expand, X  i.e., to min e lin-gusitic cues from a training dataset and use them to expand fu ture queries. However to conduct such learning, negative exampl es are required and these are quite rare to come by. So the first resea rch issue is to be able to work with only positive examples. Secon d, the precise nature of linguistic cues can involve just a single t erm (e.g., darbepoetin alfa can be expanded to darbepoetin alfa coadminis-tration or a complete collocation (e.g., darbepoetin alfa might get expanded to darbepoetin alfa concomitant use ). Mining cues and collocations is the second research issue and association m easures have to take into account the complexity of syntactic constr ucts in the published literature. Finally, in order for the mined cu es and collocations to be successfully used, they will have to be ra nked so that they prominently accompany positive examples but not n eg-ative examples. Feature selection to help separate out the c ues is hence important.

Our primary contributions are: 1. We present a domain-specific solution to drug interaction 2. We propose a new collocation mining approach which uti-3. We apply our framework on the DrugBank 2 database (which Fig. 1 gives an overview of our framework which is based on tex t mining and data-driven collocation techniques. As stated e arlier, we use linguistic cues for query expansion and aim to identif y new drug interaction sentences which can then seed DrugBank evo -lution. We begin by using existing drug interaction descrip tion sentences in DrugBank as a positive dataset, and search MED-LINE with only drug names as queries. We then aim to construct a negative dataset as a subset of the search results. Since a m an-ually labeled negative dataset is expensive, we construct t he nega-tive dataset by using the partially supervised classification method, specifically the  X  X earning from positive and unlabeled exam ples X  paradigm (a.k.a. the LPU method) 4 [22]. LPU is a classifica-tion system based on positive and unlabeled datasets, and it learns http://www.drugbank.ca http://www.nlm.nih.gov/ http://www.cs.uic.edu/  X  liub/LPU/LPU-download.html Figure 1: Flowchart for our drug interaction identification sys-tem. the negative examples automatically. These positive and ne gative datasets serve as starting points for two types of analysis, as shown in Fig. 1. First, based on these training datasets, we design a novel algorithm to extract cue words that serve as confirming evide nces for drug interaction relations. We use text feature selecti on ap-proaches to extract single-term cues. We also extract multi -word cues by using and assessing 13 different association measur es for collocation mining. All these cue words are used to query-ex pand, to help search for new drug interactions in MEDLINE. Meanwhi le, the new search results from the expanded queries are segment ed into sentence level units and classified by a state-of-art SV M, which is trained on the initial data sets (this is their second use, referred to earlier). Experimental results show that our system works i n an ef-fective and efficient manner. We perform multi-faceted eval uations. For instance, we show that the negative training dataset aut omati-cally generated is comparable to a manually labeled one and a ny differences do not have any influence on the accuracy of the ov er-all mining process. We also compare our findings with informa tion about existing drug interactions in DrugBank. Query expansion has a rich history of background research. T radi-tional query expansion uses term relationships between the original term and the expanding term. Global analysis [1, 17, 36] empl oys global statistical information gathered based on co-occur rence in-formation from the entire collection, whereas local analys is [30, 31, 44, 45] is conducted using approaches modeled after pseu do-relevance feedback, i.e., using the top ranked relevant doc uments. Some other approaches [4, 7, 14, 42] mine logs of past query us -age to construct term relationships. Significant work has al so gone into incorporating external knowledge [3, 15, 23, 25]. A rev iew of ontology-based query expansion is given in [3]. Works such a s [19, 25, 41] use collocation techniques from NLP which are also ba sed on term-term co-occurrence information. In many of these wo rks, frequency of co-occurrence is often used as a surrogate for r ele-vance and this leads to both false positives and false negati ves [33]. This is especially true in drug interaction search. A detail ed com-parison with our approach and other query expansion methods is shown in Table 1. As is clear we aim for an automated, agnostic method that exploits local linguistic cues. The training im parted to our system from drug interaction sentences endows it with the domain-specific query expansion facility. Other domain-sp ecific approaches such as [13, 24, 32] are either focused on differe nt ap-plication needs and/or they do not exploit collocations as h eavily as done here. The most important part of our system involves the extractio n of linguistic cues which is covered in detail here. We employ three criteria functions to rank all the tokens/te rms ap-pearing in the whole dataset. We classify sentences into two cat-egories: positive and negative, according to whether they c ontain any drug interaction information. We consider the top 50 tok ens ranked by each method as our single-term cues.

Mutual information (MI): The mutual information between term t and category c is given by:
Fisher kernel: We use the variant of the Fisher kernel as defined in [5], where the F-score for the i -th term is defined as:
Here, n + and n  X  are the number of positive and negative sen-tences in the training dataset, x (+) j,i and x (  X  ) j,i ture value in the j -th sentence in the positive and negative datasets, weight computed across the whole dataset, the positive data set, and the negative dataset, respectively. The term weighting sch eme thus influences the Fisher kernel; in our experiments, we use a sim ple binary weighting scheme so that the weight for a term is 1 if it appears in the sentence, 0 otherwise.

Relative frequency: The relative frequency rf for the i -th term was proposed in [21] as a ranking function: where a i is the number of positive sentences in which this term appears, and c i is the number of negative sentences it appears in. Multi-word cues, such as bigrams, require more sophisticat ed means than presented above. We extend collocation mining approaches from NLP to extract bigram cue words, ensuring properties of both coexistence and discriminativeness . Coexistence requires that the two terms in a bigram cue co-occur with each other a lot, while dis-criminativeness means these two terms in the bigram can be us ed to identify the target sentences. Collocation, as a linguistic concept, was introduced by J. R . Firth [11]. There are multiple definitions for what a colloca tion is, drawing upon different perspectives and the needs of specifi c ap-plications. Smadja views collocations as lexical clusters that are domain-specific, context-recurrent, and cohesive [40]. Ma nning and Schutze [26] mention three attributes of typical colloc ations: non-compositionality , non-substitutability , and non-modifiability . Wermter and Hahn [43] provide a useful grouping of collocati ons into three classes:
A collocation useful for drug interaction search is  X  concomitant administration  X , where the occurrence of the collocation with a drug name is likely evidence of a drug interaction sentence.
The typical way to study collocations within a text dataset i s to measure the co-occurrence frequency using statistical a ssocia-tion measures [9] and use this information to identify three cat-egories: surface co-occurrence , textual co-occurrence , and syn-tactic co-occurrence . Surface co-occurrence involves two words that appear within a certain distance, textual co-occurren ce requires that the two words appear within the same textual unit, and sy n-tactic co-occurrence requires the existence of syntactic r elations between the terms. In our study, we use the restrictive notio n of syntactic co-occurrence since it avoids setting a arbitrar y distance for surface co-occurrence, and also avoids indirect and acc idental co-occurrences. Further, compared to superficial co-occur rences, terms that are physically close to each other could be lingui sti-cally far apart, and hence should not be considered together as co-occurrence, whereas terms that are linguistically clos e could be physically remote. In the sentence  X  X imultaneous co-admin istration of cyclosporine significantly increases blood levels of sir olimus X , the word X  X o-administration X  is not close to the word  X  X ncre ases X , but serves as a nominal subject, and this combination is quit e fre-quent in drug interaction sentences (see below).
To obtain syntactically bound co-occurrence information, we uti-lize dependency parsing, specifically using the Stanford ty ped de-pendency parser 5 [27]. We use collapsed typed dependencies (a.k.a. grammatical relations) to represent specific co-occurrenc e patterns, such as adjective + noun , adverb + verb , etc. However, we do not retain all possible collapsed typed dependencies, but o nly those with grammatical relations like obj , dobj , iobj , pobj , subj , nsubj , nsubjpass , csubj , csubjpass , amod , advmod , and nn 6 . A typical dependency parse of a sample sentence from our positive data set is shown in Fig. 2.
 Figure 2: Dependency parse from the positive sentence  X  X i-multaneous co-administration of cyclosporine significant ly in-creases blood levels of sirolimus X .

We treat grammatical relations as 2-tuple co-occurrence pa irs, and store them into a co-occurrence database as candidates f or bi-gram cues. We build 2-tuple co-occurrence records for both p osi-tive and negative datasets. As an example, 2-tuples from a sa mple sentence are shown in Table 2. Moreover, all the words are sto red in lemmatized format, since words in the sentences could be i n in-flected forms. Lemmatization is used (e.g., synchronized is lemma-tized to synchronize ) to conflate these forms to a single bigram. Table 2: The 2-tuple co-occurrence database with a positive sample sentence.  X + X  means the sentence comes from the posi-tive dataset.
 http://nlp.stanford.edu/software, V1.6 http://nlp.stanford.edu/software/dependencies_manua l.pdf
By parsing all sentences from the training datasets, we crea te a syntactic co-occurrence database consisting of 2-tuples as can-didates. We propose an extended collocation model to extrac t bi-gram cues from the co-occurrence databases. As we mentioned earlier, words in a bigram cue must have both co-existence an d discriminativeness properties. Since traditional colloc ation mining approaches only guarantee the two terms co-exist with each o ther, we extend these approaches to make cues useful for identifyi ng specific drug interaction relations.

We look beyond simple co-occurrence frequency and evaluate various association measures that scale it w.r.t. marginal frequen-cies. In overall, we investigate 13 association measures: t he base-line co-occurrence frequency from the positive dataset and the 12 association measures from Table 5.

The measures from Table 5 can be understood in the context of contingency tables [9]. Table 3 depicts the traditional c ontin-gency table capturing overlaps in occurrences of two terms a cross sentences. To account for both positive and negative instan ces of drug interaction sentences, we create two virtual words:  X  pos  X  and  X  neg  X , and we make the assumption that any 2-tuple in the pos-itive co-occurrence database automatically collocates wi th  X  X os X , and that any 2-tuple in the negative database virtually coll ocates with the term  X  X eg X . Thus we  X  X ift X  the traditional bigram co ntin-gency table into a trigram table as in Table 4. The entries of t his table X  X .e., observed and expected frequencies X  X irectly f eed into the definitions of the association measures (see Table 5). Table 3: Traditional contingency table for measuring collo ca-tion between w 1 and w 2 . Table 4: Extended contingency table with virtual words "pos " and "neg". For O ijk , i , j , k means w 1 , w 2 and virtual words, respectively. A trigram or other higher order n -gram consists of n words. Al-though these words are not required to be sequential or next t o each other, we require that any two of them are connected by a valid grammatical relation. The process of finding trigrams and ot her high order n -grams is similar to the one described earlier for bi-grams. We first construct n -tuple co-occurrence databases, record-ing the n -gram candidates and their frequencies in both positive and negative datasets. We then import the same concept of vir tual words  X  X os X  and  X  X eg X  and change the n -gram cue mining problem to an (n+1) -gram collocation mining problem. We use association Table 5: Modified association measures for mining bigram cue s from the extended trigram contingency table (by adding the virtual words as the third term) measures to rank all these candidates, and high scoring coll oca-tions will be selected as valid cues. While the construction of bi-gram candidates was relatively straightforward, the const ruction of n -gram cues is more involved.

N-tuple concatenation : We construct n -gram candidates based on the original grammatical relations, which consist of onl y two words in each relation. When two grammatical relations shar e one word, they can be linked using the shared word as a pivot. This word linkage method is also used in [39] to mine traditional c ollo-cations from a single dataset. Without additional restrict ions, the number of n -tuples using the word linkage method could be pro-hibitively large. Toward this end, we require that all conca tenations be performed in the same sentence, i.e., only grammatical relations from the same sentence can be linked. This restriction immen sely prunes the number of candidate n -tuples. We give an example of the concatenated 3-tuples in co-occurrence database in Tab le 6. The eight 3-tuples are constructed based on the seven 2-tuples i n Ta-ble 2. As we can see, the number of the 3-tuples does not increa se too much due to the single sentence restriction.

For the n -tuple concatenation case, we generalize in the obvious way the 3-tuple example above: n -tuples are derived from the lower order (n-1) -tuple lists again maintaining the sentence restriction, see Alg. 1. For example, simultaneous co-administration in Fig. 2 can be extended to the candidates of simultaneous co-administration cyclosporine or simultaneous co-administration increase . At each level, by introducing the virtual words of  X  X os X  and  X  X eg X , t he n -gram (n  X  3) cue mining problem is lifted into a (n+1) -gram collo-cation extraction problem. The contingency table is extend ed sim-ilarly and the association measures from Table 5 are similar ly gen-eralized. For example, all the association measures in Tabl e 5 for the bigram cue mining can be easily extended for the trigram: For the equations 1, 3, 5, we still process all the cells in the con tin-gency table in the same way; For 2,4,6,7,8 and 9, we only need t o replace O 111 and E 111 with the observed frequency and expected Table 6: The 3-tuple co-occurrence database with a positive sample sentence.  X + X  means that this sentence comes from the positive dataset, and SID is short for  X  X entence ID X .
 Algorithm 1 : Level-wise n-tuple concatenation algorithm. frequency for the same cells in the trigram contingency tabl e where all the words co-occur. For Dice and Jaccard in 10 and 11, we ap ply the same idea from the set theory; For 12, a higher order odds-ratio should be used. Finally, as described in Fig. 1, an SVM classifier is used to cl assify search results from the expanded queries, thus speeding up d rug interaction sentence identification. Joachims [18] highli ghts the many reasons why SVMs are promising algorithms for text clas -sification: 1) the high dimensionality of representation sp aces can result in overfitting for some other classifiers; 2) in text ca tego-rization, few features are irrelevant; 3) the feature vecto rs contain too many zero entries; and 4) most text categorization probl ems are linearly separable. In our experiments, we use SVMlight a linear kernel (which have been shown to outperform other ke r-nels [46]).

Most text categorization implementations work with pre-pr ocessed input, such as mapping to a bag of words (BOW) representation and weighting the document (sentence) vectors suitably. We opted to not use stemming, since terms could play very different ro les in identifying drug interactions even though they might have t he same stem 8 . For example, in the sentence http://svmlight.joachims.org/, version 6.02
Stemming is much more aggressive than lemmatization, e.g., re-ceiving is changed to receive after lemmatization, but to receiv after being stemmed. Stemming is usually used when receiving and re-ceived need to be treated as a single form. Table 7: SVM performance with different combinations of weighting schemes and kernels (F:F-measure, P:Precision, R:Recall) the combination of use and receiving (as a present participle) strongly hints at being treated with two different drugs simultaneou sly, but the stem receiv could be aquired by stemming a normal verb re-ceive , which is rarely used when expressing two drug treatments at the same time. From the training datasets, only 31 sentences con-taining receive in the positive dataset are classified positive (0.7%), whereas 131 sentences have receiving as a present participle de-scribing patient(s) (3.3%). Conversely, in the negative dataset, 224 instances contain receive (4.4%), whereas 21 sentences have re-ceiving describing patient(s) as a present participle (0.4%). This demonstrates that authors prefer to use the present partici ple form receiving to express drug interaction. For term weighting, we in-vestigate four different methods: binary, term-frequency (tf), (tf-idf), and (tf-rf). All these weighting schemes are similar t o the concepts from traditional information retrieval domain. I n the last tf-rf scheme, rf has the same meaning of relative frequency a s in Section 4.1.
The DrugBank database contains 4772 drug entries (a.k.a. dr ug cards) corresponding to more than 12,000 different trade na mes and synonyms. Among all these drugs, more than 1350 are FDA ap-proved small molecule and biotech drugs, and 3243 are experi men-tal drugs. However, only 1036 of these 4772 entries contain d rug Table 10: Some of bi-gram cues from extended collocation min -ing Table 11: Some of tri-gram cues from extended collocation mining. Tri-grams which are just simple extension of bi-gra m cues have been removed. interaction descriptions (short paragraphs) and we focus o n these drugs.

The 1036 drug entries in DrugBank include valid webpage link s in the column interaction_insert . We retrieved all of these web-pages about detailed drug interactions, extracted plain te xt using the HTML parser tool 9 , and segmented them into sentences us-ing the LingPipe 10 toolkit. The total number of the sentences ex-tracted in this manner were 9407. To produce a high-quality t rain-ing dataset, we created a simple drug name dictionary using D rug-Bank X  X  Generic Name , Brand Name , and Synonyms fields, and re-moved all sentences that do not have any entry from this dicti onary. This reduced the number of valid positive sentences to 3900. For instance, from the description paragraph for the drug Nicotine : we see that the first sentence is a valid drug interaction sent ence but the second one merely gives a warning about required dose adj ust-ment due to the interaction.
For the purpose of evaluation we generate negative examples of drug interaction sentences using both the LPU method and man ual annotation. We first obtained 5141 candidate negative sente nces http://htmlparser.sourceforge.net/ http://alias-i.com/lingpipe/ from the search results by using only drug names. Later, usin g LPU, 45 sentences were treated as positive and removed autom at-ically; in the manual labeling approach, about 132 positive sen-tences were removed (2.56% of 5141). Finally we harvested 50 96 negative sentences through the LPU method, and 5009 manuall y labeled negative sentences in total.
As discussed earlier, for identifying single term cues, we u tilized three measures as described in Section 4.1: mutual informat ion, fisher kernel and relevance frequency. Table 8 shows that all these measures mined single term cues admirably. Since these rank ing lists share many of the same terms, especially in the top port ions of the lists, we use the union of the top 50 terms from each list as our single-term cues (consisting of 53 cue words after remov ing stop words and strong domain-related terms). 92.5% of all th ese single-term cue words are recognized as strong evidence wor ds for identifying drug interaction during a manual check.

For mining multi-word cues, we explored both basic bigrams a nd higher order n -grams (n  X  3). We first parsed all sentences in both positive and negative datasets, and curated a total of 11357 7 gram-matical dependencies. By filtering out 31 trivial relations (e.g.,  X  X et X ,  X  X uxpass X ,  X  X op X , etc.; most of them either are relat ed with stop-words like  X  X he X , or create duplicate connections), a nd re-moving all the bigrams which appear in positive dataset for l ess than 10 times, we retained 83417 of them to construct 2-tuple co-occurrence information. Next, with the concatenation idea from Section 4.3, we retrieved 167302 valid records in the 3-tupl e co-occurrence database. However, by requiring that valid 3-gr am cues must appear in positive dataset for more than 5 times, the num ber of valid 3-tuples in the candidate co-occurrence database is d ramati-cally reduced to 644. Finally, the 12 association measures f rom Table 5, together with the baseline measure of co-occurrenc e fre-quency in the positive dataset, were calculated for both the 2-tuple and 3-tuple co-occurrence databases. Some of the ranked big ram and trigram results are listed in Table 10 and 11, respective ly. Fur-ther experiments revealed that mining higher order n -gram (n  X  4) cues are not necessary for drug interaction search, since al l of them are just simple extension of tri-gram cues.
We compared the classification capability of eight SVM model s with different combinations of two kernels (linear and poly nomial) and four weighting schemes (binary, tf, tf-idf, tf-rf). We e valuated We also conducted a 5-fold cross validation and a leave one out cross validation (LOOCV). Table 7 summarizes the detailed model evaluation results. We observe that the linear kernels with binary weighting and tf-idf weighting provide the best performanc e, and use the former for convenience of implementation. We perform three categories of evaluation. We evaluated the effect of our new collocation mining approach, and also we tested th e quality of the training data labeled by LPU method. We also li sted some representative findings from MEDLINE.
To evaluate our multi-word collocation mining approaches, we employed the n -best evaluation method, which is widely used for evaluating collocation measures [9, 10, 29, 34, 37]. We first scanned all the n -tuples satisfying the threshold requirement (frequency i n positive dataset greater than 5), and generated a human-lab eled set of real cues as C real . For each association measure, we consid-ered the n -tuples from the ranking lists as valid only if they also appear in set C real . Obviously, good association measures will always put the real valid cues near the top of their ranking li sts. Therefore, after scanning the top-n results in the ranking l ists, we draw precision-recall graphs for these measures, by calculating the proportion of valid cues in the n -best list ( precision ) and the frac-tion of the number of valid cues from the n -best list to the size of C real ( recall ). Fig. 3 visualizes the precision-recall graphs using the top 300 lists from each measure. The x -axis represents the pro-portion of the ranking list, while the y -axis depicts the correspond-ing precision (recall) values. The n -best evaluation shows that log-likelihood (Log-lh) and average mutual information (Avg-M I) per-form significantly better than other measures from the preci sion-recall graphs (they are the most top curves), a result consis tent with prior research [8, 29]. Measures such as the Dice coefficient , Jac-card and t-test have performances comparable to the baselin e ap-proach of positive frequency (Freq), while the other measur es per-form poorly. For the rest of this paper, we choose the log-lik elihood method as our association measure.
Our experiments also show that the negative dataset generat ed automatically by the LPU is comparable to the one labeled man -ually, and that the difference between these two methods for con-structing negative datasets has little influence on the final results of cue word mining. We compared the average precision values and also the normalized discounted cumulative gain (nDCG) val-ues [6, 16] of the multi-word cue mining results from these tw o different negative datasets. Average precision is calcula ted by av-eraging the precision values from the rank positions where a valid cue is retrieved, and the nDCG value for the top-p list is calc ulated as nDCG p = DCG p IDCG . Here the DCG is defined as: where rel i is 1 when the i -th n -gram in the list is judged as a valid cue, and 0 otherwise. IDCG means the possible maximum DCG value when all the valid cues are ranked at the top [16].
Table 12 shows that there is no significant decrease of aver-age precision or nDCG values when we use the LPU method to generate the negative dataset. In fact, the final ranking lis ts (top 100) based on these two different negative datasets share ma ny cue words. For the bigram approach, 96 of the top 100 cues are iden ti-cal, and for the trigram approach, 97 of the top 100 are identi cal.
Table 9 depicts some of the results of our analysis, which cla s-sifies all inferred drug interaction sentences into five cate gories. Most of the results are consistent with the original drug int eraction descriptions in DrugBank (same drug, same interaction). So me de-scribe additional interactions (i.e., same drug, but inter actions with new drugs). We also found some interaction description sent ences Table 12: Collocation mining effects of log-likelihood met hod by using different negative datasets (top 100 ranking lists ) Manually labeling 83.84 0.967 85.50 0.971 which disagree with the ones in DrugBank. Among the 4772 en-tries in DrugBank, most of them (3736) have empty drug intera c-tion records, and we found new interaction information for s ome of these drugs. Finally, our approach also identifies drug inte ractions from in-vitro studies, a category often ignored in clinical studies. We have introduced a framework for mining data-driven lingu isti-cal cues and for using these cues to aid querying for drug inte rac-tions. Our famework integrates traditional collocation mi ning with discriminative association with positive/negative train ing instances/ Compared to other systems which require a priori domain knowl-edge, our system seeks to solve this problem with the help of l in-guistic features alone. By identifying many drug interacti ons not currently curated in DrugBank, our experimental results de mon-strate that this is a promising approach.

Since our framework uses only linguistic cue words to augmen t queries, this approach can be re-targeted toward many other domain-specific needs, such as for modeling biochemical interactio ns and subjective opinions. This is one direction of future work. A sec-ond issue we are investigating is to develop more structured , graph-theoretic, representations of linguistic cues from depend ency parses, i.e., beyond simple sets of words as used in collocations. This work is supported in part by a grant from the Institute fo r Critical Technology and Applied Science (ICTAS), Virginia Tech. We thank all the three reviewers for their valuable comments and suggestions. [1] J. Bai, D. Song, P. Bruza, J.-Y. Nie, and G. Cao. Query [2] C. M. Bell, W. V. Hatch, H. D. Fischer, G. Cernat, J. M. [3] J. Bhogal, A. Macfarlane, and P. Smith. A review of ontolo gy [4] B. Billerbeck, F. Scholer, H. E. Williams, and J. Zobel. [5] Y.-W. Chang and C.-J. Lin. Feature ranking using linear s vm. [6] B. Croft, D. Metzler, and T. Strohman. Search Engines: [7] H. Cui, J.-R. Wen, J.-Y. Nie, and W.-Y. Ma. Query expansio n [8] T. Dunning. Accurate methods for the statistics of surpr ise [9] S. Evert. Corpora and collocations , volume A, chapter 58. [10] S. Evert and B. Krenn. Methods for the qualitative evalu ation [11] J. R. Firth. A synopsis of linguistic theory, 1930-1955 . [12] J. Fitzgerald, B. Schoeberl, U. Nielsen, and P. Sorger. [13] G. W. Flake, E. J. Glover, S. Lawrence, and L. C. Giles. [14] B. M. Fonseca, P. Golgher, B. P X ssas, B. Ribeiro-Neto, a nd [15] W. R. Hersh, R. T. Bhupatiraju, and S. Price. Phrases, [16] K. J X rvelin and J. Kek X l X inen. Cumulated gain-based [17] Y. Jing and W. B. Croft. An association thesaurus for [18] T. Joachims. Text categorization with support vector [19] M.-C. Kim and K.-S. Choi. A comparison of [20] J. M. Kovarik, D. Beyer, and R. L. Schmouder. Everolimus [21] M. Lan, C. Tan, and H. Low. Proposing a new term [22] B. Liu, Y. Dai, X. Li, W. Lee, and P. Yu. Building text [23] S. Liu, F. Liu, C. Yu, and W. Meng. An effective approach t o [24] Z. Liu and W. W. Chu. Knowledge-based query expansion to [25] R. Mandala, T. Tokunaga, and H. Tanaka. Combining [26] C. D. Manning and H. Schtze. Foundations of Statistical [27] M. Marneffe, B. Maccartney, and C. Manning. Generating [28] Masataka.T. Network analysis of adverse drug interact ions. [29] B. T. Mcinnes. Extending the log likelihood measure to [30] M. Mitra, A. Singhal, and C. Buckley. Improving automat ic [31] M. Okabe and S. Yamada. Semisupervised query expansion [32] S. Oyama, T. Kokubo, and T. Ishida. Domain-specific web [33] H. J. Peat and P. Willett. The limitations of term [34] P. Pecina and P. Schlesinger. Combining association [35] S. C. Piscitelli and K. D. Gallicano. Interactions amon g [36] Y. Qiu and H.-P. Frei. Concept based query expansion. In [37] D. P. School, D. Pearce, and B. Qh. A comparative evaluat ion [38] C. D. Scripture and W. D. Figg. Drug interactions in canc er [39] V. Seretan, L. Nerima, and E. Wehrli. Multi-word colloc ation [40] F. Smadja. Retrieving collocations from text: Xtract. [41] O. Vechtomova, S. Robertson, and S. Jones. Query [42] X. Wang and C. Zhai. Mining term association patterns fr om [43] J. Wermter and U. Hahn. Collocation extraction based on [44] J. Xu and B. W. Croft. Query expansion using local and [45] J. Xu and B. W. Croft. Improving the effectiveness of [46] Y. Yang and X. Liu. A re-examination of text categorizat ion
