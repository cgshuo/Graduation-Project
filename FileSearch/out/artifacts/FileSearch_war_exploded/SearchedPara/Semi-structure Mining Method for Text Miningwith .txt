 In text mining, when we need more precise information than a word frequencies such as the relationships among words, it is necessary to extract frequent patterns of words with a dependency structure in a sentence. In Japanese, the dependency structure is a chunk-based dependency structure, which is a dependency struc-ture based on a chunk of words as a unit. Some examples of word chunks are verb phrases in Japanese and noun phrases and prepositional phrases in En-glish. For example, Figure 1(a) shows the chunk-based dependency structure of  X  (Japan X  X  premier Abe went to China) X . Generally speaking, a chunk-based dependency structure is represented as a tree structure in which a chunk of words is regarded as one label. This representation enables conventional semi-structure mining algorithms such as FREQT[5,6] to be used. However, the representation causes the following problem. If we want to extract frequent substructures from two trees (a) and (b) in figure 1 based on this rep-resentation schema , substructure (c) is extracted. It is a serious problem that substructure (c) has so few nodes that there is insufficient information about the relationship among words. In Figure 1, relationships such as X  (Abe) X ,  X  (went) X  X nd  X  (China) X  X re not extracted. Consequently, patterns that have too few nodes are extracted.

To solve this problem, we propose a new data structure that represents a chunk-based dependency structure. It is a tree structure in which each node has multiple items rather than one label. The multiple items correspond to the words in a chunk. In addition, we propose a mining algorithm for this data structure. Our mining algorithm is an improved algorithm of the sequential pattern mining PrefixSpan [1,2] . An example of the data structure is shown in Figure 2. Each node has multiple items and each item is a word. In Figure 2, substructure (c) is extracted from two trees (a) and (b). The key point is that in Figure 2, it is possible to extract nodes with more items than those in Figure 1. Substructure (c) in Figure 2 has three nodes, while substructure (c) in Figure 1 has one node. Therefore, our method can extract patterns that have much more information, such as the extracted patterns shown in Figure 2(c).

The remainder of this paper is organized as follows. Sections 2 and 3 introduce, as related work, sequential pattern mining and its algorithm PrefixSpan and labeled orderd tree mining and its algorithm FREQT , respectively. Section 4 explains our method and Section 5 eval uates it. Section 6 summarizes our work. In this section ,we explain briefl y Sequential Pattern Mining.

Let I = { i 1 ,i 2 ,  X  X  X  ,i n } be a set of items. This set of items is also called an el-ement . An element is denoted by ( i 1 ,i 2 ,  X  X  X  ,i m ). An inclusive relation between element e 1 and element e 2 is denoted as e 1  X  e 2 if all items of e 1 are included in e . Since an element is a set of items, it is necessary to sort items in an element in lexical order in advance: it is possible to consider the original order of items if we do not sort them in the element. A sequence is an ordered list of elements. A sequence s is denoted by s = &lt;e 1 ,e 2 ,  X  X  X  ,e l &gt; where e k is an element. The number of items in a sequence is called the length of the sequence. A sequence a subsequence of another sequence  X  = &lt;b 1 ,b 2 ,  X  X  X  ,b m &gt; if there exist integers 1  X  j relationship between  X  and  X  is denoted as  X   X  . A sequence database S is a set of tuples ( sid, s ), where sid is a sequence id and s is a sequence sequence  X  in a sequence database S is the number of tuples containing  X  in the database defined as follows: support S (  X  )= { ( sid, s ) | ( sid, s )  X  S  X   X  s } . A frequent sequence  X  is definded as a sequence whose support is greater than the minimunm support  X  , which is a threshold, i.e., support S (  X  )  X   X  .
Sequential Pattern Mining is defined as the problem of extracting all frequent sequences from a sequence database.

Constraint-based Sequential Pattern Mining is Sequential Pattern Min-ing that uses other constraints as well as minimum support[3][4]. Our proposed mining algorithm is also categorized into this type of constraint based sequential pattern mining.

PrefixSpan is proposed in 2000 as a fast sequential pattern mining algo-rithm[2]. PrefixSpan extracts frequent s equences with a depth-first search by re-cursively executing projection operati ons, which is called Prefix projection. We explain briefly Prefix projection and Prefi xspan algorithm as follows . Given a se-integer m (  X  n )suchas e 1 a, e 2 a,  X  X  X  ,e m  X  1 a, e m a. Moreover, sup-of s basedonitem a . If there is no m , prefix and postfix are not defined. Prefix projection of a sequence database S with item a is defined as the operation that constructs a projected database from the postfixes of sequences based on item a . It adds prefix  X   X  to items that are in the same element as a projecting item. An &lt;a&gt; -projected database S is defined as a database that is projected with item a and is denoted by S &lt;a&gt; . For example, when a sequence database S = { ( sid 1 ,&lt;
PrefixSpan algorithm is as follows: 1. Find length 1-frequent sequences Scan a sequence database S to find frequent items(= length 1-frequent sequences) whose supports are greater than the minimum support. Then, all frequent se-quences are partitioned into subsets tha t have the length 1-frequent sequences as each prefix. 2. Find subsets of length k  X  frequent sequence For k (  X  2), do the following procedure by incrementing k until frequent items can not be extracted.

Extract each subset of the k  X  frequent sequence by finding frequent items from a projected database proj ected corresponding to each ( k  X  1)  X  frequent sequence. In this section ,we explain briefl y Labeled Ordered Tree Mining. A labeled or-derd three is a tree in which each node has one label and which keeps the order among siblings. If a labeled ordered tree  X  is a subset of another labeled ordered tree  X  , it is defined that  X   X  X ncludes X   X  ,denoting  X   X  . A labeled ordered tree database T is a set of tuples ( tid, t ), where tid is an ordered tree id and The support of a labeled ordered tree  X  in a labeled ordered database T is the number of tuples in the database containing  X  defined as follows: support T (  X  )= { ( tid, t ) | ( tid, t )  X  T  X   X  t } . A frequent labeled ordered tree  X  is de-fined as a labeled ordered tree whose support is greater than minimum support  X  , which is the threshold, i.e., support T (  X  )  X   X  . Labeled Ordered Tree Min-ing is defined as the problem of extracting all frequent labeled ordered trees from a labeled ordered tree database corresponding to the minmum support. The number of nodes of a labeled ordered tree t is called the size of a labeled ordered tree t and is denoted as | t | .

FREQT is proposed in 2002 as a fast labeled ordered tree mining algo-rithm[5,6]. FREQT extracts frequent ordered trees by the technique of grow-ing a tree by attaching new nodes only on the rightmost branch of the tree, which is called rightmost expansion. Rightmost expansion was also proposed by Zaki et al.[7]. In this section, we propose a new data structure to represent the chunk-based dependency structure and a mining algorithm for the new data structure. This is a tree structure whose node has a element,that is, a set of items. For example, a chunk such as  X  X ith a depth-first search X  is represented as a node with an element including four items, i.e., (  X  X ith X  ,  X  X  X  ,  X  X epth-first X , X  X earch X  ). In this regard, however, items in the element keep their order.

Since our data structure is not a labeled ordered tree, an existing mining algorithm such as FREQT cannot be applied directly. But, if we transform the data in the following way, we can make the sequential pattern mining algorithm applicable to our data structure. 1. Enumerate elements by traversing the data structure from the root node 2. Assign an index to each node in the enumerated order. As the result, the data 3. Each element has index information about a structure, i.e., (parent, first The transformed data structure is called a semi-structured sequence.
An example of the above transfor mation is shown in Figure 3. The data struc-ture surrounded by the quadrangle in Figure 3 is the data structre of sequential pattern mining. Therefore, the sequential pattern mining algorithm PrefixSpan can be applied to our data structure. However, arbitrary use of PrefixSpan leads Therefore, it is necessary to put a certa in constraint on PrefixSpan. Our min-ing algorithm is an expanded PrefixSpan algorithm with a projection that is constrained in order to extract only connected patterns from the data struc-ture transformed by the method described above. This constrained projection is called a Tree Projection. 4.1 Tree Projection The tree projection of a semi-structured sequence S with item i is a projec-tion constrained as follows. Constraint: The only items included in projected database S &lt;i&gt; are ones that have a path with the items in Proj-Items.
Proj-Items is a stack into which projecting items are pushed. After projec-tion with item i ,theitem i is pushed into the Proj-Items. When the projection with item i has finished, item i is deleted from the projecting stack. The pat-terns of items in the projecting stack are frequent patterns. Figure 4 shows the running example of tree projection with item a (index=0).

Tree projection calls the tree projectio n in the following order:(1).element-projection,(2).child-projection and (3).Level k sibling-projection. After the ex-traction of frequent items on each proj ection has finished, the next projecting item is selected and tree projection is c alled recursively in each projection. We explaineachprojectionasfollows. (1) element-projection with item i is a projection selecting items whose element is equal to the element of the projecting item i . In PrefixSpan, these items are denoted by adding  X   X  X saprefix. (2) child-projection with item i is a projection selecting items whose ele-ment is the child element of projecting item i . Specifically, it operates as follows: 1. Find the index of the first child element of the projecting item i 2. Find the index of the next sibling element of the first child element. 3. Find the index of the next sibling element iteratively As described above, child-projection can extract items that have the parent-child relationship of item i . These items are stored into a p rojected database. Figure 5 shows a running example of child projection. (3) Level k sibling projection with item i is a projection selecting items whose element is a sibling element of the k-th ancestor of the projecting item i . The k-th ancestor A of the element I indicates that there exists a path between an element I and element A and the difference from depth( A )todepth( I )isk-1. The parent element of the element I is 1st ancestor of the element I .The0th ancestor of the element I is I itself. For example, in Figure 3, the 1st ancestor of element ( c, b )iselement( d, a ) and the 2nd ancestor is element ( a, b, c ).
Specifically, it operates as follows: 1. Find the index of the k-th ancestor of the projecting item i . 2. Find the index of the next sibling element of the k-th ancestor. 3. Find the index of the next sibling element iteratively.
 Suppose that d is the depth of the projecting item i from the projection start item. Iterate Level k sibling-projection from k=0 to k= d . As described above, Level k sibling-projection can extract the items that are the sibling elements of the k-th ancestor of item i . Put these items into a projected database. Figure 6 shows a running example of sibling-projection. In this section, we presen t two evaluations: one evaluating the execution time and the other evaluating the statistics of the number of extracted nodes. In particular,we show that our mining method with our new data structure extracts frequent patterns with more nodes than conventional methods.

The dataset was Aviation Safety Report 1 gathered by Japan Airlines Interna-tional Co., Ltd. Dependency parsing by Cabocha 2 is run to one sentence as a unit. In a labeled ordered tree, a segment in Japanese is regarded as a label 3 .In our data structure, a segment is an element and a morpheme in a segment is an item 4 .

No conventional mining method can handle our data structure, so we could not evaluate the execution time of our method in comparison with a conventional method. However, our data structure includes a labeled ordered tree as a subset, that is, a labeled ordered tree is our structure where an element has only one item. In this case, tree projection corre sponds to the rightmost expansion of FREQT. Therefore, we evaluated the ex ecution time of our method based on a labeled ordered tree. Our method is ca lled pFREQT(projection-based FREQT).
Figure 7 compares the execution time by pFREQT and by FREQT 5 based on a labeled ordered tree. The minimum support was two. pFREQT extracted frequent patterns faster than FREQT. I t also projected an item partially cor-responding to the relationship of the projectiong nodes. Therefore, pFREQT used less memory than FREQT when searching for patterns. Figure 8 shows the difference in memory usage for FREQT and pFREQT. Apparently, the more sentences there were to handle, the gre ater the additional memory consumed by FREQT compared with pFREQT. Figure 9 shows the statistics of the number of extracted nodes. We extracted freque nt patterns with more than two nodes. We made five datasets, which had a total of two thousand sentences. We evaluated the meanscore, median and maximal values of the number of extracted nodes. The horizontal axis shows each dataset. The vertical axis shows the number of extracted nodes. Figure 9 shows that for each set of statistics, more nodes are extracted by our method than by conventional methods. The more nodes that can be extracted, the more relationships among words with a dependency struc-ture can be extracted. This paper described a semi-structure m ining method for extracting frequent patterns of words with a chunk-based dependency structure. It also described a new data structure representing a chunk-based dependency structure and a mining algorithm for it. Our method can extract frequent patterns that the conventional methods cannot extract.
 Acknowledgments. We appreciate the cooperation of Takashi Saito and Akira Terada of Japan Airlines International Co., Ltd. This research was funded in part by MEXT Grant-in-Aid for Scientific Research on Priority Areas  X  X -explosion X  in Japan.

