 Modeling user browsing behavior is an active research area with tangible real-world applications, e.g., organizations can adapt their online presence to their visitors browsing behav-ior with positive e  X  ects in user engagement, and revenue. We concentrate on online news agents, and present a semi-supervised method for predicting news articles that a user will visit after reading an initial article. Our method tackles the problem using language intent models trained on histor-ical data which can cope with unseen articles. We evaluate our method on a large set of articles and in several experi-mental settings. Our results demonstrate the utility of lan-guage intent models for predicting user browsing behavior within online news sites.
 H.3.3 [ Information Search and Retrieval ]: Retrieval Models Algorithm, Experiment Online news, article intent models, user, browsing, behavior
Social media has changed the way news are produced and consumed, with well established news publishers having lost large share of their readers. The continuous decline in read-ership is also reflected in revenue, urging news publishers to seek new ways for monetizing their news articles. One of the many ways to do so is to increase the amount of time users spend on a news site. Central in achieving an increased user dwelling time within a site X  X  property is the concept of user  X 
This work was conducted during a three X  X onth internship at Yahoo! Research Barcelona. engagement [3], or quality of the user experience with an em-phasis on the positive aspects of the interaction. Research on this area suggests that enhancing a web page with con-textual information has positive impact on user engagement, and it has led to the development of a range of systems that address this phenomenon [9, 19]. A key ingredient here is to discover the right context for a web page, especially in a setting where user goals might change after the user visits the web page and new content is added continuously.
Context discovery can be cast as a task in the realm of se-mantics, personalization, or collaborative filtering, with the first being the most typical interpretation. Contextual in-formation is drawn from a knowledge base built on a single source, e.g., news, Wikipedia or the web page X  X  source do-main, and typically remains relatively static over time. In the news domain, there is need for systems able to adapt, and discover the right sources of context in a dynamic fash-ion. As a working example, think of one news article an-nouncing a forthcoming football game, and one reporting on the results of the game. In the first article a user might be interested in seeing information about the teams X  setup, whereas in the second in the game highlights. Other exam-ples are news articles reporting great natural disasters, e.g., Haiti X  X  earthquake, or the tsunami in Japan, where users might want to see information about emergency services, the Red Cross, or weather reports.

Browsing behavior far outweighs direct search engine in-teraction as an information-gathering activity [26]. Given so, our focus is to recommend websites as opposed to search results. In contrast with previous approaches [26] which em-ploy contextual sources for modeling a particular user X  X  in-terests, we focus only on textual features extracted from the text of the articles browsed by the user and queries issued within a query session.

The main focus on in this paper is the temporal context discovery task: For a given news article, and optionally a user, the system needs to discover webpages that the user is likely to visit after reading the article. The task is challeng-ing due to data sparsity issues that arise from the inherent volatility of the news domain, and the broad range of user intents, which lead to a heavy tailed distribution of user destinations after they visit a news article. To quantify this claim, we conducted an exploratory experiment. From a set of logical sessions extracted from query logs we identified web pages that are news articles, and classified them into categories, e.g., Science, Business, Entertainment. For each article we recorded the internet domains of the web pages that users visited after reading a news article, and assigned these domains to the article X  X  news category. We also record the popularity of a domain per category by counting the number of visits to the domain from articles in that cate-gory. Fig. 1 illustrates our findings on users navigational patterns after reading web pages in Yahoo! News. Red circles represent news categories, and white to blue shaded circles represent domains (white denotes least popular, and dark blue highly popular). News categories are laid out in space based on how they are connected to the domains. This results in an inner circle of news categories which forms a perimeter within which lie domains shared by these news categories, and outside of it are domains mostly unique to each category. The outer red dot perimeter includes cat-egories that don X  X  share common domains, i.e., Wikipedia, Yahoo! news, search engines, but share one or two rather  X  X nique X  domains attached to another category. Our find-ings suggest that there is a distinct set of domains where people navigate to depending on the category of the news article they read, forming a heavy tailed distribution of user navigational patterns. These challenges, i.e., data sparsity, and the cold start problem, restrain us from training robust recommendation models for articles that appear in user ses-sions, and make online recommendation virtually impossible for articles with no record in user sessions (we have to wait for at least one user trace).

Our approach to overcome these limitations is to cast the temporal context discovery task as an information retrieval problem, and develop methods for modeling user browsing intent in a query. These methods infer the user navigation patterns, by mapping the current article a users reads to a query into intent space which represents the content of ar-ticles likely to be clicked after the current one. This way, we aim to answer both challenges raised above; First, mod-eling article intent as proxy for user browsing intent helps to smooth out data sparsity issues. Second, modeling arti-cle intent allows for making predictions for unseen articles via the article intent space. Our experiments show that us-ing text-based features and query session trails are able to achieve good performance for the task of temporal context discovery.

We envisage our methods to have concrete applications in enhancing user experience and engagement via dynamic link suggestion, result recommendation, and personalized web content optimization. Such applications can prove valuable to news agents, publishers, and consumers. News providers can leverage this information to generate focused recommen-dations via links to their consumers. In turn, consumers can save time completing their goal as relevant hyperlinks, or snippets from likely to visit web pages, and ads can be displayed on the same web page as the article.

The main contribution of this work is a model which uses historical data for making real-time predictions about the browsing patterns of users, for which little information is needed to be available at prediction time.

The rest of the paper is organized as follows. In the follow-ing section, Section 2, we present related work. In Section 3 we describe the problem definition, in Section 4 we outline our approach to the problem, in Section 5 and 6 we present our modeling and retrieval approaches, in Section 7 we de-scribe our experimental setup, in Section 8 we report on results, in Section 9 we further discuss our findings, and in Section 10 we conclude.
 Figure 1: News categories show distinct patterns of where users navigate next after reading a news arti-cle. Red circles denote news categories, blue shaded circles denote internet domains; darker shades rep-resent targets from many news categories. The two dark blue domains in the middle correspond to Wikipedia, and Yahoo! News.
The increased availability of query sessions coming from the logs of search engines has grown a research area that deals with studying, mining and making use of trails and user actions to improve search [12]. Search trails are se-quences starting on a query and ending on a destination page, with a series of intermediate pages browsed by the user. For instance, these trails are a useful signal in order to learn a ranking function [1, 4] or to display the trails directly to the user [23] to help in the information seeking process. These approaches try to employ the query session information as implicit feedback in order to incorporate it into the ranking process. In contrast, our approach is tar-geted towards news article recommendation, using a mixture of the trail pages as a query.

There is an increased attention on techniques to identify the intent behind the query; this is one main challenge for modern search engines [7]. The first query classification was presented by Broder [6], in which queries were labeled as transactional, navigational or informational. However there are more sophisticated approaches, which take into account the multidimensionality of queries [10]. Approaches to clas-sify web queries are mostly based on click-through data [15]. These methods are a key factor into identifying the real user X  X  goals, and their applicability ranges from personaliz-ing search results to predicting ad click-through [2], or search result diversification [8, 21].

Guo et al. [11] look at intent-aware query similarity for query recommendation. Intent is identified in search result snippets, and click-through data, over a number of latent topic models. Our approach di  X  ers in that the intent is modeled to capture the characteristics of the news domain and we do not recommend queries, but rather news articles. We also do not attempt to classify queries into a predefined set of categories, but rather we use the content of the clicked articles as an extended representation of the user intent.
Finally, there exists other possibilities for article recom-mendation, for instance those based on the explore-exploit framework like the one of Li et al. [16]. Those approaches re-quire a significant amount of click-through tra c and in gen-eral are content-agnostic, using as similarity features clicks shared between users.
We cast the problem of temporal context discovery as fol-lows. Given a document  X  2 A , and a set of user sessions T , find a ranked list of documents {  X  } i  X  A that a user is likely to read after reading  X  . The session set is defined as where q 2 Q represents a query,  X  2 A is a document, and o is either a document  X  j 2 A or another query q j 2 Q .
In this work, we reduce the complexity of the problem in two ways. First, we only focus on the news domain. In this respect, documents in A are news articles, and the major-ity of user queries we deal with is of informational type [6]. Second, we focus on methods that use only textual infor-mation derived from the articles X  content. We do not use additional information from query logs or the web graph as signals for ranking, e.g., time spent on each document, hyperlinks between the documents. In particular, we omit the use of hyperlinks because they are not always present in news articles (see Section 1), and can potentially bias the evaluation as they reduce the recommendation space to the articles linked by the current one.

The problem at hand is similar to that of recommending similar articles to the article currently being read. How-ever, in the current setting, the system has to probe user intent and recommend articles not only based on the user X  X  cognitive model at the query issue time, but also on the changes that occur in their cognitive model after reading a news article. This requirement asks for an approach beyond recommending articles which are semantically or topically similar to  X  . In this setting, we face a challenging task as the recommendations have to adapt quickly and incremen-tally to reflect the ongoing process in the user X  X  cognitive model.

To make things more tangible, consider a search session from a user that consists only of queries, and news articles. These query sessions [5] are records of the queries and the ac-tions of the users of search engines, and they contain latent information about their interests, preferences, and behav-iors. Let two users 1 , and 2 issue the same informational query q to a search engine, and then click on a retrieved news article, possibly read it, then return to the search re-sults, and click on another article. In the process, they may choose to refine their query with the current state of their cognitive model which has now possibly changed after vis-iting the retrieved news articles. This iterative process will generate the following traces: In these traces we see user 1 issuing a query, then visiting article  X  1 , then going back to the results page and selecting another article  X  2 . After visiting  X  2 , 1 decided to refine their query and issued q 2 , and continued visiting other arti-cles. A similar process occurs for user 2 , however, the order visits the article is di  X  erent, and also, the position within the trace of the second query is di  X  erent. The temporal con-text discovery task is defined as: predict  X  2 ,...,  X  given q and  X  1 for a user .
Our approach is to estimate a query model  X  q that reflects user X  X  browsing intent, namely, what article the user is likely to read after clicking  X  1 and given their query trail  X  k rationale is that when  X  q is submitted to an index of articles, a retrieval system will return documents that are likely to be read from user k . To this end, our e  X  orts are concentrated on modeling the query  X  q .

A key aspect here is to derive a robust method for mod-eling the user X  X  browsing intent. We build on the intuition that user intent on a news article  X  can be captured by training models on the content of the articles that follow  X  . The rationale is that these models should capture the re-lation between content and patterns of user behavior using the query sessions. The query sessions define links between each article in the intent space. We call these models article intent models (AIMs). Fig. 2 illustrates this idea, and the steps we take afterwards.

Articles for which the system will make predictions do not necessarily exist in the news article pool, or have been recorded in user sessions which leaves them without intent models. We account for this issue by building on the as-sumption that similar articles lead to similar user traces. This way, articles that do not occur in user sessions are as-signed the intent model of the most similar article that has one. This idea also helps assigning intent models to previ-ously unseen articles, and allows coping with an expanding pool of articles.

With the article intent models in place, we estimate the query  X  q using information from either the content of the article, its corresponding intent model, and a mixture of both. For the latter case, we derive several weighting meth-ods which are explained in Section 5.4.

A retrieval system based on a widely used, state-of-the-art information retrieval method receives the query  X  q and returns a ranked list of news articles. We consider two op-tions for this. The first option submits the query to an index of articles, while the second option issues the query to an in-dex of intent models, the ranked list of which is mapped to news articles.

Relevant articles are deemed those that follow  X  in user sessions. In order to ensure that the user has read the article in question, we discard articles in which users spent less than 30 seconds [14]. The system is evaluated on whether it manages to retrieve these relevant articles in early positions.
We present the methods for addressing the steps involved in our approach: (a) Model the news article, (b) model ar-ticle intent, and (c) model queries, which we consider as a mixture model of the first two steps.

We start with a pool of news articles A := {  X  1 ,...,  X  N where N is the size of the pool, and a list T := {  X  1 ,...,  X  Pool of news articles 1 n Table 1: Description of the main symbols we use.
 of user traces  X  k := ( k ,q,  X  1 ,...,  X  l k ), similar to the ones described in Section 3. K denotes the total number of user traces in our database, k := { 1 ,...,K } , k is an anonymized user identifier, and l k is the length of user trace k in clicks. Table 1 contains a list of symbols used throughout the paper.
Articles  X  n are represented as language models drawn from di  X  erent distributions, each one defined over its own event space. To reduce clutter, we refer to all language models as  X  n to denote a vector of language models: For achieving a rich representation of the textual content of the article, we focus on three families of sources for learn-ing language models: (i) the unigrams of the news article, (ii) the named entities therein, and (iii) the time expressions mentioned in the article. We motivate the use of each source in turn.
 Article content. The body of the news article itself is an im-portant source of information for training language models that represent it [20, 24, 27], as witnessed from the success-ful previous work in probabilistic modeling for retrieval. We follow [18, 25] and use entire contents of article body, and title for training a unigram language model.
 Named entities. A great majority of news refer to and discuss people, organizations, and locations. To this extent, we extract named entities, and train a language model per named entity type, i.e., persons, organizations, and loca-tions. The rationale behind is that if an article focuses on a particular named entity, the named entity will occur many times in the article, resulting in a language model that emits this named entity with high probability.
 Temporal expressions. Real world events are central to news reporting, and news articles connect the development of events through time expressions, e.g.,  X  X ast week X ,  X  X n one month X . Using time expressions can help identify articles that discuss the same time period of an event [13]. We group time expressions into three classes, i.e., past , present , and future relative to the article X  X  publication date. A lan-guage model trained on time expressions consists of these three classes, and the probability of emitting a class is pro-portional to the number of time expressions that belong to this class.

For every article  X  n in A we train language models from the three di  X  erent sources we described above: the article content, the named entities, and the temporal expressions. We assume that each article is drawn from three multinomial distributions, each one defined over its own event space E of token occurrences w . We smooth the number of times a token w is present in the article using Dirichlet priors, thus defining the probability of a token w to be generated from the language model n as: where n ( w,  X  n ) is the frequency of token w in  X  n , |  X  article length in tokens, P ( w ) is the a priori probability of w , and  X  the Dirichlet smoothing hyper-parameter [27].
Now, we shift from the content space to the intent space through the user traces in T .An article intent model (AIM)  X  n intends to capture the original user intent by using the articles that the user reads after  X  n as proxy. More formally,  X  n is defined as the combination of the language models of the articles users browsed afterwards, where j is the position of  X  n in trace  X  k , and ( i ) a weighting function dependent on the position of an article within  X  ( i ) is likely to be a exponential decay function, however, due to the sparseness of the dataset we set it to be uniform over all article models.

Noise in query logs, along with data sparsity, i.e., the small number of articles users visit after reading a news article (see Section 7 for a description of our dataset) can lead to poor article intent models. To account for this e  X  ect, we describe a method for assigning more than one AIM to an article. We work as follows. First, we compute the pairwise simi-larity of all articles in the pool that have associated article intent models. Then, we assign each article  X  n avector V of tuples that consist of an article intent model along with the similarity scores of the article intent model X  X  associated article: where (1 ,  X  I n ) denotes the article intent model associated with  X  n , and ( s  X  ,  X  I  X  ) is the article intent model for  X  has s  X  similarity with  X  n .
 Intent models for unseen articles. In many situations, the system will need to map articles that do not exist either in A (e.g., new article is added) or in T (e.g., the article has no logged visits yet) to the intent space. Given that we define all the models over the same event distributions, the method builds on the hypothesis that users reading similar articles are likely to have similar intent, and therefore produce a similar user trace.

Let  X  n be an article with no AIM associated with it, we want to find similar articles to  X  n for which there exist AIMs. If the intent models are generated from an unknown data distribution P (  X  I ), our goal is to find a model  X  I n the marginal probability computed over the whole intent model space is maximized:
We approximate the integral using the finite set of intent models generated from the articles in A :
There are several possibilities for selecting  X  I j ;wemake the assumption that documents with similar language mod-els have similar intent models, and therefore P (  X  I n |  X  sim (  X  n |  X  j ). The article index selected is the one that max-imizes and  X   X  I n =  X  I j . The final intent model is interpolated with the original model as: where  X  is a parameter defining the weight of each language model.

In order to select the most similar intent model in Eq. 1 we create an index of all the language models generated from A , and rank them using  X  n as a query, with the standard symmetric KL-divergence as a ranking function (defined in Section 6).
The previous sections have presented our approach to modeling news articles, and article intent models. We move on how to use them for estimating a query  X  q for a user k A straightforward way is to make the simplifying assump-tion that both the query issued by the user, and the article  X  n they first read are representative for the user X  X  intent. Formally, the estimated query can be written as: where ART denotes the estimation of the query using arti-cle models, and the original query model,  X  q stands for the weight assigned to the query language model  X  q ,  X  i denotes the weights for the di  X  erent article language models i  X  content, named entities, temporal expressions. This user model operates in the vertical dimension in the sense that assumes that people are interested in reading similar articles to the one they first read, because, for example, they want to find more information about the topic of their interest. Although this assumption may stand true for certain users, it ignores the horizontal dimension, namely, users that want to read di  X  erent aspects of the article they first read, or find information related to it but not directly.

We make the hypothesis that article intent models can serve this purpose, namely, model the user intent, for find-ing articles that users are likely to read afterwards. In this respect, we estimate the query  X  q AIM from article intent mod-els associated with the article that the user visited first: where AIM denotes the estimation of the query on article intent models, V n is a vector with article intent models for  X  , and  X  is a weight for each article intent model in V n . The building block of these models depends on user trails extracted from query logs. Query logs are known to contain noise [22], and therefore using article intent models instead of article models may introduce topical shift, possibly de-grading the quality of the list of suggested articles.
A natural way to tackle this problem is to model user intent as a mixture model of the user X  X  query, the first article they read, and article intent models. We define a mixture model for modeling  X  q as  X  q ART + AIM :  X  q where inc is the weight regulating the importance of the user X  X  query, and the first read article.
A straightforward procedure for estimating the weights in Eqs. (2) X (4) is to use supervised learning. In particu-lar, without imposing any restriction in the parameters, the model could assign one weight per article in every trace, which asks for significant amounts of training data. This requirement renders supervised learning unsuitable for an online setting, where the pool of articles expands continu-ously, or where training data is scarce. The approaches we describe next aim at overcoming this problem by producing the query mixture model  X  q ART + AIM without the need for training. They build on knowledge derived from the distri-bution of similarities between the  X  I n vectors. The hypoth-esis is that the semantic similarity between an incoming ar-ticle and its intent models is a good surrogate for regulating weights in query mixture models. To this end, we describe several strategies that create query mixture models for an article model, using one or several article intent models. We separate the two cases of one and many article intent models because of the implications in weighting.
 Merge. We begin with a simple approach, namely, as-sign no weights to the article or to its article intent models, but merge their contents before training language models for content, named entities, and temporal expression. This can be generalized for any number of article intent models we want to consider.
 Pairwise. This technique considers mixture models for an article and its most similar article intent model. We assign the incoming article intent model weight 1 s  X  , and the intent model the weight s  X  , where 0  X  s  X   X  1 is the semantic similarity between them. We also try the reverse, namely, the incoming article weights 1 s  X  , and the intent model s  X  . We refer to this second approach as Pairwise-R . Average. When it comes to add more than one AIM to the mixture model, we face the problem what weight to assign to the incoming article. One way is to assume that the incoming article language model is an article intent model trained only on itself and therefore its weight is set to 1. Then, we enforce the constraint on weights to sum up to 1: where inc = 1, which transforms the weights to: Median. The previous approach makes the assumption that an article model is semantically identical to an article intent model. We try to smooth this assumption by weighting the incoming article proportionally to the set of its article intent models. The weights of similar article intent models show a broad range of values, therefore their median value can be a good indicator for weighting the incoming article. In other words, if the median value is high, then we give preference to the article intent models as they are likely to bear more information, and vice-versa, if the median value is low, then we give preference to the incoming article as it is likely to be more informative for retrieval. Formally: where m () is the median value.
All the formulation presented insofar builds comparable model representations. In order to retrieve articles, repre-sented by either their language or intent models, as a re-sponse to a query  X  q we use the symmetric Kullback-Leibler divergence. This is, given two vectors of models  X  t and  X  Figure 3: Distribution of the date di  X  erence in days between the articles users have clicked in a session, aggregated over all sessions. Positive di  X  erence in-dicates articles published prior to the input article. Showing di  X  erences less than 10 days for clarity. we compute a score as score (  X  t ||  X  n ):= sKL (  X  t |  X  n )( 5) where w is a token from the union of tokens in the respective language models.

In order to recommend articles, we need to rank  X  q with respect to  X  n . In this case  X  q plays the role of  X  t in Eq. 5 and  X  n or  X  I n play the role of  X  n , when we consider the model of the article or its AIM respectively.
 Temporal bias. Our ranking model assumes a uniform dis-tribution over the likelihood of user preference on ranked documents. We examine whether this assumption holds by plotting the time di  X  erence of publication of articles that users visited after reading an initial article. Fig. 3 shows the user preference is biased towards articles published close to the first article they read. It has a strong peak at 0 days, rapidly decreasing in both sides, possibly due to the presen-tation bias in the search results. We model this phenomenon with the standard Cauchy distribution, 1 which introduces a bias towards articles visited shortly after the article at hand:
We experimented with modeling this distribution with a block exponential function, double exponential (Laplace dis-tribution) and we found that among them using the Cauchy distribution gives the best retrieval e  X  ectiveness; see  X  9.
In this section we describe our research questions, exper-iments, dataset and evaluation methodology. Our main re-search question we aim to answer is whether our query mod-els can help in the task of temporal context discovery. We study this question in the following three dimensions: Query modeling What is the e  X  ect in retrieval e  X  ective-Weighting What is the e  X  ect in performance of our weight-Retrieval in intent space Can e  X  ectiveness be improved To answer these research questions, we proceed as follows. First, we compare the three query models we presented in Section 5.3 which use either the query and the incoming article, or the article X  X  intent model, or their combination. We study the e  X  ect of time in retrieval performance using retrieval models with and without temporal bias. Next, we focus on the weighting scheme for generating the query mix-ture models, and compare each of them. Finally, we change our index from articles to article intent models, and use our query models to retrieve article intent models which are then mapped to articles in a post-retrieval stage.

In Table 2 we list the alternatives we consider, along with their corresponding features. Runs that use only the article for modeling the query are denoted with ART, those us-ing only article intent models AIM, and their combination ART + AIM. Query models on temporally biased retrieval modes have a superscript T, and di  X  erent weighting methods are denoted in the subscript. For example, ART + AIM T M is model that uses both the incoming article and the article intent models on a temporally biased retrieval model, us-ing the Median weighting method for generating the query mixture model.
Our dataset consists of 14,180 Yahoo! News items pub-lished in February 2011, and a parallel corpus of query logs from Yahoo! Search. We apply several preprocessing steps. We extract named entities using the SuperSense tagger, 2 and time expressions using the TARSQI Toolkit. 3 The query stream is segmented into several sets of related informa-tion seeking queries, i.e., logical sessions using the technique in [5]. The logical sessions are pruned to contain only queries and articles that exist in our article dataset.
 Our experiments include a training, and a testing phase. We use 75% of the logical sessions for training article intent models for 3,060 articles, and the remaining 25% as ground truth for 434 query test articles.
We assemble our ground truth as follows. From the logical sessions in the test set we consider the first user query and article in the session as our input, and consider every fol-lowing article as relevant to this input. This process results in a ground truth of 511 relevant documents (max/min/avg: 3/1/1.18 documents).

In our experiments we work as follows. Given the user query and the article, we generate a query  X  q with our meth-ods which we then use to retrieve articles from either an index of articles, or article intent models. We treat the user query and the input article equally as in Eq. (2). For query mixture models, we consider one article intent model, the most similar to the input article.

For our experiments we use the Indri framework [17]. We set the weights in an independent held-out data-set as fol-lows: for named entities to 0.1, for temporal expressions to 0.1, and for the article content to 0.6. The smoothing pa-rameter for Dirichlet smoothing is set to  X  = 2500, except otherwise stated. For articles without article intent mod-els, we set  X  =0 . 5. We report on standard IR measures: precision at 5 (P@5), mean reciprocal rank (MRR), mean average precision (MAP), and r-precision (Rprec). Statisti-cal significance is tested using a two-tailed paired t-test and is marked as N (or H ) for significant di  X  erences for  X  = . 01, or
M (and O ) for  X  = . 05.
In this section we report on the results of our three ex-periments: (a) query models and temporal bias in retrieval, (b) weighting schemes for generating query mixture models, and (c) retrieval on article intent model index.
 Query modeling. In our first experiment, we test our three query modeling methods we described in Section 5.3: (a) the incoming article (ART), (b) the article intent models (AIM), and (c) their combination (ART + AIM). These models are tested on two retrieval models, one with, and one without temporal bias. Models on the retrieval model with temporal bias are denoted with a superscript T. Our baseline is set to the method that uses only the incoming article (AIM, and ART T ).

In Table 3 we report on the performance of these systems with (top-half) and without (bottom-half) temporal bias in the retrieval process. In the retrieval setting without tem-poral bias, the baseline proves strong, and outperforms both AIM, and ART + AIM. In the retrieval setting with tem-poral bias the picture changes. ART T outperforms AIM in MAP, MRR, and P@5. ART + AIM T , the combination of incoming article, and the most similar article intent model, yields the best run, and outperforms the baseline in all met-rics, statistically significantly so.

We explain the lower performance of AIM, and AIM T (us-ing only article intent models) by the fact that both models are dependent on the similarity of the incoming article to the article intent model. This dependency results in many in-stances to model the incoming user query X  X rticle pair with article intent models that are topically far away from the input pair. This sensitivity is smoothed out successfully in ART + AIM T where content from the input pair reduces the potential topical drift from the article intent model. Weighting. In our second experiment we compare the e  X  ect of the weighting methods we describe in Section 5.4. We set the baseline to the best run so far, ART + AIM T , which uses uniform weights. The retrieval method is temporally biased.
In Table 4 we report on results for our five weighting schemes. ART + AIM T marks the best performance, out-performing other weighting methods with statistical signifi-Table 3: Retrieval performance for three query mod-eling methods using: a) only the incoming article, b) only article intent models, c) a combination of the two, with and without temporal bias in retrieval. Boldface indicates best performance in the respec-tive metric. Statistical significance tested against ART .
 Table 4: Retrieval performance for five weighting schemes for creating input article X  X rticle intent mix-ture models. Statistical significance tested against ART + AIM T .
 cant di  X  erences in most metrics. Among the rest of weight-ing schemes, performance hovers at similar levels. We be-lieve this is a indication that the semantic similarity be-tween the incoming article, and the article intent models may not be as discriminative as we hypothesized for assign-ing weights.
 Retrieval in intent space. In our third experiment, we look at methods that retrieve article intent models instead of articles. We use Eq. (3) for query modeling. Then, we issue the query to an index of article intent models. The retrieved article models are mapped back to articles. We consider two methods for performing the mapping. AIM AIM maps a Table 5: Retrieval performance for two systems re-trieving article intent models, and then mapping them to articles.
 retrieved article intent model to the most similar article in the dataset, and AIM AIM e maps a retrieved article intent model to the I most similar articles.

In Table 5 we report on the performance of the two meth-ods. The results are not directly comparable to those re-ported for retrieving articles because we are using a di  X  erent index (an article intent model index), we observe a decrease in performance compared to the methods that directly re-trieve articles. We foresee two reasons for the drop in per-formance. First, moving from an input article to an article intent model is an error prone process, because of the topi-cal noise. This issue was also present in our first experiment when we used only article intent model for query modeling. Then, when we move back from the retrieved intent models to articles, additional noise is added multiplying the nega-tive e  X  ects in retrieval e  X  ectiveness.

In sum, our experiments demonstrate the utility of our query models to capture user intent for predicting articles that a user will visit next. The most successful strategy is to use information from both the input query and article, and article intent models for query modeling. For mixing the two sources, uniform weighting proves the most e  X  ective. Perfor-mance is further improved with the user of temporally aware retrieval models. In the next section we further discuss our findings.
To better understand the performance of our methods, we take a closer look at the results, and we perform an analysis in the following directions: (a) temporal modeling, (b) the number of article intent models we consider, and (c) param-eter optimization.
 Temporal modeling. In our temporal aware retrieval mod-els, we use the Cauchy distribution for modeling the bias of Table 6: Retrieval performance for three temporal models using: (a) Cauchy distribution , (b) a block function, and (c) Laplace distribution. Statistical significance tested against ART + AIM T .
 users towards recent news articles. We try to fit di  X  erent temporal models on the distribution shown in Fig. 3. In particular, we look at a block function, and at Laplace dis-tribution. From the shape of the distribution in Fig. 3 we derive the block function: The Laplace distribution is defined as: with  X  =0 ,b = 1. We test the potential of these models on our best run, ART + AIM T , replacing the Cauchy prior with a prior from the block function, and the Laplace distribu-tion, respectively. The Cauchy prior marks the best perfor-mance among the temporal models. Comparing the Laplace distribution to the block function, the Laplace distribution recalls less documents, with higher precision (Rprec). The block function shows the opposite behavior; it shows the highest recall among all methods in expense of precision (see Table 6).
 Number of article intent models. In our experiments for query mixture models we used one article intent model, the most similar to the input article. Here, we explore the e  X  ect on retrieval e  X  ectiveness by increasing the number of article intent models we consider.

In Table 7 we list the results from combining one, up to four article intent models with the input article. On aver-age, increasing the number of article intent models leads to a decrease in performance for all methods. ART + AIM T achieves the best performance across the board for N =1. Each method peaks at di  X  erent number of article intent models; ART + AIM T A peaks at N = 3, and ART + AIM T M at N = 2. The di  X  erences in performance at various N , however, for the later two models are small.

The performance of ART + AIM T decreases quickly as N increases. A possible explanation can be due to the uni-form weights assigned to the input article and to the article intent models. Uniform weights allow article intent mod-els topically far away from the input article to be weighted equally, multiplying the e  X  ects of topical drift. The weight-ing schemes of ART + AIM T A and ART + AIM T M manage count for this e  X  ect, and show relatively stable performance for all N .
 Parameter optimization. We explore the e  X  ect of the lan-guage model smoothing parameter on retrieval e  X  ectiveness. In our particular setting, the query models are much longer compared to traditional web search queries because they Table 7: MAP scores for three weighting schemes for combining one to four article intent models with the incoming article. Boldface indicates best perfor-mance for the respective model. Figure 4: Retrieval e  X  ectiveness in MAP for the runs ART ,and ART + AIM T over a range of values of smoothing parameter  X  . contain content of news articles, and for query mixture mod-els, contain content from several news articles. We perform a parameter sweep on the Dirichlet priors smoothing param-eter  X  for two runs, ART, and ART + AIM T . Fig. 4 illus-trates the retrieval performance against  X  . The di  X  erences in performance for di  X  erent values are small. We believe this is due to the large size of the query, which lessens the smoothing e  X  ects.
In this work we have introduced the task of temporal con-text discovery: Given a query from a user, and the first document they visit, the system aims to predict documents that are likely for the user to visit next. The task takes place in near real-time and systems need to suggest documents not necessarily seen before. The system tries to capture the user browsing intent, and to take into account the change in in-tent after the user visits the first document.

We focused on an instantiation of the task, and in par-ticular on the news domain. We approached the task as a retrieval problem, and developed query modeling meth-ods that aim to capture user intent. For this purpose, we introduced the article intent models , which are trained on the content of user queries and news articles that users have had visited, extracted from user trails in query logs. We presented methods for modeling article intent models with the input query and new article, and several weighting schemes for generating query mixture models. Our experi-ments demonstrate the utility of our methods for predicting news articles that are visited from users.
In future work, we envisage to enhance our query modeling methods with more elaborate term selection and weighting schemes. Also, we plan extending our query models for in-cremental updating so we are able to make suggestions given parts of a user trail. Finally, we would like to validate the models presented here with a user-based study, to determine whether the e  X  ect of the suggestions produce any behavioral di  X  erence in human readers. We believe this line of work is useful to online news agents for increasing the user engage-ment of their web presence.
 Acknowledgments. The authors would like to thank the anonymous reviewers for their comments.
 [1] E. Agichtein, E. Brill, and S. Dumais. Improving web [2] A. Ashkan, C. L. Clarke, E. Agichtein, and Q. Guo. [3] S. Attfield, G. Kazai, M. Lalmas, and B. Piwowarski. [4] M. Bilenko and R. W. White. Mining the search trails [5] P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis, [6] A. Broder. A taxonomy of web search. SIGIR Forum , [7] L. Calderon-Benavides, C. Gonzalez-Caro, and [8] O. Chapelle, S. Ji, C. Liao, E. Velipasaoglu, L. Lai, [9] M. Gamon, S. Basu, D. Belenko, D. Fisher, M. Hurst, [10] C. N. Gonz  X alez-Caro and R. A. Baeza-Yates. A [11] J. Guo, X. Cheng, G. Xu, and X. Zhu. Intent-aware [12] T. Joachims. Optimizing search engines using [13] N. Kanhabua, R. Blanco, and M. Matthews. Ranking [14] D. Kelly and N. J. Belkin. Display time as implicit [15] U. Lee, Z. Liu, and J. Cho. Automatic identification [16] L. Li, W. Chu, J. Langford, and R. E. Schapire. A [17] D. Metzler and W. B. Croft. Combining the language [18] D. Metzler, Y. Bernstein, W. B. Croft, A. Mo  X  at, and [19] R. Mihalcea and A. Csomai. Wikify!: linking [20] J. M. Ponte and W. B. Croft. A language modeling [21] R. L. Santos, C. Macdonald, and I. Ounis.
 [22] C. Silverstein, H. Marais, M. Henzinger, and [23] A. Singla, R. White, and J. Huang. Studying [24] M. Tsagkias, M. de Rijke, and W. Weerkamp.
 [25] M. Tsagkias, M. de Rijke, and W. Weerkamp. Linking [26] R. W. White, P. Bailey, and L. Chen. Predicting user [27] C. Zhai and J. La  X  erty. A study of smoothing methods
