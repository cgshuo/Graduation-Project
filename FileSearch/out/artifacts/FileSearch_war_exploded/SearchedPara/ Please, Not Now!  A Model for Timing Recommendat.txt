 Proactive recommender systems push recommendations to users without their explicit request whenever a recommendation that suits a user is available. These systems strive to optimize the match between recommended items and users' preferences. We assume that recommendations might be reflected with low accuracy not only due to the recommended items' suitability to the user, but also because of the recommendations' timings. We therefore claim that it is possible to learn a model of good and bad contexts for recommendations that can later be integrated in a recommender system. Using mobile data collected during a three week user study, we suggest a two-phase model that is able to classify whether a certain context is at all suitable for any recommendation, regardless of its content. Results reveal that a hybrid model that first decides whether it should use a personal or a non-personal timing model, and then classifies accordingly whether the timing is proper for recommendations, is superior to both the personal or non-personal timing models. H.2.8 [Database Management] : Database Applications -Data Mining ; H.4.0 [Information Systems Applications] : General Algorithms, Measurement, Performance, Experimentation Recommender Systems; Proactivity; Mobile; Personalization; Data Mining Proactive recommender systems (RSs) push recommendations to the user without explicit user request, trying to optimize the recommendation to the user's current needs and preferences. Recent studies [16, 17, 13, 11] report that adding contextual information such as the user's curr ent location, weather, and time of the day into the recommendation process improves the system's accuracy. However, we claim that situations exist during which the most accurately predicted recommendation will not be appreciated by the user as she may not prefer to receive any recommendations at that moment. Examples of such s ituations include: while driving, watching a movie, talking on the phone, chatting with a friend, and so on. In these cases, the accuracy of an RS that provides proactive recommendations will be low regardle ss of their content. In this paper, we propose to explore th e feasibility of improving RSs for mobile devices by identifying such situations. We propose considering the user's context not only in order to determine the most accurate recommendation's content but also in order to decide whether the user's context is suitable at all for providing any recommendation. None of the prev ious studies that mention the importance of timing proactive r ecommendations have implemented a model for doing so, nor have they evaluated such a model's capabilities using data collected by real users. In our work, we trained models that classify users' contexts that are suitable for recommendations (henceforth referred to as "now" contexts) and user contexts in which users are highly likely to refuse any recommendations (henceforth referred to as "not now" contexts). These models can be easily integrated into a proactive RS to improve its recommendations' timings. In a large scale user study, we collected data using users' mobile devices' sensors, and inferred behavioral patterns of "now" and " not now" contexts based on users' explicit feedback. The feedback and sensors sampling were obtained through an application that proactively recommended nearby POIs to users. The application enabled users to use a "not now" button if the recommendation's timing was not suitable, before providing a recommendation. We used the data collected to generate personal models which used only the user's training data, and non-personal models that used all users' training data. Preliminary tests revealed that personal models obtained higher accuracy when classifying the user's context in some cases while the non-personal model dominated in others. Thus, we propose an integration of the two to a hybrid classification model. The suggested model first decides whether it is more beneficial to use the user's personal or the non-personal model and then classifies the given context as "now" or "not now" using the chosen model. Results indicate that in nearly all cases the suggested hybrid model is able to achieve higher precision than both the personal and the non-personal models. Our contribution in this work is twofold: first we show the feasibility of inferring a model that can classify between "now" and "not now" contexts. Secondly, we present a hybrid model for such tasks and show its superiority over two other considered options. Context Aware Proactive RSs -Recent studies in the field of proactive RSs mention the importa nce of context awareness for recommendations in mobile appli cations. Some of these works suggest mobile applications that proactively recommend different items or services, e.g., an RS for mo bile applications [5], Points of Interest (POIs) RSs for tourists [3, 14], and an RS for leisure activities [4], incorporate contex t into their recommendations. While these works incorporate contex t in order to choose items that best suit users given their current context, we use the user's context in order to decide whether the RS should make recommendations to the user at all, regardless of the recommendation's content. Interruptions Management -Proactive recommendations can be referred to as interruptions for th e user, since they pop up during the user's daily routine. The field of interruption management aims to define "good" and "bad" interruptions. Recent studies in the field [12] focused on computer-based interrup tion technologies investigating various interruption modes. Various studies concluded that applications that interrupt a user at an inopportune moment have had bad effects on the user's performan ce and satisfaction compared to interruption at a more opportune mo ment [1, 6, 10]. These findings strengthen our argument that addressing the right timing for a recommendation may greatly benefit the performance of RSs. Finding the Right Timing for a Recommendation -Few studies in the field of proactive RSs mention the importance of timing recommendations. Lerchenmueller and Woerndl [11] present an algorithm that is implemented for a Smartphone application and analyzes the user's current context based on GPS data. The authors focus on correctly classifying the user's activity online. They report that they plan to use these results in order to determine the best point in time for a recommendation, while we already implemented and evaluated the feasibility of inducing models of the right contexts for recommendations. In addition, the authors use mainly GPS data and infer users' explicit activity that might be defined as suitable or not for recommendations, while we take a variety of different sensors under consideration and infer implicit contexts (rather than activities) for "now " and "not now" scenarios. In [15], the authors present a new model for proactivity in mobile CARSs. Their model periodicall y assesses whether the current context is proper for recommendations. If assessed positively, candidate items were rated to decide which recommendations would be suggested. They implemented a prototype for recommending gas stations. Their prototype used parameters such as fuel level and detour to the n earest gas station. The different parameters used in their model were in part derived from an earlier study investigating gas st ation selection [2] and building the model itself was done in previous work [8]. Their current work focused on assessing the model' s first phase's abilities using an online questionnaire. Users were asked to enter demographic data and then rate the usefulness and convenience of recommendations for 13 different scenarios presented for them. The scenarios were composed of various features that the model took under consideration while d eciding whether the timing was proper for recommendations (e.g. fuel level, the driver's stress level, etc.). The authors found that in most cases their model's results were close to the users' feedback. Our work differs from this in various aspects. First, th eir model uses a set of explicit features chosen in accordance with the domain used in the presented prototype, while we use mostly implicit features that are not domain specific. Secondly, we examined our suggested model using real data collected in a us er study, while their work used literal scenarios in an online questionnaire. In summary, works presented in this section deal with proactive RSs and realize the importance of timing such recommendations. Our work, as opposed to those presented here, uses mostly implicit features that are not domain specific in order to define user context X  X hich in turn assists in deciding whether the user is available for recommendations and acts accordingly. Our work is the first to assess this challenge, provide a solution and test it with real user data. We conducted a user study in which the main goal was to develop a machine learning based classification model that will learn the right contexts for recommendations. In order to collect the needed data, we designed and developed an application that generates proactive recommendations of POIs for users and collects data from their mobile devices. We recruited 90 students between the ages of 20-45 for our user study. 53 (58%) of them were ma le and 37 (41%) were female. They were all students from one of two academic institutions. The collection of POIs was gene rated using the Foursquare API. We selected POIs from Foursquar e that covered the cities in which participants lived and studied. The selected POIs were categorized as "Food" or "Nightlife Spots" and gained at-least 10 check-ins by Foursquare users. We developed RecommenderPro , an Android application that collects data and provides recommendations about POIs nearby to the user. The application collects sensors' data every 30 minutes for 10 seconds. This is followed by a pop-up dialog box accompanied by a notification sound, that asks whether the user is available for recommendations, as shown in Figure 1a. The user might select the "not now" option, signaling that the current timing is not suitable for recomme ndations. If the user responds positively, the application presen ts the three most highly rated recommendations by the RS for the user to rate, as presented in Figure 1b. The participants recruited for the user study watched a short introductory video that explained how to use the application. One of our main focuses while making the video was to properly explain the meaning of the different rating options. The "Like" rating means that the user finds the recommended POI a good recommendation for his or her current context , while a "Dislike" rating means the opposite. An additional "Check-in" option enabled the users to signal that they are currently at the recommended POI. After each dialog is presented, the user has two minutes to answer it before it disappears, assuming that she is not available. The user's response, i.e. rating, pressing "not now," or simply not answering the dialog and missing it (an action labeled as "not available"), is immediately sent to the server with the sampled sensors data. The application constantly runs in the background and the described mech anism repeats itself with no need of user action to invoke recommendations. The application was designed to avoid repeatin g the same recommendations in consecutive recommendations timings. https://developer.foursquare.com/ 
Figure 1: RecommenderPro 's (a) Per-Recommendation The application used a popularity-based RS algorithm. Since the users answer the question "Are you available?" before seeing the recommended POIs, the recommendi ng algorithm is not the main focus of the current work; rather, we focus on modeling the correct timings for recommendations. When attempting to generate a recommendation, the RS gathers a ll POIs that are at most 500 meters away from the user's current location. If less than five POIs are found, the RS will extend its sear ch and will gather all POIs that are at most 1,000 meters away from the user's current location. In order to generate popularity-based recommendations, the RS granted each POI with a rate that re flected the amount of "Like" and "Check-in" actions it received, re lative to the other candidate POIs. It then randomized three POIs, taking under consideration the POI's rate as its probability to be chosen . In order to handle the cold-start problem, we allowed the RS to recommend randomly during the first two weeks. During this period of time participants were exposed to, and subsequently rated, a large number of the filtered POIs (1,186 of them), enabling us to generate popularity-based recommendations during the third week of the user study. As mentioned above, the application periodically collects a set of sensors. This set consists of the nine following sensors: accelerometer, Wi-Fi, battery, light, orientation, magnetic field, gravity, audio level, and locati on. Additional information was derived as well, such as the sampling timestamp, day of the week, time of day, activity recognition, screen-log, call-log, and traffic statistics of certain applications in stalled on the user's mobile device (i.e. Facebook, WhatsApp, Waze, Chrome, Moovit, and Ynet). Raw data collected by the sensors an d the additional information listed above were aggregated, analyzed and engineered to generate 479 features. These features define the user's context. Due to limited space, we will only give limited examples of the feature processing. Accelerometer, magnetic field, orientation, and gravity are sensors that produce raw data in the form of a 3D axis and sample nearly 100 records per second for each axis. We calculated the average, median, standard deviation, co rrelation, minimum and maximum values, the range, the first and third quarters, RMS, and entropy for each axis. From the timestamp, we calculated the time of the week (midweek, weekend) and time of day (dawn, morning, afternoon, night). We also added informati on regarding the device's screen mode. To do so, we constantly sampled the timestamps in which the user turned on and off her mobile device's screen and the action that was made (i.e. "screen turned on" and "screen turned off"). Our screen log kept this type of information for the last 20 minutes at any point of time. The screen-log was processed to three features. The first feature indicates the percent of the time the screen was on during the last 20 minutes, the second was analyzed during the last 10 minutes and the third was analyzed for the past minute. RecommenderPro was installed and used by the users for three weeks, followed by an offline analysis of the collected data. The data collected consists of 22,697 records, each one describing a labeled user context. 6,158 of the contexts were labeled as "now," 2,363 were labeled as "not now" and 14,176 were labeled as "not available." For the work discussed in this paper, we treated " not available" acti ons as "not now." We split the data by the record's timestamp using 80% of it for training and the remaining 20% for testing. We aimed to train a model that would be able to classify a test-set context as "now" or "not now." First, we used the training set for feature-selection. We performed Gain Ratio (GR) feature-selection [9], which granted a rate higher than zero to 413 features, and Correlation Feature Sele ction (CFS) [7], that chose four features only. We decided to examine the following sets of features: (1) the top 50 features rated by GR, (2) the top 30 features rated by GR, and (3) the features chosen by CFS. The features that dominated mostly in these feature-sets are Wi-Fi, screen-log, and orientation. We generated a personal classification model for each user, training it by using data collected only by her own mobile device. A single non-personal model was generated for a ll of the users and thus trained using the entire training set. Both types of models were trained using RandomForest learning algorithm. Preliminary evaluations of these models' performances showed that the personal model might be more accurate in some cases and the non-personal in others. These results led us to generate a third type of m odel, a hybrid one, which uses both the personal and the non-personal models. This model was built gradually. First, we generated a dup lication of the training set, but for this version, the class-attribute was not "now" or "not now," but the type of model that better classified the context: either "personal" or "non-personal." Specifically, we classified each context in the training set using the user's pe rsonal model and using the non-personal model. We then let each one of the classification models generate a distribution that was composed of probabilities for each one of the possible classification s, "now" and "not now." If the personal model generated a distribution that was closer to the context's actual classification, the context was labeled as "personal," otherwise, it was labeled as "non-personal." At this point, we tr ained a learning algorithm and generated a model that was meant to classify whether a classification model or the non-personal model, and finally, used the chosen model for the "now" or "not now" classification. To conclude, given a user's context for classification, the suggested hybrid model will first decide whether it is better classified by the user's personal model or the non-personal model a nd then use the chosen model to classify the context either as "now" or "not now." The measure used to evaluate the classification models described above was the models' precision for a version of the top N recommendations task. We let each model classify contexts in the test set and choose the top N contexts that are classified as most likely to be "now" contexts, for each user. Precision was evaluated for each model type, using the features-sets detailed above for different N values ( N =5, 10, 15, 20, 25). Precision for the different values of N was evaluated using the suggested models for top 50 features rated by GR (Figure 2a), top 30 features rated by GR (see Figure 2b) and features selected by CFS (see Figure 2c). The precisions presented in this section are the average precision for the different users that had at least one context in the test set labeled "now" (81 users). One can see that as the amount of features increases, all models managed to achieve higher precisions. Lower values of N result in substantial advantage for the non-personal models compared to the personal models, for two of the examined features-sets (features selected by GR). This advantage fades as the value of N increases. For these two feature-sets, the suggested hybrid model managed to perform better than both the pers onal and the non-personal models for all examined values of N but N =5, for which it performed second best after the non-personal model. For the third feature-set (features selected by CFS) the hybrid model performed better than the non-personal model, alongside the personal model, for every examined value of N . Similar trends were seen for additional learning algorithms, i.e. Bagging and Vote (Ensemble of J48 and Decision Stump). These results are excluded from this paper, due to limited space. In this paper, we suggested the integration of a pre-recommending phase in proactive RSs that classifies users' contexts as either suitable or unsuitable for any recommendation. We tested three types of models for such a task: (1) a personal model, (2) a non-personal model and (3) a hybrid model combining the first two. While testing the three models' pr ecisions for different values of N , given a top N recommendations task, we found that the hybrid model was able to achieve better results than the personal and the non-personal models. A single exception was noticed for the lowest value of N among two of the examined data sets, for which the non-personal model tended to perform better. It is worth mentioning that even though our test set did not contain new users, a significant advantage of the hybrid model is that it could easily choose the non-personal model for such cases and thus be able to handle new users as well as familiar ones. We are currently conducting the final part of our user study, using the same users that participated in the first part, detailed in the current work. We used the data collected in order to generate models that are currently used to classify, online, whether a certain context is suitable for a recommendation. Meaning, the application decides whether it should recommend or not and responds accordingly, online. We hope to be able to show that recommending only at times that seem appropriate can positively affect the accuracy of the RS. [1] Adamczyk, P. and Bailey, B. 2004. If not now, when?: the effects [2] Bader, R., Neufeld, E., Woerndl , W. and Prinz, V. 2011. Context-[3] Baltrunas, L., Ludwig , B., Peer, S. and Ri cci, F. 2012. Context [4] Bellotti, V., Begole, B. and Chi, E. 2008. Activity-based [5] B X hmer, M., Bauer, G. and Kr X ge r, A. 2010. Exploring the design [6] Dey, A. 2001. Understa nding and using context . Personal and [7] Hall, M. 1999. Correlation-base d feature selection for machine [8] Hong, J., Suh, E.H., Kim, J. and Kim, S. 2009. Context-aware [9] Karegowda, A. 2010. Comparativ e study of attribute selection [10] Kwapisz, J., Weiss, G. and Moore, S. 2011. Activity recognition [11] Lerchenmueller, B. and Woer ndl, W. 2012. Inference of User [12] McFarlane, D. and Latorella, K. 2002. The scope and importance [13] Parsons, J., Ralph, P. and Ga llagher, K. 2004.Using viewing time [14] Setten, M. Van, Pokraev, S. and Koolwaaij, J. 2004. Context-[15] Woerndl, W. and Huebner, J. 2011. A model for proactivity in [16] Zheng, Y., Chen, Y., Li, Q. , Xie, X. and Ma, W.-Y. 2010. [17] Zimmermann, A., Lorenz, A. and Oppermann, R. 2007. An Figure 2: Average precision for the top N recommendations task using personal, non-personal and hybrid models for (a) the 50 most highly rated features by GR, (b) the 30 most highly rated features by GR an d (c) the features selected by 
