 The explosiv e gro wth of the world-wide-w eb and the emer-gence of e-commerce has led to the dev elopmen t of recom-mender systems |a personalized information ltering tech-nology used to iden tify a set of N items that will be of interest to a certain user. User-based and mo del-based col-lab orativ e ltering are the most successful technology for building recommender systems to date and is extensiv ely used in man y commercial recommender systems. The basic assumption in these algorithms is that there are sucien t historical data for measuring similarit y between pro ducts or users. However, this assumption does not hold in various ap-plication domains suc h as electronics retail, home shopping net work, on-line retail where new pro ducts are introduced and existing pro ducts disapp ear from the catalog. Another suc h application domains is home impro vemen t retail indus-try where a lot of pro ducts (suc h as windo w treatmen ts, bathro om, kitc hen or dec k) are custom made. Eac h pro duct is unique and there are very little duplicate pro ducts. In this domain, the probabilit y of the same exact two pro ducts bough t together is close to zero. In this pap er, we discuss the challenges of pro viding recommendation in the domains where no sucien t historical data exist for measuring simi-larit y between pro ducts or users. We presen t feature-based recommendation algorithms that overcome the limitations of the existing top-N recommendation algorithms. The ex-perimen tal evaluation of the prop osed algorithms in the real life data sets sho ws a great promise. The pilot pro ject de-ploying the prop osed feature-based recommendation algo-rithms in the on-line retail web site sho ws 75% increase in the recommendation rev enue for the rst 2 mon th perio d. D.m [ Software ]: Miscellaneous; J.m [ Computer Appli-cations ]: Miscellaneous also with the Departmen t of Computer Science and Engi-neering, Univ ersit y of Minnesota Algorithms E-Commerce, Collab orativ e ltering, Recommender systems, Pro duct Features, Web Retailer
The explosiv e gro wth of the world-wide-w eb and the emer-gence of e-commerce has led to the dev elopmen t of recom-mender systems [16]. Recommender systems are personal-ized information ltering technology used to either predict whether a particular user will like a particular item ( predic-tion problem ) or to iden tify a set of N items that will be of interest to a certain user (top-N recommendation prob-lem ). In recen t years, recommender systems have been used in a num ber of di eren t applications [22, 9, 12, 23, 21, 11, 15, 3] suc h as recommending pro ducts a customer will most likely buy; movies, TV programs, or music a user will nd enjo yable; iden tifying web-pages that will be of interest; or even suggesting alternate ways of searc hing for information. An excellen t surv ey of di eren t recommender systems for various applications can be found in [21, 16].

Over the years, various approac hes for building recom-mender systems have been dev elop ed that utilize either de-mographic, con ten t, or historical information [9, 1, 2, 22, 23, 12]. Among them, collab orativ e ltering (CF), whic h relies on historical information, is probably the most suc-cessful and widely used technique for building recommender systems [17, 12]. The rst system to generate automated recommendations was the GroupLens system [17, 12], it pro-vided users with personalized recommendations on Usenet postings. The recommendations for eac h individual were obtained by iden tifying a neigh borho od of similar users and recommending the articles that this group of users found useful.

Tw o approac hes have been dev elop ed for building CF-based top-N recommender systems. The rst approac h, re-ferred to as user-b ased [22, 12, 18, 17, 8, 19], relies on the fact that eac h person belongs in a larger group of similarly-beha ving individuals. As a result, items (e.g., pro ducts, movies, books, etc.) frequen tly purc hased/lik ed by the var-ious mem bers of the group can be used to form the basis of the recommended items. The second approac h, kno wn as model-b ased [22, 4, 18, 25, 11, 20, 10, 6], analyzes the histor-ical information to iden tify relations between the di eren t items suc h that the purc hase of an item (or a set of items) of-ten leads to the purc hase of another item (or a set of items), and then use these relations to determine the recommended items. One of the model-b ased approac h called item-b ased top-N recommendation algorithms [20, 10, 6] pro vide rec-ommender systems that can scale to very large datasets and compute recommendations in almost real-time. In addition, these algorithms pro duce recommendations and predictions whose qualit y is either comparable or better than those pro-duced by other much slower algorithms.

These algorithms build the recommendation mo del by an-alyzing the similarities between the various items and then use these similar items to iden tify the set of items to be recommended. The basic assumption in these algorithms is that there are sucien t historical data for measuring sim-ilarit y between items. However, this assumption does not hold in various application domains. For example, when a new item X is introduced to the mark et, the similarit y be-tween X and other existing items cannot be measured be-cause none of the customers bough t X before. The problem comp ounds if X has limited quan tity and runs out in short time span. By the time enough historical data are gathered to measure the similarit y between X and other items, X is no longer available. Another example can be found in a do-main suc h as home impro vemen t retail industry where a lot of pro ducts (suc h as windo w treatmen ts, bathro om, kitc hen or dec k) are custom made. Eac h item is unique and there are very little duplicate items. In this domain, the probabilit y of the same two items bough t together is close to zero.
In this pap er, we will discuss the challenges of pro vid-ing recommendation in the domains where no sucien t his-torical data exist for measuring similarit y between items. We presen t feature-based recommendation algorithms that overcome the limitations of the existing item-b ased top-N recommendation algorithms . We will pro vide exp erimen tal evaluation of the prop osed algorithms in the real life data sets. We also pro vide results from the pilot pro ject deplo y-ing the prop osed feature-based recommendation algorithms in the on-line retail web site.

The rest of this pap er is organized as follo ws. Section 2 presen ts a brief surv ey of the related researc h on collab ora-tive ltering-based recommender algorithms. Section 3 de-scrib es the feature-based recommendation algorithms. Sec-tion 4 pro vides the exp erimen tal evaluation of the prop osed algorithms and sho ws the results from the pilot pro ject. Fi-nally , Section 5 pro vides some concluding remarks.
User-based collab orativ e ltering is the most successful technology for building recommender systems to date and is extensiv ely used in man y commercial recommender systems. In general, user-based systems compute the top-N recom-mended items for a particular user by follo wing a three-step approac h [22, 12, 19]. In the rst step, they iden tify the k users in the database that are the most similar to the activ e user. During the second step, they compute the union of the items purc hased by these users and asso ciate a weigh t with eac h item based on its imp ortance in the set. Finally , in the third step, they select the N items from that union that have the highest weigh t and have not already been pur-chased by the activ e user as the items to be recommended. Within that framew ork, the metho d used to determine the k most similar users and the scheme used to determine the imp ortance of the di eren t items play the most critical role in the overall performance of the algorithm. Commonly , the similarit y between the users is computed by treating them as vectors in the item-space and measuring their similarit y via the cosine or correlation coecien t functions [18, 19], whereas the imp ortance of eac h item is determined by how frequen tly it was purc hased by the k most similar users. However, alternate approac hes for both of these steps have been explored and sho wn to lead to somewhat better results. A detailed surv ey of di eren t user-based algorithms and a comparison of their performance can be found in [18, 8, 19].
Despite the popularit y of user-based recommender sys-tems, they have a num ber of limitations related to scala-bilit y and real-time performance. The computational com-plexit y of these metho ds gro ws linearly with the num ber of customers that in typical commercial applications can gro w to be sev eral millions. Furthermore, even though the user-item matrix is sparse, the user-to-user similarit y ma-trix is quite dense. This is because, even a few frequen tly purc hased items can lead to dense user-to-user similarities. Moreo ver, real-time top-N recommendations based on the curren t bask et of items, utilized by man y e-commerce sites, cannot tak e adv antage of pre-computed user-to-user similar-ities. Finally , even though the throughput of user-based rec-ommendation algorithm can be increased by increasing the num ber of serv ers running the recommendation algorithm, they cannot decrease the latency of eac h top-N recommen-dation that is critical for near real-time performance. One way of reducing the complexit y of the nearest-neigh bor com-putations is to cluster the users and then to either limit the nearest-neigh bor searc h among the users that belong to the nearest cluster or use the cluster cen troids to deriv e the rec-ommendations [24, 15]. These approac hes, even though they can signi can tly speed up the recommendation algorithm, they tend to decrease the qualit y of the recommendations.
To address the scalabilit y concerns of user-based recom-mendation algorithms a variet y of mo del-based recommen-dation techniques have been dev elop ed. Billsus and Paz-zani [4] dev elop ed a mo del-based recommender system by treating the top-N recommendation problem as a classi -cation problem, in whic h the goal was to classify the items purc hased by an individual user into two classes like and dis-like. A classi cation mo del based on neural net works was built for eac h individual user where the items purc hased by the user were though t of as the examples and the users as the attributes. To reduce the dimensionalit y a singular value decomp osition of the user-item matrix was obtained. The prediction on an item was computed by constructing an example for that item and feeding it to the classi er. The authors rep orted considerable impro vemen ts over the traditional user-based algorithms. Though this approac h is quite powerful it requires building and main taining a neu-ral net work mo del for eac h individual user in the database, whic h is not scalable to large databases. Breese et al. [18] presen ted two mo del-based algorithms for computing both predictions and top-N recommendations. The rst algo-rithm follo ws a probabilistic approac h in whic h the users are clustered and the conditional probabilit y distribution of di eren t items in the cluster was estimated. The probabil-ity that the activ e user belongs to a particular cluster given the bask et of items was then estimated from the cluster-ing solution and the probabilit y distribution of items in the cluster. The clustering solution for this technique is com-puted using the exp ectation maximization (EM) principle. The second algorithm is based on Bayesian net work mo dels where eac h item in the database is mo deled as a node having states corresp onding to the rating of that item. The learning problem consists of building a net work on these nodes suc h that eac h node has a set of paren t nodes that are the best predictors for its rating. They presen ted a detailed com-parison of these two mo del-based approac hes with the user-based approac h and sho wed that Bayesian net works mo del outp erformed the clustering mo del as well as the user-based scheme. Hec kerman et al. [7] prop osed a recommendation al-gorithm based on dep endency net works instead of Bayesian net works. Though the accuracy of dep endency net works is inferior to Bayesian net works they are more ecien t to learn and have smaller memory requiremen ts. Agra wal et al. [25] presen ted a graph-based recommendation algorithm where the users are represen ted as the nodes in a graph and the edges between the nodes indicate the degree of similarit y be-tween the users. The recommendations for a user were com-puted by traversing nearb y nodes in this graph. The graph represen tation of the mo del allo ws it to capture transitiv e relations whic h cannot be captured by nearest neigh bor al-gorithms and the authors rep orted better performance than the user-based schemes.

A num ber of di eren t mo del-based approac hes have been dev elop ed that use item-to-item similarities as well as asso-ciation rules. Shardanand and Maes [22] dev elop ed an item-based prediction algorithm within the con text of the Ringo music recommendation system, referred to as artist-artist , that determines whether or not a user will like a particular artist by computing its similarit y to the artists that the user has liked/dislik ed in the past. This similarit y was computed using the Pearson correlation function. Sarw ar et al. [20] further studied this paradigm for computing predictions and they evaluated various metho ds for computing the similarit y as well as approac hes to limit the set of item-to-item similar-ities that need to be considered. The authors rep orted con-siderable impro vemen ts in performance over the user-based algorithm. Mobasher et al. [14] presen ted an algorithm for recommending additional webpages to be visited by a user based on asso ciation rules. In this approac h, the historical information about users and their web-access patterns were mined using a frequen t itemset disco very algorithm and were used to generate a set of high con dence asso ciation rules. The recommendations were computed as the union of the consequen t of the rules that were supp orted by the pages visited by the user. Lin et al. [13] used a similar approac h but they dev elop ed an algorithm that is guaran teed to nd asso ciation rules for all the items in the database. Finally , within the con text of using asso ciation rules to deriv e top-N recommendations, Demiriz [5] studied the problem of how to weigh t the di eren t rules that are supp orted by the ac-tive user. He presen ted a metho d that computes the sim-ilarit y between a rule and the activ e user's bask et as the pro duct of the con dence of the rule and the Euclidean dis-tance between items in the anteceden t of asso ciation rule and the items in the user's bask et. He compared this ap-proac h both with the item-based scheme describ ed in [10] and the dep endency net work-based algorithm [7]. His ex-perimen ts sho wed that the prop osed asso ciation rule-based scheme is sup erior to dep endency net works but inferior to the item-based schemes.
The basic kno wledge that the feature-based recommenda-tion algorithms tries to disco ver can be summarized as \peo-ple who bough t pro ducts with featur es like these also bough t a pro duct with featur es like these." An example of this kind of kno wledge in an electronics retail shop can be \people who bough t a TV with featur es like HDTV, Rear-Pro ject, HDMI Input, Built-In HDTV Tuner, and IEEE 1394 (FireWire) DV interface also bough t a DVD player with featur es like Progressiv e-Scan Multiformat, HDMI Output, 3D virtual surround sound, Dolb y Digital 2-channel down-mixing, Mul-tiMediaCard, and Secure Digital." Note that this statemen t is about features of pro ducts not about particular pro ducts. Now assume a customer is chec king out a brand new TV that signi can tly matc hes the pro duct features of this statemen t. The recommendation system will be able to recommend a DVD that matc hes the pro duct features of this statemen t regardless of whether that particular DVD is an existing pro duct or a new pro duct. Consider another example in a home impro vemen t retailer: \people who bough t windo ws with featur es like clad-w ood, safet y glass, and bay windo w also bough t windo w treatmen ts with featur es like natural woven shade, bam boo, semi-sheer, and scarv es." When a customer is considering custom windo ws with the features of this statemen t, the salesp erson can recommend windo w treatmen ts with features in this statemen t.

In this section, we will describ e three feature-based rec-ommendation algorithms that capture the kno wledge dis-cussed here. The rst two algorithm is designed to pro vide recommendations in the domain where the pro duct catalog changes frequen tly (e.g., electronics retail). The third algo-rithm is designed to pro vide recommendations for pro duct catalog with custom pro ducts.
In this type of catalog (e.g., electronics retail, home shop-ping net work, on-line retail), new pro ducts are introduced frequen tly and existing pro ducts become out of stock or dis-con tinue frequen tly. Challenges of recommendation system in this catalog include how to use new pro ducts in the bask et for recommendation and how to recommend new pro ducts.
We presen t two metho ds to address these challenges. We assume that we are given a training bask et data corresp ond-ing to past sales history . Eac h bask et corresp onds to single transaction where a set of pro ducts are sold to a customer. We have a corresp onding training pro duct catalog con tain-ing all the pro ducts in the training bask et data and their pro duct features. We also have a curren t pro duct catalog that con tain available pro ducts (including new pro ducts that are not in the training pro duct catalog) and their pro duct features.

In the rst metho d, given a training bask et data, we build a recommendation mo del M using item-b ased top-N recom-mendation algorithms describ ed in [10]. The recommenda-tion steps can be summarized as follo ws: 1. Giv en a set of pro ducts X in a shopping bask et, nd 2. Find recommended pro ducts R of the set S using the 3. Find recommended features F by summarizing or ag-4. Find top-N matc hing pro ducts using F from the cur-
In step 1, existing pro ducts (i.e., pro ducts in the training pro duct catalog) in X will nd themselv es as the matc h-ing pro ducts. New pro ducts in X will nd the most similar pro ducts from the training pro duct catalog. Hence, S con-tains the existing pro ducts from X and the most similar existing pro ducts of new pro ducts in X . By using S that con tains similar pro ducts of new pro ducts in step 2, this metho d utilizes new pro ducts of the shopping bask et in the recommendation pro cess.

In step 3, we utilize the recommendation score or con -dence in the summary/aggregation of pro duct features. The score of one feature is the sum of recommendation score of eac h recommended pro duct that has this feature. Hence, features that are in man y recommended pro ducts and are in highly recommended pro ducts are scored highly . These pro duct feature scores are in turn used in step 4 for matc hing pro ducts.

In step 4, eac h pro duct is scored by adding scores of fea-tures in F that this pro duct has. By scoring pro ducts from the curren t pro duct catalog using the recommended features and their scores, the best matc hing pro ducts from the cur-ren tly available pro ducts (including new pro ducts that do not exist in the training bask et) are recommended.
This prop osed metho d utilizes new pro ducts in the bas-ket for recommendation and also recommends new pro ducts. However, pro ducts that are introduced to the training bas-ket recen tly (or lately) and do not have man y shopping bas-kets with these pro ducts are not utilized in full exten t in the recommendation pro cess. For instance, assume a very pop-ular pro duct was introduced toward the end of perio d for training data. There are very small num ber of bask ets with this pro duct. However, there will be man y bask ets with this pro duct in the deplo ymen t. The recommendation with this pro duct will pro vide no hits or very low con dence recom-mendation, because there are very small num ber of bask ets in the training set. A better option is to regard this pro duct as a new pro duct and nd other similar pro ducts from the training pro duct catalog. Now the challenge is how to se-lect some of existing pro ducts as new pro ducts. A frequency or supp ort threshold-based approac h is feasible, but alw ays presen ts a dicult task of determining the righ t threshold value.

We prop ose another metho d that avoids the issue with threshold. In this metho d, instead of using item-b ased top-N recommendation algorithms to determine recommended pro ducts, we use the features of pro ducts in the bask et di-rectly .

In this metho d, given a training bask et data, we build as-sociation rules AR as follo ws. For eac h bask et in the training bask et data, for eac h pro duct in the bask et, construct a rule suc h that this pro duct is in the consequence of the rule and all other pro ducts are in the anteceden t of the rule. For ex-ample, given a bask et f a, b, c g , we will have rules f a, b g ! c, f a, c g ! b and f b, c g ! a. The recommendation steps can be summarized as follo ws: 1. Giv en a set of pro ducts X in a shopping bask et, nd 2. Find recommended features F by summarizing or ag-3. Find top-N matc hing pro ducts using F from the cur-
Note that in step 1 we simply use the features of the pro d-ucts in the bask et and nd asso ciation rules that matc h the features directly . This step eliminates the distinction be-tween existing pro ducts and new pro ducts and uses all the features of the bask et in the recommendation pro cess. In step 2, similar to the rst metho d, the matc hing scores from the step 1 are used to score the features. Step 3 is the same as the step 4 of the rst metho d.
In this type of catalog (e.g., home impro vemen t retail in-dustry , built to order on-line retail), complete enumeration of all possible pro ducts is not feasible. Only high-lev el or categorical listing with sample pro ducts is feasible. For ex-ample, in the home impro vemen t retail outlet, high level categories like windo w treatmen ts, bathro om, kitc hen, or dec k can be listed with some examples of eac h of these cat-egory . From the sales record, we will not nd man y exact duplicate pro ducts or con gurations. We migh t nd simi-lar bathro om con gurations from di eren t sales records, but they will not matc h exactly . Hence, any user-or item-based recommendation mo del will not work in this catalog data set.

We prop ose a recommendation metho d that is based on clustering and feature matc hing for this catalog data set. When the pro duct catalog does not have a pro duct hierar-chy, we construct a pro duct hierarc hy from the sales data using clustering algorithms [26]. Giv en a pro duct hierar-chy, we roll up leaf nodes in the hierarc hy if they do not have sucien t num ber of pro ducts in the node and split leaf nodes if they have too man y pro ducts and the cluster co-hesiv eness/tigh tness [26] is low. The goal of rolling up and splitting nodes in the pro duct hierarc hy is to have leaf nodes that have sucien t num ber of pro ducts and yet have high cluster cohesiv eness.

Giv en a training bask et data and the pro duct hierarc hy, we build a recommendation mo del M using item-b ased top-N recommendation algorithms describ ed in [10]. In this mo del, item corresp onds to the cluster (the leaf node) of the pro duct hierarc hy that eac h pro duct belongs to. 1. Giv en a set of pro ducts X in a shopping bask et, nd 2. Find recommended clusters R of the set C using the 3. For eac h recommended cluster in R , nd recommended 4. For eac h recommended cluster, either sho w the cluster
The recommended features F of a cluster can be deter-mined as the cen troid vector of the pro duct features in the cluster, or the pro duct features of the medoid pro duct of the cluster. Another option is to use some business rules to se-lect represen tativ e pro duct of the recommended cluster and use the features of these represen tativ e pro ducts. The busi-ness rules can be the most popular pro ducts in terms of sales, most pro table pro ducts, pro ducts with supplier incen tives, or pro ducts with most inventory . However, these options lack di eren tiation power as any com bination of pro ducts that give same C in step 1 will get the same recommenda-tion. Third option is to select features bask et-sensitiv e way in whic h the pro ducts in the bask et of X are considered. In this option, given a recommended cluster r in R , we rst se-lect past shopping bask ets that con tain pro ducts from clus-ter C and the recommended cluster r . We then rank these shopping bask ets by matc hing features of X to the pro ducts from cluster C . We then score features of pro ducts in r from these bask ets utilizing matc hing scores.

An example using electronic retails data will demonstrate the prop osed metho d. Note that electronic retails is not the prop er domain for this kind of catalog, but is used to explain the pro cess because this domain is well kno wn. Assume that a customer is buying a TV and a VCR. The cluster (or leaf node in the pro duct hierarc hy) of these pro ducts are high-end TV and high-end VCR. Giv en these clusters, assume that the recommended cluster is high-end HOME AUDIO &amp; SPEAKER using item-based recommendation of clusters of past sales bask ets.

Now the question is what are the key features of the high-end HOME AUDIO &amp; SPEAKER to use for nal pro duct recommendation. First option is to select features that are most common among all the high-end HOME AUDIO &amp; SPEAKERs. Second option is to select the most popular (in terms of sales, or some other characteristics) high-end HOME AUDIO &amp; SPEAKERs and use the features of these HOME AUDIO &amp; SPEAKERs. Third option is to select features based on the past shopping bask ets that con tain high-end TV, high-end VCR and high-end HOME AUDIO &amp; SPEAKER. From these bask ets, we will select bask ets that are most similar in terms of features of TV and VCR of the curren t shopping bask et. Then use the features of HOME AUDIO &amp; SPEAKERs in these bask ets for nal pro duct recommendation.

Giv en the set of recommended features, we can either recommend features themselv es and/or recommend custom pro ducts that matc h these features. So in the example above, we can recommend features suc h as Videostage 5 de-coding and post-pro cessing circuitry , AD APTiQ audio cali-bration system, AM/FM tuner with 50 stations. Then these features can be used to custom build an audio system. We can also nd matc hing custom pro ducts from the past sales with these recommended features.
We obtained the sales data from an upscale cable televi-sion and on-line retailer for evaluation. The data set with 4.5 million records was a random subset from one year sales data. We took rst 9 mon ths as training set and the last 3 mon ths as test set. There were 8,908 pro ducts in this sales data. From these data sets, we constructed a shop-ping bask et as pro ducts purc hased by the same customer within 2 day perio d. We dropp ed shopping bask ets with single pro duct, because these bask ets cannot be used for recommendation evaluations.

In the training set, there were 127,554 shopping bask ets with at least 2 pro ducts. In this set, there were 5,511 unique pro ducts. In the test set, there were 106,263 shopping bas-kets with average num ber of pro ducts of 2.91. Note that sales per mon th within the last 3 mon th of the data was much higher than the previous 9 mon ths. In this data set, there were 7,635 unique pro ducts and 2,803 of them are new pro ducts that did not exist in the training set. Table 1 sho ws the num ber of bask ets for di eren t bask et size.
We also obtained man ual recommendations for these pro d-ucts. Out of 8,908 pro ducts, 1,912 pro ducts have man ual recommendations. These recommendations were pro vided by pro duct suppliers or domain exp erts.

We compare the follo wing 5 approac hes in this exp erimen-tal evaluation.
 We com bined recommendations of di eren t metho ds by nor-malizing recommendation scores of eac h metho d, adding up the scores of recommended pro ducts from di eren t metho ds, and then rank the added scores of recommended pro ducts.
We evaluated these recommendation metho ds for the fol-lowing two situations.
 We sho w the num ber of hits in top 1, 3, and 6 recommended pro ducts of eac h metho d. In most real deplo ymen t of rec-ommendation system, at most 3 pro ducts are presen ted.
Table 2: Product Page Case: 310,106 possible hits Table 3: Product Page Case on Test Bask ets with New Products: 239,905 possible hits However, some of the recommended pro ducts migh t be out of stock and it migh t require more recommended pro ducts. Top 6 recommendation will cover cases like this.

Note that the man ual recommendations were used in the sales pro cess, and the data set we receiv ed con tains sales in-uenced by these recommendations. Hence, the recommen-dation results of the Man ual metho d needs to be understo od with this bias.
There were 106,263 test bask ets and were 310,106 recom-mendations for this test case. Giv en a test bask et, we made recommendation based on eac h pro duct in the bask et. We consider the recommendation to be correct or a hit if the top-k recommendation con tains any of the pro ducts in the bask et.
 Table 2 sho ws the num ber of hits in \Pro duct Page Case". For top-3 recommendation results, Man ual has 15.1% cor-rect recommendations, Item has 10.8%, Feature has 8.4%, Item+F eature has 13.1%, and Item+F eature+Man ual has 23.4%. This result sho ws that Man ual has the best single metho d result follo wed by Item and Feature. Item+F eature sho ws the impro vemen t over Item or Feature. This result demonstrates that eac h metho d has di eren t strength and the com bined metho d bene ts from these strengths. Item+F eature+Man ual has the best performance at 23.4%, whic h is 50.0% impro vemen t from the Man ual result.
We also extracted test bask ets that con tain new pro d-ucts to see the e ectiv eness of the Feature metho d in these bask ets. Table 3 sho ws the num ber of hits for this sub-set of test bask ets. There were 76,304 bask ets and 239,905 recommendations were made. For top-3 recommendation results, Man ual has 16.4% correct recommendations, Item has 6.2%, Feature has 6.7%, Item+F eature has 9.4%, and Item+F eature+Man ual has 22.6%. This result sho ws that Feature outp erforms Item in this subset as exp ected.
There were 106,263 test bask ets and were the same num-ber of recommendations for this test case. Giv en a test bas-ket of size m , we made recommendation based on the rst m 1 pro ducts in the bask et. We consider the recommen-dation to be correct or a hit if the top-k recommendation con tains the last pro duct of the bask et.
 Table 4: Chec kout Page Case: 106,263 possible hits Table 5: Chec kout Page Case on Test Bask ets with New Products: 76,304 possible hits Table 4 sho ws the num ber of hits in \Chec kout Page Case". For top-3 recommendation results, Man ual has 9.1%, Item has 6.3%, Feature has 5.1%, Item+F eature has 6.5%, and Item+F eature+Man ual has 12.2% correct recommenda-tions. Item+F eature+Man ual has the best performance at 12.2%, whic h is 34.1% impro vemen t from the Man ual result. This result is similar to that of the \Pro duct Page Case".
Table 5 sho ws the num ber of hits for the subset of test bask ets that con tain new pro ducts. For top-3 recommen-dation results, Man ual has 9.5% correct recommendations, Item has 2.4%, Feature has 2.6%, Item+F eature has 3.0%, and Item+F eature+Man ual has 10.3%. This result is again similar to that of the \Pro duct Page Case".
The upscale cable television and on-line retailer that pro-vided the test data for the exp erimen ts carried out a pilot pro ject. In this pro ject, this retailer deplo yed a recommen-dation scheme of Man ual+Item+F eature in \Pro duct Page Case" describ ed in Section 4.1. The pilot sho ws a great promise as this retailer saw 75% increase in the recommen-dation rev enue for the rst 2 mon ths of the evaluation. This result is better than the impro vemen t of 50% sho wn in Sec-tion 4.2 for the similar setting. The di erence is due to the bias of the test data we used for the exp erimen ts. The man-ual recommendations were used in the sales pro cess, and the test data set we receiv ed con tains sales in uenced by these recommendations. Hence, the result of Man ual sho wn in the exp erimen t is higher than the real performance, and the impro vemen t in the exp erimen t is lower than the real.
In this pap er, we discussed the challenges of pro viding recommendation in the domains where no sucien t histori-cal data exist for measuring similarit y between pro ducts or users. We presen ted feature-based recommendation algo-rithms that overcome the limitations of the existing top-N recommendation algorithms. The exp erimen tal evaluation of the prop osed algorithms in the real life data sets sho ws a great promise as the com bined metho ds pro vide 50% im-pro vemen t over the man ual recommendation metho d. The pilot pro ject deplo ying the prop osed feature-based recom-mendation algorithms in the on-line retail web site sho ws 75% increase in the recommendation rev enue for the rst 2 mon th perio d. [1] M. Balabano vic and Y. Shoham. FAB: Con ten t-based [2] C. Basu, H. Hirsh, and W. Cohen. Recommendation [3] D. Beeferman and A. Berger. Agglomerativ e clustering [4] D. Billsus and M. J. Pazzani. Learning collab orativ e [5] A. Demiriz. An asso ciation mining-based pro duct [6] M. Deshpande and G. Karypis. Item-based top-n [7] D. Hec kerman, D. Chic kering, C. Meek, [8] J. Herlo cker, J. Konstan, A. Borc hers, and J. Riedl. [9] W. Hill, L. Stead, M. Rosenstein, and G. Furnas. [10] G. Karypis. Exp erimen tal evaluation of item-based [11] B. Kitts, D. Freed, and M. Vrieze. Cross-sell: A fast [12] J. Konstan, B. Miller, D. Maltz, J. Herlo cker, [13] W. Lin, S. Alv arez, and C. Ruiz. Collab orativ e [14] B. Mobasher, R. Cooley , and J. Sriv asta va. Automatic [15] B. Mobasher, H. Dai, T. Luo, M. Nak aga wa, and [16] Resnic k and Varian. Recommender systems.
 [17] P. Resnic k, N. Iaco vou, M. Suc hak, P. Bergstrom, and [18] J. s. Breese, D. Hec kerman, and C. Kadie. Empirical [19] B. Sarw ar, G. Karypis, J. Konstan, and J. Riedl. [20] B. Sarw ar, G. Karypis, J. Konstan, and J. Riedl. [21] J. Schafer, J. Konstan, and J. Riedl. Recommender [22] U. Shardanand and P. Maes. Social information [23] L. Terv een, W. Hill, B. Amen to, D. McDonald, and [24] L. H. Ungar and D. P. Foster. Clustering metho ds for [25] J. wolf, C. Aggarw al, K. Wu, and P. Yu. Horting [26] Y. Zhao and G. Karypis. Criterion functions for
