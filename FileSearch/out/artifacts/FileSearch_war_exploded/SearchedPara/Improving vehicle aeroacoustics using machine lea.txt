 1. Introduction general comfort. One of the most significant sources of noise inside a car at high speed (over 100 km/h) is the aerodynamics related wind noise that is generated by the air flow around the vehicle ( George, 1990 ). In fact, at 140 km/h the wind noise can completely prevail over other sources of noise, such as the engine, tires, etc. Therefore, an improvement to the aerodynamic proper-ties is important for increasing driving comfort, but this should not be at the expense of the vehicle X  X  aesthetic and mechanical design. design and economic constraints that allow only minor changes to be made to the vehicle. This means that the airflow is improved by a careful selection of the vehicle X  X  minor external components, such as windshield wipers, door seals, antennas, etc. However, to determine the best set of components, extensive aeroacoustic testing is needed, and this is usually performed in a wind tunnel.
Since running the wind tunnel is time consuming and expensive, there is a strong need in the automotive industry to automate and speed up the process of improving the aeroacoustic properties of a vehicle and thus reducing the cost.
 improvement process by employing machine learning methods, with the aim to free aeroacoustics engineers from involvement in repetitive tasks. Moreover, software that supports the process can guide the improvement process and can also be very useful for training new engineers.

The rest of the paper is structured as follows. First, we look at the related work. We then follow this with an overview of the aeroacoustics improvement process. The following section then gives a detailed description of the tool that was developed to support the improvement process: the prediction of driver X  X  subjective wind noise evaluation. The paper is concluded with a discussion. 2. Related work
First, we will discuss the related work regarding the prediction of a subjective wind noise evaluation. The problem of subjective sound (noise) evaluation is traditionally tackled with some form of jury evaluations (tests), where a number of people drive the vehicle or listen to the vehicle sound recordings and give their subjective evaluations ( Otto et al., 2001 ; Otto, 1997 ; Society of Automotive
Engineers, 2000 ). Since such evaluations are time consuming, some research has focused on developing the Artificial Neural Networks (ANN) to reduce the dependency on human jurors by predicting their responses ( Fry et al., 2004 ; Jennings et al., 2003, 2002 )orto improve the existing paired comparison tests (person selects one of the two options that he thinks is better based on some predefined criteria), which are usually used in jury evaluations ( Baker et al., 2004 ). The drawback of ANNs is that they cannot be used for gaining new insights into what kind of objective noise descriptors are correlated with subjective perception. Bergeron et al. (2010) addressed this drawback by using multivariate linear regression for analysing the internal automotive road noise and found strong correlations between the associated perceptual dimensions and psycho-acoustic properties. Nor et al. (2008) similarly correlated the standard sound quality metrics with jury evaluation results and showed how and how much which of them has affected the acoustical comfort of the vehicle. While the previous work mostly deals with the vehicle X  X  interior noise in general (with all noise sources present, such as road noise, engine noise, etc.), our goal was to model the driver X  X  subjective perception of wind noise at high speeds. Additionally, we propose a novel approach to learning regression models consistent with expert knowledge (also referred to as domain or background knowledge) in form of qualitative constraints.

Another important task of aeroacoustics improvement process is the detection of critical vehicle components  X  components that are sources of wind noise. Automotive industry and researchers have addressed this problem mainly with Computational Fluid Dynamics (CFD) ( Wesseling, 2000 ) approach that enables the engineers to simulate the wind flow ( Tsai et al., 2009 ; Strumolo, 2002 ; Sarigul-Klijn et al., 2001 ; Ono et al., 1999 ). This is basically a virtual equivalent of a wind tunnel, requires a lot of computa-tional resources to run the simulation and the results have to be analysed by the engineers to determine which components are critical. Our approach is different. We use a machine learning model to detect the critical components and the basis for learning the model are the vehicle wind noise frequency spectra that were recorded in the wind tunnel. Our machine learning approach lacks the flexibility of the CFD approach, since we perform detection only on a set of predefined vehicle components. How-ever, our approach is less computationally complex and can run on an average personal computer. Moreover, the benefits of CFD are not required in the improvement process that is presented in this paper.

The Computational Fluid Dynamics approach is also often used in vehicle design process with the aim to improve the vehicle shape aerodynamics and aeroacoustics ( Ando et al., 2010 ; Boujo and Aoki, 2008 ; Kobayashi and Tsubokura, 2009 ). This differs from the problem that is presented in this paper. Wind tunnel engineer do not consider making changes to the vehicle shape or developing a new or improved vehicle components. They are concerned with finding best  X  X  X f the shelf X  X  vehicle components that will replace the critical components and improve the vehicle aeroacoustics. 3. Overview of the improvement process
The process as presented in Fig. 1 was developed in collabora-tion with aeroacoustics engineers at the Fiat Group Automotive wind tunnel and researchers from the Fiat Research Center. They specified the steps and tasks that are usually carried out in their daily work and a functional requirements X  analysis was performed. The result of this analysis is a process that uses computer software to steer and aid the improvement of the vehicle X  X  aeroacoustics performance.

The aeroacoustics improvement process starts with a vehicle that needs to be improved ( starting vehicle ) and a target subjective evaluation value (SEV)  X  see Fig. 1 . The subjective evaluation value defines the subjective wind noise perception of the vehicle X  X  passengers, where a higher value corresponds to a more aero-acoustically comfortable vehicle. The goal of the improvement process is not to reduce the noise as much as possible, but to reach a given aeroacoustical noise performance, which is expressed by the SEV. The target SEV is usually determined by the marketing department that is responsible for placing the newly developed vehicle model in the right vehicle segment and setting the target performances of various vehicle aspects, such as the aeroacoustical comfort.

The next step in the process is to find an existing vehicle that has a SEV which is close to the target SEV (step 1 in Fig. 1 ).
Vehicles that are more similar to the starting vehicle in terms of vehicle segment and aeroacoustical properties are preferred because of the easier transfer of the component solutions. The aeroacoustical similarity is determined on the basis of the vehi-cle X  X  wind noise frequency spectrum, which is captured for every tested vehicle. The starting vehicle is compared to every vehicle in the database (previously tested vehicles) and the list of vehicles, sorted by similarity, is obtained. We use the inverse of the
Euclidean distance as the similarity measure. This is a reasonable premise, since the frequencies of the spectra are always aligned.
However, aeroacoustics engineers have knowledge about how different audio frequencies have different impacts on a driver X  X  comfort. For instance, the frequencies in the range between 1 and 3 kHz are the most disturbing, while frequencies below 500 Hz are not problematic. Therefore, we modified the Euclidean distance to account for the different frequency impacts. This can be easily done by introducing weights into the Euclidean distance: d  X  s , s 2 , w  X  X  where s 1 and s 2 are spectra, F is a set of frequencies from 18.6 Hz to 10 kHz with a 1/12 octave step that are used for spectrum sampling and w is a vector of the weights for each frequency that was defined by the aeroacoustics engineer.

The aeroacoustics engineer then selects the most appropriate vehicle from the list, based on his or her expertise. This selected vehicle can be understood as the target vehicle , since it already conforms to the target SEV. The focus of the remaining steps in the process is then to improve the starting vehicle in such a way 6.
 that its wind noise frequency spectrum is more similar to the target vehicle spectrum and hence conforms to the target SEV.
However, the target vehicle can, in general, be from a completely different vehicle segment and be of a very different shape. are compared to identify the frequency ranges where an improve-ment can be achieved (step 2 in Fig. 1 ). The comparison is based on the frequency spectra of the wind noise produced by the vehicles at a wind speed of 140 km/h (see Fig. 2 ). The regions where the target vehicle X  X  spectrum is significantly lower than the starting vehicle X  X  spectrum, depicted in Fig. 2 as gray shaded areas, should be improved by replacing or adding the appropriate vehicle components. 1 on the vehicle X  X  wind noise frequency spectrum. This knowledge can be used in step 3 to determine the vehicle components (we shall call them critical components ) that are causing the excessive wind noise in the frequency range that was identified in step 2.
For instance, external rear view mirrors produce wind noise in the frequency range from 200 Hz to 10 000 Hz ( Fig. 3 ) and can be responsible for the loudness gap between the target and starting vehicle in Fig. 2 . The graph in Fig. 3 is obtained by subtracting the ideal component solution spectrum from the given component solution spectrum. To automate the discovery of the critical vehicle components, machine learning methods can be applied.
Previously executed wind tunnel tests were used for learning and when faced with a new starting vehicle a prediction can be made as to whether a particular component will have a critical effect on the vehicle X  X  wind noise. After the effects of all the components are predicted, a sorted list based on criticality is presented to the engineer, who selects a component he or she wishes to improve. needs to be improved, the engineers must then search for a suitable component solution. Usually, the competitor vehicles from the same or similar segments are inspected for good solutions. A good component solution is defined as a component solution whose noise frequency spectrum does not differ signifi-cantly from the noise spectrum of an ideal component solution.
Therefore, for all the solutions of a given component type and the segment in the database, we calculate the difference between the given component solution and the ideal component solution, as in
Fig. 3 , and check to see whether the average difference for a given frequency range is higher than some user specified threshold.
The selected component is then improved and the modified starting vehicle is again tested (step 4) to determine the wind noise frequency spectrum. This reveals the level of improvement using the selected component solution, which is important to determine whether the improvement is significant enough to terminate the improvement process and submit the modified vehicle to the next stage of the development process (step 5).
However, if the level of improvement is not yet satisfactory (step 6), the modified vehicle goes into another iteration of the improvement process at step 2, as shown in Fig. 1 .

Next follows a more detailed description of the tool that is essential in steps 1 and 5 and uses techniques from machine learning to predict the subjective evaluation value from wind noise frequency spectrum. 4. Subjective evaluation value prediction
A subjective evaluation value (SEV) for aerodynamic comfort is originally based on extensive road tests. It is performed by several drivers (non-engineers) testing a car on highways, who later fill in an extensive questionnaire to answer questions on different aspects of vehicle comfort. One section of this questionnaire deals with aeroacoustic comfort, and the result of this section is a single value in the range [1,10] that expresses the individually perceived comfort. The questionnaire results for aeroacoustic comfort from individual drivers are then averaged to obtain the SEV.
During the improvement process, the engineers often need to determine the SEV of the vehicle (steps 1 and 5 in Fig. 1 ).
However, due to the time and cost restrictions they need to estimate the SEV without performing any actual road tests.
Traditionally, this would involve a manual analysis, by the engineer, of the vehicle X  X  wind noise spectrum, its spectrum descriptors and taking into consideration the vehicle segment.
However, even though engineers have good domain knowledge, they cannot make quick and reliable estimations. This poses a problem, since the vehicle X  X  improvement during the improve-ment process can not be properly evaluated. To circumvent the problem of the SEV estimation, a machine learning model is proposed that can automatically predict the SEV from the basic vehicle characteristics that can be easily measured.

The main requirement for the adoption of the prediction model in the domain expert X  X  work processes is often the ability to easily interpret the model. Therefore, machine learning meth-ods like linear regression, regression trees and decision (predic-tion) rules are often used despite the better performance of other less interpretable methods, such as support vector machines, nearest neighbour methods, etc. However, the interpretability of the prediction model can introduce yet another important pro-blem. The model interpretation can be in conflict with the expert X  X  domain knowledge which leads to model rejection ( Pazzani et al., 2001 ) and could consequently result in lower willingness to use machine learning models in general. Both, the model interpretability and its compliance with expert X  X  domain knowledge, are required in the SEV prediction task.

Since the interpretability is one of the main requirements of Fiat wind tunnel engineers, we avoided using the frequency spectra as learning data for building prediction models  X  however, we do report the evaluation results for prediction models based on full spectra for comparison purposes. Spectrum is a vector of 110 floating point values that represent the sound pressure values of sound signal at different frequencies and is as such too fine grained to be successfully used in prediction models. Instead, we opted for the standard spectrum descriptors which are used by engineers on a daily basis. Table 1 shows the attributes that were used to describe the data set for the machine learning algorithms.
We used 4 attributes, of which 3 are numeric and 1 is nominal, and 1 class variable (SEV). Segment is a binary attribute that holds information about whether a vehicle belongs to the LCV (light commercial vehicle) segment or not. Originally, every vehicle belonged to one of the segments in {A, B, C, D, L, LCV}, however, we decided to join the A, B, C, D, and L segment since the differences are negligible compared to LCV and because of the problem with a small number of labelled examples  X  attributes with many possible values can lead to an undesired segmentation of the data set. Overall is the overall sound pressure level of an
A-weighted wind noise spectrum, expressed in decibels (dB) ( Aarts, 1992 ). Loudness is similar to overall, with the difference being that it captures the level of noise loudness by taking into account the psycho-acoustic properties of a human X  X  hearing apparatus and it is expressed in Sone ( Stevens, 1955 ). Articulation
Index (AI) expresses the percentage of words that are understood by a listener in a noisy environment ( Kryter, 1962 ). Note that overall, loudness, and articulation index are derived from the spectrum and we can expected them to be highly correlated. Additionally, the complex and expensive nature of the on-road
SEV testing, only 28 examples were available for learning in our application. This is another important point why we avoided using the whole frequency spectrum, since it introduces a severe dimensionality problem, known also as the curse of dimension-ality ( Beyer et al., 1999 ). In SEV prediction task this is reflected as the inability to produce sufficiently accurate prediction model.
Since aeroacoustics engineers have a general understanding of the dependencies between the spectrum descriptors (attributes) and the SEV value (class), it is reasonable to consider their knowledge and only learn models consistent with their knowl-edge. These dependencies can be represented as qualitative constraints ( Forbus, 1984 ): (1) SEV  X  Q  X  X  AI ) (2) SEV  X  Q  X  Loudness ) (3) SEV  X  Q  X  Overall )
The first constraint states that when the value of the AI ( Articulation index ) increases the SEV also increases (the  X  sign), assuming that values of other attributes stay the same. In practice, this means that if the speech is more intelligible in the vehicle, then the driver comfort is better. In contrast, the second and third constraints state that if the value of the loudness or the overall sound pressure level is increased then the SEV is decreased (the sign), again, assuming that values of other attributes stay the same. This kind of knowledge representation is intuitive to experts, who often analyse individual attributes independently of the other attributes, even though the are aware of the dependencies between them.

The validity of expert X  X  qualitative constraints can also be confirmed by analysing the scatter plots between the individual spectrum descriptors and the SEV as shown in Fig. 4 . The lines in the plots depict the univariate linear regressions:
SEV  X  k n descriptor  X  n , intercept of the linear function. We can see that the signs of slopes k in Fig. 4 conform to the qualitative constraints that were given by the aeroacoustics engineers. Intuitively, they expect that the same relations are reflected in the multivariate linear regression model.
 linear regression (LR) algorithm we obtain the following linear function for computing the SEV:
SEV  X  1 : 9259 integer  X  Segment  X  LCV  X  where integer  X  Segment  X  LCV  X  equals 1 if Segment is LCV and 0 otherwise. We can see that the coefficient of the Overall attribute is violating the third qualitative constraint  X  it has a positive sign, whereas the qualitative constraint requires a nega-tive sign. Such a model was rejected by the aeroacoustics engineers, even though it is technically correct and achieves good accuracy on the given data.
 define the numerical constraints that are based on the expert X  X  qualitative constraints and that will address the problem of the wrong coefficient signs: squares optimization method yields a linear model that conforms to the constraints, but assigns a value close to zero ( 7 : 5445 ) to the Overall attribute coefficient. This makes the model less useful for the aeroacoustics engineers, since they want to use all the available attributes. This can be avoided by slightly modifying the constraints, so that they do not allow values that are too close to zero:
SEV  X  1 : 7610 integer  X  Segment  X  LCV  X  that has all coefficient values significantly different from 0 and performs slightly better in terms of prediction accuracy. However, the problem is that the Overall and Loudness attribute coefficients are again set on the upper bound ( 0.1) of the CLS-0.1 constraint and that modifying the upper bound is directly reflected in the linear regression model. Same holds if we further lower the upper bounds for Overall and Loudness attribute coefficients. This is an undesirable effect, since the positions of bounds can directly influence the resulting linear regression model. 4.1. Learning linear regression models consistent with expert knowledge that are consistent with expert knowledge. The problems with existing methods motivated us to develop an approach that is similar to the Q 2 (Qualitatively faithful quantitative prediction,  X 
Suc et al., 2004 ) for learning the linear regression models that are consistent with the provided global constraints. The difference is that we modify the attribute values to obtain the qualitatively faithful model and that we correct the model iteratively, one attribute at the time.

Generally, the method first detects regions of the attribute space that are consistent with the global constraints and those that are not. The main problem we faced was the collinearity of the attributes; looking at the attributes separately (univariate approach) they all conform to the provided expert knowledge.
However, as seen in the above linear model, in the multivariate setting, the learning data do not imply the same correlations between the attributes and the class as given by the experts.
Therefore, we developed an iterative approach for correcting the coefficients in a linear model.

We use the recently developed method Pade  X  to detect the regions of space with different qualitative relations between attributes and class (  X  Zabkar et al., 2011 ). Pade  X  is a tool for estimating partial derivatives of the target functions from numer-ical data. It is basically a pre-processor that takes numerical data as the input and assigns computed qualitative partial derivatives to the examples. Using the preprocessed data, an appropriate machine learning method can be used to induce a generalized model  X  a model that splits the attribute space into regions with different qualitative properties. In this paper decision tree learn-ing was used. The induced decision tree shows the monotone relations between the class variable and the other attributes.
Next follows the overview of the procedure for learning linear regression models with qualitative constraints. The explanations and justifications for the individual steps of the procedure are illustrated using the example that follows the overview. (1) Build an initial linear regression model M D on the data set D . (2) Compare the coefficients X  signs in M D against the qualitative (3) Select the first attribute A whose coefficient sign is in (4) Learn a linear model M D 0 on a modified data set D 0 that has (5) Compute the class attribute residuals C 0 by subtracting the (6) Use Pade  X  to obtain the partial derivatives P  X  @ C 0 =@ A . (7) Use the attribute A and the partial derivatives P as a class (8) Update the values of the attribute A for every example e in (9) Learn a new linear regression model M Q using the updated (10) If M Q still contains any violation with respect to Q then
The procedure is best explained by continuing to use the example from the SEV prediction domain. We already performed the first three steps  X  we obtained the initial linear regression model M 0 , compared its attribute coefficients against the three qualitative constraints that were provided by the domain experts and selected the Overall attribute that is in violation of the third constraint.

Steps 4 and 5 are needed to remove the variance of the class attribute SEV that can be explained by the attributes that do not violate the qualitative constraints (and are not relevant for the remainder of the procedure). Therefore, we constructed a linear regression model using only the attributes Articulation Index , Loudness , Segment and the class attribute SEV . Then, for every example in the data set, we subtracted the predicted class value from the actual class value, computing the class attribute resi-duals SEV 0 . The remaining variance of the SEV , the SEV 0 , can then be modeled using the problematic attribute Overall . This allows us to perform the univariate analysis of the Overall attribute with regard to the residuals SEV 0 in step 6.

In step 6 we compute the partial derivatives @ SEV 0 =@ Overall for every example in the data set. The sign of the derivative determines whether the SEV 0 is increasing (  X  sign) or decreasing ( sign) at a given point. We can use this information to find the monotonic sub-regions where the Overall attribute is increasing or decreasing.

Fig. 5 shows the scatter plot for Overall and SEV 0 . First, we can see that the univariate linear regression model for the entire region (the solid line) has a slightly positive coefficient sign ( k  X  0.0172) for the attribute Overall , which is a root cause for qualitatively invalid coefficients in the initial linear regression model. Second, we can see that the signs of partial derivatives form two distinct sub-regions with the boundary at 71.45, where only the examples to the right of the boundary are in violation of the qualitative constraints. The dotted and dashed lines depict the linear regression models for the left and right sub-regions respectively.

We use the decision tree in step 7 to build a model to determine whether a certain example is violating the qualitative constraints ( Fig. 6 ). A decision tree is appropriate, since it can construct a generalized model that is less sensible to noise in the estimations of partial derivatives. Since the examples that fall into the right leaf ( Q  X  X  Overall  X  ) of the decision tree are in violation of the qualitative constraints, the Overall attribute values of those examples are corrected (step 8) by assigning them the average Overall attribute value of the remaining (valid) examples: e where V is a set of examples with the  X  X  X alid X  X  Overall value. By assigning the mean value to the Overall attribute of the violating examples, we effectively removed their influence in the learning of the linear regression model  X  machine learning methods com-monly compute the missing values using the mean value of the existing values.

Using the modified data set in step 9, we obtain a slightly different linear regression model:
SEV  X  1 : 8327 integer  X  Segment  X  LCV  X 
We can see that the violation of the third qualitative constraint is now removed and the linear regression model is now in com-pliance with the domain expert X  X  knowledge (step 10).

Since we used the linear kernel, it is also possible to use the described procedure with Support Vector Machines (SVM). The initial weights that are returned from the learning on the original data set are the following: 0 : 5148 integer  X  Segment  X  LCV  X  0 : 1937 Overall 0 : 4306 AI 0 : 4246 Loudness
Again, the Overall attribute is in violation of the qualitative constraints. When we perform the Pade  X  analysis in step 6, we obtain an almost identical scatter plot to that in Fig. 5 . The examples are again divided into two ranges with the boundary at
Overall  X  71.45, where the left side has the relation Q  X  Overall  X  and the right side has the relation Q  X  X  Overall  X  . When the data set is corrected, we get the next attribute weights from the SVM: 0 : 4251 integer  X  Segment  X  LCV  X  0 : 3878 Overall 0 0 : 1680 AI 0 : 5418 Loudness
We can see that the sign of the Overall attribute weight is successfully corrected. 4.2. Evaluation
In addition to our approach of learning regression models that are consistent with expert knowledge, we also tested several common machine learning methods for performance comparison in terms of prediction accuracy:
Linear regression (LR): a simple multivariate linear regression without attribute selection. It provides an understandable model: an equation, that can provide additional knowledge about the problem to the engineers.

Constrained least squares (CLS): a linear regression is defined as an optimization problem, which can be solved by using the least-squares method. We used the CLS implementation of
Coleman and Li (1996) , which only takes the lower and upper bound constraints (no linear inequalities or equalities) that we can use for tuning attribute coefficient values.

Support Vector Machines (SVM): we used the SMOReg imple-mentation of SVM ( Sch  X  olkopf and Smola, 2002 ) in conjunction with linear kernel (SVM-lin), quadratic kernel (SVM-quad) and
RBF kernel (SVM-rbf) with gamma  X  0.05. We used the attri-bute normalization and set the parameter c  X  2.
 frequency spectra (a vector of 110 numeric values). Attributes
Loudness , Articulation Index and Overall were substituted by attributes of sound pressure levels at 110 frequencies, while keeping the Segment attribute. The tests were performed using the following machine learning methods:
The methods were tested using the leave-one-out scheme and the root-mean-squared-error ( RMSE ) and the relative RMSE ( RRMSE ) were computed to evaluate the results. These measures of accuracy are defined as:
RMSE  X 
RRMSE  X  RMSE RMSE where y i is the actual class value for the i-th example, ^ y predicted class value, N is the number of examples and the baseline predictor always predicts the average class value of the training examples. The results of the evaluation can be found in Table 2 . with quadratic kernel performs the best. However, its support vectors can not be easily interpreted and are therefore not suitable for aeroacoustics engineers. Next are linear regression and SVM with linear kernel, which both have a very similar performance and an interpretable model that violates the qualitative constraints.
Another easily interpretable method, regression tree, performs the worst, just slightly better than predicting average value. SVM with
RBF kernel, linear regression with correlation terms and k NN performance also did not give satisfactory results.

Improvement of prediction accuracy is also obtained when using our approach in addition to providing the model that is consistent with the expert knowledge. Linear SVM coupled with our approach (SVM-lin  X  QC) achieves the highest accuracy of 0.6387 RMSE, followed by slightly lower accuracy of linear regres-sion model (LR  X  QC). Using the constrained least-squares (CLS) method with the constraints CLS-0 and CLS-0.1 we also obtained the qualitatively faithful linear models, however their prediction accuracy is comparable to that of standard linear regression.
Results in Table 3 support our decision to avoid using the entire frequency spectrum directly for learning. None of the methods can provide a sufficiently accurate model. Moreover, the GP method performs almost as the baseline predictor, despite the extensive parameter tuning. 4.3. Evaluation on the publicly available data sets
The aim of this section is to demonstrate that the proposed approach can also be applied to other real life domain that exhibit the violation of expert X  X  domain knowledge in regression models without sacrificing the prediction accuracy. For this purpose we have chosen 6 domains from the UCI ( Frank and Asuncion, 2010 ) and DELVE ( Torgo, 2010 ) repository that show similar inconsis-tencies between the expert X  X  domain knowledge and the obtained linear regression model. Qualitative constraints were obtained from domain experts or using the common knowledge in cases when a domain expert was not available.

AutoMPG : the data set contains 398 examples with 6 contin-uous and 1 discrete attribute. 2 The target to predict is the vehicle gasoline consumption in miles-per-galon unit. Interpretation of the linear regression model falsely suggests that the increase of engine displacement causes the increase of miles-per-galon or in other words the decrease of fuel consumption.

Automobile : the data set contains 201 examples with 9 contin-uous attributes. The target to predict is the vehicle price and the interpretation of the linear regression model shows a violation of expert X  X  knowledge that the higher values of vehicle length and the city miles-per-galon attributes have a negative impact on the vehicle price.

CPU : the data set contains 209 examples with 6 continuous attributes. The target to predict is the published relative perfor-mance of the computer X  X  CPU. Interpretation of the model falsely shows that the higher values of minimum channels in units attribute has a negative impact on the CPU X  X  relative performance.
CompAct : the data set contains 8192 examples with 12 con-tinuous attributes. To speed up the evaluation process we used only 10% of randomly selected examples from the original data set. The target to predict is the portion of time that CPUs run in user mode. The obtained linear regression model contains three violations of the expert X  X  constraints -the model falsely suggests that lwrite (number of writes between system memory and user memory), scall (number of system calls of all types per second) and swrite (number of system write calls per second) positively contribute to the time that CPUs run in user mode.

Cloud : the data set contains 108 examples with four contin-uous and two discrete attributes. The target to predict is the amount of rain in eastern target region of Tasmania between mid 1964 and January 1971. The resulting linear regression model contains one violation of qualitative constraints  X  it suggests that the increase of value of corresponding rainfalls in the north-west control area (NWC) attribute has a negative impact on the amount of rain in the eastern target region.

Bodyfat : the data set contains 252 examples with 14 contin-uous attributes. The target to predict is the percentage of body fat. The obtained model contains four violations of qualitative constraints  X  it falsely suggests that the increase of Neck , Thigh , Knee or Biceps circumference has a negative impact on the percentage of body fat.

The evaluation and comparison of our approach to standard machine learning methods was performed using the 10-fold cross validation scheme. Selected measure of performance was RMSE. The results of the evaluation can be found in Table 4 . Values in bold indicate the best performing method for the given data set.
Using our novel approach to learning regression models consistent with expert knowledge (LR  X  QC), we successfully obtained modified regression models that conform to all expert X  X  constraints. The evaluation results on UCI and DELVE domains show that there is no significant change in prediction accuracy between our approach (LR  X  QC, SVM-lin  X  QC) and standard regression method (LR, SVM-lin). This means that in most cases enforcing the qualitative constraints does not have a negative impact on the prediction accuracy, while providing models that are acceptable to the domain experts. 5. Discussion
In this paper we proposed a 6-step approach to reducing the wind noise in cars. The approach was implemented within the
X-Media project 3 and it was used as one of the main demonstra-tors of knowledge management in complex environments. We have shown that machine learning methods can successfully be applied to the domain of aeroacoustics. In addition to the sufficiently accurate predictions (confirmed by the domain expert) made by our tool, engineers can also gain new insights by examining the learned linear regression model.

A novel approach to building linear regression models was introduced that takes into account qualitative constraints. These constraints are provided by the domain expert and are further automatically trimmed by examining the dependencies between the attributes and the target variable. It was shown that when using this approach the obtained model is in compliance with the expert X  X  knowledge and in some cases also the prediction error is decreased. The best performing method for the SEV prediction task was the linear SVM with qualitative constraints that achieved a 0.6387 RMSE with the leave-one-out strategy. There-fore, we can expect to get reasonably small relative errors as the
SEVs are given on a 1 X 10 scale. The general applicability of our approach was also demonstrated using the six real world domains from UCI and DELVE repositories. It was shown that all incon-sistencies with expert X  X  domain knowledge are removed from the model while the prediction accuracy does not significantly differ from models learned with standard regression methods. How-ever, the approach has an important drawback.

In step 7 of our novel approach we obtain the decision tree that would  X  X  X deally X  X  split the input space into two partitions. In general, the partial derivatives could form more than two mono-tonic sub-regions that would result in a more complex decision tree (more node splits and leaves). Such partitioning would, therefore, require a more general approach of correcting the sub-regions than computing the average of  X  X  X alid X  X  values in step 8. This issue will be addressed in future work.

The entire application was also evaluated by the end users (aeroacoustics engineers). There were six persons involved and each had to score the application with a value between 1 and 10, according to its functionality , usability , and performance . The average given values were 7.5, 7.9, and 9.2, respectively. In general, the results of the evaluation were very positive, since the engineers found the application to be very useful. Besides the described machine learning tool, they also recognized the follow-ing points of strength: An ability to support a real complex improvement process.
The potential to be an excellent tool for training new aero-acoustics engineers.

An automated search for the target vehicle in 2. step of the process, which effectively relieves the engineers of the need to manually search for the vehicles.

We can conclude that the field of vehicle aeroacoustic comfort can significantly benefit from a machine learning approach and
Artificial Intelligence techniques in general. It can improve the engineers X  efficiency, which results in shorter vehicle develop-ment cycles and thus reduces the development costs.
 Acknowledgements
This work has been funded by the X-Media project ( www. x-media-project.org ) sponsored by the European Commission as part of the Information Society Technologies (IST) programme under EC grant No. IST-FP6-026978.
 References
