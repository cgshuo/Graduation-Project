 The correspondence between sentiment terminology and the active language used for expressing opinions is a crucial pre-requisite for effective sentiment analysis. Mining sentiment terminology includes the detection of new opinion words as well as inferring their polarities. In this paper, we first propose a novel approach based on the interchangeability characteristic of words to detect new opinion words through time. We then show that the current non-time-based polar-ity inference approaches may assign opposite polarity to the same opinion word at different times. To tackle this issue, we consider the polarity scores computed at different times as polarity evidences (with the possibility of flawed evidences) and combine them to compute a globally correct polarity score for each opinion word. The experiments show that our approach is effective both in terms of the quality of the discovered new opinion words as well as its ability in infer-ring their polarities through time. Furthermore, we show the application of mining sentiment terminology through time in the sentiment classification (SC) task. The exper-iments show that mining more recent new opinion words leads to greater improvement in the performance of SC. To the best of our knowledge, this is the first work that inves-tigates  X  X ime X  as an important factor in mining sentiment terminology.
 I.2.7 [ Natural Language Processing ]: Text Analysis;; H.3.1 [ Content Analysis and Indexing ]: Linguistic pro-cessing Algorithms, Experimentation.
 Opinion Word Mining, Temporal Opinion Lexicon, Senti-ment Orientation, Word Polarity
Current sentiment lexicons, contain most of the common opinion words (like excellent and amazing ), but they miss emerging sentiment words like slang and urban opinion words (such as delish and cozy ) as well as the misspelled com-mon opinion words (like excellance and recomend ). How-ever, such words are commonly used in user generated con-tents (UGCs) to express opinions. As such, there is a need to develop techniques to address the big gap between the current sentiment lexicons and the emerging opinion words. This includes the detection of new opinion words as well as inferring their polarity through time.

Previous research have mainly utilized synthetic and co-occurrence patterns to mine new opinion words [9, 1]. In this research, we show that  X  X ime X  X s another important factor for mining sentiment words in the sense that: (a) new opinion words emerge at different times as UGC is growing, (b) the current methods based on synthetic and co-occurrence pat-terns often estimate different polarity for opinion words at different times, and (c) though rarely happen, opinion words may change their sentiment orientation through time. For example, the term  X  awesome  X  X eant  X  terrifying  X  X n the past, but nowadays it means  X  amazing  X .

Figure 1 illustrates the polarity scores of several new opin-ion words estimated by the popular non-time-based Turney and Littman X  X  (2003) method at different times (the time granularity is six months). As Figure 1 shows, for each word, the polarity scores are often wrongly estimated at different times and vary through time. This is because of the varying co-occurrence patterns observed at different times.
To tackle the above challenges, we first utilize the inter-changeability characteristic of words to detect new opinion words through time. We then propose a novel polarity in-ference technique to infer time accumulated polarity scores for the new opinion words. We consider the polarity scores obtained at different times as polarity evidences and com-bine them to compute the time accumulated polarity scores. For this purpose, we use the Dempster-Shafer combination theory [2, 4] which is known to be strong with respect to flawed evidences. We show that this consideration leads to more accurate polarity inference.

To summarize, the contributions of this paper are as fol-lows: (a) we propose a time-aware approach to mine senti-ment terminology, (b) we show that polarity accumulation through time result in a more accurate polarity inference than the polarity obtained using the non-time-based meth-ods at different times, and (c) we show that mining more recent new opinion words leads to greater improvement in the performance of sentiment classification.

The average performance of our method in detecting new opinion words is 68.76%. Furthermore, our approach signif-icantly outperforms the state-of-the-art non-time-based po-larity inference method by 5.8% on average in F1 score. In addition, experiments on sentiment classification (SC) of re-views show that the new opinion words significantly improve the F1 performance over the baseline through time.
The rest of this paper is organized as follows: Section 2 elaborates our approach for mining sentiment terminology through time. Section 3 reports the experimental settings and results. Section 4 surveys the related work and, finally, Section 5 concludes the paper and discusses future direc-tions 1 .
In this section we present a context-aware approach to mine new opinion words through time.
We propose to find the interchangeable words that are dis-tributionally similar with seeds (words with already known polarity) and consider them as candidate new opinion words. We define the interchangeability between two words as fol-lows:
Definition 1 : Two words are interchangeable, if they have: 1. low co-occurrence, 2. high overlap in their left neighboring words, and 3. high overlap in their right neighboring words.
Due to the intuitive definition of interchangeability, the co-occurrence between two interchangeable words is expected to be low. For example, since  X  suggest  X  and  X  recommend  X  are interchangeable, we usually use one of them in a sen-tence to give a suggestion. Furthermore, we here separately deal with the left and right neighboring words to discard the effect of the words that occur on the opposite sides of the target words in measuring their interchangeability.
To find interchangeable words with seeds, we assume that the time-span T i includes all the reviews written in the time interval [ t i 1 , t i ]. Let T i , i j , be the source time-span and T j be the target time-span. The words of T j that are interchangeable with at least one seed of T i are candidate new opinion words. Given two words a i and b i from the same Th is research is done as part of NExT projects. NExT Search Center is supported by the Singapore National Re-search Foundation &amp; Interactive Digital Media R&amp;D Pro-gram Office, MDA under research grant (WBS:R-252-300-001-490). time-span T i , we first define the side-oriented PMI between them as follows: where Count i ( x ) is the number of sentences that contain x at time-span T i , and M i is the number of sentences at T
In addition, given the word a i from the time-span T i , we refer to its left (right) significant neighboring words (SNWs) as the words of T i that (1) occur on the left (right) side of a , and (2) have positive P M I l ( P M I r ) values with respect to a i . For each word, we only consider its top z left (right) SNWs that have the highest P M I l ( P M I r ) values with re-spect to the word.

Let v i be a seed word from T i , i j , and w j be a target left and right SNWs of v i and w j respectively and compute the context similarity between the two words as follows: where O indicates left or right, u is a common (left or right) SNW of both v i and w j , and  X  is a constant. Equation (2) computes the similarity between two words by aggregating the PMI values of their common left and right SNWs. It assigns high similarity scores to the words that either (1) frequently co-occur, or (2) rarely co-occur but have high semantic association, such as  X  recommend  X  and  X  suggest  X . According to Definition 1, we are only interested in the latter case, so, we discard the words that frequently co-occur. For this purpose, we use the side-oriented PMI as the measure of co-occurrence and compute the interchangeability score between two eords as follows: where c is a small constant. We construct an interchange-ability pool, P ij , for each source-target time-pair, ( T 8 i j , as follows: where each w j k 2P ij is a candidate new opinion word of T that is interchangeable with at least one seed of T i .
We utilize a non-time-based approach to first assign a po-larity score to each candidate new opinion word w j k that ap-pears in an interchangeability pool. In particular, for each w , we use all the reviews up to time T j to compute the polarity score of w j k obtained at time T j . This will be con-sidered as a polarity evidence for the word w in the future.
We use the optimization framework proposed in [1] to compute the polarity scores at different times. In this frame-work, seeds and candidate opinion words are respectively treated as labeled and unlabeled data and modeled in a so-called polarity graph . Edges are weighted by a function of the co-occurrence between their nodes. This framework op-timized the prediction for unlabeled nodes by assigning sim-ilar polarity scores to nodes that are connected with heavy weighted edges in the polarity graph.

In our setting, we consider each candidate opinion word w cess, will be assigned a polarity score f ( w j k ) by the optimiza-tion framework. We refer to this value as a polarity evidence for the word w obtained at T j and show it by P ol ( w j k
As we elaborated before, non-time-based polarity infer-ence methods may assign opposite polarity scores to a given opinion word at different times. This is mainly because such methods rely on the noisy co-occurrence patterns. To tackle this issue, we compute a time accumulated polarity score for each candidate opinion word using its polarity scores ob-tained at different times. For this purpose, we utilized the Dempster-Shafer (DS) combination theory as it is strong with respect to the flawed evidences.

In the DS theory [2, 4] there exist a set of mutually exclu-sive alternatives which is called the frame of discriminant  X . For example, for opinion words,  X  can be defined as follows:
The DS theory assigns a belief value to each element of the power set of  X . Formally, the function m : 2 ! [0 , 1] is called basic probability assignment (BPA), if it has the following properties: where m ( A ) is the belief value that the proposition A 2 true for an observation (a word here). Obviously, the belief values of the power set members should add up to 1.
BPAs can be inferred from various evidences using the combination rules of the DS theory. For example, let the polarity score of the word w at time-span T 1 , i.e. P ol ( w be a positive value 0 s 1. The BPAs for this evidence can be defined in DS terms as follows:
Note that, according to the DS theory, the above evi-dence only supports the positivity of w and does not con-vey anything about its negativity. Therefore, the value 1 m w 1 ( positive ) reflects the amount of uncertainty about the status of w at time T 1 , i.e. m w 1 ( positive or negative ). In other words, if the evidence is flawed, w could still be either positive or negative. The uncertainty state of the DS the-ory is the major characteristic that differentiates this theory from other theories like Bayesian probability theory.
The DS combination rule can be defined as follows: Let m w @ j ( A ) be the combined evidence about the polarity of w up to time T j . The value of m w @ j ( A ) can be computed by combining w  X  X  polarity evidences obtained at times T 1 , ..., T j evidences is as follows:
The denominator is the normalization factor that ensures that m w @ j ( A ) is a BPA. We use the above belief values, m w @ j ( A ) , 8 A 2 2 , to compute the time accumulated po-larity score of w j up to time-span T j , P ol ( w @ j ), as follows: where
I =
The value of m w @ j ( positive or negative ) indicates the amount of uncertainty that we have about the polarity of w at T j . Therefore, when this value is maximum, we avoid tagging w as a positive or negative opinion word at T j and let the future time-spans determine its polarity. We consider any candidate opinion word with a non-zero P ol ( w @ j ) as a new opinion word.

This formulation can tolerate the noise of the polarity scores obtained at different times from the co-occurrence patterns.
We first explain the datasets and some parameter settings and then report the evaluation results.
We used three popular opinion lexicons to supply the seeds. In particular, we consider the words that are either labeled as strong in the General Inquirer [8] or subjectivity lexicon [10], or have a positive or negative score of one in SentiWordNet [3] as seeds. Words with the objectivity score of one in SentiWordNet are considered as non-opinion. For SentiWordNet, we only consider the first sense of the words.
We used a large dataset of Amazon.com reviews gathered by Jindal and Liu [7] to perform the experiments. This dataset contains more than 5.8M reviews. We only per-formed the experiments on the reviews from Jan 2000 to May 2006 as there are very few reviews available before 2000 in this dataset. We divided this data into 13 time-spans at 6-monthly time intervals. For sentiment classification of re-views, we balanced the data on the positive and negative reviews. 1 met tle bro s off erred hea lings 2 to pnotch exc ellance w orshiped sti cklers 3 am assed m uss so ulfully ub ers 4 reig ning eart hshattering exc ellance exsp eriance 5 fab so ulfully u bers di mmu 1 irks gu tteral ta rgetted pl agerized 2 gro aner mo lested reg retably du mbledore 3 do omy de railed rac kets w orsened 4 um ph errie sqe aky gim mie 5 ma ggots do dged oz zfest lam er T able 1: Top 5 detected words in the latest four time-spans.

In Equation (2), we set the parameter  X  to 3, as suggested by [6], and z to the average sentence length in the above corpus. All the parameters of the optimization framework of Section 2.2 are set to the values of the best performing system as reported in [1].

In all the subsequent experiments, we used the two-tailed paired t-test p &lt; 0 . 01 for significance testing.
Table 1 shows the top five positive and negative words learned by our method for the latest four time-spans. As it is shown, some misspelled seeds like excellance , and regretably etc as well as urban words like fab , topnotch , and lamer etc have been accurately detected.

We also evaluated the quality of the discovered new opin-ion words based on the percentage of such words that are indeed opinion. For this purpose, we manually annotated them as opinion or non-opinion. The average performance was 68.76% (the corresponding Table is removed due to space limit). The annotation shows that our method accu-rately detected many misspelled seeds as opinion words. In addition, the extracted non-opinion words were mainly the words that frequently co-occurred with one type of seeds (e.g. negative) and rarely co-occurred with the other type. These words were assigned high polarity scores by the opti-mization framework and consequently labeled as opinion by our system. Such words, though non-opinion, are good po-larity indicators. For example, the word  X  Dumbledore  X  was labeled as negative as it frequently occur in negative reviews (high co-occurrence with negative seeds) but not with posi-tive ones. We noticed that this word refers to a character in the  X  X arry Potter X  series who received many negative opin-ions against his positive role in the movie. These types of non-opinion words could be used as great polarity indicators.
For this evaluation, we considered part of the seed dataset as the test data and the rest as training data, and evaluated how the time accumulated polarity improves the polarity of the test seeds computed at different times. We only con-sidered seeds that occur more than 10 times in our review corpus (i.e. 2500+ seeds) and conducted 5-fold cross valida-tion over the seed dataset based on the following evaluation measures: wh ere N correct is the number of test seeds that were assigned correct polarity (either positive or negative), N labeled number of test seeds that were assigned non-zero scores, and N seed is the total number of test seeds. Figure 2 shows the results. At each time T j , Spcf indicates the polarity inference performance of the optimization framework of [1], and Acm indicates the performance of the time accumulated polarity computed from the combination of all the polarity evidences obtained up to time T j , Equation (9). The results show that polarity accumulation through time leads to more accurate polarity inference than the non-time-based method at different times.

As Figure 2 shows, the performance of Acm increases through time with greater improvements in the latter times. This is because of the availability of more polarity evidences about the test seeds for Acm as time passes. However, the performance of Spcf depends on the co-occurrence pat-terns obtained at each time and as Figure 2 shows varies greatly through time. Acm significantly outperforms the Spcf method by 5.8% on average in F1 score. The differ-ence between the two methods is significant for all T i , i 5.
In this section, we study how the learning of new opin-ion words through time affect the performance of sentiment classification (SC) of reviews. Note that, we use a word-matching-based sentiment classifier instead of popular clas-sifier (like SVM or Naive Bayes) in order to emphasize that the performance improvements come mainly from the qual-ity of the new opinion words. However, we used manually created rules to handle negations as they reverse the sen-timent of the opinion words. In particular, we considered words/phrases like not , barely , lack of , and never etc, as well as cases that the negation word is not negating the words In total, we compiled 36 negation words and rules.
Given a review, our word-matching-based sentiment clas-sifier computes a sentiment score for the review by summing up the polarity scores of its opinion words. A positive score indicates a positive review, and a negative one indicates a negative review. We expect the performance of this classifier to be better when we use opinion words with higher quality.
Figure 3 shows the performance of SC using seeds and new opinion words. Seeds as the baseline indicates the SC per-formance when we only use seeds to classify reviews of each time-span, while Seeds+NOW OPT a nd Seeds+NOW A C respectively show the SC performance when we use both seeds and all the new opinion words we learned up to time T i to classify the reviews of the same time-span T i . Note that Seeds+NOW OPT us es the most recent polarity score of each new opinion word (obtained from [1]) to perform SC, whereas Seeds+NOW A C utilizes the time accumulated po-larity score for this purpose, Equation (9). The results show Fi gure 3: The effect of polarity inference on the per-formance of sentiment classification.
 Fi gure 4: Performance of sentiment classification through time (best seen in color). that both Seeds+NOW OPT an d Seeds+NOW A C signif-icantly outperform Seeds for all T i , i 2. This reflects the utility of the new opinion words found for SC. Also, Seeds+NOW A C significantly outperforms Seeds+NOW OPT fo r all T i , i 5. This shows the effectiveness of the time ac-cumulated polarity scores obtained by DS combination rule.
We also studied the effect of learning more recent new opinion words on the performance of SC. For this purpose, at each time, we used seeds and the current opinion words to perform SC on the current and future reviews. Figure 4 shows the results. Each SC T i indicates the performance of SC when we use both seeds and the new opinion words that we learned up to time T i to perform SC on the current and future reviews, i.e. the reviews of T k , 8 k i . Here, we use the time accumulated polarity scores.

The results show that the SC performance improves as time passes. In other words, each SC T i improves the SC performance over the earlier SC T k , 8 k i . For example consider the time T 5 . As highlighted in Figure 4, the per-formance of SC using the new opinion words we learned up to time T 5 , i.e. SC T 5, is greater than the performance of SC using the new opinion words we learned at earlier times, i.e. SC T 1 to SC T 4. In other words, the improve-ment is greater when the sentiment classifier utilizes more recent new opinion words. This is because, in the more re-cent times, the classifier receives a greater number of new opinion words with more accurate polarity scores due to the existence of more polarity evidences.
Mining opinion words from user generated content is a crucial prerequisite for effective sentiment analysis. This task includes the detection of new opinion words as well as inferring their polarities. Previous research in this area can be mainly divided into dictionary-and corpus-based ap-proaches. Dictionary-based approaches like [5] utilize dictio-naries like WordNet to mine opinion words, whereas corpus-based approaches use synthetic and co-occurrence patterns in text for this purpose [9, 1]. Dictionary-based methods are precise but, in contrast to corpus-based approaches, unable to find informal or so-called urban opinion words.
As a corpus-based approach, Turney and Littman [9] pro-posed to determine the polarity of a word by comparing its tendency toward positive or negative seeds. Amiri and Chua, (2012) showed that the polarity association among and between seeds and unlabeled words improves the perfor-mance of the above method. They showed that both labeled and unhealed data are important for learning the polarity scores.

The difference between this paper and the previous ap-proaches is that we pay attention to  X  X ime X  and consider it as another important factor for mining sentiment words.
We proposed the interchangeability method to find new opinion words through time and utilized Dempster-Shafer theory to obtain a time accumulated polarity for each new opinion word. We showed that the time accumulated po-larity better reflects the polarity of the opinion words than the polarity obtained at each time. We also showed that mining more recent opinion words leads to better sentiment classification. In the future, we aim to investigate the the effect of the length of the time span on the performance of sentiment terminology mining and sentiment classification. [1] H. Amiri and T. S. Chua. Mining slang and urban [2] A. P. Dempster. A generalization of bayesian [3] A. Esuli and F. Sebastiani. Sentiwordnet: A publicly [4] S. G. A mathematical theory of evidence. In Princeton [5] A. Hassan and D. R. Radev. Identifying text polarity [6] A. Islam and D. Inkpen. Semantic text similarity [7] N. Jindal and B. Liu. Opinion spam and analysis. In [8] P. J. Stone and E. B. Hunt. A computer approach to [9] P. D. Turney and M. L. Littman. Measuring praise [10] T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing
