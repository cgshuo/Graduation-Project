 In most existing data mining tools, visualization is only used during two particular steps of the process: in one of the first steps to view the original data and in one of the last steps to view the final results. Some new methods called Visual data Mining have recently appeared [13], [15], trying to involv e more significantly the user in the data mining process and using more intensively the visualization [1]. Usual visualization techniques for multidimensional data sets, such as parallel coordinates [7] or scatter-plot matrices [4] do not scale well to high dimensional data sets. For example, Figure 1 shows a subset of the Lung Cancer data set [8] with one hundred dimensions (among 12533 dimensions), the user cannot detect any pertinent information from the visualization. Even with low numbers of elements, high dimensionality is a serious challenge for current display techniques. 
To overcome this problem, one promising approach is dimensionality selection [10]. The basic idea is to select some pertinent dimensions without loosing too much information and then to treat the data set in this subspace. Most of these methods focus on supervised classification and evaluate potential solutions in terms of predictive accuracy. Few works [9], deal wi th unsupervised classification where we do not have prior information to evaluate potential solution. 
We present a semi-interactive algorithm we have developed, integrating automatic algorithm, interactive evolutionary algorithm and visualization. First evolutionary algorithm generates pertinent dimension subsets, according to the user choice (clustering or outlier detection). The data are displayed in these dimension subsets using parallel coordinates. The user can interactively choose the visualization that seems significant and selected dimension subsets are then in input of the next evolutionary algorithm generation and so on until having optimal visualization. The originality of our approach is to combine evolutionary algorithm to obtain optimal dimension subsets which represent the original data set without loosing information for unsupervised mode (clustering or outlier detection) with a visualization tool to present the user interactive evaluation and le t him actively participate in evolutionary algorithm searching with resulting in a fast er evolutionary algorithm convergence. We present some results obtained with several high dimensional data sets. 
This paper is organized as follows. The next section describes some existing interactive evolutionary algorithms and a brief overview of dimensionality selection methods. We describe our evaluation functions for outlier detection and clustering and then we present some results obtained by our new interactive evolutionary algorithm in section 3 before the conclusion and future work. Interactive Evolutionary Algorithm (IEA) can be defined [14] as an optimization method that adopts evolutionary algorithm (EA) based on subjective human evaluation. It is simply an EA technique whose fitness function is replaced by human. Evolutionary algorithms have attracted attention in the data mining and knowledge discovery processes. They are used for performing some pre-processing and post-processing steps of the knowledge discovery process and then extract high-level knowledge from data. They focus on dimension selection and pruning of a set of classifiers used as black box fitness function. If the user is involved, he contributes to a faster evolutionary algorithm convergence. A wide number of approaches for dimension selection have been proposed [10]. Dimension selection algorithms can broadl y be classified into three categories randomized search. Evolutionary algorithms [11] such as genetic algorithms [6] can also be used for dimension selection. We use genetic algorithm for dimension selection: the individual represents a small subset of dimensions. At first step, the initial population is ready; it is evaluated by a distance-based function for outlier The originality of our approach is to combine both user interactive validation and automatic validation (black box fitness function) for a fast algorithm convergence. The advantage is the proposed solutions are not biased by the user choice or automatic fitness function, but both are considered to generate next evolutionary algorithm generation. 2.1 Clustering Fitness Function The goal of clustering is to partition a data set into subgroups such that objects in each particular group are similar and objects in different groups are dissimilar. With most of the algorithms, the user has first to choose the number of clusters. To determine number of clusters we usually use validity indexes [12] that are based on the minimization of the sum of squared distances within (SSW) the clusters and the maximization of the sum of squared distances between (SSB) the clusters. We use this technique first to find the optimal number of clusters. Then, we try to obtain (with K-means [5]) the optimal validity index values in the dimension subsets that are generated by evolutionary algorithm to optimize clustering in this dimension subset We use the values obtained to classify the genetic algorithm individuals. Some individuals are then visualized with the parallel coordinates and presented to the user to determine and select the most significant ones for clustering. 2.2 Outlier Detection Fitness Function distinct or inconsistent with the remainder of data. The main problem is to define this dissimilarity between objects characterizing an outlier. Typically, it is estimated by a function computing the distance between objects, the next task is to determine the objects farthest from the mass. We choose an Euclidean distance-based outlier detec-tion procedure as evaluation of each evolutio nary individual. The procedure output is the outlier point and the distance between this point and the remainder of data in the subset of attributes (selected dimensions). We use the obtained distance to classify the genetic algorithm individuals [2]. The farthest element will be considered as an outlier element, the whole data will be visualized in dimension subsets and presented to the user for validation and to consider them for the next generation. After the user has chosen the problem (outlier detection or clustering) and data set, we have the view shown in fig.2 with 9 visualization screens of evolutionary individuals. Randomly 9 individuals are presented to the user who chooses the visualizations that seem significant. In our example (outlier detection), we want to find visualizations where we can see element different from the whole data set. 
For example, visualization number 4 and 7 are selected because they contain element that has extreme values and can be outlier. The corresponding dimensions are in input of the next genetic algorithm generation. Once this step is performed we operate the standard genetic operators (crossover and mutation) to create new generations guided by user choice and so on, until we obtain optimal subset displayed using parallel coordinates and scatter-plot matrices in the final view (figure 3). 3.1 Algorithm Parameters Our genetic algorithm starts with a population of 50 individuals (chromosomes), every individual is made of 4 genes (user-defined) because we want to allow visual interpretation. Once the whole population has been evaluated and sorted, we operate a crossover on two parents chosen randomly. Then, one of the children is muted with a the population, under the median. We run our algorithm for 10000 generations and each 100 generations, we propose 9 randomly chosen individuals for user interactive evaluation. Our algorithm ends after a maximum number of iterations or after the user satisfaction. 3.2 Evaluation of Convergence We evaluate how human involvement speeds up the convergence of the EA search. Since our approach deals with subjective fitness value combined with black box fitness depending on the application task (clustering or outlier detection), we compare convergence of the evolutionary algorithm described in [2] and Viz-IGA. The role of human in Viz-IGA is to select the best candidates in the 4-D visualization, while in the GA [2] user only validates the final result. We obtain the same results in some minutes with Viz-IGA (about ten times faster than automatic GA as shown in Figure 4). Traditional visualization techniques for multidimensional data sets do not scale well to high dimensional data sets, the user cannot detect any pertinent information. To overcome the problem of high dimensionality, one promising approach is dimensionality selection. We have proposed to use user perception to overcome drawbacks of dimension selection process, according his choice of the unsupervised learning problem. We have implemented semi-interactive algorithm, integrating automatic algorithm, interactive evolutionary algorithm and visualization. First evolutionary algorithm generates pertinent dimension subsets without loosing too much information. Some dimension subsets are visualized using parallel coordinates and the user interactively chooses the visualization that seems significant. The selected dimensions are in input of the next evolutionary algorithm generation and so on until having optimal visualization according to the unsupervised problem. 
The originality of our approach is to combine evolutionary algorithm to obtain optimal dimension subsets which represent the original data set without loosing information for unsupervised mode (clustering or outlier detection) with a visualization tool to propose the user interactive evaluation and let him actively participate in evolutionary algorithm searching with more efficiency resulting in a faster evolutionary algorithm convergence. 
Of course, we have improved convergence of algorithm with the user interactive involvement, but we think that if we have other fitness function easier to compute than different black boxes fitness functions, we can optimize the algorithm. 
