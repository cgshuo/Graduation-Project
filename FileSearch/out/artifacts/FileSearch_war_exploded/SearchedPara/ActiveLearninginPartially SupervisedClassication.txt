 Positiv e Example based learners reduce human annotation e ort signi can tly by remo ving the burden of lab eling the negativ e examples. Various metho ds have been prop osed in literature for building classi ers using positiv e and unla-beled examples. However, we empirically observ e that clas-si cation accuracy of the state of the art metho ds degrades signi can tly as the num ber of lab eled positiv e examples de-creases. In this pap er, we prop ose an activ e learning based metho d to address this issue. The prop osed metho d learns starting from a handful of positiv ely lab eled examples and a large num ber of unlab eled examples. Exp erimen tal results on benc hmark datasets sho w that the prop osed metho d per-forms better than the state of the art metho ds when the percen tage of lab eled positiv e examples is small. Categories and Sub ject Descriptors: I.5.2 [Pattern Recognition]: Design Metho dology -Classi er design and evaluation General Terms: Algorithms Keyw ords: Activ e Learning, Partially Sup ervised Classi -cation, Positiv e Example Based Learners
Traditionally , binary classi ers have been built using man-ually collected sets of positiv e and negativ e examples. Col-lecting this lab eled data is highly time consuming and re-quires a large amoun t of human e ort. This is esp ecially true for classi cation problems (for example, web page clas-si cation) where the negativ e class is de ned as the univ erse excluding the positiv e examples. For the negativ e class it becomes even harder and more time consuming to create a set of examples whic h would represen t the real world dis-tribution. For example, to build a review page classi er, the negativ e class will comprise of all web pages excluding review pages. Sev eral other interesting applications can be found in [5][12]. In suc h problems, the goal is to iden tify the positiv e set of examples from the univ ersal set. we no longer have only lab eled positiv e and unlab eled exam-ples, but also examples from the negativ e class. A key asp ect of this learning problem is that the distribution of the three groups of examples changes over a perio d of time as more and more examples get lab eled. Hence, it is imp ortan t to adapt the hyperparameters (that con trol the con tributions of these three groups of examples) as the learning progresses. Also, this needs to be done ecien tly. Considering these asp ects, we pro vide an ecien t and e ectiv e activ e learning based metho d using SVM classi er to address the problem of learning from very few lab eled positiv e examples and un-lab eled examples. Our exp erimen tal results on benc hmark datasets sho w that when the percen tage of lab eled positiv e examples is low, the performance of the prop osed metho d is better than BSVM under the condition that both the meth-ods use the same num ber of lab eled examples.

The rest of the pap er is organized as follo ws: Section 2 presen ts our metho d in detail, whic h is follo wed by its em-pirical evaluation and comparison with existing metho ds in Section 3.
In this section we presen t the prop osed activ e learning based metho d to learn a SVM classi er starting from very few lab eled positiv e examples P and a large num ber of un-lab eled examples U .
To start with, we have unlab eled examples U and very few lab eled positiv e examples P . During the activ e learning pro cess, examples from U get lab eled progressiv ely and we also get negativ e lab eled examples N . Giv en these three sets of examples, we use supp ort vector mac hine (SVM) to learn the classi er from P , N and U as follo ws. Let the set of is an input vector and y i is its class lab el. For i 2 P , y i =1, and y i =-1 for i 2 N . Lik e in BSVM, we lab el the unlab eled examples U as -1. Treating the unlab eled examples as neg-ativ e examples is motiv ated from the follo wing result [8]: if the sample size is large enough, we can get a good classi er by minimizing the num ber of unlab eled examples as posi-tive while constraining the positiv e examples to be correctly classi ed. Thus, we have the follo wing SVM form ulation: M inimiz e : w
Subj ect to : y i ( w T x i + b ) 1 i Here, parameters C P , C N and C U denote the hyperparam-eters that con trol the di eren t weigh ts given to the classi-cation errors in P , N and U resp ectiv ely, and w and b represen t the weigh t vector and bias term. This form ulation di ers from standard SVM as there are unlab eled examples whic h are treated as negativ e. On the other hand, it di ers from BSVM because it has constrain ts on negativ e lab eled examples. Even though this form ulation looks simple, sev-eral challenges arise from the activ e learning setting and speci c nature of the problem. 1. The activ e learning setting brings in distributional vari-may be noted that the qualit y of hyperparameter estimates impro ves with the num ber of lab eled examples. In general poor estimation can result in some ineciency in terms of the num ber of examples lab eled during activ e learning.
The key step in activ e learning is selecting the example to be lab eled from the set of unlab eled examples. Various metho ds of selecting examples for SVM classi ers have been prop osed in [10]. For demonstrating the capabilit y of our metho d, we have used simple mar gin based technique. It picks the unlab eled example whic h is closest to the decision boundary . The main motiv ation for using suc h a simple technique is that it is ecien t and often e ectiv e. Eciency is imp ortan t because the num ber of unlab eled examples can be very high in practice. While using simple techniques, some ineciency in terms of lab eling cost may be there in practice. However, the computational cost asso ciated with an exp ensiv e evaluation measure can be prohibitiv ely high when the num ber of unlab eled examples is large. In suc h cases, often the evaluation is restricted to only a subset of unlab eled examples. But the disadv antage is that we are not evaluating all the examples. While other activ e learning techniques can certainly be used, studying their impact is beyond the scop e of this pap er.
In this subsection, we presen t few heuristics that help in impro ving the scalabilit y of the prop osed metho d. These heuristics essen tially reduce the time tak en to train the clas-si er. As one can easily notice, the most exp ensiv e step of our metho d is nding the optimal values of the learner's tunable hyperparameters: C P , C N and C U . But since we exp ect them to change slowly , we can speed up this step by restricting the searc h space of tunable hyperparameters to values nearb y the optimal values of previous iteration. For building the initial classi er, though, we can not apply this heuristic and hence we have to explore the full searc h space to nd the optimal values.

Another heuristic to speed up our metho d is to tune the hyperparameters only after lab eling m examples because the likeliho od of the parameters changing drastically on addition of just one example is very small. The value of m needs to be selected carefully . A large m can lead to use of parameters that are no longer optimal, while a small m can lead to a high computational cost. In our exp erimen ts we found m =15 to be a reasonable choice.

Finally , we can use the weigh ts w learn t from the previous iteration as the starting weigh ts in the SVM optimization problem. This can also help in the optimization function to con verge faster. We evaluated the performance of the prop osed metho d on News20 and WebKB datasets. The News20[1] dataset con-tains text documen ts from 20 di eren t newsgroups. Eac h newsgroup was used as positiv e class, and the rest as neg-ativ e class. Therefore, we had 20 One-vs-All binary clas-si cation problems. The WebKB[2] dataset is a web page classi cation problem with the web page belonging to one of the 7 categories. For our exp erimen ts we chose only 4 most populous categories, thereb y giving us 4 One-vs-All binary classi cation problems.
 Figure 1: Varian t-2 ( lled boxes) vs. BSVM (un lled boxes) on Class 20; here initial lab eled set con tains 10% of the positiv e ex-amples decreasing. Since our comparison is for a xed num ber of la-beled examples, the noise in the prop osed metho d can nev er be lesser than the BSVM metho d. This is because the num-ber of positiv e examples tak en away (after lab eling) from the unlab eled examples can nev er be higher than the condition in the BSVM system. Lab eled negativ e examples are very useful to discriminate between the two classes up to a certain value (lower noise) and impro ve the performance signi -can tly. However, as increases, the noise in the system starts playing a ma jor role and nulli es the gain obtained by using lab eled negativ e examples. To validate this reason-ing we conducted an exp erimen t where we started the activ e learning pro cess when initial lab eled set con tains 50% of the positiv e examples (unlik e the previous exp erimen ts where we started with 10% lab eled positiv e examples as P ). The performance results on a set of classes where BSVM was performing better in the previous exp erimen t are given in Figure 3. We observ ed that the performance of our metho d impro ved signi can tly. This clearly indicates that the fall in performance is due to the presence of more positiv e exam-ples in U . In this con text, it may be noted that nding x positiv e documen ts (as assumed in the BSVM metho d) re-quires lab eling more than x documen ts because the pool of positiv e documen ts is not kno wn before hand and therefore the lab eling cost will be higher.

We also conducted statistical signi cance tests on WebKB dataset. Due to lack of space we have not pro vided the plots here. We observ ed that the performance di erences were not statistically signi can t particularly at lower values of . We believ e that the nature of the problem is di eren t from News20. Speci cally , the class imbalance ratio is higher and deviates from the scenario of having highly dominan t negativ e examples. As in the case of News20 dataset, the BSVM metho d starts performing better as increases. Comparison with SL and SSL: In this exp erimen t, we brie y compared our metho d with SL and SSL. As the activ e learning iterations progress, we start getting lab eled nega-tive examples. Once we get a sucien t num ber of positiv e and negativ e examples, it mak es sense to explore SL and SSL, and see how they compare with the prop osed metho d. We used standard SVM form ulation for SL and multiple switc hing transductiv e SVM [11] for SSL. These classi ers were built for di eren t values of using the initially lab eled
