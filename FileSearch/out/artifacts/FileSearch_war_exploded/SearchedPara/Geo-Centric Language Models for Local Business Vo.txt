 Voice search is an increasingly popular application of speech recognition to telephony. In particular, in the last two years several companies have come out with systems for local business voice search (LBVS). In this type of application, the user pro-vides a desired location (city/state) and a business name, and the system returns one or more match-ing business listings. The most traditional LBVS applications are commercial 411 services, which are implemented as a speech-only two-exchange dialog such as the one in Figure 1. In this approach to LBVS, the speech recognizer (ASR) uses one gram-mar to recognize city/state, and then uses separate grammars for recognizing listings in each local area. This gives relatively high recognition accuracy.
Advancements in ASR and search technology have made a more information retrieval-style LBVS feasible. In this approach, the ASR typically uses a large stochastic language model that permits the user to specify location and listing name or cate-gory together in a single utterance, and then sub-mits recognition results to a search engine (Natara-jan et al., 2002). This gives the user more flexibility to  X  X ay anything at any time X . However, in recent evaluations of one-exchange LBVS we have found that locations are recognized with much higher ac-curacy than listing names 1 . This may mean that the user has to repeat both location and listing several times (while in a traditional two-exchange interac-tion only one piece of information would have to be repeated). In effect, system developers have traded recognition accuracy for interaction flexibility, po-tentially increasing user frustration.

Advances in mobile phone technology make it possible for us to combine the advantages of two-exchange and one-exchange LBVS. The newest smart phones come with global positioning system (GPS) receivers and/or with the ability to determine location through cell tower triangulation or wi-fi. If we know the location of a LBVS user, we can use a geo-centric language model to achieve improved speech recognition accuracy and speed. This ap-proach unobtrusively exploits the benefits of two-exchange voice search applications, while maintain-ing the flexibility of one-exchange systems.
In this paper, we present an efficient algorithm for constructing geo-centric language models from a business listing database and local business search logs. Our algorithm has several advantages: it pro-vides a language model for any user in any location; the geographic area covered by the language model is adapted to the local business density, giving high recognition accuracy; and the language models can be pre-compiled, giving fast recognition time. In an experiment using LBVS queries, we achieve: a 16.8% absolute improvement in recognition accu-racy and a 3-fold speedup in recognition time with geo-centric language models when compared with a nationwide language model (such as those used in one-exchange LBVS); and a 4.4% absolute increase in recognition accuracy and a 16% speedup in recog-nition time with geo-centric language models when compared with local area language models (such as those used in two-exchange LBVS).
 The rest of this paper is structured as follows: In Section 2 we discuss related work on voice-driven local search. In Section 3 we present the motivation for and architecture of a LBVS application. In Sec-tion 4 we present our algorithm for generating geo-centric language models. In Section 5 we describe an evaluation of the performance of our geo-centric language models on business listing name queries from a deployed voice-driven search application. In Section 6 we conclude and present future work. LBVS is the most recent variation on automated di-rectory assistance (Buntschuh et al., 1998). ASR for directory assistance is difficult for several rea-sons: the vocabulary is large and includes foreign words; there may be multiple possible pronuncia-tions for many words; and the frequency distribu-tion of words in the vocabulary is unusual, with a few words occurring very often and the rest, rarely. These difficulties are compounded by directory size. For example, Kamm et al. (1995), in experiments on personal name directories, showed that ASR ac-curacy decreases from 82% for a 200 name directory to 16.5% for a 1.5 million name directory.

One way to reduce the directory size is to cover a smaller geographic area. For example, early LBVS covered only one city (Seide and Kellner, 1997; Collingham et al., 1997). Later, two-exchange, ap-plications required the user to specify their desired location in the first exchange. This information was then used to select a local area grammar or language model for recognition of the listing name (Acero et al., 2008; Bacchiani et al., 2008; Yu et al., 2007; Georgila et al., 2003). In our research, we have cre-ated a novel method for constructing language mod-els that cover a very small geographic area specific to the user X  X  geo-location.

Another way to reduce the directory size is to drop listings that are unlikely to be requested. For exam-ple, Kamm et al. (1995), in their analysis of 13,000 directory assistance calls, found that a mere 245 list-ings covered 10% of the call volume, and 870 list-ings covered 20%. Chang et al. (2008) found that in their data sets, 19-25% of the call volume was cov-ered by the top 200 listings. We take a different ap-proach: we add frequent nationwide listings to our geo-centric language models to increase coverage.
Other work related to ASR in automated direc-tory assistance has looked at ways in which users refer to locations (Gupta et al., 1998) and listings (Li et al., 2008; Scharenborg et al., 2001; Yu et al., 2007), confidence scoring for directory assistance search results (Wang et al., 2007), and ways of han-dling recognition errors through multimodal confir-mation and correction (Acero et al., 2008; Chang et al., 2008; Paek et al., 2008). We do not address these issues here. The current generation of smart phones contains GPS and/or can run applications that can detect the user X  X  geo-location using cell tower triangulation or wi-fi. We hypothesize that this geo-location infor-mation can be used in mobile LBVS to improve recognition accuracy without sacrificing interaction flexibility. Our analysis of a directory assistance data set shows that in the majority of cases, users request local listings. It is frustrating for the user of a LBVS who cannot retrieve information for a busi-ness right around the corner. So, a LBVS should maximize accuracy for local listings 2 .
 Figure 2 shows the architecture of a mobile LBVS. It includes ASR (in a speech-only or multi-modal interface), search, and presentation of results (through speech, text and/or graphics). It also in-cludes location information from GPS, cell tower tri-angulation or wi-fi, or the user X  X  query history (from previous dialogs, or previous turns in this dialog). There are two ways to use geo-location informa-tion in ASR for LBVS. One way is to use the user X  X  geo-location to automatically determine the nearest city. City and state can then be used to select a lo-cal area language model (LM) for recognizing list-ing names. The advantages of this approach include: human knowledge about location can be included in the design of the local areas; and local areas can be designed to produce a minimal number of local area LMs. However, if the user is near the edge of the pre-defined local area, the selected LM may exclude businesses close to the user and include businesses far away from the user. Also, some local area LMs contain many more directory listings than others.
Another way is to construct a geo-centric LM covering businesses in a given radius around the user X  X  geo-location. This approach has the advan-tage that listings included in the language model will certainly be close to the user. However, on-the-fly computation of geo-centric language models for large numbers of users is too computationally demanding given current database and processing technology. It is equally impractical to pre-compile all possible geo-centric language models, since com-mercial GPS provides coordinates accurate to about 20 feet. Here we present an algorithm for approxi-mating true geo-centric language modeling in a way that is computationally feasible and user relevant. 4.1 Local Area Language Models Telecommunications companies have long under-stood that customers may not know the exact town in which a desired listing is, or may be interested in listings from several nearby towns. Considerable ef-fort has been devoted to defining local service areas (LSAs) for telephone directories. In the directory service that provided the database we use, business listings are organized into about 2000 LSAs, each consisting either of several adjacent small towns or of one big city. For example, the Morristown, NJ LSA includes Morristown itself as well as 53 ad-jacent localities and neighborhoods spanning from Pine Brook in the north-east to Mendham in the south-west. By contrast, the New York, NY LSA contains only New York City, which includes sev-eral hundred neighborhoods. The Morristown, NJ LSA contains 50000 business listings while the New York, NY LSA contains more than 200000 listings.
We construct one LM for each LSA, giving roughly 2000 local area LMs for the whole of the USA. 4.2 Geo-Centric Language Models To construct a a geo-centric LM for a user, we need geo-coordinates (for the center of the LM) and a search radius (to determine the extent of the LM). It is computationally infeasible to either pre-compute geo-centric LMs for each uniquely identifiable set of geo-coordinates in the USA, or to compute them on-the-fly for large numbers of users. Fortunately, the number of business geo-coordinates in the USA is much sparser than the number of possible user geo-coordinates. There are about 17 million name-address unique businesses in the USA; assuming 8-digit geo-code accuracy they are located at about 8.5 million unique geo-coordinates 3 . So we build LMs for business geo-coordinates rather than user geo-coordinates, and at run-time we map a user X  X  geo-coordinates to those of their closest business.
To determine the search radius, we need a work-ing definition of  X  X ocal listing X . However,  X  X ocal X  varies depending on one X  X  location. In New York City, a local listing may be one up to ten blocks away (covering a smaller geographic area than the LSA), while in Montana a local listing may be one that one can drive to in 45 minutes (covering a larger geographic area than the LSA). Compare Figures 3 and 4.  X  X ocal X  is clearly related to business den-sity at a particular location. So we compute business density and use this to determine the radius of our geo-centric LMs.

We can do even better than this, however. Busi-nesses are clustered geographically (in towns, shop-ping malls, etc.). This means that the set of listings local to one business is likely to be very similar to the set of listings local to a nearby business. So we do not need to build a separate LM for each business listing; instead, we can pre-determine the number of businesses we want to be different from one LM to another. Then we can  X  X uantize X  the business geo-coordinates so that those that have fewer than that number of businesses different between their search radii end up sharing a single LM.

Our algorithm for constructing geo-centric LMs starts with LSAs. It proceeds in two stages: first, the business centers for the LMs are found. Second, a search radius is computed for each LM center; and third, the data for the LM is extracted.

The LM center finding algorithm uses two param-eters: r 1 (radius within an LSA; should be a little smaller than average LSA radius) and N q (number of businesses that should be different between two different geo-centric LMs). For each LSA: 1. Find mean latitude and longitude for the LSA: 2. Exclude national businesses which are listed in 3. Compute business density in the most business-4. Compute geo-location quantization accuracy: 5. Quantize geo-coordinates for each business in
The LM radius finding algorithm also uses two parameters: r 2 (maximum search radius for an LM); and N p (minimum number of businesses within a geo-centric language model, should be smaller than average number of businesses per LSA). For each LM center: 1. Count the number of businesses at 1-mile ra-2. Choose the smallest radius containing at least 3. Extract data for all listings within the radius. The number of geo-centric LMs can be arbitrar-ily small, depending on the parameter values. We believe that any number between 10K and 100K achieves good accuracy while maintaining tractabil-ity for LM building and selection. In the experi-ments reported here we used r 1 = 3 . 5 , N q = 50 , r for the whole USA.

To summarize: we have described an algorithm for building geo-centric language models for voice-driven business search that: gives a local language model for any user anywhere in the country; uses business density determine  X  X ocal X  for any location in the country; can be pre-compiled; and can be tuned (by modifying the parameters) to maximize performance for a particular application In this section we report an evaluation of geo-centric language models on spoken business listing queries from an existing directory assistance application. We compare the recognition accuracy and recogni-tion speed for geo-centric LMs to those of local area LMs, of a national LM, and of combined LMs. 5.1 Data Our test data comes from an existing two-exchange directory assistance application. It comprises 60,000 voice queries, each consisting of a city and state in the first exchange, followed by a business listing name in the second exchange.

We wanted to test using queries for which we know there is a matching listing in the city/state pro-vided by the caller. So we used only the 15000 queries for which there was a match in our nation-wide business listing database 4 . We categorized each query as nationwide or local by looking up the listing name in our database. We considered any listing name that occurred five or more times to be nationwide; the remaining listings were considered to be local. This method fails to distinguish between national chains and different companies that happen to have the same name. (However, from a recog-nition point of view any listing name that occurs in multiple locations across the country is in fact na-tionwide, regardless of whether the businesses to which it refers are separate businesses.) It is also quite strict because we used string equality rather than looser name matching heuristics. Example na-tional queries include Wal-mart and Domino X  X  Pizza . Example local queries include Sauz Taco (Glendale, CA); Dempsey X  X  Restaurant (Adrian, MI); and Con-cord Farmers Club (Saint Louis, MO). Some queries contain street names, e.g. Conoco on South Divi-sion ; uh Wal-Mart on five thirty five ; and Chuy X  X  Mesquite Broiler off of Rosedale .

For each query in our data, we say that its local area LM is the local area LM that comes from its city and state, and that contains its listing name. Its geo-centric LM is defined similarly. 5.2 Language Model Construction We constructed two baseline LMs. The first is a Na-tional LM. To take advantage of the non-uniform distribution of queries to listings (see Section 2), we also build a Top 2000 LM containing only informa-tion about the top 2000 most frequently requested listing names nationwide 5 . We expected this LM to perform poorly on its own but potentially quite well in combination with local LMs.

For national, top 2000, local area and geo-centric LMs, we build trigram Katz backoff lan-guage models using AT&amp;T X  X  Watson language mod-eling toolkit (Riccardi et al., 1996). The models are built using the listing names and categories in our nationwide listing database. Listing names are converted to sentences containing the listing name, street address, neighborhood and city/state.
We predict that location-specific LMs will achieve high accuracy on local listings but will not be very robust to national listings. So we also exper-iment with combination LMs: local area combined with top 2000; geo-centric combined with top 2000; local area combined with national; and geo-centric combined with national. We use two combination stategies: count merging and LM union . 5.2.1 Count Merging
The count merging approach can be viewed as an instance of maximum a posteriori (MAP) adapta-tion. Let hw be a n-gram ending in word w and with a certain context h , and let c L ( hw ) and C T ( hw be its counts in the geo-centric/local area corpus L and top 2000 corpus T respectively. Then p ( w | h ) is computed as: where  X  L is a constant that controls the contribution of each corpus to the combined model. We applied this combination strategy to local area/geo-centric and top 2000 only, not to local area/geo-centric and nationwide. 5.2.2 LM Union
The LM union approach uses a union of language models at runtime. Let W = w 0 w 1 ...w sentence, p L ( W ) be the probability of W in the geo-centric/local area corpus L , and p T ( W ) be the prob-ability of W in the top 2000/national corpus T . Then p (
W ) is computed as: p ( W ) = max (  X  L p L ( W ) , (1  X   X  L ) p T ( W )) (2)  X 
L is a constant that controls the contribution of each corpus to the combined model. We applied this com-bination strategy to local area/geo-centric and top 2000, and to local area/geo-centric and nationwide.
Given the small size of our test set relative to the large number of local LMs it is unfeasible to train  X 
L on held-out data. Instead, we selected a value for  X  L such that the adjusted frequency of the top business in the top 2000 corpus becomes similar to the frequency of the top business in the local LM. We anticipate that if we did have data for training  X  L more weight would be given to the local area/geo-centric LM. 5.3 Experimental Method In our experiments we use AT&amp;T X  X  Watson speech recognizer with a general-purpose acoustic model trained on telephone speech produced by American English speakers (Goffin et al., 2005). We ran all tests on a research server using standard settings for our speech recognizer for large vocabulary speech recognition. For each LM we report recognition ac-curacy (string accuracy and word accuracy) overall, on nationwide listings only, on local listings only, and on queries that contain street names only. We also report recognition time (as a fraction of real time speed). 5.4 Results Results are given in Table 1. Comparing the base-line (National LM) to our geo-centric LMs, we see that we achieve a 16.8% absolute increase in overall sentence accuracy with a 3-fold speedup. Most of the improvement in sentence accuracy is due to bet-ter performance on local queries; however, we also achieve a 2.9% absolute increase in sentence accu-racy on nationwide queries.
Now we look at the performance of different ap-proaches to nationwide and local language model-ing. First we compare the two nationwide LMs. As expected, we see that the overall sentence accuracy for the National LM is more than twice as high as that of the Top 2000 LM, but the recognition time is more than twice as slow. Next we compare the two local language modeling approaches. We see that geo-centric LMs achieve a 4.4% absolute increase in overall sentence accuracy compared to local area LMs and a 5.5% increase in sentence accuracy on local listings, while using less processing time. Next we look at combination language models. When we combine local and nationwide LMs us-ing LM union, we get small increases in sentence accuracy for nationwide queries compared to local LMs alone. However, sentence accuracy for local listings decreases. Also, these models use more pro-cessing time than the local LMs. When we com-bine local and national LMs using count merging, we get larger increases in sentence accuracy for na-tionwide queries over local LMs alone, and smaller decreases for local queries, compared to using LM union. LMs trained using count merging use more processing time than those trained using LM union, but still less than the National LM.

We conclude that: geo-centric language model-ing leads to increased recognition accuracy and im-provements in recognition time, compared to us-ing a national language model; geo-centric language modeling leads to increased recognition accuracy and improvements in recognition time, compared to using local area language models; and geo-centric language models can be combined with a  X  X ost fre-quently asked-for X  nationwide language model to get increased recognition accuracy on nationwide queries, at the cost of a small increase in recognition time and a slight decrease in recognition accuracy for local listings.

Further analysis of our results showed another interesting phenomenon. While geo-centric LMs achieve higher recognition accuracy than the Na-tional LM and local area LMs on nationwide and local queries, recognition accuracy on queries that contain a street name decreases. The likely reason is that small local LMs do not have rich street name coverage and people often do not refer to a street ad-dress precisely. A person might use a route number instead of a street name; if a single road has dif-ferent names at different points they might use the wrong name; or they might use a variation on the actual name. For example, the query  X  X onoco on South Divison X  is correctly recognized by our na-tional LM but not with a geo-centric LM. The clos-est matching listing in our database for that loca-tion is  X  X onoco Convenience Store on South Boule-vard X . We note that we did not make any attempt to generalize over the street names in our LMs, sim-ply pulling one street name for each listing from the database. Slightly more robust handling of street names may cause this phenomenon to disappear. Smart phones are able to give system developers increasingly detailed information about their users. This information can and should be exploited to give improved robustness and performance in customer services. In this paper, we explored the use of lo-cation information (from GPS or cell tower triangu-lation) to improve ASR accuracy in LBVS. We pre-sented an algorithm for geo-centric language model generation that: adapts to the local business density; enables good local listing coverage; and requires only a limited number of language models. We com-pared the performance of our geo-centric language modeling to an alternative  X  X ocal X  language model-ing approach and to a nationwide language model-ing approach, and showed that we achieve signifi-cant improvements in recognition accuracy (a 4.4% absolute increase in sentence accuracy compared to local area language modeling, and a 16.8% absolute increase compared to the use of a national language model) with significant speedup.

We are currently testing our geo-centric language models in a LBVS prototype. In future work, we will optimize the parameters in our algorithm for geo-centric LM computation and merging. We also plan to explore the impact of integrating language modeling with search, and to examine the impact of these different language modeling approaches on performance of a trainable dialog manager that takes n-best output from the speech recognizer.

