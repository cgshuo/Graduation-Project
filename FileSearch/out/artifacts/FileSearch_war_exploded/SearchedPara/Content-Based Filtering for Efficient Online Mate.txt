 Real-time materialized view maintenance has become increasingly popular, especially in real-time data warehousing and data streaming environments. Upon updates to base r elations, maintaining the corresponding materialized views ca n bring a heavy burden to the RDBMS. A traditional method to mitigate this problem is to use the where clause condition i n the materialized view definition to detect whether an u pdate to a base relation is relevant and can affect the materialize d view. However, this detection method does not consider the content in the base relations and hence misses a large number of filter ing opportunities. In this paper, we propose a content-based method for detecting irrelevant updates to base relations of a materialized view. At the cost of using more space, this method increases the probability of catching irrelevant updates by judic iously designing filtering relations to capture the content in the b ase relations. Based on the content-based method, a prototype real -time data warehouse has been implemented on top of IBM X  X  Syst em S using IBM DB2. Using an analytical model and our prototyp e, we show that the content-based method can catch most (or al l) irrelevant updates to base relations that are missed by the tr aditional method. Thus, when the fraction of irrelevant updates is no n-negligible, the load on the RDBMS due to materialized view main tenance can be significantly reduced. Categories and Subject Descriptors H.2.4 [Systems]: query processing, relational datab ases, H.2.7 [Database Administration]: data warehouse and repos itory General Terms Algorithms, Experimentation, Performance Keywords Materialized view maintenance, content-based filter ing 
Recently, there has been a growing trend to use dat a warehouses to make real-time decisions about a corp oration X  X  day-to-day operations. Most major RDBMS vendors hav e spent great efforts on real-time data warehousing, includ ing IBM X  X  business intelligence, Microsoft X  X  digital nervous system, Oracle X  X  Oracle10g, NCR X  X  active data warehouse, and Compaq X  s zero-latency enterprise. Since conventional RDBMSs canno t provide all the capabilities required by real-time data war ehousing, a few startup companies have appeared on this market, e.g ., GoldenGate Software Inc., DataMirror, and Information Builders. 
A real-time data warehouse needs to handle real-tim e, online updates in addition to traditional data warehouse q uery workload. traditional data warehouses  X  when a base relation is updated, maintaining the materialized view(s) defined on it can bring a heavy burden to the RDBMS. 
This problem is not limited to real-time data wareh ousing, as real-time materialized view maintenance is a genera l requirement of modern database applications. For example, the D B research community has recently identified data stream manag ement systems as a promising approach to support many fut ure data-intensive applications [13]. Storing data streams o n disks and building materialized views on them to speed up que ry processing has been proposed in [5]. In fact, the DB research community has realized the commonality between real-time data war ehousing and data stream applications [8, 13]. Also, some commer cial RDBMS vendors (e.g., Oracle, Teradata) have started to en hance existing commercial RDBMSs to support data stream applicatio ns. 
To reduce materialized view maintenance overhead, [ 2, 4] proposed several methods to detect irrelevant updat es to a base relation R that do not affect the materialized view MV defined on R . However, all these methods are  X  content-independent  X  in the sense that they only consider the where clause cond ition in MV  X  X  definition while ignoring the content in the other base relations of MV . As a result, these methods make over-conservative decisions and miss a large number of filtering opportunities.

For example, consider the following materialized vi ew MV : Assume that MV records anomaly so that very few tuples in R , S , and T satisfy the where clause condition ( R.a = S.b and S.c=T.d and R.e&gt;20 and S.f=  X  X yz X  and T.g=50 ) in MV  X  X  definition. Suppose a tuple t R whose t R .e=30 is inserted into base relation R . Since t .e&gt;20 , the existing methods in [2, 4] cannot tell whethe r or not MV will change. Therefore, the standard materialized view maintenance method has to be used. S is checked for matching tuple t S exists, T is further checked for matching tuple(s) t cached in memory, such checking can incur a large n umber of I/Os and become fairly expensive. However, since MV records anomaly, mostly likely the insertion of t R into R will not affect MV and thus all the expensive checking is wasted.
 To address this problem, we introduce the concept of content-based filtering into materialized view maintenance. More specifically, we identify four important requiremen ts for efficient filtering and propose a content-based method for de tecting irrelevant updates to base relations of a materiali zed view. To the best of our knowledge, no existing summary data str ucture [1, 3] satisfies all these four requirements. Our key idea is to design filtering relations that summarize the most relevant information in the base relations and fulfill these four requireme nts. These filtering relations capture the relationship among multiple join attributes and can be efficiently maintained in rea l time. Upon an update  X  R to a base relation R that has a materialized view MV defined on it, the RDBMS uses the corresponding fil tering irrelevant. Checking filtering relations is usually much faster than checking base relations. Also, compared to the wher e clause condition in MV  X  X  definition, filtering relations can provide more precise information about whether  X  R is irrelevant. In this way, the RDBMS can quickly and more precisely detect irr elevant updates to R and hence reduce the materialized view maintenance overhead. As discussed in detail in Section 4, exis ting RDBMSs do not have the capability of automatically buildin g filtering relations and systematically using them to perform content-based filtering for materialized view maintenance. We have implemented a prototype real-time data ware house SRW (Stream-based Real-time Warehouse) on top of IB M X  X  System S [16], a stream processing middleware that provides an application execution environment for processing el ements (or applications) developed by users to filter and anal yze data streams. Our real-time data warehouse is deployed a s a processing element on top of System S. It uses IBM DB2, and ma terialized views stored there are maintained in real-time usin g our content-based method. Figure 1 shows the architecture of ou r prototype. Data continuously comes to System S as streams. Som e  X  X ase X  data streams are stored in the real-time data wareh ouse and materialized views are built upon them. System S in teracts with the real-time data warehouse, using materialized vi ews to speed up the processing of data streams (the processing o f certain data streams requires posing queries to the RDBMS [5]). Also, upon arrival of new tuples from the  X  X ase X  data streams, the corresponding materialized views are refreshed imme diately. 
We investigate the performance of both the content-based method and the traditional content-independent meth od with an analytical model. This analytical model provides a means to determine when applying filtering relations is bene ficial. The analytical model is validated in our SRW prototype. Our results show that in a large number of cases, with minor ov erhead, the content-based method can catch most (or all) irrele vant updates to base relations that are missed by the content-indep endent method. As a result, we can avoid most of the unnecessary l oad on the RDBMS due to materialized view maintenance. 
The rest of the paper is organized as follows. Sect ion 2 describes the content-based detection method for ir relevant updates. Section 3 investigates the performance of both the content-based and the content-independent methods. We discuss related work in Section 4. 
In this section, we describe our content-based meth od for detecting irrelevant updates to base relations of a materialized view. We focus on materialized join views that store and maintain the join results of multiple base relations. Update s include insertions, deletions, and modifications. Consider a base relation R that has a join view JV defined on it. R . This filtering process allows false negatives for irrelevant updates but not false positives. In other words, fo r any update  X  R to R , this filtering process has the following characte ristics: (2) In the case that  X  R is irrelevant, with high probability p , our (3) In the case that  X  R is relevant, our method says that it does 
Our key idea is to design effective summary data st ructures that satisfy the following properties: Compactness : They are small and likely to be cached in memory. This is crucial for real-time purposes. Association : They can capture the relationship among multiple join attributes of a base relation  X  given a join a ttribute value (e.g., S.b of MV in the introduction), we can use them to find the associated values of other join attributes (e.g., S.c ). High filtering ratio : They can quickly and correctly filter out view. Easy maintenance : Upon updates to base relations, they can be efficiently maintained in real time. 
There are several existing summary data structures (e.g., bloom filters, multi-attribute B-tree indices). However, as will be shown in Section 2.5, none of them satisfies all above fo ur properties and is suitable for our filtering purposes. In the foll owing, we first give an overview of our content-based detection met hod for irrelevant updates. Then we present the details of our algorithm. 
Consider a join view JV that is defined on base relations R relation FR i that summarizes the most relevant information in R method performs the following operations: Operation O 1 : Update the filtering relation FR i accordingly. Operation O 2 : Use the where clause condition in JV  X  X  definition and the techniques in [2, 4] to detect whether  X  R i is irrelevant. Operation O 3 : If Operation O 2 cannot tell that  X  R check the filtering relations FR 1 , FR 2 , ..., FR i-1 and FR n to see whether  X  R i is irrelevant. Operation O 4 : If Operation O 3 cannot tell that  X  R check base relations R 1 , R 2 , ..., R i-1 , R i+1 exactly whether  X  R i is irrelevant. In the case that  X  R JV is refreshed. This is the standard join view maint enance method. 
Suppose that C w is the where clause condition in the definition of the join view JV . C w is rewritten into a conjunction of m terms c categories: condition on two base relations R j and R k ( 1  X  j&lt;k  X  n ). That is, c of the conjunctive form R j .a 1 =R k .b 1  X  R j .a 2 the corresponding k  X  X  are different. a single base relation R j ( 1  X  j  X  n ). For different i  X  X  ( m the corresponding j  X  X  are different. equi-join condition on two base relations nor a sel ection condition on a single base relation. For example, consider the join view MV mentioned in the introduction. The where clause condition in MV  X  X  definition is a conjunction of five terms. The first two terms ( R.a = S.b and S.c=T.d ) belong to Category 1. The other three terms ( R.e&gt;20 , S.f=  X  X yz X , and T.g=50 ) belong to Category 2. An example term of Category 3 is R.x+S.y&gt;T.z , which does not appear in the where clause condition of MV  X  X  definition. FR of R i that appear in some term of Category 1. That is, f or each term c j ( 1  X  j  X  m 1 ) that is of the form R .a 1 =R k .b 1  X  R i .a 2 =R k .b 2  X  ...  X  R i .a h =R k ( a , a 2 , ..., a h ). The selection condition C is the term of Category 2 that is on R i . That is, if for some j ( m 1 +1  X  j  X  m selection condition on R i , then C=c j . Otherwise (i.e., if no such c exists), we have C=true . 
For example, consider the join view MV mentioned in the introduction. We create three filtering relations, as shown in Figure 2. 
In Operation O 3 , upon an update  X  R i to base relation R ( 1  X  i  X  n ), the updated tuples in R i are joined with the corresponding filtering relations of the other base relations of JV (i.e., FR generated, our method knows that  X  R i is irrelevant. Otherwise our method does not know whether  X  R i is irrelevant unless it checks the other base relations R 1 , R 2 , ..., R i-1 , R i+1 is because in checking the filtering relations, the terms in Category 3 are ignored and hence we may have false negatives. 
When the updated tuples in R i are joined with the filtering relations FR 1 , FR 2 , ..., FR i-1 , FR i+1 , FR method only cares whether the join result set J S is empty. Hence, during the join process, two optimizations are used to reduce the join overhead. First, some attributes are projected out immediately after they are no longer needed. Second, for a filt ering relation whose corresponding base relation is joined with on ly one other base relation of the join view, if there are multip le matching tuples in the filtering relation for an input tuple, our m ethod only finds the first matching tuple rather than all matching t uples. In other words, for each input tuple to such a filtering rel ation, our method generates at most one join result tuple. These two optimizations essentially compute a subset S S of the projection of J are straightforward and thus omitted here. Rather, we use two examples to illustrate the point. 
Consider the join view MV mentioned in the introduction. To illustrate the first optimization, consider an upda te  X  R to base relation R . In this case, our method only joins  X  filtering relation FR S . Then for the join result J r =  X  attributes a and b are projected out before J r is joined with FR irrelevant. Actually in this case, the content-base d method can catch all irrelevant updates to base relations. Thu s, if we ignore the overhead of checking/updating filtering relatio ns, the content-based method avoids all unnecessary join view maint enance overhead in the content-independent method. (As wil l be shown in Section 3 below, the overhead of checking/updating filtering relations is often minor.) To illustrate the second optimization, suppose tupl e t inserted into S . In the filtering process, our method joins tuple t =  X  b, c (t S ) first with FR R , and then with FR searches in FR R , once it finds the first tuple t generates the join result tuple t j =  X  c (t R  X  a=b t S1 FR
R , and continues to do the join with FR T . This is because the attributes of FR R do not include the join attribute c with FR Therefore, from the perspective of determining whet her the join result with FR T is empty, there is no need to obtain more tuples i n FR R that match t S1 . (If no tuple in FR R is found to match t know that tuple t S is irrelevant.) Similarly, when our method searches in FR T , once it finds the first tuple matching t the search in FR T . 
In the traditional join view maintenance method, th e work needed when base relation R i ( 1  X  i  X  n ) is updated is as follows: When we say Operation O 2 fails, we mean that Operation O cannot tell whether the update to R i is irrelevant. 
For comparison, in our content-based detection meth od, the work needed when base relation R i ( 1  X  i  X  n ) is updated is as follows: 
Usually, due to selection and projection, filtering relations are much smaller than base relations and thus more like ly to be cached in memory. In this case, checking filtering relations is much faster than checking base relations. If a not-very-small percentage of updates to base relations are irrelev ant and using filtering relations can filter out most of the irre levant updates, the extra work of (cheap) Operations O 1 and O 3 is dominated by the work saved in the expensive Operation O 4 . As a result, the total join view maintenance overhead is greatly reduced. 
Note that in order to minimize the sizes of filteri ng relations (the compactness property), the terms in Category 3 are not considered in filtering relations and thus get igno red in the filtering process. As will be shown in Section 3 be low, using the terms in Categories 1 and 2 is usually sufficient t o filter out most of the irrelevant updates. 
In order to enhance the compactness of filtering re lations, efficiency, and functionality, we present several i mprovements to the basic algorithm. 
The performance advantages of the content-based det ection method depend heavily on the sizes of filtering rel ations. The smaller the filtering relations, the more likely th ey can be cached in memory and thus the greater performance advantag es of the content-based detection method. Therefore, it is be neficial to reduce the sizes of filtering relations. 
To achieve this size reduction goal, we use the fol lowing hashing method. For each term c i ( 1  X  i  X  m 1 ) of Category 1 that is of the form R j .a 1 =R k .b 1  X  R j .a 2 =R k .b 2  X  ...  X  R h  X  1 ), if the representation of attributes ( a 1 , a than that of an integer attribute, we use a hash fu nction H to map each ( a 1 , a 2 , ..., a h ) into an integer. In the filtering relation FR base relation R j , we store H ( a 1 , a 2 , ..., a a ). Also, in the filtering relation FR k of base relation R H ( b 1 , b 2 , ..., b h ) rather than ( b 1 , b 2 , ..., b
In practice, a large number of joins are based on k ey/foreign key attributes and the values of these attributes a re usually long strings (e.g., ids). Therefore, hashing can often r educe the sizes of filtering relations significantly. 
Suppose a hash function H (or multiple hash functions) has been applied to the filtering relation FR i of base relation R corresponding join attributes of the updated tuples  X  R is joined with the filtering relations FR 1 , FR 2 FR i+2 , ..., and FR n . 
In the above hashing method, due to hash conflicts, we may introduce false negatives in detecting irrelevant u pdates using filtering relations. However, typical modern comput ers can represent a large number of distinct integer values (e.g., a 32-bit computer can represent 2 32 distinct integer values). In practice, if a good hash function is used, the probability of havi ng hash conflicts should be low. As a result, this hashing method will not introduce a large number of false negatives. In practice, most updates occur to one (or a few) b ase relation. The other base relations are rarely updated. In thi s case, our method can only keep filtering relations for the ra rely updated base relations. No filtering relation is kept for t he most frequently updated base relation. Then for the update to the m ostly frequently updated base relation (i.e., for most up dates to the base relations), the filtering relation maintenance over head is avoided. As a tradeoff, when some rarely updated base relati on is updated (i.e., for a few updates to the base relations), th e content-based detection method cannot be used. Rather, we go back to the standard join view maintenance method.

Suppose base relation R i ( 1  X  i  X  n ) is small enough to be cached in memory in most cases. Also, no hash function has been applied to the corresponding filtering relation FR i . Then there is no need to keep FR i . Rather, in Operation O 3 , when we check filtering relations for irrelevant updates to some other base relation R ( 1  X  k  X  n , k  X  i , k  X  j ). (We may build some indices on the join attributes of R i .) This can save the maintenance overhead of FR when R i is updated. 
For each term of Category 1, we restrict the equi-j oin condition form. This condition can be relaxed so that for eac h term of Category 1, the equi-join condition on R j and R k is of disjunctive-conjunctive form h attributes ) ..., , , ( One index is built on ) ..., , , ( built on ) ..., , , ( for irrelevant updates, our method considers the eq ui-join conditions on two base relations that are of disjun ctive-conjunctive form (e.g., using index OR). 
In the basic algorithm, the entire update  X  R i to base relation R ( 1  X  i  X  n ) is treated as an entity. That is, in Operation O joined with the filtering relations FR 1 , FR 2 , ..., FR ..., and FR n . If the join result set is empty, we know that  X  R irrelevant. Otherwise in Operation O 4 , the entire  X  R with the base relations R 1 , R 2 , ..., R i-1 , R i+1
In general, if  X  R i contains multiple tuples, some tuples may be irrelevant while others may be relevant. In this ca se, treating the each individual tuple in  X  R i as an entity. In Operation O irrelevant tuples in  X  R i are filtered out. Then the remaining tuples in  X  R i are passed to Operation O 4 . 
The concrete method is as follows. Suppose  X  R i contains q is appended as an additional attribute a a to tuple t joined with the filtering relations FR 1 , FR 2 , ..., FR result set S j , if S j  X  X  X  , attribute a a is extracted from S duplicate elimination, the values of a a represent the remaining tuples in  X  R i that need to be passed to Operation O 4 Suppose multiple join views are built on the same b ase relation R . A simple method is to build multiple filtering re lations of R , one for each join view. If those join views have no n-overlapping selection conditions on R , then all the filtering relations of R contain different tuples and any update to a single tuple of R will affect at most one of these filtering relations. Th is is a good, common case in practice, where no redundancy exists among the filtering relations. 
In certain other cases where some of the join views have overlapping selection conditions on R , redundancy may exist among these filtering relations and cause two probl ems. First, the probability that the filtering relations are cached in memory is decreased. As a result, Operation O 3 becomes more expensive. Second, when R is updated, updating all the filtering relations o f R will be costly. 
In this case, if possible, it may be better to let multiple join views share the same filtering relation of base rel ation R . For example, suppose join view JV 1 is defined as follows: C is a selection condition on S.f . Join view JV 2 follows: for both JV 1 and JV 2 . Whether FR S is better than FR depends on the overlapping degree of C 1 and C 2 . 
As will be shown in Section 3 below, if either a sm all percentage of the update  X  R i to base relation R  X  R i is large enough so that hash/sort-merge join becom es the join method of choice for the join with some base relati on R j  X  i ), the content-based method may perform worse than the traditional content-independent method. In this cas e, Operation O can be skipped in the content-based method. This i s equivalent to using the content-independent method plus updati ng the filtering relation FR i accordingly. The analytical model described in Section 3 below will provide a means to determin e the upper bound on the size of  X  R i (or lower bound on the percentage of  X  R that is irrelevant) where performing Operation O 3 is beneficial. 
Recall that in Operation O 3 ,  X  R i is joined with the filtering relations FR 1 , FR 2 , ..., FR i-1 , FR i+1 , FR result, we know the (intermediate) join result size s (e.g., during query execution, the techniques in [7] can be used to collect statistics about the output cardinalities of the op erators). If these (intermediate) join result sizes are significantly different from the optimizer X  X  original estimates, we know that the st atistics in the database are imprecise. 
Then in Operation O 4 , when the remaining tuples in  X  R filtering) are joined with the base relations R 1 , R R i+2 , ..., and R n , the optimizer may use the information that is gained in Operation O 3 to choose a better query plan. 
For example, consider the join view mentioned in th e introduction. Base relation R is updated by  X  R . Suppose the optimizer thinks that each tuple in  X  R has only a few matching tuples in base relation S . As a result, in Operation O optimizer chooses index nested loops as the join me thod for the join with S . However, from the information we gained in Operation O 3 , we know that each tuple in  X  R has a large number of matching tuples in the filtering relation FR S (and thus also a large number of matching tuples in S ). Then in Operation O method may advise the optimizer to choose hash join as the join method for the join with S . 
In this section, we show that bloom filter and mult i-attribute B-tree index are generally not suitable for our filte ring purposes, as neither of them satisfies all four properties menti oned in Section 2.1. Consider the materialized view MV mentioned in the introduction. 
Bloom filter [3] is an excellent technique to suppo rt membership queries in a set. However, it does not s atisfy the association property. For example, when base relati on R is updated, given an S.b value, we cannot use a bloom filter to find the associated S.c values. 
We could create two multi-attribute B-tree indices on base given a b value, performing an index-only scan on I 1 can find the corresponding c values with f=  X  X yz X . When T is updated, given a c value, performing an index-only scan on I corresponding b values with f=  X  X yz X . However, I 1 satisfy the compactness property. The selection con dition S.f=  X  X yz X  is not used to reduce their sizes. I 1 and I attributes b , c , and f , whose representation could be fairly long, and contain duplicated information. Also, in genera l the selection condition on S could be arbitrarily complex and thus other attributes (in addition to f ) may need to be included in I
In this section, we evaluate the performance of our content-based method and the traditional content-independen t method for detecting irrelevant updates to base relations of a materialized view. (Recall that the traditional content-independ ent detection method only considers the where clause condition in the materialized view definition.) We first build an an alytical model to gain insight into the performance advantage of o ur content-based method vs. the traditional content-independen t method in maintaining join views. Then we describe experiment al results in our SRW prototype. 
Our model considers the effect that usually a signi ficant portion of filtering relations is cached in memory. This is consistent with the approach recently proposed in [10], which consi ders the content in the buffer pool when computing the cost of a query plan. The goal of this model is not to accurately p redict exact performance numbers in specific scenarios. Rather, it is to identify and explore some of the main factors that determine the effectiveness of the content-based method. Moreover , this analytical model provides the conditions for select ively skipping Operation O 3 that is described in Section 2.4.6. In Section 3.3 , we show that our model for the content-based and conte nt-independent methods predicts trends fairly accurate ly where it overlaps with our experiments with a commercial RDB MS. 
Consider the following join view JV : C is the selection condition on base relation R . C S is the selection condition on base relation S . The selectivity of C S is q . 
We make the following simplifying assumptions in th is model: (1) Base relation R ( S ) has an index I R ( I S (3) The percentage of irrelevant updates in these |  X  R | tuples is p . (4) For each tuple t R , there are N matching tuples t (5) The overhead of inserting a tuple into a filtering relation is a (6) In the content-independent method, the overhead of (7) In the content-based method, the overhead of search ing the For each tuple t R , we use as the cost metric the total workload TW , which is defined to be the total work done. This is a useful basic metric because we can derive other metrics, s uch as response time, from it easily (as shown in Section 3.1.2 below). 
For both the content-independent method and the con tent-based method, the same updates must be performed on the b ase relations and on the join view. Because of this, our model om its the cost of these updates. Then the costs that must be captured are the extra update of the filtering relation )) ( ( R FR required by the content-based method, and the diffe rences between the two methods in the cost of finding the join result tuples that need to be inserted into the join view. We now turn to quantify those costs, which we refer to as TW. 
For the content-independent method, upon an inserti on of a tuple t R , (a) Searching the index I S once has overhead SEARCH . (b) Fetching the N matching tuples t S of base relation S , applying Thus for the content-independent method, the total workload TW for each tuple t R is (i) SEARCH+N  X  FETCH , if index I clustered or (ii) SEARCH+FETCH , if index I S is clustered. For the content-based method, upon an insertion of a tuple t (a) Inserting tuple  X  a (t R ) into filtering relation FR (b) Searching filtering relation FR S has overhead SEARCH . (c) With probability 1-p , tuple t R is relevant. In this case, we So for the content-based method, the average total workload TW for each tuple t R is (i) INSERT+SEARCH+(1-p)  X  (SEARCH+N  X  FETCH) , if index I S is non-clustered or (ii) INSERT+SEARCH+(1-p)  X  (SEARCH+FETCH) , if index I S is clustered. 
Compared to the content-independent method, the con tent-based method incurs an extra INSERT+(1-p)  X  SEARCH , while p  X  FETCH , if index I S is clustered. As the percentage of irrelevant updates p grows, the savings in FETCH become significant compared to the extra overhead of INSERT+(1-p)  X  SEARCH . 
In general, for a large base relation T , the aggregate size of its filtering relation, its integer-attribute index, an d the index on its filtering relation is a small percentage of the siz e of T . For example, a tuple of a base relation may be 200 byte s long while a tuple of a filtering relation may be only 4 (say, o ne 32-bit integer join attribute) or 8 (say, two 32-bit integer join attributes) bytes long. 4/200=2% and 8/200=4% . Therefore, in a typical case, a large portion of filtering relations and indexes is cached in memory while large base relations are stored on dis k. As a result, the time spent on FETCH is much larger than that spent on INSERT and SEARCH . In the following, we will assume that both INSERT and SEARCH take 0.01 I/O, and FETCH takes 1 I/O. (A page can contain a large number of tuples. Hence, t he average logging overhead for inserting a tuple into a relat ion is a small percentage of one I/O.) Our conclusion would remain unchanged by small variations in these assumptions. 
The model in Section 3.1.1 is accurate only if for the join with base relation S , the join method is index nested loops, for which the cost is directly proportional to the number of tuples inserted. If |  X  R | is large enough, an algorithm such as sort-merge may perform better than index nested loops. To explore this issue, our model is extended to handle this case. We use sort-merge join as an alternative to index nested loops here; we belie ve our conclusions would be the same for hash joins. The p oint is that for both sort-merge and hash join, the join time is dom inated by the time to scan a relation. Unless the number of modif ied tuples is a sizeable fraction of the base relations, the join t ime is independent of the number of modified tuples. (To keep our mode l simple, we assume that for the content-based method, we use th e index nested loops join method for the join with filtering relat ion FR usually a significant portion of FR S is cached in memory [10]. Again, the model could be easily extended to handle the sort-merge/hash join method for the join with FR S . However, this would not change the conclusions that we draw from our model, cost of the join with S .) available memory in pages. In addition, we make the following simplifying assumptions: (1) The number of page I/Os is used to measure the (2)  X  R can be held entirely in memory. Given these assumptions, TW for the two methods for the multiple-tuple insertion is just |  X  R | times the TW for a single-tuple insertion. Calculating the response time is more in teresting. We can express the response time (in number of I/Os) f or either method by considering the work required by index ne sted loops join and sort-merge join. 
For the content-independent method, (a) If the join method of choice is sort-merge, (b) If index nested loops is the algorithm of choic e, the index 
For the content-based method, (a) If for the join with base relation S , the join method of choice (b) If for the join with S , the join method of choice is the index If |  X  R | is large enough that || S || + || S ||  X  q  X  log p)  X  1.01 (if index I S is clustered) are satisfied, then the sort-merge join algorithm is preferable to index nested loops.

The above analysis shows that when sort-merge is th e join algorithm of choice, the content-independent method outperforms the content-based method. This is because either me thod has the same join cost for the join with base relation S (sorting/scanning S ), while the content-based method has the extra ove rhead of the updates to FR R and the join with FR S . Similarly, if most updates are relevant and p is close to 0, the content-independent method also outperforms the content-based method. (As ment ioned in Section 2.4.6, in these two cases, it may be better for the content-based method to skip Operation O 3 . It is straightforward to apply the analytical model and get an estimate of the con ditions on when it would be better for the content-based metho d to skip Operation O 3 .) In the discussion of the experiments with the analytical model below, we discuss the implications of these facts when choosing a method for join view maintenance. 
Setting || S || =200 , M=50 pages, q=50% , N=4 (except in Figure 3), and p=85% (except in Figures 4~7), we present in Figures 3~8 the resulting performance of both the content-indep endent method and the content-based method. 
Figure 3 shows the average TW for a single-tuple insert vs. the index I S is non-clustered, for both methods, TW increases linearly with the number of matching tuples N . In either case, when N  X  1 , TW for the content-based method is smaller than that for the content-independent method. This is because the con tent-based method can filter out a large percentage of irrelev ant updates so that only a small percentage of updates need to be joined with base relation S . In the case that index I S is non-clustered, the larger the N , the more significant the performance advantage of the content-based method (note that the y-axis is on lo garithmic scale). 
Figure 4 shows the average TW for a single-tuple insert vs. the percentage of irrelevant updates p . For the content-independent method, TW is a constant 4.01 (if index I S is non-clustered) and to the insignificant  X  X iltering X  effect of the cont ent-based method, and the extra overhead of the updates to FR R and the join with FR S . However, whether or not index I S is clustered, once p  X  2% , TW for the content-based method becomes smaller than that for the content-independent method. The larger the p , the more irrelevant updates can be filtered out by the conte nt-based method and thus the smaller the overhead of the index join with base relation S . Consequently, the larger the p , the more significant the performance advantage of the content-based method. transaction execution time = 40  X  TW for a single tuple . content-based method and hence this speedup ratio i s a little bit less than 1. However, once p  X  2% , the content-based method outperforms the content-independent method and thus this speedup ratio becomes greater than 1. Moreover, thi s speedup ratio increases rapidly with p . When index I S is non-clustered, this speedup ratio is greater than that when index I S is clustered. content-independent method and that of the content-based method are a constant that is independent of the percentag e of irrelevant updates p . Moreover, the constant for the content-based meth od is greater than that for the content-independent metho d. This is because the cost of the sort-merge join with S is the same for both methods, while the content-based method has the ext ra overhead of maintaining FR R and the join with FR S . For the content-based/content-independent method, the constant when index I non-clustered is greater than that when index I S is clustered. 
Note that there is nothing special about the number 5,000 other than that the relevant portion of it (i.e., (1-p)  X  5000 ) is greater than the number of pages in S . This indicates that if the expected update transaction inserts a number of tuples, and the number of relevant tuples approximately equals to the number of pages in S , the content-independent method is the method of cho ice. 
It is an interesting empirical question whether or not such large update transactions are likely. Anecdotal evidence suggests that they are not  X  data warehouses typically store data from several years of operation, so it seems highly unlikely tha t individual update transactions (of which there are presumably many each day) insert more than a very small fraction of the warehoused data. 
Figure 8 shows the execution time of one transactio n where the number of inserted tuples varies from 1 to 2,500. F or the content-independent method, the execution time increases ra pidly with the number of inserted tuples. For the content-based me thod, the execution time increases much more slowly. For the join with base relation S , the join time of both methods reaches a constant when the number of inserted tuples is large enough for the sort-merge join method to become the join method of choi ce. The content-based method reaches this point much later than the content-independent method. This is because of the  X  X iltering X  based method is indeed worse than the content-indep endent method. 
It is straightforward to apply the above analytical model to the situation of a join view on multiple base relations . Experiments with this model did not provide any insight not alr eady given by the two-relation model, so we omit them here. We now turn to describe experiments we performed in our SRW prototype using IBM DB2 Version 8.2. Our measur ements were performed on a computer with two 3GHz processo rs, 2GB main memory, one 111GB disk. The buffer pool size o f DB2 was set to be 1.2GB. 
The three relations used for the experiments follow ed the schema of the standard TPC-R Benchmark relations [1 4]: 
We wanted to test the performance of insertion into the lineitem relation in the presence of join views. Two join vi ews were chosen for testing: (1) JV 1 records the lineitem information of certain orders : (2) JV 2 records the lineitem information of certain orders that are We repeated our experiments with other kinds of joi n views/workloads. The results were similar and thus omitted. 
The join view maintenance consists of three steps: updating the base relation, computing the changes to the join vi ew, and updating the join view. As the first step and the t hird step were the same for both the content-independent method and th e content-based method, we only measured the time spent on th e second step. 
Because DB2 does not currently support the content-based detection method, a query rewriting approach was us ed to resolve this problem. We evaluated the performance of join view maintenance when 400 tuples were inserted into the lineitem relation (these tuples each has one matching tuple in the orders relation) in the following way: (1) For both the orders relation and the customer relation, we (2) We created a new relation delta _ lineitem that had the same (3) 400 tuples were inserted into delta _ lineitem . (4) For join view JV 1 , we created relation (5) The execution time of the following two SQL stateme nts was (6) We created a temporary relation tmp_lineitem that had the (7) For join view JV 1 , we varied the selectivity s 1 of the selection (8) For join view JV 2 , the selectivity of the selection condition (9) Before we tested the content-independent method, we first (10) For each experiment, the reported number is average d over a 
Figure 9 shows the join view maintenance time of JV predicted by the analytical model. All the numbers in Figure 9 are relative ratios between them are meaningful. Figure 10 shows the experimental join view maintenance time of JV 1 . Figure 9 and Figure 10 match well. The speedup gained by the con tent-based method over the content-independent method increase s with the percentage of irrelevant updates to the lineitem relation. 
For join view JV 2 , Figure 11 shows the maintenance time that is predicted by the analytical model (the time unit is 80 I/Os), and Figure 12 shows the experimental maintenance time. Figure 11 and Figure 12 match well. 
We also ran experiments with large update transacti ons, where our analytical model predicts that the content-inde pendent method will perform better than the content-based method w hen sort-merge/hash becomes the join method for the join wit h base relation S . We did indeed observe the trend that as the trans action size increased, the performance of the content-inde pendent method first approached and then exceeded that of t he content-based method. However, the analytical model was les s accurate for large updates than for small. This is because o ur cost model for sort-merge join is too simple (e.g., it does no t take special consideration of the portion of base relations that is cached in memory). Also, it is difficult to estimate precisel y the size of available memory for the sort-merge/hash join. For these reasons the large update results are not presented here. 
The difficulty of duplicating in DB2 the analytical model results for large updates does not affect our concl usions. The model is accurate for reasonably sized updates; the se are the ones that are common in practice and also are the ones f or which the content-based method dramatically outperforms the c ontent-independent method. 
Semi-joins (and bloom-joins) in distributed RDBMSs [1] use filtering to reduce communication overhead. That fi ltering method is different from our filtering method: (1) In our method, the updated tuples of a base relatio n,  X  , are (2) Our method mainly performs inexpensive in-memory (3) Some of our techniques either do not apply to semi-joins (4) Filtering relations need to be maintained in the pr esence of [15] proposed using join indices to speed up join q uery processing. A join index links the row ids of match ing tuples in multiple base relations. In our content-based detec tion method, a base relation. 
If the hashing-based compression method is not cons idered, a filtering relation is simply a selection and projec tion of a base relation. [9] and [6] proposed using auxiliary rela tions to speed up join view maintenance in distributed data warehouse s and parallel RDBMSs, respectively. An auxiliary relation is also a selection and projection of a base relation. However, auxilia ry relations are larger than filtering relations, as auxiliary relat ions keep both join attributes and non-join attributes while filtering relations only keep join attributes. Also, we can use auxiliary re lations to compute the update to the join view. In contrast, w e can only use filtering relations to tell whether or not the upda te to the join view is empty. [12] use partial indices to reduce index maintenanc e overhead. Filtering relations can be regarded as another kind of indices  X  given a join attribute value, we can use the filter ing relation to find other join attribute values. [11] proposed maintaining additional materialized v iews in order to reduce the total maintenance cost of a tar get materialized view. Our filtering relations can be regarded as ad ditional  X  X ini X  materialized views. However, (1) Similar to the case of auxiliary relations, we can use the (2) The additional materialized views in [11] are large and reside [1] P.A. Bernstein, D.W. Chiu. Using Semi-Joins to Solve [2] J.A. Blakeley, N. Coburn, and P. Larson. Updat ing Derived [3] B.H. Bloom. Space/Time Trade-offs in Hash Codi ng with [4] J.A. Blakeley, P. Larson, and F.W. Tompa. Effi ciently Updating [5] S. Chandrasekaran, M.J. Franklin. Streaming Qu eries over [6] G. Luo, J.F. Naughton, and C.J. Ellmann et al. A Comparison of [7] G. Luo, J.F. Naughton, and C.J. Ellmann et al. Toward a [8] G. Luo, J.F. Naughton, and C.J. Ellmann et al. Transaction [9] D. Quass, A. Gupta, and I.S. Mumick et al. Maki ng Views Self-[10] R. Ramamurthy, D.J. Dewitt. Buffer-pool Aware Query [11] K.A. Ross, D. Srivastava, and S. Sudarshan. M aterialized View [12] M. Stonebraker: The Case for Partial Indexes. SIGMOD Record [13] M. Stonebraker. Stream Applications. [14] TPC Homepage. TPC-R benchmark, www.tpc.org. [15] P. Valduriez. Join Indices. TODS 12(2): 218-2 46, 1987. [16] K. Wu, P.S. Yu, and B. Gedik et al. Challenge s and Experience 
