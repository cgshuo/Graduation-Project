 Information network contains abundant knowledge about rel ation-ships among people or entities. Unfortunately, such kind of knowl-edge is often hidden in a network where different kinds of rel a-tionships are not explicitly categorized. For example, in a research publication network, the advisor-advisee relationships a mong re-searchers are hidden in the coauthor network. Discovery of t hose relationships can benefit many interesting applications su ch as ex-pert finding and research community analysis. In this paper, we take a computer science bibliographic network as an example , to analyze the roles of authors and to discover the likely advis or-advisee relationships. In particular, we propose a time-co nstrained probabilistic factor graph model (TPFG), which takes a rese arch publication network as input and models the advisor-advise e rela-tionship mining problem using a jointly likelihood objecti ve func-tion. We further design an efficient learning algorithm to op ti-mize the objective function. Based on that our model suggest s and ranks probable advisors for every author. Experimental results show that the proposed approach infer advisor-advisee rela tion-ships efficiently and achieves a state-of-the-art accuracy (80-90%). We also apply the discovered advisor-advisee relationship s to a spe-cific expert finding task and empirical study shows that the se arch performance can be effectively improved (+4.09% by NDCG@5) . H.2.8 [ Database Management ]: Database Applications X  Data Min-ing Algorithms, Experimentation Relationship mining, Time-constrained probabilistic fac tor graph, Coauthor network, Advisor-advisee prediction
With the rapid growth of the social web, particularly online net-working applications such as Facebook, Youtube and Twitter , peo-ple are closely connected via different types of relationsh ips. It is well recognized that different types of social relationshi ps have es-sentially different influence between people, which forms t he com-plex and subtle force that governs the dynamics of social net works. For example, in the social network, a graduate X  X  research to pic may be mainly influenced by his advisor; while his living habits m ay be influenced by his family. Awareness of the relationship type s can offer abundantly additional information for many mining ap plica-tions such as community discovery and expert finding. For exa m-ple, if we know advisor-advisee relationships between rese archers, we can easily discover how researchers form different commu ni-ties, how research topics have been emerging and evolving in the past years, and how a researcher influences the academic rese arch community.

However, in reality, such information (relationship type) is of-ten hidden in the networks due to different reasons. For exam ple, advisor-advisee relationships are hidden in the coauthor n etwork ( e.g. , on DBLP); family relationships are hidden in the friendshi p network ( e.g. , on Twitter or MSN). Several projects aim to main-tain the types of relationships, such as LinkedIn and AI Gene alogy. The former requires users to label their professional relat ionships (e.g., colleagues or advisor-advisee) with each friend and the latter asks human annotators to manually label the advisor informa tion for various research fields. However, these methods heavily rely on manual efforts, which significantly limits its wide use. An i deal so-lution is to design a method that automatically uncovers the hidden relationship types from the network.

In this study, we try to conduct a systematic investigation o f the case of mining advisor-advisee relationships between a uthors in a research publication network. Identification of such ad visor-advisee relationships can offer us a chance to better unders tand the insight of the research community, as it provides additiona l seman-tic information on the links other than the simple, explicit coau-thor relationships. For example, we can position each perso n in a chronological axis in the right order and sketch the whole c om-munity in a clear view. Certain applications of expert findin g can also be benefited from the identified advisor-advisee relati onships, as people looking for experts may not only care about the pers onal academic achievements but also are interested in how many  X  X  x-perts" they can foster.
To clearly illustrate the problem, Figure 1 gives an example of advisor-advisee relationship analysis on a research publi cation net-work. The left figure shows the input: an temporal collaborat ion network, which consists of authors, papers, and paper-auth or rela-tionships. The middle figure shows the output of our analysis : an author network with solid arrow indicating the advising rel ation-ship, and dotted arrow suggesting potential but less probab le rela-tionship. For example, the arrow from Bob to Ada indicates th at Ada is identified as the advisor of Bob. The triple on the edge, i.e., (0 . 8 , [1999 , 2000]) , represents Ada has the probability of 80% to be the advisor of Bob from 1999 to 2000. Such results can benefi t many potential applications such as research community det ection and evolution analysis. The right figure gives an example of v isu-alized chronological hierarchies. The parent-child relat ion in the tree corresponds to the advisor-advisee relationship. We c an see the advising path from root to leaf.

The problem we study is rather different from existing relev ant research ( e.g. , relation mining). Our work analyzes links rather than text or labeled annotations which poses a set of challen ges.
In this paper, we formulate the problem of advising relation ship mining as a probabilistic ranking problem, and propose a tim e-constrained probabilistic factor graph (TPFG) model to mod el the dynamic collaboration network. Specifically, the advisor o f each author and the advising period are modeled together as a join t prob-ability of as many hidden variables as authors. We further de sign an efficient algorithm to optimize the joint probability via a process of message propagation on the network. By experiments we sho w this unsupervised approach can achieve an accuracy of 80-90 %, leading by 5-20% against several baseline methods. We also a p-ply the identified advisor-advisee relationships to bole se arch (best supervisor finding) and demonstrate that the performance of bole search can be clearly improved (+4.1%). The proposed framew ork is generalizable to other applications. For discovering ot her type of relationships, the additional requirement is to redefine th e feature function and the potential constraints.

The rest of the paper is organized as follows. Section 2 discu sses related work. Section 3 formally formulates the problem. Se ction 4 explains the proposed approach. Section 5 presents experim ental results that validate the computational efficiency and effic acy of our methodology. Finally, Section 6 concludes the study and dis cusses the future work.
This work is different from the existing study in Relation Min-ing and Relational Learning . Previous studies in relation mining mainly employ text mining and language processing techniqu e on text data and structured data including web pages, user profi les and corpus of literature. Relational Learning [9] refers to the classifi-cation when objects or entities are presented in multiple re lations. Semantic Role Labeling is a broadly employed text mining tec h-nique, as it allows for the addition of structured semantic i nfor-mation to plain text [11]. [15] applies Natural Language Pro cess-ing to extract protein-protein relationships from rich-an notated cor-pus in biomedical domain. [6] proposes a general framework f or syntax-based relation mining and achieves high accuracy by exper-imenting with Support Vector Machine as a supervised approa ch. [17] applies a clustering-based approach to differentiate latent so-cial dimensions from social network, but does not study abou t the semantic meaning related to the extracted dimensions. [7] l earns semantic relationship in a supervised way, treating links a s features and requiring labeled pairs as training data. Since it is dif ficult to find universal features that are useful in every domain, we em-ploy a different philosophy that requires commonsense back ground knowledge about the correlation between the observed links and the latent roles of the nodes but no training data. To the best of our knowledge, there is no previous work mining semantic rel a-tions solely according to a network with neither annotation text nor labeled relations.

By means of link analysis ( e.g. , using PageRank[3]), one can compute the importance of a node and the relevance of neighbo r-ing nodes. Studies have also shown links can be explored to cl ean, fuse and reveal the knowledge hidden in a network. For exampl e, Object Distinction [20] distinguishes objects with identical names by analyzing their heterogeneous linkages. Furthermore, i ntegrated ranking and clustering can be performed on heterogeneous ne twork based on the link information [16]. [17] proposes to extract la-tent social dimensions based on network information, and th en uti-lize them as features for discriminative learning. Recogni zing the power of links, our approach extracts implicit entity seman tic rela-tionships by modeling the network.

To evaluate the discovered advisor-advisee relations we co mpare them with graduation records maintained by some online proj ects. Such projects include the Mathematics Genealogy Project [5 ], the Computer Engineering Academic Genealogy, the AI Genealogy Project and the Software Engineering Academic Genealogy. [ 19] proposes an approach based on classification to classify the rela-tions according to some local features on each pair of coauth ors but the parameters are manually tuned. We develop their method i nto a supervised learning process and compare it with our probabi listic-model-based approach.
In this section, we present the problem formulation and defin e notations used throughout the paper.

In general, our study takes as input a time-dependent collab -oration network { G } = { ( V = V p  X  V a , E ) } , where V { p 1 , . . . , p n p } is the set of publications, with p i published in time t , V a = { a 1 , . . . , a n a } is the set of authors, and E is the set of edges. Each edge e ij  X  E associates the paper p i and the author a , meaning a j is one author of p i .

The original heterogeneous network can be transformed into a homogeneous network containing only authors. Let G  X  = ( V set of authors (including a virtual node a 0 , which will be the root of an advising tree.). Each edge e  X  ij = ( i, j )  X  E connects au-thors a i and a j if and only if they have publication together, and there are two vectors associated with the edge, Pub_Year_ve ctor py ij and Pub_Num_vector pn ij . They are of equivalent length, indicating the year they have publications and the number of coau-thored papers they have at that time. For example, py ij = (1999 , 2000 , 2001) , pn ij = (2 , 3 , 4) indicates that author a coauthored 2, 3 and 4 papers in 1999, 2000, and 2001 respectiv ely. Similarly, we associate with each author two vectors py i to respectively represent the number of papers and the corre spond-ing published year by author a i . The two vectors py i and pn be derived from py ij and pn ij .

We denote the author a i  X  X  advisor as a y i , where y i is an intro-duced hidden variable. If a i  X  X  advisor is a j , we use [ st represent the time interval the advising relation lasts. Fo r brevity we denote st i = st iy i and ed i = ed iy i . If a i is not advised by anybody in the database, we let y i = 0 to direct a i  X  X  advisor to a virtual node a 0 .

In this setting, to find the advisor-advisee relationship, w e need not only to decide the value of the hidden variable y i for each author a , but also to estimate the start and the end years st iy i reality, this problem is more complicated: (i) one could hav e mul-tiple advisors like master advisors, PhD co-advisors, post -doctorial advisors; (ii) some mentors from industry behave similarly as aca-demic advisors if only judged by the collaboration history; and (iii) one X  X  advisor could be missing in the data set. Therefore, in stead of using a boolean model, we adopt a probabilistic model to ra nk the likelihood of potential advisor(s) for each author. For mally, we denote r ij as the probability of a j being the advisor of a duce the number of authors being ranked, it is beneficial to ke ep only those potential pairs of advisor-advisee. We construc t a sub-graph H  X   X  G  X  by removing some edges from G  X  and make the remaining edges directed from advisee to potential advisor . Thus H  X  = ( V  X  , E  X  s ) and E  X  s  X  E  X  . Later we will show that it is possi-ble to extract a directed acyclic graph (DAG) H  X  from G  X  the index set of potential advisors of a given author a i Y = { j | e ij  X  E  X  s } , e.g. , Y 3 = { 0 , 1 } . Correspondingly, the index set of potential advisees is denoted Y  X  1 i = { j | e ji
Then the task becomes finding r ij , st ij , ed ij for every possi-ble advising pair ( i, j )  X  E  X  s . So the output is the DAG H = ( V is illustrated in Figure 2. After the chronological DAG H is con-structed, the ranking score can be used to predict whether th ere is an advisor-advisee relationship between every pair of co authors ( a , a j ) . A simple way to predict is to fetch top k potential advi-sors of a i and check whether a j is one of them while r ij r ij &gt;  X  , where  X  is a threshold such as 0.5. We use P @( k,  X  ) to denote this method. It is predictable that large k and large  X  leads to better recall and worse precision. How to choose k and  X  could be a tricky problem. So we allow the input contains some train ing data so as to determine the parameters. If no training data is pro-vided, we can simply use some empirical values, such as the th ird quartile of all the ranking scores.
In this section, we first make basic assumptions as the prereq -uisite of our approach, then propose a two-stage framework a nd present the approach for each stage. The main idea is to lever age a time-constrained probabilistic factor graph model to dec ompose the joint probability of the unknown advisor of every author . The time-related information associated to the hidden social r ole is cap-tured via factor functions, which form the basic components of the factor graph model. By maximizing the joint probability of t he fac-tor graph we can infer the relationship and compute ranking s core for each relation edge on the candidate graph. One can apply g en-eral algorithms for inference on factor graph, e.g., sum-pr oduct and JunctionTree. However, these algorithms suffer from the pr oblem of low efficiency. Thus a new message passing algorithm on the candidate graph is designed that approximates the computat ion and greatly improves the efficiency.
Commonsense knowledge is needed for recognizing interesti ng semantic relationships. Here we make a few general assumpti ons based on the commonsense knowledge about advisor-advisee r ela-tionships.
 A SSUMPTION 1.  X  1  X  x  X  n a , ed y x &lt; st x &lt; ed x This formula reflects the following fact for general conside ration of advising relationship. At each time t during the publication history of a node x , x is either being advised or not being advised. Once x starts to advise another node, it will never be advised again . x cannot advise y at the year t 1 if x is advised by any node p at the year t 1 . If x advises y , the time y is advised by x is a continuous interval from t 1 to t 2 , t 1 &lt; t 2 . As a result of Assumption 1, we need to infer the advisors of all the nodes in the network toge ther, rather than consider them separately. In Section 4.3, we wil l use this assumption in our model.

A SSUMPTION 2.  X  1  X  x  X  n a , py 1 y That means for a given pair of advisor and advisee, the adviso r al-ways has a longer publication history than the advisee. py sents the first component of vector py x . Assumption 2 determines that all the authors in the network have a strict order defined by the possible advising relationship. Due to the order, the ca ndidate graph H  X  is assured to be a DAG. We will use this assumption in the filtering process in Section 4.2.

Additional assumptions about the correlation between the p o-tential relationship and the publication history will be di scussed in Section 4.2. Now we propose a two-stage framework solutio n for the advisor-advisee relationship mining problem. In st age 1, we preprocess the heterogeneous collaboration network to g ener-ate the candidate graph H  X  . This includes the transformation from G to a homogeneous network G  X  , the construction from G  X  and the estimate of the local likelihood on each edge of H stage 2, these potential relations are further modeled with a proba-bilistic model. Local likelihood and time constraints are c ombined in the global joint probability of all the hidden variables. The joint probability is maximized and the ranking score of all the pot ential relations is computed together. The construction of H is finished in this stage. The purpose of preprocessing is to generate the candidate gr aph H  X  and reduce the search space while keeping the real advisor no t excluded from the candidate pool in most cases. First, we nee d to generate according to the collaboration information a ho moge-neous author network G  X  by processing the papers in the network one by one. For each paper p i  X  V p , we construct an edge be-tween every pair of its authors and update the vectors py and pn . The complexity of this process is O ( P p degree of p i in G .

Then a filtering process is performed to remove unlikely rela -tions of advisor-advisee. For each edge e ij on G  X  , a i collaboration. To decide whether a j is a i  X  X  potential advisor, the following conditions are checked. First, Assumption 2 is ch ecked. Only if a j started to publish earlier than a i , the possibility is con-sidered. Second, some heuristic rules are applied, which ar e based on the prior intuitive knowledge about advisor-advisee rel ations. Many rules are reasonable but for each there is counter examp le in real world. It is unknown how well they work before the result s are tested. Thus we list the rules here and will test them in th e experiment part.

First, we introduce two measures for the coauthored publica tions between any pair of collaborators, kulc ( i.e. , Kulczinski measure [18] and IR ( i.e. , imbalance ratio). They are defined as The Kulczynski measure reflects the correlation of the two au thors X  publications. [18] shows that there usually exists high cor relation between the total publications of advisors and advisee. Her e we further incorporate the time factor, to calculate the measu re year by year, and check whether there is an increase in the sequenc e { kulc t ij } t . For IR, we calculate the sequences in the same way. IR [18] is used to measure the imbalance of the occurrence of a given a i and the occurrence of a i given a j . The intuition is that the advisor has more publications than the advisee during the ad vising time. Then we have the following rule.

Author a j is not considered to be a i  X  X  advisor if one of the fol-lowing conditions holds:
R 1 : IR t ij &lt; 0 in the sequence { IR t ij } t during the collaboration
R 2 : there is no increase in the sequence { kulc t ij } t
R 3 : the collaboration period of a i and a j lasts only for one R 4 : py 1 j + 2 &gt; py 1 ij ,
When the pair of authors passes the test of selected rules fro m them, we construct a directed edge from a i to a j in H  X  tion, we estimate the starting time and ending time of the adv ising, as well as the local likelihood of a j being a i  X  X  advisor l estimation we also have various methods. The starting time st estimated as the time they started to collaborate, while the ending time ed ij can be estimated as either the time point when the Kul-czynski measure starts to decrease, or the year making the la rgest difference between the Kulczynski measure before and after it. We refer to the two methods as YEAR1 and YEAR2. And we refer to YEAR as taking the earlier time of the two years estimated b y them. After estimating st ij and ed ij , we calculate the average of Kulczynski and IR measure during that period, and use 1)Kulc zyn-ski ; 2)IR; 3)the average of the two as three different definit ions of the local likelihood. The last definition is formally And the other two are similar. The complexity of processing e ach edge is O ( T ) , if we assume the oldest paper and the newest one dif-fers T in their publication time. The total complexity to transfor m G  X  to H  X  is O ( MT ) , where M is the number of edges in G
From the candidate graph H  X  we know the potential advisors of each author and the likelihood based on local information . By modeling the network as a whole, we can incorporate both stru cture information and temporal constraint and better analyze the relation-ship among individual links. Now we define the TPFG model.
For each node a i , there are three variables to decide: y and ed i . Suppose we have already had a local feature function g ( y i , st i , ed i ) defined on the three variables of any given node. To model the joint probability of all the variables in the netwo rk, we define it as the product of all local feature functions. with where 1 Z is the normalizing factor of the joint probability
Eq. (5) is the constraint according to Assumption 1. To find th e most probable values of all the hidden variables, we need to m axi-mize the joint probability of all of them. To estimate the app rox-imate size of the entire search space, assume each author has C candidates and the advising time can vary in a range of T , then the combination of all the variables has exponential size ( CT is intractable to do exhaustive search. We make the first simp lifi-cation as follows. Suppose a i and his advisor y i are given. Instead of letting st i and ed i vary, we fix them by optimizing local function g ( y i , st i , ed i ) , i.e. , In this way, st i and ed i are tied to the value of y i . Once y decided, they are derived correspondingly. We can pre-comp ute the best advising time as st ij and ed ij for each y i = j . Now only { y i } are variables to optimize). If we embed the constraint Eq. (5 ) into the feature function, the objective function becomes with where
I ( y x 6 = i  X  ed ij &lt; st xi ) = 1 y x 6 = i  X  ed ij &lt; st is the identity function. If any author a x is advised by a advising time conflict, the function takes 0; otherwise it ta kes 1. In this way the time constraints Eq. (5) for all hidden variab les are decomposed to many local identity function. Now we only need to optimize Eq. (7). Furthermore, to obtain the rank score of each advising relationship, e.g. , a j advise a i (shortly a j compute the conditional maximal probability This simplification assures that for each configuration of { y solution achieves either 0 or the conditional optimum given that configuration. The search space size now becomes C n a , reduced but still exponential. Since we have decomposed the depende ncy of the variables, we can use a factor graph model to accomplis h efficient computation.

Figure 3 shows a simple TPFG corresponding to the example we have been using so far. The graph is composed of two kinds of nodes: variable nodes and function nodes. Variable nodes ma p to the hidden variables { y i } n a i =0 . Each variable node corresponds to a Figure 3: Graphical representation of a time-constrained p rob-abilistic factor graph, where { y 0 , . . . , y 5 } are hidden variables defined on all nodes; f i ( . ) represents a factor function defined on a hidden variable and its potential advisee sets as neighb ors. kind, connecting a variable node with a function node. There is an edge between one variable node y x and a function node f and only if f i ( . ) depends on y x . In our case, it is equivalent with x = i or x  X  Y  X  1 i (a.k.a. i  X  Y x ). The factor graph reflects the dependency of the variables. A set of variables are correlat ed if they are neighbors of the same function node, e.g. , y 1 , y f ( y 1 , y 2 , y 3 ) . We can see that two hidden variables are correlated iff their corresponding author nodes are linked by an edge on the candidate graph H  X  , which means there is a potential advising re-lationship between them. And once a variable y i changes its value, it will affect the value of all the functions corresponding t o the po-tential advisor and advisee sets Y i  X  Y  X  1 i .

There is additional information stored in each variable nod e, as shown in the tables in Figure 3. y i can take different values from Y and the corresponding st i , ed i and g ( y i , st i , ed in stage 1. Here we take l ij as g ( y i , st ij , ed ij ) when y Theoretically, one can incorporate any types of features in to the TPFG model. For different kind of relationships, the constr aint can vary according to primary assumptions.
To maximize the objective function and compute the ranking score along with each edge in the candidate graph H  X  , we need to infer the marginal maximal joint probability on TPFG, acc ord-ing to Eq. (10). We first introduce the algorithm for general f actor graph, discuss its deficiency, and then propose our algorith m. Sum-product + junction tree. There is a general algorithm called sum-product [12] to compute marginal function on a factor graph based on message passing. It performs exact inference on a fa ctor graph without cycles. In the sum-product algorithm, the mar ginal functions of a single variable, a.k.a., messages, are passe d between neighboring variable node and function node. Message passi ng is initiated at the leaves. The process terminates when two mes sages have passed on every edge. At each variable node, the product of all incoming messages is its marginal function. To compute t he marginal maximal probability, we need to change sum-produc t to max-sum with a logarithmic transformation of the function v alue. If TPFG is tree-structured factor graph, the message passin g rule will be: where j  X   X  Y i  X  X  i } , j  X  6 = j represents f j  X  () is a neighbor node of variable y i on the factor graph except factor f j () ,  X  X  y sents all variables in Y = { y 1 , . . . , y n a } except y
Unfortunately, TPFG contains cycles. This algorithm canno t be applied directly. One solution to generalize it is a procedu re known as junction tree algorithm [2] for exact inference. The junction tree is a tree-structured undirected graph generated from arbit rary tri-angulated dependency graph, and can be solved by sum-produc t. Nevertheless, the computational cost of the algorithm is de termined by the number of variables in the largest clique and will grow ex-ponentially with this number in the case of discrete variabl es. The process to construct a junction tree alone consumes a lot in b oth time and space. In practice we found it fails to finish for 6000 vari-ables, not to mention our TPFG has the scale of more than 600,0 00 variables.

To reduce the computational cost, we can do approximate in-ference instead of exact inference. A general method loopy belief propagation (LBP) [8] simply applies the sum-product algorithm in a cycle-containing graph. It passes message iteratively with flooding schedule. To avoid repetitive information flow for m ul-tiple times through the graph, we design a special message pa ssing schedule and the following algorithm according to the speci al prop-erty of TPFG.
 New TPFG Inference Algorithm. The original sum-product or max-sum algorithm meet with difficulty since it requires tha t each node needs to wait for all-but-one message to arrive. Thus in TPFG some nodes will be waiting forever due to the existence of cyc les. To overcome this problem, we arrange the message passing in a mode based on the strict order determined by H  X  . Each node a has a descendant set Y  X  1 i and an ascendant set Y i .

The message is passed in a two-phase schema. In the first phase , messages are passed from advisees to possible advisors, and in the second, messages are passed back from advisors to possible a d-visees. Formally, there are two kinds of messages in the first phase: m is generated and sent only when all the messages from its desc en-dants have arrived. And y i immediately send it to all its ascendants f () , j  X  Y i . In phase two, there are also two kinds of messages: m direction on the edge as in phase 1. The messages are calculat ed as follows, derived from Eqs. (12) and (11). After the two phases of message propagation, we can collect t he two messages on any edge and obtain the marginal function.
This algorithm still has redundant storage and computation . The messages sent between function nodes and variables nodes ar e func-tion values, which need to be stored as vectors. Some message s are never used during the final merge, and some messages are simpl y transmitted from one variable node to its corresponding fun ction node. We further simplify the message propagation by elimin ating the function nodes and the internal messages between a funct ion node and a variable node, and we find it equivalent to a message passing procedure on the homogeneous graph H  X  , i.e. , message propagation between authors, and the messages can be stored with each author in two vectors: one sent and one received. The ord er of messages passed is illustrated by the number on each edge i n Figure 4. In this way both time and space are saved.

The improved message propagation is still separated into tw o phases. In the first phase, the messages sent i which passed from one to their ascendants are generated in a similar order as be fore. In the second, messages returned from ascendants recv i are stored in each node. After the two phases, each node collects the two vectors to generate the final ranking score. The derived rule s are as follows. In the new algorithm, the message propagation can be done by u s-ing a stack-queue. In phase 1, each node will enter the queue o nce and the vector sent i for them is computed one by one. In phase 2, we scan the queue from the tail back to the head, i.e. , treat it as a stack, and compute recv i . Then we can normalize the results and collect them to get the ranking score. By using O ( | E  X  running time of the algorithm can be reduced to O ( P n a where d i and d  X  i are the in-degree and out-degree of each node a on graph H  X  , respectively. As long as if H  X  is sufficiently sparse, the maximal degree of the node can be seen as constant C and the complexity is further reduced to O ( n a ) .
In this section, we present various experiments that evalua te the efficiency and effectiveness of the proposed approach. Data Sets. We use the DBLP Computer Science Bibliography Database maintained by Michael Ley as the dynamic collabora -tion data set G to infer the advisor-advisee. It consists of 654,628 authors and 1,076,946 publications with time provided (fro m 1970 to 2008). To test the accuracy of the discovered advisor-adv isee relationships, we adopt three data sets: One is manually lab eled by looking into the home page of the advisors, and the other tw o are crawled from the Mathematics Genealogy project 1 and AI Ge-nealogy project 2 . We refer to them as MAN, MathGP and AIGP respectively. They only paretically cover the authors in DB LP. We further separate MAN into three sub data sets: Teacher, Ph D and Colleague. Teacher contains all kinds of advisor-advis ee pairs, while PhD only contains graduated PhDs pairing with their ad vi-sors. Colleague contains colleague pairs which are negativ e sam-ples for advisor-advisee relationship. And we use these dat a to generate random data sets for test. See Table 1 for details. Method. We compare the proposed TPFG with the following base-line methods: http://www.genealogy.math.ndsu.nodak.edu/ http://aigp.eecs.umich.edu/ Evaluation Aspects. To quantitatively evaluate our method, we consider two performance measurements: accuracy and scala bility. For accuracy, ROC curve is used to evaluate the overall ranki ng of each prediction, to see whether real advisor-advisee pai rs rank higher than non advisor-advisee pairs; and P @ k,  X  is used to evalu-ate the prediction for each individual X  X  advisor, to see whe ther real advisor ranks on top among all collaborators. We also list a f ew examples to demonstrate how discovered advisor-advisee re lation-ships can benefit other applications.

The preprocess is implemented with MATLAB 2009a and all experiments are performed on a Desktop running Windows XP with two Dual-Core Intel Pentium 4 processors (3.0 GHz) and 1 GB memory. The JuncT algorithm is implemented using the packag e MALLET [13]. We implement TPFG with Visual C++ 2008. And we use LIBSVM [4] to perform SVM training and prediction. We conduct a series of experiments to explore the capability of TPFG algorithm in mining advisor-advisee relationships. F irst, as we mentioned in Section 4.1 and Section 4.2, different assum ptions about advising relationships are tested to find the best comb ination that reflects the reality. Second, we extract small fraction s of the whole DBLP network and feed them to TPFG, to prove that the power of network boosts the estimation of joint probability . Fi-nally, we compare our unsupervised approach with a supervis ed approach. We also tested whether TPFG can be further improve d by utilizing training data.
We try different rules one by one to construct the correspond ing candidate graph H , compute the ranking score with our algorithm, and compare the accuracy on some labeled data.

The accuracy is compared through ROC curves. For each pair in the tested data, we retrieve the ranking score from the outpu t. Then we sort these ranking score in a descendant order, and plot th e ROC curve.

From Figure 5(a) we can see that R2/R3 has the highest suit-ability on the tested data. R1 and R4 both lead to a slightly wo rse curve and their curves overlap. In this way we can further refi ne other rules, including the definition of local likelihood, a s shown in Figure 5(b), and estimation of the graduation year, which we found does not affect the ROC curve. In general, by applying a small set of rules our method can extract meaningful knowledge, wh ile which rules to select is flexible depending on the problem spe cifi-cation. It is also observed that TPFG is not sensitive to thos e rules. For example, if we choose R2, or even R1/R4 other than R3, the worst AOC value 0.88 is not degraded drastically from the opt i-mal choice 0.91. It indicates that our network modeling appr oach is robust in handling inaccurate local features. From now on we use R3 as filtering rules, use the combination of Kulczynski a nd IR as local likelihood evaluation measure and use YEAR2 as th e graduation year estimation method if not mentioned specific ally.
Using DFS with a bounded maximal depth d from the given set of nodes, denoted as DFS-d , we can obtain closures with controlled (a) TPFG with different rules (c) TPFG on different closures of a subnetwork (e) IndMAX, TPFG and SVM on TEST1 depth for a given set of authors to test. When d increases, the sub-network grows larger until it is already the complete closur e, i.e. , the maximal connected subgraph of H containing the given set. We run TPFG on these closures and plot the ROC curves.
 From Figure 5(c) we see that for closures with different dept hs, TPFG achieves better accuracy when the depth increases, and they all outperform the IndMAX method by more than 5% in AOC. And on the complete closure TPFG reaches the same accuracy as on t he whole network since disconnected components will not affec t each other.

On these various scaled subnetworks, TPFG achieves differe nt level of approximations to the optimal global joint probabi lity on the whole network. To compare it with the exact maximal joint probability and other approximate algorithm, we show the re sult on a small graph due to limitations of JuncT and LBP (see Sec-tion 4.4). The small graph is constructed by extracting the n odes in PhD and their advisors, and then building 1 -closure of it. It con-sists of 1310 nodes. From Figure 5(d) we find that in the small graph TPFG approximates well to the exact inference algorit hm JuncT(AOC difference &lt; 0.01), and outperforms LBP by 16.9%.
Support Vector Machines(SVMs) are accurate supervised lea rn-ing approaches and shown to be successful in syntax-based re la-data set RULE SVM IndMAX TPFG TEST1 69.9% 73.4% 75.2% 78.9% 80.2% 84.4% TEST2 69.8% 74.6% 74.6% 79.0% 81.5% 84.3% TEST3 80.6% 86.7% 83.1% 90.9% 88.8% 91.3%
IndMAX,TPFG: left - X  = 3 rd quartile of { r ij } ; right -trained tion mining[6]. If we treat advisor-advisee pairs as positi ve exam-ples and non advisor-advisee pairs as negative examples, we can reduce advisor mining to a classification problem on the orde red pairs ( a i , a j ) . In this setting it requires to define some features for each pair of coauthors, and train the classifier by feedin g both positive and negative samples. For fair comparison with our prob-abilistic model, we combined Kulczynski and IR measures wit h what were used in [19] as features.

Direct application of SVM only shows whether a given pair is a n advisor-advisee pair, and it is often the case an author is pr edicted to have multiple advisors, 1001 out of 2657 for TEST1, for examp le. Thus we examine the probabilistic scores in the test data, an d rank them to draw the ROC curve. TPFG is 4 . 2% and 2 . 4% higher in AOC than SVM in TEST1 and TEST2 respectively.

Although in this work we define our model as an unsupervised learning approach, it can also work with supervised learnin g. We have utilized labeled data to select rules in Section 5.2.1. We can also optimize the parameter  X  in the P @ k,  X  as we mentioned in Section 3 according to certain criteria such as achieving be st infor-mation gain on the training data. Then we use the trained para me-ters to do predictions on test data. Table 1 shows the improve ment by utilizing the training data. After training, TPFG can rea ch an accuracy of 84% to 91% .

SVM actually makes a supervised combination of all the as-sumptions and rules used in TPFG. The difference lies in that it does not explore the constraint and dependency replying on t he whole network structure. It does a fairly good job, but still 5-10% worse than optimized TPFG. In conclusion, TPFG can achie ve comparable or even better accuracy compared with a supervis ed method. When parameters are adjusted with training data, it s accu-racy can be further improved by around 3% .
With case study, we find that TPFG can discover some interest-ing relations beyond the  X  X round truth X  from single source. Table 2 shows some examples. Our ranking results provided with advi sing time facilitate finding such kind of advising relations, whi ch cannot be easily discovered by referring to Genealogy projects. Th e mean of deviation of estimated graduation time to the labeled tim e on the test data sets is 1 . 76  X  1 . 78 .

We find that at least 40% of the error is contributed by name ambiguity. For example, if we try to find the advisor for  X  X ose ph Hellerstein X , our algorithm returns wrong results. If we di stinguish  X  X oseph M. Hellerstein X  and his publications properly, our algo-rithm is able to find the "half" right answer Michael Stonebra ker ranked top 1. The answer is half right because there is a co-ad visor Jeffrey F. Naughton, who is also ranked high in top 15%. Dupli ca-tion are even more common among Chinese names. Therefore, if the name DISTINCTION problem [20] is solved well, the accura cy Table 2: Examples of mined relations. Time -the estimated advising time; Note -the factual relation and graduation ye ar Advisee Top Ranked Advi-sor Time Note David M. Blei Hong Cheng Sergey Brin 1. Rajeev Motwani 1997-1998 "Unofficial advisor" 3 3 cited from a blog of Sergey Brin, who left Stanford to found Figure 6: Scalability results in log-log scale. JuncT and LB P fail at 10K and 200K respectively due to memory limitation. of our algorithm can be further improved. Other reasons for f alse negatives include that one researcher collaborated with mu ltiple ad-visors or that one coauthored fewer papers with the advisor. The latter case happens more often for older researchers, for wh om the publication data are not as complete as nowadays. More examp les are provided in Section 5.4. In those situations, it is almos t impos-sible to find credible advisor-advisee relationships merel y based on their publication records. Our study can find typical cases b ut will miss such atypical cases.
Figure 6 depicts the running time required for different alg o-rithms to infer the probabilistic rank. The same preprocess ing is done for IndMAX, JuncT and TPFG, taking 48 minutes. IndMAX and RULE do not perform further learning after preprocessin g.
TPFG is shown to be scalable in Figure 6. With regard to the learning time, TPFG costs only 13 seconds on the whole DBLP dataset. As a classification approach, SVM X  X  scalability is related to the size of training data. As an example, the feature compu tation takes one hour and a half, and the model learning takes 31 seco nds for Train1 and 6min26s for Train2.
The discovered advisor-advisee relationships can benefit m any applications, such as online query of advisors, visualizat ion of ge-nealogy, and expert finding, etc. . Here we show two examples. Visualization of genealogy The visualized hierarchies of research community based on the relationship can help us gain a better in-sight of the community. With visualization technique from [ 10] we can draw the advising tree on hierarchical circles. For exam ple, in Figure 7 we show a subtree of the Mathematics Genealogy. To vi -sualize our results on it, we draw edges with different color s. We have visualized results from both the baseline algorithm RU LE and TPFG. The figure is better to be viewed in color mode. We see tha t RULE tends to give a ratio close to 1:1 of true positives to fal se neg-atives, while TPFG raises this ratio by twice. Zooming into a local Figure 7: visualization of advising relationship on geneal ogy tree, green solid=true positive, red dotted=false negativ e region, we see clearly that TPFG is able to identify Prof. Dav id Peleg X  X  students and advisor correctly while RULE could not .
The visualization also leads to some interesting finding. Pa rtic-ularly, in TPFG result, we found the red dotted edges were clo ser to the root than the green edges. This observation infers tha t TPFG tends to make mistakes for researchers who graduated earlie r. With further statistical analysis, we found that for researcher s involved in true positive relations, the average graduate time is 1994 w hile for false negative results, the average is 1983. We can also anal yze col-laboration patterns for different research topics and affil iations by looking at those mistakes. For example, the advising tree of some theoretical computer scientists centered in Prof. Manuel Blum has a lot of outliers when de-tecting their relationship. This implies they have some unusual collaboration patterns. We then found that Diane Hernek and Russell Impagliazzo have no publication coauthored with their advisor, while Peter Gem mell and Luis von Ahn only have 1/8 of their papers with Manuel Blum in DBLP.
 Expert finding and Bole search Here we illustrate one appli-cation on bole search [19], a specific expert finding task, aim ing to identify best supervisors (according to their nurture ab ility [14]) in a specific research field. The task requires advisor-advis ee re-lationships as input which are usually unavailable. To quan tita-tively evaluate how the advisor-advisee relationships can help bole search, we compare a retrieval method with and without those re-lationships on a data set used in [19]. Specifically, the data set consists 9 queries (e.g., data mining and machine learning) , and for each query, 50 top ranked researchers by ArnetMiner.org are taken as candidates. We sent an email to each of the 50 researchers a nd another 50 young researchers who start publishing papers on ly in recent years (&gt;2003) for feedbacks ( X  X es X , or  X  X o X , or  X  X ot s ure X ). Finally a list of best supervisors are organized for each que ry by simply counting the number of  X  X es X (+1) and  X  X o X (-1) from th e 100 received feedbacks. Details can be referred to [19]. For easy comparison, we did not use the learning-to-rank approach (a s re-ported in [19]). Instead, we use the language model (LM), whi ch does not consider the advisor-advisee relationships, and a heuristic-based method which simply combines the language model with the advisor-advisee relationships identified by the baseli ne method (LM+RULE) or identified our proposed approach (LM+TPFG) by (a) An example of Bole Search
Figure 8: Application: from Expert Finding to Bole Search where r i is the relevance score obtained by the language model; A is a set of advisees of researcher a i identified by RULE or TPFG;  X  is a parameter to trade off the balance between researcher X  X  exper-tise and his advisees X  expertise score. We empirically set  X  = 0 . 7 .
Figure 8 (b) shows the results (Precision@2, Precision@5, m ean average precision (MAP), and NDCG@5 [1]) of bole search by the three methods. We see that by considering the advisor-ad visee relationships (obtained by either RULE or TPFG), the perfor mance of bole search can be significantly improved. We can also see t hat with a higher accuracy, our method TPFG clearly achieves a be tter improvements, particularly for the top two retrieved resul ts (71.4% by TPFG vs. 64.3% by RULE in terms of P@2).
We have studied the mining of advisor-advisee relationship s from a research publication network as an attempt to discover hid den semantic knowledge in information networks. We propose a tw o-stage framework to transform a collaboration network step b y step until constructing the advising hierarchy with ranking. We propose a Time-constraint Probabilistic Factor Graph (TPFG) model to in-tegrate local intuitive features in the network. Finally, w e design an efficient learning algorithm to infer the TPFG model. Experi mental results on the DBLP data sets demonstrate the effectiveness of the proposed approach.

Interesting problems related to the approach include how to ex-tend the approach to general relationship mining, to incorp orate prior information to enable semi-supervised learning, and to cope with multi-typed nodes and links. Another interesting prob lem is to correlate the discovered latent relationship with socia l influence analysis. Clearly, much more can be exploited with an inform ation network by exploring inherent knowledge from it.
Additional authors: Jingyi Guo (Tsinghua University, emai l: guojy07@mails.tsinghua.edu.cn ) [1] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information [2] C. M. Bishop. Pattern Recognition and Machine Learning . [3] S. Brin and L. Page. The anatomy of a large-scale [4] C.-C. Chang and C.-J. Lin. LIBSVM: a library for support [5] H. B. Coonce. Computer science and the mathematics [6] B. Coppola, A. Moschitti, and D. Pighin. Generalized [7] C. P. Diehl, G. Namata, and L. Getoor. Relationship [8] B. J. Frey. Graphical models for machine learning and [9] L. Getoor and B. Taskar. Introduction to Statistical [10] Y. Jia and J. C. Hart. Drawing trees: How many circles to [11] S. P. Kadri, S. Pradhan, K. Hacioglu, W. Ward, J. H. Marti n, [12] F. R. Kschischang, S. Member, B. J. Frey, and H. andrea [13] A. K. McCallum. Mallet: A machine learning for language [14] B. K. Mohan. The best nurturers in computer science [15] F. Rinaldi, G. Schneider, K. Kaljurand, M. Hess, and [16] Y. Sun, Y. Yu, and J. Han. Ranking-based clustering of [17] L. Tang and H. Liu. Relational learning via latent socia l [18] T. Wu, Y. Chen, and J. Han. Re-examination of [19] Z. Yang, J. Tang, B. Wang, J. Guo, J. Li, and S. Chen. [20] X. Yin, J. Han, and P. Yu. Object distinction: Distingui shing
