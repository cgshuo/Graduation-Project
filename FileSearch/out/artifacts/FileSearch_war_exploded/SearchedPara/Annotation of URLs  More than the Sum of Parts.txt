 Recently a number of studies have demonstrated that search engine logfiles are an important resource to determine the relevance relation between URLs and query terms. We hy-pothesized that the queries associated with a URL could also be presented as useful URL metadata in a search engine re-sult list, e.g. for helping to determine the semantic category of a URL. We evaluated this hypothesis by a classification experiment based on the DMOZ dataset. Our method can also annotate URLs that have no associated queries. Categories and Subject Descriptors: H.3 [Informa-tion Storage and Retrieval] General Terms: Experimentation, Human Factors
In this study, we investigate the applicability of seman-tic annotation of web pages by creating short document descriptions (term lists) extracted from associated queries. We assume that, when presented to a user, these term lists may help in the disambiguation of a URL and/or identifying whether the URL corresponds to the user X  X  query intent [2]. In previous work, we conducted a pilot experiment that demonstrated that document descriptors extracted from the queries associated with URLs provide useful semantic infor-mation about documents in addition to descriptors extracted from the full text of the web pages [8].

In the current paper, we explore which level of URL gen-eralization (exact URL, domain, or separate URL terms) yields the most informative associations from the query logs. We use the most salient terms extracted from the (weighted) set of query terms associated with an URL as a description for that URL. Specifically, we aim to find out whether the query terms associated with the individual URL terms can be used to construct a generative model to generate a query term description for any URL based on a combination of the individual URL terms. To answer these questions we con-duct a URL classification experiment, comparing different query term based representations.

It has been shown that queries and click information can serve as a means for implicit tagging [3]. Several studies have investigated whether a collection of queries and click infor-mation can serve as an (improved) model of the semantic contents of a web page e.g. [1]. A document representation based on queries has been compared with a traditional doc-ument content vector space representation for a clustering task [5]. The query-based representation resulted in a better clustering than the content-based representation. Working with the site access logs of a portal means that log files are complete. Our experiments differ since they comprise a much larger set of web pages, are based on a search engine log file (and therefore query logs are incomplete) and clas-sify URLs without any specific associated queries. A similar comparison study has been carried out between a content-based document representation, a tag-based representation ( del.icio.us ) and an anchor text representation [6]. The tag-based representation outperformed the text and anchor-based representation in a clustering task. Web page classifi-cation experiments regularly use the DMOZ Open Directory RDF Dump 1 as a resource. Individual URL elements have been suggested as features for web page classification [4]. Our work differs since it explicitly models the relation be-tween URL elements and associated query terms.
The objective of our experiments is to evaluate whether terms derived by aggregating query log data provide useful hints for disambiguation or identifying query intent. To eval-uate the value of query log data, we performed an URL clas-sification experiment using different sets of terms extracted from the URL itself and the associated queries.
 Data: The Microsoft 2006 RFP dataset consists of approx-imately 14 million queries from US users entered into the Microsoft Live search engine in the spring of 2006. For each query the following details are available: a query ID, the query itself, the user session ID, a time-stamp, the clicked URL, the rank of that URL and the number of results.
For the classification task we used the DMOZ Dump, consisting of URLs and their class labels (e.g. bikeriders-tours.com  X  Top/ Sports/ Cycling/ Travel/ Tour Operators). We restricted the data to DMOZ level 2 labels (e.g Top/ http://rdf.dmoz.org/ Sports). We discarded the URLs labeled Top/Regional , since Regional is the top node of a different hierarchy (a regional classification). The intersection of the MSN and DMOZ collections (with the above restriction) consists of 109,493 URLs, divided over 15 classes.
 Experiments: To determine the most descriptive and dis-criminating query terms associated with a given URL, we calculated the pointwise Kullback-Leibler divergence between each pair of a query term and associated URL: where p ( w ) = P ( w | url ) is the probability of observing the query term w given the url , and q ( w ) = P ( w | C ) is the probability w is observed in the collection of all queries.
We proceeded by deriving the top fifty associated query terms for a URL in three different ways. Each different approach is an increasing generalization of the URL.
For the last method, URL tokens u were extracted by splitting the URLs on non-alphanumeric characters. This resulted in raw term strings (e.g. bikeriderstours ). We decompounded these raw strings using a script that sub-sequently looks up substrings in the CELEX lexicon stores an URL term u if the lexicon contains the term and it lemmatizes it (e.g. resulting in the URL tokens bike , rider and tour ). The URL token representation also served as a baseline for the classification experiment 3 .

Next we investigated whether the obtained query terms provide significant discriminative information for the asso-ciated URL. To do so, we used the extracted query terms as features for a URL classification experiment. The DMOZ URL class label was used as ground truth.

For our classification experiments, Adaboost.MH [7] was used. The advantages are mainly its good generalization ca-pacity, and its innate feature weighting capacity. Adaboost is particularly capable of dealing with short utterances with high lexical variation. Our data fits this description: lexi-cally varied small-sized bags of terms.
Table 1 shows the classification accuracy (proportion of in-stances that were classified with a correct DMOZ category). The majority class baseline is an artificial setting in which all urls are classified as the majority class ( X  X usiness X ). All conditions involving (aggregates of) query tags outperform the URL tokens baseline, which is encouraging. Good per-formance was obtained for aggregation at the domain name level, which can be explained by the fact that more informa-tion is available which helps to boost frequent, more reliable http://www.ldc.upenn.edu/
Unfortunately no full text crawl from the same time period is available for the URLs involved. The experimental focus is on dealing with sparseness.
 terms. The model based on associations between individ-ual URL tokens and query terms performs remarkably well. We did some preliminary tests on DMOZ URLs that did not contain clicks in the MSN dataset, but had a relation on the domain level. The results of these tests are shown in parentheses. The method that aggregated query terms across the domain scored worse than the baseline (0.26), probably indicating that many URLs with a similar domain name do have different categories. Our annotations based on the probabilistic url token to query term association dic-tionary p ( w | u ) scored slightly worse than the baseline.
We constructed several document descriptions (term lists) using click data. The representations differed in the level of aggregation applied to overcome data sparseness. The most general model is a generative model based on a URL as a bag of tokens and an association dictionary trained on the search engine logfile to annotate URLs for which we have no associated queries. These models can serve as (a basis of) useful document descriptors, as shown by a URL categorization task.
