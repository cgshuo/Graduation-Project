 Keyphrase extraction is a long studied topic in natural language processing. A keyphrase, which consists a word or a group of words, is defined as a precise and concise expression of one or more documents. In recent years, keyphrase extraction has received muc h attention [2,11,3,6,7].

Keyphrases are usually manually chosen by authors, for scientific publications, magazine articles, books, et al. Because the manual effort of assigning keyphrase is expensive and time consuming, web pages and online news rarely contain keyphrases. It should be useful to automatically extract keyphrases from online news to represent their main contents. There are already a number of studies which focus on extracting keyphrases from scientific publications or single news article [13,8,10,4]. We also notice that, currently, many websites provide the service which group related news together to facilitate users browsing. In this paper, we focus on extracting keyphras es from a group of news articles which describe the same news event by different publishers.

Most of the current methods focus on judging the importance of each phrase, and individually extract phrases with the highest scores. In this paper, we re-gard the keyphrases as a sequence and aim to extract syntactically coherent keyphrases for summarizing a collectio n of news articles about the same subject or event. After analyzing the human assi gned keyphrases, we observe that the keyphrases of news should satisfy the following properties: 1. Relevance. The keyphrases should be semantically relevant to the news 2. Indication. The keyphrases should be indicative of the whole news event. 3. Coherence. Here, coherence means keyphras es should be not only seman-4. Conciseness. We should keep least redundancy in keyphrases.
 In order to automatically select keyphrases which can satisfy the above prop-erties, we propose a keyphrase extraction approach under a learning to rank framework. This approach involves two phases: selecting candidate keyphrases and ranking all sub-permutations among candidates. Three feature sets: lexical feature set, locality feature set and coherence feature set are introduced to rank the candidates, and then the best sub-permutation is extracted as keyphrases.
The major contributions of this work can be summarized as follows: 1) We present a novel approach based on learning to rank framework to extract coher-ent keyphrases from news. 2) Keyphrases are extracted as a sequence, and the relationships among them are considered. 3) Some novel features are introduced to improve the quality of keyphrases. 4) E xperimental results on the dataset con-sisting of 150 groups of news articles with human annotated keyphrases demon-strate that our method is effective to e xtract coherent news keyphrases.
The remaining of the paper is organized as follows: In section 2, we review the related work and the state-of-the-art approaches in related areas. Section 3 presents the proposed method. Experim ental results in the t est collection of  X  X ewsKEX X  are shown i n section 4. Section 5 concludes this paper. Existing methods can be categorized into supervised and unsupervised approaches.

Unsupervised approaches usually select general sets of candidates and use a ranking step to select the most important candidates. For example, Mihalcea and Tarau propose a graph-based approach called TextRank, where the graph nodes are tokens and the edges reflect co-occu rrence relations between tokens in the document [9]. Wan and Xiao expand TextRank by using a small number of topic-related document to provide more knowle dge, which improves results compared with standard TextRank and a tf.idf baseline [13]. Liu and Sun argued that the extracted keyphrases for documents should be understandable, relevant, and good coverage and an unsupervised method based on cluster was proposed to extract high-quality keyphrases [6].

Supervised approaches use a corpus of training data to learn a keyphrase extraction model that is able to classify candidates as keyphrases. A well known supervised system is Kea that uses all n-grams of a certain length as candidates, and ranks them based on a Naive Bayes classifier using tf.idf and position as its features [2]. Extractor is another supervised system that uses stems and stemmed n-grams as candidates [11]. Tu rney introduces a feature set based on statistical word association to ensure that the returned keyphrase set is coherent [12]. Hulth argues that some linguistic knowledge, such as NP chunks and POS tag, can improve the performance when learning model is applied [3].Nguyen and Kan present a keyphrase extraction algorithm for scientific publications [10]. 3.1 LearningtoRank Recently, learning to rank technologies ha ve been intensively studied. Different from classification and regression, the goal of learning to rank is to learn a func-tion that can rank objects according to t heir degree of preference, importance, or relevance[14,1].

In this paper, we employed a kind of lea rningtorankmethodtoperformour two-phase task. We will take the phase 2 as an example to explain why it is suitable to employ a pairwise learning to rank method. The reason is that, it is more natural to consider the likelihood of a sub-permutation X  X  being keyphrase sequence in a relative sense than in an absolute sense. For example, given two phrase sequences p1 and p2, suppose, p1 is more suitable to be keyphrase se-quence than p2, but the absolute scores of them can not be easily evaluated. So we should consider the problem in a relat ive sense and a pairwise method can be employed. Specifically, in pairwise learn ing to rank framework, the optimization goal is p1 X  X  priority to p2 in the ranking list. And their absolute scores are not our concern. 3.2 Two-Phase Ranking Approa ch to Keyphrase Extraction In this section, learning to rank model is employed for our two-phase task. Candidate Keyphrase Selection. In this step, we are aiming to select suitable phrases as candidate keyphrases according to their importance. First, we regard each word w as a ranking instance, create a feature vector for each w and train a ranking model to sort the words by employing a pairwise learning to rank framework described in sect ion 3.1. Then, top-n phrases are selected as candidate keyphrases(n is assigned to 6 a fter tuning the parameter).
 Keyphrase Extraction from Candidates. This step is to find the indica-tive, coherent and concise keyphrases from the candidate keyphrases. So we need to find, not only the appropriate keyphrases from the candidates, but also the appropriate order. To accomplish this goal, we generate all the possible sub-permutations of candidate keyphrases. However, there will be exponential number of possible sub-permutations. To reduce the number of candidate sub-permutations, we use the following strategies. A sub-permutation will be selected if both conditions are satisfied. 1. Select only sub-permutations composed of two to four phrases. As observed 2. Select only sub-permutations with POS tag sequence which exists in the Then each sub-permutation is regarded as a ranking instance. We employ a pairwise learning to rank framework to sort all sub-permutations and select the top one as keyphrase sequence. 3.3 Features in Two Phases In this section, we will describe the features we used in two phases. The two phases of keyphrase extraction share some similar features, especially, lexical features and locality features. The diff erence between them is that features for candidate keyphrases selection are in wo rd-level, while features for keyphrases extraction are in phrase sequence level.
 Single Word Features for Candi date Keyphrase Selection. In this sec-tion, features are all in word-level, including TF-IDF score, position of a word X  X  first occurrence, a word X  X  appearance in n ews title [4] and keyword prior. Here, TF-IDF score and keyword prior are lexical features, and the other two are lo-cality features. Actually, the features in this paper are all based on multi-news. Phrase Sequence Features for Keyphrase Extraction. Similar to phase 1, the lexical and locality feature set are also used to represent a keyphrase sequence, but their meaning is slightly di fferent -this time, they are defined on phrase sequence level. Additionally, a new set of features for measuring coherence are introduced in this section. Next we w ill explain each feature set in detail.
Lexical Feature Set 1) TF.IDF Here we calculate the average TF.IDF value for the keyphrase sequence of K . Where n is the total number of words in the keyphrase sequence K .

Locality Feature Set 1) Appearance in Title The case of word existence in title will off er evidence to keyphrases extraction. So we also calculate the average value for keyphrase sequences.
 n is the number of words in the keyphrase sequence. 2) First Occurrence in the Article When given sub-permutation K , the feature can be calculated as: Where w is a word in the keyphrase sequence K , and n is the number of words which appears in K .

Coherence Feature Set 1) Mutual Information(MI)
Turney argued that keyphrases should be semantically related [12]. So a well-known phrase association measure mutual information is applied. To tackle the situation of arbitrary number of variables, the two-variable case can be extended to the multivariate case. The extension called multivariate mutual information (MVMI) can be gen eralized to: where n is the number of pair I ( p i ,p j ). i, j = { 1 , 2 ...k ; i = j } and p ( p i ,p j ) is co-occur times of p i and p j within a window of 10 words[5]. 2) Sequence-Based
Sequence-based feature aims to guaran tee a suitable sequence for keyphrases by ensure the consistence between keyphr ase sequence and news article. Specif-ically, we obtain the sequence-based feature by calculating average of pairwise values for keyphrase sequence.
 Where m is the number of terms in keyphrase sequence, and t ( p i ,p j )isthe frequency that phrase p i exists in front of phrase p j in a sentence in the news article. 3) Syntactic Feature Hulth argued that linguistic features can help when extracting keyphrases[3]. So in this paper, syntactic feature are applied to ensure the coherence of keyphrases. Specifically, dependency relation of keyphrase sequence is employed. In this step, keyphrase sequence are first parsed by a dependency parser, in which 24 dependency relations (e.g. SBV, VOB, ATT...) are defined.

In a dependency tree of keyphrase sequence, their dependency relation se-quence are applied to represent the keyphr ase sequence. For instance, (SBV,VOB) can represent the keyphrase sequence  X  X oyota X   X  X ecall X   X  X rius X . Dependency relations can provide evidence to the coherence of keyphrases to some extent. We can acquire possible dependency relat ion sequences from the training data, and score them according to their occurrence probabilities. The value can be calculated as: Where num ( Dependency ( K )) is the number of dependency relation sequence of K the in training set. 4.1 Experimental Data There are almost no publicly available datasets with manually annotated gold standard keyphrases for news, due to the high expense of labor and time for manual annotation. In this experiment, we randomly selected 150 groups of online news articles from Goolge News. We divided the dataset into two subsets: 100 for training and 50 for test. The detail of our dataset is shown in table 1.
In the phase of candidate keyphrases selecting, human annotators are asked to label the words with two levels of relevance, which represent whether the word is a part of keyphrases or not. In the second phase, human annotators are asked to label the each sub-permutation of candidate keyphrases with three levels. We assign level 2 to sub-permutations which are the most suitable as keyphrase sequences and level 1 to those probable as keyphrase sequences, others are assigned with level 0. 4.2 Evaluation Measures In order to evaluate news keyphrases clearly, we introduce two kinds of evaluation measures: quantitative measures and qualitative measures.
 Quantitative Measures
For evaluate the obtained keyphrases, we first report the in quantitative measures: Precision, Recall, and F-value. Precision means the percentage of  X  X eyphrases truly extracted X  among  X  X  eyphrases extracted by system X . Re-call means that  X  X eyphrases truly extracted X  among  X  X eyphrases manually as-signed X . F1 is the average of Precision and Recall.
 Qualitative Measures
We also ask 6 human annotators to evaluate the quality of extracted keyphrases, meaning that whether they can meet the properties we have pre-sented: indication, coherence and conciseness. The average Kappa statistic among them is around 85%, which shows good agr eement. Then we respectively report Indication, Coherence and C onciseness to measure these three performances. The measure is calculated by the number of news which obtains indicative (coherent or concise) keyphrases divided by the total number of news. 4.3 Performance of Keyphrase Extraction We applied the RankSVM implementation available in the SVM light package 1 . Table 2 shows the different performance based on seven different feature sets. We report the quantitative results in Precision, Recall, F-value, as well as qual-itative results in Indication, Coheren ce, Conciseness. The results show that F4 feature set obtains the best performance in Precision and F6 gets the best in Recall. These confir m that locality feature and lexical feature are both effec-tive to extract keyphrases. The table also illustrates that coherence feature set can help to improve the overall quality of keyphrases. When combined with co-herence feature set, the performances are s ignificantly improved, especially, in measure Indication, Coherence and Conciseness. And F7 feature set obtains the best performance in measure F-va lue, Indication and Coherence.
 4.4 Comparing with other Algorithms In this section, we implement two base line methods on the same dataset for comparison and here our approach is based on F7 feature set applied due to the best performance.

Baseline-1: Baseline-1 is based on a classification method, SVM. We clas-sify phrases in the multi-news documents as keyphrases and non-keyphrases by applying SVM method. The features include TF-IDF, InTitle, FirstOccur, Keyphrases prior.

Baseline-2: The title of news articles provides a good enough summary or keyphrase sequence. So baseline-2 is performed based on the titles of news ar-ticles. We sort the phrases in multi-news titles according to the TF*IDF scores and select top-k as keyphrases. We assi gn k to 4 after tuning the parameter.
Figure 1 shows the results in quantitative measures. The results illustrate that our approach perform better than both two baseline approaches in quantitative measures. As shown in Figure 2, our approach obtain significant improvement in qualitative measures compared with two baseline methods, since our method introduces some coherence features in phr ase sequence level to ensure the quality of keyphrases. These confirm that our approach can significantly improve the quality of news keyphrases with no loss in quantitative measure. The results also show that we can X  X  obtain high-quality keyphrases simply based on titles of news article. 4.5 Discussion Contribution of Individual Feature. To determine the contribution of in-dividual feature, we employ our approach, omitting one feature each time and evaluation measurements including quantitative measures, as well as qualitative measures. Table 3 shows our results in quantitative measures. We can find that each feature is effective. Specifically, when eliminating locality features  X  X nTitle X  it results in a decrease in quantitative measures. The observations imply that the locality features are discriminative in predicting the keyphrases, because the information of occurrence of title in the articles are really helpful. Table 3 also shows the lexical feature TF.IDF score have strong connection to quantitative measures, which support that lexical information is helpful in prediction the im-portance of phrases in news articles. W e also find when eliminating coherence features  X  X equence-based X  it results in a notable decrease in all quantitative measures. That confirms that consistenc e between keyphrase sequence and news articles is helpful in quantitative measures.
 As shown in figure 3, when omitting the coherence features such MI and Sequence-based, the qualitative measure : Indication, Coherence and Concise-ness significantly decreases. That imp lies coherence feature are effective when extracting high-quality keyphrases. Additionally, the feature of  X  X nTitle X  and  X  X FIDF X  are also related to qualitative measure. In this paper, we try to extract coherence keyphrases from online group news keyphrases. After that, in order to inte grate those criteria into the keyphrase extraction task, we propose a novel formulation which coverts the task to a learning to rank problem. The proposed model has been verified on multi-news collections and the results show that our approach is effective to extract co-herence keyphrases. Additionally, the effect of different feature sets and even contributions of individual feature are analyzed. We find that all of three kinds of feature set can help to extract higher quality keyphrases. Future works in-clude developing ranking algorithm and trying other measures representative of performance for keyphrases.
 Acknowledgements. The author wishes to thank the anonymous reviewers for their helpful comments. This work was partially funded by National Nat-ural Science Foundation of Chin a (61003092, 61073069), Shanghai Science and Technology Development Funds(10dz 1500104), Doctoral Fund of Ministry of Ed-ucation of China (200802460066), and Key Projects in the National Science &amp; Technology Pillar Program(2009BAH40B04).

