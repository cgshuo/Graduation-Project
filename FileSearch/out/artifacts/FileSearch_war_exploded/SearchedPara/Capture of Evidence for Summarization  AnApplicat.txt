 It is sometime necessary to analyse a single document for intelligent decision making purpose in the absence of prior domain knowledge. In such a scenario, significant sentences from a document o r rather gist of that document can only let an user know about what it is all about. Based on this filtered information, the user can decide what kind of measures to be taken to perform the analysis; thus, single-document summarization is one of the best ways to do this.
One way to do text summarization is by text extraction, which means to extract pieces of original text on statis tical basis or heuristic methods and put them together to a new shorter text with as much information as possible pre-served [9]. The concept of extracting sig nificant sentences from a document for generating extractive summaries has drawn attention in the literature.
In this paper, our approach is not mere assigning scores to a sentence. When a document is looked from the perspective of human, they analyse it by finding what the main idea of the source text is and filtering what is essential in the information conveyed by the text. In [10], the authors have pointed out that a given piece of text is interpreted by different person in a different fashion espe-cially in the way how they understand and interpret the context. Thus we see that human understanding and reasoning is subjective in nature unlike proposi-tional logic which deals with either truth or falsity of a statement. So, to deal with this kind of situation we used subjective logic to find out sentences which are significant in the context and can be used to summarize a document. In this section, we present how we formul ate  X  X pinion X  about a sentence using subjective logic. Subjective logic [3] is a logic which operates on subjective beliefs about the world, and use the term opinion to denote the representation of a sub-jective belief. An opinion can be interpreted as a probability measure containing secondary uncertainty, and as such subject ive logic can be seen as an extension of both probability calculus and binary logic. It is a type of probabilistic logic that explicitly takes uncertainty and belief into account. It is suitable for modeling and analysing situations involving uncertainty and incomplete knowledge [3], [4]. 2.1 Interpretation of Evidence in a Document How can we define evidence in a document? This is what we are building here automatically. We consider words, phrases or co-occurrence of words, or a sen-tence itself to be evidence present in a document. Now, based on this, our basic motivation is to formulate  X  X pinion X  about a proposition, which is a sentence in this case. Stronger the opinions about a sentence, more is its significance in the document. These opinions are measured by probability expectation of a sen-tence. Greater the probability expectation, more significant is the sentence. If probability expectation of two sentences are similar, then we need to look at the sentence with lower uncertainty to fetch the important one [4] between two. Assumptions: We propose the following framework for the practical application of subjective logic in a docu ment computing context. 1. All the words or terms (removing the stop words) in a document are atomic. document.
 Representation of a document: A document consists of sentences. In this paper, a sentence is considered to be a set of words. In a document, sentences are sep-arated by stop marks ( X . X ,  X ! X ,  X ? X ). Terms (stop words excluded) are extracted and the frequencies (i.e. number of occurrences) of the words in each sentence are calculated.

Let us now define the notations which we will be using in the rest of the equa-tions and explanations.  X  is the frame of discernmen t. We represent a document as a collection of words, which is where, D w is a document consisting of words like w 1 , w 2 ... w n and | D w | = n . Now, Since a document is a collection of s entences, it can be represented as where m is a finite integer and each s i is an element of  X  (  X  ). Each sentence is comprised of words, which belong to the whole word collection of the document D w . We thus represent each sentence by, where, 1  X  i, k, r  X  n and S l  X   X  (  X  ). 2.2 Definitions of  X  X ubjective Logic X  and Our Conceptualization of each word in each sentence be one for simplicity. The words and sentences (atomic and non atomic states) represent evidence. Now, we use the original definitions from [4], and explain our formulation.

The first step in applying evidential reasoning is to define a set of possible situations which is called the frame of discernment,  X  . A frame of discernment delimits a set of possible states of the world, exactly one of which is assumed to be true at any one time. In the given example, total number of all possible states are 2 5 for 5 words given.
 Definition 1 (Belief Mass Assignment). Let  X  be a frame of discernment. If with each substate x  X  2  X  anumber m  X  ( x ) is associated such that: 1. m  X  ( x )  X  0 2. m  X  (  X  )=0 then m  X  is called a belief mass assignment in  X  , or BMA for short. For each substate x  X  2  X  ,thenumber m  X  ( x ) is called the belief mass of x. We calculate BMA for each event by, where F ( x )= N k =1 f x k , where N is the total number of sentences in the docu-ment, x  X  2  X  ,and f x k is the frequency of occurrence of event x in sentence k .In words, it is the total frequency of that event in all the sentences (or the whole document).
 Z is the total frequency of the all the events which has valid evidence of truth (whose frequency is non zero). In the given example, we have 7 valid states and their corresponding frequencies in the document are: { F ( w 1 )=1 ,F ( w 2 )= 2 ,F ( w 3 )=1 ,F ( w 4 )=2 ,F ( w 5 )=1 ,F ( w 1 ,w 2 )=1 ,F ( w 2 ,w 3 ,w 4 )=1 } . Therefore, Z = 9 in this case. Using (6), we calculate BMA for each of the states (or events) in the given example.
 Definition 2 (Belief Function). Let  X  be a frame of discernment, and let m  X  be a BMA on  X  . Then the belief function corresponding with m  X  is the function b :2  X   X  [0 , 1] defined by: m ( w 1 ,w 2 ).
 Definition 3 (Disbelief Function). Let  X  be a frame of discernment, and let m
 X  be a BMA on  X  . Then the disbelief function corresponding with m  X  is the function d :2  X   X  [0 , 1] defined by: We calculate disbelief of s 1 by d ( s 1 )= m ( w 3 )+ m ( w 4 )+ m ( w 5 ) . Definition 4 (Uncertainty Function). Let  X  be a frame of discernment, and let m  X  be a BMA on  X  . Then the uncertainty function corresponding with m  X  is the function u :2  X  [0 , 1] defined by: From Josang X  X  idea, we can get the Belief Function Additivity which is ex-pressed as: Now, one can simply calculate the uncertainty of a sentence by using (11), i.e., u ( s 1 )=1  X  ( b ( s 1 )+ d ( s 1 )).
 Definition 5 (Relative Atomicity). Let  X  be a frame of discernment and let x, y  X  2  X  . Then for any given y =  X  the relative atomicity of x to y is the function a :2  X   X  [0 , 1] defined by: It can be observed that x  X  y =  X  X  X  a ( x/y )= 0andthat y  X  x  X  a ( x/y )=1. In all other cases relative atomicity w ill be a value between 0 and 1. The relative atomicity of an atomic state to its frame of discernment, denoted by a ( x/ X  ), can state then refers to the frame of discernm ent. In this case, we get the following relative atomicity for sentence s 1 as: Likewise, we calculate the atomicity for other sentences.
 Definition 6 (Probability Expectation). Let  X  be a frame of discernment with BMA m  X  then the probability expectation function corresponding with m  X  is the function E :2  X   X  [0 , 1] defined by: So, for the given example, we calculate ProbExp for sentence s 1 as follows: ing denote belief, disbelief, uncertainty, relative atomicity and opinion functions s a ( x )).

In this context, we order sentences based on descending order of their probabil-ity expectation and ascending order of their uncertainty; sentence with stronger  X  X pinion X  has greater significance in a document. 3.1 Data Processing In this experiment we used DUC2001 data set [1] for evaluation. The documents are grouped based on a specific topic. Our main aim is to see how our model works on single documents for content analysis purposes, so we focussed on this kind of data set unlike other informatio n retrieval areas. These documents were parsed, tokenized, cleaned, and ste mmed. The cleaning is done by removing the stop words. DUC2001 comes with human generated summaries and baseline summaries, providing a good platform for evaluation. 3.2 Generation of Summaries Summaries are broadly classified into text extraction and text abstraction [7], [5]. For text extraction, sentences from the d ocuments are used as summaries and for text abstraction important pieces of info rmation are extracted and then stitched together to form summaries following some linguistic rules. This evidence based model can be used as a text extraction a s we use the original sentences. We compared our method and DUC baseline summaries with the human generated summaries provided by them.
 Evidence based model (PEU): In sec.2, we described our method of sentence ranking; subjective logic based wher e we ranked the sentences based on the descending order probability expectation and ascending order of uncertainty (PEU) of that sentence in the document. We took 30% [2] of the top ranked sentences and used them as summary. 3.3 Evaluation by ROUGE ROUGE [6] stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to automatically determine the quality of a summary by com-paring it to other (ideal) summaries created by humans. ROUGE is a recall based metric for fixed length summaries. The measures count the number of over lapping units such as n-gram, word sequences, and word pairs between the computer-generated summa ry to be evaluated and the ideal summaries created by humans.

In this experiment, we present the result with ROUGE-1 (n-gram, where n=1) at 95% confidence level. ROUGE is sensitive to the length of the summaries [8]; hence we fixed the length to 100 words for the evaluation. We used DUC2001 dataset for this experiment. Among different document sets, we presented here the evaluation with  X  X  aycare X ,  X  X ealthcare X  and  X  X res92 X . We compared our method (PEU) and baselin e summaries (denoted by LP) with two different human assessors. For each set the assessors are different. The average (table.1) results show that our method out performs the baseline summaries.
Figures 2(a) and 2(b) show the evaluation comparison using daycare data, where Acc dandAcc i are two human assessors. In both the figures 2(a) and 2(b), our method outperforms the baseline summaries (90% of documents with Acc d and 80% of documents with Acc i).
 Now, figures 3(a) and 3(b) present the results with healthcare data set. Here Acc bandAcc j are the two human assessors. There was no baseline summary for the 7th document in this series. So, in both the figures we have value as 0 in the comparison results. In fig.3(a), ROUGE score for PEU with Acc bishigher than baseline on average except for 30% of the documents. In fig.3(b), baseline shows higher similarity with Acc j than PEU in 60% documents.

In figures 4(a) and 4(b), PEU outperforms the baseline summaries (90% of documents with each assessors). In ta ble.1, Acc1 and Acc2 are alias of human assessors used in each case. Except for Acc2 in healthcare data, PEU has out-performed all the baseline summaries.

From these results, we can see that summaries produced by humans are ab-stract. So overlap with human generat ed of summaries with automated ones can vary a lot unless they are compared with extractive su mmaries created by humans selecting the original sentences from documents. In this paper we presented an evidence based sentence extraction method for single document summarization. We use d enhanced subjective logic to formu-late the whole process. Here standard methods for evaluating data are used; in the whole process we figured out that summarization is subjective to the user. In our system we basically used word frequency and co-occurrence concept for formulating subjective logic; rather su perficial knowledge. But the results are good in the sense that they have outperformed baseline summaries as illustrated in the results. For our future work we will extend this method to perform deeper semantic analysis of the text and redefine some features of subjective logic in document computing context.

