 Edw ard F. Harrington edward.harrington@dsto.defence.go v.au Lock Bag 5076, Kingston, Can berra, ACT 2604, Australia In applications like information retriev al and collab-orativ e ltering we want to order or rank documen ts rather than (simply) classifying them into relevant and non-r elevant documen ts, that is, we aim at nding mappings of instances to their correct ranks chosen from an ordered set of ranks f 1 ; : : : ; k g . For example consider the information retriev al task of rating a par-ticular query-do cumen t pair into relev ant, possible rel-evant, and not relev ant, whic h we mo del as an ordered set of 3. This example requires investigating the con-ten t of both the documen t and the query and using some similarit y metric between the two, resulting in a rank ed list of documen ts. An alternativ e approac h to ranking the query-do cumen t pair is collab orativ e ltering or recommender systems (Resnic k &amp; Varia, 1997; Breese, Hec kerman, &amp; Kadie 1998) where the predicted rankings for query-do cumen t pairs are made by using the rankings (or judgemen ts) made by people with similar interests or some exp ertise in ranking the pairs. We chose to focus on collab orativ e ltering, as this seems a natural way to rank items and avoid the issue of studying the con ten t of the items. Tw o di eren t ways traditionally used in tackling rank learning are: either as a regression problem or a classi-cation problem. However, in the regression setting a metric is required whic h con verts the ranks to real val-ues. Determining this metric is in general very dicult and mak es regression algorithms very sensitiv e to the represen tation of the ranks rather than their pairwise ordering. On the other hand, classi cation algorithms completely ignore the ordering of the ranks by treating them as classes and thus require in general more train-ing data. The main dicult y with regression, speci -cally SVM ordinal regression is the quadratic gro wth in the num ber of constrain ts as the training set size increases.
 A recen t rank learning algorithm motiv ated by the Perceptron is the PRank algorithm (Crammer &amp; Singer, 2001). In con trast to other algorithms (see Herbric h, 2000), whic h usually square the training set size by working on pairs of training examples, PRank requires a much smaller training set. For large data sets memory constrain ts mak e ranking metho ds whic h perform multiple runs through the data unmanage-able. We are therefore interested in online ranking learning algorithms that can be used for truly online problems, e.g. ranking web documen ts on the internet. Classi cation algorithms involving the Perceptron have been studied extensiv ely, and recen tly there has been increased interest in using them to pro duce large margin solutions (see, e.g. the varian ts of the marginal-ized Perceptron (Duda, Hart, &amp; Stork, 2000), Maximal margin perceptron (Ko walczyk, 2000), ROMMA (Li &amp; Long, 2002), ALMA (Gen tile, 2001), and MIRA (Crammer &amp; Singer, 2003)). For example, ALMA guaran tees a margin of (1 ) after O ( 1 2 2 ) up-dates 1 , where is the maxim um achiev able margin and 2 (0 ; 1]. Ensuring a large margin solution is de-sirable in pro viding the abilit y to handle concept drift as well as to con trol generalization error. However, Herbric h, Graep el, and Ob erma yer (2000) have sho wn that this carries over into the ranking learning task. Recen tly, Shash ua and Levin (2002) sho wed two di er-ent Supp ort Vector Mac hine (SVM) algorithms whic h maximized the margin resulting in a ranking learn-ing algorithm with better generalization performance compared to PRank. Having a rank learning solution with a large margin is desirable whilst remaining in the online setting. This motiv ates the searc h for a large margin varian t of the online algorithm PRank. In the next section, we formally de ne the ranking learning setting and recall the Perceptron ranking al-gorithm (PRank) of Crammer and Singer (2001). Sec-tion 3 presen ts a large margin version of PRank, the Online Aggregate Prank-Ba yes Point Mac hine (OAP-BPM). Online varian ts of the batc h voting metho ds of Bagging (Breiman, 1996) and the voted Perceptron (Freund &amp; Schapire, 1999) are also presen ted. Exp er-imen tal results are given in Section 4 for a num ber of real world collab orativ e ltering data sets and a syn-thetic ranking data set. As bac kground we pro vide the ranking de nitions [4] relating to the PRank algorithm. We have a nite set Algorithm 1 PRank (Crammer &amp; Singer, 2002) Require: A training example at round t of ( x t ; y t ) consisting of a rank y t 2 f 1 ; : : : ; k g and instance Require: Perceptron weigh ts w t 2 R d .
 Require: The threshold set at round t , c t = ( c t (1) ; : : : ; c t ( k 1) ; c t ( k ) = 1 ) 0 . 2: if ^ y t 6 = y t then 3: for r = 1 to k 1 do 4: if ( y t r ) then l t ( r ) := 1 else l t ( r ) := 1 5: end for 6: for r = 1 to k 1 do 7: if ( w t x t c t ( r )) l t ( r ) 0 then 8: a t ( r ) := l t ( r ) else a t ( r ) := 0 9: end for 12: else 15: end if 16: return Updated weigh ts c t +1 and thresholds w t +1 of ranks Y = f 1 ; : : : ; k g from whic h a rank y t 2 Y is assigned to an instance x t 2 R d . We are con-cerned with the sup ervised learning setting where we have a training sequence of instance rank pairs z = (( ing rule H : R d !Y .
 The PRank algorithm is de ned by rounds (iterations) of the PRank update (Algorithm 1). The ranking rule H of the PRank algorithm consists of the com bination of Perceptron weigh ts w 2 R d and a threshold vec-tor c = ( c (1) ; : : : ; c ( k 1)), where it is assumed that c ( k ) = 1 . The objectiv e of the PRank algorithm is to nd a Perceptron weigh t vector w whic h successfully pro jects all the instances in z into the k subin terv als de ned by the thresholds c , i.e. for the rank of r the subin terv al is c ( r 1) &lt; w x &lt; c ( r ). This ranking pro cedure of the resp ectiv e instances x t is given by Algorithm 1. At round t of PRank the rst step is to predict the rank y t (line 1 of Algorithm 1) for a given instance x t by selecting the smallest rank r suc h that w t x t &lt; c ( r ). If the prediction ^ y t is not the correct rank then a lab el of l t ( r ) = +1 is allo cated to those subin terv als above the target rank y t and l t ( r ) = 1 to those below 2 (lines 3, 4 and 5 of Algorithm 1). For eac h subin terv al, if the ranking rule H consisting of is subtracted from the threshold c t ( r ), and the Per-ceptron is updated w t +1 = w t + l t ( r ) x t . Our intu-ition tells us that updating w and c in this way has the e ect of moving the threshold of the desired rank c t +1 ( r ) and the updated predicted rank w t +1 x t +1 closer together. This pro cedure is rep eated for all the subin terv als r = 1 ; : : : ; k 1 for round t . Tw o imp ortan t results whic h are signi can t when con-sidering the bene ts of the PRank algorithm are: 1. The ranking order is preserv ed [4] between rounds, 2. The num ber of mistak es (up dates) made by this In other words, we kno w that the learning algorithm is exploiting the order of the ranks (prop erty 1) and con verges as fast as a multi-class Perceptron learning algorithm (prop erty 2). Although for the PRank algorithm the num ber of up-dates required to correctly rank the training sequence is bounded, there is no guaran tee on the size of the margin of PRank as the Perceptron (of PRank) only guaran tees &gt; 0. At rst glance a large margin could be pro duced with a varian t of the Perceptron men-tioned in the introduction. However, there is the added complication of the thresholds of c whic h are cen tral to ranking the instances.
 Metho ds whic h achiev e the maxim um margin solution on the training examples do not guaran tee the same generalization performance as the Bayes point (Her-bric h, 2000). The Bayes point is the single hypothesis chosen from a xed class of classi ers H that achiev es the minim um probabilit y of error. Hence the Bayes point di ers to the Bayes optimal classi er in that the latter may not be in H . The Bayes optimal classi er in general is dicult to evaluate even if all the prob-abilit y distributions are kno wn, whic h motiv ates the use of the Bayes point instead.
 A suitable estimate of the Bayes point for linear classi ers is to generate N div erse solutions w i , by training eac h classi er with a di eren t perm utation, i.e. ( z ) := ( z (1) ; : : : ; z ( T ) ) and have an equally Algorithm 2 OAP-BPM algorithm Require: A training sample z = (( x 1 ; y 1 ) ; : : : ; ( x T ; y T )).
 Require: A online learning algorithm PRank ( c j;t ; w j;t ; x t ; y t ).
 Require: A subroutine Bernoulli( ) whic h returns in-dep enden t Bernoulli random variables with proba-bilit y of taking the value 1.
 Require: Parameters N 2 N and 2 (0 ; 1]. 1: Initialize weigh ts w j; 1 = 0 and thresholds . 2: for t = 1 to T do 3: ~ w t := 0 4: for j = 1 to N do 5: b j;t := Bernoulli ( ) 6: if b j;t = 1 then 8: else 11: end if 14: end for 15: end for 16: return weigh ted sum ~ w = P N i =1 w i =N (Herbric h, Graep el &amp; Campb ell, 2001). This is an elegan t tric k but in the form presen ted requires that we see all training examples before we can perm ute them. Our aim is in nding an online metho d to estimate the Bayes point for the ranking learning problem. Our idea is as follo ws: Giv en a training sequence z , we run N Perceptrons in parallel and ensure div ersit y of their -nal solutions by randomly choosing to presen t a given sample z t to Perceptron j only if b j;t = 1, where b j;t j = 1 ; : : : ; N , t = 1 ; 2 ; : : : are indep enden t Bernoulli random variables with Pr f b j;t = 1 g = . This metho d should not be confused with voting metho ds like Bag-ging (Breiman, 1996) where, instead of the weigh ts w j , the hyp otheses x 7! sgn ( w j x ) are averaged. Con-ceptually , this algorithm (see Algorithm 2) is similar to the OBPM algorithm presen ted in Harrington et al. (2003) for classi cation. In Harrington et al. (2003) it was sho wn that OBPM achiev ed comparable per-formance in pro ducing a linear solution to the exact large margin (SVM) (using a fast SVM optimization, SVMligh t) on a num ber of real world data sets. On the largest data set of 100 000 training examples and instance dimension of 6125, OBPM was sev eral orders of magnitude faster than the SVM. In line 12 of Algorithm 2 we tak e the equal weigh ted com bination of the weigh t vectors of the resp ectiv e PRank algorithms to estimate the Bayes point. It seems natural that in order to achiev e a good gen-eralized solution and truly estimate the Bayes point for ranking, we also have to tak e an equally weigh ted com bination of threshold vectors of the N PRank al-gorithms. Interestingly , com bining the threshold this way still preserv es the order of the thresholds between updates, as eac h PRank algorithm main tains c j (1) : : : c j;t ( k 1) c j;t ( k ) for all j = 1 ; : : : ; N , whic h implies that P N j =1 c j (1) : : : P N j =1 c j;t ( k 1) P To see why ~ c t = P N j =1 c j;t =N mak es sense, consider a two dimensional space where all the instances with the same rank are group ed together. We justify consider-ing the ranks separately due to the idea that PRank represen ts a rank y = r by eac h subin terv al's thresh-old c ( r ) i.e. w x c ( r ), and there is order pre-serv ed amongst the thresholds. We add a dimension to the weigh ts for eac h rank, putting the threshold at w (1) = c ( r ) for subin terv al r and mak e the instance's rst dimension x (1) = 1. For the example consider that there are ve instances with a rank of three in z whic h de nes half spaces f w : w x &gt; 0 g (see Figure 1). The shaded region of Figure 1 de nes the intersection of half spaces|a region whic h represen ts all the solu-tion weigh ts whic h correctly classify the ve instances. We can see from Figure 1 that the cen ter of this region (indicated by the w cm ) would give some imm unit y to unseen examples.
 A kernel implemen tation of OAP-BPM can be eas-ily deriv ed by rst expressing eac h Perceptron f j , j = 1 ; : : : ; N by the represen ter theorem (Her-bric h, 2002) as f j ( ) = P T t =1 j;t K ( x t ; ) where ducing prop erty giving ~ f ( x ) = 1 rithm we need to bound the num ber of instances x t needed to be stored for the kernel expansion (Kivinen, Smola &amp; Williamson 2001).
 We exp ect OAP-BPM to tak e longer to con verge since the mistak e bound of OAP-BPM is driv en by the mis-tak e bound of worst solution (smallest ) amongst the N PRank algorithms. This is not a bad thing as OAP-BPM will con tinue to learn after the Perceptron based PRank stops. This metho d of creating div ersit y by therefore has a trade-o of achieving a better general-ization performance (large margin) and with the con-vergence of the algorithm to the largest margin pos-sible. The smaller the greater the div ersit y but the slower the con vergence to the nal target margin. This metho d can be applied in an online parallel fashion making it well suited to large data sets with parallel application. 3.1. Ensem ble varian ts of OAP As men tioned in the previous section the OAP-BPM is di eren t to ensem ble metho ds, like Bagging. Whilst Bagging in general is considered a batc h learning metho d, Oza (2001) presen ted an online learning ver-sion. The online Bagging metho d of Oza is di eren t to the sampling prop osed for the OAP-BPM, in Oza (2001) eac h training example is presen ted to the on-line base mo del learning algorithm q times, where q is chosen from the Poisson distribution with a mean of one. Aside from the sampling technique being di er-ent, the other di erence is our interest in the PRank as the base mo del learning algorithm. The Bagging metho d prop osed in this pap er uses the same Bernoulli sampling used in OAP-BPM, hence we refer to this as the OAP-Bagg algorithm.
 Whilst Bagging is one ensem ble metho d worth in-vestigating another is the voted Perceptron (Freund &amp; Schapire, 1999). In the voted Perceptron, ap-plied to the PRank algorithm at eac h update i = 1 ; : : : ; u the weigh t w i is stored and the num ber of correct ranks between updates, v i . At the end of training the nal hypothesis of the voted Perceptron is given by H ( x ) = P u i =1 v i h i ( x ), where h i pose, rather than a single Perceptron/PRank algo-rithm, com bining N indep enden t PRank algorithms sampled using the same technique used in OAP-BPM. We store the num ber of correct ranks made by eac h PRank algorithm, v i , and com bine them suc h that the nal hypothesis is H ( x ) = P N i =1 v i h i ( x ) = j P the Bagging case, OAP-Bagg the nal hypothesis is H ( x ) = P N i =1 h i ( x ) =N ) . Note that we normalize the voted Perceptron by v , since rank learning in general is sensitiv e to the scale, whic h is not true in the case of binary classi cation. We refer to this algorithm as OAP-VP , since we com bine the voted Perceptron (VP) with the online sampling of OAP-BPM.
 It is well accepted that Bagging and the voted Percep-tron perform well in the classi cation problem setting, Bagging esp ecially in the presence of noise. The ques-tion is how does OAP-Bagg and OAP-VP compare with OAP-BPM in the rank learning setting, whic h motiv ates the empirical study in the exp erimen tal sec-tion. Exp erimen ts comparing PRank, the regression algo-rithm of Widro w-Ho (1960) (WH) with the OAP-BPM (Ba yes Point Mac hine) and the ensem ble vari-ants OAP-Bagg (Bagging) and OAP-VP (voted Per-ceptron), were performed on a syn thetic ranking prob-lem and using collab orativ e ltering on sev eral real-world data sets. 4.1. Ranking with a syn thetic data set We performed the syn thetic data exp erimen t of Her-bric h, Graep el and Ob erma yer (2000), and Crammer and Singer (2002) in the batc h setting with a non-homogeneous kernel of degree two. To generate the data eac h instance at round t , x t = ( x t (1) ; x t (2)) was chosen according to the uniform distribution on the unit square i.e. x 2 [0 ; 1] [0 ; 1] R 2 . The ranks 1 ; : : : ; 5 were assigned by y = max r 2f 1 ;::: ; 5 g 10(( x (1) 0 : 5)( x (2) 0 : 5)) + n &gt; c r g with the rank thresholds c = ( 1 ; 1 ; 0 : 1 ; 0 : 25 ; 1) give that c (5) = 1 and n normally distributed with zero mean and standard deviation of 0 : 125. The exp erimen t consisted a polynomial kernel K ( x 1 ; x 2 ) = (( x 1 x 2 ) + 1) 2 20 Mon te-Carlo trials with 50000 training examples and a separate test set of 1000 examples.
 To study the online nature of the ranking algorithms we used the same measure of performance as Cram-mer and Singer (2002), the average rank losses of
P T t =1 j ^ y t y t j where T is the num ber of rounds performed so far. Figure 2 sho ws the average rank losses from 20 trials for PRank, OAP-BPM ( N = 100 and = (0 : 3 ; 0 : 6 ; 0 : 9)), Widro w-Ho (plotting the lowest losses with learning rates/step sizes of = (0 : 2 ; 0 : 1 ; 0 : 05 ; 0 : 01)) and OAP-Bagg ( N = 100 and = (0 : 3 ; 0 : 6 ; 0 : 9)) and OAP-VP ( N = 100 and = for WH than rep orted in Crammer and Singer (2002), as they only tried = 1. WH result with = 0 : 1 is sligh tly better average rank loss than PRank after 5000 training examples. It is not that surprising that WH is better than a mistak e driv en Perceptron, as the squared loss function for WH can pro duce a large margin like solution. Comparing the ve di eren t al-gorithms the OAP-BPM had the lowest averaged rank loss after the 5000 examples, though OAP-VP was the lowest until 1000 examples.
 We then took the test set of 1000 examples and cal-culated the averaged rank losses for the same ve algorithms PRank, WH, OAP-BPM, OAP-Bagg and OAP-VP , plus we tried PRank with the voted Per-ceptron. The averaged rank loss results of the algo-rithms with their 95 % con dence interv als for a Stu-den t's t-distribution were: PRank 0 : 37 0 : 07, PRank with voted Perceptron 0 : 31 0 : 00, with = 0 : 1 WH 0 : 30 0 : 2 and table 1 sho w the rest for = (0 : 3 ; 0 : 6 ; 0 : 9). The results from the test examples sho w that OAP-BPM had the lowest averaged rank loss over the three choices of . From Table 1 we see as is made smaller so is the con dence interv al. 4.2. Collab orativ e ltering To allo w for a fair comparison a general frame work for the collab orativ e ltering exp erimen ts was consisten t for all three data sets: OHSUMED 3 , cystic brosis 4 and Eac hMo vie 5 . We constructed a training set and test set, where given an item (i.e. query-do cumen t pair) to be rank ed, at rst the target rank y t was dra wn randomly from the ratings made on that item and then the remaining ratings were used as dimensions of the instance vector x t . All the results in this section are averages pro duced by 500 Mon te-Carlo trials. Rank Loss Rank Loss Rank Loss The detail of the exp erimen tal setup for eac h data set used are as follo ws: Rank Loss From the results of Table 2 in two of the collab ora-tive ltering exp erimen ts OAP-BPM had the lowest average rank loss for the test sets. In OHSUMED re-sult OAP-BPM was close to the better WH, though this would be considered the easier of the three exp er-imen ts with only a dimension of two.
 Figures 3 (a), (b) and (c) give some insigh t into the con vergence beha viour of the ve di eren t rank learn-ing metho ds on the training examples. We see that the OAP-VP has a faster con vergence than both OAP-Bagg and OAP-BPM. We also notice that for the smaller rank set of three and lower dimensional data sets of OHSUMED and cystic brosis, the WH regres-sion algorithm had the fastest con vergence and com-parable performance to the OAP-BPM on the test examples. Yet even though the con vergence is slow the results of Table 2 sho w that the Perceptron based OAP-BPM had the best performance overall. It is not surprising that the test set results for OAP-BPM of Table 2 are better than the training set results in Figures 3 (a), (b) and (c), for two reasons: the test set results are using the nal trained weigh ts and the OAP-BPM has larger rank losses at the start making the average rank loss higher, since eac h rank loss at time t has equal weigh t over the entire training set. We prop ose a simple OAP-BPM rank learning algo-rithm whic h impro ves the generalization performance of the PRank algorithm. The impro ved generalization performance is achiev ed by having the rank prediction w t +1 x t +1 in the cen tre of the subin terv al true rank y . To estimate the cen tre of the subin terv al we en-able div ersit y amongst the ranking rules pro duced by N di eren t PRank algorithms run in parallel by a sim-ple online randomization tric k. It was demonstrated that averaging the N rank rules (pro ducing the nal ranking rule of OAP-BPM) had a lower averaged rank loss for a separate test set of examples compared to the algorithms of Widro w-Ho , PRank and ensem ble versions OAP-Bagg and OAP-VP for a num ber of ex-perimen ts. The exp erimen ts involved rank learning on a syn thetic and the collab orativ e ltering on the real world data sets of Eac hMo vie, OHSUMED and cys-tic brosis. The adv antage of OAP-BPM is impro ved generalization performance compared to PRank whilst remaining in an online learning setting. There is an added computational cost in achieving a large margin, whic h on average is an order of O ( N ) more than the original PRank algorithm.
 For future work, an interesting extension to the OAP-BPM would be the incorp oration of ROMMA rather than the Perceptron in the update rule of PRank. This work was conducted by the author whilst at The Australian National Univ ersit y. The author would like to thank Evan Greensmith, Ralf Herbric h, Jyrki Kivi-nen, John Platt and Bob Williamson, for there assis-tance in pro ducing this man uscript and to the anon y-mous review ers for their helpful commen ts.

