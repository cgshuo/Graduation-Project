 As an important data mining problem, frequent itemsets mining plays an essential role in many data mining tasks, such as mining association rules, classification, and clus-tering. Recently, frequent itemset is widely used in text mining, such as text classifi-cation [1] and text clustering [2]. 
There have been many algorithms developed for efficient mining of frequent item-ting method, with Apriori [3] as its representative, (2) Apriori-based, vertical format-ting method, such as CHARM [7], and (3) projection-based pattern growth method, which may explore some compressed data structure such as FP-tree, as in FP-growth the generation of the correct and complete se t of frequent itemsets. But when used in main) mining encounters new challenges. (1) Text data is usually high dimensional and sparse which makes most common frequent itemsets mining algorithms ineffi-leads to the generation of large number of patterns, including short patterns and long text area. (4) Text database can be very large. 
The second problem can be solved by mining top-k frequent itemsets without algorithms [6]. 
Based on the observation above, we provide the following task of finding frequent itemsets in very large text database: mining top-k frequent itemsets with minimum min_l is the minimal length of each itemset. A transaction database TDB is a set of tr ansactions, where each transaction, denoted transaction identity tid. Let I = {i1, i2, ..., in} be a set of items. An itemset Y is a non-empty subset of I. The length of itemset Y is the number of items contained in Y, and X&gt; if Y as sup(Y), is the number of transactions in TDB which contain Y. Definition 1. (top-k frequent itemsets) An itemset Y is a frequent itemset if length min_l if there exist no more than (k  X  1) itemsets of length at least min_l whose support is higher than that of Y .  X  Many algorithms such as Apriori and FP-growth [8] can be applied to this problem. and can X  X  suit very large dataset since it needs too much memory when the dataset is very large. The author of FP-growth also pointed out this algorithm does not perform well on sparse data [5] and proposed a new pattern-growth algorithm named H-mine [9]. In this paper, we propose a novel parallel algorithm, named parTFI (Parallel Top-frequent itemsets of minimal length min_l in very large sparse database. A controlling server and n mining servers are used in parTFI. 3.1 Method Development need itemsets with minimum length min_l , we can reduce the size of the H-struct and improve the performance of the mining algorithm based on the following remarks: Remark 1. (Absolute short transaction) If a transaction T contains less than min_l can contribute to an itemset of minimum length min_l .  X  currently, i be the item linked by the header table H I in transaction t. The length of I is l called a relative short transaction and it can X  X  contribute to the frequent itemset begin with I.  X 
For example, in Fig. 1, transaction 300 is a relative short transaction. The absolute short transaction remark can be used when the H-struct is constructed and the relative short transaction remark can be used when mining the H-struct for frequent itemsets. 
The basic idea of our algorithm at each mining server is to set min_support = 0 at the beginning and construct a full H-struct. When mining frequent itemsets in the H-struct, a simple data structure called K-itemset table as shown in table 1 is used. The current top-k frequent itemsets is stored in the table sorted by the support of the item-set. Remark 3. (Header table pruning) The minimum support in the k-itemset table is safe to be used to prune the header table.  X 
To support large dataset, data partitioning technology is used. Usually data is parti-mining algorithms. We call this horizontal partition. sulting frequent itemsets. As described in [9], the result of H-mine is partitioned into subsets and there is no overlap between subsets. So we can partition the data logically according to the resulting subsets. For example, suppose we have six items from a to f, we call the resulting subset containing item a a-subset, that containing b but not a b-subset, and so on. We can partition the six subsets into 2 partitions as shown in Fig.3. Remark 4. (Global top-k frequent itemsets) Using the logical vertical partition, the global top-k frequent itemsets must be in the local top-k frequent itemsets.  X  support of each frequent itemset is the same as the global support of that itemset. So the global top-k frequent itemsets must be in the local top-k frequent itemsets. 3.2 parTFI Algorithm Now we summarize the entire mining pro cess and present the parTFI algorithm. large text database. Algorithm for Controlling Server: Input: (1) A very large text database, (2) an integer k, i.e., the k most frequent item-sets to be mined, and (3) min_l , the minimal length of the frequent itemsets. Output: The set of the frequent itemsets which satisfy the requirement. Method: Algorithm for Mining Server: Input: (1) A logical vertical partition, (2) an integer k, i.e., the k most frequent item-sets to be mined, and (3) min_l , the minimal length of the frequent itemsets. Return: The local top-k frequent itemsets in the partition. Method: In this section, we report our performance study of parTFI. We compare the effi-ciency of parTFI with two other frequent itemsets mining algorithms: FP-growth, currently considered one of the fastest algorithm for frequent itemsets mining, and the Christian Borgelt X  X  implementation of Apriori 1 . We provide traditional horizontal partition for FP-growth and Apriori since they can X  X  run in the logical partition mode like parTFI. We run these two algorithms in each mining server to find frequent item-generate frequent itemsets with reasonable size and then sort the itemsets to find the top-k frequent itemsets. 
The datasets used in our experiments can be grouped into the following two cate-gories: (1) Sparse real dataset which is collected from public forums in the internet by robots. (2) Dense synthetic dataset which is generated from a set of seeds. We use 4 HP demonstration units connected with fast Ethernet. Each unit has 4 10g database (4 node cluster). 
We first compare the performance of parTFI with FP-growth and Apriori on the real sparse dataset with size 4GB. parTFI performs consistently better than FP-growth and Apriori if the min_l is not too small. Fig. 4 and fig. 5 shows the running time of has comparable performance with FP-growth and is better than Apriori. We have also studied the performance of parTFI on 40GB sparse text dataset. As shown in Fig. 9, parTFI can well suit very large text dataset which most other algorithm can X  X  process. 
From these experiments we can conclude that parTFI is efficient for mining top-k frequent itemsets with a specified minimum length in very large sparse dataset. Unlike Apriori and FP-growth whose performance deteriorates as min_l increases, parTFI's running time almost stays low. In addition, parTFI has better scalability since technique for very large database. The parTFI represents a novel, highly efficient and scalable mining method for large needed, including further improvement of the performance by applying other heuris-tics to pruning the header table and using new method to reducing the number of local frequent itemsets need to be mined. 
