 Universitat Polit ` ecnica de Val ` encia 1 of large training data sets that grow constantly over time is becoming more and more frequent in the field of SMT X  X or example, in the context of translation agencies or the daily translation of government proceedings. When new knowledge is to be incorporated in the SMT models, the use of batch learning techniques require very time-consuming estimation processes over the whole training set that may take days or weeks to be executed. By means of the application of online learning, new training samples can be processed individually in real time. For this purpose, we update rules for each of these submodels. To test our techniques, we have studied two well-known
SMT applications that can be used in translation agencies: post-editing and interactive machine quality translations. These user-validated translations can be used to extend the SMT models by means of online learning. Empirical results in the two scenarios under consideration show the great impact of frequent updates in the system performance. The time cost of such updates was also measured, comparing the efficiency of a batch learning SMT system with that of an online learning system, showing that online learning is able to work in real time whereas the performance of online learning is comparable to that of batch learning. Moreover, the proposed techniques were able to learn from previously estimated models or from scratch. We also propose two new measures to predict the effectiveness of online learning in SMT tasks. The translation system with online learning capabilities presented here is implemented in the open-source Thot toolkit for SMT. 1. Introduction
Multiplicity of languages is inherent to modern society. Phenomena such as global-ization and technological development have extraordinarily increased the need for translating information from one language to another. One possibility to deal with this growing demand of translations is the use of machine translation (MT) techniques. the sentence of maximum probability in the target language given the source sentence.
Statistical MT (SMT) requires the availability of parallel texts to estimate the statistical models involved in the translation. It is also important that such parallel texts belong to the same domain the system will be used for. These kinds of texts are referred to as in-domain corpora in the domain adaptation literature. However, in-domain corpora are often not available in real translation scenarios, forcing us to estimate the system models by means of large out-of-domain texts, such as Parliament proceedings. Unfortunately, this results in a significant degradation in the translation quality (Irvine et al. 2013). generated over time (e.g., translation agencies or the daily translation of government proceedings). The newly generated training data could be used to mitigate the problem of data scarcity. However, this situation poses new challenges in the SMT framework, because the vast majority of the SMT systems described in the literature makes use of the well-known batch learning paradigm . In the batch learning paradigm, the train-ing of the SMT system and the translation process are carried out in separate stages. preventing the statistical models to be extended when the system starts generating translations. To solve this problem, the online learning paradigm can be applied. Online learning is a machine learning task that is structured in a series of trials, where each trial has four steps: (1) the learning algorithm receives an instance, (2) a label for the instance is predicted, (3) the true label for the instance is presented, and (4) the learning algorithm uses the true label to update its parameters. In this paradigm, the training and prediction stages are no longer separated.
 translation for each source sentence is validated by a human expert and thus can be used to produce new training pairs. One possible CAT implementation consists of post-editing (PE) the output of an MT system. In this implementation, the MT system intervention. Another instance of CAT is interactive machine translation (IMT), where the user generates each translation in a series of interactions with the system. ing recent years, capturing the attention of internationally renowned research groups and translation companies. A good example of this is the work carried out in the TransType (Foster, Isabelle, and Plamondon 1997) and TransType-II (SchlumbergerSema S.A. et al. 2001) research projects, where the IMT paradigm was developed, and the
CasMaCat (Alabau et al. 2014) and MateCat (Federico et al. 2014) projects, where a substantial part of the effort was focused on developing adaptive learning techniques for CAT. Literature also offers demonstrations of CAT applications (Koehn 2009; Ortiz-benefits of CAT (Green, Heer, and Manning 2013; Ortiz-Mart  X   X nez et al. 2015). update the statistical models used by the system, avoiding the necessity of execut-ing costly retraining processes. The properties of the proposed techniques will be tested in the two CAT scenarios we have mentioned. As noted earlier, in such sce-narios there is a human translator that supervises each system translation. However, it is important to remark that our proposed techniques can also work in scenar-ios where there are no human experts involved. One example of this can be found in fully automatic translation tasks where the initial models can be extended from 122 new blocks of training data obtained from different sources, such as parliamentary proceedings.
 foundations of SMT and its adaptation to the PE and IMT scenarios. Section 3 explains the online learning techniques proposed here, including the definition of a log-linear SMT model as well as a set of incremental update rules for each one of its components.
The content of Section 3 is complemented by Appendix A, which presents an alternative incremental update rule for word-alignment models. Experimental results as well as their discussion are shown in Sections 4 and 5, respectively. Section 6 describes related work on online learning. The work conclusions are given in Section 7. 2. Statistical Framework
In this section we describe the details of the statistical framework adopted in the rest of the article. For this purpose, we briefly describe the statistical formulation of SMT as well as the required modifications for its use in two well-known applications of SMT, namely, post editing and interactive machine translation. 2.1 Statistical Machine Translation In the statistical approach to MT, given a source sentence f language F , we want to find its equivalent target sentence e language E , where f j and e i note the i th word and the j th word of the sentences f e interested in that with the highest probability according to the following equation: taining two new distributions, Pr ( e I 1 ) and Pr ( f J 1 of parametric statistical models. Specifically, Pr ( e I 1 model , and Pr ( f J 1 | e I 1 ) is modeled by means of a translation model . models . Regarding the translation models, they are commonly implemented using the so-called phrase-based models (Koehn, Och, and Marcu 2003). The basic idea of phrase-based translation is to segment the source sentence into phrases, then to translate each source phrase into a target phrase, and finally to reorder the translated target phrases in order to compose the target sentence. The decisions made during the phrase-based translation process can be summarized by means of the hidden variable  X  a where  X  a k denotes the index of the target phrase  X  e k phrase  X  f k , determining a bisegmentation of the source and target sentences of length K . Such formalizations are based on the direct modeling of the posterior probability, linear models use a set of feature functions h r ( f J 1 , e weight  X  r , which are typically estimated by means of the well-known minimum error rate training (MERT) algorithm (Och 2003). Common log-linear model implementations are strongly focused on these phrase-based models, obtaining the best alignment at phrase level: where a total of R feature functions are assumed.
 tion (2) using iterative algorithms that build partial target translations from left to right. 2.2 Post-Editing the Output of Statistical Machine Translation
Post-editing (PE) involves making corrections to machine generated translations (see TAUS-Project [2010] for a detailed study). PE is used when raw machine translation is not error-free, a common situation for current MT technology. PE tends to be carried out via tools built for editing human-generated translations, such as translation mem-ories (some authors refer to this task as simply editing ). Because in the PE scenario, the user only edits the output of the MT system without further intervention from the system, there are no differences in the way in which the MT system is designed and implemented. Hence, the statistical framework for MT described previously can be adopted without modifications in order to build the PE system. 2.3 Statistical Interactive Machine Translation
One alternative to the serial collaboration model adopted by PE is interactively com-bining the MT system with a human translator, constituting the interactive machine translation (IMT) paradigm (also referred to as interactive translation prediction). One possible IMT implementation uses SMT systems to produce target sentence hypotheses that can be partially or completely accepted and amended by a human translator (Barrachina et al. 2009). Each partially corrected text segment, or prefix, is then used by the SMT system as additional information to achieve improved suggestions. complete translation hypothesis, e s , given the source sentence, f user moves the mouse to accept the prefix composed of the first eight characters To view (that is, the prefix of the sentence the user deems to be correct) and presses the a key (k), producing the prefix, e p . Then the system suggests completing the sentence with list of resources (a new e s ), given the accepted and correct prefix. Interactions-2 and -3 are similar. In the final interaction, the user accepts the current translation suggestion. p ( f 1 | e p , e s ), that are very similar to those obtained for conventional SMT, since e e . This allows us to use the same models if the search procedures are adequately 124 modified. Specifically, the search is restricted to generate target sentences compatible whereas the IMT interface described in Figure 1 works at the character level. This is not an important issue because the transformations that are required in the statistical models for their use at character level are trivial. Specifically, the compatibility with the user prefix is verified by comparing characters instead of words. 3. Online Learning for Statistical Machine Translation
In this section we describe the concept of online learning and its application to SMT. 3.1 Definition of Online Learning
Online learning algorithms proceed in a sequence of trials. Each trial can be decomposed into four steps: 1. The learning algorithm receives an instance. 2. The learning algorithm predicts a label for the instance according to its 3. The true label of the instance is presented to the learning algorithm. 4. The learning algorithm uses the true label to update its parameters.

The system uses the true label to measure the prediction error incurred by the learner and discarded afterwards. The ultimate goal of the online learning algorithm is to minimize the cumulative prediction error along its run by modifying its parameters. algorithm produces a sequence of parameters:  X  (0) ,  X  (1) parameters at trial t ,  X  ( t ) , depends only on the previous parameters,  X  current sample x t . that the computational complexity of processing a new sample does not depend on the number of samples that has been previously seen. That is, the computational complexity of processing a new sample is constant.
 dating the learner are also referred to as incremental learning algorithms by some authors (see Anthony and Biggs [1992]). However, this constraint can be relaxed by using mini-batches (small sets of samples).
 training patterns are presented to the learner before learning takes place and the learner is no longer updated after the learning stage has concluded.

In a stationary environment, all instances are drawn from the same underlying proba-bility distribution. By contrast, because online learning algorithms continually receive prediction feedback, they can be used in non-stationary environments.
 settings. Three of them are identified in Giraud-Carrier (2000): (1) Chronology : the order in which knowledge is acquired is an inherent aspect of online learning, (2) Learning curve : the learner may start from scratch and gain knowledge from examples given one at a time over time; as a result, it experiences a sort of learning curve, and (3) Open-world assumption : all the data relevant to the problem at hand is not available a priori. ing. In this paradigm the system queries the user to obtain the true labels of specific instances, obtaining greater accuracy using less training data. Active learning can also be applied in online settings, where the capability of the system to learn in an online or incremental manner using techniques like those proposed here is crucial. One example (2012), where active learning techniques for IMT are proposed. 3.2 Implementing Online Learning
The key aspect to be considered when implementing online learning algorithms is how to update the system parameters given the previous ones and the new training sample.
If the online learning algorithm is based on statistical models, then we need to maintain a set of sufficient statistics for these models that can be incrementally updated. A sufficient statistic for a statistical model is a statistic that captures all the information that is relevant to estimate this model. If the estimation of the statistical model does not require the use of the expectation X  X aximization (EM) algorithm (e.g. n -gram language models), then it is generally easy to incrementally extend the model given a new training sample. By contrast, if the EM algorithm is required (e.g., word alignment models), the estimation procedure has to be modified, since conventional EM is designed for its use in batch learning scenarios. To solve this problem, an incremental version of the EM algorithm is required. 3.3 Predicting the Effectiveness of Online Learning in SMT Tasks
According to the work presented in Irvine et al. (2013), the presence of unknown source words and known source words with unknown translations explains the majority of the performance degradation when an SMT system is migrated to a new domain.
The use of online learning can mitigate these two problems, because the system is 126 now able to efficiently learn translations for new or previously seen words. However, the benefits will only be significant when the document to be translated presents a high internal repetition rate, since this will allow the system to take advantage of the newly acquired knowledge. This should not be seen as a limitation specific to online learning. In batch learning scenarios the translation quality is strongly weakened if the training corpus is not representative of the text to be translated. When we move to an online setting, we still have the same requirement but now the training and translation stages are no longer separated. This is why we speak about repetitiveness instead of representativeness. In any case, sufficiently high repetition rates for test doc-uments are common, according to the document-internal repetition property defined in Church and Gale (1995).
 the potential usefulness of online learning: the repetition rate (RR). In this section we will slightly modify the definition of RR and propose two additional measures. text. More specifically, the rates of non-singleton n -grams from n = 1 to 4 are calculated and geometrically averaged, using a sliding window of 1, 000 words to make the rates comparable across different sized corpora. Here we use a slightly modified version in which the sliding window calculation is removed, because in real translation scenarios the text to be translated is available beforehand and should be completely translated. Thus, we define our modified RR (MRR) measure as follows: where | X | represents the length of a given set, I n ,1 + n -grams contained in the in-domain corpus I , and I n ,1 n -grams occurring only once in I .
 or not in the out-of-domain corpus that has been used to estimate the SMT models.
According to Irvine et al. (2013), unseen events constitute a major cause of translation errors when migrating an existing SMT system to a new domain. Thus, it is interesting to restrict the calculation of the repetition rate to those n -grams that are not contained in the out-of-domain corpus. We will refer to this measure as the restricted repetition rate (RRR): where O n ,1 + represents the set of different n -grams contained in the out-of-domain corpus O .
 corpus to be translated. However, such unseen n -grams constitute only a fraction of the in-domain corpus. A high value of the RRR is not enough to predict good results if the fraction of unseen n -grams is very low. To capture this corpus property, we define the unseen n -gram fraction (UNF) measure: where c I ( w ) represents the count of n -gram w in corpus I .
 attention only to the RRR and the UNF measures. In spite of this, MRR will be also reported so as to compare the information provided by the three measures. 3.4 Statistical Phrase-Based Log-Linear Model for Online SMT
As stated in Section 2.1, log-linear models including phrase-based models as feature functions constitute the state-of-the-art in statistical machine translation. In this section we will describe the components of our log-linear model for SMT. Later, in Section 3.5, the update rules required to extend such components will be presented.
 our log-linear model: an n -gram language model ( h model ( h 2 ), inverse and direct phrase-based models ( h get phrase-length model ( h 5 ), a source phrase-length model ( h (or phrase reordering) model ( h 7 ). All these feature functions, with the exception of the one related to the direct phrase-based model ( h proper decomposition of the distribution Pr ( e I 1 | f Ortiz-Mart  X   X nez [2011]).
 art SMT systems such as the Moses decoder (Koehn et al. 2007). The main difference of our proposal with existing works is that we have paid special attention to the formal justification of the features.
 n -gram target language model ( h 1 ) 4 128 where p ( e i | e i  X  1 i  X  n + 1 ) is defined as follows: one and two counts respectively), N 1 + ( e i  X  1 i  X  n + 1 c X (  X  ) can represent true counts c T (  X  ) or modified counts c lower order n -grams. Given a certain n -gram, its modified count consists of the number of different words that precede this n -gram in the training corpus. with an interpolated version of the Kneser-Ney smoothing (Chen and Goodman 1996). source sentence-length model ( h 2 ) where  X  I (  X  ) is the cumulative distribution function for the normal distribution (the cumulative distribution function is used to integrate the normal density function over an interval of length 1). A specific target sentence length I will be assigned during decoding time when a new empty hypothesis is created. After that, this hypothesis will be extended in successive trials, but it will be constrained to have I words when all the source words are covered. The sentence length model is introduced to avoid the generation of too short or too long target sentences, which negatively impact translation quality (other authors use models that simply penalize the number of target words).
 each target sentence length I . inverse and direct phrase-based models ( h 3 , h 4 ) where p (  X  f k |  X  e  X  a
In Equation (8), p phr (  X  f k |  X  e  X  a dictionary used in regular phrase-based models. p phrase) alignment model (see Vogel, Ney, and Tillmann 1996): The HMM-based alignment model probability is used here for smoothing purposes.
Analogously, h 4 is defined as: target phrase-length model ( h 5 ) where p ( |  X  e k | ) =  X  (1  X   X  ) |  X  e k | . with probability of success on each trial  X  .
 source phrase-length model ( h 6 ) where p ( |  X  f k |||  X  e  X  a absolute value function.
 penalizes the difference between the source and target phrase lengths). distortion model ( h 7 ) source phrase covered by  X  a k and l  X  a covered by  X  a k  X  1 .
 penalizes the reorderings). 130 3.5 Online Update Rules After translating a source sentence f J 1 , a new sentence pair ( f
SMT system. To do this, a set of sufficient statistics that can be incrementally updated is maintained for the statistical models that implement each feature function h
Regarding the weights of the log-linear combination, they are not modified because of the presentation of a new sentence pair to the system. These weights can be adjusted offline by means of a development corpus and well-known optimization techniques, such as the Powell algorithm or the downhill simplex algorithm, which are commonly used in a typical MERT procedure. 3.5.1 Language Model (h 1 ). Feature function h 1 implements a language model. According to Equation (7), the following data are to be maintained: c
N 1 + (  X  ), and c X (  X  ) (see Section 3.4 for the meaning of each symbol).
 1  X  i  X  I + 1, the set of sufficient statistics is modified, as is shown in Algorithm 1. The algorithm checks the changes in the counts of the k -grams to update the set of sufficient statistics. For a given k -gram, e i i  X  k + 1 , its true count and the corresponding normalizer are updated at lines 13 and 14, respectively. The modified count of the ( k  X  1)-gram and its normalizer are updated at lines 7 and 8, respectively, only when the k -gram e appears for the first time (condition checked at line 2). The value of the N been seen for the first time following these contexts. Finally, sufficient statistics for D
Algorithm 1 Pseudocode for the update suff stats lm algorithm. This algorithm is used to incrementally update the sufficient statistics of a language model with Kneser-
Ney smoothing. The meaning of the different symbols is explained in Section 3.5.1.
Algorithm 2 Pseudocode for the updD algorithm. This algorithm is used internally by the update suff stats lm algorithm to update the value of the D the generation of language model probabilities. following the auxiliary procedure shown in Algorithm 2. 3.5.2 Source Sentence Length Model (h 2 ). Feature function h length model. h 2 requires the incremental calculation of the mean  X  deviation  X  I of the normal distribution associated with a target sentence length I . For this purpose, the procedure described in Knuth (1981) can be used. In this procedure, two quantities are maintained for each normal distribution:  X  auxiliary quantity from which the standard deviation can be obtained, as is explained according to the following equations: where c ( I ) is the count of the number of sentences of length I that have been seen so far, and  X  ( t  X  1) I and S ( t  X  1) I are the quantities previously stored (  X  sentence length of the first sample and S (0) I is initialized to zero). Finally, the standard deviation can be obtained from S ( t ) I as follows:  X  ( t ) 3.5.3 Inverse and Direct Phrase-Based Models (h 3 and h 4 ment inverse and direct phrase-based models, respectively. These phrase-based models are combined with HMM-based alignment models via linear interpolation. In this work we have not studied how to incrementally update the weights of the interpolation.
Instead, these weights can be estimated from a development corpus. 132 model is maintained. The inverse phrase model probabilities, p ( phrase counts, c(  X  f ,  X  e ), as follows: the inverse phrase model consists of a set of phrase counts, c ( estimation method (see Zens, Och, and Ney [2002] and Koehn, Och, and Marcu [2003] for a detailed explanation) uses a word alignment matrix, A , between f the set of phrase pairs that are consistent with the word alignment matrix: BP ( f This consistency relation is formally defined as follows:
Hence, the set of consistent phrase pairs is constituted by those bilingual phrases where all the words within the source phrase are only aligned to the words of the target phrase and vice versa.
 phrase pairs, BP ( f J 1 , e I 1 , A ), the phrase counts are updated as follows: where c (  X  f ,  X  e ) ( t ) is the current count of the phrase pair ( count, and c (  X  f ,  X  e | BP ( f J 1 , e I 1 , A )) is the count of ( lation probabilities. For this purpose, we maintain in memory both the current phrase counts and their normalizers.
 to generate word alignment matrices. To solve this problem, we use the direct and inverse HMM-based alignment models that are included in the formulation of the IMT system. Specifically, these models are used to obtain word alignments in both translation directions. The resulting direct and inverse word alignment matrices are combined by means of the symmetrization alignment operation (Och and Ney 2003) before extracting the set of consistent phrase pairs.
 also need to incrementally update the HMM-based alignment models. In the following section we show how to efficiently incorporate new knowledge into these models. 3.5.4 Inverse and Direct HMM-Based Alignment Models (h 3 and h models play a crucial role in log-linear components h 3 and h to smooth phrase-based models and to generate word alignment matrices. HMM-based alignment models were chosen here because, according to Och and Ney (2003) and Toutanova, Ilhan, and Manning (2002), they outperform IBM 1 to IBM 4 alignment models while still allowing the exact calculation of the likelihood. However, our pro-posal is not restricted to the use of HMM-based alignment models.
 by means of the EM algorithm. However, the standard EM algorithm is not appropriate to incrementally extend our HMM-based alignment models because it is designed to work in batch training scenarios. To solve this problem, the incremental view of the EM algorithm (Neal and Hinton 1998) can be applied.

Model Definition . HMM-based alignment models are a class of single-word align-ment models. Single-word alignment models are based on the concept of alignment between word positions of the source and the target sentences f alignment is defined as a function a : { 1  X  X  X  J } X  X  0  X  X  X  I } , where a position is aligned with the i th target position. Additionally, a position j of f J 1 has not been aligned with any word position e and f J 1 , we formulate Pr ( f J 1 | e I 1 ) in terms of the alignment variable as follows: generality as follows: specifically, they only differ in the assumptions made over the alignment probabilities.
HMM-based alignment models use a first-order alignment model p ( a imate the distribution Pr ( a j | f j  X  1 1 , a j  X  1 1 , e approximate the distribution Pr ( f j | f j  X  1 1 , a j 1 where we assume that a 0 is equal to zero and is the set of hidden parameters.

Incremental EM Algorithm . The incremental EM algorithm was introduced by Neal and Hinton (1998) in batch learning settings. In such settings, the set of training samples is known before the training process takes place (see Section 3.1). Here we will 134 instantiate the incremental EM algorithm for a batch learning translation task with a given set of training pairs, { ( f 1 , e 1 ), ... , ( f m the application of the algorithm in an online learning setting.
 ficient statistics for the model parameters, where s m ( f statistics for data item m : f for the sentence pair ( f m , e m ); and c ( i | i 0 , I ; f the alignment i has been seen after the previous alignment i composed of I words for the sentence pair ( f m , e m ).
 of the hidden alignment variable:  X  s ( t ) m , where counts are replaced by expected counts, c ( f | e ; f m , e m , a m ) ( t ) and c ( i | i 0 , I ; f at trial t , then the E step requires the following operations: obtaining the following update equations: statistics  X  s ( t ) = P m  X  s ( t ) m for the model parameters.

Application to an Online Setting . The previous instantiation of the incremental EM algorithm works in a batch learning setting where the set of training samples is given a priori. By contrast, in the online learning paradigm the training samples are not available a priori but become available over time X  X pecifically, one at a time. Given sufficient statistics,  X  s ( t ) , is given by the following expression: where  X  s ( t ) t represents the sufficient statistics for sample at trial t . statistics for individual samples at trial t  X  1:  X  s learning case (compare the previous equation with Equation (21)), since the training samples are discarded after being processed. This implies that only one training epoch for individual samples,  X  s ( t  X  1) m , should not be stored, allowing us to save memory in a substantial manner (the memory requirements may become prohibitive for large sample sets). The execution of only one training epoch can be seen as a limitation with respect to batch training, but empirical results in Section 4.4 show that the online update rule is competitive with the batch update rule due to the faster convergence of incremental
EM. Additionally, this online update rule can be easily modified to execute multiple epochs while storing a reduced quantity of sufficient statistics for the last samples, as it is explained in Appendix A.
 given sentence pair are nonzero for a small fraction of its components. As a result, the time required to update the parameters of the HMM-based alignment model depends only on the number of nonzero components.
 parameters. For this purpose, the normalizer factors for  X  s gously to those of the inverse model. 3.5.5 Source Phrase Length, Target Phrase Length, and Distortion Models (h  X  parameters of the geometric distributions associated with the feature functions h and h 7 are left fixed. Because of this, there are no sufficient statistics to store for these feature functions. 4. Experimental Results
This section describes the experiments that we carried out to test our proposed online learning techniques. Our experiments were focused on the PE and IMT scenarios, because they fit nicely into the online learning paradigm.
 described in Section 3.4. The IMT experiments reported here combine this log-linear
SMT model with stochastic error correction models following the technique introduced in Ortiz-Mart  X   X nez (2011). This technique uses word graphs to avoid retranslating the source sentence at each interaction of the IMT process. The incremental language and phrase-based models involved in the interactive translation process were generated and accessed by means of the open source Thot toolkit (Ortiz, Garc  X   X a-Varea, and Casacuberta 136 experimentation has been made freely available in a new version of toolkit. not consider the use of the Moses decoder (Koehn et al. 2007) in our experiments because it is not prepared to work in the IMT framework and it does not implement the incremental version of the EM algorithm (it implements the stepwise version, which is unstable in online learning settings, according to Blain, Schwenk, and Senellart [2012]).
However, translation quality results reported in Ortiz-Mart  X   X nez (2011) show that Thot is competitive with Moses for corpora of different complexities. 4.1 Corpora
The experiments were performed using the XRCE, the Europarl, and the EMEA cor-pora. The XRCE corpus (SchlumbergerSema S.A. et al. 2001) consists of translations of XRCE printer manuals from English to three different languages X  X amely, Spanish,
French, and German. Table 1 shows the main figures of the XRCE corpora for training, development, and test partitions. The XRCE corpus is included here because it has been extensively used in the literature to report SMT and IMT results (a complete set of experiments with this corpus is shown in Barrachina et al. [2009]). This feature will allow us to compare the results of our proposed system with those obtained by state-of-the-art systems.
 learning for this particular translation task, including the modified repetition rate (MRR), the restricted repetition rate (RRR), and the unseen n -gram fraction (UNF) (see
Section 3.3). In this work we propose to use only RRR and UNF measures to assess the usefulness of online learning. However, MRR will also be reported so as to give a better idea of the accuracy of these two measures. The three XRCE test sets present moderately high values for the three measures. Slight drops of the RRR measure with respect to the
MRR measure are observed (that is, there are repeated n -grams in the test corpus that were already seen in the training set), suggesting that the repetition rate present in the test sets cannot be fully exploited by online learning.
 pean Parliament, which are written in the different languages of the European Union. In our experiments we used the version created for the shared task of the ACL 2013
Workshop on Statistical Machine Translation (Bojar et al. 2013). To simplify the experi-ments, all those sentences whose length in words was greater than 40 were removed from the training set. Regarding the language pairs under consideration, again, we will translate from the English language to Spanish, French, and German. Table 2 shows the main figures of training, development, and test sets. The Europarl corpus constitutes one good example of a complex, real-world translation task that is also very well known in the MT scientific community. Regarding the measures to predict the effectiveness of online learning, it should be noted that the MRR measure is much lower than that observed for the XRCE corpora (see Table 1). Moreover, a significant drop in the RRR measure with respect to the MRR is observed, indicating that the vast majority of the repeated n -grams in the test corpus has already been seen in the training corpus. Therefore, we expect a limited effectiveness of online learning for this task.
 consists of documents from the European Medicines Agency, made available with the
OPUS corpora collection (Tiedemann 2009). In this work we extracted specific test sets of 3,000 sentences from the whole set of parallel sentences. Before doing this, we first removed the duplicate sentence pairs contained in this corpus (they represent a very high percentage of the total number of sentence pairs). Table 3 contains some statistics of the resulting corpora. The main interest of the EMEA corpus in our proposed experimentation is that it constitutes an example of an in-domain translation task. The models of the SMT system can be estimated from the out-of-domain Europarl corpus and then used to translate the EMEA corpus, simulating a non-stationary translation task. As it can be seen in Table 3, MRR, RRR, and UNF measures clearly suggest the potential usefulness of online learning in this task (RRR and UNF were calculated using the Europarl training corpus as the out-of-domain corpus). 4.2 Assessment Criteria We evaluated our SMT system with online learning using three evaluation measures:
WER, BLEU, and KSMR. System performance was assessed by comparing the system 138 translations with the corresponding target language references of the test set. WER and
BLEU measures are intended for its use in the evaluation of the PE scenario:
IMT scenario, we need to estimate the effort required by the user to produce correct translations using the system. To this end, we use the target references to simulate the translations that the user has in mind. The first translation hypothesis for each given source sentence is compared with a single reference translation and the longest common character prefix (LCCP) is obtained. The first non-matching character is replaced by the corresponding reference character and then a new system translation is produced. This process is iterated until a full match with the reference is obtained. Each computation of the LCCP would correspond to the user looking for the next error and moving the pointer to the corresponding position of the translation hypothesis. We refer to a pointer movement as a mouse-action . On the other hand, each character replacement would character of the new system hypothesis in a given interaction, no LCCP computation is needed; that is, no pointer movement would be made by the user. Bearing this in mind, we define the following IMT evaluation measure: require the same effort from the user. This constitutes an approximation, since these two actions are different and require different types of effort (Macklovitch 2006). additionally report the learning time in seconds after each training sample presentation.
The learning time is important to assess the ability of the learning algorithms to work in a real time scenario. All the experiments were executed on a Windows PC with a 2.00
Ghz Intel Xeon processor with 1GB of memory. 4.3 Experimentation Protocol
We evaluated our techniques by simulating real users. Because the different corpora used in the experiments contained source and target translations, we used the latter to simulate the reference translations that the user has in mind for each source sentence. the experimentation follows the learning process structured as a sequence of trials that experience some sort of learning curve as they gain knowledge after each training sample presentation. Given that such a learning curve is an important issue when designing online learning algorithms, some of the results reported here include plots with the evolution of cumulative error measures.
 in Section 4.1 have been used throughout the experimentation. One factor that has influenced the decisions in this regard is the high computational cost of batch retraining. provides a valuable reference when assessing the performance of online learning. In such experiments, we have defined specific subsets of the training corpora in order to speed up the experiments. More specifically, the first 10,000 sentences of the XRCE and Europarl corpora have been used.
 summarized as follows. The training sets of the XRCE and Europarl corpora were used to measure the convergence properties of the incremental EM algorithm (Section 4.4).
The above-mentioned subset of the training corpora was used to study the impact of the update frequency in the results (Section 4.5), to compare the performance of batch and online learning (Section 4.6), and to analyze the influence of sentence ordering in the system performance (Section 4.7). Finally, in the experiments to test the capability of our online learning techniques to learn from previously estimated models (Section 4.8), we used the training and development sets of the XRCE and Europarl corpora to initialize the system models, and the test sets to obtain translation results. For the system trained with the Europarl corpus, the experimentation is complemented with translation results using the in-domain EMEA corpus. 4.4 EM Algorithm Convergence Experiments
The standard estimation procedure for current phrase-based models relies on the gen-eration of word alignment matrices. As it was explained in Section 3.5, in our proposal such alignment matrices are generated by means of HMM-based word alignment mod-els that are incrementally updated from user feedback. For this purpose, we need to replace the batch EM algorithm by the incremental EM algorithm. Given the great importance of generating word alignments in the estimation of phrase-based models (see Section 3.5.3), we carried out experiments to compare the convergence rates of batch and incremental EM algorithms for HMM-based word alignment models. 140 to five training epochs 6 of the batch and incremental versions of the EM algorithm (common training schemes in state-of-the-art SMT systems frequently execute five EM training epochs to train the different word-alignment models). Plots were obtained for the XRCE and Europarl training corpora and the three translation directions (from
English to Spanish, French, and German). However, in the figure only the XRCE English to Spanish (Figure 2a) and the Europarl English to Spanish (Figure 2b) results are reported 7 (very similar results were obtained for the other language pairs). able to obtain a greater normalized log-likelihood than that obtained by the batch EM algorithm for the two corpora under consideration. In addition to this, such a greater log-likelihood can be obtained with fewer EM training epochs. These observed results are due to the fact that the incremental EM algorithm executes complete E and M steps for each training sample, resulting in a much greater rate of model updates per each training epoch (Neal and Hinton 1998).

EM algorithm is performed when training HMM-based alignment models (i.e., each training sample is processed only once by the learning algorithm and discarded after-wards). This contrasts with the conventional batch training scheme, in which a few training epochs (typically five) are executed. Hence, to fairly compare batch learning with our proposed online learning strategy, we should observe the relationship between the normalized log-likelihood of the incremental EM algorithm at the first training values shown in Figures 2a and 2b, we can appreciate a very small degradation in the log-likelihood ( &lt; 1% for the Europarl corpus) or no degradation at all. algorithms is negligible, we consider that the update rule for HMM-based alignment models given by Equation (24) is able to obtain word-alignment models comparable to those that can be obtained using batch learning. This claim will be supported with additional empirical evidence in Section 4.6. of the incremental EM algorithm by slightly modifying the conditions imposed by the online learning framework adopted in this paper (see Section 3.1). In such a framework, only the last sample presented so far to the learning algorithm can be used to modify the model parameters at each trial. This constraint can be slightly relaxed, allowing us to define alternative update rules for the HMM alignment models that execute more than one EM algorithm iteration over each sample. One example of such alternative update rules is described in Appendix A. Empirical results also given in the same appendix show that the obtained log-likelihood and the evaluation measures can be marginally improved with respect to the strict observation of the online learning framework. incremental EM could be suitable to replace batch EM in a batch-learning scenario.
However, one disadvantage of applying incremental EM to a batch-learning task is the necessity of storing the sufficient statistics for the whole data set: s data sets, the sufficient statistics may not fit in memory. Nevertheless, this information can be stored on disk and accessed efficiently, because the algorithm reads the data in a sequential manner. By contrast, this disadvantage is totally removed when incremental training sample are discarded at the end of each trial, or after a finite number of trials for the alternative update rule described in Appendix A. 4.5 Impact of Update Frequency
One important aspect to be clarified when designing PE or IMT systems is the influence of the system update frequency on the obtained performance. It is expected that updat-ing the system in a sentence-wise manner will produce the best results. However, this updating strategy poses efficiency problems because of the necessity of executing model updates in real time. This problem can be alleviated by defining an alternative update strategy in which the training process is delayed until a certain number of samples have been gathered. Delaying model updates may cause performance degradation, but it also constitutes one way to reduce the strong time requirements of a sentence-wise updating strategy. Specifically, if the time between updates is sufficiently high, the use of batch learning techniques could be appropriate (e.g., the training process can be executed overnight), removing the necessity of implementing online learning.

PE and IMT experiments using the XRCE and the Europarl corpora in the three dif-ferent language pairs (from English to Spanish, French, and German). In the experi-cumulative WER and KSMR to measure the user effort in the PE and IMT scenarios, respectively. The system was initialized with empty models, and after that such mod-els were extended from the user validated translations using three different update frequencies: every 10, 100, and 1,000 sentences. Five training epochs were executed in all cases. We did not consider sentence-by-sentence updating because of the huge computational cost of the retraining. Model updates were performed by means of conventional batch-learning techniques, that is, the whole set of training samples seen so far is batch-retrained whenever the model is updated. Additionally, we adopted default values for the weights of the log-linear model. The results of the experiments are shown in Figure 3. Again, we only report results for the English X  X panish XRCE corpus (Figures 3a and 3b) and for the English X  X panish Europarl corpus (Figures 3c and 3d).
Very similar results were obtained for the other language pairs. 142 lower when the update frequency was increased. More specifically, batch retraining every 10 samples (Batch10) consistently outperformed the rest of the systems in all cases and retraining every 100 samples (Batch100) was also consistently better than retraining every 1,000 sentences (Batch1000). Sharper curves were obtained when translating the
XRCE corpora, probably reflecting that in this corpus, there are groups of sentences with highly different translation difficulties from the system point of view.

This is because of the fact that the system copies to the output all those unknown words contained in the input. In some cases such copied words (names, dates, etc.) are correct words contained in the reference translations.
 system. Figure 4 shows the time cost in seconds of batch retrainings when we increase the number of training samples presented to the system. Results are shown for an update frequency equal to 1,000 when translating the XRCE (XRCE Batch1000) and the
Europarl corpora (Europarl Batch1000). Higher update frequencies produced exactly the same results but with a higher number of points in the plots. As it was expected, the training times increase linearly with the number of training samples presented to the system. Time costs were higher for the more complex Europarl corpus. After processing 10,000 sentences, batch retraining took 19 minutes for the XRCE corpus and 45 minutes for the Europarl corpora. This gives a clear idea of the infeasibility of batch retraining in a sentence-wise updating strategy. Moreover, time costs of batch retraining soon become unaffordable because of their linear growth with the number of translated sentences. wise update strategy if the update frequency is decreased. This constitutes a strong argument in favor of the application of our proposed online learning techniques, which are specifically designed to learn from individual training samples. By contrast, batch learning requires the execution of expensive retraining processes whenever a new sam-ple is presented to the learner. These findings are further supported in the next section, where the performance of batch and online learning systems are compared. 4.6 Batch versus Online Learning, Learning from Scratch
The great impact of frequent updates in the system performance demonstrated in the previous section poses the question of the necessity of replacing conventional batch learning techniques by online learning techniques. EM convergence experiments pro-vided in Section 4.4 showed that the log-likelihood of HMM-based word alignment models using the incremental version of the EM algorithm is competitive with that online learning will cause a degradation in the quality of the translations with respect to the use of batch learning.
 of online learning. For this purpose, we compared the performance of a batch system executing five training epochs every 10 sentences (Batch10) with that of an online system (Online). Plots show the evolution of the user effort required to obtain correct translations. This effort is measured in terms of cumulative WER and KSMR for the
PE and IMT scenarios, respectively. Initial models were empty in all cases. We report the results obtained when translating the first 10,000 sentences of the English X  X panish
XRCE (Figures 5a and 5b) and Europarl training corpora (Figures 5c and 5d). Very similar results were obtained for English X  X rench and English X  X erman language pairs. than that of batch learning for both corpora and for the two scenarios under con-144 higher update frequency of online learning, since the SMT models are extended for each individual training pair. It should be noted that the shape of the curves obtained with online learning is very similar to that of batch learning. This implies that incremental
EM presents a stable behavior, which contrasts with the instability of the stepwise EM algorithm reported in Blain, Schwenk, and Senellart (2012). Finally, it is also worthy of note that the results also show that the system is able to learn from scratch. training sample that were obtained during this experiment. Figure 6 shows a boxplot summarizing the main statistics of the learning times for the XRCE and Europarl corpora. As it can be seen, the boxplot clearly show the small time cost of the learning process for the two different corpora under consideration. Specifically, the learning time was never greater than 1 second, and the median times were 0 . 03 and 0 . 16 seconds for the XRCE and the Europarl corpora, respectively. The learning time was greater for the Europarl corpus because of the greater length in words of the sentence pairs with respect to that of the XRCE corpus. 4.7 Ordering Effects
The order in which knowledge is acquired is an important issue in online learning tasks (see Section 3.1). When the label of a new sample is presented to the learning algorithm, its parameters are modified to minimize cumulative prediction error. Hopefully, this modification will allow the system to provide more accurate predictions for similar samples. However, modifying parameters may also produce lateral effects . A lateral effect can cause the system to generate a wrong prediction for a given sample because of undesired changes in the learning algorithm parameters. One possible way to minimize the number of lateral effects is by processing similar samples in consecutive trials. dering in both WER and KSMR results when translating the first 10,000 sentences of the English X  X panish XRCE and Europarl training corpora by means of an online SMT system. For both tasks we translated the original portion of the training corpus and the same portion after being randomly shuffled.
 original corpora than for the shuffled ones. The reason for the improved results is due to the fact that, in the original corpora, similar sentences appear more or less contiguously (because of the organization of the contents of the printer manuals for the XRCE corpus or to the chronological order of the parliamentary sessions for the Europarl corpus). This circumstance increases the accuracy of online learning, since with the original corpora the number of lateral effects occurred between the translation of similar sentences is decreased. By contrast, the accuracy was worse for shuffled corpora. Shuffling causes similar sentences to no longer appear contiguously and thus, the number of lateral effects that may occur between the translation of similar sentences is increased. greater for the XRCE corpus than for the Europarl corpus. One possible explanation for this phenomenon is the lower repetition rate of the latter corpus. For low repetition rates, the number of lateral effects between the translation of similar sentences will be lower, since such sentences appear in a small number. 4.8 Learning from Previously Estimated Models
In the previous sections, we have shown empirical results where the models used by the SMT system were initially empty. In this section we show experiments in an alternative learning scenario where the SMT systems learn from previously estimated models. Under these circumstances, we compared the performance of a conventional
SMT system with that of an online SMT system. More specifically, the conventional 146
SMT system is a system that is not able to take advantage of user feedback after each translation, whereas the online SMT system uses the new sentence pairs provided by the user to revise the statistical models. Both systems used log-linear models trained in batch mode by means of the XRCE or the Europarl training corpora (five training epochs were executed). The weights of the log-linear model were adjusted for the corresponding development corpora via MERT. 4.8.1 XRCE Experiments. Table 4 shows the obtained results when translating the XRCE test corpora from English to Spanish, French, and German using conventional (batch learning without retraining) and online SMT systems. The table shows the BLEU, WER, and KSMR measures for both systems (95% confidence intervals are shown in all cases).
The table also shows the average online learning time (LT) for each new sample pre-sented to the system. All the improvements obtained with the online SMT system for the different measures were statistically significant. Greater improvements were obtained when translating to French and German. Such improvements could not be accurately predicted by means of the MRR measure (see Table 1), because, for instance, English to
German presented a lower MRR value than English to Spanish. However, RRR and UNF measures were lower for English to Spanish, demonstrating the utility of such measures to obtain refined predictions of the impact of online learning in the results. The average learning times allow the system to be used in a real-time scenario.
 our proposed online SMT system, with those obtained by different state-of-the-art IMT systems described in the literature. These IMT systems are based on different trans-lation approaches, including the alignment templates (AT), the stochastic finite-state transducer (SFST), and the phrase-based (PB) approaches to IMT (see Barrachina et al. [2009] for more details). AT and SFST systems follow the word graph-based approach to generate the IMT suffixes, whereas the PB system retranslates the source sentence at each interaction of the IMT process. Experiments reported in Barrachina et al. (2009) showed that word graph X  X ased systems are much faster than systems that retranslate the source sentence at each interaction, but obtain slightly worse results. Because quick response times are critical in an IMT scenario, the majority of the IMT systems reported in the literature, as well as the one proposed here, follow a word graph X  X ased imple-mentation strategy. Our system significantly outperformed the results obtained by the state-of-the-art systems, except those of the PB system for English to Spanish. Even in this case, our system obtained slightly better results. 4.8.2 Europarl Experiments. Table 6 shows the translation results from English to Spanish,
French, and German for the Europarl corpus when using conventional and online SMT systems. Again, BLEU, WER, and KSMR measures for conventional and online SMT 148 systems are shown. The table also reports the average LT for the system with online learning.
 improvement in the three measures under consideration with respect to the conven-tional system (without retraining). However, the improvements were not statistically significant in some cases (WER for English to French, BLEU and WER for English to
German). These smaller improvements with respect to those observed for the XRCE task could be predicted from the lower repetition rates that the Europarl corpus present (see Table 2), especially for the RRR measure, which reflects how frequently unseen n -grams are repeated in the corpus to be translated.
 in Table 4. Despite this, it was small enough for its use in a real-time scenario. 4.8.3 EMEA Experiments. Table 7 shows the obtained results measured in terms of BLEU, WER, and KSMR when translating the EMEA test corpora from English to Spanish,
French, and German. Conventional and online SMT systems with models estimated from the Europarl training corpora were used. In this experimentation, we also consid-ered a third SMT system that used online learning from scratch. The average online LT for each new sample presented to the system is also reported.
 previously estimated models, significantly outperformed the results obtained by the conventional SMT system (batch learning without retraining) for the three evaluation measures. The magnitude of the improvements were greater than that observed for the XRCE and Europarl corpora, as could be predicted from the MRR, RRR, and UNF measures provided in Table 3. Note that, although the values of the MRR measure of
EMEA were similar to that obtained for the XRCE corpus, the improvements were greater because of the higher number of unseen events (explained by the RRR) and their more-frequent presence in the EMEA corpora (explained by means of the UNF).
The online learning system using previously estimated models consistently produced improvements of more than 10 points for the three evaluation measures and for each of the language pairs. The improvements were smaller for the online learning system from scratch. Despite this, it is worth noting that for this task, it would be better to use conventional SMT system with models trained on out-of-domain corpus. small enough to allow the use of online learning in real-time scenarios. 5. Discussion The set of experiments presented in the previous section validates the use of incremental EM to design online learning algorithms for SMT. One common criticism of incremental
EM is its great memory requirements due to the necessity of storing the set of sufficient statistics for each individual sample. However, this criticism was initially made in the context of batch learning (see Liang and Klein 2009), and there were no studies on its application to online learning tasks, with the exception of the work presented in Ortiz-
Mart  X   X nez, Garc  X   X a-Varea, and Casacuberta (2010). Here we have proposed two update rules that present constant (and very small) memory requirements while maintaining the same or even better performance than batch retraining. The first proposed update rule (see Equation (24)) allows us to execute one epoch over the training samples memory requirements of incremental EM applied in a batch learning context, where the sufficient statistics for all of the samples seen so far need to be stored (for a more detailed explanation, see Equation (24) and the subsequent discussion). The second quantity of the last samples.
 batch retraining, resulting in a very stable learning algorithm whose behavior contrasts with the stability problems reported in other works for stepwise EM (Blain, Schwenk, and Senellart 2012).
 and IMT scenarios. In both cases, system performance was greatly improved when the update frequency was increased. This constitutes a strong argument in favor of using online learning, because of the prohibitive time cost of frequent batch retrainings. 150 online learning: the ordering effects of training samples in system performance. We compared the results that are obtained when the sentences to be translated were chrono-logically ordered with those obtained with a randomly ordered corpus. The benefits of online learning are favored by the former situation, since similar sentences appear more or less contiguously. This would be an example of the document internal repetition phenomenon mentioned by some authors. Moreover, this is the expected situation in real translation scenarios.
 goal of learning from scratch in an efficient manner. Learning from scratch is not only a theoretical scenario that can be proposed in an SMT research context, but a technique with potential utility in real domain adaptation tasks. It is generally acknowledged that in-domain corpora are difficult to obtain, and, as a result, SMT system models presented here show that online learning from scratch can produce significantly better results than a conventional SMT system with models estimated from out-of-domain corpora. This would not be the only possible application of online learning in this scenario. Indeed, online learning from scratch has already been applied to build au-tomatic post-editing systems designed to work in situations where in-domain corpora are not available (Lagarda et al. 2015). Another possibility would be to linearly combine a model trained from out-of-domain data with an initially empty and separate online learning model. This online learning model could be useful both for learning new translations as well as for giving preference to the in-domain data. For example, Mirking et al. (2013) demonstrate the utility of a similar system, but implemented with batch retraining.
 of online learning is able to learn from previously existing models. We compared the ob-tained BLEU, WER, and KSMR measures of a conventional SMT system (batch learning without retraining) with that of an online system. The improvements were significant in almost all cases, and very strong for specific tasks and language pairs (their magnitude was greater than 10 points for the different measures under consideration). 6. Related Work
However, in the SMT framework, the vast majority of the work has been devoted to the study of the batch-learning setting. The application of online learning to SMT has been mostly centered on estimating the feature weights of a log-linear model by means of discriminative training techniques. Examples of this kind of work can be found in Och and Ney (2002), Liang et al. (2006), Watanabe et al. (2007), Chiang, Marton, and Resnik (2008) and Mart  X   X nez-G  X  omez, Sanchis-Trilles, and Casacuberta (2012). These works differ from the one presented here in that we apply online learning techniques to train the features of the log-linear model instead of their weights.
 model features is Cesa-Bianchi, Reverberi, and Szedmak (2008). That paper presents a very constrained version of online learning applied to a CAT scenario, where the trans-lation model cannot be extended because of the high computational cost of retraining the whole model for a new training pair. The literature on online learning for SMT has tried to solve or alleviate this problem in different ways, as it is discussed in the following sections, where we identify four different approaches. 6.1 Online Learning Constrained by Previously Existing Models
The first approach accounts for work that relies on previously estimated models as a measure to avoid full model retraining. An early attempt can be found in Nepveu et al. (2004), where dynamic adaptation of an IMT system via cache-based model exten-sions to language and translation models is proposed. That work constitutes a domain adaptation technique and not an online learning technique, since the proposed cache components require pre-existent models estimated in batch mode. As pointed out by the authors, one of the most important limitations of their proposal is the inability to process words that were not seen during the estimation of the pre-existent models. In addition to this, their IMT system does not use state-of-the-art models. The work presented in Hardt and Elming (2010) applies a similar strategy to a modern phrase-based SMT system, using heuristic IBM4-based word alignment techniques to add new phrase pairs to a local phrase table. Their technique shares similar limitations with the work presented in Nepveu et al. (2004), since it requires pre-existent models estimated in batch mode.
In addition to this, according to the empirical results that are reported, their proposal is slow (average learning times per sentence of up to 1 minute) and unable to obtain the same results as conventional batch retraining because of the heuristic decisions that are made to incrementally train the phrase models. Bertoldi, Cettolo, and Federico (2013) present an online learning technique based on cache components, which is also proposed technique is able to extend the translation model by obtaining alignments at the phrase level, the phrase model that is used to generate such alignments is not updated from user feedback. Again, this makes the system dependent on previously existent models estimated in batch mode and presumably less reliable when learning from new sentence pairs that contain poorly represented or unseen events during to Bertoldi, Cettolo, and Federico (2013) that also includes discriminative training methods.
 a new log-linear component for the set of phrase pairs contained in the translation table is used. This component is updated so as to increase or decrease the score of specific phrase pairs depending on whether they are present or not in the user validated translations. The main difference between that work and other techniques isting parameters. Another alternative approach is presented in Denkowski, Dyer, and Lavie (2014), where a translation grammar, a language model, and a set of log-linear weights are adapted in a post-editing task. In that case, pre-existent word alignment models estimated in batch mode are required to extend the translation grammar. 6.2 Online Learning Based on Output to Reference Alignments
Other works try to avoid retraining the phrase model by aligning the output of the de-coder with the reference given by the user (Blain, Schwenk, and Senellart 2012; Simard and Foster 2013). Specifically, Blain, Schwenk, and Senellart (2012) propose obtaining word alignments between the source and reference sentences using the system output as pivot. Such alignments are obtained by combining the word alignments from source to system output and from system output to reference. Because the output and the 152 reference sentences are (hopefully) very similar, they can be aligned using edit-distance X  based algorithms, which do not require being trained. Regarding the work of Simard and Foster (2013), it conceives the translation as a two stage process, first the source is translated by a regular SMT system, and after that, the output is translated again using an automatic post-editing module. This module is implemented as a phrase translation system trained from the system translations and their references. To extract the phrase pairs, word level alignments based on edit distance are used.
 put and the reference sentences is the strong assumption regarding the similarity of such sentences. The similarity may be low when the source sentence contains poorly very common in real translation tasks. A low similarity could negatively affect the resulting word alignments because of the great simplicity of edit-distance algorithms.
As a consequence, the obtained performance will be worse than that obtained by means that paper claim that the only alternative to retraining is the application of techniques based on the so-called stepwise EM algorithm (Capp  X  e and Moulines 2009), which is unstable when used in an online learning setting and has a lower performance. By contrast, in this paper we empirically demonstrate that the incremental version of the
EM algorithm (Neal and Hinton 1998) can also be applied and does not have such disadvantages. 6.3 Quick Adaptation Based on Retraining
Mirking and Cancedda (2013) propose techniques to achieve quick model updates using batch retraining. Such techniques are based on maintaining different translation tables for out-and in-domain data. Separated in-domain models allow the user to quickly update the models via batch retraining and to give preference to the in-domain table via tuning of log-linear weights. Unfortunately, such quick model updates cannot be executed in a sentence-wise manner but in longer lapses of time (e.g., a day). Moreover, the proposed configurations have the disadvantage of becoming slower over time.
Mirking and Cancedda state the great interest of replacing batch retraining by prin-cipled incremental training, but they also point out that such a technology is not still mature or available. 6.4 Pure Online Learning Techniques lowing a pure online learning approach, removing the constraints on model updates imposed by the techniques mentioned previously. Levenberg, Callison-Burch, and
Osborne (2010) introduced stream-based adaptation for SMT. This technique is able to incrementally learn from scratch or from previously estimated models. However, their approach only captures a restricted notion of online learning, because it is designed to process large amounts of incoming data. Indeed, their training regime uses the stepwise
EM algorithm, which works by processing large blocks of training data and not in a sentence-wise manner.

Casacuberta (2010) introduces a state-of-the-art log-linear SMT model using a set of incremental update rules for the feature functions. The resulting system is able to learn from scratch or from previously estimated models, and it is applied in an IMT scenario.
One key element of the proposal is the use of the incremental EM algorithm. As far as we know, such work constitutes the first proposal that successfully applies online learning to SMT, solving the technical limitations encountered in previous works. However, some important aspects of the proposal were not clarified, such as its performance in a PE scenario or its effectiveness when compared with batch retraining.
 both theoretically and empirically. Regarding the theoretical aspects of online learning in SMT, we provide a much more detailed explanation of the different online update rules. Additionally, we introduce an alternative update rule using the incremental EM algorithm, which solves one important limitation of the update rule that was originally new update rule allows us to execute more than one training epoch over the incoming data while maintaining constant time and spatial complexity (see Sections 3 and 4.4 as well as Appendix A for more details). In addition to this, we have integrated the log-linear model proposed in this paper into the IMT technique based on stochastic error correction models described in Ortiz-Mart  X   X nez (2011). This IMT technique is able source sentence at the initial interaction of the IMT process. By contrast, the technique implemented in Ortiz-Mart  X   X nez, Garc  X   X a-Varea, and Casacuberta (2010) is much slower, work of Bertoldi, Cettolo, and Federico (2013) on measuring the effectiveness of online learning by proposing two new automatic measures.
 ways. First, the proposed online learning techniques have been applied to an ad-ditional CAT scenario (specifically, the PE scenario). Additionally, the experimenta-online learning that were not studied previously, such as the convergence proper-ties of the incremental EM algorithm, the impact of the frequency of model updates in the error measures, or the differences in performance between batch and online learning. 7. Conclusions and Future Work
We have proposed online learning techniques for SMT. Such techniques allow us to incrementally extend the statistical models involved in the translation process in an efficient manner. Our proposal breaks technical limitations encountered in other works, as is explained in Section 6.
 namely, PE and IMT, since they fit nicely into the online learning paradigm. However, restricted to such strict online learning scenarios. Another suitable scenario is the one described by Levenberg et al. (2010), where the incoming data are processed in large blocks instead of in a sentence-wise manner.
 pus, which has been extensively used in the literature to report CAT results, the well-known Europarl corpus, and the EMEA corpus, which is used in this work to simulate a non-stationary translation task. As summarized in Section 5, the results demonstrate the appropriateness of the incremental EM algorithm to implement online learning, the great impact of frequent model updates in translation quality, the importance of 154 from scratch or from previously estimated models.
 ing in SMT tasks X  X he restricted repetition rate (RRR) and the unseen n -gram fraction (UNF). It has been empirically demonstrated that such measures allow us to refine the predictions that can be made with the modified repetition rate (MRR) measure, which is based on the repetition rate introduced in Bertoldi, Cettolo, and Federico (2013). capabilities used in this paper is implemented in the freely available Thot toolkit. of the log-linear model features instead of their weights. We consider that weight model parameters, whereas estimation of feature parameters (including those of phrase and language models) may involve millions of parameters. In addition to this, weight adjustment can be performed offline, since typical MERT procedures use closed de-velopment corpora of a few thousand sentences (i.e., the training data is bounded and relatively small). In spite of that, we think that removing any offline training stages from practical online SMT system implementations could be useful to simplify their usage and design. Additionally, for future work we plan to incorporate bounds to the data structures used to store the model parameters, because incoming data is in principle unbounded.
 to other natural language processing applications, where the system output is super-vised by the user. In addition to this, our proposed techniques can also be useful to implement active learning algorithms for their use in online settings.
 Appendix A: Alternative Update Rule for HMM-Based Alignment Models
In this appendix we introduce an alternative update rule for HMM-based alignment models. This rule allows us to execute more than one training epoch over the in-coming data in contrast to the rule given by Equation (24). For this purpose, at them.
 plement the update rule is to keep the last E samples at a given trial, executing one the way in which conventional batch training works. Specifically, batch training only starts the next training epoch after having processed the whole training corpus in the set of training samples is unbounded. Nevertheless, it is possible to obtain a training the last R samples instead of the last E , with R E , processing a total of E samples at each trial. To increase the lapse of time (or the number of trials) until a given sample is reprocessed, the samples are processed in an interlaced way, as it is depicted in
Figure A.1. Specifically, the figure shows which samples are processed by means of the incremental EM algorithm at t = 10 when we want to execute E = 3 epochs, keeping the last R = 5 samples. Under these circumstances, samples 6, 8, and 10 would be processed. keep the last R samples, then the proposed update rule is as follows: where b X c is the floor operator.
 update rule given by Equation (24) is a particular case of the interlaced rule where E and R are set to 1. In order to measure the performance of interlaced training, we briefly report here the results of some experiments that we carried out for the XRCE and the
Europarl corpora. Because we obtained very similar results for the different language pairs involved in the experimentation, namely, from English to Spanish, French, and German, we only report here the English to Spanish results.
 terlaced update rule is the convergence rate of the EM algorithm. In this case, we cannot show plots of normalized log-likelihood per training epoch as we did in Section 4.4, because interlaced updates execute the different training epochs simultaneously for a given training set. Instead, we report the final normalized log-likelihood that is obtained 156 at the end of the estimation process. Table A.1 shows the normalized log-likelihood of the EM algorithm with batch, incremental, and interlaced (with R equal to 10, 100, and 1, 000) updates, using the English X  X panish training set of the XRCE and Europarl corpora. 8 As we can see, interlaced training outperformed batch and incremental EM algorithms for all values of the R parameter. In addition to this, increasing the value of R produced improvements in the final normalized log-likelihood.
 update rule with that of batch and online rules. Figure A.2 shows plots with the evolution of WER and KSMR for online and interlaced (with R equal to 10, 100, and 1, 000) update rules when translating the first 10, 000 sentences of the English X  X panish language pair of the XRCE and Europarl training corpora. As we can see, the value of the R parameter had a strong influence in the system performance. Specifically, the interlaced system with R = 10 clearly underperformed the results obtained by the online system; increasing the value to R = 100 obtained almost identical results; and R = 1,000 produced slightly better results. We think that this phenomenon is linked to the propensity of HMM-based alignment models for overfitting (see Och and Ney 2003 for more details). Under this point of view, the worse results for R = 10 would be due to some sort of local overfitting, which is alleviated for greater values of R .
 time per sentence. Figure A.3 shows boxplots for the learning time per sentence that was required to train the first 10, 000 training samples of the XRCE and Europarl English to Spanish corpora using online and interlaced systems for different values of the R parameter. The online system executed only one training epoch, whereas the interlaced systems executed five. All the times are reported in seconds. As we can see, interlaced updates increased the training time with respect to that of basic online updates (this was the expected outcome since five samples were processed at each trial instead of one).
However, the time costs of interlaced updates were still affordable for both corpora (worst case times of a few seconds, median times less than 1 second for the different values of R ).
 Acknowledgments References 158 160
