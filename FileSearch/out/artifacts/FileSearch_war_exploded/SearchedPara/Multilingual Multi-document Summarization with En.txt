 Facing the explosive expansion of network information, users have to spend vast time to discover what they want. It is a significant challenge to f ind an effective tool t o filter the unnecessary information and provide a precise and concise synopsis. Hence document summarization has become one of the im-portant technolog ies for research. R esearchers have worked on different topics, including s ingle docu-ment summarization , m ulti -document summarization and m ultilingual m ulti -document s ummarization which is just the topic of this paper and also the most difficult one . 
T he field of document summarization has accumulated a lot of research results a fter 60 years of re-search . Summ arization methods can be classified into extractive and abstractive ones . Extractive sum-marization aim s to select important sentences from the original document and reorganize these sentences it like human. The mainstream is extractive summarization currently because a bstractive summarization needs effective and deep natural language processing technologies . For extractive summarization, the representa tive algor ithms involve graph model [1], sentence clustering [2], linear programming[3], topic model [4] and so on.

This paper focus es on the extractive summari zation and topic model method . In recent years, w e are constantly using and mining hLDA [5 ] featu res . The hLDA algorithm is selected as our main algorithm. hLDA has many advantages. On the one hand, it is a language -independent algorithm, s o we don't need a lot of professional linguistic knowledge . On the other hand, it is a corpus -oriented algorithm , i t can deal with large scale corpus . hLDA can be an e xcellent multilingual multi -document modeling algorithm. Many hLDA scholars [ 6 ][ 7 ] [8] are just exploring the cluster and document modeling ability of hLDA , yet t hey haven't made clear the semantic features behind the model. Based on the r esearch of hLDA, t his paper propose s a new level distribution feature from it . In combination with other traditional features, we build our new summarization system with a better performance . After compari son with other meth ods, it shows the superiority of our system in some respects . 2.1 hLDA
The hLDA (Blei et al. 2004) can organize latent topics of sentences in a set of document s and their probability. Hence, a topic can be interpreted as probability distribution over words. The following figure 1 shows an example hLDA tree with the depth of 3 . Please refer to (Blei et al. 2004) for more details. Parameter Setting Parameter Setting ETA 1.2,0.5,0.05 GEM_SCALE 100 GAM 1.0,1.0 SCALING_SHAPE 1 GE M_MEAN 0.5 SCALING_SCALE 0.5
Owing to using the sentence as the input unit of hLDA algorithm, every sentence will be allocated into a path from the root to a leaf in the tree as shown with ar rows in figure 1 . Sentences having the same path will be considered to be related to the same theme. In light of our previous research experience, we set the depth of the tree to 3. There are 6 parameters in total to control the structure of the tree. The parameter settings in our system can be found in Table 1. More details have been presented in the research of Heng Wei[ 9 ] . 2 .2 Experimental D ata MultiLing (http://multiling.iit.demokritos.gr) is a special session in SIGdial 2015, which holds 4 tasks, i.e. , MMS ( Multilingual Multi -document Summarization ) , MSS (Multilingual Single -document Sum-marization), OnForumS ( Online Forum Summarization ) and CCCS (Call Centre Conversation Summa-rization). This multilingual multi -document summarization (MMS) (Giannakopoul os, 2015) task aims to evaluate the application of partially or fully language -independent summarization algorithms. It contains ten languages: Arabic, Chinese, Czech, English, French, Greek, Hebrew, Hindi, Romanian and Spanish.
The multi -document summariz ation task required participants to generate a fluent and representative summary from the set of documents describing an event sequence. The language of each document set belonged to one of the aforementioned set of languages and all the documents in a set were of the same language. The output summary was expected to be in the same language and between 240 and 250 words. The task corpus is based on a set of WikiNews English news articles comprising 15 topics, each containing ten documents. Each English docu ment was translated into the other nine languages to cre-ate sentence -parallel translations. Please refer to [10] for m ore detail ed introduction of MultiL ing2015 .
The experimental data of this paper is the test data of MMS task. Each la nguage contains 10 t o 15 topics and e ach topic contains 10 documents.
The f ramework for our system is shown in F igure 2 . In particular, w e only treat Chin ese with word segmentation . The kernel module is constructing an hLDA model.
 3.1 Pre -process i ng 1. Merge Documents 2. Split Sentences 3. Word Segmentation 4. Remove Stop Words 5. Generate hLDA input File 3.2 hLDA M odeling ( http://www.cs.princeton.edu/~blei/topicmodeling.html ). Through hLDA modeling, we can get the final hLDA modeling tree information. The main three files are  X  X ode X  file,  X  X od e.assign X  file , and feature is extracted from them. The only purpose that we utilize hLDA in this paper is to get the value of level distribution featur e for sentence scoring . The other features for sentence scoring are independ-ent with hLDA modeling process. In the n ext section, we will elaborate on introduc tion to all features we used in this paper. features (except Level Distribution) that are used in single document summarization widely . The validity features, we have also performed extensive experiments to illustrate its effectiveness in m ulti l ingual multi -document summarization . (1) Level Distribution: this feature is just the achievement of our latest research. In this feature, we think tha t after hLDA modeling, if a word appear s in more level s or more node s , then it has a higher possibility to be involved into summar y . Formula 4 is our scor ing method.

Blei , t he author of hLDA , has proposed that the lower level nodes in the hLDA modeling res ults are more abstract. Thus in previous years, we consider ed that the abstract word is more suitable to appear in summary. In light of this idea , our previous level scoring formula is:
In formula 1,  X  X  X  X  (  X  0 ) ,  X  X  X  X  (  X  1 ) and  X  X  X  X  (  X  2 ) refer to the amount of words in a sentence as-signed to each level respectively. Usually we se t the three weights according to our own experience, which is a as 0.75, b as 0.25, and c as 0.1. We have utilize d this feature for sentence scoring to imple-ment several summarization system s . For example, TAC -2014 multi -document summarization system, mult iLing -2015 summarization system, NLPCC -2015 text summarization system. Through these expe-riences, we find out that the effect of this feature and the performance is not satisfactory. Usually, it will reduce the performance of summarization system. After pa rticipating in the NLPCC2015 Shared Task4, we use NLPCC2015's corpus to perform more deeply exploration in features contained in hLDA mod-eling results. We find a more reasonable understanding of the abstract nature of the level. In hLDA modeling tree, the abstract node possibly means that the words appearing in the node either appear in a lot of contexts or their frequency is very low. In the high level of nodes, the words appearing in these nodes usually have some very specific context and even only one co ntext. In our work, we have found out that most of the words in root node are low frequency words, while in the leaf nodes, although some words are high frequency one s , they always appear in a fixed context. Under the guidance of this un-derstanding, a new law has been found in the hLDA modeling that if a word appears in more nodes and more levels, then the word has a higher probability to be selected into the summary. After more explo-ration of this rule, we propose a new formula of level feature for sentenc e scoring called level distribu-tion. Formula 2 shows the result of our research.

In formula 2, N is the total number of words in a sentence.  X   X  is the weight of the level in the hLDA distribution score is based on the law above. Every word will be mapped to a single score according to their distribution information in hLDA modeling tree. Mapping rule is defined through many controlled node where T  X  is assigned to. Formula 3 reveals its calculation method.
Note that NLPCC 2015 summarizat ion task is only for single Chinese document. We will demon-effectiveness and robustness for mult i lingual multi -d ocument summarization (MMS) . Hence, we s elect M ultiLing2015  X  s MMS test data as our experiment al data. The most important point is that we aban-doned the last item in formula 2. This is mainly because we cannot get the keywords of other language s except Chinese. So the final level distribution for mula in this paper is as formula 4.

We will specific ally discu ss the performance of level distribution feature in later section for e xperi-ments. In short, t his feature greatly improves the performance of Chinese language . For some other NLPCC 2015 Chinese summarization task. Through some experiment al exploration, we acquire the parameter s ettings in formula 4. Table 2 shows the final settings in this paper.
 W 0.5 0.1 0.4 4 1 Word score (0 -2) 3 1 -1 0 0.5
In table 2, W 0 is the weight of the first level of hLDA modeling tree. W 1 is the weight of the s econd level of hLDA modeling tree. W 2 is the weight of the last level of hLDA modeling tree. For every word appear in three layer s, (0,1,2), then the word score will be set to 4. If a word only appear s in the first layer (0), then the word score will be -1.

It must be noted that we do not elaborate on how we find the law of Level Distribution and how we Distribution and verify the assumption in another paper in detail. In fact, the discovery of Level distri-bution law is based on the statistical analysis of the human summary. Through performing hLDA mod-eling on human summary and analyzing the law of these hLDA modeling results, we acquire the law of Level distribution. In this paper, we just want to demonstrate that the Level distribution is effective in m ultilingual m ulti -document s ummarization . (2 )Title Sim ilarity: For news, the title s entence can be very good at reveal ing the central theme . So we calculate the tf -idf similarity between each sentence with the title sentence. In every topic, there are 10 documents. We choose the first sentence of each article as the title sentence . The similarity score of each sentence is calculate d as the similarity between the sentence and th e title sentence . Formula 5 reveals the calculation method. document vector representation of the title sentence . (3 )Sentence Length: We believe that the length of the sentence in the news is subjected to Gauss ian distribution. If a sentence is c loser to the average length, then it is more likely to be select ed into sum-mar y .  X  is the average value of sentence length in all documents of a topic .  X   X  is the length of a sen tence at position i of the merge d documents . (4) Sentence Position: Here we use the monotonous sentence position scoring method. Usually, if the summar y . Note that our sentence position score is not referr ing to the sentence position in the merge d document. The sentence position score is just calculate d as the sentence position score in the original single document the sentence belongs to. Hence, there are possibly many sentences with the same sen-te nce position score. If two document s have the same amount of sent ences, the sentence in the same position will have the same sentence position score. sentence position in the single document the sentence belongs to . (5)Sentence Coverage: I f a word appears in many sentences, then the possibility of the sentence containing the word being selected into summar y will be higher. (6)TF : this feature is referred from [11 ] .The system won the first prize in the NLPCC 2015 Shared Task 4. 
Where N repres ents the number of different words that are included in the article.  X   X  is the times the word  X   X  appears in the article.  X   X  is the i th word in the article.

At last , we combine all features  X  score s mentioned above. Formula 12 is the final sco re of one sen-different influence s in the performance of summarization.
 The following algorithm descr ibes the sentence extraction strategy in our system.
 Our algorithm firstly select s a set of parameter s to calculate the final score of every sentence. Then we rank the sentences of the merged document by function ranking() according to the ultimate significance score of each sente nce calculated by formula (12 ). We control the final total length of the summary to the limit of 250 words using the parameter totalL ength and order the select ed sentence s in the generat-ed summary with function ordering() according to the sentence position.
We use the Rouge package [ 12 ] [13 ] to evaluate effectiveness of ou r approach vs. other summarization methods. The results of other summarization me thods are published by M ultiLing2015 X  X  organizer . The experiment al data is M ultiLing2015 MMS test dat a. We evaluate the results of 63 different feature combination s of parameters ( each para in para 1~6 is either 0 or 1 ). Through these experiments, we languages , we evaluate their Rouge score s . Table 3 show s the Rouge score s of summari es generated using only one feature.
 That X  X  to say, the single Level Distribution feature seems to have no re a son to exist. Nevertheless, when we try to combine this feature with other features, a very s urpris ing result appear s . This surpris ing and good information is that this feature can improve the comprehensive result when combine d with others. F urthermore , it ha s positive effect with other features in most situation s . There is no same phenomenon on other features. Table 4 reveals part of this phenomenon.

Table 3 . single feature summarization result (Owin g to the limit of this paper space, all rouge score s in this paper except table 6 are ROUGE -1 F, Ts = Title Similarity, Levels = Level Distribution,SenLen = Sentence Length,SenPos = Sentence -Position,SenCov = Sentence Coverage) All Language s 0.36303 0.30325 0.31687 0.35115 0.34012 0.31642 Arabic 0.23775 0.13752 0.14194 0.16408 0.21231 0.19236 Chinese 0.49661 0.30 538 0.34594 0.53596 0.31484 0.36193 C zech 0.44861 0.43 309 0.45452 0.45027 0.44519 0.43403 English 0.42502 0.39756 0.39852 0.39844 0.41834 0.40326 French 0.47388 0.43186 0.44607 0.46911 0.46888 0.44210 Greek 0.25339 0.18067 0.20507 0.22718 0.29537 0.15405 H ebrew 0.25719 0.19954 0.20060 0.29113 0.21739 0.24 119 H indi 0.07933 0.05629 0.10094 0.04426 0.06948 0.04846 R omanian 0.43059 0.38766 0.39540 0.41449 0.42047 0.40081 S panish 0.52443 0.45659 0.46978 0.50906 0.47676 0.45796 All Language s 0.35481 0.32714 0.36608 0.35647 0.33786 Arabic 0.24917 0.19710 0.23659 0.23261 0.21748 Chinese 0.47326 0.40162 0.61449 0.54868 0.52351 C zech 0.44943 0.44195 0.47419 0.45349 0.43256 English 0.4150 0 0.41063 0.43187 0.42530 0.41703 French 0.47811 0.43080 0.47870 0.45036 0.44211 Greek 0.24394 0.21578 0.17089 0.21187 0.15830 H ebrew 0.23027 0.19130 0.24472 0.27597 0.26993 H indi 0.08899 0.07778 0.09419 0.07273 0.03997 R omanian 0.41866 0.40842 0.4314 4 0.41035 0.40280 Spanis h 0.50755 0.47206 0.50846 0.47696 0.46728
The results in table 4 show that the All Language Rouge score wil l increase when Level Dis tribution is combine d with other feature s except Title S imilarity . Note that this phenomenon of performance increasing is not unilateral . For example, when Sentence Length is combine d with Level Distribution, the final result not o nly surpass es the result using single Sentence Length, but also surpass es the result using single Level Distribution. For other features, the phenomenon of performance increasing is usually unilateral . What X  X  more, a n important fact in table 4 is that this feature improve s the performance of Chinese summarization g reatly . This result ha s just verified our expectation . Because Level Distribution feature is origin ed from Chinese single document summarization . We find this feature through performing experiment s o n NLPCC2015 Shared Task 4 data.
 Table 3 and Table 4 are the experiment al results based on the corpus without remov ing stop words. Actually, stop word s have a great impact on the performance of the summarization system. Especially for Level Distribution feature, the effect will be weaken if we do not remove stop words. In light of our research results, if we use the corpus with stop words to perform hLDA modeling, the stop words will have the similar distribution characteristic s with those important word s which Level Distributi on words.
 All Language s 0.36466 0.33745 0.31729 0.35115 0.35440 0.33688 Arabic 0.23775 0.18475 0 .16756 0.16408 0.22202 0.19385 Chinese 0.52479 0.53915 0.33620 0.53596 0.49557 0.51904 C zech 0.44869 0.43867 0.44678 0.45027 0.44514 0.44318 English 0.42470 0.41071 0.39425 0.39844 0.41544 0.41382 French 0.47291 0.41608 0.44536 0.46911 0.45765 0.45388 Greek 0.25339 0.20009 0.20507 0.22718 0.29537 0.15405 H ebrew 0.25719 0.24113 0.21421 0.29113 0.25934 0.26475 H indi 0.07933 0.03997 0.08794 0.04426 0.07704 0.04999 R omanian 0.42776 0.41170 0.39564 0.41449 0.40101 0.41623 Spanish 0.52388 0.47904 0.46444 0.50906 0.46055 0.46548
Table 5 show s that almost all results are better than the corresponding ones in table 3 when we compare the same feature. This is a good evidence of that stop words can reduce the Rouge score of summarization system. In these feature s , we can find out that the Levels feature can b enefit most from removing stop words especially for Chinese summarization. W hen we use only one feature, Level Distribution is top 1 in Chinese summarization. For other languages, the result of Level Distribution is not that bad like that of table 3. That X  X  to say, the effect of Level Distribution are strongly related to whether we remov e stop words or not .

F inally, we compare our best experimental result with several other summarization methods. There are 9 system s in M ultiLing2015 MMS task involving a human summatization (This summarization is written by human). Not all system s have participated in all langu age s . Table 6 reveals the comparison result. In table 6, we represent a system not participat ing the language by the symbol " --" . Through the comparison in table 6, we can find out that our system has absolute advantage in Chin e se summarization. The result s are very similar to the human results . In Hebrew, the result of our system is also just second to the result of human summarization. However, in Arabic,Greek, Hindi, the performance of our system is extremely bad. E specially for Hindi, o ur results are fa r less than others . W e need more experiments later to explore the reasons for this situation. But on the whole, our system is still competitive . The performance s on Chinese, Czech and Hebrew are all just rank ed behind human results. One thing we need to em phasize is that our best Chinese summarization results have used Level Distribution feature. Although the best summarization results of other languages is not always involv ing Level Distribution, it can indicate that Level Distribution feature is most help ful in Chinese summarization. In light of our experience on single document text summarization with Level Distribution, the parameter setting in this paper await s to be improved in the future . Generally speaking, the proportion of other feature s and Level Distribution feature is at least 3:1. It maybe because this reason that our Level Distribution feature cannot improve the best summarization result s of other languages.

This paper introduce s an improvement of multilingual multi -document summarization system based on Multi2015 MMS data. We propose a new feature of Level Distribution, combine it with multiple other feature s and demonstrate the superiority of this new summarization system t hrough experiments in some aspects . Specifically, Chinese summarization results have been improved greatly. Experimental results have also reveal ed that our new feature is valuable in multilingual multi -do cument summarization sys-tem. I n the future , w e still need more experiments and research to improve the application of Level Distribution feature . W e will perform more experiments to verify the robust ness and effectiveness of Level Distribution feature in m ore languages . More features will be introduced into our system. For level distribution law, we will explore more r ational and scientific explanation s applications .

This work was supported by the National Natural Science Foundation of China under Grant 91546121, 61202247, 71231002 and 61472046; EU FP7 IRSES MobileCloud Project (Grant No. 612212); the 111 Project of China under Grant B08004; Engineering Research Center of Information Networks, Ministry of Education; Beijing Institute of Scien ce and Technology Information; CapInfo Company Limited.

