 Recent work on statistical models for spoken di-alogue systems has argued that Partially Observ-able Markov Decision Processes (POMDPs) provide a principled mathematical framework for modeling the uncertainty inherent in human-machine dialogue (Williams, 2006; Young, 2006; Williams and Young, 2007). Briefly speaking, POMDPs extend the tra-ditional fully-observable Markov Decision Process (MDP) framework by maintaining a belief state , ie. a probability distribution over dialogue states. This enables the dialogue manager to avoid and recover from recognition errors by sharing and shifting prob-ability mass between multiple hypotheses of the cur-rent dialogue state. The framework also naturally incorporates n-best lists of multiple recognition hy-potheses coming from the speech recogniser.
Due to the vast number of possible dialogue states and policies, the use of POMDPs in practical dia-logue systems is far from straightforward. The size of the belief state scales linearly with the number of dialogue states and belief state updates at every turn during a dialogue require all state probabilities to be recomputed. This is too computationally intensive to be practical with current technology. Worse than that, the complexity involved in policy optimisation grows exponentially with the number of states and system actions and neither exact nor approximate al-gorithms exist that provide a tractable solution for systems with thousands of states. The Hidden Information State (HIS) dialogue man-ager presented in this demonstration is the first train-able and scalable dialogue system based on the POMDP model. As described in (Young, 2006; Young et al., 2007) it partitions the state space using a tree-based representation of user goals so that only a small set of partition beliefs needs to be updated at every turn. In order to make policy optimisation tractable, a much reduced summary space is main-tained in addition to the master state space. Policies are optimised in summary space and the selected summary actions are then mapped back to master space to form system actions. Apart from some very simple ontology definitions, the dialog manager has no application dependent heuristics.

The system uses a grid-based discretisation of the Figure 1: The HIS Demo System is a Tourist Infor-mation application for a fictitious town state space and online -greedy policy optimisation. While this offers the potential for online adaptation with real users at a later stage, a simulated user is needed to bootstrap the training process. A novel agenda-based simulation technique was used for this step, as described in (Schatzmann et al., 2007). The HIS demo system is a prototype application for the Tourist Information domain. Users are assumed to be visiting a fictitious town called  X  X asonville X  (see Fig. 1) and need to find a suitable hotel, bar or restaurant subject to certain constraints. Exam-ples of task scenarios are  X  X inding a cheap Chinese restaurant near the post office in the centre of town X  or  X  X  wine bar with Jazz music on the riverside X  . Once a venue is found, users may request further in-formation such as the phone number or the address.
At run-time, the system provides a visual display (see Fig. 2) which shows how competing dialogue state hypotheses are being ranked. This allows de-velopers to gain a better understanding of the inter-nal operation of the system. In a recent user study the demo system was evalu-ated by 40 human subjects. In total, 160 dialogues were recorded with an average Word-Error-Rate of 29.8%. The performance of the system was mea-sured based on the recommendation of a correct venue and achieved a task completion rate of 90.6% with an average number of 5.59 dialogue turns to completion (Thomson et al., 2007).
 Figure 2: A system screenshot showing the ranking of competing dialogue state hypotheses
The results demonstrate that POMDPs facilitate design and implementation of spoken dialogue sys-tems, and that the implementation used in the HIS dialogue manager can be scaled to handle real world tasks. The user study results also show that a simulated user can be successfully used to train a POMDP dialogue policy that performs well in ex-periments with real users. The demo system and related materials are accessi-ble online at our website
