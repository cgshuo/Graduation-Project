 Category hierarchies often evolve at a much slower pace than the documents reside in. With newly available documents kept adding into a hierarchy, new topics emerge and documents within the same category become less topically cohesive. In this paper, we pro-pose a novel automatic approach to modifying a given category hierarchy by redistributing its documents into more topically cohe-sive categories. The modification is achieved with three operations (namely, sprout , merge , and assign ) with reference to an auxiliary hierarchy for additional semantic information; the auxiliary hierar-chy covers a similar set of topics as the hierarchy to be modified. Our user study shows that the modified category hierarchy is se-mantically meaningful. As an extrinsic evaluation, we conduct ex-periments on document classification using real data from Yahoo! Answers and AnswerBag hierarchies, and compare the classifica-tion accuracies obtained on the original and the modified hierar-chies. Our experiments show that the proposed method achieves much larger classification accuracy improvement compared with several baseline methods for hierarchy modification.
 H.3.3 [ Information Storage and Retrieval ]: Information Filtering Category Hierarchy, Hierarchy Maintenance, Classification
With the exponential growth of textual information accessible, category hierarchy becomes one of the most widely-adopted and e ff ective solutions in organizing large volume of documents. Hi-erarchy provides an organization of data by di ff erent levels of ab-straction, in which each node (or category) represents a topic that is shared by the data in it. The connection between two nodes denotes supertype-subtype relation. Examples include Web directories pro-vided by Yahoo! and Open Directory Project (ODP), hierarchies for community-based question-answering services by Yahoo! An-swers (YA) and AnswerBag (AB), product hierarchies by online retailers like Amazon and eBay, as well as the hierarchies for news browsing at many news portal websites. Figure 1 shows a small portion of Yahoo! Answers hierarchy. Questions in the same cate-gory are usually relevant to the same topic.

Hierarchy enables not only easy document browsing, but also searching of the documents within user defined categories or sub-trees of categories. Additionally, hierarchy information can be uti-lized to enhance retrieval models to improve the search accuracy [4]. On the other hand, users X  information needs can only be satisfied with the documents accessible through the hierarchy (but not the category hierarchy itself). That is, the usefulness of a hierarchy heavily relies on the e ff ectiveness of the hierarchy in properly or-ganizing the existing data, and more importantly accommodating the newly available data into the hierarchy. Given the fast growth of text data, continuously accommodating large volume of newly available text data into a hierarchy is nontrivial. Automatic text classification techniques are often employed for e ffi cient catego-rization of newly available documents into category hierarchies. However, hierarchy often evolves at a much slower pace than its documents. Two major problems often arise after adding many documents into a hierarchy after some time.
These two problems not only hurt user experiences in accessing information through the hierarchy, but also result in poorer clas-sification accuracy for the classifiers categorizing newly available documents because of the less topically cohesive categories [15]. Consequently, the poorer classification accuracy further hurts user experience in browsing and searching documents through the hi-erarchy. This calls for category hierarchy maintenance , a task to modify the hierarchy to make it better reflect the topics of its doc-uments, which in turn would improve the classification accuracy . Although a category hierarchy is relatively stable, many websites have modified or adjusted their hierarchies in the past. In May 2007, Yahoo! Answers added a new category Environment into her hierarchy, and added several categories like Facebook and Google under Internet later. By comparison, eBay adjusted her hierarchy more frequently, because there always emerge new types of items, like tablets and eReaders.

Hierarchy modification is nontrivial. Manual modification of category hierarchy is a tedious and di ffi cult task, because it is hard to detect the semantic changes as well as the newly emerged topics. This motivates the data-driven automatic modification of a given hierarchy to cope with semantic changes and newly emerged topics. This is a challenging task because of at least two reasons, among others. First, the resultant modified category hierarchy (hereafter called modified hierarchy for short) should largely retain the se-mantics of the existing hierarchy and keep its category labels se-mantically meaningful. Second, the categories in the modified hi-erarchy shall demonstrate much higher topical cohesiveness, which in turn enables better classification accuracy in putting new docu-ments into the modified hierarchy.

To the best of our knowledge, very few work has addressed the hierarchy modification problem (see Section 2). Tang et al. propose a novel approach to modifying the relations between categories aiming to improve the classification accuracy [17]. However, their proposed method does not change the leaf categories of the given hierarchy, and thus cannot solve the aforementioned problems. For example, the method may move the leaf category Petroleum to be child category of Politics . However, it is more reasonable to par-tition the documents in Petroleum into two categories: one being the child category of Geography , and the other child category of Politics . The method [17] fails to do so since it is unable to detect the newly emerged hidden topic "Petroleum politics".

In this paper, we propose a data-driven approach to modify a given hierarchy (also called as the original hierarchy) with ref-erence to an auxiliary hierarchy using three operations (namely, sprout , merge , and assign ). An auxiliary hierarchy is a category hierarchy that covers a similar set of topics as does the given hier-archy ( e.g., the Yahoo! hierarchy and ODP can be used as auxiliary hierarchy to each other). Similar to the concept of bisociation [8], our approach discovers finer and more elaborate categories (also known as hidden topics) by projecting the documents in the given hierarchy to the auxiliary hierarchy. This operation, similar to a cross-product operation between the categories from the given hi-erarchy and the categories from the auxiliary hierarchy, is named sprout 1 . The similar hidden topics are then merged to form new categories in the modified hierarchy. The assign operation rebuilds the parent-child relations in the modified hierarchy. The category labels in the modified hierarchy are either borrowed from or gen-erated based on both the original and the auxiliary hierarchies. We emphasize that the reuse of category labels from original and aux-iliary hierarchies largely ensures semantically meaningful category labels in the modified hierarchy. When such an auxiliary hierar-chy is unavailable, the given hierarchy can be used as an auxiliary hierarchy. Because of the three operations ( i.e., sprout , merged , and assign ), we name our approach the SMA approach. The main contributions are summarized as follows. 1) We propose a novel data-driven approach SMA to automati-cally modify a category hierarchy making it better reflect the topics of its documents. The proposed approach exploits the semantics of the given hierarchy and an auxiliary hierarchy, to guide the modifi-cation of the given hierarchy. 2) We evaluate the proposed approach using data from three real-world hierarchies, Yahoo! Answers, Answerbag, and ODP. The user study shows that the modified hierarchy fits with the data bet-ter than the original one does. As we argue that the categories in the modified hierarchy are more topically cohesive compared to the original hierarchy, we employ text classification as an extrin-sic evaluation. Our experimental results show that the classifiers trained on the modified hierarchy achieve much higher classifica-tion accuracy (measured by both macro-F 1 and micro-F 1 classifier built on the original hierarchy, or the classifiers modeled on the hierarchies generated by three baseline methods, including the state-of-the-art method in [17] and the hierarchy generation method in [2].

The rest of this paper is organized as follows. Section 2 surveys the related work. We describe the research problem and overview the proposed approach in Section 3. The three operations are de-tailed in Section 4. The experimental evaluation and discussion of the results are presented in Section 5. Finally, we conclude this paper in Section 6. Hierarchy Generation . Hierarchy generation focuses on extract-ing a hierarchical structure from a set of categories, each containing a set of documents. The generation process can be either fully au-tomatic [2,5,11] or semi-automatic [1,7,22]. The semi-automatic approaches involve interaction with domain experts in the hierarchy generation process. In the following, we review the fully automatic approaches in more detail.

Aggarwal et al. use the category labels of documents to super-vise hierarchy generation [2]. They first calculate the centroids of all categories and use them as the initial seeds. Similar categories are merged and clusters with few documents are discarded. The process is iterated to build the hierarchy. User study is employed to evaluate the quality of the generated hierarchy.

Punera et al. utilizes a divisive hierarchical clustering approach, which first splits the given set of categories into two sets of cate-gories, and each such set is partitioned recursively until it contains only one category [11].

An algorithm for generating hierarchy for short text is proposed by Chuang et al. [5]. They first create a binary-tree hierarchy by hierarchical agglomerative clustering, and then construct a multi-way-tree hierarchy from the binary-tree hierarchy. They use both classification measurement and user evaluation to evaluate the gen-erated hierarchy.

Recently, Qi et al. employ genetic algorithms to generate hier-archy [12]. Given a set of leaf categories, a group of hierarchies are randomly generated as seeds, and genetic operators are applied to each hierarchy to generate new ones. The newly generated hi-erarchies are evaluated and the hierarchies with poor classification accuracy are removed. The process is repeated until the classifica-tion accuracy is not improved.

Di ff erent from hierarchy generation which assumes a set of cat-egories as input, our hierarchy modification method takes a hierar-chy as the input. Hierarchy generation does not change the given categories hence it cannot solve the structure irrelevance problem. Hierarchy Modification . Tang et al. present a method of modi-fying a hierarchy to improve the classification accuracy [17]. The method introduces three operations. The promote operation lifts a category to upper level; the merge operation generates a new par-ent for a category and its most similar sibling; the demote opera-tion either demotes a category as a child of its most similar sibling, or makes the sibling a child of the category. For each category in the given hierarchy, promote operation is tested, followed by merge and demote operations, in a top-down manner. The opera-tion comes into e ff ect if it can improve the classification accuracy. The approach iterates the process until no improvement can be ob-served or some criterion is met. In experiments, this method out-performs clustering-based hierarchy generation method in terms of classification accuracy. However, this method does not change the leaf categories, leaving the topically incohesive leaf categories un-touched. In addition, the method [17] has a high time-complexity. Due to the high time complexity of the method [17], Kiyoshi et al. propose an approach [10] to addressing the e ffi ciency issue. Discussion. With the existing work on either hierarchy generation or hierarchy modification, the leaf categories in the modified hierar-chy ( i.e., either generated or modified) remain unchanged. Clearly, without changing leaf categories, the topical incohesiveness among documents in the same leaf category remains unaddressed. Conse-quently, the likely poorer classification accuracy for these topically incohesive categories results in poorer document organization in the hierarchy. In this paper, we therefore propose an automatic ap-proach to modify a given hierarchy where the leaf categories could be split or merged so as to better reflect the topics of the documents in the hierarchy.
We observe that each category in a hierarchy may contain sev-eral "hidden topics", each of which is topically cohesive, e.g., cat-egory Computer contains hidden topics like Internet Programming , Operating Systems , etc. With more documents adding to a cate-gory hierarchy, new "hidden topics" emerge within a single cate-gory leading to topical incohesiveness among its documents (see Section 1). Our proposed approach, therefore, aims to find the hid-den topics within each category and then sprout categories based on its hidden topics, merge similar hidden topics to form new cate-gories, and then assign the parent-child relation among categories. We name our approach SMA after its three major operations.
The key challenges in the approach include: (i) How to detect the "hidden topics" at the appropriate granularity? (ii) How to eval-uate the similarity between "hidden topics"? and (iii) How to as-sign the parent-child relation between the unmodified and modified categories? Further, recall from Section 1, the modified hierarchy has to largely retain the semantics of the existing hierarchy, with meaningful category labels and topically cohesive categories. In the following, we give a high-level overview of the SMA approach and then detail the three major operations in the next Section.
The framework of our SMA algorithm is illustrated in both Fig-ure 2 and Algorithm 1, where H c is the category hierarchy to be modified, H n is the modified hierarchy, H n is the intermediate hi-Algorithm 1 : SMA algorithm for hierarchy modification Input : H c : category hierarchy to be modified Output : H n : modified category hierarchy
H h  X  number of levels of H c ; foreach Level from 2 to h of H n do
H n  X  Relabel ( H c , H a , H return H n erarchy during the modification process, and H a is the auxiliary hierarchy.
 Auxiliary Hierarchy . Briefly introduced in Section 1, an auxiliary hierarchy H a is a hierarchy covering similar topics as the given hi-erarchy H c . For example, Yahoo! hierarchy and ODP hierarchy can be auxiliary hierarchy to each other. Similarly, Yahoo! An-swers and AnswerBag can be auxiliary hierarchy to each other.
The auxiliary hierarchy H a plays an essential role in finding hid-den topics. Note that the hidden topics are not readily present in the auxiliary hierarchy, and our approach does not simply use the structure of auxiliary hierarchy as part of the modified hierarchy. Instead, they contain semantics from both the original hierarchy and the auxiliary hierarchy. We use the following example to il-lustrate. Suppose that the original hierarchy has two categories, Action movie and Comedy movie , and the auxiliary hierarchy con-tains two categories America and Asia . Our approach will find that Action movie has two hidden topics, namely American action movie and Asian active movie ; Comedy movie also has two hidden topics, namely American comedy movie and Asian comedy movie .

The auxiliary hierarchy also plays an important role in guiding the merge operation, which is to merge similar hidden topics to generate the categories of the modified hierarchy. Continue with the earlier example, after merging the generated hidden topics, we may get new categories X  American movie and Asian movie (if "ac-tion vs. comedy" is evaluated to be less discriminative compared with "American vs. Asian"). The semantics of the hierarchy to be modified, together with the semantics of the auxiliary hierarchy, will be exploited to define the similarity between hidden topics.
Validated in our experiments (Section 5), our approach is equally applicable when the original hierarchy H c is used as the auxiliary hierarchy to itself.
 Algorithm Overview . Shown in Figure 2 and Algorithm 1, H is first initialized to H c (line 1). In a top-down manner, the SMA algorithm modifies the hierarchy level by level. Note that the root category is the only category at level 1. Starting from level 2, for each category C i in this level, the documents contained in C jected to the auxiliary hierarchy H a . A set of categories from each of which contains a reasonable number of documents origi-nally from C i is identified to represent C i  X  X  hidden topics (line 5). The two parameters, minimum coverage ratio  X  and maximum loss ratio  X  , adjust the number of hidden topics. New finer categories are then sprouted from C i according to the hidden topics and the documents in category C i are assigned to these finer categories (or hidden topics) (line 6). Given the expected number of categories n on level (line 7), the merge operation forms n number of new categories on level of the intermediate hierarchy H n (line 8). If the current level is not the lowest level in the hierarchy, the parent-child relations between the modified categories and the unmodified categories on the next level are assigned (line 9). The last step in the SMA algorithm is to generate category labels with reference to both the original and auxiliary hierarchies (line 10). We detail the three operations to address the challenges in the SMA framework ( i.e., to identify hidden topics, evaluate the simi-larity between hidden topics, and assign the parent-child relation).
The sprout operation first discovers the hidden topics for the doc-uments in a category C i and then sprouts the category. Without loss of generalization, a leaf category is represented by all documents belonging to the category; a non-leaf category is represented by all documents belonging to any of its descendent categories.
Ideally, for a category we find a set of its hidden topics, which are comprehensive and cohesive, and have no overlap. This is however a challenging task. We proceed to give an overview of the proposed method. Given a category C i in the intermediate hierarchy ing the modification process (see Algorithm 1), we assign all its documents into the categories of the auxiliary hierarchy H get a set of candidate categories from H a in a tree-structure. Each candidate category contains a number of documents from C i with the consideration of both cohesion and separation, we select a set of categories from the tree as hidden topics. The selection pro-cess is modeled as an optimization problem. We now elaborate the details.
 Document Projection . To assign documents from C i to H a represent a document by its word feature vector, and a category in
H a by its centroid vector. Based on cosine similarity between the document and the centroids, we recursively assign each docu-ment d  X  C i to H a from its root to a leaf category along a single path of categories. If a good number of documents from C i signed to a category C a in H a , then the topic of C a is relevant to C , and the semantics of C a can be used to describe a hidden topic of C i . Thus, multiple categories in C a can be identified to describe all hidden topics of C i . For example, large number of documents from category Programming assigned into two categories Security and Network in an auxiliary hierarchy, implies that Programming has two hidden topics: Network Programming and Security Pro-gramming . We have also tried to build a classifier on H a documents from C i to H a using Naive Bayes and support vector machine, respectively, and the set of generated hidden topics is al-most the same.
 The process of assigning documents from a category C i in categories in H a is called projection . We denote the set of docu-ments projected from category C i to category C a by  X  ( C C is a leaf category, then  X  ( C i  X  C a ) denotes the set of documents from C i that are projected into C a ;if C a is a non-leaf category, then  X  ( C i  X  C a ) denotes the set of documents projected into any of the descendent leaf categories of C a in H a .
 Candidate Topic Tree . Based on the projection, we select cate-gories from H a to represent the hidden topics of C i . A selected category can be either a leaf category or a non-leaf category. Be-fore describing the selection process, we introduce the notions of major category and minor category . Let  X  denote the minimum coverage ratio parameter.

D efinition 1( Major Category) . A category C a from H a is a major category for category C i if |  X  ( C i  X  C a ) | / |
D efinition 2( Minor Category) . A category C a from H a is a minor category for category C i if |  X  ( C i  X  C a ) | / | For example, suppose  X  = 15%. As shown in Figure 3, category C is projected to the categories in H a . In the left tree, in which each number besides a node represents the percentage of documents of C projected to the node, the nodes in dark color are major cate-gories while the others are minor categories.

Naturally, only the major categories are considered candidate categories to represent hidden topics of C i because a good num-ber of documents in C i are projected into them. However, not all major categories need to be selected because of two reasons. First, let C p be the parent of a major category C a . By definition, the parent of a major category is also a major category. Selecting both C C would lead to semantic overlap. Second, assume all C p  X  X  other child categories are minor categories, but altogether those minor categories contain a large number of documents. Then selecting C but not C p would lead to a significant loss of documents from C (hence semantic loss). We therefore define the notion of loss ratio .
D efinition 3( Loss Ratio) . The loss ratio of a leaf category is defined as 0. For a non-leaf category C a , let C  X  a be the set of minor categories among C a  X  X  child categories. The loss ratio of C respect to C i , the category being projected, is the ratio between the projected documents in all its child minor categories and C projected documents, i.e., C  X  X 
We set a threshold maximum loss ratio  X  . After projecting doc-uments from C i to categories in H a , we only keep the major cate-gories whose parent X  X  loss ratio is smaller than  X  . Note that, if a non-leaf category is not selected in the above process, the subtree rooted at this category is not selected. After the selection, we obtain a sub-hierarchy from H a containing only eligible major categories, which is called candidate topic tree for C i , denoted by
For example, suppose  X  = 30%. The candidate topic tree for C is shown on the right hand side of Figure 3. Although node C a major category, it is not part of the candidate topic tree since the loss ratio ((10% + 10%) / 50% = 40%) of its parent node C than  X  . Hidden Topic Selection . We next present how to choose a set of nodes from T C i to represent hidden topics of C i . Ideally, we expect the hidden topics to be comprehensive but not overlap with each other. Hence, we use tree-cut to define the selection [18].
D efinition 4( Tree-Cut) . A tree-cut is a partition of a tree. It is a list of nodes in the tree, and each node represents a set of all leaf nodes in a subtree rooted by the node. The sets in a tree-cut exhaustively cover all leaf nodes of the tree, and they are mutually disjoint.

There exist many possible tree-cuts for T C i to generate hidden topics. Two example tree cuts for the candidate topic tree in Fig-to choose the tree-cut such that each resultant hidden topic (cate-gory) is cohesive and well separated from other categories in the tree-cut. In the following, we prove that the tree-cut containing only leaf nodes of the candidate topic tree satisfies this require-ment. Note that a leaf node in T C i is not necessary a leaf category in
H a . For example, in Figure 3, C topic tree, but not a leaf category in the auxiliary hierarchy. We proceed to show the proof. We first define the Sum of Square Error (SSE) of cohesion for a category C a .
 where d is a document and c a is the centroid of category C Given a set of categories { C a } (1  X  a  X  k ), the Total-SSE and Total Sum of Square Between (Total-SSB), denoted by  X  E and respectively, are  X  E = k a = 1 SSE ( C a ) and  X  B = k a where c is the centroid of documents in all categories { C verified that, given a set of documents, the sum of  X  E and separation is equivalent to minimizing cohesion error. We therefore formulate the problem of selecting categories from T C i to represent hidden topics for category C i as following: This problem can be reduced to the maximum flow problem by viewing T C i as a flow network. Thus, it can be solved directly by Ford-Fulkerson method [6]. However, its complexity is relatively high. Note that we need to solve the optimization problem for every category in the original hierarchy, and thus an e ffi cient algorithm is essential.
 Lemma 1 : The SSE of a category is not smaller than the Total-SSE of its child categories.
 Proof : Suppose there is a category C p with k child categories For a child category C i , the Sum of Square Distance (SSD) of its mum value when x = 1 | C Thus, when x is the mean of data in C i (or c i ), the SSD of C comes SSE of C i , and gets its minimum value. One step further, we have where c p is the mean of data of C p . This demonstrates that the SSE of C i is smaller than the SSD of data of C i to the overall mean, and this result leads to This demonstrates that the SSE of a category is not smaller than the Total-SSE of its child categories.
 Procedure ProjectedCategories Input : C i : the category to be sprouted
Result :  X  C i []: the list of projected categories for C repeat until No more unprocessed category in  X  C i [] return  X  C i []
Lemma 1 enables us to use an e ffi cient method to solve Eq.1 as follows. According to Lemma 1, specializing a category by its child categories can reduce Total-SSE. That is, among all possible tree-cuts in T C i , the cut that contains only leaf categories has the minimum value of Total-SSE.

In summary, for a category C i in H n , we build a candidate topic tree T C i and the leaf nodes of T C i are used to represent the hidden topics of C i . The pseudocode is given in Procedure 2 Projected-Categories . As discussed, according to Lemma 1, we only need the leaf nodes of the candidate topic tree T C i as the result. Instead of explicitly building T C i and then finding T C i  X  X  tree cut containing only leaf nodes, we find T C i  X  X  leaf nodes directly in our procedure. More specifically, we start from the root category of H a down manner (the root node is a major category by definition as its coverage ratio is 1). Each time we get a unprocessed categories C from the list of projected categories  X  C i [], and check its child cate-gories (lines 3-4). The major categories among the child categories are put into a major category list (lines 6-8) for further testing on loss ratio. If the loss ratio of C a is smaller than maximum loss ratio  X  , then C a is replaced by its child major categories (lines 9-11); oth-erwise, C a is selected as a candidate category (line 13). We iterate the process until all major categories are processed (line 14).
For a category C i of H n , we sprout it based on the projected cate-gories  X  C i returned by Procedure ProjectedCategories . Recall that each of the projected category C a  X   X  C i represents a hidden topic of C and contains a good number of documents projected from C i  X  ( C i  X  C a ). We sprout C i with |  X  C i | number of categories. How-ever, not all documents from C i are contained in all these newly sprouted categories, i.e., C a  X   X  C documents in C i but not contained in any of the newly sprouted cat-egories, we assign them to their nearest sprouted categories. As the result, each document in C i is now contained in one and only one sprouted category of C i . Figure 4: SMA operations by example. The hidden topics and sprouted categories for a category of the original hierarchy are in the same color. The Network and Programming categories have 3 and 2 hidden topics, respectively, leading to 5 sibling sprouted categories. These 5 categories are merged into 3 cat-egories and the category WAN is reassigned to 2 of the merged categories.
 Example 4.1: Shown in Figure 4 2 , suppose after applying pro-cedure ProjectedCategories , we find Network is projected to Se-curity , Protocol , and Cable . According to the three hidden topics, we sprout Network into three categories Network Security , Network Protocol , and Network Cable .

The sprout operation may be reminiscent of the work on hierar-chy integration, aiming to integrate a category from a source hierar-chy into similar categories in the target hierarchy, which has a dif-ferent purpose from our mapping. Most of proposals (e.g., [3,21]) on hierarchy integration employ a hierarchical classifier built on the target hierarchy to classify each document in the source hierarchy into a leaf node of the target hierarchy, which is too fine a granular-ity to represent hidden topics as in our approach. Frameworks that can map a category to categories on proper levels in target hierarchy are proposed ( e.g., [19]). However, they do not take the cohesion and separation between mapping categories into account, which are essential to find good hidden topics in our approach. Thus, they cannot be applied to our work.
The sprout operation in Section 4.1 generates a set of sprouted categories, each representing a hidden topic. The merge operation aims to combine the newly sprouted categories with similar hidden topics.

Suppose we are now working on level of the intermediate mod-ified hierarchy H n and we have a set of sprouted categories orig-inated from the categories on level . Our task is to merge some of these sprouted categories such that the number of resultant cat-egories on level is the same as before (i.e., n ). Note that the number of resultant categories can also be specified by users. To ease the presentation, the modified hierarchy has the same size as the given hierarchy in our discussion.

During merge, we need to consider an important constraint  X  we can only merge categories under the same parent category. Thus, existing clustering algorithms need to be modified to accommo-date such a constraint. Another key issue here is how to define the similarity between two sprouted categories by considering their se-mantics enclosed in H c and H a . In the following, we first define a similarity measure and then describe our merge method.

We consider two aspects when defining the similarity for a pair of sprouted categories C 1 and C 2 on level : (i) the distribution of their documents over categories of H c and H a , and (ii) the similarity between the categories within H c and H a , respectively. Let L c be the set of categories on level in the original hierarch H , L s be the set of categories sprouted from L c , and L a set of projected categories in auxiliary hierarchy representing the hidden topics of the categories in L c . That is, L a = C For a sprouted category C s  X  X  s , its document distribution over L c is defined to be the ratios of its documents in each of the cate-gories in L c . That is, the document distribution of C s eled as a |L c | -dimensional vector v cs . The j -th element of v where C j is the j -th category of L c . Similarly, we get the data dis-tribution vector v as for C s over L a based on the ratio of documents in C s projected to each of the categories in L a . Because v v as usually have di ff erent dimensionality for di ff erent sprouted cat-egory C s  X  X , we extend v cs to be |H c | -dimensional (each category is one dimension) by filling up zeros for corresponding categories in H c but not in L c . Similarly v as is extended to be |H a |
We use two matrices M c , M a to represent the similarity between categories of H c and H a , respectively. M c is a |H c | and M a is a |H a | -by-|H a | matrix. Each element m ij represents the similarity in the corresponding hierarchy between a pair of categories C i and C j , which is defined by Inverted Path path between C i and C j in the hierarchy.

Considering both document distribution and structural similar-ity from the two hierarchies, the similarity between two sprouted categories C 1 and C 2 on level of H n is defined as: This similarity definition considers both the similarity estimated based on H c and the similarity estimated based on H a . With simi-larity between two sprouted categories defined, we proceed to detail the merge operation.

We first explain the notion of sibling sprouted category through an example. Let C i 1 and C i 2 be the two categories sprouted from category C i , and C j 1 and C j 2 be the two categories sprouted from C If C i and C j in H m are both children of category C p , then naturally, all the newly sprouted categories C i 1 , C i 2 , C j 1 , C C . These four example categories are known as sibling sprouted categories. All the five sprouted categories shown in Figure 4 are sibling sprouted categories.

The merge operation is as follows. We first calculate the sim-ilarity between sibling sprouted categories on level . Then, we pick up the pair of categories with the largest similarity, and merge them into a category, and recompute its similarities with its sib-ling sprouted categories. The process iterates until the number of remaining categories on equals n , the number of categories on level of the original hierarchy H c . When all the sibling sprouted categories under the same parent node are merged into a single cat-egory, we shrink the single category into its parent node. Note that we cannot merge two sprouted categories on level if they have di ff erent parent node.
 Example 4.2: Recall Example 4.1. We sprout Network into three categories Network Security , Network Protocol , and Network Ca-ble . Suppose there is another category Programming on the same level of Network and sprouted into Security Programming , and Pro-tocol Programming (see Figure 4). Based on the similarity, Network Security and Security Programming are merged together (both are about the Security topic), and Network Protocol and Protocol Pro-gramming are merged to generate a new category about protocol. After modifying categories (by sprout and merge) on level of H n , the original parent-child relations between the categories on level and the categories on next level + 1 do not hold any longer. Hence we need to reassign the parent-child relation.

Based on the fact that a non-leaf category of a hierarchy sub-sumes the data of all its descendants, we rebuild the children for each of the modified categories on by checking document contain-ment. If the documents of a category on level are also contained in a category on level + 1, then the latter category is assigned to be the children of the former category. In other words, for each cate-gory C on , we calculate the intersection of documents between C and the categories on + 1. The intersections form new children for category C . Because one category has only one parent category, if a category has intersections with more than one category on level , the category will be split into multiple categories, each containing the intersection with one category on level .
 Example 4.3: Recall Example 4.2. Suppose WAN was a child cat-egory of Network before sprout (see Figure 4). After sprout and merge, Network no longer exists and WAN lost its parent. We com-pare the documents of WAN and the two newly formed categories after merge ( i.e., Network Security &amp; Security Programming and Network Protocol &amp; Protocol Programming ). If WAN has overlap with both categories, then WAN have two hidden topics (about se-curity and protocol). Thus, we divide WAN into two categories and assign them to di ff erent parent nodes, shown in Figure 4.
Unlike most of previous work, our approach is able to automati-cally generate readable labels for every modified category. By pro-jecting documents from H n to H a , we can consider the three hier-archies H n , H c and H a , which contain the same set of data. For every document in H n , we trace its labels in H c and H a them together as the label of the document; the semantic of the new label is the intersection of semantics of its two component labels. We then aggregate such labels for all documents in a category of H , and use them as candidate labels for the category. The candi-date labels for a category are ranked according to the proportion of documents in their corresponding original categories from H . In this paper, the top-1 ranked label is chosen.

The labels generated in this way are mostly readable and seman-tically meaningful, as reflected in our user study (see Section 5.3) and case study (see Section 5.4). Nevertheless, a manual verifi-cation of the labels for the newly generated categories can be em-ployed when the proposed technique is used in real applications.
We designed two sets of experiments. The first set of experi-ment, similar to that in [17], is to evaluate whether the modified hierarchy improves the classification accuracy. Discussed in Sec-tion 1, if a category hierarchy better reflects the topics of its con-tained documents and each category in the hierarchy is topically cohesive, then better classification accuracy is expected than that on a hierarchy with less topically cohesive categories. The second set of experiments employs a user study to manually evaluate the semantic quality of the modified hierarchy following the settings in [2,5]. Finally, we report a case study comparing a part of Yahoo! Answers hierarchy with its modified hierarchy. We use data from three real-world hierarchies: Yahoo! Answers, AnswerBag, Open Directory Project, denoted by H YA , H AB Number of documents 421,163 148,822 203,448 Number of leaf nodes 75 195 460 Number of non-leaf nodes 40 70 98 Height 454 H
ODP , respectively. Since the modified category hierarchy contains adi ff erent set of leaf nodes, the labels for documents given in the original dataset do not stand in modified hierarchy. Manual anno-tation of documents in the modified hierarchy is therefore unavoid-able. To make the annotation manageable, we selected the doc-uments from two major topics Sports and Computers from these three hierarchies (because the annotators are familiar with both top-ics). Nevertheless, the number of documents in the two major top-ics in the three hierarchies ranges from 148,822 to 421,163, and the number of categories ranges from 115 to 558. These numbers are large enough for a valid evaluation. Table 1 reports the statistics on the three hierarchies.
 tains 421,163 documents (or questions) from Sports and Comput-ers &amp; Internet categories.

H AB : We collected 148,822 questions from Recreation &amp; Sports and Computers categories from AnswerBag to form H AB . Cate-gories with fewer than 100 questions are pruned and all a questions are moved to their parent categories.

H ODP : The set of 203,448 documents from Sports and Comput-ers categories are collected 4 in H ODP . Categories containing fewer than 15 documents or located on level 5 or deeper are removed in our experiments.

The preprocessing of the documents in all three hierarchies in-cludes stopword removal and stemming. Terms occurred no more than 3 times across the datasets are also removed.
The proposed SMA algorithm modifies a category hierarchy to better reflect the topics of its documents, which in turn should im-prove the classification performance. Following the experimental setting in [17], we evaluate the e ff ectiveness of hierarchy modifi-cation by comparing the classification accuracies obtained by the same hierarchical classification model applied on the original cate-gory hierarchy and the modified hierarchy, respectively.
Another three methods for hierarchy modification are employed as the baselines, namely, Bottom Up Clustering (BUC), Hierarchi-cal Acclimatization (HA) [17], and Supervised Clustering (SC) [2]. Table 2 gives a summarized comparison of the three baselines with the proposed SMA, and Section 5.2.1 briefs the baseline methods.
The modified hierarchies by all the methods evaluated in this pa-per have the same size as the original hierarchy ( i.e., same number of levels, and same number of categories in each level). For each hierarchy modification method, we evaluate the percentage of clas-sification accuracy increment obtained by the same classification model ( e.g., Support Vector Machine) on the modified hierarchy over the original hierarchy. The classification accuracy is mea-sured by both micro-average F 1 (Micro-F 1 ) and macro-averaged F (Macro-F 1 ) [20]. The former gives equal weight to every document while the latter weighs categories equally regardless the number of documents in each category.

We remark that this is a fair evaluation for all the methods, each generating a hierarchy with the same size as that of the original Aspect / Methods BUC HA [17] SC [2] SMA
Utilize original hierarchy  X 
Change leaf category  X  X 
Utilize auxiliary hierarchy  X  X  X  Optional hierarchy, where the same classification method is applied to the modified hierarchies to evaluate the improvement of each modified hierarchy over the original one in terms of classification accuracy. Baseline 1: Bottom Up Clustering (BUC) . In this method, each leaf category is represented by the mean vector of its contained doc-uments. The categories are then clustered in a bottom-up manner using K-means to form a hierarchy.
 Baseline 2: Hierarchical Acclimatization (HA) . The HA algo-rithm is reviewed in Section 2, In simple words, it employs pro-mote, demote and merge operations to adjust the internal structure, but leaves the leaf nodes unchanged [17].
 Baseline 3: Supervised Clustering (SC) . Given a set of docu-ments with labels, SC first calculates the mean vector of each cat-egory as the initial centroid and then reassigns the documents to the categories based on the cosine similarity with their centroids. Then, similar categories are merged and minor categories are re-moved. These procedures are repeated, and during each iteration, a constant portion of features with smallest term-frequencies are set to zero (projected out) [2]. The process stops when the number of features left is smaller than a pre-defined threshold. This method cannot generate category labels. We take the most frequent words in a category to name it.
From the data of H YA , we randomly selected 500 questions as test data (used for classification evaluation with manual annota-tions). To evaluate the possible improvement in classification accu-racy, the same set of test documents are classified on the original (or unmodified) H YA , and the modified H nYA  X  X . Two classifiers, multi-nominal Naive Bayes (NB) and Support Vector Machine (SVM) classifiers are used as base classifiers for hierarchical classifica-tion. We build Single Path Hierarchical Classifier (SPH) [9] as it performs better than other hierarchical classification methods for question classification according to the evaluation [13]. In the train-ing phase of SPH, for each internal node of the category tree, SPH trains a classifier using the documents belonging to its descendent nodes. In the testing phase, a test document is classified from the root to a leaf node in the hierarchy along a single path. SMA Settings . Recall that SMA uses auxiliary hierarchy in the modification process. We evaluated SMA with three settings, to modify H YA using H YA , H AB , and H ODP as auxiliary hierarchy, re-spectively. The three settings are denoted by SMA YA | YA and SMA YA | ODP , respectively. The first setting is to evaluate the ef-fectiveness of using the original hierarchy as auxiliary hierarchy, and the last two are to evaluate the e ff ectiveness of using external hierarchies.
 Parameter Setting . Before evaluating the test documents on the modified hierarchies, we set the parameters required by SMA for hierarchy modification. Recall that SMA requires two parame-ters: minimum coverage ratio  X  and maximum loss ratio  X  . Usu-ally parameters are set using a development set or through cross-validation. In our case, however, there is no ground truth on how good a modified hierarchy is and manual assessment of every mod-ified hierarchy for parameter tuning is impractical. We therefore adopt a bootstrapping like approach described below.

After the test data selected, the remaining data is used for hierar-chy modification. We split the remaining data of H YA into 3 parts: P , P 2 , P 3 , and the proportion of their sizes is 12:3:1. Using P H
YA and a given auxiliary hierarchy, we obtain a modified hierar-chy H nYA . Naturally, all documents in P 1 have category labels from hierarchy H nYA . We then build a classifier using all documents in P and their labels from H nYA . The classifier classifies documents in P 2 and P 3 . Assume that the classifier gives reasonably good clas-sification accuracy, then all documents in P 2 and P 3 have their cate-gory labels assigned according to H nYA . With these labels, we can evaluate the classification accuracy of documents in P 3 by the clas-sifier built using P 2 on H nYA . Intuitively, if a hierarchy organizes documents than another hierarchy H 2 , then the classifier trained on H 1 is expected to have higher classification accuracy for P than a classifier built on H 2 . We then select the parameters lead-ing to the best classification accuracy for P 3 . In our experiments, the parameters ( i.e.,  X  and  X  ) set for SMA YA | YA , SMA SMA YA | ODP are (0.29 and 0.11), (0.17 and 0.17), (0.38 and 0.08), respectively.
 Test Data Annotation. With the chosen parameters, each SMA setting generated a modified hierarchy using P 1 as H YA and its cor-responding auxiliary hierarchy. The preselected 500 test questions are used as test data to fairly evaluate the modified hierarchies by the three SMA settings and the baseline methods. Recall that the 500 questions are not included in the three parts ( P 1 , P parameter setting. Because BUC and HA do not change the leaf categories, the original labels of the 500 questions remain applica-ble. For SC and SMA, both changing leaf categories, we invited two annotators to label the 500 questions to their most relevant leaf categories in the modified hierarchies. We synthesized the results of the annotators, and assigned the labels for questions. If two an-notators conflicted about a label, a third person made the final judg-Classification Results . Classification accuracy measured by Micro-F using NB and SVM as base classifiers for the six methods ( i.e., three baselines BUC, HA, SC, and the three SMA settings) on mod-ified hierarchies is reported in Figure 5(a). For comparison, the classification accuracy on the original (or unmodified) Yahoo! An-swers hierarchy is also reported under column named H YA . Fig-ure 5(b) reports Macro-F 1 .

As shown in Figures 5(a) and 5(b), all the three settings of SMA achieve significant improvement over the results obtained on the original hierarchy. For example, using NB as the base classifier, SMA YA | YA improves Micro-F 1 over the results on the original hier-archy by 41.0% and improves Macro-F 1 by 40.3%. NB achieves better accuracy than SVM probably because NB was used as the base classifier for parameter setting. The three baseline modifica-tion methods only slightly improve the classification accuracy over the original hierarchy and even deteriorate the accuracy in some cases. Recall that SC and SMA modify leaf categories while BUC and HA only modify internal structures of hierarchy without chang-ing leaf categories. All the methods that change leaf categories out-perform the methods that keep leaf categories unchanged. Note that SMA YA | YA significantly outperforms SC. One possible reason could be that SMA YA | YA utilizes the semantics of the original hierarchy in hierarchy modification while SC does not.

We observe that the auxiliary hierarchies employed by SMA have e ff ect on the classification accuracy of the modified hierarchy. Figure 5: Micro-F 1 and Macro-F 1 on the modified hierarchies by three baselines and three SMA settings, and on the original Yahoo! Answers hierarchy.
 Table 3: Classification accuracy on modifying AnswerBag Measure / Hierarchy H AB SMA AB | YA Improvement(%) Macro-F 1 (NB) 0.3444 0.5638 63.7% Macro-F 1 (SVM) 0.3691 0.4933 33.6% Micro-F 1 (NB) 0.4671 0.6669 42.8% Micro-F 1 (SVM) 0.4371 0.5697 30.3% Measured by Macro-F 1 , SMA YA | YA without using an external hier-archy slightly outperforms its counterpart SMA YA | AB or SMA which uses an external hierarchy; while in terms of Micro-F performs worse than do its counterparts.
In this set of experiments, SMA is used to modify the AnswerBag hierarchy. The main purpose is to evaluate whether SMA remains e ff ective when the size of the auxiliary hierarchy is smaller than the one to be modified. Specifically, we use H YA as auxiliary hierarchy to modify H AB and evaluate the classification accuracy as we did in the earlier set of experiments. Note that the H AB has 265 categories which is more than twice of the 115 categories contained in The parameters  X  and  X  were set as 0.17 and 0.08, respectively, using the parameter setting approach described earlier. The classi-fication accuracy is reported in Table 3. Observe that SMA proves the classification accuracy (Macro-and Micro-F 1 to 63%, compared with the result obtained before hierarchy mod-ification. This demonstrates that the proposed SMA approach is e ff ective for di ff erent hierarchies, even if the size of the auxiliary hierarchy is smaller than the hierarchy to be modified. A good category hierarchy must be semantically meaningful: (i) Its category labels should be easy to understand, facilitating data browsing; and (ii) Its category structure should reflect the topics of its data. We would like to note that it is challenging to evaluate these. We evaluate the modified hierarchy by SMA YA | AB through two types of user study by following the methods [2, 5], respectively. Table 4: Comparison on appropriateness of category labels
Table 5: Averaged scores of H YA and H nYA (by SMA YA | AB Through the study, we aim to quantify both the appropriateness of the category labels and the structure of the modified hierarchy. Category Labels . Following a similar setting as in [2], we ran-domly selected 100 questions from the labeled test set originated from Yahoo! Answers. For each question, we gave the path of the categories in H YA from the second level category to the leaf cat-egory, and similarly the category path from H nYA (by SMA We asked three students to annotate which category path better re-flects the topic of the question. Which hierarchy a category path was originated from was not provided to the annotators. Given a question, each volunteer is asked to rate each path from 1(lowest) to 5(highest) based on its quality. hen, we select one of the follow-ing choices based on the averaged ratings ( r YA and r nYA paths, respectively). (1) H nYA is better than H YA ,if r and r nYA &gt; r YA ; (2) H nYA is not as good as H YA ,if r (3)Both are equally good, if r nYA , r YA  X  [3 , 5] and r (4)Neither is good, if r nYA , r YA  X  [1 , 3). The statistics of the la-bels are reported in Table 4. The table shows that the number of questions having better labels in H nYA is larger than that in though for majority of questions, the category paths from the two hierarchy are equally good. This result also suggests that the gen-erated labels well reflects the content of categories.
 Category Structure . Following the evaluation approaches in [5], we evaluate the quality of Yahoo! Answers hierarchy and the mod-ified hierarchy by five measures. Cohesiveness : Judge whether the instances in each category are semantically similar. Since it is im-practical to read all questions in a large category, we randomly se-lect 50 questions from each category for cohesiveness evaluation. Isolation : Judge whether categories on the same level are discrimi-native from each other.We also use the 50 randomly selected ques-tions to represent each category. Hierarchy : Judge whether the concepts represented by the categories become finer from top to bottom. Navigation Balance : Judge whether the number of child categories for each internal category is appropriate. Readability : Judge whether the concept represented by each category is easy to understand.
 We invited three students to evaluate the two hierarchies, and H nYA (by SMA YA | AB ) and assigned scores ranging from 0 to 7 on each measure. The mean of the scores is reported in Table 5.
The cohesiveness of the modified hierarchy is better than the original one. A possible reason is that our approach detected the hidden topics and merged the most similar ones together. The iso-lation of the modified hierarchy is slightly better. This is probably because the proposed method takes isolation into consideration. To find out the reasons that caused the relatively low isolation of the original hierarchy, we get the list of categories with low scores from Figure 6: Portion of Yahoo! Answers hierarchy and its modi-fied hierarchy. the annotators. As an example, a number of questions that are re-lated to motor-cycling were put under Other -Auto Racing by their askers, resulting in low isolation between the two categories. The modified hierarchy does not deteriorate hierarchy quality, naviga-tion balance, and readability of the original hierarchy on average. In summary, the modified hierarchy is of high quality comparable to the original hierarchy generated by domain experts. As a case study, we select three categories Software , Internet and Hardware from Yahoo! Answers as an example to illustrate the dif-ferences before and after modifying H YA . The modified hierarchy H nYA is by SMA YA | AB utilizing AnswerBag as auxiliary hierarchy.
The two hierarchies are shown in Figure 6. We make the follow-ing observations: 1) Di ff erent from the original hierarchy, Software and Internet become three categories  X  Operating System &amp; Appli-cation Software , Internet &amp; E-mail and Internet Software . The third category is formed based on the overlapping part of the original two categories, which contains questions about instant messaging (IM) and blog software. This demonstrates that the proposed ap-proach can discover and detach the overlapping hidden topics. 2) Two pairs of categories of the original hierarchy, ( Laptops &amp; Note-books and Desktops ), and ( Printers and Scanners ), are merged into two categories in the modified hierarchy, because of the high sim-ilarity between the categories within each pair. This shows that categories with high overlap in semantics are merged. 3) For Hard-ware , some hidden topics are discovered and new categories are formed, like Storage and CPU &amp; Memory &amp; Motherboard , whose questions come from Desktops , Add-ons and Other -Hardwares in the original hierarchy. These newly formed categories are more isolated from each other.
Category hierarchy plays a very important role in organizing data automatically (through classifiers built on the hierarchy) or manu-ally. However, with newly available documents added into a hi-erarchy, new topics emerge and documents within the same cate-gory become less topically cohesive. Thus the hierarchies su from problems of structure irrelevance and semantic irrelevance, leading to poor classification accuracy of the classifiers developed for automatically categorizing the newly available documents into the hierarchy, which in turn leads to poorer document organization. To address these problems, we propose a novel approach SMA to modify a hierarchy. SMA comprises three non-trivial operations (namely, sprout , merge , and assign ) to modify a hierarchy. Experi-mental results demonstrate that SMA is able to generate a modified hierarchy with better classification accuracy improvement over the original hierarchy than baseline methods. Additionally, user study shows that the modified category hierarchy is topically cohesive and semantically meaningful. Quan Yuan would like to acknowledge the Ph.D. grant from the Institute for Media Innovation, Nanyang Technological University, Singapore. Gao Cong is supported in part by a grant awarded by Microsoft Research Asia and by a Singapore MOE AcRF Tier 1 Grant (RG16 / 10).
