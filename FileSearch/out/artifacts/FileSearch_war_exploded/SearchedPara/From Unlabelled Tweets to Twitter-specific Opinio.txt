 In this article, we propose a word-level classification model for automatically generating a Twitter-specific opinion lexicon from a corpus of unlabelled tweets. The tweets from the corpus are repre-sented by two vectors: a bag-of-words vector and a semantic vector based on word-clusters. We propose a distributional representation for words by treating them as the centroids of the tweet vectors in which they appear. The lexicon generation is conducted by training a word-level classifier using these centroids to form the instance space and a seed lexicon to label the training instances. Experi-mental results show that the two types of tweet vectors complement each other in a statistically significant manner and that our gener-ated lexicon produces significant improvements for tweet-level po-larity classification.
 I.2.7.7 [ Artificial Intelligence ]: Natural Language Processing X  Text Analysis Experimentation, Measurement Lexicon Generation; Sentiment Analysis; Twitter
Twitter 1 is a massive microblogging service in which users post short messages limited to 140 characters referred to as tweets. The large amount of personal opinions that is constantly generated on this platform has drawn increasing attention among the sentiment analysis research community.

The main challenge in analysing Twitter opinions is how to deal with the informal dialect used on this plattform, because it contains expressions such as acronyms, abbreviations, slang words, and mis-spelled words, that are not observed in traditional media [5].
Opinion lexicons, which are resources that associate words with sentiment polarities, play a central role in sentiment analysis ap-plications [11]. However, most existing opinion lexicons focus on formal English expressions, and are unsuitable for Twitter senti-ment analysis.

In this article, we propose a method for automatically generating a Twitter-oriented opinion lexicon from a collection of unlabelled tweets. We classify each word from a corpus into one of three different polarity classes: positive, negative, or neutral. The words are represented by vectors of attributes that are based on the context in which the words occur. We use a seed lexicon to label a sample of the words and train a linear classifier on the labelled instances. The fitted model is then used to classify the remaining unlabelled words.

Our approach based on word-level vectors takes the Distribu-tional Hypothesis [7] as inspiration, which states that words occur-ring in the same contexts tend to have similar meanings. We ex-ploit the short nature of Twitter messages to treat a whole tweet as a word X  X  context, and we model tweets as vectors calculated from the textual content. We calculate word-level vectors based on the centroids of the tweet vectors in which a word occurs. In essence, we are assuming that words exhibiting a certain polarity are more likely to be used in contexts expressing the same polarity than in contexts exhibiting a different one.

We study and compare two different vector space models for tweet-level representation. The first is a high-dimensional bag-of-words model using word frequencies as dimension values. The sec-ond, is a semantic representation based on word-clusters. We rely on the Brown clustering algorithm [2] to tag a tweet according to a sequence of word clusters and create cluster frequency vectors.
Previous approaches for Twitter-specific lexicon generation rely on collections of tweets that were previously labelled to sentiment classes using distant supervision [13, 20] or pre-trained classifiers [1]. In contrast, our approach takes a raw collection of tweets and a seed lexicon to perform the generation. To the best of our knowl-edge, this is the first lexicon generation model for tweets in which a word-level classifier is trained using features calculated from un-labelled corpora.

The remainder of this article is organised as follows. In Sec-tion 2, we review some previous work on opinion lexicon genera-tion. In Section 3, we formalise our word-level vector space mod-els. Our main experiments and results are presented in Section 4. The conclusions are discussed in Section 5.
Lexicon generation techniques normally rely on a small seed lex-icon which is expanded by exploiting word relations from two type of resources: a lexical database such as WordNet, or a corpus of documents. Methods based on WordNet consider semantic rela-tions such as synonyms, antonyms, [9, 10] or dictionary definitions [3, 4] to perform the expansion. As semantic databases cover a fixed vocabulary, they are not suitable for the Twitter dialect. On the other hand, corpus approaches exploit statistical patterns ob-served in document corpora. Thus, they can potentially be applied to any domain. Statistical patterns can be computed using different types of methods, such as conjunction relations between adjectives [8], latent semantic analysis [16], and pointwise mutual informa-tion (PMI) [16, 17]. Previous work on Twitter lexicon generation computes the PMI between words and tweet-level sentiment labels. The tweets are automatically labelled to polarity classes using ei-ther distant supervision [13, 20] or self-training [1]. Distant su-pervision methods rely on strong sentiment clues found in a mes-sage such as emoticons [13, 20] or hashtags [13] to label the mes-sages. Tweets where these clues are not observed are discarded. In the self-training approach [1], a message-level polarity classifier is trained from a corpus of manually labelled tweets and used to tag a large corpus of unlabelled tweets.
In this section, we describe the word vectors for lexicon gen-eration. These vectors are distributional representations [18] in which words are described according to their context. We assume that a word X  X  context is the entire tweet in which it occurs. The first model we discuss is the bag-of-words (BOW) tweet-centroid model, which represents words according to the other words that co-occur with it.

Suppose we have a corpus C formed by n tweets t 1 ,...,t where each tweet t is a sequence of words. Let V be the vocab-ulary formed by the m different words w 1 , ...,w m found in C . The tweet-level bag-of-words model represents each tweet t as a m -dimensional vector value f j ( t ) that corresponds to the frequency of the word w the sequence of words of t .

For each word w , we define the word-tweet set W ( w ) as the set of tweets in which w is observed:
We define the bag-of-words vector tweet vectors in which w is used. In other words, dimensional vector in which each dimension wb j is calculated as follows:
However, because bag-of-word models tend to produce high-dimensional sparse vectors, we also study another word vector rep-resentation with lower dimensionality based on the interaction of word clusters.

Let c be a clustering function that maps the m words from V to a partition S containing k classes, with k m . In our experiments, this function is trained in an unsupervised fashion from a corpus of tweets using the Brown clustering algorithm [2], which produces hierarchical clusters by maximising the mutual information of bi-grams. These clusters have shown to be useful for tagging tweets according to part-of-speech classes [5].

We tag the word sequences of the tweets from C with the cluster-ing function c . Afterwards, we create a new tweet-level vector of k dimensions based on the frequency of occurrence of a cluster s in the tweet. The cluster-based word vectors  X  X  X  wc are calculated analogously to the bag-of-words vectors in the first approach. We take the centroids of the cluster-based vectors of W ( w ) , producing k -dimensional vectors for each word.
We evaluate the proposed vectors for lexicon generation using two different collections of tweets: the Edinburgh corpus (ED) [15], and the Stanford Twitter Sentiment corpus (STS) 2 [6].
The ED corpus is a collection of 97 million tweets acquired from the Twitter Streaming API covering multiple topics and languages. We take a random sample of 2.5 million English tweets from this collection. The STS corpus is a collection of 1.6 million English tweets collected by submitting queries with positive and negative emoticons to the Twitter search API. The emoticons are removed from the content. The ED corpus represents a realistic sample from a stream of tweets, whereas STS was intentionally manipulated to over-represent subjective tweets. We study these datasets to ob-serve the effects of manipulating the collection of tweets for lexicon generation.

We tokenise the tweets from both collections and create the vec-tors was taken from the TweetNLP project 3 . This function was trained to produce 1000 different word clusters from a collection of around 56 million tweets using the Brown-clustering algorithm.

The two vectors level classifier for lexicon generation. To avoid learning spurious relationships from infrequent words, vectors of words that occur in less than 10 tweets are discarded ( |W ( w ) | &lt; 10 ). We also discard the dimensions from Analogously, we remove all dimensions from  X  X  X  wc associated with clusters appearing in less than 10 tweets.

We label the words that match a seed lexicon formed by words categorised into three sentiment categories: positive, negative, and neutral. The seed lexicon is built from the union of four existing hand-made lexicons, and a list of 87 positive and negative emoti-cons: MPQA [19], Bing Liu [11], Afinn [14], and NRC-emotion lex-icon [12]. We discard all words labelled with conflicting polarities by different lexicons. The resulting seed lexicon has 3769 positive, 6414 negative, and 7088 neutral words. The main properties of the ED and STS datasets are summarised in Table 1.

We first study the problem of classifying words into positive and negative classes. We train an L2-regularised logistic regression model with the regularisation C parameter set to 1 . 0 using Lib-LINEAR 4 . For performance estimation, we apply 10 times 10-folds cross-validation on the positive and negative labelled words from the two datasets. We compare three different instance spaces: bag-of-words vectors both: [ wb 1 ,...,wb m ,wc 1 ,...,wc k ] . We compare classification accuracy and the weighted area under the ROC curve (AUC) ob-tained by the different instance spaces using a corrected resampled paired t -student test with an  X  level of 0 . 05 . Results are displayed in Table 2. Statistically significant improvements over the bag-of-words approach are denoted with the symbol  X  .
 Table 2: Word-level 2-class polarity classification performance.
We can observe that the classification results are slightly better for ED than STS. The cluster-based representation is better than the bag-of-words representation in STS. However, this pattern is not observed in ED. The concatenation of both vector models produces significant improvements in accuracy and AUC over the baseline in both datasets.
 Table 3: Word-level three-class polarity classification performance.
The detection of neutral words is an important task in sentiment analysis because it enables removal of non-opinion words from a passage of text. In the next experiment, we include neutral words to train a three-class polarity classifier. The classification results are given in Table 3. We can see that the classification performance is lower than in the previous experiment. The cluster-based vec-tors are significantly better than the bag-of-words vectors in both datasets. This suggests that word clusters are especially helpful in distinguishing neutral and non-neutral words. The concatenation of the two vectors achieves the best performance among all the ex-periments.
We use the three-class classifiers trained using both vectors to label the unlabelled words from the two collection of tweets. A sample of the generated words from the ED corpus with the es-timated probabilities for negative, neutral, and positive classes is shown in Table 4.

As an additional validation for the generated words, we study their usefulness for classifying the overall polarity of Twitter mes-sages. To do this, we compare the classification performance ob-tained by a simple classifier that uses attributes calculated from the seed lexicon, with the performance obtained by a classifier with attributes derived from both the seed lexicon and the generated words. The evaluation is done on three collections of tweets that were manually annotated to positive and negative classes: 6Hu-manCoded 5 , Sanders 6 , and SemEval 7 . The number of positive and negative tweets of these datasets is given in Table 5.

The baseline of this experiment is a logistic regression model trained using the number of positive and negative words from the seed lexicon that are found within the tweet X  X  content as attributes. For each expanded lexicon, we train a logistic regression model us-ing the baseline attributes together with a positive and a negative score calculated as the weighted sum of the corresponding proba-bilities of words classified as positive or negative, respectively.
The classification results obtained for message-level classifica-tion in the three datasets are shown in Table 6. We observe from the table that with the exception of the accuracy obtained by the STS-based lexicon on the Sanders dataset, the generated lexicons produce significant improvements over the baseline. Furthermore, the lexicon generated from the ED corpus outperforms the per-formance of the STS lexicon in accuracy and AUC score respec-tively. These results indicate that collections of tweets manipulated to over-represent subjective tweets such as STS, are not necessar-ily better for lexicon generation than random collections of tweets such as ED.
In this paper, we studied two distributional representations for classifying Twitter opinion words in a supervised fashion. Our ex-perimental results show the usefulness of the generated words for message-level polarity classification. The main advantage of the proposed technique is that it depends on resources that are rela-tively cheap to obtain: a seed lexicon, and a collection of unla-belled tweets. The former can be obtained from publicly available resources such as the ones used in this work, and the latter can be freely collected from the Twitter API. The source code and gener-ated lexicons are released to the research community 8 .
The proposed method does not depend on labelled tweets or tweets with emoticons, in contrast to previous approaches [1, 13, 20]. Thus, our model can be used to identify domain-specific opin-ion words by collecting tweets from the target domain. This could be useful in domains such as politics, in which emoticons are not frequently used to express negative and positive opinions.
Considering that our model represents words by the centroid of tweet-level vectors, we could extend it to include any kind of fea-ture used for message-level sentiment classification. These features could include textual properties such as bigrams, part-of-speech tags, negations, among others. In future work, we will also study how to include attributes provided by low-dimensional distributed representations or word embeddings such as the neural language models implemented in the Word2vec library 9 .

Finally, it would be possible to extend the model to produce a more fine-grained word-level categorisation based on emotion cat-egories, e.g., anger, fear, surprise, and joy. This could be achieved by relying on the labels provided by an emotion-associated lexicon [12] and multi-label classification techniques. [1] L. Becker, G. Erhart, D. Skiba, and V. Matula. Avaya: [2] P. F. Brown, P. V. Desouza, R. L. Mercer, V. J. D. Pietra, and [3] A. Esuli and F. Sebastiani. Determining the semantic [4] A. Esuli and F. Sebastiani. Sentiwordnet: A publicly [5] K. Gimpel, N. Schneider, B. O X  X onnor, D. Das, D. Mills, [6] A. Go, R. Bhayani, and L. Huang. Twitter sentiment [7] Z. Harris. Distributional structure. Word , 10(23):146 X 162, [8] V. Hatzivassiloglou and K. R. McKeown. Predicting the [9] M. Hu and B. Liu. Mining and summarizing customer [10] S.-M. Kim and E. Hovy. Determining the sentiment of [11] B. Liu. Sentiment Analysis and Opinion Mining . Synthesis [12] S. Mohammad and P. D. Turney. Crowdsourcing a [13] S. M. Mohammad, S. Kiritchenko, and X. Zhu. Nrc-canada: [14] F. Nielsen. A new ANEW: Evaluation of a word list for [15] S. Petrovi  X  c, M. Osborne, and V. Lavrenko. The edinburgh [16] P. D. Turney. Thumbs up or thumbs down?: semantic [17] P. D. Turney and M. L. Littman. Measuring praise and [18] P. D. Turney and P. Pantel. From frequency to meaning: [19] T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing [20] Z. Zhou, X. Zhang, and M. Sanderson. Sentiment analysis on
