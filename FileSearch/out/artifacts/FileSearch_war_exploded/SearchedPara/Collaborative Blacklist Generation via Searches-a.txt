 This paper presents an intent c onformity model to collaboratively generate blacklists for cyberporn filtering. A novel porn detection framework via searches-and-clic ks is proposed to explore collective intelligence embedded in query logs. Firstly, the clicked pages are represented in te rms of the weighted queries to reflect the degrees related to pornography. Consequently, these weighted queries are regarded as discriminative features to calculate the pornography indicator by an inverse chi-square method for candidate determinati on. Finally, a candidate whose URL contains at least one pornographic keyword is included in our collaborative blacklists. The experiments on a MSN porn data set indicate that the generated blacklist achieves a high precision, while maintaining a favorably low false positive rate. In addition, real-life filtering simulations reveal that our blacklist is more effective than some publicly released blacklists. H.3.3 [ Information Search and Retrieval ]: Information filtering Experimentation, Human Factors. Collaborative cyberporn filtering, search intents, user behaviors Filtering the wide spreading objectionable web content, e.g., pornography, violence, drug and gamb ling, has attracted intensive attention for protecting children or anyone else from inappropriate materials [11]. The URL blocking approach rejects any requests to URLs on a blacklist, while accepting requests to URLs that are not blacklisted [7, 12]. The dynamics of the web requires such a blacklist to be constantly updated for sustainable blocking performance. Traditionally, the UR Ls in blacklists are manually listed or automatically generated by intelligent content analysis. Different form the previous work , we generate blacklists with collective intelligence embedded in search query logs, but without web page content. Submitting que ries to search engines and clicking search results are two co mmon operations in daily life. These actions provide implicit ta ggings on web pages, which are useful feedbacks to search engines for filtering inappropriate materials in necessary situations. How to follow the changing trails of objectionable web sites and maintain a steady and satisfactory filtering performance is a major challenging issue. In this paper, we explore the variability of objectionable one, which was successfully accessed in search query logs, to approximately keep up with the changing trails. Query log analysis showed that the top three categories in terms of popularity are pornography, entertainment and music [1]. About 25% of the highest used query terms apparently dealt with sexual topic [3]. We take the pornography, a category of top popularity, as a target to demonstrate the filtering effectiveness. This paper proposes an intent conformity model for collaborative blacklist generation via searches-a nd-clicks. Firstly, the clicked pages are represented in terms of the queries that retrieve them. After weighting the issued queries with the degrees related to pornography, the pornography indicator of a web page is calculated by an inverse chi-squa re method. A clicked page is regarded as a candidate if its por nography indicator is larger than a threshold. Finally, we further check the corresponding URLs of the candidates with the help of their host name and path information. Candidate URLs are included in a blacklist if their URLs contain pornographic keywords. Pornography is usually named differently. The socially accepted variants contain adult material, explicit sexuality, and nudity in related work. Traditional filtering techniques regard this problem as categorization with statically crawled data sets. The intelligent content analysis approach attempts to understand the context in which the discriminative features appear and make classification decision. Several numerical algorithms, including neural networks [8], statistical text an alysis [7], and pattern recognition techniques [5] were used to trai n the classifier for pornography filtering. Features from skin pixels were usually adopted for pornographic image recognition [13]. Motion information was combined with image features in detecting pornographic video content [4]. In addition to content features, analysis of linking structure through hyperlinks was also used to filter internet pornography [2]. The URL-based features were empirically shown as an effective approach for correctly identifying pornographic websites [12]. More over, query-URL click pairs were also exploited for clusteri ng the similar pornographic images [10]. The strength of intelligent content analysis lies in its superior accuracy achieved by analyzing texts and images on web pages. However, comparativel y more training time and human intervention are needed for the claimed performance. Different from the previous work which focuses on intelligent content analysis by web conten t and structure mining, we only exploit users X  searches-and-clicks from query logs for web usage mining. In this study, we analyze query logs to reflect implicitly collective intelligence from users X  perspectives to collaboratively generate pornographic blacklists for cyberporn filtering. Our intent conformity model incl udes two steps, i.e., indicator calculation and category recognition. The details are described in the following subsections. A user intent may be transforme d to a query with many-to-many relationships. The same intent ma y be in terms of the same or different queries issued by users at different time. Beitzel et al. [1] employed manually defined domain-specific keywords to determine the categories of the issued queries. The study of web sexual queries also indicated se xual query terms are constrained in range and variance [9]. In our model, suspected query terms are identified with an automatically constructed lexicon. Firstly, we select terms from the catal og of pornographic web sites as seed queries. Empirical observa tions show that the catalog of pornographic web sites usually implicitly reflects porn-seeking information needs. Consequently , we use any five queries of seeds as combination for expa nding related query terms by Google Sets. Google Sets automati cally creates sets of related terms from the given seeds. For example, given three terms  X  X ex X ,  X  X aked X  and  X  X orn X , Google Sets will predict at most 50 related items such as  X  X ude X ,  X  X xx X  a nd  X  X -word X . All automatically expanded terms and seeds are put in our constructed lexicon for suspected query identification. In total, there are 410 expanded terms and seeds in the lexicon. How to weight the issued queries with the degrees of domain-specific tendency is challenging. A query term is identified as a suspected term if it is contained in our automatically constructed pornographic lexicon. Equati on (1) shows the porn tendency weight of an issued query q , denoted as w q , where st the number of suspected query terms and the number of query terms in q , respectively. Queries are weighted in the range of 0 to 1 in such a way that the values above (or below) 0,5 are considered positive (or negative) to pornography-seeking intents. Clicked web pages are represented in terms of the queries retrieving them. Assume a clicked URL u is retrieved by n queries, q 1 , q 2 , ..., q n , in search query logs. The pornography indicator of u is determined by an inverse chi-square method defined in Equations (2)-(4). This indicator value of pornography is calculated using two p -values derived from inverse chi-square distribution, assuming the null hypothesis H 0 is that the clicked web page is a random collection of issued queries, each independent of the others, is true; the alternative hypothesis H indicates the null hypothesis is not true. In Equation (2), degrees of freedom; C -1 () denotes an inverse chi-square function to derive the p -value from a chi-square distributed random variable. The p -value derived from C -1 () in Equation (2) is named as P (Positive). In Equation (3), we replace w q with (1-w denotes the non-porn tendency of an individual issued query, and N (Negative) stands for the p -value derived in this hypothesis testing. The indicator value of pornography, denoted as I , specifying the difference between the values of P and N , is normalized to be in the range of 0~1 by Equation (4). A clicked page can be in terms of the related queries with similar intents in search query logs. For example, the clicked pages retrieved by the query term  X  X ex X  are very likely to be also retrieved by the term  X  X aked X . This nonrandom tendency produces results of small p -value (either P or N ) to reject the null hypothesis. A pornographic web page has a much smaller value contrast, a non-pornographic web pa ge has a much smaller value We regard a clicked page as a candidate if its I-value is larger than a threshold. In a related work, Lee and Luh [7] employed an inverse chi-square method to mine conten t features from web pages for blacklist generation. Different from their supervised learning approach, we use weighted queries as discriminative features to represent clicked pages for pornogr aphy indicator calculation. Unsupervised learning with query logs relieves the extra human efforts to label data for trai ning a classifier. In addition, classifying a URL with our model is a cost-effective operation compared to crawl web pages and extract their content features. In our statistics, the clicked web pages are represented in terms of 40.2 weighted queries on average. The number of weighted queries and the threshold are two f actors in the inverse chi-square method. In the later experiments, we use at most 150 queries of the higher weight w q to represent a clicked page and the threshold is empirically set to 0.65, as suggested by the related study [7]. In the past, URL-based features were empirically shown as an effective approach for correctly identifying pornographic websites [12]. A categorical keyword set is formulated automatically for category recognition as follows. We first employ the blacklist released publicly in URLBlacklist.com to collect categorical keywords common used in URLs of pornographic web pages, then remove  X  X ttp:// X  and  X / X  from URLs, further segment the remaining part of host name and path into all possible n-grams, and finally compose a 172-categorical-keyword set by consulting a pornographic dictionary, which is available online at theporndictionary.com. A candidate whose URL contains at least one categorical keyword will be included in our pornographic blacklist for collaborative cyberporn filtering. The data set comes from the MSN 2006 RFP data. It consists of an MSN search query log excerpt with 15 million queries from US users during May 2006. Data made available include the issued queries, the clicked URLs and the time-stamps. We randomly selected 1% of MSN search query logs and removed those queries issued only once because no collective intelligence was involved in them. After sa mpling, we manually labeled the pages as ground truth by examining their contents. Those pages which could not be accessed successfully at the labeling time were ignored. The number of queri es in our testing data set is 1,631,961, of which 43,198 queries are unique . Total 5,821 and 10,135 unique URLs are annotated in porn and non-porn categories, respectively. For performance evaluation, we use three metrics: precision, recall and false positive rate. Fa lse positive rate is the proportion of non-pornographic web pages that are incorrectly classified as pornographic ones. From filtering point of view, incorrect blocking will cause unfair penalties. In addition to achieving high filtering performance, reducing false positive errors is also important. Four query logs based models s hown as follows are compared to demonstrate their performance diffe rences in blacklist generation. (1) User Intent model This model exploited implicit collective intelligence from query logs for pornographic blacklist generation [6]. Firstly, suspected queries are identified along with their clicked URLs by an automatically constructed lexi con. A candidate URL is determined if the number of clicks satisfies some majority voting rules. Finally, a candidate whose URL contains at least one categorical keyword will be included in a blacklist. (2) Inverse chi-square with query features ( InChi2-Query ) model This model only considers the firs t step of our proposed intent conformity model, i.e., the method specified in Section 3.1. If the indicator value of a clicked page is larger than a pre-defined threshold, the corresponding URL is included in a blacklist. (3) URL Checking model The category of a clicked page is determined by its corresponding URL. This model only considers the second step of our intent conformity model specified in Section 3.2. (4) Intent Conformity model This model considers the two step s proposed in Sections 3.1 and 3.2 together for collaborative blacklist generation. Figure 1 shows experimental results of these four models on the MSN porn data set. URL Checking model achieves the best recall, but the worst false positive rate. It reveals that URL contains categorical keywords does not always represent the category of web pages. Error analysis s hows that most of non-pornographic pages, e.g., those describing sex education, nude art, and adult dating, with categorical n-grams in their host names or paths for clear category recognition usually lead to false positive cases . User Intent and InChi2-Query models achieve promising precision and false positive rate, but relatively worse of recall. For User Intent model, we further analyze the reason of lower recall, and find that the number of clicks is distributed among different URLs of the same pornogra phic content. In such a case, the clicks cannot satisfy any majority voting rules. Because pornographic content is the major target for objectionable web content filtering, the pornographic content providers create more hosts and redirections to avoi d being found and filtered. For InChi2-Query model, the issued queries are usually short and the suspected query terms cannot be completely identified, especially the names of web sites for naviga tional query to particular porn sites or the names of pornogra phic actress, which leads to incorrect query weighting with pornography tendency. The Intent Conformity model achieves the best precision 0.8242, while maintaining the lowest false positive rate 0.0413 of all the models. It naturally reveals that exploiting searches-and-clicks in query logs is an effective approach for collaborative blacklist generation with collective intelligence. 
Figure 1 . Performance of various meth ods on testing data set. We also conduct experiments fo r comparing filtering effects among different blacklists. The data set in Section 4.1 is divided into two parts: the first half of query logs, i.e., from May 1st to May 15th, for generating blacklists and the second half of query logs, i.e., from May 16th to May 31st, for verifying filtering effects. Totally, 4,742 and 7,988 unique URLs are regarded as porn and non-porn for investigating real-life filtering effects. Of the five blacklists to be compared, two blacklists are generated using the User Intent model [6] and our Intent Conformity model, respectively. There are near 1 thousand URLs in these two query log based blacklists. The three others are publicly released pornographic blacklists from SquidGuard (http://www.squidguard.org/), Shalla Secure Services (http://www.shallalist.de/) and URLBlacklist.com . They consist of about 51 thousands, 55 thousands, and 171 thousands URLs, respectively. For filtering evaluation, the number of blocking cases, denoting as #Block, illustrates total pornographic URLs that have correctly included in the blacklists. Th e number of over-blocking cases, denoting as #Over-Block, shows how many non-pornographic URLs are incorrectly lis ted in the blacklists. Table 1 shows the filtering effects among blacklists. We can find that the three public blacklists cover very few blocking cases, even over-blocking normal accesses, although the number of URLs in the lists is much larger th an that of the lists generated by query log based models. It reveals that the coverage of pornographic blacklist is a very im portant issue. If a blacklist does not reflect real user web surfi ng behaviors, its filtering effect will be very limited. The blacklists generated by User Intent and Intent Conformity models are much closer to the real-world situation of user accesses, due to searches-and-clicks in query logs reflect collective intelligence during web surfing. Table 1. Comparison of filteri ng effects among blacklists Comparing the User Intent and the Intent Conformity models, the former can block slightly more pornographic URLs, and the latter can decrease about two-third of over-blocking cases of normal accesses. Obviously, Intent Conformity model is more proper to incorporate implicit user intent s and collective intelligence to search engines to mask the search results before users click them. Query ambiguity is a challenging issue for intent conformity approach. For example, the information need for query  X  X reast X  may be related to  X  X reast cancer X . A query term with different intents results in many diffe rent pages to be clicked. The same query issued independen tly by the same or different users with similar intents may ha ve different search results at different time. That will affect the clicking behaviors of users. Capturing the refreshing relations hip between search engines and blacklist generation may have some effects on filtering performance. This paper proposes an effectiv e intent conformity method for collaborative blacklist generation and its application on cyberporn filtering. It only exploits search es-and-clicks in query logs, but without crawling the content of a URL and manually labeling training data for machine learni ng. The experiments on a MSN porn data set indicate that the generated blacklist achieves a high precision, while maintaining a favorably low false positive rate. In addition, real-life filtering simulations reveal that our user-centric blacklists are more effective than some publicly released blacklists for cyberporn filtering. Obviously, our intent conformity method is much closer to real-world users X  surfing behaviors to reflect real-life situation. We will extend this method to other objectionable domains such as gambling, drugs, violence, and suicide. A more aggressive query weighting scheme will be investigated in the future to represent clicked pages for achie ving more satisfactory filtering performance. This research was partially supported by National Science Council, Taiwan under grant NSC99-2221-E-002-167-MY3. We are also grateful to Microsoft Research Asia for the support of MSN Search Query Log excerpt. [1] Beitzel, S. M., Jensen, E. C ., Chowdhury, A., Grossman, D., [2] Hammami, M., Chahir, Y., and Chen, L. 2006. WebGuard: a [3] Jansen, B. J., Spink, A., and Te fko, S. 2000. Real life, real [4] Jansohn, C., Ulges, A., and Breuel, T. M. 2009. Detecting [5] Lee, J.-S., Kuo, Y.-M., Chung, P.-C., and Chen, E.-L. 2007. [6] Lee, L.-H., and Chen, H.-H. 2011. Collaborative cyberporn [7] Lee, L.-H., and Luh, C.-J. 2008. Generation of pornographic [8] Lee, P. Y., Hui, S. C., and Fong, A. C. M. 2005. An [9] Spink, A., Ozmutlu, H. C., and Lorence, D. P. 2004. Web [10] Szummer, M. and Craswe ll, N. 2008. Behavioral [11] Weitzner, D. J. 2007. Free speech and child protection on the [12] Zhang, J., Qin, J., and Yan, Q. 2006. The role of URLs in [13] Zuo, H., Hu, W., and Wu, O. 2010. Patch-based skin color 
