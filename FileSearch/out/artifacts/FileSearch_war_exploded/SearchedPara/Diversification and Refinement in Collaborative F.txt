 This paper considers a popular class of recommender systems that are based on Collaborative Filtering (CF) and proposes a novel technique for diversifying the recommendations that they give to users. Items are clustered based on a unique notion of priority-medoids that provides a natural balance between the need to present highly ranked items vs. highly diverse ones. Our solution estimates items diversity by comparing the rankings that different users gave to the items, thereby enabling diversification even in common sce-narios where no semantic information on the items is available. It also provides a natural zoom-in mechanism to focus on items (clus-ters) of interest and recommending diversified similar items. We present DiRec , a plug-in that implements the above concepts and allows CF Recommender systems to diversify their recommenda-tions. We illustrate the operation of DiRec in the context of a movie recommendation system and present a thorough experimental study that demonstrates the effectiveness of our recommendation diversi-fication technique and its superiority over previous solutions. Categories and Subject Descriptors: H.2.8 [Database Applica-tions]: Data mining General Terms: Algorithms, Experimentation Keywords: diversification, refinement, recommendations, CF
Online shopping has grown rapidly over the past few years. Be-sides the convenience of shopping directly from one X  X  home, an im-portant advantage of e-commerce is the great variety of items that online stores offer. However, with such a large number of items, it becomes harder for vendors to determine which items are more relevant for a given user and, given the limited size of the screen, which of these possibly relevant items should be presented first. Much research has been devoted recently to the development of Recommender systems [2]. These systems predict the rating (e.g., a grade on a scale of 1 to 5) that a user would assign to an unseen
This work was partly supported by the EU project Mancoosi, by the Israel Science Foundation and by the US-Israel Binational Sci-ence Foundation.
 item, and consider items with a high predicted rating to be relevant. But, which of these highly rated items should be presented first to the user? A naive solution would be to simply sort the items by their estimated rating and present the top-k that fit onto the screen. This however may result in an over-specialized items list. For ex-ample, suppose that a user is interested in movie recommendations. Assume that only 5 movies may fit onto the screen and that the top-5 ranked movies, for this user, all happen to be Star Wars sequels. While the given user may indeed like this series, a more diverse and wider view of the highly ranked movies may be desirable. For instance one that includes a Star Wars movie, but also other movies like Star Trek or E.T., with the access to more Star Wars sequels enabled via a  X  X ore of that X  zoom-in button.

This papers aims to provide precisely such diversification and zoom-in facilities. Specifically, we focus here on a popular class of recommender systems that is based of Collaborative Filtering (CF), in which user ratings to items based on previous ratings of (simi-lar) items by (similar) users[15]. A first question that needs to be addressed when designing such a diversification mechanism is how to measure the similarity/diversity of two given items. Previous proposals are often based on the assumption that some semantic in-formation on items (e.g. the genre of the movie, the director, the actors) is given. CF recommender systems, however, typically do not carry such semantic information [2]. But even if they had, a problem is that it is not always clear how to define item diversity based on a given semantic information [20]. For example, some movies of the same director/leading actor may indeed be similar, whereas others may not. To overcome this difficulty, we follow the CF approach [15, 17] and instead of relying on semantic infor-mation, determine items similarity (and correspondingly diversity) based solely on ratings that previous users gave to the items. Intu-itively, each item here is viewed as a vector of ratings, with vector distance (measured, e.g., by cosine, L i distance, or Pearson corre-lation coefficient) used as measure of similarity/diversity.
A second important challenge is the need to balance, when choos-ing items, between two possibly conflicting objectives: presenting highest ranked items vs. choosing highly diverse ones. Some pre-vious works attempted to resolve this by assigning a weight to each objective and selecting an items set that maximizes the weighted sum[9]; others used thresholds to bound the allowed similarity be-tween items and the drop in rank [16]. But the difficult question always is which weights or thresholds to choose ?. Indeed, a manual tuning of weights/thresholds (e.g. by experimentation) for a given data set is not only time consuming but is also no longer effective when the data changes [9]. To solve this problem we propose here a novel approach that avoids the use of weights/thresholds altogether . We introduce the notion of priority-medoids , an adaptation of the classical notion of medoids [11] to a context where items have pri-orities (ratings). Priority-medoids (to be defined formally in the sequel) allow for natural clustering of items and the selection of cluster representatives that balance rank and diversity. The cluster-ing further allows the realization of an intuitive  X  X oom-in X  mech-anism, where users can focus on specific items on the screen and view similar recommended items. Priority-medoids sub-clustering is then be used, recursively, to diversify their presentation (and to allow further zooming-in).

To best of our knowledge, the only other previous algorithm without weights/threshold is Algorithm Greedy of [16], which does not support zoom-in. The tradeoff between ranking and diversity is hard-coded in the algorithm without any declarative notion of opti-mality. An advantage of a declarative definition is that it is not tied to a particular algorithm and thus allows for formal analysis and optimization. While we show that identifying the optimal priority-medoids is NP-hard, we present an efficient (ptime) heuristic based on priority cover-trees , a particular sub-class of cover-trees [4] that proves to be extremely effective in this context. Our experiments show that the representatives chosen by our algorithms, with no need for weights tuning whatsoever, are as good and sometimes even superior to those obtained even with optimally-tuned weights of previous algorithms. We further present an optimization tech-nique that exploits the properties of our algorithm for an efficient realization of the above mentioned  X  X oom-in X  mechanism.
 DiRec . To demonstrate the effectiveness of our approach, we im-plemented the above solution in the DiRec prototype system. Di-Rec is designed as a plug-in that can be deployed on CF-based recommender systems, and was demonstrated in [7]. [7] provides a high-level description of the system, while the current paper presents the underlying model and algorithms.
 Related Work. As explained above, a recommendations list that consists of the items with top-k predicted ratings may suffer from over specialization. Indeed, [19] evaluated the diversity of top-k items generated by traditional CF algorithms and showed it to be fairly low. Several algorithms that attempt to diversify the recom-mendation were proposed in the literature (see [9] for a survey). They fall generally into two classes: greedy heuristics , where the recommendation list is constructed  X  X ne-by-one X  by maximizing a given distance function at each step (e.g. [10, 20, 16]), and inter-change (Swap) heuristics , where an initial list is first constructed and then refined by a series of actions (e.g. [17, 16]). But com-mon to most is the use of predefined weights or thresholds to de-termine the balances between ranking and diversity or to bound the allowed similarity between items and the drop in rank [10, 20, 17, 18]. While the selected weights/thresholds clearly affects the performance of the algorithms, their precise choice is left open in all the works we are aware of. Such use of weights/thresholds is problematic since their manual tuning (e.g. by experimentation) for a given data set is not only time consuming but is also no longer effective when the data changes [9]. As explained above, our so-lution employs, instead, priority medoids, to declaratively capture the desired balance. This is in contrast to [16] where the trade-off is hard-coded in the algorithm. It further has the advantage of allowing for a natural (and optimizable) zoom-in mechanism.
The importance of results diversification has been recognized also in the context of database queries [8, 14, 12]. For exam-ple, [8] proposes a notion of diversity over structured query results which are post-processed and organized in a decision tree to help users navigate them; [14] uses attributes content to group tuples in a meaningful way that allows for convenient data exploration. This line of works however relays heavily on the structured data con-tent . But such structured (semantic) information is not available in CF Recommender systems. Our work alleviates this problem by adopting the CF approach and relying on CF (dis)similarity mea-sures rather than semantic ones.

The most relevant to our work, although also targeted to struc-tured databases, is [12], where the authors used the notion of classi-cal medoids (approximated by classical cover-trees) to select repre-sentatives for the query results and to zoom in on similar answers. While our work was inspired by [12], a key difference is that [12] completely ignores tuples rating/priority . We will see that our use of priority medoids and, resp., priority cover-trees, over the classi-cal ones, prove to be extremely effective and greatly improves that generated recommendations.
 Contributions. The technical contributions of this paper can be summarized as follows:
The paper is organized as follows. Section 2 presents priority-medoids. Section 3 then explains how they are approximated and how item representatives are selected. Section 4 describes the zoom-in mechanism,and our experiments are described in Section 5 . Fi-nally, we conclude in Section 6. For space constraints, some details of the algorithms and the experiments are omitted and can be found in the full version of the paper [6]. We start by providing the needed background and notation for Collaborative Filtering (CF). We then consider the problem of bal-ancing the ratings and the diversity of the recommended items and define priority-medoids.
Common CF algorithms are item-based , consisting of two main steps: (1) choosing for each item a neighborhood of similar items, and (2) predicting the rating that a user u will give to an item i us-ing some aggregation function on the actual ratings, gave by u , to the items within the neighborhood of i [15]. Symmetric user-based variants also exist but are less frequently used [15]. A key ingre-dient in the algorithm is thus the estimation of similarity between two items. Intuitively, each item is viewed as a vector of ratings in a multi-dimensional speace, where each dimension corresponds to a given user, (recording her rating of that item). The distance between item vectors is then used as a measure for the items sim-ilarity. In principle, any distance measure can be employed here (e.g. Cosine or L i distance) but Pearson X  X  correlation coefficient [13] seems to be the preferred choice in most major systems. The basic intuition behind Pearson X  X  measure is to give a high similarity score for two items that tend to be rated the same by many users. In the reminder of this paper we use rate ( u, i ) do denote the predicted rating of a user u to item i . When u is known from the context we omit it and simply write rate ( i ) . We use dist ( i, j ) to denote the distance between items i and j . W.l.o.g. we assume below that distance values are in the range of [0 , 1] . (When this is not the case one may naturally map the values to this range). The smaller the distance is, the more similar (and less diverse) are the items.
We can now describe our main problem: given a set I of items and a size k , where the former holds the most relevant items for a given user (as decided by the given CF recommender system) and the latter denotes the number of items fitted onto the screen, we need to choose the subset I k  X  I (of size k ) that will be presented to the user. A naive solution simply selects the top-k items with the highest rate () values, namely the ones who maximize the sum P i  X  I k rate ( i ) . This however may result in an over-specialized subset, as described in the Introduction. Thus, we should consider the diversity of the items as well, which may be analogically mea-sured by the sum P i,j  X  I measures, one needs to provide a good balance between the two. Additionally, this subset should also provide a good coverage for the entire set I , which intuitively can be viewed as a classic clus-tering problem, where we need to minimize the distances between the items in I and the  X  X enter X  of the cluster they belong to.
Our solution, as mentioned in the Introduction, is based on the notion of priority-medoids , an adaptation of the classical notion of medoids to this context. To explain this, let us first briefly (and informally) recall what standard medoids are. Consider a set I of items split into k disjoint subsets, referred to as clusters. The medoid of a given cluster (also called the cluster X  X  representative) is an element in the cluster s.t. the sum of the distances from it to the other items in the cluster is minimal. Other variants that con-sider e.g. the average, min or max distance, also exist [11]. This sum is called the cluster X  X  weight. The classical goal is to find a clustering that minimize the overall sum of cluster weights. Note that, given a set I k  X  I of k items in I , the minimal-weight clus-tering for which the I k items serve as representatives (medoids), is one where each item i  X  I is associated (clustered) with the ele-ment in I k that is closest to it. Thus to find the best clustering one essentially needs to identify the best I k set.

In our context we are interested in representatives with high rat-ing. Priority-medoids therefore add the requirement that the repre-sentatives are the ones having highest rating in their corresponding clusters. Thus, when considering a set I k of priority-medoids, the clusters it forms are different than the ones formed when consider-ing standard medoids.
 More formally, consider a subset I k  X  I of size k of items, s.t. I contains, among others, an item having the highest rating in I . We will explain below why having such an item in I k is important. For an element i  X  I , we denote by rep ( i ) the item within I satisfying the following two constraints: The items with the same representative rep ( i ) form a cluster, and thus I k yields a clustering formation for the items of I . We refer to the items in I k as the priority-medoids of their corresponding clusters. Note that the fact that the highest rated element in I is a member of I k guarantees that all elements in I indeed have a cluster to which they may belong.

E XAMPLE 2.1. The example in Figure 1 illustrates the differ-ence between the cluster formation in regular medoids and that of priority-medoids. Assume that k = 2 and that the set I k consists of the two items i 0 and i 00 . Also assume that the euclidian distance between items describes their similarity. The number in paren-thesis, next to each item, describes its rating. On the right (resp. left) hand side we see the clusters formed when the items in I treated as regular (resp. priority-) medoids. The arrows outgoing the elements i 1  X  i 4 point to their cluster representative. On the right hand side (regular medoids) items i 2 , i 3 and i 4 with i 00 , as they are closer to it than to i 0 . i 1 is clustered with i In contrast, on the left hand side (priority-medoids), the clustering formation is different as the item ratings are now also being con-sidered. Specifically, since the rating of i 00 is lower than that of i i is clustered with (and represented by) i 0 , that has higher rating, even though it is slightly further.

The quality of the obtained clustering (and thereby the quality of the set I k of priority-medoids that yielded the clustering), is mea-sured, as before, by the distance of the items to the corresponding cluster representatives, namely by  X  i  X  I dist ( i, rep ( i )) . When I is known from the context, we use a simplified notation and denote this sum by weight ( I k ) . As for standard medoids, the lower the weight, the better the clustering (and the set I k of priority-medoids) is. We are thus interested in a set I k with minimal weight ( I However, we point out that there may be several sets with the same minimal weight, in which case we break the tie by choosing the one where rating values are lexicographically higher.

For example, assume k = 3 and we have two sets I 3 = { i 1 I = { i 0 1 , i 0 2 , i 0 3 } , where weight ( I 3 ) = weight ( I values of the three elements in I 3 (resp. I 0 3 ), sorted in decreasing order are 5 , 4 , 1 , (resp. 5 , 3 , 2 ) then we choose I ternative could be to prefer, e.g., item sets with higher average/sum of rating). Ties may still occur when distinct items have the same rating, in which case we break it arbitrarily.

We can show that identifying the best priority-medoids is NP-hard (proof is omitted). We thus use a heuristic, based on priority cover-trees -an adaptation of the classical cover-trees [4] to our context. We explain this next.
A cover-tree is a data structure originally designed to speed up a nearest neighbor search [4]. The use of cover-trees as a tool for selecting (regular) medoids was recently proposed in [12], in the context of diversification of query results. A key difference from the present work is that item ratings were not taken into consider-ation . We next show that a fairly simple modification to the algo-rithm of [12] allows to account for such ratings and thereby gradely improve the quality of the generated recommendations.

A conventional cover-tree can be thought of as a hierarchy of levels, where each node corresponds to a specific item, and each level is a  X  X over X  for the level beneath it. (The root is at level zero, its children at level one, and so on). Each node in the tree is asso-ciated with an item in I . An item can be associated with multiple nodes but can appear at most once in every level l . A conventional cover-tree obeys, for all levels, the first three invariants below. In our algorithms we use a special sub-class of these trees, which we call priority cover-trees, that further obey the forth invariant . 1. (Nesting) If a node is associated with an item i , then one of 2. (Separation) All nodes at level l are at least 1 2 l far from one 3. (Covering) Each node at level l is within distance 1 2 l 4. (Priority) Each node has a rating higher or equal to that of
An example for such a tree can be found in [6]. Next, we explain the role that invariant 4 plays in our algorithms for constructing priority-cover trees and for selecting items representatives, based on the constructed tree.
We first recall the conventional algorithm for cover-tree con-struction [4], then explain the needed modifications.

Given a set I of items, the standard algorithm first selects one item, arbitrarily, to serve as the root of the tree. Then it inserts the other items, iteratively, one by one (again in an arbitrary order), into the tree using an Insert Single Item function. For each item, the function finds the upper-most level into which the given item can be inserted, in a recursive fashion. Intuitively, it traverse the tree top-down, level-by-level, where at each step it maintains a set of nodes which can act as possible ancestors for the given item. These nodes are the ones whose descendants may potentially preserve the first three cover-tree invariants describe above. The given item is finally added once the algorithm reaches a point in the tree where all these invariants hold.

Now, to construct our priority cover-tree, only two simply changes to this algorithm are required:
For space constraints the full details of the algorithm, as well as its correctness proof, are deferred to [6]. We only note here that ordered insertion suffices to guarantee Invariant 4. Tight inser-tion, on the other hand, is not mandatory for the correctness of the construction. However it will prove useful later, when considering recommendations refinement (zoom-in). We discuss this issue in more detail in Section 4.
We next explain how the constructed priority cover-tree is used to select item representatives. We use below the following notations. Given a node n in the tree and an integer l  X  0 , we say that n is at level l in the tree, if the distance between n and the root of the tree (counted by the number of edges on the path between them) is l . We use C l to denote the set of nodes at level l .

The pseudo-code of the algorithm is given in [6] and we sketch below the key ideas. Consider a set I of items which the CF recom-mender determined as most relevant for a given user. As explained above, the k items that we want to present to users are the priority-medoids of I . To find such a subset, with low weight, we use the priority cover-tree of I as follows: Starting from the tree root, we search for the first level l within the tree that includes at least k nodes, namely where | C l  X  1 | &lt; k and | C l |  X  k . We then choose our k representatives from within C l . Recall that due to the struc-ture of the priority cover-tree the nodes in C i are at least from one another and have rating higher than their descendants. If C l contains exactly k nodes, then we simply choose these nodes for representatives and we are done. Otherwise, we need to select a subset of size k . To select good representatives, we use the tree structure: Recall the nesting property of the tree, which implies that C l  X  1  X  C l . Moreover, because of the hierarchical structure of the tree, the nodes (items) within C l  X  1 have rating  X  than those in C l and are pairwise further apart from each other than from the remaining nodes. Thus, we first select the nodes (items) in C then add the remaining k  X  X  C l  X  1 | from within C l  X  C consider in our implementation and experiments three alternative methods for choosing these additional elements:
Note that, during the tree construction, we can easily record the number of descendants each node has, and use this information for the implementation of the Max-coverage variant. Thus, all three options are equivalent in terms of computational effort. They may differ however, as we shall see later, in the quality of the generated representatives set.
Alongside each item (representative) i that is presented on the screen, DiRec offers a  X  X ore of that X  zoom-in button that allows the user to view further related items.

One possible approach for identifying such items in I is to select the ones whose distance from i (as measured by the dist () func-tion) is below a certain threshold. However, as it is never obvious which threshold should one choose, we take, instead, an alternative approach based on the following intuition: when a user clicks on a specific item i , she not only signals her interest in item X  X  i family but also signals that i interests her more than the other k  X  1 pre-sented representatives. Recalling the clustering formation gener-ated by the presented representatives (priority-medoids), we deter-mine the items in the cluster represented by i as relevant, denoting this set by relevant ( i ) .

Here again, the set relevant ( i ) often contains more items than could fit on the screen and a subset needs to be chosen, to be pre-sented to the user.

A straightforward approach to choose k representatives for relevant ( i ) is to build a priority cover-tree for the set, then use it to select rep-resentatives, as described above. Rather than doing so, we employ instead an optimized, significantly more efficient, algorithm that is based on the following observation: In the priority cover-tree previously constructed for I , most of the elements in relevant ( i ) already appear in subtree rooted at i . Indeed, the tight Insertion used in to the construction algorithm (Section 3.1) was employed precisely to increase the number of such elements. We thus use this subtree as a basis for the construction of the priority cover-tree of relevant ( i ) . Note however that the subtree may not include all the members of relevant ( i ) and also it might include some redundant elements that are not members of relevant ( i ) . Full details of the algorithm is available at [6].
We have implemented the above algorithms in DiRec [7], a plug-in that allows CF Recommender systems to diversify the recom-mendations that they present to users. We used DiRec in a variety of settings to evaluate the described algorithms by (1) a user study, (2) empirical evaluations, (3) performance measures and (4) refine-ment process. Due to space constraints, we present in this paper the results only for (2) and a short summary for (1). Nevertheless, the full description of all experiments are available at [6] for the intrigue readers.
 Experiments setting. In our experiments, DiRec was employed on top of a CF-based recommender system ( C2F [5]). For estimat-ing item similarity, C2F (and thus DiRec ) uses Pearson X  X  corre-lation coefficient [13]. We used a natural linear inverse mapping to compute items distance out of their Pearson correlation value: dist ( i, j ) = (1  X  P earson ( i, j )) / 2 . The experiments were pre-formed on an Intel quad-core machine (Q9400) with 2.66 GHz CPUs, (using only a single core of the CPU), 4GB memory and windows XP x64 edition. As data, we used a real-life data set from the cinema domain, provided by Netflix [3], which contains over 100 million distinct raw movie ratings (such as 1 to 5  X  X tars X ), by almost 500,000 users, and no semantic information on the movies. Algorithms. Our algorithm for representatives selection first con-structs a priority cover tree, then chooses representatives out of this tree. We consider the three variants of this choice: Max-rating, Max-diversity and Max-coverage, denoted below PCT-R , PCT-D and PCT-C , respectively. (PCT stands for Priority Cover-Tree). As we have mentioned, our use of priority cover-tree, instead of the classical cover-tree of [12], allows to take items rating into con-sideration. To illustrate the resulting improvement in the quality of the generated recommendations we had also implemented the cover-tree algorithm of [12], denoted below CT .

Recall that previous works typically use semantic information, to diversify items, and predefined weights/thresholds, to balance be-tween rating and diversity. Since no sematic information is avail-able in our context, one can employ here only algorithms that oper-ate without it. We have implemented the state of the art such algo-rithms from [16] ( Greedy and Swap ) and compared them to ours. Note that Algorithm Swap, like all other previous works (except for Algorithm Greedy), use predefined thresholds to balance rating and diversity. We had thus first optimized the thresholds ([6]) and had our algorithms compete against these optimized versions. The results for Greedy and Swap were similar and we thus show below only those of Swap . (Interested readers can find a brief description of the algorithm in [6]).

Finally, as a base line, we had also implemented the two  X  X x-treme case X  algorithms, optR (for Optimal Rating), which operated like a standard CF algorithm, selecting the k items having high-est rating and ignoring diversity, and optD (for Optimal Diversity), which ignores the rating of items and selects k items whose pair-wise distance values is the highest. 1
Note that optD require solving an NP-hard problem [9]. Its EXP-time algorithm iterates over all subsets of size k to find the best one. In our experiments this became infeasible for items sets of size  X  100, and we thus show results for them only up to that size. User Study. To assess the quality of the item sets that DiRec gen-erates (and thereby the quality of our algorithms), we ran a set of experiments with 50 volunteers who were asked to evaluate the quality of the presented movie recommendations. Due to space constrains, we only note the final results of the experiment (for a full description see [6]). Algorithm PCT-R got the highest results, with PCT-C , Swap and PCT-D not so far behind. Not surprisingly, these four algorithms got much higher results than optR , optD and CT , as they consider both the relevance and the diversity of the items (while the others focus solely on one property). While the grade difference between PCT-R and Greedy is smaller, recall that the former has further the advantage of supporting a natural zoom-in mechanism.
To better understand the results and how the PCT algorithms (and the preferred PCT-R in particular) balance ranking and di-versity, we run a second set of experiments over the Netflix data where we analyzed the quality the item sets generated by all the algorithms, in terms of their rating and diversity. In each set of ex-periments reported below we randomly chose a set of 1000 users from the Netflix data set and run the experiment for each of them. The results presented here are the average of all 1000 users. (The variance was less that 5%). We ran all experiments for varying size I of item candidates returned by the CF-system ( I ranging from 10 to 1000) and varying number k of representative items selects out of them ( k ranging from 3 to 20). The results were generally inde-pendent of the number k of selected representative. Thus, except when stated otherwise, we present below a representative sample for k = 5 , the common number of recommendations given by typ-ical recommender systems. For a generated set I k of representa-tives, we evaluated its quality w.r.t to the following measures. Rating. We measure the relevance of the suggested set of item I to the current user by the sum of the element ratings, i.e. rating ( I P i  X  I k rate ( i ) . (Higher value means better results). Diversity. In the absence of semantic information, the diversity of the items in I k may be measured by the pairwise-distances of the items, namely diversity ( I k ) = P i,j  X  I higher value means better results).

Although our algorithms do not require semantic information, it is interesting to examine the actual semantic diversity of the se-lected items. To get a sense of this, we extracted for each movie information from the Internet Movie Databases IMDb [1] and used it to determine, for each movie, to which of series it belongs (if any). We also extracted the movie X  X  genre (action, drama, etc.). For diversification, it is intuitively preferable not to have multiple movie sequels in the set presented to the user, and to have movies from different genres. We quantify this as follows.
Figure 2 shows the values for the relevance, distance-based di-versity, and sequel-based diversity, for the various algorithms, for varying sizes of item sets I. The results for genre-based diversity are similar to those of sequel-based one and are thus omitted for space constraints. The figure depicts these values, for the sets com-puted by the seven algorithms mentioned before: PCT-R , PCT-D , PCD-C , Swap (with its tuned threshold), CT , optR and optD . k here equals 5 and the size of the set I ranges from 10 to 1000 .
Recall that higher values here mean better results. Diversity gen-erally increases when I grows, as there are more items to choose from; Rating decreases, as more diverse but lower ranked items are chosen. Table 1 provides a summary of the graphs in Figure 2 that highlights how the various algorithms perform (for the var-ious measures) relative to PCT-R , and helps to explain why users may have found its results superior. For an algorithm A and mea-sure M , an  X  +  X  (resp.  X  ++  X ) entry indicates that Algorithm A generally performed slightly (significantly) better than PCT-R in measure M . Similarly,  X   X   X  (resp.  X   X  X  X   X ) indicates that A per-formed slightly (significantly) worse than PCT-R in M . An  X  =  X  entry indicates similar performance.

As expected optR have the highest rating value and lowest di-versity. Analogously, optD has lowest rating value and highest distance-based diversity. CT too has lowest rating value as it ig-nores item ranks. An interesting point to observe is that although some algorithms (and in particular optD ) achieve better distance-based diversity than PCT-R , no algorithm achieves better sequel di-versity. This discrepancy occurs, intuitively, because optD tries to maximize the total sum of distances without considering the (mini-mal) distance between two individual representatives (and thus may select two sequels in the same set). For a concrete example see [6]. The same phenomenon occurs more generally in many real life cases and explains why PCT-R is not handicapped by its non optimal distance diversity. Indeed, its sequel diversity is close to 1 (meaning that, as desired, the result contains no sequels) and we can see that no other algorithm was able to achieve better semantic (sequel) diversity. Furthermore, among the algorithms that achieve sequel diversity equal to that of PCT-R , it is the one with high-
Recall that optD became infeasible for items sets of size greater than 100, and we thus show results for them only up to that size. est rating score, which can explain why its recommendations were more favorable than the rest.
The DiRec plug-in presented in this paper allows CF recom-mender systems to diversify the recommendations that they present to users. It is based on a novel notion of priority-medoids that declaratively balances the rating and the diversity of the recom-mended items. We introduced priority cover-trees as a tool for efficient selection of item representatives. Our solution further al-lows for an effective realization of a natural  X  X oom-in X  mechanism, presenting to users similar yet diversified items. Our experiments demonstrated the effectiveness of our recommendation diversifica-tion technique and its superiority over previous proposals.
DiRec provides an effective solution in common scenarios where semantic information is unavailable. Combining our ratings-based (quantitative) approach with a semantic (qualitative) one, when such semantic data is available, is an intriguing future research direction.
