 Publication Time (P-time for short) of Web pages is often required in many application areas. In this paper, we address the issue of P-time detection and its application for page rank. We first propose an approach to extract P-time for a page with explicit P-time dis-played on its body. We then present a method to infer P-time for a page without P-time. We further introduce a temporal sensitive page rank model using P-time. Experiments demonstrate that our methods outperform the baseline methods significantly.
 Categories and Subject Descriptors: H.3.3 [Information Search and Retrieval]: Search process General Terms: Algorithms, Experimentation, Performance Keywords: temporal information detection, publication time ex-traction, publication time inference, page rank
Publication time (P-time) is the inception (creation) time when a Web page was published. In most cases, P-time is a precise tem-poral expression with a limited number of fixed formats. P-time is very useful temporal information in many applications [1].
As P-time detection, a method to extract P-time of a news story was discussed in [2]. However, the news story is not a page but a search result record returned from a search engine. Web document was dated based on its own Last-Modified value, the average Last-Modified value of its incoming links, outgoing links and assets [3]. A document corpus was first groupe d into time partitions, and then a document X  X  timestamp is determined by the partition with max-imum similarity score to it [4]. However, almost all literatures do not use the format and link information of Web pages. This leads to performance decreasing for P-time detection.

As P-time application, a model was presented to measure the distribution of documents retrieved in response to a query over the time domain in order to create a temporal profile for a query [5]. Implicitly year qualified queries were investigated in [6]. This kind of query does not actually contain a year, but yet a user may have implicitly formulated the query with a specific year in mind.
In this paper, we propose an approach to automatically detect P-time of Web pages and a temporal sensitive page rank model using P-time. A page may have explicit P-time in its HTML body or not. For the former, we present a domain and language independent machine learning method to extract the P-time. For the latter, we infer the P-time based on the link and text similarity relations with its neighbors. As an application, we introduce a model for page rank, which considers the relevance between the text of a page and a query, the P-time, as well as the important score of the page.
For a given page, we first try to extract P-time from its body. If the P-time can not be found, we then infer it.
 P-Time Extraction (PTE)
We present a machine learning approach to extract P-time unit from the body of a page which has explicit P-time. We incorporate only general linguistic and format information as the features for the machine learning model. We mainly use following information. (1) Linguistic information: Number of numerical characters, Num-ber of alphabetic characters, Number of all characters. (2) Position information: Position of Unit before the page title, Position of Unit after the page title, Position of Unit from bottom of the page, Width and Height of Unit in the page. (3) Format information: Temporal expression format, Font size, Font weight, Font family, Alignment: center, left, right, and justify. (4) Tag information: H1, H2, ..., H6, DIR, A, U, BR, Class name ( X  X ime X ,  X  X ate X ), etc.

With above information, we create 88 binary features used by the model of Support Vector Machine (SVM) to identify the P-time. P-time Inference (PTI)
We infer P-time based on link and text information of a page and its neighbors. For a page, we get the span of its P-time according to the link relation with its neighbors. A page X  X  P-time is later than its outlink pages X  P-time and earlier than its inlink pages X  P-time. For a page p i with P-time pt i , its outlink pages are represented as { inlink pages are denoted by { p I 1 , p I 2 ,..., p I w } pt i  X  TS i = [MAX { pt O 1 , pt O 2 ,..., pt O e } , MIN
Then, we infer its exact P-time in terms of the text similarity between its content and those neighbors content whose P-time be-longs to the span. Many pages are published by some sites to report an event when it happens. The reverse case, pages describing the same event may be published at the same time. Thus, the intuition is that highly relevant pages may share the same P-time. For two pages: p i with unknown P-time pt i ,and p j with known P-time pt we infer pt i in terms of pt j and the text similarity of p P-time of the page with maximum simscore is estimated as pt P-time Extraction Experiments
We annotated P-time of 2500 pages in English and 2500 pages in Chinese. We compared six approaches. The first fives methods, represented as FLT, LLT, LaT, FfT and BhT, are baseline methods and utilize the first time, the last time, the latest time, the first time before title, the first time behind title in a page as its P-time respec-tively. The last method, PTE SVM , is ours. Precision , the fraction of extracted P-time that agrees with the annotated P-time, is used to evaluate PTE results.

Figure 1 shows the results. Our approach significantly outper-forms these baseline methods. It seems that use of only linguistic or position information is not enough for extracting P-time e tively. Our approach is e ff ective since it makes full use of not only linguistic information but also various format information. As ex-pected, the performance of FLT is much better than that of LLT, and BhT achieves the best performance among these baseline methods. This is because P-time often locates in the front part of pages, es-pecially following titles. A small number of English authors write P-time before the page tile, while none of Chinese authors write P-time before the page tile. Thus, FfT gets the lowest performance. P-time Inference Experiment
We collected 11,000 pages with a span of 40 days and annotated the P-time. We then randomly selected 500 pages and inferred their P-time. The rest of pages were grouped into 40 partitions accord-ing to the P-time. We define an evaluation measure time_distance , which is the time gap between the inferred P-time and the anno-tated P-time in days. The first method, PTI B , uses the date of the partition with maximum similarity score as the inferred P-time [4]. The second, PTI 1 , is ours, except that the similarity is computed between a page and each partiti on. The third method, PTI
Experiment result is shown in Figure 2. Both our approaches surpass the baseline method significantly. This is because our ap-proaches use both link and text information to improve the e tiveness and e ffi ciency of PTI. The performance of PTI 1 than that of PTI 2 . The reason may be that a partition, which is merged using all titles of pages which belong to a certain date, con-tains more noisy information than a page title.
Many queries imply users X  intention associated with time. We propose an approach to rank pages considering their text content, temporal information (i.e. P-time in this paper), and page impor-tance. Our hypothesis is that the text similarity of a page to a query does not change over time, while its importance changes over time. For a query q , the rank score of the page i is computed as follow: where sim ( i , q ) is the cosine similarity between i and q , pagerank ( i ) is the importance score of i ,andweset  X  =  X  = 0 . 5. f ( i ) is a time based weight function and its value depends on the P-time of i . where DR denotes the decay rate of a page X  X  importance over time. We set DR = 0.5. D ( C ) is current time, D ( i ) is the P-time of i ,and D ( C )  X  D ( i ) is the time gap in days. x u , which denotes the sensitive degree of a query to time, can be dynamically tuned in terms of the distribution of q over time from query log of a search engine.
We issued 20 queries to Google and Yahoo! Search, and col-lected top 20 results for each query, denoted by GCorpus and YCor-pus. And, we recruited four experts to judge the result rating. Nor-malized Discount Cumulative Gain (NDCG) was used to evaluate the results [7]. The first method, PR E , ranks results in the original order returned by a search engine. The second, PR T , ranks results taking the linear combination of text similarity, temporal informa-tion and page importance [8]. The last method, PR P , is ours. We list the results in Table 1 and Table 2. We can see that PR achieves the best performance for both GCorpus and YCorpus. PR and PR T both outperform PR E . It is clear that methods using P-time are better than that does not. In addition, PR E on GCorpus is superior to that on YCorpus. This may reflect the fact that the performance of Google is better than that of Yahoo! Search. Note that the NDCG values of all methods are very high because we only collected top 20 relevant results returned by the search engine.
