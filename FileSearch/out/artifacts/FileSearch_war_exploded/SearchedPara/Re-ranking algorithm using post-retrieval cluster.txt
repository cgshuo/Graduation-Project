 1. Introduction
Rapid advances in science and technolog yhave produced a large amount of image data in medical image archiving. We often need to store, manage, and retrieve image data to perform assigned tasks and to make intelligent decisions. Content-based image retrieval (CBIR) methods have been developed in recent years for distinguishing useful images from extraneous ones, and for retrieving relevant images that satisf yuser interests (Rui, Huang, &amp; Chang, 1999).
In general, a CBIR system extracts visual features from an image, transforms the image into a feature vector, and calculates the similarities between a quer yimage and images stored in the database. Then, it presents a sequence of images in decreasing order of similarit yb yranking. As a result, users are able to minimize the time spent on finding useful images b ygetting the top-ranked images first.

Users evaluate the effectiveness of a CBIR system by the ranked results, but the relevant images are often not at the top of the rankings. Even if a system finds particular relevant images, many others ma ybe substantiall yfurther down in the ranking. We call this the rank inversion problem .
To remed ythis problem, we re-calculate the similarit yb ygrouping and anal yzing the retrieved results. We classif ythe retrieved results into sub-groups via a post-retrieval clustering method.
The sub-groups so formed should be such that members of the same sub-group have a high degree of association to each other and a low degree of association to members of other sub-groups.
Thus, when images are re-ranked according to the proposed algorithm, the images of the cluster that is nearest to the quer yimage could achieve a rank higher than the ydid in the originall y calculated rank.

In the literature on information retrieval, a variet yof cluster anal ysis techniques for improving retrieval effectiveness have been proposed, and man ycorresponding retrieval techniques have been developed to attain higher retrieval effectiveness. The original goal of document clustering was to improve the efficienc yof a search b yreducing the number of documents that need to be compared to the query. Recent research also shows that document clustering should be able to improve the retrieval effectiveness, as well as the efficiency, of a search.

There has been some research on how to emplo yclustering to improve retrieval effectiveness in the document information retrieval field. Anick exploited the synergy between document clus-tering and phrasal analysis for the purpose of automatically constructing a context-based retrieval system (Anick &amp; Vaithyanathan, 1997). The scatter/gather method on retrieval results (Cutting,
Karger, Pederson, &amp; Tukey, 1992; Hearst &amp; Pederson, 1996) showed that clustering on retrieved results is effective in browsing documents b yusing document sub-groups and summar ytext.
Hearst and Pederson compared a ranking of documents in a best cluster to an equivalent cut-off in the original top-ranked documents. A re-ranking model using static clustering and dynamic view was proposed to improve retrieval effectiveness (Lee, Park, &amp; Choi, 2001). This work re-evaluated the similarit yof documents based on their proposed model. Tombros, Villa, and Van Rijsbergen (2002) showed that query-specific clustering increased retrieval effectiveness, compared to static clustering and conventional inverted file search. The results of previous research show that clustering is an effective method for document information retrieval.

Traditionally, clustering methods have been applied statically over the whole image collection to improve the retrieval efficienc yof CBIR s ystems (Krishnamachari &amp; Abdel-Mottaleb, 1999; Mukherjea, Hirata, &amp; Hara, 1998; Sheikholeslami, Chang, &amp; Zhang, 2002; Yu &amp; Zhang, 2000).
Little effort, however, has been made to appl yclustering techniques to improve the retrieval ef-fectiveness of CBIR systems. In this paper, we examine how much improvement can be achieved b yre-ranking images through using post-retrieval clustering for CBIR s ystems.
The basic idea of our method is that the images in a cluster that are similar to a quer yimage should be ranked higher than the initial ranking. First, we retrieve images using a traditional image retrieval method. Next, we analyze the retrieved images by using hierarchical agglomerative clustering methods (HACM), and then we re-rank the results according to the distance of a cluster from a query. In experiments, we show that our method can significantly improve retrieval ef-fectiveness in CBIR systems.

The paper is organized as follows. Section 2 describes the basic image retrieval model. We describe clustering methods in Section 3. Section 4 provides details of the re-ranking algorithm using post-retrieval clustering, and states its advantages in the CBIR system. In Section 5, we present experimental results and discussions. Concluding remarks are given in the last section. 2. Image retrieval model
Most of the research on CBIR has focused on techniques of representing images with visual features. A variet yof image features, such as color, shape, and texture, have been used. In a typical image retrieval model, an image is represented as a feature vector in a n -dimensional vector space as follows: where f i is an element of the image feature vector.
 A typical image retrieval model calculates the similarity between images as follows:
The sum of absolute differences, square root, or quadratic distance etc. were used to compute the similarit yin the previous CBIR s ystems (Faloutsos et al., 1994; Swain &amp; Ballad, 1991).
The similarit ybetween images depends on two feature vectors. Hence, the selection of the feature vectors is an important factor affecting the effectiveness of the image retrieval. A full description of all the image features, their advantages/disadvantages, and their comparative ef-fectiveness for image retrieval is beyond the scope of this paper. We wish to evaluate only the improvements of the proposed re-ranking method. However, because the effectiveness of initial retrieval b ythe proposed method is related to the nature and qualit yof the features used to represent image content, we will explain image representation and some similarit yfunctions briefl yin the following sections. 2.1. Color histogram Color is an important attribute to describe the content of image. A color histogram (Swain &amp;
Ballad, 1991), which represents the proportion of specific colors in an image, has been widel yused among color representation methods. It has been found that a color histogram provides rea-sonable retrieval effectiveness using the hue, saturation, value (HSV) color space (Ma &amp; Zhang, 1998; Yoo, Jung, Jang, &amp; Na, 2002). The HSV color model is the most frequentl yused for CBIR, because it presents human perception well (Smith, 1997). In this paper, we use a 128 quantization level (HSV: 8  X  4  X  4), and histogram intersection. The histogram intersection is calculated as follows; H  X  I ; I 0  X  X  intersection is equivalent to the use of the sum of absolute differences or city-block metric (Swain &amp; Ballad, 1991). City-block distance is defined as follows:
Since our techniques are independent of color representation methods, in this paper we will study all the techniques using the color histogram method: HSV color space, 128 quantization level, and city-block metric. 2.2. Gray level co-occurrence matrix features
The textural features of an image are represented b ythe propert yof gra yvalues. Texture has effective image retrieval than does using color alone. We use gra ylevel co-occurrence matrix (GLCM), which is a simple and effective method for representing texture (Haralick &amp; Shapiro, 1992). The GLCM represents the direction h of, and distance d between, gra yvalues i and j of an image. The GLCM P  X  i ; j ; d ; h  X  is defined as follows: where # denotes the number of elements in the set. The value of Eq. (4) depends on the size of the and h .

In order to use the information contained in the GLCM, we use the five features that are used most frequently in the literature: energy, entropy, correlation, inertia, and local homogeneity (Ballard &amp; Brown, 1982; Celebi &amp; Alpkocak, 2000). To simplif yand reduce the dimension of a feature vector, we quantize the gra ylevels into 16 steps (textural properties are preserved b ythis operation), then we compute the five features when d  X  1, 2, 3, 4, 5 and h  X  0 ,45 ,90 , 135 .
Finally, we get the 100-dimensional feature vector. To compute the similarity of these features, we calculate the sum of absolute differences (Eq. (3)). 2.3. Edge direction histogram
We define the attributes of the edges of shapes in an image b ymeans of an edge direction of shape representation and has the advantage that we do not need to segment the image. For the edge direction histogram, 73 bins are defined to represent the edges of shapes in an image; the first 72 bins are used to represent edge directions and the last bin is used to represent non-edge pixels.
To compensate for different images sizes, we use the normalization method defined as follows (Vailaya &amp; Jain, 1998): where H 0  X  i  X  is the count in bin i , n e is the total number of edge points, and n of pixels in the image.

We use the Cann yedge detector (Parker, 1997) to extract the edges from an image. To compute the similarit yof these features, we calculate the sum of absolute differences (Eq. (3)). 2.4. Normalization and integration of features
Since different features can generate different ranges of values of similarity, a normalization method should be applied to each similarit ycomputation. We normalize each similarit yb ythe min/max normalization (linear scaling) method as follows:
After normalizing similarity, the total similarity between the query and the image in the data collection is calculated via a weighted sum of the similarities provided b yeach of the features. The equation for combining the similarities is defined as follows: where D combine  X  I ; I 0  X  is the weighted sum of similarities, N color histogram, N glcm  X  I ; I 0  X  represents GLCM features, and N rection histogram. x 1 , x 2 and x 3 are weighting factors to adjust the relative importance of image features. We choose x 1  X  1 : 0, x 2  X  0 : 2, and x 3  X  0 : 2 for our experiments in this paper. Com-bining features with these weights is more effective than using each feature alone. 3. Clustering methods
In this section, we explore the clustering methods that have been widel yapplied to information retrieval, and the algorithm for constructing the image clusters.
 Most conventional clustering methods fall into two classes (Frakes &amp; Baeza-Yates, 1992;
Voorhees, 1986): non-hierarchical and hierarchical. Non-hierarchical clustering methods were first used because of their low computational requirements. These methods generall yrequire a fixed number of clusters, which restriction makes them inappropriate for improving retrieval effectiveness. Recent applications of partitioning algorithms for information retrieval have also focused on issues of efficiency, rather than effectiveness. Hierarchical clustering methods have attracted much attention because the ygive the user the maximum amount of flexibilit y. Rather than requiring parameter choices to be pre-determined, the results represent all possible levels of granularity. So, most of the research on cluster analysis in information retrieval has employed hierarchical methods.

Hierarchical clustering methods can be classified into two kinds: agglomerative and divisive. In general, agglomerative methods are more effective than divisive methods. Hence, hierarchical agglomerative clustering methods are frequentl yused in the information retrieval field. In this paper, we constructed image clusters b yusing HACM and defined the resulting cluster structure as a tree structure: dendrogram . There are several methods for constructing a dendrogram from the use of HACM, such as single link, complete link, group average link, and Ward  X  s method. A general algorithm for such construction is to identif yand merge the two closest points until onl y one cluster remains.

There are three approaches to implementing the general HACM. Among them, we use the stored matrix approach. We first calculate a N N matrix containing all pairwise dissimi-larit yvalues using an association of measure function. The Lance X  X illiams update formula makes it possible to re-calculate the dissimilarit ybetween cluster centers b yonl yusing the stored values. Eq. (8) shows the update formula, and Table 1 shows its parameters (Frakes &amp; Baeza-
Yates, 1992)
A general algorithm for constructing the image clusters in this paper is as follows: (1) Calculate the similarities between the quer yimage and the N -top initiall yretrieved images. (2) Make the similarit ymatrix ( N N ) for N images. (3) Identif ythe two closest images and combine them in a cluster. (4) Update the similarit ymatrix using Eq. (8). (5) Until onl yone cluster remains, return to step (3).

The hierarchical agglomerative clustering algorithm that we used in this paper does not have an optimal time complexity. However, efficiency is not an important factor in this paper, because our method clusters a small number of images and we are concerned primaril ywith effectiveness.
Because images are represented as vectors in CBIR systems, we believe that clustering can be an are grouped together into one cluster b yhierarchical clustering. The advantage of clustering is that it brings ver ysimilar images together, and it is well known that these images are likel yto be relevant to similar queries. In this study, we are interested in improving effectiveness by applying clustering techniques to the initial ranked results. We will do that b ycreating s ystems that combine the initial ranked results with the effects of clustering on those results. 4. The re-ranking algorithm using post-retrieval clustering We propose a model based on similarity re-evaluation using cluster analysis, while a typical
CBIR system retrieves and ranks images according to the similarity based on the feature vector distance only. The idea of this model is to combine the results of feature-based retrieval and cluster analysis on the retrieval results. The proposed method is depicted in Fig. 1. We first re-trieve relevant images using image features. As we use post-retrieval clustering on the top-ranked images, we make relevant groups that contain similar images. Then, we analyze the similarity relationship between clusters of retrieved results and the quer yimage. The rank and similarit yof retrieved images are adjusted according to the cluster analysis, so we use a two-step method to retrieve the images.

In the first step, we calculate similarities between the quer yimage and the images from the database based on the image features. We use three image features for the techniques of repre-senting and retrieving images, because the yare widel yused and pla yan important role in CBIR.
The retrieved results are ranked in decreasing order of similarit ybetween the quer yimage and the images in the database.

Next, we construct a tree structure for the HACM as shown in Fig. 2. We use the top-ranked images of the first step and the city-block distance metric for the cluster construction. We employ four HACM for our experiments: single link, complete link, group average link, and Ward  X  s method. The comparative advantages and disadvantages of these methods have been reviewed comprehensivel yin the information retrieval literature (Frakes &amp; Baeza-Yates, 1992; Voorhees, 1985, 1986; Willett, 1988). To construct a clustering structure, we calculate a dissimilarit ymatrix using Eq. (3). Then the image or cluster pair at each stage joins the one whose merger minimizes the increase in the total distance according to the construction definition of each method. At each stage, the matrix carrying the difference of the values is updated using Eq. (8) and parameters in Table 1.
 After constructing the clustering structure, we partition the cluster set using proper thresholds.
To calculate the query-cluster similarity, we define the distance between the query image and clusters. We use four methods to compute the distance, as shown in Table 2: distance to a centroid, minimum distance to a quer yimage, maximum distance to a quer y, and average distance to all images in a cluster.
 Based on values of query-cluster similarity, we modify the distance of the results according to Eq. (9): image I 0 , and a and b are weighting factors to adjust the importance of the first result and the second result (clustering result).
 The I centroid is the centroid of cluster C  X  I 0  X  , and is defined as follows (Lee et al., 2001);
I size of C  X  I 0  X  .

Using Eq. (9), we re-calculate the similarities between the quer yimage and the images in the data collection. Then we re-order the ranks of the images according to the re-calculated values in decreasing order. Fig. 2 shows the sequence of re-evaluating the similarit ythat explains the construction of image clusters, and the combination of two similarities. According to the clus-tering hypothesis, images that have a greater similarity to each other are grouped into one cluster and irrelevant images are separated into different clusters. Therefore the similarit ybetween the modified to a larger value b yEq. (9).

In our method, we consider the five factors that influence the clustering analysis as follows:  X  Cut-off size ( N ): How man ytop-ranked images are clustered?  X  Cluster partitioning threshold ( T ): What is the best threshold at the agglomerative hierarchical clustering tree?  X  Weighting factors: What is the more important factor in combining the similarities? ( a ; b in Eq. (9)) ter analysis in the CBIR system?  X  Clustering method: What is the best clustering method for the CBIR system? 5. Experimental results
In previous sections, we have explained in detail the algorithm of the proposed method. In this section, we describe a test collection, state the evaluation measure based on a normalized ranking method, and state and discuss the implications of our experimental results. 5.1. Test collection
In order to evaluate the proposed method, we used 5466 images from MPEG-7 experimental data set to form the image database. The database included a variet yof images such as stock photo galleries, screen shots of television programs, and animations etc. We used a set of 50 common color queries (quer ysets), each with specified ground truth images. We used a color histogram based on 128 color bins of HSV color space, GLCM features, and an edge direction histogram for the initial retrieval. We also employed four HACM and four query-cluster simi-larit yfunctions for cluster anal ysis as introduced in previous sections. 5.2. Retrieval effectiveness evaluation measure: ANMRR
There are several evaluation measures for CBIR systems, such as precision/recall graph, simple ranking method, and precision/recall with scope. In our experiments, we used a normalized ranking measure: average normalized modified retrieval rank (ANMRR) that was defined b ythe MPEG-7 research group. This value is defined as follows (Manjunath, Ohm, Vasudevan, &amp; Yamada, 2001; Vinod &amp; Manjunath, 1999).

First, we define K  X  q  X  as min  X  4 NG  X  q  X  ; 2 GTM  X  , where GTM is max f NG  X  q  X g for all query of an image k . Rank  X  k  X  is defined as follows: Using Eq. (10), average rank (AVR) for query q is defined as follows:
However, with ground truth sets of different size, the AVR value depends on NG  X  q  X  . To minimize the influence of variations in NG  X  q  X  , modified retrieval rank (MRR) is defined as follows:
The upper bound of MRR depends on NG  X  q  X  . To normalize this value, normalized modified retrieval rank (NMRR) is defined as follows:
NMRR  X  q  X  has values between 0 (perfect retrieval) and 1 (nothing found). Finally, for the whole quer ysets, ANMRR is defined as follows: 5.3. Results
To evaluate the effectiveness of the proposed method, we examined various clustering pa-examined the effects of the four query-cluster similarity methods: Average, MIN, MAX, and
Centroid. Then we employed the four clustering methods: single link, complete link, group av-erage link, and Ward  X  s method. The results of the various parameters and clustering methods were complicated, so we fixed some of the parameters in each case. Finally, we examined how much improvement could be achieved b yusing the proposed method with optimal clusters, as opposed to using a method without clustering.

In our experiments we fixed the value of a to 1.0, and changed the b value varying from 0.25 to 1.5, using increments of 0.25. We also changed the value of T in each case, because each clustering method had different scope for the value of T . The value of T is related to the number of clusters, so we changed the value of T from the minimum to the maximum number of clusters. It was under these conditions that we conducted the experiments, the results of which are shown in Figs. 3 X 6 and Table 3. To compare our methods with the method without clustering, we computed the effectiveness of the initial retrieval b ycombining the three image features, and the ANMRR of initial retrieval was 0.0649.

Fig. 3 shows the effectiveness of the proposed method using various cut-off sizes. In this ex-periment, we used Ward  X  s method for HACM, and the centroid method for query-cluster simi-larity. Overall, the retrieval effectiveness was not much affected by the variation of N . However, when the value of N was either ver ysmall or ver ylarge, retrieval effectiveness worsened slightl y.
When the cut-off size was small, effectiveness improved little because the system could not perform little improvement, because the clustering results contained man yirrelevant images. All of the results in Fig. 3 are better than those of the initial method.
 Fig. 4 shows the effectiveness of the proposed method using MIN, MAX, Average, and
Centroid functions for query-cluster similarity. In this experiment, we used Ward  X  s method for
HACM, and 120 top-ranked images. The results show that the retrieval effectiveness of the method using the average method is better than other methods.

The results that are illustrated in Fig. 5 show the effectiveness of four clustering methods. In this experiment, we used the centroid method for query-cluster similarity, and 120 top-ranked images.
The results over the four clustering methods show that the group average method performed the best with respect to effectiveness, while the complete link method performed the worst.
The results of Figs. 4 and 5 show that considering all members of a cluster improved effec-tiveness more significantl yand was affected little b yweighting factors of combining similarities. All of the results in Figs. 4 and 5 are better than those of the initial method.

Fig. 6 shows the retrieval effectiveness of different numbers of clusters. In this experiment, we used the group average link method for HACM, the average method for query-cluster similarity, and 120 top-ranked images. Overall, almost all of the results in Fig. 6 are better than those of the initial method. As shown in Fig. 6, a ver ysmall number (under 5) or a ver ylarge number (over 75) of clusters did not improve retrieval effectiveness. The reason is that a small number of clusters or method without clustering.

Finally, Table 3 shows the results with best effectiveness and percentage change in each case, compared to the method without clustering, when we used four clustering methods and four cases of N values. To acquire these results, we changed all of the parameters, such as the number of clusters, values of b , and query-cluster similarity functions within possible ranges. When using the group average link method, effectiveness is improved more than 30% compared to the initial method. Table 3 also shows that the proposed method achieves an improvement of retrieval effectiveness of over 10% on average. The results of our experiments indicate that significant improvement of retrieval effectiveness could be achieved b ythe proposed method.

The retrieval examples of the method without clustering and our method are shown in Figs. 7 X  10. We mark the relevant images, which are pre-defined b ythe MPEG-7 communit y. It is clear that images relevant to the quer yare ranked higher in the results of the proposed method than in those of the method without clustering.

Note that the proposed method improves retrieval effectiveness significantly. As shown by the experiment results, when using the group average link method effectiveness improved over 30% in
ANMRR measure. We also knew that the retrieval effectiveness of the proposed method was affected by four factors: clustering methods, query-cluster similarity, the number of clusters, and combining weights. Our results over all experiments indicate that the methods with particular parameters are more effective. We experienced good and stable results when we used a cut-off size from 100 to 140, a value of b from 0.5 to 0.9, a number of clusters from 20 to 40, an Average query-cluster similarity function, and the group average link clustering method. In particular, the group average link clustering method was affected a little b yvalues of b .
 6. Concluding remarks In this paper, we have proposed a new re-ranking algorithm using post-retrieval clustering for
CBIR. This algorithm has advantages as it can utilize the relationship among the retrieved results via clustering. Extensive experiments with MPEG-7 image data show that our method improves retrieval effectiveness b yover 10% on average and more than 30% at best, compared to the method without clustering. This algorithm does have additional computation time for con-structing the clusters, but the additional time is small because the operation is performed on a small number of images (fewer than 200). In addition, we analyzed the effects of various clustering methods, query-cluster similarity methods, and the parameters of clustering. The experiments showed that the proposed method performs the most effectivel yunder our experimental condi-tions, when we use the group average link, the average distance function, around 25 numbers of clusters, and about 0.8 value of b . Since our method can use the tendenc yof grouping the re-trieved images, we believe that the re-ranking algorithm is a good method for enhancing effec-tiveness, compared to general image retrieval methods that use feature vectors only. References
