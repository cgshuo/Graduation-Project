 sively on building and scaling LinkedIn X  X  instant search ex-perience. To the best of our knowledge, this is the first tutorial that covers both theoretical and practical aspects of instant search.
 Information Retrieval; Instant Search; Query Understanding
Over the years search has become more focused on get-ting results as you type . Instant search has become a com-mon part of the user experience in nearly all popular search engines, including web search engines (like Google), verti-calized search engines (like Kayak) as well as social search engines (like Facebook, LinkedIn). The two broad categories of instant search include: 1. Instant Results (Figure 1). Here the actual result is 2. Instant Suggestions (Figure 2). Here the user is For the rest of this proposal, instant search refers to both the above aspects unless otherwise stated. From an infor-mation need perspective, it is useful to think about queries as belonging to two categories: 1. Navigational search . Here the user has a single en-2. Exploratory search . Here multiple results can sat-
The general approach for navigational search is to provide the result right away  X  most often in a typeahead dropdown box. As illustrated in Figure 1, this means providing the current temperature for San Jose, or presenting the people search results for the query  X  X h X  . For exploratory queries where the need can be met by multiple documents, the goal is not to provide results in the typeahead box, but instead guide the user in framing their query before they end up on the search engine results page (SERP).

For a great instant search experience, we will need the following aspects to work in tandem: researchers and practitioners would greatly benefit from an overview of these challenges, potential solutions and alter-natives, as well as the various trade offs involved.
Our goal in this tutorial is to provide an overview of the challenges involved, the various pieces of technology and rel-evance components that need to work together, and then walk the audience through the process of building a scalable system end-to-end. To the best of our knowledge, such a tutorial has not been presented before in the in-formation retrieval community. That said, there X  X  prior research that attempts to address various challenges posed by instant search  X  although in a piecemeal manner.
In the area of indexing and retrieval, Bast et al. [9] pro-posed a block-based index to improve retrieval speed by re-ducing random accesses to posting lists. But this does not address the problem of efficiently finding candidate comple-tions of the partially typed query. Li et al. [16] describe a trie based approach to represent prefixes, with posting lists at the leaf nodes. While such an approach works well for query autocomplete systems with few million entries, it X  X  much harder to scale further without additional retrieval techniques like early termination [7, 21, 22].

Early termination is a retrieval technique that avoids ex-haustively scoring all matching documents; this is achieved by reorganizing the index such that documents with high prior probability of relevance (generally referred to as  X  X tatic rank X ) appear first. Commonly used scores include within-document term frequencies [18], or some notion of document quality or popularity [10, 17]. Needless to say, the effec-tiveness of early termination hinges on the choice of  X  X tatic rank X , which in turn is highly dependent on the problem domain.

Fuzzy search is an area of research that aims to build retrieval systems that are tolerant to minor spelling errors or variations. While full word spelling correction is a well-studied problem [15, 13, 6], fixing spelling errors in partial queries as the user is typing is a relatively new area of re-search [11, 12].

In the area of personalized query suggestions, Bar-Yossef et al. [8] propose an approach that biases query completions towards previous queries in the same session. But this does not address single-query sessions, which are very common in navigational search use cases. Weber et al. [20] focused on how query likelihoods differ by demographics. Milad [19] provides a machine learning framework that can combine demographic and user features for generating personalized query completions.
 In terms of open source technologies, there are several JavaScript libraries for implementing client side autocom-plete, e.g. typeahead.js [4] and Bootstrap [3]. For the search backend, Apache Lucene [14] is a search engine library with support for full text search via a fairly expressive query lan-guage, extensible scoring, and high performance indexing. Elastic Search [1] is a search server based on Lucene that provides the ability to quickly build scalable search engines. It provides a distributed, multitenant-capable search engine with a HTTP web interface.

In this tutorial, we aim to bring together the best ideas from prior research and leverage open source technologies to put together a working end to end instant search experience over a publicly available dataset.
Ganesh Venkataraman currently leads jobs relevance at LinkedIn. His contributions at LinkedIn include, leading end to end re-architecture of job search, machine learned ranking for people search typeahead, introducing machine learned ranking towards skills search at LinkedIn. He co-authored a paper on personalized ranking which won the best paper award at the IEEE Big Data Conference 2015. He holds a Ph.D. from Texas A&amp;M in Electrical &amp; Com-puter Engineering where he was the recipient of the Dean X  X  graduate merit scholarship.

Abhimanyu Lad Abhimanyu (Abhi) Lad leads query understanding efforts at LinkedIn. His contributions include major improvements to query intent prediction, query sug-gestions, spelling correction, name search and leading a ma-jor re-architecture of LinkedIn people search stack. He holds a Ph.D. in Language and Information Technologies from Carnegie Mellon University, where he was the recipient of the Yahoo! Ph.D. Fellowship. He has several publications in the field of information retrieval and machine learning with over 130 citations.

Viet Ha-Thuc leads machine learning efforts for improv-ing search quality at LinkedIn. He has played a key role in designing and implementing machine learned ranking for personalized search and federation across several verticals at LinkedIn. His work on LinkedIn search has been published at conferences such as CIKM, Big Data and WWW. One of the publications received the Best Application Paper Award at 2015 IEEE Big Data. Prior to LinkedIn, he was a scientist in the Content Understanding group at Yahoo! Labs, where he developed a machine learning system for extracting rel-evant entities and concepts in text documents. The system was deployed to annotate every email and news article in the Yahoo! ecosystem. He received a Ph.D. in Computer Science from the University of Iowa in 2011.
 Dhruv Arya currently leads job search quality at LinkedIn. His goal is to apply machine learning and data mining ap-proaches to build talent matching algorithms that connect job seekers to the most relevant jobs. Apart from this, he has made key contributions to query understanding and rewrit-ing, whole page optimization, as well as personalized fed-erated search, which was presented at CIKM 2015. He re-ceived a Master X  X  degree in Computer Science from Univer-sity of Pennsylvania in 2013. [14] E. Hatcher and O. Gospodnetic. Lucene in action. [15] M. D. Kernighan, K. W. Church, and W. A. Gale. A [16] G. Li, J. Wang, C. Li, and J. Feng. Supporting [17] X. Long and T. Suel. Optimized query execution in [18] M. Persin, J. Zobel, and R. Sacks-Davis. Filtered [19] M. Shokouhi and K. Radinsky. Time-sensitive query [20] I. Weber and C. Castillo. The demographics of web [21] H. Yan, S. Shi, F. Zhang, T. Suel, and J.-R. Wen. [22] F. Zhang, S. Shi, H. Yan, and J.-R. Wen. Revisiting
