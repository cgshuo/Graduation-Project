
Learning communities from a graph is an important problem in many domains. Different types of communities can be generalized as link-pattern based communities. In this paper, we propose a general model based on graph ap-proximation to learn link-pattern based community struc-tures from a graph. The model generalizes the traditional graph partitioning approaches and is applicable to learn-ing various community structures. Under this model, we derive a family of algorithms which are flexible to learn various community structures and easy to incorporate the prior knowledge of the community structures. Experimental evaluation and theoretical analysis show the effectiveness and great potential of the proposed model and algorithms.
Learning communities from a graph is an important problem in many domains, such as web mining, so-cial network analysis, bioinformatics, VLSI design, and task scheduling. In many applications, users are inter-ested in strongly intra-connected communities in which the nodes are intra-community close and inter-community loose. Learning this type of communities corresponds to finding strongly connected subgraphs from a graph, which has been studied for decades as graph partitioning problem.
In addition to the strongly intra-connected communities, other types of communities also attract intensive attention in many important applications. For example, in Web mining, we are also interested in the communities of Web pages that sparsely link to each other but all densely link to the same Web pages [20], such as a community of music  X  X ans X  Web pages which share the same taste on music and are densely linked to the same set of music Web pages but sparsely linked to each other. Learning this type of communities cor-responds to finding dense bipartite subgraphs from a graph,
Figure 1. A graph with mixed community structures (a) and its community prototype graph (b). which has been listed as one of the five algorithmic chal-lenges in Web search engines [15].

The strongly intra-connected communities and weakly intra-connected communities are two basic community structures, and various types of communities can be gener-ated based on them. For example, a web community could take on different structures during its development, i.e., in its early stage, it has the form of bipartite graph, since in this stage the members of the community share the same in-terests (linked to the same web pages) but have not known (linked to) each other; in the later stage, with members of the community start linking to each other, the community becomes a hybrid of the aforementioned two basic commu-nity structures; in the final stage it develops into a larger strongly intra-connected community.

These various types of communities can be unified into a general concept, link-pattern based community. A link-pattern based community is a group of nodes which have the similar link patterns , i.e., the nodes within a commu-nity link to other nodes in similar ways. Let us have an illustrative example. Figure 1(a) shows a graph of mixed types of communities. There are four communities in Fig-ure 1(a), C 1 = { v 1 ,v 2 ,v 3 ,v 4 } , C 2 = { v 5 ,v 6 { v the strongly intra-connected community C 1 , the nodes have the similar link patterns, i.e., they all strongly link to the nodes in C 1 (their own community) and C 3 , and weakly link to the nodes in C 2 and C 4 ; Within the weakly intra-connected community C 3 , the nodes also have the similar link patterns, i.e., they all weakly link to the nodes in (their own community), and C 2 , strongly link to the nodes in
C 1 and C 4 ; Similarly for the nodes in community C 3 and the nodes in community C 4 . Note that graph partitioning ap-proaches cannot correctly identify the community structure of the graph in Figure 1(a), since they seek only strongly intra-connected communities by cutting a graph into dis-joint subgraphs to minimize edge cuts.

In addition to unsupervised community learning appli-cations, the concept of the link-pattern based community also provides a simple approach for semi-supervised learn-ing on graphs. In many applications, graphs are very sparse and there may exist a large mount of isolated or nearly-isolated nodes which do not have community pat-terns. However, according to extra supervised informa-tion (domain knowledge) these nodes may belong to certain communities. To incorporate the supervised information, a common approach is to manually label these nodes. How-ever, for a large graph, manually labeling is labor-intensive and expensive. Furthermore, to make use of these labels, instead of supervised learning algorithms, different semi-supervised algorithms need to be designed. The concept of the link-pattern based community provides a simple way to incorporate supervised information by adding virtual nodes to graphs. The idea is that if the nodes which belong to the same community according to the supervised information, they are linked to the same virtual nodes. Then an algorithm which is able to learn general link-pattern based communi-ties can be directly applied to the graphs with virtual nodes to make use of the supervised information to learn commu-nity patterns.

For example, to find the hidden classes from a collection of documents, a common approach is to represent the col-lection as a graph in which each node denotes a document and each edge weight denotes the similarity between two documents [10, 35]. Usually the similarities are calculated based on the term-frequency vectors of documents. How-ever, there may exist documents which share no or very few words with each other but still belong to the same commu-nity according to extra domain information. Let us have an illustrative example. In Figure 2, the dark color nodes (documents) do not share same words and are not linked to each other. However, they all belong to the  X  X ehicle X  com-munity. By adding virtual nodes (documents) (light color nodes in Figure 2) which are concept documents consisting of popular words for the  X  X ehicle X  community, the origi-nally isolated document nodes are linked to the virtual doc-ument nodes and the supervised information is embedded into link patterns.

Therefore, various applications involving unsupervised as well as semi-supervised community learning have pre-sented a great need to link-pattern based community learn-ing algorithms. In this paper, we propose a general model based on graph approximation to learn the link-pattern based community structure from a graph. By unifying the traditional edge cut objectives, the model provides a new view to understand graph partitioning approaches and at the same time it is applicable to learning various commu-nity structures. Under this model, we derive three novel algorithms to learn the general community structures from a graph, which cover three main versions of unsupervised learning algorithms, hard, soft and balanced version, to pro-vide a complete family of community learning algorithms. This family of algorithms has the following advantages: they are flexible to learn various types of communities; when applied to learning strongly intra-connected commu-nities, this family evolves to a new family of effective graph partition algorithms; it is easy for the proposed algorithms to incorporate the prior knowledge of the community struc-ture into the algorithms. Experimental evaluation and the-oretical analysis show the effectiveness and great potential of the proposed model and algorithms.
Graph partitioning divides the nodes of a graph into com-munities by finding the best edge cuts of the graph. Several edge cut objectives, such as the average cut [5], average as-sociation [30], normalized cut [30], and min-max Cut [11], have been proposed. Various spectral algorithms have been developed for these objective functions [5, 30, 11]. These algorithms use the eigenvectors of a graph affinity matrix, or a matrix derived from the affinity matrix, to partition the graph. Since eigenvectors computed do not correspond directly to individual partitions, a postprocessing approach [34], such as k-means, must be applied to find the final par-titions.

Multilevel methods have been used extensively for graph partitioning with the Kernighan-Lin objective, which at-tempt to minimize the cut in the graph while maintaining equal-sized clusters [4, 14, 17]. In multilevel algorithms, the graph is repeatedly coarsened level by level until only a small number of nodes are left. Then, an initial partition-ing on this small graph is performed. Finally, the graph is uncoarsened level by level, and at each level, the partition-ing from the previous level is refined using the refinement algorithm.

Recently, graph partitioning with an edge cut objective has been shown to be mathematically equivalent to an ap-propriate weighted kernel k-means objective function [7, 8]. Based on this equivalence, the weighted kernel k-means al-gorithm has been proposed for graph partitioning [9, 7, 8].
Learning communities from a graph has also been in-tensively studied in the context of social network analysis [29]. Hierarchical clustering [29, 33] has been proposed to learn communities. Recent algorithms [13, 24, 6] address several problems related to the prior knowledge of com-munity size, the precise definition of inter-nodes similar-ity measure, and improved computational efficiency [25]. However, their main focus is still learning strongly intra-connected communities. Some efforts [12, 31, 16, 16, 2] can be viewed as community learning based on stochastic block modeling.

There are efforts in the literature focusing on finding communities based on dense bipartite graphs [20, 27]. The trawling algorithm [20] extracts communities (which are called emerging communities in [20] as the counterpart con-cept of strongly intra-connected community) by first ap-plying the the Apriori algorithm to find all possible cores (complete bipartite graphs) and then expanding each core to a full-fledged community with HITS algorithm [19]. [27] proposes a different approach to extract the emerging com-munities by finding all bipartite graphs instead of finding cores.

In this study, we focus on how to divide the nodes of a graph into disjoint communities based on link patterns.
In this section, we propose a general model to learn link-pattern based communities from a graph.

To derive our model to learn latent community structure from a graph, we start from the following simpler prob-lem: if the link-pattern based community structure of any graph is known, can we draw a simple graph with explicit latent community structure (latent link patterns) to represent the original graph? We present the concept of a commu-nity prototype graph as an answer. A community prototype graph consists of a set of the community nodes and a set of links including self-links for each community node and inter-links for a pair of community nodes.

For example, Figure 1(b) shows a community prototype graph for the graph in Figure 1(a). Note that for conve-nience, in all the examples, we use 0-1 graphs where the edge weight 0 denotes the absence of edge between two nodes and the edges with weight 0 are not shown in the graphs. However, all the discussions are applicable to a gen-eral weighted graph. In Figure 1(b), the top-left community node is associated with the nodes of C 1 = { v 1 ,v 2 ,v 3 from the original graph; the self-link of the top-left com-munity node implies that all its associated nodes are linked to each other; the inter-link between the top-left commu-nity node and the bottom-left community node implies that the nodes of C 1 = { v 1 ,v 2 ,v 3 ,v 4 } arelinkedtothoseof C 3 = { v 9 ,v 10 ,v 11 ,v 12 } . Hence, the community prototype graph in Figure 1(b) provides a clear view of the community structure and link patterns for the original graph in Figure 1(a). Given the community structure of any graph, we can always draw its community prototype graph.

Therefore, learning the hidden community structures
Figure 3. A graph with strongly-connected communities (a) and its community prototype graph (b); the graph affinity matrices for (a) and (b), (c) and (d), respectively. from a graph can be formulated as finding its optimal com-munity prototype graph which is the  X  X losest X  to the orig-inal graph, i.e., based on this community prototype graph, the original graph can be constructed most precisely. By representing a graph as an affinity matrix, this problem can be formally formulated as an optimization problem of ma-trix approximation, where A  X  R n  X  n + denotes the affinity matrix of the orig-inal graph and A  X   X  R n  X  n + denotes the affinity matrix of a community prototype graph. The examples of A and A  X  are given in Figure 3(c) and 3(d), which are the affinity ma-trices for the original graph Figure 3(a) and its community prototype graph Figure 3(b), respectively.

Due to the special structure of a community prototype graph, its affinity matrix can be represented as a product of three factors such that A  X  = CBC T , where C  X  X  0 , 1 } n  X  k such that k is the number of communities and j C ij =1 , i.e., C is an indicator matrix that provides the community membership of each node (without loss of generality, we assume there is no empty community); B  X  R k  X  k + such that B is the community structure matrix that provides an intuitive representation of the community structure, since B ii denotes the self-link weight for the i th community node and B ij for i = j denotes inter-link weight between the i and the j th community nodes.

Based on the above observation, formally we define the problem of learning communities from an undirected graph as follows.
 Definition 3.1. Given an undirected graph G =( V , E ,A ) where A  X  R n  X  n + is the affinity matrix, and a positive in-teger k , the optimized communities are given by the mini-mization, where 1 denotes a vector consisting of 1 X  X  (we omit its di-mension, since it is clear in the context).
 Definition 3.1 provides a general model, Community Learning by Graph Approximation (CLGA), to learn var-ious community structures from graphs. In the CLGA model, the number of communities k is given. How to de-cide the optimal k is a non-trivial model selection problem and beyond the scope of this paper.

The problems of finding specific types of communities can be formulated as special cases of the CLGA model. For example, although there are different formulations of graph partitioning with different objective functions, they all can be viewed as special cases of the CLGA model. Since graph partitioning is a very important case of community learning, we propose the following theorem to establish the connec-tion between the CLGA model and the existing graph parti-tioning objectives.

Without loss of generality, we first re-define the cluster indicator matric C as the following weighted cluster indica-tor matrix  X  C , where |  X  j | denotes the number of nodes in the j th commu-nity. Clearly  X  C still captures the disjoint community mem-berships and  X  C T  X  C = I k where I k denotes k  X  k identity matrix.
 Theorem 3.2. The CLGA model in Definition 3.1 with the extra constraint that B is an identity matrix, i.e., is equivalent to the maximization where  X  c p denotes the p th column vector of  X  C . Proof. Let tr ( X ) denote the trace of a matrix X and L de-note the objective function in Eq. 3.
 The above deduction uses the property of trace tr ( XY )= tr (
YX ) . Based on Eq.(8), since tr ( A T A ) and k , the num-ber of communities, are constants, the minimization of L is equivalent to the maximization of k p =1  X  c T p A  X  c p is completed.

Table 1. A list of variations of the CLGA model.

Theorem 3.2 states that if we fix the community structure matrix B as the identity matrix I k (the more general case is aI k for any a  X  R + ), the CLGA model is reduced to the trace maximization in (4). Since various graph partitioning objectives, such as ratio association [30], normalized cut [30], ratio cut [5], and Kernighan-Lin objective [18], can be formulated as the trace maximization [7], Theorem 3.2 establishes the connection between the CLGA model and the existing graph partitioning objectives.

Therefore, the traditional graph partitioning can be viewed as a special case of the CLGA model in which B is restricted to be an identity matrix. By fixing B as an identity matrix, the traditional graph partitioning objectives make an implicit assumption about community structure of the target graph, i.e., they assume that the nodes within each community are fully connected (the diagonal elements of B are all 1 X  X ) and the nodes between communities are dis-connected (the off-diagonal elements of B are all 0 X  X ), i.e., the community prototype graphs consist of a set of sepa-rated community nodes with self-links. This assumption is consistent with our intuition about an ideal partitioning (we call this special case of CLGA model Ideal Graph Par-titioning (IGP)). However, it cannot catch the community structures deviating from the ideal case. For example, for a graph that has one strongly intra-connected graph and one relative weak intra-connected graph, assuming B to be CLGA model provides the flexibility to learn B under var-ious constraints. If B is relaxed from the identity matrix to any diagonal matrix, i.e., if we assume zero connectivity between communities but let the algorithm learn the within-community connectivity, we obtain a new graph partitioning model as another special case of the general CLGA model, which we call General Graph Partitioning (GGP).
 Similarly, with the appropriate constraint on B ,the CLGA model may focus on other specific types of com-munity structures. For example, by restricting B to be the matrix whose diagonal elements are 0 and off-diagonal ele-ments are 1, CLGA learns the ideal weakly intra-connected communities among which each pair of communities forms a dense bi-partite graph (call it Ideal Bi-partite Community Learning (IBCL)); by restricting B to be the matrix whose diagonal elements are 0, CLGA learns communities of gen-eral bi-partite subgraphs (call it General Bi-partite Commu-nity Learning (GBCL)).

Table 1 summarizes several variations of the CLGA model. For simplicity, for the general situation without any constraints on B , we call it as General Community Learning (GCL). The community structure matrix B plays an impor-tant role in the CLGA model. If we have prior knowledge about the community structure of the graph or we are only interested in some special types of communities, it is easy to incorporate it into the model by putting an appropriate constraint on B .
In this section, we derive algorithms for the basic CLGA model in Definition 3.1 and its extensions, soft CLGA model and balanced CLGA model.
The CLGA model in Definition 3.1 seeks hard commu-nity membership for each node and the problem can be shown to be NP-hard. The proof is easy since based on The-orem 3.2 it can be reduced to the graph partitioning prob-lem, which is NP-hard. We derive an alternative optimiza-tion algorithm for the hard CLGA model.

We prove the following theorem which is the basis of our algorithm.
 Theorem 4.1. If C  X  X  0 , 1 } n  X  k and B  X  R k  X  k + are the optimal solution to the minimization in Definition 3.1, then Proof. The objective function in Definition 3.1 can be ex-panded as follows.

L = || A  X  CBC T || 2 Take the derivative with respect to B , we obtain Solve  X  X   X  X  =0 to obtain Note that C T C is a special diagonal matrix such that [ C T C ] pp = |  X  p | , the size of the p th community, and since A is a non-negative symmetric matrix, so is B . This com-pletes the proof of the theorem.

Based on Theorem 4.1, we propose an iterative algorithm which alternatively updates B and C and converges to a local optimum. First, we fix C and update B .Eq(9)in Theorem 4.1 provides an updating rule for B . This updat-ing rule can be implemented more efficiently than it looks Algorithm 1 Hard CLGA algorithm like. First, it does not really involve computing inverse ma-trices, since C T C is a special diagonal matrix with the size of each community on its diagonal; second, the product of C T AC can be calculated without normal matrix multipli-cation, since C is an indicator matrix.

Second, we fix B and update C . Since each row of C is an indicator vector with only one element equal to 1, we adopt the re-assignment procedure to update C row by row. To determine which element of the h th row of C is equal to 1, for p =1 ,...,k , each time we let C hp =1 and com-pute the objective function L = || A  X  CBC T || 2 , which is denoted as L p , then Note that when we update the h th row of C , the necessary computation involves only the h th row or column of A and
The algorithm, Hard CLGA, is summarized in Algorithm 1. The hard CLGA algorithm learns the general community structures from a graph, since it does not put any constraint on B . However, it is trivial to modify it to solve the varia-tions of the general CLGA model, such as IGP, GGP, IBCL and GBCL in Table 1. For example, the hard IGP algorithm works as follows: fix B as the identity matrix and simply update C by updating rule (12) until convergence; the hard GGP algorithm works as follows: fix the off-diagonal ele-ments of B as zero; update the diagonal elements of B by updating rule (9) and update C by updating rule (12) until convergence. Besides the variations in Table 1, it is easy for Algorithm 1 to incorporate other prior knowledge through B .
 The complexity of hard CLGA can be shown to be O ( tn 2 k ) where t is the number of iterations. It can be fur-ther reduced for sparse graphs. When applied to graph par-titioning task, the hard CLGA algorithm is computationally more efficient than the popular spectral approaches which involve expensive eigenvector computation and extra post-processing on eigenvectors to obtain the partitioning. Com-pared with the multi-level approaches such as METIS [17], CLGA does not restrict communities to have an equal size.
The proof of the convergence of Algorithm 1 is easy due to the following facts. First, based on Theorem 4.1, the ob-jective function is non-increasing under updating rule (9); second, by the criteria for reassignment in updating rule (12), it is trivial to show that the objective function is non-increasing under updating rule (12).
In the hard CLGA model of Definition 3.1, each node belongs to only one community. It is natural to extend it to a soft version, in which each node could belong to more than one community with certain degrees. Formally, we define the soft CLGA model as follows.
 Definition 4.2. Given an undirected graph G =( V , E ,A ) where A  X  R n  X  n + is the affinity matrix, and a positive in-teger k , the optimized communities are given by the mini-mization,
In the soft CLGA model, C is a soft membership matrix such that C ij denotes the degree that the i th node is associ-ated with the j th community and the sum of all the degrees for each node equals to 1. Since the soft CLGA model de-fines a constrained non-convex optimization, it is not real-istic to expect an algorithm to find a global optimum. We propose an alternative optimization algorithm which con-verges to a local optimum.
 Deriving the updating rules for C and B in the soft CLGA model is more difficult than in the hard CLGA model. First, it is difficult to deal with the constraint  X  X oft X  constraint, i.e., we implicitly enforce the constraint by adding a penalty term,  X  || C 1  X  1 || 2 where 1 is a k-dimension vector consisting of 1 X  X ,  X  is a positive constant. Therefore, we obtain the following optimization.
Fixing B , the objective function in (14) is quartic with respect to C . We derive a simple and efficient updating rule for C based on the bound optimization procedure [28, 22]. The basic idea is to construct an auxiliary function which is a convex upper bound for the original objective function based on the solution obtained from the previous iteration. Then, a new solution for the current iteration is obtained by minimizing this upper bound.
 Definition 4.3. G ( S, S t ) is an auxiliary function for if G ( S, S t )  X  F ( S ) and G ( S, S )= F ( S ) .
The auxiliary function is useful due to the following lemma.
 Lemma 4.4. If G is an auxiliary function, then F is non-increasing under the updating rule S t +1 = arg min Proof. F ( S t +1 )  X  G ( S t +1 ,S t )  X  G ( S t ,S t )  X  F
We propose an auxiliary function for C in the following theorem.
 Lemma 4.5.
 is an auxiliary function for Proof. For convenience, we let  X  =  X  nk .

During the above deduction, the second step uses Jensen X  X  inequality and the fifth step uses the inequalities x  X  1+ log x and x 2 + y 2  X  2 xy .
 The following theorem provides the updating rule for C . Theorem 4.6. The objective function F ( C ) in Eq. (15) is nonincreasing under the updating rule, where  X  C denotes the solution from the previous iteration, denotes a k  X  k matrix of 1 X  X , denotes entry-wise product, and the division between two matrix is entry-wise division.
The Theorem can be proved by solving  X  X  ( C,  X  C )  X  X  and using Lemma 4.4 (details are omitted due to the space limit).

Similarly, we present the following theorems to derive updating rules for B . Note that Theorem 4.1 cannot be used to update B , since C does not have the special structure of the indicator matrix in this case; updating rule (9) cannot guarantee that B is non-negative. To guarantee that B can be updated appropriately, we have the following theorems. Lemma 4.7.
 is an auxiliary function for Theorem 4.8. The objective function F ( B ) in Eq. (17) is nonincreasing under the updating rule
Following the way to prove Lemma 4.5 and Theorem 4.6, it is easy to prove the above theorems. We omit details here.

The soft CLGA algorithm is summarized in Algorithm 2. The implementation of the algorithm is simple and it is easy to take the advantage of the distributed computation for very large data. The complexity of the algorithm is still O ( tn 2 k ) for t iterations and it can be further reduced for sparse graphs. The convergence of the soft CLGA algo-rithm is guaranteed by Theorem 4.6 and 4.8.

Like the hard CLGA algorithm, the soft CLGA can be applied to learning the specific types of community struc-tures by enforcing the corresponding constraint on B .For example, soft IGP and GGP provide another two new graph partitioning algorithms and they deal with the soft graph partitioning problem which has not been addressed exten-sively in the literature of graph partitioning.
 Algorithm 2 Soft CLGA algorithm
In some applications, users may be interested in commu-nities of a balance size. We propose the balanced CLGA model as follows.
 Definition 4.9. Given an undirected graph G =( V , E ,A ) where A  X  R n  X  n + is the affinity matrix, and a positive in-teger k , the optimized communities are given by the mini-mization, Unlike C 1 = 1 in the soft CLGA model, we have C T 1 = 1 in the balanced CLGA model, i.e., the sum of elements in each column of the community membership matrix equals to 1. This constraint enforces that for each community, the sum of degrees that each node is associated with this community equals to 1. As a result, the more the nodes in a certain community, the smaller the average de-gree that each node is associated with this community, the more a node tends to belong to other communities with a relative larger degree. Therefore, compared with the other two CLGA models, the balanced CLGA model tends to provide more balanced communities. Note that this con-straint does not enforce strictly balanced communities of equal sizes and it just pushes the model to provide commu-nities as balanced as possible.

Due to the following lemma, the balanced CLGA model can be simplified by dropping the constraint C T 1 = 1 . Lemma 4.10. If C  X  R n  X  k + , B  X  R k  X  k + , and D  X  R k is a diagonal matrix s.t. D jj = 1 Proof. omitted.

Lemma 4.10 implies that we can always normalize C to satisfy the constraint without changing the value of the ob-jective function. Hence, the balanced CLGA can be reduced to the following optimization, Algorithm 3 Balanced CLGA algorithm
Following the way to derive the soft CLGA algorithm, we derive the balanced CLGA algorithm. Since Lemma 4.7 and Theorem 4.6 still hold true for the optimization in (20), the balanced CLGA has the same updating rule for B as the soft CLGA algorithm. By dropping off the term  X  || C 1  X  1 || 2 in (14), the theorems similar to lemmas 4.5 and 4.6 can be obtained to derive a simpler updating rule for C (details are omitted due to the space limit). The balanced CLGA algorithm is summarized in Algorithm 3. Similarly, by enforcing constraints on B , it is easy to obtain other ver-sions of the balanced CLGA algorithm, such as balanced IGP and balanced GGP.
In this section, we present experimental results to show the effectiveness of various CLGA algorithms.
The data sets used in the experiments include synthetic graphs with different types of community structures and real graphs for text mining and social network analysis. The synthetic graphs are 0-1 graphs generated based on Bernoulli distribution. The distribution parameters to gen-erate the graphs are listed in the second column of Table 2 as matrices. In a parameter matrix P , P ij denotes the prob-ability that the nodes in the i th community are connected to the nodes in the j th community. For example, in graph W1, the nodes in community 1 are connected to the nodes in community 2 with probability 0 . 1 and the nodes within communities are connected to each other with probability 0. The graph G2 has ten communities mixing with strongly intra-connected and weakly intra-connected communities. Due to the space limit, its distribution parameters are omit-ted here. Totally G2 has 5000 nodes and about 2 . 1 million edges.

The graphs based on the text data have been widely used to test graph learning algorithms [11, 10, 35]. We use
Table 2. Summary of the graphs with general communities
Table 3. Summary of graphs based on text datasets various data sets from 20-newsgroups [21], WebACE and TREC [1] to construct the real graphs. The data are pre-processed by removing the stop words and each document is represented by a term-frequency vector using TF-IDF weights. Then we construct a graph for each data set such that each node denotes a document and the edge weight de-notes the cosine similarity between documents. A summary of all the data sets to construct graphs used in this paper is shown in Table 3, in which n denotes the number of nodes in a graph, k denotes the number of true communities, and balance denotes the size ratio of the smallest community to the largest community. Besides the graphs constructed di-rectly from these data sets, we also construct three graphs with virtual nodes, v-tr23, v-tr45 and v-NG1-20, for three relatively difficult data sets. 5% n virtual nodes are added into the original graphs to incorporate supervised informa-tion. To simulate the concept documents provided by do-main expert in real applications, the  X  X ean X  documents of the communities, which contain popular words of the cor-responding communities, are used as virtual documents.
For performance measure, we elect to use the Normal-ized Mutual Information (NMI) [32] between the resulting community labels and the true community labels, which is a standard way to measure the cluster quality. For the num-ber of communities k , we simply use the number of the true communities, since how to choose the optimal number of communities is a nontrivial model selection problem and beyond the scope of this paper.

Three versions of algorithms under different CLGA models as listed in Table 1 are tested in the experiments. We use  X  X - X ,  X  X - X  and  X  X - X  to represent hard, soft and balanced versions, respectively. Two representative graph
Table 4. NMI scores on graphs of general communities learning algorithms are selected as comparisons. Spectral approaches have been applied to a wide range of graph learning tasks from regular graph to bi-partite[10] and k-partite graph learning [23]. In this study, we select to use Spectral Graph Clustering (SGC) [26] that is generalization of a number of graph learning algorithms. SGC learns link-pattern based community structure by embedding commu-nity structures into eigen-space and discovering them by the eigenvectors. Another comparison is the classic multilevel graph partitioning algorithm, METIS [17].
Table 4 shows the NMI scores of the eleven algorithms on the graphs listed in Table 2. Each NMI score is the aver-age of ten test runs. The graph S1 has three strongly intra-connected communities. We observe that all the GGP algo-rithms provide perfect scores on S1. However, the GBCL algorithms totally fail, since their goal is to learn weakly intra-connected communities which do not exist in S1. The GCL algorithms perform not as good as the GGP algo-rithms. The possible reason is that they do not focus on strongly intra-connected communities and hence have more local optimal solutions to converge. The graph W1 con-sists of three weakly intra-connected communities. This time the GBCL algorithms provide perfect or nearly per-fect performance scores. METIS totally fails, since it only looks for strongly intra-connected communities. SGC iden-tifies part of community structures but its performance is not satisfactory. Both G1 and G2 are graphs of mixed-type community structures. Since there is only one strongly intra-connected community in G1, it is still difficult for the GGP algorithms and METIS to identify it. The graph G2 is a large graph of ten communities consisting of four strongly intra-connected communities and six weakly intra-connected communities. The GGP and METIS algorithms do not totally fail on G2, since they could learn strongly intra-connected part from G2. The GBCL algorithms could learn weakly intra-connected part from G2. However, over-all the GCL algorithms perform better especially on G1 and G2, since they are capable of learning general communities of various types. In summary, the CLGA model provides a family of algorithms for effectively learning general link-pattern based community as well as specific types of com-munity.
 Table 5 shows the NMI scores of the nine algorithms. Since the graphs mainly consist of strongly intra-connected communities, GBCL algorithms are not appropriate. Hence IGP (GGP works similarly to IGP and their result are omit-ted) and GCL results are reported in comparison with SGC, METIS and a state-of-the-art document clustering algo-rithm, VMF, which is based on von Mises-Fisher distrib-ution and was reported as one of the best document clus-tering algorithm [3]. We observe that although there is no single winner on all the graphs, for most graphs CLGA al-gorithms perform better than or close to SGC, METIS and VMF. The CLGA algorithms provide the best performance on eight out of the nine graphs. By adding virtual nodes into the graphs, the community structures are reinforced by link patterns induced by the virtual nodes. Although all the al-gorithms benefit from the virtual nodes, CLGA algorithms always achieve the best performance on the graphs with vir-tual nodes. For example, S-GCL provides the best perfor-mance on v-tr23 and increases the performance about 50% by making use of the virtual nodes. Hence, when learning the communities of documents (with or without supervised information), the CLGA model provides a family of new algorithms which are competitive compared with the exist-ing state-of-the-art graph learning algorithms and document clustering algorithm.

We also run the GCL algorithm on the actor graph based on IMDB movie data set for a case study of social network analysis. We formulate a graph of 20000 nodes, in which each node represents an actor and the edges denote collab-oration between actors. However, we delete all the links between the actors of the same gender, i.e., the links be-tween male actors and the links between female actors. Al-though there is no ground truth for the community structure of this graph, the GCL algorithm provides a large number of meaningful communities, which represent the major cast members of one movie or movie series. For example, Ta-ble 6 shows Community 11 consisting of 10 male actors and Community 87 consisting of 12 female actors and the community structure shows that the two communities are strongly related to each other. In fact, all these actor/actress are from the movies series  X  X merican Pie X . Although the links within the communities are missing, these communi-ties are still identified by the GCL algorithm.
In this paper, we propose a general model based on graph approximation to learn link-pattern based community struc-tures from a graph. The model demonstrates a good theo-retic generalization by unifying the traditional graph parti-tioning objectives and providing a new view to understand
Table 6. Two communities from the actor graph.
 the graph partitioning problem. Under this model, we de-rive three novel algorithms to learn the general community structures from a graph, which cover three main versions of unsupervised learning algorithms, hard, soft and balanced versions, to provide a complete family of community learn-ing algorithms. Besides the theoretic analysis, extensive experiments on both real and synthetic graphs also demon-strate the effectiveness and the great potential of the pro-posed model and algorithms. This work is supported in part by NSF (IIS-0535162), AFRL (FA8750-05-2-0284), and AFOSR (FA9550-06-1-0327), and a research internship at Google Research.
