 Interdisciplinary scientific research (IDR)[2] is important to create new research areas, such as quantum information processing and bioinformatics, by utilize several subjects theories or methods. It is important to find promising methods that can be used in multiple areas. Christos[16] said that  X  The criterion is that if I see a method being applied two or three times, or being reinvented two or three times, then it is probably a method that could have application also in databases.  X  If one method can be applied in several scientific fields, the diversity of its citing papers is often high while the diversity of its cited papers and the paper itself is often low. This paper is aiming to identify those influential papers for IDR by proposing a ranking measure that takes the diversity of the citations into consideration. We also combine the Latent Dirichlet Allocation topic model with diversity measure to find the influential paper for interdisciplinarity. The main contributions can be summarized as follows.
 1. We study the problem of finding influential papers from the literature of 2. A citation diversity-based approach is proposed to measure the importance 3. We conduct extensive experiments both on real and synthetic datasets to
The rest of the paper is organized as follows. In Section 2, the related work is discussed based on diversity. Section 3 describes the taxonomy of papers consid-ering the citing relationship and propose the methods to explore the influential papers. Experimental evaluation usi ng real and generated data are shown in Section 4. Conclusion and future work are discussed in section 5. There are many metrics to measure the influence or importance of one pa-per, such as the citation number (in-degree), H-index, and PageRank value. Recently, [15] proposes a graph ranking method by utilizing citations, authors, journals/conferences, and the publication time information. However, the impact on interdisciplinary is ove rtaken by these measures.

In recent years, various diversity mea sures have been employed to measure the impact of paper for interdisciplinary research [3,10,11,13]. [13] proposes three different attributes of diversity: variety, balance and disparity.  X  X ariety X  is the number of topics,  X  X alance X  is the topics distribution and  X  X isparity X  is the distance between each pair topics. The classic diversity measure, such as Shannon entropy, combines the variety and balance while ignores disparity. Stirling[13] proposes a general diversity heuristic function as follows: where d is a document, P ( i | d )and P ( j | d ) are the proportions of category i and j , sim ( i,j ) is the similarity between category i and j ,and  X  ,  X  are the tuning parameters. When  X  =  X  = 1, the expression (1) is collapsed to a variant of Rao X  X  diversity [12]. [10] uses the number of disciplines, their distribution and distance between knowledge sources to measure the diversity by (1). Their ex-periments conducted on publications from six research domains between 1997 and 2005 to demonstrate the rising interdisciplinarity. Rafols[11] treats the di-versity and network coherence as indicato rs of interdisciplinarity and carries out case studies on bionanoscience publications. The intuition behind these two in-dicators are verified from the experimen ts: diversity reflects the breadth of a paper X  X  knowledge, and coherence represents the novelty. Text-based measures are employed in [3] and the LDA topic model is adopted to measure the variety, balance and disparity.

Similar to former work,thispaper follows[3]to calculatethepaper/publication X  X  diversity. However, instead of detecting the interdisciplinarity or diversity of each paper itself, we focus on detecting the influential papers with diverse citation from differentareas.Thoseinfluentialpapers,wheresomepromisingmethodsor theories areproposed,areveryimportantforIDR.Besidesthevariety,balanceanddisparity of each paper, we also take into account the citations, which are an important factor to measure the diverse influence of a paper/publication. This section presents our method to find influential papers for interdisciplinarity. Firstly, we discuss the characteristics of papers and classify them into three categories according to the citation relationships. 3.1 Categories of Papers Given a paper d , cited papers are the references of d , denoted as R ( d ), while citing papers are these papers which cite d , denoted as C ( d ). As Figure 1, we observe that most of the papers can be classified into three categories: interdisciplinary, influential and single-domain. Here, the recently published papers are ignored, because there is no citation information for them. In the following section, we propose a method to find these influential papers.  X  Interdisciplinary Paper: These papers in this category not only cite pa- X  Influential Paper: The paper like D2 in Figure 1 belongs to this category.  X  Single-Domain Paper: The last category of papers is single-domain paper
This paper is focusing on identifying the influential papers belong to the second category. 3.2 Our Measure Intuitively, if one method can be applied in several scientific fields, the diversity of its citing papers is often high while the diversity of its cited papers and the paper itself is often low. For example, the paper which proposes Latent Dirichlet Allo-cation(LDA) topic model has been cited b y many papers in theoretical computer science, natural language processing, computer vision and recommender systems. Combining both diversity of a paper d , paper X  X  cited papers and its citing papers, we propose the following score to measure its influence for interdisciplinarity.  X  is a tradeoff parameter in the range [0 , 1].

The Rao X  X  diversity [12] is adopted as in [3]. where P ( i | d ) is the probability of topic i in a paper d (i.e., P ( i | d )= n di n n di is the number of words in d belonging to topic i , n d is the number of words in d ),  X  ( i,j ) is the distance between two topics i and j and T is the topics set.
The topic distribution P ( i | d ) can be estimated through training Latent Dirich-let Allocation (LDA) topic model [4] on publication repository.
 topic distribution of citing papers (denoted as P c (  X | d ) ) and cited papers (de-noted as P r (  X | d ) ) should be estimated from the pap er repository. Besides those distributions, the distance between them should also be calculated. The next two sections will discuss the detail. 3.3 Topic Co-occurrence Similarity Analysis The topic distance  X  ( i,j ) is opposite to the topic co-occurrence similarity. We use  X  ( i,j )=1 /sim ( i,j ) as the distance between topic i and topic j . Several similarity measures can be used. The formula of the cosine similarity is as follows: The joint probability of two topics appearing in one paper is defined as: where P ( d )isestimatedby n d N and N is the number of words of all papers.
The above similarity measure assumed that each word contributes equally. Al-ternatively, we can treat each document equally. The similarity can be computed as the function of topic distributions: or, where D is the paper set and | D | is the number of papers.

Note that there are a large number of topic pairs i,j , the similarity sim ( i,j ) between them may be very small or even equal to zero which leads  X  ( i,j )to be very large or singular. When using the Rao X  X  diversity, it has little impact on measuring the diversity of paper itself. Because sim ( i,j ) is near to zero, P ( i | d ) P ( j | d ) is also very small or near to zero. The diversity of the paper is sim ( i,j ) = 0. The similarity between topics does not need to be smoothed.
However, when computing the diversity of a paper X  X  cited or citing papers, it is sensitive to the disparity attribute. For some topic pair i,j ,ithappens over-amplification of the diversity score. In order to mitigate this problem, the Dirichlet prior smoothing [17] is employed: where  X  d is a constant or a variable value based on the word count of paper d (e.g.,  X  d =0 . 1 | d | ) 3.4 Topic Distribution Analysis of Cited Papers and Citing Papers Now the remaining problem is estimating the topic distributions of R ( d )and C ( d ). Intuitively, we can treat R ( d )or C ( d ) as one document respectively. Then their topic distributions can be estimated as follows:
Note that when defining the formula (10), it is assumed that each word con-tributes equally. When the length of papers varies largely in the dataset, the influence of longer papers may be overestimated by this method. To overcome this deficiency, we treat all the cited or citing papers equally. We sum the P ( i | d )s of R ( d )and C ( d ) respectively as normalization factors. This normalization is de-fined as follows: where P r ( i,k | d )or P c ( i,k | d ) is the probability of topic i in the document k which is a cited or citing paper of d .

However, for papers with many citations, some topics X  proportion may be very large. When P c ( i | d )forsometopic i is high, the overall diversity score may be dominated by this topic distribution unevenly.

Example 1. Consider the case shown in Table 1. The paper d 1 has 900 citations on topic A and 100 citations on topic B respectively. Another paper d 2 has 70 citations on topic A and 30 citations on topic B respectively. The proportion of each topic P ( i | d ) calculated using formula (12) are listed in the right two columns. We assume that  X  ( A,B )=1 and  X  ( A,A )=  X  ( B,B )=0 .So div d 1 c all =0 . 9  X  0 . 1  X  1=0 . 09 the influence for interdisciplinarity of d 1 is more than d 2 .

From the above example, we know that for papers with more citations, the balance attribute affects the diversity score too much. To tackle this problem, we should reduce the weight of balance. Therefore we propose the following adjusted formulation by adding a discounting weight  X  i for each topic i :
To calculate this measure, we need to rank cited papers and citing papers firstly. One straightforward and efficient way is ordering papers by years of pub-lication. For each topic i , the total distance from other topics, j  X  T  X  ( i,j ), represents the similarity with ot her topics. Therefore, we take j  X  T  X  ( i,j )into small constant (e.g. is set to 0.05 or 0.01) to avoid  X  i =1. We evaluated the method proposed in this paper using both synthetic and real datasets. In this section, we first elaborate on datasets and experimental setting. We then compared the three methods on those datasets under specific parameter setting. 4.1 Settings Firstly, the stemming technique is used to process all documents in the paper collection. Then we use MALLET [1] to train LDA topic model, where standard stop-word removal, lowercase transformation and word segmentation were con-ducted. When training LDA topic model, the parameters setting follows [3]. We learn LDA topic models with 10, 30, and 100 topics.

As there is no ground truth dataset, we gen erate artificial citation relationship between papers. We use five journals from PubMed Central Open Access dataset (PubMed) to set up the pseudo-relationships. These five journals are shown in Table 2 and they are all unrelated. Here we create two kinds of artificial citation relationships. In the first setting, we assign each paper with 10 cited papers and 1to80citingpapers.Bothcitedpapersa nd citing papers are selected randomly from one or two journals. So there are three kinds of artificial documents rep-resenting D1 , D2 and D3 . For each case, we create 200 papers and 600 papers respectively. By this setting, we aim to examine the effectiveness of our method on distinguishing the influential papers from other papers. The second one is set to measure the effectiveness of three meth ods with different variety or citations. We use the same number of citing papers (e.g., five papers) of each journal and different number of journals to simulate different variety. In another way, the same number of journals and different n umber of citing papers (e.g., one kind has 5 citing papers of each journal and another has 10 citing papers with the same number of journals.) are created to simulate different citations. We also carry out case studies on a real dataset, the ArnetMiner dataset [14]. We train the LDA on the paper X  X  abstract repository. However, the abstract of many papers is missed. We crawl them from the Microsoft Academic Search 1 . We choose the papers whose number of cited papers are greater than 5 and have more than 10 citations. There are about 20k documents and 290k referring or citing relationships. 4.2 Experimental Results on Pseudo-Document Dataset In this section, we discuss the experimental results on pesudo-document dataset. Since the results are similar with cosine similarity and joint probability, we just report the results with the cosine similarity. We compare the performances of three methods on the synthetic dataset:  X  All cited or citing papers as One document(AO): treats all cited or citing  X  Normalized Cumulative Topic Distributions(NCTD): uses the cumulative  X  Normalized Discounted Cumulative Topic Distributions(NDCTD): uses the
According to [3], the area under the receiver operating characteristic (ROC) curve, known as the AUC[5], is used to e valuate the effectiveness of our ap-proaches. The ROC plots on the X-axis and TP(14) on the Y-axis.

FP =
The AUC represents the probability that a randomly chosen negative example will have a smaller estimated probability of belonging to the positive class than a randomly chosen positive example.

Firstly, we examine the ability of three approaches on distinguishing influential papers from others. In this set of experiments, the parameter  X  is set to 0.4. The results are shown in Table 3. It can be seen that all three methods can be used to distinguish the influential papers from others well. The approach NDCTD outperforms other two methods, while AO and NCTD have similar performance. Moreover, the best results are achieved for the three methods with 30 topics. When the number of topics is set to more than 30, the effectiveness of the three methods degrades. The reason is that the diversity is sensitive to high topic distance  X  ( i,j ) even using Dirichlet prior smoothing. We also conduct another experiment where we take papers from 4 or 5 journals into cited or citing papers (high diversity). On the other hand, the low diversity papers are with cited or cited papers from 1 or 2 journals. We find that the results are more better and all are higher than 0.97. These results indicate that these methods can distinguish the influential papers from other two kinds effectively.

To test the sensitiveness of method on the parameter  X  , we set the value of  X  from 0.2 to 0.6 with 10, 30 and 100 topics. From the results shown in the Figure 2, we can find that it is reasonable to set  X  to be less than 0.5. In the most cases, the best results of three methods are achieved when  X   X  0 . 3 or 0 . 4. It means that the cited papers X  influence is a little more than the citing papers.
Next we examine the effectiveness of three methods with different variety or citations. Table 4 shows the results with different variety.  X 1vs2 X  means that the data set has two kinds of artificial citing relationships to compare:  X 1 X  means that there is only one kind/category of journals in the citing papers and  X 2 X  means two kinds/categories.  X 2vs3 X ,  X 3vs4 X  and  X 4vs5 X  denotes the similar meaning. The results show that when the number of journals grows, it is harder to distinguish. Especially, while the number of journals is not less than 2, it is not easy to distinguish them.
For the influential papers, the citations are also an important factor besides variety, balance and disparity. The importance of papers is reflected by the num-ber of citations. So we conduct another experiment. We fix the journals and vary the number of citations from five to ten. The result is shown in Table 5. As ex-pected, the method NDCTD is the best. However, all three methods have no good performance. This problem is left to explore and improve in the future. 4.3 Case Studies on Real Dataset We also conduct experiments on the real dataset. We show the top 10 papers X  title ranked by our method with 30 topics in Table 6. Note that LDA topic model used in this paper ranks 10th which we examined the topics distribution of cited papers and citing papers. We find that the cited papers of LDA have the low diversity. The probability of their top 5 topics is about 0.89 as shown in Table 7. On the other hand, the probability of top 5 topics in citations only about 1/3 as shown in Table 8. As we know that LDA topic model is proposed to process text (topic modeling), while it can applied in many other areas, such as computer vision, recommender systems and location based service, etc. Besides LDA, we can see that most of top 10 papers are the classic influential papers. This paper is to explore the influential paper for interdisciplinarity. To the best of our knowledge, this is the first work to find such kind of important literature among many research areas. LDA and diversity techniques are used to quantify the influence of a paper for interdisciplinarity. And this score can be also as an indicator of the importance of a paper. E xperiments have shown the effectiveness of the proposed approach. In the future, we want to consider the link analysis, such as PageRank, to improve the effect iveness; and the efficiency is also our consideration.
 Acknowledgments. This work was supported by the 973 project (No. 2010CB328106), NSFC grant (No. 61170085 and 61033007), Program for New Century Excellent Talents in China (No.NCET-10-0388) and Shanghai Knowledge Service Platform Project (No. ZF1213).

