 We present SUDA2, a recursive algorithm for finding Minimal Sample Uniques (MSUs). SUDA2 uses a novel method for representing the search space for MSUs and new observations about the properties of MSUs to prune and tra-verse this space. Experimental comparisons with previous work demonstrate that SUDA2 is not only several orders of magnitude faster but is also capable of identifying the boundaries of the search space, enabling datasets of larger numbers of columns than before to be addressed.
Improvements and innovations in computer processing power, disk storage and networks have led to dramatic in-creases in the ability to accumulate and analyze personal data. However, if personal data is made available, even in an anonymized form, there is a risk of individuals being identified using statistical disclosure through the matching of known information with the anonymized data, resulting in material specific to those individuals being revealed. This work focuses on the identificatio n of individual records with a high risk of disclosure, a process otherwise known as Sta-tistical Disclosure Assessment. The records belonging to certain individuals have a significant chance of being iden-tified as their contents, or attributes, are unique and there-fore have the potential to be matched directly with details (including names and addresses) from another dataset. An illustration of a  X  X isky X  record of this type is a sixteen-year-old widow in a population survey. A record can contain more than one such unique pattern and its classification of-ten depends on the number and size of such attribute sets (referred to as uniques ) that it contains [6].

The ability to comp rehensively locate and grade such records leads to more efficient Statistical Disclosure Con-trol (SDC) of released data. In order to carry out an ex-haustive search of this nature all possible attribute sets must be checked (directly or indirectly) for uniqueness. While it may be possible to concentrate only on attributes most likely to be problematic, there would always be the possi-bility of missing some.

Existing techniques can find outliers (unusual records) in a dataset if a generic dissimilarity measure between records can be constructed (such as a distance metric in n -dimensional space where n is the number of attributes per record, or a measure of variation between DNA sequences in biological data) [2]. However, many datasets contain cat-egorical variables (such as Marital Status in a population survey) for which generic dissimilarity measures are diffi-cult to derive and for which distance metrics are not rele-vant. In general, a record classified as an outlier does not automatically contain unique patterns which can be directly matched with records in an independent dataset and the de-tection of outliers does not guarantee that all records con-taining unique attribute patterns are identified.
Previous work in SDC has led to the development of algorithms designed to protect the confidentiality of indi-vidual records under certain conditions, for example, tech-niques for modifying classifiers so as to protect record-level privacy [7] and techniques for assessing the maximum num-ber of queries that can be made without compromising the confidentiality of a given dataset [3], but these have not ad-dressed the uniques problem directly. Although some ar-eas of SDC research have focused on the location of  X  X isky X  records [5, 8, 12] this work, although theoretically interest-ing, does not overcome the combinatorially explosive prop-erties of the search for uniques and cannot yet be used to provide a full analysis of the risk associated with any given dataset.

A sequential algorithm, SUDA (Special Unique De-tection Algorithm), has been designed and implemented specifically for this problem [6] and is currently used by the Office for National Statistics (ONS) in London. The ONS releases many data samples from very large confiden-tial datasets, such as the Census of Great Britain. These samples are assessed for potential risk of statistical disclo-sure by applying SUDA. SUDA was inspired by techniques used in association rule discovery [1, 4].

SUDA employs a two-stage approach: firstly, all uniques (up to a user-specified size) are located at record level and, secondly, the size and distribution of uniques within each record is used to make statistical inferences about the records that are likely to be most  X  X isky X  in the entire dataset [6]. Only unique attribute sets without any unique subsets  X  Minimal Sample Uniques (MSUs)  X  are considered in order to avoid the use of redundant information and to keep the classification process as focused as possible; the smaller the number of attributes contained in a unique pattern the more  X  X isky X  it is considered to be [6]. It is therefore impor-tant to know if a unique is minimal.

The search for MSUs is extremely challenging as the problem of finding the smallest combination of attributes that have a unique pattern for a particular record is an -complete problem [13]. The delet erious effect of the mas-sive computational requirement is exacerbated by the fact that SDC is often an iterative process, requiring a complete risk assessment as each masking technique is tested for ef-fectiveness.

Although SUDA has greatly increased the depth of risk assessment possible, the demanding levels of execution time required to find all MSUs in stage one mean that it is restricted to small datasets, particularly in terms of the number of columns that they possess. This problem formed the motivation for the development of a new algorithm, SUDA2.
The target datasets are assumed to have rows of equal length as this is usually the case for survey-type data. Con-sider a dataset as a table with rows and columns . For con-venience, the columns are labeled , ,etc. An item is a column label juxtaposed with a value that is valid for that column. Examples of items in Table 1 are: and (corresponding to A=1, A=2 in column 1 and E=3 in col-umn 5). The number of times an item occurs in a dataset is referred to as its repetition count . The following discus-sion refers to sets of items as an itemset . An itemset is a Minimal Sample Unique if it satisfies two properties: (i) the pattern described by appears in exactly one row of the dataset (the reference row ), and (ii) every proper subset of appears in multiple rows of the table (the minimality constraint). A k -MSU is a MSU of size k .

The Minimal Uniques Problem can be outlined as fol-lows: given a table of discrete data  X  both numerical data (such as AGE) and numerically-coded categorical data (such as Marital Status with 1=single, 2=married etc.)  X  containing C columns and R rows, the problem is to find all k -MSUs, ,where and is user-specified.
 It is assumed that the entire table (and all data structures used for the algorithm) fit into main memory completely. The terms  X  X able X  and  X  X ataset X  are used interchangeably in the following sections.
The SUDA algorithm essentially generates all possible column subsets in a depth-first manner and scans the input dataset for unique patterns in those columns. Using the ob-servation that once an MSU is discovered no superset of the MSU need be considered, it is possible to prune parts of the search space. By selecting in succession all column subsets with the same prefix any extensions of a unique prefix at a given row are ignored. For example, given four ordered columns, labeled , , and , the column subsets with prefix are: , , and . If column was found to have a unique value for row S then column subsets the effect of reducing the number of rows that need to be considered for each column subset while at the same time minimizing memory usage [6].

The process of identifying MSUs is conducted by par-titioning the rows of the dataset according to the value of each of the columns in a given column subset. For example, if the column subset was (AGE, SEX) the dataset would be divided into groups of rows containing items such as (AGE=20, SEX=male), (AGE=40, SEX=female) etc. Any group containing only one row represents a unique itemset and a check for minimal uniqueness would then be made to determine MSU status. The minimal uniqueness of a unique itemset X of size n (where ) is determined by confirming that all subsets of X of size are non-unique. The partitioning method of SUDA has the effect of minimizing the amount of data storage that is necessary to identify minimal uniques by localizing the required infor-mation. The generation of column subsets according to their prefixes also allows this partitioning procedure to be under-taken efficiently and without redundant sorting [6]. This process continues until either all possible column subsets have been considered or all those up to the artificial upper limit on , M, have been addressed.
 Table 1 shows a dataset with six rows (labeled ROW1 to ROW6) and five columns (labeled A to E). Figure 1 illus-trates the process of finding MSUs with column subsets A, AB, ABC, ABCD and ABCDE. Sorting on column A di-vides the dataset into two partitions but does not yield any unique itemsets. When each of these partitions is further sorted on column B three unique itemsets are discovered ( , and ), at rows 4, 5 and 6. These are all MSUs. When the remaining rows (1, 2 and 3) are sorted on column C row 3 is unique. However, this does not con-tain an MSU as A=1, C=2 is unique. Sorting on D yields unique itemsets at both rows 1 and 2, but only that at row 1 is an MSU. There are no rows left to check for ABCDE. The search then proceeds to ABCE, ABD, ABDE etc.

The maximum size of an MSU is often far smaller than the number of columns in the input dataset. However, SUDA makes little attempt to identify the boundaries of the search space. Although its method of pruning has the effect of reducing the number of rows in the sorting procedures associated with each column subset, it has less impact on the number of column subsets considered. If any two rows in the dataset are identical then all possible column sub-sets will be generated for checking. It is important to note, however, that SUDA is driven by the data itself and only considers itemsets that exist within a row of the dataset (i.e. itemsets that have the potential to be an MSU). If this were not the case redundant searching could ensue.

SUDA2 aims to use a more flexible representation of the search space and to identify its boundaries, but, at the same time, maintain the data driven approach of SUDA. Table 1 shows a table with six rows and five columns. The search space for MSUs in this table can be viewed as all possible, distinct subsets of each of these rows.
This search space can be altered as new information be-comes available. For example, if is found to be
Table 2. The effect of removing one 2-MSU from the search space
Table 3. The effect of removing one item, , from the search space an MSU at row 6, the search space at row 6 can be re-duced from all subsets of to all subsets of ered, as shown in Table 2. Each time a new MSU is identified the search space associated with that row can be reduced so that is no longer a subset of any of its item-sets. Row-level search spaces can continue to shrink in this way as MSUs are discovered. The search will terminate when all subsets have been considered, either directly or in-directly.

However, keeping track of row-level search spaces is likely to be complex and potentially demanding on mem-ory. A more methodical approach is therefore required.
It is possible to consider all MSUs containing a given item independently. For example, Table 3 shows all MSUs pertaining to and the corresponding effect on the search space; the search space at rows 4 and 6 is adjusted by removing , a step which is straightforward to imple-ment. Table 4 shows the search space and the MSUs after the final list of MSUs (i.e. when the search space is empty). In summary, as more MSUs are discovered the search space shrinks.

The above example illustrates a dynamic method of rep-resenting the search space which maintains the data driven aspect of SUDA. By considering items individually, rather than in blocks of entire columns of the table, it is possible to take advantage of properties that they possess, such as their differing levels of repetition counts, as discussed in the next section.

Table 4. The effect of removing four items,
As the problem of finding MSUs is known to be -complete [13], the best that can be achieved (unless of the search space. The SUDA2 algorithm relies upon a number of properties of MSUs as follows:
All non-unique items are arranged in ascending order of repetition count as this helps to improve the potential for pruning via the Uniform Support Property. Unique items, or 1-MSUs, are recorded immediately and then removed from the search as they cannot yield further MSUs. Any item that appears in all rows of the dataset cannot lead to an MSU by the Uniform Support Property and is removed from the search altogether. If two items have the same repetition count then: The ordered item list is referred to below as ITEM-LIST. The relative position within ITEM-LIST is called the rank of an item. By giving the items a complete ordering, every itemset  X  in particular, every MSU  X  contains an item with lowest rank, called the reference item.
The first stage of SUDA2 is to scan the input dataset in order to find repetition counts for all items that appear at least once. Unique items (1-MSUs) are recorded. The list of non-unique items is sorted in ascending order of repetition count to form ITEM-LIST as described in Section 4.3.
Items with the same repetition count are checked for per-fect correlation. One of every pair of perfectly correlated items is removed from ITEM-LIST. For each item that re-mains in ITEM-LIST the set of items that are perfectly cor-related with it is stored. Note that this step is optional as the rest of the algorithm works correctly even with perfectly correlated items. Finding some or all perfectly correlated items is an efficiency strategy.

The main data structures are then built as a pre-processing step. Firstly, table T is created with each item replaced by its rank which means that ranks and relative ranks can be determined immediately. Secondly, each item is associated with a set of rows that contain it so that, for any given item, the rows in which it occurs can be found immediately. This, in turn, enables the coexisting items (i.e. items within the same row) to be determined from T.
The following example applies SUDA2 to the data in Ta-ble 1 in order to find the MSUs shown in Table 5.
Performance tests were applied to SUDA and SUDA2 on a Dell Workstation with a 3GHz Pentium 4 processor with 2Gbytes main memory. The operating system used was Red Hat Linux 3.3.2-5. SUDA was written in C and SUDA2 in C++ and both were compiled with gcc version 3.2.2 using -03 optimization.

The effectiveness of SUDA and SUDA2 were tested on three datasets as follows: Figure 2. Running time for the 1991 SARs data Figure 4. Running time for the Mushroom data
SUDA2 can be seen to outperform SUDA on all these datasets and its ability for its performance curve to flatten off after the largest MSU is clearly demonstrated in two of the examples.
The execution times for SUDA2 were considered ac-cording to rising numbers of rows on the same machine and environment as in the previous section and the results are shown in Table 13 ( X  X  X  X  refer to jobs that were too large to run on this resource). The data samples were selected at regular values of column AGE from the 1991 SARs [11] and the columns were chosen at random. Figures 5, 6, and 7 plot the log of the number of rows against the log of the execution time for SUDA2. An n-squared line  X  the hypo-thetical case where the execution time is O( ), where n is
Table 13. Execution times for SUDA2 for rising numbers of rows with time in hours:minutes:seconds the number of rows  X  is also shown. It can be seen that the execution time for SUDA2 falls below this line.
Figure 5. Log plot for the 8 column 1991 SARs data
SUDA2 has been shown to have the ability to identify the boundaries of the search space for MSUs with an execution time which is several orders of magnitude faster than that of SUDA. This has been brought about by a more sophis-ticated representation of the search space, the identification of a number of properties of MSUs, improved pruning tech-niques and a more efficient traversal of the search space. Not only will these developments provide statistical agen-cies with a much faster tool to work with, but the ability to assess data samples with more columns than before will now be possible.

The next step will be to put SUDA2 onto more powerful machines and architectures. SUDA2 is a good candidate for parallelism as the searches can be divided up according to Figure 6. Log plot for the 16 column 1991
SARs data Figure 7. Log plot for the 32 column 1991
SARs data rank; the challenge will be to produce efficient load balanc-ing.
The research presented here was funded by the Engineer-ing and Physical Sciences Research Council (Grant Num-bers GR/S27790/01 &amp; GR/S22295/01). We would also like to thank members of the Centre for Novel Computing at Manchester University for providing invaluable feedback.
