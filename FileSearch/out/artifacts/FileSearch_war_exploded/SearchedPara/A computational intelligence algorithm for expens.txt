 1. Introduction In the modern design optimizatio n process, researchers replace laboratory experiments with computer simulations to reduce the duration and cost of the design pr ocess. Such a simulation-driven setup transforms the design process into an optimization problem having three distinct features ( Tenne et al., 2010a ): The simulation acts as an objective function, assigning a candi-date design its corresponding objective value. However, the simulation is often a legacy code or a commercial software available only as an executable, and so there is no analytic expression defining how candidate designs are mapped to their corresponding objective values. Such a black-box function pre-cludes the use of optimizers which require an analytic function. Each simulation run is computationally expensive , that is, it requires anywhere from minutes to weeks of CPU time, and this severely restricts the number of permissible evaluations. Both the real-world physics being modeled, and the numerical simulation process, may yield an objective function which has a complicated, multimodal landscape.

Accordingly, such optimization scenarios are commonly termed as expensive black-box optimization problems , and a diverse range of optimization algorithms have been proposed to effectively address the challenges above ( Tenne et al., 2010a ).
However, expensive optimization problems introduce another difficulty, namely, the simulation may  X  X rash X  and fail to return an objective value for some candidate designs. We refer to such designs as simulator-infeasible (SI), while those for which the simulation completes successfully and provides the objective value are termed simulator-feasilbe (SF) . SI designs have two main implications on the optimization search:
Since they do not have a corresponding objective value, the objective function becomes discontinuous, which exacerbates the difficulty of the optimization, and
Such designs can consume a large share of the limited computational budget, without providing any objective values, and can thus lead to search stagnation and a poor final result.
A literature survey, for example, as indicated by Poloni et al. shows that SI candidate designs are common in real-world optimi-zation problems, and so it is important to effectively handle them.
Existing strategies either discard such vectors altogether, or assign them a penalized objective value and then incorporate them into the model. However, both these strateg ies have significant demerits, for example, they discard information which can be beneficial to the search, or they result in a model with a severely deformed landscape.
To address these issues, we pro pose in this study a new com-the optimization search. The role of the classifier is to predict if a candidate design is SI or not, and the proposed algorithm leverages on this prediction to bias the search to designs predicted to be SF. However, the effectiveness of the algorithm strongly depends on the type of the model and classifier used , but the limited computational budget implies that it is impractical to experiment with different models and classifiers. As such , the proposed algorithm also incorporates rigorous statistical methods to select an optimal model and classifier from a family of candidates. Both the model and the classifier types are continuously adjusted during the search to maximize the search effectiveness. To the best of our knowledge, such a computational intelligence algorithm, combining both a classifier and a model, and the ability to adapt both of them, is new. We evaluate the proposed algorithm using a real-world application of airfoil shape optimization. A rigorous analysis shows that the proposed algorithm is both effective, namely it outperforms existing approaches in terms of the final result obtained, and is efficient, that is, it performs a search with a competitively low number of SI vectors, so it minimizes the computer resources wasted on failed evaluations. Analysis also highlights the contribu-tion of incorporating the classifier, and of the model and classifier selection during the search.

The remainder of this paper is as follows: Section 2 provides the pertinent background information, Section 3 describes in detail the proposed algorithm, and Section 4 provides a rigorous performance analysis. Lastly, Section 5 concludes this paper. 2. Background 2.1. Expensive optimization problems and computational intelligence algorithms
Expensive optimization problems arise in diverse domains across engineering and science, and as mentioned in Section 1 ,a typical scenario is engineering design optimization problems driven by computer simulations. Fig. 1 shows the layout of such problems, where the simulation effectively acts as a black-box function, namely it assigns objective values to candidate designs, while the analytic expression of this function is unknown. In such optimization problems, candidate designs are represented as vectors of design variables and are provided as inputs to the simulation.

Also as mentioned, the resultant objective function often has a complicated, multimodal landscape, a scenario in which gradient-based optimizers may converge to a poor local optimum. This has motivated using computational intelligence (CI) optimizers in such problems, as they tend to be more explorative and hence are typically more resilient to multimodal landscapes. Such optimi-zers typically employ a population of candidate solutions and manipulate the latter both deterministically and stochastically. One such CI optimizer which is widely used is the EA, which typically applies the following three operators inspired by the theory of evolution ( Tenne et al., 2010a ): Selection : The vectors with the best objective value are selected as parents .
 Recombination : Two parents are selected, typically at random, and their vectors are combined to yield an offspring. This is repeated several times to generate a population of offspring. Mutation : Offspring are selected at random, and some of their vector components are randomly changed.

The offspring population is then evaluated, and the fittest mem-bers, namely those with the best objective values, are taken to be the population of the next generation. The process then repeats until some termination criterion is met, such as no improvement in the best function value, or if the maximum number of generations has been reached. The EA emphasizes the fittest solutions, and this leads to a gradual adaptation of the population to the function landscape and convergence to an optimum. Algorithm 1 gives a pseudocode of a baseline EA.

Algorithm 1. A baseline evolutionary algorithm. initialize a population of solutions; evaluate each solution in the population; / main loop repeat select a group of solutions and designate them as parents ; recombine the parents to create a population of offspring ; mutate some of the offspring ; evaluate the offspring ; select the best solutions as the population of the next generation ; until convergence , or maximum number of generations reached Since CI optimizers rely on a popu lation of solutions, and do not utilize gradient information, they often require many thousands of obstacle in applying them to expe nsive optimization problems, where the number of function evaluations is severely restricted. An established strategy to circumv ent this issue is to employ a model which serves as a computationally cheaper approximation of the true expensive function. Models are typi cally interpolants trained with previously evaluated vectors, and variants include artificial neural networks (ANN), Kriging, polynomials, and RBF ( Simpson et al., 2001 ). However, while models alleviate the bottleneck of expensive evaluations, they introduce several new challenges: Model management : Due to the small number of permissible expensive function evaluations, only a small number of vectors will be available to train the model, which results in an inaccurate model. This can hamper the optimization search, and if the model accuracy is poor, the optimizer may even converge to a false optimum, namely an optimum of the model which is a not an optimum of the true expensive function ( Jin et al., 2002 ). Accordingly, it is necessary to manage the model and ensure its accuracy during the search. To accomplish this, the proposed algorithm leverages on the TR approach which originated in the field of nonlinear programming ( Conn et al., 1997 ), and in which the optimization proceeds by a sequence of trial steps , where each is constrained to the TR, namely the region where the model is assumed to be accurate. Based on the success of the trial step, that is, whether a better solution has been found or not, the TR and model are updated, and the sequence repeats until some termination condition is met. A strong merit of the TR approach is that it ensures asymptotic convergence to an optimum of the true expensive function ( Conn et al., 1997 ). Section 3 gives a detailed description of the TR approach implemented in this study.
 Model selection : As mentioned above, numerous types of models have been proposed, but no single model type is optimal for all problems. Accordingly, a priori fixing the model type may result in an unsuitable model, and can thus degrade the search effectiveness. To illustrate th is, we used two models, namely Kriging and RBF, which are described in Appendix A , to approximate five tests functions, namely Ackley, Rastrigin, Rosenbrock, Schwefel 2.13, and Weierstrass, each in dimension d  X  5 ; 10 , and 20. In each case, the models were trained using the same set of 30 vectors, and their prediction error (root mean square) was calculated using a set of 20 new test vectors, using the same vectors for both models. Table 1 shows the results, with the best (lowest) prediction error highlighted at each case, showing that the optimal model varied with function type and dimension. This implies that it is beneficial to match the model type to the problem being solved, but due to the restricted number of function evaluations it is impractical to experiment with different models. To address this, namely to efficiently select the model type, the proposed algorithm leverages on the statistical model selection theory and uses an accuracy estimator to select the optimal model type out of a family of candidates ( Burnham and Anderson, 2002 ). Specifically, the accuracy of each candidate model is estimated, and the model chosen is the one having the best estimated accuracy. Section 3 gives a detailed description of the model selection procedure implemented in this study. 2.2. Simulator-infeasible vectors As mentioned in Section 1 , this study focuses on expensive optimization problems with simulator-infeasible (SI) vectors, namely which crash the simulation code. Numerous studies have acknowledged the existence of such vectors, and the difficulties they introduce into the optimization search. For example, Poloni et al. (2000) mentioned  X  X  X ailure of the simulation code X  X  during an optimization, Booker et al. (1999) highlighted that during their experiments  X  X  X ttempts to evaluate the objective function failed X  X , and similarly, B  X  uche et al. (2005) described a simulation-driven optimization problem where  X  X  X valuation of all points fails X  X .
Additional pertinent studies include Koehler et al. (1996) , Conn et al. (1998) and Okabe (2007) .

Given the prevalence of SI vectors in real-world applications, several techniques have been proposed to handle them. For example,
Rasheed et al. (1997) performed design optimization using an EA, and used a classifier to screen vectors before evaluating them with the simulation. Those predicted to be SI were assigned a  X  X eath quickly eliminate them from the p opulation. The authors did not consider the use of models, and in their implementation the EA called the simulation directly. Emmerich et al. (2002) also used the penalty approach, but incorporated the penalized vectors into the model to bias the search towards SF solutions. In contrast, the model, and used only the SF vectors. These techniques, and similar ones, have several demerits in the context of expensive optimization problems:
Assigning SI vectors a penalized objective value and then incorporating them into the model can severely deform the model landscape and degrade its accuracy.

Discarding SI vectors results in a loss of potentially beneficial information which can assist the optimization search.
As an example, Fig. 2 shows the effect of penalizing SI vectors and incorporating them into the model, where the left figure shows a model trained using 30 vectors which are all SF, while the right figure shows the resultant model when 20 SI vectors were added to the baseline set and were assigned a penalized fitness taken as the worst objective value in the baseline set. The resultant model is severely deformed and contains many false optima, and its poor accuracy exacerbates the difficulty of finding an optimum of the true objective function.

Such issues have motivated exploring alternative approaches for handling SI vectors. For example, Tenne and Armfield (2008) proposed a dual model approach, where one model was used for the objective function and another for the penalty value which was interpolated between SI vectors. This way, vectors predicted to be SI received a high penalty, and this penalty decreased with the distance from SI vectors. Other studies have examined using classifiers for constrained non-linear programming, though unre-lated to SI vectors ( Handoko et al., 2010 ). Further exploring the use of classifiers, Tenne et al. (2010b) obtained preliminary results with a classifier-assisted algorithm for handling SI vectors. However, the algorithm used a single type of model and classifier, and it did not consider model-selection. 3. Proposed algorithm
Leveraging on the discussion in Sections 1 and 2 , this section describes in detail the proposed algorithm, and explains how it addresses the optimization challenges discussed earlier. We empha-size that the proposed algorithm leverages on three main concepts:
Classification of candidate vectors : Each candidate vector is treated as having two attributes, namely its objective value , which is predicted by the model, and its class , namely, if it is SI or SF. Appendix B provides more details on classifiers and the specific variants used in this study.

Model and classifier selection : To improve the optimization search, the proposed algorithm selects an optimal type of model and classifier, out of a family of prescribed candidates, based on statistical model selection theory.

Trust-region (TR) optimization : To safeguard the optimization search and ensure convergence to an optimum of the true expensive objective function, the proposed algorithm leverages on the TR approach and performs at each iteration an optimiza-tion trial-step, followed by updates of the TR and the model.
Specifically, the algorithm operates in five main steps: initi-alization, model selection, classifier selection, a TR trial step for seeking an optimum, and management of the model and the TR. The details of these steps are as follows:
Step (1) Initialization : The proposed algorithm begins by gener-
Step (2) Model selection : As mentioned, the proposed algorithm
Step (3) Classifier selection : In an analogous step, the proposed
Step (4) TR trial step : Next, the best vector in the cache is taken
Step (5) Model and TR update : The optimum found by the EA, x n , optimum is indeed better than the current best solution, namely x b . Accordingly, the TR is centered at the new opti-mum, and the TR is enlarged by doubling its radius.
 The search was unsuccessful since the predicted optimum is not better than the current best vector. However, since there are sufficient SF vectors in the TR, the model is considered to be accurate enough to justify contracting the TR. Accordingly, the TR is contracted by halving its radius.
 TR: The search was unsuccessful, but this may be due to poor model accuracy, namely there are too few vectors inside the
TR. As such, the algorithm adds a new vector ( x n ) inside the TR, as explained below.

As a change from the classical TR framework, the proposed algorithm monitors the number of vectors in the TR to ensure it is not contracted too quickly, as this can lead to premature convergence ( Conn et al., 1997 ). The threshold number for the interior vectors was set to d , namely the function dimension, as this is the number of function evaluations which would have been required to approximate the gradient by finite-differences ( Conn et al., 1997 ). We emphasize that the proposed algorithm does not use finite-differences, but only uses d as an indicator to the number of vectors needed to approximate the gradient, and hence to obtain a better solution.

Another change from the classical framework is the addition of a new vector ( x n ) to improve the local model accuracy. For this, the vector should be placed in an unexplored part of the TR, namely it should maximize its distance to existing TR vectors ( Madych, 1992 ). Mathematically, this new vector is obtained from the following max X  X in criterion: x : max
TR ( Johnson et al., 1990 ). To simplify the solution of (5), the proposed algorithm generates a LH sample in the TR and selects the sample vector having the largest max X  X in distance value.
Lastly, if the TR has contracted for q consecutive iterations, this is taken as an indication of convergence to an optimum. To improve the global model accuracy and to assist in locating new optima, in this case the proposed algorithm adds a new vector outside the TR.
The vector is generated using the same procedure for generating x but now considering the entire search space instead of the TR. Based on numerical experiments, q  X  2 was identified as a suitable setting.
To further clarify the mechanics of the proposed algorithm, Fig. 4 gives a schematic layout of its optimization iteration. While in this paper the proposed algorithm used specific models (Kriging, RBF) and classifiers ( k NN, SVM, LDA), it can readily accommodate any other type or number of models and classifiers. Lastly, to complete this description, Algorithm 2 gives the pseudocode of the proposed algorithm.
 Algorithm 2. Proposed optimization algorithm. / initialization % / generate an initial LH sample; evaluate the sample vectors and store them in memory; / main optimization loop % / repeat = select an optimal model type % = for each candidate model do b estimate the model prediction error ; select the model type with the lowest prediction error ; train a new model using all the SF vectors stored in memory ; = select an optimal classifier type % = for each candidate classifier do b estimate the classifier prediction error ; select the classifier with the lowest prediction error ; train a new classifier using all the vectors stored in memory ; = perform a TR trial step % = set the TR center to the best vector stored in memory ; find the model optimum in the TR , while using the modified objective function  X  4  X  ; = manage the model and the TR % = evaluate the predicted optimum with the true expensive function ; if the new optimum is better than the
TR current best vector then b double the TR radius elseif the new optimum is not better than the current best vector and there are sufficient vectors in the TR then b halve the TR radius ; elseif the new optimum is not better than the current best vector and there are insufficient SF vectors in the TR then b add a new vector in the TR to improve the model ; if there have been q consecutive TR contractions then b add a new vector in the search space to improve the model globally ; add to the memory storage all the new vectors evaluated with the true expensive function ; until maximum number of analyses reached; 4. Numerical experiments: Results and discussion
For a rigorous evaluation, the proposed algorithm was applied to a set of airfoil shape optimization problems since they are both simulation-driven and contain SI vectors, as explained below.
The formulation of the airfoil optimization problem is as follows. During flight, an aircraft generates lift which counters the aircraft weight and keeps it airborne, and drag which is an aerodynamic friction force. Therefore, the optimization goal is to find an airfoil shape which generates lift while minimizing the drag. In practise, the design requirements for airfoils are specified in terms of the non-dimensional lift and drag coefficients, c c , respectively, defined as c  X 
L 1 2 r V c  X 
D 1 2 where L and D are the lift and drag forces, respectively, r is the air density, V is the aircraft speed, and S is a reference area, such as the wing area. Besides the lift and drag coefficients, the other relevant physical quantities involved are the aircraft altitude, speed, and angle of attack ( AOA ), which is the angle between the aircraft velocity and the airfoil chord line . Fig. 5 shows the layout of the airfoil problem.
 In this study, two variants of the airfoil optimization problem were used ( Filippone, 2006 ):
Variant (1) Minimum drag X  X ixed lift : Here, the airfoil should
Variant (2) Maximum lift-to-drag : Here, the airfoil should max-Candidate airfoils were represented using the Hicks X  X enne parameterization ( Hicks and Henne, 1978 ), which defines the profile of a candidate airfoil as y  X  y  X  where y b is a baseline airfoil profile, taken as the NACA0012 symmetric airfoil, b i are basis functions, which following Wu et al. (2003) , are defined as b and a i A  X  0 : 01 , 0 : 01 are coefficients, which are the problem X  X  design variables. Ten basis functions were used for the upper and lower airfoil profile, respectively, resulting in a problem of 20 design variables. Fig. 5 summarizes the nomenclature of the physical quantities and airfoil parametrization involved in this test problem. The lift and drag coefficients of candidate airfoils were obtained using XFoil , a computational fluid dynamics simu-lation for analysis of airfoils operating in the subsonic regime ( Drela and Youngren, 2001 ). Each airfoil evaluation required up to 30 s on a desktop computer.
 The airfoil shape optimization problems are pertinent test cases since they contain SI vectors. The prevalence of such vectors depends on two major factors: the angle of attack (AOA) and the aircraft operating conditions (flight altitude and speed). The effect of these factors on the prevalence of SI vectors was evaluated as follows: Angle of attack ( AOA ): Since the turbulence of the flow field increases with the AOA, at higher angle values it will be more difficult to complete the aerodynamics simulation, and more trial designs will be SI. To verify this, 30 different airfoils were sampled and evaluated in identical flight conditions, except for the AOA which was increased from 0 1 to 40 1 . Fig. 6 (a) shows the obtained results, where, as expected, the number of failed evaluations increased with the AOA. Therefore, by changing the AOA we could change the density of SI vectors in the search space, and hence the relative difficulty of the tests. In view of these results, the proposed al gorithm was tested at the three settings AOA  X  20 1 ,30 1 ,and40 1 , which following Fig. 6 (a), correspond to a low, medium and high prevalence of SI vectors in the search space, respectively.
 Operating conditions ( altitude , speed ): In an analogous proce-dure, a sample of 30 vectors was evaluated at altitudes of 10 X 35 kft with 2.5 kft increments, and velocities of Mach number Ma  X  0.3 X 0.8, namely, 30% X 80% of the speed of sound, with an increment of 0.025. The AOA was unchanged in all evaluations. Fig. 6 (b) shows the obtained results, where shades indicate the percentage of failed evaluations, namely the rate of SI vectors, at the different operating conditions. Based on these results, we have selected the following two operating conditions for the test cases, and which are indicated on the plot, as they both correspond to a rate of approximately 40% failed evaluations: (A) a speed of Ma  X  0.325 and an altitude of 15 kft, and (B) a speed of Ma  X  0.775 and an altitude of 32 kft.
Overall, we have used six test cases, that is, at each selected operating condition we repeated the optimization for the three
AOAs settings. This allowed us to evaluate the proposed algorithm on a variety of problem settings. Table 3 shows the details of the test cases.

For a comprehensive evaluation, the proposed algorithm was also benchmarked against two representative model-assisted EAs:
A model-assisted EA with periodic sampling (EA X  X S) ( Ratle, 1999 ): This is a model-assisted EA which is representative of many others in the literature. The algorithm safeguards the model accuracy by periodically evaluating a small subset of the population with the true objective function, and incorpor-ating these evaluated members into the model training set. 0.4 0.6 0.8 Aircraft speed, Mach number ( Ma )
The algorithm begins by generating and initial sample of candidate solutions and evaluates them with the expensive function. The main optimization loop then begins, where the algorithm trains a model using the candidate solutions evalu-ated so far, and uses a real-coded EA to search for the optimum of the model. After the search is completed, the algorithm evaluates the best 10 candidate solutions in the population with the true expensive function. The entire process then repeats, until the maximum number of expensive function evaluations is reached.

Expected-improvement with model-assisted CMA-ES (EI X  X MA-ES) ( B  X  uche et al., 2005 ): The algorithm combines a covariance matrix adaptation evolutionary strategy (CMA-ES) optimizer ( Hansen and Ostermeier, 2001 ) with a Kriging model, and updates the model based on the expected improvement frame-work ( Jones et al., 1998 ). The algorithm begins by generating an initial sample of points and evaluates them with the true function. Its main loop then begins, where at each generation it trains a local Kriging model using both the recently eval-uated vectors, and the vectors stored in memory which are nearest to the best solution. A CMA-ES algorithm then searches for an optimum of the model in a bounded region defined by the model training sample. In the spirit of the expected improvement framework ( Jones et al., 1998 ), it uses the merit function ^ f  X  x  X  X  m  X  x  X  r z  X  x  X  ,  X  11  X  where m  X  x  X  is the Kriging model prediction, r is a prescribed coefficient, and z  X  x  X  is the estimated Kriging prediction error, which is zero at sampled points since there the true objective value is known. The search is repeated for r  X  0 ; 1 , 2 , and 4, to obtain four solutions corresponding to different search pro-files, namely ranging from a local search ( r  X  0) to a more explorative one ( r  X  4). All non-duplicate solutions found are evaluated with the true expensive function and are cached. In case no new solutions were evaluated, for example, because they already exist in the cache, the algorithm generates a new solution by perturbing the current best one. Following B  X  uche et al. (2005) , the algorithm used a training set of 100 vectors comprising of the 50 most recently evaluated ones and 50 nearest-neighbors.

To study the contribution of the model and classifier selection step, two variants of the proposed algorithm were also included in the tests, but each used a fixed model and classifier type and therefore did not employ any model or classifier selection. The two variants were: (i) KK: used a Kriging model and a k NN classifier, and (ii) RS: used an RBF model and an SVM classifier.
In all the tests the optimization budget was 200 expensive evaluations, that is, calls to the aerodynamics simulation, and the size of the initial sample was 20. To support a valid statistical analysis, 30 runs were repeated with each algorithm at each test case.

For a rigorous analysis, three performance aspects were stu-died: the test statistics corresponding to the best objective values obtained, the number of SI vectors encountered during the search, and the pattern of model and classifier updates during the search:
Tests statistics for the best objective values: Table 4 gives the test statistics of mean, standard deviation (SD), median, best, and worst objective value related to each of the algorithms in each of test cases, and where the best mean and median results are emphasized. The table also gives the significance-level a at which the proposed algorithm was better than each of the other four algorithms, namely either 0.01, 0.05, or an empty cell if performance was not statistically significant at the latter levels. Statistical significance tests were done using the Mann X  X hitney nonparametric test ( Sheskin, 2007 ). In the first variant of the minimum drag X  X ixed lift, the proposed algorithm outperformed the other algorithms in all cases, as it obtained the best mean and median statistics. With respect to the standard deviation, the pr oposed algorithm obtained an intermediate score in the AOA  X  20 1 and 30 1 cases, but had a higher variability in the 40 1 case, which is attributed to the higher rate of SI vectors at this AOA. Specifically, a higher rate of SI vectors exacerbates the optimization difficulty, and therefore leads to a higher variability in performance. Also, the proposed algorithm outperformed the RS and KK variants (which did not employ any model and classifier se lection), which highlights the beneficial contribution of the model and classifier selection steps. Lastly, statistical significance tests show that except for the comparisons with the EI X  X MA-ES algorithm at AOA  X  30 1 and 40 1 , the proposed algorithm had a statistically significant advan-tage at the 0.01 level in all cases.
 In the second problem variant of maximum lift-to-drag, the proposed algorithm maintained its effectiveness and consistently outperformed the other algori thms, as evident from the mean and median statistics. With respect to the standard deviation, the proposed algorithm obtained an intermediate score, indicating there was some variability in its performance, but it is compar-able to that of the other algorithms. In a single case, namely for AOA  X  20 1 , the RS algorithm obtained a better mean and median result. This may due to the landscape of this problem in which the combination of an RBF model and SVM classifier performed well. However, this combination performed best only in this specific case, namely AOA  X  20 1 , which indicates the combination is not globally optimal for all cases. In contrast, the proposed algorithm performed best in the other two cases of AOA  X  30 and 40 1 , which highlights the merit of the model and classifier selection steps, as they allowed t he proposed algorithm to adapt to the problem being solved. Overall, results show that the proposed algorithm either performed best or near-best, and its performance was robust across the d ifferent test cases. The latter is attributed both to the use of the classifier, which avoids deforming the model landscape, and to the model and classifier selection steps, which allow the algorithm to adapt to the specific problem being solved.
 Number of SI vectors encountered during the search: Investigat-ing another aspect of the algorithms X  performance, Table 5 gives the test statistics for the number of SI vectors encountered during the optimization search. These statistics are important as they indicate the efficiency of the algorithms with respect to failed simulation runs, namely how the algorithms compared in terms of reducing the number of failed evaluations and wasted computer resources. As before, the table provides the mean, standard deviation, median, best, and worst statistics for each algorithm in each test case, and the best mean and median scores are emphasized for each case.
 For the first problem variant of minimum drag X  X ixed lift, the EA X  X S algorithm obtained the best mean in two cases (AOA  X  20 and 40 1 ) and the best median in two cases (AOA  X  30 1 and 40 These results indicate that the penalty approach used by the EA X  X S algorithm strongly biased the optimizer away from SI vectors. However, this algorithm yielded poor final results when compared to the other algorithms, which is attributed to the deformed model landscape of the penalty approach making it difficult to locate a good optimum of the true objective function, as discussed in Section 2.2 .
 In contrast, the EI X  X MA-ES variant had the largest number of SI vectors, indicating an ineffici ent search where many function evaluations failed. This is attributed to this algorithm X  X  strategy of discarding SI vectors, and therefore it does not adapt or modify the search based on them. With respect to the proposed algo-rithm, statistics in dicate that its corresponding number of SI vectors was intermediate between the best and worst results. As the proposed algorithm typically obtained the best or near-best objective value, this implies that obtaining a good solution requires exploring some SI vect ors, as the optimum may lie near such vectors. This also emphas izes the demerit of the penalty approach, since it deforms the model landscape and can thus bias the optimizer away from exploring the vicinity of SI vectors. For the second problem variant of maximum lift-to-drag, the trends are consistent with those observed in the first variant, namely the EA X  X S algorithm obtained the best mean and median statistics in all cases, while the statistics of the proposed algorithm were intermediate.
 Overall, results indicate that the proposed algorithm performed a search which was not only effective but also efficient, namely it maintained a competitive number of SI vectors when compared to the other algorithms.
 The pattern of model and classifier updates: This performance aspect was studied to understand if a single type of model and classifier was used during most of the search, which would negate the need for the selection steps, or if they were frequently updated, which would emphasize the benefit of the selection steps. Fig. 7 shows representative plots of these updates in two tests, from which it follows that both were frequently updated. This indicates that the optimal type was not only problem dependant but also varied during the search.
Also, these results highlight the demerit of using a single type of model and classifier, since a model and classifier which have been a priori fixed may be unsuitable to the problem being solved. The proposed algorithm circumvents this issue by continuously adapting the model and classifier types during the search.
 Lastly, to demonstrate results from the optimization searches,
Fig. 8 shows representative airfoils obtained by the proposed algorithm at each of the six test cases, namely, the two problem variants, with three AOA settings per variant, as given in Table 3 .
Overall, results show the proposed algorithm was both effective and efficient, namely it consistently obtained the best or near-best objective value, and maintained a competitively low number of SI vectors during its search. These re sults emphasize the contribution of the approaches proposed in this study, namely:
Incorporating the classifier into the optimization search improved the search effectiveness, as evident from the comparisons to the penalty approach, as used by the EA X  X S algorithm, or to discard-ingSIvectors,asusedbytheEI X  X MA-ESalgorithm.

Selecting the model and classifier during the search improved the search effectiveness as evident from the comparisons to the KK and RS variants which used a fixed type of model and classifier. 5. Conclusion The modern engineering design process often replaces labora-tory experiments with computer simulations, which results in what is commonly termed as expensive black-box optimization problems. Often, such problems will contain candidate solutions Kri.
 RBF k NN LDA SVM which cause the computer simulation to fail and would therefore have no objective value associated with them, a scenario which can degrade the search effectiveness. Existing approaches to handle such candidate solutions either assign them a penalized fitness, or discard them altogether, but both these approaches have significant demerits, as discussed in Section 2 . Accordingly, this study has proposed a new computational intelligence opti-mization algorithm which employs a model and a classifier. The latter predicts which solutions are expected to crash the simula-tion, and its prediction is used to bias the search towards candidate solutions for which the simulation is expected to successfully complete. To further enhance the effectiveness of the search, the proposed algorithm also uses statistical model selection techniques to continuously adapt the type of model and classifier during the search.
 In an extensive performance analysis using a set of airfoil shape optimization problems, the proposed algorithm was bench-marked against two representative algorithms from the literature and two variants with no model and classifier selection. Results show that: (i) incorporating the classifier into the search was an effective approach to handle SI vectors, as evident from the comparisons to algorithms from the literature, and (ii) selecting the model and classifier type during the search improved the search effectiveness, as evident from the comparisons to the variants with no model and classifier selection. Overall, the proposed algorithm consistently obtained the best or near-best objective values across all tests, while also producing a competi-tively low number of SI vectors during its optimization search. Appendix A. Candidate models Models serve as computationally cheaper approximations of the true expensive objective function, and are typically interpo-lants trained using previously evaluated vectors. In this study, the proposed algorithm selects between two candidate models ( Queipo et al., 2005 ): Kriging : This model takes a statistical approach to interpola-tion by combining two components: a  X  X rift X  function, which is a global coarse approximation of the true function, and a local correction based on the correlation between the interpolation vectors. Given a set of evaluated vectors, x i A R d , i  X  1 ... n , the Kriging model is trained such that it exactly interpolates are the model and true objective function, respectively. Using a constant drift function ( Koehler et al., 1996 ) gives the Kriging model m  X  x  X  X  b  X  k  X  x  X  ,  X  A : 1  X  with the drift function b and local correction k  X  x  X  . The latter is defined by a stationary Gaussian process with mean zero and covariance
Cov  X  k  X  x  X  k  X  y  X  X  s 2 c  X  y , x , y  X  ,  X  A : 2  X  where c  X  y , x , y  X  is a user-prescribed correlation function. A common choice for the correlation is the Gaussian correlation function ( Forrester and Keane, 2008 ), defined as c  X  y , x , y  X  X  and combining it with the constant drift function transforms the model from (A.1) into the following form: m  X  x  X  X  ^ b  X  r  X  x  X  T R 1  X  f 1 ^ b  X  :  X  A : 4  X 
Here, ^ b is the estimated drift coefficient, R is the symmetric matrix of correlations between all interpolation vectors, f is the vector of objective values, and 1 is a vector with all elements equal to 1. r T is the correlation vector between a new vector x and the sample vectors, namely r T  X  X  c  X  y , x , x 1  X  , ... , c  X  y , x , x n  X  :  X  A : 5  X 
The estimated drift coefficient ^ b and variance ^ s 2 , which are required in Eq. (A.4), are obtained as follows: ^ b  X  X  1 T R 1 1  X  1 1 T R 1 f ,  X  A : 6a  X  ^ s 2  X  1 n  X  X  f 1 ^ b  X  T R 1  X  f 1 ^ b  X  :  X  A : 6b  X 
Fully defining the model requires the correlation para-meters h , which are commonly taken as the maximizers of the model likelihood. This is achieved by minimizing the expression c  X  h  X  X  9 R 9 1 = n ^ s 2 ,  X  A : 7  X  which is a function only of the correlation parameters h and the sample data. While a different correlation parameter can be used for each variable, the model used in this study, as is commonly done in the literature, is isotropic, namely it employs a single correlation parameter. This results in a univariate likelihood function, which is relatively easy to optimize. Overall, the above formulation results in a univariate optimization problem of minimizing the likelihood-related function c  X  y  X  . The numerical code used in this study ( Lophaven et al., 2002 )performsthis minimization by employing the Hooke X  X eeves pattern search algorithm ( Hooke and Jeeves, 1961 ), which is a direct search algorithm which does not require gradient information, and which performs well in relatively simple objective landscapes as those typical of the univariate likelihood function.
Radial Basis Functions (RBF): The model approximates the objective function by a superposition of basis functions of the form f i  X  x  X  X  f  X  J x x i J 2  X  ,  X  A : 8  X  where x i is an interpolation point. Given the training data x
R d , i  X  1 ... n , and corresponding objective values f  X  x
RBF model is then given by m  X  x  X  X  a i where a i and c are coefficients determined from the interpola-tion conditions m  X  x  X  X  f  X  x i  X  , i  X  1 ... n ,  X  A : 10a  X  i  X  0 :  X  A : 10b  X 
A common choice is the Gaussian basis function ( Koehler et al., 1996 ), defined as f  X  x  X  X  exp where t controls the width of the Gaussians and is determined by
CV ( Golberg et al., 1996 ). The set of interpolation Eq. (A.10a) is often ill-conditioned, and so the proposed algorithm solves them using the singular value decomposition (SVD) procedure ( Simpson et al., 2001 ).
 Appendix B. Candidate classifiers
Classifiers were originated in the domain on machine learning and data mining, and their goal is to predict the group or class of a vector. Specifically, given a set of vectors, where each is asso-ciated with a group, the goal of a classifier is to map a new input vector into one of these groups based on a similarity between the new vector and existing ones. Mathematically, given a set of such that each vector has a corresponding class label F  X  x example, I  X f 1 ,  X  1 g , a classifier performs the mapping c  X  x  X  : R d -I ,  X  B : 1  X  where c  X  x  X  is the class assigned by the classifier.
In this study, the proposed algorithm selects between three well-established classifier types ( Wu et al., 2008 ): k Nearest Neighbors (kNN) : The classifier assigns the new vector the same class as its closest training vector, as determined by a distance measure d  X  x , y  X  , such as the l 2 norm, namely c  X  x
An extension of the approach is to assign the class most frequent among the k 4 1 nearest neighbors ( k NN). In this study the classifier used k  X  3.

Linear Discriminant Analysis (LDA): In a two-class problem, where model the conditional probability density functions of a vector belonging to each class, where the latter functions are assumed to be normally distributed. The classifier considers the separation between classes as the ratio of: (a) the variance between classes, and (b) the variance within the classes, and obtains a vector w which maximizes this ratio. The vector w is such that it is orthogonal to the hyperplane separating the two classes. A new vector x is classified based on its projection with respect to the separating hyperplane, that is, c  X  x  X  X  sign  X  w x  X  :  X  B : 3  X 
Support Vector Machines (SVM): The classifier projects the data into a high-dimensional space where it can be more easily separated into disjoint classes. In a two-class problem, with
F  X  x
 X  A I  X f 1 ,  X  1 g , an SVM classifier tries to find the best classification function for the training data. For a linearly separable training set, a linear classification function is the separating hyperplane passing through the middle of the two classes. Once this hyperplane has been fixed, new vectors are classified based on their relative position to this hyperplane, that is, whether they are  X  X  X bove X  X  or  X  X  X elow X  X  it. Since there are many possible separating hyperplanes, an SVM classifier adds the condition that the hyperplane should maximize the dis-tance between the hyperplane and the nearest vectors to it from each class. This is accomplished by maximizing the Lagrangian L  X  where n is the number of samples (training vectors), F  X  x class of the i th training vector, and a i Z 0, i  X  1 ... n , are the
Lagrange multipliers, such that the derivatives of L P with respect to a i are zero. The vector w and the scalar b define the hyperplane.
 References
