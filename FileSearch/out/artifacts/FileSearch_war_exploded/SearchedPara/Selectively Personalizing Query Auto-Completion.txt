 Query auto-completion (QAC) is being used by many of today X  X  search engines. It helps searchers formulate queries by providing a list of query completions after entering an initial prefix of a query. To cater for a user X  X  specific information needs, personalized QAC strategies use a searcher X  X  search history and their profile. Is per-sonalization consistently effective in different search contexts?
We study the QAC problem by selectively personalizing the query completion list. Based on a lenient personalized QAC strategy that encodes the ranking signal as a trade-off between query popularity and search context, we propose a model for selectively personaliz-ing query auto-completion (SP-QAC) to study this trade-off. We predict effective trade-offs based on a regression model, where the typed query prefix, clicked documents and preceding queries in the same session are used to weigh personalization in QAC. Experi-ments on the AOL query log show the SP-QAC model can signifi-cantly outperform a state-of-the-art personalized QAC approach.  X  Information systems  X  Information retrieval query processing; Personalization; Query auto completion; Web search
Personalization techniques have been widely adopted by today X  X  search engines [1, 3, 12]. Query auto-completion (QAC) is no ex-ception [2]. In general, personalized lists of query completions pro-duced by a generic QAC ranking approach are obtained by distin-guishing individuals and their contexts, either based on their search history [1, 3, 7] or on their profiles [12]. Such personalization strategies have been proven to be effective as evidenced by a series of personalized query auto-completion approaches [1, 3, 7, 10, 12].
Generally, when ranking query completions in response to a pre-fix entered by a user, most existing personalized QAC approaches use an interpolation parameter  X  that controls the trade-off between query popularity and the searcher X  X  personal search context [1, 3]. This trade-off is uniformly applied to all typed prefixes [1, 3], so as to achieve a modest performance across all cases. It is unclear whether personalization will always boost the ranking performance over a generic QAC approach. As an aside, in web search and rec-ommendation systems, it has been shown that not all queries should be personalized equally as personalization strategies occasionally harm the search accuracy [13, 14]. Similarly, we hypothesize that in QAC personalization of query prefixes should not be handled in a uniform manner because: (1) a user X  X  initial information needs may be addressed by previous (2) users may change their search intent during a search session. Such clues can be explicitly expressed by the clicks or directly re-vealed by the query flow in a session.

We propose a model for selectively personalizing query auto-completion (SP-QAC) to re-rank the top N query completions pro-duced by the MPC (Most Popular Completion) model [1]. In partic-ular, personalization in the proposed SP-QAC model is individually weighed when combined with ranking signals from search popu-larity. We study the following factors for weighing personaliza-tion: the typed prefix for which we recommend query completions, the clicked documents for inferring a user X  X  satisfaction, and the topic changes of preceding queries in the same session for detect-ing search intent shifts. We use the description of each URL from the ODP data 1 to represent documents and queries based on the word2vec model [9] when inferring a user X  X  satisfaction as well as shifts in query intent in a session. Finally, we test the improvements of our proposal over state-of-the-art QAC baselines on a publicly available query log dataset. We find that SP-QAC outperforms a traditional non-personalized QAC approach and a uniformly per-sonalized QAC approach with a fixed trade-off controlling the con-tribution of search popularity and search context. Our contributions in this paper are summarized as: (1) We propose a model for selectively personalizing query auto-(2) We study the role of typed prefixes, clicked documents, and
A straightforward approach to ranking query completions is based on the popularity of queries. Bar-Yossef and Kraus [1] refer to this type of ranking as the Most Popular Completion (MPC) model: where f ( q ) denotes the number of occurrences of query q in search http://www . dmoz . org log L , and S ( p ) is a set of query completions matching prefix p .
To cater for a user X  X  particular information need, personalization has been incorporated into the MPC model, as described in [1, 3]. A generic personalized QAC approach employs a fixed parameter  X  to control the contribution of personal information to generate the final ranking of query completions. For instance, Bar-Yossef and Kraus [1] compute a hybrid score for each query candidate q which is a convex combination of two scores, i.e., a query popular-ity score MPCsco ( q c ) and a personalization score Psco ( q where MPCsco ( q c ) is estimated by candidate q c  X  X  frequency in the query log and Psco ( q c ) is measured by q c  X  X  similarity to the search context in session. This approach handles each prefix uni-formly. However, users may modify their search intent during a session and personalization may harm the quality of the ranking of query completions if we continue to use the previous search context. Hence, we propose a model for selectively personaliz-ing query auto-completion (SP-QAC) that varies the importance of personalization when generating the final hybrid score of a query completion: hybsco ( q c ) =  X  (  X  )  X  MPCsco ( q c ) + (1  X   X  (  X  ))  X  Psco ( q where  X  (  X  ) outputs a trade-off in [0 , 1] and is parameterized by three arguments: the typed prefix, clicked documents and preced-ing queries in the same session; see below.
Most previous work on query auto-completion [1, 3, 7, 12] only considers the typed prefix for generating a list of query comple-tions, ignoring the potential signal hidden in the typed prefix for personalization. However, the typed prefix normally reveals a strong clue for inferring a user X  X  personal query activity, such as query ex-pansion and query repetition, etc. We introduce a factor f the signal from the typed prefix p on weighing the personalization for query auto-completion as follows: where |W ( p ) | and |S| indicate the number of words that start with p and that appear in the current session, respectively; c is a small constant used for smoothing. A larger value of f p could imply a higher importance of personalization in the final ranking score in (3).
User X  X  clicks on documents retrieved in response to a query are a widely used behavioral signal for measuring search satisfaction [8]. Search satisfaction can be further approximated by the closeness between a submitted query and its clicked documents: the closer they are, the more satisfied the user could be [5]. The cosine simi-larity can be applied to model a factor f d for measuring closeness as follows: f where D q is a set of clicked documents corresponding to a sub-mitted query q in a set Q of previous queries in the session. To each clicked document d c  X  D q we assocaite a short description T extracted from the ODP. We vectorize this document descrip-tion consisting of a sequence of words using the word2vec model [9], where each word is represented by a vector v w . In doing so, a clicked document can be vectorized by averaging the words in T as d sented by averaging its clicked documents D in the training log, i.e., documents, the same representation of its most semantically simi-lar query q o , which is identified by the word2vec model [9] and has been vectorized in the training period, is assigned to it by where Q L is a set of queries that have clicked documents in the training period.

Intuitively, a large score of f d in (5) indicates a high probability weight of personalization in QAC. We assign a small constant c to f when no clicks are available, where personalization could make sense because the user X  X  request has not been addressed and they may continue to submit similar queries.
A long session may contain queries on multiple topics [6]. We use this observation to infer signals for weighing personalization in QAC. A strong topical shift in the preceding queries implies a low-weight personalization in QAC because the user may have shifted topics. Hence, we model a factor f q based on topic shifts in pre-ceding queries in the session: where r is the query position in session and each query is vector-ized by the scheme described in  X 2.2. For queries at the beginning of a session, i.e., r = 1 or 2, the topic shift from queries is un-available, making no impact on personalization, and thus we assign a small constant c to f q . Similarly, at query position r = 3 , the relative topical shift of queries is still unavailable. Instead, we use the absolute query similarity between q r -1 and q r -2 of query topical shift. For queries at position r &gt; 3 , we study the topic shift from their preceding queries, i.e., q r -1 , q
A large value of f q is produced if the topical similarity of pre-ceding queries is high, which, in turn, implies with high probability that the user X  X  search intent has remained unchanged from previous queries in the current session. In this case, personalization should be emphasized in (3).
Taking these discussed factors into account, i.e., the typed prefix, clicked documents and preceding queries in the same session, we adopt logistic regression to model how likely each factor should affect the weight of personalization in a QAC task. In the training period, for each typed prefix, we manually change the value of  X  in (3) from 0 to 1 (with steps of size 0.1) to guarantee that the final submitted query is ranked at the top position. By doing so, we obtain an optimal weight for personalization, which is used as a label in the regression model.

Regarding the inputs to the regression model, the factors dis-cussed above, i.e., f p , f d and f q , are involved. For the cases that no word appearing in the current session starts with the typed pre-fix, we perform the regression model based on the factors f f ; otherwise, we perform the regression model based on all three factors. Hence, the selective weight  X  (  X  ) in (3) is determined as follows: We use the personalization scenario proposed in [3] to compute the Psco ( q c ) score in (3) when generating the optimal personalization weights, i.e., where Q is a set of preceding queries in the current session and Z is used for normalization; p ( q c | q s ) is measured using the common strings of query terms in q c and q s .
We write SP-QAC for our proposed selectively personalized query auto completion model; it personalizes query completions based on a regression model considering the factors described in  X 2.1,  X 2.2 and  X 2.3, respectively. Our research questions are: ( RQ1 ) Does selective personalization help improve the accuracy ( RQ2 ) What is the performance of the proposed SP-QAC model
We use the publicly available AOL query log dataset [11] in our experiments, which is split into three parts: a training set, a vali-dation set and a test set consisting of the first 60%, the following 20% and the last 20% of the query log, respectively. A large vol-ume of navigational queries containing URL substrings (.com, .net, .org, http, etc.) are removed. One-query and no-click sessions are both excluded in our experiments as not enough search context is available. In addition, we follow previous QAC work and adapt a commonly used evaluation methodology in QAC [3, 7, 12] by only keeping cases where the final submitted query is included in the top N query completions returned by the MPC approach,
For comparison, the following baselines are selected: (1) the most popular completion (MPC) method, which ranks query can-didates by their frequency [1]; (2) a personalized QAC approach based on session context with a fixed tradeoff  X  = 0 . 5 in (2), de-noted as P-QAC [3].

We use Mean Reciprocal Rank (MRR) for evaluating the per-formance of QAC models. For a prefix p associated with a list of query completions L ( p ) and the user X  X  finally submitted query q the Reciprocal Rank (RR) is computed as: Then, MRR is computed as the mean of RR for all prefixes.
In addition, we set N = 10 in our experiments, which means the top ten query completions returned by the MPC approach are to be re-ranked. We randomly assign a small value 0.01 to the constant c in our experiments.
To answer research question RQ1 , we compare the results of our proposed model, i.e., SP-QAC, with those of the baselines. We re-port the results in Table 1. Clearly, as shown in Table 1, a generic Table 1: Performance of QAC models in terms of MRR at a prefix length # p ranging from 1 to 5 characters. The best per-formance per row is highlighted. Statistical significance of pair-wise differences of SP-QAC vs. MPC and SP-QAC vs. P-QAC are detected using a two-tailed t-test ( N / H for  X  = .01, or  X  = .05) and marked in the upper left and upper right hand corners of SP-QAC scores, respectively. Table 2: Performance of QAC models in terms of MRR at vari-ous query positions. The best performer per row is highlighted. Statistical significance of pairwise differences of SP-QAC vs. MPC and SP-QAC vs. P-QAC are detected using a two-tailed t-test ( N / H for  X  = .01, or M / O for  X  = .05) and marked in the upper left and upper right hand corners of SP-QAC scores, re-spectively.
 personalization scheme helps to improve the QAC performance in terms of MRR as the MRR scores of the P-QAC model are higher than that of the MPC approach at every prefix length. In addition, when a selective personalization strategy is embedded into the P-QAC model, the QAC performance is further boosted as the MRR scores of the SP-QAC model are higher than those of MPC and P-QAC. Compared to the MPC approach, significant MRR improve-ments of the SP-QAC approach are observed at level  X  = . 05 for the short prefixes, i.e., # p = 1 , 2 , 3 , and at level  X  = . 01 for the long prefixes, i.e., # p = 4 , 5 . Compared to short prefixes, long prefixes are able to reveal a stronger signal for search personaliza-tion, like query repetition. However, compared to the results of the P-QAC model, significant MRR improvements of the SP-QAC model are only observed at short prefixes, i.e., # p = 1 , 2 . This is due to the fact that, compared to short prefixes, long prefixes often return the correct query early in the list of query completions by both models.

To further examine the effectiveness of selective personalization for QAC, we examine the performance of QAC models at different query positions, i.e., at the beginning (1, 2 or 3), in the middle (4, 5 or 6) and in later (  X  7 ) parts of a session. See Table 2. At the start of a session, these three models return competitive MRR scores as limited information from search context is available for the P-QAC and SP-QAC models. However, as the search context becomes richer, significant improvements in terms of MRR are achieved by both personalization models.

Next, we turn to research question RQ2 and examine the perfor-mance of the SP-QAC model under different inputs to the regres-sion model for generating the personalization weights for QAC. We manually remove one factor and keep the other two for the re-gression model, resulting in the SP-QAC-f d f q , SP-QAC-f SP-QAC-f d f p models, which corresponds to the SP-QAC model without considering the factors f p , f d and f q for selectively per-sonalizing QAC, respectively. We plot the results in Figure 1, in-cluding the model incorporating all three factors for selective per-sonalization (i.e., SP-QAC). Figure 1: Performance in terms of MRR of the SP-QAC models under different schemes for weighing personalization, tested at varying prefix lengths (left) and varying query positions (right).
Generally, the SP-QAC model achieves the best performance in terms of MRR at any prefix length and any query position. As shown in Figure 1a, as the prefix length increases, the MRR scores monotonously go up because a long prefix can sharply cut down the space of possible completions matching the input prefix, resulting in increasing MRR scores. In contrast, as shown in Figure 1b, the MRR scores decrease when users continue to query in a session. In the latter part of a search session, users are inclined to submit uncommon queries, making it difficult for MPC to return a correct completion early, which our proposal depends on.

Next, we zoom in on the three factors considered in selective per-sonalization for QAC. As shown in Figure 1a, the MRR scores of the SP-QAC-f p f q and SP-QAC-f d f p models approximate those of the SP-QAC model as the prefix length increases. The MRR scores of SP-QAC-f d f q lag behind those of the SP-QAC model: the sig-nal for personalization from the typed prefix becomes stronger as the prefix length increases, which benefits SP-QAC-f p f QAC-f d f p (both consider the factor f p ). Regarding the QAC per-formance at varying query positions, Figure 1b shows that the mod-els perform similarly at early positions of a session, as insufficient search context is available to tell them apart. In addition, SP-QAC-f f q outperforms SP-QAC-f d f q and SP-QAC-f d f p at most query positions. For later queries in a session, where a richer search con-text is available, information from the typed prefix and previous queries helps for QAC.

In essence, from the results in Figure 1, the SP-QAC model that does not consider the factor f p works worst, from which we infer that f p is the most important factor for selectively personalizing QAC. Similarly, we infer that f q is more important than f
We have proposed a selectively personalized approach for query auto-completion (QAC). Our model predicts whether a specific pre-fix prefers a personalized approach when ranking the query com-pletions. We have explored several factors that influence the weight of personalization in a generic personalized QAC model, such as the typed prefix, the clicked documents and the preceding queries in the same session. The typed prefix yields the most benefits for weighing personalization in query completion re-ranking, and that the preceding queries contributes more than click information.
This work unifies prior work on personalized QAC by studying when and how to incorporate personalization in a QAC task. As to future work, other sources can be explored for investigating how to best personalize query auto-completion, e.g., a user X  X  dwell time or their long-term search history. In addition, it is interesting to zoom in on individual users to determine whether they are likely to benefit from personalization in QAC and whether they stand to gain from diversifying query completions [4].
 Acknowledgments. This research was supported by Ahold, Am-sterdam Data Science, the Bloomberg Research Grant program, the Dutch national program COMMIT, Elsevier, the European Com-munity X  X  Seventh Framework Programme (FP7/2007-2013) under grant agreement nr 312827 (VOX-Pol), the ESF Research Network Program ELIAS, the Royal Dutch Academy of Sciences (KNAW) under the Elite Network Shifts project, the Microsoft Research Ph.D. program, the Netherlands eScience Center under project number 027.012.105, the Netherlands Institute for Sound and Vision, the Netherlands Organisation for Scientific Research (NWO) under pro-ject nrs 727.011.005, 612.001.116, HOR-11-10, 640.006.013, 612.-066.930, CI-14-25, SH-322-15, 652.002.001, 612.001.551, the Ya-hoo Faculty Research and Engagement Program, and Yandex. All content represents the opinion of the authors, which is not nec-essarily shared or endorsed by their respective employers and/or sponsors.
 [1] Z. Bar-Yossef and N. Kraus. Context-sensitive query [2] F. Cai and M. de Rijke. Query auto completion in [3] F. Cai, S. Liang, and M. de Rijke. Time-sensitive [4] F. Cai, R. Reinanda, and M. de Rijke. Diversifying query [5] S. Fox, K. Karnawat, M. Mydland, S. Dumais, and T. White. [6] J. Jiang, D. He, and J. Allan. Searching, browsing, and [7] J.-Y. Jiang, Y.-Y. Ke, P.-Y. Chien, and P.-J. Cheng. Learning [8] Y. Kim, A. Hassan, R. W. White, and I. Zitouni. Modeling [9] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and [10] B. Mitra. Exploring session context using distributed [11] G. Pass, A. Chowdhury, and C. Torgeson. A picture of [12] M. Shokouhi. Learning to personalize query [13] J. Teevan, S. T. Dumais, and D. J. Liebling. To personalize [14] W. Zhang, J. Wang, B. Chen, and X. Zhao. To personalize or
