
Nevertheless, there are situations in which many of the existing measures become consistent with each other. First, the measures may become highly correlated when support-based pruning is used. Support-based pruning also tends to eliminate uncorrelated and poorly correlated patterns. 
Second, after standardizing the contingency tables to have uniform margins[12, 3], many of the well-known measures become equivalent to each other. 
If both situations do not hold, we can find the most appro-priate measure by comparing how well each measure agrees with the expectations of domain experts. This would require the domain experts to manually rank all the patterns or con-tingency tables extracted from the data. However, we show that it is possible to select a small set of "well-separated" contingency tables such that finding the most appropriate measure using this small set of tables is almost equivalent to finding the best measure using the entire data set. 
The problem of evaluating objective measures used by data mining algorithms has attracted considerable atten-tion in recent years [7, 6, 10]. For example, Kononenko et al. [10] have examined the use of different impurity func-tions for top-down inductive decision trees while Hilderman et al. [7, 6] have conducted extensive studies on the behav-ior of various diversity measures for ranking data summaries generated by attribute-oriented generalization methods. 
The specific contributions of this paper are:  X  We present an overview of various measures proposed  X  We describe several key properties one should examine  X  We present two scenarios in which most of the exist- X  We present an algorithm to select a small set of tables 
Let T(D) = (tl,t2,...tn} denotes the set of patterns, represented as contingency tables, derived from the data set D and P is the set of measures available to an analyst. 
Given an interestingness measure M E P, we can compute the vector M(T) : {ml,m2,... , iN}, which corresponds to the values of M for each contingency table that belongs to 2--maxj P(As)-maxh: P(Bk) p(~)2, ' 1--P(A) ) max(P(B[A) -P(B), P(AIB) -P(A)) PI: M = 0 if A and B are statistically independent; 
P2: M monotonically increases with P(A, B) when P(A) 
P3: M monotonically decreases with P(A) (or P(B)) when 
These properties axe well-known and have been extended by many authors [8, 6]. Table 6 illustrates the extent to which each of the existing measure satisfies the above properties. tion. These properties can be described using a matrix for-mulation. In this formulation, every 2  X  2 contingency table is represented as a contingency matrix, M = [fllfxo; folfoo] while every interestingness measure is a matrix operator, O, that maps the matrix M into a scalar value, k, i.e., OM = k. 
For instance, t:he  X  coefficient is equivalent to a normal-ized form of the determinant operator, where Det(M) = fllfoo-fmflo. Thus, statistical independence is represented by a singular matrix M whose determinant is equal to zero. 
The underlying properties of a measure can be analyzed by performing various operations on the contingency tables as depicted in Figure 1. property, P2, proposed by Piatetsky-Shapiro is equivalent to adding the matrix M with [k -k; -k k], while the third property, P3, is equivalent to adding [0 k; 0 -k] or [00; k -k]toNi. 
Property 5. [Null Invariance] A binary measure of association is null-invariant if O(M + C) = O(M) where C = [00; 0 k] and k is a positive constant. For binary variables, this operation corresponds to adding more records that do not contain the two variables under consideration, as shown in Figure l(e). Some of the null-invariant measures include IS (cosine) and the Jaccard simi-larity measure,  X . This property is useful for domains having sparse data sets, where co-presence of items is more impor-tant than co-absence. 
The discussion in this section suggests that there is no measure that is better than others in all application do-mains. This is because different measures have different in-trinsic properties, some of which may be desirable for certain applications but not for others. Thus, in order to find the right measure, one must match the desired properties of an application against the properties of the existing measures. 
Support is a widely-used measure in association rule min-ing because it represents the statistical significance of a pat-tern. Due to its anti-monotonicity property, the support measure has been used extensively to develop efficient al-gorithms for mining such patterns. We now describe two additional consequences of using the support measure. 
First, we show that many of the measures are highly cor-related with each other under certain support constraints. To illustrate this, we randomly generated a synthetic data set that contains 10,000 contingency tables and ranked the tables according to all the available measures. Using Defi-nition 1, we can compute the similarity between every pair of measures for the synthetic data set. Figure 3 depicts the pair-wise similarity when various support bounds are imposed. The dark cells indicate that the similarity, i.e., correlation, between the two measures is greater than 0.85 while the lighter cells indicate otherwise. We have re-ordered the similarity matrix using the reverse Cuthill-McKee algo-rithm [4] so that the darker cells are moved as close as possi-ble to the main diagonal. Our results show that by imposing a tighter bound on the support of the patterns, many of the measures become highly correlated with each other. This is shown by the growing region of dark cells as the support bounds are tightened. In fact, the majority of the pair-wise correlation between measures is greater them 0.85 when the support values axe between 0.5% and 30% (the bottom-right figure), which is a quite reasonable range of support values for many practical domains. 
Many association rule algorithms allow an analyst to spec-ify a minimum support threshold to prune out the low-support patterns. Since the choice of minimum support analysis where such a pruning strategy is used extensively. political science and social science studies to harldle contin-gency tables that have non-uniform marginals. Mosteller suggested that standardization is needed to get a better idea of the underlying association between variables [12], by transforming an existing table so that their marginals are equal, i.e., f~+ = f~+ = f~-i = f~-o = N/2 (see Ta,-ble 7). A standardized table is useful because it provides a visual depiction of how the joint distribution of two variables would look like aster eliminating biases due to non-uniform marginals. is called the Iterative Proportional Fitting algorithm or IPF [3], (b) Distribution of C-coefficient for contingency tables that are removed by applying a minimum support threshold.. standardized contingency tables for each example given in Table 3. Observe that the rankings are identical for all the measures. This observation can be explained in the following way. After standardization, the contingency matrix has the following form [x y; y x], where x = ff~l and y = N/2 -x. The rankings are the same because many measures of as-sociation (specifically, all 21 considered in this paper) are monotonically increasing functions of x when applied to the standardized, positively-correlated tables. We illustrate this with the following example. 
Example 1. The tit-coefficient of a standardized table is: For a fixed N,  X  is a monotonically increasing function of x. Similarly, we can show that other measures such as o~, I, IS, PS, etc., are also monotonically increasing functions of of x. The only exceptions to this are ~, gini index, mutual information, J-measure, and Klosgen's K, which are con-vex functions of x. Nevertheless, these measures are mono-tonically increa~ing when we consider only the values of x between N/4 and N/2, which correspond to non-negatively correlated tables. Since the examples given in Table 3 are positively-correlated, all 21 measures given in this paper pro-duce identical ordering for their standardized tables. 
Note that since each iterative step in IPF corresponds to either a row or column scaling operation, odds ratio is pre-served throughout the transformation (Table 6). In other words, the final rankings on the standardized tables for any measure are consistent with the rankings produced by odds ratio on the original tables. For this reason, a casual ob-server may think that odds ratio is perhaps the best mea-sure to use. This is not true because there are other ways to standardize a contingency table. To illustrate other stan-dardization schemes, we first show how to obtain the exact Figure 7: Average distance between similarity matrix computed from the samples (Ss) and the similarity ma-trix computed from the entire set of contingency tables (ST) for the re0 data set. that are furthest apart in terms of their relative rankings and tables that create a huge amount of ranking conflicts. Even at k = 20, there is little difference (D &lt; 0.15) between the similarity matrices Ss and ST. 
L._N_~_.~......~J.._De.scriptio.....___n Number of Variables ~ ~ter~~ 2886 
We complement our evaluation above by showing that the ordering of measures produced by the DISJOINT algorithm on even a small sample of 20 tables is quite consistent with the ordering of measures if the entire tables are ranked by the domain experts. To do this, we assume that the rankings provided by the experts is identical to the rankings produced by one of the measures, say, the C-coefficient. Next, we re-move  X  from the set of measures M considered by the DIS-JOINT algorithm and repeat the experiments above with k = 20 and p = 10. We compare the best measure selected by our algorithm against the best measure selected when the entire set of contingency tables is available. The results are depicted in Figure 8. In nearly all cases, the difference in the ranking of a measure between the two (all tables versus a sample of 20 tables) is 0 or 1. 
In this paper, we have described several key properties one should consider before deciding what is the right measure to use for a given application domain. We show that there is no measure that is consistently better than others in all cases. Nevertheless, there are situations in which many of these measures are highly correlated with each other, e.g., when support-based pruning or table standardization are used. If both situations do not hold, one should select the best 
