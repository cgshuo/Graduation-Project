 Jun Wang  X  Stephen Robertson  X  Arjen P. de Vries  X  Marcel J. T. Reinders Abstract Collaborative filtering is concerned with making recommendations about items ratings, assuming past data of explicit user ratings is available. However, in practice we may only have implicit evidence of user preference; and furthermore, a better view of the task is of generating a top-N list of items that the user is most likely to like. In this regard, we argue that collaborative filtering can be directly cast as a relevance ranking problem. We begin with the classic Probability Ranking Principle of information retrieval, proposing a probabilistic item ranking framework. In the framework, we derive two different ranking models, showing that despite their common origin, different factorizations reflect two cussions to implicit user preference data, and adopt an approximation method introduced in frequency counts and presence/absence counts in the preference data. Furthermore, we extend the basic formula by proposing the Bayesian inference to estimate the probability of relevance (and non-relevance), which largely alleviates the data sparsity problem. Apart proposed methods perform significantly better than other strong baselines.
 Keywords Collaborative filtering Recommender systems Probability Ranking Principle Relevance ranking Personalization 1 Introduction Collaborative filtering aims at identifying interesting information items (e.g. movies, books, websites) for a set of users, given their user profiles. Different from its counterpart, perform predictions, thus making direct analysis of content features unnecessary. User profiles can be explicitly obtained by asking users to rate items that they know. However these explicit ratings are hard to gather in a real system (Claypool et al. 2001 ). It is highly desirable to infer user preferences from implicit observations of user interactions with a system. These implicit interest functions usually generate frequency-counted pro-files, like  X  X  X layback times of a music file X  X , or  X  X  X isiting frequency of a web-site X  X  etc.
So far, academic research into frequency-counted user profiles for collaborative filtering focuses on rating-based user profiles (Adomavicius and Tuzhilin et al. 2005 ; Marlin 2004 ). Research started with memory-based approaches to collaborative filtering (Herlocker et al. 1999 ; Sarwar et al. 2001 ; Wang et al. 2006 ; Xue et al. 2005 ) and lately came with model-based approaches (Hofmann 2004 ; Jin et al. 2006 ; Marlin 2004 ).

In spite of the fact that these rating-based collaborative filtering algorithms lay a solid foundation for collaborative filtering research, they are specifically designed for rating pre-diction, making them difficult to apply in many real situations where frequency-counted user profiling is demanded. Most importantly, the purpose of a recommender system is to suggest to a user items that he or she might be interested in. The user decision on whether accepting a suggestion (i.e. to review or listen to a suggested item) is a binary one. As already demon-strated in (Deshpande and Karypis 2004 ; McLaughlin and Herlocker et al. 2004 ), directly using predicted ratings as ranking scores may not accurately model this common scenario.
This motivated us to conduct a formal study on probabilistic item ranking for collab-orative filtering. We start with the Probability Ranking Principle of information retrieval (Robertson 1997 ) and introduce the concept of  X  X  X inary relevance X  X  into collaborative filtering. We directly model how likely an item might be relevant to a given user (profile), and for the given user we aim at presenting a list of items in rank order of their predicted relevance. To achieve this, we first establish an item ranking framework by employing the log-odd ratio of relevance and then derive two ranking models from it, namely an item-based relevance model and user-based relevance model . We then draw an analogy between the classic text retrieval model (Robertson and Walker et al. 1994 ) and our models, effectively decoupling the estimations of frequency counts and (non-)relevance counts from implicit user preference data. Because data sparsity makes the probability estimations less reliable, we finally extend the basic log-odd ratio of relevance by viewing the prob-abilities of relevance and non-relevance in the models as parameters and apply the Bayesian inference to enforce different prior knowledge and smoothing into the probability estimations. This proves to be effective in two real data sets.

The remainder of the paper is organized as follows. We first describe related work and empirical evaluation of the recommendation performance and the impact of the parameters of our two models, and finally conclude our work. 2 Related work 2.1 Rating prediction In the memory-based approaches, all rating examples are stored as-is into memory (in contrast to learning an abstraction), forming a heuristic implementation of the  X  X  X ord of Mouth X  X  phenomenon. In the rating prediction phase, similar users or (and) items are sorted items, a prediction of an item rating for a test user can be generated. Examples of memory-based collaborative filtering include user-based methods (Breese et al. 1998 ; Herlocker et al. 1999 ; Resnick et al. 1994 ), item-based methods (Deshpande and Karypis 2004 ; Sarwar et al. 2001 ) and unified methods (Wang et al. 2008 ; Wang et al. 2006 ). The advantage of the memory-based methods over their model-based alternatives is that less parameters have to be tuned; however, the data sparsity problem is not handled in a principled manner.

In the model-based approaches, training examples are used to generate an  X  X  X bstrac-before. In this regard, many probabilistic models have been proposed. For example, to consider user correlation, (Pennock et al. 2000 ) proposed a method called personality item can be predicted. On the other hand, to model item correlation, (Breese et al. 1998 ) utilizes a Bayesian Network model, in which the conditional probabilities between items are maintained. Some researchers have tried mixture models, explicitly assuming some hidden variables embedded in the rating data. Examples include the aspect models factor model (Canny 2002 ). These methods require some assumptions about the underlying data structures and the resulting  X  X ompact X  models solve the data sparsity parameters has prevented these methods from practical usage. For instance, in the aspect user. 2.2 Item ranking Memory-based approaches are commonly used for rating prediction, but they can be easily extended for the purpose of item ranking. For instance, a ranking score for a target item can be calculated by a summation over its similarity towards other items that the target user liked (i.e. in the user preference list). Taking this item-based view, we formally have the following basic ranking score: practice cosine similarity and Pearson X  X  correlation are generally employed. To specifically target the item ranking problem, researchers in (Deshpande and Karypis. 2004 ) proposed an alternative, TFxIDF-like similarity measure, which is shown as follows: where Freq denotes the frequency counts of an item Freq  X  i m 0  X  or co-occurrence counts for of empirical observations, they also introduced two normalization methods to further improve the ranking.

In Wang et al. ( 2006 ), we proposed a language modelling approach for the item ranking problem in collaborative filtering. The idea is to view an item (or its presence in a user linear smoothing technique (Zhai and Lafferty 2001 ), we have the following ranking formula: k [ [0, 1] is used as a linear smoothing parameter to further smooth the conditional probability from a background model ( P  X  i m 0  X  ).

Nevertheless, our formulations in Wang et al. ( 2006 ) only take the information about presence/absence of items into account when modelling implicit user preference data, completely ignoring other useful information such as frequency counts (i.e. the number of visiting/playing times). We shall see that the probabilistic relevance framework proposed in this paper effectively extends the language modelling approaches of collaborative fil-tering. It not only allows us to make use of frequency counts for modelling implicit user preferences but has room to model non-relevance in a formal way. They prove to be crucial to the accuracy of recommendation in our experiments. 3 A probabilistic relevance ranking framework The task of information retrieval aims to rank documents on the basis of their relevance (usefulness) towards a given user need (query). The Probability Ranking Principle (PRP) of information retrieval (Robertson 1997 ) implies that ranking documents in descending order by their probability of relevance produces optimal performance under a  X  X  X easonable X  X  assumption, i.e. the relevance of a document to a user information need is independent of other documents in the collection (van Rijsbergen 1979 ).

By the same token, our task for collaborative filtering is to find items that are relevant (useful) to a given user interest (implicitly indicated by a user profile). The PRP applies introduce the concept of  X  X  X elevancy X  X  into collaborative filtering. By analogy with the rel-evance models in text retrieval (Lafferty et al. 2003 ; Robertson and Sparck Jones et al. 1976 ; Taylor et al. 2003 ), the top-N recommendation items can be then generated by ranking items in order of their probability of relevance to a user profile or the underlying user interest.
To estimate the probability of relevance between an item and a user (profile), let us first define a sample space of relevance: U R and let R be a random variable over the relevance space U R . R is either  X  X elevant X  r or  X  X on-relevant X  r : Secondly, let U be a discrete random variable over the sample space of item id  X  X : U I  X f i 1 ; ... ; i M g ; where K is the number of identifiers and I refers to the item identifiers.
 We then denote P as a probability function on the joint sample space U U 9 U I 9 U R . The the collection U I for a given user U = u k can be formulated as the log odds of the relevance: i , respectively. 3.1 Item-based relevance model Two different models can be derived if we apply the Bayes X  rule differently. This section introduces the item-based relevance model, leaving the derivations of the user-based rel-evance model in Sect. 3.2.
 can be obtained from Eq. 4 : Notice that, in the ranking model shown in Eq. 5 , the target user is defined in the user id space. For a given new user, we do not have any observations about his or her relevancy towards an unknown item. This makes the probability estimations unsolvable. In this regard, we need to build a feature representation of a new user by his or her user profile so as to relate the user to other users that have been observed from the whole collection.
This paper considers implicit user profiling: user profiles are obtained by implicitly observing user behavior, for example, the web sites visited, the music files played etc., and a user is represented by his or her preferences towards all the items. More formally, we treat a user (profile) as a vector over the entire item space, which is denoted as a bold letter user played or visited item i m 0 : Note that we deliberately used the item index m 0 for the items in the user profile, as opposed to the target item index m . For each user u k , the user profile vector is instantiated (denoted as l k ) by assigning this user X  X  item frequency counts visited item i m 0 : Changing the user presentation from Eq. 5 , we have the following: tionally independent, given relevance or non-relevance. 1 Although this conditional independent assumption does not hold in many real situations, it has been empirically shown to be a competitive approach (e.g., in text classification (Eyheramendy et al. 2003 )). utilise the correlations between items is crucial to the item-based approach.

For the sake of computational convenience, we intend to focus on the items ( i m 0 ; where m 0 [ {1, M }) that are present in the target user profile ( c m 0 user profile into two groups, i.e. presence and absence, we have: Both subtracting to the first term and adding it from the second (where ln x ln y  X  ln x y ) gives o  X  i m  X  X  evidence that a user who likes item i m , what is the probability that this user plays item i m 0 c 0 times.

In summary, we have the following ranking formula: where From the final ranking score, we observe that the relevance ranking of a target item in the item-based model is a combination between the evidence that is dependent on the target Sect. 3.2 that, due to the asymmetry between users and items, the final ranking of the user-based model (Eq. 27 ) only requires the  X  X  X ser profile X  X -dependent evidence. 3.1.1 Probability estimation tribution. Yet, an item occurring in a user profile does not necessarily mean that this user likes this item: randomness is another explanation, particularly when the item occurs few times only. Thus, a better model would be a mixture of two Poisson models, i.e. a linear combination between a Poisson model coping with items that are  X  X  X ruly X  X  liked by the user and a Poisson model dealing with some background noise. To achieve this, we introduce a hidden random variable E m 0 2f e ; e g for each of the items in the user profile, describing ( E describing the probabilistic relationships among the random variables is illustrated in Fig. 1 a. More formally, for the relevance case, we have where k 1 and k 0 are the two Poisson means, which can be regarded as the expected item the probability that the user indeed likes item i 0 m ; given the condition that he or she liked another item i m . A straight-forward method to obtain the parameters of the Poisson mix-tures is to apply the Expectation-Maximization (EM) algorithm (Dempster et al. 1977 ). To illustrate this, Fig. 1 b plots the histogram of the item frequency distribution in the Last.FM data set as well as its estimated Poisson mixtures by applying the EM algorithm. (a)(b)
The same can be applied to the non-relevance case. Incorporating the Poisson mixtures for the both cases into Eq. 11 gives  X   X  the non-relevance case, while W i 0 item and the item in the user profile.
 making the model difficult to apply in practice. Furthermore, it should be emphasised that the component distributions estimated by the EM algorithm may not necessarily corre-spond to the two reasons that we mentioned for the presence of an item in a user profile, even if the estimated mixture distribution may fit the data well.

In this regard, this paper takes an alternative approach, approximating the ranking been proposed for modeling within-document term frequencies (Harter 1975 ). To make it applicable also, (Robertson and Walker et al. 1994 ) introduced an approximation method, resulting in the widely-used BM25 weighting function for query terms. Following the same way of thinking, we can see that the weighting function for each of the items in the target user profile W i 0 monotonically with respect to the item frequency count c m 0 k ; and (2) it reaches its upper-bound, governed by log( p (1 -q )/ q (1 -p )), when c m 0 k becomes infinity ? (Sparck et al. 2000 , Sparck et al. 2000 ). Roughly speaking, as demonstrated in Fig. 2 , the parameters k 0 and k 1 can adjust the rate of the increase (see Fig. 2 a), while the parameters p and q mainly control the upper bound (see Fig. 2 b).

Therefore, it is intuitively desirable to approximate these two characteristics sepa-asymptotic maximum, to model the monotonic increase with respect to the item fre-quency counts. Since the probabilities q and p cannot be directly estimated, a simple lowing ranking function: where the free parameter k 3 is equivalent to the normalization parameter of within-query frequencies in the BM25 formula (Robertson and Walker 1994 ) (also see Appendix A), if item m 0 occurs in a profile of a user who is relevant (or non-relevant) to item i m . Equa-tion 16 essentially decouples frequency counts c m 0 k and presence (absence) probabilities (e.g. P ( l m 0 [ 0| i m , r )), thus largely simplifying the computation in practice.
Next, we consider the probability estimations of presence (absence) of items in user profiles. To handle data sparseness, different from the Robertson-Sparck Jones probabi-Bayesian inference (Gelman et al. 2003 ) to estimate the presence (absence) probabilities. h tion. For simplicity, we treat the parameter as a random variable and estimate its value by maximizing an a posteriori probability. Formally we have where R m denotes the number of user profiles that are relevant to an item i m , and among addition, we choose the Beta distribution as the prior (since it is the conjugate prior for the updated parameters. (a)(b) Maximizing an a posteriori probability in Eq. 18 (i.e. taking the mode) gives the estimation of the parameter (Gelman et al. 2003 ) Following the same reasoning, we obtain the probability of item occurrences in the non-relevance case.
 in a user profile (See Table 1 ). Replacing Eqs. 19 and 20 into Eq. 16 , we have Varying choices for them leads to different estimators (Zaragoza et al. 2003 ). In the information retrieval domain (Robertson and and Sparck Jones et al. 1976 ; Robertson and Walker 1994 ), adding an extra 0.5 count for each probability estimation has been widely used to avoid zero probabilities. This choice corresponds to set tiny constant values a r  X  a  X  b r  X  b r  X  1 : 5 : We shall see that in the experiments collaborative filtering needs relatively bigger pseudo counts for the non-relevance and/or absence estimation ( a r ; b r and b ). This can be explained because using absence to model non-relevance is noisy, so more smoothing is needed. If we define a free parameter v and set it to be equal to a r -1, we have the generalized Laplace smoothing estimator. Alternatively, the prior can be fit on a distribution of the given collection (Zhai and Lafferty 2001 ).
 Applying the Bayesian inference similarly, we obtain X i m as follows: For the last term, the popularity ranking Y i m ; we have
Notice that in the initial stage, we do not have any relevance observation of item i m .We may assume that if a user played the item frequently (say played more than t times), we treat this item being relevant to this user X  X  interest. By doing this, we can also construct the contingency table to be able to estimate the probabilities. 3.2 User-based relevance model Applying the Bayes X  rule differently results in the following formula from Eq. 4 : target item i m , we get discarded. Thus we have where / u k denotes same rank order with respect to u k .

Following the same steps (the approximation to two-Poisson distribution and the MAP probability estimation) as discussed in the previous section gives where K X  k 1  X  X  1 b  X  X  bL m  X  : k 1 is the normalization parameter of the frequency counts for the target item, L m is the normalized item popularity (how many times the item i m has been  X  X  X sed X  X ) (i.e. the popularity of this item divided by the average popularity in the collection), and b [ [0, 1] denotes the mixture weight. Notice that if we treat an item as a document, the parameter k 1 is equivalent to the normalization parameter of within-document frequencies in the BM25 formula (see Appendix A). Table 2 shows the contingency table of user pairs. 3.3 Discussion Previous studies on collaborative filtering, particularly memory-based approaches, make a distinction between user-based (Breese et al. 1998 ; Herlocker et al. 1999 ; Resnick et al. 1994 ) and item-based approaches (Deshpande and Karypis 2004 ; Sarwar et al. 2001 ). Our probabilistic relevance models were derived with an information retrieval view on col-laborative filtering. They demonstrated that the user-based (relevance) and item-based (relevance) models are equivalent from a probabilistic point of view, since they have actually been derived from the same generative relevance model. The only difference corresponds to the choice of independence assumptions in the derivations, leading to the model, the item-to-item relevancy is estimated while in the user-based one, the user-to-user relevancy is required instead. We shall see shortly in our experiments that the probability estimation is one of the important factors influencing recommendation performance. 4 Experiments 4.1 Data sets using implicit user profiles. This paper adopts two implicit user profile data.
The first data set comes from a well known social music web site: Last : FM : It was collected from the play-lists of the users in the community by using a plug-in in the users X  media players (for instance, Winamp, iTunes, XMMS etc). Plug-ins send the title (song name and artist name) of every song users play to the Last.FM server, which updates the user X  X  musical profile with the new song. For our experiments, the triple {userID, artistID, Freq} is used.

The second data set was collected from one well-known collaborative tagging Web site, del : icio : us : Unlike other studies focusing on directly recommending contents (Web sites), here we intend to find relevance tags on the basis of user profiles as this is a crucial step in such systems. For instance, the tag suggestion is needed in helping users assigning tags to new contents, and it is also useful when constructing a personalized  X  X  X ag cloud X  X  for the purpose of exploratory search (Wang et al. 2007 ). The Web site has been crawled between May and October 2006. We collected a number of the most popular tags, found which users were using these tags, and then downloaded the whole profiles of these users. We extracted the triples {userID, tagID, Freq} from each of the user profiles. User IDs are randomly generated to keep the users anonymous. Table 3 summarizes the basic charac-teristics of the data sets. 2 4.2 Experiment protocols For 5-fold cross-validation, we randomly divided this data set into a training set (80% of the users) and a test set (20% of the users). Results are obtains by averaging 5 different runs (sampling of training/test set). The training set was used to estimate the model. The test set was used for evaluating the accuracy of the recommendations on the new users, whose user profiles are not in the training set. For each test user, 5, 10, or 15 items of a test recommendations.

In information retrieval, the effectiveness of the document ranking is commonly measured by precision and recall (Baeza-Yates and Ribeiro-Neto 1999 ). Precision mea-sures the proportion of retrieved documents that are indeed relevant to the user X  X  successfully retrieved. In the case of collaborative filtering, we are, however, only inter-ested in examining the accuracy of the top-N recommended items, while paying less attention to finding all the relevant items. Thus, our experiments here only consider the recommendation precision , which measures the proportion of recommended items that are estimates the true precision. 4.3 Performance We choose the state-of-the-art item ranking algorithms that have been discussed in Section 2.2 as our baselines. For the method proposed in (Deshpande and Karypis 2004 ), we adopt their implementation, the top-N suggest recommendation library 3 which is denoted as SuggestLib : We also implement the language modelling approach of collaborative fil-tering in (Wang et al. 2006 ) and denote this approach as LM LS while its variant using the Bayes X  smoothing (i.e., a Dirichlet prior) is denoted as LM BS : To make a comparison, the parameters of the algorithms are set to the optimal ones.

We set the parameters of our two models to the optimal ones and compare them with these strong baselines. The item-based relevance model is denoted as BM25 Item while the user-based relevance model is denoted as BM25 User : Results are shown in Figs. 3 and 4 over different returned items. Let us first compare the performance of the BM25 Item and BM25 User models. For the Last : FM data set (Fig. 3 ), the item-based relevance model consistently performs better than the user-based relevance model. This confirms a previous observation that item-to-item similarity (relevancy) in general is more robust than user-to-user similarity (Sarwar et al. 2001 ). However, if we look at the del : icio : us data (Fig. 4 ), the performance gain from the item-based relevance model is not clear any more X  X e obtain a mixture result and the user-based one even outperforms the item-based one when the number of items in user preferences is set to 15 (see Fig. 4 c). We think this is because the characteristics of data set play an important role for the probability estimations in the models. In the Last : FM data set, the number of users is larger than the number of items (see Table 3 ). It basically means that we have more observations from the user side about the item-to-item relevancy while having less observations from the item side about user-to-user relevance model is more reliable than that of the user-based relevance model. But in the del : icio : us data set (see Table 3 ), the number of items is larger than the number of users. Thus we have more observations about user-to-user relevancy from the item side, causing a significant improvement for the user-based relevance model.

Since the item-based relevance model in general outperforms the user-based relevance model, we next compare the item-based relevance model with other methods (shown in Table 4 and 5 ). From the tables, we can see that the item-based relevance model performs consistently better than the SuggestLib method over all the configurations. A Wilcoxon signed-rank test (Hull 1993 ) is done to verify the significance. We also observe that in most of the configurations our item-based model significantly outperforms the language mod-elling approaches, both the linear smoothing and the Bayesian smoothing variants. We integrates frequency counts and probability estimation of non-relevance into the ranking formula, apart from other alternatives. 4.4 Parameter estimation This section tests the sensitivity of the parameters, using the del : icio : us data set. Recall that for both the item-based relevance model (shown in Eq. 10 ) and the user-based (a) (c) relevance model (shown in Eq. 27 ), we have frequency smoothing parameter k 1 (and b )or k , and co-occurrence smoothing parameters a and b . We first test the sensitivity of the frequency smoothing parameters. Figure 5 shows recommendation precision against the parameters k 1 and b of the user-based relevance model while Fig. 6 shows recommenda-tion precision varying the parameter k 3 of the item relevance model. The optimal values in the figures demonstrate that both the frequency smoothing parameters ( k 1 and k 3 ) and the length normalization parameter b , inspired by the BM25 formula, indeed improve the recommendation performance. We also observe that these parameters are relatively insensitive to different data sets and their different sparsity setups.

Next we fix the frequency smoothing parameters to the optimal ones and test the co-occurrence smoothing parameters for both models. Figures 7 and 8 plot the smoothing parameters against the recommendation precision. More precisely, Figs. 7 a and 8 a plot the smoothing parameter for the relevance part v 1 = a r -1 while Figs. 7 b and 8 b plot ( v 2  X  a r 1  X  b r 1  X  b r 1) in order to minimize the number of parameters while still retaining comparable performance. From the figures, we can see that the optimal smoothing parameters (pseudo counts) of the relevance part v 1 are relatively small, compared to those of the non-relevance part. For the user-based relevance model, the pseudo counts of the non-relevance estimations are in the range of (Deshpande and Karypis 2004 ; Hofmann 2004 ) (Fig. 7 b) while for the item-based relevance model, they (a)(b) (c) estimation is not as reliable as the relevance estimation and thus more smoothing is required.
 (a)(b) (a)(b) 5 Conclusions This paper proposed a probabilistic item ranking framework for collaborative filtering, variants (Robertson and and Sparck Jones et al. 1976 ; Robertson and Walker 1994 ; Sparck et al. 2000 ; Sparck et al. 2000 ). We have derived two different models in the relevance framework in order to generate top-N item recommendations. We conclude from the experimental results that the proposed models are indeed effective, and significantly improve the performance of the top-N item recommendations.

In current settings, we fix a threshold when considering frequency counts as relevance number of times a user played an item. To do this, we may weight (sampling) the importance of the user profiles according to the number of times the user played/reviewed an item when we construct the contingency table. In current models, the hyperparameters evidence approximation framework (Bishop and 2006 ) by which the hyperparameters can integrates over the hyperparameters and the model parameters by adopting variational methods (Jordan 1999 ).
 spondence between user interest and information items. We have setup a close relationship facilitates a flexible framework to tryout more of the techniques that have been used in text vations can be easily incorporated in the framework once we have relevance feedback from users. An interesting observation is that, different from text retrieval, relevance feedback for a given user in collaborative filtering is not dependent of this user X  X   X  X  X uery X  X  (a user whole collection; Relevance feedback from one user could influence the ranking order of relevant items as query items or re-calculating (re-constructing) the contingency table according to the relevance information. (a)(b)
Finally, a combination of the two relevance models is of interest (Wang et al. 2008 , (Robertson et al. 1982 ). However, there are also some differences: in information retrieval, impact which we have already identified in the present (non-unified) models for collabo-rative filtering. These subtle differences make the exploration of the unified model ideas particularly attractive.
 Appendix A: The Okapi BM25 document ranking score To make the paper self-contained and facilitate the comparison between the proposed model and the BM25 model of text retrieval (Robertson and Walker 1994 ; Sparck et al. 2000 ), here we summarise the Okapi BM25 document ranking formula. The commonly-used ranking function S q ( d ) of a document d given a query q is expressed as follows: where  X  c t q denotes the within query frequency of a term t at query q , while c t d denotes the with  X  k 1 and k 3 are constants. The factors k 3 + 1 and k 1 + 1 are unnecessary here, but help  X  K k 1  X  X  1 b  X  X  bL d  X  : L d is the normalised document length (i.e. the length of this  X  n t is the number of documents in the collection indexed by this term t .  X  N is the total number of documents in the collection.  X  r t is the number of relevant documents indexed by this term t .  X  R is the total number of relevant documents.
 For detailed information about the model and its relationship with the Robertson-Sparck Jones probabilistic retrieval (RSJ) model (Robertson and and Sparck Jones 1976 ), we refer to (Robertson and Walker 1994 ; Sparck et al. 2000 ).
 References
