 Resource Description Framework (RDF) [10] is a World Wide Web Consortium (W3C) Recommendation and is a data model to represent information on the Web. It uses Uniform Resource Identifier (URI) references 1 to identify things and RDF triples of the form ( s, p, o ) to make statements, where s , p , o are the subject, property and object respectively. (Tom, rdf:type, Professor) is an exam-ple of RDF triples that would appear in the university domain, which we will use throughout the paper to illustrate some concepts. RDF Schema (RDFS) is an extension of RDF. It provides a vocabulary to describe application-specific classes, properties, class and property h ierarchies, and which classes and prop-erties are used together. For example, (Professor, rdf:type, rdfs:Class) means that Professor is a class. We often divide RDF triples into two sets. One con-tains triples the subjects of which are either classes or properties. We call them schema triples. The other contains triples the subjects of which are instances. We call them instance triples. Schema triples are more permanent and definitional in nature while the instance triples are more dynamic.

Because of lack of knowledge, some triples are known to be true with a certain degree of belief. Huang et al. X  X  probabilistic RDF database [5] encodes probabilis-tic knowledge by assigning each triple a probability and assuming that triples are statistically independent of each other. However, it cannot encode statistical relationships among correlated triples. It also does not comply with the RDFS semantics. Probabilistic RDF (pRDF) [12] encodes probabilistic knowledge by specifying the probability distribution over possible objects of a triple. Any tri-angular norm can be used to compute the probability of a conjunction of triples. pRDF restricts the probability distributions to those over triples with the same subject and property.

In this paper, we introduce probabilistic RDFS (pRDFS), which has greater flexibility in encoding probabilistic knowledge. It assumes schema triples are al-ways true and models statistical relationships among correlated instance triples by specifying the joint probability distributions over them. The probability dis-tributions cannot be specified arbitrarily since there may exist some truth value assignments for triples that violate the RDFS semantics. We provide an algo-rithm to check the consistency. We als o describe how to compute answers with probabilities to queries in SPARQL [11], which is a W3C Recommendation and is a query language for RDF.

The remainder of this paper is organized as follows. Sections 2 and 3 define the syntax and semantics of pRDFS resp ectively. Section 4 discusses how to check the consistency of a pRDFS theory. Section 5 describes query evaluation based on a pRDFS theory. Section 6 evalua tes experimentally the execution time performance of consistency checking and query answering on top of a pRDFS theory. Section 7 reviews the related w ork. Finally, Section 8 concludes this paper. Let V be a set of vocabulary, which consists of a set of URI references U and a set of literals L . C , P and I are the sets of classes, properties and individuals respectively. They are subsets of U and we assume that they are mutually dis-joint. A pRDFS schema H is a set of RDF triples, whose subjects are classes or properties. A pRDFS instance ( R,  X  ) consists of a set of RDF triples R ,whose subjects are individuals and a mapping  X  describing the uncertainty of R .Each triple in R can be interpreted as a boolean variable and takes a value from { true, R such that any two different elements of the partition are statistically indepen-dent. Let  X  be a truth value assignment function for the triples in R .Itisfrom R to { T,F } .  X  | R distribution function of R i that maps  X  | R the independence assumption, the joint probability distribution function of R , P
R (  X  ) can be written as P R 1 (  X  ping  X  ,whichisfrom R to { P R 1 ,...,P R pRDFS theory is a triple ( H, R,  X  ), where H and ( R,  X  )arethepRDFSschema and instance respectively.
 Example 1. Let h 1 = (Student, rdf:type, rdfs:Class), h 2 = (Professor, rdf:type, rdfs:Class), h 3 = (Course, rdf:type, rdfs:Class), h 4 = (takesCourse, rdf:type, rdf:Property), h 5 = (teacherOf, rdf:type, rdf:Property), r 1 =(semanticWeb, rdf:type, Course), r 2 = (Tom, rdf:type, Professor), r 3 = (May, rdf:type, Profes-sor), r 4 = (Tom, teacherOf, semanticWeb), r 5 = (May, teacherOf, semanticWeb), r 6 = (John, rdf:type, Student), r 7 = (Mary, rdf:type, Student), r 8 = (John, takesCourse, semanticWeb) and r 9 = (Mary, takesCourse, seman-ticWeb). H = { h 1 ,...,h 5 } is a pRDFS schema. R = { r 1 ,...,r 9 } is a pRDFS instance. Professors Tom and May both sp ecialize in semantic web. Their chance dents John and Mary have the same interest and are good friends. Their chance } ( r } . The probability that Tom is the only teacher of semantic web and both ( r 5 ,F), ( r 6 ,T), ( r 7 ,T), ( r 9 ,F), ( r 10 ,F) P  X  Aworld W is a set of triples that follows the semantics of RDFS. Specifically, it satisfies the following criteria. 1. RDFS axiomatic triples  X  W . 2. If ( x , rdfs:domain, y ), ( u , x , v )  X  W ,then( u ,rdf:type, y )  X  W . 3. If ( x , rdfs:range, y ), ( u , x , v )  X  W ,then( v ,rdf:type, y )  X  W . 4. If ( x , rdf:type, rdf:Property)  X  W ,then( x , rdfs:subPropertyOf, x )  X  W . 5. If ( x , rdfs:subPropertyOf, y ), ( y , rdfs:subPropertyOf, z )  X  W ,then( x , 8. If ( x , rdf:type, rdfs:Class)  X  W ,then( x , rdfs:subClassOf, x )  X  W . 9. If ( x , rdfs:subClassOf, y ), ( y , rdfs:subClassOf, z )  X  W ,then( x , In this paper, we ignore the handling of blank nodes, containers and datatypes.  X  is the set of all possible worlds. A pRDFS interpretation is a mapping I :  X   X  [0 , 1], such that W  X   X  I ( W )=1. I satisfies a pRDFS theory ( H, R,  X  ) any truth value assignment  X  ,where A is the set of RDFS axiomatic triples. A pRDFS theory is consistent if it has a satisfying interpretation. A theory of ( H, R 1 , X  1 ) is a satisfying interpretation of ( H, R 2 , X  2 ). Example 2 (Consistent theory). Consider the pRDFS theory in Example 1. Let worlds W i = A  X  H  X  X  r 1 ,r 2 ,r 3 ,r 6 ,r 7 } X  B i for i =1 ,..., 8, where A is the B theory has a satisfying interpretation I , which maps W 1 , W 4 , W 5 , W 8 to 0.2, W 2 , W 3 , W 6 , W 7 to 0.05, and all other worlds to 0. Therefore, it is consistent. Example 3 (Inconsistent theory). Consider another pRDFS theory ( H , R ,  X  ), h 2 = (Department, rdf:type, rdfs:Class), h 3 = (worksFor, rdf:type, rdf:Property), h 4 = (headOf, rdf:type, rdf:Property), h 5 = (headOf, rdfs:subPropertyOf, works-For), r 1 = (Tom, rdf:type, Professor), r 2 = (department of computing, rdf:type, Department), r 3 = (Tom, headOf, department of computing), r 4 =(Tom,works-P ( { } P no world that corresponds to this truth value assignment. Suppose such a world W ,then r 4  X  W . This is a contradiction. The theory considered in this example has no satisfying interpretation and so is inconsistent. This section describes an algorithm us ed to check the consistency of a pRDFS theory ( H, R,  X  ). Inconsistency arises when a theory assigns a non-zero proba-bility value to a truth value assignment which assigns the false value to a triple t and assigns the true value to a set of other triples which, together with the schema, derives t .

Algorithm 1 shows an algorithm to check the consistency. The basic idea is to value. For each set of triples P , the algorithm checks whether the probability is non-zero, the theory is inconsistent. Otherwise, the theory is consistent. Algorithm 1. Check whether a given pRDFS theory ( H, R,  X  ) is consistent (return true) or not (return false).
The RDF specification [10] provides a se t of deduction rules with respect to the RDFS semantics. Specifically, Algorithm 1 considers the following rules to find all sets of triples each of which derives t . 1. ( a , rdfs:domain, x )( u , a , y ) ( u ,rdf:type, x ) rdfs2 2. ( a , rdfs:range, x )( u , a , v ) ( v ,rdf:type, x ) rdfs3 4. ( a , rdfs:subPropertyOf, b )( u , a , y ) ( u , b , y ) rdfs7 5. ( u , rdfs:subClassOf, x )( v ,rdf:type, u ) ( v ,rdf:type, x ) rdfs9 It ignores rules that handle the blank nodes, containers and datatypes. It first uses rules rdfs5 and rdfs11 to find transitive closures of rdfs:subClassOf and rdfs:subPropertyOf in Line 1. Then, it divides the triples t  X  R that can take the false value into two groups to process. Lines 2-35 handle triples with property rdf:type while Lines 36-40 handle triples the properties of which are not rdf:type. In both cases, backward chaining approach is used to find all sets of triples each of which derives t . The former uses combinations of rules rdfs2, rdfs3, rdfs7 and rdfs9 while the latter uses rule rdfs7.
 Example 4 (Cause of inconsistency). Consider the theory in Example 3. Algo-rithm 1 examines triples r 3 , r 4  X  R , which take the false value with the proba-r } derives r to be always true, we only need to check the probability that r 3 =Tand r 4 = the theory. This section describes the evaluatio n of a SPARQL query on a pRDFS theory. We first review the evaluation on an RDF data set D .Let V be the set of query Again, we ignore the handling of blank nodes. A simple graph pattern G is a set of triple patterns. Let var( G )  X  V be the set of variables in G .Asolution  X  is a function from V to ( U  X  I ). G (  X  ) denotes a set of triples obtained by replacing every variable v in G with  X  ( v ). In this paper, we restrict our discussion to a SPARQL query of the form:  X  X elect V s where G  X , where V s  X  var( G )isasetof selected variables and G is a simple graph pattern. The result of the query is a
A pRDFS theory can express the negation of a triple  X  t by specifying that t = F whereas an RDFS document cannot. To ask questions about the negated triples in a pRDFS theory, we introduce a way to express negated triples in the SPARQL query. For a triple t =( s , p , o ), the negation of t is expressed by adding a special symbol  X  before the property, that is,  X  t =( s ,  X  p , o ). The result of Algorithm 2. Find the result of a SPARQL query  X  X elect V s from G  X  X na pRDFS theory ( H, R,  X  ). Parameters and  X  are used to approximate probability. aqueryonapRDFStheoryisasetofpairs S = { (  X  | V s ,P (  X  | V s )) | G (  X  )  X  D  X  t ( t,  X  t  X  G (  X  )) } ,where P (  X  | D = H  X  R  X  X  X  t | t  X  R  X  P R ( { ( t, F ) } ) &gt; 0 } .

Algorithm 2 shows an algorithm to find the result. It first constructs a data set D , which consists of schema triples H , instance triples R and negated triples. Then, it searches for intermediate solutions  X  such that G (  X  ) is a subset of D and because the probabilities of such solutions are zero. The final solutions S include the restriction of  X   X  M to selected variables V s .
 The algorithm then finds the probability of each solution s  X  S , denoted by P ( s ). M s in Line 6 is a subset of M . The restriction of  X   X  M s to V s is the same as s .Let M s = {  X  1 ,..., X  m } .If m = 1, the exact probability P ( s )is computed as in Line 7, where P R is specified by  X  .If m&gt; 1, the calculation of P ( s ) is formulated as a disjunctive normal form (DNF) probability problem. F s =  X   X  M s t  X  G (  X  ) t is the DNF formula for solution s . It is with respect to boolean variables in  X   X  M truth value assignments for the boolean variables is defined by  X  , together with the assumption that all t  X  H are true. A truth valu e assignment satisfies F s if F s is true under the assignment. The DNF probability problem is to find the probability P ( F s ) that a truth value assignment randomly chosen satisfies F s . P ( s )equals P ( F s ). The computation of exact probability of this problem is very hard. Therefore, Algorithm 2 in Lines 11-21 uses the coverage algorithm [6], which is a polynomial time Monte-Carlo algorithm with respect to m .Thecov-erage algorithm is an ,  X  approximation algorithm, which computes an estimate  X  specifies the relative closeness of  X  P ( s )to P ( s ).
 Example 5 (Negated triple). This example demonstrates a use of negated triples in queries. The query  X  X elect ? x where { ( John, takesCourse, ? x ), ( Mary,  X  takesCourse, ? x ) }  X  asks what courses that John takes but Mary does not. The result is { (semanticWeb, 0.1) } .
 Example 6 (Query evaluation). Suppose the query  X  X elect ? x where { (? x , teacherOf, ? z ), ( ? y ,takesCourse,? z ) }  X  is made on the pRDFS theory ( H , R ,  X  ) in Example 1. The inputs to Algorithm 2 are the query, the theory, =  X  r semanticWeb) } ,  X  3 = { (? x , May), (? y , John), (? z , semanticWeb) } and  X  4 = { (? x , May), (? y ,Mary),(? z , semanticWeb) } . The selected variable V s is { ? x } , so the final solutions S are {{ (? x ,Tom) } , { (? x ,May) }} . For solution s = { (? x ,Tom) } , M s in Line 6 is {  X  1 ,  X  2 } and the DNF formula F s is ( r 4  X  r 8 )  X  ( r 4  X  r 9 ). F s has two conjunctive clauses, that is, m = 2. The probabilities of to approximate P ( s ). N = 56255.8. After the loop in Lines 14-20 is repeated
N times, C equals 33855 and  X  P ( s ) is computed as 0.3009 (The exact value is 0.3). We have ( { (? x ,Tom) } , 0.3009 ) as a member of the result R . Similarly, the approximate probability of solution s = { (? x ,May) } is computed as 0.2980. Hence, R = { ( { (? x ,Tom) } , 0.3009 ), ( { (? x ,May) } , 0.2980 ) } . This section studies the execution time pe rformance of checking the consistency of a pRDFS theory and answering queries on a pRDFS theory. The data set that we use is the Lehigh University Benchmark (LUBM) [4], which has a schema 2 for the university domain, and an instance data generator. The generator can output data sets of different sizes, and a university is a minimum unit of data generation. Note that the instance triples do not contain any blank nodes.
To generate the probabilistic knowledge, we randomly select four triples each time from the instance data and assume these four triples are statistically cor-related. We call them uncertain triples. We enumerate all combinations of truth value assignments for them. The probabilities of the combinations are randomly generated and then normalized such that their sum equals 1. The probabilistic knowledge is encoded in RDF tripl es using a specialized vocabulary 3 .
The experiments were carried out on a computer with an Intel Pentium pro-cessor E5200 and 8 GB memory. The software code was written in Java and used Jena [1], which is an RDF toolkit including an RDF/XML parser, reasoners and a SPARQL query engine. Each experiment was run for 5 times and the average execution time was taken. 6.1 Consistency This section examines how the execution time of checking the consistency of a pRDFS theory (Algorithm 1) scales with the data set size (the total number of schema and instance triples) and the number of uncertainties (the percentage of uncertain triples). Algorithm 1 is modified so that it does not stop when an inconsistency is found. It finds all causes of inconsistencies.

Two experiments were performed. In the first one, we varied the number of universities in the instance data from 1 to 15, and kept the percentage of uncer-tain triples at 5% of the total number of schema and instance triples. The result is shown in Fig. 1(a), which indicates t hat the execution time scales exponen-tially with the data set size. In the second experiment, we varied the percentage of uncertain triples from 5% to 20% and kept the number of universities in the instance data at 1. The result is shown in Fig. 1(b), which indicates that the execution time scales linearly with the number of uncertainties. 6.2 Query Evaluation This section examines how the executi on time of query answering on a pRDFS theory (Algorithm 2) scales with the dat a set size and the number of uncertain-ties. Parameters and  X  of Algorithm 2 are set to 0.1 and 0.9 respectively. 20 queries are randomly generated fo r each data set. We randomly select 3 connected instance triples to form the graph pattern of a query. The triples are connected in the way that at least one individual of each triple is the same as an individual of another triple. Then, we randomly select two elements from the triples, create a variable for each of th em, and replace all occurrences of each element with its corresponding variable. For the two variables, one of them is the selected variable while the o ther is the non-selected one.

Two experiments were performed. In the first one, we varied the number of universities from 1 to 15, and kept the percentage of uncertain triples at 5%. Fig. 2 shows both the total and query evaluation time. The total time was obtained by measuring all steps from loading the data set into the memory to query evaluation. Moreover, Fig. 2 shows both the mean and median of the time to answer 20 different queries because a few queries require much longer time than others to answer. Most of the query evaluation time of these few queries was spent on the computation of the probability of a very long DNF formula. The total time scales linearly with the data set size, but the query evaluation time does not depend on it. In the second experiment, we varied the percentage of uncertain triples from 5% to 20% and kept the number of universities at 1. Fig. 3 shows that the total time scales linearly with the number of uncertainties but the query evaluation time does not depend on it. There are attempts to model probabilistic knowledge in RDF/OWL [5,12]. Us-ing Bayesian networks [9] is another approach. A vocabulary is provided in [3] to represent probabilistic knowledge in RDF, which can be mapped to a Bayesian network to do inference. PR-O WL [2] provides a vocabulary to repre-sent probabilistic knowledge in OWL based on Multi-Entity Bayesian Networks (MEBN). MEBN is a first-order Bayesian logic that combines first-order logic with Bayesian networks.

OWL [8] has richer schema capabilities than RDFS. OWL DL is a sublan-guage of OWL. It has the maximum expressiveness without losing decidabil-ity of key inference problems. It is based on the expressive description logic SHOIN ( D ). A lot of work has been done to represent probabilistic knowledge in description logics. We choose to recall the expressive probabilistic description logic P-SHOIN ( D ) [7] because it is the most expressive in terms of the de-scription logic and probabilistic knowledge. P-SHOIN ( D ) uses the conditional constraint ( A | B )[ l , u ] to express probabilistic knowledge at both schema and instance levels, where A and B are class expressions that are free of probabilistic individuals. At the schema level, ( A | B )[ l , u ] is defeasible and means that the is associated with a probabilistic individual o . It is strict and means that the probability that o belongs to A given o belongs to B lies between l and u .Note that each probabilistic individual is associated with its own set of conditional constraints. Hence, P-SHOIN ( D ) cannot model statistical relationships among correlated statements involving different probabilistic individuals. In this paper, we introduce pRDFS to model statistical relationships among correlated instance triples in RDFS data sets. We define its syntax and semantics. A consistency checking algorithm is provided to identify truth value assignments that violate the RDFS semantics. Experimental study shows that the execution time scales linearly with the number of un certainties but exponentially with the data set size. Moreover, a query evaluation algorithm is provided to find answers to queries in SPARQL. Experimental study shows that the query evaluation time does not depend on the data set size and th e number of uncertainties. However, a few queries require much longer time than others to compute the probabilities of answers.
 Acknowledgements. The work described in this paper was partially supported by grants from the Research Grants Council of the Hong Kong Special Admin-istrative Region, China (PolyU 5174/07E, PolyU 5181/06E).

