 ORIGINAL PAPER Hideaki Goto Abstract Weanalyzesomespatialfrequency-basedfeatures used for text region detection in natural scene images, and redefine the DCT-based feature. We employ Fisher X  X  dis-criminant analysis to improve the DCT-based feature and to achieve higher accuracy. An unsupervised thresholding method for discriminating text and non-text regions is intro-duced and tested as well. Experimental results show that a wide high frequency band, covering some lower-middle fre-quency components, is generally more suitable for scene text detection despite the original definition of the DCT-based feature.
 Keywords Scene text  X  Text region detection  X  Discrete cosine transform  X  Fisher X  X  discriminant analysis 1 Introduction Various kinds of texture features for text region detection in scene images and in video images have been proposed so far [ 1 , 3  X  7 , 10 ]. Some features, particularly those based on the image X  X  spatial frequency, have been proved to be very use-ful [ 1 , 7 , 10 ]. Crandall etal. developed a feature based on the Discrete Cosine Transform (DCT) [ 1 ]. An advantage of the DCT-based method is that it can realize a fast text detection in the JPEG/MPEG compressed domain. Gllavata et al. pro-posed another feature based on the Wavelet Transform (WT) [ 3 ]. Interestingly, a discrepancy in the spatial frequency can be seen between the two features, as the former one uses the DCT coefficients of lower frequency, while the latter uses the Wavelet coefficients of higher frequency.

In the conventional work, the evaluations of the features for text detection have been made mainly through the evalu-ations of the final results of text region detection. However, comparisons and analyses of the features with respect to the features X  intrinsic goodness for text/background separation have not been studied enough. Moreover, no research has yet been made for finding a frequency band that is potentially good for text region detection. In this research note, we rede-fine the DCT-based feature by analyzing it in depth. In order to analyze and compare features for text region detection, we propose to use Fisher X  X  discriminant criterion [ 2 ], which has been used in many linear discriminant analyses. Experimen-tal results show that the discriminant analysis is very useful for optimizing the features.

Both easiness of handling the feature vectors/values and the classification process are also very important to realize a good text detection method. One of the drawbacks of the conventional method [ 1 ] is that a large number of training data are required. In this research note, we propose to use an unsupervised thresholding method well-known as Otsu X  X  binarization [ 9 ] to achieve high performance text detection without laborious parameter tuning.

This note is not aimed at presenting a new text detec-tion algorithm. Instead, we focus on the analyses and evalu-ations of the DCT-based feature. We intentionally omit any performance improvement/enhancement techniques such as Multi-Resolution Analysis (MRA) and overlapping blocks, in order to make the feature analyses as free as possible from text localization algorithms.

In Sect. 2 , we introduce DCT-based features using vari-ous frequency bands, redefine the DCT-based feature, and present an unsupervised thresholding method. In Sect. 3 ,an evaluation method for text detection features is proposed. We analyze and compare the spatial frequency-based features in detail in Sect. 4 . Section 5 concludes this note. 2 Text region detection using DCT-based features 2.1 Original DCT-based feature The original DCT-based feature for text region detection was proposed by Crandall et al. [ 1 ]. The feature value, also known as text energy (TE), is defined as the sum of the absolute val-ues of some DCT coefficients selected by a certain criterion. The input image is partitioned into 8  X  8-pixel blocks and the DCTisappliedtoeachblock.Theauthorsmanuallyclassified the blocks into text and background in advance, calculated the average absolute values of the DCT coefficients sepa-rately, sorted the values in descending order, and picked up the top 19 coefficients (except the DC component) to calcu-late the feature. Specifically, the triangle-shaped lower fre-quency band shown in Fig. 1 was used.

Zhong et al. [ 10 ] proposed another type of DCT-based fea-ture. They extracted two text energy values, one for detecting horizontal variances and another for vertical, by summing up the absolute values of some empirically selected coeffi-cients. Since the text energies are used separately during the text localization process, it makes feature analyses difficult, Therefore, we do not examine it in this note and focus on Crandall X  X  feature only. 2.2 DCT-based features using various frequency bands An intuitive and empirical idea commonly seen in technical papers is that  X  X igh spatial frequency components are use-ful in characterizing text-like textures. X  A simple question arose X  X hy are low frequency coefficients used in the origi-nal DCT-based feature? We probably need to seek the reasons for the difference in spatial frequency.
 The coefficient selection scheme used in the original DCT-based feature corresponds to choosing the coefficients thathavelargerbetween-classvariances.Ingeneral,however, within-class variances should be taken into account as well as between-class variances in order to obtain a good feature.
These observations above have motivated us to use a lin-ear discriminant analysis technique in the analyses of the DCT-based features as to be described in Sects. 3 and 4 .
To analyze the frequency dependency of the DCT-based features, we roughly partition the DCT coefficient matrix and define the middle frequency band (Middle) and the high frequency band (High) as shown in Fig. 1 in addition to the low frequency band (Low) used in the conventional method. We use the triangular band for Low instead of a square one to simulate the original feature. We have confirmed through experiments that the statistical characteristics are quite sim-ilar between the two shapes.

We use 16  X  16-pixel blocks as well, because the 8  X  8-pixel blocks used in [ 1 ] seem to be too small for recognizable Japanese characters. It is quite difficult even for humans to classify such a small block into text and non-text correctly by viewing the block image containing only a few partial character strokes. 2.3 Revised DCT-based feature and target characters We define a revised DCT-based feature for scene text detec-tion. The main difference from the original one is the fre-quency band to be used. The feature value (text energy) is defined as the sum of the absolute values of all the DCT coefficients except the low frequency square region of size d  X  d around the DC component. The details will be given in Sect. 4.2 .

Any text detection method based on this feature would be dependent to the image scale to some extent due to the block-based processing. We assume that the characters fit-ting in the size range from 0 . 5 B  X  0 . 5 B to 2 B  X  2 B should be detected using this text detection feature, where B is the block size, typically B = 16. We ignore smaller and largercharacters.Thecharactersshouldbevisibleinthegrey-converted images. The range of character stroke width will be discussed in Sect. 4.1 .

We basically do not make any other assumptions such as on edge sharpness, stroke color/texture, fonts used, and back-ground color/texture. Even if an image contains characters whose edges are severely blurred, they should be detected as long as humans can perceive them as characters. Although we make no assumption on the language, only Japanese and English texts are used in the experiments. 2.4 Unsupervised thresholding method using A thresholding process of the feature values is needed for discriminating text regions from non-text objects. In the conventional method [ 1 ], two parameters were manually tuned using a lot of training data as the authors had found a strong linear correlation between the image contrast and the optimum threshold of the feature value (text energy). The manual tuning is quite laborious. We call the method  X  X on-trast method. X 
In this research note, we propose to use Otsu X  X  binariza-tion method [ 9 ], which was designed to find the best thresh-old value using the discriminant analysis. None of the other researchers has ever verified the usefulness of the method combined with the DCT-based feature in scene text detec-tion as far as we know in the literature.

The procedure of the discriminant analysis-based thres-holding is as follows. 1. Calculate the feature value for each block. 2. Calculate the histogram of the feature values over the 3. Assign the label  X  X on-text X  to the blocks whose feature 3 Evaluation method for text detection features 3.1 Making ground truth data Ground truth (GT) data are needed for the evaluations of the feature and the text detection process. We manually classi-fied every image block into four classes to create the GT data. Figure 2 shows an example scene image and its GT data.
The criteria used in the manual classification process are as follows. 1. A block containing no character stroke at all should be 2. We ignore very small characters shorter than 6 pixels 3. We classify the characters taller than double of the block 4. A block containing only a portion (a few pixels) of char-5. The other blocks should be classified as  X  X ext blocks. X 
Figure 3 shows some examples of text blocks, non-text blocks, intermediate blocks, and large character blocks. We do not take into account the intermediate blocks and the large character blocks in the analysis of features.
 In our experiments, we used two sets of scene images. The first set, the OsakaF-set, is from the collection of scene images provided at the Osaka Prefecture University X  X  web-site. 1 The OsakaF-set consists of 12 scene images with mainly Japanese characters. We created GT data of these images at 16  X  16-pixel block size, and also made GT data at 8  X  8-pixel block size by shrinking the images. Some of the scene images are shown in Fig. 4 . The original color images are converted to grey-scale ones.
The second set, the ICDAR-set, is from the TrialTrain data used in the ICDAR 2003 Robust Reading Competition [ 8 ]. Large images were scaled down to fit into 720  X  480 pixels (or 480  X  720 pixels for portrait), since the current block-based text detection algorithm is not fully scale-inde-pendent. We manually created GT data for 258 images at 16  X  16-pixelblocksize.127imagesoutof258wereexcluded because these images contain characters too large for the block size or have no text. All the color images are grey-converted. Ultimately, the ICDAR-set consists of 131 scene images. 3.2 Evaluation of features using Fisher X  X  discriminant ratio A feature is thought to be good if two classes can be sep-arated easily by the feature and if the thresholding of the feature is easy. The ratio between the between-class variance
B and the within-class variance discriminant ratio (FDR for short hereinafter) [ 2 ]. FDR = where  X  i , M i ,and  X  2 i denotethenumberofblocks,meangrey level, and the variance, respectively, in the class i ( i In general, the greater the FDR is, the more easily the clas-ses can be separated. Using the FDR is expected to be very beneficial to the feature evaluation. The procedure of the evaluation is as follows. 1. Calculate the feature value for each block. 2. Classify every block into text or non-text using the GT 3. Calculate the FDR of the two classes over the entire 3.3 Evaluation of the text region detection To compare some features for text detection, we use Recall , Precision , and Score , which have been widely used in per-formance evaluations [ 1 ].
 Recall = Precision = Score = where  X  is a weight value. We use the typical value  X  = 0 in our work so that we evaluate Recall and Precision evenly. Correct_detects denotes the number of text blocks correctly classified as text, and Missed_detects denotes the number of text blocks incorrectly classified as non-text. False_alarms is the number of non-text blocks falsely classified as text. The GT data are used to calculate these values. 4 Experimental results and discussions 4.1 Frequency dependency of the DCT-based feature We first analyzed the frequency dependency of the DCT-based feature with 16  X  16-pixel blocks (DCT16) and the text detection performance Score using 12 test images from the OsakaF-set. Table 1 shows the FDRs and Score for each frequencyband.ThebestFDRamongLow,Middle,andHigh are shown in bold letters. The underline shows the value is the best among all five bands (HWide and All will be defined later). A strong correlation can be seen between the FDR and Score . This observation supports the validity of using FDR for feature analyses.

If we compare Score among Low, Middle, and High fre-quency bands, High band wins with only one image. The average FDR is the lowest for High, and the average Score is inferior to that of Middle. The highest frequency band alone does not seem so suitable for text detection, despite the pop-ular expectation.

Although the average FDR is the highest for Low fre-quency band, the Middle band gives better FDRs with 8 images out of 12 compared with the Low band. The aver-age Score of the Low band is critically inferior to the others. At this point, it seems the Middle frequency band is the best for text detection among these three bands.

Table 2 shows the average FDRs and Score with the 8  X  8-pixel block feature (DCT8). The text energy smoothing [ 1 ] has been enabled for this block size as it yields slightly bet-ter Score . None of the images has given the highest Score or FDR in Low frequency band, while 8 images has shown the highest Score in High.

Figure 5 shows the average FDR of each DCT coefficient over the 12 images. The FDRs show a clear descent in the low frequency region. The same tendency can be found with the 16  X  16-pixel block feature. These observations suggest that the middle and the high frequency regions are generally more suitable for scene text detection than the low frequency was expected to be in [ 1 ].

On the other hand, some lower frequency components seem to be still useful with some types of images. The images 01, 09, 10, and 11 give very high FDRs and Score in Low fre-quencybandcomparedwithMiddleandHigh.Wehavefound that these images consist mainly of characters with strokes wider than about 2-pixels by visual inspection (Fig. 6 ). The other images marked with an asterisk (*) in Table 1 have a common characteristic in that they contain thin charac-ter strokes ( &lt; 1 . 5 pixels) or fine, complex textures such as trees.

To investigate the frequency dependency further with a much larger dataset, we have carried out some experiments using the ICDAR-set. The results are shown in Table 3 .
This dataset shows higher performances in the Low fre-quency band in comparison with those of the High band, unlike the average performances of the OsakaF-set. The rea-son may be that the percentage of wide strokes in the ICDAR-set is much higher than that of the OsakaF-set. Many of the character strokes are 3-or 4-pixel wide. To verify this reasoning, we have tested a half-resolution version of the ICDAR-set with 8  X  8-pixel blocks. The character stroke width in pixels is reduced to half in this dataset. Note that each block covers exactly the same subimage as in 16  X  16-pixel block dataset and the only difference is the image res-olution. The FDRs and Score are shown in the bottommost rows in Table 2 . The performance in the Low band deterio-rates, while it improves in the High band. This result supports our reasoning.

Putting all the results together, there is actually a depen-dency between the optimum frequency and the image con-tent, which is probably related to the width of character strokes. Using the Low band alone does not seem to be a good choice for text detection. 4.2 Tuning the revised DCT-based feature UsingtheMiddlefrequencybandmaybethebestchoice,since the images with complex backgrounds are more general, and since a lot of thin strokes can be seen in many scene images. Especially, any devices dealing with Japanese/Chinese char-actersmusthaveahighperformancewiththinstrokes,bacause thinstrokesaremorecommoninJapanese/Chinesecharacters thathavemorestrokesthanLatincharacters.Atthesametime, we probably need to keep the text detection performance high enough even with images containing wide character strokes. Otherwise, the text detection algorithm would become picky and miss a lot of wide strokes.

A straightforward way is to sum up all the DCT coeffi-cientsexcepttheDCcomponenttocomputethefeaturevalue. Let the word  X  X ll X  represent this case. Unfortunately, Score drops significantly with this feature as shown in Tables 1 and 2 . It seems the coefficients of very low frequencies are harmful.

An alternative idea is to use a wide frequency band that covers some low frequency components as well as high fre-quency ones. We have defined the revised DCT-based fea-ture  X  X Wide X  to test this idea. The feature value is defined as the sum of the absolute values of the DCT coefficients in High_wide frequency band (HWide) shown in Fig. 7 .The low frequency square region of size d  X  d around the DC component is excluded.
 The FDRs and Score at d = 4 are shown in Table 1 . Although the average Score is a little worse than that of the Middle feature, the average FDR is the best using the HWide feature. The average Score is still much higher than that of the Low feature.

Figure 8 shows the average Score for various parameter values of d . Score has a peak around d = 6usingtheOsa-kaF-set. We have chosen d = 4 as the optimum value because we wanted to make the text detection algorithm work well with wide character strokes commonly found with printed Latin characters.

When the ICDAR-set is used, Score of HWide has its peak around d = 3. This means the predetermined param-eter d = 4 is near optimum. The HWide feature yields the best Score as shown in Table 3 . If we compare Score between d Low and HWide, the HWide wins with 86 images out of 131. Score drops to 43.6% if we set d = 6.

The spatial frequency is likely to be related to the char-acter stroke width. The DCT coefficients at the rightmost column correspond to the horizontal cosine base function of the highest frequency. The half wavelength of the function is about 1-pixel (Fig. 7 ). Thus, these coefficients are expected to be suitable for discriminating thin character strokes from the background images. In the same way, the coefficients at the center of the matrix are expected to work well with 2-pixel wide character strokes. If we set d = 4, the longest half wavelength becomes 4-pixels. If a character stroke is wider than 4-pixel, it is very likely to belong to a character too large for the block size (see Sect. 3.1 ). We can ignore such a stroke, since the current block-based text detection algorithm is not fully scale-independent. 4.3 Performance of the discriminant analysis-based We compared the performances between the discriminant analysis-based thresholding proposed in Sect. 2.4 and the conventional contrast method [ 1 ]. Table 4 shows the results using the ICDAR-set. Although some tendency differences can be seen in Recall and Precision , the proposed method shows better Score . The image contrast varies from 127 to 256 in this dataset. In addition, the discriminant analysis-based thresholding is superior with respect to its being free from supervised learning. % 4.4 Performance comparison of various frequency features We compare text detection performances using various fre-quency features; the DCT-based features at 8  X  8-pixel and 16  X  16-pixel block sizes, and the WT-based feature pro-posed in [ 3 ]at16  X  16-pixel block size. Figure 9 shows aver-age Recall , average Precision , and average Score of these features using the ICDAR-set. For WT-based feature, Fig. 9 shows only the results of the one dimensional feature which is the sum of the standard deviations of WT coefficients in LH, HL, and HH subbands. The 5/3 filter bank has been used [ 3 ].

Whichever the block size is, the High_wide band (HWide) gives better Score compared with the Low band using the DCT-based features. The feature DCT16_All, which is the sum of all DCT coefficients except DC component, does not yield good Score . The revised DCT-based feature proposed in this note, i.e., the DCT-based feature with HWide band at 16  X  16-pixel block size, is the best with respect to the average Score .

A strictly fair comparison between 8  X  8-pixel and 16  X  16-pixel block sizes is impossible because the input image and the GT data are both different. In our experiment, the DCT-feature with 8  X  8-pixel blocks has shown lower Score . The results are presented here for showing the advantage of HWide band rather than for comparison between the block sizes. A further analysis on the optimization of the block size, probably with an adaptive technique, should be included in the future work.
The lower Recall rate of the WT-based feature might be due to low filter responses to wide strokes. Developing a new WT-based feature incorporating lower frequency com-ponents is out of the scope of this note, although it would be an interesting topic. 5 Conclusions We have proposed some analysis and evaluation techniques using Fisher X  X  discriminant criterion for designing better fea-tures for text detection applications. We have analyzed the frequency dependency of DCT-based text detection features in depth to find the best frequency band.

The experimental results have confirmed that the higher frequency region including the middle one is more suitable for scene text detection than the low frequency band alone that was expected to be useful in the conventional work. This finding gives a rational explanation on the discrepancy in the spatial frequency between some proposed features, and also supports the intuitive and empirical idea in some papers say-ing  X  X igher frequency components are useful for text detec-tion. X 
Another interesting finding is that we should take into account lower-middle frequency components as well as the higher ones to gain high accuracy for wide range of character stroke width.

We have redefined the DCT-based feature for text region detection and proposed to use Otsu X  X  method for text/non-text discrimination. The revised DCT-based feature outperforms the features using the other frequency bands, and also the WT-based feature.

Our future work includes further optimization of the DCT coefficient selection, further analyses of the WT-based fea-ture, and comparisons of some other text detection features not limited to frequency-based ones.
 References
