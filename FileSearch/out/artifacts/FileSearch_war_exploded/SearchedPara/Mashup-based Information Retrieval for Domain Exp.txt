 In this paper, we tackle the problem of helping domain ex-perts to construct, parameterize and deploy mashups of data and code. We view a mashup as a data processing flow, that describes how data is obtained from one or more sources, processed by one or more components, and finally sent to one or more sinks. Our approach allows specifying patterns of flows, in a language called Cascade. The patterns cover dif-ferent possible variations of the flows, including variations in the structure of the flow, the components in the flow and the possible parameterizations of these components. We present a tool that makes use of this knowledge of flow patterns and associated metadata to allow domain experts to explore the space of possible flows described in the pattern. The tool uses an AI planning approach to automatically build a flow, belonging to the flow pattern, from a high-level goal, speci-fied as a set of tags. We describe examples from the financial services domain to show the use of flow patterns in allow-ing domain experts to construct a large variety of mashups rapidly.
 Categories and Subject Descriptors: H.5.2 [Informa-tion Interfaces and Presentation]: User Interfaces,D.2.2 [Soft-ware Engineering]: Design Tools and Techniques General Terms: Design, Human Factors.
 Keywords: Patterns, Composition, Flows, Planning, Tags.
Data mashups, where data from one or more sources are combined into a single tool or visualization, have become increasingly popular over the past few years. In addition, there are a number of tools that support the building of data-plus-code mashups, where data is obtained from one or more sources and further processed by one or more compo-nents. Examples of such tools are Yahoo Pipes [22], Mi-crosoft Popfly [12] and IBM Mashup Center [7]. We view a data-plus-code mashup as a data processing flow, described as a graph of data sources and black-box processing com-ponents. We take a general view of such flows, where the data can come from any kind of source (not just web-based sources) and can be processed by an extensible set of com-ponents. In fact, data processing flows appear in various other component based systems, such as Event-Driven Sys-tems, Stream Processing Systems, Service-oriented Systems, Extract-Transform-Load systems and the Grid.

Visual composition tools like Yahoo Pipes, Microsoft Popfly and IBM Mashup Center have become fairly popular among casual programmers, with hundreds of thousands of flows having been created on them already. However, such end-user driven creation of data-plus-code mashups is less com-mon among domain experts or analysts. There are a few rea-sons for this. Firstly, even though visual programming envi-ronments like Yahoo Pipes makes data-plus-code mashups more approachable for non-programmers, it still requires careful manual assembly of the flows by the end user. These end-users may not be aware of composition constraints of different components, and may also not be aware of the best practices in creating flows for their problems. Secondly, vi-sual programming environments become increasingly diffi-cult to use as the number of available components increases and/or the size of the composed flows increases. Finally, most visual programming environments just support a fixed set of components. They do not work very well when the set of components is extensible and evolves with time.
Hence, in a number of domains (such as financial services, manufacturing, security, etc.), domain experts are reliant on an IT development team to support them in different data analysis tasks. The IT team may create a set of flows for use by the experts. However, these flows are typically rigid in structure. Hence, if the expert wants to change the structure of the flow or parameterize it differently, she might actually have to change the underlying flow script in the language supported by the system. This may not be practical for most domain experts. While graphical user interfaces may sometimes allow experts to change the flow, they do not scale well with increasing numbers of components and increasing sizes of the flows. Hence, most often the domain experts must refer back to the developer in order to change the flows to meet new needs.

This rigidity is a big problem when the experts need to respond rapidly to a certain situation and there is no pre-built mashup flow that meets their current needs. Such ap-plications are often called X  X ituational applications X  X 2], since they need to be built by end-users to address a particular situation, problem, or challenge.

In this paper, we propose an approach to simplify the con-struction, parameterization and deployment of data-plus-code mashups by end-users, especially domain experts. We make use of the observation that in many domains, the set of useful flows for end-users (domain experts) often follow cer-tain patterns. Hence, in our approach, flow developers can specify not just independent flows, but patterns of flows . A flow pattern describes a space of possible flows that are structurally similar and perform similar tasks. Flow pat-terns are similar to regular expressions, in the sense that just as regular expressions define a set of satisfying strings, a pattern defines a set of satisfying flows. The patterns cap-ture the different points of variability in a flow, including 1) the space of possible data sources that can be accessed, 2) the space of possible operations that can be performed on the data, 3) the space of possible sinks or visualizations of the result data, and 4) the space of possible parameters specifiable by the end-user.
 Different platforms have their own flow languages, e.g. BPEL for service-oriented systems, SPADE [3], used in IBM X  X  System S Stream Processing Platform [6], GSFL[10] used in the Grid, etc. In this paper, we present Cascade, our lan-guage for specifying patterns of flows. Cascade is platform independent, i.e. it can be used to describe flows in any platform. It allows components to be described recursively, where a component is either a primitive component or a com-posite component, which internally defines a flow of com-ponents. A primitive component can embed code snippets from any platform-specific flow-based language (like BPEL, SPADE, etc). Some of the other key features of Cascade are an inheritance model for components, a number of ways for parameterizing components and the ability to define differ-ent structural variations for flows.

We also present a mechanism for end-users (domain ex-perts) to explore the set of flows encapsulated within a flow pattern. For this, we make use of a tool called MARIO [1], which provides a tag-based, faceted navigation user interface where users can specify their mashup needs (or goals) as a set of tags. MARIO then returns all satisfying flows to the end-user, ranked according to a pre-defined measure of cost. The composed flows can then be translated into a flow-script in a target platform (such as BPEL or SPADE), using the code snippets embedded within the primitive components. MARIO uses an AI planner for composing the flows dynam-ically given end-user goals. In order to compose the flows, the planner needs descriptions of the inputs and outputs of different components, specified as sets of tags. These input-output descriptions are generated from flow pattern definitions in Cascade.

Patterns provide several advantages over free-form, bottom-up composition that we have presented in previous work [1]. They offer a top-down, structured approach to defining al-lowable flows rather than relying on independent descrip-tions of individual components. In this way, they help re-strict the search space of the planner to a smaller set of useful flows. They also help capture reusable design patterns for information processing in a certain domain.

In summary, the key contributions of the paper are a model and a language for flow pattern definitions. The use of flow patterns requires a little extra effort from the flow de-veloper to identify possible variations and parameterizations of the flow. In addition, we describe our tool for processing pattern definitions, that makes available a large number of possible flows for the domain expert. We present examples from a case study in the financial services domain to demon-strate the use of these flow patterns in giving end-users more flexibility and power in creating mashups.

The paper is structured as follows. In Section 2, we pro-vide an overview of our approach for creating and using pat-terns. Sections 3 and 4 describe the model of components and flows, and of patterns. In Section 5, we describe how patterns are compiled. In Section 6, we show how end-users can select a suitable flow among all the flows available in a pattern and then parameterize it. In Section 7, we provide some performance results from a financial services domain. Sections 8 and 9 describe related work and conclusions.
Figure 1 shows an example flow in the financial services domain. This flow gets TAQ (Trade and Quote) data from the NYSE, which describes data on trades and quotes of different stocks. The flow then filters the trades based on a set of tickers, calculates the VWAP (Volume Weighted Asset Price) of the stocks, and then a bargain index of these stocks by comparing the trade data with the quote data of the stocks. The bargain index, which is a measure of how good a certain quote on a stock is compared to previous trades on the stock, is then visualized on a graph. Figure 1: Example flow in financial services domain,
The above flow may be run by financial experts (like traders) on a real-time stream processing platform, such as System S [6] or StreamBase [19]. The flow may be written in a stream processing language like SPADE [3], developed by a team of developers supporting the financial expert. While the flow is useful in its current form, it is not possible for the expert to modify the flow, in response to changed circum-stances in the financial world. For example, if he wanted to apply a different algorithm for calculating the bargain index or apply the analysis on data from a different source, like archived trade and quote data, it is difficult for the expert to do this without help from the developer.

In this paper, we propose an approach to support the end-user in modifying and configuring the flow. In our approach, the developer specifies flow patterns, which describe different degrees of freedom or different possible variations of a flow. The domain expert can then pick one among the different variations of the flow depending on the current requirements.
For example, Figure 2 shows an example pattern that de-scribes possible variations of the flow in Figure 1. In this pattern definition, the data can be obtained from either a TAQ File Source or a TAQ Real-time Source, the trades and quotes can be filtered by either a set of tickers or by an in-dustry, and the VWAP and the Bargain Index calculations can be performed by a variety of components (which inherit from an abstract Calculate VWAP component and from an ab-stract Calculate Bargain Index component respectively). The final results can either visualized in some manner, or can be streamed out on a TCP port. The filter components are optional (indicated by the  X ? X  in the figure), and if they do appear, they can be parameterized by a ticker or an industry parameter, specifiable by the end-user.
 Figure 2: Example flow pattern showing different pos-
A single flow pattern may define a large number of ac-tual flows. In this flow pattern, TAQ File Source, TAQ Real Time Source, Calculate VWAP, Calculate Bargain Index, VizSink and TCPSink are all abstract components that have multiple descendant concrete components. Abstract compo-nents can be replaced by any of their concrete descendants in the flow. As an example, let us assume there are 5 dif-ferent descendants of each of these components. Then, the number of possible flows in this flow pattern (not includ-ing different parameterizations of the filter components) is (5 + 5)  X  3  X  3  X  5  X  5  X  (5 + 5), or 22500 flows.
A key component in our approach is MARIO (Mashup Au-tomation with Runtime Invocation and Orchestration) [17], which is a AI-planning based tool that automates composi-tion of mashups from primitive components. It supports an iterative goal-refinement process for end-users to select their goals (described in Section 6).

Figure 3 describes the overall process of developing and using patterns. This process starts with a single flow that a developer may want to generalize into a pattern. The generalization process involves identifying different possible variations of the flow, and annotating different components with tags. The pattern definition is compiled by a Pattern Compiler to produce component descriptions with tag-based input-output constraints. These constraints ensure that the components can only be composed based on the defined pat-terns. The MARIO planner can then use these component descriptions to generate a web interface where end users can submit goals. These goals get automatically planned into flows. The user can then specify any parameters the flow requires, and MARIO then takes care of deploying the com-posed and parameterized flows on the available platforms(s).
Components can have zero or more input ports and zero or more output ports. In addition, components can be instan-tiated or configured with parameter values that influence the way they behave. We treat a component as a black-box, where the only things we know about the component are its inputs, outputs and parameters. For example, the Calculate VWAP Based on Number of Trades component in Fig-ure 1 calculates a volume weighted average price of a stock, where the averaging is done over a configurable number of trades. It has one input port, where it gets trade data, one configuration parameter, the number of trades for doing the average, and one output port, which is the VWAP (volume weighted asset price).

A flow is a directed acyclic graph of components, where the vertices are components and the edges are data links between the component input and output ports. The key requirement in a flow is that all directed edges (data links from source output ports to target input ports) are valid, i.e. the data produced at the source output port is semantically and syntactically compatible with the data required at the target input port.

We have a fairly general notion of data links. In different platforms, the data links may be implemented in different manners. For example, in web-based mashup systems like Yahoo Pipes, the links are RSS feeds. In stream processing and event-driven systems, the data links are data or event streams. In extract-transform-load systems, the links are tables. In service-based systems, the links may be messages in a binary or XML format.

Formally, a flow is a directed acyclic graph, G ( V , E ). Each vertex v  X  X  represents the invocation of a component. Each the j  X  X h output port of u to the k  X  X h input port of v .
Flow patterns allow developers to generalize existing flows so as to capture all the possible variations the flow can take and all possible parameterizations of the flow. There are five key elements in the description of Flow Patterns: 1. Tagging Model for Components 2. Inheritance model for components 3. Recursive, Hierarchical nature of components 4. Parameterizations of components 5. Structural Variations of flows
In this section, we describe the different aspects of pat-terns. We also provide a formal description as well as exam-ple code snippets from Cascade, our language for describing patterns.
Developers can annotate components with tags (or key-words). More specifically, they can annotate the output ports of components with tags to describe the semantic and syntactic properties of the data produced by these output ports. Figure 4 shows some examples of component descrip-tions. For example, the output of the Calculate P/E Ratio component is associated with one tag, P/E Ratio .
In addition, output ports can also be annotated with X  X egated X  tags, which are represented with a preceding tilde ( X  ~  X ). This means that the data produced by this output port will not be annotated by this tag. This feature is particularly use-ful in the case of components that perform operations that result in certain semantic properties of the input not appear-ing on the output. Examples of such components are filters, anonymizers or aggregators that can mask or remove some of the properties of the incoming data.

Formally, a component, x , can have zero or more named output ports, with the names { O i x } , i = 1 , . . . n . Each output port is associated with a description, d ( O i x ). Let T be the set of all available tags. Let ~ T represent the set containing the negations of these tags. Then, d ( O i x )  X  ( T  X  ~ T ).
The tags that we use to annotate output ports can be de-scribed as  X  X ticky tags X . This is because if any output port Figure 4: Example components with tags describing is annotated by a tag, then all downstream data links in a flow are also annotated by this tag, unless another compo-nent explicitly removes this tag. Figure 5 shows an example flow showing the tags that annotate different output data links of components. The figure shows how each component adds or removes tags on its output data link. For example, consider the Filter Trade By Tickers component. It adds three tags, FilteredTrade, ByTickers, SomeCompanies , and removes one tag, AllCompanies to the tags it receives on its input link.
The tags on any data link in a flow depend on all the com-ponents that appear before (or  X  X pstream X ) of the data link in the flow. More specifically, it depends on all  X  X pstream X  output ports of these components.
In Cascade, a component can be invoked to transform input data links to output data links.

Each component definition has a head and a body. The head lists input and output ports and parameters of the component, and any metadata. The body depends on the kind of component. There are three kinds of components in Cascade: 1. An Abstract component , which has no body defined. 2. A Composite Component is internally made up of a flow of other components. The component body describes the flow graph. 3. A Primitive Component has a body, which can embed fragments of code from any other flow-based language (like SPADE or BPEL).

The head of a component definition includes the compo-nent name and lists its ports and parameters. The metadata is enclosed within /#* and *#/ . An example component description is shown below: /#* @type  X  X  X pade X  X  @title  X  X  X ample X  X  @tags K tag1 tag2 @tags L tag3 *#/ component M (output K, L; input G, H) { &lt;component body&gt; }
The component M has two output ports, K and L , and two input ports, G and H . It has two parameters $P, $Q . The metadata indicates the type of the component (en-closed within quotes), the title (a short natural language sentence enclosed within quotes), and tags on each of the output ports. For example, the tags on port K are tag1 and tag2 , and the tag on port L is tag3 .

In a Primitive Component, the native flow-based language code is embedded within a X /$ X  X nd X $/ X . Parameters within the code are enclosed within @ X  X . Also, any names of input or output links must be enclosed within @ X  X . The reason for encoding the names of parameters and input and output ports is so that these names can be replaced by parameter strings or newly generated input and output data link names in a composed flow. Hence, the Cascade compiler does not need to know about the grammar of the embedded code; it only needs to know certain key strings in the embedded code such as any references to input and output ports, and parameters.

The code snippet below shows an example of a primi-tive component that embeds code in the SPADE language, which is used for describing flows in the System S stream processing platform. These SPADE code snippets are used in translating a composed flow containing these components into a SPADE script that can be deployed in System S. /#* @type "spade" @title "Filter Trade By Industry" @tags TradeFilter Trade FilteredTrade ByIndustry *#/ component FilterTradeByIndustry //embedding SPADE code snippet /$ stream @TradeFilter@ (schemaof(@TradeQuote@)) $/ }
The flow pattern model support a single inheritance model, where a component can inherit from another component. The key rules of inheritance are: 1. The inherited component has the same signature as the 2. If the inherited component defines a body, then this 3. The inherited component can define tags on the inputs
Figure 6 shows an example of how the tags of children components are generated based on inheritance.
A component is defined, recursively, as being one of the following:
Both primitive and composite components have an ex-ternal interface, that can be described as sets of input and output ports, and parameters.

A composite is declared with a graph clause in the com-ponent body. The graph clause of a composite describes a data flow subgraph, which can then be expanded in different contexts when the composite is invoked. Here is an example: component M (output K, L; input G, H) { graph } The above example describes a flow graph for composite . This flow graph contains invocations of other components O,P, Q, R . We use the term  X  X tream X  to refer to data links in general. The term  X  X tream X  came about since the first use of Cascade was in a stream processing environment, where all data links are streams. Figure 7 shows the component grahically.
Apart from input and output ports, the external inter-face of a component (primitive or composite) can also have parameters. In any invocation of a component within a com-posite, the values of the parameters to the component must be supplied. There are 3 different ways in which the values of the parameters can be supplied: 1. Composite hard-coded value . The value of a pa-2. User Specified value . The invoking composite can 3. Tagged value . The parameter value may be associ-
Flow patterns allow capturing variations in the structure (or topology) of a flow. There are three kinds of structural variations: 1. Enumerations. In a flow, each vertex represents the invocation of a component (with certain input data links and parameter values) to produce output data links. In a flow pattern, each vertex can specify an enumeration of pos-sible component invocations. The only constraint is that all the possible component invocations must produce the same number and format of output data links. Enumerations are specified by listing the different possible component invoca-tions and separating them by  X  |  X . As an example, in the code fragment below, the TradeQuote data link is produced by either invoking the TAQFileSource component with a file-NameParam obtained from the end user or by invoking the TAQRealTimeSource component with the ipaddress parameter obtained from the end user. stream TradeQuote = TAQFileSource() {param fileName: UserParam("TAQ Filename","");} {param ipaddress: 2. Optional components. In a flow pattern, a vertex can be specified as optional. This means that it may or may not appear in an actual flow. If the vertex does not appear in the flow, then it is as if each incoming edge to the vertex is merged with an outgoing edge. (All edges are ordered). The only constraint is that each of the possible components invoked in the vertex must have the same number and format of input ports and output ports.
 A filter component is a good example of this. For instance, FilterTradeByTickers is a component that receives trade data and only outputs trade data for tickers that belong to a user-defined set (e.g., IBM, MSFT). Note that for this com-ponent, the input and output data have the same format, and the component has only one input and one output port. As a result, we could simply remove the FilterQuoteByTickers altogether from a flow and still have input/output compat-ibility between its predecessors and successors in the flow.
Optionals are specified by adding a  X  ?  X  to the set of out-put data links produced by the optional component. As an example, in the code fragment below, the TradeFilter data link may be produced by either invoking the FilterTradeByT-ickers component with the input data link, TradeQuote , or by not invoking the component at all, which means that the TradeFilter data link is the same as the TradeQuote data link. stream TradeFilter? = 3. Use of high-level components. In a flow pattern, a component invoked in a vertex can be replaced by any of its descendants. This allows the use of high-level or abstract components in the flow pattern definition.
 For example, the code fragment below, shows the Bargain-Index stream produced by invoking the BIComp component with two input streams to its two input ports. BIComp is de-clared as an abstract component and has two concrete chil-dren. So, in effect, this means that the BargainIndex stream may be produced by either invoking the BIComp Simple com-ponent or the BIComp Complex component. stream BargainIndex = BIComp(Vwap; QuoteFilter)
A Cascade program consists of a set of component defi-nitions, possibly spread across multiple files. The set of all files (or directories) to find component definitions is speci-fiable in a configuration file. A main component is used to define the top-level component.

In summary, a flow pattern is described as a directed acyclic graph, G ( V , E ). Each vertex, v  X  X  , can be one or more of the following : 1. The invocation of a primitive component 2. The invocation of a composite component, which is 3. The optional invocation of a component 4. The invocation of one of an enumeration of compo-5. The invocation of a component with descendants 6. The invocation of a component with parameter values,
Note that an enumeration can be used to describe a com-ponent with concrete descendants, by enumerating all the descendants in the flow pattern. The only difference is that inheritance adds a layer of indirection; hence, it is possible to add a new descendant to a component and have new flows be available without changing other composite definitions.
The main aim of compiling the pattern language is to al-low users to explore the space of possible flows and param-eterizations of the flows described in the pattern. For this purpose, we make use of the MARIO tool[1] for composing flows from descriptions of primitive components using tag-based goals expressed by the end-user. The MARIO tool includes a planner for composing flows and a deployer for deploying composed flows on backend platform(s).

The compilation of flow patterns results in the generation of a number of MARIO component descriptions. A MARIO component description has tag-based input and output con-straints. Some of the tags in a MARIO component descrip-tion are those specified by the developer in annotating com-ponents. Other tags in a MARIO component description are generated by the Cascade compiler and are used to encode composition constraints between different components, so as to ensure that the components are only composed into flows as specified in the pattern.

The MARIO planner can determine if the data link pro-duced from the output port of one component can be fed into the input port of another component. It does this by checking if all the tags on the input port appear in the data link. At a high level, the planner works by checking if a set of links available in the current state can be used to construct an input to a component, and if so, it generates a new data link corresponding to the output. It performs this process recursively and keeps generating new links un-til it produces one that matches the goal, or until no new unique links can be produced. It incorporates a number of techniques to optimize the search process such as grouping together similar components, maintaining an index of com-patible components and eliminating some components that don X  X  help in reaching the goal [16]. As shown in [16], it is more scalable than other classical planners in composing flows in data-processing domains.
 We briefly outline the pattern compilation process. The Cascade Pattern Compiler generates tag-based input and output constraints for components based on where they ap-pear in a pattern. Each appearance of a component in a pattern results in the generation of a separate MARIO com-ponent description with its own set of input and output tag-based constraints. Each link in the flow pattern is also asso-ciated with a unique tag. The output port of all components that can produce this link is annotated by this unique tag, and all input ports that this link can be connected to also has the same unique tag. This ensures that components are connected only according to the pattern. For each compo-nent with descendants, additional MARIO components are generated corresponding to each concrete descendant. For each optional component, an additional no-op MARIO com-ponent is generated that performs no operation and that has the same number of input and output ports. Note that no-op components are only used for planning purposes; they do not correspond to any components actually deployed on the underlying platform.
One of the key advantages of our approach is that it is possible for domain experts to rapidly come up with desired flows by submitting high-level goals. We describe a user in-terface that allows end-users (who may be domain experts) to submit a goal, consisting of a set of tags, to the planner [17], which then composes a flow satisfying the goal. Note that tags can correspond to names of patterns (composites); so, end-user goals can include the pattern(s) they are inter-ested in.

In order to simplify the construction of the goal for the user, we use a faceted navigation interface. The set of tags that are available for inclusion within the goal are displayed in a tag cloud that is partitioned into a number of facets. Facets may correspond to the patterns available, different aspects of the pattern, various possible parameterizations of components in the pattern, etc.

An example of such a faceted tag cloud is shown in Figure 8. These tags appear in the faceted tag cloud because they are part of goals that can be satisfied by at least one compos-able flow built from a library of available components. That is, some flow is capable of satisfying the goal FileSource , an-other is capable of satisfying ByIndustry , etc. Note that some tags are larger, indicating that they are relevant to a larger number of user-specified goals, i.e. they appear in a larger number of composable flows.
 Figure 8: Example of faceted tag cloud for Bargain Index computation, with the facets on the left and the tags in each of the facets shown on the right.
For example, one possible goal refinement path is to first select a high-level source tag from the Sources facet (such as FileSource ), followed by a more specific file source type like (such as CSV ). Next, the user can pick other tags corre-sponding to different flow functionalities like LinearIndex (for the bargain index calculation), and FileSink , for sending the results to a file. Figure 9 shows the user interface when the current goal is FileSource, CSV, LinearIndex, FileSink . In this case, the flow depicted was selected by our planner as the  X Sbest  X  T assembly of known components to satisfy the goal. The notion of  X Sbest  X  T is based on minimizing a cost metric, where each component is associated with a cost. By default, all the components have the same cost; this results in the shortest flows being shown to the user.

The flow that is shown does not filter the trade and quote source data. Hence the description of the flow at the bottom right contains a couple of no-op components, which were in-serted by the planner in lieu of the actual filter components. Remember that the filter components were specified as op-tional in the flow pattern. Hence, the user can refine the current goal further by picking a tag from the Filters facet like ByIndustry or ByMonitoredTickers . This will cause the no-op components to be replaced by actual filters.

The tag cloud is built by the planner by generating all possible flows for the current goal, and then aggregating the tags corresponding to the data links produced by these flows. One of the key features of our planner is that it can perform this complete generation of all satisfying flows very efficiently.

As the user selects the tags in any order the selected tags are added to the goal. The selection of these tags succes-sively refines the goal. Each time the user selects a tag, the planner generates all possible flows that can satisfy the cur-rent goal. In addition, it computes a new tag cloud that contains only those tags that can be added to the current goal and still be satisfiable. For example, asking merely for FileSource could result in the assembly of a large number of flows (that process data in different formats, route data to different sets of services, log different artifacts, etc.). The user can then select a new tag from the subsequent tag cloud to refine the goal. This iterative goal refinement makes it easy for end-users to arrive at the desired flow(s) quickly. In addition, the process only allows user to select goals for which flows exist, hence, they cannot submit goals with in-compatible tags. Another key advantage of the faceted, tag cloud based interface is that it exposes a variety of flow building and parameterization options that the user may not have been aware of. Hence it places more power in the hands of the user.

The value of the parameter may be obtained from end-users in two ways -they can either directly specify the value of the parameter using an appropriate UI widget like a textbox, or they can pick a tag (or a set of tags) in their goal which may be associated with a pre-specified parameter value. For example, in the current example, picking the tag Finance would result in a Filter By Industry component placed in the flow, with the industry parameter value set of  X  X i-nance X . Picking the ByMonitoredTickers tag, would result in a Filter By Tickers component placed in the flow, and also a textbox in the webpage, where the user can enter a set of tickers to monitor.

Once the user is satisfied with a flow composed by MARIO and has supplied any necessary parameters, the flow can be deployed on a backend platform. Before this can happen, the composed flow is first translated into a script in the platform-specific language. For example, this script may be SPADE, if the platform is System S. For each possible supported platform, MARIO has a platform-specific plugin which converts a flow into the platform-specific language. This plugin can make use of the code snippets that are em-bedded in the primitive component definitions.
We have used the pattern-based composition approach to aid domain experts in different areas including financial ser-vices, weather analysis, and manufacturing. In each of these areas, a team of developers and software architects specified flow patterns in Cascade using an Eclipse based IDE. The generated web interface was then made available to the end-users (domain experts). The process of specifying the pat-terns often involved communication between the developers and the domain experts, particularly in coming up with a set of descriptive tags. Most our current deployments are used for composing stream processing flows that can be deployed on systems such as System S [6].

To give an idea of the performance characteristics of the pattern-based composition approach, we use a financial ser-vices example, which includes the Bargain Index flows. This example had 87 components defined (primitive and compos-ite). All primitive components embedded scripts in SPADE. Table 1 presents some example goals and planning times of our planner for our prototype domain. The experiments were performed with the planner running on an Intel Xeon 4-core machine, with a 3 GHz processor and 8 GB RAM. Note that a goal of Null causes the planner to construct all possible flows (i.e. the planner is given no constraints for composition). This goal results in the generation of the ini-tial tag cloud in the web interface.

We observe that the composition requests are satisfied in less than 30 seconds, which is acceptable performance for most end-users. Our planner is a complete planner, i.e. it generates all possible plans that satisfy the goals. Hence, the times shown are for generating all possible plans (as op-posed to just the first plan, as many other classical planners do). Note that, in general, as the goal contains more and more tags, the planning time decreases (except for the Null goal). The reason for this is that our planner is complete; i.e. it produces all possible plans, and then ranks them. Hence, the more constrained the composition request, the lesser the number of possible plans, and hence the faster the planning. The non-monotonic nature of the planning times with the goal size comes from various optimizations performed by the planner that work well on certain combinations of goals [16].
A number of tools, typically featuring drag and drop ed-itors, have been built supporting manual composition (e.g. [12, 22]). A few tools ([21, 4]) also catalog available patterns for use in composition. The key novelty in our work is the use of automated, goal-driven composition that removes the need for end-users to construct flows manually.

Various works have tackled the problem of supporting end-user programmers. For example, [5] describes an approach by which end-user programmers choose and parameterize found examples. [9] uses assertions to help end-user pro-grammers create dependable web macros. The key differ-ence in our work is that we aim to support end-users with little or no programming experience, which is often the case with domain experts in many fields. In contrast, other works assume that the end-users have some programming skills in web-based languages like Javascript or Ruby. Hence, we take the approach of goal-directed composition with itera-tive goal refinement to support these users.

A closely related area is web service composition. Many different kinds of web service models have been proposed in prior work, and these models have been used for discovery and automatic composition. Some of these approaches use ontologies and associated standards such as OWL-S to de-scribe components used in composition [13, 20]. Other works use process models or transition systems [14]. The key differ-ence in our approach is that we use a simpler model of com-ponents, based on tags. This reduces the knowledge engi-neering effort required upfront for composition (compared to the more complex models suggested in these works). In ad-dition, we use patterns to describe composition constraints, instead of inputs, outputs, preconditions and effects as used by these works. Finally, in our domain of information pro-cessing, we do not have to worry about state-changes or side-effects.

Other composition works (e.g. [18]) use templates for composition, where different services can be used within a template. Our flow patterns are more expressive than tem-plates and can capture structural variations in flows, which simple templates cannot.

In other works, component composition at the code level is addressed in [15]. More recent work proposes dynamic hier-archical component composition [8], which also emphasizes type-oriented composition models. However, these works use type and other syntactic information to drive composi-tion, while we use patterns to drive composition.
Other automated software composition work includes the work by Margaria and Steffen [11], who were able to syn-thesize sequential orchestrations, expressed in BPEL, given process constraints defined in linear temporal logic. The key difference in our approach is that we take a goal-directed planning approach to the task of composition, where the goals are expressed using sets of tags.
In this paper, we have proposed an approach for simplify-ing the task of domain experts in constructing, parameter-izing and deploying data-plus-code mashups. Our approach makes use of flow patterns defined by developers in a lan-guage called Cascade. We also described a tool that makes use of the flow patterns to generate a web interface, where end-users can specify high-level flow composition requests as sets of tags. A planner takes the end-user X  X  request and com-poses a flow belonging to the pattern. The composed flow is then deployed on one or more platforms. We have described examples from the financial services domain to show how flow patterns helps end-users to construct a large variety of mashups rapidly.

Our pattern-based composition of mashups has a num-ber of advantages. It allows domain experts and other end-users to rapidly create situational applications in the form of mashups in response to a particular situation or problem, without having to go through a developer. It also allows end-users to explore the space of possible mashups that can be built with the available components, as specified by the pattern creators. Another side effect of the use of patterns is that it forces developers to design modular and reusable components that can be easily composed with other compo-nents in different patterns.
