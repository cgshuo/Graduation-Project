 Collaborative filtering (CF) approaches proved to be effec-tive for recommender systems in predicting user preferences in item selection using known user ratings of items. This subfield of machine learning has gained a lot of popularity with the Netflix Prize competition started in October 2006. Two major approaches for this problem are matrix factor-ization (MF) and the neighbor based approach (NB). In this work, we propose various variants of MF and NB that can boost the performance of the usual ensemble based scheme. First, we investigate various regularization scenarios for MF. Second, we introduce two NB methods: one is based on cor-relation coefficients and the other on linear least squares. At the experimentation part, we show that the proposed approaches compare favorably with existing ones in terms of prediction accuracy and/or required training time. We present results of blending the proposed methods.
 I.2.6 [ Artificial Intelligence ]: Learning X  parameter learn-ing  X 
All authors are also affiliated with Gravity Research &amp; De-velopment Ltd., H-1092 Budapest, Kinizsi u. 11., Hungary, info@gravitrd.com Algorithms, Experimentation Collaborative filtering, matrix factorization, neighbor based methods, Netflix Prize
Recommender systems attempt to profile user preferences over items, and model the relation between users and items. The task of recommender systems is to recommend items that fit the user X  X  taste, in order to help the user in select-ing/purchasing items from an overwhelming set of choices. Such systems have great importance in applications such as e-commerce, subscription based services, information filter-ing, etc. Recommender systems providing personalized sug-gestions greatly increase the likelihood of a customer making a purchase compared to unpersonalized ones. Personalized recommendations are especially important in markets where the variety of choices is large, the taste of the customer is important, and last but not least the price of the items is modest. Typical areas of such services are mostly related to art (esp. books, movies, music), fashion, food &amp; restaurants, gaming &amp; humor.

With the burgeoning of web based businesses, an increas-ing number of web based merchant or rental services use recommender systems. Some of the major participants of e-commerce web, like Amazon.com and Netflix, successfully apply recommender systems to deliver automatically gener-ated personalized recommendation to their customers. The importance of a good recommender system was recognized by Netflix, which led to the announcement of the Netflix Prize (NP) competition to motivate researchers to improve the accuracy of the recommender system of Netflix (see de-tails in Section 5.1).
There are two basic strategies that can be applied when generating recommendations. Content-based approaches pro-file users and items by identifying their characteristic fea-tures using, such us demographic data for user profiling, and product information/descriptions for item profiling. The profiles can be used by algorithms to connect user interests and item descriptions when generating recommendations. However, it is usually laborious to collect the necessary in-formation about items, and similarly it is often difficult to motivate users to share their personal data to help create the database for the basis of profiling.

Therefore, the alternative approach, termed collaborative filtering (CF), which makes use of only user activities of the past (for example, transaction history or user satisfaction expressed in rating) is usually more feasible. CF approaches can be applied for recommender systems independently of the domain. CF algorithms identify relationships between users and items, and make associations using this informa-tion to predict user preferences.

In this paper, we focus on the case when users express their opinion of items by means of ratings. In this framework the user first provides ratings of some items usually on a discrete numerical scale, and the system then recommends other items based on ratings already provided by other users.
The first works on the field of CF have been published in the early 1990s. In [7], the Tapestry system is presented that uses collaborative filtering to filter mails simultaneously from several mailing lists based on the opinion of other users on readings. In [12], the GroupLens system is described that was one of the pioneer applications of the field where users could rate articles on a 1 X 5 scale after having read them, and were then offered suggestions. In [5], the underlying techniques of predicting user preferences are divided into two main groups. Memory-based approaches operate on the entire database of ratings collected by the vendor or service supplier. On the other hand, model-based approaches use the database to estimate or learn a model, and then apply this model for prediction.

Over the last broad decade many CF algorithms have been proposed that approach the problem by different tech-niques, including similarity/neighborhood based approaches [12, 16], personality diagnosis [10], Bayesian networks [5], restricted Boltzman machines [14], and various matrix fac-torization techniques [6, 8, 15, 17]. In [19], an MF approach is presented that incorporates demographic information and ratings to enhance plain CF algorithms. In [5], the major CF approaches of the early years are surveyed, while in [11], short descriptions of most recent methods are given.
The NP competition boosted the interest in CF, and yielded the publication of a number of new methods. We should also mention here the NP related KDD Cup and Workshop [3], which indicated the possible directions of scalable and ac-curate CF methods. We feature among them the matrix factorization and neighbor based approaches.

Several matrix factorization techniques have been success-fully applied to CF, including singular value decomposition [15], probabilistic latent semantic analysis [8], probabilistic matrix factorization [13], maximum margin matrix factor-ization [17] and alternating least squares [1].

Simon Funk (Brandyn Webb) published a detailed imple-mentation of a regularized MF with separate feature up-date. 1 In [9], a bunch of novel techniques is introduced, including biased MF, kernel ridge regression on the residual of MF, linear model for each item, and asymmetric factor model (NSVD1, NSVD2). In [1], an improved neighbor-hood based approach is applied successfully, which removes the global effect from the data, and calculates optimal sim-ilarity values by solving regression problems.
We define the problem of collaborative filtering (CF) in the following setting. The problem can be modeled by the random triplet ( U,I,R ), where A realization of ( U,I,R ) denoted by ( u,i,r ) means that user u rated item i with value r . The goal is to estimate R from ( U,I ) such that the root mean squared error of the estimate, is minimal, where  X  R is the estimate 2 of R .

In practice, the distribution of ( U,I,R ) is not known, we are only given a finite sample, T 0 = { ( u 1 ,i 1 ,r 1 ), ( u ..., ( u t ,i t ,r t ) } , generated by it. The sample T used for training predictors. We assume  X  X ampling with-out replacement X  in the sense that (user ID, item ID) pairs are unique in the sample, which means that users do not rate items more than once. Let us introduce the nota-tion T = { ( u,i ) :  X  r : ( u,i,r )  X  T 0 } for the set of (user ID, item ID) pairs. Note that |T 0 | = |T| , and typically |T| N  X  M , because most of the users rate only a few items. Denote the set of items rated by the u -th user by T u = { i : ( u,i )  X  X } . Denote the set of users who rated the i -th item by T ( i ) = { u : ( u,i )  X  X } .

The sample can be represented as a partially specified matrix denoted by R  X  R N  X  M , where the matrix elements are known in positions ( u,i )  X  X  , and unknown in positions ( u,i ) /  X  X  . The value of the matrix R at position ( u,i )  X  X  , denoted by r ui , stores the rating of user u for item i . For clarity, we use the term ( u,i )-th rating in general for r and ( u,i )-th training example if r ui : ( u,i )  X  X  .
When we predict a given rating r ui by  X  r ui we refer to the user u as active user , and to the item i as active item . The ( u,i ) pair of active user and active item is termed query .
Matrix factorization (MF) is one of the most often applied techniques for CF problems. The idea behind MF techniques is very simple. Suppose we want to approximate the matrix R as the product of two matrices: where P is an N  X  K and Q is a K  X  M matrix. This factor-ization gives a low dimensional numerical representation of http://sifter.org/~simon/journal/20061211.html
In general, superscript  X  X at X  denotes the prediction of the given quantity, that is,  X  x is the prediction of x . both users and items. Note, that Q and P typically contain real numbers, even when R contains only integers.
 In the case of the given problem, the unknown ratings of R cannot be represented by zero. For this case, the approx-imation task can be defined as follows. Let p uk denote the elements of P  X  R N  X  K , and q ki the elements of Q  X  R K  X  M Let p T u denote the transpose of the u -th row of P , and q the i -th column of Q . Then: Here  X  r ui denotes how the u -th user would rate the i -th item, according to the model, e ui denotes the training error mea-sured at the ( u,i )-th rating, SSE denotes the sum of squared training errors. Eq. (4) states that the optimal P and Q min-imizes the sum of squared errors only on the known elements of R .
To avoid overfitting, we apply regularization by penalizing the magnitude of vectors, which introduces the following variables: Eq. (6) states that the optimal P and Q try to give a good approximation of R while containing only small numbers.
In order to minimize RMSE 0 , which is equivalent to mini-mize SSE 0 , we apply a simple incremental gradient descent method to find a local minimum of SSE 0 , where one gradient step intends to decrease e 0 ui .

Suppose we are at the ( u,i )-th training example, r ui , and its approximation  X  r ui is given. We compute the gradient of e ui for k  X  X  1 ,...,K } :  X  We update the weights in the direction opposite to the gra-dient: that is, we change the weights in P and Q to decrease the square of actual error and keep the weights of P and Q small. Note that opposed to Simon Funk, we train all values of P and Q simultaneously. We remark when the training has finished, each value of R can be computed easily
Also known as stochastic gradient descent. using eq. (2), even for unknown ratings. In other words, the model ( P  X  0 and Q  X  0 ) provides a description of how an arbitrary user would rate any item, though for known ratings the value may be considerably different from the predicted value. We refer to this method as Regularized Incremental Simultaneous MF (RISMF).
The presented MF has 4 important meta-parameters:  X  ,  X  , and the initial value of P and Q , which we denote by P 0 and Q 0 resp. We can get the proper setting of these parameters via trial by error or a parameter optimization algorithm to maximize the performance of a recommender system.

If we introduce more parameters, then we are able to get better performance, but the task of setting these param-eters will become harder. In the followings, we introduce many-many parameters to get a very general method, then we present some special cases that will have advantageous properties.
 Let p 0 uk and q 0 kj denote the elements of P 0 and Q 0 resp. We replace  X  and  X  with  X  p ( u,i,k ),  X  q ( u,i,k ),  X  p and  X  q ( u,i,k ) resp.

The formulas of eq. (8) for the ( u,i )-th rating and the k -th feature become the following: p 0 uk = p uk +  X  p ( u,i,k )  X  ( e ui  X  q ki  X   X  p ( u,i,k )  X  p For the training algorithm of this MF, see Algorithm 1. Note that we use different terminal conditions in Algorithm 1 and in eq. (6), because we optimize in the former case for the validation set, not for the training set.

Algorithm 1 : Training algorithm for XRISMF
We get BRISMF by introducing a bias feature per user and per item for RISMF. BRISMF is defined by specializing XRISMF in the following way: These settings mean that we set the first feature of each user and the second feature of each item to 1, and never change these values. We have different learning rate and regularization for users and items, and for bias and non-bias features. In short, BRISMF has the following meta-variables to initialize P 0 and Q 0 .

An interesting propery of this MF is that it converges much faster and is more accurate than RISMF.
In RISMF, the regularization of user and item feature vec-tors is done per rating (eq. (5)). Thus the weight penaliza-tion of a user X  X  or item X  X  feature vector is proportional to the number of ratings of that user or item resp.

However, a CF problem may require that the features of users or items with many ratings should be penalized less. To achieve this goal, we introduce an extension of BRISMF by specializing XRISMF in the following way: We replace regularization and learning rate parameters with functions with 7 parameters such that the value of those functions depend only on the number of ratings of active user and item. Let The definition of SBRISMF has a similar structure to BRISMF:
Now we have 7 times as many parameters as BRISMF, not counting the two random variables for initialization.
Though at first sight this parametrization seems as an unnecessary overcomplication, it can give a very accurate model, which blends well with other models.
Neighbor based methods exploit the observation that sim-ilar users rate similar items similarly. In this scheme for each query a set of similar users is selected from those ones who rated the active item. Or analogously, a set of similar items is selected from those ones that have been rated by the ac-tive user. The prediction is then calculated from the ratings of similar users (items) for the active item (user). The first variant is termed user neighbor based, and the second is termed item neighbor based approach.

We present our algorithms for such a CF setting in which the number of items is much smaller than the number of users (ten thousands vs. millions). For recommendation systems with so many users it is impossible to keep all user X  user similarities in the memory, however it may be possible to do this for items. In such cases the item neighbor based variant is much more efficient than the user neighbor based one. Therefore the algorithms will be presented using the item neighbor based scheme. The corresponding user neigh-bor based variants can be easily obtained by exchanging the terms  X  X ser X  and  X  X tem X .

Now let us define the item neighbor based scheme more formally. Recall that the set of items rated by user u is denoted by by T u . Denote the neighborhood set of the query ( u,i ) by N ui ( N ui  X  T u ). The prediction of the ( u,i )-th rating is the following: where w ( u,i,j ) is the j -th interpolation weight and p ( u,i,j ) is the j -th subprediction at making prediction for the ( u,i )-th rating. Various item neighbor based algorithms differ in how they define N ui , w ( u,i,j ) and p ( u,i,j ).
The most common approach is to use a correlation based similarity and restrict the number of relevant neighbors to a fixed number K . A plenty of slightly different variants exist within this algorithm family [11, 16, 18]. Here we pro-pose our variant that is quite accurate on the Netflix Prize problem [4].

The empirical correlation coefficient c ij between items i and j can be calculated as the following:
If there are only a few users who rated both the i -th and j -th item, then the estimate (12) is bad: | c ij | is typically larger than the absolute value of the true correlation. Therefore it is useful to shrink c ij towards zero to get an improved estimate c 0 ij : where  X  is called the first regularization term. The similar-ity between items i and j denoted by s ij is defined as the following: where  X  is called the amplification factor. The value s ij high, if items i and j are similar, and 0 if they are negatively correlated. Now we are ready to define N ui , w ( u,i,j ) and p ( u,i,j ): where  X  is called the second regularization term and  X  i de-notes the average rating of item i in the training set.
An advantageous property of this algorithm is that it can be implemented without training phase. Having said this, it is useful to precompute the correlation coefficients and keep them in the memory, because this decreases prediction time.
One may say that the definitions of N ui , w ( u,i,j ), and p ( u,i,j ) are too complicated in NB-CORR. It would be in-teresting to see what happens if simpler definitions are used. The only thing that has to be specified is s ij .

This model was first introduced by Paterek in [9] under the name linear model for each item . He suggested using gradient descent for training, here we propose a different approach.

The goal is to find s ij values such that the sum squared error is minimal.

Now we show that minimizing the SSE is equivalent to solving M linear least squares problems. Recall that the set of users who rated the i -th item is denoted by T ( i ) . Order the elements of T ( i ) and denote the k -th element by t ( k = 1 ,..., |T ( i ) | ). Define B i as a |T ( i ) | X  M matrix and r as a |T ( i ) | X  1 column vector such that where v = t ( i ) k . Denote the column vector ( s i 1 ,...,s s . Using the above definitions the SSE can be written as therefore the minimization of the SSE is equivalent to solving M linear least squares problems.

If the i -th item has only a few ratings, then minimizing | B i s i  X  r i k 2 can lead to poor results because of overfitting. To handle this we modify the objective function by adding a regularization term: where  X  is the regularization factor. Note that this modifi-cation does not affect the computational complexity of the problem.

It can be shown with differentiation that the minimum of the SSE 0 is at: where I M is the M  X  M identity matrix.

Unfortunately, calculating (13) for all i is computationally expensive: we have to invert an M  X  M matrix for each item which is O ( M 4 ) operations in total 4 . Therefore we also present a faster approximate solution.

Let us define the N  X  M matrix B as:
The approximation of (13) is where  X  is called the amplification factor. Calculating (14) for all i needs only O ( M 3 ) operations, because it is enough to compute the inverse only once and then perform a matrix-vector multiplication for each item.
We neglected the cost of computing B T i B i +  X  I M B
We evaluated our algorithm against the Netflix Prize (NP) dataset, since currently this is the most challenging prob-lem for the collaborative filtering and recommender sys-tem community, and our work was greatly motivated by it. Netflix initiated the Netflix Prize contest in order to im-prove their recommender system X  X alled Cinematch X  X hat provides movie recommendations to customers. The dataset released for the competition is substantially larger than for-mer benchmark datasets, and contains about 100 million ratings from over 480k users on nearly 18k movies. For com-parison, the well-known EachMovie dataset 5 only consists of about 2.8m ratings of 73k users and 1628 movies.

In the Netflix Prize dataset, a rating record is a quadruple ( u,i,r ui ,d ui ) representing that user u rated item i as r date d ui  X  D , where D is the ordered set of possible dates. The ratings r ui are integers from 1 to 5, where 1 is the worst, and 5 is the best. The data were collected between October, 1998 and December, 2005 and reflect the distribution of all ratings received by Netflix during this period [4]. The col-lected data was released in a train-test setting. A hold-out set was created from the most recent ratings of the users, consisted of about 4.2 million ratings. Earlier ratings form the Training set. The Hold-out set were split randomly with equal probability into three subsets of equal size: Quiz, Test and Probe. The Probe set was added to the Training set and was released with ratings. The ratings of the Quiz and Test sets were withheld as a Qualifying set to evaluate competi-tors. The Quiz/Test split of the Qualifying set is unknown for the public. We remark that the date based division of the entire NP dataset into train-test sets reflects the origi-nal aim of recommender systems, which is the prediction of future interest of users from their past ratings/activities.
As the aim of the competition is to improve the prediction accuracy of user ratings, Netflix adopted RMSE as evalua-tion measure. The goal of the competition is to reduce by at least 10 percent the RMSE on the Test set, relative to the RMSE achieved by Cinematch. 6 The contestants have to submit prediction for the Qualifying set. The organizers return the RMSE of the submission on the Quiz set, which is also reported on a public leaderboard. 7 Note that the RMSE on Test set is withheld by Netflix.

In this experimentation section we evaluate the presented methods on a randomly selected, but fixed 10% subset of the Probe set, which we term as Probe10. 8 We added the rest of the Probe set to the training set. Unless we ex-plicitly mention, from now on the RMSE values refer to the Probe10 RMSE. We have decided to report on RMSE values measured on the Probe10 set, since in our experiments the
It used to be available upon request from Compaq, but in 2004 the proprietary retired the dataset, and since then it is no longer available for download.
The first team achieving the 10 percent improvement is promised to be awarded by a Grand Prize of $1 million by Netflix. Not surprisingly, this prospective award drawn much interest towards the competition. So far, more than 3 000 teams submitted entries for the competition. http://www.netflixprize.com/leaderboard
A Perl script has been made available at our homepage, which selects the Probe10 from the original Netflix Probe set to ensure repeatability and comparability.
 Probe10 RMSE are significantly closer to the Quiz RMSE than Probe RMSE, and Quiz RMSE tell us more about the accuracy of the predictor, since it excludes the impact of overtraining. On the other hand the rules of NP competi-tion allows only 1 submission daily, which limits the num-ber of the Quiz RMSE calculation drastically. We remark that we measured a maximum 0 . 0003 difference between the Probe10 and the Quiz RMSE values, while this was of an order of magnitude larger for the Probe set. This advanta-geous property nominates the Probe10 set for being a stan-dard and Netflix-independent evaluation set for predictors trained on the NP dataset.
In the experiments similarities were calculated only be-tween the 6000 items with most ratings. Most of the queries involve these items. For other items the prediction was made by a baseline method (50% user average, 50% item average). NB-CORR was run on the original while NB-LS-BIN on the double centered ratings matrix.
 Table 1: Probe10 RMSE of neighbor based methods.
We recall that we applied linear combination of methods for blending. For the matrix factorization methods, we or-dered the training examples user-wise and then by date.
To initialize the P and Q matrices, we use continuous uniform distribution with parameters w p and w p for P , and w q and w q for Q .

We introduce a new meta-parameter, G , which we term as global offset. If not mentioned, we assume G = 0. Otherwise we subtract this number from each rating before learning, and add back after prediction.
We compare:
RISMF#0 reaches its optimal RMSE in the 13th epoch: 0.9214, while these numbers for BRISMF#0 are: 10th and 0.9113, which is a 0.0101 improvement.

We can obtain even better results if we set  X  to 0 . 007 and  X  to 0 . 005: Probe10 RMSE is 0.9056 (after 10 epochs), which is a 0.0057 improvement. We refer to this MF in the following as BRISMF#1. The running time for this MF is only 14 minutes! Note that running time depends only on K , and on the optimal number of epochs, it is linear in both variables. We applied parameter optimization to get accurate MFs. Also, we applied the  X  X rial and error X  method to get man-ually parameterized accurate MFs. Unless not mentioned otherwise, the parameter settings of the following MFs are found by parameter optimization. Here we describe some results of both:
See Table 2 for the RMSE values of the each method and their blended versions. Table 2: Probe10 RMSE of MFs, NB-CORR and NB-LS-BIN
We compare the presented Probe10 RMSE values (which differ from Quiz RMSE values at most by 0 . 0003) with other RMSE values reported for the Netflix Prize dataset. Authors often report Probe RMSE or Quiz RMSE values.
In [1], a detailed description of their alternating least squares approach proposed to matrix factorization is pro-vided. They report on Probe RMSE=0.9167 for their pos-itive MF, and their methods need to run the specialized quadratic optimizer for (17770+480189)  X  n  X  times, where n is  X  X ew tens X . The computational complexity for the special-ized quadratic optimizer is approx. O ( K 3 ) for K features. They report on Probe RMSE=0.9071 and Quiz RMSE=0.8982 for their neighbor method executed on the residuals of their MF.

The best results are reported by [2], where they briefly describe their approach for the Netflix Progress Prize 2007. The MF methods described in that paper have the same computational complexity as mentioned above ([1]). They report only on Quiz RMSE values. Here we summarize the best results of their paper:
Table 3 compares our best methods with the results re-ported by [2].

Simple MF BRISMF 0.8938 0.8939 0.8998
Tweaked MF SBRISMF 0.8895 0.8893 N/A
Neighbor on N/A N/A N/A 0.8953 Table 3: Comparison of our best Probe10 and Quiz RMSE values against the Quiz RMSE values re-ported by [2]
Clearly, our matrix factorization methods outperform Bell et al. X  X  MF methods. Additionally, our methods are much faster.
This paper surveyed some of our approaches for collab-orative filtering. We presented several MF and NB meth-ods. We evaluated our algorithms against the Netflix Prize dataset. We showed that linear combination of various meth-ods can significantly improve the accuracy of the blended solution. We showed that they compare favorably with ex-isting methods in terms of prediction accuracy measured by RMSE, and time complexity. The experiments prove that the proposed methods are scalable to large recommender systems having with hundreds of millions of ratings. [1] R. M. Bell and Y. Koren. Scalable Collaborative [2] R. M. Bell, Y. Koren, and C. Volinsky. The BellKor [3] J. Bennett, C. Eklan, B. Liu, P. Smyth, and D. Tikk. [4] J. Bennett and S. Lanning. The Netflix Prize. In Proc. [5] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [6] J. Canny. Collaborative filtering with privacy via [7] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. [8] T. Hofmann. Latent semantic models for collaborative [9] A. Paterek. Improving regularized singular value [10] D. M. Pennock, E. Horvitz, S. Lawrence, and C. L. [11] A. M. Rashid, S. K. Lam, G. Karypis, and J. Riedl. [12] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [13] R. Salakhutdinov and A. Mnih. Probabilistic matrix [14] R. Salakhutdinov, A. Mnih, and G. Hinton. Restricted [15] B. M. Sarwar, G. Karypis, J. A. Konstan, and [16] B. M. Sarwar, G. Karypis, J. A. Konstan, and [17] N. Srebro, J. D. M. Rennie, and T. S. Jaakkola. [18] G. Tak  X acs, I. Pil  X aszy, B. N  X emeth, and D. Tikk. On the [19] M. G. Vozalis and K. G. Margaritis. Using SVD and
