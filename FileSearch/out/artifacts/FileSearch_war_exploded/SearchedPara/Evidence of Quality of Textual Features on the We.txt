 The growth of popularity of Web 2.0 applications greatly in-creased the amount of social media content available on the Internet. However, the unsupervised, user-oriented nature of this source of information, and thus, its potential lack of quality, have posed a challenge to information retrieval (IR) services. Previous work focuses mostly only on tags, although a consensus about its effectiveness as supporting information for IR services has not yet been reached. More-over, other textual features of the Web 2.0 are generally overseen by previous research.

In this context, this work aims at assessing the relative quality of distinct textual features available on the Web 2.0. Towards this goal, we analyzed four features ( title tags , description and comments ) in four popular appli-cations (CiteULike, Last.FM, Yahoo! Video, and Youtube). Firstly, we characterized data from these applications in or-der to extract evidence of quality of each feature with respect to usage, amount of content, descriptive and discriminative power as well as of content diversity across features. After-wards, a series of classification experiments were conducted as a case study for quality evaluation. Characterization and classification results indicate that: 1) when considered sepa-rately, tags is the most promising feature, achieving the best classification results, although its absence in a non-negligible fraction of objects may affect its potential use; and 2) each feature may bring different pieces of information, and com-bining their contents can improve classification. H.3.5 [ Online Information Services ]: Web-based services Experimentation, Measurement Web2.0,TextualFeatures,SocialMedia
Web 2.0 applications have grown significantly in diver-sity and popularity in recent years. Popular examples in-clude Youtube and Yahoo! Video 1 (or simply YahooVideo), two social video sharing applications, Last.FM 2 (or simply LastFM), an online radio and music community website, and CiteULike 3 , a scholarly reference management and discov-ery service. By distributing mostly user generated content and enabling the establishment of online communities and social networks, these applications make use of collaborative knowledge to increase the amount and diversity of content offered. Youtube, for example, is currently the largest video database in the world 4 , and the second most searched Web-site 5 . Although the musical content available in LastFM is not generated by its users, it is currently one of the most popular Internet radio stations, due to its community based organization, which gives users the ability to describe musi-cal content and interact over social networks.

Social media is here used to refer to the content, most commonly generated by users, available in Web 2.0 appli-cations. This typically comprises a main object, stored in one of various media types (text, image, audio or video), as well as several other sources of information, commonly in textual form (and thus referred to as textual features ), asso-ciated with it (e.g., tags). Being often unsupervised sources of data, social media offers no guarantee of quality, thus pos-ing a challenge to information retrieval (IR) services such as search, recommendation, and online advertising. In fact, a recent discussion pointed the commonly low quality of mul-timedia objects, particularly videos, and its impact on the effective use of state-of-the-art multimedia IR techniques as one of the reasons for their limited use on the Web 2.0 [4].
In contrast, tagging has emerged as an effective form of describing and organizing content on the Web 2.0, being a main topic of research in the area. Previous work includes the investigation of its use for supporting search, recommen-dation, classification and clustering [12, 18, 5, 16] and anal-yses of tag usage and patterns [7, 19]. However, being also social media content, the effectiveness of tags as supporting information for IR services is questionable. In fact, previous analyses of tags in different applications reach contradictory results [3, 14]. More broadly, other textual features, such as object title and description, do exist in most Web 2.0 ap-plications, but their potential use for IR services have been mostly neglected by previous research.

In this context, this paper aims at providing evidence of the relative quality of different textual features commonly found in Web 2.0 applications. The term quality is here used to refer to the feature X  X  potential effectiveness as sup-porting information for IR services. Towards that goal, we crawled object samples from four popular applications, namely, Youtube, YahooVideo, LastFM and CiteULike, col-lecting the contents of four textual features, namely, title tags , description and comments . We then characterized the data in order to extract evidence of quality of each fea-ture with respect to usage, amount of content, descriptive and discriminative power, as well as evidence of content di-versity across features. Our main findings are: (1) all four features but title are unexplored in a non-negligible frac-tion of the collected objects, particularly in applications that allow for the collaborative creation of the feature content; (2) the amount of content tends to be larger in collaborative features; (3) the typically smaller and more often used title and tags features exhibit higher descriptive and discrimi-native power, followed by description and comments ;(4) there is non-negligible diversity of content across features as-sociated with the same object, indicating that features may bring different pieces of information about it.

We also assessed the relative quality of the features with respect to a specific IR task, that is, object classification, chosen for its common applicability to several services (e.g., automatic construction of web directories) and for enabling automatic assessment of feature quality. To that end, we performed a series of classification experiments, varying the source of information for the classifier and the term weight-ing scheme. In particular, we tested six classification strate-gies consisting of taking each feature in isolation as well as two combinations of all four features. Our main results, which are supported by our characterization findings and hold across all weighting schemes analyzed, are: (1) tags if present, are, in fact, the most promising feature in iso-lation; (2) combining content from all four features can im-prove the classification results due to the presence of distinct but somewhat complementary content; (3) for classification, feature quality is affected by the amount of content, being title the one with lowest quality, despite its good discrim-inative/descriptive power and large object coverage.
This paper builds a more solid understanding of issues re-lated to the quality of textual features commonly found in Web 2.0 applications. The knowledge produced here may be of use to Web 2.0 application designers, who can address is-sues such as the usefulness and attractiveness of each feature to their users. It may also be of relevance to designers of IR services for the Web 2.0 as it uncovers evidence of quality of each feature as a potential source of information. In sum, we here offer a more thorough exploration of the problem than previous work covering different features, in different applications, and thus providing more sound conclusions.
The rest of this paper is organized as follows. Section 2 discusses related work. The textual features analyzed are presented in Section 3, whereas Section 4 summarizes our data collection methodology. Sections 5 and 6 discuss the characterization of the features and the classification exper-iments, respectively. Finally, conclusions and directions for future work are offered in Section 7.
Some evidence of quality of Web 2.0 features, mainly tags, has been produced by previous work. Suchanek et al [20] look up the amount of known tag terms in Delicious 6 ac-cording to lexical databases. They find that approximately half of the used tags have entries in these dictionaries, and that nearly half of these known tags have 10 or more mean-ings. Bischoff et al [3] analyze the quality of tags in the context of search in some Web 2.0 applications. By check-ing the overlap of tags with content, metadata assigned by experts, and external sources such as search engines, they find that tags tend to be accurate with respect to the object content, and are related to search queries.

In the context classification and clustering, Ramage et al [16] contrast the usage of tags assigned by users in Deli-ciouswiththeusageofthefulltextualcontentofthebook-marked webpages. The authors show that combining both webpage content and tags improves the effectiveness of two different clustering algorithms. Another interesting result is that of Chen et al [5], which developed a classification model based on both content features and tagging data of musical tracks from LastFM. The authors show that the use of both types of features improves classification results when compared to baseline based only on content features.
In spite these examples, comparing tags with other textual features found on Web 2.0 applications is still an open issue. A very recent publication gives somewhat different insights on the matter, manually comparing three different textual features ( title , tags and descriptions )whendescribing versions of images with the same content (i.e., a touristic place), and raising the question whether tags are the most reliable source of information [14]. In comparison with these previous work, we note that our analysis is broader, fully au-tomatic, focusing on far more objects, evaluating many more properties of the features, across different Web 2.0 applica-tions. However, some interesting insights, which can only be captured by human reviews, are presented on that last study. One example are assertions about which features are more semantically related with the context of the image as a whole (i.e., if it is a couple on a holiday or a person shar-ing the picture with a friend.). The author concludes that tags are not the best textual feature, since title and descrip-tions better capture the context within the picture and tags are used, mostly, for organizational purposes. This result is contradictory to most previous work on tags.
In addition to the analysis of tags, there is also some work on the analysis of commentaries posted by users in blogs [15]. The authors characterize the use, popularity, temporal dis-tribution and amount of information in blog comments. It is shown that the information in comments can be used to in-crease the amount of documents retrieved by search queries and that the temporal distribution can be use to re-rank query results according to blog entries X  post dates.
All of the examples above can be seen as evidence of qual-ity, but they focus either on a single feature or on a small sample of objects. To the best of our knowledge, ours is the first effort to automatically analyze in a large scale the quality of different textual features associated with the same object in four different Web 2.0 applications. Moreover, we extract and analyze evidence of quality with regard of usage, quantity, and descriptive and discriminative power.
Recent efforts towards applying multimedia IR techniques on Web 2.0 applications are also worth mentioning. Exam-ples include the use of both content and textual features [17, 5]. These are indications that multimedia IR techniques and social media is converging at some level, a question posed by the previously discussed work of Boll [4]. Also worth mentioning are studies on the matter of social media quality such as the one by Agichtein et al [2] focused on the quality of social media objects in QA applications.
AWeb2.0 object is an instance of a media (text, audio, video, image) in a given Web 2.0 application. There are various sources of information related to an object, here referred to as its features. In particular, textual features , the focus of this study, comprise the self-contained textual blocks that are associated with an object, usually with a well defined topic or functionality [6]. We here select four textual features for analysis, namely, title , description tags ,and comments , which are found in many Web 2.0 ap-plications, although some of them are referred to by different names in some applications. CiteULike, for instance, a so-cial bookmarking website for scientific publications, refers to the description as abstract , as it usually contains the publication abstract, and name user comments as reviews . LastFM refers to comments as shouts .

Textual features may be categorized according to the level of user collaboration allowed by the application. In particu-lar, the textual features analyzed can be either collaborative or restrictive . Collaborative features may be altered or ap-pendedbyanyuser,whereasrestrictiveonesmayonlybe altered by one user, typically the one who uploaded the ob-ject into the system. This property of a feature is here called its annotation rights , a generalization of the previously used tagging rights notation [13].

Tags are a collaborative feature in CiteULike, LastFM and YahooVideo, as any user can add tags to an existing ob-ject in these applications. In Youtube, in contrast, only the video uploader can add tags to it. Moreover, while restric-tive in both YahooVideo and Youtube, description has a collaborative nature in both LastFM and CiteULike. In the former, users can edit information on an artist or music in a wiki-like manner. In the latter, users can provide different abstracts to the same publication, although we found that to be very rare in our collected dataset. In all four applications, title is restrictive and comments is collaborative.
We note that some of the applications may automatically fill some of these features at upload time. Youtube, for in-stance, adds the name of the object as its title and as tags , if these features are not provided. However, it does allow users to remove automatically added tags ,ifa title is provided. In CiteULike, the user may request for the sys-tem to extract title and description from several digital libraries. Nevertheless, in all but one application, users are allowed to change all features, according to their annotation rights. The exception is LastFM, in which title (i.e., artist names) is automatically inserted via media player software based on music files metadata.
In order to perform our study, we built crawlers to sample objects and associated textual features from each applica-tion. For Youtube, YahooVideo and LastFM, our crawlers follow a snowball sampling strategy [8]. Each crawler starts with a number of objects as seeds (at least 800). For each ob-ject under consideration, it retrieves all related objects (fol-lowing links provided by these applications), storing them for future consideration. In Youtube and YahooVideo, the seeds were randomly selected from the list of all-time most popular videos provided by the applications. In LastFM, they were selected among the artists associated with the most popular tags 7 . For CiteULike, which does not provide explicit related object links but makes daily snapshots of stored objects available for download, we collected a ran-dom sample of one snapshot.

The Youtube, YahooVideo and LastFM crawlers ran for approximately two weeks in July, September, and October 2008, respectively, whereas the sampled CiteULike snapshot is from September 2008. In total, we collected 678,614 arti-cles from CiteULike, 193,457 artist pages from LastFM, and 227,562 and 211,081 videos from YahooVideo and Youtube.
Both Youtube and YahooVideo allow users to assign one of a set of pre-determined categories to their videos. In order to use these categories as object classes in our classi-fication experiments (Section 6), our two crawlers collected the category of each object, along with its associated textual features. For LastFM, even though an official category list-ing is not provided by the application, external data sources can be used to retrieve the musical genre of artists, which, in turn, can be used as object classes. In particular, as in [5], we sampled musical genres from the AllMusic website 8 ,which self claims to be the largest musical database available. We were able to find categories for 5,536 artists in our dataset, a larger categorized sample than previous work [5].
Similarly to LastFM, CiteULike does not provide any ar-ticle category listing. Moreover, we are not aware of any reliable categorization covering multiple scientific areas (as in our sample). Thus, we do not include CiteULike in our current classification experiments, leaving it for future work. In total, there are 20 and 15 categories in YahooVideo and Youtube, respectively, whereas 9 musical genres were used in the categorization of artists in LastFM. These categories, referred to as object classes, are listed in Table 1.
In this section, we analyze the use of the four selected tex-tual features in the four studied applications. Our character-Application Classes
Yaho oVideo Action, Animals, Art &amp; Animation, Com-ization, performed over our collected datasets 9 , covers four aspects, aiming at providing evidence of the relative quality of the features as supporting information for IR tasks.
First, we characterize feature usage , investigating which features are more explored by users (Section 5.1). Feature usage is of key importance, as under-explored features, that is, features that are absent in a non-negligible fraction of the objects, may not be a reliable source of information. Second, we characterize the amount of content in each fea-ture (Section 5.2). If present, a feature should also provide enough content to be effective for IR. Third, we use heuris-tics, adapted from previous work [6], to assess the descrip-tive and discriminative power of each feature (Section 5.3). Effective sources of information for IR tasks should offer a reasonably accurate description of the object content and/or discriminate objects into different pre-defined categories (for services such as browsing, recommendation and advertising) and into levels of relevance (for searching). Lastly, we char-acterize the diversity of content across features (Section 5.4), motivating the exploration of different feature combination strategies in the next section. The main findings from our characterization are summarized in Section 5.5. Through-out this section, we refer to the set of terms in a feature associated with one given object as an instance of feature
Table 2 shows, for each feature and application, the per-centage of empty feature instances, i.e., objects with no terms in the given feature. The annotation rights of each fea-tureisshowninparenthesis, C for collaborative and R for re-strictive. The fraction of empty instances is much larger for collaborative features. In fact, some of these features, such as comments in all applications but Youtube, and descrip-tion in LastFM and CiteULike, are vastly under-explored. Even Youtube, with millions of users, has a significant frac-tion of empty comments , similarly to previous findings on blog and photo sharing systems [15, 14]. The tags feature, focus of most previous efforts to enhance Web 2.0 IR ser-vices, is also absent in non-negligible fractions of 16% and of almost 19% of the objects collected from YahooVideo and LastFM, respectively. Only title , restrictive in all applica-tions, is present in practically all objects. Table 2: Percentage of Empty Feature Instances (C = collaborative feature, R = restrictive feature).
These results may be partially explained by restrictions imposed by the application, such as the case of title and tags in Youtube, which may be automatically filled by the system. However, none of the applications enforces the us-age of Description , for instance. Nevertheless, it has a much larger presence in YahooVideo and Youtube, where it is restrictive, than in the other two applications. In fact, in YahooVideo, it has a much larger presence than tags , a collaborative feature. This is surprising, as we expected that users would be more willing to provide a few words as tags than a few sentences as description . An interest-ing comparison is that of tags in CiteULike and LastFM. Even though both applications motivate the organization of personal libraries, CiteULike does explicitly ask users to associate tags 10 to their articles, whereas no such incen-tive exists in LastFM. Comparing the usage of tags in both applications, it seems like users may need extra incentives to use collaborative features, an issue previously raised for tagging systems [13].

Thus, considering solely the object coverage in terms of feature presence, the restrictive title offers the best qual-ity of all features, in all applications. This is consistent with a previous analysis of Flickr 11 , which also reported a much larger presence of title than of tags and description [14]. More broadly, the feature annotation rights seems to play an important role on its usage. In particular, using only collab-orative tags , description or comments as single source of data for IR tasks may not be effective due to the lack of information for a significant fraction of objects.
In this section, we analyze the amount of content avail-able in textual features. Since this analysis is language-dependent, we focus on the English language, applying a simple filter that disregards objects with less than three En-glishstop-wordsintheirtextualfeatures 12 .Wealsofocus our analysis on non-empty feature instances .

After removing non-english objects and empty feature in-stances, we were left with a varying number of objects for the analysis of each feature in each application. This number is larger than 150,000 for title , description and tags in all applications but LastFM, for which they exceeded 86,500 objects. Our cleaned datasets also include 152,717, 76,627, 6,037 and 76 objects with comments in Youtube, LastFM, YahooVideo and CiteULike, respectively. We removed terms containing only non-alphanumeric characters, and applied the Porter stemming algorithm 13 to remove affixes, remov-ing stop-words at the end. This was done to remove mean-ingless terms and normalize semantically equivalent ones.
We characterize the number of distinct terms in each fea-ture instance, here referred to as its vocabulary size ,which represents the amount of content available for use by IR services. These results are summarized in Table 3, which presents the mean  X  , coefficient of variation CV (ratio of standard deviation to the mean), and maximum values 14 . The AR columns show the feature annotation rights.
In general, title has instances with the smallest vocabu-lary, followed by tags , description and comments . More-over, with few exceptions, instances of collaborative features tend to have vocabularies with larger average sizes and high variability (CV). For instance, the table shows that com-ments instances (if present) have the largest vocabulary, on average (except in CiteULike), also exhibiting very large co-efficient of variation. Similarly, instances of description CiteULike and LastFM, and of tags in LastFM, also collab-orative, have larger vocabularies than instances of the same features in Youtube, where they are restrictive. Neverthe-less, comments carry much less content in YahooVideo and CiteULike than in the other two applications, as it is not often explored by their users (Section 5.1). These results are consistent with the ones previously observed for title tags and description in Flickr [14].

In CiteULike, the tags feature, in spite of being collab-orative, tends to have instances with smaller vocabularies, providing less content than title , unlike in the other appli-cations. This is possibly due to long article titles and the stabilization of tagging vocabulary with time [7, 12]. Nev-ertheless, a small fraction of objects have tags with very large vocabularies (up to 194 terms). Unlike in all other applications, description has larger instances on average, possibly because they typically carry article abstracts, with more information than the poorly used comments .

In LastFM, title has a much stronger bias towards small vocabularies than in the other applications. This is expected since the feature is usually referring to artist names. In con-trast, the tags feature tends to carry much more content, with an average of 27 terms and reaching up to a maximum of 269. Comments is the feature with the largest amount of content, but this average is biased towards very popu-lar artists, for which comments canhavemorethan22,000 terms. Description instances also have large vocabular-ies, larger than in the other applications, likely due to its collaborative nature, as users collectively write a text, in a wiki-like manner, describing the artists.

YahooVideo and Youtube show similar trends, although the vocabularies of instances of both description and com-ments tend to be much larger in Youtube, possibly due to its larger audience. In contrast, the instances of title and tags have larger vocabularies in YahooVideo. Whereas the differences in tags may be due to the higher degree of collab-oration in YahooVideo, the differences in title may reflect differences in usage patterns.
Web 2.0 features normally define different content blocks in Web pages. For instance, in Youtube, the comments about a video are placed near to each other into a common (comments) block. Thus, in this section, we use metrics previously proposed to assert the importance of traditional Web page blocks to assess the importance of the four tex-tual features analyzed. In particular, we adapt metrics based on heuristics, proposed as part of an Information Retrieval model [6], to the context of textual features of Web 2.0 ob-jects in order to assess their descriptive and discriminative power. In the following, we first formally define each metric, and then present the characterization results.
Our assessment of the descriptive power of each feature is basedona heuristic metric called Average Feature Spread , which can be computed as follows. We start by defining the spread of a term in a given object. Let o be an object in the collection O ,and t a term which appears in at least one fea-ture instance f associated with o .The term spread , TS ( measures the number of feature instances associated with o which contain t ,thatis:
The assumption behind TS ( t, o ) is that the larger the number of features of o that contain t , the more related with o  X  X  content. For instance, if the term  X  X ting X  appears in all features of a given video, there is a high chance that the video is related to the famous singer.

Next, we define the Feature Instance Spread of a feature instance f associated with an object o , FIS ( f, o ), as the average term spread across all terms in f . That is, given the number of terms in instance f , FIS ( f, o )isdefinedas:
The Feature Instance Spread is a heuristic to assess how the terms of a given feature instance f are related to the content of instances of other features associated with the same object o . Itisthusaheuristictoestimatehowthe feature instance f is related to o  X  X  content, being here used as an estimate of the average descriptive power of feature instance f for the given object o .
 Following this reasoning, the descriptive power of a feature F in the object collection O canbecapturedbyaveraging the values of FIS across all objects. We refer to this metric and FI Values.
 as the Average Feature Spread of F , AF S ( F ). Given each object o in the collection and the instance of F associated with it, f ,the AF S ( F ) is computed as:
In order to assess the discriminative power of a feature, we use a heuristic called Average Inverse Feature Frequency (AIFF) .The AIF F metric builds on a small variation of the IDF metric, called Inverse Feature Frequency (IFF) ,which considers instances of a feature F as a separate  X  X ocument collection X . Given a feature F with | F | instances 15 ,and aterm t that occurs in at least one of F  X  X  instances, the IFF ( t, F ) of term t in F is defined as: where F requency ( t, F ) is the number of instances of F which the term t appears.

The IFF metric assesses how much information carries the occurrence of a given term in a given feature .The assumption is that terms occurring in many instances of the feature are bad discriminators of content. For example, whereas the occurrence of  X  X usic X  in a title of a Youtube object brings little information about its content in relation to other music videos, the occurrence of  X  X ting X  may be more useful to discriminate it from the other objects.
We then define the Average Inverse Feature Frequency of feature F , AIF F ( F )astheaverage IFF over all terms that occur in all instances of F . It is thus a heuristic to estimate the discriminative power of the feature F in the object col-lection. Given | V F | the size of the complete vocabulary of feature F (i.e., considering all instances of F in the object collection), the AIF F ( F ) is computed as:
We note that | F | is not necessarily equal do | O | ,sincesome objects may have empty instances of F .

Finally, the values of FS and AIF F are used to estimate the Feature Importance ( FI ), which measures how good a feature is considering both its discriminative and descriptive power. The FI of a feature F is given by their product, that is
FI ( F )= AF S ( F )  X  AIF F ( F )
We computed the AIF F , AF S and FI values of each feature in all four applications, using our stemmed datasets and considering only objects with non-empty instances of all features. Given the negligible fractions of non-empty com-ments in YahooVideo and CiteULike, we disregarded this feature in both applications. As Table 4 shows, the AF S values provide a consistent ranking of features in all four applications. Title is the most descriptive feature, followed by tags , description and, if considered, comments .In contrast, the AIF F values show little distinction across fea-tures in any application. The FI metric, dominated by its AF S component, produces a ranking in agreement with it.
In order to understand why the AIF F metric is not able to clearly distinguish one feature from the other, we plotted the term popularity distribution of each feature, considering all instances of the feature. Figure 1 shows that the distri-butions are heavy-tailed in all applications, thus containing a large number of terms with very low popularity. These terms have very large IFF values, and end up boosting the AIF F of all features somewhat similarly. In fact, previous studies [16, 9] showed that IDF ,onwhich AIF F is based, over-emphasizes unique and very unpopular terms, and that thesetermsarenothelpfulfortaskssuchasclusteringand classification, since, being rarely shared, they are unable to help grouping objects into semantically meaningful groups.
Thus, we recomputed the AIF F values considering only terms that appeared in more than 50 instances 16 .There-Table 5: AIF F Values (ignoring unpopular terms). sults, presented in Table 5, show a more clear distinction be-tween the features. Overall, according to the AIF F heuris-tic, title is the most discriminative feature, followed by tags , description and, if considered, comments ,arank-ing that is consistent with the AF S results. The exception is CiteULike in which tags has a larger AIF F value than title . This may be due to the use of terms in article ti-tles that are less specific than those in tags , possibly to facilitate discovery and understanding of the article subject by potential readers. As consequence, the same terms may co-occur in many title instances, thus reducing its IFF .
So far we have characterized aspects of each feature sep-arately. We now investigate whether different features con-tribute with different content (i.e., terms) about the asso-ciated object. As in Section 5.2, we focus on the English language, using the stemmed datasets. We quantify the similarity betweentwofeatureinstancesintermsofterm co-occurrence using the Jaccard Coefficient. Given two sets of items T 1 and T 2 , the Jaccard Coefficient is computed as J (
We compute the similarity between two features associ-ated with the same object using as input sets the N most highly ranked terms from each feature instance based on the product of the TS and IFF metrics 17 . We then compute the average similarity between two features across all objects containing non-empty instances of them.

Table 6 shows the average similarity between all pairs of features in all four applications for N =5 and, in parenthe-sis, when all terms of each feature instance are considered. Results for N =15, 30 and 50 are in the same range. As in the previous section, we disregard comments in CiteU-Like and YahooVideo. There seems to be more similarity between restrictive features (e.g., title and description in YahooVideo and Youtube), as the same user tends to use common words in them. The exception is tags in Ya-hooVideo, which, despite collaborative, shares some similar-ity with the restrictive title and description features, per-haps an indication that tags are often used only by the video owner herself. Nevertheless, the Jaccard Coefficients are all under 0.52. Thus, although there is some co-occurrence of highly ranked terms across features, each feature may still bring new (possibly relevant) information about the object.
Our characterization results may be summarized into four main findings. First, all four features but title ,havea non-negligible fraction of empty instances in at least two of the analyzed applications, and thus may not be effec-tive as single source of information for IR services. More broadly, restrictive features seem to be more often explored by users than collaborative ones, even within the same fea-Table 6: Average Similarity (Jaccard Coefficient) Between Non-Empty Feature Instances.
 ture category. Second, the amount of content tends to be larger in collaborative features. Third, the typically smaller and more often used title and tags exhibit higher descrip-tive and discriminative power, according to our AF S and AIF F heuristics, followed by description and comments . Finally, there is significant content diversity across features associated with the same object, indicating that each feature may bring different pieces of information about it.
In the next section, we assess the relative quality of the textual features when applied to a specific IR task, namely, object classification. We choose to focus on classification, leaving the analysis of other IR tasks for future work, for its common applicability to several services such as auto-matic construction of web directories and recommendation, as well as for allowing the automatic assessment of feature quality. The classification results are discussed in light of our characterization findings, as amount of content, descriptive and discriminative power have impact on the effectiveness of the feature as source of information for object classifica-tion. Moreover, the content diversity observed motivates the experimentation with feature combination strategies.
This section presents our object classification experiments, which use the collected categories, introduced in Section 4, as object labels. As discussed in that section, we focus our experiments on LastFM, Youtube and YahooVideo. In Sec-tion 6.1, we present the model adopted for object represen-tation, and define the various classification strategies con-sidered. Our experimental setup is described in Section 6.2, whereas the main results are discussed in Section 6.3.
In order to perform object classification, we first need to define a model to represent the objects. We adopt the vector space model (VSM), representing each object as a vector in a real-valued space whose dimensionality | V | is the size of the vocabulary of the object feature(s) being considered as in-formation source. Each term in the feature(s) is represented by a real value in the vector, which must, ideally, represent the degree of relationship between the term and the object it was assigned to. Once defined the object representation model, two important issues are: (1) how to determine the weight of each term in order to capture the semantics of the object, and (2) how to model the objects in the VSM using their distinct textual features. We considered the following term weighting schemes: TS :theweightofaterm t in an object o is equal to the TS  X  IFF :theweightof t is equal to the product TS ( t, o TF :theweightof t is given by the frequency of t in the TF  X  IFF : the weight is given by the product TF  X  IFF .
ThelasttwoschemesallowustocomparetheTSandthe more commonly used Term Frequency (TF) metrics.

We also examine six strategies to model an object o as a vector V , which is normalized so that || V || =1: Title : only terms present in the title of o constitute the Tags : V = V tags ,where V tags is the vector that represents Description : V = V desc. ,where V desc. is the vector that Comments : V = V comm ,where V comm is the vector that Bag of Words : all four features are taken as a single doc-Concatenation All textual features are concatenated in a
In each strategy, vector V is defined as w f 1 ,w f 2 , ..., w where w fi is the weight of term t in the instance of the considered feature f . In particular, vector V bagw is defined as w o 1 ,w o 2 , ..., w on where w oi is the weight of term the entire object. Note that, in this case, the IFF metric is equal to the more traditional IDF metric.

These strategies do not cover all possible combinations of features, but are useful to compare their quality for object classification. In particular, the last two strategies are mo-tivatedbytheresultsinSection5.4,andallowustoinves-tigate how textual features that are effective, when used in isolate, compare with the combination of multiple features.
Our classification experiments were performed using a Sup-port Vector Machine (SVM) algorithm with linear kernel implemented in the Liblinear tool [1]. This algorithm was selected because it is an efficient state-of-art classification algorithm for large samples of textual data, and because lin-ear kernels work particularly well for text classification tasks [11]. As before, we used our stemmed datasets, consider-ing only objects with non-empty instances of all features and classes associated, except in YahooVideo, for which the comments feature was disregarded. Moreover, as Figure 2 shows, some object classes are highly underpopulated in our datasets 18 . Thus, we choose to filter out all classes with a fraction of objects under than 2.2%, removing 8 and 4 classes from YahooVideo and Youtube, respectively.

Our experiments consisted of 10 runs, each with a distinct sample of 5000 objects from each application, using 10-fold cross-validation within each sample. Best SVM parameters (i.e., cost C ) were searched for within each training sample, being the default ( C =1) the best one in most cases.
We assess the quality of the features using two commonly used classification evaluation metrics, namely Macro-F1 and Micro-F1 . These metrics capture both precision and recall of the classification. Let TP , FP and FN be, respectively, the numbers of true positives, false positives and false negatives of the classification output for a class c . P recision is defined as the fraction of correctly classified objects of a class in relation to all objects that were assigned to that class, i.e., P recision = TP fraction of objects of a class that were assigned to that class by the classifier, that is, Recall = TP TP + FN .
P recision and Recall are combined into the F 1 metric classes are provided by Macro-F1 and Micro-F1 . Macro-F1 is defined as the average of the F 1 values over all classes,
The class names in Figure 2 are reduced due to space con-straints. We refer to Table 1 for their complete names. Table 7: Classification Results: Macro-F1 (Average and 90% Confidence Intervals).
 whereas Micro-F1 is computed using values of TP , FP and FN calculated as the sum of respective values for all classes.
We performed classification experiments combining each term weighting scheme with each feature or feature combina-tion object model. Initially we present the results obtained using the TS  X  IFF weighting scheme, as these are the heuristics proposed for assessing the descriptive and discrim-inative power of featureS. Tables 7 and 8 show the Macro-F1 and Micro-F1 values for each feature combination strategy.
Considering the results obtained when each feature is used in isolation as object representation, tags are, undoubt-edly, the best single feature in all applications, considering both Micro and Macro-F1 values. This is consistent with our characterization results which show that tags have: (1) good descriptive and discriminative power, according to our heuristics, with AF S and AIF F values close to those of title , and (2) at least twice more terms than title ,onav-erage, in the three applications. The larger amount of con-tent favors tags as source of information for the classifier, as SVM is known to work better in the presence of larger infor-mation (term) spaces [11]. This issue of amount of content may also explain the poor performance of title ,theworst feature in all applications, despite its AF S and AIF F val-ues being the largest ones. For example, instances of title in LastFM typically contain the name of the artist, which is usually very short. Regarding the other two features, com-ments is better than description in Youtube, consider-ing both metrics. In spite of the smaller AF S (descrip-tive power) and a somewhat similar AIF F (discriminative power), comments instances have, on average, more than 8 times more terms than description instances, which turns to be a dominant factor for the classification effectiveness. In contrast, we find that description outperforms comments in LastFM, in spite of the somewhat larger amount of con-tent, AF S and AIF F of the latter. Despite not completely supported by our characterization, this result may reflect the wiki-like collaborative nature of the description feature in LastFM, which brings a tendency for a high quality seman-tic content, a phenomenon also observed in Wikipedia [10]. This is an aspect involving social behavior not captured by our current metrics, and is subject of future work.
The Jaccard Coefficients presented in Section 5.4 suggests that there may exist distinct content in each feature which can be leveraged for classification purposes. This is con-firmed by the results of both feature combination strategies.
The tables also show that, in most cases, for a given feature (combination) strategy, the classification results in LastFM, for both Micro and Macro-F1, are much higher than in the other applications. This is possibly because LastFM object classes are defined by experts of the music Table 8: Classification Results: Micro-F1 (Average and 90% Confidence Intervals).
 industry, guaranteeing a higher level of consistency in the class assignments when compared to the other applications, in which individual users are responsible for the manual clas-sification. This problem is exacerbated if we consider that Youtube and YahooVideo have a larger number of classes, and some of them may have semantic overlap, making it even harder for users to determine to which class an object belongs. For example, a comedy video can be rightfully in-serted into either the  X  X ntertainment X  or the  X  X unny Videos X  category. Figure3showstheresultsofF1valuesperclass for both Tags and Concatenation strategies. Clearly, the classifier achieves higher F1 values in LastFM, being greater than 0.65 for all classes. Moreover, the results are more evenly distributed across classes. In contrast, in Youtube and YahooVideo, the F1 values can be as low as 0.27 and 0.33, being also more unevenly distributed.

Finally, we analyzed the impact of the different term weight-ing schemes, and found that, surprisingly, results do not dif-fer significantly. This finding is, at first sight, not in conso-nance with previous work [16, 9] which showed that weight-ing schemes based on IDF-like metrics may be detrimental to the effectiveness of some IR services because noisy and non-informative terms. Nevertheless, we should consider that SVM is robust to such terms, being capable of filtering some of them out in a feature selection manner [11].

In sum, we can conclude that: 1) tags , when present, is the best feature in isolation for classification purposes due to a combination of good descriptive and discriminative power and large amount of content; 2) combination of features may bring some benefits due to the presence of distinct but some-what complementary content; 3) terms in different feature instancesshouldbeconsideredintheiroriginalcontextinor-der to preserve their descriptive/discriminative power; 4) a combination of fewer classes, with less ambiguity, and more qualified human labelers, made classification more effective in LastFM than in the video applications; and 5) the use of different weighting schemes does not produce much differ-ence due to inherent properties of the SVM classifier.
We investigated issues related to the quality of textual features in Web 2.0 applications. To provide insights on the matter, we sampled data from title , description , tags and comments associated with objects in CiteULike, LastFM, YahooVideo and Youtube. Our characterization of the fea-tures revealed that collaborative features, including tags are absent in a non-negligible fraction of objects. How-ever, if present, they tend to provide more content than restrictive features, such as title . We also found that the smaller title and tags have higher descriptive and discrim-inative power, according to our adapted heuristics, and that there exists significant content diversity across features. As a case study, we also assessed the quality of features when applied to object classification. Our results show that tags if present, is the most promising feature. However, its ab-sence in a non-negligible fraction of objects in some applica-tions should be of concern. Moreover, we found that com-bining content from all features can lead to classification improvements. Though widely present and highly ranked according to both descriptive and discriminative heuristics, the title feature achieved the worst classification results, being severely impacted by the small amount of content.
Future work includes further investigation of feature qual-ity issues in classification and other IR services, correlating our results with social network aspects, and exploring fea-ture quality enhancement strategies. Flavio Figueiredo and Jussara Almeida are sponsored by UOL (www.uol.com.br), through its UOL Bolsa Pesquisa program, process number 20090215103600. This research was also partially funded by the Brazilian National Institute of Science and Technology for Web Research (MCT / CNPq / INCT Web Grant Number 573871/2008-6), by project REBU (MCT / CNPq / CTInfo Grant Number 550995 / 2007-2) and by project Infoweb (MCT / CNPq / CTInfo Grant Number 55.0874 / 2007-0). [1] Liblinear: A library for large linear classification. J. [2] E. Agichtein, C. Castillo, D. Donato, A. Gionis, and [3] K. Bischoff, F. Claudiu-S, N. Wolfgang, and [4] S. Boll. MultiTube X  X here Web 2.0 and Multimedia [5] L. Chen, P. Wright, and W. Nejdl. Improving music [6] D. Fernandes, E. de Moura, B. Ribeiro-Neto, [7] S. Golder and B. Huberman. Usage Patterns of [8] L.A.Goodman.SnowballSampling. Annals of Math. [9] T. Haveliwala, A. Gionis, D. Klein, and P. Indyk. [10] M. L. E. Hu, A. Sun, H. Lauw, and B. Vuong.
 [11] T. Joachims, C. Nedellec, and C. Rouveirol. Text [12] X.Li,L.Guo,andY.Zhao.Tag-basedSocialInterest [13] C. Marlow, M. Naaman, D. Boyd, and M. Davis. [14] C. Marshall. No Bull, No Spin: A comparison of tags [15] G. Mishne. Using blog properties to improve retrieval. [16] D. Ramage, P. Heymann, C. Manning, and [17] M. Rege, M. Dong, and J. Hua. Graph Theoretical [18] R. Schenkel, T. Crecelius, M. Kacimi, S. Michel, [19] B. Sigurbjornsson and R. van Zwol. Flickr Tag [20] F. Suchanek, M. Vojnovic, and D. Gunawardena.
