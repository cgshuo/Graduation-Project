 Robert Gens rcg@cs.washington.edu Pedro Domingos pedrod@cs.washington.edu Graphical models can compactly represent many com-plex distributions, but inference in them is generally intractable (Roth, 1996). Deep architectures, with many layers of hidden variables, are particularly ex-pressive, but inference in them is correspondingly more difficult (Bengio, 2009). Recently, Poon and Domingos (2011) turned this around by introducing sum-product networks (SPNs), a class of models where adding lay-ers increases expressiveness without losing tractabil-ity. SPNs are defined recursively, as weighted sums and products of smaller SPNs, with univariate distri-butions as the base case. SPNs have many interesting and important classes of probabilistic models as special cases, including mixture models, thin junction trees, non-recursive probabilistic context-free grammars, and others. They are also significantly more general than each of these. SPNs X  combination of expressiveness and tractability makes them potentially a very attrac-tive representation for many applications. In particu-lar, they have achieved impressive results in several vision problems (Poon &amp; Domingos, 2011; Amer &amp; Todorovic, 2012; Gens &amp; Domingos, 2012).
 Given the structure of an SPN, its weights can be learned generatively or discriminatively. For the gen-erative case, Poon and Domingos (2011) proposed an online hard EM algorithm, where each example is pre-sented in turn to the SPN and the weight of each sum node X  X  MAP child is incremented. They showed that this algorithm can successfully learn very deep SPNs, but they used a pre-defined SPN structure that was both expensive to learn (because of the large number of nodes) and insufficiently flexible (because the best nodes were often not in the predefined structure). For the discriminative case, Gens and Domingos (2012) proposed a backpropagation-style gradient descent al-gorithm which obtained state-of-the-art results on im-age classification problems, but again faced a trade-off between flexibility and cost of learning.
 This trade-off can be avoided, or at least ameliorated, by learning the structure of the SPN from data. How-ever, the only algorithm for SPN structure learning to date, proposed by Dennis and Ventura (2012), is quite limited. It essentially forms a set of hierarchical clus-terings of the variables and builds the SPN based on them, and as a result is not able (except at the root) to take advantage of the context-specific independences that are crucial to SPNs X  expressiveness. It clusters variables that have similar values in similar instances, and is therefore prone to splitting highly dependent variables, causing a large loss of likelihood. (For ex-ample, if X is the negation of Y , they will never be clustered.) The cost of learning and size of the SPN are worst-case exponential (order of the number of sum nodes raised to the number of sub-regions in a region of the SPN). The number of sum nodes in a region is a fixed input parameter, and not learnable. Weights are learned as a post-processing step, and cannot be optimized during structure learning. The algorithm is quite complex and ad hoc , with no guarantee of finding even a local optimum of the likelihood, and no sense of how good the output SPN is. It has only been tested on an image completion task.
 SPNs are related to multilinear formulas (Raz, 2004), arithmetic circuits (Darwiche, 2003), AND-OR graphs (Dechter &amp; Mateescu, 2007), and other compact repre-sentations. Lowd and Domingos (2008) and Gogate et al. (2010) proposed algorithms for learning tractable models that are related to SPNs but more restricted. Lowd and Domingos X  algorithm learns a Bayesian net-work with context-specific independence using the net-work X  X  inference cost as the regularization penalty. Gogate et al. learn tractable high-treewidth Markov networks by recursively searching for features that split the remaining variables into approximately in-dependent subsets.
 In this paper, we propose the first algorithm for learn-ing the structure of SPNs that does not sacrifice any of their expressiveness. We start by introducing a sim-plified definition of SPN that incorporates Poon and Domingos X  conditions for tractability, avoids the use of indicator functions and network polynomials, and generalizes more easily to continuous variables. Our algorithm takes advantage of it by having a recursive structure that parallels the recursive structure of the definition. It can be viewed as an intimate combina-tion of mixture model EM (for learning sum nodes) and graphical model structure learning (for learning product nodes). We test our algorithm on a large num-ber of datasets from a wide variety of domains. Sur-prisingly, the learned SPNs typically have comparable likelihoods to unrestricted graphical models learned on the same data. At inference time they dominate in both speed and accuracy. The scope of an SPN is the set of variables that appear in it. A univariate distribution is tractable iff its par-tition function and its mode can be computed in O (1) time.
 Definition 1 A sum-product network (SPN) is de-fined as follows. 1. A tractable univariate distribution is an SPN. 2. A product of SPNs with disjoint scopes is an SPN. 3. A weighted sum of SPNs with the same scope is 4. Nothing else is an SPN.
 It would be straightforward to relax Part 2 of this def-inition to allow for non-decomposable but consistent SPNs, as in Poon and Domingos (2011), but there is no advantage in doing it for this paper X  X  purposes. An SPN can be represented as a rooted directed acyclic graph with univariate distributions as leaves, sums and products as internal nodes, and the edges from a sum node to its children labeled with the corresponding weights. The sub-SPN S i rooted at a node i represents a probability distribution over its scope. For simplic-ity, we focus on the case of SPNs over discrete vari-ables, but the extension to continuous ones is straight-forward.
 Let x = ( x 1 ,...,x d )  X  X be a state. The unnormal-ized probability S ( x ) of x according to the SPN S is the value of S  X  X  root when each leaf is set to the prob-ability of the corresponding variable X  X  value in x . The partition function of an SPN is Z = P x  X  X  S ( x ). The normalized probability of x is P ( x ) = S ( x ) /Z . It is easily seen that, if the weights at each sum node sum to one and the leaf distributions are normalized, then Z = 1 and P ( x ) = S ( x ).
 Theorem 1 The following quantities can be computed in time linear in the number of edges in an SPN. 1. The partition function of the SPN. 2. The probability of evidence in the SPN. 3. The MAP state of the SPN.
 Proof. The proof is recursive, starting from the leaves of the SPN. By definition, the partition func-tion of a leaf distribution can be computed in O (1) time. Let Z i be the partition function of node i , and Z ij the partition functions of its children. Let X i be the set of possible states of i  X  X  scope, and similarly for X ij . If i is a product node, its partition function is Z i = P x P Q its partition function is Z i = P x P P the weight of the i th child. Therefore the partition function of a node can be computed in time linear in its number of children, and the partition function of the root can be computed in time linear in the number of edges in the SPN.
 The probability of evidence in an SPN S is just the ratio of the partition functions of S 0 and S , where S 0 is an SPN obtained from S by replacing the univari-ate distributions over the evidence variables by delta functions centered on the evidence values. Therefore it can also be computed in linear time.
 The (or an) MAP state of an SPN can be computed as follows: (1) replace sum nodes with max nodes; (2) evaluate the SPN from the leaves to the root in a manner identical to computing the partition function; (3) starting from the root and following all children of each product node, for each sum node S i choose the (or a) child with highest value of w ij M ij , where M ij is the child X  X  value computed in the previous step; (4) at each leaf node, choose the (or a) mode of the corresponding distribution. The total number of operations is thus also linear in the size of the SPN. The method we propose for learning SPN structure is summarized in Algorithm 1 and illustrated in Figure 1. LearnSPN inputs an i.i.d. sample of a vector-valued variable, in the form of a matrix of instances by vari-ables. If the vector is of unit length, LearnSPN returns the corresponding univariate distribution, with MAP estimates of the parameters. For example, for discrete variables the distribution may be a multinomial with Dirichlet prior, and for continuous ones it may be a normal with normal-Wishart prior. If the vector is of length greater than one, LearnSPN recurses on subma-trices with either fewer rows or fewer columns. If it is able to split the variables into mutually independent subsets, it recurses on those, and returns the prod-uct of the resulting SPNs. Otherwise, it clusters the instances into similar subsets, recurses on those, and returns the weighted sum of the resulting SPNs. The weight of an SPN is the fraction of instances in the corresponding subset; it can also be smoothed using a Dirichlet prior.
 Algorithm 1 LearnSPN( T,V ) input: set of instances T and set of variables V output: an SPN representing a distribution if | V | = 1 then else end if If there are no detectable dependencies among the vari-ables, LearnSPN returns a fully factorized distribu-tion. At the other extreme, if LearnSPN always fails to find independent subsets of variables until | T | = 1 (at which point all variables are independent), it returns a kernel density estimate of the distribution (Parzen, 1962). More typically, if | T | | V | LearnSPN will likely split on subsets of instances, and if | V | | T | it will likely split on subsets of variables. Crucially, LearnSPN can choose different variable splits for dif-ferent sets of instances, resulting in tractable models with few or no conditional independences.
 LearnSPN is an algorithm schema rather than a single algorithm. It can incorporate a variety of methods for splitting variables and instances into subsets. In par-ticular, instances can be clustered using the EM algo-rithm (Dempster et al., 1977), and this is the method we will use in the rest of this paper. At each splitting step, we assume a naive Bayes mixture model, where all variables are independent conditioned on the clus-ter: P ( V ) = P i P ( C i ) Q j P ( X j | C i ) , where C i th cluster and X j is the j th variable. For soft EM, where instances can be fractionally assigned to clus-ters, T needs to be extended with a weight for each instance, and each instance is passed to each cluster it has nonzero weight in. However, this is consider-ably less efficient than hard EM, where each instance is wholly assigned to its most probable cluster, and we will use the latter method. In either case, the learned SPN weights are now the mixing proportions P ( C i ). We use online EM with restarts, which automatically determines the number of clusters by assigning each new instance to its most likely cluster, possibly a new one. Overfitting is avoided via an exponential prior on the number of clusters.
 Under this scheme, we can see that at each instance splitting step LearnSPN( T,V ) locally maximizes the posterior probability of the sub-SPN over ( T,V ). The mixture model X  X  posterior is also a lower bound on the posterior of the SPN that LearnSPN will ultimately return for ( T,V ), since the posterior can only increase when the recursive calls attempt to model dependen-cies between variables within each cluster.
 An alternative to clustering instances is to split them according to the value of a specific variable or subset of variables. The best variables to split on can be chosen using a mutual information criterion. This results in an algorithm similar to Gogate et al. X  X  (2010) and with some of the flavor of learning graphical models with context-specific independence.
 Variable splits can also be found in a number of ways. Since mutual information is a submodular function, Queyranne X  X  algorithm can be used to find in cubic time a split of the variables into two subsets with min-imum empirical mutual information (Queyranne, 1998; Chechetka &amp; Guestrin, 2008). However, we have found this to be too slow in practice. Alternatively, we can consider only pairwise dependencies. In this case, we can apply an independence test to each pair of vari-ables, form a graph with an edge between each pair of variables found to be dependent, and recurse on each connected component. If the graph has only one con-nected component, the variable split fails, and Learn-SPN proceeds to form an instance split.
 Let an independence oracle be an independence test that declares two variables X 1 and X 2 to be indepen-dent iff all subsets of variables V 1 3 X 1 and V 2 3 X 2 are independent. Using such an oracle, factorizing the sub-SPN into the connected components found causes no loss of likelihood. Let a granularity sequence be a choice of the number of clusters at each step of LearnSPN, and assume LearnSPN uses soft EM for instance clustering and maximum likelihood estimates for univariate distributions. Then LearnSPN returns a locally optimal SPN, in the sense that no higher-likelihood SPN can be reached from it by a local repar-tition of variables or instances. This can be summa-rized in the following proposition.
 Proposition 1 Given a granularity sequence, Learn-SPN with an independence oracle for variable splitting and EM for instance clustering returns a locally max-imum likelihood SPN. We evaluated LearnSPN on twenty real-world datasets and compared with popular graphical model structure learning algorithms. This is a much greater number of datasets than is typical in empirical evaluations of graphical model structure learning. The diverse set of domains includes click-through logs, plant habi-tats, nucleic acid sequences, collaborative filtering, and many others. The number of variables in a dataset ranges from 16 to 1556, and the number of instances varies from 2k to 388k.
 We used the WinMine toolkit (Chickering, 2002) to learn Bayesian network structure. WinMine allows context-specific independence in the form of a deci-sion tree at each node (Chickering et al., 1997), and is the most sophisticated graphical model structure learning package available. For Markov network struc-ture learning, we ran algorithms by Della Pietra et al. (1997) and Ravikumar et al. (2010). The Della Pietra et al. algorithm is the canonical Markov network struc-ture learner. Ravikumar et al. learns structure by in-ducing sparsity in a large set of weights with an L1 penalty.
 The dimensions of the datasets are detailed in Ta-ble 1. We used discrete datasets because the three comparison systems do not support continuous vari-ables. Thirteen of the datasets were processed by Lowd and Davis (2010); seven were assembled by Van Haaren and Davis (2012). We used the authors X  train-validation-test splits, where most datasets reserve 10% of instances for validation and 15% for testing. 4.1. Learning To cluster instances, we used hard incremental EM (Neal &amp; Hinton, 1998) over a naive Bayes mixture model with the exponential prior P ( S )  X  e  X   X C | V | where C is the number of clusters and  X  is the cluster penalty. We ran ten restarts through the subset of in-stances T four times in random order. We estimated P ( X j | C i ) with Laplace smoothing, adding 0.1 to each count.
 For variable splits, we used a G-test of pairwise inde-pendence: G ( x 1 ,x 2 ) = 2 P where the summations range over the values of each variable and c (  X  ) counts the occurrences of a setting of a variable pair or singleton (Woolf, 1957). For each dataset, the cluster penalty  X  and G-test significance p were chosen based on validation set performance 1 . We compared with Bayesian networks learned by the WinMine toolkit on test set log-likelihood (LL). We chose WinMine X  X  per-parameter penalty  X  according to validation set likelihood.
 Since computing likelihood is intractable for the learned Markov networks, we instead compared test set pseudo-log-likelihood (PLL). This comparison greatly favors the Markov networks since they are trained to optimize PLL, and PLL is known to be a poor surrogate for likelihood. The methods of Della Pietra et al. (1997) and Ravikumar et al. (2010) are denoted as DP and L1, respectively. For DP, struc-ture was learned using the open source code of Davis and Domingos (2010). L1 structure was learned using the OWL-QN package (Andrew &amp; Gao, 2007) for L1 logistic regression. Weights were learned by optimiz-ing PLL with the limited-memory BFGS algorithm. Markov networks with learned structure and weights were provided by Van Haaren and Davis (2012).
 Table 2 shows the log-likelihood and pseudo-log-likelihood of learned methods. In all tables, bold in-dicates p =0 . 05 significance on a paired t-test. For a majority of datasets, the SPN X  X  likelihood is not sig-nificantly different from WinMine X  X  likelihood. SPN PLL is also comparable to DP and L1 on more than half of the datasets, even though those systems have the advantage of directly optimizing it. Presumably, if the Markov networks X  likelihoods could be measured, they would be systematically worse than the SPNs X . LearnSPN X  X  learning times ranged from 4m to 12h, WinMine X  X  from 1s to 10m, DP X  X  from 16m to 24h, and L1 X  X  from 9s to 6h. The current implementation of LearnSPN could be made faster in a number of ways, such as reusing counts, as is done in WinMine. 4.2. Inference High likelihood is not very useful if approximate infer-ence hurts accuracy at query time. In this section we test the speed and accuracy of the learned models at query time, where the goal is to infer the probability of a subset of the variables (the query) given the values of another (the evidence).
 We generated queries from the test set of each dataset, varying the fraction of randomly selected query and evidence variables. For each proportion of query and evidence variables (e.g., 10% query, 30% evi-dence), a thousand instances were randomly selected from the test set. For each selected test instance, a query P ( Q = q | E = e ) was created by randomly choos-ing the appropriate fraction of variables and assign-ing their values. We report the average conditional log-likelihood (CLL) of the queries given the evidence, which approximates the KL-divergence between the in-ferred probabilities and the true ones, sampling from the test set. We normalize the CLL by the num-ber of query variables to facilitate comparison among datasets and query proportions.
 The SPN performs exact inference in time linear in the number of edges. Since exact inference is intractable for the learned graphical models on these domains, we used Gibbs sampling as implemented by the open source Libra package (Lowd). We used the Libra de-fault of 1000 samples with 100 iterations of burn-in. As detailed in Table 3, SPNs are two orders of mag-nitude faster and significantly more accurate. We also ran Gibbs sampling with more chains and iterations; even when we allowed Gibbs sampling a factor of 10 or 100 more time, it did not close the gap in accuracy. In Figure 5, for each of several representative datasets we plot graphs of normalized CLL where the fraction of query or evidence variables is varied. When query proportion is varied, evidence is fixed at 30%, and vice-versa. The learned SPNs have much higher CLL, a disparity that becomes more pronounced with longer queries and larger datasets.
 To be sure that the difference between SPNs and the other methods was not just due to Gibbs sam-pling, we also tried using loopy belief propagation (BP). This only computes single-variable marginals, so we measured the conditional marginal log-likelihood (CMLL) instead of CLL: CMLL ( X = x | e ) = P x i  X  Q log P ( X i = x i | e ), where Q is the set of query variables and e is the set of evidence variable val-ues. We ran the same set of inference tasks as de-tailed above for the ten variable proportions presented in the graphs, running loopy BP 2 for the Bayesian and Markov networks and measuring CMLL for all models. Averaged across the ten proportions, SPNs achieved higher CMLL than WinMine on 11 datasets, 17 com-pared with DP, and 16 compared with L1. This is re-markable, considering that the PLL training of Markov networks naturally pairs with testing CMLL.
 Overall, these experiments show that learning SPNs is a very attractive alternative to learning graphical models. In learning accuracy, SPNs were comparable to Bayesian networks on most data sets, and compara-ble to or better than Markov networks. For inference accuracy and speed, SPNs are clearly the representa-tion of choice. Further, inference in SPNs does not involve tuning settings or diagnosing convergence as with MCMC or BP, and an SPN predictably takes the same amount of time to compute any query. Sum-product networks (SPNs) compactly represent all marginals of a distribution, in contrast to graphical models, which compactly represent only the probabil-ities of complete states. As a result, inference in SPNs is always tractable. In this paper, we proposed a sim-ple schema for learning SPN structure from data. Our algorithm recursively splits an SPN into a product of SPNs over independent sets of variables, if they can be found, or into a sum of SPNs learned from sub-sets of the instances, otherwise. In experiments on a large number of datasets, the SPNs obtained were typically comparable in likelihood to graphical mod-els, but inference in them was much faster, and also more accurate.
 Directions for future work include large-scale appli-cations of SPNs, further algorithms for SPN struc-ture and weight learning, SPNs with multivariate leaf distributions, approximating intractable distributions with SPNs, relational SPNs, and parallelizing SPN learning and inference.
 Code and supplemental results are available at http://spn.cs.washington.edu/learnspn/.
 Amer, M. R. and Todorovic, S. Sum-product networks for modeling activities with stochastic structure. In CVPR , 2012.
 Andrew, G. and Gao, J. Scalable training of L1-regularized log-linear models. In ICML 24 , 2007. Bengio, Y. Learning deep architectures for AI. Foun-dations and Trends in Machine Learning , 2:1 X 127, 2009.
 Chechetka, A. and Guestrin, C. Efficient principled learning of thin junction trees. In NIPS 20 , 2008. Chickering, D. M. The WinMine Toolkit. Microsoft, Redmond, WA MSR-TR-2002-103 , 2002.
 Chickering, D. M., Heckerman, D., and Meek, C. A
Bayesian approach to learning Bayesian networks with local structure. In UAI 13 , 1997.
 Darwiche, A. A differential approach to inference in Bayesian networks. JACM , 50:280 X 305, 2003.
 Davis, J. and Domingos, P. Bottom-up learning of Markov network structure. In ICML 27 , 2010.
 Dechter, R. and Mateescu, R. AND/OR search spaces for graphical models. AIJ , 171:73 X 106, 2007.
 Della Pietra, S., Della Pietra, V., and Lafferty, J. In-ducing features of random fields. PAMI , 19:380 X 392, 1997.
 Dempster, A. P., Laird, N. M., and Rubin, D. B. Max-imum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B , 39:1 X 38, 1977.
 Dennis, A. and Ventura, D. Learning the architecture of sum-product networks using clustering on vari-ables. In NIPS 25 , 2012.
 Gens, R. and Domingos, P. Discriminative learning of sum-product networks. In NIPS 25 , 2012.
 Gogate, V., Webb, W., and Domingos, P. Learning efficient Markov networks. In NIPS 23 , 2010. Lowd, D. The Libra Toolkit. URL http://libra. cs.uoregon.edu/ . Version 0.5.0, 2012.
 Lowd, D. and Davis, J. Learning Markov network structure with decision trees. In ICDM 10 , 2010. Lowd, D. and Domingos, P. Learning arithmetic cir-cuits. In UAI 24 , 2008.
 Neal, R.M. and Hinton, G.E. A view of the EM algo-rithm that justifies incremental, sparse, and other variants. NATO ASI SERIES D: Behavioural and Social Sciences , 89:355 X 370, 1998.
 Parzen, E. On estimation of a probability density func-tion and mode. The Annals of Mathematical Statis-tics , 33(3):1065 X 1076, 1962.
 Poon, H. and Domingos, P. Sum-product networks: A new deep architecture. In UAI 27 , 2011.
 Queyranne, M. Minimizing symmetric submodular functions. Math. Programming , 82(1):3 X 12, 1998. Ravikumar, P., Wainwright, M. J., and Lafferty, J. D.
High-dimensional ising model selection using L1-regularized logistic regression. The Annals of Statis-tics , 38(3):1287 X 1319, 2010.
 Raz, R. Multi-linear formulas for permanent and de-terminant are of super-polynomial size. In STOC 36 , 2004.
 Roth, D. On the hardness of approximate reasoning. AIJ , 82:273 X 302, 1996.
 Van Haaren, J. and Davis, J. Markov network struc-ture learning: A randomized feature generation ap-proach. In AAAI 26 , 2012.
 Woolf, B. The log likelihood ratio test (the G-test). Annals of Human Genetics , 21(4):397 X 409, 1957.
CLL
CLL
CLL
CLL
CLL
CLL
