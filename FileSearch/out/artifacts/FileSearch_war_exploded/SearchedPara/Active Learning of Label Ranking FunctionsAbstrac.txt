 Klaus Brinker kbrinker@uni-paderborn.de Germany The increasing shift from predetermined and static to personalized and highly adaptive systems has af-fected various areas of application. Techniques to in-dividualize application flows and to incorporate user preferences have produced more efficient systems in the domains of e-commerce (Riecken, 2000), informa-tion retrieval and design of user interfaces (Langley, 1997), among others. A fundamental prerequisite of systems which consider individuals rather than prede-fined standard users is the ability to efficiently acquire accurate preference models.
 We consider a special category of preference learning problems, so-called (label) ranking problems . The fun-damental objective is to learn a mapping from a given input space to the set of total orders over a finite and a priori fixed set of alternatives (labels) . For exam-ple, suppose we are given a set of customers which are represented by features (such as age, income, family status, etc.) and their ordered preferences over a set of car models { Porsche, Toyota, Ford, Lada } . Then, the learning task consists in inducing a mapping from cus-tomers to the set of permutations of these car models. We can employ the induced ranking function to predict the order of preference for new customers. In contrast to a classification setting, we are not only interested in the top-ranked alternative but in the complete prefer-ence order. By incorporating this additional informa-tion, we can build more powerful prediction systems which, for instance, are able to make preference sug-gestions in situations where the top-ranked alternative is currently not available for some reason.
 As in the case of multiclass classification, there ex-ist different approaches to reduce ranking problems to binary classification problems. As a straightforward generalization of one-against-one (multiclass) classifi-cation, ranking problems can be decomposed into bi-nary classification problems considering all pairwise preferences between two alternatives (F  X urnkranz &amp; H  X ullermeier, 2003). Each pairwise preference prob-lem is treated independently as a binary classification problem and predictions are made by means of a vot-ing procedure. An alternative approach to the expres-sion of a ranking problem in terms of a single binary classification problem has been proposed by Har-Peled et al. (2002). Transforming the initial ranking prob-lem both involves embedding the training data in a higher dimensional space and expanding single ranking examples into multiple binary classification examples. Both approaches consider the problem of learning a ranking function in a supervised batch learning sce-nario. Hence, it is assumed that we are given a train-ing set of examples associated with the corresponding permutations. However, there are many applications in which assigning permutations to examples (herein after referred to as labeling in compliance with stan-dard notation) cannot be performed automatically but involves human decisions or costly interviews. There-fore, it is a time-consuming and expensive task. While this already constitutes a major issue in classification learning, it becomes an even more serious problem when dealing with the more complex target domain of the set of permutations: To ask for a customer X  X  top preference is less expensive than to request a complete preference order over all possible alternatives. The superordinate concept of active learning refers to a collection of approaches that aim at reducing this labeling effort (see section 5 for a more detailed dis-cussion). We consider the pool-based active learning model 1 (Lewis &amp; Gale, 1994): Starting with only a small amount of labeled examples, the learning algo-rithm sequentially selects new examples from a finite set of unlabeled examples and requests the correspond-ing permutations. The crucial point is that by select-ing only the most informative examples to be labeled, in many applications it is possible to learn a model by using fewer labeled examples without a significant loss of generalization accuracy in comparison to conven-tional batch learning based on the entire set of labeled examples.
 In the field of kernel machines, active learning has been successfully applied to classification problems to re-duce the labeling effort (Tong &amp; Koller, 2000; Camp-bell et al., 2000; Warmuth et al., 2002). All these approaches are restricted to either binary or multi-class classification problems and do not extend to rank-ing problems. We propose a novel extension of active learning to ranking problems. Considering both pair-wise decomposition (F  X urnkranz &amp; H  X ullermeier, 2003) and the constraint classification technique (Har-Peled et al., 2002), we propose heuristic strategies to the se-lection of new training examples. Experimental results indicate a significant reduction of the labeling effort. This paper is organized as follows: The subsequent section discusses the above stated techniques to ex-press and train ranking functions. In section 3, we investigate active learning in the case of ranking prob-lems and introduce our novel generalization. Section 4 discusses experimental results conducted on a number of synthetic datasets and demonstrates the benefits of our approach. In section 5, we point out references to related research and finally give a conclusion. This section recapitulates two techniques to solve ranking problems. Formally, the learning problem that we are investigating can be stated as follows: Based on a given training set of labeled examples with X denoting a nonempty set and S ( d ) being the symmetric group of degree d , i.e. a function to the prediction of new examples. In other words, the objects to be learned are total orders over a finite and a priori fixed set of alternatives which are rep-resented as permutations. A permutation y is inter-preted as follows: If alternative i precedes alternative j in y , then i is preferred over j . This representation is based on the reasonable assumption that the order over the set of labels is irreflexive and anti-symmetric (for a more detailed discussion see (F  X urnkranz &amp; H  X ullermeier, 2003)).
 Both to increase expressivity and to make use of (typi-cally) highly accurate base classifiers, we embed exam-ples from input space X using a kernel k : X  X X  X  R . The corresponding kernel feature space is denoted by F and the feature map by  X  : X  X  F (Sch  X olkopf &amp; Smola, 2002). 2.1. Constraint Classification The constraint classification approach (Har-Peled et al., 2002) provides a framework to solve a variety of more complex learning problems, such as ranking and multilabel problems, based on (binary) linear classi-fiers. We restrict our discussion to ranking problems in the linear case, i.e. X = R n endowed with the canon-ical dot product  X  X  ,  X  X  to avoid a lengthy and rather technical presentation. Later on we will comment on how to integrate the concept of kernels.
 Let us consider the class of linear sorting functions : with w 1 , . . . , w d  X  R n denoting weight vectors of lin-ear functions and argsort returning a permutation of { 1 , . . . , d } where i precedes j if  X  w i , x  X  &gt;  X  w the case of equality, i precedes j if i &lt; j ). Transforming the initial ranking problem both involves embedding the training data in a higher dimensional space and expanding single ranking examples into mul-tiple binary classification examples: Let v ( x, i ) de-note an embedding of x in R nd such that the fea-( i  X  1) n + 1 , . . . , i n of the augmented vector and the remaining features are set to 0.
 We expand ( x, y ) into a set T + ( x, y ) of d  X  1 positive binary classification examples in R nd  X  { X  1 , +1 }
T + ( x, y ) = [ and a set of d  X  1 negative examples
T  X  ( x, y ) = [ The transformed training set T 0 is defined as the union of all expanded examples: Suppose we apply an arbitrary learning algorithm to the training set T 0 that calculates a separating hy-perplane h ( x ) =  X  w , x  X  with w  X  R nd . Further-more, we consider w as the concatenation of d n -dimensional vectors w 1 , . . . , w d and by this means de-fine a linear sorting function f : R n  X  S ( d ) . Since h is a separating hyperplane, it follows that for all ( t, +1) = v ( x, [ y ] i )  X  v ( x, [ y ] i +1 ) , +1  X  T Hence, the linear sorting function f correctly arranges the alternatives [ y ] i and [ y ] i +1 . Since all constraints on consecutive alternatives are encoded as (positive) bi-nary examples, f is consistent with the original rank-ing training set. In fact, to ensure consistency in this case, we do not need the expansion into negative exam-ples. While the expansion into both positive and nega-tive examples makes this framework applicable regard-less of the underlying training algorithm, we can ex-ploit the fact that the training set is symmetric around the origin. In the case of support vector machines, the one-class algorithm proposed by Sch  X olkopf et al. (2001) can be modified in a straightforward fashion to work on the positive set only. However, we do not make use of this modification because our reasoning is based on a C  X  parametrization whereas (Sch  X olkopf et al., 2001) use a  X   X  parametrization.
 Apart from theoretical analysis, one should not im-plement the constraint classification framework by ex-plicitly expanding examples. It is more efficient to store constraints imposed by consecutive alternatives and references to original examples in expanded ex-amples and make use of a suitable (meta-)kernel. Fur-thermore, the standard kernelization technique can be incorporated at this place. 2.2. Pairwise Ranking Pairwise ranking (F  X urnkranz &amp; H  X ullermeier, 2003) is a generalization of one-against-one (multiclass) clas-sification which learns a separate binary classifier for each of the d ( d  X  1) / 2 pairs of alternatives. Each bi-nary classifier h ij (with 1  X  i &lt; j  X  d ) decides for a given example whether alternative i or j is preferred. The training set for h ij consists of the complete set of feature vectors x 1 , . . . , x m with the class label y of each example ( x, y ) being assigned depending on whether i precedes j in y or vice versa.
 To predict a new ranking, we determine the classifi-cations of all binary classifiers h ij ( x )  X  { X  1 , +1 } and interpret the outcome as a vote for alternative i or j . Finally, all possible alternatives are sorted in descend-ing order with respect to the sum of votes. In the case of ties, though it might be suboptimal, we prioritize al-ternatives with smaller indices. Formally, this strategy can be stated as follows: x 7 X  argsort Pairwise ranking provides a framework that is applica-ble without any further assumptions on the underly-ing binary classifier. We consider support vector ma-chines as base classifiers. Whenever there is a close decision between two alternatives, i.e. the given ex-ample is close to the classification boundary, it is not necessarily a clever strategy to assign a complete vote to one of them. Therefore, in addition to the above stated standard voting strategy , we investigate a mod-ified strategy: Using an approach proposed by Platt (1999), we estimate posterior (positive) class proba-bilities h 0 ij ( x )  X  [0 , 1] instead of class labels and assign partial votes to both alternatives: We refer to this method as probabilistic voting . This section introduces novel heuristic active learning criteria for both the constraint classification and the pairwise decomposition technique.
 We derive a selection criterion for the constraint clas-sification method based on the version space model for binary classification problems: Let us consider a linearly separable (in feature space) binary classifica-tion problem. Note that we can deal with noisy, lin-early nonseparable data in an elegant way by adding some constant  X  &gt; 0 to the diagonal elements of the kernel matrix, k ( x i , x j ) +  X  ij  X  , such that the training set becomes linearly separable when using the L2-loss (Shawe-Taylor &amp; Cristianini, 1999).
 The nonempty set which consists of all (normalized) weight vectors cor-responding to linear classifiers in feature space which separate the training set without errors is called ver-sion space (Mitchell, 1982). We can view learning as a search problem within version space: Each train-ing example ( x i , y i ) limits the volume of the version space because to correspond to a consistent classifier a weight vector has to satisfy In other words, consistent solutions are restricted to a halfspace whose boundary is the hyperplane with nor-mal vector y i  X  ( x i ). For a fixed feature vector  X  ( x the class label y i determines the orientation of the half-space. Moreover, V is the intersection of m halfspaces (a convex polyhedral cone) with the unit sphere in fea-ture space F .
 A classical result from the theory of convex sets states that any halfspace containing the center of mass of a convex set comprises at least 1 /e of the overall vol-ume (Gr  X unbaum, 1960). Assume we are able to re-peatedly select unlabeled examples which correspond to restricting hyperplanes passing exactly through the current center of mass of version space w center . Then, independent of the actual class label, the volume of version space is reduced exponentially in terms of the number of labeled examples. 2 To derive a practical selection criterion, we have to make a number of approximations: It is computation-ally expensive to calculate the center of mass in high dimensional spaces. Therefore, the center of mass is approximated by the center of the largest radius ball  X  w center in version space. When working on a normal-ized set of examples, this approximation corresponds to a support vector machine. Moreover, since we are only given a finite set of unlabeled examples to choose from, mostly we will not be able to find an example which exactly meets the above stated criterion. Hence, we select that unlabeled example whose restricting hy-perplane is closest to the approximation of the cen-Assume that the requested example is labeled such that the larger part of the current version space re-mains. The ratio of volume reduction still approaches at least 1  X  1 /e the closer the restricting hyperplane to the center of mass. For a convex set in isotropic position, any halfspace at distance t from the center of mass contains at least 1 e  X  t of its volume (Bertsi-mas &amp; Vempala, 2002). Based on analogous reasoning, can be considered as an approximate measure of the reduction of volume where lower values correspond to a higher reduction and negative values correspond to the case where the smaller part of the version space re-mains. Considering a best worst-case approach, we ob-selection criterion which is a reformulation of the for-mer criterion in the binary case. Apart from the ver-sion space model which has been considered in (Tong &amp; Koller, 2000), there are additional theoretical justi-fications for this approach (Campbell et al., 2000). Coming back to the constraint classification frame-work, the notion of the margin can be generalized in a straightforward fashion as the minimum margin within the set of expanded binary examples (Har-Peled et al., 2002): Definition (Generalized Margin). The margin  X  : X  X  S ( d )  X  R of a ranking example ( x, y ) with re-spect to the linear sorting function f is defined as  X  ( x, y ) = min If a support vector machine is used as the component learner on the expanded binary training set to solve the corresponding ranking problem, it maximizes this gen-eralized margin. Moreover, this definition reduces to the standard margin for ranking problems with d = 2 (which can be considered as binary classification prob-lems).
 It is straightforward to derive an upper bound on the margin of a ranking example ( x, y ):  X  ( x, y )  X  max Note that this bound is tight in the sense that for every x there exists a y such that equality holds in (1): If and only if y = argsort i =1 ,...,d  X  w i , x  X  , then  X  ( x, y ) =  X  Therefore, given an unlabeled example x ,  X  + ( x ) evalu-ates to the worst-case margin for all choices of y  X  S ( d ) Now, in a straightforward fashion, we can general-ize selection of new training examples based on min-imum worst-case margin from classification learning to the problem of learning ranking functions: For all unlabeled examples, we evaluate  X  + ( x ) and request the correct ranking corresponding to that example with minimum worst-case margin. From a different point of view, we select examples yielding (approxi-mately) maximum worst-case volume reduction of ver-sion space.
 The pairwise ranking technique conducts an expan-sion into binary classification problems considering all pairs of alternatives. Hence, we are given a set of in-dependently treated binary problems which is not di-rectly amenable to analysis in the binary version space model. In order to derive a heuristic selection crite-rion, we consider a best worst-case approach with re-spect to the minimum binary margin on the set of bi-nary examples corresponding to a given ranking exam-ple. In contrast to the constraint classification frame-work, margins have to be evaluated based on different binary classifiers. More precisely, for a labeled ranking example, we have to consider the real-valued output of d ( d  X  1) / 2 binary classifiers h ij (with 1  X  i &lt; j  X  d ) to calculate the minimum binary margin. However, for an unlabeled example, it is computationally infea-sible to consider all d ! possible permutations to eval-uate the minimum margin on the set of binary ex-amples in the worst-case. Therefore, we approximate the permutation yielding minimum margin by the pre-dicted permutation of an unlabeled ranking example. In the case of the probabilistic voting strategy, we con-sider an analogous best worst-case approach with re-spect to minimum binary class probabilities. To sum-marize the selection criterion for the pairwise ranking model, we calculate the predicted rankings for all un-labeled examples and select that unlabeled example which achieves minimum margin (class probability) on the set of binary problems. 4.1. Experimental Setting To evaluate the efficiency of our novel selection crite-ria, we conducted a number of experiments using sup-port vector machines (Chang &amp; Lin, 2001) as binary linear learners. Due to the lack of suitable real-world datasets, we generated artificial data considering three different settings.
 Linear: We replicate a setting proposed by F  X urnkranz and H  X ullermeier (2003) from the field of expected util-ity theory: An expected utility maximizing agent is given a set { 1 , . . . , d } of alternative actions to choose from. The agent faces a problem of decision under un-certainty with alternative i yielding a utility [ U ] ij  X  if the world is in state  X  j  X   X  = {  X  1 , . . . ,  X  n } . The probability of state  X  j is denoted by [ p ] j and, there-fore, the expected utility of alternative i is given by order over the set of alternative actions. We assume the set of alternatives to be in decreasing order with respect to expected utility in the following. Let us assume the probability vector p = ([ p ] 1 , . . . , [ p ] be the feature vector of a ranking example while the number of alternatives d and the set of world states  X  being fixed and the d  X  n utility matrix U having inde-pendently uniformly distributed entries [ U ] ij  X  [0 , 1]. Then, for a given probability vector p the above stated decision-theoretic scenario gives rise to an order over the set of alternative actions. Now, a set of m fea-ture vectors is independently drawn from a uniform distribution over { p  X  R n | p  X  0 , [ p ] 1 +  X   X   X  + [ p ] and assigned to corresponding permutations to gener-ate a ranking dataset. Note that this setting corre-sponds to a noise-free scenario in the constraint classi-fication framework since for a given feature vector p an alternative way to express the corresponding ranking is y = argsort i =1 ,...,d  X  u i , p  X  (with u i denoting the i -th row vector of U ). We conducted our experiments on this dataset using a linear kernel with penalty param-eter C = 100.
 MinMax: This setting considers a modified (non-linear) preference relation generated by E ( i ) = min j =1 ,...,n max([ U ] ij , 1  X  [ p ] j ). It can be viewed as a special case of a pessimistic criterion to evaluate the worth of an alternative in a possibilistic decision frame-work (Dubois et al., 2001). To stay consistent with the herein stated assumptions, for each feature vector p a single feature is randomly selected and set to 1. On this problem, we used an RBF-kernel with  X  = 0 . 1 and penalty parameter C = 100.
 QRank: We train a Naive Bayes classifier on the ve-hicle multiclass dataset from the UCI repository. For each example the set of possible class labels (alterna-tives) is ordered with respect to the a posteriori prob-abilities assigned by the Naive Bayes classifier. From a more abstract point of view, we consider the problem of learning a qualitative replication of the order over a set of alternatives induced by a probabilistic classifier. As for the former setting, we use an RBF-kernel with the default value of  X  = 1 / #features and C = 100. For both the Linear and the MinMax scenario, we fixed the number of input features to n = 10. For each num-ber of alternatives d  X  { 5 , 10 , 15 , 20 } , we generated 100 different datasets consisting of 2000 examples, each dataset originating from a different utility matrix U . Each dataset was randomly split into a training set and a test set of equal size. In the QRank scenario, we cannot sample new data for each run. Instead, the same underlying dataset was randomly split into a training set and a test set of equal size for each run in compliance with comparable research on real-world data. While new training examples were selected from the training sets, the generalization accuracy was esti-mated on the test sets.
 The well-known Spearman rank correlation coefficient (rank correlation) was used as the evaluation metric on the true rankings y and predicted rankings y 0 : The rank correlation evaluates to  X  1 for reversed pref-erence orders and to +1 for identical orders. Moreover, the rank correlation was averaged over all examples in a test set. Due to space restrictions, we do not com-ment on alternative evaluation measures.
 In addition to our novel active learning generaliza-tion of the pairwise and constraint classification tech-nique, we investigated random selection of new exam-ples as a baseline strategy for each of the approaches. We started with a randomly selected set of 10 la-beled examples in all experiments and sequentially se-lected 90 examples using the different selection crite-ria. The rank correlation was evaluated after every 10 rounds and finally the results were averaged over all 100 datasets generated in each of the settings. 4.2. Experimental Results Remember that the choice of kernel is not optimized with respect to the different techniques. Therefore, we compare random learning with their active counter-parts separately for each approach and do not focus on quantitative comparison of different techniques. Ta-ble 1 shows average rank correlations and correspond-ing standard errors of the mean for different numbers of labeled examples. Due to space restrictions, for the Linear and MinMax scenario, detailed results are stated only for the number of alternatives being fixed to d = 10.
 Linear: All active strategies consistently outperform their random counterparts for all choices of the number of alternatives. While there is a substantial increase of accuracy in the case of d = 5 alternatives, it becomes marginal in the case of constraint classification with the number of alternatives increasing. In contrast to this, for the pairwise decomposition techniques, the absolute rise in accuracy at fixed numbers of labeled examples increases with the number of alternatives. MinMax: The active standard pairwise strategy achieves a level of accuracy for 20 labeled examples (independent of d ) that is very close to that of ran-dom learning of 100 examples. For the probabilistic pairwise technique there is a substantial increase of accuracy for d = 5 , 10, whereas for d = 15 , 20 the ac-tive strategy is superior at the beginning while random learning slightly outperforms its active counterpart at the end. In the case of constraint classification, we ob-served a pattern similar to in the former setting: Ac-tive learning consistently outperforms random learn-ing. The gain of accuracy decreases with the number of alternatives increasing.
 QRank: Again, active constraint classification learn-ing consistently outperforms random learning. Com-pared to the former approach, both pairwise decom-position strategies yield an even more significant de-crease of the labeling effort: The reduction is roughly two-fold, e.g. actively learning circa 50 examples yields the same estimated generalization accuracy than ran-domly learning 100 examples.
 As in classification learning, the efficiency of active learning clearly depends on the given ranking prob-lem. In our experiments, active learning based on the constraint classification approach consistently outper-forms random learning. Both active learning based on standard and probabilistic pairwise decomposition yields a more significant relative reduction of the la-beling effort in most of the experiments. Furthermore, the computational effort to solve a ranking problem based on the constraint classification technique was more than two orders of magnitude higher than that of both pairwise decomposition techniques. Therefore, our experiments suggest that it is favorable to make use of the pairwise decomposition approach when ac-tively learning a ranking function. Beyond the (label) ranking model, there are alterna-tive preference models which consider different learn-ing scenarios. In the field of statistical decision theory and mathematical economics, the problem of learning a (preference) utility function (von Neumann &amp; Mor-genstern, 1944) of a given individual is referred to as preference elicitation. While in this case the objec-tive is to assign real-valued utility scores to examples according to a single user X  X  preferences, ranking func-tions assign a finite preference order to each example. More generally, in the former model, examples corre-spond to decision alternatives, whereas in the latter model a finite set of alternatives is a priori fixed and examples correspond to different individuals. Learn-ing a utility function can be considered as a regression problem. In the field of kernel methods, Crammer and Singer (2002) introduced an online algorithm to learn a utility function on an ordinal scale which is used to order a set of new examples with respect to their ordinal utility scores. This problem is also referred to as ordinal regression and has been investigated in the batch setting by Herbrich et al. (2000). Beyond the class of regression-based preference models, Cohen et al. (1999) propose a two-stage approach to prefer-ence learning: In stage one, they learn a probabilistic preference function on pairs of given examples which in stage two is used to order a given set of new examples in some (approximately) optimal sense.
 In the field of active learning, there are two princi-ple categories of approaches: So-called query learn-ing (Angluin, 1988) refers to a learning model where the learning algorithm is given the ability to gen-erate new examples and request the corresponding true class labels. Whereas in selective sampling the learner is restricted to request labels of a finite set of examples ( pool-based model ) or the learning algo-rithm has to decide whether to request the correspond-ing true labels for sequentially presented single exam-ples ( stream-based model ). The well-studied Bayesian query-by-committee (Seung et al., 1992; Freund et al., 1997) approach considers the latter scenario and de-cides to request class labels based on the disagreement within a set of Gibbs classifiers. We introduced novel extensions of pool-based active learning to label ranking problems based on both the constraint classification technique and pairwise decom-position of preferences. Experimental results clearly indicate that active learning can significantly reduce the labeling effort in ranking learning. Considering that is more expensive to label ranking rather than classification examples, the benefit of active ranking learning becomes even more evident.
 We would like to thank Eyke H  X ullermeier and Chih-Len Lin for helpful suggestions and comments. Angluin, D. (1988). Queries and concept learning. Journal of Machine Learning , 2 , 319 X 342.
 Bertsimas, D., &amp; Vempala, S. (2002). Solving con-vex programs by random walks. Proceedings of the 34th ACM Symposium on the Theory of Computing (STOC  X 02) (pp. 109 X 115). Montreal.
 Campbell, C., Cristianini, N., &amp; Smola, A. (2000).
Query learning with large margin classifiers. Pro-ceedings of the Seventeenth International Confer-ence on Machine Learning (ICML) (pp. 111 X 118). Chang, C.-C., &amp; Lin, C.-J. (2001). LIBSVM: a library for support vector machines . Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm .
 Cohen, W. W., Schapire, R. E., &amp; Singer, Y. (1999).
Learning to order things. Journal of Artificial Intel-ligence Research , 10 , 243 X 270.
 Crammer, K., &amp; Singer, Y. (2002). Pranking with ranking. Advances in Neural Information Processing Systems 14 (pp. 641 X 647). Cambridge, MA: MIT Press.
 Dubois, D., Prade, H., &amp; Sabbadin, R. (2001).
Decision-theoretic foundation of qualitative possi-bility theory. European Journal of Operational Re-search , 459 X 459.
 Freund, Y., Seung, H. S., Shamir, E., &amp; Tishby, N. (1997). Selective sampling using the query by com-mittee algorithm. Machine Learning , 28 , 133 X 168. F  X urnkranz, J., &amp; H  X ullermeier, E. (2003). Pairwise preference learning and ranking. Proceedings of the 14th European Conference on Machine Learning (pp. 145 X 156). Cavtat, Croatia: Springer-Verlag. Gr  X unbaum, B. (1960). Partitions of mass-distributions and convex bodies by hyperplanes. Pacific J. Math. , 10 , 1257 X 1261.
 Har-Peled, S., Roth, D., &amp; Zimak, D. (2002). Con-straint classification: A new approach to multiclass classification and ranking. Advances in Neural In-formation Processing Systems 15 (NIPS) .
 Herbrich, R., Graepel, T., &amp; Obermayer, K. (2000).
Advances in large margin classifiers , chapter Large margin rank boundaries for ordinal regression, 115 X  132. Cambridge, MA: MIT Press.
 Langley, P. (1997). Machine learning for adaptive user interfaces. Proceedings of the 21st German Annual Conference on Artificial Intelligence (pp. 53 X 62). Lewis, D. D., &amp; Gale, W. A. (1994). A sequential algorithm for training text classifiers. Proceedings of SIGIR-94, 17th ACM International Conference on
Research and Development in Information Retrieval (pp. 3 X 12). Dublin, IE: Springer Verlag.
 Mitchell, T. M. (1982). Generalization as search. Jour-nal of Artificial Intelligence , 18 , 203 X 226. Platt, J. (1999). Probabilistic outputs for support vec-tor machines and comparison to regularized likeli-hood methods. Advances in Large Margin Classi-fiers (pp. 61 X 74). Cambridge, MA: MIT Press.
 Riecken, D. (2000). Personalized views of personaliza-tion. Communications of the ACM , 43 , 26 X 28. Sch  X olkopf, B., Platt, J., Shawe-Taylor, J., Smola, A. J., &amp; Williamson, R. C. (2001). Estimating the support of a high-dimensional distribution. Neural Compu-tation , 13 , 1443 X 1472.
 Sch  X olkopf, B., &amp; Smola, A. J. (2002). Learning with kernels: Support vector machines, regularization, optimization, and beyond . Cambridge, MA: MIT Press.
 Seung, H. S., Opper, M., &amp; Sompolinsky, H. (1992). Query by committee. Proceedings of the Fifth Anual
ACM Workshop on Computaional Learning Theory (pp. 287 X 294).
 Shawe-Taylor, J., &amp; Cristianini, N. (1999). Further re-sults on the margin distribution. Proceedings of the twelfth annual conference on Computational learn-ing theory (pp. 278 X 285). Santa Cruz, California, United States: ACM Press.
 Tong, S., &amp; Koller, D. (2000). Support vector machine active learning with applications to text classifica-tion. Proceedings of the Seventeenth International Conference on Machine Learning (pp. 999 X 1006).
Morgan Kaufmann, San Francisco, CA. von Neumann, J., &amp; Morgenstern, O. (1944). Theory of games and economic behavior . Princeton Univer-sity Press.
 Warmuth, M. K., R  X atsch, G., Mathieson, M., Liao, J., &amp; Lemmen, C. (2002). Active learning in the drug discovery process. Advances in Neural information
