 The assumption that training and test data are governed by identical distributions underlies many popular learning mechanisms. In a variety of applications, however, data at application time are generated by an adversary whose interests are in conflict with those of the learner. In computer and network security, fraud detection, and drug design, the distribution of data is changed  X  by a malevolent individual or under selective pressure  X  in response to the predictive model. An adversarial interaction between learner and data generator can be modeled as a single-shot game in which one player controls the predictive model whereas the other player exercises some control over the distribution of the input data. The optimal action for either player generally depends on both players X  moves.
 The minimax strategy minimizes the costs under the worst possible move of the opponent. This et al. [1] study the so called Minimax Probability Machine. This classifier minimizes the maximal probability of misclassifying new instances for a given mean and covariance matrix of each class. El Ghaoui et al. [2] study a minimax model for input data that are known to lie within some hyper-rectangle. Their solution minimizes the worst-case loss over all possible choices of the data in these intervals. Similarly, minimax solutions to classification games in which the adversary deletes input features or performs a feature transformation have been studied [3, 4, 5]. These studies show that the minimax solution outperforms a learner that naively minimizes the costs on the training data without taking the adversary into account.
 When rational opponents aim at minimizing their personal costs, then the minimax solution is overly pessimistic. A Nash equilibrium is a pair of actions chosen such that no player gains a benefit by available concept of an optimal strategy in a game against a rational opponent. If, however, multiple equilibria exist and the players choose their action according to distinct ones, then the resulting combination may be arbitrarily disadvantageous for either player. It is therefore interesting to study whether adversarial prediction games have a unique Nash equilibrium. W e study games in which both players  X  learner and adversary  X  have cost functions that consist of data-dependent loss and regularizer. Contrasting prior results, we do not assume that the players X  cost functions are antagonistic. As an example, consider that a spam filter may minimize the error rate whereas a spam sender may aim at maximizing revenue solicited by spam emails. These criteria are conflicting, but not the exact negatives of each other. We study under which conditions unique Nash equilibria exist and derive algorithms for identifying them.
 The rest of this paper is organized as follows. Section 2 introduces the problem setting and defines action spaces and cost functions. We study the existence of a unique Nash equilibrium and derive an algorithm that finds it under defined conditions in Section 3. Section 4 discusses antagonistic loss functions. For this case, we derive an algorithm that finds a unique Nash equilibrium whenever it exists. Section 5 reports on experiments on email spam filtering; Section 6 concludes. We study prediction games between a learner ( v = +1 ) and an adversary ( v =  X  1 ). We consider static infinite games . Static or single-shot game means that players make decisions simultaneously; neither player has information about the opponent X  X  decisions. Infinite refers to continuous cost functions that leave players with infinitely many strategies to choose from. We constrain the players to select pure ( i.e., deterministic) strategies. Mixed strategies and extensive-form games such as Stackelberg, Cournot, Bertrand, and repeated games are not within the scope of this work. Both players can access an input matrix of training instances X with outputs y , drawn according to a probability distribution q ( X , y ) = to choose parameters of a linear model h a a transformation function  X  a q transformations as matrices a  X  1  X  A  X  1  X  R m  X  n . Transformation  X  a a  X  1 ,i . If, for instance, inputs are word vectors, the perturbation matrix adds and deletes words. The possible moves a = [ a +1 , a  X  1 ] constitute the joint action space A = A +1  X  A  X  1 which is assumed to be nonempty, compact, and convex. Action spaces A v are parameters of the game. For zero vectors for non-spam messages; this reflects that spammers can only alter spam messages. main contribution in Section 3 regards non-antagonistic loss functions. For instance, a learner may minimize the zero-one loss whereas the adversary may focus on the lost revenue.
 Both players aim at minimizing their loss over the test distribution q test . But, since q and con-sequently q test are unknown, the cost functions are regularized empirical loss functions over the sample  X  a tion as player-specific loss plus regularizer. The learner X  X  regularizer  X  a the capacity of h a inflict on the data and thereby the extent to which an information payload has to be preserved. Each player X  X  cost function depends on the opponent X  X  parameter. In general, there is no value a v arg min a This solution is optimal for a malicious opponent whose goal is to inflict maximally high costs on the learner. In absence of any information on the opponent X  X  goals, the minimax solution still gives the lowest upper bound on the learner X  X  costs over all possible strategies of the opponent. If both players  X  learner and adversary  X  behave rationally in the sense of minimizing their personal costs, then the Nash equilibrium is the strongest available concept of an optimal choice of a v . A from changing the strategy unilaterally. That is, for both players v  X  X  X  1 , +1 } , The Nash equilibrium has several catches. Firstly, if the adversary behaves irrationally in the sense of inflicting high costs on the other player at the expense of incurring higher personal costs, then choosing an action according to the Nash equilibrium may result in higher costs than the minimax solution. Secondly, a game may not have an equilibrium point. If an equilibrium point exists, the may be a poor joint strategy and may give rise to higher costs than a worst-case solution. However, if a unique Nash equilibrium exists and both players seek to minimize their individual costs, then the Nash equilibrium is guaranteed to be the optimal move. cost functions as in Equation 1. We derive an algorithm that identifies the unique equilibrium if functions; however, we omit such cost factors for greater notational harmony. This section X  X  main monotonically increasing, and one is decreasing for any fixed y  X  then the game has a unique Nash equilibrium that can be found efficiently.
 Theorem 1. Let the cost functions be defined as in Equation 1 with strictly convex regularizers  X  a let action spaces A v be nonempty, compact, and convex subsets of finite-dimensional Euclidean monotonicity, convex in y 0 , and twice differentiable in y 0 , then a unique Nash equilibrium exists. Proof. The players X  regularizers  X  a ` ( h a Hence, both cost functions  X  v are continuously differentiable and strictly convex, and according to Theorem 4.3 in [6], at least one Nash equilibrium exists. As each player has an own nonempty, compact, and convex action space A v , Theorem 2 of [7] applies as well; that is, if function is positive definite for any a  X  A (see Theorem 6 in [7]). This matrix is the Jacobian of the pseudo-gradient of  X  r ( a ) , that is, umn is a +1 and all other elements are zero, let  X  v be the diagonal matrix with diagonal elements  X  tions, the Jacobian of Equation 4 can be rewritten, for any y 0 and consequently r X  +1 ,i + (1  X  r )  X   X  1 ,i  X  0 . Hence, the first summand of Jacobian J regularizers X  Hessians as follows: where  X  v is the smallest eigenvalue of  X  2  X  a the second summand in Equation 7 is positive semi-definite. Hence, it suffices to show that matrix values; these are (1  X  r )  X   X  1 and derivatives have a different sign for any y 0  X  R and consequently b  X  0 . This implies that the addition, b is bounded from below as action spaces A v , and therefore the value of h a that the value under the square root in Equation 9 attains a non-negative value, that is, or alternatively F or such r all eigenvalues in Equation 9 are strictly positive which completes the proof. According to Theorem 1, a unique Nash equilibrium exists for suitable loss functions such as the squared hinge loss, logistic loss, etc. To find this equilibrium, we make use of the weighted Nikaido-Isoda function (Equation 13). Intuitively,  X  r savings that the players can enjoy by changing from strategy a v to strategy b v while their opponent continues to play a  X  v . Equation 14 defines the value function V r a  X  is a Nash equilibrium if, and only if, V r V To find this global minimum of V r fixed scaling factors of the players X  objectives which do not affect the Nash equilibrium in Equa-a descent direction for the value function at any position a , where b b is the maximizing argument b t  X  [0 , 1] ( i.e., a point between a and b b ) is a valid pair of actions.
 Algorithm 1 Nash Equilibrium of Games with Convex Loss Functions Requir e: Cost functions  X  v as defined in Equation 1 and action spaces A v . 1: Select initial a 0  X  A +1  X  A  X  1 , set k := 0 , and choose r that satisfies Inequality 10 or 11. 2: repeat 4: Set d k := b k  X  a k . 6: Set a k +1 := a k + t k d k and k := k + 1 . Algorithm 1 exploits these properties and finds the global minimum of V r Nash equilibrium, under the preconditions of Theorem 1. Convergence follows from the fact that if If d k 6 = 0 , then d k is a descent direction of V r this ensures V r converges to the global minimum of V r influence on the solution. Any value of r that satisfies Inequality 10 or 11 ensures convergence. Algorithm 1 is guaranteed to identify the unique equilibrium if the loss functions are convex, twice differentiable, and of distinct monotonicities. We will now study the case in which the learner X  X  cost function is continuous and convex, and the adversary X  X  loss function is antagonistic to the learner X  X  loss, that is, ` +1 =  X  `  X  1 . We abstain from making assumptions about the adversary X  X  regularizers. Because of the regularizers, the game is still not a zero-sum game. In this setting, a unique Nash equilibrium cannot be guaranteed to exist because the adversary X  X  cost function is not necessarily strictly convex. However, an individual game may still possess a unique Nash equilibrium, and we can derive an algorithm that identifies it whenever it exists.
 The symmetry of the loss functions simplifies the players X  cost functions in Equation 1 to Even though the loss functions are antagonistic, the cost functions in Equations 15 and 16 are not, unless the player X  X  regularizers are antagonistic as well. Hence, the game is not a zero-sum game. However, according to Theorem 2, if the game has a unique Nash equilibrium, then this equilibrium is a minimax solution of the zero-sum game defined by the joint cost function of Equation 17. Theor em 2. If the game with cost functions  X  +1 and  X   X  1 defined in Equations 15 arg min a The proof can be found in the appendix. As a consequence of Theorem 2, we can identify the unique Nash equilibrium of the game with cost functions  X  +1 and  X   X  1 , if it exists, by finding the minimax solution of the game with joint cost function  X  0 . The minimax solution is given by where b a  X  1 is set to the value b a  X  1 = arg max a is convex in a +1 with gradient The significance of Danskin X  X  Theorem is that when calculating the gradient  X  a The convexity of b  X  0 ( a +1 ) suggests the gradient descent method implemented in Algorithm 2. It identifies the unique Nash equilibrium of a game with antagonistic loss functions, if it exists, by finding the minimax solution of the game with joint cost function  X  0 .
 Algorithm 2 Nash Equilibrium of Games with Antagonistic Loss Functions Requir e: Joint cost function  X  0 as defined in Equation 17 and action spaces A v . 1: Select initial a 0 +1  X  A +1 and set k := 0 . 2: repeat 5: Find maximal step size t k  X  X  2  X  l : l  X  N } with 7: Project a k +1 to the admissible set A +1 , if necessary. A minimax solution arg min a the learner X  X  costs when playing against the most malicious opponent; for instance, Invar-SVM [4] finds such a solution. By contrast, the minimax solution arg min a joint cost function as defined in Equation 17 constitutes a Nash equilibrium of the game with cost that seek their personal advantage. Algorithmically, Invar-SVM and Algorithm 2 are very similar; the main difference lies in the optimization criteria and the resulting properties of the solution. We study the problem of email spam filtering where the learner tries to identify spam emails while the adversary conceals spam messages in order to penetrate the filter. Our goal is to explore the relative strengths and weaknesses of the proposed Nash models for antagonistic and non-antagonistic loss functions and existing baseline methods. We compare a regular SVM , logistic regression , SVM with Invariances (Invar-SVM, [4]), the Nash equilibrium for antagonistic loss functions found by identifying the minimax solution of the joint cost function (Minimax, Algorithm 2), and the Nash equilibrium for convex loss functions (Nash, Algorithm 1). Minimax and the Nash model. Consequently, the adversary X  X  loss for the Minimax solution is the a convex approximation of the adversary X  X  zero-one loss, that is, correct predictions by the learner incur high costs for the adversary. We use the additive transformation model  X  a the adversary X  X  parameters; for non-spam we set a  X  1 ,i = 0 . That is, the spam sender can only transform spam emails. This model is equivalent to the component-wise scaling model [4] with compact, and convex. We use l 2 -norm regularizers for both players, that is,  X  a  X  v is the regularization parameter of player v . For the Nash model we set r to the mean of the interval defined by Inequality 11, where b =  X  n 4 is a lower bound for the chosen logistic loss and regularization parameters  X  v are identical to the smallest eigenvalues of  X  2  X  a We use two email corpora: the first contains 65,000 publicly available emails received between 2000 and 2002 from the Enron corpus, the SpamAssassin corpus, Bruce Guenter X  X  spam trap, and several mailing lists. The second contains 40,000 private emails received between 2000 and 2007. All emails are binary word vectors of dimensionality 329,518 and 160,981, respectively. The emails are sorted chronologically and tagged with label, date, and size. The preprocessed corpora are available from the authors. We cannot use a standard TREC corpus because there the delivery dates of the spam messages have been fabricated, and our experiments require the correct chronological order. Our evaluation protocol is as follows. We use the 6,000 oldest instances as training portion and set the remaining emails aside as test instances. We use the area under the ROC curve as a fair all methods 20 times for the first experiment and 50 times for the following experiments on a subset of 200 messages drawn at random from the training portion and average the AUC values on the test set. In order to tune both players X  regularization parameters, we conduct a grid search maximizing the AUC for 5-fold cross validation on the training portion.
 In the first experiment, we explore the impact of the regularization parameter of the transformation model, i.e.,  X   X  1 for our models and K  X  the maximal number of alterable attributes  X  for Invar-SVM. Figure 1 shows the averaged AUC value on the private corpus X  test portion. The crosses indicate the parameter values found by the grid search with cross validation on the training data. In the next experiment, we evaluate all methods into the future by processing the test set in chrono-logical order. Figure 2 shows that Invar-SVM, Minimax, and the Nash solution outperform the reg-ular SVM and logistic regression significantly. For the public data set, Minimax performs slightly better than Nash; for the private corpus, there is no significant difference between the solutions of Minimax and Nash. For both data sets, the l 2 -regularization gives Minimax and Nash an advantage over Invar-SVM. Recall that Minimax refers to the Nash equilibrium for antagonistic loss functions found by solving the minimax problem for the joint cost function (Algorithm 2). In this setting, loss functions  X  but not cost functions  X  are antagonistic; hence, Nash cannot gain an advantage over Minimax. Figure 2 (right hand side) shows the execution time of all methods. Regular SVM and logistic regression are faster than the game models; the game models behave comparably. Finally, we explore a setting with non-antagonistic loss. We weight the loss functions with player-and instance specific factors c v,i , that is, ` c v ( h a
Figure 2: Left, center: AUC evaluated into the future after training on past. Right: execution time. Our model reflects that an email service provider may delete detected spam emails after a latency pe-threshold balances a trade-off between non-spam recall (fraction of legitimate emails delivered) and storage costs. For a threshold of  X  X  X  , storage costs and non-spam recall are zero for all decision functions. Likewise, a threshold of  X  gives a recall of 1, but all emails have to be stored. Fig-ure 3 shows this trade-off for all methods. The Nash prediction model behaves most favorably: it outperforms all reference methods for almost all threshold values, often by several standard errors. Invar-SVM and Minimax cannot reflect differing costs for learner and adversary in their optimiza-tion criteria and therefore perform worse. Logistic regression and the SVM with costs perform better than their counterparts without costs, but worse than the Nash model. regularizer. A learner produces a linear model while an adversary chooses a transformation matrix to be added to the data matrix. Our main result regards regularized non-antagonistic loss functions that are convex, twice differentiable, and have distinct monotonicity. In this case, a unique Nash equilibrium exists. It minimizes the costs of each of two players that aim for their highest personal benefit. We derive an algorithm that identifies the equilibrium under these conditions. For the case of antagonistic loss functions with arbitrary regularizers a unique Nash equilibrium may or may not exist. We derive an algorithm that finds the unique Nash equilibrium, if it exists, by solving a minimax problem on a newly derived joint cost function.
 We evaluate spam filters derived from the different optimization problems on chronologically or-dered future emails. We observe that game models outperform the reference methods. In a setting with player-and instance-specific costs, the Nash model for non-antagonistic loss functions excels because this setting is poorly modeled with antagonistic loss functions.
 Acknowledgments We gratefully acknowledge support from STRATO AG. [1] Gert R. G. Lanckriet, Laurent El Ghaoui, Chiranjib Bhattacharyya, and Michael I. Jordan. A [2] Laurent El Ghaoui, Gert R. G. Lanckriet, and Georges Natsoulis. Robust classification with in-[3] Amir Globerson and Sam T. Roweis. Nightmare at test time: robust learning by feature deletion. [4] Choon Hui Teo, Amir Globerson, Sam T. Roweis, and Alex J. Smola. Convex learning with [5] Amir Globerson, Choon Hui Teo, Alex J. Smola, and Sam T. Roweis. Dataset Shift in Machine [6] Tamer Basar and Geert J. Olsder. Dynamic Noncooperative Game Theory . Society for Industrial [8] Anna von Heusinger and Christian Kanzow. Relaxation methods for generalized Nash equi-[9] John M. Danskin. The theory of max-min, with applications. SIAM Journal on Applied Mathe-
