 In many data mining applications, we often face the problem of cross-domain learning, i.e., to transfer the already learned knowledge from a source domain to a target domain. In par-ticular, this problem becomes very challenging when there is no or little labeled training data available in the target do-main, which is not an uncommon scenario as it is expensive and in certain cases even impossible to obtain any labeled training data in the target domain in many real world ap-plications. In the literature, though few efforts are reported to attempt to solve this challenging problem, the solutions are all rather limited making this problem still open and challenging. On the other hand, as it is not uncommon to face this problem in many applications, an effective solu-tion to this problem shall generate substantial societal im-pacts. In this paper, we address this problem and propose a new framework, called DISMUTE, taking advantage of the typically available multiple views of the data in domains. Consequently, DISMUTE is based on discriminative feature selection for multi-view cross-domain learning. Theoretic analysis and extensive evaluations in the specific application of object identification and image classification against sev-eral state-of-the-art methods demonstrate the outstanding superiority of DISMUTE.
 I.4.8 [ Computing Methodologies ]: Scene Analysis X  Ob-ject recognition ; I.5.2 [ Computing Methodologies ]: De-sign Methodology X  Classifier design and evaluation, Feature evaluation and selection, Pattern analysis Algorithms, Experimentation transfer learning; sparsity; feature selection; multi-view; clas-sification
In many data mining applications, we often face the prob-lem of cross-domain learning, i.e., to transfer the already learned knowledge from a source domain to a target domain, where a domain can be a specific data source, a specific me-dia type, or even a specific semantic representation space. Examples of these applications where this problem occurs include, video event understanding and detection where the source domain is a collection of web videos and the target domain is a real-time stream of consumer video data in a spe-cific application, object identification and image classifica-tion where the source domain is a collection of images about many objects and the target domain is another collection of different images about the same objects, and cyberspace-reality analysis where the source domain is the real-world and the target domain is a cyber space.

In particular, this problem becomes very challenging when there is no or little labeled training data available in the tar-get domain, which is a common scenario as it is expensive and in certain cases even impossible to obtain any labeled training data in the target domain in many real world appli-cations. In the literature, though few efforts are reported to attempt to solve this challenging problem, the solutions are all rather limited making this problem still open and chal-lenging. On the other hand, as it is not uncommon to face this problem in many applications, an effective solution to this problem shall generate substantial societal impacts.
Though there is a lack of sufficient labeled training data in the target domain, the data in different domains are often represented in different heterogeneous feature spaces, which may be further considered as multiple views. These views provide additional unsupervised information that can be ex-ploited to facilitate and enhance the transfer learning. For example, an image can be described by different types of high dimensional heterogeneous features, such as, the global features of color, shape, and texture, or the local features of SBN [20], SIFT, and GLOH (Gradient Location and Orien-tation Histogram). These heterogeneous features form dif-ferent views capture the underlying cluster structures of the data. It is reported that certain structures of the features are proven to be shared across different domains for the seman-tics of classes [17]. Though it has been shown that leveraging the consistencies between different views helps improve the learning performance [30, 16], there is still limited atten-tion paid in the literature to the problem of integrating the characteristics of multi-view features into transfer learning.
Most existing methods integrate the multi-view learning into transfer learning by simple strategies, such as heuris-ti cally converting the multi-view data into the single-view data by concatenating the heterogeneous feature spaces into one homogeneous feature space. Also previous work only considers the view consistency and ignores the contribution of the sparseness of the representative features in transfer learning [29]. Thus, most existing transfer learning meth-ods fail to take advantage of the multi-view information. Consequently, it still remains an open problem on how to effectively and appropriately exploit the high dimensional multi-view data for transfer learning.

On the other hand, different views of the heterogeneous features have different intrinsic discriminative powers to char-acterize data semantics. Only a limited part of the heteroge-neous features helps distinguish the semantics of each label from those of others. Feature selection for transfer learning then becomes a natural approach. Consequently, a critical problem in multi-view transfer learning arises: how to effec-tively select representative features for the accurate predic-tion in cross-domain regression and classification.
In response to this challenge and the substantial applica-tion potential, we propose a new scheme to address the prob-lem of feature selection in multi-view transfer learning with a brand new framework: DIscriminative feature Selection for MUlti-View Transfer lEarning, named as DISMUTE. In this framework, we simultaneously conduct an unsupervised feature learning and a supervised regression training as a unified approach. Taking advantage of the correspondence relations between different views of the features, we exploit the consistency prediction between different views. For mit-igating the gap between the domains, we incorporate the Maximum Mean Discrepancy (MMD) criterion as a regular-izer on the feature mapping coefficient matrix. Furthermore, we enforce a l 2 , 1 -norm regularization on the coefficient ma-trix to ensure the sparsity and to select the representative features shared by the semantics of the same class-labels across the domains. To enhance the predictive power in the target domain, we not only encode the local manifold struc-tures of the data distribution into the predicted class indi-cator matrix through a geometric graph regularization, but also incorporate the cross-domain global discriminative in-formation to avoid overfitting and to make the results more robust.

The key contributions of this paper are highlighted as fol-lows:
The rest of the paper is organized as follows. In Section 2, we discuss the related work. Section 3 describes the data notations and symbols used in this work, and introduces the formulation of the proposed framework. The derivation of the algorithm for the framework is given in Section 4. Section 5 investigates the convergence of the algorithm. We report the experimental results for DISMUTE in comparison with the peer methods in the literature in Section 6. Section 7 concludes the paper.
In the context of data mining application, transfer learn-ing has attracted an increasing amount of attention these days [24]. It has been successfully used for different research problems such as object identification, text classification [33, 11], and visual event recognition with limited labeled train-ing samples in the target domain. It focuses on how to effectively utilize the valuable labeled information from the source domain to enhance the learning procedure in the tar-get domain [26, 12]. Yang et al. [1] propose A-SVM to adapt the target classifier from an auxiliary classifier. Duan et al. [8] propose A-MKL to learn an adapted classifier based on multiple base kernels and the prelearned average classi-fiers for transfer learning. However, in most of the existing methods, training the target classifier still requires a limited number of labeled data in the target domain. Transfer learn-ing without any supervised information in the target domain still remains a big challenge [29, 12, 13, 5]. Nevertheless, we aim to tackle with this problem in this paper.

Meanwhile, in many applications, data objects usually have multiple views of the features obtained through dif-ferent ways. This multi-view information carries valuable correspondence information between the views [6, 25] and has inherent correlation with the class semantics. Many ex-isting methods are developed for the multi-view learning and attempt to regularize the consistencies between the different views to improve the generalization performance. Farquhar et al. [9] propose SVM-2K to construct a classifier on each view and regularize the consistencies between the different views. Li et.al [16] incorporate the consistency term into a solution to the multi-view semi-supervised learning prob-lem, and show a substantial improvement on the classifica-tion performance. However, most of them focus only on the single domain setting.

In the transfer learning setting, the difference of the data distribution between different domains is expected to be taken into account. With the multi-view information, how to effectively select the features adaptive for the multiple do-mains imposes an imperative demand for transfer learning. The existing feature selection methods have made a great progress due to the application of sparsity technology [22]. Wu et al. [27] propose sparsity-based approaches for group selection in a high-dimensional heterogeneous feature space and achieve an improvement in discriminative classification performance. Zhao et al. [31] use spectral regression with l 2 , 1 -norm constraint to evaluate features jointly and their method effectively removes redundant features. With the benefits of sparse feature selection, we apply it to our frame-work with the extension to the multi-view transfer learning.
In this work we carry on the cross-domain classification without any labeled training information in the target do-main. We only use the auxiliary labeled data in the source domain to assist the training, with the additional multi-view in formation of the data in both domains. To our best knowl-edge, few efforts have been developed to incorporate the lat-est advanced techniques of feature selection and multi-view learning into a single framework for transfer learning. Zhang et al. [29] utilize the data from both domains to impose con-sistencies between multiple views while using only labeled data from the source domain to construct a large margin classifier. Chen et al. [5] extract the shared concept space between different class semantics in both the source and target domains with a linear transformation simultaneously minimizing the embedded distribution gap between differ-ent domains. Gong et al. [12] propose to learn a geodesic flow kernel to model the domain shift from the source to the target domain but with the performance sensitive to the optimal dimensionality for the kernel construction. These existing literature ignore the contribution of the sparseness of the representative features in transfer learning. Thus, the generalization performance of these methods in the target domain is still limited, which is one of the issue our frame-work addresses.
We first introduce the notations used in this paper. Then we give the problem statement for the formulation of the proposed framework, DISMUTE (DIscriminative feature Se-lection for MUlti-view Transfer lEarning).

Suppose that we are given a set of labeled data for training in the source domain D s from m independent views, X s v = { x x the source domain. n s is the total number of source do-main data instances and d v is the dimensionality of the v th view. e Y = [ e y 1 , e y 2 ,  X  X  X  , e y n s ] T  X  { 0 , 1 } { 0 , 1 } c  X  1 (1  X  i  X  n s ) is the label class indicator vector for the data instances { x s v,i } m v =1 and c is the number of the label classes. The k th element of e y i is 1 if x s v,i belongs to the k th class and 0 otherwise. Besides the source domain data instances, a set of unlabeled target domain data instances from m views are also available, and the data matrices are where n t is the total number of data instances in the target domain. Following [28], we define the scaled pseudo-class la-bel matrix Y = [ y 1 ,  X  X  X  , y n s ] T = e Y ( e Y T e Y ) the k th column of Y is given by : wh ere l k is the number of the data instances in the k -th class.

Similar to that in the source domain, the unknown class label indicator matrix for the data instances in the target domain D t is e Z = [ e z 1 , e z 2 ,  X  X  X  , e z n t ] T  X  { 0 , 1 } e z  X  X  0 , 1 } c  X  1 (1  X  i  X  n t ) is the label class indicator vector for the data instances { x t v,i } m v =1 . The k th element of e z if x t v,i belongs to the k th class and 0 otherwise.
Also, we define the pseudo-class label matrix Z  X  X  n t  X  c [ z ,  X  X  X  , z n t ] T = e Z ( e Z T e Z )  X  1 / 2 , where z i of Z is given by : wh ere l k is the number of the data instances in the k -th class.

Given the notations above, the goal is to select a subset of the representative features from each view of the features, and simultaneously predict the pseudo-class label matrix Z for the data instances in the target domain by making use of the labeled data from the source domain as well as the auxiliary information carried by the multiple views of the features.
To tackle with the challenge imposed by the lack of class labels in the target domain, we combine the unsupervised feature learning model of the target domain with the su-pervised regression prediction model of the source domain. Intrinsically, the supervised information is transferred from the source domain to the unsupervised feature learning in the target domain.

Furthermore, taking advantage of these relations between different views of the features, we design the model to con-duct the consistency prediction between different views. where s v =  X  ( function. q v is the number of the features to select for the v th view where s v ( j ) = 1 indicates that the j th feature from the v th feature view is selected. The original feature views X  X  v (  X  = s, t ) can be represented as e X  X  v = diag ( s with q v features selected. W = { W 1 ,  X  X  X  , W m } is the set of feature mapping matrices, with W v  X  X  d v  X  c .

Meanwhile, we observe that diag ( s v ) and W v are always in the form of diag ( s v ) W v in Eq.(3). Since s v is a binary vector and h v  X  q v rows of diag ( s v ) are all zeros, diag ( s is a matrix where the elements of many rows are all ze-ros. This motivates us to absorb diag ( s v ) into W v , W diag ( s v ) W v , and add l 2 , 1 norm on W v to ensure the spar-sity of W v in rows and achieve the feature selection.
Further, recall that Z is the scaled pseudo-class label ma-trix. According to the definition, in each row of Z , only one element is positive and all the others are 0. Additionally note that We add the constraint Z T Z = I , Z  X  0 in the objective function, and obtain the following optimization problem. trols the capacity of W v and also ensures that W v is sparse in rows, making it particularly suitable for selecting rep-resentative features shared by the semantics of the same class-label across different domains. It effectively identifies a small number of features by removing the irrelevant, re-dundant, and noisy features between different domains. The parameter  X  v controls the sparsity of W v .
In transfer learning, due to the change of distribution in different domains, training with samples from the source domain may degrade the generalization performance in the target domain. Here, we adopt the Maximum Mean Discrep-ancy (MMD) [2, 23] to measure the embedded distribution distance between the source domain with sufficient but finite labeled data samples and the target domain with sufficient unlabeled data. The empirical estimate of the distance be-tween domains D s and D t defined by MMD is as follows. .

Here , the function  X  (  X  ) maps the original data views into the representations of the feature selection results for both domains,  X  ( x s v,i ) = W T v x s v,i ,  X  ( x t v,i ) = W feature learning in the v th view, the square of the MMD in (6) can be written as, Particularly for feature learning across domains, some fea-tures may cause the data distribution between domains to be different, while others may not. Some features may pre-serve the structures of the data for adaptation, while others may not. To learn a shared latent feature space across differ-ent domains, we intuitively incorporate the MMD distance as a regularization on the mapping matrices W v for domain adaptation.
Even with the lack of class-label information in the tar-get domain, the unlabeled data in the target domain are still valuable to explore the cluster characteristics which cap-ture the distribution of the semantic classes. The unlabeled data instances may help identify a low-dimensional mani-fold structure along which labels can be assumed to vary smoothly. Here, we introduce the manifold regularization based on the geometric graph of multi-view features. The inherent structure of unlabeled data in the target domain is incorporated via a regularization term with the role to pe-nalize the predicted pseudo-class labels for changing rapidly along the underlying manifold.

The empirical estimate of these underlying structures is encoded as a graph with vertices as the unlabeled data points and edge weights as the appropriate pairwise similarity rela-tionship between the points. The element of the edge weight matrix G v for the v th data view in the target domain is de-fined as follows: where  X  is the bandwidth parameter, and N p ( x t v,i ) denotes the set of p nearest neighbors of x t v,i . Given this graph, one can bias predicting the labels in the target domain towards the resulting labels that vary smoothly along the underly-ing geometric manifold structures. The graph regularizer used to measure the smoothness of the predicted class-labels along the geodesics in the intrinsic geometry of the data from the target domain is as follows.
 defined as D v ii = the labels predicted sufficiently smooth on the data mani-fold. If two data points x t v,i and x t v,j are close, z similar to each other. Therefore, we add the graph regular-izer on labels in the framework for optimization.
Here we additionally incorporate a cross-domain discrim-inative regularization term in the objective function to ex-plore the global class structure taking into account of the data from both domains.

Data instances from both domains of each individual view are represented as, X a v = [ X s v , X t v ]  X  X  d v  X  ( n class and the total scatter matrices are defined as follows, respectively: where F = [ Y T , Z T ] T .

To achieve the maximum discrimination of the class struc-tures in both domains, we aim to obtain a pseudo-class label matrix, according to which the distance between the data from different classes should be as large as possible and the distance between the data from the same class should be as small as possible. Under such a criterion and inspired by the classical LDA algorithm [10] , it is reasonable to maximize the following; make ( S t v +  X  I ) nonsingular. To incorporate the criterion in the minimization framework, we add it as a negative item,  X  ( Z , Y ) =  X  Tr
Finally, we obtain the unified framework of DISMUTE, which integrates the optimization objectives throughout sub-sections (3.1-3.4). The joint optimization objective to mini-mize is defined as follows. where L v = D v  X  G v .
Below, we apply an alternating approach to solve this problem and update { W v } m v =1 and Z iteratively and alter-natingly to find an optimal solution to Eq. (12).
When computing { W v } m v =1 given Z fixed, the constraints on { W v } m v =1 are independent, suggesting that the relations between the views are decoupled. Thus, we optimize each W v (1  X  v  X  m ) separately by solving the following prob-lem. where Taking the derivation of L ( W v ) +  X  v k W v k 2 , 1 and setting it to zero, we obtain the update rule for W v as where D W v ( i, i ) is a diagonal matrix with the i th diagonal
Given { W v } m v =1 fixed, we compute Z through solving the following optimization problem, where we incorporate the orthogonality constraint into the objective function as a regularizer.  X  &gt; 0 is a parameter to control the orthogonality condition.  X  is the Lagrangian multiplier for the constraint of nonnegativity and
Taking the derivation of L ( Z ) and setting it to zero, with the KKT condition,  X  ij Z ij = 0, we obtain which leads to the following update rule for Z , where M = X N v = ( | N v | X  N v ) / 2, N + v = ( | N v | + N v ) / 2.
In summary, we present the iterative alternative updating algorithm of DISMUTE in Algorithm 1.
 Al gorithm 1 : the Discriminative Feature Selection of Multi-view Transfer learning (DISMUTE)
In this section, we provide a theoretical justification of the convergence in Algorithm 1.
The convergence analysis of updating W v for the objec-tive function begins with the following lemma.

Lemma 1. [22] The following inequality holds if w  X  i | r are nonzero vectors, where r is an arbitrary number.
Wit h the above lemma, we develop the following theorem regarding the convergence of updating W v in Algorithm 1.
Theorem 2. At each iteration of Algorithm 1 with Z fixed, the value of the objective function in Eq.(13) monotonically decreases when updating W v according to Eq.(14).
Proof. The updating rule of W v is the solution to the following problem which indicates that Th en we have the following inequality According to Lemma 1, we obtain which completes the proof.
Next we use the auxiliary function approach [15] to show that the update rule in Eq.(17) monotonically decreases the value of the objective in Eq.(15). The definition of the aux-iliary function can be found in [15].

Definition 1. [15] J ( h, h 0 ) is an auxiliary function for L ( h ) if the following conditions are satisfied.
 Lemma 3. [15] If J is an auxiliary function for L , then L is non-increasing under the updating rule Lemma 4. [7] For any nonnegative matrices A  X  R n  X  n , ric, then the following inequality holds Le mma 5. The following function is an auxiliary function for L ( Z ) . Furthermore, it is a con-vex function in Z and its global minimum is obtained by
Theorem 6. Updating Z using Eq.(17) monotonically de-creases the value of the objective in Eq.(15). Hence, Algo-rithm 1 converges.
 By Lemma 3 and Lemma 4, Lemma 5 can be proven.
 Further, Theorem 6 can be proven as well. The detailed proofs are omitted due to the space limitation.
In this section, we demonstrate the promise of DISMUTE by reporting experiments on benchmark datasets for the application of cross-domain object identification and image classification. In the experiments, we measure the perfor-mance using the accuracy criterion for each class, and also using the mean accuracy over all the classes.
The experiments use the four image datasets which were studied in [26, 12]: amazon , in which images are downloaded from online merchants; webcam , in which low-resolution im-ages are obtained by a web camera; and dslr , in which high-resolution images are obtained by a digital SLR camera. Moreover, following [12], we have added images of dataset caltech -256 [14] as the fourth dataset caltech . We con-sider each dataset as a domain. Ten classes common to all the four datasets are selected to construct the datasets for cross-domain object identification and image classifica-tion: backpack , bike , calculator , headphones , keyboard , laptopcomputer , monitor , mouse , mug , projector . There are in total 2533 images in the four domains. Exemplar im-ages in the four domains from the category of bike are shown in Figure 1 to highlight the difference among the domains. Fi gure 1: Example images from the bike category in amazon , dslr , webcam , and caltech . As can be seen, the vi-sual appearance of the images from different domains varies a lot.

To obtain multiple views of the features for the image data, we use three descriptors to represent the three views of the features: pyramid of histograms of the oriented gra-dients (PHOG) [3], SIFT descriptor [18], and Gabor texture descriptor [19].

For the PHOG and Gabor descriptors, we resize the im-ages to 256  X  256 pixels each. Both descriptors extracted from 64  X  64 pixel patches are densely sampled from each image on a grid with a stepsize of 32 pixels. For SIFT de-scriptor, images are resized to 240  X  240 pixels each. SIFT descriptors extracted from 40  X  40 pixel patches are densely sampled from each image on a grid with a stepsize of 20 pixels.

After extracting the three views for each image, vector quantization into visual words is performed to generate the final feature vector. Codebooks of size 400, 400, and 800, respectively for PHOG, Gabor, and SIFT views, are con-structed by k-means clustering on these descriptors corre-sp ondingly. All the images are converted to histograms over the resulting visual words.
To verify the effectiveness of DISMUTE, we compare it with the following competitors:
Support Vector Machines (SVM) [4], which is a supervised classification method training in the source domain and pre-dicting in the target domain;
LLGC [32], which is a semi-supervised learning method propagating the label information in the source domain to the target domain;
LapSVM [21], which is also a semi-supervised classifica-tion method with a geometric manifold regularization;
SVM-2K [9], which is a multi-view learning method com-bining multi-view of the features for data classification;
DCDA [5], which is a transfer learning method for unsu-pervised target domain extracting the shared subspace be-tween multiple classes and minimizing the gap between the domains for classification.

MVTL [29], which is a multi-view transfer learning method for unsupervised target domain by regularizing the consis-tency between different feature views for cross-domain clas-sification.

GFK [12], which is a method to construct geodesic flow kernel for cross-domain. The classification in the unsuper-vised target domain is conducted by the KNN classifier.
Notice that except for the algorithms DISMUTE, MVTL, and SVM2K, the other algorithms only work in the single-view settings. For the sake of a fair comparison, we con-catenate the features from different views, and apply these methods on this single view.
Without loss of generality and with respect to the com-paring method SVM2K working in two views settings, we conduct the cross-domain classification with the data of two views in the following experiments.

In DISMUTE, the parameter  X  v weighs the loss penalty of predication for different views in the domains and  X  v trols the relative weight of the feature selection. To facili-tate the procedure of the parameter cross validation, we fix  X  1 =  X  2 denoted as  X  and  X  1 =  X  2 denoted as  X  . Then we report the parameter tuning results for various values of  X  and  X  in Figure 2. Note that different views of the fea-tures play different roles in the class prediction. We further investigate the trade-off between  X  1 and  X  2 in different view-pairs. We fix  X  1 and  X  2 , and report the parameter tuning results. for various values of  X  1 and  X  2 in Figure 3.
Consequently, the parameters of coefficients  X  v and  X  v , v = 1 , 2 remain to be tuned. Here the parameters of co-efficients  X  v and  X  v , v = 1 , 2, are set as 0 . 5, which weigh equal over each view of the features. The parameter p that specifies the p nearest neighbors used to compute the graph matrix G v is set to 5 for all the datasets. To ensure the pre-dicted pseudo-class labels orthogonal, we set the parameter  X  to 10 3 .

The parameters in the comparing methods are set through five fold cross validation, respectively, as well.
We report the comparison results in Tables 1, 2, 3 for dif-ferent view-pairs on 12 domain-pair transfer learning datasets, respectively. The A  X  B indicates that we use the labeled training data in source domain A to predict the labels for the data in target domain B .

All the methods are repeated five times for five random partitions on the source and target domains. The average performance and standard deviation are reported.

To investigate the details of these comparing methods on each class, we show details of the classification on the exem-plar dataset caltech  X  amazon in Figure 5. The subfigures in the figure show the accuracy on the ten classes in the three view-pairs, respectively. Note the substantial and significant variations in object visual appearance, background, object repetitions, object shape and style change, and lighting con-dition for the bikes found to be the same objects between caltech and amazon shown in Figure 1, which showcases the difficulty in cross-domain classification.

From Table 1, 2, 3 and Fig 5, we have the following ob-servations:
From all the three view-pairs, DISMUTE outperforms al-most all the other methods. These results have confirmed the advantage of DISMUTE in effectively exploiting the multi-view feature information for transfer learning. The overall superior performance of DISMUTE is further verified from Figure 5, where DISMUTE achieves the highest classi-fication accuracy for the most times (13) on the ten classes and the other methods perform inferior as summarized in Table 4. Specifically, the next best method is GFK with a significant difference in the number of times to achieve the best performance (6 vs 13), demonstrating an outstanding superiority in performance of DISMUTE over all the com-parison methods.

Comparing with SVM, we see that concatenating the fea-tures from different views may not necessarily result in an increase in the classification performance in the transfer learning though SVM uses information from both views. Comparing with the semi-supervised classification methods, LapSVM and LLGC, which both exploit the underlying ge-ometric manifold of the data to enhance the label prediction performance, DISMUTE delivers a superior performance. DISMUTE not only considers the geometric structures in the datasets, but also takes the domain divergence into ac-count. Due to the domain divergence, the feature distribu-tions are different between the domains. Thus simply uti-lizing the features to construct the graph from the data of both domains is not appropriate. Based on this observation, we only construct the affinity graph in the target domain to preserve the data structures in the predicted pseudo-labels. Moreover, we ensure the label prediction using the repre-sentative features by a sparse feature selection. The ex-tracted feature space ensures that the gap between different domains is minimized. The benefit of the effective feature selection is also confirmed in the comparison with the multi-view methods, MVTL and SVM2K. With respect to the per-formance of transfer learning in the unsupervised target do-main, DISMUTE outperforms the transfer learning methods DCDA, MVTL and GFK. In addition to the multi-view reg-ularization between different views and MMD regularization that minimizes the domain divergence, DISMUTE simulta-neously incorporates the global class structures across the domains and the local geometric manifold structures in the target domain, leading to a superior generalization perfor-mance in various domain settings. Specifically, the domain adaptive method GFK performs inferior to DISMUTE in (a ) Classification accuracy with the views of Gabor and PHOG features Figure 3: Parameter tuning examples of DISMUTE for  X  1 and  X  on the dataset webcam  X  dslr with different views of the the features method achieves the best performances for the circled classes. mo st cases due to the performance of GFK depends on the optimal dimensionality for the kernel construction. The op-timal dimensionality is sensitive to different domain-pairs while our method DISMUTE does not depend on parameters for specific domain-pairs. DISMUTE can adaptively select the effective discriminative feature for cross-domain classi-fication in various domain cases. In summary, DISMUTE outstands among all the comparison methods in most ex-perimental cases with a significant margin in performance. To further investigate the convergence rate of DISMUTE. Figure 4 shows the average classification accuracy with re-spect to the number of iterations on four domain-pair datasets with different views of the features. We see that the average classification accuracy of DISMUTE increases steadily when the number of iteration increases and then converges after 50 iterations. This experiment empirically verifies the conver-gence property of DISMUTE obtained from the theoretical analysis.
In this paper we have addressed the open and challenging problem of cross-domain learning with no labeled training data at all in the target domain. We exploit the multi-view feature information to enhance the transfer learning. Specif-ically, we propose a unified framework, DISMUTE, which si-multaneously conducts the sparse feature selection and mini-mizes the gap between the domains. Moreover in this frame-work, to effectively incorporate the inherent data structure, we encode the data local manifold structure in target domain and global class structure across domains into the predicted pseudo-class labels. Theoretic analysis and extensive evalu-ations on a specific application of object identification and image classification against several state-of-the-art methods demonstrate the effectiveness and promise of DISMUTE. This work is supported in part by National Basic Research Program of China (2012CB316400), ZJU X  X libaba Financial Joint Lab, and Zhejiang Provincial Engineering Center on Media Data Cloud Processing and Analysis. ZZ is also sup-ported in part by US NSF (IIS-0812114, CCF-1017828).
