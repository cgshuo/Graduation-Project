 ORIGINAL PAPER Ulrich Reffle  X  Annette Gotscharek  X  Christoph Ringlstetter  X  Klaus U. Schulz Abstract The detection and correction of false friends X  also called real-word errors X  X s a notoriously difficult prob-lem. On realistic data, the break-even point for automatic correction so far could not be reached: the number of addi-tional infelicitous corrections outnumbered the useful correc-tions. We present a new approach where we first compute a profile of the error channel for the given text. During the cor-rection process, the profile (1) helps to restrict attention to a smallsetof X  X uspicious X  X exicaltokensoftheinputtextwhere it is  X  X lausible X  to assume that the token represents a false friend. In this way, recognition of false friends is improved. Furthermore, the profile (2) helps to isolate the  X  X ost prom-ising X  correction suggestion for  X  X uspicious X  tokens. Using a conventional word trigram statistics for disambiguation we obtain a correction method that can be successfully applied to unrestricted text. In experiments for OCR documents, we show significant accuracy gains by fully automatic correction of false friends.
 Keywords False friends  X  Error correction  X  Error dictionaries 1 Introduction False friends, in the context of text correction, are spelling errors that result in lexical words. It has been estimated that false friends X  X lso called real-word errors X  X ccount for about a quarter to a third of all spelling errors [ 14 ]. From the perspective of information retrieval, false friend errors are much more serious than non-word errors as they directly affect the precision for queries that use the misspelled word. The detection and correction of false friends is a notori-ously difficult problem of natural language processing and to say that the problem is unsolved from a practical point of view.

The difficulty of the problem explains to some extent that evaluation results presented for existing approaches are typically based on artificial corpora. Moreover, experiments found in the literature often only indicate which percentage of a given list of false friends can be successfully corrected, ignoring the serious problem of how to find false friends. Unfortunately,eachstrategyforautomatedcorrectionoffalse friends tends to damage correct words. This is not a  X  X ide effect X : in practice, real texts contain much more correct wordsthanfalsefriends,henceitisaseriouschallenge X  X ven the core problem X  X o correct false friends while leaving cor-rect words untouched. Missing standards for evaluation tests and the diversity of corpora and lists used in experiments leads to a situation where it is difficult to directly compare distinct approaches [ 16 , 20 ].

In this paper, we present a new approach for detecting and correcting false friends. Using a fully automated procedure, we first compute a profile of the input text that aims to list those character replacements that represent error patterns fre-quently found in the given text. We apply these error patterns to the given background lexicon and trace all transformations that accidentally lead to a correct word of the lexicon. The resulting list of image words represents a natural candidate set in the sense that for an occurrence w of a word of the list in the text it is plausible to assume that w represents a false friend.

In this way, error profiles help to detect false friends. In a similar way they also help to find the appropriate correc-tion : we may use the reversed list of typical error patterns to compute optimal correction suggestions from the lexicon for the false friend candidates. Finally, a simple statistics on word trigram frequencies shows if it makes sense to prefer the original word (candidate) found in the text or one of the correction suggestions.

The most important ingredient of the method is the first step, where we compute a characteristics of the error channel of the text. Typically, the list of frequent error patterns for a given text is rather small compared to, say, the full list of all possible substitutions, deletions, insertions, merges, splits, etc. As a consequence, our correction strategy is text sensi-tive and restricts attention to only a relatively small set of lexical words of the input text plus a small number of plau-sible correction suggestions. This helps to avoid the above-mentioned problem of  X  X nfelicitous corrections X  to a large extent.

The new method leads to a fully automated correction strategy that can be applied to unrestricted text. In order to simplify the comparison of our method with others, we use a standard data set of the text correction and IR com-munity (TREC-5 [ 8 ]). Our evaluation results on this cor-pus show that the number of cases where we successfully correct a false friend by far exceeds the number of  X  X nfe-licitous X  corrections. In a second experiment based on the Brown corpus [ 9 ] we got similar results. This shows that we obtain a real benefit and the method is ready for use in practice.

The paper is structured as follows. In Sect. 2 ,weshow how to compute a profile of the given input text that lists the typical error patterns found in the text. Section 3 explains how we may use the profile for computing a list of tokens (FF-candidates) for which it is plausible to assume that they represent false friends. For each FF-candidate, we also obtain a small set of correction suggestions. In Sect. 4 , we fully describe our correction strategy. Section 5 is meant as a step towards standardizing evaluation tests for detection and correction of false friends. We precisely define criteria and notions used for evaluation. Section 6 describes our evalua-tion results on the TREC-5 corpus and on the Brown corpus. Section 7 extends these results, introducing a refined cor-rection strategy. Section 8 briefly summarizes related work. In the conclusion, we comment on possible refinements for the correction method introduced below, also looking at dis-tinct practical application domains. An earlier version of this paper has been published in [ 15 ]. 2 Profiling errors of a text In what follows, we face a scenario where a garbled input text T is given. For practical reasons we assume that most of the errors occurring in T can be described by means of the following edit operations : substitutions (replacing one character by another), (single character) deletions, (single character) insertions, merges (replacing a pair of characters by a single character) and splits (mapping a single charac-ter to a pair of characters). 1 We show how to automatically compute an error profile of T which estimates the relative occurrence frequency of each edit operation, depending on the specific characters that are involved in the transformation. The method does not rely on any kind of ground truth data. Details have been described in earlier work [ 13 , 17 ], hence we keep the description short. In the Conclusion, we briefly comment on variations of the method.

By an error lexicon , we mean a collection E of non-lexical stringsthatisgeneratedfromacollectionofcorrectwords, D , systematically applying edit operations of a particular form. In an annotated error lexicon we store with each erroneous token w the corresponding correct word w from D and the edit operation op that was used to produce the error. Entries are represented as triples of the form (w,w , op ) .Anerror lexicon is unambiguous if for a given string w there is at most one entry of the form (w,w , op ) in E . Note that at this point errors stored in error lexica are restricted in the sense that the corresponding correct word is obtained with just one (inverse) edit operation. Of course this restriction could be relaxed. 2.1 Building unambiguous annotated error lexica When constructing an error lexicon for a text profiling task, the main challenge is to find a list of possible errors of accept-able size which still captures most of the errors found in a typical input text. The following procedure describes the con-struction of our annotated error lexicon E , which is directed towards OCRed input texts and which resulted from a series of experiments with related lexica. A lexicon of English, D with 315,500 entries and frequency information was at our disposal. The reader should note that we would end up with a lexicon of astronomical size when applying all possible edit operations to all entries of D E . Hence, a more cautious strategy was chosen. 1. To the most frequent 100,000 words of D E we applied all 2. Inaddition,tothe25,000mostfrequentwordsweapplied 3. to the 5,000 most frequent words we applied all other Entries of E were produced by applying only one edit oper-ation at a time to a correct word. To avoid situations where a correct token is misinterpreted as an error, we deleted all produced strings that were found in an extension  X  D E of the English lexicon where we added to D E various kinds of for-eign language expressions, abbreviations, geographic names, and other non-standard expressions. The construction is visu-alized in Fig. 1 .

Note that for each of the remaining strings w , it is plau-sible to assume that an occurrence of w in a text repre-sents an error. For each such string w , we only stored the retranslation which leads to the most frequent entry w of D
E . As a consequence, the error lexicon is unambiguous. It contains 38,794,294 triples. For applications, E is compiled into a deterministic finite state transducer to be held in main memory. 2.2 Text profiling with unambiguous annotated error lexica As a core step of our procedure, the error lexicon E is used to estimate the occurrence frequency of edit operations in an input text T in the following way. Given T , we first produce a list L with entries of the form (w,w , op ) . Starting with an empty list, we successively process each token w of the text. If
E contains an entry of the form (w,w , op ) , this triple is added to L . Implicitly, w is interpreted as an error with cor-rection w .Otherwise,if w appearsinourbackgroundlexicon D
E , we add the triple This means that w is considered to be a correct word. Tokens of the text that neither appear in E nor in D E are disregarded, they do not contribute to L .
 Consider an edit operation op of the form u  X  v .Given L , the relative occurrence frequency of op in T is estimated as Fr ( op ) := f ( u  X  v)/ f ( u ).
 Here f ( u  X  v) denotes the number of triples in L with edit operation op , and f ( u ) denotes the number of occurrences of u in the first components of all triples. The set of all estimates Fr ( op ) represents our error profile of T . Note that it repre-sents a model for the error channel leading from the correct ground truth version to the garbled input text. 3 FF-detection: computing FF-candidates for a text We now consider the problem of how to detect tokens of the input text T that are likely to represent false friends. One preliminary step is needed. 3.1 Typical edit operation of T The error profile gives us for each edit operation op an esti-mate Fr ( op ) for the relative occurrence frequency of op in the input text T .If Fr ( op ) exceeds a certain threshold we call op a typical edit operation of T . The threshold can be user-defined. In our experiments below, we used a standardized threshold (cf. Sect. 6 ). In the present setting, once we have defined the set M of typical edit operations op , we henceforth forget the values Fr ( op ) . For a refinement of the correction method described below it might be interesting to take the values Fr ( op ) of typical edit operations into account. 3.2 FF-candidates Given the set M of typical edit operations for T we garble the most frequent words w of the English lexicon D E ,follow-ing the same procedure as described in the previous section. However, at this point we only use typical edit operations op  X  M . As before, each lexical string is only garbled at one position, using one operation at a time. Whenever a produced string w accidentally is again in the lexicon of correct words D
E and has an occurrence in the input text T , we store the pair (w ,w) . Note that it is plausible to assume that w rep-resents an erroneous version of w , given that M describes typical error patterns occurring in T . The set of all such pairs E FF , T is called the lexicon of FF candidates for the input text T . The construction is visualized in Fig. 2 .
 E However, it differs in many respects from the full error lexi-con E described above:  X  E  X  The selection of entries of E  X  In E  X  E It is worth mentioning that the FF error lexica E FF , T that we found in the two experiments described below are  X  X lmost X  unambiguous.

For pairs (w ,w)  X  E FF , T , all occurrences of w in T are called FF-candidates . 4 FF-correction: complete correction strategy The procedure explained above leads to a situation where the set of lexical tokens w of the input text T is split into two categories, namely (i) the set of FF-candidates, and (ii) all other lexical tokens. Two problems remain to be solved: 1. How to find the best correction suggestions w for a FF-2. How to decide either to leave w unmodified or to replace For each token w of type (i), the lexicon E FF , T contains at least one pair of the form (w ,w) . Each such string w is called a promising correction suggestion for w . It is important to note that the set of promising correction suggestions for is sensitive to the error profile of the input text T since always obtained from w using a typical edit operation in M . In what follows, only promising correction suggestions are considered for correcting false friend candidates. Our correction strategy never modifies a token of type (ii). We employ a final step where we decide for each FF candi-date w of T either to leave w unmodified, or to replace it by one of its promising correction suggestions. A standard idea is used to solve this disambiguation problem. We assume that a large list of word trigrams w 1 w 2 w 3 with frequencies f pus) is at our disposal. For the given occurrence of w in T we take the two neighbor tokens u and v . We then compare the frequency of the trigram u w v with the frequency of all trigrams of the form u wv , where w represents a promising correction suggestion for w .If f tri ( u w v) is optimal, we leave the given occurrence of w unmodified. We decide to replace w by a candidate w with optimal trigram frequency for w exceeds the score of w by factor 10.
 Remark 1 In the experiments described below, we often find a situation where all relevant trigram frequencies are 0 and the given occurrence of w is left unmodified. The sets of promising correction candidates w for a false friend candi-date w are very small in most cases, often containing only one candidate.

It should be noted that there are several possibilities for refining this decision strategy. In the conclusion we comment on this point. 5 Notions and criteria for evaluation Before we describe our evaluation results, we want to make notions and concepts precise. We also suggest a list of evalua-tion criteria which simplify X  X e hope X  X  direct comparison of the results reached with distinct approaches to false friend detection and correction. 5.1 False friends Given a background lexicon D used for correction, we call a spelling error w a false friend iff w is in D . Since lexica tend to differ as to size and contents, it is worth mention-ing that the notion depends on the lexicon used. In our own experiments described below, we refer to our lexicon D E for English. Recall that during the construction of error lexica described in Sect. 2 , we used an extended list  X  D E . This list contains many entries that probably would be classified as  X  X on-words X  by many native English speakers. Hence, we decided to use D E for defining false friends.

As any strategy for correcting false friends in a fully auto-mated way, our procedure modifies some of the lexical tokens of the input text. Each such modification can be either suc-cessful (we replaced a wrong word by the correct word), or infelicitous (we replaced a correct word by a wrong word), or effectless (we replaced a wrong word by another wrong word). In this situation, there are distinct meaningful notions both for  X  X ecall X  and  X  X recision X . 5.2 Variants of recall In order to formally define recall (which can be considered as a kind of  X  X etection rate X ) it seems most natural to ask for the percentage of false friends of the text T that have been modified in any way, regardless of the success of the modification. In what follows, this percentage is called FF detection recall . As an alternative, we may also describe FF correction recall where we only count false friends that are successfully modified. Both criteria are directly applicable to any automated procedure for detection and correction of false friends. For the special procedure introduced above, yet another notion makes much sense. Note that the FF candi-dates represent our set of  X  X uspicious X  tokens. Whenever the given formalism produces such a set of  X  X uspicious X  tokens, it is natural to ask which percentage of all false friends are  X  X uspicious X . We call this rate the recall for extended FF detection . For interactive FF correction we may highlight all occurrences of suspicious tokens. Last not least, since it is very difficult to correct words of length  X  3 and, on the other hand, longer content words are more critical in terms of information retrieval, we might also introduce variants of the above rates where we use as a basis only false friends of length  X  4. 5.3 Variants of precision Since precision is more  X  X uccess oriented X  the percentage of modified tokens that represent successful modifications seems most relevant. This percentage is called FF correction precision . The percentage of false friends among all modi-fied tokens, which we call FF detection precision , is probably less interesting. For our special procedure it is interesting to ask for the percentage of FF candidates that represent false friends ( precision of extended FF detection ). As above, we might want to restrict considerations to false friends of length  X  4. 5.4 Success criteria In order to judge the success of a given method, we com-pare the number of successful modifications m succ and the number of infelicitous modifications m inf . A method is suc-cessful in absolute terms iff m succ  X  m inf &gt; 0. This measure ignores the length of the input text. Let us define the accuracy acc ( T ) of the text T as the percentage of correctly spelled tokens of T . We may compare this number with the accuracy acc ( T corr ) of the output text T corr of the correction proce-dure. We define the accuracy gain as acc ( T corr )  X  acc 6 Experiments To evaluate the method for detecting and correcting false friends suggested in Sects. 2  X  4 , we conducted two experi-ments described below. 6.1 Experimental setting Recall that a threshold is needed to fix the set of typical edit operations after profiling the input text (cf. Sect. 3 ). In our experiments, edit operations op were added to the set of typical edit operations for the input text whenever a normal-ized variant of  X  ln Fr ( op ) did not exceed 0.6. 2 As a second ingredient of the method, a word trigram model is needed for the correction of false friend candidates (cf. Sect. 4 ). Our model was derived from the data set contributed by Google Inc. containing N-grams up to 5-grams and their frequency counts [ 2 ].

As a general policy, we only corrected words of length  X  4. With respect to the effects of errors on the performance of information retrieval systems, these longer content words are of special interest [ 11 , 18 , 19 ]. 6.2 Examples To illustrate different situations of false friend correction, we give examples collected from the two experiments described below. A prominent edit operation for TREC5 discovered by our error profiling was r substituted by h , which led to an entry in the list of potential false friends with the word pair hate and rate . Now, every occurrence of hate in the TREC5 data was alerted as a potential false friend. At one of the  X  X ot spots X , the correction was successfully triggered by the tri-gram postal rate commission . Examples of the experiment on the Brown corpus successfully detected by the error dictio-nary and resolved by the language model were, quilt instead of guilt and reel instead of feel . Two of the rare negative examples of infelicitous corrections are the substitution of head to read caused by the high frequent trigram to read the that overruled the rarer to head the and the correction of transit to transmit caused by the trigram to transmit to . 6.2.1 TREC-5 corpus Our first experiment uses the TREC-5 corpus [ 8 ]. This huge corpus contains OCRed documents together with the cor-responding ground truth version. It is freely available and represents a standard corpus for evaluating correction strate-gies for OCRed documents. The overall error rate of the OCR output is about 5% on character level. We processed the first 200,000 words of the corpus. We only looked at  X  X ormal X  tokens of the OCR output consisting of standard letters only (not including numbers, dates etc.). Comparing 177,086 nor-mal tokens with the ground truth version we found 18,236 errors 2,019 of which were false friends according to our definition.
Theresultsobtainedwhenapplyingourcorrectionstrategy to the normal tokens of length  X  4 are described in Table 1 , Column (a). The first four lines compare the number of suc-cessful corrections (a false friend was replaced by the correct word) with the number of infelicitous corrections (a correct word was replaced by a wrong word). We had 264 successful corrections and only 4 infelicitous corrections (FF correction precision: 98.51%). This shows that the method gives a real practical benefit.

The accuracy gain of 0.15% reached by our correction on the set of normal tokens is modest. This is not surprising: due to the small number of false friends, even a perfect correc-tion of all false friends would only lead to an accuracy gain of 1.14%. Since correction of false friends is difficult, we might be happy with the numbers reached. Still, one may ask why not a larger percentage of all false friends can be cor-rected. This is due to a mixture of two problems, (1) subopti-mal detection and (2) suboptimal correction of false friends. As to (1) it is important to note that more than 50% of all false friends (1,042) are not even considered by our method because they have length  X  3. Among the set of  X  X ong X  false friends with  X  4 symbols, 20% are missed since they are not classified as false friend candidates. Reasons for this include errors involving more than one edit operation, rare words not covered by the lexicon of FF candidates, or an edit opera-tion that was not spotted by the channel profile. As to (2) Table 1 shows that only 13.13% of all false friends are modi-fied by the correction component (FF detection recall). Many false friend candidates that in fact are false friends are left unmodified since we do not have statistical evidence that the correct word should be preferred. We sometimes simply lack the correct trigram in the basis for our language model. For other false friends, the left or right context word is itself erroneous and thus causes the trigram not to be found (cf. Sect. 7 ). Running a conventional text correction method in advance might help to correct those errors in at least some of the cases. Figure 3 gives a graphical summary of results.
For a deeper analysis, and in order to see the benefit obtained from text profiling, we computed a second lexicon of FF candidates, this time considering all edit operations and not only the  X  X ypical X  ones. We again tried to detect and correct false friends in the set of 177,086 normal tokens. The results are shown in Column (b) of Table 1 . Here the num-ber of long FF errors classified as false friend candidates (extended FF detection recall) is 98.57%. Comparing this with the corresponding number in Column (a) we see that not all relevant error operations could be anticipated by the channel profile. Yet, looking at the FF correction recall, (a) shows a plus of 3.17% (6.55% for long words) due to the much smaller and more precise correction suggestions. The benefit of the channel profile becomes most obvious when comparing precision values in Columns (a) and (b). The lan-guage model alone (b) cannot lift the FF correction precision above 10.45%, which results in an unacceptable number of infelicitous corrections. 3
As a first r X sum X  it is apparent that only with the combi-nation of both, channel profile and language model, we can achieve good precision values: if a word is modified by the method, in 98.14% of all cases it is a false friend error being replaced by the correct word. 6.2.2 Brown-corpus For our second experiment we used an initial extract from the Brown corpus [ 9 ]. The first 24,643 words of the corpus were printed on paper (30 pages), scanned and processed by an OCR engine. We obtained a corpus with authentic OCR errors and the corresponding ground truth version. The char-acter error rate was about 4.5%. The experimental setting for the detection/correction of false friends was as above. Results are described in Table 2 .

Comparing both experiments, there is one remarkable dis-tinction. In the Brown corpus, the percentage of  X  X hort X  false friends of length  X  3 is very high. Since we do not touch these words, the numbers in Table 2 that refer to all false friends are much lower than before.

Ignoring this distinction, percentages reached for  X  X ong X  false friends are very similar in both experiments. Note that extended FF detection recall for long words (percentage of long false friends classified as FF candidates) is lower in the Brown experiment. This indicates that the error profile obtained is less sharp than the error profile for TREC. The effect is not surprising since we used a much smaller text basis for computing the error profile. Even with this profile, 12 successful corrections are obtained without introducing any new error. 7 Global correction strategy The correction strategy defined in Sect. 4 and evaluated above can be characterized as local : as a fundament for our decision we only inspect the left and right neighbor words of the false friend candidate. A global strategy would treat FF candidates w with several occurrences in the text in a special way. Local evidences for correction or a rejection (leaving w unmodi-fied) obtained from the distinct occurrences of w could be aggregated to a global view, thus reaching a better fundament for local decisions. To give an example, if w has five occur-rences in the text, and if at four positions we decide to leave w unmodified (or to replace it, say, by the same correction suggestion w ), then this might be a very strong argument to treat the fifth occurrence in the very same way.

To realize such a global approach, we may use a second pass of document processing where we revisit all hot spots that saw a correction (replacement) decision in the first round backed by our very restrictive language model. The idea is that these positive correction decisions give additional evi-dence that occurrences of the same false friend candidate at other passages in the text should be corrected as well, pos-sibly overriding a weaker correction signal provided by the language model. There are two possible drawbacks of such a strategy: FF candidates wrongly categorized as false friends in the first run can boost more infelicitous corrections; sec-ondly, precision also drops if a correctly categorized false friend pushes a wrong correction decision at another position in the text.

As a preliminary test, we used a naive and brute force variant of this strategy. For our two data sets, after collect-ing local decisions in a first round as before, we revisited all false friend candidates and corrected candidates within the text that had been classified as a false friend at one spot in round 1. In all the cases we observed, there was a unique cor-rection candidate. Though the strategy has to be refined for obvious reasons, the results obtained for the two data sets are surprisingly encouraging. For the TREC-5 data, the FF cor-rection recall for long words improves from 27.02 to 59.06%. Correction precision is reduced from 98.14 to 90.30%. For the Brown corpus, we gain three additional FF corrections but on the other hand we have two infelicitous corrections. Because of the small data basis, the latter results for the Brown corpus are not statistically significant. Still, the differ-ent improvements obtained with the global strategy respec-tively for the TREC-5 and the Brown corpus have a natu-ral statistical and a linguistic interpretation. For the Brown corpus, because of the smaller text basis it is unlikely that a recognized FF candidate occurs again. Furthermore, the TREC-5 corpus is homogeneous with respect to language genre and style, whereas the Brown corpus by definition is composed of different sources from different registers. This feature rises the probability of the use of infrequent words. Both phenomena suggest that a global correction strategy is more promising for long and homogeneous documents, namely, books. 8 Related work A survey on text correction in general which also mentions the correction of false friends can be found in [ 3 ]. In [ 10 ] one section is concerned with errors that represent a valid entry of the background lexicon. The more specialized literature can be separated into contributions that examine the algorithmic side of disambiguation problems, working on pairs of correc-tion candidates (i.e. limited task [ 16 ]), and such that investi-gate realistic applications of false friend correction working with a full scale correction system (i.e. full task [ 16 ]). 8.1 Work on candidate disambiguation One string of the literature on real word errors is centered around the disambiguation of candidate pairs, as for example desert and dessert [ 4  X  6 , 21 ]. Although the practical problems of how to achieve unique candidate pairs and how to avoid a high number of infelicitous corrections is disregarded, the described sophisticated methods for the disambiguation of correction candidates can be of great use for an application oriented text correction system. 8.2 Pure statistical methods An early paper that claimed the effective correction of false friends on synthetic spelling data with a trigram language model was contributed by Mays and Damerau [ 12 , 20 ]. How-ever, as recently clarified by Wilcox et al., Mays and Dame-rau, that had a more realistic approach with regards to the size of the candidate sets than the literature on disambigu-ation strategies, neglected the problem of lacking precision by discarding the data leading to false positives (infelicitous corrections)fromtheirexperiments[ 12 , 20 ];thereimplemen-tation of Wilcox et al., included a fair amount of error-free test data with the intention to measure false positives more realistically. Their experiments show encouraging results of 32.5% (measured on all words) to 21.7% (measured only on content words) precision for the detection of 10% randomly introduced real word errors on a test set of the Wall Street Journal corpus. 5
The results seem to relate a good explanation of the text by the language model gathered from homogeneous training data combined with the randomly introduced errors that are covered by the vocabulary. 6
A more linguistically motivated approach that employed semantic knowledge gathered from Wordnet did not lead to satisfactory results and was outperformed for the used data set by the statistical approach [ 7 , 20 ]. An interesting idea in the field of false friend correction provides the work of Bolshakov et al. on malapropisms. 7 The detection of vio-lated text cohesion by testing word collocations via a data-base seems to deliver promising additional knowledge [ 1 ] and should be integrated into a hybrid system. 8.3 Related own work Error dictionaries have been used by the authors in [ 13 , 17 ]. In [ 17 ] we investigated how a fixed strategy for correcting non-lexical tokens appearing in OCR results can be improved by computing an error profile for the text. The basic strategy can be sketched as follows. For each word w of the OCR result not found in the dictionary , a small list of correction candidates are generated using the dictionary. Each correc-tion candidate v receives a score based on the Levenshtein distance between w and v and the frequency of v .Theword w is replaced by the correction suggestion v with the best score if this score exceeds a given threshold. Using the error profile the basic strategy is refined by replacing the Levenshtein dis-tance (which has a uniform cost of 1 for all edit operations) by a variant with symbol dependent edit weights. Weights for symbol dependent edit operations are derived from the error profile. In [ 13 ] we face the twofold problem of how to retrieve good candidate sets for garbled words from a back-ground dictionary in a very fast way.  X  X ood X  means that the candidate sets are small and have high recall (often contain the right correction). Text profiling based on error dictio-naries is used to improve the quality in this sense. The use of language models and the problem of candidate ranking is not considered. In both papers [ 13 , 17 ] the problem of detect-ing/correcting false friends is not touched. 9 Conclusion We introduced a procedure for detecting and correcting false friends that yields positive results in a realistic appli-cation scenario in the sense that the number of successful corrections was much larger than the number of infelicitous corrections.Thecurrentmethodwasonlyappliedtotokensof length  X  4. In our example corpus we found that many false friends have length  X  3. The correction of garbled tokens of length  X  3 represents a future challenge; we expect that it is hard to achieve a substantial progress when using fully automated formalisms.

We already mentioned at various places above that there are many ways to improve our strategy for detecting and cor-recting false friends. Let us summarize some possibilities, which represent future work.

For the construction of error dictionaries, there are many possible variations. The current construction was motivated by the desire to keep the size of the error dictionaries under control. We initially used error dictionaries based on much more restricted set of edit operations X  X rominent errors known from other OCR experiments. However, it turned out that new OCR corpora come with their own errors. Hence, we preferred to have a large basis of edit operations, which is only applied to a subset of the lexicon of correct words. Obviously the current construction of the error lexicon E designed for OCR output texts. To be used, say, within a spell checker, error dictionaries have to be adapted. Trans-positions of characters should be treated as edit operations. Neighborhood of keys on the keyboard should be taken into account. It might also be possible to directly trace the typical typing errors made by a person during typing, and to use this information when defining the set of FF candidates.
The current use of language models in the last step of the procedure is primitive. For an occurrence of an FF candidate w with left (right) neighbor u ( v ) in the text we only take the frequency of the  X  X entral X  trigram u w v into account. We might be more careful at this point, also looking at the fre-quency of trigrams u u w ( w vv ) that include two left (right) neighbors. Furthermore, when all relevant trigram frequen-cies are 0 at a given disambiguation step, we do not go back to bigrams, or unigrams, neither do we use any kind of smooth-ing. Both remarks show that a much more sophisticated use of language models is possible.

In the present procedure we just split the lexical tokens of the input test T into two categories, FF candidates and others. The relative occurrence frequency in T of the operations that are used to produce these candidates represents a meaningful second score (in addition to trigram statistics) which could be integrated into a refined disambiguation procedure. Such a step could contribute to improved recall values since more edit operations could be taken into account when defining FF candidates.

The global correction strategy discussed in Sect. 7 has to be further investigated for longer textual materials, as for example digitized books. A promising heuristic approach to protect precision is to apply the method to relatively infre-quent words only. In a way, this effect combines the global correction strategy with a backoff language model.
The main contributions of the paper are twofold. First, our approach improves the state of the art. To the best of our knowledge, we describe the first method for fully auto-mated detection and correction of false friends that offers a real practical benefit for OCRed texts. Furthermore, the paper also opens a perspective for future research. Possible paths have been described above. From a more general per-spective we want to emphasize the great potential role of methods that help to compute (approximate) error channels in an automated way (without the use of ground truth data). From our point of view, the study of such methods deserves much more attention, and possible applications go far beyond detection/correction of false friends.
 References
