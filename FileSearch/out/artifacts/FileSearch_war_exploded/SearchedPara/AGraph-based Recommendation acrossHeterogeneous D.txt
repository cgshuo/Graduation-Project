 z jingrui.he@gmail.com Given the users from a social network site, who have been tagged with a set of terms, how can we recommend the movies tagged with a completely different set of terms hosted by another website? Given the users from a website dedicated to Type I and Type II dia-betes, how can we recommend the discussion threads from another website dedicated to gestational diabetes, where the keywords used in the two websites might be quite diverse? In other words, how can we recommend across heterogeneous domains characterized by barely overlapping feature sets?
Despite the vast amount of existing work devoted to recommen-dation within homogeneous domains (e.g., with the same set of features), or collaborative filtering, emerging applications call for new techniques to address the problem of recommendation across heterogeneous domains, such as recommending movies hosted by one website to users from another website with barely overlapping tags. To this end, in this paper, we propose a graph-based approach for recommendation across heterogeneous domains. Specifically, for each domain, we use a bipartite graph to represent the rela-tionships between its entities and features. Furthermore, to bridge the gap among multiple heterogeneous domains with barely over-lapping sets of features, we propose to infer their semantic relat-edness through concept-based interpretation distilled from online encyclopedias, e.g., Wikipedia and Baike. Finally, we propose an efficient propagation algorithm to obtain the similarity between en-tities from heterogeneous domains. Experimental results on both Weibo-Douban data set and Diabetes data set demonstrate the ef-fectiveness and efficiency of our algorithm.
 H.3.5 [ Information Storage and Retrieval ]: On-line Information Services-Web-based services; H.2.8 [ Database Management ]: Database applications-Data mining; I.2.4 [ Artificial Intelligence ]: Knowl-edge Representation Formalisms and Methods-Semantic networks Corresponding author.
 c  X  cross-domain recommendation, heterogenous domains, graph prop-agation, semantic matching
Up until now, recommender systems have been successfully ap-plied to a variety of domains, ranging from movies to research pa-pers, from online friends to social tags. Existing techniques for recommender systems can be mainly categorized into three differ-ent groups: collaborative filtering (CF for short) [15,16], content-based filtering [3,6], and hybrid recommender systems [5]. Most of these techniques focus on a single domain [27,36]. In other words, the users and the items come from the same website.

More recently, researchers have studied cross-domain recom-mendation [19,21,24,32], where the users and the items come from different websites. The main goal of cross-domain recommenda-tion is to alleviate the cold start problem, such that the matching between users and items across different domains is satisfactory in the beginning. Notice that, most, if not all, of existing techniques for cross-domain recommendation work best if different domains share a large number of features. In this way, the relevance between users from one domain and items from another can be naturally ob-tained based on the common features. Please refer to Section 4 for a detailed review of related works.
Nowadays, with the emergence of various e-commerce websites, a natural question is: how can we recommend items across hetero-geneous domains, i.e., the different domains sharing very few fea-tures? Take Weibo (Chinese version of Twitter, http://www. weibo.com ) and Douban (the largest Chinese movie database, http://www.douban.com ) as an example. The tags used by Weibo users are quite different from those used to specify movies on Douban, which is illustrated by the tag clouds in Figure 1. From this figure, we can see that the common Weibo tags include  X  X u-sic X ,  X  X ovie X ,  X  X ood X ,  X 80s X , which generally characterize a Weibo user X  X  hobby, age, constellation, etc. In contrast, Douban tags are generally used to specify a movie X  X  nation, year and genre, such as  X  X SA X ,  X  X apan X ,  X  X nimation X ,  X  X lassic X , etc. For this case, ex-isting techniques for cross-domain recommendation may not be able to accurately identify the movies from Douban that may be of potential interest to Weibo users. Another example is the rec-ommendation of articles across different websites. In particular, among the various social network websites dedicated to diabetes patients, some of them might be open to all types of diabetes pa-tients, such as http://www.tudiabetes.org (denoted by obtained.
 Diabetes1), which is for patients of Type I, Type II, and predia-betes. And some of them might focus on a specific type of diabetes patients, such as https://diabetessisters.org (denoted by Diabetes2), which is for female diabetes patients, especially for those with gestational diabetes. In this case, due to the different vocabulary used by the different websites, existing techniques for cross-domain recommendation may not be able to effectively rec-ommend discussion threads from Diabetes2 to the users of Dia-betes1 who are not aware of the other website.
The main difference between our concern of recommendation across heterogeneous domains and traditional cross-domain recom-mendation is demonstrated in Figure 2. Previous solutions mainly focused on two typical cross-domain settings. In the first setting, either users or items are shared in both domains. For example, in [24], there is an one-one mapping between the users and items of the two domains. It indicates that the two domains have the same groups of users and items as depicted in Figure 2(a). As de-picted in Figure 2(b) and (c), the two domains share either users or items [7, 21]. The second setting is illustrated in Figure 2(d), both users and items are disjoint, but the relations between the two do-mains can be derived through the shared features, such as the same tag space [32,37] or similar user-item interactive patterns [19]. Fur-thermore, in the preceding four cases, the user-item interactive re-lations (the solid lines in the figures) such as rating, review or pur-chase exist in each domain. However, all the solutions for these cases obviously can not be directly used to solve the problem set-ting as shown in Figure 2(e), where domain A only contains users and domain B only contains items and no shared features can be used to establish the links between the users in domain A and the items in domain B.

However, the heterogenous cross-domain recommendation sce-nario of Figure 2(e) is a popular and valuable setting in real world. For example, it will create a lot of business opportunities if we can accurately recommend products in eBay to a user in Tweet or Face-book. Therefore, in this paper, we focus on the challenging prob-lem of recommendation across heterogeneous domains. In general, this new problem setting poses two challenges. 1. The first challenge is the sparsity of shared features across 2. The second challenge is designing an effective and efficient
To overcome these challenges, we propose to use bipartite graphs to represent the relationships between entities and their features, and build the connection between heterogeneous domains through semantic matching of features. Based on the composite multi-partite graph, we propose an effective and efficient propagation al-gorithm to infer the global similarity between entities across differ-ent domains. The major contributions of this paper can be summa-rized as follows. 1. We propose a novel recommendation approach based on a 2. We conduct extensive experiments on two real applications:
The rest of this paper is organized as follows. In Section 2, we in-troduce our graph-based approach for recommendation across het-erogeneous domains including the semantic matching between dif-ferent tags/keywords. In Section 3, we evaluate the performance of our approach against existing techniques. Finally, we survey the related works in Section 4 and conclude our paper in Section 5.
Different from traditional CF-based methods, in this paper, we target a more challenging problem of cross-domain recommenda-tion, i.e., recommending the items from one domain to the users from another heterogenous domain. This problem essentially boils down to inferring the similarity between different types of objects (users and items) from multiple domains. In this section, we present our graph-based method: we first start with some notations, fol-lowed by the introduction of the global similarity and the efficient computation of the relevance vectors, and finally discuss semantic matching for inducing cross-domain correlation.
Without loss of generality, in this paper, we consider 2 different domains, although the proposed method can be easily generalized to multiple domains. Formally, for the i th domain ( i =1,2), we use a bi-partite graph G i = f V i ; E i g to represent the relationships be-tween the objects in this domain and their characterizing features, where V i is the set of nodes in this graph, and E i is a set of undi-rected edges. Let n i denote the number of objects in the i and m i denote the number of features. Therefore, V i consists of two types of nodes: n i object nodes, and m i feature nodes. Notice that in E i , an edge only exists between different types of nodes, i.e., between an object node and a feature node, and the edge weights are set to the feature value of the corresponding object. Let X n i m i , denote the connectivity matrix between the two types of nodes, whose elements are set to be the edge weights.

In cross-domain recommendation where only a small fraction of features are shared across different domains, a critical question is how to build the connection between the bi-partite graphs for dif-ferent domains. To address this problem, in our method, we pro-pose the following matching graph between features from the two domains. Let G 0 = f V 0 ; E 0 g denote such a bi-partite matching graph, where V 0 includes all the feature nodes from the two do-mains, and E 0 denotes the set of edges connecting features from different domains. Based on this graph, we define connectivity matrix X 0 , ( m 1 + m 2 ) ( m 1 + m 2 ) , whose elements measure the similarity between features from different domains. Details of learning the connectivity matrix X 0 based on semantic matching will be discussed in Subsec. 2.4.
 Putting all above graphs together, we get a multi-partite graph G = f V; E g as shown in Figure 3, where V = V 1 E = E 1 graph. X is an ( n 1 + n 2 + m 1 + m 2 ) ( n 1 + n 2 + m 1 matrix and is represented as, where ( ) T denotes matrix transpose and 0 is a zero matrix. Based on this graph, our goal is to infer the similarity between object nodes from different domains.
In graph G , the direct connections between object nodes from different domains are absent, e.g., between user nodes and item nodes in Figure 3. Thus, we will measure their similarity based on graph propagation. To be specific, we first normalize the affinity matrix X as follows.
 Figur e 3: A multi-partite graph across two domains. Red lines are user-feature edges in domain 1 and blue lines are item-feature edges in domain 2. The green lines between red rect-angles and blue rectangles are the edges between user features and item features, which can be established by the semantic similarity of features. where D is a diagonal matrix with each element equal to the row sum of X ; S 1 , S 2 , and S 0 are normalized versions of X and X 0 , respectively.

In order to compute the global similarity between the i th and all the other nodes in the composite multi-partite graph, we use v to denote the ( n 1 + n 2 + m 1 + m 2 ) dimensional vector, whose i element is 1 and all the others are 0. Using the manifold ranking algorithm proposed in [35], the global similarity vector with respect to the i th node can be written as ( I S ) 1 v i , where I is an ( n 1 + n 2 + m 1 + m 2 ) ( n 1 + n 2 + m 1 + m 2 ) identity matrix, and is a positive scalar whose value is close to 1. Putting all these vectors together, we have the following ( n 1 + n 2 + m 1 ( n 1 + n 2 + m 1 + m 2 ) global similarity matrix K , Each element in K measures the global similarity between each pair of nodes. The property of the global similarity matrix K can be interpreted using Taylor expansion [14], i.e., K = Notice that the i th term measures the weighted i th -step similarity on the multi-partite graph, and its impact on the overall similarity decreases exponentially with respect to i .
 It is easy to see that K has the following block structure. According to Equation 2, we conclude that, A = [ and C = ces of K , which are of the same dimensionality as A , B , and C respectively. Since we are only interested in the similarity among objects from different domains, instead of the whole matrix K , we only compute the submatrix K 1 , ( n 1 + n 2 ) ( n 1 + n 2 has the following closed form solution.
 Proof. Lemma 1 can proved by applying the Woodbury formula [25] on Equation 2, and leveraging the block structure of both K K .  X 
Notice that the inverse of both C and BC 1 B T exists. This is because K 1 is part of K , which is the inverse of the symmetric positive definite matrix I S .

Based on K 1 , if the objects in the first domain are users, and the objects in the second domain are items, the relevance between the k th user and all the items can be obtained from the k column of K , since K 1 is a symmetric matrix. In other words, the relevance vector can be written as s i = K 1 u i , where u n 1 + n 2 dimensional vector. The elements of u i are 0 except the i one, which is set to 1.
In this subsection, we focus on the efficient computation of the relevance vector, which is summarized in Algorithm 1. It takes as input matrices B and C , the query vector u (with only one non-zero entry), and the number of iterations n iter . The output is the relevance vector s with respect to u . Here we define form C = I ~ S 0 .

The algorithm works as follows. In Step 1, we initialize the rel-evance vector to be the query vector u . In the outer loop starting from Step 2, we set w to be B T s in Step 3, initialize r to be w in Step 4, and pass both vectors to the inner loop starting from Step 5. In the inner loop, we update r in Step 6 n iter times. Finally, in the outer loop, we re-scale r in Step 8, based on which we obtain the current estimate of the relevance vector s .
 Algorithm 1 Graph-based Recommendation across Heterogeneous Domains Input: B , C , u , , n iter Output: s 1: Initialize s to be u 2: for i = 1 to n iter do 3: w B T s 4: Initialize r to be w 5: for j = 1 to n iter do 6: r ~ S 0 r + (1 ) w 7: end for 8: r 1 1 r 9: s B r + (1 ) u 10: end for
The convergence property of Algorithm 1 is presented in the fol-lowing theorem.

T HEOREM 1. As n iter goes to infinity, s returned by Algorithm 1 converges to (1 ) K 1 u .
 Proof. We prove Theorem 1 via the following two steps. In the first step, we analyze the convergence property of the inner loop be-tween Step 5 and Step 7 of Algorithm 1; then in the second step, we analyze the convergence property of the outer loop between Step 2 and step 10.

First, the following lemma shows the convergence property of the inner loop.
L E MMA 2. Given w , as n iter goes to infinity, in the inner loop of Algorithm 1, r converges to (1 ) C 1 w .
 Proof. To prove Lemma 2, simply observe that upon convergence, r = ~ S 0 r + (1 ) w . Therefore, ( I ~ S 0 ) r = (1 ) w . Together with the fact that C = I ~ S 0 , we conclude the proof for Lemma 2.  X 
Based on Lemma 2, we can see that the inner loop provides an efficient way of computing r = (1 ) C 1 w . Combined with Step 2 and Step 8 of Algorithm 1, we can see that in Step 9, the vec-tor r is equal to C 1 B T s . Upon convergence, s = BC 1 B (1 ) u . Therefore, ( I BC 1 B T ) s = (1 ) u . Together with the definition of K 1 in Equation (3), we conclude our proof for Theorem 1.  X  Comparing Algorithm 1 with direct computation of s = ( I BC 1 B T ) 1 u , the major advantage is its time efficiency. In our applications, it is often the case that both B and ~ S 0 are very sparse. Let l B and l ~ S ~ S 0 respectively. The time complexity of Algorithm 1 can be shown as follows.

L EMMA 3. The time complexity of Algorithm 1 is O ( l B + l Proof. It is easy to see that the major computation in Algorithm is matrix vector multiplication. Since both B and ~ S 0 are very sparse, the computational complexity of ~ S 0 r is O ( l ~ S tional complexity of B is O ( l B ) , which completes the proof.
Therefore, Algorithm 1 scales to large data sets since its time complexity is linear with respect to the number of non-zeros el-ements in B and ~ S 0 . On the other hand, for direct computation of s via matrix inversion, the typical time complexity is O (( n n ) 2 : 373 ) using optimized CW-like algorithms [12], which is pro-hibitive for large data sets.
According to our algorithm, some relationships between features should be established in order to discover the similarity of objects in the two domains, i.e., inferring E 0 in G 0 . In this subsection, we introduce how to find the relationships between different fea-tures from two heterogeneous domains, respectively. For a better interpretation, we use the case where the features are represented by tags to illustrate our method.
As we declared before, most tags coming from heterogenous do-mains are different, which demands us to correlate two tags on se-mantic level rather than lexical level. In general, semantic matching requires more context information of tags. To accomplish it, we try to discover hyper-links existing among millions of concepts in on-line encyclopedias.

Most prior works on computing semantic relatedness resorted to some well-defined lexical resources, such as WordNet [18]. How-ever, lexical resources require lexicographic expertise and only cover a small fraction of language lexicons. As we observed, the tags adopted by Weibo users contain many proper names, neologisms, and etc., which are seldom included in current lexical resources. The authors in [11, 22] used substantial semantic information of online encyclopedias, e.g., Wikipedia, to enrich the semantic rep-resentation of terms. In this paper, we also utilize online encyclo-pedias to achieve the semantic matching of tags. Concretely, we adopt Wikipedia and Baike ( http://baike.baidu.com ) for English tags and Chinese tags, respectively.

As we known, an online encyclopedia contains millions of con-cepts including person, location, organization, hobby and etc. There exists an article page describing the fact about each concept. As well, there are many hyper-links linking to other concepts on each article page to enrich its semantic description. According to the principle of previous Wikipedia based methods [11,22], two terms, i.e., two concepts, are considered semantically related if they co-occur as hyper-links in one article page. The more such article pages can be found, the more semantically related the two terms are. Figur e 4: The articles in online encyclopedias derive the con-cept vectors of tags. The left part display some articles in the online encyclopedia. In this case, tag x and tag y are mapped into Concept x and Concept y respectively, and then tag x mantically related to tag y through some encyclopedia concepts although they are not represented by the same term.
Then, we formalize the semantic interpretation of a tag. In order to represent the semantics of a tag through the contexts provided by the encyclopedia, we should first map a tag into an article entry (i.e., a concept) of the encyclopedia. Given a tag i and a concept c , we map i into c if i and c are exactly same or c  X  X  string is a maximal substring of i  X  X  string. Under this mapping scheme, we can find a mapped concepts for nearly 90% of tags. As depicted in Figure 4, tag x and tag y are first mapped into Concpet x and Concpet spectively. Then, we can find that Concept x and Concept y occur in the article page of Concept 1 , indicating their semantic relatedness. Similarly, we may find another evidence, i.e., Concept 6  X  X  article page. Therefore, although Concept x and Concept not same, they are still semantically related. Clearly, the indirect matching through the contexts provided by concepts X  article pages in online encyclopedia rather than lexical matching, is exactly what we expect in the semantic matching for two tags.

According to Explicit Semantic Analysis (ESA for short)  X  X  ba-sic idea [11], the semantic interpretation of a tag i can be rep-resented by a concept vector which is formally defined as [ c ; :::; c C ] 2 R C . C is the total number of concepts in the en-cyclopedia and c j (1 j C ) represents the semantic relevance of concept j to tag i , i.e., the TF-IDF score of concept i  X  X  occur-rence in concept j  X  X  article. Figure 4 describes the compositions of  X  C x and  X  C y . Thus, the semantic similarity between tag x and tag y can be represented as the cosine similarity of  X  C x and i.e., E 0 in the bi-partite graph G 0 , we can set a threshold . Then, the edge between x and y is created if cos (  X  C x ;  X  C y cos (  X  C x ;  X  C y ) is set as the element of connectivity matrix X to Figure 3). Accordingly, decides the density of X 0 . In our experiments, we will display how affects on the performance of our recommendation algorithm.
In this section, we evaluate the performance of our proposed graph-based algorithm through two applications of recommenda-tion across heterogeneous domains.
We first present some experiment settings including data sets, baseline methods and performance metrics.
To demonstrate the performance of our algorithm, we focus on the following two different types of data sets in our evaluation ex-periments.
The first data set is collected from two Chinese websites: Weibo and Douban. Weibo is the largest Chinese Twitter which has more than 0.6 billion accounts and 90 million active users per day. Rec-ommending various products to Weibo users can create plenty of business opportunities. On the other hand, Douban is a famous Chinese website of movie reviews. Although both Weibo users and Douban movies are profiled by a set of tags, the tags in these two websites are quite different (recall to Figure 1 in Section 1). Thus, recommending Douban movies to Weibo users is a typical recom-mendation problem across heterogeneous domains. To construct the bi-partite graphs for this problem, we define the edge weight between an object node and a feature node (the weight of E by a tag score , which quantifies the extent to which a tag can char-acterize the user/movie. For a Weibo user, the tag score is com-puted by a local tag propagation algorithm proposed in [33]. For a Douban movie, the score of a tag is its tagging frequency for this movie which can be fetched directly from Douban website. From Douban website, we totally collected 4,028 movies whose average rating scores are above 7 : 5 (10 is the best) and review numbers are greater than 2000 . Since most Weibo tags and Douban tags are both written in Chinese, we used Baike encyclopedia to explore the semantic similarity of these tags.
The second data set is collected from two diabetes social network websites, i.e., Diabetes1 and Diabetes2 introduced in Section 1. It can be obtained from our Lab X  X  website ( http://gdm.fudan. edu.cn/GDMWiki/Wiki.jsp?page=Network%20DataSet ).
 The former is dedicated to diabetes patients of Type I, Type II, and pre-diabetes, whereas the latter focuses on female diabetes patients, especially those with gestational diabetes. Our goal is to recommend discussion threads from Diabetes2 to the users of Diabetes1. Due to the different vocabulary used by the differ-ent websites, we can also regard this problem as recommendation across heterogeneous domains. In this data set, we randomly col-lected 5,000 users from Diabetes1. Each user is profiled by a set of keywords extracted from his/her historical posts on this web-site. From Diabetes2, we collected 2,790 posts (threads) each of which is also characterized by a set of keywords. Furthermore, to fully demonstrate the effectiveness of our proposed approach, we removed some tags shared by the two forums as a pre-processing step. When we constructed the bi-partite graphs, we set the edge weights of E i ( i =1,2) as the TF-IDF scores of the keywords for each user/post.
Then, we introduce how to capture the ground truths of the two cross-domain recommendation tasks in our experiments. Unlike some famous movie recommendation data set such as MovieLens ( https://movielens.org. ), there are no explicit rating/review data of Weibo users on Douban movies, it is dif-ficult to directly obtain the ground truth of Weibo users X  prefer-ences on Douban movies. Therefore, we have to rely on human assessments for generating ground truth of Douban movie recom-mendation. Specifically, we randomly selected 100 Weibo users from our data set as volunteers, to whom we recommended some Douban movies generated by the tested approaches. Then we asked each volunteer whether to accept the recommended movies or not. Each volunteer can give one of three answers, i.e., yes , no and unknown . We only took the move of yes as a hit recommenda-tion. We took their average acceptance rates as the performance measure of the tested approaches.
To generate the ground truth of a diabetes patient X  X  preferred posts, we first generated a representative vector for each Diabetes1 X  X  user and Diabetes2 X  X  post. Given a Diabetes1 X  X  user, we collected all his/her published posts as a corpus from which a set of keywords were extracted. Each element of the user vector is the TF-IDF score of one keyword. So does a Diabetes2 X  X  post vector. Then, we ranked all posts according to the cosine similarity of the user vector and the post vectors. Finally, we assume that the user will only accept top 30% of the posts whose cosine similarity is greater than 0. These posts were considered as recommendation ground truth of the user. Since all Diabetes keywords are English words, we used Wikipedia X  X  concepts to compute the semantic similarity of keywords.
To emphasize the effectiveness of our approach, we also com-pared the performance of some state-of-the-art baselines.
It is the most naive method for recommendation. To let this base-line be more competitive, we randomly recommended items from some filtered candidates. In this naive baseline, for Douban movie recommendation, we randomly selected movies from those having more than 15,000 reviews and more than 8.8 rating scores. For Diabetes recommendation, we randomly recommended the posts from those having more than 2 keywords shared with the users. We denote this baseline as RAND.
It measures the similarity between a user and an item by com-puting the cosine similarity of their feature (tag/keyword) vectors. This recommendation scheme can be further divided into two base-lines, i.e., LEXIC1 and LEXIC2. In LEXIC1, the vector X  X  element is set as 1 if the user/item has the corresponding feature, otherwise as 0. In LEXIC2, each element of the vector equals to the corre-sponding feature X  X  score to the user/item. Obviously, an item will not be recommended to a user by this method if they do not share any common feature.
To highlight the effectiveness of our graph propagation approach, we adopted ESA scheme [11] as a baseline. Specifically, a user or an item are characterized by a profile vector that is the sum of concept vectors of user/item X  X  features. Then, we measure the sim-ilarity between a user and an item by the cosine similarity of their profile vectors.
Besides ESA, Normalized Google Distance (NGD for short) [9] is also an effective measure on two terms X  semantic relatedness. For recommendation, the similarity between a user and an item can be represented by the NGD of their feature (tag/keyword) sets. Specif-ically, given a user u and an item v , suppose T u is the in-neighbor concept set of u  X  X  features in the encyclopedia hyper-link graph, so is T v for v  X  X  features. Then the NGD similarity of u and v is computed as
GS ( u; v ) = 1 max where N is the total number of concepts in the encyclopedia. We denote this baseline as GGLDIST.
In our experiments, we use the following three metrics to quan-tify the acceptance rate of the users (Weibo users or diabetes users) to the top-k recommended items (Douban movies or diabetes posts). The results of these metrics directly reflect the performance of all recommendation methods.
 Precision at rank k (Pr). It is defined as the proportion of top-k recommended items that are accepted by the users. sion score of top-k recommended items and is defined as: where r el ( i ) is an indicator function. It equals to 1 if the i -th rec-ommended item is accepted, otherwise 0. P ( i ) is the accepted pro-portion of top-i items and M is the total number of accepted items in all top-k items. Compared with Pr, AP is more accurate to mea-sure ranking performance.
 another popular metric to measure relevance level of search results to the query in IR systems [17]. For a set of top-k recommended items, the nDCG score can be calculated as: where rel ( i ) is same as Eq. (5) and Z is a normalized factor. Com-pared with AP, nDCG is more sensitive to rank position of recom-mended items. In general, a user pays less attention to the items listed behind, hence nDCG is better to evaluate recommendation performance. Next, we present our experimental results. In particular, we use Precision, Average Precision and nDCG as evaluation metrics to quantify the acceptance rate of the users to the top-k recommended items, i.e., movies and posts. Note that we set the in Equation (2) to 0.99 when running our algorithm in the experiments. Small vari-ations of will not affect the comparative performance of our ap-proach versus the competitors. We also study the impact of the parameter on the overall performance, which is used to construct the connectivity matrix based on semantic matching.
For Douban movie recommendation task, as mentioned before, the performance results were evaluated by surveying the 100 volun-teers who have Weibo accounts in our data set. In order to highlight our graph-based approach X  X  superiority, we compared our approach with all baselines for this recommendation task. Furthermore, we selected an optimal value of (=0.01) in our algorithm. The pa-rameter study of will be introduced in the following subsection.
Figure 5(a) (c) display the average scores of all competitors X  performance under the three metrics including the performance of recommending top-4 to top-8 movies. We only list the results from top-4 to top-8 due to the space limitation of the figures. The re-sults of other top-k recommendations also highlight our method X  X  superiority. In the figures, our graph-based method is denoted as GRAPH. GRAPH0 is a variation of our method where the weights of E i ( i = 0 ; 1 ; 2) are set to 1 or 0 instead of concrete feature score (for E 1 and E 2 ) or semantic similarity value of two terms (for E 0 ). From the results we find that all methods perform best when recommending top-4 movies. Naturally, good recommenda-tion methods should rank the hit items to priority positions. Com-pared with other competitors, GRAPH almost always performs the best. The superiority of GRAPH over GRAPH0 justifies the ad-vantage of fine-grained edge weight in the multi-partite graph. The superiority of ESA and GRAPH over LEXIC1/2 justifies the effec-tiveness of concept-based semantic interpretation w.r.t. uncovering the latent relationships between users and items. The superiority of GRAPH over LEXIC1/2, GGLDIST and ESA indicates that, our graph-based method can discover more similarities between users and items that are originally neglected due to the gap of heteroge-nous domains. The outperformance of our approach over these baselines should be mainly attributed to graph propagation prin-ciple.
By statistics, we found that there are many shared keywords across the two diabetes domains. Specifically, the Jaccard coef-ficient of the keyword sets of two domains is 0.221. As a result, we first removed a fraction of shared keywords before running the algorithms in order to simulate the setting of cross-heterogenous-domain recommendation, i.e., few common keywords can be found in the two domains. Then, we tested the algorithms under differ-ent situations when a specific proportion of shared keywords are deleted. As introduced in Subsec. 3.1.2, the ground truth of dia-betes post recommendation were generated according to the prin-ciple of LEXIC2. Consequently, we only compared GRAPH with RAND, GGLDIST and ESA for this recommendation task. Re-ferring to the results of Douban movie recommendation, we only list the performance of top-4 diabetes posts since all approaches perform best when recommending top-4 items. The other top-k re-sults will not affect the comparative performance of our proposed approach versus the competitors.

Figure 6(a) (c) depict performance scores of the competitors as the function of removed proportion of shared keywords where the proportion varies from 0% to 50%. From the figures we can find that, although the performance of all methods except for RAND de-cays evidently as more shared keywords are removed, GRAPH only decays a bit. Even when 50% of shared keywords are removed, our method X  X  performance can still stay above 0.6. It indicates that the graph-based method is more qualified for recommendation across heterogenous domains with rarely shared features.
As mentioned before, the parameter in our algorithm decides the sparsity of E 0 in the bi-partite graph G 0 . That is, for two fea-ture nodes belonging to two different domains respectively, an edge linking them is established only when the semantic similarity of the two features is bigger than . Then, how does it affect the perfor-mance of our graph-based algorithm? To answer this question, we tested the performance of our approach when the is set to differ-ent values.

Figure 7(a) (c) show our approach X  X  performance as the func-tion of on Douban movie recommendation. In the figures, each line corresponds the performance of a top-k recommendation where k varies from 4 to 8. From the figures we can see the performance of our proposed approach is robust with respect to small variations in the value of . In particular, our approach gains the best per-formance in all metrics when = 0 : 01 . The results of other k X  X  values also agree this point. On one hand, it is obvious that too sparse edges in G 0 (larger ) are not beneficial to the recommen-dation performance because fewer connections across two domains can be derived through them. On the other hand, our experiment results indicate that more edges in G 0 (smaller ) between user features and item features will not improve the recommendation performance either because potential noises will be imported by the additional edges with lower weights in G 0 .
In this section, we survey the research works related to our work through the following three categories.
By now, Social Recommender Systems have become the main part of recommender systems including content-based and structure-based mechanisms. Hannon et al. [13] proposed content-based user profiling based on CF for recommending new friends in Twitter. In [1], users are first represented by a frequency vector of hashtags and entities in tweets and then are recommended to with the URLs having similar profile vectors. In [3], consumers are recommended to based on the analysis of product reviews. For structure-based mechanism, the authors in [4, 8] emphasized that the structure of social links is an important clue to recommend new users. The so-cial clues are effective on mitigating cold start problem in CF.
More recently, cross-domain recommendation has been a hot spot in recommendation field. Ignacio et al. [10] made a survey of emerged solutions for cross-domain recommendation and em-phasized two major tasks. One is to exploit knowledge about the users and the items in the source domain for improving recom-mendation quality for the items in the target domain. The second task is to make joint recommendations for the items belonging to different domains. Many previous works on cross-domain recom-mendation focus on improving CF-based scheme. For example, the authors in [19,32] tried to migrate the rating data from a dense aux-iliary domain to alleviate the cold start problem in a sparse target domain resulting in the improvement of recommendation perfor-mance in the target domain. Besides, [2, 29] merged user profiles distributed in different domains for better recommendation. The settings in above works are different from our problem setting. The cross-domain setting of Zhang et al. X  X  work [34] is similar to ours. But they correlated Facebook users to eBay products through Face-book X  X  page categories and eBay taxonomy other than the semantic similarities between features in the heterogenous domains. Transfer learning has been extensively studied in the past decade. It aims to improve a learning task in a target domain by using the knowledge transferred from other domain in which a related task is known [23]. Recently, transfer learning techniques have been widely applied to mitigate the sparsity problem of collaborative fil-tering in cross-domain recommendation.

In [19], Li et al. proposed a transfer learning approach that per-forms a co-clustering strategy on the rating matrix of an auxiliary domain with high rating density, and discovers rating patterns at the cluster level. Assuming that user rating behavior is similar in two domains, the approach establishes relations between domains based on the found rating patterns. In their other work [20], Li et al. ex-tended the previous approach by means of a probabilistic model in which a user or item belonging to a particular cluster is not binary, but is described in terms of probability density function. In this case a common model is built from the ratings of all the considered domains, without requiring a dense source domain. Also address-ing the sparsity problem in CF-based recommendation, W. Pan et al. [24] transferred the rating knowledge from some auxiliary data source in binary form to a target numerical rating matrix through a novel framework of transfer by collective factorization. In all above works, the user-item relations, i.e., users X  ratings on items exist in both domains which is different to our scenario. Y. Zhu et al. [37] also applied transfer learning method to learn image classification by using the knowledge of document/image labels in auxiliary do-mains. In this work, relations between documents and images are captured by their co-occur tags. B. Cao et al. [7] proposed a non-parametric Bayesian framework for solving the collective link pre-diction, which allows knowledge to be adaptively transferred across heterogeneous tasks while taking into account the similarities be-tween tasks. These methods are not suitable to be applied in our setting, where we aim to build the connections between heteroge-neous entities across different domains instead of learning multiple models.
In NLP, measuring semantic relatedness of two terms or entities is an important task. Many prior works utilized the lexical con-cepts in WordNet X  X  taxonomy [18] based on the deepest point in the taxonomy [31] or information content [26]. To expand con-cept coverage, many researchers took Wikipedia as the knowledge base of semantic interpretation. M. Strube et al. [28] and D.Milne et al. [22] used the taxonomy and the Normalized Google Dis-tance [9] in Wikipedia to compute semantic relatedness, respec-tively. E.Gabrilovich et al. [11] proposed a widely applied model of semantic interpretation, i.e., Explicit Semantic Analysis which is also based on the relations between concepts in online encyclo-pedia. More recently, T. Mikolov et al. [30] proposed word embed-ding which learns a distributed representation for a word through neural network. Then the semantic relatedness of two words can be computed by the distance of two word vectors. This approach is effective but costly in computation and depends training corpus.
In this paper, we address a new challenging problem of recom-mendation across heterogenous domains. That is, recommending the items in one domain to the users in another domain when the features of the two domains rarely overlap, as well as no user-item interactive relations in each domain can be obtained. To this end, we first capture the semantic relations between user features and item features (tags/keywords) through ESA-based concept interpre-tation from online encyclopedias. Then, we propose a novel graph-based algorithm to discover the hidden similarity between two enti-ties (users/items) via propagation principle. We not only exploit our algorithm with solid proofs, but also justify our approach X  X  perfor-mance superiority over the state-of-the-art competitors through ex-tensive evaluations. The results demonstrate our approach X  X  merits to many real world applications of cross-domain recommendation.
This paper was supported by the National NSFC (No.61472085, 61171132, 61033010), by National Key Basic Research Program of China under No.2015CB358800, by Basic research project of Shanghai science and technology innovation action plan under No.15JC1400900, and by Shanghai Science and Technology De-velopment Funds (13dz2260200, 13511504300). This paper was also partially supported by an IBM Faculty Award. [1] F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing [2] F . Abel, E. Herder, G.-J. Houben, N. Henze, and D. Krause. [3] S. Aciar, D. Zhang, S. Simoff, and J. Debenham.
 [4] M. J. Brzozowski and D. M. Romero. Who should i follow? [5] R. Burke. Hybrid web recommender systems. LNCS , [6] I. Cantador, A. Bellogin, and D. Vallet. Content-based [7] B. Cao, N. N. Liu, and Q. Yang. Transfer learning for [8] J. Chen, W. Geyer, C. Dugan, M. Muller, and I. Guy. Make [9] R. L. Cilibrasi and P. M. Vitanyi. The google similarity [10] I. Fernandez-Tobias, I. Cantador, M. Kaminskas, and [11] E. Gabrilovich and S. Markovitch. Computing semantic [12] L. Gall and Fran X ois. Powers of tensors and fast matrix [13] J. Hannon, M. Bennett, and B. Smyth. Recommending [14] Hazewinkel and Michiel. Taylor series . Encyclopedia of [15] T. Hofmann. Collaborative filtering via gaussian probabilistic [16] T. Hofmann. Latent semantic models for collaborative [17] K. J  X  larvelin and J. Kek  X  lal  X  lainen. Cumulated gain-based [18] F. L., G. E., and Matias. WordNet: An Electronic Lexical [19] B. Li, Q. Yang, and X. Xue. Can movies and books [20] B. Li, Q. Yang, and X. Xue. Transfer learning for [21] Z. Lu, E. Zhong, L. Zhao, E. Xiang, W. Pan, and Q. Yang. [22] D. Milne and I. H. Witten. An effective, low-cost measure of [23] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE [24] W. Pan, N. N. Liu, E. W. Xiang, and Q. Yang. Transfer [25] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. [26] P. Resnick. Using information content to evaluate semantic [27] S. Sen, J. Vig, and J. Riedl. Tagommenders: Connecting [28] M. Strube and S. P. Ponzetto. Wikirelate! computing [29] M. Szomszor, H. Alani, I. Cantador, K. OHara, and [30] M. Tomas, S. Ilya, C. Kai, C. Greg, and D. Jeffrey. [31] Z. Wu and M. Palmer. Verb semantics and lexical selection. [32] W. C. Wynne, H. Mong, and L. Lee. Making [33] D. Yang, Y. Xiao, H. Tong, J. Zhang, and W. Wang. An [34] Y. Zhang and M. Pennacchiotti. Predicting purchase [35] D. Zhou, J. Weston, A.Gretton, O.Bousquet, and [36] T. C. Zhou, H. Ma, M. R. Lyu, and I. King. Userrec: A user [37] Y. Zhu, Y. Chen, Z. Lu, S. J. Pan, G.-R. Xue, Y. Yu, and classification. In Proc. of AAAI , 2011.
