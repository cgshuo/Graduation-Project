 Chinese Academy of Sciences Chinese Academy of Sciences Queens College and Graduate Center, The City University of New York Dublin City University Chinese Academy of Sciences between different annotation formats.
 cause of the lack of morphology in Chinese, we perform annota tion adaptation from the much training. 1. Introduction
Much of statistical NLP research relies on some sorts of manu ally annotated corpora to train models, but annotated resources are extremely expe nsive to build, especially on a large scale. The creation of treebanks is a prime example (Marcus, Santorini, and Marcinkiewicz 1993). However, the linguistic theories motivating these annotation efforts are often heavily debated, and as a result there ofte n exist multiple corpora for the same task with vastly different and incompatible ann otation philosophies. For example, there are several treebanks for English, includin g the Chomskian-style Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), the HPSG LinGo Redwoods
Treebank (Oepen et al. 2002), and a smaller dependency treeb ank (Buchholz and Marsi 2006). From the perspective of resource accumulation, it se ems a waste in human efforts. 1 ferent domains, which for the above example range from financ ial news (Penn
Treebank/ Wall Street Journal ) to transcribed dialog (LinGo). It would be nice if a system could be automatically ported from one set of guideli nes and/or domain to another, in order to exploit a much larger data set. The secon d problem, domain adaptation, is very well studied (e.g., Blitzer, McDonald, &amp; Pereira 2006; Daum  X e III 2007). This work focuses on the widely existing and equally i mportant problem, an-notation adaptation, in order to adapt the divergence betwe en different annotation guidelines and integrate linguistic knowledge in corpora w ith incongruent annotation formats.
 principles of the solutions, and present a series of success ively improved concrete models, the goal being to transfer the annotations of a corpu s ( source corpus ) to the annotation format of another corpus ( target corpus ). The transfer classifier is the fun-damental component for annotation adaptation algorithms. It learns correspondence regularities between annotation guidelines from a parallel annotated corpus , which has two kinds of annotations for the same data. In the simplest mo del (Model 1), the source classifier trained on the source corpus gives its predications to the tr ansfer classifier trained on the parallel annotated corpus, so as to integrate the knowledge in the two corpora. In a variant of the simplest model (Model 2), the tra nsfer classifier is used to transform the annotations in the source corpus into the anno tation format of the target corpus; then the transformed source corpus and the target co rpus are merged in order to train a more accurate classifier. Based on the second model , we finally develop an optimized model (Model 3), where two optimization strategi es, iterative training and predict-self re-estimation, are integrated to further imp rove the efficiency of annotation adaptation.
 the efficacy of our methods. For word segmentation, the probl em of incompatible annotation guidelines is one of the most glaring: No segment ation guideline has been widely accepted due to the lack of a clear definition of Chines e word morphology.
For dependency parsing there also exist multiple disparate annotation guidelines. For 120 example, the dependency relations extracted from a constit uency treebank follow syn-tactic principles, whereas the semantic dependency treeba nk is annotated in a semantic perspective.
 pus (PD) (5 . 86M words) (Yu et al. 2001) and the smaller but more popular Pe nn
Chinese Treebank (CTB) (0 . 47M words) (Xue et al. 2005). They utilize very differ-ent segmentation guidelines; for example, as shown in Figur e 1, PD breaks Vice-
President into two words and combines the phrase visited-China as a compound, compared with the segmentation following the CTB annotatio n guideline. It is prefer-able to transfer knowledge from PD to CTB because the latter a lso annotates tree structures, which are useful for downstream applications l ike parsing, summariza-tion, and machine translation, yet it is much smaller in size . For dependency pars-ing, we use the dependency treebank (DCTB) extracted from CT B according to the rules of Yamada and Matsumoto (2003), and the Semantic Depen dency Treebank (SDT) built on a small part of the CTB text (Che et al. 2012). Co mpared with the automatically extracted dependencies in DCTB, semantic de pendencies in SDT re-veal semantic relationships between words, rather than the syntactic relationships in syntactic dependencies. Figure 2 shows an example. Experim ents on both word seg-mentation and dependency parsing show that annotation adap tation results in signifi-cant improvement over the baselines, and achieves the state -of-the-art with only local features.
 of the problem of annotation adaptation. Section 3 briefly in troduces the tasks of word segmentation and dependency parsing as well as their state-of-the-art models. In Section 4 we first describe the transfer classifier that indicates the intrinsic principles of annotation adaptation, and then de pict the three successively enhanced models for automatic adaptation of annotations. A fter the description of experimental results in Section 5 and the discussion of appl ication scenarios in Sec-tion 6, we give a brief review of related work in Section 7, dra wing conclusions in
Section 8. 2. Automatic Annotation Adaptation
We define annotation adaptation as a task aimed at automatically adapting the divergence between different annotation guidelines. Stat istical models can be de-signed to learn the relevance of two annotation guidelines i n order to trans-form a corpus from one annotation guideline to another. From this point of view, annotation adaptation can be seen as a special case of t ransfer learning.
Through annotation adaptation, the linguistic knowledge i n different corpora is integrated, resulting in enhanced NLP systems without comp licated models and features.

McDonald, and Pereira 2006; Daum  X e III 2007), which also can be seen as a special case of transfer learning. It aims to adapt models trained in one d omain (e.g., chemistry) to work well in other domains (e.g., medicine). Despite superfi cial similarities between domain adaptation and annotation adaptation, we argue that the underlying problems are quite different. Domain adaptation assumes that the lab eling guidelines are preserved between the two domains X  X or example, an adjectiv e is always labeled as JJ regardless of whether it is from the Wall Street Journal (WSJ) or a biomedical text, and only the distributions are different X  X or example, the word control is most likely a verb in WSJ but often a noun in biomedical texts (as in control experiment ).
Annotation adaptation, however, tackles the problem where the guideline itself is changed, for example, one treebank might distinguish bet ween transitive and intransitive verbs, while merging the different noun types (NN, NNS, etc.), or one treebank (PTB) might be much flatter than the other (LinGo), n ot to mention the fundamental disparities between their underlying linguis tic representations (CFG vs. HPSG).
 be the data and Y be the annotation. Annotation adaptation can be understood as a
Through annotation adaptation, we want to change the annota tions of the data from one guideline to another, leaving the data itself unchanged. Ho wever, in domain adaptation,
P ( X ) changes, but P ( Y ) is assumed to be constant. The word assumed means that the adaptation aims to make the model better adapt to a different domain with the same annotation guidelines.
 linguistic (rather than statistical) point of view, and tac kles a serious problem fun-damentally different from domain adaptation, which is also a serious problem (often leading to &gt; 10% loss in accuracy). More interestingly, annotation adap tation, without any assumptions about distributions, can be simultaneousl y applied to both domain and annotation adaptation problems, which is very appealin g in practice because the latter problem often implies the former. 122 3. Case Studies: Word Segmentation and Dependency Parsing 3.1 Word Segmentation and Character Classification Method
In many Asian languages there are no explicit word boundarie s, thus word segmen-tation is a fundamental task for the processing and understa nding of these languages.
Given a sentence as a sequence of n characters: where x i is a character, word segmentation aims to split the sequence into m (  X  n ) words: where each subsequence x i : j indicates a Chinese word spanning from characters x to x j .

Shen 2003), where each character in the sentence is given a bo undary tag representing its position in a word. Following Ng and Low (2004), joint wor d segmentation and part-of-speech (POS) tagging can also be solved using a character classification approach by extending boundary tags to include POS information. For wor d segmentation we adopt the four boundary tags of Ng and Low (2004), B , M , E , and S , where B , M , and E mean the beginning, the middle, and the end of a word, respectivel y, and S indicates a single-character word. The word segmentation result can be generat ed by splitting the labeled character sequence into subsequences of pattern S or BM  X  E , indicating single-character words or multi-character words, respectively.
 score function:
Where function f maps ( x , y ) into a feature vector, w is the parameter vector generated score of the sentence is further factorized into each charac ter, where y classification label of character x i .
 the inputs x to the outputs y . Algorithm 1 shows the perceptron algorithm for tuning the parameter w . The  X  X veraged parameters X  technology (Collins 2002) is us ed for better performance. The feature templates of the classifier is show n in Table 1. The function to function values 1, 2, 3, and 4, respectively. 3.2 Dependency Parsing and Spanning Tree Method
Dependency parsing aims to link each word to its arguments so as to form a directed graph spanning the whole sentence. Normally, the directed g raph is restricted to a
Algorithm 1 Perceptron training algorithm. 1: Input : Training set C 2: w  X  0 3: for t  X  1 .. T do  X  T iterations 4: for ( x , y )  X  C do 5:  X  z  X  argmax z f ( x , z ) w 6: if  X  z 6 = y then 7: w  X  w + f ( x , y )  X  f ( x ,  X  z )  X  update the parameters 8: end if 9: end for 10: end for 11: Output: Parameters w dependency tree where each word depends on exactly one paren t, and all words find their parents. Given a sentence as a sequence n words: dependency parsing finds a dependency tree y , where ( i , j )  X  y is an edge from the head word x i to the modifier word x j . The root r  X  x in the tree y has no head word, and each x is dependent on x i , then all the words between i and j must be directly or indirectly dependent on x i . Therefore, if we put the words in their linear order, preced ed by the root, all edges can be drawn above the words without crossing . We follow this constraint because the dependency treebanks in our experiments are pro jective.
 pendency tree can be factorized into the dependency edges in the tree. The spanning 124 tree method (McDonald, Crammer, and Pereira 2005) factoriz es the score of the tree as the sum of the scores of all its edges, and the score of an edge i s defined as the inner product of the feature vector f and the weight vector w . Given a sentence x , the parsing procedure searches for the candidate dependency tree with t he maximum score: bottom X  X p dynamic programming algorithm is designed to sea rch for the candidate parse with the maximum score as shown in Algorithm 2, where V [ i , j ] contains the candidate dependency fragments of the span [ i , j ]. The feature templates are similar to those of the first-ordered MST model (McDonald, Crammer, a nd Pereira 2005). Each feature is composed of some words and POS tags surround word i and/or word j , as well as an optional distance representation between the two words. Table 2 shows the feature templates without distance representations. 4. Models for Automatic Annotation Adaptation
In this section, we present a series of discriminative learn ing algorithms for the auto-several shortened forms are adopted for convenience of desc ription. We use source corpus to denote the corpus with the annotation guideline that we do not require, which is of course the source side of adaptation, and target corpus denotes the corpus with the desired guideline. Correspondingly, the annotation gu idelines of the two corpora are denoted as source guideline and target guideline , and the classifiers following the two annotation guidelines are respectively named as source classifier and target clas-sifier . Given a parallel annotated corpus , that is, a corpus labeled with two annotation
Algorithm 2 Dependency parsing algorithm. 1: Input : sentence x to be parsed 2: for [ i , j ]  X  [1, | x | ] in topological order do 3: buf  X  X  X  4: for k  X  i .. j  X  1 do  X  all partitions 5: for l  X  V [ i , k ] and r  X  V [ k + 1, j ] do 6: insert D ERIV ( l , r ) into buf 7: insert D ERIV ( r , l ) into buf 8: end for 9: end for 10: V [ i , j ]  X  best K in buf 11: end for 12: Output: the best of V [1, | x | ] 13: function D ERIV ( p , c ) 14: return p  X  c  X  X  ( p root , c root ) }  X  new derivation 15: end function guidelines, a transfer classifier can be trained to capture the regularity of transforma-tion from the source annotation to the target annotation . The classifiers mentioned here are normal discriminative classifiers that take a set of features as input and give a classification label as output. For the POS tagging problem , the classification label is a POS tag, and for the parsing task, the classification labe l is a dependency edge, a constituency span, or a shift-reduce action.

The annotation quality and data size of the parallel annotat ed corpus determine the we can generate a noisy one automatically from the source cor pus and the target corpus.
For example, we can apply the source classifier on the target c orpus, thus generating 126 a parallel annotated corpus with noisy source annotations a nd accurate target anno-tations. The training procedure of the transfer classifier p redicts the target annotations with guiding features extracted from the source annotation s. This approach can alleviate accurately. By reducing the noise in the automatically gene rated parallel annotated corpus, a higher accuracy of annotation adaptation can be ac hieved.
 intrinsic principles of annotation adaptation, then descr ibe a series of successively enhanced models that are developed from our previous invest igation (Jiang, Huang, lower source classifier provide additional guiding feature s to the upper transfer classi-fier, yielding an improved classification result. A variant o f the first model (Model 2) uses the transfer classifier to transform the source corpus f rom source guideline to target guideline first, then merges the transformed source c orpus into the target corpus in order to train an improved target classifier on the enlarge d corpus. An optimized model (Model 3) is further proposed based on Model 2. Two opti mization strategies, iterative training and predict-self re-estimation, are ad opted to improve the efficiency of annotation adaptation, in order to fully utilize the know ledge in heterogeneous corpora. 4.1 Transfer Classifier
In order to learn the regularity of the adaptation from one an notation guideline to annotated corpus is a corpus with two different annotation g uidelines, the source guide-line and the target guideline. With the target annotation la bels as learning objectives and the source annotation labels as guiding information, th e transfer classifier learns the statistical regularity of the adaptation from the sourc e annotations to the target annotations.
 normal classifier except for the introduction of additional guiding features. For word dependency parsing, an effective guiding feature is the dep endency path between the hypothetic head and modifier, as shown in Figure 3. However, o ur effort is not limited to this, and more special features are introduced: A classifi cation label or dependency path is attached to each feature of the baseline classifier to generate combined guiding features. This is similar to the feature design in discrimin ative dependency parsing (McDonald, Crammer, and Pereira 2005; McDonald and Pereira 2006), where the basic features, composed of words and POSs in the context, are also conjoined with link direction and distance in order to generate more special fea tures.
 segmentation, where  X   X  = B X  indicates that the source classification label of the cur rent character is B , demarcating the beginning of a word. The combination strat egy derives sifications. The parameter-tuning procedure of the transfe r classifier will automatically learn the regularity of using the source annotations to guid e the classification decision.
In decoding, if the current character shares some basic feat ures in Table 3 and it is it as M . D to leverage the knowledge from the target annotation of the p arallel annotated corpus, and the training procedure of the transfer classifier also le arns the relative weights between the guiding features and the original features. The refore, the knowledge from both the source annotation and the target annotation are aut omatically integrated together, and higher and more stable prediction accuracy ca n be achieved.
Guiding  X   X  =B 128 4.2 Model 1
The most intuitive model for annotation adaptation uses two cascaded classifiers, the source classifier and the transfer classifier, to integrate t he knowledge in corpora with different annotation guidelines. In the training procedur e, a source classifier is trained on the source corpus and is used to process the target corpus, generating a parallel annotated corpus (albeit a noisy one). Then, the transfer cl assifier is trained on the parallel annotated corpus,with the target annotations as t he classification labels, and the source annotation as guiding information. Figure 4 depi cts the training pipeline. The on the development sets of the source corpus and target corpu s.
 words (for dependency parsing) is input into the source clas sifier to obtain a classifica-tion result under the source guideline; then it is input into the transfer classifier with this classification result as the guiding information to get the final result following the target guideline. This coincides with the stacking method f or combining dependency parsers (Martins et al. 2008; Nivre and McDonald 2008), and i s also similar to the Pred baseline for domain adaptation in Daum  X e et al. (Daum  X e III a nd Marcu 2006; Daum  X e III 2007). Figure 5 shows the pipeline for decoding. 4.3 Model 2
The previous model has a drawback: It has to cascade two class ifiers in decoding to integrate the knowledge in two corpora, which seriously deg rades the processing speed.
Here we describe a variant of the previous model, aiming at au tomatic transforma-tion (rather than integration as in Model 1) between annotation guidelines of human-annotated corpora. The source classifier and the transfer cl assifier are trained in the same way as in the previous model. The transfer classifier is u sed to process the source corpus, with the source annotations as guiding information , so as to relabel the source corpus with the target annotation guideline. By merging the target corpus and the accuracy can be achieved.
 pseudo-codes for simplicity and convenience of extensions . Algorithm 3 shows the overall training algorithm for the variant model. C s and C and the target corpus. M s and M s  X  t denote the source classifier and the transfer classifier. C q p denotes the p corpus relabeled in q annotation guideline; for example, C is a corpus that labels the text of the source corpus with the t arget guideline. Func-tions T RAIN and T RANS T RAIN train the source classifier and the transfer classifier, respectively, both invoking the perceptron algorithm, but with different feature sets. Functions A NNOTATE and T RANS A NNOTATE call the function D models (source/transfer classifiers), feature functions ( without/with guiding features), and inputs (raw/source-annotated sentences).
 simplicity. Compared to the online knowledge integration m ethodology of the previous model, annotation transformation leads to improved perfor mance in an offline manner by integrating corpora before the training procedure. This approach enables processing speeds several times faster than the cascaded classifiers in the previous model. It also has another advantage in that we can integrate the knowledge in more than two corpora without slowing down the processing of the final classifier. 4.4 Model 3
The training of the transfer classifier is based on an automat ically generated (rather than a gold standard) parallel annotated corpus, where the s ource annotations are
Algorithm 3 Baseline annotation adaptation. 1: function A NNO T RANS ( C s , C t ) 2: M s  X  T RAIN ( C s )  X  source classifier 6: C t  X   X  C t s  X  C t  X  integrated corpus with target guideline 7: return C t  X  8: end function 9: function D ECODE ( M ,  X   X   X  , x ) 10: return argmax y  X  GEN ( x ) S ( y | M ,  X   X   X  , x ) 11: end function 130 provided by the source classifier. Therefore, the performan ce of annotation transfor-mation is correspondingly determined by the accuracy of the source classifier, and we can generate a more accurate parallel annotated corpus for b etter annotation adaptation if an improved source classifier can be obtained. Based on Mod el 2, two optimization strategies X  X terative bidirectional training and predict -self hypothesis X  X re introduced to optimize the parallel annotated corpora for better annot ation adaptation. accuracy by iteratively optimizing the parallel annotated corpora. In each training iteration, both source-to-target and target-to-source an notation transformations are per-formed, and the transformed corpora are used to provide bett er annotations for the parallel annotated corpora of the next iteration. Then in th e new iteration, the better parallel annotated corpora will result in more accurate tra nsfer classifiers, resulting in the generation of better transformed corpora.
 loop of lines 6 X 13 iteratively performs source-to-target a nd target-to-source annota-tion transformations. The source annotations of the parall elly annotated corpora, C are trained on the current parallel annotated corpora (line s 7 X 8); they are used to produce the transformed corpora (lines 9 X 10), which provid e better annotations for the parallel annotated corpora of the next iteration. The it erative training terminates when the performance of the classifier trained on the merged c orpus C (line 13).
 guidance of source annotations. In the first iteration, the t ransformed corpora generated
Algorithm 4 Iterative annotation transformation. 1: function I TER A NNO T RANS ( C s , C t ) 2: M s  X  T RAIN ( C s )  X  source classifier 4: M t  X  T RAIN ( C t )  X  target classifier 6: repeat 7: M s  X  t  X  T RANS T RAIN ( C s t , C t )  X  source-to-target transfer classifier 8: M t  X  s  X  T RANS T RAIN ( C t s , C s )  X  target-to-source transfer classifier 12: M  X   X  T RAIN ( C t  X  )  X  enhanced classifier trained on merged corpus 13: until E VAL ( M  X  ) converges 14: return C t  X  15: end function 16: function D ECODE ( M ,  X   X   X  , x ) 17: return argmax y  X  GEN ( x ) S ( y | M ,  X   X   X  , x ) 18: end function the transformed corpora provide better annotations for the parallel annotated corpora of the subsequent iteration; the transformation accuracy w ill improve gradually along with the optimization of the parallel annotated corpora unt il convergence. from another perspective. This hypothesis is implicit in ma ny unsupervised learning approaches, such as Markov random field; it has also been succ essfully used by Daum  X e
III (2009) in unsupervised dependency parsing. The basic id ea of predict-self is, if a original input by a reverse procedure. If applied to annotat ion transformation, predict-self indicates that a better transformation candidate foll owing the target guideline can be more easily transformed back to the original form followi ng the source guideline. tion transformation is using a reversed annotation transfo rmation procedure to filter out unreliable predictions of the previous transformation . In detail, a source-to-target annotation transformation procedure is performed on the so urce corpus to obtain a pre-diction that follows the target guideline; then a second, ta rget-to-source transformation procedure is performed on this prediction result to check wh ether it can be transformed back to the original source annotation. The source-to-targ et prediction results that fail filtering .
 using the reversed transformation procedure for filtering, the re-estimation strategy integrates the scores given by the source-to-target and tar get-to-source annotation transformation models when evaluating the transformation candidates. By properly tuning the relative weights of the two transformation direc tions, better transformation performance is achieved. The scores of the two transformati on models are weighted, integrated in a log-linear manner:
The weight parameter  X  is tuned on the development set. To integrate the predict-self reestimation into the iterative transformation train ing, a reversed transformation model is introduced and the enhanced scoring function is use d when the function T
RANS A NNOTATE invokes the function D ECODE . 5. Experiments
To evaluate the performance of annotation adaptation, we ex periment on two impor-tant NLP tasks, Chinese word segmentation and dependency pa rsing, both of which can be modeled as discriminative classification problems. F or both tasks, we give the performances of the baseline models and the annotation adap tation algorithms. 5.1 Experimental Set-ups
We perform annotation adaptation for word segmentation fro m People X  X  Daily (PD) (Yu et al. 2001) to Penn Chinese Treebank 5.0 (CTB) (Xue et al. 2005). The two corpora are built according to different segmentation guidelines a nd differ largely in quantity of data. CTB is smaller in size with about 0 . 5M words, whereas PD is much larger, containing nearly 6M words. Table 4 shows the data partition ing for the two corpora. 132 extract from PD a subset that is comparable to CTB in size. Bec ause there are many extremely long sentences in the original PD corpus, we first s plit them into normal sen-tences according to the full-stop punctuation symbol. We ra ndomly select 20, 000 sen-sentences from the PD test data as the new testing/developin g set. We label the smaller version of PD as SPD. The balanced source corpus and target co rpus also facilitate the investigation of annotation adaptation.
 syntactic dependency treebank (DCTB) (Yamada and Matsumot o 2003) to the Seman-tic Dependency Treebank (SDT) (Che et al. 2012). Semantic de pendency encodes the semantic relationships between words, which are very diffe rent from syntactic depen-dencies. SDT is annotated on a small portion of the CTB text as depicted in Table 5; therefore, we use the subset of DCTB covering the remaining C TB text as the source corpus. We still denote the source corpus as DCTB in the follo wing for simplicity. 5.2 Baseline Segmenters and Parsers
We train the baseline perceptron classifiers for Chinese wor d segmentation on the train-ing sets of CTB and SPD, using corresponding development set s to determine the best training iterations. The performance measurement indicat or for word segmentation is P is the percentage of words in segmentation results that are s egmented correctly, and R is the percentage of correctly segmented words in the gold st andard words. parsing that predicts the graphic dependency structure for the input sentence without considering dependency labels. The perceptron-based base line dependency models are trained on the training sets of DCTB and SDT, using the develo pment sets to determine the best training iterations. The performance measurement indicator for dependency parsing is the Unlabeled Attachment Score, denoted as Preci sion P , indicating the percentage of words in predicted dependency structure that are correctly attached to their head words.
 tion on the development set. Accuracies of the baseline clas sifiers are listed in Table 6.
We also report the performance of the classifiers on the testi ng sets of the opposite corpora. Experimental results are in line with our expectat ions. A classifier performs better in its corresponding testing set, and performs signi ficantly worse on testing data following a different annotation guideline.
 as the performance of the parsers on the testing sets of the op posite corpora. Similar 134 to the situations in word segmentation, two parsers give sta te-of-the-art accuracies on their own testing sets, but perform poorly on the other testi ng sets. This indicates the degree of divergence between the annotation guidelines of D CTB and SDT. 5.3 Automatic Annotation Adaptation
As a variant of Model 1, Model 2 shares the same transfer class ifier, and differs only in training and decoding of the final classifier. Tables 8 and 9 sh ow the performances of systems resulting from Models 1 and 2, as well as the classifie rs trained on the directly merged corpora. The time costs for decoding are also listed t o facilitate the practical comparison.
 accuracy, due to the different and incompatible annotation guidelines. Model 1, the simplest model for annotation adaptation, gives significan t improvement over the baseline classifiers for word segmentation and dependency p arsing. This indicates that the statistical regularities for annotation adaptation le arned by the transfer classifiers bring performance improvement, utilizing guided decision s in the cascaded classifiers.
Model 2 leads to classifiers with accuracy increments compar able to those of Model 1, while consuming only one third of the decoding time. It is inc onsistent with our expec-tation. The strategy of directly transforming the source co rpus to the target guideline also facilitates the utilization of more than one source cor pus.
 development sets are used to determine the best training ite rations for the iterative annotation transformations. After each iteration, we test the performance of the clas-sifiers trained on the merged corpora. Figures 7 and 8 show the performance curves for Chinese word segmentation and semantic dependency pars ing, respectively, with iterations ranging from 1 to 10. The performance of Model 2 is naturally included 136 in the curves (located at iteration 1). The curves show that, for both segmentation and parsing, the accuracies of the classifiers trained on the merged corpora consis-tently improve in the earlier iterations (e.g., from iterat ion 2 to iteration 5 for word segmentation).
 are shown in Figures 9 and 10. The curves show the performance s of the predict-self re-estimation with a series of weight parameters, rang ing from 0 to 1 with step 0 . 05. Note that in both figures, the points at  X  = 0 show the performances of Model 2.
We find that predict-self filtering brings a slight improveme nt over the baseline for word segmentation, but even decreases the accuracy for depe ndency parsing. An initial analysis on the experimental results reveals that the filter ing strategy discards some complicated sentences in the source corpora, and the discar ded sentences would bring further improvement if properly used. For example, in word s egmentation, predict-self filtering discards 5% of sentences from the source corpus, co ntaining nearly 10% of the strategy. With properly tuned weights, predict-self re-es timation can make better use of the training data. The largest accuracy improvements achie ved over Model 2 for word segmentation and dependency parsing are 0 . 3 points and 0 . 6 points.
 iterative training and predict-self re-estimation on the b asis of Model 2 (this enhanced 138 model is denoted as Model 3). We find that the predict-self re-estimation brings im-provement to the iterative training at each iteration, for b oth word segmentation and dependency parsing. The maximum performance is achieved at iteration 4 for word segmentation, and at iteration 5 for dependency parsing. Th e corresponding models are evaluated on the corresponding testing sets, and the exp erimental results are also shown in Tables 8 and 9. Compared to Model 1, the optimized ann otation adaptation strategy, Model 3, leads to classifiers with significantly hi gher accuracy and to process-ing speeds that are several times faster. Tables 10 and 11 sho w the experimental results compared with previous work. For both Chinese word segmenta tion and semantic de-pendency parsing, automatic annotation adaptation yields state-of-the-art performance,
SemEval contest (Che et al. 2012), many other technologies i ncluding clause segmen-tation, system combination, and complicated features were adopted, as well as elab-orate engineering. We also performed significance tests 2 annotation adaptation.We find that for both Chinese word seg mentation and semantic dependency parsing, annotation adaptation brings signific ant improvement (p &lt; 0 . 001) over the baselines trained on the target corpora only. on the results of annotation adaptation. For word segmentat ion, the words are grouped according to POS tags. For dependency parsing, the dependen cy edges are grouped according to POS tag pairs. For each category, the recall val ues of baseline and annota-tion adaptation are reported. To filter the lists, we set two s ignificance thresholds with respect to the proportion of a category and the performance fl uctuation between two systems. For word segmentation, only the categories with pr oportions of more than 1% and with fluctuations of more than 0 . 1 points are reserved, and for dependency word segmentation and dependency parsing, respectively. F or both tasks, annotation adaptation brings improvement for most of the situations.
 140 iments are conducted for word segmentation and dependency p arsing with fixed-size source corpora and varying-size target corpora. We use SPD a nd DCTB as the source corpora for word segmentation and dependency parsing, resp ectively. Figures 13 and 14 show the performance curves on the testing sets. We find tha t, for both word segmen-tation and dependency parsing, the improvements brought by annotation adaptation are more significant when the target corpora are smaller. It m eans that the automatic annotation adaptation is more valuable when the size of the t arget corpus is small, which is good news for the situation where the corpus we are co ncerned with is smaller but a larger differently annotated corpus exists.
 strategies without using additional training data is unfai r. Our work aims to find another way to improve NLP tasks: focusing on the collection of more training data instead of making full use of a certain corpus. We believe tha t the performance of automatic annotation adaptation can be further improved by adopting the advanced technologies of previous work, such as complicated feature s and model combination. It would be useful to conduct experiments with more source-ann otated training data, such as the SIGHAN data set for word segmentation, to investigate the trend of improvement along with the further increment of annotated sentences. It would also be valuable to evaluate the improved word segmenter and dependency parser on the out-of-domain data sets. However, currently most corpora for word segment ation and dependency parsing do not explicitly distinguish the domains of their d ata sections, making such evaluations difficult to conduct. 6. Discussion: Application Situations
Automatic annotation adaptation aims to transform the anno tations in a corpus to the annotations following other guidelines. The models for ann otation adaptation use a transfer classifier to learn the statistical correspondenc e regularities between different annotation guidelines. These statistical regularities ar e learned from a parallel anno-tated corpus, which does not need to be manually annotated. I n fact, the models for annotation adaptation train the transfer classifier on an automatically generated parallel annotated corpus, which is generated by processing a corpus with a classifier trained on another corpus. That is to say, if we want to conduct annota tion adaptation across several corpora, no additional corpora need to be manually a nnotated. This setting makes the strategy of annotation adaptation more general, b ecause it is much harder to manually annotate a parallel annotated corpus, regardless of the language or the NLP problem under consideration. To tackle the problem of noise in automatically generated annotations, the advanced models we designed generate a bet ter parallel annotated corpus by making use of strategies such as iterative optimiz ation.
 multiple corpora with different and incompatible annotati on philosophies for the same task. As our case studies, both Chinese word segmentation an d dependency parsing have more than one corpora with different annotation guidel ines, such as the People X  X 
Daily and the Penn Chinese Treebank for Chinese word segment ation. In a more abstract view, constituency grammar and dependency grammar can be tr eated as two annota-tion guidelines for parsing. The syntactic knowledge in a co nstituency treebank and a dependency treebank, therefore, can be integrated by autom atic annotation adaptation.
For example, the LinGo Redwoods Treebank can also be transfo rmed to the annotation guideline of the Semantic Dependency Treebank.
 unsupervised induction can be seen as following a special an notation philosophy. For bilingually projected annotations, the annotation guidel ine would be similar to that of the counterpart language. For unsupervised induced annota tions, the annotation guide-the underlying annotation guidelines may be largely differ ent from that of the testing sets, which usually come from human-annotated corpora. The system trained on a bilin-gually projected or unsupervised induced corpus may perfor m poorly on an existing 142 testing set, but if the projected or induced corpus has high i nner consistency, it could improve a system trained on an existing corpus by automatic a nnotation adaptation.
In this point of view, the practical value of the current work on bilingual projection and unsupervised induction may be underestimated, and anno tation adaptation could make better use of the projected or induced knowledge. 3 7. Related Work
There has already been some preliminary work tackling the di vergence between dif-ferent annotation guidelines. Gao et al. (2004) described a transformation-based con-verter to transfer a certain word segmentation result to ano ther annotation guideline.
They designed class-type transformation templates and use d the transformation-based error-driven learning method of Brill (1995) to learn what w ord delimiters should be modified. Many efforts have been devoted to manual treebank t ransformation, where
PTB is adapted to other grammar formalisms, such as CCG and LF G (Cahill et al. 2002; Hockenmaier and Steedman 2007). However, all these ar e heuristic-based X  X hat is, they need manually designed transformation templates a nd involve heavy human engineering. Such strategies are hard to be generalized to P OS tagging, not to mention other complicated structural prediction tasks.
 differently annotated corpora (Jiang, Huang, and Liu 2009; Jiang et al. 2012), which can be seen as the preliminary work of automatic annotation adap tation. Motivated by our initial investigation, researchers applied similar metho dologies to constituency parsing (Sun, Wang, and Zhang 2010; Zhu, Zhu, and Hu 2011) and word seg mentation (Sun and Wan 2012). This previous work verified the effectiveness of automatic annotation adaptation, but did not reveal the essential definition of th e problem nor the intrinsic principles of the solutions. Instead, this work clearly defi nes the problem of annotation a series of gradually improved models. The most advanced mod el learns transformation regularities much better and achieves significant higher ac curacy for both word segmen-tation and dependency parsing, without slowing down the fina l language processors. transfer learning (Pan and Yang 2010), where the source and t arget tasks are similar, but not identical. More specifically, the problem related to ann otation adaptation assumes that the labeling mechanism across the source and target tas ks are the same, but the predictive functions are different. The goal of annotation adaptation is to adapt the source predictive function to be used for the target task by e xploiting the labeled data of the source task and the target task. Furthermore, automat ic annotation adaptation approximately falls into the spectrum of relational-knowl edge-transfer problems (Mihalkova, Huynh, and Mooney 2007; Mihalkova and Mooney 20 08; Davis and
Domingos 2009), but it tackles problems where the relations among data between the source and target domains can be largely isomerous X  X r, in ot her words, with different and incompatible annotation schemes. This work enriches th e research of transfer learning by proposing and solving an NLP problem different f rom previous situations.
For more details of transfer learning please refer to the sur vey of Pan and Yang (2010). notated corpus (which may be automatically generated); thi s fact puts the method into the neighborhood of the family of approaches known as annota tion projection (Hwa et al. 2002, 2005; Ganchev, Gillenwater, and Taskar 2009; Sm ith and Eisner 2009; Jiang and Liu 2010; Das and Petrov 2011). Essentially, annotation adaptation and annotation projection tackle different problems; the former aims to tr ansform the annotations from one guideline to another (of course in the same language), whereas the latt er aims to project the annotation (as well as the annotation guideline ) from one language to another.
Therefore, the machine learning methods for annotation ada ptation pay attention to automatic transformation of annotations, while for annota tion projection, the machine learning methods focus on the bilingual projection across l anguages.
 two techniques for training improved dependency parsers. T he co-training technique lets two different parsing models learn from each other duri ng the parsing of unlabeled text: One model selects some unlabeled sentences it can confi dently parse, and provides them to the other model as additional training data in order t o train more powerful parsers. The classifier combination lets graph-based and tr ansition-based dependency parsers utilize the features extracted from each other X  X  pa rsing results, to obtain com-bined, enhanced parsers. The two techniques aim to let two mo dels learn from each other on the same corpus with the same distribution and annot ation guideline, whereas our strategy aims to integrate the knowledge in multiple cor pora with different annota-tion guidelines.
 ilarities with the co-training algorithm in parsing (Sarka r 2001), where the training procedure lets two different models learn from each other du ring parsing of the raw text. The key idea of co-training is to utilize the complemen tarity of different parsing models to mine additional training data from raw text, where as iterative training for annotation adaptation emphasizes the iterative optimizat ion of the parallel annotated many unsupervised learning approaches; it has been success fully used in unsupervised dependency parsing (Daum  X e III 2009). We adapt this idea to t he scenario of annotation adaptation to improve transformation accuracy.
 mentation and dependency parsing. For example, the introdu ction of global training or complicated features (Zhang and Clark 2007, 2010); the in vestigation of word struc-tures (Li 2011); the strategies of hybrid, joint, or stacked modeling (Nakagawa and
Uchimoto 2007; Kruengkrai et al. 2009; Wang, Zong, and Su 201 0; Sun 2011); and the semi-supervised and unsupervised technologies utilizing raw text (Zhao and Kit 2008;
Johnson and Goldwater 2009; Mochihashi, Yamada, and Ueda 20 09; Hewlett and Cohen 2011). We believe that the annotation adaptation technolog ies can be adopted jointly with complicated features, system combination, and semi-s upervised/unsupervised technologies to further improve the performance of word seg mentation and depen-dency parsing. 8. Conclusion and Future Work
We have described the problem of annotation adaptation and t he intrinsic principles of its solutions, and proposed a series of successively enha nced models that can au-tomatically adapt the divergence between different annota tion formats. These models learn the statistical regularities of adaptation between d ifferent annotation guidelines, 144 and integrate the knowledge in corpora with different annot ation guidelines. In the problems of Chinese word segmentation and semantic depende ncy parsing, annotation adaptation algorithms bring significant improvements by in tegrating the knowledge in differently annotated corpora, People X  X  Daily and Penn Chi nese Treebank for word seg-mentation, and Penn Chinese Treebank and Semantic Dependen cy Parsing for depen-dency parsing. For both tasks, annotation adaptation leads to a segmenter and a parser achieving the state-of-the-art, despite using only local f eatures in single classifiers. future. First, models for annotation adaptation can be adap ted to other NLP tasks such as semantic analysis. Second, jointly tackling the diverge nces in both annotations and domains is an important problem. In addition, an unsupervis ed-induced or bilingually projected corpus, despite performing poorly on the specifie d testing data, may have high inner annotation consistency. That is to say, the induc ed corpora can be treated as a knowledge source following another annotation guideli ne, and the performance of current unsupervised or bilingually projected models may b e seriously underestimated.
Annotation adaptation may give us a new perspective on knowl edge induction and measurement for such methods.
 Acknowledgments References 146
