 ORIGINAL PAPER Mathieu Delalandre  X  Ernest Valveny  X  Tony Pridmore  X  Dimosthenis Karatzas Abstract This paper deals with the topic of performance evaluation of symbol recognition &amp; spotting systems. We propose here a new approach to the generation of synthetic graphics documents containing non-isolated symbols in a real context. This approach is based on the definition of a set of constraints that permit us to place the symbols on a pre-defined background according to the properties of a par-ticular domain (architecture, electronics, engineering, etc.). In this way, we can obtain a large amount of images resem-bling real documents by simply defining the set of constraints and providing a few pre-defined backgrounds. As documents are synthetically generated, the groundtruth (the location and the label of every symbol) becomes automatically available. We have applied this approach to the generation of a large database of architectural drawings and electronic diagrams, which shows the flexibility of the system. Performance eval-uation experiments of a symbol localization system show that our approach permits to generate documents with different features that are reflected in variation of localization results. 1 Introduction This paper deals with the topic of performance evaluation. Performance evaluation is a particular cross-disciplinary research field in a variety of domains such as Informationz Retrieval [ 1 ], Computer Vision [ 2 ], CBIR 1 [ 3 ], DIA etc. Its purpose is the development of frameworks to eval-uate and compare a set of methods in order to select the best-suited for a given application. Due to the heterogeneity of the fields where performance evaluation can be applied to [ 1  X  4 ], it is difficult to find a common definition of  X  X hat a performance evaluation framework is X . Two main tasks are usually identified (Fig. 1 ): groundtruthing, which provides the test and reference data to be used during the evaluation (both for training and testing), and performance characteriza-tion, which determines the metrics and the protocol to match the results of a given method with the groundtruth in order to give a measure of the performance.

In this paper, we are especially interested in the first of these two tasks, applied to two particular topics of DIA: sym-bol recognition &amp; spotting. Figure 2 compares these two pro-cesses. Symbol recognition is an active topic in the field of graphics recognition. Several surveys [ 5  X  8 ] review the exist-ing work on logical diagrams, engineering drawings, maps, etc. In a very general way, a symbol has been defined as  X  a graphical entity with a particular meaning in the context of an specific application domain  X  and then, symbol recognition as  X  a particular application of the general problem of pattern recognition, in which unknown input patterns are classified as belonging to one of the relevant classes (i.e. pre-defined symbols) in the application domain  X  X  7 ].

Usually, symbols do not appear isolated but are connected to other elements of the document (connecting lines, back-ground, other symbols, etc.). Thus, one of the major problems of symbol recognition is to combine segmentation and recog-nition. This problem is known as the segmentation/recogni-tion paradigm in the literature [ 9 ]: a system should segment the symbols before recognizing them but, at the same time, some kind of recognition may be necessary to obtain a correct segmentation. In order to overcome this paradox, research has been directed to symbol spotting [ 10 ]. Since research on symbol spotting is just starting, definitions of symbol spot-ting are still a little ambiguous. In [ 8 ], it is defined as  X  away to efficiently localize possible symbols and limit the compu-tational complexity, without using full recognition methods  X . So, spotting is presented as a kind of middle-line technique combining recognition and segmentation. While symbol rec-ognition tries to find the location and label of every symbol in the document, symbol spotting methods can be viewed as a kind of retrieval system [ 11  X  16 ]. Spotting is usually initiated with a query selected by the user from a drawing, what we call a QBE. 3 Then, the example is used as a model to find similar symbols in the document database. At the end, the system provides a ranked list of similar symbols along with their localization data (i.e. url of the source document with the coordinates of the symbol).
In both cases (spotting and recognition), a hard problem is how to obtain and compare experimental results from exist-ing systems. Traditionally, this step was done independently for every system [ 5  X  8 ], by comparing manually the results with the original images and checking the recognition errors. This process was unreliable as it raises conflicts of interest and does not provide relevant results. Moreover, it does not allow the comparison of different systems or support testing with large amounts of data. In order to solve these problems, research has been initiated over the last few years on the per-formance evaluation of symbol recognition/spotting systems [ 17 ], resulting in the organization of several international contests on symbol recognition [ 18  X  21 ]. However, this work has focused on the recognition of isolated symbols. They do not take into account segmentation or spotting of symbols in real documents. The main reason for that is the difficulty of obtaining a large set of documents with the corresponding groundtruth. Doing that manually would require an unafford-able amount of time, as all the symbols in the document must be precisely located and labeled.

In this paper, we propose a new approach to the auto-mated generation of test documents to enable performance evaluation of symbol recognition and/or spotting systems in real context. The novelty in this approach is that it is constraint-driven and general enough to be applied to differ-ent domains. The constraints permit us to place the symbols on pre-defined backgrounds. They are defined according to a particular domain such as electronics, architecture or engi-neering. Thus, by simply defining the set of constraints and providing a few pre-defined backgrounds, we are able to pro-duce a large amount of images resembling to real documents. As documents are synthetically generated, the groundtruth corresponding to the location and the label of every sym-bol becomes automatically available. We have applied this approach to the generation of large databases of architectural drawings and electronic diagrams, which shows the flexibil-ity of the system.

In the rest of the paper, first we will review in Sect. 2 the previous work done on groundtruthing applied to symbol rec-ognition &amp; spotting. In Sect. 3 , we will present our approach to generate synthetic documents based on positioning con-straints of symbols. In Sect. 4 , we will introduce the graphical user interface to define the constraints and generate the doc-uments. The results of the application of the system, to the generationofarchitecturaldrawingsandelectronicdiagrams, are presented in Sect. 5 . Finally, in Sect. 6 , we state the main conclusions and future perspectives of this work. 2 Overview The first step to evaluate any graphics recognition system is to provide test documents with their corresponding groundtruth data [ 22 ]. Concerning the specific topic of symbol recogni-tion &amp; spotting, several systems have been proposed in recent years: [ 8 , 18 , 23  X  25 ] and [ 17 ]. They can be classified in two main approaches: based on real or synthetic data. In the first case, test data consist of real documents. The groundtruth is defined from these documents by human operators using GUI. 4 Concerning synthetic data, the documents are built automatically, or semi-automatically, with their correspond-ing groundtruth by the systems, using some models of doc-ument generation.

In the rest of this section, we will present and discuss both approaches inSects. 2.1 and 2.2 . Inadditiontothat, tosupport this discussion, we compare the systems in Table 1 accord-ing to different criteria: speed of the groundtruthing process, realism of test documents, reliability, number of symbols per image, generation of connected or disconnected symbols and ability to add noise with degradation methods. Finally, con-clusions are drawn in Sect. 2.3 . 2.1 Real data The natural approach to obtain the groundtruth is to define it from real-life documents. In that case, GUI are used by human operators in order to edit manually the groundtruth data. Thus, the groundtruthing starts from raster images in order to provide a vector graphics description of the con-tent (e.g. graphical labels, region of interest, etc.). As the groundtruth data are edited by humans, it is necessary to do this task collaboratively with different operators [ 22 ]. In this way, errors produced by a single operator can be avoided.
In the past, this approach has been mainly applied to the evaluation of layout analysis and OCR 5 systems [ 26  X  28 ]. Concerning symbol recognition &amp; spotting, only the EPE-IRES 6 platform exists to date [ 8 ]. 7 It is presented in Fig. 3 . This system is based on a collaborative approach using two main components: a GUI to edit the groundtruth data con-nected to an information system. The operators obtain, from the system, the images to annotate and the associated symbol models. Groundtruthing is performed by mapping (moving, rotating and scaling) transparent bounded models on the doc-ument using the GUI. The information system allows users to collaboratively validate the groundtruth data. Experts check the groundtruth data generated by the operator by emitting alerts in the case of errors.

Despite this existing platform, a problem still remains [ 22 ]: the time and cost required to edit the groundtruth data. Similar contributions made in OCR and layout analysis [ 26  X  28 ] highlight that, in most of the cases, the groundtruthing effort makes the creation of large databases very hard. An alternative approach to avoid this problem is semi-automatic groundtruthing. In this case, the key idea is to use a recog-nition method to obtain an initial version of the groundtruth data. Then, the user only has to validate and to correct the recognition results in order to provide the final groundtruth data. This approach has already been used in other applica-tions like OCR [ 29 ], layout analysis [ 30 ], chart recognition [ 31 ], etc.
Concerning symbol recognition &amp; spotting, only the system described in [ 23 ] has been proposed to date. This system recognizes engineering drawings using a case-based approach. It is mainly used to learning and recognition, but it could be easily extended to groundtruthing. The user starts by targeting a graphical object (i.e. a symbol) in an engi-neering drawing. The symbol is next vectorized into a set of straight-lines and represented as a model tree. This model tree is used to localize and recognize similar objects in the drawing. During the learning process, the system also takes into account user feedback on positive and negative exam-ples. It modifies the original tree by computing tolerances about the primitives and their relations (length, angle, line number, etc.).

In any case, the systems presented previously render the groundtruthing impractical for constructing large-scale data-bases. In [ 24 ], the authors propose an alternative way to solve this problem. Their key idea is to use vector graph-ics documents (e.g.  X  X XF, SVG, CGM, etc. X ) and to con-vert them into images. In this way, they can take advantage of already existing groundtruth data: it is not necessary to re-define it. Their system has been used to evaluate raster to vector conversion [ 24 ]. However, it could be easily extended tosymbolrecognition&amp;spottingbyusingthesymbollayerof the CAD files. The remaining difficulty in this approach is to collect and to record the electronic documents [ 32 ]. Several problems still exist: to check the copyrights of documents, to organize the documents in the database (to define single id, to associate duplicates, etc.), to validate the formats and to convert them to a standard one if necessary, to edit metadata about the documents in order to index the database, etc. 2.2 Synthetic data The systems using real-life documents result in realistic test data but render the groundtruthing complex (errors, delay and cost, copyright, database indexing, etc). A complemen-tary approach, which avoids these difficulties, is to create and to use synthetic documents. Here, the test documents are gen-erated by an automatic system which combines pre-defined models of document components in a pseudo-random way. Test documents and groundtruth can therefore be produced simultaneously. In addition, a large number of documents can be generated easily and with limited user involvement. Several systems have been proposed in the literature [ 18 , 25 ] and [ 17 ], mainly used in the context of international con-tests of symbol recognition. Figure 4 gives some examples of documents produced by these systems.

Thesystemdescribedin[ 18 ] employs anapproachtobuild documents composed of multiple unconnected symbols. Figure 4 a gives an example of such a document. Each symbol is composed of primitives (circles, lines, squares, etc.) ran-domly selected and mildly overlapped. Next, they are placed on the image at a random location and without overlapping with the bounding boxes of other symbols. The systems pro-posed in [ 25 ] and [ 17 ] support the generation of degraded images of segmented symbols as shown in Fig. 4 b, c. In these systems, the models of the symbols are described in a vector graphics format. They use a random selection process to select a model from the model database and apply to it a set of transformations (rotations, scaling, and binary or vectorial distortions). 2.3 Conclusion In recent years, several pieces of work have been undertaken to provide groundtruthed databases in order to evaluate sym-bol recognition &amp; spotting methods, using real [ 8 , 23 , 24 ]as well as synthetic [ 17 , 18 , 25 ] data. As indicated in Table 1 , the time needed to collect and groundtruth the real-life docu-mentsmakestheiruse,forconstructinglarge-scaledatabases, complex. Moreover, the groundtruthing is done by human operators making the results unreliable. For that reason, syn-thetic data have been mainly used to date for the evaluation of systems, for example during the international contests of symbol recognition [ 8 , 18 , 19 , 21 ]. With such data, test docu-mentsandgroundtruthareproducedsimultaneously.Then,as mentioned in Table 1 , data can be generated quickly making the production of statistically important groundtruth datasets feasible. Moreover, the groundtruth is produced directly from the models and, therefore, without errors. Finally, the content of documents can be controlled, which is an interesting prop-erty to evaluate the methods regarding scalability, geometry invariance, noise robustness, etc.

The major problem when using synthetic data is the dif-ficulty of reproducing the variability of real documents. The systems proposed in the literature [ 17 , 18 , 25 ] only generate documents composed of segmented symbols, no whole doc-uments which is the original goal of groundtruthing systems. Indeed, real-life documents (engineering and architectural drawings, electrical diagrams, etc.) are composed of multiple objects constrained by spatial relations (connectivity, adja-cency, neighborhood, etc.). Systems capable of generating whole synthetic documents would be very helpful. Such sys-tems would provide a much more realistic context in which evaluation could take place. In this paper, we present some contributions in this direction that we will introduce in next Sect. 3 . 3 Our approach In this paper, we present a new approach to the building of synthetic documents for the performance evaluation of sym-bol recognition &amp; spotting systems. Our key contribution is the building of whole documents (drawings, maps, diagrams, etc.), and the underlying aim of our work is to make the pro-duced documents more realistic. The design of a suitable process is a challenging task. Indeed, realistic documents cannot be produced without importing human know-how into the process. In our work, we have considered a shortcut way to solve this problem. Our key idea observes that graphical documents are composed of two layers: a background layer and a symbolic one. We use this property to build several document instances as shown in Fig. 5 . We generate sev-eral different symbolic layers and place them on the same background obtaining different documents. In this way, the building process is made easier and can be considered as a problem of symbol positioning on a given document back-ground.

In order to place randomly symbols on a given back-ground, we have developed a building system based on the use of positioning constraints. These positioning constraints determine where and how the symbols can be placed on a background image. Figure 6 presents the architecture of our system. It uses as input data a background image, a database of symbol models and a file describing the positioning con-straints. Using these data, it generates vector graphics docu-ments with the corresponding groundtruth. These documents are next rasterized and noise added, to generate the final test images for evaluation. The central part of our system is the buildingofdocuments.Twomainprocessestakepart:symbol positioning and document generation. Symbol positioning is in charge of placing symbols on the background accord-ing to the parameters and conditions of given constraints. Document generation controls the positioning process, through a building loop including upstream and downstream steps, to ensure the generation of correct documents. It starts with empty documents and fills them with symbols in a pseudo-random way. The interactions between the two pro-cesses are explained in the workflow diagram presented in Fig. 7 . For each loop, a constraint and a symbol are selected. Then, the symbol is placed on the background according to the specifications of the constraint. After that, several tests are carried out to ensure that the symbol is well positioned. The process continues until some stopping criteria (concern-ing the number of symbols and the amount of free space) are satisfied.

In the rest of this section, we will introduce first in Sect. 3.1 the positioning constraints. Next, in Sects. 3.2  X  3.8 , we will describe all the steps (1) X (7) mentioned in the workflow dia-gram of Fig. 7 , and will detail how the constraints are pro-cessed at each of these steps. The last Sect. 3.9 will give details about the final test image generation process. 3.1 Positioning constraints The key mechanism employed in our system is symbol posi-tioning using constraints. Figure 8 a, b explain how it works. The constraints specify which symbols can be placed and where in a background (Fig. 8 a). Each constraint defines a set of symbol models to instantiate, a shape to specify where symbols can be placed on the background (either a single point, a straight-line or a polygon), and some parameters that specify how these symbols are placed (concerning geo-metric transformations and the definition of control points). Then, a symbol is placed in such a way that its control point will match a point inside the shape defined in the constraint (Fig. 8 b). More specifically, a constraint addresses the fol-lowing issues: Symbol models The list of symbol models that can be Constraint size The maximum number of symbols that can Constraint satisfaction It specifies whether the constraint Geometric transforms Geometric transformations (rota-Positioning shape It defines where the symbols can be Positioning control The parameters to compute the control
Figure 9 gives an example of a rule declaration used in the positioning. It is composed of a model and an associated con-straint. This specifies mainly the link(s) between the model and the constraint and the parameters used for the position-ing (the control point and the shape coordinates). Additional parameters can be employed to produce more complex rules. Table 2 gives the full explicit list of parameters we use in our rules. These are employed at different steps (1) X (7) of our building process shown in Fig. 7 . We will detail each of them in next subsections. 3.2 Constraint &amp; model selection To initiate a building loop in our workflow (Fig. 7 ), we have to select a symbol model and an associated constraint. We have implemented two selection modes: a constraint-based selec-tion and model-based selection. The motivation for defining two selection strategies is that some constraints are manda-tory to be satisfied while others are optional, as illustrated in Fig. 10 . For instance, doors and windows are mandatory in order to close the house, and a bed is also required in a bedroom while a sofa is optional. Constraint-based selec-tion permits to ensure that all mandatory constraints are taken into account in the generation of the document, while model-based selection also includes optional constraints.
The constraint-based selection selects the constraints first and the symbol models next. This way, it will coerce the positioning i.e. the constraint will be satisfied. Figure 11 a details the selection process we use. It is done by managing a constraint stack. All the constraints defined as  X  X anda-tory X  in the constraint file are loaded and pushed into this stack. Then, when starting a building process these con-straints ( c 1 ,..., c i ) are popped-up from the stack at each loop. A symbol model ( s k ) linked to this constraint is next selected at random using a uniform probability distribution ( p eration shifts to the model-based selection as illustrated in Fig. 7 .
 The model-based selection works in the opposite way. It selects symbol models first and linked constraints next. The selection of symbol models is performed so that it will satisfy a maximum number of constraints among documents. We favor symbols linked to several constraints, or those linked to weak associated constraints. The constraints are next selected at random with an uniform probability distribu-tion. This guaranties a better spatial distribution of symbols among documents, and thus a better visual rendering of doc-uments. Figure 11 b presents the method we use to achieve this. First, a weight w c is computed for each constraint based on the number of symbols n s associated with it. The weight w s of a symbol is next obtained by summing the weights of constraints linked with it. The obtained w s are at last nor-malized by the total number of constraints n c to obtain the selection probabilities p s of symbols. Using these probabil-ities, a symbol model can be selected at random. This way, the system increases the selection probabilities of symbols linked to several constraints, or those linked to weak associ-ated constraints like, respectively, s 3 and s 6 in Fig. 11 b. 3.3 Symbol loader Once a model is selected, we instantiate the corresponding symbol by loading its model file. These model files are kept inside our database as illustrated in Fig. 6 . They are in a vector graphics format, describing the symbols using geometrical primitives (straight-lines, arcs and circles) with their associ-ated thickness attributes. Once loaded, the symbols have to be adapted to the background image. Indeed, these back-ground images are made from real-life document images (web images, digitized documents, etc.) picked-up at ran-dom. As they are not adapted to our symbol library, we must apply a set of geometric transformations (scaling, morphing and random rotation) to the symbols before placing them on the background.

Scaling aims to adapt the symbols to the size of the back-ground image. It employs a single parameter defined in the positioning constraint, to scale the symbols in relation to their gravity centers. In the same manner, the morphing operation adapts the thickness of the symbols to the background image. Figure 12 a gives two examples of a symbol placed on a back-ground, without and with thickness adaptation. In a last step, the symbols are rotated. This rotation is done using a param-eter that can be null, a fixed value or a range. In the last case, the final value is selected at random inside the range. A gap can also be defined to sample the rotation values within the range. The key objective of making these rotations random is to increase the variability of the documents. Figure 12 b gives an example of a tub rotated in two different ways using a same constraint. In this example, the range is  X  2 , 3  X   X  with a  X  gap. 3.4 Symbol control Once a symbol is loaded, our system initiates the positioning. The first step is to compute the control point of the symbol as detailed in Fig. 13 . We define this control point in relation to the bounding box of the symbol. Indeed, the bounding box is a common way to handle graphical objects inside a doc-ument analysis system. The method we employ to compute it is given in Annex A1. It takes into account the thickness of the lines and permits also to apply an alignment rotation, both to the symbol and the control point. It allows the symbol to be aligned to the background elements. Figure 13 gives an example of a symbol ( asofa ) aligned to a background ele-ment ( awall ).

In our approach, we have made the computation of con-trol points fully independent of the symbol models. Like this, we make the association of different models to a single con-straint easier i.e. it is not necessary for a user to define a specific control point for each of the models. For that pur-pose, we have defined the control points in our constraints with polar coordinates as shown in Fig. 14 . The key process is then, starting from a control point p defined in the polar space, to find for a given symbol i the right control point p in its bounding box. In the polar space, the control points p are represented using two coordinates ( L , X ) . We use then some standard geometric methods to find the right length and direction ( L i , X  i ) for a given symbol (see Annex A2). 3.5 Shape positioning Once the control point is computed, we position the symbol on the background. It is based on the matching of the con-trol point with a positioning one defined on the background. The symbol will be then positioned so that its control point matches with the positioning one. In order to introduce some variability in the built documents, we employ different pos-sibilities to select the positioning point in a constraint. It can be defined as being a fixed point ( x , y ) or can be selected at random inside a straight line (the point is selected at ran-dom along the line) or a polygon (the point is selected at random inside the polygon). Figure 15 a,b gives examples of random positioning in both cases. To perform the ran-dom selection, we employ different computational geometry methods detailed in Annex A3. 3.6 Checking of constraints When a straight-line or a polygon is used to select the posi-tioning point, their boundaries could also be employed as delimiters to constraint the positioning of the whole symbol. Figure 16 a,b present some examples where this option could be useful. In the case of Fig. 16 a, the straight-line delimits the positioning of the sofa to a wall part. In this way, a sofa will not be placed in front of the room entrances. The case of Fig. 16 b shows how a polygon could constrain the position-ing of a table within a hall. Then, this table will not obstruct the way to the window or be placed along the flat X  X  wall.
In our system, we allow the user to choose if a constraint has to be used as delimiter or not. Such a choice will depend on the context of the constraint and the user will decide then in regard to his domain know-how. However, position-ing might fail. Such failures appear when parts of a symbol overflow the area of the constraint. To check it, we use over-flow tests between the symbols and the straight-line/polygon shapes defined in the constraints (Fig. 17 ). Both are based on some standard overlapping and line intersection methods as detailed in Annex A4. A positive result will cancel the positioning. Afterward the document generation will initiate a new building loop.

Another particularity related to the use of straight-lines or polygons in the constraint is that more than one symbol could be positioned. Figure 18 gives some examples of that. In the case of Fig. 18 a, several sinks are placed along a wall using a straight-line. Concerning the case of Fig. 18 b, the furni-ture composing a living-room is placed at random inside a polygon. Thus, in our approach, we have allowed the user to specify a maximum number (between 1 and n ) of symbols to position per constraint. When a constraint becomes  X  X ull X , the positioning is canceled. 3.7 Space management In addition to the checking, the system also continuously monitors the document space. Indeed, during the building process, the document is filled gradually. The system has to ensure that any new generated symbol falls entirely within the image and do not overlap with the existing symbols. Such detection is achieved using overlapping tests (see Annex B5) between the bounding box of the new symbol and all the already positioned in the document.

However, it could appear than some symbols have to be mildly overlapped. This case appears when we want to make connect some symbols on the background. Figure 19 agives examples of that in a bathroom and in a cellar. In order to take into account these cases in our system, we work with two building layers as illustrated in Fig. 19 b. In the first layer, we forbid the overlapping as detailed previously. In the second layer, we allow a mildly overlapping between symbols. We use the line width of symbols as a threshold to control the overlapping degree. At the end, the symbols placed in this second layer are overlayed to the first layer and the back-ground, to produce the final document. The selection of a given layer for a constraint is set up by the user. Like this, the mildly overlapping between symbols will be allowed accord-ing to his needs. 3.8 Stopping criterion Our building system starts with empty documents and fills them in a pseudo-random way with generated symbols. The building process is stopped when the maximum number of symbols to position in the document is reached. This number corresponds to the sum of the maximum numbers of allowed symbols per constraint. However, in some cases, a complete satisfaction of all constraints could be difficult to achieve. The user could define a large number of symbols per docu-ment that will be hard to achieve without relaxing the defined constraints. The system must then detect and count these cases, and stop the building if necessary in order to avoid an infinite building process.

To achieve this, we use the checking and space manage-ment tests presented in Sects. 3.6 and 3.7 . When the results of these tests are negative, we trigger a building failure as shown in Fig. 7 . We count then these building failures and compare them to a threshold set up by the user. He defines it in relation to the edited constraints, the considered domain and background image, his satisfaction requirement, etc. If the number of building failures becomes greater than this threshold, we stop the process. 3.9 Generation of test images Once vector graphics are documents obtained, we convert them into raster images for performance evaluation. How-ever, to test recognition systems one needs noisy images. In our system, we use two different workflows to add noise to the images (Fig. 20 ): scan-based and web-based. The first one aims to distort the images in a way similar to the scan-ning process, whereas the second produces low-resolution and lossy compressed images as the ones found on the Web.
We exploit three processing steps to produce the scan-based images: scaling, rasterization and image degradation. Vector graphics documents are first scaled with their corresponding groundtruth. Indeed, our synthetic documents are produced from pre-defined background images. These are selected at random from digital libraries and there-fore, appear at different scales. Thus, we resize all the produced documents in order to put them at a same scale in our datasets. The groundtruth data are also resized in order to keep them valid. Next, we raster-ize the vector graphics documents using tools such as ImageMagick 8 or Inkscape 9 Rasterized images are obtained in gray-level, we binarize them using a fixed thresh-old. In a final step, we employ the image degradation algorithm of [ 33 ]. This algorithm tries to reproduce the process of printing and acquisition. It has been used in different applications of DIA (especially OCR), and in all the past contests on symbol recognition [ 18  X  21 ]. Figure 21 a gives examples of degraded images using this algorithm.
 Web-based images are produced using a similar workflow. Vector graphics documents are also scaled with their corre-sponding groundtruth to make them homogenous and are next rasterized. However, they are scaled at lowest levels to obtain low resolution images as the ones found in the Web. Figure 21 b gives some examples of degradation at lowest resolutions (from scales 1 / 1to1 / 4). In a final step, we com-press the rasterized images with the jpeg lossy compression algorithm. 4 Graphics user interface In previous Sect. 3 , we have presented our system to generate synthetic documents and their corresponding groundtruth at the symbol-level. The system relies on the use of position-ing constraints. It employs different entry data, a background image, a set of symbol models and a file describing the posi-tioning constraints. As presented previously, the position-ing process exploits various operations (scaling, morphing, random and alignment rotation, etc.). Therefore, a constraint file is expected to contain a lot of data depending on the num-ber and the complexity of constraints. Thus, it can be difficult to edit it manually.

In order to help the user, we have developed a GUI allow-ing different editing tasks: loading and attaching a back-groundimage,loadingamodeldatabase,creatingandplacing constraints, linking constraints to models, setting constraints, saving and loading constraint files, etc. Figure 22 gives a snapshoot of this GUI with some edited constraints. In prac-tice, it is difficult to edit the constraints without observing their effect on document building. In order to make the edit-ing easier, we have plugged our GUI to our building engine as shown in Fig. 23 a. Using this plugin, the editing of con-straints is done in interaction with the user in three steps: (1) editing process in progress (2) running of the engine (3) dis-play of the building result. This last step relies on a building viewer presented in Fig. 23 b.

An editing process could take 1 X 3hours per background, depending on the number and complexity of constraints (from 20 to 40). A user must be familiar with the document domain (architectural, electrical, etc.). In addition, he must be trained about the constraint mechanism employed in our system that involves some skills in computer science. Thus, this system is mainly intended for people working on the computer vision field, interested in the performance evalua-tion aspects. At this time, it has been employed by different Master and PhD Students following a short training (half a day).

Once all the constraints are edited from a background image, the user can produce a full database of synthetic doc-uments using the main GUI. It is only necessary to specify the total number of documents to be generated and stored in the database. The system will export the test documents to a directory with the corresponding groundtruth files. Ground-truth files contain metadata about the symbols composing the test documents: locations of bounding boxes, labels, orien-tations, scaling and morphing parameters. Annex D gives an example of the content of groundtruth files. Test documents are in a vector graphics format (i.e. with vectorial data for the symbol layer and a raster image for the background). In a final step, we use batch processing to rasterize the vector graphics documents and to add noise to the obtained images, as explained in Sect. 3.9 . 5 Experiments and results In this section, we present the experiments performed and the results obtained with our system. The main objective of these experiments is to create collections of test documents, with the corresponding groundtruth, to be used in evalua-tion frameworks of symbol recognition &amp; spotting systems. To achieve this, we set up our system so that it generates different collections of test documents. Our key objective is to highlight the flexibility of our approach. 10 Table 3 gives the details about these collections in terms of the numbers of datasets, images, symbols placed on the documents and models used. All these collections are free and downloadable from our website. 11 In next Sects. 5.1  X  5.3 , we will present the collections of documents we have produced, and how we have set up our system to do it. In Sect. 5.3 , we will highlight how our approach is suitable for performance evaluation, by presenting characterization results of a spotting system obtained on our document collections. 5.1 Bags of symbols We have built a first collection composed of  X  X ag of sym-bols X  documents. Figure 24 presents some examples of these bags. In them, the symbols are positioned at random on an empty background, without any connection, and using dif-ferent rotation or scaling parameters. These bags present an  X  X asy X  localization problem. The key idea of this collection is to establish a bridge with the datasets provided during the past contests on symbol recognition held during the GREC 12 Workshop [ 8 , 19 , 21 ], composed of only one segmented sym-bol per image.

Toproducethis collection, wehaveusedthesymbol model library 13 created during the previous editions of the GREC contest. This library is composed of 150 models of architec-tural and electrical symbols. Based on this library, we have set up our system with a single square zone constraint sur-rounding an empty background. In order to produce bags of a reasonable size, we have resized the original symbol models of the past contest editions 13 from 512  X  512 to 256  X  256 pixels. Based on this symbol size, we have gen-erated bags of 1 , 024  X  1 , 024 pixels composed of around 10 symbols each. This corresponds to a symbol density of between the background and the foreground parts as shown in Fig. 24 .

Using these size parameters, we have generated 16 data-sets of 100 bags each. This corresponds to an overall num-ber of 1,600 bags composed of around 15,000 symbols as indicated in Table 3 . These 16 datasets have been generated by respecting the protocol used during the previous runs of the contest 13 . First we have used different model numbers (25, 50, 100 and 150) in order to test the scalability of the methods. Next we have applied and combined different geo-metrical operations as illustrated in Fig. 24 a X  X . These trans-formations have been set up as follows: from 0 to 2  X   X  for the random rotation with a gap of 2  X   X  1000 , and from 75 % to 125% for the scaling with a gap of 0.05% ( 50 1 , 000 ) . 5.2 Architectural floorplans Our second collection aims to provide whole documents using filled backgrounds. For that purpose, we have dedi-cated this collection to architectural floorplans. We have cho-sen architectural floorplans in recognition of their interesting properties concerning the connectivity and the orientation of symbols. Figure 25 presents some examples of floorplans automatically produced by our system.

In order to generate these floorplans, we have defined first a set of architectural symbol models. Our set is composed of 16 models, Fig. 26 gives their thumbviews and labels. In this set, the sizes of the symbols respects existing propor-tions appearing in real-life floorplans. We give in Fig. 26 the scales of thumbviews 14 regarding the real sizes of symbols in floorplans.
Then, we have used these models and some background images in order to produce our constraints. Figure 27 a explains the process we use. First, to create our backgrounds, we have picked-up at random some images of real floorp-lans (digitized documents, web images, etc.). We have next cleaned these images by deleting elements like texts, sym-bols, arrows, dimensions, etc. Once the background images are obtained, we use our GUI to edit the constraints and to link them to the symbol models. As we want the documents to be as real as possible, we use during the editing step, the original images in order to reproduce the domain rules in the constraints. Figure 27 b gives some examples of the original floorplans, and the documents we have built from them. The initial information concerning the types and the locations of symbols has been preserved in the constraints.

We have created our whole floorplan collection using 10 different backgrounds. However, to address the time com-plexity problem of symbol recognition &amp; spotting processes, we restrict ourselves to background images composed of a small number of rooms. Like this, we produce floorplan images of reasonable dimensions. The number of edited con-straints per background image changes from 21 to 41. Using these constraints, we have generated 100 instances of doc-uments per background. Our final collection of documents is composed of 1,000 images and around 28,000 symbols to locate as indicated in Table 3 . This corresponds to a mean number of 28 symbols per image, with a minimum of 18 and a maximum of 40. In a final step, we have scaled all the pro-duced images to make their resolution homogenous across the whole database. The scaling parameter has been defined in order to reach a symbol size of 192  X  192 for the smallest symbol models and 460  X  460 for the biggest ones (corre-sponding respectively to the scaling parameters 1 . 0 and 2 of Fig. 26 ). 5.3 Electrical diagrams Our last collection is concerned with electrical diagrams. Our key objective here is to show that our approach is not domain dependent, and could be applied therefore to build other doc-ument types. Figure 28 shows some examples of diagrams we produce.

To build these diagrams, we have first created a model library of electrical symbols. Figure 29 gives thumbviews of them, our set is composed of 21 models. Then, the process we have used to construct this collection is similar to the one of floorplans. In a first step, we have picked-up at random some images of real diagrams and cleaned them to obtain the backgrounds. The obtained background images contain only wires joining empty symbol places. Next, we have used our GUI to edit constraints for the obtained backgrounds by reproducing domain rules of original diagrams.

We have generated our whole collection of diagrams from 10 different backgrounds. We restrict ourselves to diagrams composedofafewnumberofcomponents,inordertoaddress the time complexity problem of the symbol recognition &amp; spotting processes. Then, in the case of diagram collection, the number of edited constraints per background image var-ies from 7 to 26. Using these constraints, we have generated 100 instances of documents per background. Our final collec-tion of documents is composed of 1,000 images and around 14,000 symbols to locate as indicated in Table 3 . This cor-responds to a mean number of 14 symbols per image, with a minimum of 7 and a maximum of 26. In a final step, we have scaled all the produced images to make their resolution homogenous across the whole database. The diagrams have been produced in order to respect a mean symbol size of 192  X  192 (from 57  X  57 for the smallest ones to 288  X  288 for the biggest ones). 5.4 Application to performance evaluation In past Sects. 5.2 and 5.3 , we have illustrated how our system can produce documents that look realistic, by repro-ducing domain rules of true-life documents in positioning constraints. Using these constraints, our system generates document instances i.e. different symbolic layers on a same background. In this subsection, we illustrate how these doc-uments are suitable for performance evaluation. To do it, we have employed them to evaluate the symbol localization sys-tem of [ 15 ]. This system detects parts of documents that may correspond to symbols, without a priori knowledge about the type of the document. It provides a set of ROIs 15 correspond-ing to potential symbols, without any information about their classes. It relies on a structural approach using a two-step process.

First, it extracts topological and geometric features from an image and organizes them through an ARG 16 (Fig. 30 ). The image is first vectorized into a set of quadrilateral prim-itives. These primitives become nodes in the ARG (labels 1, 2, 3, 4), and the connections between them, arcs. Nodes have, as attributes, relative lengths (normalized between 0 and 1) whereas arcs have the connection-types ( L junction , T junction ) and relative angles (normalized between 0  X  and 90  X  ).

In the second step, the system looks for potential ROIs corresponding to symbols in the image. It detects parts of the graph that may correspond to symbols i.e. symbol seeds. Scores, corresponding to probabilities of being part of a sym-bol, are computed for all edges and nodes of the graph. They are based on features such as lengths of segments, perpendic-ular and parallel angular relations, degrees of nodes, etc. The symbol seeds are detected next during a score propagation process. This process seeks and analyzes the different short-est paths and loops between nodes in the graph. The scores of all the nodes belonging to a detected path are homogenized (propagation of the maximum score to all the nodes in the path) until convergence, to obtain the seeds.

To evaluate this system, we have constituted a dataset of synthetic documents using our collections. Table 4 gives details about it. It is composed of architectural floorplans and electrical diagrams. We have selected 100 drawings produced using 5 different background images (20 drawings are gener-atedperbackgroundimage)foreachdomain.Thus,thewhole dataset contains 200 documents composed of 3,861 sym-bols (2,521 architectural and 1,340 electrical). These sym-bols belong to 16 and 17 architectural and electrical models, respectively, appearing in the selected backgrounds.
Our key objective here is to illustrate that our documents are suitable for performance evaluation. To do it, we propose to analyze the variability of the localization results, obtained by the system [ 15 ], on our dataset. We compute for each test image a symbol detection rate. This rate is obtained by comparing the bounding boxes of the localization results and the groundtruth (see Annex B5 for details about the overlap-ping test). We exploit the overlapping relations to identify matching cases as detailed in Table 5 . The detection rate of a given document corresponds to d = s n , with s the num-ber of single localization, and n the number of symbols in groundtruth.

Figure 31 presents plots of results we have obtained on architectural floorplans and electrical diagrams. In these plots, the detection rates are grouped per drawings produced from the same background image. Each curve gives the rates for a set of document instances (i.e. documents gen-erated from a same background). Each set is composed of 20 document instances, and each plot gives results for 5 sets for an overall number of 100 documents. To draw the curves, we have sorted the detection rates per set from highest to lowest values.

These curves illustrate the variability of synthetic documents produced using our system. Variations in the symbol layer impact in a significative way the results of the system, despite the use of a same background image to produce the drawings. In order to quantify this vari-ability, we present in Table 6 a statistical analysis. For each drawing set, we have computed the mean detection rates  X  b and their corresponding standard deviations  X  b  X  b is the mean standard deviation of the drawing sets, ing documents generated from different backgrounds). In these experiments, we obtain  X  b 1 2  X  w . These results show that our method can produce, for a given back-ground, drawings with different features. Depending on the number and type of symbols and constraints, these features can significantly affect the performance of sym-bol localization and thus, be used for performance evalua-tion. 6 Conclusion and perspectives In this paper, we have presented a system for the genera-tion of synthetic documents for the performance evaluation of symbol recognition &amp; spotting systems. Our key contri-bution is the building of whole documents (drawings, maps, diagrams, etc.) and, our underlying aim, to make these doc-uments more realistic. To do it, we have exploited the layer property of graphical documents in order to position sym-bol sets in different ways using the same backgrounds. This way, we obtain a large amount of documents that look real-istic by simply providing, a small number of constraints, and a few predefined backgrounds. The groundtruth (the locations and the labels of symbols) becomes automatically available along with the produced documents. We have employed this system to produce documents of architectural and electronic domains which proves the flexibility of our approach. In addition, using these documents, we have done performance evaluation experiments of a symbol localization system. They show that the different parameters used in our system result in generated documents with different features that are reflected in variation of the localization results of the system.

As a continuation of this work, our challenge is the com-parison of synthetic documents with real ones in terms of performance evaluation. The goal will be to compare local-ization results, of one (or several) system(s), on real and on synthetic documents. The generation parameters (num-ber and type of symbols, constraints and noise) used in our system should establish some kind of relation and compari-son to the same parameters in real documents. However, this is not an straightforward task due to the lack of groundtruthed datasets of real documents and characterization methods. To the best of our knowledge, it is not possible to achieve such a comparison today, because no groundtruthed dataset of real scanned documents exists. In addition, performance charac-terization metrics must be reformulated to take specificities of whole documents into account. With whole documents, characterization becomes harder because it has to be done between symbol sets. These symbol sets can have different sizes, and gaps can also appear concerning the locations of symbols. Different matching cases then exist, and the char-acterization methods must be able to detect them properly. Some recent research work on these problems can be found in [ 34 , 35 ]. Additional methods should be proposed by the graphics recognition community and compared, in order to identify the best-suited one for performance characteriza-tion.
 Appendix: organization of the annexes Annex A: positioning methods A1: Computation of bounding boxes
See Annexes B1 and B2 for the point offset and direction inclusion test within an arc .
 A2: Computation of control points A3: Generation of random points
See Annexes B1 and B3 for the point offset and point inclusion test within a polygon .
 A4: Overflow tests
See Annexes B5 and C for the overlapping tests and line intersection methods .
 Annex B: computational geometry methods B1: point offset B2: direction inclusion test within an arc
See Annex B4 for the clockwise angle computation between straight-lines .
 B3: point inclusion test within a polygon
See Annex B4 for the clockwise angle computation between straight-lines .
 B4: clockwise angle computation between straight-lines B5: overlapping tests Annex C: line intersection methods Annex D: groundtruth format References
