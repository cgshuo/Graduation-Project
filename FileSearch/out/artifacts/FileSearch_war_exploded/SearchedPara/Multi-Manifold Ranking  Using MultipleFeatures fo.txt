 Yang Wang 1 , 2 , Muhammad Aamir Cheema 1 ,XueminLin 1 , and Qing Zhang 2 , 1 Traditional image retrieval techniques rely on the semantic labels attached to the images such as image annotations [13] and tags [7]. However, a severe drawback of such techniques is that the manual labelling is laborious, expensive and time-consuming. Another disadvantage is that such techniques do not consider the content of the images and this may lead to p oor results especially if the quality of the labelling is poor.

To address the issues mentioned above, content-based image retrieval (CBIR) [10,5,12] may be used which utilizes the l ow-level features (e.g., color, shape, texture) for image retrieval. These low-l evel features can be e xtracted automati-cally and remain consistent for each image in contrast to the manually attached labels. However, it is difficult to choose an ideal descriptor for the images be-cause the low-level features may not rep resent the same semantic concepts. For example, two images having similar color visualization may have totally different semantic meanings (e.g., a green apple and a tennis ball as shown in Fig. 1). This is one of the main challenges CBIR needs to address.
To address this challenge, He et al. [4] used manifold ranking that uses low-level features as well as the intrinsic structure of the images. The basic idea behind the manifold ranking is as follows. A weighted graph is constructed where the vertices represent the images and, fo r each vertex, its near by vertices are connected to it by weighted edges. The q ueries are assigned a positive ranking and the remaining vertices are ranked wit h respect to the queries. The vertices spread their ranking scores to their neigh bors via the weighted graph. The spread process is repeated until convergen ce. This approach has been shown to yield better retrieval results because it utili zes the intrinsic structure of the image set. Xu et al. [18] proposed a faster manifold ranking approach that uses anchor graphs [8] to approximate the original graph and provides the results of similar quality.

The above mentioned manifold ranking techniques use a single feature. In other words, these techniques utilize the intrinsic structure of the images based only on a single feature. The ranking based on the single manifold may have low precision especially if the selected featur e is not very representative. Motivated by this, in this paper, we propose a technique called multi-manifold ranking (MMR) that ranks the images by considering multiple manifolds each constructed using a different feature. MMR demonstrates excellent ability to retrieve relevant images because it considers multiple intrinsic structures of the images. We propose a novel cost function that is minimzed to obtain the ranking scores of the images. Our proposed approach provides better results than the existing techniques. Furthermore, we present efficient techniques to create the multiple manifolds. We remark that Huang et al. [6] also utilizes more than one low-level features. However, they construct only one manifold by using average manifold distance of multiple features. Since only a single manifold is used, the proposed approach does not preserve the original geometric structure of any of the features. In contrast, our approach constructs multiple manifolds and utilizes the geomet-ric structure of each feature. This enables our approach to yield better results as demonstrated in our experiments. Furthermore, we show that our proposed approach is more efficient and can be used on large image databases.
Our contributions in this paper are summarized below.  X 
We propose multi-manifold ranking (MMR) that utilizes multiple intrinsic structures of the images to provide a better ranking of the images.  X 
To handle large image databases, we improve the efficiency of MMR by using singular value decomposition [1] as well as anchor graphs.
  X 
Our extensive experimental results on real world image databases demonstrate that our algorithm provides better retrieval results than state of the art existing techniques (MR [4], ADF [6] and EMR [18]) that use a single manifold for image retrieval. Furthermore, the running time of our algorithm is similar to that of EMR and is significantly lower than those of MR and ADF. We also present simple extensions of MR and EMR that use more than one manifolds. Although these extended versions demonstrate be tter retrieval results than the original versions, our proposed multi-manifold ranking performs significantly better. The rest of the paper is organized as follows. Related work is reviewed in Sec-tion 2. The details of multi-manifold ranking are presented in Section 3. Exten-sive experimental study on real world image databases is presented in Section 4. Section 5 concludes the paper. Zhou et al. [20] explored the importance of intrinsic geometrical structure of the data. They propose manifold ranking [21] that considers the intrinsic structure of the data for the ranking. Manifold ranking has been successfully used on various data types such as text [15], image [4] and video [19]. He et al. [4] are the first to use manifold ranking for image retrieval. While the proposed approach demonstrates good quality results, it is computationally expensive. Xu et al. [18] propose a more efficient approach that can efficiently handle large image databases. They replace the original image graph with anchor graph [8] which is significantly smaller in size but provides the results of similar quality. Huang et al. [6] use a probabilistic hypergraph for image retrieval. They construct a single manifold using the average manifold distance of multiple features.
All of the above manifold ranking based approaches consider geometric struc-ture of a single image manifold which may not precisely represent the image content. Motivated by this, we propose a multi-manifold ranking based method for image retrieval which exploits the geometric structure of multiple manifolds each constructed using a different fea ture. Our idea for MMR is inspired by [3], which addresses the problem of video annotation through multi-graph using different video features. 3.1 Preliminaries Let X be a set containing n images, i.e. X = { x 1 ,x 2 ,  X  X  X  ,x n } . Multi-manifold ranking assigns each image x i a ranking score F i . F = { F 1 ,F 2 ,  X  X  X  ,F n } is the an indicator label vector where L i =1if x i is the query image, otherwise L i =0.
Multi-manifold ranking (MMR) constructs N graphs each using a different feature. G k denotes a s -NN graph constructed on X using k th feature. Specif-ically, G k is constructed by conn ecting every two vertices x i and x j if one is among the s nearest neighbors of the other. H ere, the nearest neighbors are computed using Euclidea n distance between the k th feature vectors of the im-ages. The Euclidean distance between the k th feature vectors of x i and x j is denoted as || x i ,x j || k .

W k denotes the edge affinity matrix of G k .Eachentry W k ij in W k represents the similarity between x i and x j according to the k th feature vector. W k ij is edge in G k between x i and x j .Otherwise, W k ij is zero. D k is the diagonal matrix of G k where each element D k ii is defined as D k ii = n j =1 W k ij . 3.2 Objective Cost Function In this section, we propose a novel cost function, inspired by [3], to obtain the ranking scores of the images in X . The cost function O ( F )considers N image manifolds each constructed using a differ ent feature. The ranking score vector F is obtained by minimizing the cost function O ( F ) given in Eq. 1. The first term ensures that nearby points (i.e., similar images in the multiple image manifolds) are assigned similar ranking scores. The second term is the fitting constraint which ensures that the ranking results should fit the initial label assignment.  X  is the regularization trade-off parameter for the fitting constraint.
We minimize O ( F ) by setting  X  X  ( F )  X  X  = 0, which leads to the following equa-tion.
 equation.
 final optimal ranking score vector denoted by F  X  can be obtained as follows. where I is the identity matrix. Since both (1 - X  )and N remain the same for all the images, they do not affect th e retrieval results. Therefore, F  X  can be obtained as follows.

Eq. 5 is the closed form for the optimal solution F  X  . In large scale problems, the iteration scheme is preferred [18]. Therefore, we also consider the iterative form which is given below.
 the following equation can be obtained.
 Since N remains constant for all images, it is sufficient to consider the following equation which omits N .
 The above iterative form can be used in the iterative scheme. During each it-eration, each vertex (i.e., image) receive s information from its neighbors (the first term) and retains its initial information (the second term). The iteration process is repeated until convergence. By following the arguments similar to [21], it can be shown that Eq. 8 is conver ged to the following equation when F (0) is initialized to L .
 Note that both N and (1  X   X  ) can be omitted from Eq. 9 without changing the final retrieval results because they are co nstant for all images. Therefore, the optimal ranking results can be obtained as follows.
 We remark that although Eq. 10 may assign negative scores to some of the images, the relative ranking order of the images is preserved. Nevertheless, if desired, the scores of all the images may be normalized (e.g., by shifting) such that each image gets a positive score. 3.3 Improving the Efficiency of MMR The approach we mentioned in the previous section has two major limitations. Firstly, the time complexity for constructing the affinity matrix for n data points using s nearest neighbors is O ( sn 2 ) [8]. Secondly, the inver se matrix computation in Eq. 5 requires O ( n 3 ). Clearly, the cost of constructing the affinity matrix and inverse matrix computation is prohibitive for large image databases. Hence, this approach is not suitable for the large image databases.
The first limitation can be addressed by using anchor graphs [8] in a similar way as used in [18]. This reduces the cost from O ( sn 2 )to O ( dmn )where m n and d n . Next, we use singular decomposition to address the second limitation and reduce the cost from O ( n 3 )to O ( m 3 )where m n .

Let I r denote an identity matrix of size r  X  r .Beforewepresentthedetails of efficient matrix inversion, we prove that the following equation holds. Proof . We prove the correctness of the equation by showing that R.H.S. divided by L.H.S. equals to an identity matrix. Based on Eq. 11, we show that the cost of the matrix operation can be reduced. Let H k be defined as following.
 The following equation can be verified.
 Recall that R.H.S. of Eq. 14 equals to S k (see Eq. 2 in Section 3.2). We replace S k in Eq. 5 with its value in Eq. 15 which yields the following. symmetric matrix. Without loss of generality, we set S = N k =1 H k ( H k ) T which is a n  X  n gram matrix.
 We decompose S by using singular value decomposition [1] S = U X U T such that U
T U = I n . Note that the decomposition takes O ( n 3 ) but it can be efficiently approximated in O ( m 3 ) by using the techniques presented in [16]. Assume that we have obtained the approximate decomposition of S as follows.
 where U m is a n  X  m matrix formed by the first m normalized eigenvectors of U and m equals to the number of anchor images.  X  m is the diagonal matrix with m diagonal elements (sorted in decreasing order from left to right) and correspond to the m largest eigenvalues of S . Eq. 18 is equivalent to the following equation. where Y = U m  X  1 2 m . By combining Eq. 17 and Eq. 19, we obtain the following equation.
 F  X  =( NI n  X   X S )  X  1 L =( NI n  X   X YY T )  X  1 L = Since N remains constant for all of the images, the optimal ranking score vector F  X  can be obtained as follows.
 Note that Eq. 21, requires the inversion of a m  X  m matrix in contrast to Eq. 5 that requires the inversion of a n  X  n matrix. Hence, Eq. 21 reduces the cost from O ( n 3 )to O ( m 3 ). In this section, we evaluate the performance of our proposed approach (MMR) by using several real world image databases. All the experiments are implemented in Matlab R2009a and C++. First, we present the experimental setup in Section 4.1. Then, in Section 4.2, we evaluate the performance of our proposed approach. 4.1 Experimental Setup Data Sets. We evaluated the performance of MMR on the following data sets.  X 
COREL: It is composed of 7700 images divided into 77 categories.  X 
Caltech101: This image database contains 8677 images from 101 different cat-egories.  X 
MSRC: The data set contains 18 different categories and consists of approxi-mately 4300 images.
 Competitors. We compare our proposed approach with several manifold rank-ing based algorithms. Below are the details.  X 
MR . This is the first work [4] that applied manifold ranking (MR) for image retrieval.  X 
EMR . This is the algorithm proposed by Xu et al. [18]. While MR demon-strated good quality results, it is not suitable for large scale image databases because of its high computational cost. EMR proposes interesting techniques to improve the efficiency of MR and demonst rates that it retrieves the results of similar quality.  X 
ADF . This algorithm is proposed in [6]. ADF uses multiple features to con-struct a single image manifold.

Recall that our proposed approach uses multiple features to construct multiple image manifolds. We argue that using multiple image manifolds yield better results than the previous techniques. A natural question is whether previous approaches (e.g., MR and EMR) can perform better if they also utilize more than one features. To answer this question, w e extend the previous techniques such that they utilize multiple features. Below are the details of how each technique is extended.  X 
MR + N . N denotes the total number of features used by the algorithm. Let F k i be the ranking score of x i computed by MR [4] using k th feature. The final score of each image x i is N k =1 F k i .MR + N ranks the images according to the final scores. Note that MR +1 is the same as original MR algorithm proposed in [4].  X 
EMR + N . Similar to MR + N ,EMR + N computes the score of each image ac-cording to each feature. The images are then ranked according to their final scores. We remark that EMR +1 is the original EMR algorithm proposed in [18].
Later, we show that these extended versions retrieve better results than their respective original versions. Moreover, the quality of the retrieved results im-proves as the value of N increases. Similar to the notations used for extended version of MR and EMR, we use MMR + N to denote that our algorithm MMR was run using N features. Similarly, ADF + N denotes that ADF was run using N features.
 Features used by the algorithms . We use some of the most popular features in the algorithms. More specifically, we use DoG-SIFT (Scale-Invariant Feature Transform) [9], HOG (Histogram of Oriented Gradients) [2], LBP (Local Binary Patterns) [11], Centrist [17] and RBG-SIFT [14]. Table 1 shows these features in a particular order. Any algorithm using N features uses the first N features shown in Table 1. For example, MMR +3 is our algorithm and uses the first three features (DoG-SIFT, HOG and LBP). Similarly, EMR +2 denotes that EMR was run using first two features (DoG-SIFT and HOG). ADF +5 denotes that ADF was run using all of the features. We remark that this order of the features best suits EMR + N which is our main competitor.
 Evaluation metric. Each image in the image databases has its own category la-bel (e.g., car, aeroplane etc.). A query is randomly selected from these databases and a retrieved result is considered co rrect if its label matches with the query label. For each query, we retrieve top-K results where the default value of K is 10 unless mentioned otherwise. We use precision as the main evaluation metric which corresponds to the number of correct results in the top-K retrieved results divided by K .Since K is fixed for all competitors, the recall value is directly related to the precision, i.e., if precision is high then the recall is also high and vice versa. Hence, we use precisi on as the only evaluation metric.

Recall that our algorithm (MMR) samples m anchor points and, for each image x i , x i is connected to its d nearest neighbors. We set m to 500 and d to 5 because our preliminary experimental evaluation demonstrated that these values of m and d give a reasonable trade-off betw een the precision and efficiency of the algorithm. 4.2 Performance Comparison In this section, we compare the performance (precision and efficiency) of our algorithm with the other competitors. At the end, we present a case study where we show the top-10 results returned by MMR, EMR and ADF for three queries. Precision. In Fig. 2, we increase the number of features used by each algorithm and study its affect on the precision. Note that the performance of each algo-rithm improves as it uses more features. However, the precision obtained by our algorithm (MMR + N ) is the highest. This is because our algorithm constructs multiple manifolds and minimizes the cost function to obtain the ranking scores in contrast to the other algorithms that use multiple features (manifolds) some-what trivially. Note that the improvement in precision is less significant when N&gt; 3. Since the running time increases with the increase in N ,wechoose N =3 for rest of the experiments (unless mentioned otherwise). As noted in [18] and observed from Fig. 2 (a), the precision of EMR + N and MR + N is quite similar. Furthermore, EMR + N is more efficient than MR + N as we demonstrate later. Therefore, for a clearer illustration of results, in the rest of the experiments we exclude MR + N . In Fig. 2 (b), we issue top-K queries and vary K from 10 to 70 and study its affect on the precision. We observe that the precision of each of the algorithms remain unaffected with the increase in K . Also, note that our algorithm consistently gives better results than the other competitors.

In Fig. 3, we study the precision at a more d etailed level. More specifically, we randomly choose 90 categories from the three image databases. For each category, we randomly choose one image as the query. For each query, we obtain top-10 results and record the precision. Fig . 3 shows the precision of each algorithm for the queries selected from each of the 9 0 categories. It can be observed that our approach MMR +3 consistently performs better than the other methods. The EMR proposed in [18] (shown as EMR +1 ) has the lowest precision. However, EMR +3 that uses three manifolds has better retrieval performance than ADF + N . Running Time. In Fig. 4(a), we increase the number of features used by each algorithm and study its affect on the running time. Note that the running times of ADF + N and MR + N are much higher than the running time of our algorithm (MMR + N )andEMR + N .ThisisbecauseMMR + N and EMR + N present efficient techniques for matrix inversion and use the anchor graphs to approximate the large image graphs. Also, note that EMR + N and MMR + N scale better as the number of features increases. The cost of MR + N is the highest. In order to better illustrate the performance of other approaches, we do not display the cost of MR + N when N&gt; 2.

In Fig. 4(b), we increase the size of image databases and study its affect on the running times of all algorithms. It can be observed that ADF + N and MR + N cannot handle large scale databases (e.g., the running time is more than 80 seconds when the image database contains 8000 images). On the other hand, our proposed algorithm scales better and can handle large scale image databases. The cost of EMR +1 is the lowest. This is because it uses a single image manifold whereas our algorithm MMR +3 uses three image manifolds. Nevertheless, the running times of both of the algorithms are quite close to each other. A case study. In this section, we display the top-10 results returned by MMR +3 , ADF +3 and EMR +3 for three different queries. Fig. 5 displays the results re-turned by each of the algorithms. Irrelevant results returned by our algorithm are denoted by red square. Note that our algorithm returns more relevant results than the other two algorithms. In this paper, we propose a novel method name multi-manifold ranking (MMR) which uses multiple image manifolds for image retrieval. We conduct extensive experimental study on real world image databases and demonstrate that MMR provides better retrieval results than state of the art techniques. Our experi-mental results demonstrate that our algorithm is much more efficient than two existing algorithms and is comparable to the most efficient existing approach. Acknowledgments. Muhammad Aamir Cheema is supported by AR-CDP130103405 and ARCDE130101002; Xuemin Lin is supported by ARC DP0987557, ARC DP110102937, ARC DP120104168 and NSFC61021004.
