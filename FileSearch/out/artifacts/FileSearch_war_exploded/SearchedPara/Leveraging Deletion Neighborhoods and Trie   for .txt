 data vol u me. With the advent of WEB 2.0 era, many novel applications appeared, s u ch as social-networkin g websites (e. g . Facebook, Goo g le+, etc) and micro-blo gg in g websites (e. g . Twitters, Jaik u , etc), which f u rther boost text u al data vol u me at an ex-lates several problems. One of the major concerns is poor data q u ality problem, s u ch strin g similarity q u ery methods. The strin g similarity q u ery has involved many appli-cation scenarios, s u ch as data cleanin g [1], record linka g e [9], q u ery a u to-completion [2], approximate named entity extraction [4,5] and bio-informatics. The ability to rather costly. Therefore many st u dies have been devoted to developin g techniq u es for and memory efficient. Most of modern strate g ies adopt preprocessin g to index dataset for facilitatin g the fast eval u ation of q u eries. 
One widely adopted techniq u e employs a filter-and-verify framework [8],[13,14] verification step: verifyin g candidates by comp u tin g their real similarity and compar-filter-and-verify framework performs the strin g similarity q u ery efficiently. However verification step can be avoided. 
Another powerf u l scheme s u itable for short strin g s is based on nei g hborhoods g en-the al g orithm FastSS based on deletion nei g hborhoods scheme which en u merates nei g hbors by deletin g characters no more than  X  . It red u ces the space req u irement to O( n l  X  ) which is insensitive to the alphabet size. In [19] the a u thors proved the selectiv-[16] the a u thor proposed an improved deletion nei g hborhood g eneration method base len g th). Inspired by [4], [19] developed an index red u ction method which indexes the hoods instead of entire ones and makes their filter conditions weaker than the ori g inal one in [17]. Notice that the red u ction in space req u irement is on the cost of admittin g more false positives in candidates and req u ires more time for verification. 
In this paper, we foc u s on achievin g a faster q u ery speed with affordable memory cons u mptions. O u r contrib u tions are the followin g :  X 
We present a novel method which levera g es the power of deletion nei g hborhoods and trie to answer the edit distance based strin g similarity q u eries.  X 
Index partition and optimization strate g ies are proposed to f u rther red u ce index size. The bit vector based verification method is proposed to speed u p verification.  X 
We implement o u r method on both similarity search and join and compare o u r method with the state-of-the arts methods. The experimental res u lts report a si g nif-icant promotion on the performance of methods based on deletion nei g hborhoods. 
The remainder of this paper is or g anized as follows: Section 2 presents prelimi-Section 5. Section 6 concl u des this paper. There are two types of f u nctions for q u antifyin g the similarity of strin g s. One is called token-based similarity, which tokenizes strin g s as token sets (ba g of words or g rams) and then q u antifies similarity by comp u tin g the overlaps between token sets, e. g , J a c-and the most widely-u sed f u nction is Edit D ist an ce . Its formal definition is the mini-tance between r and s . The classical al g orithm for comp u tin g edit distance is dynamic pro g rammin g and its time complexity is O(| r | X | s |) [6]. An improved al g orithm red u ces the comp u tation in O(  X   X  min(| r |,| s |)) time [3].
 stri ng s {id i | ed(s i ,q)  X   X  , &lt;id i ,s i &gt;  X  D }.
 &lt;id j ,s i &gt;  X  S }. If R= S , it is c a lled self si m il a rit y joi n . 
Let  X  be a finite alphabet of symbols, each symbol is called a character. A strin g s D ( s ,  X  ). We now define the  X  -variant family. de n oted b y F(s,  X  ), F(s,  X  )={s X  X  s X   X  D (s, k ), 0  X  k  X  X  }. the filterin g condition in lemma 1 is a necessary condition. Even the strin g s meet this condition, their edit distance may not be within  X  . E. g ., F (abcd,1)  X  F (abdf,1)={abd}, tion list which records the deleted position to transform s to s  X  . |
 X  (s 1  X )  X   X  (s 2  X )|  X   X  . 
Lemma 2 extends lemma 1 with a verification method by comp u tin g cardinality of | [3,4]|=2&gt;1, th u s ed (abcd, abdf)&gt;1. 3.1 Basic Structure and Verification The  X  -variant family is g enerated rec u rsively by deletin g characters in order. To avoid needs to be processed and is decreased by 1 at each rec u rsion level. After the  X  -variant family of strin g s is g enerated, we insert them in a trie with some extensions. General-the leaf node. Algorithm 1. DNF-Gen( s , p ,  X  ,  X   X  , v ) Output:  X  -variant family of s , F ( s ,  X  ). 1. p  X  1, l  X  | s |,  X   X   X  X  ; 2. for i = p to l do 3. te m p  X  s ; 4. delete te m p [ i ]; 5. new a bit-vector b v and b v [ i ]  X  1; 6. b v  X  ( b v  X  (  X   X   X   X  ))&amp; v ; 7. F(s,  X  )  X  &lt; te m p , b v &gt;; 8. if (  X  -1)&gt;0 and |te m p |&gt;  X  -1 then 9. D NF-G e n ( te m p , i ,  X  ,  X  -1, v ); rays, i.e., they store the position of deleted character in the c u rrent rec u rsion in order. space req u irement for these deletion lists, we adopt a bit vector to record the positions (al g orithm 1, line 4-6). S u ppose the maxim u m strin g len g th of a dataset is L and then we only need  X  L /8  X  bytes to store a deletion-list. For the short strin g s whose len g th is the bit vector format deletion list definitely saves the index space. Different from the step, the bit vector format deletion list stores the absol u te deleted positions in ori g inal ori g inal strin g . We observe that if the n u mber of overlapped  X 1 X  in two deletion lists overlapped  X 1 X  is y , then it needs 2 y edit operations for transformation. If two strin g s are within edit distance  X  , then x +2 y  X   X  is always tr u e. Based on this observation, we propose a fast verification method u sin g bit vector format deletion list. First we define shows the description. Algorithm 2. BV(&lt; s 1  X  ,  X  ( s 1  X  )&gt;,&lt; s 2  X  ,  X  ( s 2  X  )&gt;) Output : tr u e: ed ( s 1 , s 2 )  X  X   X  false: otherwise. 1. if s 1  X   X  s 2  X  then 2. ret u rn false; 3. else  X  X  co un t_bit (  X  ( s 1  X  )  X  X R  X   X  ( s 2  X  )); 4. if  X  X  X  then 5. ret u rn tr u e; 6. else 7. ret u rn false; g i v e n t h e stri ng s s 1 =ste v e n , s 2 =ste v e m s, s 3 =se w de n . F(s 1 ,2)  X  F(s 2 ,2)=&lt;ste v e,  X  1 =00100000&gt;,&lt;ste v e,  X  2 =01100000&gt;; F(s 1 ,2)  X  F(s 3 ,2)=&lt;see n ,  X  3 =00001010),&lt;see n ,  X  4 =00001100&gt;. 
Given a dataset D , we g enerate the  X  -variant family for every strin g in D and insert them in a trie with the bit vector format deletion list, see Fi g . 1(a). For convenience of narration, we call it S-DNT (Sin g le Deletion Nei g hborhoods Trie). Obvio u sly, S-DNT scalable, S-DNT may be too lar g e for small memory comp u ters. So we adopt some ( P artition based Deletion Nei g hborhoods Trie). Followin g are the partition strate g ies. Length based partition (LP). The motivation comes from the fact that if two strin g s Let  X  denote a partition of the P -DNT index, i.e. a trie. The partition strate g y can be variant family whose ori g inal strin g len g th belon g s to the specified ran g e. The over-to look u p in several index partitions that cover the ran g e [| q |- X  , | q |+  X  ]. Deletion number based partition (DNP). Given an edit distance threshold  X  and g enerate the  X  -variant family of all strin g s in a dataset. Each i -deletion nei g hbors was benefits are that it s u pports any edit distance threshold no lar g e than  X  and the candi-date size is small as for some certain index partitions, the verification can be skipped. (  X   X  [0,  X  ]), if  X  +  X  &lt;  X  , the verification can be skipped. 
For P -DNT, the index partitions for a q u ery to look u p are clearly specified. It aims to red u ce the candidate size b u t on the cost of additional space req u irement. Beca u se sharin g prefix. As we can preprocess the dataset and retrieve the partitions of P -DNT from disk whenever the q u ery needs, it saves in-memory index space. 3.2 Subtree Merging similar strin g s and indexin g them in a trie costs red u ndant space. In order to remove s u btrees which are identical or isomorphic. Many techniq u es are devoted to compress a trie, e. g ., do u ble array trie which achieves 17 per cent smaller than the list based trie b u t the insertion is q u ite time cons u min g [7]. From Fi g . 1(a) we can see that mer g in g common s u btrees (d u plicate path) may achieve a remarkable red u ction on index size. We notice three cases of common s u btrees can be mer g ed. 
Case 1. Two nodes are with the same label (character) and their s u btrees are liter-Fi g . 1(a), we mer g e the deletion list pairs on the same labeled leaf nodes (26 and 31, 19 and 34), then divert the incomin g ed g e of node 28 to node 20 and delete node 28 and all its s u btrees. Finally we obtain the node 5 in Fi g . 1(b) with the mer g ed list item N27:{S 1 ,S 2 }-[000001].

Case 2. Two nodes are with the different labels b u t their s u btrees are literally iden-we divert the incomin g ed g e of node 21 and 24 to node 14 and 17, mer g e the deletion list pair on the leaf nodes with ro u tin g information for the deletion list, then delete the node 21 and 24 and their s u btrees. Finally we obtain the node 5 in Fi g . 1(b) with the mer g ed list item N2:{S 1 ,S 2 }-[000010]. 
Case 3. Two nodes with the different characters and their s u btree are isophmoic b u t the strin g ids on the leaf nodes are different. E. g ., the node 6 and 10 in Fi g . 1(a), their correspondin g to the strin g s 1 and node 10 ( X  w  X  ) is correspondin g to the strin g s 2 . mer g in g common s u btree definitely achieves a red u ction in size of trie index. 4.1 Similarity Search First, we prove that the deletion nei g hborhoods based strin g similarity search retrieves d u plicate res u lts. Then we g ive the al g orithm of similarity search. Lemma 3. Given an edit distance threshold  X  , we consider  X  -variant family as a u ni-have overlap, i.e., { F ( r ,  X  )-F ( r ,  X   X  )}  X  { F ( s ,  X  )-F ( s ,  X   X  )}  X   X  . x = k -k  X  , { F ( r ,  X  )-F ( r ,  X   X  )}  X  { F ( s ,  X  )-F ( s ,  X   X  )}  X   X  . Lemma 3 proves that the deletion nei g hborhoods scheme ca u ses d u plicate res u lts. 
In order to remove the d u plicate res u lts in retrieval process, we adopt a minim u m-heap data str u ct u re to store the strin g ids that has passed the verification step. When a strin g id is inserted into the heap, it calls for a binary search to check if it has already existed. Finally it pops elements from heap as res u lts. Al g orithm 3 shows the pse u do-which exactly matches s . Algorithm 3. SimilaritySearch-DNT( R , q ,  X  ) Input: dataset R , a q u ery strin g q , edit distance threshold  X  . Output: { r | ed ( r,q )  X   X  , r  X  R }. 1.

 X  ( R ,  X  )  X  D NF_ G EN ( r ,1,  X  ,  X  , u ); 2. F ( q ,  X  )  X  D NF_ G EN ( q ,1,  X  ,  X  , v ); 3. foreach q X   X  F ( q ,  X  ) do 4. Candidates  X  exactly_search( q X  ,  X  ( R ,  X  )); 5. Min-Heap H  X  BV(  X  ( q X  ),  X  ( c , c  X  Candidates)); 6. pop H 7. end 4.2 Similarity Join An int u itive way to perform similarity join for two datasets is to index their  X  -variant family in S-DNT, then apply depth-first or breadth-first traversal al g orithm to retrieve the candidates on the leaf nodes and verify the candidates pairwisely (referred as SJ-SDNT). However it is inefficient since the traverse cannot start u ntil the index is con-str u cted, and for two lar g e datasets, it may fail d u e to the limited memory space. To address this problem, we proposed an incremental similarity join al g orithm called ISJ-i  X  j , r i , r j  X  R . To minimize the space req u irement, we adopt the non-overlappin g len g th order to save the memory space if meetin g the strin g s with len g th | r i |+1. The pse u do-code is shown in al g orithm 4. Algorithm 4. ISJ-DNT( R ,  X  ) Input : dataset R , edit distance threshold  X  . Output : similarity pairs {&lt; r i ,r j &gt;| ed ( r i ,r j )  X  X  , r i ,r j  X  R }. 1. Sort R in ascendin g order of strin g len g th and lexico g raphic order; 2. for each r  X  R do 3. F ( r ,  X  )  X  D NF_ G e n ( r ,1,  X  ,  X  , v ); 4. for each r X   X  F ( r ,  X  ) do 6. Candidates=exactly_search( r X  ,  X  i ); 7. Min-Heap H  X  BV(  X  ( r X  ),  X  ( c , c  X  Candidates)); 8. pop H 9. end are implemented in C++ and complied in GCC 4.1.2 with the  X  X 3 fla g . To gu arantee machine with AMD Opteron 4 X 8 cores, 800MHz and 32GB Memory r u nnin g Red Hat Enterprise Lin u x Server 5.5 with kernel 2.6.18. The experiments are cond u cted on a p u blicly available dataset: ENGLISH-DICT 1 . It has 150K records and the aver-a g e len g th is 9, |  X  | is 27. We compared o u r method with followin g methods:  X 
The na X ve method that directly indexes deletion nei g hbors with inte g er deletion arrays, denoted by HashTable(Ori-Nohash). The candidates are verified by com-parin g two deletion lists.  X 
In [17], it indexes the hash val u e of deletion nei g hbors and alon g with inte g er dele-tion list, denoted by HashTable(Ori-BKDR). The hash f u nction is BKDR desi g ned specifically for strin g s. The candidates are verified by comparin g two deletion lists.  X 
In [4], it indexes the prefix of deletion nei g hbors and verifies candidate strin g s by comp u tin g the edit distance u sin g al g orithm in [3], denoted by HashTable(pre-l p ).  X 
In [19], it indexes the s u ffix of deletion nei g hbors and verifies candidate strin g s by comp u tin g the edit distance u sin g al g orithm in [3], denoted by HashTable(s u f-s p ). 5.1 Evaluating Index Construction We compare the constr u ction performance of the indices mentioned above, incl u din g S-DNT, P -DNT with non-overlappin g len g th based partition (L P -NO), P -DNT with over-(DN P ). Since the max len g th of En g lish-Dict is 30, we divide the len g th partition based after compression. We can see that constr u ction time of DNT index (witho u t compres-compress the index, and (M) means the index after s u btree mer g in g . We can see that the path and the size of hashtable is smaller than DNT. From  X  =1 to 3, the s u btree mer g in g red u ce the DNT index by 2.5 to 4 times and achieves the same level with the HashTa-prefix or s u ffix based hash table as the latter does not store any deletion lists. The time abo u t 3 times as constr u ction time. 5.2 Evaluating Similarity Search We st u dy similarity search performance on different indexin g schemes. Firstly, we fix Then we fix the maxim u m edit distance threshold to 3, vary the q u ery file with 1000-5000 q u eries with edit distance threshold from 0 to 3 randomly. The total q u ery time o u r method o u tperform the prefix/s u ffix based hash index beca u se o u r method obtains smaller candidates size and o u r verification al g orithm performs faster. Then we select second experiment as they req u ire smaller index space than HashTable(ori-BKDR) for  X  =3. We can see that for the random threshold q u ery, o u r method performs u p to 10 times faster and g enerate smaller candidate size per q u ery. The res u lts proved that o u r method achieves a faster q u ery speed with affordable memory cons u mptions. 5.3 Evaluating Similarity Join We st u dy the performance of similarity join by varyin g the edit distance threshold. To the best of o u r known, there isn  X  t any experimental eval u ation of similarity join u sin g the deletion nei g hborhoods scheme. We compare o u r method with the state-of-art 
We see that for  X  =1, Trie-Join is 1.6 times faster than o u r method; for  X  =2, o u r me-thod is very close to Trie-Join; for  X  &gt;2, o u r method o u tperforms Trie-Join. The main reason is that for a small edit distance threshold, the active node set for comp u tin g in processin g indicates that ISJ-DNT is related to len g th distrib u tion of the dataset. space req u irement for deletion nei g hborhoods and propose s u btree mer g in g to f u rther power of deletion nei g hborhoods. Experimental res u lts show o u r method is more efficiently than the state-of-art method based on deletion nei g hborhoods. Acknowledgements. This work is partly s u pported by China National 863 Hi g h Technolo g y P ro g ram (No.2013AA13204, 2012AA01A401), China National Nat u ral Science F u nds (No. 60903047, 61272361). 
