 Generally speaking, recommender systems provide users with personalized sug-gestions by predicting the rating or preference that the users would give to an item. They have become increasingly common recently and are used by many internet leaders. Examples include movie recommendation by Netflix [ 1 ], web page ranking by Google [ 2 ], related product recommendation by Amazon [ 3 ], social recommendation by Facebook [ 4 ], etc.
 usually in one of the two ways: (1) content-based filtering based on the charac-teristics it has and the item descriptions which could be automatically extracted or manually created, and (2) collaborative filtering that predicts other items the users might like based on the knowledge about preferences (usually expressed in ratings) of users for some items. Due to the limitations of content-based filter-ing algorithm (sometimes characteristics are unobvious and item descriptions are hard to extract), most recommender systems are based on collaborative filtering. according to the same taste or common experiences from others and based on the assumption that people who agreed in the past will also agree in the future over time. There are two primary strategies to deal with collaborative filtering: the neighborhood approaches and latent factor models. Neighborhood methods [ 5 ] concentrate on the relationship between items or users, so they are good at detecting localized relationships (e.g., someone who likes Superman also likes Batman), but fall short of power in detecting the user X  X  overall preference. By transforming both items and users to the same latent space, latent factor models try to explain the ratings by items and users, aiming at making them directly comparable. Latent factor models are good at estimating the overall structure (e.g., a user likes comedy movies), but less effective in analyzing associations among small sets of closely related items.
 Matrix factorization methods, such as Non-Negative Matrix Factorization (NMF) [ 6 ] and Singular Value Decomposition (SVD) [ 7 ], are widely used for constructing a feature matrix for users and for items, respectively. Generally, matrix factorization, as one of the most successful realizations of latent fac-tor models, can produce better accuracy than classic nearest neighbor methods when dealing with product recommendations because of the incorporation of additional information such as implicit feedback and temporal effects [ 8 ]. In real life situations, when a new user comes in, most recommender systems would only ask the user to rate a certain number of items (which is a small pro-portion comparing with the whole set). Therefore the ratings matrices are often extremely sparse, which means there is not enough knowledge to form accurate recommendations for the user. To get precise recommendations for this user, active learning in collaborative filtering is often used to acquire more high-quality data in order to improve the precision of recommendations for the target user. However, traditional active learning methods [ 9  X  11 ] only evaluate each user independently and only consider the benefits of the elicitation to the  X  X ew X  user, but pay less attention to the effects of the system. In this work we propose a rating elicitation strategy that improves the accuracy of the whole system by eliciting more ratings for  X  X xisting X  users. In some previous works, ratings were elicited one by one per request [ 9 ] or user X  X  by user X  X  per request [ 11 ]. The consequence is that the model is trained at each request, which is significantly time-consuming. In this paper, we design a series of methods that elicit ratings simultaneously with matrix factoriza-tion algorithms. Through this special preprocessing step not only are the compu-tational costs reduced, but also the performance of matrix factorization methods is greatly improved.
 The rest of the paper is organized as follows. We start with preliminaries and related work in Sect. 2 . Then in Sect. 3 we introduce a new way to apply active learning to recommender systems. A more accurate model is proposed in Sect. 4 . Experimental results and analyses are provided in Sect. 5 . Section 6 concludes the work. 2.1 Regularized SVD Normally, matrix factorization methods are used to deal with the issue of missing values in a given ratings matrix. However, ratings matrices are usually extremely sparse. For example, the density of the famous Netflix and Movielens data sets are 1 . 18 % and 4 . 61 %, respectively, which means that only a few elements are rated while most of them are unknown. Another challenge is that the data set we use in real world recommender systems is typically of high dimensionality. Due to high sparseness and computational complexity, directly applying SVD algorithms to rating matrices is not appropriate.
 for collaborative filtering which decomposes the ratings matrix into two lower rank matrices. Suppose R  X  R m  X  n is the ratings matrix of m users and n items. The regularized SVD algorithm finds two matrices U  X  R k  X  the feature matrix of users and items: about the various latent factors of that movie. So each rating r the j th movie in the matrix R can be represented as: where U i , V j are the feature vectors of the i th user and the j th movie, respec-tively. Once we get the best approximation of U and V , we can obtain the best prediction accordingly. The optimization of U and V can be performed by min-imizing the sum of squared errors between the existing scores and prediction values [ 12 ]: where  X  is a set of elements in the ratings matrix R that have been assigned values, k u and k v are regularization coefficients to prevent over-fitting. Descent (SGD) is widely used and has shown to be effective for matrix fac-torization [ 12  X  14 ]. SGD loops through all ratings in the training set  X  and for each rating it modifies the parameters U and V in the direction of the negative gradient: where  X  is the learning rate.
 smaller matrices which minimize the resulting approximation error in the least square sense. By solving this optimization problem, the end result is the same as SVD which just gets the diagonal matrix arbitrarily rolled into the two side matrices, but could be easily extracted if needed. 2.2 SVD++ Since matrix factorization for recommender systems based on regularized SVD was first proposed, several variants have been exploited with extra information on the ratings matrix. For example, Paterek [ 13 ] proposed an improved regularized SVD algorithm by adding a user bias and an item bias in the prediction function. Koren [ 14 ] extended the model by considering more implicit information about rated items and proposed a SVD++ model with the prediction function: where u is the global mean,  X  i is the bias of the i th user and  X  j th item. U i is learnt from the given explicit ratings, I ( i ) is the set of items user i has provided implicit feedback for. | I ( i ) | (  X  1 / 2) of implicit feedback. The implicit information enables SVD++ to produce better performance than regularized SVD model. 2.3 Dataset Movielens is a classic recommender system data set that recommends films to users through collaborative filtering algorithms. It contains 100,000 ratings from 943 users on 1,682 movies and each rating is an integer ranging from 1 to 5 which represents the interests the user has to this movie. All users were selected at random for inclusion and each user selected had rated at least 20 movies. The whole data set is randomly partitioned into training set and test set with exactly 10 ratings per user in the test set. The quality of results is usually measured by their RMSE: where T is the total number of test samples.
 RMSE is one of the common error metrics and often used to evaluate recom-mender systems especially in the official Netflix contest [ 1 ]. It is important to note that the characteristics of the prediction algorithm may influence the prediction accuracy. Matrix factorization methods learn the model by fitting a limited number of existing ratings, hence we could make an assump-tion that the more reliable ratings we have, the better accuracy the model can reach. However, in most recommendation system data sets, the ratings matrices are extremely sparse because a user typically only rates a small proportion of movies while most ratings are unknown, which motivates us to add more high quality data for matrix factorization.
 3.1 The Item-Oriented Approach Classic active learning methods focus on different individual rating elicitation strategies for a single user when a new user comes in. These strategies include: 1. Randomization: It can be regarded as a baseline method (e.g., [ 11 , 15 , 16 ]). 2. Popularity-based: Items with the largest number of ratings are preferred. It 3. Entropy-based: Items with the largest entropy are selected [ 15 ]. 4. Highest predicted Items with the highest predicted ratings are preferred [ 16 ]. 5. Lowest predicted: Items with the lowest predicted ratings are chosen. The 6. Hybrid: This includes Log(popularity)*entropy [ 15 ], Voting , which considers tions for  X  X  single user X  and the model was trained in each iteration user by user, which incurs high computational costs. While implementing classic active learn-ing strategies, the items selected for different users to elicit are always different. For example, the items with the highest predicted ratings for a user may not be the same as another user X  X  since not all users have the exactly same tastes. Hence strategy has to be applied repeatedly for each user to elicit ratings which are corresponding to different items but with one exception: popularity-based strategy.
 lens data set for example, the maximal and minimum number of popularity is 495 and 0, respectively, which means that the most popular movie is rated by 495 users while for some movies there is no one has rated them before. Popularity is based on the number of ratings of each item only and it is irrelevant to users, therefore the popularity remain unchanged no matter which users we choose. Here we only select the top N most popular movies for all the users to form a new block matrix, based on the idea that users tend to rate world-famous movies than movies in the minority. Then the missing values in this block would be the  X  X esirable X  movies in some sense for the users who missed before. Our strategy is to elicit these specific ratings for all the users at the same time in one iteration through matrix factorization on this block matrix. After adding these ratings to the original rating matrix, a more accurate matrix factorization model could be extracted. The overall procedure of this approach are shown in Algorithm 1 . all users, in order to improve the performance of the whole system. Therefore, it reduces the training iteration for as high as the number of users to only 2, and evaluate the benefits of the system instead of each user. Algorithm 1. The item-oriented approach 3.2 The User-Oriented Approach Traditional active learning for collaborative filtering is a set of techniques to intelligently select a number of  X  X tems X  to rate so as to improve the rating pre-diction for the user, while Carenini et al. [ 17 ] proposed an item-focused method that elicits ratings by choosing some special users to rate a specific item in order to improve the rating prediction for the item. Because of the feasibility of this item-focused method we also propose a user-oriented approach as shown in Algorithm 2 to further explore its potential.
 Generally, the number of movies each user has rated varies significantly (e.g., in Movielens data set the maximal and minimum number for different user X  X  are 727 and 10, respectively). In fact, though active users who are enthusiastic about movies may watch far more than the ones who are not into movies, there still exist some movies the users have watched but not yet rated. For these reasons, it is easier to accept that they would give ratings to the movies they have not rated yet. In Algorithm 2 we select this kind of special users based on the number of movies they have rated. After these movie enthusiasts are chosen, ratings of the movies they never rate would be elicited by matrix factorization as the missing values in the new block. Then we add these new ratings to the original matrix for matrix factorization again to get the target values we want.
 by eliciting ratings of all movies for only active users simultaneously. Therefore it also has the benefits that Algorithm 1 has. However, both algorithms still may suffer from large computational cost because of the extensively selection of elicitations, especially when the number of popular movies or active users selected in the block matrix is large.
 Algorithm 2. The user-oriented approach So far we have presented an item-oriented approach and a user-oriented app-roach, both based on the idea that eliciting a group of reliable and meaningful ratings simultaneously for matrix factorization model to learn. The reason why these new ratings from Algorithms 1 and 2 should be reliable is because they are predicted from a denser block which is formed from the top numbers of ratings in either item-view or user-view by a matrix factorization method. Typically the denser the matrix is, the better the matrix factorization model we can obtain. Take the Movielens data set as an example, the density of the original matrix is 5 . 71 %. However, if only the top 5 % of the most popular movies are chosen, we can obtain a block of density 29 . 47 % which consists of more ratings that have been already rated by the users. While selecting the top 5 % of the most active users, the density of the new block we obtain is 23 . 33 %. Based on this assumption we propose a density-oriented approach which combines previous item-oriented and user-oriented methods in Algorithm 3 .
 Algorithm 3. The proposed density-oriented approach Because both the popularity of movies and the activity of users depend on the numbers of ratings each user rates or each movie is rated, by choosing the top N popular movies and active users we can obtain the densest block matrix. With the Movielens data set, if we choose the top 5 % of the most popular movies and most active users, the density of the newly-formed block matrix would be 77 . 28 %. The missing values in this block matrix can be explained as ratings of the most famous movies but have not been rated by a group of most active users. By applying matrix factorization on this block, a better model could be extracted and the missing values (elicited ratings) could be predicted with higher accuracy. Finally a more accurate matrix factorization model can be learnt by fitting the existing ratings and extra high quality elicited ratings. We conducted experiments of our proposed item-oriented, user-oriented and density-oriented approach (ESVD) on the classic recommender system data set: Movielens 100K. We also performed some experiments with the larger version and obtained similar results. However, it requires much longer time to perform our experiments since we train and test the models each time for different choice of the number of N . Therefore, we focused on the smaller data set to be able to run more experiments, in order to explore how this parameter N affects the results of our matrix factorization methods. We use RMSE as the default met-ric which is widely used in the Netfilx Competition and proved to be effective to measure recommender systems. The number of the latent factors (rank) are set to be 10 for training each matrix factorization model. Although increasing it does raise the performance, the computational cost is proportional to latent factors. For matrix factorization of the comparatively smaller block matrix M M 2 and M 3 , the coefficient of the regularization term is 0.01 for both k k , and the learning rate  X  is 0.1 with a decrease by a factor of 0.9 each iter-ation. For matrix factorization of the ratings matrix (with elicited ratings) R , the coefficient of regularization term is 0.1 for both k u rate  X  is 0.01 with decrease by a factor of 0.9 each iteration. items or users N selected in the block matrix. We see that as the number of items or users N increases, the errors set keeps dropping since more ratings are added into the training matrix, afterwards the errors fluctuate in a small region. Specif-ically, the results of the item-oriented approach (Algorithm 1 ) are not promising. Because in the item-oriented approach we only elicit ratings based on the most popular movies, which may lead to a lot of bias and distort the latent factor model. For example, most people prefer happy endings, the consequence is that comedies are more popular than tragedies. Then a lot of comedy movies would be elicited for each user to give ratings which leads the latent factor model (reg-ularized SVD in this case) to put more weights on the factor corresponding to comedies. Although the RMSE of user-oriented approach (Algorithm 2 ) fluctu-ates around the baseline method (the red line) at first, it gets lower as N goes up. The best result of Algorithm 2 we obtain is 0.9619 which reduces RMSE by 0.09 when compared with the regularized SVD 0.9709. It is apparent from the figure that our proposed ESVD consistently outperforms other methods including the baseline method: regularized SVD.
 In Table 1 , we illustrate the RMSE of proposed density-oriented (ESVD) method which incorporates both item-oriented and user-oriented approach on the same data set. We compare different RMSE based on how many items and users (from 0 % to 20 %) we select. Note that the basic matrix factorization is a special case of our method when setting N = 0 %, which is used as the baseline for comparison. After selecting a certain percentage of items and users, we can obtain a block matrix. We can observe that the more items and users we choose, the sparser the block matrix will be. The missing values in the block are chosen to be elicited ratings. Although sparser matrix may lead to a less accurate matrix factorization model and the quality of elicited ratings may not as good as the ones from the denser matrix, the number of the elicited ratings is increased. Therefore more ratings can be added into the process of learning the target matrix factorization model. At last we compute predictions on the test set and get results. Because the block matrix is the intersection of the top N items and N users, its density is much greater than the one from item-oriented or user-oriented approach. Even with less ratings to be elicited compared with item-oriented and user-oriented, the results are better. In our experiments, we observed that the performance fluctuates as the number of top projects increases (Table 1 ). The optimal point that balances the quality (density of block matrix) and the quantity (number of elicited ratings) depends on the distribution of ratings. The Algorithm 3 can reach to 0.9570 (when N = 20 %) which reduces the RMSE by 0.0139 compared with the regularized SVD 0.9709. 5.1 Extension: ESVD++ Broadly speaking, our proposed ESVD approach can be seen as a preprocess-ing step and it can be incorporated with other variants of SVD models, such as SVD++ [ 14 ]. We conduct ESVD++ by just changing the prediction algo-rithm from SVD to SVD++. Compared with SVD model, SVD++ improves the prediction accuracy by adding biases and implicit information I ( i ), and the pre-diction function is shown in Eq. 6 . Specifically, I ( i ) contains all items for which the i th user has provided a rating, even if the value is unknown. Therefore, for prediction of elicited ratings as shown in Step 4 of Algorithm 3 , I ( i )issettobe the number of existing ratings and the missing values in the block matrix that are also shown in the test set. For prediction of test set as shown in Step 7 of Algorithm 3 , I ( i ) is the same as the one in original matrix without considering the elicited ratings.
 elicited would also be the same. The results show that the ESVD++ outperforms the state-of-art SVD++ model and greatly reduces the RMSE by 0.0214 (from the baseline SVD++ 0.9601 to 0.9387 when N = 10 %). The lack of information is an acute challenge in most recommender systems. In this paper, we present a new matrix factorization method called ESVD which applies SVD with ratings elicitation that best approximates a given matrix with missing values. We conduct corresponding experiments on the Movielens data set. Instead of looking at the active learning from the individual user X  X  point of view, we deal with the problem from the system X  X  perspective. Although the proposed method cannot deal with the cold start problem where the database keeps growing as new users or items continue to be added, it does reduce the computational costs greatly (the iteration number from as high as the number of users to only 2) since all the ratings are elicited simultaneously. Compared with traditional matrix factorization models, it can be incorporated with differ-ent SVD-based algorithms and greatly improve the performance of the whole system. Because the model is learnt by extra high-quality-elicited ratings that are extracted from the densest block matrix we create based on item popular-ity and user activity. Even using basic SVD as a prediction algorithm, without considering the effect of implicit feedbacks, the performance is better than its counterpart SVD++.

