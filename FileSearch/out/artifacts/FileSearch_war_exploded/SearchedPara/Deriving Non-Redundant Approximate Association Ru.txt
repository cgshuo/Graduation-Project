 Association rule mining plays an important job in knowledge and information discovery. However, th ere are still shortcomings with the quality of the discovered rules and often the number of discovered rules is huge and cont ain redundancies, especially in the case of multi-level datasets. Pr evious work has shown that the mining of non-redundant rules is a promising approach to solving this problem, with work by [6,8,9,10] focusing on single level datasets. Recent work by Shaw et. al. [7] has extended the non-redundant approaches presented in [6,8,9] to include the elimination of redundant exact basis rules from multi-level datasets. Here we propose a continuation of the work in [7] that allows for the removal of hier archically redundant approximate basis rules from multi-level datasets by using a dataset X  X  hierarchy or taxonomy. H.2.8 [ Database Management ]: Database Applications  X  Data Mining .
 Algorithms. Multi-level datasets, redunda nt association rules. Since its introduction in [1], association rule mining is now an important and widely used data mining technique. The aim of this technique is to extract frequent patterns, interesting co-occurrences and associations am ongst sets of items in large transactional databases. Traditionally there has been two steps in obtaining association rules: dete rmining the frequent patterns or itemsets and generating the rules from these frequent patterns/itemsets. Often too many association rules containing redundancies are discovered which too often become overwhelming and difficult to comprehend. Through the use of frequent closed itemsets the issue of redundancy can be dealt with by deriving non-redundant associati on rules [6,8,9,11]. However, this work has only dealt with re dundancy in single level datasets. Multi-level datasets (in which the items are not all at the same concept level) contain information at different levels and to obtain it all, techniques that take all the levels into account are needed [2,3,4,5]. Rules derived from multi-level datasets can also have the same issues with redundanc y as those from single level datasets. While existing approaches used to remove redundancy in single level datasets [6,9,10] can be adapted for use in multi-level datasets, they still fail to remove all of the redundancies present, namely the redundancy of hierarchy, where one rule at a given level gives the same information as another rule at a different level. This paper looks into hierarch ical redundancy for approximate basis association rules (which ha ve a confidence of less than 1) and proposes a continuation and extension of the work in [7]. From this a more concise non-re dundant approximate basis rule set can be derived. Whether a rule is interesting and/ or useful is usually determined through the support and confidence values that it has. However, this does not guarantee that all of the rules that have a high enough support and confidence actually convey new information. For example, the item 1-1-1 (rule 1) is a descendant of the more general/abstract item 1-*-* (rule 2) . If we know that rule 2 says 1-*-* is enough to fire the rule with consequent C, whereas rule 1 requires 1-1-1 to fire with cons equent C, any item that is a descendant of 1-*-* will cause a rule to fire with consequent C. It does not have to be 1-1-1. Thus rule 1 is more restrictive. Because 1-1-1 is part of 1-*-* having rule 1 does not actually bring any new information to the user, as the information contained in it is actually part of the information contained in rule 2. Thus we consider rule 1 to be redundant. The exception to this would be if a rule which would normally be considered redundant in fact has a higher confidence value than the rule it is being considered redundant to. Since approximate association rules are measured by their confidence, which indicates their strength, trustworthiness, accuracy and/or reliability, it is important to ensure those rules with a high confidence are kept. Thus rule 1 (1-1-1 ==&gt; 2-2-*, 2-1-1) would normally be considered redundant to rule 2 (1-*-* ==&gt; 2-1-1, 2-2-*) as the antecedent of rule 1 is a descendant of the antecedent of has a confidence of only 0.6, we have more confidence in that rule 1 is correct than rule 2. Becau se of this, rule 1 should be kept in the approximate basis rule se t and should not be considered redundant. From the previously described de tails for hierarchical redundancy in approximate basis rule sets, we propose the following definition for hierarchical re dundancy in approximate basis association rules. Definition 1 (Hierarchical Redundancy for Approximate Basis) : Let R 1 = X 1 =&gt; Y with confidence C 1 and R confidence C 2 be two approximate association rules, with exactly the same itemset Y as the consequent. Rule R 1 is redundant to rule R if (1) the itemset X 1 is made up of items where at least one item in X 1 is descendant from the items in X 2 and (2) the itemset X is entirely made up of items where at least one item in X ancestor of the items in X 1 and (3) the other non-ancestor items in X are all present in itemset X 1 and (4) the confidence of R is less than or equal to the confidence of R 2 (C 2 ). As can be seen, the use of our approach has reduced the approximate basis rule set for n early all cases shown here. In some instances the basis set was only reduced by a few rules, but in other cases there was a more significant reduction in the size of the basis set. For example, in Table 1 for dataset T4 there was a reduction of 1583 rules from 6427 to 4844, which is about 24.6%. Also a reduction of around 25% fo r dataset H1 was achieved and around 18.1 to 13.7% for dataset T3. For other datasets the reduction is between about 11 to 16%. By using this approach we have successfully reduced the size of the approximate basis without losing any information as all algorithms successfully recover all of the approximate rules. For the above table (Table 1), MMA and RAB refer to existing algorithms presented in [6,10] respectively. MMA with HRR and RAB with HRR are our extended algorithms (based on the algorithms presented in [6,10]) that have been enhanced to remove hierarchical redundancy. Redundancy in association rules a ffects the quality and usefulness of the information presented in a rule set. The goal of redundancy elimination is to improve the quality and use of the rules by reducing the number of rules. Our work aims to remove hierarchical redundancy in multi-level datasets, thus reducing the size of the rule set to improve the quality and usefulness, without causing the loss of any information. We have proposed an approach which removes hierarchical redundancy on top of removing non-hierarchical redundancy through the use of hierarchy/taxonomy. [1] R. Agrawal, T. Imielinski &amp; A. Swami,  X  X ining Association [2] J. Han &amp; Y. Fu,  X  X ining Multip le-Level Association Rules [3] T.-P. Hong, K.-Y. Lin &amp; B.-C. Chien,  X  X ining Fuzzy [4] M. Kaya &amp; R. Alhajj,  X  X ining multi-cross-level fuzzy [5] B. Liu, M. Hu &amp; W. Hsu,  X  X ulti-Level Organization and [6] N. Pasquier, R. Taouil, Y. Bastide, G. Stumme &amp; L. Lakhal, [7] G. Shaw, Y. Xu &amp; S. Geva,  X  X liminating Redundant [8] Y. Xu &amp; Y. Li,  X  X ining Non-Redundant Association Rules [9] Y. Xu, &amp; Y. Li,  X  X enerating Concise Association Rules X , in [10] Y. Xu, Y. Li &amp; G. Shaw,  X  X oncise Representations for [11] M. J. Zaki,  X  X ining Non-Re dundant Association Rules X , 
