 1. Introduction
The modeling of foreign accents remains difficult and inaccu-rate due to the large number of non-native accents and to the insufficiency of non-native speech data available for training.
Byrne et al. (1998) worked on the analysis of non-native English speakers by collecting a corpus of conversational English speech from non-native English speakers. They used a Hidden Markov
Model (HMM)-based speech recognition system. Their corpus contains both read and conversational speech recordings. They concluded that it is hard to recognize non-native English speakers compared to native ones, especially with regard to conversational type. Another study performed by Livescu (1999) focused on analyzing and modeling the non-native speech to improve the automatic speech recognition. She examined  X  among other tasks  X  the problem of non-native speech in a speaker independent, large-vocabulary, spontaneous speech recognition system for
American English with native training data. She showed that the interpolated native and non-native models reduce the word error rate on a non-native test set by 8.1% relative to a baseline recognizer using models trained on pooled native and non-native data. Bartkova and Jouvet proposed in Bartkova and Jouvet (2004) multiple models to improve the speech recognition system performance for non-native speakers. They considered French as the native language. In this latter research, the authors included
English, Spanish, Italian, Portuguese, Turkish, and Arabic non-native groups. In a previous work ( Alotaibi et al., 2008 ), we have investigated the effect of changing the native language for speak-ers in both the training and testing data sets. We analyzed the effects of these variations on the overall system accuracy and the individual phoneme accuracies. We studied some major differ-ences related to the phonetic confusion in order to determine the phonemes that play a significant role in the recognition perfor-mance between native and non-native speakers. The effect of the language model was also investigated.
 speakers, various speaker adaptation techniques can be used. The goal is to improve the recognition performance with small amount of non-native data available. The most straightforward approach consists of applying general speaker adaptation techniques such as the MLLR and the MAP to adjust the speaker-ind ependent (SI) acoustic models so 2003 ). Recently discriminative linear transform (DLT) have been widely employed to construct more accurate speaker adaptive speech recognition systems, where discriminative criteria such as maximum mutual information (MMI), minimum classification error (MCE), and minimum phone error (MPE) training are used for the parameter estimation ( Chen et al., 2008 ; Wang, 2006 ). In Wang and Woodland (2008) , the minimum phone error (MPE) criterion is adopted for DLT estimation. Uebel and Woodland (2001) performed an interpolation of ML and MMI training criteria to estimate the DLT. Povey et al. (2003) studied the incorporation of the MAP algorithm into MMI and MPE for task and gender adaptation.

In the present work, we propose an approach that aims at investigating more solutions while simplifying the foreign-accented speech adaptation process through the determination of a global transformation set of parameters that are optimized by Genetic Algorithms (GAs) using an MPE-based objective function.
The goal is to achieve better adaptation than conventional techniques whatever the amount of available adaptive data. The rest of this paper is organized as follows. Section 2 gives a background on the conventional adaptation approaches (MLLR and MAP). Section 3 introduces the MPE-based discriminative training approach for speaker adaptation. Section 4 describes the evolutionary-based paradigm that we introduce to perform non-native speaker adaptation. Section 5 describes the data and the experimental setup made to evaluate the proposed evolutionary-based (GA-MPE) algorithm for an unsupervised adaptation of foreign-accented speech. Section 6 concludes and indicates the perspective of this work. 2. Conventional approaches for speaker adaptation
The modeling of foreign accents remains difficult and inaccu-rate due to the large number of non-native accents and to the insufficiency of non-native speech data available for training. It is the reason why many studies propose to adapt native phoneme models to accented phoneme models using first language data. The widely used adaptation technique is MLLR ( Legetter and
Woodland, 1995 ; Mokbel, 2001 ). It is a parameter transformation technique that has proven successful while using a small amount of adaptation data. It computes a set of transformations that will reduce the mismatch between an initial model set and the adaptation data. MLLR is a model adaptation technique that estimates a set of linear transformations for the mean of Gaussian mixture HMM system. The effect of these transformations is to shift the component means in the initial system so that each state in the HMM is more likely to generate the adaptation data. The principle of mean transform in the MLLR scheme, assumes that
Gaussian mean vectors are updated by linear transformation. Let be the baseline mean vector and ^ m k the corresponding adapted mean vector for an HMM state k . The relation between these two vectors is given by: ^ m k  X  A k x k where A k is the d  X  d  X  1  X  trans-formation matrix and n k  X  X  1 , m k 1 , m k 2 , ... , m k d mean vector. It has been shown in Legetter and Woodland (1995) that maximizing the likelihood of an observation sequence o is equivalent to minimizing an auxiliary function Q given as follows: Q  X  where g k  X  t  X  is the probability of being in the state k at time t , given the observation sequence o t . C k is the covariance matrix which is supposed to be diagonal. The general form for computing optimal elements of A k is obtained by differentiating Q with respect to A k k  X  t  X  C 1 k o t x Depending on the amount of available adaptive data, a set of
Gaussians, and more generally, a number of states will share a transform, and will be referred to as regression class r . Then, for a particular transform case A k , Gaussian components will be tied together according to a regression class tree and the general form of (2) expands to
In standard MLLR, the column by column estimation of A k elements is given as follows: a  X  G 1 i z i ,  X  4  X  where z i refers to the i th column of the matrix which is produced by the left hand side of (3), and where G i is given by P P
In the proposed paradigm described in the next section, only one regression class is used.
 The system adaptation can also be accomplished using the Maximum a posteriori (MAP) technique ( Lee and Gauvain, 1993 ). For MAP adaptation, the re-estimation formula for Gaussian mean is a weighted sum of the prior mean with the maximum like-lihood mean estimate. It is formulated as ^ m where t km is the weighting parameter for the m th Gaussian component in the state k , and j t  X  k , m  X  is the occupation likelihood of the observed adaptation data o t . One of the drawbacks of MAP adaptation is that it requires more adaptation data to be effective compared to MLLR. 3. MPE-based discriminative linear transforms for speaker adaptation
Discriminative training algorithms, such as the maximum mutual information (MMI) training and the minimum phone error (MPE) training, have been successfully applied in large vocabulary speech recognition ( Woodland and Povey, 2002 ; Povey, 2004 ) and speaker adaptation tasks ( Wang and Woodland, 2004 ). The main characteristic of these algorithms is that they consider not only the correct transcription of the training utterance, but also the competing hypotheses that are obtained by performing the recognition step. For evaluation purposes a baseline system is constructed by performing the MPE training to improve the SD acoustic models obtained by the MLLR. This system is depicted by the block diagram given in Fig. 1 . The SI model is first adjusted by MLLR using limited speaker-specific data. Then, the adapted SD model is updated by a MPE-based discriminative training. The numerator lattice is obtained through the alignment process on the transcriptions of the adaptation data. The denominator lattice is approximated with the N-best phone hypotheses after performing the recogni-tion process on the adaptation data. In our approach, a MPE discriminative training is performed by using speaker-specific data. The method consists of using a weak-sense auxiliary func-tion in HMM to re-estimate the mean ~ m km of mixture component m of state k of a new adapted model. This re-estimation is done as follows: ~ m denominator sum of observation data weighted by the occupation probability for mixture m of state k ; D km is the Gaussian-specific smoothing constant; g num km and g den km are respectively the numerator occupation probabilities and the denominator occupation prob-abilities summed over time.
 4. Evolutionary linear transformation paradigm
Genetic Algorithms (GAs) have been successfully integrated in the framework of speaker adaptation of acoustic models ( Selouani and O X  X haughnessy, 2006 ; Selouani, 2011 ). One of the approaches consists of using the genetic algorithm to enrich the set of speaker-dependent systems employed by the EigenVoices ( Lauri et al., 2003 ). In this later work, the best results are obtained when the genetic algorithms are combined with the eigen decomposi-tion. Since the eigen decomposition provides the weights of  X  X  X igen-voices X  X  by using the Expectation X  X aximization (EM) algorithm ( Dempster et al., 1977 ), it can only find a local solution.
In the GA-MPE method we propose, the eigen decomposition is avoided and the MPE criterion is used as an objective function.
Note that the MPE-based training has proven to be very effective in the generalization from training to test data, compared with conventional maximum likelihood (ML) approach. Our motivation for an evolutionary-based discriminative transform is based on the fact that DLTs were initially developed to correctly discrimi-nate the recognition hypotheses for the best recognition results rather than just matching the model distributions.

In the proposed GA-MPE method, the A k matrix will contain weighting factors that represent the individuals in an evolution process. These individuals evolve through many generations in a pool where genetic operators such as mutation and crossover are performed ( Davis, 1991 ). Some of these individuals are selected to reproduce according to their performance. The individuals X  eva-luation is performed through the use of an objective function ( fitness ). The evolution process is terminated when no improve-ment of objective function is observed. When the fittest indivi-dual is obtained, that is the global optimized matrix A gen used in the test phase to adapt data of non-native speaker. Note that the problem of determining regression classes is not needed, since the optimization process is driven by a performance max-imization whatever the amount of available adaptive data. The
GA-based adaptation process is illustrated by Fig. 2 . For any GA, a chromosome representation is needed to describe each individual in the population. The representation scheme determines how the problem is structured in the GA and also determines the genetic operators that are used ( Davis, 1991 ). GA-MPE involves genes that are represented by the components of A gen matrix elements. 4.1. Population initialization initial population. This initial population is created by  X  X loning X  the elements of a global A matrix issued from a first and single
MLLR pass. This procedure consists of duplicating the a i constitute the initial pool with a predetermined number of individuals. Hence, the pool will contain a v i individuals where v refers to an individual in the pool and it varies from 1 to PopSize (population size). With this procedure, we expect to exploit the efficiency of GAs to explore the entire search space, and to avoid a local optimal solution. The useful representation of individuals involves genes or variables from an alphabet of floating point numbers with values within the variables X  lower and upper bounds, noted ( b 1 , b 2 ) respectively. 4.2. Objective function requires finding fittest individuals representing column vectors a v i A S , where S is the search space, so that a certain quality criterion is satisfied namely that objective function F : S maximized. a i gen is the solution that satisfies defined in such a way that the newly genetically optimized parameters are guaranteed to increase the phone accuracy of adaptation data. For this purpose, we used the minimum phone error (MPE) criterion known as a very efficient discriminative training procedure, utilizing phone lattices ( Selouani, 2011 ; Wang et al., 2003 ). The standard function reflecting the MPE criterion involves competing hypotheses represented as word lattices, in which phone boundaries are marked in each word to constrain the search during statistical estimation of an HMM model l . For a specific model, this function is defined as utterance u given observation O u , current model l and acoustic scale l . P q A s PhAcc  X  q  X  is a the sum of phone accuracy measure of all phone hypotheses. The objective function used in the GA-MPE to evaluate a given individual a v i , considers the overall phone accuracy and then it is defined as
F  X  a  X  X  the objective function is normalized to unity. Fig. 3 plots varia-tions of the best individual F  X  a i gen  X  with respect to the number of generations, in the case of totally random and first step MLLR initializations of population. 4.3. Selection function
Since the offspring population is larger than the parent population, a mechanism has to be implemented in order to determine the individuals that will conform to the new parent population. The selection mechanism chooses the fittest indivi-duals of the population and allows them to reproduce, while removing the remaining individuals. The selection of individuals to produce successive generations is based on the assignment of a probability of selection, P v to each individual, v , according to its fitness value. In the  X  X oulette wheel X  method ( Goldberg, 1989 ), the probability P v is calculated as follows:
P  X  where F  X  a k i  X  equals the value of objective function of individual k and PopSize is the population size in a given generation.
In the  X  X oulette wheel X  variant implemented in GA-MPE, we introduced a dose of an elitist selection by incorporating in the new pool, the top two parents of previous population to replace the two fitness-lowest offspring individuals. 4.4. Recombination
Recombination allows for the creation of new individuals based on previous generation. Many schemes of recombination exist and are being used in GAs ( Michalewicz, 1996 ). In GA-MPE method, heuristic crossover is chosen as a recombin ation operator. It generates a random number from a uniform distribution and does an exchange of the parents X  genes x and y belonging to a X i and a Y i ofcrossoverisjustifiedbythefactthatitistheonlyoperatorthat utilizes fitness information. The offspring is created using the follow-ing equation: x 0  X  x  X  U  X  0 ; 1  X  X  x y  X  , y 0  X  x ,  X  11  X  random variable of uniform distribution on the interval (0, 1). 4.5. Mutation
Mutation operators tend to make small random changes in an attempt to explore all regions of the solution space. Mutation consists of randomly selecting one gene x of an individual and slightly perturbing it. In GA-MPE, the non-uniform mutation is used. The principle of this mutation operator consists of randomly selecting one component, x k of an individual and setting it equal to a non-uniform random number, x 00 k  X  where the function f(Gen) is given by f  X  Gen  X  X  u 2 1 Gen Gen where u 1 , u 2 are uniform random numbers in the range (0, 1), t is a shape parameter, Gen is the current generation, Gen max maximum number of generations, and ( b 1 , b 2 ) are lower and upper bounds of each individual. The multi-non-uniform muta-tion generalizes the application of the non-uniform mutation operator to all the components of the parent x . 4.6. Termination
The evolution process is terminated when a number of max-imum generations is reached. This maximum number of genera-tions is obtained in such a way that it corresponds to the stabilization of objective function. In fact, no improvement of the objective function is observed beyond a certain number of generations. It is also important to note that as expected, the single class MLLR initialization yields rapid convergence, in contrast to the fully random initialization of the pool. When the fittest individual is obtained, it is used to produce a non-native speaker-specific system from the original HMM set. 5. Experiments and results 5.1. Data and baseline systems
The West Point Arabic Corpus provided by LDC (2002) is used in our experiments. It consists of collections of four main Arabic scripts. The first script (Script 1) contains 155 sentences uttered by 74 native Arabic speakers. Script 1 has a total of 1152 tokens and 724 types. The second script is composed of 40 sentences pronounced by 23 non-native speakers. Script 2 has a total of 150 tokens and 124 types. The Collection Script 3 contains 41 sentences uttered by four non-native speakers. It has a total of 138 tokens and 84 types. Finally, there is Collection Script 4 that contains 22 sentences pronounced by nine non-native speakers having three years of Arabic speaking. It has a total of 72 tokens and 59 types. Total number of distinct words is 1131 Arabic words. All scripts were MSA written and were diacritized.
The Hidden Markov Model Toolkit (HTK) ( Young et al., 2005 )is used throughout all experiments. The speech recognition system was designed initially as a phoneme level recognizer with three active states, continuous, left-to-right, no skip HMM models. The system was designed by considering all 37 MSA phones as given by LDC catalog. Context-dependent phoneme models are used to characterize transition information, which is very important for the discrimination of confusable speech units. Since most of words consisted of more than two phonemes, context-dependent triphone models were created from the monophone models mentioned above. The training phase consists of re-estimating
HMM models by using Baum X  X elch algorithm after aligning and tying the models by using the decision tree method ( Deng and O X  X haughnessy, 2003 ).

The acoustic parameters of the system are the following: 22.05 KHz sampling rate with 16 bit sample resolution, 25 ms
Hamming window duration with a step size of 10 ms, MFCC coefficients with 22 as the length of cepstral liftering, 26 as the number of filter-bank channels, 12 as the number of MFCC coefficients, and 0.95 as the pre-emphasis coefficients. 5.2. Genetic algorithm parameters
To control the run behavior of a genetic algorithm, a number of parameter values must be defined. The initial population is composed of 200 individuals and was created by duplicating the elements of global transform matrix obtained after the first and single regression class MLLR. The genetic algorithm was halted after 300 generations. The percentage of crossover rate and mutation rate are fixed respectively at 38% and 10%. The number of total runs was fixed at 60 per list. GA-MPE uses a global transform where all mixture components were tied to a single regression class. 5.3. Evaluation results of adaptation techniques
From the West Point corpus, we selected four different and disjointed lists; all have been chosen randomly from non-native
Arabic speakers only. The first list called AD100, contains 100 utterances; the second list called AD150, contains 150 utterances; the third list called AD200, contains 200 utterances; the last list called AD250, contains 250 utterances. The four lists are chosen randomly from all available scripts, speakers, and genders. The designed lists were used to adapt a native Arabic speaker based system to deal with non-native Arabic speakers. For this purpose, the three adaptation techniques were used: MAP, MLLR, and GA-
MPE. The performance is analyzed at the word level (by incorpor-ating a language model). Based on the above explanations, we refer to our experiments as AD100/MLLR, AD100/MAP, AD100/ GA-MPE, etc. All native Arabic speakers X  data provided by the LDC
West Point corpus was used for training the original recognition system. After that, all non-native Arabic speakers X  data provided by the same corpus was used for testing the system. As a result of that test, the accuracy (correctness) of the system was 89.46% for word level. This performance is relatively low compared to the correct word recognition rate 99.05% obtained by the same system involving testing data of native Arabic speakers ( Alotaibi et al., 2008 ). As it can be inferred from the results given in Table 1 , the improvement of system performance increases when the size of the adaptation list is increased. This performance is improved rapidly to reach its best at 97.84% which represents a 8.38% improvement (at word level) in comparison with the unadapted system. This result is obtained by the adaptation list AD250 and the GA-MPE adaptation technique (i.e., experiment AD250/GA-
MPE). We have tested the fully random initialization of popula-tion and the one using individuals cloned from MLLR global transformation matrix components. For both cases, as shown in
Fig. 3 , the final performance is the same. However, the adaptation is reached rapidly (180 generations) with MLLR-based initializa-tion. In the proposed algorithm the fittest individual within the pool and the best over the 60 runs is retained to perform the adaptation. Table 2 gives the statistical variation of the best individuals X  performance over the runs for each list of data used in the experiments. 6. Conclusion evolutionary-based MLLR technique (GA-MPE) to adapt speech uttered by Arabic non-native speakers. We also analyzed the performance of conventional MLLR and MAP adaptation techni-ques. Experiments show the effectiveness of GA-MPE compared to conventional approaches in rapid and unsupervised adaptation.
The accuracies of the unadapted system were 89.46% for word level accuracy. The best system accuracy improvement was 8.38% and this was obtained in experiment AD250/GA-MPE. Besides this, using GA-MPE avoids the regression class process. Investi-gating more solutions while simplifying the adaptation process through the use of only one global transformation set of geneti-cally optimized parameters, permits us to overcome the problem of huge memory and time consuming requirements such as in the conventional techniques. This work will be continued by investi-gating the best way to adapt the Arabic automatic speech recognition system to foreign accents by introducing the phonetic knowledge acquired from the common errors of non-native speakers.
 Acknowledgments
This work is supported by the King Saud University (KSU)  X  X  X PST X  X  Key Project No. 10-INF1325-02, Kingdom of Saudi Arabia and by the Natural Sciences and Engineering Research Council of Canada (NSERC).
 References
