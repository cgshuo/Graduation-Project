 Multi-document summarization has been a major concern in information processing due to multiple information overloads. Compared with single document summariza-tion, multi-document summarization faces two difficulties. One is that given multiple documents for one event or relevant events, the information in the documents tends to contents of the documents. Another difficulty is that the structural information of documents cannot be readily used in the same way as in single document cases. 
In general, the strategies for multi-document summarization fall in two categories, extraction-based and abstraction-based. An extraction-based strategy generally ranks sentences in some way and selects top-scoring sentences as summaries. An abstrac-tion-based strategy involves some understanding of the contents in the documents, e.g., concepts and relations, etc., and then creates the summaries based on some gen-eration techniques. 
Under the extraction-based strategy, the main method is to define a criterion based on some superficial features, e.g., key words in documents and positions of sentences and then rank the sentences according to the criterion. 
For the abstraction-based strategy, one main method is to produce some kind of semantic representation of the main contents in the documents, and then use some generation techniques to create summaries based on the semantic representation. One particular example is by information fusion [1], which tried to combine similar sentences across documents to create new sentences based on language generation technologies. Although this could model, to some extent, the human X  X  efforts in sum-resources, e.g., dependency parsers, interpretation or generation rules, etc., which would limit its portability. Another difficulty is that when generating similar sen-tences, it needs manual intervention to set similarity thresholds or number of the clus-ters; however, this is not generally known in advance. 
Another main method within this category is built on compression of sentences [6], in which longer sentences were converted to shorter ones based on parse tree trans-ducers by keeping the main constituents and cutting down others. One difficulty of involved. However, for languages other than English, such an effective full parsing system may be not available. Another problem is that the algorithm now focuses on sentence to sentence transductions, while for a multi-document summarization, a many to one sentence transducer is needed. 
In this paper, we propose a method for multi-document summarization based on unsupervised clustering. In detail, the main topics are first determined by a MDL-based clustering strategy with capabilities of inferring optimal cluster numbers. Then, the problem of multi-document summarization is formalized using an entropy-based object function. Although sentence extraction method is not the usual way humans create summaries for documents, we cannot deny the fact that some sentences in the documents do rep-increase on the Internet, speed will be a key factor for summarization. So, extraction-based summarization is still a promising candidate. 
To ensure good coverage and avoid redundancy, the main themes should be deter-mined in the multiple documents. To do that, some clustering methods have been pro-posed. Stein and Bagga et al. [11] grouped documents into clusters by clustering sin-gle document summaries, and then selected representative passages from each cluster to form a summary. Boros et al. [2] clustered sentences, with the cluster number pre-defined as 30, and the performance is not very good. Hardy et al. [4] selected repre-sentative passages from clusters of passages, and the system worked well in DUC 2001 with some parameter adjustments. Siddharthan et al. [10] clustered sentences with SimFinder [5] to generate summaries, in which a similarity threshold for clusters needed to be pre-specified, although the cluster number needed not. 
One common problem among these clustering methods is that they need to specify the number of the clusters or the similarity threshold in advance. However, this num-ber or threshold is not known before clustering in most cases. In this work, we try to use a MDL-based strategy [2] to automatically infer appropriate cluster numbers as well as members of the clusters. overall performance of the summary in representing the whole document set. In this work, we adopt the pair-wise entropy of clusters to model the overall representative-ness of a summary for a document set. In practice, we construct a vector for a candi-and compute the entropy of the new cluster group. The optimal summary is the one, which results in the highest entropy of the new cluster group. We employ a Gaussian mixture model algorithm with a MDL criterion to estimate the optimal cluster number and the member of each cluster. The MDL criterion is given by 1). number of the data points, M is the number of the dimensions, and L is given by 2). For each K , an EM algorithm can be used to seek the solution, which contains K clus-ters as well as their members. The algorithm will be terminated until the change of the criterion is below a threshold. By comparing the values of MDL among all K , we can get K * , which minimizes MDL . one representative sentence from each cluster, and they together form a summary. Let v the entropy for F( v 1 , v 2 , ..., v n ) is defined as (3). plus the summary, then the entropy for F( v 0 , v 1 , ..., v n ) is (4). of the perplexity when the summary vector is inserted. Intuitively, a good summary, if having better coverage, tends to make (5) higher. With the number of the representative sentences fixed (the same as the number of the clusters), the increase of the coverage on one hand means the decrease of the redun-dancy on the other hand. So, if a summary having higher entropy difference as in (5), and less redundancy at the same time. Formally, the multi-summarization problem can be defined as in the following. to seek a summary, whose vector v 0 maximizes (4) sentence at one time, unless the sentence is the only representative of one cluster, and each deletion maximizes the entropy of the remaining summary together with the n sentence clusters. The data is document sets of DUC2004 [8] Task 2 run by National Institute of Stan-dards and Technology (NIST). We chose ROUGE-1 as the evaluation measure for our results. Regarding the clustering configuration, we set the cluster number range as from 6 to 12, considering the size of the clusters. 
Table 1 gives the comparison between the performance with cluster validation (i.e., automatically determining appropriate cluster numbers) and that without cluster vali-dation (i.e., pre-specifying cluster numbers manually). 
From Table 1, we can see that the performance with cluster validation is consis-tently better than that without cluster validation. The reason may be that the appropri-cluster structure, which would affect the performance. 
To confirm the reason, we checked the separability of the generated clusters based on two views. One view is from discrimination between clusters in general. To do shows the change of the average pair-wise entropy, E ( CC ), which was normalized by the number of cluster pairs (| C | | C |) to ensure comparability. 
Another view is from discrimination of probabilities of one sentence belonging to clusters. To do so, we constructed a matrix S C , where S and C are sets of sentences cosine similarity between vectors of s and c . Fig. 1 also shows the change of the aver-number of the sentence-cluster pairs to ensure comparability. 
Fig.1 indicates that in both views, the normalized pair-wise entropy is minimized with cluster validation, which means that with the optimal cluster number automatically determined, a clearer cluster structure would be acquired. In such cases, more represen-tative sentences could be selected to form better summaries. 
In addition to Rouge scores for evaluation, we can use the similarity between the extracted sentences and the cluster-based topics to evaluate the coverage. On the other hand, we can use the similarity between the extracted sentences to evaluate the redun-dancy. In this section, we use these two measures to compare our methods with su-among all pre-specified) and MEAD X  X  ranking [9]. 
Regarding coverage, we took the highest similarity between sentences in a sum-mary and a topic as the similarity between the summary and the topic, and chose the change of the average summary-topic similarity applied to the generated summaries by the three methods, which shows that the unsupervised method acquired higher similarity between summaries and topics. 
Regarding redundancy, we chose representation entropy of a summary for evalua-formation embedded in the sentences. So, higher representation entropy corresponds to lower redundancy. 
We constructed a S S covariance matrix, where S is the set of the summary sen-malized eigenvalues: 
These normalized eigenvalues meet the properties of commonly used probabilities, shows the change of the representational entropy when applied to the generated sum-maries by the three methods. 
The comparison indicates that the summary generated by the unsupervised cluster-ing acquired the highest average representational entropy, which means the informa-tion is more widely distributed among the summary sentences. In this paper, we propose an approach for multi-document summarization based on unsupervised clustering. For sentence cl ustering, we adopt a MDL-based strategy with capabilities of inferring optimal cluster numbers automatically. For sentence se-lection, we formalize it as an optimization problem using an entropy-based criterion. 
As the first step for multi-document summarization, sentence clustering has an im-the noise. Together with automatic determination of optimal cluster numbers, feature selection would be a very interesting topic in future. 
For multi-document summarization, we can see it as an optimization problem: to select a subset of sentences that meets some constraints. With sentences being clus-tered, one constraint can be created for the optimization problem: one sentence to be extracted per cluster. In this work, we formalize the overall optimization problem based on pair-wise entropy. There may be other ways to formalize the problems ac-cording to different views about multi-document summarization, e.g., a view based on coverage of the main concepts in the documents. To compare the performance across different views could be another interesting topic in future. 
Another important future work is how to make the extracted summary more coher-focus and shift or anaphor co-reference would be future topics in this area. 
