
Instituto Tecnol X gico de Buenos Aires, Buenos Aires, Argentina Department of Computer and Decision Engineering (CoDE) CP 165/15, Universit X  Libre de Bruxelles, Bruxelles, Belgium 1. Introduction
The possibility of obtaining information of moving objects through the use of Global Position Sys-tems (GPS) or Radio Frequency IDentification (RFID) [30] has been consistently increasing since these devices became widely available. Moving objects (MO) [29,31,32] carrying location-aware devices pro-duce trajectory data in the form of a sample of ( O id ,t,x,y ) -tuples, that contain object identifier and time-space information. The analysis of these data can be of interest in many domains, like traffic anal-ysis, road planning, or location of advertisement in city streets, among other ones.

A typical problem in this field concerns the analysis of trajectory similarity, aggregation, and pattern discovery. Some approaches to these problems are based on the use of different data mining techniques, particularly sequential pattern mining. Due to the huge volume of these trajectory data, some form of compression facilitates data processing. For example, the notions of stops and moves [4,23,27] allow compressing trajectory data produced by moving objects using application-dependent places of inter-tion. For instance, in a tourist application, such places can be hotels, restaurants and tourist attractions. In a traffic control application, they may be road segments, traffic lights and junctions. If a moving object spends a sufficient amount of time in a place of interest, this place is considered a stop for the object X  X  trajectory. Between stops, the trajectory is considered to have moves . Thus, we can replace a raw trajec-tory given by ( O id ,t,x,y ) -tuples by a sequence of application-relevant stops and moves . The concepts of stops and moves are the basis for defining so-called semantic trajectories [14,27,34]. In a nutshell, a semantic trajectory is a trajectory obtained from replacing raw data with a sequence of stops, enriched with metadata of the places of interest corresponding to such stops. Hidden movement patterns in these kinds of trajectories can be discovered using different variations of existing data mining techniques, like the well-known Generalized Sequential Patterns (GSP) algorithm [3,28]. Also, some proposals allow expressing patterns intensionally by means of regular expressions [10,23] over the items that are being mined. These techniques can take advantage of semantic information about the places of interest.
Interesting trajectory patterns can be inferred if moving objects are integrated with other kinds of information, like spatial or multidimensional data. Spatial data are analyzed in practice using Geographic Information Systems (GIS) [26,33]. The NCGIA 1 defines a GIS as a system of hardware, software and procedures to facilitate the management, manipulation, analysis, modeling, representation and display of georeferenced data to solve complex problems regarding planning and management of resources. In general, information in a GIS application is represented in several so-called thematic layers or themes containing related data that deal with one thematic topic. For example, rivers, volcanoes and regions can be organized in different layers. Information in each layer consists of purely spatial data, associated with classical alpha-numeric attribute data. Usually, data are stored in a relational database. The spatial integration of these layers can be carried out by using a common coordinate system. 1.1. Paper contributions
Our first contribution is a language based on regular expressions over constraints, denoted RE-SPaM, that can intensionally express sequential patterns. Constraints are defined as conjunctions of equalities over metadata of the places of interest considered in a particular application. This language can express patterns of the form:  X  X ourists first visit cheap restaurants then visit tourist attractions repeatedly, and finish at 2-star hotels X . The language is defined over a formal data model which is extensively discussed in the paper. RE-SPaM can be used as a query language over a trajectory database, or as a constraint language that can be used to prune, during the data mining process, sequences that are not of interest to the user. This leads us to the second contribution of the paper, a data mining algorithm based on the well-known sequential pattern mining technique, where uninteresting sequences are pruned in advance making use of the automaton that accepts a RE-SPaM expression. The third contribution of this paper is an extension of RE-SPaM, denoted RE-SPaM + S , that allows defining patterns that include spatial data. This way, RE-SPaM + S can express patterns like  X  X rajectories that start at a 3-star hotel close to the Dijle river, and finish in a city w ithin the Limburg province X , where t he second and thi rd constraints contain geometric functions over spatial data. The proposal is completed with an experimental study of the variables that affect the performance of the data mining algorithm. 1.2. Paper organization
The remainder of the paper is organized as follows. Section 2 presents formal definitions of trajecto-ries and the notions of Place of Interest , Stops and Moves that we use throughout this paper. Trajectory compression is also addressed, and semantic trajectories and semantic equivalence of trajectories are defined. In Section 3 we present a query language for semantic trajectories, along with the data model that it supports. We denote this language RE-SPaM. RE-SPaM is based on regular expressions over constraints, defined as conjunctions of conditions over attributes of the trajectory stops. In Section 4 we present an algorithm for mining semantic trajectories, where RE-SPaM is used as a constraint lan-guage to reduce the number of sequences obtained. Section 5 describes RE-SPaM + S , an extension of RE-SPaM with spatial functions. Section 6 presents a case study and extensive experimental results. Finally, Section 7 discusses related work and compares such work with our proposal. We conclude in Section 8. 2. Preliminaries: Moving objects and semantic trajectories
Consider the following situation. Figure 1 (left) shows a simplified map of Belgium, containing two hotels, denoted Hotel 1 and Hotel 2 (H1 and H2 from here on), the Cathedral of Our Lady and the Eclair Bruxelles Sport Club. We consider three moving objects: O1, O2 and O3. Object O1 goes from H1 to the Cathedral, the Eclair, spends just a few minutes there, and returns to the hotel. Object O2 goes from H2 to the Cathedral, the Eclair (spending a couple of hours visiting each place), and returns to the hotel. Object O3 leaves H2 to the Eclair, visits the place, and returns to H2. Figure 1 (center) shows portion of a table containing the raw trajectories (i.e., expressed for each object as t, x, y -tuples). All points of the same trajectory are temporally ordered and stored together (i.e., the raw trajectories table is sorted by O id and t ). In what follows, we use the object identifier as the trajectory identifier, unless specified.
Many useful applications arise in this scenario. For instance, a GIS user may be interested in finding out trajectory information like  X  X umber of persons going from H1 to the Cathedral of Our Lady and then to the Eclair Sport Club (stopping to visit both places) in the same day X . An analyst may also want to discover hidden information using data mining techniques. For instance, she would like to identify interesting patterns in the trajectory data using association rule mining. She may also want to check if certain pattern holds, for example:  X  X eople visit two castles in the same day X . Let us first formally define the notion of trajectory.
 x time domain of the trajectory.

For the sake of finite representability, we assume that the time-space points ( t i ,x i ,y i ) have rational coordinates. We define a table denoted Moving Object Table (MOT), that stores a collection of spa-tiotemporal locations of MO. A MOT (see the table in the center of Fig. 1) contains a finite number of identified trajectories. 2 Definition 2. (Moving Object Table) Given a finite set T of trajectories, a Moving Object Table (MOT) for T is a relation with schema &lt; Oid, T, X, Y &gt; ,where Oid is the identifier of the moving object, T represents time instants, and X and Y represent the spatial coordinates of the objects. An instance M of the above schema contains a finite number of tuples of the form ( O id ,t,x,y ) , that represent the position ( x, y ) of the object O id at instant t for the trajectories in T . 2.1. Compressing trajectory data
In practice, the MOT can contain huge amounts of data. For instance, suppose that a GPS takes obser-vations of daily movements of one thousand people, every ten seconds, during one month. This gives a MOT of 1000  X  360  X  24  X  30 = 259,200,000 records. In this scenario, querying raw trajectory data may become extremely expensive. Sometimes we are not interested in such level of detail, but we look for more aggregated information instead. For example, we may want to know how many people go from a hotel to a sport club on weekdays. Or we can even want to perform data mining tasks like inferring trajectory patterns that are hidden in the MOT. These tasks require semantic information , not present in the MOT. As a solution, we propose to use the notion of stops and moves in order to obtain a more concise MOT, that can represent a trajectory in terms of places of interest for a particular application, characterized as stops . This table cannot replace the whole information provided by the MOT, but allows to quickly obtain information of interest without accessing the complete data set. We first define the no-tion of  X  X lace of Interest of an Application X  and then formalize the concept of stops and moves ,basing ourselves on the definition proposed by Alvarez et al. [4].
 Definition 3. (Place of Interest) A place of interest (PoI) C is a tuple ( R C ,  X  C ) ,where R C is a (topo-logically closed) polygon, polyline or point in R 2 and  X  C is a strictly positive real number. The set R C is called the geometry of C and  X  C is called its minimum duration . Given an application A , the places this application.
 trajectory. Also, P A = { C 1 =( R C 1 ,  X  C 1 ) , ..., C N =( R C N ,  X  C N ) } .
 y +1 ) , ..., ( t i + ,x i + ,y i + ) of T such that for some k  X  X  1 , ..., N } the following holds: (a) ( x
A move of T with respect to P A is: (a) a maximal contiguous subtrajectory of T in between two temporally consecutive stops of T ; (b) a maximal contiguous subtrajectory of T in between the starting point of T and the first stop of T ; (c) a maximal contiguous subtrajectory of T in between the last stop of T and ending point of T ; (d) the trajectory T itself, if T has no stops.

This definition of stops and moves of a trajectory can be modified in many ways, depending for in-stance, on the interpolation technique used on the trajectory samples, or in the tolerance used to consider whether an object is inside or outside a place of interest.

Now we are ready to describe how we go from MOTs to application-dependent compressed MOTs, identifier, g id is an identifier of the geometry of a place of interest and t s and t f are two instants that raw trajectories) by other table that represents the same trajectory more concisely by listing its stops and the time intervals spent in them. In this sense, the concise MOT, which we denote SM-MOT (standing for Stops and Moves-MOT), behaves like a summarized materialized view of the MOT. Also, note that the information about the moves remains implicit, because we know that between two stops there could only be a move. Moreover, if a trajectory passes through a PoI, but remains there an insufficient amount of time for considering the place a trajectory stop, the stop is not recorded in the SM-MOT. Definition 5. [ SM-MOT ] Let P A = { C 1 =( R C 1 ,  X  C 1 ) , ..., C N =( R C N ,  X  C N ) } be the PoIs of an application, and let M be a MOT. The SM -MOT M sm of M with respect to P A consists of the tuples ( (right) shows the SM -MOT for our running example.

Note that even though the SM-MOT could be computed algorithmically (see e.g. [13]), the definition of the relevant PoIs for an application, i.e., the set P A would require the intervention of an expert on the application domain. 2.2. Semantic trajectories of stops defined from the collection of PoIs. More formally: Definition 6. (Semantic Trajectory) A semantic trajectory is a trajectory (see Definition 1) with added metadata is an attribute representing a characteristic of s i and value is the value of such attribute for s . Moreover, S is time-ordered, that means, the s i  X  X  are listed in the order they were traversed by O id in T .

Basically, Definition 6 is implemented by the notion of SM-MOT defined above, plus a collection of metadata. In addition, it allows to define the notion of semantic equivalence of trajectory, a concept whose usefulness we will show in this paper. For now, let us consider the following example. We have a collection of PoIs corresponding to restaurants and banks. Assume that restaurants are characterized by their specialities, e.g., French and Italian food (these are the metadata mentioned in Definition 6). Figure 2 depicts a simplified view of those PoIs. Banks are represented by squares, Italian restaurants by grey circles and French restaurants by empty circles. There are also three compressed trajectories, let Trajectories t1 and t3 visit exactly the same sequence of PoIs. Trajectory t2 visits the same bank, then an Italian restaurant (different than the one visited by t1 and t3), the same French restaurant than t1 and t3, and finishes at a bank (again, not the same bank than in the other trajectories). Trajectories t1 and t3 present the same movement pattern (they visit exactly the same places), but t2 may appear to follow a different one. However, for many applications, we may consider all the Italian restaurants as equivalent with respect to the attribute type of food . Analogously, if we consider that all banks offer basically the same service (i.e., they belong to the same class of objects), we can say that t1, t2 and t3 are semantically equivalent .

Traditional approaches to trajectory mining consider that two trajectories are similar if they visit ex-actly the same places. For some applications, particularly when dealing with semantic trajectories, we can relax the notion of equality of places, replacing it by the notion of semantic equivalence of places . Intuitively, two places are semantically equivalent if both of them are characterized by the same value of some relevant/s attribute/s. In our example above, the two Italian restaurants were considered semanti-cally equivalent because they serve the same speciality. Other attributes could be considered, for instance their prices (expensive, cheap), the rule of accepting or not accepting pets, etc. Notice that the notion of equality of places implies the notion of equivalence of places , but the latter lets us detect behavioral patterns that may not be discovered using the comparison of places in a strict sense.
 assume that the stops in the trajectories belong to a set S . Also, consider that there is a set of k classes C = C 1 ,...,C T 1 and T 2 are Semantically Equivalent if  X  ( s 1 semantic trajectory maps to the same class. 3. RE-SPaM: A query language for semantic trajectories
Sequential pattern mining algorithms can be applied to semantic trajectories in order to obtain inter-esting information from a collection of trajectory samples. These algorithms are based on the apriori principle, first applied in the field of Association Rule Mining [2]. Apriori-based algorithms return all frequent sequences present in a database, although in general only a few ones are interesting from a user X  X  point of view. Thus, post-processing tasks are required in order to discard uninteresting sequences. In scenarios dealing with a large number of patterns this strategy could be tedious and costly. To avoid this drawback, languages based on regular expressions (REs) were proposed to restrict frequent sequences to the ones that satisfy user-specified constraints. Proposals like SPIRIT [9,10] are aimed at pruning unin-teresting sequences using regular expressions to express these constraints. However, in these proposals, REs are applied over items , limiting their applicability in complex real-world situations. In this section we present a more powerful language, based on regular expressions, denoted RE-SPaM (standing for Regular Expressions over Sequential Pattern Mining), where the basic elements are constraints defined over the (temporal and non-temporal) attributes of the items to be mined. Expressions in this language may include attributes, functions over attributes, and variables.

In the remainder of this section we will be using a tourist application in Belgium, where the items to be mined are sequences of stops composed of the identifiers of the PoIs visited by tourists, the time spent by each moving object at each stop , and the attributes of the PoIs. Each item can be classified as belonging to a category described by a set of attributes. In our example we have four categories: hotels, restaurants, castles and zoos, with different attributes and number of occurrences. In this scenario our ultimate goal is to discover frequent sequential pa tterns for moving objects (al though the approach could be used in any application domain), restricting these patterns to the ones that satisfy a set of constraints, specified by means of regular expressions over the attributes of the objects. These constraints are of the form  X  X rajectories that first visit cheap restaurants, then go to a 3-star hotel, and finish at the first restaurant X . 3.1. Data model
We first present the formal data model, and then the regular language supporting it. As usual in databases, we work with the notion of a schema and its associated instances .Wehaveasetofattribute names A , and a set of identifier names I . Each attribute attr  X  A is associated with a set of values in dom ( attr ) , and each identifier ID  X  I is associated with a set of values in dom ( ID ) . Definition 8. (Category Schema and Category Occurrence) A category schema Sisapair ( ID , A ) , where ID  X  I is a distinguished attribute denoted identifier ,and A = { attr | attr  X  A } . Without loss of generality, and for simplicity, in what follows we consider the set A ordered. Thus, S has the form (
ID , attr 1 , ..., attr n ) . Given a category schema S , a category occurrence for S is the pair ( ID,id , P ) , where ID is the have the same set of attributes; (d) ID is unique for a category occurrence.

In what follows, to simplify the presentation, we assume that attr 0 stands for ID . Thus, a category occurrence is the set of pairs [( attr 0 ,v 0 ) , ( attr 1 ,v 1 ) , ..., ( attr n ,v n )] . Definition 9. (Category Instance) A set of occurrences of the same category is denoted a category instance. Also, given a set of category instances (see Table 2), we extend the condition (d) in Definition 8 to hold for the whole set: ID is unique for a set of category instances, meaning that no two occurrences of categories in the set can have the same value for ID .
 Example 1. The schemas of the four categories in our running example are shown in Table 1. The corresponding set of category instances is shown in Table 2 (for example, the category hotels has two occurrences).

Adding a time interval to a category occurrence, produces an item . The time interval of an item is described by its initial and final instants, and denoted [ts, tf]. In the sequel, we decompose the temporal attributes ts and tf into date and time parts of the form ts_date, ts_time, tf_date and tf_time, respectively. This allows, for example, to talk easily about the different parts of the day, and an implementation can make use of the many features provided by DBMSs to handle temporal data types. Nevertheless, it must be clear that we can indistinctly use both forms of referring to temporal attributes. An itemset g =( i 1 ,i 2 , ...i same. The starting time and ending time values of g are denoted v ts (g) and v tf (g), respectively. Items are stored in a Table of Items (ToI), as the next example shows.
 Example 2. Table 3 shows an instance of a ToI corresponding to the category instances of Table 2. Note that the first two items for OID = O 2 have the same ID because they correspond to the same geom , we assume that pol 7 represents the geometric extension of Z. 3.2. Sequential expressions
We now present a language capable to express trajectory patterns. A simple language based on paths over constraints is the starting building block that we use to elaborate the concept of support of regular expressions .A constraint is a formula enclosed in squared brackets or the empty constraint, denoted as  X  []  X . If C is not an empty constraint we denote F ( C ) the formula of C. The syntax of a constraint (and of a formula) is depicted in Table 4. In short, this language expresses paths of constraints (denoted sequential expressions). We define the support of a path as the number of trajectories in a database that contain such path. Definition 10. (Sequential Expression) A sequential expression (SE) of length n is an ordered list of n sub-expressions c 1 .c 2 .c 3 ...c n , where each c i is a constraint,  X  i, i =1 ..n.
 Constraints can include functions over attributes. In our running example we use functions typical in On-Line Analytical Processing (OLAP) hierarchies, denoted rollup functions [6]. These functions have dimension _ k ,where attribute is the bottom level, a member of this level aggregates over a member of functions in queries Q5 and Q7 in Section 3.4. The semantics of sequential expressions is given in the definitions that follow.
 Definition 11. (Satisfability of a Constraint) Given a constraint C and an Item I, we say that I satisfies C if one of the following conditions hold:  X  if C is the empty constraint  X  []  X .  X  if F ( C ) has the form attr = @x where attr is an attribute in I, @ x isavariablein dom ( attr ) .  X  if F ( C ) is a formula of the form F 1  X F 2 , and F 1 and F 2 are satisfied.
 Example 3. The sequential expression SE =[] . [ price = X  cheap ] includes two constraints. The first one is the empty constraint, satisfied by all the items in an instance of a ToI. The second one expresses the equality condition. In our running example it is satisfied by the items with category occurrence identifier Z, R1 or R3.
 Definition 12. (Contiguous List) A sequence of consecutive, time-ordered, items in a ToI, associated to an object O j is denoted a Contiguous List associated to that object, and it is denoted CL ( O j ) .
Contiguous lists are used to check satisfability of SE. Intuitively, a contiguous list CL ( O j ) = g 1 , g , ..., g n satisfies an SE of length n if  X  j, j =1 ..n ,theitem g j satisfies the constraint c j in the SE. If the SE contains variables, there should be at least one instantiation of the variables that, together with the previous condition satisfies the SE (occurrences of the same variable in different constraints must have the same value when instantiated). Each item is composed of a temporal part and a category occurrence. Removing the temporal part, we obtain a list composed of only the parts corresponding to the category occurrence of these n items. We denote this list LCat( O j ,SE).
 Definition 13. (Matching of a Sequential Expression) Given a sequential expression SE and a ToI in-stance with tuples of the form O j ,i k , we say that an object O j matches SE if it contains at least one CL ( O j ) that satisfies SE.
 Example 4. For the SE of Example 3 and the ToI of Table 3, object O 1 matches SE, using the second and third items in Table 3, call them g 1 and g 2 , respectively. Also object O 2 matches SE, using the seventh and eight items in the mentioned table, call them g 3 and g 4 , respectively. We can see that both objects O 1 and O 2 match SE using different items, illustrating the idea of semantically equivalent trajectories previously introduced.
 We can now give a precise definition of the notion of Support of a sequential expression.
 Definition 14. (Support of a Sequential Expression) Given a sequential expression SE and a ToI instance with tuples of the form O j ,i k . The support of SE is the fraction of the different objects O j in the ToI that matches SE. We denote the support of SE as Supp ( SE ) and the set of objects that match SE as ObjMatches ( SE ) .

Given a set of category occurrences M, a sequential expression SE, a ToI instance T , and a param-eter minsup  X  [ 0, 1 ]  X  R (denoted minimum support) ,the frequent patterns in T restricted by SE, are defined as the sequences of category occurrences in LCat ( O j , SE ) ,  X  O j  X  ObjMatches ( SE ) , such that Supp ( SE ) minsup.
 Example 5. In Example 4 the support of the SE is 100%. Moreover, the sequences identified by IDs { BR 3 } and { ZZ } are discovered. As another example, the support of the SE =[ name =  X  X elfortCastle X  ] . [ typeOfFood =  X  X rench X   X  price =  X  X heap X  ] is 50%, and the sequence identified by IDs {
BR 1 } is discovered. 3.3. The RE-SPaM language
We now introduce RE-SPaM, a language based on r egular expressions (fro m now on, RE) where in-stead of atomic items (e.g., as in [10,28]), the atoms are constraints expressed as formulas over attributes of the complex items defined in Section 3.1. We formalize the language in the remainder of this section. Definition 15. (RE over constraints) A regular expression over constraints is an expression generated by the grammar where C is a constraint, and represents the empty expression. The meaning of each operator is shown in Table 5, amd the precedence is the usual one.
 Given a regular expression R we can build the Deterministic Finite Automaton (DFA) A R that accepts R constraints, the words accepted by A R are sequential expressions .
 Definition 16. (Matching of a RE) Consider a regular expression R generated by the grammar shown in Definition 15, the DFA A R that accepts R ,andW ( A R ) the set of words accepted by A R .Thereis also a ToI instance with tuples of the form O j ,i k . We say that O j matches RE, if there exists at least one contiguous list CL ( O j ) that matches awordw  X  W ( A R ) .WedenoteLCat( O j ,RE)theordered list obtained removing the temporal part from the items in CL ( O j ) that match the RE (i.e., the list containing only the category occurrences of the items in such contiguous list).
Now we extend the notion of Support of a Sequential Expression (Definition 14), defining the support of an RE.
 Definition 17. (Support of a RE) Given a regular expression R and a ToI instance with tuples of the form O j ,i k , the support of RE is the fraction of the different objects O j in the ToI, associated with a contiguous list CL ( O j ) that matches R . We denote Supp ( RE ) the support of RE, and ObjMatches ( RE ) the set of objects that math the RE.

Given a set of category occurrences M, a sequential expression SE, a ToI instance T , and minsup  X  [0,1]  X  R ,the frequent patterns in T restricted by RE are the sequences of category occurrences in LCat ( O j , RE ) ,  X  O j  X  ObjMatches ( RE ) , such that Supp ( RE ) minsup.
 Example 6. Consider the RE-SPaM expression:
Figure 3 shows the DFA A R that accepts the language generated by R . We want to check if the trajectory of object O 1 in Table 3 matches R . Consider the contiguous list CL ( O 1 ) composed of the third and fourth itemsets, denoted as g 1 and g 2 , respectively: g ( ID,R 3 ), ( categoryName, restaurant ), ( geom, pol 5 ), ( price, cheap ), ( typeOfFood, Italian )]) g ( ID,R 1 ), ( categoryName, restaurant ), ( geom, pol 3 ), ( price, cheap ), ( typeOfFood, French )]) The SE of length 2 accepted by A R is: junction composed of: (a) an equa lity condition between an attribute and a variable; (b) an equality between a function and a constant such as the instantiation of the attribute ts_date in the rollup func-tion with its value in i 2 yields  X  X 3 X ; (c) an equality condition between an attribute and a constant, and the instantiation of the attribute typeOfFood with its value in i 2 yields  X  X rench X , and coincides with the constant in c 2 . Also, the instatiantion @x = cheap satisfies c 2 . Then, we have found a contiguous list CL( O 1 ) that satisfies SE, and we can conclude that CL( O 1 ) matches SE . Summarizing, a contiguous list CL( O 1 ) composed by the items identified by R3 and R1 was found. Analogously, object O 2 matches SE by means of a contiguous list of length 2 composed of its second and third itemsets. In this case, a sequence composed by the items identified by Z and R1 is found.

Note that, even if the contiguous list { R 3 R 1 } and { ZR 1 } are not exactly the same, they can be considered semantically equivalent with respect to the attribute price , i.e., both of them are associated with a  X  X heap X  price. 3.4. RE-SPaM by example
Through a set of queries, we next give the intuition of what RE-SPaM can express and how it dif-fers from and substantially improves other proposals. Expressions can be built with attributes, functions, constants and variables. We now present different kinds of expressions supported by RE-SPaM, using our running example.
 Constraints without variables.

Q1:  X  X rajectories of tourists who visit hotel H1, then optionally stop at restaurant R3 and the Zoo, and end either at H1 or visiting the Belfort Castle X . [ID =  X  X 1 X  X .([ID =  X  X 3 X  X )  X  .([ID =  X  X  X  X )  X  .([ID =  X  X  X  X  | [ID =  X  X 1 X  X )
Note that Q1 uses only ID attributes in all its subexpressions. This example shows how supporting disjunction allows writing concise expressions. On the contrary, existing proposals force the user to enu-merate the IDs of the items to express disjunctions. In practice, when the number of items is large, this solution would not be applicable.
 Q2:  X  X rajectories that visit hotel H1, then, optionally visit different places, and finish at the Belfort Castle Tower or going back to H1 X . [ID =  X  X 1 X  X .[]  X  .([ID =  X  X  X  X  | [ID =  X  X 1 X  X )
The use of the empty constraint allows avoiding the enumeration of all the items. If an expression in-cludes an empty constraint, during evaluation it is instantiated with all the IDs of the category instances. Figure 4 shows the DFA that accepts the language generated by this expression.

Q3:  X  X rajectories of tourists who visit hotel H1 and then a cheap place or a place serving French food X . [ID =  X  X 1 X  X .([price =  X  X heap X  X  | [typeOfFood =  X  X rench X  X )
Q3 contains a subexpression with no ID. Places with cheap prices are R1, R3 and Z, and places that serve French food are R1 and R2. During evaluation, the items which satisfy these conditions are computed. Note that the expression is equivalent to [ID =  X  X 1 X  X .([ID =  X  X 1 X  X  | [ID =  X  X 3 X  X  | [ID =  X  X  X  X  | [ID =  X  X 2 X  X ).

Q4:  X  X rajectories that visited hotel H1 and then some cheap place, on 10/10/2007 X . [ID =  X  X 1 X  X .([ts_date =  X 10/10/2007 X   X  price =  X  X heap X  ])
Q4 contains a subexpression with a temporal attribute , which characterizes the occurrences of items in the database of sequences (i.e., the ToI).
Q5:  X  X rajectories that visit a cheap place during the third quarter of any year X . [rollup(ts_date,  X  X uarter X ,  X  X ime X ) =  X  X 3 X   X  price =  X  X heap X  X 
Q5 contains a rollup function over time. Like in the previous query, during evaluation, the items that satisfy the temporal constraint are computed accessing the ToI. The rollup function works as follows: when the expression is instantiated by a trajectory, the ts_date bottom level of the  X  X ime X  aggregation hierarchy will be assigned the time value of the trajectory stop, say t 1 .If t 1 corresponds to the third quarter of some year (i.e., t 1 aggregates over the element  X  X 3 X  in the aggregation level  X  X uarter X , the trajectory will match the sub-expression rollup(ts_date,  X  X uarter X ,  X  X ime X ) =  X  X 3 X .
 Constraints with variables.

Q6:  X  X rajectories that start at a place characterized by price (i.e., price is an attribute of the item representing this kind of place), then stop either at the zoo or the Belfort Castle, and end up going to a place that serves French food, and has the same price range as the initial stop X . [price = @x].([ID =  X  X  X  X  | [ID =  X  X  X  X ).[typeOfFood =  X  X rench X   X  price = @x]
Figure 5 shows the DFA that accepts the language generated by the expression. In our running exam-ple,  X  X heap X  and  X  X xpensive X  are the only possible values for prices; thus, the only valid combinations are: cheap-cheap and expensive-expensive. Sequences in objects of ToI such as {H1 Z R1} and {Z B R2} do not satisfy the query. The first one because hotel H1 is not characterized by price, the second one because Z has cheap prices but R2 is an expensive restaurant. The sequence {Z Z R1} satisfies the expression. In our implementation, variables are bound to items at execution time, as we explain later.
Q7:  X  X rajectories that stopped at two places (the second one having cheap prices), at the same part of the day (e.g., both of them during the morning) on October 10th, 2008 X . [rollup(ts_time,  X  X ange X ,  X  X ime X ) =@ z  X  ts_date =  X 10/10/2008 X  X . [rollup(ts_time,  X  X ange X ,  X  X ime X ) =@ z  X  ts_date =  X 10/10/2008 X   X  price =  X  X heap X  X 
Here, Q7 uses variables that the system binds during evaluation, to the result of applying a function over temporal attributes.

Although, in general, variables are used to express matching conditions between different subexpres-sions, they can also be used to constraint items according to their structure. We call these kinds of expressions metadata constraints .

Q8:  X  X rajectories that visited a place characterized by price X . [price = @Z]
The semantics here is: a sequence is in the result if it contains an item with an attribute price in it. As a more involved example, the constraint [price = @x] + is verified by sequences of one or more item (not necessary the same ones), all of them with the same price. In our example, Z, R1, R2 and R3 are the items that satisfy this constraint. 4. Mining semantic trajectories with RE-SPaM
We now discuss the use of RE-SPaM as both, a query language (like in the examples of Section 3), or as a Constraint Definition L anguage (CDL). We here discuss the la tter, showing how RE-SPaM is used to prune uninteresting sequences in a sequential pattern mining algorithm applied over semantic trajecto-ries. The sequential pattern algorithm we present here is based on the ideas of the Generalized Sequential Patterns algorithm (GSP) [28]. We denote this algorithm STPM, standing for Semantic Trajectory Pat-tern Mining. STPM extends GSP and its variations in many ways. Regular expressions in RE-SPaM can contain constants, attributes, and variables in a way that substantially expands the expressiveness of the constraints considered in previous proposals. We also allow functions over attributes. This implies not merely an extension of previous proposals, but introduces new theoretical and practical problems, providing a powerful language for sequential pattern mining, relevant to many real-world applications, particularly in MO scenarios. 4.1. The semantic trajectory pattern matching algorithm
We explained in Section 3.1 that the ToI is composed of itemsets where items are associated with an object identifier OID. In a MO setting, at every time instant each OID can be in exactly one place, meaning that itemsets are of length one . The STPM algorithm takes advantage of this fact, although it could be applied to itemsets of any length. We illustrate our presentation with the category instances depicted in Table 2. Temporal information associated with item occurrences is stored in the ToI (Table 3), which in our implementation is decomposed (i.e., normalized) as follows: we have a table with schema (OID, ts_date, ts_time, tf_date, tf_time, ID), where ID is the identifier of the corresponding category instance. All other attributes of the ToI are stored in a different structure and retrieved via the ID. This normalization does not reduce generality of the approach, but makes the presentation easier to understand. Table 6 shows the normalized ToI instance for our running example.

Typically, in GSP-based algorithms, frequent sequences of length k satisfying a user-specified mini-mum support are computed iteratively. At each intermediate step k , the following occurs: (1) A temporary set C k is built using the previous set C k  X  1 . Its elements are candidate sequences of length k . (2) Each element in C k which contains at least one sub-sequence with support less than the minimum is discarded due to anti-monotony property ( C k  X  1 is analyzed). (3) The database is accessed in order to analyze sup-port, and each element in C k with at least minimum support is added to the set F of frequent sequences. (4)Whenanempty C k set is obtained, F contains the frequent sequences with minimum support.
In the STPM algorithm, in phase (2) above, we use the DFA (denoted A R ) which accepts the language generated by the RE-SPaM expression R (an RE over constraints) to prune the SE that cannot satisfy R . Theideaofusing A R for pruning C k before querying the database has been first proposed in the SPIRIT algorithm [9]. There, instead of using the original constraint C, a relaxed constraint C X  (not necessarily anti-monotonic) is used. The sequences in C k that do not contain at least one subsequence which satisfies C X  are pruned. In what follows, we use a relaxed constraint C X  that accepts the sequences (denoted legal )  X  X cabd X , then the sequence  X  X ab X  will not be pruned because it is a substring of the second one, but the sequence  X  X bd X  will be pruned because it is not a substring of any of these words In phase (3) of our algorithm, C k is pruned using the ToI instance (see below), and added to a set F of frequent candidate sequences. In the last phase, F is analyzed to obtain the frequent sequences that satisfy C, i.e., a strict verification of the original C is carried out.
 Figure 6 sketches STPM algorithm.

Once the user defines the regular expression RE and the minimum support, the DFA automaton is built. The (relaxed) c onstraint C X  is also defined . The algorithm proceeds in inc remental steps until the final conditio n holds, which depends on the relaxation choi ce. Garofalakis et al. [9,10] proposed four variations of the algorithm, namely Na X ve , Legal , Valid WRT , Regular . For example, in the Legal algo-rithm (which we have used in the discussion above), the final state is reached when no legal sequences of length k with respect the start state of the automaton can be generated.

The main loop is the core of the algorithm. Line 8 corresponds to the generation of candidate se-quences. For example, in the Legal and Valid WRT algorithms this phase corresponds to the generation of C k using C k  X  1 . However, adopting the Valid variation would require using F and the automaton. Lines 10 X 11 analyze each of the candidate sequences c i  X  C k . The idea consists in detecting all the paths in the automaton, which in fact represent sequences of conditions satisfied by c i .Todothiswe need the information stored in the automaton and the category instances. If c i does not satisfy any path of length k , it is pruned. Lines 13 X 14 scan the ToI instance to compute support. If we are using early evaluation for the temporal attributes, here is where the ToI is used to validate temporal conditions. For each OID the algorithm calculates the c i  X  C k supported by consecutive sequences. Given that we are introducing semantic information into the mining process and we consider equivalent sequences to be interchangeable, we add all the sequences c i supported by at least one OID to the set F, and prune the ones not supported by any OID. While the support of the set F is equal or greater than the minimum, the algorithm continues. Finally (lines 21 X 22), the algorithm repeats the sequence of phases performed inside the loop, but using C instead of C X .
 Handling variables. The treatment of variables requires a detailed description. First, note that when building the set C k , only sub-paths of length k are considered. If the same variable is used in both extremes of a path of length k, sets C j with j&lt;k cannot be used to check if these variables coincide. Second, we need to choose the best strategy for variable instantiation when a variable appears only once in an expression. We thus study two possibilities which depend on the moment when the verification phase for non-temporal attributes takes place: early evaluation and late or postponed evaluation .In the former, the system determines if a sub-condition with no temporal attributes belonging to an edge of the automaton is verified by an item when building C k , and before querying the ToI instance. In the latter, the verification occurs when the algorithm enters its final phase, i.e., when it must prune the set F using the original (not relaxed) constraint C. Thus, verification is postponed until the final phase and constraints are not checked while building intermediate C k  X  X . Obviously, late or early evaluation only affects performance, not the final result. In the remainder we use early evaluation for conditions that involve non-temporal attributes and constants ,and late evaluation for conditions that involve non-temporal attributes and variables . Either using early or late evaluation, we need to bind a variable to a value. In RE-SPaM, there is no limit on the number of variables that can be defined. Thus, we use a hashing structure to store and check if a variable has already been bound. This structure is built for each one of the candidate sequences, i.e., the bindings cannot be shared between sequences.
 Example 7. For the query [ price =@ x ]+ , suppose we obtain a candidate sequence { R 1 R 2 } . Due to the item identified by R1, @x is stored in a hash table with its corresponding value ( X  X heap X ). Later, analyzing the price associated with the item R2, we obtain the value  X  X xpensive X , which does not match the previous one. Thus, the candidate sequence does not satisfy the expression.
 C X , is stored in main memory. In a step k , the algorithm finds out whether or not the conditions in the edges of paths of length k in A R are satisfied by the candidate sequences in C k . Here, note that the edges of the automaton are labeled with constraints , which is a relevant difference with existing approaches (where edges are labeled with IDs ).
 attributes that characterize the item identified by ID j . Note that our intention is to prune C k without accessing the ToI; thus, the only sources of information we can use are the automaton and the category instances (this table is also likely to be stored in main memory), and the only kinds of attributes that can be analyzed at this point are the ones in categories. The analysis of temporal attributes is postponed to a later stage. In summary, during this phase we only use the automaton and category instances to verify the sub-conditions that do not involve temporal attributes, and postpone the evaluation of the conditions over temporal attributes. Figure 7 depicts the three steps for computing C 1 . Note that A R prunes H1 and H2 in step2, because they do not match any of the edges of the automaton. Example 8. In query Q6, the sub-conditions to evaluate are four: price = @x, ID =  X  X  X , ID =  X  X  X  and typeOfFood =  X  X rench X . As none of them involves temporal attributes, all of them can be analyzed using A
However, in the case of query Q7, the sub-conditions are three: rollup ( ts_time,  X  X ange X ,  X  X ime dimension X  )=@ z , ts_date =  X 10/10/2008 X  and price =  X  X heap X . The only sub-condition that can be ana-Using the ToI. We use the ToI for pruning candidate sequences with support less than the minimum. As-sume we have computed C k , which now contains the candidate sequences that satisfy the subexpression of length k . We analyze Q6 to find out the sequences that satisfy the pattern with a support of 100%. At a first glance, in Table 6 there is one sequence generated from OID = O 1 which satisfies Q6: { R1, B, R1 } . With a similar analysis, there exists only one sequence generated from OID = O 2 satisfying the expression: { Z, Z, R1 } . Since we are interested in categorical mining, not just in counting strict occur-rences of items, we have to modify the way of counting support. Although none of the two transactions in Table 6 contains the same sequence, both satisfy Q6. Here, Z and R1 are semantically equivalent with respect to Q6 because both have a cheap price associated with them. This illustrates why the algorithm cannot discard a candidate sequence (although it has support less than the minimum), if it is supported by at least one transaction.
 final phase, i.e., the strict verification of the sequences in F.
 Using F. The final step of the algorithm uses all sequences in the temporary set F (which now may con-tain sequences of different lengths) and proceeds as follows. First, it uses the automaton to prune all sequences which are not accepted . Notice that here we are using the automaton for acceptance verifi-cation and not for legal verification. Also note that using the automaton to find sequential patterns with minimum support does not suffice, i.e., the ToI must be scanned. This scan has different goals: for ver-ification of the conditions that have been postponed (for example, expressions which involve variables or temporal constraints), and for calculation of minimum support. Until this phase we only know that the sequences in F are present in some transaction. Now, we have to check which sequences in the set F have enough support. In our example, OID = O 1 supports {R1 B R1} and OID = O 2 supports {Z Z R1}. Thus, all of these sequences verify the original expression, yielding a support of 100% . Figure 10 shows the set F before and after automaton verification, and set F after the ToI is scanned. As our expression does not involve temporal attributes, the ToI scan does not change the sequences in the set F. However, this scan is necessary to compute the support. 4.2. Complexity analysis
We now analyze the complexity of the STPM algorithm. Each step of the algorithm is composed of three phases. Each phase generates candidate sequences of the same length (i.e., at each step k, candidate sequences of length k are computed in three phases). The elements in C k (line 8, first phase) are computed using the sequences in the set C k  X  1 . We compute C k by means of a self-join between the sequences in C k  X  1 , and discard the ones such that their suffixes and prefixes of length k  X  2 do not match. For example, when joining the sequences  X  X BC X  and  X  X CD X , we generate  X  X BCD X  (the suffix and where | C k  X  1 | is the number of candidate sequences in C k  X  1 .

The second phase (see lines 10 X 11) consists in using C k and pruning it with the automaton generated from the constraints used in the query (i.e., the automaton is used to verify if a candidate sequence of IDs in C k satisfies some path of length k ). If |A R | is the number of states of the automaton, then, in the an expression in a path of length k in the automaton. Since |A R | is the number of nodes of the graph representing the automaton, the number of paths of length k could be at most |A R | ( k +1) , because the automaton accepts loops. Checking which sequences in set C k (generated in the previous phase) satisfy candidate C k are organized in a hash table, for the following phase.
 The last phase of step k consists in pruning using the ToI, thus, accessing the database (lines 13 X 14). A database scan must be performed in order to build contiguous lists (see Definition 12) of length k .Let us denote | Items | the number of items in the ToI. In the worst case, all these items belong to the same object and the number of consecutive lists (each one of these lists is composed of IDs.) of length k that are generated is given by | Items | X  k +1 . This is an upper bound. If these items were distributed among different objects (transactions) the number of lists would become considerably smaller. The candidate sequences in C k are organized in a hash table; thus, checking if a list of IDs belonging to the ToI matches a list of IDs in C k could be done in O (1). Depending on the query, this phase requires more than a simple matching between IDs in the list and IDs in some element in C k . For example, if a sequence in C k is  X  X BA X  and there is a list  X  X BA X  in the database, at first glance we may think that this sequence satisfies the query. However, let us consider the [ ts =@ x  X  price =  X  X heap X  ] . [ tf =@ x  X  food =  X  X talian X  ] . Although  X  X B X  is a candidate sequence in C2 (because A satisfies price =  X  X heap X  and B verifies food =  X  X talian X ), we must postpone the evaluation of ts and tf to the database scan stage. We cannot do this with the automaton because temporal attributes are not part of category occurrences. Thus, the database scan is not only for evaluating support. Then, in the worst case, this phase can be done in O ( | Items | X  k +1) . These three phases are performed repeatedly until no more candidate sequences are generated or the candidate sequences in C k are all pruned accessing the ToI, because there does not exist any useful list in the database of length k.

The last part of the algorithm (line 21) is analogous to the former ones, except for the first phase (generation of C k ). Phases two and three use all the candidate sequences not pruned in previous steps, to detect if they are recognized by the automaton and have the required support. 5. Extending RE-SPaM with spatial functions: RE-SPaM + S
We now show that RE-SPaM can be extended to support spatial functions to allow trajectory analysis that accounts for the geometric environment where the trajectories occur. We call the resulting language RE-SPaM + S (with the  X  X  X  stands for Spatial ). We also show that the overhead of this extension is negli-gible in terms of execution time of the algorithm, due to the caching techniques we explain below.
Let us consider the query pattern  X  X rajectories that start at a place characterized by price (i.e., a place and end up at a place that serves French food, has the same price range than the initial stop, and is close the Dijle river X . We assume (for completeness of this example) that  X  X ear X  implies that it is at 0.05 distance units in the coordinate reference system, and that the geometry of the Dijle river is expressed by the literal  X  X ULTILINESTRING ((4.714209 50.931933, 4.69394 50.974907)) X  (in this case, using PostGIS 4 syntax). We could write this query in RE-SPaM as follows:
The function near follows the RE-SPaM syntax, i.e., its first argument is an attribute (the geometry of the PoI) and the other ones are literals. Using RE-SPaM to express this query implies knowing in advance the string expression of a geometry. It would be more efficient and practical to use a spatial query language to obtain such information dynamically. This requires extending the language to be able to support sets. For this, we add a new kind of function that can iterate over the result set returned by a spatial query, and make this result set available at the moment the RE is evaluated. Below, we explain this in detail. 5.1. Functions in RE-SPaM + S
We extend RE-SPaM with a new kind of function, with two attributes: a variable for a cursor, and a geometry. The cursor is defined over a set of objects returned by a spatial query (technically, a set of lit-erals). This set is made available when the RE expression mentioning the function is evaluated. A WITH statement is added to the SELECT clause in the query language. This statement defines an alias over the cursor. In more detail, the first parameter of the function corresponds to an attribute of a category occurrence (for example, geom )ora temporal attribute (ts, tf, or their subparts). The second parameter is of the form a.b ,where b is the name of an attribute, and a is the name of a cursor defined in the WITH clause. The function returns a literal. We give the flavor of the language using our running example.
Q9:  X  X rajectories that stop at a place which belongs to a region that contains a river, and whose next stop is a zoo or a castle, finishing there. X  WITH TABLE regRiver(the_geom) AS SELECT DISTINCT (bel_regn.the_geom) FROM bel_regn, bel_river WHERE contains(bel_regn.the_geom, bel_river.the_geom); [ containedBy (geom, regRiver.the_geom)= X  X rue X  X . ([categoryName=Zoo X  X |[categoryName= X  X astle X  X ) The spatial part of the query (written in postGIS here, although any spatial query language could be used) returns a set of geometric objects (polylines) representing regions containing rivers, in the cursor regRiver(the_geom) . In the RE-SPaM part of the query (the lower one), the first constraint checks if the PoI is contained in one of the regions in the set. In other words, when an item in the ToI is being evaluated, the corresponding PoI geometry (represented by the attribute geom ) is compared against each one of the geometric elements in the cursor.

The syntax of RE-SPaM + S is shown in Table 7. In this table, SpatialQuery and RE-SPaMQuery denote the syntax of the spatial and RE-SPaM queries, respectively.
 Below we give some examples to illustrate the syntax and semantics of RE-SPaM + S .

Q10:  X  X rajectories that stop at a place with cheap prices and very close to a district located in a region crossed by a river, and finish at the Belfort Castle X . WITH TABLE district(the_geom) AS SELECT DISTINCT (bel_dist.the_geom) FROM bel_dist, bel_regn, bel_river WHERE intersects(bel_regn.the_geom, bel_river.the_geom) and contains(bel_regn.the_geom, bel_dist.the_geom); [price= X  X heap X   X  short _ distance (geom, district.the_geom)= X  X rue X  X . [name= X  X elfort Castle X  X 
This example shows how the spatial part of the query is used to link trajectory and spatial data. The spatial query returns districts (i.e., polygons) in a map. At evaluation time, each geometry of the PoI where a trajectory stops is compared with the geometry of each district in the cursor, to check if the PoI being visited is close to it (we are not interested here in how the function short _ distance is actually implemented).

Q11:  X  X rajectories that visit a place offering cheap prices and stop at the zoo (finishing there), such that both stops are either located in regions crossed by a river (although not necessarily the same region), or in regions not crossed by rivers X .
 WITH TABLE regCrByRiver(the_geom) AS SELECT GIS DISTINCT (bel_regn.the_geom) FROM bel_regn, bel_river WHERE intersects(bel_regn.the_geom, bel_river.the_geom); [price= X  X heap X   X  containedBy (geom,regCrByRiver.the_geom)= @ x ]. [ containedBy (geom, regCrByRiver.the_geom)= @ x  X  categoryName= X  X oo X  X .
 The variable @ x is of boolean type. At evaluation time it is bound to  X  X rue X  or  X  X alse X , and the two constraints are instantiated with this value. In this example, the two constraints in the RE-SPaM + S ex-pression include the spatial function containedBy . 5.2. Implementation
We now analyze the implementation of the mining algorithm, and show the consequences of adding spatial objects support to RE-SPaM. Strictly speaking, no changes are needed to be introduced to the mining algorithm presented in Section 4. However, since the mining algorithm proceeds in incremental steps, and in each one of them a portion of the candidate sequence is evaluated to decide if it satisfies some constraint labeling the edges of the automaton, we must guarantee that the new expressions intro-duced in RE-SPaM + S can be efficiently evaluated. To accomplish this objective we borrow ideas from dynamic programming techniques, where once a function is evaluated with some parameters its result is stored in a cache avoiding recalculation. We take advantage of two types of caching which we de-note macro and micro-cache , respectively. The former stores the result of a function of type fn (  X  value  X , tableName.attribute ) (that is, functions returning sets). The latter stores the result of a function of the form fn (  X  value  X ,  X  literal  X , ...). We explain the former ideas helping ourselves with an example.
Consider query Q9, and the category occurrences in Table 2. The spatial part returns regions in the cursor denoted regRiver.the_geom. To clarify the example, we must first give some geographic information about Belgium. There are three regions: Vlaams Gewest in the north, Brussel-Hoofdstad (the small region within the former one) and the Wallonne (in the southern part of the country). The three regions are shown in Fig. 11. Brussel-Hoofdstad is crossed by the Kanaal van Charleroi river, but this river is not contained by the region. Vlaams Gewest contains the Ieperlee river and the Wallonne region contains the Ourthe Occle river. Thus, both regions are in the cursor after the spatial query is evaluated. For clarity, in Fig. 11 the names of the rivers were omitted, but we can see that the large northern and southern regions contain rivers, while the small region is crossed by a river.
The algorithm starts by building C 1 with all the category occurrences. Then, it uses the automaton for pruning: if a candidate sequence does not satisfy any path in the automaton, it is pruned. We can see three paths of length 1 in the automaton (see Fig. 12).
The constraint [categoryName =  X  X oo X  X  is satisfied by the zoo occurrence in Table 2, while [categoryName= X  X astle X  X  is satisfied by the Belford Castle (denoted B); further, the constraint [ containedBy (geom, regRiver.the_geom)= X  X rue X  X  must be evaluated for the category oc-currences of hotels and restaurants, to check which PoIs are in regions crossed by rivers (returned by the spatialpartoftheRE-SPaM + S expression). Given that the constraint contains a function, the cache is used for this evaluation. The engine first looks up in the macro-cache (implemented as a hash table) for the value associated with the key containedBy (  X  pol 1  X , regRiver.the _ geom ) . No value is retrieved in this case, and the function starts browsing the cursor. The first tuple in the cursor is  X  V laams Gewest  X  . Instead of evaluating the function, the micro-cache is now queried for the value associated with the key containedBy (  X  pol 1  X ,  X  V laams Gewest  X  ) . We can see in Fig. 11 that the geometry of Hotel H1 (i.e.,  X  pol 1  X ) is contained in the Vlaams Gewest region. Then, the association between containedBy (  X  pol 1  X ,  X  V laams Gewest  X  ) and  X  X rue X  is stored in the micro-cache . Since the value returned by the function is  X  X rue X  there is no need to continue browsing the cursor. Moreover, the macro-cache is also updated , asso-ciating the key containedBy (  X  pol 1  X , regRiver.the _ geom ) with the value  X  X rue X  (see below how this is used in the next step). Next, we evaluate containedBy (  X  pol 2  X , regRiver.the _ geom ) . Again, nothing is retrieved from the macro-cache , therefore we must browse the cursor. The engine looks up in the micro-cache for a value associated with containedBy (  X  pol 2  X ,  X  V laams Gewest  X  ) . Since nothing is retrieved, the function must be evaluated, returning the value  X  X alse X , and this association is stored in the micro-cache . Similarly, the micro and macro-cache are updated with the associations containedBy (  X  pol 2  X ,  X  Wallonne  X  ) and  X  X alse X , and containedBy (  X  pol 2  X , regRiver .the_geom) and  X  X alse X , respectively. Fi-nally, the candidate sequence H2 is discarded since it does not satisfy any path of length 1 in the au-tomaton.

Analogously, the system finds out whether or not  X  X ol3 X ,  X  X ol4 X  and  X  X ol5 X  are contained in some tuple of the cursor regRiver.the_geom by taking advantage of the macro and micro cache . Figure 13 shows against the ToI to check for minimum support. For the second step, let us suppose that all candidate sequences of C 1 are maintained (i.e., all candidates will be checked for minimum support). Thus, the system populates the set C 2 in the second step by joining C 1 with itself. Similarly to the first step, using the automaton the engine determines which candidate sequences of length 2 satisfy some path of length 2. Many candidate sequences are discarded here, for instance, those combinations which do not end at zoos or castles. Again, it becomes important to optimize the evaluation of functions. For this, we use now the macro-cache . When deciding if the candidate sequence of length 2 { H 1 Z } is accepted by some path of length 2 in the automaton, the function containedBy (  X  pol 1  X  ,regRiver.the _ geom ) must be evaluated. But now, this key and its associated value can be obtained from the macro-cache ,sincethe value was calculated in the previous step and the cache was updated accordingly. The process continues until a step k such that no sequences of length k exist in the ToI. In Fig. 14 we show the state of C 2 before and after pruning.

Note that taking advantage of the cache strategy, spatial queries are evaluated only once, i.e. during the first step of the mining process; the subsequent evaluations of the same function (with the same parameters) reduce to a lookup in the macro o micro-cache . Thus, the overhead is introduced only at the beginning of the process. 6. Case study
We now present a complete case study based on a collection of maps of Belgium and a set of trajec-tories obtained through a simulation process. We discuss the data preparation and run different experi-ments, reporting and analyzing the results. 6.1. Data preparation
We start by describing the characteristics of the datasets we used in our experiments, and the prepara-tion process. 6.1.1. GIS data
We used geographical information of Belgium, obtained through the GIS Center over the web. 5 This information is composed of map layers for rivers, cities, districts, provinces and regions. Cities are rep-resented by points, rivers as polylines and the other layers as polygons. Therefore, we have a spatial aggregation hierarchy, conformed by cities, districts, provinces and regions. Additional information in-cludes for example, population and number of agricultural employees for provinces, or number of olives cultivated per hectare (for regions). The number of tuples in the tables corresponding to rivers, cities, districts, provinces and regions are 39, 583, 43, 9 and 3, respectively. 6.1.2. Trajectory data RE-SPaM + S works over semantic trajectories, which we implemented as an SM-MOT. Preparing the SM-MOT from raw data requires some data pre-processing that we explain next.
 Real vs. synthetic trajectories. We first analyzed the convenience of working with real-world or synthetic trajectories. Real-world trajectories are difficult to acquire due to privacy issues. It is a well-known fact that it is not enough to encode the identity of MOs to protect privacy. Depending on the number of trajec-tories in a pattern the identity could be disclosed. Thus, most MO trajectories are not publicly available. There are exceptions, however: some research projects have published real-world raw trajectories.
We decided to work with simulated data in order to obtain a wide spectrum of trajectories, and use real-world spatial data. Thus, trajectories were simulated to move on the actual Belgium road network. We worked with the Network-based Generator of Moving Objects , 6 which, by using the information of a network in a proprietary graph format, generates samples of raw trajectories. The simulator uses parameters such as maximum speed of MO, maximum capacity of connections, external objects that affect the movement of an object, influence of external objects, and interval time between samples. We simulated movement of different kinds of MO, like pedestrians, cars, bikes. 7 Preparing and running the simulator. We obtained a graph with the Belgium road network from the MapCruzin.com website 8 and transformed this format into the one supported by the Network-based Generator. The process generated a network with 756,498 nodes and 1,542,051 edges. (The network is a digraph, i.e., some of the roads are double-way).

Several parameters of the simulator can be configured. We used the road network, the maximum time duration, the number of initial MOs, the maximum number of MOs generated at each instant, the maximal range of speed of the MOs (e.g., low, medium, high), and the name of the file that stores the  X  X oint X  and  X  X isappearpoint X  for indicating that this row corresponds to a new, existing or disappearing point (MO); (b) a point ID (i.e., a MO identifier); (c) a sequence number for an specific point ID; (d) the type of the MO (for instance, pedestrian, cyclist, motor cyclist, car); (e) the x,y coordinates; (f) an integer that represents a time instant; and (g) the speed. The information is ordered by time in ascending order, i.e., the information of MOs is interleaved.

We ran the generator several times and processed all the simulated trajectories that belonged to the same file as if they had been generated on the same day. In all these experiments we used a maximum simulation time duration between 400 and 1200 iterations (we then transformed these iterations in actual time intervals). Different speeds were used. We generated two raw trajectory databases, namely RTD1 and RTD2. The former contains 2,204 raw trajectories and the minimum, average and maximum lengths of those trajectories were 1,157, and 1,593, respectively. The latter contains 13,406 ones and the mini-mum, average and maximum lengths of those trajectories were 1, 43, and 763, respectively. That means, the longest simulated raw trajectory consists in 763 reported positions (each taken aproximately every 30 seconds).
As an example, Fig. 15 depicts a raw trajectory generated by the simulator. The trajectory starts at the bottom-center of the figure and follows the northwest direction. When it arrives at the top, it takes the same (double-way) road, and follows the south-east direction (bottom-right). 6.1.3. Preparing the places of interest
Information about PoIs in Belgium was obtained from the PoI Plaza website. 9 We grouped these data in six different categories: stores (supermarkets and department stores), sport clubs (basketball, football, golf and tennis clubs), gastronomy (pubs and restaurants), banks, hotels, tourist attractions (abbeys and castles). The dataset contains a total of 1,230 PoIs. Table 8 gives the totals per category. The file format was Google Earth X  X  KML, 10 and we converted them to ESRI Shapefile format 11 before populating a PostgreSQL database.

The attributes related to each category instance were obtained from these files. In order to make the experiments even more comprehensive, we added other information: price (for gastronomy, sport clubs inferred or generated randomly. For example, in the case of  X  X rice X  for sports clubs, we proceeded as follows: golf and tennis were considered expensive, and basketball and football, cheap. We show the category schema for the case study in Table 9.
Finally, we generated the SM-MOT from the MOT. Since the simulator generates continuous move-ment, but cannot simulate a stop in the trajectory, again, some additional data pre-processing was needed to simulate these stops. Table 10 shows the maximum and minimum stop durations for each category.
Using these times, trajectory stops were randomly generated. For this, we used two sets of PoIs, one of size 800, and another one of size 1,200. The MOTs containing the raw trajectories RTD1 and RTD2 were compressed using these two sets of PoIs. More precisely, compressing RTD1 with 800 and 1,230 PoIs yielded two SM-MOTs of 2,581 tuples and 4,484 tuples. Repeating the procedure we generated another two SM-MOT datasets by compressing RTD2 with 800 and 1,230 PoIs, yielding two SM-MOTs of 4,060 tuples and 7,183 tuples. In the sequel we will refer to them as DB1, DB2, DB3 and DB4, respectively. We will work with these four databases, representing four different sets of semantic trajectories. 6.2. Experiments
We ran our tests on an Intel Core i5 CPU, at a clock speed of 2.6 GHz, equipped with 4GB RAM and running over Windows 7 Operating System. All the data (PoI and ToI) was stored in PostgreSQL 8.2.3 database. The application framework was developed as a java plug-in for OpenJump. Algorithms have been implemented in Java 1.6.

Many factors could affect the execution time of the STPM algorithm. To name a few: the number of trajectories to be mined, the minimum support, the length of the query, the kind of spatial query (in the case of and RE-SPaM + S query), the number of intermediate steps, the number of PoIs, the attributes that these PoIs share. It is not trivial to isolate one of them while keeping the other ones fixed. We devised different experiments to get an insight of the algorithm, and compare the theoretical complexity computation presented in Section 4.2 against real-world implementation results. That means, we are not aimed at measuring execution time, but to assess the impact of different variables over such time. We remark than in our RE-SPaM + S implementation the minimum support works as a threshold. Implementing the concept of semantic equivalence , we defined the support of a RE rather than the support of a SE, i.e., if the RE has enough support all the sequences which satisfy this support will be retrieved, even if the sequences, individually, do not reach such support. Thus, given a minimum support, we would obtain a collection of sequences, or no sequence at all, making it irrelevant to vary the minimum support value in the experiments. That is the reason why during all of our experiments we chose 0.01 as our value for the minimum support. 6.2.1. Goal 1. Effectiveness of the pruning by automaton
Since RE-SPaM + S uses an automaton for pruning candidate sequences before scanning the ToI. Our first goal is to assess the impact of this pruning phase.
 Experiment 1.1. We formulated several queries using the legal algorithm variation and computed, at each step, the number of candidate sequences generated in phases 0 and 1, i.e., before and after the use of the automaton. We used the following queries, and show first the number of frequent sequences of different lengths returned by them (Table 11).
 Q1: [ categoryName =  X  X astronomy X  ] . [ price =  X  X heap X   X  game =  X  X asket X  ] Q2: [ speciality =  X  X eer X  ] . [ game =  X  X asket X  ] Q3: [ categoryName =  X  X astronomy X  ] . [ game =  X  X asket X  ] + Q4: [ categoryName =  X  X astronomy X  ] . [ game =  X  X asket X  ] + . [ star =  X 3 X  ] Depending on the dataset used, we obtained different numbers of frequent sequences for queries Q1, Q2, Q3 and Q4. Execution times for these queries were also measures. From these two variables, we can infer that execution time is not related to the number of sequences obtained. For example, for dataset DB1 the performance of Q4 is two times slower than Q1 although the former does not return any se-quence. Analogously, for dataset DB4, the performance of Q3 is faster than Q4, but the former produces 18 frequent sequences. These results also suggest that execution time is not the best indicator of the effectiveness of the pruning.

In fact, performance is associated with the number of intermediate steps that the mining process uses to generate the frequent sequences and with the number of candidate sequences that the algorithm generates at each step. We remark that the third phase of step k scans the ToI (i.e., requiring accessing the disk) for building contiguous lists and compares the sequences there with the candidate sequences in C k . Thus, if the number of candidate sequences in C k could be reduced, the total execution time would be lower. Table 12 shows for each dataset and each query, the number of candidate sequences generated during Phase 0 (before using the automaton) and during Phase 1 (after the use of the automaton), i.e., the size of C k in each phase (for each intermediate step). As a measure of the automaton effectiveness, we show in the last column the percentage of reduction of the size of each set C k . The use of the automaton substantially reduces the number of candidate sequences in intermediate steps, which is relevant since this steps precede the scanning of the ToI. For example, we show that query Q2 does not produce any frequent candidate sequences for dataset DB3: the automaton has pruned all the 3364 candidate sequences in the second step such that no database scanning was needed in this step and the algorithm moves to its final phase. 6.2.2. Goal 2. Impact of the presence of variables
One of the novel features of RE-SPaM consists in the support of variables. Thus, our second goal is to estimate the impact of variables in the queries over the algorithm X  X  performance.
 Experiment 2.1. In Section 4 we mentioned that there are at least four possibilities for implementing the mining algorithm. These possibilities combine algorithm variations and the moment when variables are bound to values and are called: legal-early, legal-late, valid-early and valid-late. The early bindings are aimed at discarding as soon as possible the candidate sequences that do not satisfy the matching condition. The late binding option postpones the evaluation of variables until the final phase of the algorithm. For our tests, we propose four queries containing a variable and a matching condition, such that in query Q i the distance between the conditions is larger that in query Q i +1 . This allows to measure the effect of the distance between the variables in the performance of STPM. The queries were: Q5: [price=@x].[price=@x] Q6: [price=@x].[subtype= X  X astle X  X .[price=@x] Q7: [price=@x].[subtype= X  X astle X  X .[].[price=@x] Q8: [price=@x].[subtype= X  X astle X  X .[].[]+.[price=@x]
Note that conditions are checked many times during query evaluation. The STPM algorithm does not only answer if a query satisfies a RE, but also computes all the sequential lists of items within each trajectory that satisfy a RE, i.e., it returns all the sequences that satisfy a certain pattern. Thus, the performance of the four algorithm variations is affected by the lengths of the trajectories. In our experiments we ran the queries over each one of the DB1, DB2, DB3 and DB4 datasets, and the lengths of the trajectories range from 1 to 27 (that means, the largest trajectory in the MO database contains 27 stops), 1 to 43, 1 to 15, 1 to 24, respectively. Therefore, our tests consider the influence of the lengths of the semantic trajectories in the datasets.

In Fig. 16 we report the results of running the four algorithm combinations: early and late variable evaluation, using the legal and valid approaches. In almost all the cases the legal approach outperformed the valid approach (for both variations, late and early binding): only Query Q7 over DB3 ran better using valid algorithm.

Note that Query Q8 captures the case of a variable length query: it asks for places with same prices separated by at least by a castle and at least any two additional PoIs). Therefore, the patterns obtained can be of any length. In the DB4 dataset the available RAM was exceeded and Query Q8 did not end (a  X  X eap size error X  was returned). For the same query, in DB2 (smaller than BD4) only the legal variation ended successfully. The conclusion here is that in variable length queries, the legal approach consumes less RAM than the valid one.

As a conclusion, since executions with the valid approach were extremely bad with respect to the legal one, we discarded the use of the former for the rest of the experiments.
 Experiment 2.2. The number of different values that a variable can take could affect its performance (re-call that an equality condition over attributes other th an IDs is equivalent to a disjunction over the IDs). The queries we used contain two equality conditions over a variable, at distance  X 1 X  from each other in the pattern (e.g., [star=@x].[star=@x] ). In addition, Queries Q14 through Q20 include disjunc-tions. Therefore, we covered a wide range of cases. We used the algorithm with the legal-late evaluation alternative, to analyze to what extent the number of different occurrences (i.e., possible values) for the attributes that appear in the ToI affects algorithm X  X  performance. We grouped the queries according to these values as follows. The number of different occurrences (denoted #PV) for the attributes used in the queries are: (a) 6 for categoryName ( X  X ank X ,  X  X astronomy X ,  X  X otel X ,  X  X portclub X ,  X  X tar X ,  X  X ourist attrac-tion X ); (b) 3 for price ( X  X ree X ,  X  X heap X , and  X  X xpensive X ); (c) 3 for star ( X 3 X ,  X 4 X ,  X 5 X ); (d) 2 for subtype ( X  X bbey X ,  X  X astle X ) in all the datasets DB1 though DB4. In the case of the game attribute we had #PV = 2 in DB1 ( X  X asket X ,  X  X ootball X ), and 4 in the other databases ( X  X asket X ,  X  X ootball X ,  X  X olf X ,  X  X ennis X ). The queries were chosen to cover cases with variables where the #PV ranges from 2 to 10. We next list such queries.
 Q09: [categoryName=@x].[categoryName=@x] Q10: [star=@x].[star=@x] Q11: [price=@x].[price=@x] Q12: [game=@x].[game=@x] Q13: [subtype=@x].[subtype=@x] Q14: ([price=@x] | [star=@x]).([price=@x] | [star=@x]) Q15: ([game=@x] | [star=@x]).([game=@x] | [star=@x]) Q16: ([game=@x] | [price=@x]).([game=@x] | [price=@x]) Q17: ([categoryName=@x] | [subtype=@x]).([categoryName=@x] | [subtype=@x]) Q18: ([categoryName=@x] | [price=@x]). ([categoryName=@x] | [price=@x]) Q19: ([categoryName=@x] | [star=@x]). ([categoryName=@x] | [star=@x]) Q20: ([categoryName=@x] | [game=@x]). ([categoryName=@x] | [game=@x])
For displaying the results we formed groups of queries with the same #PV, for each dataset. For example, in the DB1 dataset, queries Q12 and Q13 both have been grouped together since #PV is 2 for game and subtype, and the execution times have been averaged. Thus, in Fig. 17, for DB1, the execution time for the point with #PV = 2 corresponds to the average of the execution times for both queries. In the other datasets Q12 and Q13 have been kept separately. Analogously, in all datasets Q9 and Q14 have been grouped together since #PV is 6 in both of them. This is why in Fig. 17 (which reports the complete results of the tests), we have 8 points in spite of covering 12 queries.

From the experiments, although we cannot draw definitive conclusions, we can see that there exists a relation between #PV and execution time, although the kind of correlation appears to differ according to the dataset. In all datasets, queries involving variables with #PV = 7 showed better performance than queries with #PV = 6. However, there seems to exist a correlation showing that the larger the #PV the larger the execution time. Moreover, in all datasets, execution time increases substantially from #PV = 8.

The next experiment is aimed at looking for other variable that can influence performance: the number of PoIs in the dataset. 6.2.3. Goal 3. Impact of the number of PoIs that satisfy a condition
This goal is aimed at verifying the conjecture that the higher the number of PoIs satisfying a condition, the higher the amount of memory required, therefore decreasing the algorithm X  X  performance. For the tests we used the legal algorithm variation and a set of queries such that the number of PoIs satisfying the constraints is different for each query, therefore covering a wide range of values.
 Experiment 3.1. We ran queries that include constraints satisfied by different numbers of PoIs, over the four datasets . The queries we ran were: Q21: [game= X  X asket X  X .[game= X  X asket X  X  Q22: [speciality= X  X eer X  X .[speciality= X  X eer X  X  Q23: [game= X  X olf X  X .[game= X  X olf X  X  Q24: [speciality= X  X izza X  X .[speciality= X  X izza X  X  Q25: [speciality= X  X asta X  X .[speciality= X  X asta X  X  Q26: [categoryName= X  X otel X  X .[categoryName= X  X otel X  X  Q27: [categoryName= X  X portClub X  X .[categoryName= X  X portClub X  X  Q28: [star= X 3 X  X .[star= X 3 X  X 
The results are shown in Fig. 18. We can see that as the number of PoIs that match a condition increases, the performance decreases, confirming our hypothesis.
 Experiment 3.2. The STPM algorithm does not only check if a trajectory satisfies a pattern, but also finds all the sub-trajectories that satisfy such pattern. As a consequence, the same trajectory may satisfy the same pattern several times (through its sub-trajectories), hence consuming much more time than one that only satisfies the pattern once. This situation is captured by the second experiment for this goal. Instead of displaying execution time as a function of the different numbers of PoIs satisfying a constraint, we report execution time for the different numbers of stops that satisfies it. In other words, this measure reflects the actual number of matchings during the execution of the algoritm which is a more representative indicator that the one of Experiment 3.1, reflecting the incidence of trajectories containing several sub-trajectories satisfying the same pattern. We used the same queries than in Experiment 3.1. The results are shown in Fig. 19. We can see that as the number of stops that match a condition increases, the performance decreases, confirming again our hypothesis. 6.2.4. Goal 4. Impact of the spatial queries
We now move to RE-SPaM + S queries that include spatial queries. We explained in Section 5 that these new capabilities should not affect performance substantially due to the use of macro and micro-cache strategies. We try to confirm this through the following experiment.

The experiment was designed taking into consideration that pushing the evaluating of spatial functions into the internal process could be useful precisely if spatial functions help to prune candidate sequences the invocation to an extended (spatial) function in RE-SPaM + S . At runtime, a cursor browses a collec-tion of identifiers of spatial objects returned by the spatial query. Condition c2 is an equality expression. We use the extended function containedBy , and run the query. We then run the query removing c 1 ,that is, the query becomes of the form [ c 2] . The experiment is aimed at verifying the impact of the extended function in the condition c 1 (it could be positive, if it reduces the number of candidate sequences in the intermediate steps of the algorithm, or negative, if the overhead of evaluating the function overcomes the positive effect).

In order to generate extreme conditions we chose queries that exhibit similar behavior in all of our four datasets: a) a query where the number of candidate sequences pruned by the spatial expressions is very significant against the same query without the spatial expression; b) a query where the number of candidate sequences pruned by the spatial expressions is negligible. The queries are listed below (we denote Q29-short and Q30-short, the corresponding queries Q29 and Q30 without the spatial condition): Q29: WITH TABLE distRiver(the_geom) AS SELECT GIS DISTINCT (bel_dist.the_geom) FROM bel_dist, bel_river WHERE crosses(bel_dist.the_geom, bel_river.the_geom) AND bel_river.name= X  X ijle X ; [ containedBy (geom, distRiver.the_geom)= X  X rue X   X  price= X  X heap X  X . [ containedBy (geom, distRiver.the_geom)= X  X rue X  ] Q29-short: [price= X  X heap X  X .[] Q30: WITH TABLE distRiver(geom) AS SELECT GIS DISTINCT (bel_dist.the_geom) FROM bel_dist, bel_river WHERE crosses(bel_dist.the_geom, bel_river.the_geom); [ containedBy (geom, distRiver.geom)= X  X rue X   X  price= X  X heap X  X . [ containedBy (geom, distRiver.geom)= X  X rue X   X  price= X  X heap X  X  Q30-short: [price= X  X heap X  X .[price= X  X heap X  X  The results are shown in Table 13.

In fact, the execution time reported by query-short variation does not include the extra time of post-final phase execution required to prune the undesired sequences. For example, for dataset DB4 we can see that Q29 prunes 514 sequences by means of the spatial expression. If a user only poses query Q29 she would obtain 569 sequences and should run a program to discard those 514 undesired sequences later. Without even taking into account this extra time we found that it is worth pushing spatial conditions in the intermediate steps because it substantially reduces the overall execution time. Nevertheless, the use of geometric functions introduces an overhead at the beginning of the process because the geometric condition (i.e., the spatial query) must be evaluated. Thus, it worsens the overall execution time when no significative number of sequences are pruned by this spatial expression.

In our experiments we obtained that independently of the size of the dataset, evaluating spatial func-tions during the intermediate steps might improve the overall performance if the number of candidate sequences pruned due to this expression is significant. 7. Related work
In this section we review some relevant efforts in Moving Object Databases (MOD) and mobility patterns literature, comparing these approaches against our proposal, when it corresponds. 7.1. Moving object databases
The field of moving object databases (MODs) has been extensively studied in the last ten years, spe-cially regarding data modeling and indexing. G X ting and Schneider [16] provide a good reference to this large corpus of work.
 Trajectory query languages. Wolfson et al. [32] stated a set of capabilities that a moving object data-base must have, and introduced the DOMINO system, which develops those features on top of existing Database Management Systems (DBMS) [31].

As moving objects report their changes very frequently, MODs must deal with frequent updates. Thus, the proposal consists of managing dynamic attributes instead of traditional static ones. A dynamic at-tribute changes its value continuously without being explicitly updated (e.g. the position of an object). The main intention is to be able to analyze current data (properties of a MO such as location and speed) to predict future positions. The proposal does not deal with pattern detection, but introduces a query lan-guage called FTL (Future Temporal Language) which manages location uncertainty. For instance, the query  X  X bjects that will intersect some region within the next 5 minutes X  is supported. Although MO are implemented using an object-relational database and a GIS to allow users to interact with geographic objects within a map (e.g. draw a region from scratch), no details are provided about the experiments, number of MO analyzed, average length of trajectories, etc.

Hornsby and Egenhofer [17] introduced a framework for modeling MOs, which supports viewing objects at different granularities, depending on the sampling time interval. The idea is to model all the locations visited by an object by inferring them from discrete samples. The basic modeling element they Id is the identifier of the object, location is given by x-y coordinates, and time is the timestamp of the observation. The possible positions of an object between two observations is estimated to be within two inverted halfcones that conform a lifeline bead (also usually called space-time prism), whose projection over the x-y plane is an ellipse. Thus, the movement recorded by samples is generalized to a coarser view.
 Trajectory aggregation. Aggregation of trajectories is related to the problem of trajectory similarity. Detecting similarities among trajectories could reduce their storage and facilitate analysis. Existing work focuses on the spatial notion of similarity, sometimes borrowing from the time-series analysis field. This is the approach followed by Pelekis et al. [25] who introduce a framework consisting of a set of distance operators based on parameters of trajectories like speed and direction, and propose distance operators based on this. Frentzos et al. [7] propose an approximation method for supporting the k-most-similar-trajectory search using R-tree structures. Meratnia and de By [22] tackle the topic of aggregation of trajectories, identifying similar trajectories and merging them into a single one, by dividing the area of study into homogeneous spatial units. Papadias et al. [24] index historical aggregate information about moving objects. Finally, Kuijpers et al. [18] propose a taxonomy of aggregation queries on moving object data. 7.2. Mobility patterns Techniques that add semantic information to trajectory data have been recently proposed. Mouza and Rigaux [23] present a model where trajectories are represented as a sequence of moves (zones repre-sented by labels or IDs). They propose a query language based on regular expressions aimed at obtaining so-called mobility patterns. The la nguage introduced in the present paper differs considerably from [23]. First, the language only supports IDs or names. Moreover, the proposal does not relate trajectories with the GIS environment and/or non-spatial data . On the contrary, RE-SPaM uses functions which bind MO information with attributes of the PoIs and other external information, which can be introduced in the form of OLAP (i.e., multidimensional) data -for instance as rollup functions-, or as spatial data (like in the RE-SPaM + S extension). The regular expressions proposed by Mouza and Rigaux talk about zones represented by some label (a constant) or a variable (@x). In this language, each occurrence of a variable in the pattern is instantiated with the same value. The units of time spent by the moving object inside some zone are expressed with the symbol + (undetermined time) or via the temporal constraint bound-aries {min, max}. The query  X  X bjects that started in zone A, visited another zone and five minutes later came back to A X , is expressed in this language as:  X  X ,7.@X + A,12 X . Variables can only be associated with places (represented by labels or IDs) visited by objects. Thus, the language cannot deal with time constraints or categories. On the contrary, our approach allows variables to be associated with any at-tribute of an item. For example, we can express  X  X rajectories that visit two places with the same price X  with the query [price=@x].[price=@x] where the variable @x is instantiated with prices.

Giannotti et al. [11] study trajectory pattern mining, based on Temporally Annotated Sequences (TAS), an extension of sequential patterns, where there is a temporal annotation between two nodes. a trajectory pattern is a set of trajectories that visit the same sequence of places with similar travel times between each one of them. They also propose three different mining methods and introduce the concept of Region of Interest (RoI) which is dynamically computed from the trajectories. They also introduced the notion of t-pattern for mining sequential patterns on regions of interest. A t-pattern is an expres-where regular expressions allow us to define more complex patterns in an intensional fashion, t-patterns are basically defined by extension.

The work by Giannotti et al. [11] also introduced the notion of Region of Interest (RoI). Although with similar goals, our work clearly differs from this proposal in several ways. First, we work with stops and moves instead of pre-defined regions of interest. This allows to identify which of the RoIs are really relevant to a trajectory. We also use these stops and moves to  X  X ncode X  or compress a trajectory, which, in many practical situations is enough to identify interesting sequences very efficiently. Second, the authors focus on computing the RoIs dynamically from the trajectories. On the contrary, in our approach the user defines the places of interest of an application in advance, and from them the stops and moves are computed prior to performing trajectory mining. Finally, our approach allows integration between trajectories and background geographic data, an issue mentioned albeit not addressed in [11].
With a similar idea, Damiani et al. [27] introduce the concept of stops and moves, in order to enrich trajectories with semantically annotated data. Alvares et al. [4] presented a framework for trajectory analysis based on stops and moves . The concept of Stop differ from the RoI. The former is application-dependant, defined in advance and really relevant to a trajectory. The latter is detected dynamically. Their work proposes how to compress trajectories with the notion of stops and moves, and use SQL to ask for trajectories which satisfy some conditions. No mining algorithm is discussed to detect patterns within trajectories. 7.3. Data mining and its application to mobility analysis
Data mining refers to collection of techniques aimed at discovering interesting patterns hidden in large volumes of data. These techniques have been applied to the field of MOD in different ways.
Clustering is a well-known mining algorithm for grouping together similar objects. Lee et al. [19] re-mark that by applying clustering to whole trajectories, many interesting patterns could be lost. Thus, their proposal aims at discoveri ng common sub-trajectories, and a lso propose a par tition-and-group framework for clustering trajectories. For that, they partition a trajectory into lines using the minimum description length (MDL) principle, and cluster those segments to detect trajectory similarities. No tem-poral component is analyzed during the mining process, i.e., they reduce trajectories to their spatial component (only the shape of the trajectory is analyzed).

For mining trajectories constrained by road networks , Brakatsoulas et al. [5] propose to add spa-tial information to trajectories of moving objects. They consider to incorporate information about the relationships between trajectories (e.g., intersect, meets, near), and between a trajectory and the GIS environment (e.g. stay/within/leave some building). A mining language denoted SML (standing for Spa-tial Mining Language) is also introduced, oriented to traffic networks. Note that this approach requires all information on moving objects to be processed. In our proposal, on the contrary, we use semantic information to reduce, whenever possible, the amount of data to be considered.

We remark that all of these proposals cannot detect if trajectories are semantically equivalent ,they only work with the classical notion of similarity.

Also in the framework of road traffic mining, Gonzalez et al. [15] use a partitioning approach for obtaining interesting driving and speed patterns from large sets of traffic data. They compute frequent path-segments at the area level with a support relative to the traffic in the area (i.e., a kind of adaptive support), and propose an algorithm to automatically partition a road network and build a hierarchy of areas.

Classic data mining algorithms (in particular sequential pattern algorithms) can be applied to trajec-tory databases if we view the latter as a collection of ordered sequences. Two main approaches had been followed in the field of pattern discovery in sequences: the classic Agrawal and Srikant proposal [3], the approach of Mannila et al. [20]. The former is aimed at discovering inter-transaction patterns, based on previous work [1,2] dealing with detecting intra-transactions patterns. The information to be mined is organized in transactions and the system returns the frequent sequential patterns among them. The latter, instead, considers the information to be mined as a large single sequence. The choice of the algorithm depends on the application domain. In their seminal work, Agrawal et al. [1,2] propose data to be pre-processed in a way such that each customer (in a market basket analysis scenario) is associated with all her transactions ordered by time of occurrence. The idea is to find inter-transaction patterns correspond-ing to the same customer with a certain support. An interesting sequential pattern is one that appears in the database at least as many times as a user-specified threshold, denoted minimum support . The sup-port of a sequence is defined as the fraction of the total number of transactions containing it. In further work, the authors extend their proposal [28] in order to support three kinds of constraints: (a) time-gap constraints; (b) taxonomies; (c) time windows. The resulting algorithm is called Generalized Sequential Patterns (GSP). In this work only items (IDs) can participate in hierarchies. In the present paper we extended this idea allowing any kind of attribute (including temporal ones), and showed that supporting attribute, variables, and categorization yields a much powerful Constraint Definition Language.
Although many frequent sequential patterns could be obtained using GSP, it is likely that only a few of them could be relevant to the user. To avoid this situation, Garofalakis et. al. [9,10] propose a variation of the GSP algorithm, denoted SPIRIT, where user-defined regular expressions are used to prune the information obtained. Like in the other proposals already commented, SPIRIT only deals with the IDs of items. As we explained above, using attributes lets us avoid item enumeration. Moreover, besides writing concise queries, our proposal supports the binding of variables t o any attribute (or function over an attribute) during the mining process. As far as we are concerned, this is the first proposal in this sense, in sequential pattern discovery. In our mining algorithm, STPM, the original idea of counting for sequences support has been kept, although regular expressions have been introduced to constrain the number of sequences to be obtained. To illustrate this idea with a simple example, the expression (
A | B ) .C is satisfied by sequences like A.C or B.C. Even though the semantics of this RE suggests that both of them are equally interesting to the user, if neither of them verifies a minimum support (although altogether they do), they would not be retrieved. Suppose that a database contains two transactions, the now that we only want sequences expressed by ( A | B ) .C with minimum support 75%. No sequence would be retrieved by SPIRIT. This is because during the mining process the itemsets of length 1 are composed of the items A, B and C, although only C is maintained as the other ones are considered separately and they do not have minimum support (i.e., A has 50% support and B has 50% support). We count support in a different way because we consider both, A.C and B.C equivalent under the RE. Thus, our algorithm returns these two sequences as the ones that satisfy the RE and have minimum support. 8. Conclusion
In this work we have shown that MO data can be effectively integrated with other kinds of data, like spatial and multidimensional (OLAP) data. We first showed that trajectories can be semantically enriched with information about the geography where they develop. We discuss how mining techniques can identify semantically equivalent trajectories, contributing to the detection of patterns that cannot be discovered with traditional approaches. We then introduced a sequential pattern mining algorithm and a regular expression query language (called RE-SPaM) to restrict the number of sequences to be discovered. This proposal differs from previous ones in many ways: first, it formalizes all the concepts related to the mining process by means of a data model; second, it supports categorical attributes, and the use of functions and variables; third, expresses patterns as regular expressions instead of sequences (i.e., patterns are expressed by intension rather than by extension); finally, it introduces the idea of computing the support of a regular expression. We also showed that spatial queries can be included in RE-SPaM expressions, leading to a more powerful language called RE-SPaM + S . We performed an extensive set of experiments, aimed at identifying the variables that affect the performance of the data mining algorithm we proposed, and reported the results. We also presented an implementation of the mining algorithm using the RE-SPaM and RE-SPaM + S languages. 8.1. Open research directions
In traditional sequential pattern discovery the support of a sequence is computed as the number of data-sequences satisfying a pattern with respect to the total number of data-sequences in the database. In our approach it is the fraction of number of trajectories satisfying a RE over the total number of complete conclusions. For instance, in the examples discussed in Section 6, we assumed that the schema of categories and also the values associated to category occurrences are invariant over time. The pattern discovery algorithm assumes that no changes have occurred in these categories. In light of this, for some situations it can be important to revise the classic notion of support in sequential pattern mining and consider the notion of Temporal Support of a RE , that accounts for the commented category updates. Acknowledgements The authors were partially funded by the LACCIR project  X  X onitoring Protected Areas using an OLAP-enabled Spatio-temporal GIS X . A. Vaisman is partially funded by the  X  X pen Semantic Cloud for Brussels (OSCB) X  project, funded by the Brussels Capital Region, Belgium.
 References
