 1. Introduction and motivation
Design is one of the most important steps in the software development process. In most systems analysis and design literature, the process of design always comes before implementation, and carries a major weight in determining the success of a project.
The process of conceptual design is the phase of design that is independent of the final platform and the medium of implemen-tation, and is usually in a form that is understandable and usable by managers and other personnel who may not be familiar with low level implementation details, yet play an influential role in the development process. Most of the development methods uti-lized in today's software development include such a conceptual design phase. For instance, in relational database development, the conceptual design is presented using the well-accepted Entity-Relationship (ER) diagrams [1] , in software model develop-ment, the conceptual model is presented using data flow diagrams (DFD's) [2] , in Object-Oriented design, the conceptual model is presented using the Unified Modeling Language (UML) [3] , and so forth.

The Entity-Relationship approach is a well-accepted technique for data modeling, and is one of the techniques most used in the design process of applications involving relational databases. Unfortunately, the design process of XML-based applications does not involve an accepted conceptual modeling methodology, although several tree-based methods and ER-based methods have been proposed (see e.g., [4,5] ). The goal of this research is to propose a conceptual design method building on top of the
ER model, staying as true to the original model as possible, yet creating a semantic equivalence between the conceptual model and the final schema. Just as in ER, the model should lead to an equivalent schema representing the modeled data structure. As an added motivation, the well-established domain of model-driven architecture [6] recommends the use of conceptual models for software development because of the benefits it provides to the software development process, both short term and long term. We derive further motivation from the principles of metamodeling which show that the need for concise models can be language based on familiar notation, an important principle for universal design. In fact, the Entity Relationship approach has been successfully applied to the design of the Eclipse Modeling Framework (EMF) [8] , a metamodel framework used extensively in software development in the open software foundation domain. EMF also uses an XML-based model specification, and a guide-line has been proposed for using the Entity Relationship approach for EMF metamodel definition [8] .

The concept of web services, SOAP (Simple Object Access Protocol), and a host of other XML-based standards mandates the use of XML at the level of design, representation, as well as retrieval of data; yet there is no standard mechanism for modeling and designing XML structures without a low-level hierarchy-based design. Most XML design processes start by directly marking up data in XML, and the metadata is typically designed at the time of encoding the documents. Users who prefer a more graphical method typically employ an XML editor to design the schema, typically via a process of creating the hierarchical structure conceptual models and have a process to translate the model into the schema, as is typical in relational database design. The methodology described in this paper utilizes the fact that conceptual models are network-based structures rather than hierarchy-based, which one needs to achieve when building XML applications. XER relieves the designer by not enforcing the hi-erarchy constraint but allowing a flexible method for extracting the best possible hierarchy for the data from an unconstrained conceptual model. In this respect we present XER (pronounced known ER model [1] , which is capable of handling all the nuances of XML in a highly presentable graphical form.
While the presentation of the modeling technique is one contribution of this article, the most important contribution of this paper lies in the process of analyzing user behavior while using a modeling technique for designing a new application or analyz-comparable conceptual techniques as well as direct application of schema. We develop a theory based on existing literature on systems analysis and design, and demonstrate that the use of a domain-independent modeling methodology may lead to better user performance in accurately and efficiently designing and analyzing XML applications.
 The contribution of this paper, thus, lies in the conservative extension of the ER modeling method for conceptual modeling of
XML, and empirically establishing its effectiveness in improving user performance in the design and analysis of XML data oriented applications. The biggest claim we intend to make in this paper is that any visually inclined metamodeling architecture should provide a better modeling experience for XML-based applications. The metamodel architecture provides a strong theory for this claim, and our empirical study shows results supporting this claim as well. We hope that in the recent future, W3C and the research community will work together to develop a recommendation for a commonly known and understood conceptual model for XML. 1.1. Modeling nuances in XML
The biggest question in the reader's mind will likely be: current modeling strategies not work?  X  The proper answer for this question comes from the fact that XML has a complex ordered and multi-level structure. This structure is more complex than the flat relational model, yet less complex than the semantically rich object-oriented model. At first glance, the Entity-Relationship (ER) model seems to be an appropriate modeling approach amonds to describe the data objects and the relationships between them. However, XML structures are typically not designed with a data relationship view, but they are designed more from a document perspective, with primarily textual content, that has embedded links, meta-data information, and a structural hierarchy. The main complicating factors that make the standard
ER model hard to adapt to XML are as follows: stances of the same element. Ordering is not a constraint but an inherent design aspect of XML, and several structural con-structs are included in both DTDs and Schemas to handle document order. 2 Hierarchy : XML does not have a direct way to support many-many relationships, since the structure is essentially hierarchical.
Every document must represent a strict hierarchy to be well-formed. 3 Heterogeneity : XML structures often involve heterogeneous types, a concept in which different instances of an element may have different structures. al, required and multi-valued elements, unlike the essentially flat nature of structures in ER models. characteristic in the document, perhaps augmented with attributes. items at the same time. 7 Namespaces : Last but not the least, XML supports many related concepts such as namespaces that makes the task of creating a conceptual model nontrivial.

Given these departures from the norm (primarily compared with relational systems), we contend that an extension to the ER model can appropriately result into a method for conceptual development of XML Schema, retaining the ease of use and success of the ER approach and still allow the possibility of modeling XML structures.
This paper is organized as follows. Section 2 provides a background in XML design, from both research as well as commercial perspectives. Section 3 introduces the XER methodology, and Section 4 shows how XER assists in design and analysis of XML ap-plications. Section 5 presents the empirical study comparing XER against two other artifacts from the perspectives of both design models used in the empirical study in Appendix A and statistical analysis results in Appendix B . 2. Background in XML design and modeling
Conceptual modeling is a fairly standard aspect of software engineering and all software engineering models involve concep-tual design as the first phase of an application development life cycle. Although XML has matured as a well-developed language for the internal representation of most web-based application-to-application data interchange, XML for core data representation still hasn't caught up to where it was hyped to be. W3C has released different models for XML for the purpose of programmatic traversal (DOM), as well as query language understanding (XPath/XQuery data model). DOM (Document Object Model) [9] is a low level programmatic model that allows traversal of the XML parse trees and provides APIs for the purpose of developing XML based applications. The XPath/XQuery data model [10] is a formal model for describing the query language features of XML. Neither active manipulation. While conceptual modeling has been a topic of research for some time, a standard conceptual modeling method has not yet been accepted as the method of choice for XML. In this section, we review some of the conceptual modeling methods in literature, as well as some of the research in comparing conceptual models with schema-based models.

Most of the methodologies explored in literature are based on currently existing modeling techniques. Two of the most pop-ular modeling approaches in current use are the Entity Relationship (ER) model and the UML (Unified Modeling Language), both last ten years that show various methods for conceptual modeling. In this section, we summarize a selection of such techniques to introduce the basis for our work.
 Some of the early research on XML modeling involved capturing the development of Document Type Definitions (DTDs). Dos
Santos Mello and Heuser [12] describe a semiautomated process for converting a DTD to a conceptual schema and for providing a canonical representation of the same. The process involves a set of conversion rules that consider DTD elements, attributes, syn-tactical constructs and heuristics related to default semantic interpretations of these constructs to generate the corresponding conceptual concept. It entails human intervention to generate the final graphical conceptual model using a three-phase conver-the DTD definition, applying appropriate rules according to the syntax of the element and its attribute definitions to generate a conceptual schema. Rule-based translation of XML specification to XML Schema using XSLT stylesheets [13] has also been developed the output schemas of the stylesheet specifications.

Extending the Entity-Relationship approach [1] to model XML has also been fairly common. Such methods involve adapting the ER modeling approach with extensions to incorporate XML capabilities. Common methods among these approaches include EER (Extended Entity Relationship) and ERX (Entity Relationship Extended).

EER [16] uses the semantic data modeling capabilities of XML Schema's to capture the mapping between features of XML Sche-ma and existing models. This work formalizes a core set of features found in various XML Schema languages into XGrammar, a commonly used notation in formal language theory. XGrammar is an extension of the regular tree grammar definition, and use a six tuple notation to describe the model of XML Schema languages. XGrammar has three pertinent features: (i) Ordered binary ER model; and based on this comparison, extend the ER model to better support XML. Mani et al. term this extended model as the
Extended Entity Relationship model (EER). The main extensions from the ER are (i) modification of the ER constructs to better support order and (ii) introduction of a dummy  X  has  X  relationship to describe the element in XML.
 Psaila [17] introduces ERX (Entity Relationship for XML) as a conceptual model based on the Entity Relationship model [1] .
ERX is designed primarily to provide support for the development of complex XML structures. It provides a conceptual model tities, Relationships and Attributes have been modified or extended to support XML specific features such as order, complex structures etc. ERX is not constrained by the syntactic structure of XML and is specifically focused on data management issues.
ERX however does not support some XML specific features such as mixed content, and does not describe how complex types with their various nuances can be modeled into the system. ERX does not provide support for ordered and unordered attributes.
XML, but however there is no mechanism to determine the order of attributes within an XML concept. ERX however establishes the algorithms to translate XML DTD's into a corresponding ERX model. Combi and Oliboni [19] also present a similar Entity-
Relationship-based technique that is demonstrated using a prototype and a translation mechanism into XML Schema. Other tech-
The modeling technique described in this paper, XER (Extensible Entity Relationship) builds on an earlier conference presen-tation [21] and falls in the category of extending the ER model. The biggest difference between this approach and many of the other approaches described earlier includes the use of semantic extension
Relationship model is kept intact with very minor structural changes. Instead of changing the ER model significantly, we use se-mantics that allow transformation of the ER constructs to XML.

UML, the well-accepted object-oriented modeling technique has also been used for modeling XML. Conrad et al. [22] describe various UML constructs such as classes, aggregation, composition, generalization and packages and explain their transformation into appropriate DTD fragments. Their work also extends UML to take advantage of all facets that DTD's offer. UML classes are used to represent XML element type notations. The element name is represented using the class name and the element content top-bottom order. DTD constructs for element types, which express an element straints and use the same to express relationship cardinalities. One advantage of using UML is the easy incorporation of Object-
Oriented design in implementing generalization. The conceptual model as proposed by the authors can handle most of the con-structs that are commonly used in a DTD. Further, some of the UML constructs such as UML attributes for classes, which do not have an equivalent XML representation, are suitably modified to represent XML specific features. This method is fairly successful in the conversion of DTD fragments into corresponding conceptual models. But since the author's work restricts the model to
DTD's, the expressive power of the model is limited. The UML based method also entails the user designing an XML conceptual model to learn the concepts of UML.

The UML models can then be used to build XML Schema using a mapping process. One such mapping is presented by Routledge et
XML stereotypes such as  X  Simple Element  X  and  X  Complex Element
Schema. The above definitions enable a direct representation of the XML Schema components in UML. More details of the UML profile implementation language namely XML Schema. The authors have not included algorithms to directly convert the logical model to a Schema and vice-versa.

Other advanced concepts have also been used for modeling XML. One such approach uses the concept of semantic data net-works [24] . This methodology uses a semantic network in the top level that provides a semantic model of the XML document through (i) atomic and complex nodes, (ii) direct edges representing semantic relationship between nodes, (iii) labels denoting includes element/attribute declarations and simple/complex type definitions. The main idea is that the mapping between these two levels can be used to transform the XML semantic model into a XML schematic model, which can then be used to create, modify, manage and validate documents. Research has also been performed on identifying dependencies in Entity-relationship models via constraints for the purpose of automated model interpretation [25] . This paper is influenced by many of the above articles.
Many commercial tools have also been developed for the purpose of building XML structures. A list of these tools is available from W3C [26] , that includes XMLSpy from Altova, a full featured XML editor with capabilities for visually editing DTDs and XML Schema. A few additional tools are described in the rest of this section.

XML Authority [27] provides a visual representation of a DTD or a XML Schema. It supports two different views, a tree represen-DTD's and also provides conversion tools to convert between XML and SGML.

Microsoft Visual Studio .NET Suite [29] includes XML Designer, a graphical XML Schema editor. XML Designer provides a set of visual tools for working with XML Schemas. The designer provides the following 3 views or modes to work on XML files and datasets namely Schema View, XML View and Data View. The schema view provides a visual representation of the elements, attributes, types, etc., components that make up the XML Schema and ADO.NET datasets. The XML view provides an editor for editing raw XML and provides IntelliSense and color-coding.

In summary, a fair amount of work Table 1 provides a comparison of the existing methods cited above, with respect to six functional aspects. Literature does not show any existing work in empirically evaluating conceptual design methods for XML.
We select six functional criteria from the systems covered, primarily based on the main four design complexities of XML struc-tures and adding in the forward and reverse engineering methodologies capabilities of conceptual designs. The first criterion order represents representation of document and structure order. The next two (heterogeneity and complex content) are also structural aspects of XML, and all the models faithfully represent them. The fourth criterion, mixed content is an important data representation characteristic of XML. The next two criteria refer to the processes of translating an existing application up or the extent these methods support the XML Schema standard.
Although the UML method by Conrad et al. [22] does support almost all the criteria, its limitation to XML DTDs limits it as a conceptual representation of XML Schema. In the methodology we present in this paper, XER addresses all of the functional as-pects of XML conceptual modeling. In addition, we demonstrate empirically, that conceptual modeling artifacts such as XER do result in improved user performance, both from the perspectives of efficiency and accuracy, and provide greater satisfaction to users for development of new applications, as well as for analyzing existing applications. 3. The XER modeling methodology
We present XER, an extension of the popular ER model [1] as a conceptual model for XML. To avoid the minute details on all the various features of XML, we assume a canonical view of XML called ENF (Element Normal Form) [30] , which is a representation of
XML documents without using any attributes. Any XML document with attributes can be transformed into ENF by converting the attributes to elements with a special naming convention (e.g., prefixed with a symbol like formed using XSLT [13] , and the original document can be obtained back from an ENF representation using XSLT as well. Note that given the ENF specification, we assume that the ENF translation process places the term  X  attribute  X  in XML has an entirely different meaning from the same term in Entity Relationship models.
Given the metamodel architecture motivation introduced earlier, XER fits well with the layered metamodel-based design prin-
Schema forms the model layer, and at the bottom is the data represented in XML. The design goal in this method aims at developing a metamodel-based design paradigm for XML, whereby a domain model is captured via XER, and the schema may be generated as needed. Note that XER is not necessarily a complete structural equivalent of XML Schema, and in fact requires some simplification of XML Schema before an up-translation algorithm can be applied. However, designs in XER can always be translated into an equiv-alent XML Schema. The metamodel architecture is shown in Fig. 1 . 3.1. XER constructs
As noted earlier, XER extends the ER model [21] by introducing some semantic modifications to the ER constructs. Before discuss-ing the constructs, we would like to emphasize the design principle for XER allowingonly semantic variationstoenableXML functionality. For thefollowingdiscussion, weare goingtoassumesomebackground in XML constructs to avoid defining all the related XML terms. However, because of the overlap between the terms and concepts in
XML and ER, some of the terms in the rest of this paper will refer to XER concepts. For example, an entities and not XML attributes of elements (we are assuming ENF, thereby eliminating the need for attributes). The XER model in-
XML schema translation of each construct, highlighting the primary aspects of the translation process in bold in the XML Schema. 3.1.1. XER entity (i) Ordered Entity : XER entities are ordered by default. An ordered entity indicates that the XER attributes in the entity must (iii) Mixed Entity : XER supports mixed entities, in which text content as well as element content is allowed. The mixed entity 3.1.2. XER relationships
Relationships denote a connection between two or more XER entities. Relationships can be (1  X  M) or  X  many to many  X  (M  X  M). In the XER diagram, a relationship is represented as a diamond like in the ER model. The reader tured by XML because of its hierarchical nature, and hence must be properly translated when building the schema. However, using XER, designers do not need to worry about this internal translation mechanism and may develop models as simply as they would develop relational models. When translated into a schema, a relationship becomes part of the entity's complexType ated and they are referenced using the KEY/KEYREF feature in XML Schema. Relationships may or may not be named, and labels along the connectors indicate participation constraints for a relationship and the connecting entity. An example of a 1 lationship is shown in Table 3 , and a more complex example involving a ternary relationship is shown in Table 5 . Note that the or 1  X  M relationships) or the relationship (for ternary or M  X 
Participation and cardinality in relationships: Participation and cardinality constraints in XER are exactly the same as those in standard ER models. Unfortunately there are a large number of and cardinality are represented. Hence we use a  X  minmax  X  tion/cardinality constraints indicate the minimum and maximum number of times the entity participates in the relationship. This was chosen since it comes closest to the minOccurs and maxOccurs attributes of elements. Table 3 , for example, shows that a book should have a minimum of one chapter but could have many chapters, while a chapter is associated with only one book. This is closest to the XML equivalent where within the complex type book, the minOccurs and maxOccurs of Chapter are defined as 1 and
M respectively. 3.1.3. XER generalizations archy). Conceptually, a generalization allows one entity to have multiple sub-entities that may have properties in common, but also distinguishing properties. The closest concept in XML Schema is a
Type involving appropriate values for minOccurs and maxOccurs can be used. In XER, we present generalizations using a covering rectangle containing the specialized XER entities as shown in Table 4 .

This is equivalent to using the  X  choice  X  tag in XML Schema. The choice for including the sub-entities within the body of the parent entity follows the trend of incorporating element structure within the element, although the readers should note that a choice does not indicate any form of order. While heterogeneity in XML seems different from ER generalization conceptually, the heterogeneity typically used in documents to provide alternative structures of a parent element, a semantic that is close to generalization; and hence supports our use of generalization to model heterogeneous structures. 3.1.4. Other XER concepts
Like the ER model, XER can also have weak entities, ternary relationships, and aggregations with similar semantics. A weak entity in XER indicates a strong relationship between the of creating an IDREF relationship). For example, consider the XER diagram in Table 5 . The weak entity the strong entity  X  question  X  since answers cannot exist without a corresponding entity in the Question entity set. Question has other relationships, for example the relationship between question and category, or the ternary relationship between question, tures in XML.

Table 5 demonstrates the use of weak entities and ternary relationships, showing the pertinent translations in bold. Finally, aggregations, in the same manner as ER aggregations, provide a method for turning a relationship into an entity, thus restructur-a schema, although a weak entity in a model is translated in the same manner as a 1 application, including all of the major constructs of XER described here is shown in Fig. 3 as well as in Appendix A ( Fig. 5 ).
In summary, we designed XER as more of a semantic extension to ER rather than syntactic or structural. While some structural differences exist, most extensions involve semantic re-positioning of ER constructs for applicability in XML. Table 6 summarizes these structural and semantic differences. 4. Using XER to design/analyze XML applications
Designing XML applications involves a systematic construction of the XML Schema. Using XER, users do not need to work through the textual verbosity of the XML Schema, and instead, construct a model conceptually using graphical tools. This process model is constructed, it can be translated into a fully conforming XML Schema (a process that we describe as down-translation).
Analysis of existing XML applications can also be easily performed using XER. Any conformant XML Schema can be neered  X  (or up-translated) into an XER model. The ensuing graphical model can be easily used for the purpose of reasoning and analyzing the structure of the existing XML data.

In this section, we will algorithmically describe the above two translation. For the sake of explanation, we will term the trans-lation from a schema to XER as  X  reverse translation  X  or  X  down translation  X  . 4.1. Down-translation from XER to schema
The down-translation process follows the basic schema construction methods discussed in the previous section. The biggest issue in down translation is the creation of an XML hierarchical structure from the network structure of the model. The designer hierarchy. However, the more typical method is to let the algorithm create a root element and incorporate all primary entities as multiply occurring children of the root element. The algorithm is presented below as pseudocode in Listing 1 . 4.1.1. Notes on the algorithm
In the above algorithm, there are two important items that deserve additional explanation. The first is the priority order. Since there is no explicit hierarchy in an ER model, we prioritize the entities based on how many other entities it may be a a weak entity, sub-entities in a generalization, or have the most number of relationships associated with them. The second item that deserves special attention is termination. To demonstrate that this algorithm always terminates, note that there are only a finite number of elements in xermodel, each of which is unmarked to start with, and as each node gets incorporated, the node is marked and never considered again for re-modeling. The selection of the tities as its children. 4.2. Up-translation from schema to XER
Before we discuss the up-translation process, please note that an XML Schema needs to be pre-processed to the Element Nor-mal Form (ENF) before up-translation, which can be easily achieved using an XSLT transformation. Also, we ignore the data types and external namespaces for the presentation of the algorithm, as well as expand implicit complexTypes to complexTypes with automatically generated names. Since XER is primarily meant to be a conceptual modeling methodology and not an exact repre-sentation of an XML Schema in a graphical means, some of the specialized schema elements are not represented in a visual form, but saved as properties of the diagram for future down translation purposes. For example, the mation about the namespace from which the elements and the data types used in the schema are derived from. This information in the diagram. Listing 2 presents the up-translation algorithm. 4.2.1. Notes on the algorithm
This algorithm involves traversing the XML tree structure of the schema. The macro er termination of this algorithm is based on the fact that in XML Schema as well as in XER, every element (in schema) and entity (in XER) has a unique name. However, because of the xs:ref feature in XML, the same element may be encountered multiple structure where an element contains a complexType including a reference to that element itself, the algorithm will create a rela-providing the location for that relationship within the section entity.

The reader should note that the above algorithm provides higher weights to entities, and thus may result in fewer relation-ships than what a human designer may create. However, the resulting models behave similarly, and literature suggests entities to be better in representing composites than relationships [33] . As far as the quality of the model generated from the schema, and understandable model.Models created from very complex XML Schemamay not bevery presentable in thebeginning, but should we consider such quality analysis of the generated model as a future extension of this article.

In summary, the translation between XML Schema and ER creates a form of semantic mapping that is implemented by these forward and reverse translation algorithms. Fig. 2 demonstrates the translation and mapping process by showing the same XER model as in Table 5 and demonstrates how the XML Schema structure is formed for each element in the XER diagram. 4.3. Prototype implementation of XER We developed two prototype implementations of XER: the first using VBA (Visual Basic for Applications) based on top of
Microsoft Visio X ; and the second using XML and XSLT (XML Stylesheet Language Transformations) on top of Dia, an open source drawing utility. We designed both implementations to create new XER diagrams and performing up and down translations. How-ever, we abandoned the development of the Visio-based system because of some limitations on the size of diagrams that we ran into. The Dia implementation is also more open and capable of incorporating more current techniques and standards. Also, be-cause of the functional nature of XSLT, and the fact that XML traversal is built into XSLT, the XSLT implementation does not need to perform any specific tree traversal  X  the traversal of the XML trees is taken care of by the XSLT engine works by implementing the down and up translation algorithms functionally by attaching semantics to nodes and paths in the parse/translation step in XSLT transformation.

In the Dia-based prototype, users create XER diagrams in Dia by using an XER stencil that we created. The users create entities, objects (such as the occurrence indicators of attributes) using context menus associated with the objects. A screenshot from the implementation showing a partial XER model and the XER stencil is shown in Fig. 3 . 5. Empirical evaluation of XER
We conducted an empirical study to determine user reactions with respect to comprehension and design of XML structures using XER. The study had a two-pronged objective: on one hand we intended to determine whether the use of a conceptual model was helpful for the purpose of designing solutions to new problems or understanding existing solutions; and on the other hand whether any of the individual tools (XER, ERX, .NET) had a significant advantage over the others in the process of design as users were used.Since theprocess of conceptual designis independent ofthe final platformand the medium of implementation and is usually in a form that is understandable and usable even to people who are not familiar with low level implementation details, we investigated the use of the above models as a means of design as well as for comprehension.

Studies determining the effectiveness of conceptual models are not uncommon. Batra [35] provides a framework that demon-strates that data retrieval using conceptual methods provide superior user performance than other querying approaches, and that users tend to make fewer errors in retrieval when using concept-based methods. Using this framework, Batra et al. [36] found that conceptual modeling approaches make a major impact especially for end-user development of information systems, when com-paring the low-level relational model with the conceptual EER model. Chan et al. [37] observe a pattern of improved user perfor-process for querying. The general notion here once again is that the users perform better using a conceptual model. We extend implementation stage, as well as a post-implementation analysis of existing systems. Thus, our primary research question is:  X 
What will be the performance improvements of XER over other existing methods, either conceptual (e.g., ERX), or graphical schema-based (e.g., .NET)?  X  To test this research question, we conducted a lab experiment with the following hypotheses.
 H1. The use of XER will generate more accurate models for analysis (H1a) and design (H1b) tasks, when compared to ERX and .NET. H2. The use of XER will generate more efficient models for analysis (H2a) and design (H2b) tasks, when compared to ERX and .NET. H3. The use of XER will lead to more satisfaction in analysis (H3a) and design (H3b) tasks, when compared to ERX and .NET.
Although technically the comparison should be between XER (or ERX) against XML Schema, practically speaking, the syntax-heavy nature of XML Schema makes it difficult for any feasible comparison with more visual conceptual models. Hence, we choose the Visual Studio .NET Schema designer, which is a graphical tool comparable to XER and ERX. More details on the rationale for the choice of the artifacts are presented later in this section. 5.1. Research methodology
The primary goal of this research is to establish a model of user performance in design and analysis tasks for XML using one of three artifacts  X  two conceptual and one schema-based. Fig. 4 shows a pictorial representation of this model.
Fig. 4 shows the two factors that impact user performance in the design and analysis of XML structures. Two types of task (de-sign and analysis), and three modeling artifacts (XER, ERX, .NET) impact user performance. 5.1.1. Subjects 45 students (33 males and 12 females) from a graduate level Information Systems course on Web based programming with internship experience and/or part-time work experience in information systems. As a result, the students were in the 23 range. A university Human Subjects Committee approved the study, and the students participating in the experiment received extra course credit and were ensured complete confidentiality. The students had prior exposure to conceptual modeling, XML and writing XML Schemas. 5.1.2. Dependent variables
The primary dependent variable, accuracy was measured by the following criteria. For the analysis task, the subjects' answers subjects was determined by coding each answer based on the following metrics (based on Batini et al. [38] ).
Completeness : A model is complete when it represents all relevant features of the application domain. Completeness is checked in principal by ensuring that all mentioned requirements are represented in the model and all concepts mentioned in the model are present in the requirements.
 Correctness : A model is said to be correct when it properly uses the concepts of the conceptual model being tested. Minimality : The model is said to be minimal if every aspect of the requirements occurs only once in the schema. Expressiveness : The model is expressive when it represents requirements in a natural way and can be easily understood.
Readability : The model has good readability when it respects certain aesthetic criterion that makes the diagram graceful such as symmetry.

Extensibility : A model is easily adaptable to changing requirements when it can be decomposed into pieces so that changes are applied within each piece.

Self-Explanatory : The model is self-explanatory when a large number of properties can be expressed in the conceptual model itself without other formalisms (ex: annotations in natural language).

The second dependent variable, efficiency, was measured by the amount of time the subjects used in each of the tasks. The artifact compared to XML Schema. 5.1.3. Independent variables
This study used a repeated measures design in which all participants performed two tasks, namely analysis and design. The independent variable was the modeling artifact XER, ERX or .NET. The choice of ERX was straightforward, due to its prominence jects were enrolled in an XML development course utilizing .NET tools, and had prior exposure of developing XML Schema using the .NET tool.
 5.2. Tasks
To simulate the two types of tasks, two separate question sets were created. The first question set (design) described a typical data representation scenario that had to be modeled as a XML database. The scenario was chosen to include most of the nuances of XML modeling mentioned earlier. The subjects of the study had to model the scenario using the randomly assigned artifact (XER, ERX or .NET). The second question set was designed to test the ability of users to analyze a given conceptual model. A con-ceptual model describing a typical business situation was chosen as part of the analysis task. Each subject received a conceptual model that was created using the same modeling treatment that they were assigned to, namely XER, ERX or .NET. (See Appendix able to comprehend the underlying XML structure with only the diagrammatic model shown to them. Both the design and anal-ysis tasks also included questions related to the subjects' judgment regarding the simplicity and ease of use of the model they used, and their preferences of the model over others that they were exposed to during training.

Table 8 shows the different types of tasks used for both the analysis and design domains. For the analysis domains, the tasks 5.3. Experimental procedure
A pilot study was first conducted to determine the feasibility of the final experiment. The pilot study involved three subjects, one each for each modeling treatment. The final study was conducted over two days (two class periods). On the first day, the sub-ture) on how to use the above conceptual models to design XML Schemas and also on how to comprehend the constructs from the above models. An example scenario different from those used in the experimental materials was used for training purposes. The ex-ample incorporated most of the nuances of XML and all the constructs supported by these models. The students were also given doc-umentation and research papers describing the above models, which they were allowed to consult during the actual experiment.
On the day of the tests the subjects were randomly assigned to one of the modeling treatment conditions. Each subject an-swered the two questions sets described in the previous section as per the modeling treatment condition they were assigned
All the questions were answered directly using a web based interface. Students were instructed to choose the correct answer and explain the rationale behind their choices. The subjects indicated their ease of use and preference perception on the same ques-tionnaire. The time taken by the students to answer the questions was recorded by the web interface.

For measuring the accuracy of the analysis task, a 5-point Likert scale was used to measure the subject's responses: 1) incorrect uators were used to code the answers. One evaluator evaluated all the responses. The other evaluated a random subset of the used. For repeated measures comparison, the scores from both the tasks were normalized for a total of 15 points. 6. Results
We designed a 3 X 2 mixed randomized-repeated measures MANOVA (Multivariate Analysis of Variance) [39] analysis for evaluating the results. MANOVA is a generalized form of univariate Analysis of Variance (ANOVA). We applied this measure in this research because it helps answering the question regarding whether the changes in independent variables have significant impact on the dependent variables. MANOVA measures are also used to determine interactions between the dependent and in-dependent variables.

In the statistical model (see Fig. 4 ), we used with  X  task for comparison was set at 0.05. Table 9 provides the means and standard deviations for the 6 cells for the dependent variables.
To further test the effect of the model artifact on each of the dependent variables, repeated-measures ANOVA was performed [40] . As shown in Table 10 , the main effect of model, the main effect task and the interaction effects of task for accuracy and efficiency. Only the main effect of model is significant for ease of use.

The model type has a significant effect on accuracy (F (2, 42)=40.197, p ease of use (F (2, 42)=10.876, p b 0.001). Pair-wise comparisons (see Table 12 in Appendix B ) further indicate that when compared to ERX, XER generated more accurate results (p b generated more accurate results (p b 0.001) and was more efficient (p To compare the effects of the models across the two types of tasks, One-way ANOVA was performed (see Table 13 in Appendix
B ). Results indicate that for the analysis task, XER generated more accurate results when compared to ERX (p (p b 0.001) and was easier to use when compared to ERX (p b 0.01). There were no significant differences for efficiency across the models. For the design task, XER generated more accurate results, was more efficient when compared to .NET (p and was significantly easier to use when compared to ERX (p Within model comparisons were performed to further elicit the interaction effects of task and model (see Table 14 in
Appendix B ). Results demonstrate that for XER, the accuracy score is significantly lower for the design task when compared to the analysis task (F (1, 14)=15.44, p=0.0015), whereas for .NET it is significantly higher (F (1, 14)=24.08, p=0.0002). Efficien-is no substantial difference. Ease of Use comparisons were not performed as the interaction effect for this dependent variable is not significant.
 One additional comparison of preference was performed using repeated-measures logistic regression (using PROC GENMOD in
SAS). Pair-wise comparisons indicate that XER is preferred more when compared to ERX (Chi-sq: 13.78, p=0.0002) and .NET (Chi-sq: 6.58, p=0.0103) (see Table 15Appendix B ). 6.1. Discussion
The study compared the accuracy, efficiency and satisfaction of XER when compared to the other modeling artifacts: ERX and .NET. Results demonstrate the superiority of XER over the other modeling artifacts, in both the analysis and design tasks for XML applications.
 scores were45% higher compared to ERXand 120% higher when compared to .NET. For thedesigntask, theaccuracy scoreswere com-scores. Thus, XER was found to be better suited for both analysis and design tasks, when compared to ERX and .NET.
Additional statistical analyses yielded some interesting results. The interaction effect of the task and the model encouraged comparison of the differences between the tasks within each model, for each dependent variable. XER achieved higher accuracy efficiency, the design task was performed in 45% less time when compared to the analysis task using ERX, followed by 36% for artifacts are probably better suited for design tasks more so than analysis tasks.

More than 95% of the subjects in the XER condition preferred it over the XML Schema for both the tasks, whereas in the other other modeling artifacts.

Thus, results indicate that XER performs better on both objective and subjective aspects. XER generated more accurate, more efficient and more satisfying results in both analysis and design tasks when compared to ERX and .NET. However, there are a few limitations in the study that we discuss below to ensure a complete and unbiased explanation of the results and analyses. 6.2. Limitations This section discusses potential limitations of the study concerning student subjects, ordering of tasks and training procedure.
These students were part of a graduate course that the primary researcher was handling, and hence represent a convenience sam-tabases, conceptual modeling and XML, these students represent an appropriate sample for the target population, i.e. those people who are more likely to develop XML databases and schemas and hence appropriate. Second, the ordering of the tasks was kept constant for each of the modeling treatments. To make effective comparison between the tasks, it is suggested that the ordering of the tasks be blocked (or randomized) across treatments especially when one employs repeated-measures design [42] . However, consistent ordering of the tasks may not have had a confounding effect on the interpretations. Third, the experimental procedure was performed over two days, which poses the question the differential effectiveness of the training, with respect to the treat-ments received by each subject. Subjects might fail to remember some key issues while solving the tasks, or may have received additional information on any one of the treatments between the days. To counter this, subjects were randomly assigned to the treatment conditions on the second day and were allowed to refer to materials while solving the tasks. However, no post-hoc measures were collected for the effectiveness of the training, and hence could not be compared. Thus, even though limitations exist, they did not constitute any serious threat to the findings. 7. Contributions and conclusion
XER provides a novel method for providing a conceptual presentation for XML. Typically XML document structures are repre-sented using DTDs or XML Schema, both heavily textual formats and often fairly complex to understand in their written or printed forms. XER is an extension to the ER model to represent all the nuances of XML. It provides mechanisms for forward and reverse translations for going back and forth between the visual and textual views and also provides a means for quality assessment of
XML data designs. The prototype implementation is capable of performing all the transformations presented in this paper, and has shown its robustness by preserving the schema structure through multiple up and down translations. Given that the up and down translations are implemented as XSLT transformations, an XML Schema, reverse translated into XER, and then forward translated to a new schema maintains a mapping between the original XML Schema and the generated schema, and hence no of the underlying domain model, but provides users with a conceptual view of the model, and allows the user to then improve on the design based on long-understood modeling principles.

Commercial and industry applications of XER constitute an important effect of the methodology presented in this article. De-velopment of XML applications falls within the overall bounds of software development, and hence a strong design cycle is def-initely required for the purpose of successful implementation of software projects involving XML data. Although a new level of design is introduced by including a conceptual modeling stage in XML data design, such a stage is commonplace in other data-driven application development domains such as the relational and object-oriented domains. Studies on relational and object-oriented designs show that a conceptual modeling approach not only improves the designs, but also improves user performance field of XML application development, a result that should assist XML application developers in improving designs as well as en-hancing design and analysis performance of developers and users.

While XER provides a method that designers of small-to-medium scale application can use to simplify and expedite the design process, it suffers from some of the same weaknesses that other visual design concepts (ER, UML, Flowcharts) suffer from designs do not scale very well. For very large schema, XER models can also be fairly large, and hence a multi-level model (e.g., cepts such as namespaces, Xlink and Xpointer. Other limitations of XER that were not addressed in the current implementation include the  X  ANY  X  content type, which allows an element to have any other element in the schema in its content. However, such a design, when literally mapped into XER, would result in a fully connected and unusable model. A project-based study where user performance in team projects involving XML application development including frequent requirement modifications, should determine whether or not XER can be used appropriately in a commercial project development settings. However, given and users alike, both for the purposes of design and analysis of XML applications.
 Appendix A. Empirical study models and tasks Models used for XML analysis task
References
Appendix B. Details of analysis results
