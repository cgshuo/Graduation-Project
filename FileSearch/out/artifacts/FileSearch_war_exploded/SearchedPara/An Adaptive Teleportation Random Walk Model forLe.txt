 Social tags are known to be a valuable source of information for image retrieval and organization. However, contrary to the conventional document retrieval, rich tag frequency in-formation in social sharing systems, such as Flickr, is not available, thus we cannot directly use the tag frequency (analogous to the term frequency in a document) to repre-sent the relevance of tags. Many heuristic approaches have been proposed to address this problem, among which the well-known neighbor voting based approaches are the most effective methods. The basic assumption of these methods is that a tag is considered as relevant to the visual content of a target image if this tag is also used to annotate the vi-sual neighbor images of the target image by lots of different users. The main limitation of these approaches is that they treat the voting power of each neighbor image either equally or simply based on its visual similarity. In this paper, we cast the social tag relevance learning problem as an adap-tive teleportation random walk process on the voting graph. In particular, we model the relationships among images by constructing a voting graph, and then propose an adaptive teleportation random walk, in which a confidence factor is introduced to control the teleportation probability, on the voting graph. Through this process, direct and indirect re-lationships among images can be explored to cooperatively estimate the tag relevance. To quantify the performance of our approach, we compare it with state-of-the-art methods on two publicly available datasets (NUS-WIDE and MIR Flickr). The results indicate that our method achieves sub-stantial performance gains on these datasets.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Social Tag Relevance, Neighbor Voting, Random Walk
With the advance of social media sharing platforms, such as Flickr, users are allowed to upload personalized photos and annotate these photos with freely chosen tags. These user contributed tags bring a new way to retrieve and or-ganize the huge volume of photos available online, and re-cently have attracted increasing attention among the re-search and commercial communities. However, tags con-tributed by common users are known to be ambiguous, in-complete, and personalized [23, 13], which makes it an ob-stacle to utilize tag information for image retrieval and or-ganization. Moreover, another obstacle is the lack of rele-vance information in the tag list of images. For example, on the Flickr website, the tag frequency information is not available, and the order of the tags of an image does not reflect any relevance level information (e.g., a tag in the top positions does not indicate its relevance is higher than the relevance of a tag in the bottom positions). Thus a funda-mental problem is how to accurately and efficiently learn the relevance of a tag with respect to the visual content the tag is describing 1 . To be precise, a tag is considered as relevant to an image if the tag accurately describes objective aspects of the visual content [13].

Over the years, many approaches have been dedicated to cope with the tag relevance learning issue. In [14], Liu et al. proposed an approach to automatically learn relevance score of each tag for an image. This method first leveraged the Kernel Density Estimation to estimate the initial tag relevance and then a random walk was performed to refine tag relevance by further exploring the relationships between tags through a tag graph. The learnt relevance scores are used for ranking tags of the target image. The work in [25] proposed to learn tag relevance by taking into account three kinds of correlations: tag co-occurrence, tag visual corre-lation, and image conditioned tag correlation. Specifically, they adopted the Rankboost [5] to learn an optimal combi-nation of these multi-modality correlations, and generated a ranking function for tag recommendation.

The most related work to ours are [13, 12, 22], which em-ploy different neighbor voting strategies for learning tag rele-vance for tag-based image retrieval. Li et al.[13, 12] proposed to learn tag relevance by accumulating the neighbor votes received from these visually similar images of the target im-age. The learnt tag relevance scores are then embedded into the classical OKAPI-BM25 model for tag-based image re-
For simplicity, hereafter we use  X  X he tag relevance X  to denote  X  X he relevance of tag with respect to the images that the tag is describing X . Figure 1: The relationship between intra-class sim-ilarity (diagonal blocks) and inter-class similar-ity (non-diagonal blocks). Warmer colors indicate higher visual similarities and colder colors indicate lower visual similarities. trieval. The main limitation of this method is that it treats the voting power of each visual neighbor equally. Due to the existence of noisy or less relevant tags in images, this will inevitably hurt the learning performance. In order to tackle this problem, a variant method [22] is proposed by Truong et al. In [22], they claim that different visual neighbors should have different voting weights, and they exploit four content and contextual features (i.e., image similarity, tag match-ing, tag influence, and refined tag relevance) for estimating the voting weights. Experimental results show that signifi-cant improvements are achieved only based on the content feature, while other three features have not shown to have beneficial effects on the performance.

Although these neighbor voting methods (e.g., weighted and unweighted) are simple and have achieved encouraging results, directly using visual similarity as the voting weights will inevitably be affected by the semantic gap(the gap be-tween the low-level features and high-level image semantic concept [20]). Specifically, visual similarity can not effec-tively reflect the semantic relationship between images. To illustrate this problem, we randomly sample 10,000 images from 10 different classes (e.g., animal, buildings, dog, flow-ers, horses, sky, sports, sunset, tower, window) with 1,000 images per each class, and compute their intra-class simi-larities (i.e., average image similarity within the same class) and inter-class similarities (i.e., average image similarity be-tween different classes). Figure 1 illustrates the relationship between intra-class similarity (diagonal blocks) and inter-class similarity (non-diagonal blocks). From Figure 1 we can see that many intra-class similarities are smaller than some of the corresponding inter-class similarities, e.g., the intra-class similarity of the concept  X  X lower X  is much smaller than its corresponding inter-class similarity with the concept  X  X orse X .

In this paper, we propose a unified voting framework which can seamlessly integrate the relationship information among images into the general neighbor voting schemes through a novel random walk process. To this end, we first exploit the relationship information among images by constructing a novel graph, called voting graph. In the voting graph, we consider these tagged visual neighbors 2 as the nodes. More-over, there is a direct edge from node i to node j if and only if node i appears in the k visual nearest neighbors of node j . The k visual nearest neighbor set of node j is cal-culated for the entire image set, which means it can contain both tagged and untagged images. This can be interpreted in that image i will compete with all other images in the image set, including both tagged and untagged images, and there is a direct edge from node i to j only when i can win a position in the k visual nearest neighbor set of node j (More details about the construction of voting graph are given in Secion 3). Furthermore, we propose a novel random walk model, called adaptive telepotartion random walk model, to learn relevance scores based on the voting graph. In exist-ing random walk models, such as time-homogenous random walk (e.g., PageRank [18], Personalized PageRank [8]) or time-variant random walk (e.g., DivRank[16]), each node has the same fixed teleportation probability(e.g., 1  X   X  ) to randomly transit its scores to an arbitrary node. However, our new model considers involving a new factor, called con-fidence factor (see Section 4.1), where a node with a larger confidence factor will assign a relative high proportion of its score to vote the corresponding neighbors, otherwise it will assign a high proportion of its score to do teleportation in order to reduce the risk of incorrect voting.

We conduct extensive experiments on two publicly avail-able image datasets: NUS-WIDE [3] and MIR Flickr [7], which consists of 269,648 and 25,000 images, respectively. Experimental evaluations demonstrate that by further ex-ploiting the relationships among all visual neighbors through the voting graph, the proposed method can significantly im-prove the effectiveness of tag-based image retrieval.
Overall, the main contributions of this work includes:
The rest of the paper is organized as follows. In Section 2, we give a brief review of related works. Section 3 describes the construction of the voting graph. Our adaptive tele-portation random walk algorithm is introduced in Section 4. Section 5 shows the experimental results of our empirical studies, and finally conclusions are made in Section 6.
For convenience, we call all the visual neighbors which have been annotated by the given tag as tagged visual neighbors, and the remaining visual neighbors as untagged visual neigh-bors.
In this section, we briefly review two research topics which are closely related to our work: social image tag relevance learning and random walk.

Social Image Tag Relevance Learning. Over the years, due to the increasing amount of tag information avail-able online, social image tag relevance learning has received a considerable attention in the research community.
Li et al. [13, 12] proposed to learn tag relevance by em-ploying a neighbor voting strategy (i.e., accumulating votes from visual similar neighbor images). The assumption of this method is that a tag is considered as relevant to its annotated image if it is also adopted by different persons to annotate other visually similar images. In this approach, for a given image d (called target image), its k -nearest neigh-bors, denoted by N k ( d ), are first obtained based on some visual similarity measurements (e.g., Euclidean similarity). Then for each tag t in image d  X  X  tag list, denoted by T the relevance of t is measured by the number of neighbor images in N k ( d ) which are also annotated by the tag t . The experimental results demonstrate that the neighbor voting algorithm is a good measure for both image ranking and tag ranking. In [21], Sun et al. also compared three tag rele-vance formulations, namely, unit relatedness, tag position, and neighbor voting. Their experimental results demon-strate that neighbor voting achieves the best performance for singe-tag queries in the image search task, while obtain-ing comparable performance to other two formulations for multi-tag queries.

In [22], a variant of the neighbor voting algorithm is pro-posed. In this work, Truong et al. suggested to exploit a content-based feature (image visual similarity) and three context-based features (tag matching, refined tag relevance, and tag influence) of social images, and incorporate these features in the neighbor voting framework. Based on these features, different neighbor voting schemes are investigated and the results show that only the content-based feature can significantly improve the accuracy in tag relevance learning for tag-based image retrieval. To be precise, the content-based feature was used to measure the voting weights of the visual neighbors. We call this method weighted neighbor vot-ing . The main limitation of this method is that using the visual similarity as the neighbor voting weights may suffer from the semantic gap problem (i.e., gap between low-level images features and high-level semantic concepts).

In existing neighbor voting schemes, the voting power from neighbor images are either treated equally [13, 12] or simply weighted based on their visual similarity [22], thus they have not effectively exploited the relationship among these visual neighbors. Our model differs from these neigh-bor voting methods in that we formulate the learning tag relevance problem as an adaptive teleportation random walk process on the voting graph. The basic idea of our approach is that we attempt to boost the structure information of these visual neighbors for better estimating tag relevance.
Random Walk. Random walk has been successfully adopted in a broad range of applications, such as web search [18, 6], community detection[9, 19], recommender system[11, 17], and so on. A random walk on a given (either directed or undirected) graph G is a Markov process, where each node represents a state and a walk transiting from the state i to the state j is based on a transition probability matrix P .
Since the graph G may not be strongly connected, the convergence of the Markov process is not guaranteed. In [18], L. Page et al. proposed the well-known PageRank al-gorithm. In PageRank, at each step, the surfer either jumps to an arbitrary node or follows one of the out-going edges of the current node. Formally, the random walk process of PageRank can be defined as where P is a transition matrix, r t is the importance score vector of all pages at step t , and  X  is a damping factor (also called teleportation probability) which controls how often the surfer jumps to an arbitrary node, v is a uniform distri-bution , with elements 1 /N , where N is the number of nodes in the graph. We can also substitute the uniform distribu-tion v in Eq. 1 with other distributions by incorporating the prior preference of visiting certain kinds of nodes. In this case, the random walk process then yields the famous Personalized PageRank[6, 8].

Recently, there are some works oriented towards using a random walk for estimating tag relevance. For example, in [14], Liu et al. proposed to construct a tag graph in order to take into account the relationship among tags. In the tag graph, the nodes are the tags of the image and the edges are weighted by pairwise tag similarity. Then a random walk is performed over the tag graph for learning the tag rele-vance. Some other works [4, 10] are proposed to model the relationship among images through constructing an image graph, and then performing random walk based methods on the graph. For example, Craswell et al. [4] constructed a click graph, where the nodes are queries or images, and edges indicate clicks. Jing et al. [10] also constructed a similarity graph, where nodes are the images (e.g., the top 1,000 search result images from search engines), and edges are weighted based on their pairwise visual similarity. The limitation of these methods is that they either depend on some external resources (e.g., [14]), or the generated graph is very dense and may contain noisy information (e.g., [4, 10]), thus needing more computational effort and possibly being inaccurate.
 In our work, we do not depend on any external resource. Besides, our voting graph is a sparse graph which only con-siders tagged images of the query tag as the nodes, and can be computational effective. At last, contrasting to the ex-isting random walk and its variants [6, 8, 16], which use a same fixed teleportation probability across all nodes in the graph, we introduce an adaptive teleportation random walk process. We will illustrate in Section 4 the rationality of our proposed models in dealing with the task of learning tag relevance.
In this section, we formally define the notations and in-troduce the concept of voting graph .

Given a tag t , let X = { x 1 ,x 2 ,  X  X  X  ,x n } be the set of fea-ture vectors for all images annotated by the tag t , where x  X  R d represents the feature vector of the i -th image in X and n is the number of images annotated by t . Let N k ( i ) denote the k nearest neighbor set of image i based on met-rics such as the Euclidean distance or cosine distance. It is worth noting that for computing N k ( i ) we consider not only images annotated by t , but also account for images which are not annotated by t . That is, we take into consideration the entire image set for finding the k nearest neighbor set N ( i ) for an image i .
Definition 1. (Voting Graph). A voting graph G = ( V,E ) is a directed graph where nodes are images in X , i.e., images annotated by a given tag t . There is an edge e = ( i,j )  X  E if and only if image i appears in N k ( j ) .

Both our voting graph and the typical k -NN graph [24] compute the k nearest neighbor set N k ( i ) from all images without considering whether these images are annotated by the given tag t or not. However, these two graphs use differ-ent set of images as the nodes, e.g., in existing k -NN graph models, nodes are all the available images, while our vot-ing graph uses only images annotated by the given tag t as nodes 3 .

The construction of the voting graph can be summarized as follows: 1. For the given tag t , we gather all the images annotated 2. For each image j in X , we get its k nearest neighbors 3. Set the edge weight w ij based on the visual similarity
Figure 2 illustrates how a voting graph is constructed. For a given tag,  X  X ar X  in this example, there are 6 images asso-ciated with it in the dataset. In each row, the image on the left side of the vertical dashed line is the tagged image, and the images on the right side are its k ( k = 5 in this case) nearest neighbors. Notice that the images on the right side may contain both tagged images (marked with red frame) and untagged images. A solid arrow represents a directed edge from a neighbor image on the right side to the tagged image on the left side . Figure 2(b) corresponds to the re-sulting voting graph where each node represents a tagged image (i.e., the image annotated by the given tag  X  X ar X ), and each directed edge from node i to node j represents that image i appears in the k nearest visual neighbor of image j .
After we construct the voting graph, the next step is to measure the tag relevance. There are many methods that can be adopted to compute the relevance based on the con-structed voting graph. For example, we can directly con-sider using the in-degree, denoted as d  X  i , of each node i in the voting graph as the tag relevance measurement, which is equivalent to adopting the standard neighbor voting ap-proach as mentioned in [12, 13]. Moreover, if we further take into account the weight of the edges when we aggregate the in-degree as the tag relevance measurement, then we get a variant of the standard neighbor voting model. This model is equivalent to the weighted neighbor voting algorithm pro-posed in [22] which was proved to have best performance in the empirically evaluation 20 different neighbor voting schemes. The limitations of these methods have been dis-cussed in Section 2. In the next section, we will introduce
Here our purpose is to learn these user contributed tags with respect to the visual content of their annotated images. our approach, which performs an adaptive random walk on the voting graph in order to learn the tag relevance.
In this section we first introduce the concept of confidence factor , and then seamlessly encode it into the standard ran-dom walk process in a unified way. Finally, we theoretically analyse the mathematical property of our model, and prove that the novel model still holds a convergence property.
In the scenario of learning tag relevance, the link from one image to another image is strictly constrained by their visual similarity, in contrast to the Web link graph scenario where links can be freely added by the content owners. Fur-thermore, while in the web page search scenario the nodes of the graph probably come from different concepts, in our case, since all the images in the voting graph are the im-ages annotated by general users for describing a specified concept, they can be seen as the exemplars of the concept. If an image has many out-link neighbors in the graph (i.e., it frequently appears in the neighbor image set of other ex-emplar images), then it indicates that the image is similar to the exemplar images of the concept, and should be more related to the concept represented by the exemplars.
In this work, we make use of the above property and intro-duce a novel factor, called confidence factor , into the stan-dard random walk process. The confidence factor reflects what proportion of the score of a node is used for voting its out-link neighbors. To be precise, nodes with a large number of out-link neighbors will comparably devote larger scores for voting on their out-link neighbors than those nodes with less out-link neighbors. In summary, the confidence factor of node i is formulated as follows, where d + i is the number of out-link neighbors of node i .  X  is introduced to control the degree of the impact of the number of out-link neighbors. When  X  = 1, c i is proportional to the number of out-link neighbors of i . When  X  = 0, our model will regress to PageRank, where all nodes have the uniform confidence, i.e., c i = 1. If 0 &lt;  X  &lt; 1, then nodes with a small number of out-link neighbors will be boosted to have relatively higher confidence values. If  X  &gt; 1, then nodes with a large number of out-link neighbors will be boosted to have relatively higher confidence values.

In our experiments,  X  is empirically set to 1.0. In Sec-tion 5.6, we will give a detailed discussion on the impact of parameter  X  .
Whereas in previous random walk methods, walkers can either follow out-links with probability  X  or teleport to a random node with probability 1  X   X  , in our model, each node will have an adaptive teleportation probability. Specifically, the teleportation probability is determined not only by the probability 1  X   X  (1  X   X  is the typical setting in previous random walk algorithms), but also by the confidence factor c ( i = 1 , 2 ,  X  X  X  ,n ). Formally, the teleportation probability of a node i is equal to (1  X   X  ) + (1  X  c i )  X   X  , where the first edge from node i to node j shows that image i appears in N item can be considered as the prior teleportation probability which is identical for all nodes, and the second term can be considered as the observed teleportation probability which relies on the confidence factor c i of the node i . Thus the combined teleportation probability can be seen as a posterior probability.

Intuitively, the adaptive teleportation process can be ex-plained as follows: when the current node has a high con-fidence factor, then walkers will follow the out-links with a higher probability and contribute most of the voting impact to its out-link neighbors. Otherwise, walkers will more likely teleport to a random node, and devote less voting impact to out-link neighbors in order to reduce the risk of incorrect voting. Let us denote by P an n -by-n transition matrix, where an element p ij indicates the probability of transition from node i to node j and it is computed as where w ij denotes the visual similarity between node i and j (see Eq. 2). For a given voting graph G = &lt; V,E &gt; with n nodes, let r t be a vector whose i -th element r t ( i ) indicates the relevance score of node i at step t . The novel adap-tive telepotation random walk process is then formulated as follow: where v j is the initial probabilistic relevance score of tag t and c i is the confidence factor defined in Eq. 3.
It is worth noting that the new random walk process still converges to a stationary distribution. Let  X  denote the di-agonal matrix with diagonal elements equal to ( c 1 ,c 2 ,  X  X  X  ,c Let e = (1 , 1 ,  X  X  X  , 1) T denote the vector of all ones, where the superscript T denotes the transpose. Let I denote the n  X  n identity matrix, and let v = ( v 1 ,v 2 ,  X  X  X  ,v n ) after, we will prove the convergence property of the iteration of Eq. 5.
 Lemma 1. For all P ,  X  ,  X  , and v , ( I  X   X  ( P T  X  + ve  X ))) is invertible.

Proof. Let Q = P T  X + ve T ( I  X   X ), then we should prove that ( I  X   X  Q ) is invertible. It is equivalent to prove that its transpose ( I  X   X  Q T ) is invertible. For this purpose, we need prove that ( I  X   X  Q T ) x = 0 only has a trivial solution x = 0. Note that 0  X  c i P ij +(1  X  c i ) v j  X  1  X  i,j (since min { P c
P ij + (1  X  c i ) v j  X  max { P ij ,v j } ), and P j ( c c ) v j ) = c i P j P ij +(1  X  c i ) P j v j = 1  X  j . Let m = arg max { x x m =  X  P j ( c m P mj + (1  X  c m ) v j ) x j  X   X  P j ( c m c ) v j ) x m =  X x m . Thus, (1  X   X  ) x m  X  0 and x m  X  0. Simi-larly, let M = arg max { x i } , we also have (1  X   X  ) x M x m  X  0. Thus x i = 0  X  i .

Theorem 2. The iteration of Eq.5 converges to
Proof. Eq.5 can be rewritten in the matrix form
Let Q = P T  X  + ve T ( I  X   X ), then we have and thus we have Note that transition matrix P has been row normalized to 1, and v is the probabilistic relevance score (i.e., P i v For 0 &lt;  X  &lt; 1, there exists  X  &lt; 1, such that  X  &lt;  X  , and we can derive that
X Thus the column sums of (  X Q ) n converges to zero. Then according to Eq. 11 and Lemma 1 we have which is the unique stationary distribution.

Although the closed-form solution is derived, in practice, the iterative process (See Eq. 5) is more preferable.
For a given query tag, we first construct a voting graph for all images annotated by the tag. Then we perform the adaptive teleportation random walk algorithm over the vot-ing graph in order to learn the relevance score of each tagged image (i.e., the relevance of the query tag with respect to the visual content of that tagged image.). Finally, all images are ranked according to their relevance scores.

We propose two versions of our method according to whether the visual similarity is used as an edge weight in the vot-ing graph or not. The first method is running the adap-tive teleportation random walk over the unweighted voting graph, where all edges in the voting graph have the same weight w ij = 1, and the second method is performing over the weighted voting graph, where edges in the voting graph are weighted based on their visual similarity as defined in Eq. 2. For simplicity, let us call the method over the un-weighted voting graph Graph Voting (GV), and the one over the weighted voting graph Weighted Graph Voting (GV-W). It is natural to perform a standard random walk, such as PageRank, on the voting graph, and use the estimated node importance scores as the tag relevance. Although random walk models have achieved great success, directly adopting random walk for social tag relevance learning on the voting graph is problematic. In Figure 3, we illustrate the problem of performing a random walk on our voting graph for tag relevance learning and compare its performance with our proposed method. Intuitively, a good tag relevance learning method should satisfy the following two voting assumptions.
Assumption 1: The voting impact from a highly relevant voting node 4 should be higher than the voting impact from a less relevant voting node.

Assumption 2: The voting impact from many voting nodes should usually be higher than the voting impact from fewer voting nodes.

As we can see from Figure 3(a), the importance scores learned by a standard random walk do not fulfill the as-sumption 1 for learning tag relevance. For example, it is reasonable that node 5 should have a higher score than node 9, since node 5 has a more relevant voting node (node 3) than the voting node (node 4) of node 9. While the results of standard random walk method show that node 9 receives a much higher score (0.160) than the node 5 (0.107). Figure 3(b) shows the results of our proposed method. Compared with the results of standard random walk in Figure 3(a), our method has a more reasonable results. For example, in our method node 5 receives a relatively higher score (0.117) as compared with the score (0.113) of node 9.

In Figure 3(a), we also observe that the assumption 2 has not been satisfied by performing a standard random walk. For example, the score (0.160) of node 9 is nearly close to that (0.164) of node 3, and much higher than the score (0.103) of voting node 4. While in our model, the score (0.113) of node 9 become close to the score (0.109) of its vot-ing node 4, and much more small than the score (0.128) of node 3 which has two voting nodes (node 1 and node 2).
These observations can be attributed to the fact that in the standard random walk (e.g., PageRank), as defined in Eq. 1, all nodes share the same fixed teleportation proba-bility, determined by the parameter  X  . In other words, the walker will jump to the neighbor nodes with probability  X  , and jump to an arbitrary node with probability 1  X   X  . By considering the jump probability as a type of voting impact from one node to its out-link neighbors, nodes with large out-degree will consequently have a slight voting impact to each of its neighbors. For example, in the voting graph in Figure 3 (a), node 3 has 4 out-link neighobrs, thus the con-tributed voting power to each of its neighbor is only 1 / 4 of the total impact of node 3. In contrast, node 4 can con-tribute all of its impact to the sole out-link neighbor, since it merely has one out-link neighbor (node 9) .

In the typical Web link graph scenario, a standard ran-dom walk is reasonable, since authors of the Web pages can freely add links to other web pages. Therefore, for nodes with many out-links, the impact to their out-link neighbors
We call all the nodes with a directed edge towards node i as the voting nodes of node i . Figure 3: An explanatory comparison between the standard random walk model and our proposed model. (a) results of standard random walk model. (b) results of our adaptive teleportation random walk model. should be penalized (i.e., discounted by the number of out-link neighbors as in the standard random walk). However this property does not satisfy the requirements in the sce-nario of learning tag relevance through the voting graph.
In this section we present a set of extensive experiments to evaluate the performance of our proposed method on two publicly available datasets, including NUS-WIDE [3] and MIR Flickr [7]. The experimental results demonstrate that our method outperforms state-of-the-art methods for tag-based image retrieval.
The NUS-WIDE dataset [3] collected from Flickr 5 con-tains 269,648 web images with their associated tags. In NUS-WIDE, both global features (such as color histogram, edge direction histogram, and wavelet texture) and local features (such as bag-of-visual words features) are avail-able. In this work, we measure the visual similarity between two images based on 265-D global features, including 64-D color histogram, 73-D edge direction histogram, and 128-D wavelet texture. Furthermore, since the owner information of images has not been released in NUS-WIDE, we crawled this information for 239,891 images 6 . In NUS-WIDE, 81 concepts with manual ground-truth labels are provided and will be used for evaluating the performance of our method.
The MIR Flickr collection [7] consists of 250,00 images, and the original tag data contributed by users. For each image in this dataset, we use Lire [15] to extract 305-D global features, including the 192-D Fuzzy Color and Tex-ture Histogram [2], 33-D MPEG-7 Color layout [1], and 80-D MPEG-7 Edge Histogram [1]. All features are normalized to a zero mean and unit variance. For the evaluation, 17 poten-tial concepts [7], which have more than 100 tagged images, http://www.flickr.com/
Due to link failure, the owner ID of some images are unavailable. Here we also release our crawled owner ID on http://www.l3s.de/  X  zhu/NUS-WIDE OwnerInfo.txt for easily reproducing the experiments.
 Table 1: Statistics of the two publicly available datasets: NUS-WIDE and MIR Flickr. (The num-ber of unique owners and the average number of im-ages per owner in NUS-WIDE are calculated based on our crawled owner information.) are selected as the ground-truth concepts. Table 1 shows basic statistics for both datasets.
To evaluate the performance of each approach, we use both Precision@K and MAP as the performance evaluation measures.

Precision @ K ( P @ K ) . P @ K is a localized evaluation criterion, which measures the ranking quality of the top re-sults. For a given query, it is calculated as the fraction of relevant images of the top-K retrieved results, formally, P @ K = P K i =1 rel ( i ) K , where rel ( i ) is a binary function on the relevance of the i -th instance, rel ( i ) = 1 if the i -th instance is relevant and 0 otherwise. Similar to [22], we choose to re-port P @100 only. For each method, the reported P @100 is the macro-average of P @100 values of all evaluated queries.
Mean Average Precision (MAP) . Average Precision (AP) measures the ranking quality of the entire list. For a given query, the AP value is calculated as where R is the number of relevant instances, N is the number of retrieval instances, R i is the number of relevant images in the top i ranking list. To evaluate the overall performance, we get the Mean Average Precision (MAP) by averaging the AP values over all the queries.
To evaluate the performance of our methods for tag-based image ranking, we compare them against (a) Neighbor Vot-ing (NV) [12, 13], (b) Weighted Neighbor Voting (NV-W) [22], (c) Random Walk(RW), and (d) Weighted Random Walk (RW-W). NV uses the frequency of a tag in the vi-sual neighbors of the target image as the tag X  X  relevance to that image. NV-W further take into account the visual simi-larities between the visual neighbors and the target image as the voting weights in a neighbor voting framework. In order to gain in-depth insights into the effects of importing the adaptive teleportation in the random work process, we also compare our methods with two random walk based meth-ods: RW and RW-W. RW is a method which performs a standard random walk over the unweighted voting graph for learning the tag relevance, and RW-W performs a standard random walk on the weighted voting graph.
For a fair comparison of the different methods, the number of nearest neighbors k are set to the same value (e.g., k = Table 2: Performance of different methods on the metric MAP and P@100. The  X  (  X  ) indicates statis-tical significance at p-value &lt; 0.05 using the Student X  X  t-test with regard to the baseline NV (NV-W). The underline indicates the best performance.
 Method NUS-WIDE MIR Flickr MAP P@100 MAP P@100 NV 0.3766 0.7406 0.2918 0.8906 NV-W 0.3778 0.7480 0.2921 0.8935 RW 0.3526 0.6336 0.2869 0.8571 RW-W 0.3531 0.6359 0.2871 0.8559 GV 0.3788  X   X  0.7453  X  0.2921 0.8918
GV-W 0.3790  X   X  0.7501  X   X  0.2923 0.8965  X  100) for all methods. A detailed discussion of the impact of parameter k to our methods is given in Section 5.6. For NV-W, RW-W, and GV-W, the radius parameter  X  in Eq. 2 is set to the average Euclidean distance of all images (i.e.,  X  = 6 . 7 in NUS-WIDE and  X  = 22 . 48 in MIR Flickr). The parameters  X  and  X  are set to their optimal values (e.g.,  X  = 0 . 85 and  X  = 1 . 0).

The evaluation results on both NUS-WIDE and MIR Flickr datasets are shown in Table 2. For each method, we report the MAP and P@100. For each column in Table 2, we have underlined the best performer. The statistical significance of improvement was assessed using the Student X  X  paired t-test, and p-values less than 0.05 were used to reject the null hypothesis.

As can be seen from the results, in the NUS-WIDE dataset, our method GV-W significantly ( p  X  value &lt; 0 . 05 ) out-performs all the four baselines on both metrics MAP and P@100. The reason is because GV-W simultaneously takes into account both the relationship information among neigh-bor images and their visual similarity for learning tag rele-vance.

Generally, the weighted methods (e.g., NV-W, RW-W, and GV-W) are better than the unweighted methods (e.g., NV, RW, and GV) on MAP and P@100. Moreover, among all three unweighted methods (NV,RW, and GV), our method GV is significantly ( p  X  value &lt; 0 . 05 ) better than the other two baselines NV and RW, which is due to the fact that tag relevance can be estimated more accurately by further con-sidering the structure information among neighbor images. It is worth noting that the random walk based voting meth-ods (i.e., RW and RW-W) have the worst performance. As we explained in Section 4.5, directly using existing random walk methods may hurt the voting since these methods share a fixed teleportation probability for all nodes in the random walk process. This is the main motivation for introducing an adaptive teleportation process into the standard random walk for better voting. In the MIR Flickr dataset, similar results are observed.
In this section, we further analyse the performance of our methods over different categories of images. To this end, we group the 81 concepts in the dataset NUS-WIDE into 6 categories 7 : events (e.g., dancing), program (e.g., sports), scene (e.g., sky), people (e.g., police), objects(e.g., horses),
We use the the concept taxonomy provided in [3] to group the concepts.
 Table 3: Group Analysis on NUS-WIDE based on the metric MAP. The underline indicates the best performance.
 Category NV NV-W RV RV-W GV GV-W Events 0.332 0.333 0.285 0.286 0.337 0.335 Scene 0.344 0.347 0.317 0.317 0.345 0.347 People 0.391 0.394 0.376 0.377 0.395 0.396
Objects 0.438 0.438 0.403 0.403 0.440 0.439 and graphics(e.g., map). Since the categories program and graphics have solely 1 concept each, we report here only the other 4 categories: events, scene, people, and objects, which have 9, 33, 4 and 33 concepts, respectively.

The evaluation results for all methods on the NUS-WIDE dataset in terms of MAP are shown in Table 3. We can no-tice that the random walk based methods (RW and RW-W) have the worst performance over all 4 categories. Neigh-bor voting based methods (NV and NV-W) perform better than the two random walk based methods (RW and RW-W). Moreover, our proposed methods (GV and GV-W) are con-sistently outperforming both neighbor voting based methods and random walk based methods on all categories.

This observation confirms that our proposed methods (GV and GV-W) can achieve better performance than all base-lines for different categories of concepts.
In this section, we conduct experiments to analyze the sensitivity of our methods with respect to the parameters: k ,  X  ,  X  and  X  .
The parameter k represents the number of nearest neigh-bors considered, and controls the density of the voting graph. When k is small, less edges are generated for building the voting graph. However, when k becomes large, the con-structed voting graph will have more edges and become denser.

For this set of experiments, we fix the other parameters to the following values:  X  = 1 . 0,  X  = 0 . 85, and  X  is set to 6 . 7 in NUS-WIDE and 22 . 48 in MIR Flickr. We use MAP as the performance measure. Figure 4 shows the change in performance when k is varied in the range from 100 to 1000 with a step length of 100. We can observe that on the NUS-WIDE dataset, the MAP gradually increases as k increases, and the increasing rate becomes small after k &gt; 400. On the MIR Flickr dataset, the MAP first increases when the k varies from 100 to 200, and start to decrease as k &gt; 200. This happens because when given more nearest neighbors, more useful relationship information can be used for constructing the voting graph. On the other hand, when k becomes too large, noisy relationships would be introduced into the voting graph and hurt the performance. It is also worth noting that for the concepts in the MIR Flickr dataset, the average number tagged images is much smaller than that in NUS-WIDE, thus it suffers an early drop in performance on the MIR Flickr dataset.
The parameter  X  in Eq. 3 controls how the number of out-link neighbors affects the confidence value. In our ex-Figure 4: The impact of number of nearest neigh-bors k to our proposed methods GV and GV-W on NUS-WIDE (Above) and MIR Flickr (Below) periments, we vary  X  in the range 0 to 2 with a step size of 0.2, and use MAP as the performance measure. The results are shown in Figure 5. We can see that on both datasets the performance increases as  X  increases until  X  = 1 . 0; when  X  &gt; 1 . 0, there is a slight decrease of the performance. This is because with a small  X  value, the adaptive teleportation random walk model will have nearly the same teleportation probabilities for all nodes, and regress to the standard ran-dom walk model. While  X  gets too large, the useful informa-tion from these nodes with less number of out-link neighbors will be omitted. The best setting is  X  = 1 . 0, which indicates that the confidence value of each node should be linearly proportional to the number of its out-link neighbors.
We also conduct experiments to analyse the impact of the parameters  X  and  X  . Due to space limitations, here we directly report the results.

The parameter  X  in Eq. 5 can be considered as a pa-rameter which controls the prior teleportation probability. We vary  X  from 0.1 to 1.0 with step size 0.1, and observe that our methods are not very sensitive to  X  as compared with the case of standard random walk based methods. This is because in the random walk based methods the telepor-tation probability is exclusively determined by  X  , while in our methods this probability will be characterized by both parameters  X  and  X  .

The parameter  X  in Eq 2 will affect the sensitivity of the similarity measure. When  X  is small, neighbor images which are very close to the target image will have a larger similar-ity, thus have more voting power in the weighted version method, i.e., GV-W. On the contrary, when  X  is large, al-Figure 5: The impact of parameter  X  to our pro-posed methods GV and GV-W on NUS-WIDE (Above) and MIR Flickr (Below) most all neighbor images will have similar voting powers. At the extreme,  X  can be set to infinity which will result in all neighbor images having equal voting power, in this case GV-W will regress to GV. We varied the value of  X  from 2 to 100 with step size 2, and find the optimal value is around the average Euclidean distance of all images in each dataset.
In this paper, we have presented a novel framework for learning social tag relevance. We show that the relation-ships among visual neighbors may embed rich information which can be further exploited to boost the neighbor voting performance. In particular, these previous neighbor voting methods can be considered as a flat voting, which heavily rely on the visual similarity between images while neglect the structure information among images. While our pro-posed methods can be considered as a structured voting, where the relationships among images are further exploited. To this end, we introduce an adaptive teleportation random walk model and prove theoretically that the proposed model can converge to a stationary distribution and also give its closed-form solution. Experimental results show that our method outperforms existing tag relevance learning algo-rithms for the tag-based image retrieval.

For future work, we would like to apply the proposed method in other applications, such as web search, query recommendation. By further considering each node X  X  confi-dence information, our adaptive teleportation strategy may help to improve the performance in these applications. Be-sides, we will also investigate using the textual information to reduce the noise propagation in the voting graph since there still exists some incorrect relationships in the graph. This research work was partially funded by the European Commission FP7 under Grant No. 287704 (CUbRIK). [1] S. F. Chang, T. Sikora, and A. Puri. Overview of the [2] S. A. Chatzichristofis and Y. S. Boutalis. Fcth: Fuzzy [3] T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and [4] N. Craswell and M. Szummer. Random walks on the [5] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An [6] T. H. Haveliwala. Topic-sensitive pagerank. In [7] M. J. Huiskes and M. S. Lew. The mir flickr retrieval [8] G. Jeh and J. Widom. Scaling personalized web [9] D. Jin, D. Liu, B. Yang, C. Baquero, and D. He. Ant [10] Y. Jing and S. Baluja. Pagerank for product image [11] M. Li, B. M. Dias, I. Jarman, W. El-Deredy, and P. J. [12] X. Li, C. G. Snoek, and M. Worring. Learning tag [13] X. Li, C. G. M. Snoek, and M. Worring. Learning [14] D. Liu, X.-S. Hua, L. Yang, M. Wang, and H.-J. [15] M. Lux and S. A. Chatzichristofis. Lire: lucene image [16] Q. Mei, J. Guo, and D. Radev. Divrank: The [17] K. Onuma, H. Tong, and C. Faloutsos. Tangent: A [18] L. Page, S. Brin, R. Motwani, and T. Winograd. The [19] P. Pons and M. Latapy. Computing communities in [20] A. W. M. Smeulders, M. Worring, S. Santini, [21] A. Sun, S. S. Bhowmick, K. T. Nam Nguyen, and [22] B. Q. Truong, A. Sun, and S. S. Bhowmick. Content is [23] C. Wang, F. Jing, L. Zhang, and H.-j. Zhang. Scalable [24] J. Wang, J. Wang, G. Zeng, Z. Tu, R. Gan, and S. Li. [25] L. Wu, L. Yang, N. Yu, and X.-S. Hua. Learning to
