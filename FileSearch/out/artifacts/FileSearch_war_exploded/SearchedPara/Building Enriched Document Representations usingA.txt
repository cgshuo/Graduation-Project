 It is well known that anchor text plays a critical role in a va-riety of search tasks performed over hypertextual domains, including enterprise search, wiki search, and web search. It is common practice to enrich a document X  X  standard textual representation with all of the anchor text associated with its incoming hyperlinks. However, this approach does not help match relevant pages with very few inlinks. In this pa-per, we propose a method for overcoming anchor text spar-sity by enriching document representations with anchor text that has been aggregated across the hyperlink graph. This aggregation mechanism acts to smooth, or diffuse, anchor text within a domain. We rigorously evaluate our proposed approach on a large web search test collection. Our results show the approach significantly improves retrieval effective-ness, especially for longer, more difficult queries. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation anchor text, web search, link structure, term weighting
One of the most unique characteristics of the web is its dy-namic, human generated hypertext structure. The web has allowed millions of everyday users to publish their own con-tent. Most web pages contain one or more hyperlinks that point to other pages. These links, referred to as anchors , consist of a destination URL and a short piece of text. The short piece of text, which is called anchor text , typically pro-vides a description of the destination URL. For example, the anchor text associated with http://www.acm.org/sigir in-cludes  X  X igir X ,  X  X cm sigir X , and  X  X nformation retrieval X . How-ever, since anchor text is user generated, it may not always be a useful description of the destination URL. For example,  X  X lick here X  which provides no meaningful description of the destination URL, is often used as anchor text.

It is well known that the link structure of the web can be exploited for improving web search, as evidenced by PageR-ank [3] and other link analysis algorithms, such as HITS [15] and SALSA [20]. While link analysis algorithms are use-ful for identifying authoritative pages, most of them only consider the link structure and ignore the anchor text. De-spite the claimed importance of link-based algorithms, an-chor text is arguably the most important piece of evidence used in web ranking functions. Anchor text is so useful be-cause it is similar in nature to queries. Returning to the ACM SIGIR homepage example, it is easy to see that the anchor text  X  X igir X ,  X  X cm sigir X , and  X  X nformation retrieval X  are reasonable queries that users may enter when they are searching for the page. Therefore, the lexical gap between queries and anchor text is relatively small, whereas the gap between queries and document texts is much larger, making anchor text highly useful for matching queries to documents.
However, anchor text is only useful for ranking pages with incoming links. Previous research has shown that the distri-bution of the number of inlinks on the web follows a power law [4]. Thus, a small number of pages will have a large amount of anchor text associated with them, while most will have very little, or no, anchor text. We refer to this as the anchor text sparsity problem . The primary goal of this paper is to overcome this problem by enriching the an-chor text representations of documents, especially for those documents that have little anchor text to begin with. We propose enriching anchor text representations by augment-ing documents with auxiliary anchor text that is derived by aggregating , or propagating , anchor text over the web graph. Given the importance of anchor text for ranking, we hypothesize that retrieval effectiveness can be significantly improved by using these auxiliary anchor text-enriched doc-ument representations. However, the impact of our work is not limited to web search. Indeed, the enriched document representations can be used in a number of other ways, in-cluding estimating improved document models, developing advanced textual matching features, and even improving the quality of document classification algorithms.

Our work has four primary contributions. First, to the best of our knowledge, we are the first to directly formu-late and address the anchor text sparsity problem. Second, we propose a number of methods for aggregating anchor text across the web graph. Third, we propose various ways to use the aggregated anchor text to build enriched document rep-resentations. Finally, we show that our enriched document representations, when used in conjunction with a state-of-the-art ranking function, results in significant improvements in retrieval effectiveness on a very large web test collection. The remainder of this paper is laid out as follows. First, Section 2 surveys relevant related work. Then, Section 3 provides an overview of our proposed anchor text aggrega-tion algorithms. An evaluation of our method applied to a large-scale web search test collection is presented in Sec-tions 4. Finally, Section 5 concludes the paper and describes various avenues for future work.
Anchor text has always been deemed an important source of information for relevance. Brin and Page were one of the first to note the importance of associating anchor text both with the page it occurs on, as well as the page it points to [3]. Anchor text is not only useful for enriching textual representations. Harmandas et al. showed that propagated anchor text was useful for building textual representations of images [12]. Given its importance, anchor text is extensively exploited in most, if not all, commercial search engines, and is useful for a wide range of applications.

Anchor text can be modeled in a variety of ways. Recent work by Fujii [11] describes two techniques for using anchor text within retrieval models  X  one using all anchor text as a surrogate of the original document and the other treating each line of anchor text independently by considering the importance of each line. We adopt a similar approach here, by representing anchor text as individually weighted lines of text.

A great deal of recent work has looked at how to effectively rank structured, or fielded, documents [25, 28, 30]. Robert-son et al. explored an extension of the popular BM25 model to multiple weighted fields in documents [27, 28]. Similar work by Ogilvie and Callan [25], done within the language modeling framework for information retrieval, treats docu-ments as a mixture of field language models, thereby achiev-ing a similar type of ranking function. Our focus here is not to evaluate ranking functions for structured documents. In-stead, our aim is to show the utility of auxiliary anchor text for building enriched document representations. Indeed, the methods described here can be used in conjunction with any retrieval model that takes document structure into account. We will return to BM25F later in this paper, in the context of our experimental evaluation.

As we will show, our proposed approach can be construed as a form of smoothing, in which we smooth the original an-chor text with auxiliary anchor text obtained from the web graph. This is similar in nature to cluster-based smoothing from the language modeling framework [16, 21], except we make explicit use of the web graph, rather than clusters or induced links [17, 22, 31]. Furthermore, the language model-based approaches construct expanded probabilistic repre-sentations of the documents, whereas our approach explic-itly constructs enriched document representations by adding new (weighted) text to documents.

Finally, our approach, although similar in spirit to, dif-fers from the previously proposed approaches for spreading activation [8], link analysis [3, 15], graph regularization [9], score aggregation [29], and term frequency aggregation [26]. Although all of these approaches are branded, or framed, as different problems, they all essentially tackle the same task. The primary difference between these approaches and ours is that we aggregate (weighted) textual representations across the web graph, rather than scores or term frequencies. Our approach is more general, in the sense that the textual rep-resentations that we propagate can be used in a variety of ways, including building enriched document representations and computing textual features, among others.
We now describe our proposed method for aggregating anchor text over the web graph and how the aggregated text can be used to enrich existing document representations.
As described earlier, our proposed method aggregates, or propagates, anchor text along the web graph. The input to our method is a URL u and the output is a weighted set of aggregated anchor text lines . This is achieved in two steps. First, the aggregated anchor text lines are collected. Then, the lines are combined and weighted to produce the final result. The remainder of this section details one possible instantiation of this general framework. However, it should be noted that the idea is quite general. Indeed, the aggre-gated anchor text can be collected and weighted in many different ways beyond the approaches described here. We now describe our specific instantiation of the approach.
We begin by describing how we collect the aggregated an-chor text. Given a URL u , we first collect all pages P , within the same site (domain), that link to u . These links are known as u  X  X  internal inlinks , since they come from within the same site. We then gather all anchor text A from pages that are linked to P from outside the site. This is known as the ex-ternal anchor text , because it originates from pages outside of the site. Thus, in short, the aggregated anchor text for u is the external anchor text of the internal inlinks of u .
Figure 1 illustrates this process by way of an example. In the example, anchor text is being aggregated for the URL http://dancing.com/lindyhop.html . The original anchor text of the page consists of lines such as  X  X indy Hop X  and  X  X wing dancing X , while the aggregated anchor text lines in-clude  X  X avoy Ballroom X  and  X  X ances in New York, X  that are not present in the original anchor text.

This particular approach is used to collect aggregated an-chor text because internal inlinks typically link related pages within a given site. These links are typically created by the owner of the site, and therefore can be considered somewhat authoritative, as opposed to links originating from external sites, which may not be as purposefully generated. It is very important to notice that we do not use the anchor text associated with the internal inlinks in any way, since such anchor text tends to be navigational in nature (e.g.,  X  X ome X ,  X  X ext page X , etc.). This is why we use the external anchor text of the internal inlinks as our source of auxiliary anchor text. Such anchors are less likely to be navigational and are more likely to provide good descriptions of their destina-tion. Therefore, since internal links connect related pages, we hypothesize that the external anchor text of these pages will also be good descriptors, by semantic transitivity, of the URL of interest. being aggregated for the URL http://dancing.com/lindyhop.html.
Next, we describe how the aggregated anchor text lines are combined and weighted. We assume that every line l of anchor text associated with a URL u has some weight wt ( l,u ) assigned to it. Since lines are aggregated from mul-tiple sources (internal inlinks), it is possible that the same line of aggregated anchor text may originate from multiple URLs, each with a potentially different weight. Since we re-quire one weight wt ( l,u ) per distinct line of anchor text, we must combine the weights of lines originating from multiple sources in some way. If we treat the weighted lines of anchor text as result lists, then we can easily apply standard result set fusion techniques to combine the weights [10, 18].
We use the six following weight aggregation functions, in-spired by result set fusion techniques, to weight the aggre-gated lines of anchor text: wt wt
SumMNZ ( l,u ) = | u 0  X  X  ( u ) : wt ( l,u 0 ) &gt; 0 | X where N ( u ) is the set of internal inlinks and wt ( l,u original weight of anchor text line l for URL u 0 . Notice that if some line of aggregated anchor text originates from a single URL u 0 , then the aggregated weight will equal wt ( l,u 0 gardless of the aggregation function chosen. However, when a line originates from multiple URLs, each of the aggregation functions computes the weight differently.

Before moving on, we note that there is no canonical way to compute the original anchor text line weights (i.e., wt ( l,u 0 )), which we assume are calculated a priori . These weights will be computed differently for every search engine implementation. For our purposes, original lines of anchor text are weighted as follows: where S ( u ) is the set of external sites that link to u ,  X  ( l,u,s ) is 1 if and only if anchor text l links to u from some page within site s , and | anchors ( u,s ) | is the total number of unique anchors originating from site s that link to u .
Now that we have described how to collect and weight ag-gregated anchor text, we explain various ways that we can use the output to build enriched document representations. Aggregated anchor text-enriched document representations may be useful for various information retrieval and natural language processing tasks including web search, contextual advertising, text classification, and summarization, to name just a few. The best representation will depend on the task. For completeness, we now briefly describe four possible rep-resentations.

The first representation is the flat representation . Here, all document structure, such as fields, formatting, and meta-data, are ignored. The aggregated anchor text weights are discarded and only the raw text itself is added to the orig-inal document. We do not expect this representation to be particularly useful for most tasks, but is one very simple possibility.

A more reasonable representation is the combined repre-sentation , which preserves the document structure, and aug-ments the original anchor text lines with the aggregated an-chor text lines. The aggregated anchor text weights may also be used here, as long as the search engine X  X  indexing architecture supports it.

One issue with the combined representation is that there may be a great deal of overlap between the original and aggregated anchor text lines. The aggregated anchor text lines may add noise to a set of high quality original anchor text lines. To overcome this issue, the backoff representation only adds aggregated anchor text to documents that do not originally have any anchor text lines associated with them.
Finally, the new field representation adds the aggregated anchor text as a completely new field to every document. Unlike the combined and backoff representations that add the aggregated anchor text to the original anchor text field, the new field representation treats the new lines of anchor text as a new source of evidence. This may be useful for textual features, such as BM25F, that weight the impor-tance of each field separately. In this representation, the original and aggregated anchor text fields can be weighted differently, which may be useful.
We evaluate our proposed anchor text aggregation method-ology and document representation schemes using web search as our task. Web search is a natural choice due to its prac-tical importance, and because our proposed methods are particularly amenable to the task.
Our experiments make use of a large-scale web search test collection consisting of 22,822 queries. For each query, we have judgments for an average of 23 URLs, resulting in 524,418 judged query/URL pairs. Each URL has been judged by a human editor and given a rating as to how rel-evant it is for the corresponding query. This rating is one of Perfect, Excellent, Good, Fair, or Bad.

We chose to use this test collection, rather than one of the standard TREC Web [7], Terabyte [6], or Million Query [1] Track test collections, because it is more characteristic of real web search. In particular, the number of queries and judgments is substantially larger than the TREC web col-lections. Furthermore, the query and document population reflects real systems better, as well, since the queries are randomly sampled and the documents are retrieved from the entire web, rather than a small snapshot or single top level domain, as in the WT10G, GOV, and GOV2 collec-tions. Finally, and perhaps most importantly, the anchor text and link structure used in our experiments covers the crawlable web, rather than just a subset, which can skew or bias results.

Since we have graded relevance judgments, we make use of discounted cumulative gain (DCG)-based evaluation met-rics [13]. The DCG at rank K is computed as: where g ( i ) is the gain associated with the rating of result at rank i and K is maximum depth result to consider. We report DCG-1 and DCG-5 in our experiments, which are commonly used to evaluate web search effectiveness.
In addition to these two metrics, we also report normalized discounted gain (NDCG), which is a normalized version of DCG, which can be computed as: where N ( Q ) is the number of URLs ranked for query Q . From this, NDCG is calculated as: where IDCG ( Q ) is the  X  X deal DCG X  achieved if the results for Q were ranked perfectly. Therefore, NDCG ( Q ) = 1 indicates the best possible ranking. In this paper, we use gains of 10, 7, 3, 0.5, and 0, respectively, corresponding to the ratings described above.
For ranking, we use BM25F, which is an extension of the popular BM25 model that takes into account structured (fielded) documents and been shown to be highly effective for web search in the past [33]. Our original, unenriched documents contain several fields, including title , body , and anchor , that we will use in combination with our aggregated anchor text, to rank documents using BM25F.

The BM25F model first computes term field weights for every field f in the document u and every term t in the query. If the field f is the original or aggregated anchor text (when using the new field representation), then the term X  X  field weight is computed as: where L ( u ) is the set of anchor text lines associated with u , wt ( l,u ) is the weight associated with the line of anchor text, tf ( t,l ) is the number of times that term t occurs in line l , x ( q,l ) is the number of terms in line l that do not occur in the query, m ( q,l ) is the number of query terms missing from line l , and  X  and  X  are free parameters in the range (0 , 1] that penalize missing and extra terms. Thus, the term X  X  an-chor text field weight depends on the weight of the line, the number of times the term occurs in the line, and how closely the line matches the query (  X  x ( q,l )  X   X  m ( q,l ) ). This final com-ponent, which is a simple measure of the lexical similarity between the query and the line of anchor text, is added be-cause it was shown to be useful in previous research [2].
If f is any other field, such as the body, then the term field weight is computed as follows: where tf ( t,f,u ) is simply the number of times that term t occurs in field f in document u .

Given a term field weight, BM25F first normalizes the weight with respect to the field length as follows: where wt ( t,f,u ) is the original, non-normalized term field weight, l ( f,u ) is the length of field f in document u , l ( f ) is the average length of field f across all documents, and b f is a free parameter that controls the amount of docu-ment length normalization. The weight for a term t in a document u is then simply the weighted summation of the length normalized term field weights, which is computed as: where each wt ( f ) is a free parameter that determines how much each field contributes to the overall term weight.
The final BM25F score for a query q with respect to doc-ument u is then computed as follows: where N is the total number of documents in the collection, df t is the total number of documents that term t occurs in, and k 1 is a free parameter that controls term frequency saturation.

Therefore, BM25F has a number of free parameters that need to be tuned to be effective. In our experiments, we use 2-fold cross validation for this purpose. In all cases, we opti-mize the various BM25F parameter values to maximize the NDCG on our training set using the optimization procedure described in [33]. The parameters learned on the training set are then applied to the test set for evaluation purposes.
This section describes the results of our experimental eval-uation. We begin by showing how our proposed method helps overcome the anchor text sparsity problem. The re-mainder of the section details how aggregated anchor text can consistently and significantly improve retrieval effective-ness for web search.
Earlier, we posed the anchor text sparsity problem, which is based on the fact that many URLs have very few lines of anchor text associated with them. Given the importance of anchor text for ranking, this phenomenon may result in sub-optimal ranking, especially for highly relevant pages with little, or no, anchor text that adequately matches the query.
Figure 2 plots the distribution of lines of anchor text per URL for the original document representation (solid line) and the combined representation (dashed line) over the URLs in our test collection. As the graph shows, 211,565 URLs originally have no anchor text lines associated with them. This is consistent with previous observations that the distribution of inlinks, and hence anchor text, follows a power law distribution [4]. However, when aggregated an-chor text is included in the combined representation, only 152,911 URLs have zero lines of anchor text associated with them, which is a 38% reduction.

As Figure 2 shows, the combined representation has many more URLs with 1 line of anchor than the original represen-tation. This trend, although barely visible in the graph, continues. In fact, the average number of lines of aggre-gated anchor text per document is 34 and the maximum is 997.

The URLs in our test collection, which were collected us-ing pooling, are strongly biased, and do not represent a ran-Number of URLs Figure 2: Distribution of the number of anchor text lines in the original (solid line) and combined (dashed line) document representations. dom sample of URLs. For this reason, we also computed various anchor text measures over a random sample of 1 mil-lion URLs. Our results showed that 32,715 of the URLs had original anchor text, while 50,127 have aggregated anchor text. Of these 50,127 URLs, 43,841 did not have any orig-inal anchor text. Therefore, by aggregating anchor text we can more than double the number of URLs that have some type of anchor text associated with them. Furthermore, our analysis showed that the average number of original lines of anchor text associated with the URLs was 1, while the average number of lines of aggregated anchor text was 11.
Therefore, these results show that our approach is effec-tive at overcoming the anchor text sparsity problem. The method not only significantly reduces the number of URLs with no anchor text, but also adds new anchor text to URLs that have few original anchor text lines.
We have just shown that our proposed method helps over-come the anchor text sparsity problem. However, this does not guarantee that the new document representations will be useful in practice. Therefore, we evaluate how useful our aggregated anchor text enriched document representations are in the context of web search.

Our first experiment investigates the usefulness of dif-ferent combinations of weight aggregation functions (Sec-tion 3.2) and document representations (Section 3.3). We do not perform any experiments with the flat representa-tion, since HTML documents are inherently structured, and for this reason, we expect the representation to give poor results.
 The outcome of our experiments are shown in Table 1. Our baseline, which corresponds to the last row in the ta-ble, uses the original document representation and does not perform any anchor text aggregation. The results show that various combinations of weight aggregation functions and document representations, across all metrics, yield statisti-cally significant improvements over the baseline.

In terms of document representations, the backoff repre-sentation generally performs the worst. The new section and combined representations perform comparably. How-Representation Agg. Func. DCG-1 DCG-5 NDCG New Section Min 3.271  X  7.584  X  .8258  X  New Section Max 3.274  X  7.595  X  .8260  X  New Section Mean 3.270  X  7.583  X  .8258  X  New Section Mean-MNZ 3.261 7.577  X  .8254  X  New Section Sum 3.270 7.592  X  .8257  X  New Section Sum-MNZ 3.269 7.585  X  .8259  X  Table 1: Comparison of results for different docu-ment representations and weight aggregation func-tions. The  X  and  X  symbols represent statistically significant improvements versus the baseline at the p &lt; 0 . 1 and p &lt; 0 . 05 level, respectively. The  X  represents a statistically significant decrease at the p &lt; 0 . 05 level. Bold values indicate the aggrega-tion function that produces the best effectiveness for each pair of metrics and representations. ever, the combined representation appears to be consistently, yet only slightly, better than the new section representa-tion. One may expect the new section representation to per-form consistently better than the combined representation, because the combined representation uses a single BM25F field weight for the field that consists of the combined orig-inal and aggregated anchor text, whereas the new section representation uses separate BM25F field weights for the original and aggregated anchor text sections. This extra degree of freedom, one may suppose, would improve effec-tiveness. However, our experiments show that the BM25F field weights learned for the original and aggregated anchor text sections are almost always equal. Therefore, tying the two weights together, which the combined representation es-sentially does, is a reasonable thing to do. The new section representation, which has an extra degree of freedom, may actually be slightly overfitting to the training data, thereby resulting in a small loss in effectiveness versus the combined representation.

One interesting observation is that the best weight ag-gregation function differs for each representation. The best functions for the combined, backoff, and new section repre-sentations are min, sum, and max, respectively. This sug-gests that there is no  X  X ne size fits all X  weight aggregation function, and that the best choice will depend on how the anchor text is originally weighted, how the anchor text is aggregated, and how the resulting document is represented. The max function, however, seems to be a rather robust choice, as it achieves statistically significant improvements over the baseline across all representations and metrics. One may notice that the relative improvements in the var-0.00  X  0.25 29 +0.02% 0.00% 0.00% 0.25  X  0.50 765 +1.73%  X  +28.8%  X  +17.3%  X  0.50  X  0.75 6256 +1.23%  X  +16.6%  X  +3.22%  X  0.75  X  1.00 15772 -0.24%  X  -0.97%  X  -0.35%  X  Table 2: Relative improvements in retrieval effec-tiveness across query difficulty levels when using ag-gregated anchor text. The  X  and  X  symbols indicate statistically significant improvements over the base-line at the p &lt; 0 . 1 and p &lt; 0 . 05 level, respectively. ious metrics are rather small. For example, the best DCG-5 of 7.596 is achieved using the combined representation with the min weight aggregation function. This improvement, which is highly statistically significant, is only a 0.26% rel-ative improvement over the baseline. While this may seem small, especially compared to studies on TREC collections that achieve improvements over 10%, this improvement is actually quite large for this particular test collection. In-deed, relative improvements in DCG-5 greater than 0.1% are regarded as  X  X ubstantial X  for this test collection. One of the primary reasons why it is difficult to obtain large improve-ments on this data set stems from the fact that the queries were randomly sampled, meaning that a large proportion of the queries are short, navigational queries or long, very diffi-cult queries. Most of the short, navigational queries achieve the maximum possible DCG-5 using the original document representation, because the original anchor texts in these cases provide overwhelming evidence in favor of relevance. On the other hand, the long, very difficult queries tend to achieve a DCG-5 of near 0 for both the baseline and enriched document representations. Therefore, substantially smaller improvements in retrieval effectiveness are to be expected.
We just hypothesized that our method did little to im-prove the retrieval effectiveness of short, navigational queries and long, difficult queries. We can test this hypothesis by performing a stratified evaluation of the queries according to difficulty and length.

In Table 2, we stratify queries according to their difficulty, where difficulty is quantified as the NDCG achieved by the baseline system. The table shows the number of queries for each strata and the relative improvements in NDCG, DCG-1, and DCG-5, respectively. The results shown are for the combined representation using the min aggregation function, which achieved the best overall NDCG. The results for other document representations show similar trends.

This detailed breakdown of the results reveals that aggre-gated anchor text does little to improve the most difficult queries (0.0  X  0.25 range), but significantly improves queries of medium difficulty. Indeed DCG-1 and DCG-5 for queries in the 0.25  X  0.50 range are improved by well over 10%. This supports our hypothesis that our aggregated anchor text im-proves difficult (but not the most difficult), non-navigational queries. However, the results also show that aggregated an-chor text significantly decreases the retrieval effectiveness for easy queries in the range 0.75  X  1.0. These queries make up most of the queries, which is why the overall improve-ments reported in the previous section were on the order of the baseline at the p &lt; 0 . 1 and p &lt; 0 . 05 level, respectively. 0.2%. This result is somewhat unexpected, as we hypoth-esized that aggregated anchor text would not considerably hurt the easy queries. One possible explanation for this be-havior is that the aggregated anchor text brings in noisy lines of anchor text for navigational web pages, thereby leading to decreased retrieval effectiveness for these easy queries.
In addition, Table 3 shows the DCG-5 results for the best weight aggregation function and document representation combinations stratified by query length. The results show that aggregated anchor text improves longer queries more than shorter queries. This supports our claim that shorter queries, which are mostly navigational, are not helped by aggregated anchor text.

Thus, our proposed method is better at improving longer, more difficult queries, which are more often informational. This means that anchor text sparsity is less of a problem for short, navigational queries, since relevant documents can easily be found using the original anchor text. However, for longer, informational queries, relevant documents tend to be those that have little, or no, original anchor text. By augmenting these documents with aggregated anchor text, we are able to establish better, more effective rankings for such queries. These findings suggest that aggregated anchor text is likely to be most beneficial when used in conjunction with a navigational/informational query classifier [19] or a query difficulty predictor [34] in order to avoid using it for easy queries.
Finally, we address a practical concern of our methodol-ogy. By aggregating anchor text across the web graph, we may introduce spam, unrelated, or simply junk anchor text into a document X  X  representation. Furthermore, as we de-scribed before, our approach adds, on average, 11 lines of aggregated anchor text to affected URLs. This may seem like a small amount of space overhead, but can quickly be-come problematic, especially for indexes that contain mil-lions, or even billions, of documents. Therefore, we inves-tigate the effect on effectiveness of limiting the number of lines of anchor text added to each document.

The plot in Figure 3 shows how DCG-5 varies with respect to the maximum number of lines of aggregated anchor text allowed to be added to each document. In this experiment, we only keep, at most, the k highest weighted lines of aggre-gated anchor text. The rest of the aggregated anchor text lines are discarded.

It is important to note that the plot in Figure 3 begins with one aggregated anchor text line, not zero. The zero case, which is the baseline system, corresponds to DCG-5 = 0.7576. As the plot indicates, no matter how many lines of aggregated anchor text we add, the result is still better than the baseline. This is encouraging, because, at the very DCG-5 Figure 3: Effect of aggregated anchor text pruning. The plot shows DCG-5 versus the maximum number of aggregated anchor text lines allowed per URL. The dashed line indicates the DCG-5 obtained from using all of the anchor text. minimum, we can add a single line of aggregated anchor text to each document, and still achieve considerable gains in retrieval effectiveness. The plot indicates that allowing a maximum of 100 lines of aggregated anchor text is the op-timal policy. Interestingly, this policy is even better than the policy of using all of the aggregated anchor text lines. One possible explanation of this behavior is that spam, un-related, or junk lines start to occur somewhere around the 100th line of anchor text.

Therefore, by limiting the maximum number of lines of aggregated anchor text per document, we can not only save space by dropping some lines of aggregated anchor text, but we can also improve retrieval effectiveness at the same time.
In this paper, we framed the anchor text sparsity prob-lem, which highlights the importance of anchor text for rep-resenting documents. We argue that document representa-tions enriched with auxiliary anchor text can be useful for a variety of information retrieval and natural language pro-cessing tasks, including web search, contextual advertising, document classification, and summarization.

To address the problem, we proposed a method of aggre-gating, or propagating, anchor text across the web graph. Our approach defines the aggregated anchor text for a given page as the external anchor text of the internal inlinks. We also proposed six different weight aggregation schemes, in-spired by result set fusion techniques, that can be used to combine anchor text weights from multiple sources. In ad-dition, we described various ways that document represen-tations can be enriched with the aggregated anchor text, including the flat, combined, backoff, and new section rep-resentations. Finally, experimental evaluations were car-ried on a large-scale, real world web test collection. The results showed that our proposed approach reduces anchor text sparsity by 38% and consistently and significantly im-proves retrieval effectiveness, especially for longer, informa-tional queries, which exhibited DCG-1 and DCG-5 improve-ments of over 10%.
 There are several interesting directions of future work. This paper proposed a general framework for overcoming anchor text sparsity. However, in the future, it would be useful to extend this framework by exploring novel meth-ods for collecting anchor text, weight aggregation functions, and enriched document representations. It would also be worthwhile to explore beyond simple BM25F scoring. For example, use the enriched document representations in con-junction with term proximity models [23, 32] or as a feature within a machine learned ranking function [5, 24, 14]. Fi-nally, we would like to apply our framework to aggregated other textual representations, including document titles, ab-stracts, or social media tags.
