 Kun Zhang kzhang@tuebingen.mpg.de Bernhard Sch  X olkopf bs@tuebingen.mpg.de Krikamol Muandet krikamol@tuebingen.mpg.de Zhikun Wang zhikun@tuebingen.mpg.de Max Plank Institute for Intelligent Systems, T  X ubingen, Germany The goal of supervised learning is to infer a function f from a training set D tr = { ( x tr 1 ,y tr 1 ) ,..., ( x X  X Y , where X and Y denote the domains of pre-dictors X and target Y , respectively. The estimated f is expected to generalize well on the test set D te = { ( x te 1 ,y te 1 ) ,..., ( x te n ,y te n ) }  X  X  X Y , where y known. Traditionally, the training set and test set are assumed to follow the same distribution. However, in many real world problems, the training data and test data have different distributions, i.e., P tr XY 6 = P te and the goal is to find a learning machine that per-forms well on the test domain. This problem is known as domain adaptation in machine learning.
 If the data distribution changes arbitrarily, training data would be of no use to make predictions on the test domain. To perform domain adaptation successfully, relevant knowledge in the training (or source) domain should be transferred to the test (or target) domain. For instance, the situation where P tr XY and P te XY only differ in the marginal distribution of the covariate (i.e., P
X 6 = P te X , while P shift (Shimodaira, 2000; Sugiyama et al., 2008; Huang et al., 2007) or sample selection bias (Zadrozny, 2004), and has been well studied. For surveys on domain adaptation for classification, see, e.g., Jiang (2008); Pan &amp; Yang (2010); Candela et al. (2009).
 In particular, we address the situation where both the marginal distribution P X and the conditional distri-bution P Y | X may change across the domains. Clearly, we need to make certain assumptions for the training domain to be adaptable to the test domain. We first consider the case where P X | Y is the same on both do-mains. As a consequence of Bayes X  rule, the changes in P X and P Y | X are caused by the change in P Y , the marginal distribution of the target variable. We term this situation Target Shift (TarS) which is frequently encountered in practice; for instance, it is known as choice-based or endogenous stratified sampling (Man-ski &amp; Lerman, 1977) in econometrics, and is sometimes called prior probability shift (Storkey, 2009). We further discuss the situation where P Y remains the same, while P X | Y changes, as termed conditional shift (ConS). Estimation of P te X | Y under ConS is in general ill-posed; we consider a rather practical yet identi-fiable case where P X | Y changes under location-scale (LS) transformations on X . We show how to trans-form the training points to mimic the distribution of test data and facilitate learning on the test domain. Finally, the situation in which both P Y and P X | Y change across domains is termed generalized target shift (GeTarS); we focus on LS-GeTarS, i.e., GeTarS with P X | Y changes under LS transformations, and pro-pose practical methods to estimate both changes, mak-ing domain adaptation possible.
 It has been demostrated that causal information can be derived from changes in data distributions (Tian &amp; Pearl, 2001); on the other hand, knowledge of the data generating process, or causal knowledge, would imply how the data distribution changes across do-mains and help in domain adaptation. Sch  X olkopf et al. (2012) demonstrated that a number of learning tasks, especially semi-supervised learning, can be understood from the causal point of view. The problems studied here, TarS, ConS, and GeTarS, have clear causal inter-pretations. Throughout the paper, we assume that Y is a cause of X . 1 If we further know that X depends on the domain (or selection variable) only via Y , we have the TarS situation: the marginal distribution of the cause, P Y , describes the process which generates Y in the domain, and P X | Y describes the data generating mechanism for X from the cause Y , which is indepen-dent of the domain. According to Woodward (2003), the invariance of P X | Y w.r.t. the change in P Y is one of the features of the causal system Y  X  X . Consider the clinical diagnosis as an example. The disease is nat-ually considered as the cause of symptoms; moreover, the marginal distribution of the disease could change across different regions, but the conditional distribu-tion of the symptoms given the disease is expected to be invariant. Furthermore, if both Y and the domain are causes of X while Y is independent of the domain, we have the ConS situation. More generally, the situ-ation where Y is a cause of X and both P Y and P X | Y depend on the domain corresponds to GeTarS.
 In the classification scenario, target shift was re-ferred to the class imbalance problem by Japkowicz &amp; Stephen (2002). To solve it, sometimes it is assumed that P te Y is known a priori (Lin et al., 2002), or that some knowledge about the change in P Y is known (Yu &amp; Zhou, 2008). However, this is usually not the case in practice. Chan &amp; Ng (2005) proposed to estimate P te with an EM algorithm. Unfortunately, this approach has to estimate P tr X | Y , which is a difficult task if the di-mensionality of X is high; moreover, it does not apply to regression problems. In fact, lack of information on P
Y causes the main difficulty in domain adaptation under TarS.
 In this paper we provide practical approaches for domain adaptation under TarS, LS-ConS, and LS-GeTarS, by sample importance reweighting or sample transformation. The approach for TarS also applies to regression. Kernel embedding of both conditional and marginal distributions provides a convenient tool to es-timate the importance weights or the sample transfor-mations. With it, we are able to avoid estimating any distribution explicitly, and the proposed approaches apply to high-dimenional problems without any dif-ficulty. We note that kernel distribution embedding has been used to correct for covariate shift in Huang et al. (2007); Gretton et al. (2008), but the studied problems are inherently different: they used the kernel mean matching to estimate the ratio P te X /P tr X , avoid-ing estimating P te X and P tr X explicitly from data; in our problems we are interested in how P te Y is different from P tr Y (for TarS and GeTarS) or how P tr X | Y changes to P te X | Y (for ConS and GeTarS), but there are no data points available to estimate P te Y or P te X | Y , making the problems much more difficult to solve. In this section, we outline two scenarios for distribu-tion shift correction, namely, importance reweighting and sample transformation .
 Importance Reweighting We aim to find the function f ( x ) that minimizes the expected loss on test data. Assume the support of P te XY is contained by E E notes the parameters in the loss function l ( x,y ;  X  ),  X  we factorize P XY as P Y P X | Y instead of P X P Y | X be-cause it provides a more convenient way to handle the change in P XY , according to our assumptions given later. In practice, we minimize the empirical loss, to find the supervised learning machine which is ex-pected to work well on test data, if  X   X  ( y tr i )  X   X  ( x are given. Readers who are interested in how to re-duce the variance of the empirical expected loss may refer to, e.g., Shimodaira (2000); Robert &amp; Casella (2004).
 Sample Transformation and Reweighting Sam-ple reweighting only applies when the suport of P te XY is contained in that of P tr XY ; even under this condition, it is usually very difficult to estimate  X   X  ( x,y ) without prior knowledge on how P X | Y changes. Therefore, in the case where both P Y and P X | Y change, the appli-cation of the sample reweighting scheme is rather lim-ited. Instead, if we can find the transformation from P the conditional distribution of X new = T ( X tr ,Y tr pected loss on the test domain: R [ P te , X ,l ( x,y ;  X  )] = E Note that Y tr is an argument of the transformation T , i.e., T might be different at different Y values. This empirical loss can be calculated on the transformed training points ( x new , y tr ) with weights  X   X  : Classification and Regression Machines In this paper, we use support vector machine (SVM) and ker-nel ridge regression (KRR) for classification and re-gression problems, respectively. The standard formu-lation of both SVM and KRR can be straightforwardly modified to incorporate the importance weights ac-cording to (1) and (2). Details are skipped. Unfortunately, unlike the covariate shift, the weights  X  ( y i )  X   X  ( x i ,y i ) cannot be directly estimated because P
Y and P first consider the situation where P te X | Y = P tr X | Y  X  ( x,y )  X  1, and propose a practical method to esti-mate  X   X  ( y tr ) as well as P te Y based on kernel embedding of conditional and marginal distributions. 3.1. Assumptions We first consider Target Shift (TarS): A 1 : P That is, the differ-ence between P tr XY and P te XY is caused by a shift in tar-get distribution P Y .
 Fig. 1 shows a causal interpretation of TarS. For clas-sification problems, it is possible to estimate P te Y in an iterative way by maximizing the likelihood on x te , for instance, with the EM algorithm (Chan &amp; Ng, 2005); however, such approaches involve estimation of P tr X | Y explicitly, which is difficult for high-dimensional prob-lems. They are also not practical for regression. We make the following assumptions on P te Y and P tr X | Y A 2 : The support of P A 3 : There exists only one possible distribution of Imagine that we can draw a biased sample from the training data; here the selection variable depends only on Y , i.e., it is independent of X given Y . Denote by P new (  X  ) the distribution on this sample. Note that P identical to P te X by adjusting P new Y .
 Let  X  ( y ) be the ratio of the P new Y to P tr Y , i.e., P
Y =  X  ( y )  X  P P
X , we can adjust  X  ( y ) to minimize D ( P ference between two distributions; it can be the mean square error or the Kullback-Leibler distance. To solve this problem, we have to estimate P tr X | Y and P tr X from the training set, and moreover, the integral makes op-timization very difficult. 3.2. A Kernel Mean Matching Approach Instead, we solve this problem by making use of the kernel mean embedding of the marginal and con-ditional distributions; see Table 1 for the notation we use. The kernel mean embedding of P X (Smola et al., 2007; Gretton et al., 2007) is a point in the Reproducing Kernel Hilbert Space (RKHS) given by  X  [ P X ] = E X  X  P X [  X  ( X )], and its empirical estimate is ditional distribution has been studied by Song et al. (2009; 2010). The embedding of P X | Y can be con-sidered as an operator mapping from G to F , defined the (uncentered) cross-covariance and covariance op-erators, respectively (Fukumizu et al., 2004). Further-more, we have  X  [ P X ] = U [ P X | Y ]  X  [ P Y ]. We make the following assumption on the kernels: A 4 : Product kernel kl on X  X Y is characteristic. For characteristic kernels, the kernel mean map  X  from the space of the distribution to the RKHS is injective, meaning that all information of the distribution is pre-served (Fukumizu et al., 2008; Sriperumbudur et al., 2011). In this paper we use the Gaussian kernel, i.e., width. Note that under assumptions A TarS 3 and A TarS 4 , for the embedding U [ P tr X | Y ], which is a mapping from G to F , the pre-image of  X  [ P te X ] is unique. random variable X Y domain X Y observation x y data matrix x y kernel k ( x,x 0 ) l ( y,y 0 ) kernel matrix on training set K L feature map  X  ( x )  X  ( y ) feature matrix on training set  X   X  RKHS F G The kernel mean embedding of P new Y is The embedding of P new X is then given by  X  [ P new X ] = sion, we can find  X  ( y ) by minimizing the maximum mean discrepancy: subject to  X  ( y )  X  0 and E P tr antees that P new Y =  X  ( y ) P tr Y is a valid distribution. Theorem 1 Under assumptions A TarS 2 , A TarS 3 , and A 4 , the minimization problem (4) is convex in  X  . Further suppose A TarS 1 holds. Then the solution to (4) For a proof see the supplementary material. In prac-tice we have to use an empirical version. The empirical estimate of U X | Y is  X  U X | Y =  X ( L +  X I )  X  1  X  | . Recall that m and n are the sizes of the training and test sets. Denote by 1 n the vector of 1 X  X  of length n , and by K c the  X  X ross X  kernel matrix between y te and y tr , i.e., K ij = k ( x  X  ( y tr i ). The empirical version of the square of (4) is where we use short-hand notation  X  , L ( L +  X I )  X  1 . As shown by Huang et al. (2007, Lemma 3), if  X  i  X  [0 ,B  X  ], i.e., B  X  is the upper bound of  X  , given that  X  i has finite mean and non-zero variance, the sample mean 1 m P m i =1  X  i converges in distribution to a Gaus-sian variable with mean E P tr viation bounded by B  X  2  X  m . As E P tr have the following constrained quadratic programming (QP) problem: where a good choice of is O B 2  X  m .
 Note that  X  estimated this way is not necessarily a function of y : different data points in the training set with the same y value could correspond to different  X  values. We also found that the  X  values estimated by solving the above optimization problem usually change dramatically along with y . We can improve the esti-mation quality of  X  by making use of reparameteriza-tion. First consider the case where Y is discrete. Let C be the cardinality of Y and denote by v 1 ,...,v C its possible values. We can define a matrix R ( d ) where R ik is 1 if y i = v k and is zero everywhere else.  X  can then be reparameterized as  X  = R ( d )  X  ,where the C -dimensional vector  X  is the new parameter.
 We then consider the case where Y is continuous. Usu-ally both distributions P tr Y and P te Y are smooth, and so is  X  ( y ). Therefore, we would like to enforce the smoothness of  X  ( y ) w.r.t. y . Let R ( c ) , L  X  ( L  X  I )  X  1 , where L  X  is a kernel matrix of y with the Gaussian kernel and  X   X  is the regularization param-eter. 2 Inspired by KRR (Saunders et al., 1998), we parameterize  X  ( y tr ) as  X  = R ( c )  X  with new parameter  X  . One can consider  X  as a smoothed version of  X  . Finally, we find  X  (and  X  ) in both cases by solving: minimize where R stands for R ( d ) or R ( c ) , depending on whether Y is discrete or continuous. In all our experiments, we set B  X  = 10 and = B  X  4  X  m . We then set  X   X  in (1) to the estimated  X  and  X   X  ( x i ,y i )  X  1. Minimizing (1) produces the classifier or regression model after correction for TarS. might differ to some ex-tent. It is certainly not possible to transfer useful knowledge from the train-ing domain to the test do-main if P X | Y changes arbi-trarily. However, under certain assumptions on the change in P X | Y , one could estimate P te X | Y without knowing Y on test data. In this section we assume that P X | Y changes across domains and that P tr Y = P te We term this situation Conditional Shift (ConS); Fig. 2 gives its causal interpretation. This situation might be less realistic in practice and will not be considered in our experiments; however, it serves as a foundation of a more general situation, GeTarS, which will be stud-ied in Sec. 5. When considering ConS and GeTarS, we focus on classification problems. 4.1. Assumptions and Identifiability In some situations, we can formulate how the conditional distribution changes.
 For instance, for the same image, features such as intensities and colors are influ-enced by illumination, viewing angles, etc., which might change across domains. Mod-eling such a change enables distribution matching between the training domain and test domain, and consequently improves the performance on the test domain. Here we use the approach of transforming training data to reproduce the covariate distribution on the test domain ; see Sec. 2. Since we can model the trans-condition that the support of P te X | Y is contained in that of P tr X | Y , making the approach more practical. We assume that the shape of the distribution of each feature X i , as well as the dependence structure be-tween features, is preserved across the domains. More precisely, we assume that given any y value, P te X P X i | Y only differs in the location and scale: A
ConS : There exists w ( Y tr ) = We term this situation location-scale ConS (LS-ConS). In matrix form, the transformed training points where the i th columns of W and B are [ w 1 ( y i ) ,...,w d ( y i )] | and [ b 1 ( y i ) ,...,b d ( y spectively, are expected to have the same distribution as the test data. Fig. 3 illustrates on how the contours of P X | Y change across domains under LS-ConS. The following theorem states that P new X | Y is identifiable under some conditions on P tr X | Y ( x | y i ). version of P tr X | Y ( x | y i ) with parameters ( w i P
Y = P A If  X  ( w i , b i ) such that P te X = P i P tr Y ( y i ) P A necessary condition for A ConS 2 is that P tr X | Y i = 1 ,...,C , are linearly independent after any LS transformations. Rougly speaking, the higher d , the less likely for this assumption to be violated. 4.2. A Kernel Approach As in Sec. 3.2, we parameterize W and B as W = R G and B = R H , where G and H are the parameters to be estimated, and R is R ( c ) or R ( d ) , depending on whether Y is discrete or continuous. In this way W and B are guaranteed to be functions of y , and the number of parameters is greatly reduced.
 Noting the relationship between X new and X tr , and using the substitution rule, we have
The empirical estimate of U [ P new X | Y ] is consequently where  X   X  =  X  ( x new ).
 Let  X  K be the kernel matrix corresponding to the fea-ture matrix  X   X , i.e.,  X  K i,j = k ( x new i ,x new j the cross kernel matrix between x te and x new , i.e.,  X  K ij = k ( x  X  [ P te X ] 2 , whose empirical version is We then estimate W (or G ) together with B (or H ) by minimizing J ConS . In practice we also regular-ize (9) to prefer the change in P X | Y to be as little as possible, i.e., to make entries of W close to one and those of B close to zero. This is particularly useful in case assumption A ConS 2 is violated; we then prefer the slightest change in the conditional, among all possibil-ities. The regularization term is One can find the derivarive of J ConS and J reg w.r.t. G and H , and use the scaled conjugate gradient (SCG) to minimize J ConS + J reg . After estimating W and B , we transform x tr to x new according to (7), and ( x new , y tr ) would have the same distribution as the test data, under assumption A ConS . Consequently, the classifier or regressor trained on ( x new , y tr ) is expected to generalize well to the test domain. We then consider a more general situation where both P Y and P X | Y change, called Generalized Target Shift (GeTarS). Fig. 4 gives the causal model underlying the GeTarS situation.
 In this setting, we assume that P te Y 6 = P tr Y and that as-sumption A ConS holds, i.e., we consider LS-GeTarS, and aim to estimate the importance weights  X   X  ( y i ) , transform the training data to mimic the distribution of the test data, and the learning machine learned on the reweighted transformed data is expected to work well on the test data. Parameters can be estimated by reweighting and transforming the training data to reproduce P te X , i.e., by minimizing ||  X  [ P new X ]  X   X  [ P P provides the identifiability of p new Y and P new X | Y . Theorem 3 Suppose A ConS holds. Under assump-tion A ConS 2 , if there exist ( w i , b i ) such that P P Combining (3) and (8), we can find the empirical ver-sion of ||  X  [ P new X ]  X   X  [ P te X ] || 2 : When minimizing J , we would also like the difference in (10), to be as little as possible. Combining both constraints, we estimate the involved parameters  X  , W , and B by minimizing Finally, for parameter estimation, we iteratively alter-nate between the QP to minimize (11) w.r.t  X  and the SCG optimization procedure w.r.t. { W , B } . For de-tails of the two optimization sub-procedures, see Sec-tions 3 and 4, respectively. After estimating the pa-rameters, we train the learning machine by minimizing the weighted loss (2) on ( x new , y tr ).
 For how to select the hyperparameters involved in our methods, please refer to the supplementary mate-rial or the approach used for kernel-based conditional independence test (Zhang et al., 2011). The MAT-LAB source code for correcting TarS and LS-GeTarS is available at We use simulations to study the performance of the proposed approach for TarS and LS-GeTarS in four scenarios. They are (a) a nonlinear regression problem under TarS, (b) a classification problem under TarS, (c) a classification problem approximatly following LS-GeTarS, and (d) a classification problem under non-LS-GeTarS with slight changes in the conditionals. See Fig. 5 (left) for the training and test points generated in one random replication. The training and test sets consist of 500 and 400 data points, respectively. We compare our approaches to correction for TarS (Section 3) and for LS-GeTarS (Section 5) with the baseline (unweighted) least squares KRR or SVM, the importance weighting approach to correction for co-variate shift (CovS) proposed in Huang et al. (2007); Gretton et al. (2008), as well as two  X  X racle X  ap-proaches: one uses the theoretical values of  X   X  ( y ) = P rectly on the test set. Note that the result learned on the test set certainly has the best performance, but in practice it cannot be applied; it is given to show the limit of the performance that any domain-adaptation approach can achieve. Since in the considered classi-fication problems X is low-dimensional, it is possible to apply the EM algorithm proposed by Chan &amp; Ng (2005) to estimate P te Y , so it is also included for com-parison. We repeated the simulations for 100 times. Fig. 5 (right) shows the boxplot of the performances of all approaches, measured by the mean square er-ror (MSE) or classification error on the test set; for illustrative purposes, the left panels show the data points generated in one replication as well as the re-gression lines or decision boundaries learned by se-lected approaches. Under TarS, (a, b) , and non-LS-GeTarS with slightly changing conditionals, (d) , com-pared to the baseline unweighted method, clearly our approaches for TarS and LS-GeTarS improve the per-formance significantly. For regression under TarS, the estimated  X  values are very close to the theoretical ones, as seen from the lower-right corner of Fig. 5 (a, left). EM achieves a similar performance as TarS, since P
X | Y can be modeled well in this simple case. In (c) the conditional P X | Y changes significantly, such that none of the approaches correcting for CovS or TarS helps, but since the change approximately follows LS-GeTarS, our approach for LS-GeTarS greatly improves the classification performance. Compared to the un-weighted method, the important reweighting approach for CovS slightly improves the performance in settings (b) and (d) , and make it worse in (a) and (c) . We evaluate the performance of the proposed ap-proaches for regression and classification on real data. We first consider prediction of nonstationary pro-cesses, and then tackle the remote sensing image clas-sification problem, with images obtained on different areas. (d) Classification under non-location-scale GeTarS 7.1. Regression under TarS We first applied our approach for prediction on suit-able data selected from the cause-effect pairs. 3 We selected data set No. 68, since 1) the data are non-stationary time series, 2) there is a strong dependence between the two variables so that one can be predicted non-trivially by the other, and 3) the variables are be-lieved to have a direct causal relation, so that the in-variance of the conditional distribution of one variable (effect) given the other (cause) is likely to hold approx-imately. Fig. 6 (top) showing the time series as well as the joint distribution. Here X and Y stand for the number of bytes sent by a computer at the t th minute and the number of open http connections at the same time, respectively. It is natural to have the causal rela-tion Y  X  X , and we aim to predict Y from X without making use of temporal dependence in the data. One subsample was always used for training, because on it Y has large values. The remaining data were divided into four subsets, and each time one of them was used for test and the others included for training. Fig. 6 (bottom) shows the estimated  X   X  values on the four test sets; they match P te Y well. Table 2 gives the MSE on the four test sets produced by different ap-proaches. Note that to achieve robustness of the pre-diction result, we incorporated an exponent q for  X   X  as the importance weights, as in correction for CovS with importance re-weighting (Shimodaira, 2000). q = 1 (i.e., the proposed standard approach) and q = 0 . 5 were used. From Table 2 one can see TarS gives the best results on all four test sets. 7.2. Remote Sensing Image Classification We used a benchmark data set for remote sensing im-age classification with 14 classes and 145 features; for details of this data set, see (Ham et al., 2005). The labeled samples were collected on two different and spatially disjoint areas, and one would expect that not only P Y , but also P X | Y changes across them, due to physical factors related to ground, vegetation, and atmospheric conditions. The samples taken on each area were partitioned into a training set TR and a test set TS by random sampling. TR 1 , TS 1 , TR 2 , and TS 2 have sample sizes 1242, 1252, 2621, and 627, respectively. We consider two adaptation problems, TR 1  X  TS 2 and TR 2  X  TS 1 .
 After estimating the weights and/or transformed training data (with  X  LS = 10  X  4 ), we applied the multi-class classifier with a RBF kernel on the weighted or transformed data. Hyperparameters were selected by cross-validation. Table 3 shows the overall classifica-tion error (i.e., the fraction of misclassified points) ob-tained by different approaches for each domain adap-tation problem. We can see that in this experiment, correction for target shift does not significantly im-prove the performance; in fact, the estimated  X  values for most classes are rather close to one. However, cor-rection for conditional shift with LS-GeTarS substan-tially reduces the overall classification error in both cases.
 We have considered domain adaptation where both the distribution of the covariate and the conditional distri-bution of the target given the covariate change across domains. From the causal point of view, we assume the target causes the covariate, such that the change in the the data distribution can be modeled easily. In par-ticular, we studied three situations, target shift, con-ditional shift, and generalized target shift which com-bines the above two situations. We presented practical approaches to handle them based on the kernel mean embedding of conditional and marginal distributions. Simulations were conducted to verify our theoretical claims, and experimental results on diverse real-world problems, showed that (generalized) target shift often happens in domain adaptation, and that the proposed approaches could substantially improve the classifica-tion or regression performance.
 Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N. (eds.). Dataset Shift in Machine Learning . MIT Press, 2009.
 Chan, Y. S. and Ng, H. T. Word sense disambigua-tion with distribution estimation. In Proceedings of the 19th International Joint Conference on Artificial Intelligence , pp. 1010 X 1015, Scotland, 2005.
 Fukumizu, K., Bach, F. R., Jordan, M. I., and
Williams, C. Dimensionality reduction for su-pervised learning with reproducing kernel hilbert spaces. JMLR , 5:73 X 99, 2004.
 Fukumizu, K., Gretton, A., Sun, X., and Sch  X olkopf, B.
Kernel measures of conditional dependence. NIPS 20 , pp. 489 X 496, Cambridge, MA, 2008.
 Gretton, A., Borgwardt, K., Rasch, M., Sch  X olkopf, B., and Smola, A. A kernel method for the two-sample-problem. In NIPS 19 , pp. 513 X 520, Cambridge, MA, 2007.
 Gretton, A., Smola, A., Huang, J., Schmittfull,
M., Borgwardt, K., and Sch  X olkopf, B. Covari-ate shift and local learning by distribution match-ing. In Qui  X nonero-Candela, J., Sugiyama, M.,
Schwaighofer, A., , and Lawrence, N. (eds.), Dataset shift in machine learning , pp. 131 X 160. MIT Press, Cambridge, MA, 2008.
 Ham, J., Chen, Y., Crawford, M. M., and Ghosh, J.
Investigation of the random forest framework for classification of hyperspectral data. IEEE Trans. Geosci. Remote Sens. , 43(3):492 X 501, 2005.
 Huang, J., Smola, A., Gretton, A., Borgwardt, K., and Sch  X olkopf, B. Correcting sample selection bias by unlabeled data. In NIPS 19 , pp. 601 X 608, 2007. Japkowicz, N. and Stephen, S. The class imbalance problem: A systematic study. Intelligent Data Anal-ysis , 6:429 X 450, 2002.
 Jiang, J. A literature survey on domain adaptation of statistical classifiers , 2008. Lin, Y., Lee, Y., and Wahba, G. Support vector ma-chines for classification in nonstandard situations. Machine Learning , 46:191 X 202, 2002.
 Manski, C. and Lerman, S. The estimation of choice probabilities from choice-based samples. Economet-rica , 45:1977 X 1988, 1977.
 Pan, S. J. and Yang, Q. A survey on transfer learning.
IEEE Transactions on Knowledge and Data Engi-neering , 22:1345 X 1359, 2010.
 Robert, C. P. and Casella, G. Monte Carlo Statistical
Methods . Springer Press, New York, 2nd edition, 2004.
 Saunders, C., Gammerman, A., and Vovk, V. Ridge regression learning algorithm in dual variables. In Proc. ICML , pp. 515 X 521, Madison, WI, 1998.
 Sch  X olkopf, B., Janzing, D., Peters, J., Sgouritsa, E.,
Zhang, K., and Mooij, J. On causal and anticausal learning. In Proc. ICML 2012.
 Shimodaira, H. Improving predictive inference under covariate shift by weighting the log-likelihood func-tion. Journal of Statistical Planning and Inference , 90:227 X 244, 2000.
 Smola, A., Gretton, A., Song, L., and Sch  X olkopf, B. A hilbert space embedding for distributions. In Proceedings of the 18th International Conference on Algorithmic Learning Theory , pp. 13 X 31. Springer-Verlag, 2007.
 Song, L., Huang, J., Smola, A., and Fukumizu, K.
Hilbert space embeddings of conditional distribu-tions with applications to dynamical systems. In Proc. ICML 2009.
 Song, L., Boots, B., Siddiqi, S., Gordon, G., and
Smola, A. Hilbert space embeddings of hidden markov models. In ICML 2010 .
 Sriperumbudur, B., Fukumizu, K., and Lanckriet, G.
Universality, characteristic kernels and rkhs embed-ding of measures. JMLR , 12:2389 X 2410, 2011.
 Storkey, A. When training and test sets are differ-ent: Characterizing learning transfer. In Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence,
N. (eds.), Dataset Shift in Machine Learning , pp. 3 X 28. MIT Press, 2009.
 Sugiyama, M., Suzuki, T., Nakajima, S., Kashima, H., von B  X unau, P., and Kawanabe, M. Direct impor-tance estimation for covariate shift adaptation. An-nals of the Institute of Statistical Mathematics , 60: 699 X 746, 2008.
 Tian, J. and Pearl, J. Causal discovery from changes: a bayesian approach. In UAI2001 , pp. 512 X 521, 2001. Woodward, J. Making things happen: A theory of causal explanation . Oxford University Press, New York, 2003.
 Yu, Y. and Zhou, Z. A framework for modeling positive class expansion with single snapshot. In PAKDD 2008 .
 Zadrozny, B. Learning and evaluating classifiers under sample selection bias. In Proc. ICML , pp. 114 X 121, Banff, Canada, 2004.
 Zhang, K., Peters, J., Janzing, D., and Sch  X olkopf, B.
Kernel-based conditional independence test and ap-
