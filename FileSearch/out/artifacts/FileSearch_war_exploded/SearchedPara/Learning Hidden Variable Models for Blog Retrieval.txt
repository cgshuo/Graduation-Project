 We describe probabilistic models that leverage individual blog post evidence to improve blog seed retrieval perfor-mances. Our model offers a intuitive and principled method to combine multiple posts in scoring a whole blog site by treating individual posts as hidden variables. When applied to the seed retrieval task, our model yields state-of-the-art results on the TREC 2007 Blog Distillation Task dataset. H.3.3 [ Information Storage and Retrieval ]: Retrieval Models Design, Algorithms, Experimentation, Performance Learning to Rank, Passage Retrieval, Blog Retrieval
In blog seed retrieval tasks, we are interested in finding blogs with relevant and recurring interests for given top-ics. Rather than ranking individual blog posts, whole sites are ranked (i.e. all posts within a blog). We propose two discriminatively trained probabilistic models that model in-dividual posts as hidden variables.
We make a modeling assumption that given a set of top-ranked passages of a document, the document is relevant if any one of the passages is relevant.

The first independent model (IND) assumes that the rel-evance of a specific top-ranked passage s i is independent of the relevance of any other passage in ~s . We use the logistic function to model the relevance of a passage. Our second model (RBM) takes a step further and exploit the correla-tions among individual passages in a Restricted Boltzmann Machine framework.

P ( ~  X  z | ~s )) = 1 Z exp( P i&lt;j ~  X  ~ f ( s i ,s j ,z where ~ f ( s ) is a feature vector of the passage s , and the corresponding weight vector. Z is the partition func-tion computed by summing over all possible relevance as-signments. ~ f ( s i ,s j ,z i ,z j ) are passage correlation features (cosine-sim, URL overlapping) and ~g ( s i ,z i ) are passage rel-evance feature (e.g., rank, score).
We evaluated our models on TREC 2007 Blog Distilla-tion Track dataset. We would first obtain top 5 ranked pas-sages for each document using Indri X  X  LM-based retrieval system, and then apply our model to re-rank each docu-ment. Training and testing is done by performing 5-fold cross-validation. We compare our models with four strong baselines. The first two are the Indri language model pas-sage and document retrieval systems (Indri-psg, Indri-doc). The third one is the CMU system, which gives the best per-formance in TREC 2007 and 2008 evaluations [1]. The last one is the ReDDE federated search algorithm used in [2]. Our IND model showed significant improvements over the Indri passage and document retrieval baselines (58.5% and 9.4% relative improvements). The RBM model gained a small improvement over the IND model, and significantly outper-formed the baseline CMU and ReDDE models.

In this paper, we introduced two probabilistic models that model individual blog posts as hidden variables for blog seed retrieval tasks. Our models produced state-of-the-art results on TREC 2007 Blog Distillation dataset. [1] J. Elsas, J. Arguello, J. Callan, and J. Carbonell. [2] J. Elsas, J. Arguello, J. Callan, and J. Carbonell.
