 People have multiple accounts on Online Social Networks (OSNs) for various purposes. It is of great interest for third parties to collect more users X  information by linking their accounts on different OSNs. Unfortunately, most users have not been aware of potential risks of such accounts linkage. Therefore, the design of a control methodology that allows users to share their information without the risk of being linked becomes an urgent need, yet still remains open.
In this paper, we first aim to raise the users X  awareness by presenting an effective User Accounts Linkage Inference (UALI), which is shown to be more powerful to users than existing methods. In order to help users control the risks of UALI, we next propose the first Information Control Mech-anism (ICM), in which users X  information is still visible as intended and, in the meanwhile, the risk of their accounts linkage can be controlled. Using real-world datasets, the performance of ICM is validated, and we also show that it works well for various linkage inference approaches. Both UALI and ICM approaches, designed to take generic inputs, extend their ability to be widely applied into many practical social services.
 H.4 [ Information Systems Applications ]: Miscellaneous; F.2.2 [ Analysis of Algorithms and Problem Complex-ity ]: Nonnumerical Algorithms and Problems Algorithms, Experimentation, Theory User Accounts Linkage Inference, Information Control Mech-anism, Multiple Online Social Networks, Computational Hard-ness, Algorithms, Experiments
Over the past few years, we have witnessed the rapid growth of Online Social Networks (OSNs). People sign up multiple accounts on OSNs for different purposes [23]. For example, users provide their professional profiles and estab-lish their professional networking on Linkedin. In the mean-while, people create their accounts on Facebook mainly to communicate with friends, share interest groups, etc. [16]
On the other hand, third parties and companies find it useful to link different user accounts due to the collection of more user information. For example, many companies have established legitimate business models to weed out job ap-plicants via X  X ocial Media Screening X , in which the linkage of a person X  X  Linkedin and Facebook accounts helps to capture both his/her technique and behavior background [22]. In another example, recommender service provider (e.g., Yelp, Amazon) can filter out spam reviews based on the review-er X  X  behaviors on other OSNs after linking their accounts [13]. This has increasingly attracted researchers X  attentions [7, 19, 28], targeting on inferring the user accounts linkage across multiple OSNs.

Unfortunately, such user accounts linkage is not necessar-ily always beneficial. For instance, the user accounts linkage inferred by malicious third parties could result in the dis-closure of a user X  X  private information and friend lists [15]. More seriously, such third parties could create fake accounts pretending to be this person on OSNs and then solicit oth-ers to connect. These conspiratorial connections, once es-tablished, could be abused to deliberately leak the user X  X  privacy to unwanted audiences, which could quickly trans-form into losing jobs, damaging relationships, or even worse [20]. However, most users still have not realized such risks of accounts linkage. Therefore, it is highly desirable to design a methodology for helping users control their visible infor-mation by taking into consideration the linkage inference of their multiple accounts.
 The goal of this paper is two-fold (as shown in Figure 1). First, in order to raise the users X  awareness, we present an effective User Accounts Linkage Inference (UALI), extend-ing a novel idea which enables generation of complementary features only using little public information. As such, UALI is shown to be much more powerful than existing inference approaches [7, 19, 28]. On the other hand, UALI also impos-es much more risks of users X  private information than other methods.
Second, in order to help users control the risks of practi-cal and easy-to-conduct UALI, we propose the first Informa-tion Control Mechanism (ICM), studying how users can still make their information visible as intended without the risk of being linked. More specifically, we formulate an optimiza-tion problem to study the trade-off between user information sharing and user privacy via k -anonymity. We then propose a greedy algorithm, incorporating the reduction of search spaces that tackles the substantial challenge due to a huge magnitude of OSN users and their information on OSNs.
Our main contributions are summarized as follows:
The rest of paper is organized as follows. Section 2 intro-duces notations and problem definitions of User Accounts Linkage Inference (UALI) and Information Control Mecha-nism (ICM). The solutions of these two problems are pro-posed in Section 3 and 4, respectively. Section 5 reports the experimental results, and related work is presented in Sec-tion 6. At last, we discuss the generalization of our proposed UALI and ICM approaches and their applications onto other social services in Section 7.
In this section, we define some notations and two problem-s, User Accounts Linkage Inference (UALI) and Information Control Mechanism (ICM). The rest of paper will focus on developing their solutions and conducting extensive experi-mental evaluations.
An OSN consists of user accounts and their interactions, i.e., edges formed by people indicating their neighbors. Two accounts on different OSNs are referred to as crossing ac-counts if they correspond to the same physical person ( cross-ing user ). More specifically, we name crossing accounts as linked crossing accounts (denoted as L ) if the linkage infor-mation is available in public and unlinked crossing accounts
Account on service OSN (denoted as U ) otherwise. For a crossing user w ,wedenote w =( w 1 , w 2 )inwhich w 1 and w 2 represent his/her two ac-counts on OSN1 and OSN2 respectively. Note that when user accounts on multiple OSNs are publicly linked, the ag-gregation of information in all these accounts can be used to infer the linkage between them and another account, i.e., OSN in our solution, which can be easily extended to a set of accounts.

Each user account w i on OSN i is associated with a set of features denoted as F w i , such as name, location, friends, etc., in which some features are public while others are protected by users X  privacy settings and therefore not available. The neighbors of a user account w i on OSN i is denoted as N ( The set of all user accounts on OSN i is defined to be V i User Accounts Linkage Inference. In User Accounts Linkage Inference (UALI), the objective is to learn a univer-sal function (  X  ,  X  ) for the pair of accounts to identify if they are the unlinked crossing accounts. Ideally, ( u, v )= 1 Then, UALI problem can be defined as:
Definition 1 (UALI Problem). Consider a crossing user w =( w 1 , w 2 ) with two unlinked accounts. Account on OSN1 is given while w 2 on OSN2 is unknown. The ob-jective is to learn a function (  X  ,  X  ) and use it to find the account w 2 on OSN2 to link w 1 such that ( w 1 , w 2 )=1 and ( w 1 ,u )=  X  1 for any other account u  X  V 2 on OSN2. Note that such account w 2 may not always be able to found. The result might be either a set of accounts or no account identified, leading to false positive or false negative errors. In this case, we aim to minimize these errors.

Information Control Mechanism. Information Con-trol Mechanism (ICM) is designed to act as a gatekeeper to help users control the risks of the harmful and easy-to-conduct UALI inference. As shown in Figure 1, ICM pro-vides the service for each user on OSN1, called service OSN , to control his account on OSN1 from being linked in his an-other account on OSN2, called auxiliary OSN (there could be more than one auxiliary OSN). We denote OSN1 &gt; OSN2 if and only if OSN1 is a service OSN and OSN2 is an aux-iliary OSN. Our ICM problem focuses on studying helping each user to maximize their information visibility on OS-N1, and in the meanwhile control the sharing information against the risks of linking his/her two accounts on OSN1 and OSN2. (1) User Information Visibility Maximization: One of our objectives is to maximize the visibility of user w  X  X  informa-tion when protecting his privacy. Therefore, we take advan-tage of the user-specific input, v w i  X  [0 , 1], representing the visibility probability of each information i .Bydenoting S the visible information after conducting the privacy preser-vation, our objective function is to maximize the expected information visibility, defined as (2) Information Control: We take into account a well-accepted privacy notion, k -anonymity and define an alter-native novel k -linkage anonymity as follows:
Definition 2 ( k -Linkage Anonymity). k -linkage anonymity is achieved if and only if there exist at least accounts S on OSN2 such that m ( w 1 , w 2 )  X  m ( w 1 ,u any u  X  S .
 Note that m (  X  ,  X  ), called matching score function , is deter-mined by the above function (  X  ,  X  )welearnedinSection3. As such, the detailed selection of m (  X  ,  X  ) will be introduced in Section 4.1.
 We then define the following optimization ICM problem:
Definition 3 (ICM Problem). Given a positive inte-ger k , a crossing user w =( w 1 , w 2 ) with accounts w 1 w 2 on OSN1 and OSN2 respectively. The objective of ICM problem is to maximize user w  X  X  visible information on OS-N1(service OSN) and achieve the k -linkage anonymity for user w between his account w 1 and all user accounts (denot-ed as V 2 ) on OSN2 (auxiliary OSN(s)).
In this section, we present the learning and testing algo-rithms for UALI problem, which smartly generate features, called quasi features , to enhance the quality of (  X  ,  X  and testing results. More specifically, our learning algorithm is to learn a function (  X  ,  X  ) and our testing algorithm fur-ther uses (  X  ,  X  ) to identify a user X  X  unlinked crossing account. Therefore, our UALI approach turns out to be a more pow-erful and easy-to-conduct inference than existing methods.
For a pair of user accounts, we consider three types of features: profile (i.e., name, gender, location, etc.), neigh-borhood (i.e., friends, followers, followees, etc.), quasi (fea-tures unavailable in original datasets and smartly generated in our algorithm). We denote the features of a pair of users as follows:
The idea of iteratively (  X  ,  X  ) learning (Algorithm 1) is to (1) learn (  X  ,  X  ) on existing features in each iteration; (2) use (  X  ,  X  ) to test other pairs of accounts, generate quasi features and update the feature vector f (  X  ,  X  ). The algorithm termi-nates when the features cannot be updated any more.
However, due to the huge amount of account-pairs on t-wo OSNs, i.e., | V 1 | X | V 2 | , it is almost impossible to generate feature vectors of all pairs only to determine a very small number of unlinked crossing accounts for updating the quasi features. Therefore, the main challenge is how to efficient-ly update the quasi features in each iteration. The idea of our learning algorithm is based on the intuition that cross-ing accounts usually share at least one same neighbor on two OSNs . That is, we only construct the features for potential quasi crossing accounts (denoted as P ) which have at least one common friend/follower/followee, which can be repre-sented linked crossing accounts or inferred unlinked crossing accounts, as shown in Figure 2.

Our iterative (  X  ,  X  ) learning algorithm (Algorithm 1) is executed as follows: We take all users V 1 and V 2 in OSN1 and OSN2, along with a set of linked crossing accounts L . We first randomly construct non-crossing account-pairs, de-noted as U . Account-pairs in L and U are labeled 1 and -1 respectively. Next, we construct the base features of L and U as discussed in later Section 5.2.1 and set all of their quasi features to be (0,0,0). Then, we iteratively learn the function (  X  ,  X  ) and update the quasi features. As illustrated in Figure 2, we only consider updating quasi features from potential quasi crossing accounts. After constructing the features for potential quasi crossing accounts, we test them using the current learning function (  X  ,  X  ). The three values in f are incremented by the number of inferred unlinked crossing friends/followers/followees, i.e., the number of correspond-ing potential quasi crossing accounts labeled 1 by (  X  ,  X  loop terminates if no features in all account-pair in L and can be updated.
 Algorithm 1 has its worst-case running time | X  u  X  L  X  U N ( 1 Set the labels of account-pairs in L to 1; 2 Randomly generate the same size of non-crossing 3 Construct base features f p (  X  ,  X  )and f n (  X  ,  X  )for 4 Set quasi feature values f q (  X  ,  X  ) to (0,0,0) for 5Do 6 Learn (  X  ,  X  ); 7 Search potential quasi crossing accounts P ; 8 Construct features on P ; 9 Label account-pairs in P using the current (  X  ,  X  ) 10 Update quasi features f q (  X  ,  X  ) in account-pairs L 11 While  X  an account-pair in L and U whose f (  X  ,  X  ) is 12 return function (  X  ,  X  );
Algorithm 1: Learning: Iterative (  X  ,  X  ) Learning running time of learning (  X  ,  X  ) (based on the specific classifi-er used to train (  X  ,  X  )). This is because in the worst case we can infer one unlinked crossing account from neighbors of a user account in L  X  U in each iteration, and the potential quasi crossing accounts could be all user accounts on OSN2. However, we show in the experiment that our algorithm run-s much faster in practice as the number of potential quasi crossing accounts in real-world OSNs is very small.
Unlike the testing/labeling step in Algorithm 1(line 9) on a given account-pair, our testing phase takes an account w on OSN1 and all accounts V 2 on OSN2 as input. In order to improve the precision of testing results, we need to take advantage of such quasi features. Thus, the key point is how to efficiently construct the quasi features.

The idea of our linkage inference algorithm is to construc-t quasi features only when necessary (Algorithm 2). Here we consider two cases: (1) When none of the accounts in OSN2 is identified as unlinked crossing account initially, we return  X  X nference Failed X ; (2) When more than one accoun-t, say W , are identified as unlinked crossing account, we then search potential crossing accounts between w 1  X  X  neigh-bors and all neighbors of W . We then construct features of these account-pairs and use (  X  ,  X  ) to label them. The values in f q (  X  ,  X  ) between w 1 and W are incremented by the num-ber of inferred unlinked crossing friends/followers/followees, i.e., the number of corresponding potential quasi crossing accounts labeled 1 by (  X  ,  X  ). Next, we test on account-pairs between w 1 and W with new quasi features using (  X  ,  X  )a-gain, and update W by removing those which are labeled -1. Our algorithm reports X  X nference failed X  X hen two conditions hold at the same time: No quasi features of account-pairs between w 1 and W can be updated and w 2 cannot be suc-cessfully linked.

In the worst case, UALI algorithm takes | N ( w 1 ) | X | V where testing is the running time of testing (  X  ,  X  ). However, 1 Construct base features between w 1 and V 2 ; 2 Label all these account-pairs using (  X  ,  X  ) function; 3if No w 2 is identified then 4 return Inference Failed 5end 6 while More then one w 2 are identified do 7 Set W to be identified unlinked crossing 8 Construct features on potential quasi crossing 9 Label account-pairs in P using (  X  ,  X  ) function; 10 Update quasi features f q (  X  ,  X  ) in account-pairs 11 Label account-pairs ( w 1 , W ) and remove 12 if No f q (  X  ,  X  ) in account-pairs ( w 1 , W ) can be 13 return Inference Failed 14 end 15 end 16 return account w 2
Algorithm 2: Testing: Linkage Inference using (  X  ,  X  ) we again show in the experiment that UALI algorithm ac-tually runs very fast in practice due to the small number of quasi features needed to be constructed.
In this section, in order to help users control the risks of UALI, we first choose the most suitable matching score function m (  X  ,  X  ) in the definition of ICM problem based on the UALI results. Then we prove the hardness of approxi-mation for ICM problem, followed an effective Controllable Accounts Linkage (CAL) algorithm.
The key point in the definition of ICM problem lies in how to select the matching score function m (  X  ,  X  ). Moti-vated by the experimental results in Figure 3(a) in Section 5.2.1, which ends up with the highest AUC score when us-ing Adaboost (Decision Stump) algorithm to learn (  X  ,  X  ), we consider using the result from Adaboost (Decision Stump) classifier as our matching score function. Moreover, a ratio-nal attacker, when using Adaboost algorithm, can careful-ly choose any reasonable threshold to categorize the result instead of simply applying the default threshold 0. There-fore, we take the fractional value from Adaboost (Decision Stump) classifier as m (  X  ,  X  ): where  X  j and h j [ f (  X  ,  X  )] is the weight and result of decision stumponthe j th weak learner for all T weak learners. Note that m (  X  ,  X  ) can be calculated during the learning of ( ing Adaboost algorithm, i.e., (  X  ,  X  )=Sign { T i =1  X  i As a feature could be trained more than once in Adaboost, we reorganize m (  X  ,  X  ) and obtain r.h.s. in (3) w.r.t. the fea-ture set F w , where  X  i (  X  ,  X  ) is the summation of  X  j for the weak learners (decision stump) which build a stump on the i th feature. For simplicity, we denote the contribu-tion of i th feature to differentiate w from a user u on OSN2 as
Particularly, this ICM problem can be further generalized when using different social service metrics and matching s-cores. More details will be discussed in Section 7.
As a new optimization problem, the computational hard-ness of ICM problem is of interest in the first place. In this subsection, we show the inapproximability factor for ICM problem, which gives us the lower bound of near-optimal so-lution with theoretical performance guarantee. That said, no-one can design an approximation algorithm with a bet-ter ratio than the inapproximability factor. The idea is to prove the gap-preserving reduction from maximum clique problem, defined as follows:
Definition 4 (Maximum Clique). Given an undirect-ed graph G =( V,E ) , find a clique of maximum size. A subgraph of G is called a clique if all its nodes are pairwise adjacent.

Theorem 1. For any constant  X &gt; 0 , the ICM problem is hard to be approximated within an absolute error O ( F 1  X   X  unless P=NP ,wherethenumberoffeatures F = | F w | is large enough.

Proof. In the proof, we show a gap-preserving reduction from the Maximum Clique (MC) problem to ICM. Accord-ing to H  X  astad , MC is proven NP-hard to be approximat-ed within n 1  X   X  . Let an undirected graph G =( V,E )with | V | = n nodes, | E | = m edges and a positive integer h  X  n be an MC instance  X  . We construct the instance as fol-lows: We first construct the feature set F w = V in G , i.e., F = | F w | = n . For each edge ( s i ,t i )  X  E , we construct a us-er u i on OSN2 whose  X   X  s i ( w 1 , w 2 ,u i )=  X   X  t i ( er u i . Therefore, the number of users on OSN2 equals to the number of edges m in G . Moreover, considering a positive constant  X &gt; 0, we choose k = n 1  X   X  2 . Clearly this con-struction can be done in polynomial time. Then, denoting the reduced instance as ICM(  X  ), we show the completeness and soundness respectively.

Completeness: OPT (  X  )= n 1  X   X   X  OPT (ICM(  X  )) = n  X 
When OPT (  X  )= n 1  X   X  , there must exist a clique S  X  G with n 1  X   X  nodes. In the constructed instance ICM(  X  ), we can select k = n 1  X   X  users on OSN2 with respect to the edges in clique S to achieve k -anonymity. After hiding all features of these k users, the visibility will be n  X  X  X  k
Soundness: OPT (  X  )  X  n  X   X   X  OPT (ICM(  X  ))  X  n  X 
We focus on analyzing the lower bound of the number of features associated with arbitrary k users. According to Tur  X an X  X  theorem in [4], if a graph G =( V,E )hasno p -clique, then the number of edges | E | X  p  X  1 2 p | V | 2 . Therefore, given k users on OSNs corresponding to k edges in G ,wehavethe number of associated features  X  lower bounded by where the first two steps are derived from Tur  X  an X  X  theorem and k = n 1  X   X  2 ; the last step is calculated by using binomial series expansion. Therefore, we have the visibility upper
Due to the intractability of ICM problem, it seems unre-alistic for one to quickly obtain its optimal solution within time constraint. Therefore, we propose an effective algorith-m, Controllable Accounts Linkage (CAL) algorithm, to solve ICM problem in a timely manner.

The idea of CAL algorithm is based on our observation that most of users u on OSN2 are distinctive users , i.e., users with  X   X  i ( w 1 , w 2 ,u )  X  0 for all features between themselves and user w . According to Lemma 1, our proposed CAL algorithm greedily hides a feature to maximize where V j 2 is the set of non-identical users on OSN2 after iteration j . And the indicator variable I ( x ) is defined as Note that when v w i = 0, this information is selected to hide without any penalty. Therefore, our algorithm always select information with zero visibility to hide first.

Lemma 1. For a distinctive user u who has  X   X  i ( w 1 , w 0 for all features between himself and w , u  X  S if and only if all features with  X   X  i ( w 1 , w 2 ,u ) &gt; 0 are hidden.
Then, the challenge mainly lies in how to efficiently find the feature i with maximum  X  ( i ) in each iteration .Toover-come this, we propose the idea using three priority queues with respect to the distinctive and non-distinctive users on OSN2 and feature sets. 1 S  X  F w ; 2 Construct priority queues Q d , Q n , Q f ; 3 D  X  X  u | priority( u )=0 ,u  X  Q d } ; 4 Remove D from Q d ; 5 N  X  X  u | priority( u )  X  0 ,u  X  Q n } ; 6 while | D  X  N | &lt;k do 7 Hide feature i with highest priority in Q f 8 Update Q d and Q n after removing feature i ; 9 Insert { u | u  X  Q n ,  X   X  i ( w 1 , w 2 ,u )  X  0  X  i  X  F 10 N  X  X  u | priority( u )  X  0 ,u  X  Q n } ; 11 D  X  D  X  X  u | priority( u )=0 ,u  X  Q d } ; 12 Remove D from Q d ; 13 Update min i  X  F w \ S  X  ( i )in Q f ; 14 end 15 return S ; Algorithm 3: Controllable Accounts Linkage Alg.

Specifically, in each iteration, our CAL algorithm picks the feature in Q f with highest priority. Then, we update and Q n after removing the selected feature. CAL algorithm terminates if the number of users in Q d with priority 0 plus thenumberofusersin Q d with non-positive priority is larger than or equal to k . Otherwise, if there are users in Q n converting to distinctive users, remove them from Q n and insert to Q d .In Q f , we recompute the feature with highest priority if some users in Q d becomes to identical users to w , i.e., their priorities change to 0. If its new priority is invalid, we remove it from Q f and insert into the existing order. Note that in most cases, we only need to compute once to update Q f and this increases the efficiency of our CAL algorithm. The detail of CAL algorithm is described in Algorithm 3.

The running time of CAL algorithm is O ( | F w | ( | F w | | V 2 | log | V 2 | )) in the worst case. Note that a more careful im-plementation can reduce the running time to O ( | F w | ( | V 2 | )) by maintaining Q d ,Q n and Q f within time O ( | F and O ( | V 2 | ) respectively. In addition, CAL algorithm achieves k -anonymity of user w for any k&gt; 0.
In this section, we first introduce the mechanism by which we crawled the real-world datasets from multiple OSNs. Then, we evaluate our UALI and ICM approaches on these dataset-s, along with the applications enabled by ICM methodology. We collect datasets from three of the most popular OSNs, Google+, Twitter and Foursquare, via their public APIs. Due to the infeasibility of collecting all users X  information, we crawled the complete information for a few user accounts, called ego users and evaluate our methodologies using these user accounts. The linked crossing users are further crawled between ego users using APIs of these three OSNs. The dataset statistics is summarized in Table 1.
We start with Twitter API to obtain the information of a set of randomly selected Twitter users, marked as Twit-ter ego users. Next, we use the Twitter,Google+ and
Foursquare,Twitter linked crossing user collection method discussed below to find the linked crossing users to the above Twitter ego users on Google+ and Foursquare respectively. The links between Google+ and Foursquare ego users are further conducted using Google+, Foursquare linked cross-ing user collection method. The information of Google+ and Foursquare ego users are obtained using Google+ API and Foursquare API in the end. Note that in Foursquare, friends are considered as both followers and followees.
We discuss how to obtain the linkages for each pair of the above three OSNs.  X  Twitter,Google+ Linkage: In order to find linked Google+ users from Twitter users, we first search in Google+ API people/search function using the user X  X  first and last name, returning a list of users with the same name. Then, we search this list based on their Google+ user IDs and find thematcheduserbasedonhistwitterscreenname.Onthe other hand, starting from Google+ user, we can find their Twitter ID (if exists) using Google+ API directly.  X  Foursquare,Twitter Linkage: The usage of Foursquare API is enough to link Twitter and Foursquare users as it can start from either Foursquare ID or Twitter screen name.  X  Google+,Foursquare Linkage: There are two option-s to obtain the linked Google+ and Foursquare users: (1) use Google+ API to obtain Foursquare linked users from Google+ users; (2) search the set of Twitter users obtained using the above two linkage method. If a Twitter user links both a Google+ user and a Foursquare user, we link this pair of Google+,Foursquare users together.

Finally, we link all neighborhood of ego users, including friends, followers and followees, between these three OSNs and complete our datasets, shown as a summary in Table 1.
Account-Pair Features f (  X  ,  X  ) Construction. We ap-ply the following methods to construct the features of each account-pair based on users X  public information on all three OSNs described above. Note that the access of these data does not require the account authentication, which therefore will not be affected by user privacy settings.

Profile Features: (1) User First/Last Name: To calculate the similarity between first name and last name for two users on different OSNs, we employ a well-known string matching method, Jaro-Winkler distance [25]. This metric is designed to compare short string and give a score in the range of [0 , 1], in which the higher score stands for the higher simi-larity between two strings. (2) Location: We consider the geographical distance [6] between two cities, which calculat-ed by their longitudes and latitudes obtained using Google Geocoding API. (3) Profile Avatar: To compare two avatar images, we use OpenCV library [17] to first convert both im-ages to greyscale and generate their image histograms with the entire tonal distributions. Then, the difference of these two images can be obtained by comparing generated his-tograms.
Neighborhood Features: We select neighborhood features to be vector of length equal to the number of initially linked accounts. For each account-pair, the entry is set to 1 when the linked accounts are both their friend, follower or followee.
For example, consider four initially linked accounts ( A 1 ,  X  X  X  , ( D 1 ,D 2 ), where A 1 ,  X  X  X  ,D 1 and A 2 ,  X  X  X  ,D accounts on OSN1 and OSN2 respectively. For an account-pair ( E 1 ,E 2 ), when A 1 ,E 1 and A 2 ,E 2 , D 1 ,E 1 and are friends, we have their neighborhood vector (1,0,0,1).
Quasi Features: These features are defined as in Section 3.1. They are initially set to 0 and need to be iteratively obtained and updated.

Results. On each pair of OSNs, we construct the in-stances as follows: For the instances with positive labels, we construct the account-pair features for each linked cross-ing ego user. Then, we randomly select equal number of account-pairs who are surely not crossing users. To mea-sure the performance of UALI, we randomly select a subset of instances as an input of Algorithm 1 and test the rest of them using Algorithm 2. Note that we also conduct the experiments between a user account on one OSN and his crossing two linked accounts on other OSNs. As this gives us a similar result as that between two user accounts on two OSNs,wenextfocusontheresultoneachpairofOSNs.

We first show our results using different classifiers during training the function (  X  ,  X  ) in Algorithm 1, including Deci-sion Tree, Naive Bayes, SVM and Adaboost with Decision Stump as weak learners. We compare our predicted UALI back with the ground truth, using the metric of AUC s-core, the higher AUC score represents the more accurate user account linkage. As can be seen in Figure 3 (left col-umn), when using the Adaboost with Decision Stump to train (  X  ,  X  )inAlgorithm1,theAUCscoreofUALIreach-es more than 0.85 when only using 0.5% of linked crossing users as input in all these three datasets. The AUC score reaches up to 0.95 when taking 5% of linked crossing users as input in Algorithm 1. More specifically, we observe that
Foursquare, Twitter dataset achieves the best performance due to the sufficient large number of training set given by over 5000 linked crossing users. Moreover, the performance of our UALI model remains consistently good when using Adaboost for training (  X  ,  X  ). The reason is that Adaboost can always select the best features (when we use decision s-tump on each features) and assign an appropriate weight for each of them. In terms of the running time, as our approach only needs to take 0.5% to achieve high precision in most of practical scenarios, the running time of the best classifier, Adaboost, is less than 10 seconds. In addition, the running time of testing (Algorithm 2) is less than 3 seconds for each user accounts linkage, to find the linked user account among over 5000 users on another OSN.

Moreover, we further compare our UALI approach with other existing works, i.e., q -TFIDF [18], MOBIUS [28] (MO-BIUS contains Markov-Chain method in [18] as a subrou-tine), LU-Link [7], using precision and recall in which high recall means that an algorithm returned most of the cor-rect results, while high precision means that an algorithm returned substantially more correct results than incorrec-t. As illustrated in Figure 3 (right column), our proposed UALI method consistently outperforms existing methods in all three datasets. This is because the smartly generated quasi features turn out to be more useful than private user information required in MOBIUS and LU-Link methods.
Optimization of ICM. We compare the solution qual-ity of CAL algorithm, the core of ICM approach, with the optimal solution, which is provided via mathematical pro-gramming as follows: For each feature (public information) i of user w and each user u on OSN2, we define two indicator variables x i and y u as We have the following Integer Linear Programming (ILP): max s.t. i  X  F  X   X  ( w 1 , w 2 ,u ) x i  X   X (1  X  y u )  X  u  X  V where V 2 is the set of users on OSN2 and  X  is a large enough constant. The objective is to maximize the user information visibility as described in problem definition. The first con-straint ensures m ( w 1 , w 2 )  X  m ( w 1 ,u )foreachuser in the k -anonymity, i.e., y u = 1 for u  X  S . The second constraint guarantees the k -anonymity. This IP formulation is implemented using the CPLEX optimization suite from ILOG, which includes the simplex method [11], embedded with the branch &amp; bound algorithm and advanced cutting-plane techniques [26].

We test our CAL algorithm with different k values from 90% to 100% users on auxiliary OSN. As the experiments using one and two auxiliary OSNs again obtain very similar results, we next focus on the results with one auxiliary OSN.
Results. Table 2 shows the average performance of CAL algorithm against optimal solutions on each pair of OSNs. As one can see, the visibility returned by CAL algorithm is at most 0.4% smaller than optimal solution, and reaches op-timality in 3 datasets (marked bold). Moreover, the running time of CAL algorithm is consistently less than 10 seconds, which is up to 20 times faster than solving optimal solution. Service OSN1 Auxiliary OSN2 Foursquare Google+ 47.729 47.729 Twitter 49.254 49.312 Robustness for Various Inference Methods. As our CAL algorithm enables a majority of user X  X  information vis-ible when achieving the k -anonymity with high k values, one may question whether or not the visible information re-turned by CAL algorithm will leak the user X  X  privacy when using other classifiers in our UALI or other inference meth-ods. Therefore, we conduct UALI on the datasets with on-ly visible user information returned by CAL algorithm and show that it also works, i.e., robustness , for various classifiers of (  X  ,  X  ) learning in UALI as well as for existing methods.
Figure 4 shows the robustness of CAL algorithm by mea-suring anonymity level with respect to different k .Forin-stance, if we take k = 100 as an input in CAL algorithm for the user w and his visible information results in anonymizing himself from 10 users if using SVM in UALI, the anonymity level is said to be 10% with respect to SVM. The results reveal the average anonymity level using different inference methods on visible information returned by UALI. As illus-trated in Figure 4, this anonymity level remains consistently Figure 4: Robustness of CAL against various inference methods larger than 40% for distinct classifiers in UALI and reach over 90% for other existing methods. Since we select k be-tween 90% and 100% as described in previous experiments, the application of our ICM approach can still anonymize a user with at least other 40% users on average (almost achieve k -linkage anonymity for existing methods). In terms of dif-ferent datasets, when Foursquare is a service OSN, the ap-plication of CAL algorithm is more robust as there are very few friends for each user on Foursquare such that very few quasi features can be inferred. On the contrary, the ability to infer quasi features between Google+ and Twitter slightly reduces the robustness of CAL algorithm.
With the effectiveness of CAL algorithm observed through the above experiments, we confidently use it to further in-vestigate the applications enabled by our ICM approach in real-world traces and exploit some insight properties with respect to the user privacies and securities on OSNs. As we discussed in the introduction, user privacy disclosure is one of the most devastating consequences of user identity linkage attack. Therefore, we first explore the number of connections, including friends, followers and followees, that can be protected from being disclosed before and after ap-plying ICM. Next, as ICM studies the trade-off between user information visibility and privacy, we are also interested in observing the visible information after applying ICM for d-ifferent users. We explore these two aspects using the ego users in Table 1.
Figure 5 reports the distribution of protected user X  X  con-nections in the six datasets, i.e., each pair of OSNs as de-scribed in Section 5.1 with different service OSN. As one can see, our ICM approach results in the protection of at least 60% and up to 80% of users X  connections when either Google+ or Twitter is the service OSN. The protection per-centage drops dramatically when taking Foursquare as a ser-vice OSN due to the very small average number of friends.
Figure 6 shows that, although ICM lends a hand with privacy preservation, it can also provide the social service to the greatest extent by leaving a major of user informa-tion available in public. In spite of the lower visibility in Foursquare, again due to its limited number of friends, the visibility of over 75% user consistently remain between 80% and 100% in other datasets. The number of such users reach-es over 95% in Google+ &gt; Foursquare and Twitter &gt; Google+ datasets, mainly because of the large amount of connection-s which do not help with the user account linkage across OSNs.
User Account Linkage across Social Networks: Vosecky et al. [24] first studied the user identification across vari-ous OSNs via user X  X  profile information. Perito et al. [18] proposed to use usernames to link multiple profiles across social services. Unfortunately, most social services are using email addresses instead of usernames, which leads to the in-validation of this approach. Henderson et al. [10] developed the ReFeX method to recursively find effective node features for within-network and across-network classification and de-anonymization tasks. Shen et al. [19] proposed LINDEN to link named entities with the help of rich semantic knowl-edge. Goga et al. [7] introduced an approach to combine user X  X  posts features and link the users between Twitter and other OSNs. Recently, Zafarani et al. [28] proposed MO-BIUS for finding a mapping among identities of individuals across social media sites after identifying users X  behavioral patterns. However, most behavior patterns and user X  X  posts are usually unavailable in public, resulting in the impracti-cality of these two approaches. More importantly, the above researches only focused on the user identification, yet entire-ly ignored the countermeasures against the privacy issues created by such user accounts linkage across social media. In this paper, we identify a practical and easy-to-conduct user identity linkage inference with higher precision.
User Privacy: Irani et al. [12] showed that a user with only one OSN account reveals 4.3 personal information fields on average and this number increases to 8.25 when a user has 8 OSN accounts. Bilge et al. [3] investigated how easy it would be for an attacker to launch automated crawling and identity theft attacks across different OSNs and obtain a large amount of user private information. By conduct-ing profile cloning attacks, Shen et al. [20] illustrated that threats (e.g., malware, worm) can influence a lot more users after linking user accounts, resulting in user privacy leak-age, as threats can be propagated across different OSNs. The surveys of privacy and security in OSNs can be found in [15, 1]. However, the defense of these privacy issues still remains open and becomes an urgent need. In this paper, we show that our proposed countermeasure helps to largely reduce user X  X  privacy leakage and decrease the number of infected users during threats propagation.

Anonymization in Single OSN: There are many works ad-dressing the user anonymization [9]. Hay et al. [9] quantified the privacy risks for three classes of attacks, along with an anonymization approach with respect to network structure. Narayanan et al. [14] introduced a framework for priva-cy and anonymity analysis and de-anonymization algorithm only based on the network topology. Gundecha et al. [8] defined vulnerable friends and employed new strategies of unfriending vulnerable friends to leverage user X  X  privacy p-reservation. Zhou et al. [29, 30] defined another type of pri-vacy attacks, neighborhood attacks, and devised a practical approach for computing k -anonymous and l -diverse OSNs. A survey of privacy preservation in OSNs can be found in [27]. Unfortunately, these works only focused on network topologies and largely ignored many other public user in-formation. Taking into account the rich user information, Bhagat et al. [2] developed new techniques for anonymiz-ing social network data based on grouping the entities into classes. Recently, Shen et al. [21, 5] proposed a novel idea to construct on-the-fly trust circle to prevent the message from being propagated to unwanted audiences. However, these works fail to protect user X  X  privacy when the message are diffused across multiple OSNs via linked user accounts. Our proposed control mechanism on top of user account linkage inference helps to avoid the privacy leakage proactively.
Generalization of UALI inference and ICM control ap-proaches: Our proposed UALI and ICM approaches can be widely applied onto many other social services, i.e., help users raise their awareness of other risks and share their var-ious information to control different risks. As UALI takes arbitrary base features, it can extended into the inference of the user X  X  other information on OSNs such as group, check-in, interest and so on. ICM methodology, when taking dif-ferent matching score function m (  X  ,  X  ), can be generalized to control other risks in the literature [7, 10, 19, 28]. In addi-tion, by taking alternative v w i parameters, ICM can also be used to study the trade-off between risks and other social services (e.g., information sensitivity, utility).
Future Work: In this first control mechanism, we provide k -anonymity to measure the user privacy with only consider-ing the information on OSNs. When there are more external information available, such as third-party data repository, as k -anonymity is no longer provable, we are going to study more powerful provable privacy preservation schemes even with arbitrary public information, such as differential priva-cy, cryptography techniques and so on.
