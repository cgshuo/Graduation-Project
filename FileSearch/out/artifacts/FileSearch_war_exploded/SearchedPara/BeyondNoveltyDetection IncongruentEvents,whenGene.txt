 Machine learning builds models of the world using training data from the application domain and prior kno wledge about the problem. The models are later applied to future data in order to estimate the current state of the world. An implied assumption is that the future is stochastically similar to the past. The approach fails when the system encounters situations that are not anticipated from the past experience. In contrast, successful natural organisms identify new unanticipated stimuli and situations and frequently generate appropriate responses.
 By definition, an une xpected event is one whose probability to confront the system is low, based on the data that has been observ ed pre viously . In line with this observ ation, much of the computa-tional work on novelty detection focused on the probabilistic modeling of kno wn classes, identifying class classifiers have been proposed and used for novelty detection without the direct modeling of data distrib ution [3, 4]. There are man y studies on novelty detection in biological systems [5], often focusing on regions of the hippocampus [6].
 To adv ance beyond the detection of outliers, we observ e that there are man y dif ferent reasons why some stimuli could appear novel. Our work, presented in Section 2, focuses on une xpected events which are indicated by the incongruence between prediction induced by prior experience (training) and the evidence pro vided by the sensory data. To identify an item as incongruent, we use two parallel classifiers. One of them is strongly constrained by specific kno wledge (both prior and data-deri ved), the other classifier is more general and less constrained. Both classifiers are assumed to yield class-posterior probability in response to a particular input signal. A suf ficiently lar ge discrepanc y between posterior probabilities induced by input data in the two classifiers is tak en as indication that an item is incongruent.
 Thus, in comparison with most existing work on novelty detection, one new and important charac-teristic of our approach is that we look for a level of description where the novel event is highly probable. Rather than simply respond to an event which is rejected by all classifiers, which more often than not requires no special attention (as in pure noise), we construct and exploit a hierarchy of representations. We attend to those events which are recognized (or accepted) at some more abstract levels of description in the hierarchy , while being rejected by the more concrete classifiers. There are various ways to incorporate prior hierarchical kno wledge and constraints within dif ferent classifier levels, as discussed in Section 3. One approach, used to detect images of une xpected in-congruous objects, is to train the more general, less constrained classifier using a lar ger more diverse set of stimuli, e.g., the facial images of man y indi viduals. The second classifier is trained using a more specific (i.e. smaller) set of specific objects (e.g., the set of Einstein X  s facial images). An incongruous item (e.g., a new indi vidual) could then be identified by a smaller posterior probability estimated by the more specific classifiers relati ve to the probability from the more general classifier . A dif ferent approach is used to identify une xpected (out-of-v ocab ulary) lexical items. The more general classifier is trained to classify sequentially speech sounds (phonemes) from a relati vely short segments of the input speech signal (thus yielding an unconstrained sequence of phoneme labels); the more constrained classifier is trained to classify a particular set of words (highly constrained sequences of phoneme labels) from the information available in the whole speech sentence. A word that did not belong to the expected vocab ulary of the more constrained recognizer could then be identified by discrepanc y in posterior probabilities of phonemes deri ved from both classifiers. Our second contrib ution in Section 2 is the presentation of a unifying theoretical frame work for these two approaches. Specifically , we consider two kinds of hierarchies: Part member ship as in biological taxonomy or speech, and Class member ship , as in human cate gorization (or levels of cate gorization). We define a notion of partial order on such hierarchies, and identify those events whose probability as computed using dif ferent levels of the hierarchy does not agree. In particular , we are interested in those events that recei ve high probability at more general levels (for example, the system is certain that the new example is a dog), but low probability at more specific levels (in the same example, the system is certain that the new example is not any kno wn dog breed). Such events correspond to man y interesting situations that are worthy of special attention, including incongruous scenes and new sub-classes, as sho wn in Section 3. 2.1 Intr oducing label hierar chy The set of labels represents the kno wledge base about stimuli, which is either given (by a teacher in supervised learning settings) or learned (in unsupervised or semi-supervised settings). In cogniti ve systems such kno wledge is hardly ever a set; often, in fact, labels are given (or can be thought of) as a hierarchy . In general, hierarchies can be represented as directed graphs. The nodes of the graphs may be divided into distinct subsets that correspond to dif ferent entities (e.g., all objects that are animals); we call these subsets  X  X e vels X . We identify two types of hierarchies: Part membership , as in biological taxonomy or speech. For example, eyes, ears, and nose combine to form a head; head, legs and tail combine to form a dog.
 Class membership , as in human cate gorization  X  where objects can be classified at dif ferent levels of generality , from sub-ordinate cate gories (most specific level), to basic level (intermediate level), to super -ordinate cate gories (most general level). For example, a Beagle (sub-ordinate cate gory) is also a dog (basic level cate gory), and it is also an animal (super -ordinate cate gory). The two hierarchies defined abo ve induce constraints on the observ ed features in dif ferent ways. In the class-member ship hierarchy , a parent class admits higher number of combinations of features than any of its children, i.e., the parent cate gory is less constrained than its children classes. In contrast, a parent node in the part-member ship hierarchy imposes stricter constraints on the observ ed features than a child node. This distinction is illustrated by the simple  X  X o y X  example sho wn in Fig. 1. Roughly speaking, in the class-membership hierarchy (right panel), the parent node is the disjunction of the child cate gories. In the part-membership hierarchy (left panel), the parent cate gory represents a conjunction of the children cate gories. This dif ference in the effect of constraints between the two representations is, of course, reflected in the dependenc y of the posterior probability on the class, conditioned on the observ ations. In order to treat dif ferent hierarchical representations uniformly we invoke the notion of partial specific concept, which corresponds to a smaller set of events or objects in the world, is always smaller than the more general concept, which corresponds to a lar ger set of events or objects. To illustrate this point, consider Fig. 1 again. For the part-membership hierarchy example (left panel), the concept of  X  X og X  requires a conjunction of parts as in DOG = LEGS \ HEAD \ TAIL , and therefore, for example, DOG LEGS ) DOG LEGS . Thus In contrast, for the class-membership hierarchy (right panel), the class of dogs requires the conjunc-tion of the indi vidual members as in DOG = AFGHAN [ BEA GEL [ COLLIE , and therefore, for example, DOG AFGHAN ) DOG AFGHAN . Thus 2.2 Definition of Incongruent Ev ents Notations We assume that the data is represented as a Graph f G; E g of Partial Orders ( GP O ). Each node in G is a random variable which corresponds to a class or concept (or event). Each directed link in E corresponds to partial order relationship as defined abo ve, where there is a link from node a to node b iff a b .
 For each node (concept) a , define A s = f b 2 G; b a g -the set of all nodes (concepts) b more specific (smaller) than a in accordance with the given partial order; similarly , define A g = f b 2 G; a b g -the set of all nodes (concepts) b more general (lar ger) than a in accordance with the given partial order .
 For each concept a and training data T , we train up to 3 probabilistic models which are deri ved from T in dif ferent ways, in order to determine whether the concept a is present in a new data point X : Examples To illustrate, we use the simple examples sho wn in Fig. 1, where our concept of interest a is the concept  X  X og X : In the part-membership hierarchy (left panel), j A g j = 3 (head, legs, tail). We can therefore learn 2 models for the class  X  X og X  ( Q s In the class-membership hierarchy (right panel), j A s j = 3 (Afghan, Beagle, Collie). If we further assume that a class-membership hierarchy is always a tree, then j A g j = 1 . We can therefore learn 2 models for the class  X  X og X  ( Q g Incongruent events In general, we expect the dif ferent models to pro vide roughly the same probability for the presence of concept a in data X . A mismatch between the predictions of the dif ferent models should raise the red flag, possibly indicating that something new and interesting had been observ ed. In particular , we are interested in the follo wing discrepanc y: Definition : Observation X is incongruent if ther e exists a concept 0 a 0 suc h that Alternati vely , observ ation X is incongruent if a discrepanc y exists between the inference of the two classifiers: either the classifier based on the more general descriptions from level g accepts the X while the direct classier rejects it, or the direct classifier accepts X while the classifier based on the more specific descriptions from level s rejects it. In either case, the concept recei ves high probability at the more general level (according to the GP O ), but much lower probability when relying only on the more specific level.
 Let us discuss again the examples we have seen before, to illustrate why this definition indeed captures interesting  X  X urprises X : Our definition for incongruent events in the pre vious section is indeed unified, but as a result quite abstract. In this section we discuss two dif ferent algorithmic implementations, one generati ve and one discriminati ve, which were developed for the part member ship and class member ship hierar -probability as defined abo ve, and p ( x ) for the estimated probability . 3.1 Part membership -a generati ve algorithm Consider the left panel of Fig. 1. The event in the top node is incongruent if its probability is low, while the probability of all its descendants is high.
 In man y applications, such as speech recognition, one computes the probability of events (sentences) based on a generati ve model (corresponding to a specific language) which includes a dictionary of parts (w ords). At the top level the event probability is computed conditional on the model; in which case typically the parts are assumed to be independent, and the event probability is computed as the multiplication of the parts probabilities conditioned on the model. For example, in speech pro-cessing and assuming a specific language (e.g., English), the probability of the sentence is typically computed by multiplying the probability of each word using an HMM model trained on sentences from a specific language. At the bottom level, the probability of each part is computed independently of the generati ve model.
 More formally , Consider an event u composed of parts w and assuming the conditional independence of the parts given this model, the prior probability of the event is given by the product of prior probabilities of the parts, where L denotes the generati ve model (e.g., the language).
 For measurement X , we compute Q ( X ) as follo ws using p ( X j u; L ) = p ( X j u ) and (3), and where u = arg max tion. At the risk of notation abuse, f w u . We assume that the first sum is dominated by the maximal term.
 Given a part-membership hierarchy , we can use (1) to compute the probability Q g ( X ) directly , without using the generati ve model L .
 It follo ws from (4) and (5) that We can now conclude that X is an incongruent event according to our definition if there exists at least one part k in the final event u , such that p ( w roughly the same conditional and unconditional probabilities). In speech processing, a sentence is incongruent if it includes an incongruent word -a word whose probability based on the generati ve language model is low, but whose direct probability (not constrained by the language model) is high. Example: Out Of Vocab ulary (OO V) words For the detection of OO V words, we performed experiments using a Lar ge Vocab ulary Continuous Speech Recognition (LVCSR) system on the Wall Street Journal Corpus (WSJ). The evaluation set consists of 2.5 hours. To introduce OO V words, the vocab ulary was restricted to the 4968 most frequent words from the language training texts, lea ving the remaining words unkno wn to the model. A more detailed description is given in [7].
 In this task, we have sho wn that the comparison between two parallel classifiers, based on strong and weak posterior streams, is effecti ve for the detection of OO V words, and also for the detection of recognition errors. Specifically , we use the deri vation abo ve to detect out of vocab ulary words, by comparing their probability when computed based on the language model, and when computed based on mere acoustic modeling. The best performance was obtained by the system when a Neural Netw ork (NN) classifier was used for the direct estimation of frame-based OO V scores. The netw ork was directly fed by posteriors from the strong and the weak systems. For the WSJ task, we achie ved performance of around 11% Equal-Error -Rate (EER) (Miss/F alse Alarm probability), see Fig. 2. Figure 2: Several techniques used to detect OO V: (i) Cmax: Confidence measure computed ONL Y from 3.2 Class membership -a discriminati ve algorithm Consider the right panel of Fig. 1. The general class in the top node is incongruent if its probability is high, while the probability of all its sub-classes is low. In other words, the classifier of the parent object accepts the new observ ation, but all the children object classifiers reject it. Brute force computation of this definition may follo w the path tak en by traditional approaches to novelty detection, e.g., looking for rejection by all one class classifiers corresponding to sub-class objects. The result we have obtained by this method were mediocre, probably because generati ve models are not well suited for the task. Instead, it seems lik e discriminati ve classifiers, trained to discriminate between objects at the sub-class level, could be more successful. We note that unlik e traditional approaches to novelty detection, which must use generati ve models or one-class classifiers in the absence of appropriate discriminati ve data, our dependence on object hierarchy pro vides discrimi-nati ve data as a by-product. In other words, after the recognition by a parent-node classifier , we may use classifiers trained to discriminate between its children to implement a discriminati ve novelty detection algorithm.
 Specifically , we used the approach described in [8] to build a unified representation for all objects in the sub-class level, which is the representation computed for the parent object whose classifier had accepted (positi vely recognized) the object. In this feature space, we build a classifier for each sub-class based on the majority vote between pairwise discriminati ve classifiers. Based on these classifiers, each example (accepted by the parent classifier) is assigned to one of the sub-classes, and the average mar gin over classifiers which agree with the final assignment is calculated. The final classifier then uses a threshold on this average mar gin to identify each object as kno wn sub-class or new sub-class. Pre vious research in the area of face identification can be vie wed as an implicit use of this propsed frame work, see e.g. [9].
 Example: new face recognition from audio-visual data We tested our algorithm on audio-visual speak er verification. In this setup, the general parent cate-gory level is the  X  X peech X  (audio) and  X  X ace X  (visual), and the dif ferent indi viduals are the offspring (sub-class) levels. The task is to identify an indi vidual as belonging to the trusted group of indi vid-uals vs. being unkno wn, i.e. kno wn sub-class vs. new sub-class in a class membership hierarchy . The unified representation of the visual cues was built using the approach described in [8]. All objects in the sub-class level (dif ferent indi viduals) were represented using the representation learnt for the parent level ( X  X ace X ). For the audio cues we used the Perceptual linear predicti ve (PLP) Cepstral features [10 ] as the unified representation. We used SVM classifiers with RBF kernel as the pairwise discriminati ve classifiers for each of the dif ferent audio/visual representations separately . Data was collected for our experiments using a wearable device, which included stereo panoramic vision sensors and microphone arrays. In the recorded scenario, indi viduals walk ed towards the device and then read aloud an identical text; we acquired 30 sequences with 17 speak ers (see Fig. 3 for an example). We tested our method by choosing six speak ers as members of the trusted group, while the rest were assumed unkno wn.
 The method was applied separately using each one of the dif ferent modalities, and also in an in-tegrated manner using both modalities. For this fusion the audio signal and visual signal were synchronized, and the winning classification mar gins of both signals were normalized to the same scale and averaged to obtain a single mar gin for the combined method.
 Since the goal is to identify novel incongruent events, true positi ve and false positi ve rates were calculated by considering all frames from the unkno wn test sequences as positi ve events and the kno wn indi vidual test sequences as negati ve events. We compared our method to novelty detection based on one-class SVM [3] extended to our multi-class case. Decision was obtained by comparing the maximal mar gin over all one-class classifiers to a varying threshold. As can be seen in Fig. 3, our method performs substantially better in both modalities as compared to the  X  X tandard X  one class approach for novelty detection. Performance is further impro ved by fusing both modalities. Une xpected events are typically identified by their low posterior probability . In this paper we em-plo yed label hierarchy to obtain a few probability values for each event, which allo wed us to tease apart dif ferent types of une xpected events. In general there are 4 possibilities, based on the classi-fiers X  response at two adjacent levels: Figure 3: Left: Example: one frame used for the visual verification task. Right: True Positi ve vs. False We focused abo ve on the second type of events -incongruent concepts, which have not been studied pre viously in isolation. Such events are characterized by some discrepanc y between the response of two classifiers, which can occur for a number dif ferent reasons: Conte xt: in a given conte xt such as the English language, a sentence containing a Czech word is assigned low probability . In the visual domain, in a given conte xt such as a street scene, otherwise high probability events such as  X  X ar X  and  X  X lephant X  are not lik ely to appear together . Ne w sub-class: a new object has been encountered, of some kno wn generic type but unkno wn specifics.
 We described how our approach can be used to design new algorithms to address these problems, sho wing promising results on real speech and audio-visual facial datasets.

