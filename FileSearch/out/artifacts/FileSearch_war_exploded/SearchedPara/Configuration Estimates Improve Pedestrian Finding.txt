 Very accurate pedestrian detectors are an important technical goal; approximately half-a-million pedestrians are killed by cars each year (1997 figures, in [1]). At relatively low resolution, pedestri-ans tend to have a characteristic appearance. Generally, one must cope with lateral or frontal views of a walk. In these cases, one will see either a  X  X ollipop X  shape  X  the torso is wider than the legs, which are together in the stance phase of the walk  X  or a  X  X cissor X  shape  X  where the legs are swinging in the walk. This encourages the use of template matching. Early template matchers in-clude: support vector machines applied to a wavelet expansion ([2], and variants described in [3]); a neural network applied to stereoscopic reconstructions [4]; chamfer matching to a hierachy of con-tour templates [5]; a likelihood threshold applied to a random field model [6]; an SVM applied to spatial wavelets stacked over four frames to give dynamical cues [3]; a cascade architecture applied to spatial averages of temporal differences [7]; and a temporal version of chamfer matching to a hierachy of contour templates [8].
 By far one of the most successful static template matcher is due to Dalal and Triggs [9]. Their method is based on a comprehensive study of features and their effects on performance for the pedestrian detection problem. The method that performs best involves a histogram of oriented gra-dient responses (a HOG descriptor). This is a variant of Lowe X  X  SIFT feature [10]. Each window is decomposed into overlapping blocks (large spatial domains) of cells (smaller spatial domains).In each block, a histogram of gradient directions (or edge orientations) is computed for each cell with a measure of histogram  X  X nergy X . These cell histograms are concatenated into block histograms followed by normalization which obtains a modicum of illumination invariance. The detection win-dow is tiled with an overlapping grid. Within each block HOG descriptors are computed, and the resulting feature vector is presented to an SVM. Dalal and Triggs show this method produces no errors on the 709 image MIT dataset of [2]; they describe an expanded dataset of 1805 images. Fur-thermore, they compare HOG descriptors with the original method of Papageorgiou and Poggio [2]; with an extended version of the Haar wavelets of Mohan et al. [11]; with the PCA-Sift of Ke and Sukthankar ([12]; see also [13]); and with the shape contexts of Belongie et al. [14]. The HOG descriptors outperform all other methods. Recently, Sabzmeydani and Mori [15] reported improved results by using AdaBoost to select shapelet features (triplets of location, direction and strength of local average gradient responses in different directions).
 A key difficulty with pedestrian detection is that detectors must work on human configurations not often seen in datasets. For systems to be useful, they cannot fail even on configurations that are very uncommon  X  it is not acceptable to run people over when they stand on their hands. There is some evidence (figure 1) that less common configurations present real difficulties for very good current pedestrian detectors (our reimplementation of Dalal and Triggs X  work [9]).
 1.1 Configuration and Parts Detecting pedestrians with templates most likely works because pedestrians appear in a relatively limited range of configurations and views (e.g.  X  X ur HOG detectors cue mainly on silhouette con-tours (especially the head, shoulders and feet) X  [9], p.893). It appears certain that using the architec-ture of constructing features for whole image windows and then throwing the result into a classifier could be used to build a person-finder for arbitrary configurations and arbitrary views only with a major engineering effort. The set of examples required would be spectacularly large, for example. This is unattractive, because this set of examples implicitly encodes a set of facts that are relatively easy to make explicit. In particular, people are made of body segments which individually have a quite simple structure, and these segments are connected into a kinematic structure which is quite well understood.
 All this suggests finding people by finding the parts and then reasoning about their layout  X  essen-tially, building templates with complex internal kinematics. The core idea is very old (see the review in [16]) but the details are hard to get right and important novel formulations are a regular feature of the current research literature.
 Simply identifying the body parts can be hard. Discriminative approaches use classifiers to detect parts, then reason about configuration [11]. Generative approaches compare predictions of part appearance with the image; one can use a tree structured configuration model [17], or an arbitrary graph [18]. If one has a video sequence, part appearance can itself be learned [19, 20]; more recently, Ramanan has shown knowledge of articulation properties gives an appearance model in a single image [21]. Mixed approaches use a discriminative model to identify parts, then a generative model to construct and evaluate assemblies [22, 23, 24]. Codebook approaches avoid explicitly modelling body segments, and instead use unsupervised methods to find part decompositions that are good for recognition (rather than disarticulation) [25].
 configuration of the best person available in that window; second, we extract features for that win-dow conditioned on the configuration estimate, and pass these features to a support vector machine classifier, which makes the final decision on the window.
 We are presented with a window within which may lie a pedestrian. We would like to be able that this estimate will improve pedestrian detector perfomance by reducing the amount of noise from a window to a (rectified) figure. We follow convention (established by [26]) and model the configuration of a person as a tree model of segments (figure 2), with a score of segment quality and a score of segment-segment configuration. We ignore arms because they are small and difficult to localize. Our configuration estimation procedure will use dynamic programming to extract the best configuration estimate from a set of scores depending on the location of vertices on the body model. However, we do not know which features are most effective at estimating segment location; this is a well established difficulty in the literature [16]. Structure learning is a method that uses a series of correct examples to estimate appropriate weightings of features relative to one another to produce a score that is effective at estimating configuration [27, 28]. We will write the image as I ; coordinates in the image as x ; the coordinates of an estimated configuration as y (which is a stack of 7 point coordinates); the score for this configuration as W T f ( I , x ; y ) (which is a linear combination of a collection of scores, each of which depends on the configuration and the image).
 For a given image I and this can be found with dynamic programming for appropriate choice of f and y ( I variety of sensible choices of features for identifying body segments, but there is little evidence that a particular choice of features is best; different choices of W may lead to quite different behaviours. In particular, we will collect a wide range of features likely to identify segments well in f , and wish to learn a choice of W that will give good configuration estimates.
 We choose a loss function L ( y is y t . Write the set of n examples as E , and y p,i as the prediction for the i  X  X h example. Structure learning must now estimate a W to minimize the hinge loss as in [29] subject to the constraints At the minimum, the slack variables  X  move the constraints to the objective function, which is: 1 2 Notice that this function is convex, but not differentiable. We follow Ratliff et al. [29], and use the subgradient method (see [30]) to minimize. In this case, the derivative of the cost function at an extremal y everywhere). There are two sets of features: first, those used for estimating configuration of a person from a window; and second, those used to determine whether a person is present conditioned on the best estimate of configuration. 3.1 Features for Estimating Configuration We use a tree structured model, given in figure 2. The tree is given by the position of seven points, and encodes the head, torso and legs; arms are excluded because they are small and difficult to identify, and pedestrians can be identified without localizing arms. The tree is rooted at hips, and the arrows give the direction of conditional dependence. We assume that torso, lef tleg, rightleg are conditionally independent given the root (at the hip).
 The feature vector f ( I , x ; y ) contains two types of feature: appearance features encode the appear-ance of putative segments; and geometric features encode relative and absolute configuration of the body segments.
 Each geometric feature depends on at most three point positions. We use three types of feature. First, the length of a segment, represented as a 15-dimensional binary vector whose elements encode whether the segment is longer than each of a set of test segments. Second, the cosine of the angle between a segment and the vertical axis. Third, the cosine of the angle between pairs of adjoin-ing segments (except at the lower torso, for complexity reasons); this allows the structure learning method to prefer straight backs, and reasonable knees.
 Appearance features are computed for rectangles constructed from pairs of points adjacent in the tree. For each rectangle, we compute Histogram of Oriented Gradient (HOG) features, after [9]. These features have a strong record in pedestrian detection, because they can detect the patterns of orientation associated with characteristic segment outlines (typically, strong vertical orientations in the frame of the segment for torso and legs; strong horizontal orientations at the shoulders and head). However, histograms involve spatial pooling; this means that one can have many strong vertical orientations that do not join up to form a segment boundary. This effect means that HOG features alone are not particularly effective at estimating configuration.
 To form these features, we concatenate the horizontal and vertical gradients of the patches in the segment coordinate frame, then normalize and apply PCA to reduce the number of dimensions. Since we want to model the appearance, we do not align the orientation to a canonical orientation as in PCA-SIFT. This feature reveals whether the pattern of a body part appears at that location. The PCA space for each body part is constructed from 500 annotated positive examples. 3.2 Features for Detection Once the best configuration has been obtained for a window, we must determine whether a person is present or not. We do this with a support vector machine. Generally, the features that determine configuration should also be good for determining whether a person is present or not. However, a set of HOG features for the whole image window has been shown to be good at pedestrian detection [9]. The support vector machine should be able to distinguish between good and bad features, so it is natural to concatenate the configuration features described above with a set of HOG features. We find it helpful to reduce the dimension of the set of HOG features to 500, using principal components. We find that these whole window features help recover from incorrect structure predictions. These combined features are used in training the SVM classifier and in detection as well. Dataset: We use INRIA Person, consisting of 2416 pedestrian images (1208 images with their left-right reflections) and 1218 background images for training. For testing, there are 1126 pedestrian images (563 images with their left-right reflections) and 453 background images.
 Training structure learning: we manually annotate 500 selected pedestrian images in the training set examples. We use all 500 annotated examples to build the PCA spaces for each body segment. In training, each example is learned to update the weight vector. The order of selecting examples in each round is randomly drawn based on the differences of their scores on the predictions and their scores on the true targets. For each round, we choose 300 examples drawn (since structure learning is expensive). We have trained the structure learning on 10 rounds and 20 rounds for comparisons. Quality of configuration estimates: Configuration estimates look good (figure 2). A persistent place legs on top of one another. This occurs if one uses only appearance and relative geometric features. However, our results suggest that if one uses absolute configuration features as well as different appearance features for left and right legs (implicit in the structure learning procedure), the left and right legs are identified correctly. The conditional independence assumption (which means we cannot use the angle between the legs as a feature) does not appear to cause problems, perhaps because absolute configuration features are sufficient.
 Bootstrapping the SVM: The final SVM is bootstrapped, as in [9]. We use 2146 pedestrian images with 2756 window images extracted from 1218 background images. We apply the learned structure model to generate on these 2416 positive examples and 2756 negative examples to train the initial SVM classifier. We then use this classifier to scan over 1218 background images with step side of 32 pixels and find hard examples (including false positives and true negatives of low confidence by using LibSVM [31] with probability option). These negatives yield a bootstrap training set for the final SVM classifier. This bootstrap learning helps to reduce the false alarm significantly. Testing: We test on 1126 positive images and scan 64x128 image windows over 453 negative test images, stepping by 16 pixels, a total of 182, 934 negative windows.
 Scanning rate and comparison: Pedestrian detection systems work by scanning image windows, and presenting each window to a detector. Dalal and Triggs established a methodology for evaluating pedestrian detectors, which is now quite widely used. Their dataset offers a set of positive windows (where pedestrians are centered), and a set of negative images. The negative images produce a and the false positive per window (FPPW) rate on the negative windows. This strategy  X  which evaluates the detector, rather than the combination of detection and scanning  X  is appropriate for comparing systems that scan image windows at approximately the same high rate. Current systems do so, because the detectors require nearly centered pedestrians. However, the important practical parameter for evaluating a system is the false positive per image (FPPI) rate. If one has a detector that does not require a pedestrian to be centered in the image window, then one can obtain the same detect rate while scanning fewer image windows. In turn, the FPPI rate will go down even if the FPPW rate is fixed. To date, this issue has not arisen, because pedestrian detectors have required pedestrians to be centered.
 4.1 The Effect of Configuration Estimates Figure 3 compares our detector with that of Dalal and Triggs, and of Sabzmeydani and Mori on the basis of detect and FPPW rates. We plot detect rate against FPPW rate for the three detectors. For this plot, note that at low FPPW rate our method is somewhat more sensitive than that of Sabzmey-dani and Mori, but has no advantage at higher FPPW rates.
 However, this does not tell the whole story. We scan images at steps of 16 pixels (rather than 8 pixels for Dalal and Triggs and Sabzmeydani and Mori). This means that we scan four times fewer windows than they do. If we can establish that the detect rate is not significantly affected by big offsets in pedestrian position, then we expect a large advantage in FPPI rate.
 We evaluate the effect on the detect rate of scanning by large steps by a process of sampling. Each positive example is replaced by a total of 256 replicates, obtained by offsetting the image window by steps in the range -7 to 8 in x and y (figure 4). We now conduct multiple evaluation runs. For each, we select one replicate of each positive example uniformly at random. For each run, we evaluate the detect rate. A tendency of the detector to require centered pedestrians would appear as variance in the reported detect rate. The FPPI rate of the detector is not affected by this procedure, which evaluates only the spatial tuning of the detector.
 Figure 3 compares system performance, combining detect and scanning rates, by plotting detect rate against FPPI rate. We show four evaluation runs for our system; there is no evidence of substantial variance in detect rate. Our system shows a very substantial increase in detect rate at fixed FPPI rate. There is a difficulty with the evaluation methodology for pedestrian detection established by Dalal and Triggs (and widely followed). A pedestrian detector that tests windows cannot find more pedes-trians than there are windows. This does not usually affect the interpretation of precision and recall statistics because the windows are closely packed. However, in our method, because a pedestrian need not be centered in the window to be detected, the windows need not be closely packed, and there is a possibility of undercounting pedestrians who stand too close together. We believe that this does not occur in our current method, because our window spacing is narrow relative to the width of a pedestrian.
 Part representations appear to be a natural approach to identifying people. However, to our knowl-edge, there is no clear evidence to date that shows compelling advantages to using such an approach (e.g. the review in [16]). We believe our method does so. Configuration estimates appear to have two important advantages. First, they result in a detector that is relatively insensitive to the placement of a pedestrian in an image window, meaning one can look at fewer image windows to obtain the same detect rate, with consequent advantages to the rate at which the system produces false positives. This is probably the dominant advantage. Second, configuration estimates appear to be a significant help at high specificity settings (notice that our method beats all others on the FPPW criterion at very low FPPW rates). This is most likely because the process of estimating configurations focuses the detector on important image features (rather than pooling information over space). The result would be that, when there is low contrast or a strange body configuration, the detector can use a somewhat lower detection threshold for the same FPPW rate. Figure 1 shows human configurations detected by our method but not by our implementation of Dalal and Triggs; notice the predominance of either strange body configurations or low contrast. Structure learning is an attractive method to determine which features are discriminative in configuration estimation, and it produces good configuration estimates in complex images. Future work will include: tying W components for legs; evaluating arm detection; and formulating strategies to employ structure learning for detecting other objects.
