 The efficiency of personal suggestions generated by collabo-rative filtering techniques is highly dependent on the quality and quantity of the available consumption data. Extending data sets with additional consumption data (from the past) might enrich the user profiles and generally leads to more ac-curate recommendations. Although if a considerable amount of profile information is already available and detailed per-sonal preferences can be derived, supplementary consump-tion data may not have any (or a very limited) added value for the recommendation algorithm. These additional con-sumption data increase the required storage capacity and the computational load to generate the personal recommen-dations. Moreover, since personal preferences and the rele-vance of content items may vary over time, older consump-tion data might be outdated and lead to inaccurate recom-mendations. Therefore, we investigate which consumption data are (the most) relevant to feed the conventional collab-orative filtering algorithms. For provider-generated content systems, we demonstrate that the accuracy of collaborative filtering algorithms increases by extending user profiles with additional older consumption data. In contrast, we witness the opposite effect for user-generated content systems: in-volving older consumption data has a negative influence on the recommender accuracy. The se results are important for website owners who intend to employ a recommendation sys-tem at a minimum storage and computation cost.
 H.4 [ Information Systems Applications ]: Miscellaneous Algorithms, Performance Recommender systems, Collaborative filtering, Data quality
Despite the popularity of collaborative filtering (CF) tech-niques, the required storage and computational cost might seriously increase for large-scale online systems due to the quadratic nature of the neighbourhood selection process [7]. Therefore, we opted for a different approach by investigat-ing the minimal amount of consumption data required as input to acquire optimal recommendations. If as soon as a certain amount of consumption data is obtained, additional consumption data do not contribute to a further increase in recommendation accuracy, then these additional data can be considered as useless for a recommender. As a result, these additional consumption data do not have to be stored anymore and can be excluded from the calculations, which reduces the storage and calculation costs for website owners. The remainder of this paper is organised as follows: Sec-tion 2 presents the applied research process and describes in detail the employed data sets, evaluation method and eval-uation metrics. In Section 3, we discuss the results obtained by three different experiments on two representative data sets. Finally, we offer a brief conclusion and point out inter-esting future work in Section 4.
To determine the minimal amount of consumption data that is required to acquire optimal recommendations, we calculated recommendations based on different versions of the consumption history in successive iterations. These ver-sions vary in the number of consumptions and as a result in the sparsity of the data matrix, which can be derived from the consumption history. The accuracy of the gener-ated recommendations will be compared for the successive iterations based on evaluation metrics which are generated by an offline analysis on a test set of consumptions.
To estimate the effectiveness of personal recommenda-tions, two different evaluation methods are possible. On the one hand, online evaluations measure how the user in-teracts (e.g. clicking, buying behaviour) with the presented recommendations on a running service. Offline evaluations, on the other hand, partition historical consumption data in a training set and a test set. Based on the training set, the rec-ommender has to predict the consumption behaviour in the test set. Although online evaluation methods are closest to reality, we opted for an offline evaluation based on data sets because such an evaluation is fast, reproducible and com-monly used in recommendation research. We performed the evaluations with two different data sets: one data set that contains consumption behaviour of provider-generated con-tent and one with consumption behaviour of user-generated content. To evaluate the recommendations for provider-generated content, we opted for a data set that is commonly used to bench-mark recommendation algorithms, namely the (medium-size) Movielens data set [8]. This set contains 3,706 items (videos), 6,040 active users and 1,000,209 dis-tinct consumptions, logged from April 2000 until February 2003, which we ordered chronologically and transformed to a binary scale.

Although user-generated content systems are increasingly popular on the Internet, data sets with consumption be-haviour of user-generated content are less common in recom-mendation research. Therefore, we used a less well known data set with user-generated content behaviour collected at PianoFiles [1]. PianoFiles is a user-generated content site that offers users the opportunity to exchange, browse and search for sheet music they like to play. Currently, users can manage their personal collection of sheet music on Pi-anoFiles but they do not yet receive personal recommen-dations. The main consumption behaviour, used to feed the recommendation algorithm, consists of the personal col-lections of the users. Each addition to a personal collec-tion is used to populate the consumption matrix. This full data set contains 110,809 items (sheets), 85,537 active users and 1,211,572 distinct consumptions in chronological order, logged from May 2003 until September 2009. So, the con-sumption behaviour is gathered over a longer period of time on PianoFiles than on Movielens. Nevertheless, the time window of these two data sets is comparable since most con-sumption behaviour of PianoFiles was registered during the last 3 years. Moreover, Movielens and PianoFiles contain ap-proximately the same number of consumptions in their data set. However, due to the typical content (production) char-acteristics of user-generated content systems [3], the spar-sity of the PianoFiles data set is much higher than that of Movielens, which makes it more difficult to calculate accu-rate predictions for PianoFiles. For instance, approximately 50% of the PianoFiles users are suffering from the cold start problem, having a limited profile of less than 5 sheets in their collection. Conversely, a considerable part of the PianoFiles users (approximately 14%) has a collection containing more than 20 sheets, which enables a recommendation system to calculate detailed suggestions.
For evaluation purposes, we used the 50% most recent con-sumption data as the test set. The remaining 50% of the con-sumption records were used as input data. This offline eval-uation methodology, in which a data set is chronologically split in training set and test set, is commonly used to eval-uate recommendation algorithms [4]. In order to study the performance of the algorithm with data of different sparsity levels, we composed ten different training sets by eliminating 0%, 10%, 20%, ...up to 90% of the i nput data. Afterwards, the recommendation algorithm used these different training sets in successive iterations to generate personal suggestions. As is commonly done for the evaluation of recommendations under sparse data [6], the test set was first filtered to include only consumptions that are predictable with the input data as a priori knowledge. A consumption of an item that is Figure 1: The evaluation of the UBCF with ran-domly depleted input data as training set. The graphs visualize the evolution of the precision, re-call and F1 as a function of the percentage of input data that is eliminated. not contained in the input data or a consumption of a user without any consumption behaviour in the input data is im-possible to predict with CF techniques. All users of this filteredtestsetwereincludedintoasetoftargetconsumers. For each of these consumers, the algorithm generated five ordered lists of 10, 20, 30, 40 and 50 recommendations re-spectively, which were compared with the test set. (Only the results for 20 recommendations per user are shown in this paper, since the other results illustrate the same con-clusions.) One of the most frequently used error metrics is the Root Mean Squared Error (RMSE) [5, 2], which was also adopted by the official Netflix contest. However, the Netflix contest was mainly focused on predicting accurate ratings for an entire set of items, while web-based applications are mostly interested in providing the users with a short rec-ommendation list of interesting items [2]. To evaluate this top-N recommendation task, i.e. a context in which we are not interested in predicting user ratings precisely, but rather in giving an ordered list of N attractive items to the users, error metrics are not meaningful. Therefore, information-retrieval classification metrics, which evaluate the quality of a short list of recommendations, are most suitable. The most popular classification accuracy metrics are precision, recall and F1 [2], which we adopted in this research.
Compared to an item-based CF algorithm, a user-based strategy achieves much better results for our sparse data set, obtained from PianoFiles. A possible explanation for this is the high number of items (compared to the number of users), which makes it difficult to find optimal neighbourhoods of similar items. Therefore, we applied the standard user-based CF algorithm (UBCF) with the cosine similarity as a mea-sure to compare user profile vectors, for all our bench-marks [9]. Because of the difference in the sparsity level between the provider-generated and th e user-generated content sys-tem, the absolute values of the evaluation metrics can not be compared. However, the evolution of these metrics un-der different sparsity levels is an interesting characteristic to study the time dependency.
In a first experiment, personal suggestions were generated with a UBCF algorithm based on randomly depleted input data. In a primary iteration, the initial input data without modification were used as a training set to obtain a baseline situation. Next, the input data were depleted by randomly eliminating 10%, 20%, until 90% of the consumptions, in successive iterations.

Figure 1 shows that the evaluation metrics decrease lin-early for the Movielens data set as more consumptions are removed from the input data. Indeed, the reduced amount of available consumption information and the accordingly con-fined user profiles lead to more inaccurate recommendations, which lower the precision and the recall value. Moreover, the recall value might also decrease if the CF algorithm is no longer able to generate (sufficient) suggestions for users with a severely depleted profile. As with Movielens, the evaluation metrics obtained with the PianoFiles data set decrease linearly for the first i terations. In contrast, the evaluation metrics drop suddenly after a certain amount of consumption data was removed. This can be explained by the sparsity of the data set for user-generated content sys-tems: as soon as the amount of available consumption data is below a certain threshold, the data matrix is too sparse to produce accurate recommendations.
In a second experiment, the input data were depleted chronologically. Again, a primary iteration, which was based on all the consumptions of the input data, represented the baseline situation. In the following iterations, 10%, 20%, . . . up to 90% of the consumptions were eliminated from the input data, starting with the oldest consumptions. So, in the second iteration for example, the most recent 90% of the input data were used as training information for the recommender.

Figure 2 shows that the evaluation metrics decrease lin-ear for the Movielens data set just like the random depletion process of the first experiment. However, the comparison of Figure 1 and 2 indicates this deterioration is less severe if the oldest data are removed instead of random data. This proves that the oldest consumption behaviour has the lowest infor-mation value for recommendation systems. The results that were obtained with the PianoFiles data set deviate from the previously observed behaviour. Figure 2 illustrates that if older consumption data are removed from the input, the re-call value decreases, but unlike the previous experiment, the precision improves. This increasing precision value can be attributed to two influence sources. Firstly, since the UBCF Figure 2: The evaluation of the UBCF with chrono-logically depleted input data as training set. The graphs visualize the evolution of the precision, re-call and F1 as a function of the percentage of input data that is eliminated. algorithm can not generate recommendations for users with-out consumption behaviour in the training data, the gener-ated recommendations are limited to the users that were active in the most recent time period for which consump-tion behaviour is available. This way, the recommender has to focus on generating recommendations for recently-active users, whose behaviour might be easier to predict than that of users without recent activity on the website. So, in suc-cessive iterations, the number of users for whom recommen-dations are generated is reducing, which might increase the precision of these recommendations. Secondly, eliminating old consumption data from the input might clear the user profiles by reducing the number of obsolete items. User-generated content can be very transient, evolving from very popular to totally outdated in a very short period. Remov-ing old consumptions from the input reduces the risk that obsolete items will be recommended, which might increase the precision of the recommendations as well.
To distinguish the two previously described influences, which increase the precision value for the PianoFiles data set in successive iterations, we modified the previous experi-ment. In this experiment, the recommender had to produce recommendations only for users that were active in the most recent 10% of the input data, instead of generating recom-mendations for all the users with an available profile. For Figure 3: The evaluation of the UBCF, limited to the users that were recently active, with chronologi-cally depleted input data as training set. The graphs visualize the evolution of the precision, recall and F1 as a function of the percentage of input data that is eliminated. this set of users, it is still possible to generate a personal profile if the oldest 10%, 20% up to 90% of the consumption data are removed from the input. So, the number of users for whom the UBCF algorithm can generate recommenda-tions remains unchanged for successive iterations. This way, the first influence source, which was described in the previ-ous section, is eliminated in this experiment. So, Figure 3 merely reveals the effect of removing old consumption data from existing user profiles on the accuracy of the recommen-dations. The graph confirms that older consumption data still have an important information value for the Movielens data set, since the precision and recall decrease if these data are removed from the input. However, we witness the oppo-site effect for the PianoFiles data set: precision and recall remain stable as older consumption data are removed in suc-cessive iterations. We even notice a slight increase for the last iterations (70%, 80% and 90% removed data), which means that the accuracy of the recommendations improves if old information is not considered in the algorithm.
In this research, we investigated the necessity to utilize all the available consumption data to generate recommen-dations with a traditional collaborative filtering algorithm. Our results showed that additional consumption data from the past can provide a positive contribution to the accu-racy of the recommendations for provider-generated con-tent (Movielens data set). For user-generated content (Pi-anoFiles data set) however, the results showed that older consumption data have no added information value for tra-ditional collaborative filtering algorithms. Inserting older consumption data in user profiles of user-generated content systems might even lead to less accurate recommendations. We consider the transient popularity of user-generated con-tent responsible for this decline. This conclusion has im-portant consequences for recommendation systems for user-generated content. Since older consumption data have no added value for the recommender, there is no need to store these data or incorporate the data into the calculations. This reduces the storage and computational burden for large user-generated content systems which offer personal sugges-tions to their customers. In future research, we will verify our conclusion with other data sets and an online evalua-tion. Moreover, we will try to generalize the conclusions for more types of recommendation algorithms. Finally, we will investigate the optimal time period to log the consumption data for recommendation purposes.
We would like to thank the Research Foundation -Flan-ders for the research position of Toon De Pessemier (Aspi-rant FWO) and Thomas Bonte, the founder of PianoFiles, for putting the data set of his website at our disposal. [1] T. Bonte. PianoFiles / Free sheet music for piano, [2] E. Campochiaro, R. Casatta, P. Cremonesi, and [3] M. Cha, H. Kwak, P. Rodriguez, Y.-Y. Ahn, and [4] C. Hayes, P. Massa, P. Avesani, and P. Cunningham. [5] J.L.Herlocker,J.A.Konstan,L.G.Terveen,andJ.T. [6] Z. Huang, D. Zeng, and H.Chen. A link analysis [7] G. Linden, B. Smith, and J. York. Amazon.com [8] M. Harper et al. Grouplens research -movielens data [9] T. Segaran. Programming col lective intel ligence .
