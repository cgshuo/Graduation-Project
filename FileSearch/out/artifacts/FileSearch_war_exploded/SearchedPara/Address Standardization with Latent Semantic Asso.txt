 Address standardization is a very challenging task in data cleansing. To provide better customer relationship manage-ment and business intelligence for customer-oriented coop-erates, millions of free-text addresses need to be converted to a standard format for data integration, de-duplication and householding. Existing commercial tools usually em-ploy lots of hand-craft, domain-specific rules and reference data dictionary of cities, states etc. These rules work better for the region they are designed. However, rule-based meth-ods usually require more human efforts to rewrite these rules for each new domain since address data are very irregular and varied with countries and regions. Supervised learn-ing methods usually are more adaptable than rule-based ap-proaches. However, supervised methods need large-scale la-beled training data. It is a labor-intensive and time-consuming task to build a large-scale annotated corpus for each tar-get domain. For minimizing human efforts and the size of labeled training data set, we present a free-text address stan-dardization method with latent semantic association (LaSA). LaSA model is constructed to capture latent semantic associ-ation among words from the unlabeled corpus. The original term space of the target domain is projected to a concept space using LaSA model at first, then the address standard-ization model is active learned from LaSA features and infor-mative samples. The proposed method effectively captures the data distribution of the domain. Experimental results on large-scale English and Chinese corpus show that the proposed method significantly enhances the performance of standardization with less efforts and training data. H.2.8 [ Database Management ]: Database Applications X  Data mining; I.2.7 [ Natural Language Processing ]: Text Analysis Algorithms, Experimentation Address, Data standardization
Large customer-oriented organizations like banks, hospi-tals and telecommunication companies collect millions of free-text address records. These addresses have little explicit structure in the original form. Moreover, address data are highly irregular since most of them are often generated by different people at different times. To support better cus-tomer relationship management and business intelligence, all the addresses should be converted to a standard consis-tent format during data warehouse construction. Address standardization already becomes one of the key steps in the warehouse data cleansing process. It extracts struc-tured semantic elements from a plain-text string. For exam-ple, given the address string  X  1101 Kitchawan Road, Route 134, Yorktown Heights, N.Y. 10598  X , address standardiza-tion segments this string into semantic elements: [House No.: 1101 ], [Street: Kitchawan Road ], [Route: Route 134 ], [City: Yorktown Heights ], [State: N.Y. ], [Zip: 10598 ]. In customer relationship management (CRM), business intel-ligence and various data mining applications, standardized address enables better querying, and significantly enhances the quality of de-duplication or householding.

Address standardization is a very challenging task. It con-sists of address parsing and normalization. Address parsing segments the address string into semantic elements. Address normalization converts abbreviation elements (e.g.  X  Ave.  X ) into a canonical format and corrects the spelling mistakes. Free-text address often contains an implicit semantic schema which consists of semantic elements such as  X  Street  X ,  X  City  X ,  X  State  X . However, explicit separators between elements in the string are also rarely pr esent. The order of semantic elements is not fixed [20]. Thus, it is a big challenge to cor-rectly segment such free-text data into structured semantic elements. The quality of address standardization can be considerably enhanced by first parsing the addresses cor-rectly. Existing commercial tools [2] employ hand-written rules and a massive reference data of cities, states and zip codes. These rules usually work better for the region they are designed. However, address formats are varied with countries (see Figure 1). For example, the sequence schema implicated in Chinese postal address is very different from that one in western address. Since there is no space to mark word boundaries and no standard definition of words in Chinese, it is more difficult to determine the boundary of each semantic element in Chinese address. Obviously, it is very difficult to directly employ these rule-based tools to effectively process the wide variety of patterns. With the expanding globalization of business, the scalability of rule-based tools is limited since more human efforts are required to rewrite the rules for each new domain.
 Figure 1: Address examples from different countries
Technologies and processes to reduce costs or make the task more efficient are crucial in address standardization. Supervised learning methods are more trainable and adapt-able than rule-based approaches. However, they usually need a large-scale labeled training data set. It is a labor-intensive and time-consuming task to build a large-scale an-notated data set for each domain in practice. Thus, it is a big challenge to learn a high-quality model with less ef-forts and labeled data. Supervised learning classifiers usu-ally lose accuracy when they are trained on a small labeled data set. The reason for accuracy loss is that each semantic element type often has various specific term representations and context clues in the domain. It X  X  difficult to effectively capture the underlying domain distribution using limited la-beled training data. Thus, we expect to better approximate the domain distribution by exploiting latent semantic asso-ciation among words in the domain. Some approaches have been proposed to group words into  X  X opics X  to capture impor-tant relationships between words, such as Latent Semantic Indexing (LSI) [6], probabilistic Latent Semantic Indexing (pLSI) [11], Latent Dirichlet Allocation (LDA) [5]. These models have been successfully employed in topic modeling, dimensionality reduction for text categorization [5], ad hoc IR [21], and so on. We propose an address standardiza-tion method with latent semantic association (LaSA). LaSA model is presented to augment the limited labeled training data set. LaSA model is constructed from the unlabeled corpus at first. It learns latent semantic association among words from their related context snippets. LaSA feature among words is incorporated in a discriminatively trained standardization model. Meanwhile, uncertain-based infor-mative sampling is used to select training examples in the model learning. The intuition behind our method is that words in one concept set will have similar semantic features or latent semantic association, and share syntactic and se-mantic context in the corpus. They can be considered as behaving in the same way for discriminative learning in the domain. LaSA-based address standardization model asso-ciates words in the domain on a semantic level rather than by lexical occurrence. It can better capture the domain dis-tribution. Experimental results on large-scale English and Chinese corpus show that our method significantly enhances the performance with much less labeled training data.
In this paper, we show our experiences and lessons learned in building a supervised address standardization system. The reminder of this paper is organized as follows. Section 2 briefly introduces the related works. Section 3 presents latent semantic association (LaSA) model. Section 4 illus-trates the address standardization method with LaSA model and informative sampling. Experimental results are dis-cussed in Section 5. The conclusion is given in Section 6.
Free-text addresses are far more irregular, and separa-tors between semantic elements seldom are present. These properties make semantic element tagging in free-text ad-dress more difficult. Current address standardization tech-niques include rule-based and supervised learning-based ap-proaches. Existing commercial tools [2] rely on hand-tuned, domain-specific rules, and a massive reference data set. Rule-based approaches require domain experts to design and main-tain amounts of rules for each new domain over time. Su-pervised approaches can automatically learn segmentation models from training data [20, 1]. Agichtein and Ganti [1] present an automatic segmentation method using the ref-erence tables mined from data warehouses and relational databases. Borkar et al. [20] present a segmentation method using Hidden Markov Modeling, which employs multiple sources (e.g. the sequence of elements and reference data dictionary). In this paper, we present a supervised address standardization method with latent semantic association. The model is learned from LaSA features and informative samples using Robust Risk Minimization (RRM) linear Clas-sifier [22]. No reference data dictionary is employed in our method.

Semantic elements in the address records actually can be considered as atomic named entities (e.g persons, organi-zations, locations etc.). Named entity recognition (NER) is an important task in information extraction and natural lan-guage processing applications. Supervised learning methods can effectively solve NER problem by learning a model from manually labeled data [15, 22]. For example, RRM classi-fier have been successfully employed in NER [8, 12, 10], and performs best in CoNLL-2003 NER contest [15]. Freitag [9] and Miller et al. [14] respectively employ distributional and hierarchical clustering to improve NER. In this paper, we present LaSA model to capture the data distribution.
Active learning is an efficient method to reduce the train-ing data. The popular approaches include committee-based methods [7] and certainty-based methods [17, 18, 13]. They select the most informative samples for which the current model are most uncertain. Active learning method has been studied in NER [16, 10], information extraction [18] and text classification [19, 3]. Shen et al. [16] propose a multi-criteria-based active learning approach which integrates in-formativeness, representativeness and diversity in the NER model training. Guo et al. [10] employ an uncertain-based sampling method for reducing the training cost in NER.
Existing supervised approaches require comprehensive man-ually labeled training data. However, it is often hard to obtain enough labeled data to illustrate all features of the domain. In this section, we present LaSA model to capture latent semantic association among words from the unlabeled corpus. LaSA model better augments the training data set.
Address standardization segments a plain text address string into semantic elements. We consider it as a classi-fication problem. Let X be a feature space to represent the observed word instances, and let Y be the set of seman-tic labels. Let p s ( x, y )and p t ( x, y ) be the true underlying distributions for the labeled training data set and the tar-get data set, respectively. In order to minimize the human efforts, we expect to use p s ( x, y ) to approximate p t
The limited labeled data set usually is not comprehensive enough to reflect the underlying distribution of the domain. Hence, the data distribution gap often exists between the labeled data set and huge amounts of target data. For ex-ample, in the postal address set, although many terms can be captured from the labeled training data set, some terms in the target data set maybe do not appear in the training data set. Some useful predictive features from the training data set maybe do not appear in the target data set. The new terms in the target data set and the known terms in the training data set often appear in the similar syntactic and semantic context. For example, terms in the organiza-tion names often appear around the indicates  X  X ank X ,  X  X om-pany X  and  X  X niversity X  etc. Such latent semantic association among words provides useful hints for capture the underly-ing distribution of the domain.

Hence, we present LaSA model  X  s,t to capture latent se-mantic association among words in the domain.  X  s,t is learned from the unlabeled domain data. Each instance is character-ized by its co-occurred context distribution in the learning. Semantic association feature in  X  s,t is a hidden random vari-able that is inferred from data. In the address analytics, we transfer the problem of semantic association mapping to a posterior inference task using LaSA model. Latent seman-tic concept association set of a word instance x (denoted by SA ( x )) is generated by  X  s,t . Instances in the same con-cept set are considered as behaving in the same way for discriminative learning in address analytics. Even though word instances do not appear in a training corpus (or ap-pear rarely) but are in similar context, they still might have relatively high probability in the same semantic concept set. Obviously, SA ( x ) can better bridge the gap between the two distributions p s ( y | x )and p t ( y | x ). Hence, LaSA model can enhance the estimate of the distribution p s ( y | x ;  X  s,t ter approximate the real domain distribution p t ( y | x ;  X 
In address standardization, LaSA model is employed to find the latent semantic association structures of  X  X ords X  in the domain. We will illustrate how to build LaSA model from words and their context snippets in this section. LaSA model actually can be considered as a general probabilistic topic model. It can be learned on the unlabeled corpus using the popular hidden topic models such as LDA or pLSI.
For learning latent relationships among words from the unlabeled corpus, each word is characterized by a virtual context document. Given a word x i , the virtual context document of x i (denoted by vd x i ) consists of all the context units around x i in the corpus. Let n be the total number of the samples which contain x i in the corpus. vd x i is con-structed as follows. where, F ( x s k i ) denotes the context feature set of x address sample s k ,1  X  k  X  n .

Given the context window size { -t, t } (i.e. previous t words and next t words around x i in s k ). F ( x s k i ) usually consists of the following features. 1. Anchor unit A x i C : the current focused word unit x i 2. Left adjacent unit A x i L : The nearest left adjacent unit 3. Right adjacent unit A x i R : The nearest right adjacent 4. Left context set C x i L : the other left adjacent units 5. Right context set C x i R : the other right adjacent units For example, given x i =  X  X oute X  , s k =  X 1101 Kitchawan Road, Route 134, Yorktown Heights, N.Y. 10598 X  . Let the context window size be { -3,3 } . F ( Route )= { Route , A L ( Road ), A R (134), C L ( Kitchawan ), C L (1101), C R ( Yorktown ), C ( Heights ) } . vd x i actually describes the semantic and syntactic feature distribution of x i in the domain. We construct the feature vector of x i with all the observed context features in vd ture around x i ,1  X  j  X  m , m denotes the total number of features in vd x i .Theweightof f j is calculated by Mutual Information [4] between x i and f j .
 where, P ( f j ,x i ) is the joint probability of x i and f occurred in the corpus, P ( f j ) is the probability of f curred in the corpus. P ( x i ) is the probability of x i in the corpus.
Topic models are statistical models of text that posit a hidden space of topics in which the corpus is embedded [5]. LDA [5] is a probabilistic model that can be used to model and discover underlying topic structures of documents. LDA assumes that there are K  X  X opics X , multinomial distributions over words, which describes a collection. Each document ex-hibits multiple topics, and each word in each document is associated with one of them. LDA imposes a Dirichlet dis-tribution on the topic mixture weights corresponding to the documents in the corpus. The topics derived by LDA seem to possess semantic coherence. Those words with similar semantics are likely to occur in the same topic. Since the number of LDA model parameters depends only on the num-ber of topic mixtures and vocabulary size, LDA is less prone to over-fitting and is capable of estimating the probability of unobserved test documents. LDA is already successfully Algorithm 1 : LaSA Model Training applied to enhance document representations in text classi-fication [5], information retrieval [21].

In the following, we illustrate how to construct LDA-style LaSA model  X  s,t on the virtual context documents. Algorithm 1 describes LaSA model training method in de-tail, where, Function AddT o ( data, Set ) denotes that data is added to Set . Given a large-scale unlabeled data set D u tual context document for each candidate word is extracted from D u at first, then LaSA model  X  s,t with Dirichlet dis-tribution is generated on the virtual context document set VD s,t using the algorithm presented by Blei et al [5]. Table 1: Top 10 words from 4 randomly selected topics computed on the real-life address data set
LaSA model learns the posterior distribution to decom-pose words and their corresponding virtual context docu-ments into topics. Table 1 lists top 10 words from a random selection of 4 topics computed on the unlabeled domain data. As shown, words in the same topic are representative. They actually are grouped into broad concept sets. For example, set 1, 2, 3 and 4 correspond to organization suffixes, person names, place indicates and city names, respectively. With a large-scale unlabeled corpus, we will have enough words assigned to each topic concept to better approximate the underlying semantic association distribution.

In LDA-style LaSA model, the topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all the virtual context documents. Hence, given a word x i in the corpus, we may perform posteri or inference to determine the conditional distribution of the hidden topic feature variables associated with x i . Latent semantic association set of x (denoted by SA ( x i )) is generated using Algorithm 2. In the address analytics, we do semantic association inference on the domain data using LaSA model at first, then the address analytics model is learned on the training data set by incorporating these semantic association features.
Algorithm 2 : Generate Latent Semantic Associa-tion Set of Word x i Using K -topic LaSA Model
By grouping words into concepts, LaSA model better aug-ments the training data set. Thus, we may reduce the number of parameters required to model the domain data, and improve the quality of the estimated parameters in ad-dress analytics. LaSA model extends the traditional bag-of-words topic models to context-dependence concept associa-tion model. It has potential use for concept grouping.
Address standardization focuses on segmenting a free-text address string into elements with semantic labels. It actually is a semantic element tagging task. For achieving better performance with less efforts and training data, we employ LaSA model and informative sampling in the tagging model learning. LaSA model effectively augments the training data set. Uncertain-based informative sampling is used to select training examples in the model learning. Our address standardization system employs Robust Risk Minimization (RRM) classification method [22]. We view address standardization as a sequential classification prob-lem. If we use w i ( i =0 , 1 , ..., n ) to denote the sequence of tokenized text, which is the input to the system, then each token w i should be assigned a class-label t i . The class-label sequence encodes the information of semantic elements in the given address sample. The class label value t i associ-ated with each token w i is predicted by estimating the con-ditional probability P ( t i = c | x i ) for each possible class-label value c ,where x i is a feature vector associated with w i
We assume that P ( t i = c | x i )= P ( t i = c | w i , { feature vector x i can depend on previously predicted class labels { t j } j  X  i , but the dependency is typically assumed to be local. In RRM method, the above conditional probability model has the following parametric form: where T ( y )=min(1 , max(0 ,y )) is the truncation of y into the interval [0, 1]. w c is a linear weight vector and b c constant. Parameters w c and b c can be estimated from the training data. Given training data ( x i ,t i )for i =1 , ..., n , the model is estimated by solving the following optimization problem for each c [22]: where y i c =1when t i = c ,and y i c =  X  1otherwise. The function f is defined as:
Given the above conditional probability model, the best possible sequence of t i  X  X  can be estimated by dynamic pro-gramming in the decoding stage.
A crucial aspect of building a high-quality supervised ad-dress standardization system is how to encode useful features so that the underlying learning algorithm can effectively uti-lize. This modeling aspect is task dependent, and essential for achieving good performance. Words usually make a sig-nificant impact on the performance of address standardiza-tion. Thus, we focus on capturing latent semantic associa-tion for high-frequency words (i.e. occurrence count  X  10) in the unlabeled corpus. LaSA model is learned from the unla-beled corpus using the LaSA model training algorithm (see Algorithm 1 in section 3.2.2). Our empirical study shows that better performance is obtained with a 50-topic LaSA model. Therefore, we set the number of topics N as 50, and define the context view window size as { -3,3 } (i.e. previous 3 words and next 3 words) in the LaSA model learning.
All the address standardization models are trained on the labeled training data using RRM classifier. We set the con-text view window size as { -2,2 } in address standardization. Given a word instance x , we employ local linguistic features (e.g. word unit, part of speech) and semantic association features of x and its context units ( i.e. previous 2 words and next 2 words ). The semantic association features of each unit in the observation window { -2,2 } are generated by LaSA model at first, then the standardization model is learned on the labeled training data set by incorporating LaSA features and local basic linguistic features. For exam-ple, given the address  X 1101 Kitchawan Road, Route 134, Yorktown Heights, N.Y. 10598 X  , Figure 2 illustrates vari-ous features and views at the current word w i = X  Route  X  X n LaSA-based address standardization method. In the view-ing window at the word  X  Route  X (seeFigure2),eachword unit around  X  Route  X  is codified with a set of primitive fea-tures (e.g. SA , Tag ), together with its relative position to  X  Route  X . Here,  X  SA  X  denotes semantic association feature set which is generated by LaSA model.  X  Tag  X  denotes the semantic tags labeled in the data set.

Given the input vector constructed with the above fea-tures, RRM method is applied to train linear weight vectors, one for each possible class-label. In the decoding stage, the Figure 2: Feature window in LaSA-based address standardization class with the maximum confidence is selected for each token unit.
A higher performance system usually requires more fea-tures and large-scale training data. This requires larger sys-tem memory and more efficient training method, which may not be available. In order to overcome the limitation of avail-able training data and computational resources, we present an informative sample selection method using a variant of uncertainty-sampling [13].
 Algorithm 3 : Informative Sampling Algorithm
The informativeness of each training sample is measured from the viewpoints of its uncertainty. More uncertain frag-ments are contained in the sample, more informative the sample is. Given an address sample S i = { tok j } N j =1 tok j denotes the j th token unit in S i , the confidence score of S i is defined as follows.
 where, Score ( tok j ) denotes the confidence score of tok in S i , which is assigned by the standardization model.  X  is the predefined confidence score threshold (  X  =0.7 in our experiments). Those token units with lower confidence score (i.e. Score ( tok j )  X   X  ) are considered as uncertain units. TokNum ( S i ) denotes the total number of token units in S UncNum ( S i ) denotes the number of uncertain units in S
Algorithm 3 illustrates the informative sampling algorithm in detail. In each iteration, we train an address standardiza-tion model on the available labeled data and apply it on the candidate unlabeled data set D t,u . Among these candidate samples, the sample predicted with the lowest confidence is selected and removed from D t,u . Totally top K samples with lower confidence score are selected from D t,u .They are considered as informative samples for which M t is most uncertain. These informative samples are tagged and added to D t,l .Then M t is retrained on the newly D t,l .
In this section, we measure the efficacy of the proposed techniques on real-life address data sets. We quantify the benefits of LaSA model and informative sampling, and the sensitivity of our results to the number of training instances.
We built large-scale English and Chinese annotated ad-dress corpus. All the data are real-life customer contact ad-dresses collected from several enterprises. The English cor-pus contains 24,413 English address records (totally 110,750 English words). The Chinese corpus contains 7,643 Chinese address records (totally 136,914 Chinese characters). All the semantic elements in both corpus are manually tagged. Cross-validation checking is employed to ensure the quality of the annotated corpus. The unlabeled raw corpus are used to build English and Chinese LaSA models, respectively.
All the training data and test data in the experiments are selected from these two annotated corpus, respectively (see Table 2 and 3). Moreover, test data do not overlap with training data. All Chinese texts in the experiments are automatically segmented into words using HMM.

In the experiments, we focus on detecting 25 semantic el-ement types in English address records, including { House Number, House Number Suffix, Street Prefix Directional, Street Prefix Type, Street Name, Street Suffix Type, Street Suffix Qualifier, Street Suffix Directional, Rural Route Type, Rural Route Value, Box Type, Box Value, Floor Type, Floor Value, Unit Type, Unit Value, Multi Unit Type, Multi Unit Value, Building Name, Additional Address Information, City Name, State Abbreviation, Zip Code, Zip for Add-on Code, Country Code } . Chinese address records are segmented into a set of 17 semantic element types, including { Province, City, District, Township, Street, Street Number, Residen-tial, Lane, Block, Unit, Floor, Room, Organization, Depart-ment, Direction, Post box, Remark } .

In our evaluation, only semantic elements with correct boundaries and correct class labels are considered as the correct recognition. We use the standard P (i.e. Precision), R (i.e. Recall), and F (i.e. F-measure, defined as 2 PR measure the performance of the given model.
All the experiments are conducted on the above large-scale English and Chinese corpus. The overall performance enhancement by LaSA model is evaluated at first. Since training cost is a bottleneck for supervised learning method, we also investigate the effect of LaSA model on the training data set size and the accuracy. Finally, we analyze the cu-mulative impact of LaSA model and informative sampling.
We evaluate the impact of LaSA model on the accuracy in this section. In the experiment, all the address standardiza-tion models are trained on the English and Chinese training data sets (see Table 2 and 3 in Section 5.1), respectively.
Table 4 and 5 show the experimental results on both cor-pus, respectively. Model LaSA incorporates LaSA features and basic local features while Model Base only uses the basic local features. Compared with Model Base , the relative per-formance enhancement and error reduction by Model LaSA are also shown in the tables. For example, let F Base and F
LaSA be F-measure of Model Base and Model LaSA ,respec-tively, the relative F-measure enhancement by Model LaSA Table 4: Experimental results on English corpus Table 5: Experimental results on Chinese corpus Experimental results on English corpus demonstrate that Model LaSA significantly enhances P , R and F (see Table 4). For example, F Base is 90.96% while F LaSA achieves 96.58%. Compared with F Base , Model LaSA significantly enhances F by 6.18%, and effectively reduces 77.94% errors in Recall. Experimental results on Chinese corpus also show that Model LaSA effectively increases the accuracy (see Table 5). Especially, compared with F Base , Model LaSA significantly increases F-measure and Recall by 9.18% and 11.34%, re-spectively.

Experimental results on both corpus show that Model LaSA significantly reduces more th an 45% errors compared with Model Base . The major reason for such significant enhance-ment is that Model LaSA better captures the data distribu-tion by incorporating LaSA features. Even though word in-stances do not appear in a training corpus (or appear rarely) but are in similar context, they still might have relatively high probability in the same semantic concept set. Using LaSA features, Model LaSA better associates various words on the semantic level.
The size of labeled training data is always an important concern in supervised learning methods in practice since lots of manual effort are required in tagging the instances. Thus, we evaluate the impact of LaSA feature on the size of train-ingdatainthissection.

In the experiment, an initial address standardization model is trained with a small sample set (totally 100 token units). Then the model is incrementally retrained by randomly adding some new training data (about 100 token units) each itera-tion till the performance isn X  X  enhanced significantly. Figure 3: Performance curves of Model LaSA and Model base on English corpus
We compare performance of Model LaSA and Model Base on various training data set sizes. The results on English and Chinese data sets show that Model LaSA is a fast learner (see Figure 3 and 4).

In the experiments on English corpus (see Figure 3), with only 300 English words of training, Model LaSA performs much better than Model Base . At this operation point, the performance of Model LaSA exceeds a F-score of 90% on the English test data set (36,466 words) a level not reached by Model Base until it has observed 11,500 words of train-ing. Furthermore, with 2,600 words of training, Model LaSA yields an accuracy of 95.09% on the test instances. Com-pared to 84.00% for Model Base , a 69.31% reduction in er-ror. Further increasing the training size, Model LaSA only slightly enhances the accuracy.
 Figure 4: Performance curves of Model LaSA and Model base on Chinese corpus
Similar trend is observed from the results on the Chinese data set (see Figure 4). With only 200 Chinese characters of training, Model LaSA significantly outperforms Model Base With 700 Chinese characters of training, Model LaSA achieves an accuracy of 85% on the Chinese test data set (81,703 Chi-nese characters), a level not reached by Model Base until it has observed 2,100 Chinese characters of training. When 8,800 Chinese characters of training are employed in the learning, Model LaSA yields a F-score of 90.09% on the given test instances. Compared to 88.31% for Model Base , a 15.91% reduction in error. Further increasing the training size, Model LaSA only slightly boasts the accuracy.

Experimental results on both corpus show that Model LaSA model obtains much better performance with much less train-ing data. The major reason for such significant training data reduction is that Model LaSA better approximates the un-derlying data distribution by incorporating LaSA features. Even though the model does not know the word in the appli-cation, it now can know something about the concept group to which a word belongs.
The goal of our work is to minimize the human annota-tion efforts to learn an address standardization model with the same performance level as supervised learning. Thus, we combine LaSA-model with informative sampling in the model learning, denoted by LaSA-Info method. LaSA-Info method incorporates LaSA features. Moreover, it incremen-tally learns the model from informative samples till the peak performance is achieved. In each iteration, informative sam-ples are selected from the candidate training data set (see Table 2 and 3 in Section 5.1) using the sampling algorithm described in section 4.3. In this section, we evaluated the cumulative impact of LaSA model and informative sampling on the accuracy and the size of training data set.
In the experiments, we compare our LaSA-Info method with supervised learning, simple informative sampling and random selection methods, including Base-Random , LaSA-Random , Base-Info , Base-Supervised and LaSA-Supervised . In the random selection methods Base-Random and LaSA-Random , a batch of examples is randomly selected itera-tively. Base-Random method learns the model without us-ing LaSA features while LaSA-Random method learns the model by incorporating LaSA features. Base-Info method incrementally learns the model from informative samples without using LaSA features. LaSA-Supervised and Base-Supervised methods learn Model LaSA and Model Base from all the training data using supervised learning method, re-spectively. The performance of LaSA-Supervised is consid-ered as the topline.

We make the comparisons on English and Chinese corpus, respectively. Figure 5 and 6 show the learning curves of the above methods on both corpus, respectively. They show a plot of training data size versus F-measure achieved by these methods. In the figures, the horizontal solid line is the performance level achieved by LaSA-Supervised method. The horizontal dot line is the performance level achieved by Base-Supervised method.
 We investigate the impact of informative sampling at first. Informative sampling demonstrates a noticeable increase in learning rates. Moreover, the enhancement of learning rate is more significantly when LaSA feature is introduced. The major reason for the enhancement is that LaSA feature pro-vides better confidence measure for informative sampling. Figure 5 and 6 also show the cumulative impact of both LaSA model and informative sampling. For example, on English corpus (see Figure 5), LaSA-Info method achieves a F-score of 90 with only 300 words of training while Base-Random method achieves the same performance with 11,500 words of training. At 1,900 words of training, LaSA-Info method (F=96.58%) continues to exhibit a 62.17% reduc-tion in error compared to the peak performance of Base-Supervised (F=90.96%). Experimental results indicate that LaSA-Info method significantly reduces the annotation ef-forts. LaSA-Info method performs much better than the other given methods since it captures more fine-grain infor-mative LaSA features.
 Figure 5: Active learning curves on English corpus: effectiveness of LaSA-Info method comparing with the random selection Figure 6: Active learning curves on Chinese corpus: effectiveness of LaSA-Info method comparing with the random selection
We also compared the training efforts used in various methods to achieve the same performance level as super-vised learning. Table 6 shows the amount of training data needed in these methods to achieve the performance of Base-Supervised . Table 7 highlights the amount of training data required in LaSA-Info and LaSA-Random to achieve the performance of LaSA-Supervised . From the experimental results, we find: 1. Base-Supervised achieves F-measure 90.96% on the En-Table 6: Training data sizes for various methods to achieve the same performance level as Base-Supervised method Table 7: Training data sizes for various methods to achieve the same performance level as LaSA-Supervised method 2. LaSA-Supervised achieves the peak F-measure 96.58% 3. LaSA-Info and LaSA-Random outperforms Base-Info
Experiments on English and Chinese address corpus show that, the combination of LaSA model and informative sam-pling outperforms the single informative sampling and ran-dom selection. The labeling cost can be significantly reduced by at least 95% compared to the supervised learning. So we believe this combination method will help to learn the stan-dardization model more quickly with less efforts.
Address standardization problem is very challenging. Free-text address data are highly irregular since most of them are often generated by different people at different times. Thus, efficient and robust standardization model is very impor-tant in practice. Supervised learning classifiers are train-able and adaptable. However, it is a labor-intensive and time-consuming task to build a large-scale annotated train-ing data set in practice. For minimizing human efforts and the size of labeled training data set, we present an address standardization method with LaSA model and informative sampling in this paper. This proposed method effectively captures the data distribution with less efforts. LaSA model captures latent semantic association among words from the unlabeled corpus. It better groups words into a set of con-cepts according to the related context snippets. The origi-nal term space of the target domain is projected to a con-cept space using LaSA model at first, then the standardiza-tion model is learned using LaSA features and informative samples. Experimental results on large-scale English and Chinese corpus show that the proposed LaSA-Info method significantly enhances the performance of standardization. The proposed method achieves more than 45% reduction in error over the state-of-the-art RRM trained on the same material. Compared to the supervised learning method, the present approach requires only 5% as much annotated data to achieve the same level of performance. Given the encour-aging results, we believe that this combination approach is effective for practical information extraction problems. [1] E. Agichtein and V. Ganti. Mining reference tables for [2] R. Associates. Raab associates guide to customer [3] K. Brinker. Incorporating diversity in active learning [4] K. W. Church and P. Hanks. Word association norms, [5] A. N. David Blei and M. Jordan. Latent dirichlet [6] S.Deerwester,S.T.Dumais,andR.Harshman.
 [7] S. A. Engelson and I. Dagan. Committee-based [8] R.Florian,A.Ittycheriah,H.Jing,andT.Zhang.
 [9] Freitag. Trained named entity recognition using [10] H. Guo, L. Zhang, and Z. Su. Empirical study on the [11] T. Hofmann. Probabilistic latent semantic indexing. In [12] H. Jing, R. Florian, X. Luo, T. Zhang, and [13] D. Lewis and J. Catlett. Heterogeneous uncertainty [14] S. Miller, J. Guinness, and A. Zamanian. Name [15] E. F. T. K. Sang and F. D. Meulder. Introduction to [16] D. Shen, J. Zhang, J. Su, G. D. Zhou, and C. Tan. [17] M. Tang, X. Luo, and S. Roukos. Active learning for [18] C. A. Thompson, M. E. Califf, and R. J. Mooney. [19] S. Tong and D. Koller. Support vector machine active [20] K. D. Vinayak Borkar and S. Sarawagiz. Automatic [21] X. Wei and B. Croft. Lda-based document models for [22] T. Zhang and D. E. Johnson. A robust risk
