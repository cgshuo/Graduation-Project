 CHUNG-HSIEN WU, JUI-FENG YEH, AND MING-JUN CHEN National Cheng Kung University, Tainan, Taiwan ________________________________________________________________________ ________________________________________________________________________ 1. INTRODUCTION During the last decade, question-answering (QA) systems were designed to find the most Conference (TREC) enables researchers to sh are their experiences and provides a global metric for assessing QA system performance. These methods are summarized as rule-based, statistical, and mixed approaches. Ru le-based QA systems usually contain rule gram model. The mixed approach was realized in QASM [Radev et al. 2001], which included the Expectation-Maximization (EM) al gorithm and 15 basic operations for the form, and the QA system can understand the tabular structure by inference. systems such as FAQ-Finder [Hammond et al. 1995; Burke et al. 1997], QASM [Radev et al. 2001], and the systems proposed in TREC [Na et al. 2002; Paranjpe et al 2003] used the WordNet as a lexicon. Automated question-answering methods proposed in Chu-Carroll et al. [2002] and Sneiders [2002] used multi-lexicons as the knowledge base. In addition, ontology has been demonstrated to provide a sound semantic basis in Tong et al. [2003] and Ahmedi and Lausen [2002]. systems retrieve the existing QA pairs from th e frequently-asked question files [Burke et al. 1997]. In general, FAQ retrieval is a task of retrieving information from a set of semi-structured texts. FAQ systems include the fo llowing characteristics: (1) the FAQ system is designed for the retrieval of the very fr equent, popular, and highly reusable question-answer pairs, called QA pairs; (2) QA pairs are generally maintained and periodically FAQ retrieval is also different from traditional in formation retrieval, in that in general no semantic representation and knowledge are us ed in traditional information retrieval, while FAQ retrieval is usually domain-specific and adopts inference and reasoning to retrieve a more accurate QA pair for a query. [Whitehead 1995] relied on a shallow, surf ace-level analysis for FAQ retrieval. FAQ-Finder [Hammond et al. 1995; Bu rke et al. 1997] adopted two major aspects, i.e., concept expansion using the hypernyms defined in WordNet and the TF-IDF weighted score in the retrieval process. In FAQ-Finder, inte rrogative words like  X  X hat X  and  X  X ow X  are, results in misdetection of question types, and therefore degrades system performance. To eliminate the above problem in FAQ-Finder, Tomuro [2002] combined lexicon and semantic features to automatically extract the interrogative words from a corpus of questions. Besides WordNet, FALLQ [Lenz et al. 1998] retrieved FAQs via case-based reasoning (CBR). Sneiders [1999] defined four types of words, i.e., required keywords, optional keywords, forbidden keywords, and irrelevant words for prioritized keyword-matching. Sneiders [2002] used question templates with entity slots that are replaced by data instances from the underlying database to interpret the structure of queries and questions. Berger et al. [2000] proposed a statistical lexicon correlation method. DiQuest e-Answer [Lee and Lee 2003] used the dyna mic passage selection and lexicon-semantic patterns for FAQ retrieval. information retrieval [Baeza-Yates and Ri beiro-Neto 1999], a domain-specific FAQ retrieval system with high content-to-noise ratio is still a core research topic for practical independent aspects. In this approach, questions in the QA pairs are classified according to the question stems. In order to provide a more precise answer to a query, each answer in the QA pairs is segmented into several para graphs. These paragraphs are then clustered using Latent Semantic Analysis (LSA) [Manning et al. 1999] and the K-means algorithm. and the QA pairs can be interpreted based on independent aspects. Utilizing the probabilistic mixture model, the retrieval pr ocess is considered a maximum likelihood problem. The probabilistic mixture model based on the independent aspects provides a powerful and conceptually transparent forma lism for the causal relation and identifies the included in the QA questions. Additionally, predef ined relation rules, such as  X  X esult-in X  and  X  X esult-from, X  regarding the relationship between diseases and syndromes proposed algorithm is employed to estimate the optimal mixing weights in the probabilistic mixture model. and answer paragraphing. Section 3 presents the modeling of a problem for the FAQ algorithm. Section 4 presents the experimental results for the evaluation of our approach. Section 5 provides concluding remarks. 2. DATA ANALYSIS AND ANSWER PARAGRAPHING This study constructs a medical FAQ retrieval system with a collection of 1172 medical convey different information an d should be analyzed separately. For the question part, the question stem is the most important word in an interrogative sentence. Consequently, ten the answers in the QA pairs can be classified into four types based on their contents: (a) Boolean type: answers with only  X  X es X  or  X  X o X  words (b) Set type: answers with only some keywords or concepts. (c) Short description type: answers with a short paragraph. Generally, this type does not (d) Long description type: answers with different topics and long descriptions. Greetings difficult to collect sufficient paragraphs for the statistical approach, paragraphs should be clustered. In previous approaches, most sema ntic theories characterized the meaning of a combined. In this study, latent semantic anal ysis is adopted for distance estimation and is used to filter out the noisy constituents and th us preserve the discriminative concepts in a vector. Finally, the segmented 3312 paragraphs were assembled into 320 clusters via the K-means algorithm. 3. PROBLEM MODELING FOR QA collected QA pairs [Hammond et al. 1995]. The problem can be characterized using a conditional probability model. In this model, the QA pairs can be interpreted based on a conditional probability model over all QA pairs and their associated queries is defined by the mixtures (|) (|)(|,) Sss s = . answer part, where QA M MM += . As in many conditional probabilistic models, the conditional independence assumption is introduced, namely that only the corresponding interpretation of each aspect in a QA pair ca n be activated. Accordingly, the equation can be further simplified as where m Q represents the m-th interpretation from the question part with respect to the m-respect to the m-th aspect , A m s . considered the maximum likelihood estimation. The objective of this study is to identify the best QA pair, * QA , which maximizes the likelihood of (|) PQA q from the collected QA pairs; that is, investigation considers the aspects for the question and answer parts separately. 3.1 Aspects for the Question Part stem, (2) the key concept, and (3) the vector space representation. words like  X  X ho, X   X  X ow, X   X  X hat, X  etc., in a sentence provide one of the useful identification of the expected answer types [Moldovan et al. 2003]. The question stems in questions and queries are analyzed usin g the collected query and QA pairs. The defined as where () Stem  X  represents the question stem of the query or question. keyword-based systems introduce two problems. First, ambiguity generally results from the polysemy of a word due to over expansion. Second, relations between the concepts should be expanded and weighted to include more semantic information. Hence, in this the synsets in WordNet with the corresponding Chinese words defined in HowNet. A medical domain corpus is collected and used to extract the domain-specific concepts encyclopedia are also integrat ed into the domain ontology. and the question is defined as the similarity between the two bags of words. The similarity measure based on key concepts defined in the constructed ontology [Yeh et al. 2004] is defined as follows. similarity H kl as The conditional probability of the i-th QA pair with respect to aspect ,2 Q s and query q is defined as where () K C  X  represents the key concept of the query or question. 3.1.3 Aspect ,3 Q s : Vector Space Representation. The LSA approach is generally adopted obtained using singular value decomposition [Manning and Schutze 1999]. Besides dimensionality reduction, this approach can be used to measure the similarity between the vectors are calculated in the reduced LSA space. Meanwhile, the conditional probability of the i-th QA pair with respect to aspect ,3 Q s and query q is defined as representation of the query or question. 3.2 Aspects for the Answer Part For the answer part, two aspects are investig ated separately, namely: (1) the relation and (2) the paragraph cluster. 3.2.1 Aspect ,1 A s : Relations. Relations such as  X  X esult in X  and  X  X esult from X  that describe influence system performance. Data on sy ndromes and diseases was obtained from a medical encyclopedia that defines 1213 axioms containing the relationships between diseases and syndromes. Each disease was assigned to one of three levels, depending on example of the axiom for the disease  X  X iabete s. X  The  X  X esult in X  relation score is defined as (,) i RI A q if a disease occurs in the input query and its related syndromes appear in the follows. of feature of and query q is defined as where () REL  X  represents the relation of the query or answers. 3.2.2 Aspect ,2 A s : Paragraph Clusters. For the long description answer type, paragraphs techniques are applied to retrieve QA pairs [Harabagiu and Maiorano 1999; Clarke et al. 2001]. Accordingly, in this as pect, all answer parts with short or long description types in the QA pairs are segmented into paragraphs via a topic-segmentation algorithm [Hsieh et al. 2003]. For all the segmented paragrap hs, the LSA and the K-means algorithm are adopted to assemble all the paragraphs into cl usters. Therefore, paragraphs in each cluster are assumed to belong to the topics with semantically similar words. paragraph cluster is statistically independent, and the conditional probability of the answer with n paragraphs where the above equation is derived as follows: The prior probability can be estimated as where N(PC) represents the number of o ccurrences of paragraph cluster PC and k denotes conditional probability of the answer with n paragraphs can be co nsidered the conditional probability of the paragraph w ith the highest probability fo r a particular input query thus defined as where () PC  X  represents the paragraph cluster of the answer and i paragraph cluster for the j-th paragraph in the i-th answer. 3.3 Probabilistic Mixture Model Tr aining Using the EM Algorithm From the modeling above, a probabilistic mixtur e model is proposed to linearly combine the above aspects for FAQ re trieval. This mixture model has a density function (|,) PQA q  X  that is governed by the set of parameters  X  . The model also has a data set with distribution P . Therefore, the resulting density for the data is The mixture weight parameters are estimated using the EM algorithm [Dempster et al. 1977]. 4. EXPERIMENTAL RESULTS A medical domain FAQ retrieval system wa s constructed in order to evaluate the proposed approach. The QA pairs were collected from the websites and contain a total of 1172 medical QA pairs. Forty individuals wh o did not participate in system development were asked to provide queries given the answer part of the QA pairs. Moreover, 5371 training queries and 5907 test queries were obtained. On average, each query corresponds to the answers from 17.23 QA pairs, and there are 6.72 terms per query, as listed in Table I in the QA database. vector space model using key term expansion and the TF-IDF score were implemented as the baseline system. A performance measure, ca lled 11-AvgP, or the average of precision overall performance of the system is describe d in Section 4.1. The overall evaluation for Types. 100%) and the vertical axis shows the range of precision (0% to 100%). For Boolean type baseline FAQ-Finder system obtained good precision and recall rates. The best 11-AvgP score using question stems achieved 0.6643, shown in Table II. Since the most important information in the QA pair s with Boolean type answer is embedded in the question part, the experiment using only the question stem obtained the most promising results. However, similar to the question type misclassification problem described in Hammond et al. [1995], this study still has some problems when using question stems: (1) there exists confusion between some question stems such as  X   X  X  X  (what) X  in question type 1 and  X   X  X  X  X  (why) X  in question type 4 because the word  X   X   X  (what) X  is a substring of the word  X   X  X  X  X  (why), X  and the error in word segmentation results in misclassification of question stems; Table II. Best 11-AvgP Score and Relative Aspect for Answers with Different Types question types. For example, the query  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  (The flu virus infects the childr en in many ways) X  was detected as type 6, in which the word  X   X  (many) X  was misdetected as the question stem  X   X  (how many) X ; and (3) although there are some words not coll ected in the question stem set, th e intention is still embedded in the sentence pattern. Fo r example, the query  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X  (May it be cured using aspirin?) X  contains the word pattern  X   X ... X   X  not defined in the question stem set. However, the word pattern  X   X ... X   X  can be regarded as question stem  X   X  X  (may) X  in type 8. because the key concept also plays an important role in characterizing the question part of word ambiguity; and (2) expansion by the other relations provides more effective inference. 4.1.2 Set Type. In this experiment on the Set type answers the relation between diseases and syndromes is important for semantic inference. There ar e 81.3% QA pairs relevant to diseases and syndromes in medical domain FA Q retrieval. The experimental results are shown in Table II. The results show that the relations  X  X esult in X  an d  X  X esult from X  greatly improve the retrieval performance for the answers with Set type. improvement is obtained when the diseases and their related syndromes (and vice versa) appear, respectively, in both the question and answer parts. Besides, improvement in the recall rate is also due to robustness in answer ing users X  incomplete queries. That is, even though the user query only contains one or two syndromes out of three resulting from one the approach using question stems also achieved good results for question types 1 and 9 because the correspondence between the questio n stem and answers is fixed. Hence we find that some new words are contained in the set type answers. The OOV (out-of-vocabulary) problem is another important issue for this type, especially in domain-specific applications. description type were segmented into paragr aphs. The results for an swers with short and performance for the FAQ retrieval system with the paragraph-based approach is better than with the whole-answer-based approach , showing that a paragraph with a specific topic can provide a more precise answer. The best 11-AvgP score is 0.6327 using paragraph clusters as shown in Table II, which agrees with the conclusion in our previous data analysis. In addition, vector space re presentation and paragraph clustering using LSA were beneficial in keeping information for the folding-in query, which refers to the query with the question not contai ned in the original training collection. According to this experiment, the paragraph or subparagraph with a focused topic is more precise than the document as a whole and more suitable as the unit for query output. On the other hand, the key concept approach does not obtain promising results for short short, but the improvement w ill decrease as the length of the answer increases. 4.2 Overall Evaluation for All Answer Types the nAP measure were evaluated. probabilistic mixture model with equal wei ghts and the baseline FAQ-Finder system algorithm. Compared to the baseline system, the prop osed probabilistic mixture model achieved a conspicuous improvement in the preci sion rate. This result also confirms that the integration of di fferent aspects, which span the question stem and syntactic to semantic information, improves retrieval performance. In ad dition, approaches based on semantic expansion in the baseline system. 4.2.2 Performance Evaluation Using the nAP Measure. The non-interpolated Average performances. We define the difference equation as follows: A value of / A B nAP equal to 0 indicates that both methods have equivalent performance. A positive value of / A B nAP indicates a better performance by method A, while a negative value indicates a better performance by method B. our investigation, expansion via ontology got better performance when the number of key concepts was smaller than 5. On the other hand, synonym pruning [Turcato et al. 2000] eliminated the problem of unnecessary expa nsion when the number of key concepts is larger than 8. the number of key concepts per query is smaller than 6, shows that the key concept approach obtains a better perfo rmance; otherwise the vector space representation is better, answers. 5. CONCLUSIONS This article presents a probabilistic mixture model using independent aspects for medical domain FAQ retrieval. First, data analysis is performed to categorize the QA pairs into 10 question types and 4 answer types. In FAQ retrieval using the proposed model, the input query and the QA pairs can be interpreted as a set of independent aspects, and a probabilistic mixture model is adopted to m odel FAQ retrieval. Based on this mixture model, the retrieval process can be cons idered the maximum likelihood estimation problem. The EM algorithm is employed to optimize the mixing weights in the mixture model. achieved promising results for the Boolean and set type answers. Rather than keywords, the concepts in the ontology are important in term expansion using synonym pruning and expansion from relations for the specific domain. The folding-in answers can be effectively retrieved by the LSA approach, especially for long description answers. case in which the question and answer parts contain no common concepts. Moreover, the retrieval outputs based on topic-based paragr aphs outperformed those based on the whole answer. Finally, the experimental results demonstrate that the mixture model can effectively improve the perf ormance of the medical domain FAQ retrieval system compared to the baseline FAQ-Finder system. APPENDIX A. EXAMPLES OF TEN TYPES OF QUESTION STEMS REFERENCES 
