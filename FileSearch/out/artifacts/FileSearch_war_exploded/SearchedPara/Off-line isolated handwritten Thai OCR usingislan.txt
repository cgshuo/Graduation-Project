 1. Introduction
Character recognition (CR) contributes tremendously to improve the interaction between human and machine in many applications, including office automation, signature verification, many data entry applications in an organization (Ren, 2000) i.e., Handwritten Address Interpretation (HWAI) system (Srihari, 1997), reading of cheque information (Madhvanath, McCauliff, &amp; Mohiuddin, 1999), automatic reading of identity cards and passports (Llads, Lumbreras, Chapaprieta, &amp; Que, 2001), and data entry on some machines such as Pocket PC. In contrast with on-line CR where a user writes characters on an electronic input device, making writing sequence and temporal information known, off-line CR (also known as optical character recognition or OCR) digitizes all characters on a printed media at once. Because of lacking sequence and temporal information, the off-line CR was claimed to be more difficult than the on-line CR. In the early stage of Thai OCR, most research focused on recognizing printed/typed characters, such as (Kimpan, Itoh, &amp; Kawanishi, 1983; Kimpan, 1986) while recent works (Methasate, Jitapunkul,
Kiratiratanaphrug, &amp; Unsiam, 2000; Phokharatkul &amp; Kimpan, 2000; Veerathanabutr &amp; Homma, 2000) have coped with handwritten characters. In general, the quality of handwritten characters is a crucial factor in how difficult the recognition problem is, affecting the level of success. For hand-printed or politely-written characters, neighboring characters are clearly separated. On the other hand, when one writes characters informally, roughly or quickly, the quality of characters becomes poor, e.g., contiguous char-acters (semi-cursive) and/or indigested (or distorted) characters. Normally, the connection of contiguous characters causes the degradation of recognition ability since it is necessary for us to correctly segment single characters from such contiguous characters. Following several works on English character seg-mentation in the writings of Elliman and Lancaster (1990) and Dunn and Wang (1992), many researchers have tried to tackle the similar problem of contiguous Thai characters, such as those in Chaiyakhet and
Chamnongthai (1999), Lohakan, Airphaiboon, and Sangworasil (1999), Premratanachai, Premchaiswadi, and Premchaiswadi (1999), Premchaiswadi, Premchaiswadi, and Narita (2000). Unfortunately, there have not yet been any report of good approach on contiguous-character recognition, i.e., segmentation and recognition of contiguous characters. The solution to recognize contiguous characters is still open. At present, most researchers on Thai OCR have assumed that the input characters are already isolated such as
Airphaiboon and Kondo (1996) and Phokharatkul and Kimpan (1998). To recognize a character, it is necessary for us to extract some features from a character and use them for recognition. There are two different possible types of features used in this task, i.e., global and local features. Some systems (Dehghani,
Shabani, &amp; Nava, 2001; Hee-Seon &amp; Seong-Whan, 1996; Jirayusakul &amp; Siriboon, 2002; Nafiz &amp; Fatos, 1998; Nishimura, Kobayashi, Maruyama, &amp; Nakano, 1999; Wongtapan, Theeramunkong, &amp; Sinthupinyo, 2002; Meknavin, Kijsirikul, Chotimongkol, &amp; Nuttee, 1998) used only global features, which are infor-mation extracted from the whole character image, to recognize the character. In Airphaiboon and Kondo (1996), Methasate et al. (2000), Phokharatkul and Kimpan (1998), Phokharatkul and Kimpan (2000),
Veerathanabutr and Homma (2000), local features, information extracted from some parts of the character such as circles, concavity, endpoints and lines, are utilized for recognition. The utilization of this infor-mation strongly depends on individual languages, i.e., the need of linguistic knowledge. However, there also are some works (Kundu, He, &amp; Chen, 1998; Chen &amp; Kundu, 1994) using the combination of local and global features. In the early stage of Thai CR (Kimpan et al., 1983) used template matching directly with 2-D image data of characters, i.e., global features, to recognize printed Thai characters. This technique is very simple but it needs highly intensive computation and is sensitive to noise and distorted characters.
However, to achieve more performance and robustness, most previous Thai OCR methods extracted local features (or dominant features) of Thai characters, such as head and loop (or circle), concavity (or curl), endpoint, and line. Then a number of different techniques, e.g., structural technique (Airphaiboon &amp; Kondo, 1996; Kimpan, 1986) and neural network (Phokharatkul &amp; Kimpan, 1998; Phokharatkul &amp;
Kimpan, 2000; Veerathanabutr &amp; Homma, 2000) were applied. Although these local features are useful in improving recognition accuracy, in real situation, they are often omitted as shown in Fig. 1, leading to a lower recognition rate.

On the other hand, there were still few works using global features in Thai character recognition. Ji-rayusakul and Siriboon (2002) applied global features with HMM on online Thai OCR. Wongtapan et al. (2002) proposed a feature extraction method called island-based projection (IBP) together with interpolated n -gram model ( n -gram) for recognizing off-line Thai handwritten characters. In this work, the IBP repre-sented a character image by transforming 2-D image data to 1-D data in vertical and horizontal directions.
Although the method is very promising, it was just a preliminary work with no comparison with other existing methods. In this paper, we propose a method, called multi-directional island-based projection (for short, MDIBP), to extract features from isolated handwritten characters. As the recognition model, two alternative statistical approaches, namely interpolated n -gram model ( n -gram) and hidden Markov model (HMM), also are proposed and compared with each other. The performance of the proposed feature extraction and recognition models is investigated using nearly 23,400 naturally-written Thai characters, collected from 25 subjects. The result is compared to some common previous feature extraction techniques.
An application to English characters also is explored. The rest of this paper is organized as follows. Section 2 gives a review of previous feature extraction methods. In Section 3, the proposed multi-directional island-based projection is described. Section 4 illustrates two recognition models; n -gram and HMM. The over-view of our recognition scheme is displayed in Section 5. Section 6 provides the experimental results. The result analysis is given in Section 7. Finally, a conclusion is made in Section 8. 2. Previous feature extraction methods
Besides the recognition model applied, selection of a feature extraction method is the most important factor in achieving high recognition performance. Recently, some literatures (Govindan &amp; Shivaprasad, intensive reviews on existing feature extraction methods. However, given the vast number of papers pub-lished on OCR every year, it is almost impossible to illustrate all the available methods. This section gives a brief summary on a number of some related previous methods in order to position the method proposed in this paper. The techniques described are useful for not only character recognition but also general image recognition including of objects and textures. Feature extraction methods are varied according to the type of an image the features are extracted from, e.g., gray-scale images and binary raster images. Possible features extracted from a gray-scale image are typically larger than those extracted from a binary raster image. One challenge of using gray-scaled image-based methods is to locate candidate character locations.
Applying a locally adaptive binarization method, one can obtain a good binary raster image and use connected components of the expected character size to locate the candidate characters. In the situation that recognition based on the binary raster representation fails, a gray-scale-based method becomes useful to recognize characters. Although one may expect better recognition using gray-scale-based methods, the improvement seems trivial since intuitively the gray-scale information does not contribute to the recogni-tion significantly.

In the past, several research works were done to achieve high recognition rate using features extracted from binary raster images. Existing feature extraction techniques includes template matching (Gader et al., 1991; Tubbs, 1989), unitary transforms (Andrews, 1971; Garris et al., 1994), project histograms (Glau-berman, 1956; Kasturi, 1990), zoning (Bokser, 1992), geometric moments (Yang &amp; Albregtsen, 1994;
Belkasim, Shridhar, &amp; Ahmadi, 1991) and so forth. In the template matching approach, the feature step, a similarity (or dissimilarity) measure between each template and the test character image is computed by means of some distance formula, such as mean-square distance, correlation, Jaccard distance and Yule distance (Pratt, 1991; Tubbs, 1989). Some obvious limitations include rotation-and size-invariance and noise sensitiveness. However, the input image can be scaled to suit template sizes, thus making it scale-independent. As another primitive approach, the projection histogram technique applies projections on a set of axes to reduce the number of features. Although it is mostly used nowadays for segmenting char-acters, the technique can be extended for recognition. Histograms of horizontal and vertical projection of the character on these two axes are calculated and used as features. The features become scale independent by using a fixed number of bins on each axis and dividing by the total number of print pixels in the character image. Histograms are very sensitive to rotation and variability in writing style. A unitary transform reduces the number of features while preserving most of the shape information of the character.
The unitary transform has to be applied to a training set to obtain estimates of the variance of the pixels in the transformed space. There are some possible transforms such as KL Fourier, Hadamard and Haar transforms. The features extracted by unitary transforms are not rotation-and size-invariant. The scaling and orientation rotation are needed to improve the accuracy. Zoning on binary characters was used to compute the percentage of black pixels in each zone. This information is applied for recognition. This method is designed to recognize machine-printed characters of almost non-decorative font, possibly se-verely degraded by, for example, several generations of photocopying. This method is not size-and rota-tion-invariant. Additional features may be needed to improve the performance of general handwritten characters. Even though most of the above-mentioned approaches are not rotation-, translation-and size-invariant, it is possible to apply some preprocessors to adjust the orientation and the position, and nor-malize the character size before using the methods to recognize the character.

As direct solutions to the variance problems, one can make use of some invariant features of characters for pattern recognition. The approach was first introduced by Hu (1962). Hu developed absolute orthogonal moment invariants, i.e. invariant to translation, scale and rotation. This approach requires the detection of the center of gravity of the object (character). The features are extracted by way of calculating regular moments of some orders around the detected center. The recognition accuracy using geometric moment invariants decreases when the center of gravity is not correctly detected. It was said that at least 10 X 15 features are needed for a successful CR (Reiss, 1993). As another kind of moment invariant, Zinike moments have been used by Khotanzad and Hong (1990) and Belkasim et al. (1991). Some techniques from the outer contour curve or the skeleton of the character. Moreover, several previous methods combine more than one techniques (Cao, Ahmadi, &amp; Shridhar, 1994; Hee-Seon &amp; Seong-Whan, 1996; Nishimura et al., 1999). For instance, the regional projection contour transformation (RPCT) combines histogram projection, zoning and contour approach (Hee-Seon &amp; Seong-Whan, 1996). 3. Multi-directional island-based projection
If a statistical model is applied directly on 2-D character image grids, it is necessary to consider a large number of parameters and hence it requires a large amount of training data. To solve this problem, there were some attempts (Kundu et al., 1998; Chen &amp; Kundu, 1994; Dehghani et al., 2001; Hee-Seon &amp; Seong-
Whan, 1996; Nafiz &amp; Fatos, 1998; Nishimura et al., 1999; Wongtapan et al., 2002) to transform a 2-D character image grid to 1-D sequential data before applying a statistical model. In this section, a new feature extraction method called multi-directional island-based projection (MDIBP) is introduced. After orientation and translation adjustment, the character image is normalized to a fixed size window. The basic principle of the MDIBP is that for each of multiple directions, the normalized window is cut into a set of small slices, and then features are extracted from these slices. There are two main steps in the feature extraction based on the MDIBP. The former step is to extract raw feature vectors ( rfv ) from each training image, while the latter is to reduce the numerosity (variety) of features by performing so-called vector applying a zoning technique with a new concept called island-based projection . Vector quantization is a clustering technique to group and then replace similar feature vectors with a same label. 3.1. Ra wfeature extraction
It is possible to slice an image in various directions. Though there is no limitation to these, some possible left diagonal  X  R  X  directions. Fig. 2 shows horizontal and vertical directions, and Fig. 3 indicates the two diagonal directions. For each direction, the number of extracted features corresponds to the number of slices, i.e., a feature per slice. In the MDIBP method, a feature is represented by a vector each element of which is the number of islands in a zone in the slice, where an island is defined as a group of consecutive active pixels. For instance, in the example given in Figs. 2 and 3, the window size is 36  X  36 pixels and the is encoded by dividing a slice into a number of even regions, e.g., six even regions (each of which holds six consecutive pixels) as shown in the figures. The first element of the vector is the number of islands in the whole slice. The second to the seventh elements are the numbers of islands in the six regions, respectively. To clarify the concept, the method can be formulated as follows. Assume that A is an image matrix consisting of N N pixels, a ij is the binary value of each pixel ( i th row and j th column), taking 0 for an inactive pixel (white) and 1for an active pixel (black), the number of slices is N and the number of zones is concise explanation, only the horizontal feature set is described. However, the others can be easily induced in the same manner. The feature set H  X  A  X  X f h 1 ; h 2 ; ... ; h h vector f a k 1 ; a k 2 ; ... ; a kN g . The first element of h zones. The h k  X  m  X  1  X  is the number of islands in the m th zone.

For instance, given N  X  36 and M  X  6, the feature vectors for the 16th and 25th slices of the V and H directions respectively, can be extracted as illustrated in Fig. 2. The vector v
The vertical projections reflect the upper-right to lower-left diagonal  X  R  X  and the projections along the horizontal direction reflect the upper-left to lower-right diagonal  X  L  X  directions. Therefore, there are 36 feature vectors generated for each direction. These vectors form a feature set. Due to 4-directioned slicing, a character is represented by 4 feature sets each including 36 feature vectors. 3.2. Numerosity reduction using clustering
Due to high numerosity of the raw feature vectors ( rfv ) extracted in the previous step, we need to reduce the numerosity. The process is known as vector quantization in the field of speech recognition. When there are M elements in a rfv , we can think of this as an M -dimensional space containing many points. Vector quantization divides this M -dimensional space into a set of K labelled regions. Therefore, each extracted rfv can be represented with only a single label, one of K predefined labels, rather than a vector of M numbers.
Although this may cause some information loss in going from a feature vector to a label that summarizes a whole neighborhood around the vector, it is helpful to improve the tolerance when the writing style is quite various, and there are some automated methods for selecting an optimal quantization of the vector space so that little or no inaccuracy is introduced (Jelinek, 1990). As one possible quantization technique, clustering is useful for grouping a set of physical or abstract object into classes of similar objects. A cluster is a collection of data objects that are similar to one another within the class cluster and are dissimilar to the objects in other clusters. Although there exist several clustering algorithms, we describe the K -means algorithm, an iterative-improvement algorithm, that is applied in this work. The K -mean is a most well-known and commonly used algorithm based on partitioning approach. It can be formulated as follows. Let
D  X f x 1 ; x 2 ; ... ; x n g be n distinct rfv  X  X , gathered from all images. The task is to find K clusters f C 1 ; C 2 ; ... ; C K g that give the best clustering of the data. for k  X  1 ; 2 ; ... ; K let r  X  k  X  be a randomly chosen rfv  X  X  from D ; while there are some changes in clusters C k do end
Here, the distance between two points, say d  X  p ; q  X  , can be computed by means of an inner product of those two vectors, i.e., p q . Given the result clusters, the rfv  X  X  for images can be replaced with labels corresponding to them. 4. n -gram and HMM for character recognition 4.1. Basic formulation of character recognition problem Consider a set of V character symbols C  X f c 1 ; c 2 ; ... ; c training character images T  X  c v  X  . Given a slicing direction, each character image e 2 T  X  c set of features extracted O  X f o 1 ; T g X f o 1 ; o 2 ; ... ; o
K possible feature symbols F  X f f 1 ; f 2 ; ... ; f K g , i.e., o 4.2. Statistical approach
An n -gram model and HMM are both types of statistical approach. In a statistical approach, character recognition is to find the character c v whose probability p  X  c given below.
Here, P  X  o 1 ; T  X  can be omitted since its value does not affect the value-ranking order of P  X  c
P  X  c v  X  is the a priori probability that is modeled by a probability model of the character occurrence fre-quency, and hence it will be ignored if one assumes that the a priori probabilities P  X  c identical. Normally, a large set of training data is required in order to obtain relatively highly reliable
P  X  o 1 ; T j c v  X   X  X  due to its high complexity. Toward the problem, n -gram and HMM are useful to reduce the complexity by approximating values but retain the model X  X  accuracy. 4.3. n -gram models for character recognition
An n -gram is a sequence of n events that appear consecutively in the context. Based on a Markov model, n -grams are used extensively in language modeling for automatic speech recognition systems, as well as in other recognition and disambiguation tasks. Graphically represented by a Markov chain, an n -gram model drastically approximates the probability of an occurrence of an event by its probability of occurrence within a short sequence of its preceding n events. These dependencies also are known as a Markov assumption.
That is, n -gram is a special form of a Markov model. In the case of n  X  3 (a trigram model), P  X  o be estimated as follows.

The second equation is derived by introducing a Markov assumption on the original first equation. The first two terms of the last equation represent the probability of the first two events of o two previous events upon which to condition the probability. Finally, with two pseudo events o the equation is simplified as follows.

To create a 3-gram model for each character symbol, pairs and triples of events which form that character symbol in the training set, are counted and recorded. That is, they are the numbers of o number. Although the trigram model is a good estimation for the original probability, it usually suffers a well-known major problem called data sparseness when the training set is not sufficient. That is, some relevant trigrams never appear and hence their expected probabilities become zero. One solution to this problem is to smooth the probabilities by interpolating the trigram with bigrams and unigrams as shown below.

Here, a 1 , a 2 , a 3 are three positive constants such that a of unigrams, bigrams and trigrams, respectively. If we assume that most of the time we do have trigrams and that they yield a more accurate assessment of the probabilities than bigrams or unigrams, then a should be so much higher than the other two that it dominates the probability calculations. 4.4. HMMs for character recognition
A HMM is a doubly statistical process with an underlying Markov process that is not directly observable (hidden), but can only be observed through another set of statistical processes that produce the sequence of observed symbols (Kundo, 1997) (also see Rabiner, 1989). In contrast with an n -gram model where the transition among states is deterministic, a HMM is a generalization of Markov chains in which a given state may have several outgoing transitions all with the same input symbol (i.e., non-deterministic). The HMM is characterized by a finite-state Markov chain and a set of output distributions. The transition parameters in the Markov chain model temporal variabilities, while the parameters in the output distributions model spectral variabilities. Following the notation introduced by Rabiner (1989), the elements of the first-order HMM for character recognition are formally defined as follows.
 M : the number of observation symbols;
Hence, a model can be denoted by a parameter set k  X  X  A ; B ; P  X  . In character recognition framework, we can construct a model for each character symbol  X  c v  X  using its training images  X  T  X  c
HMM, three problems are usually mentioned: optimization criterion, classification and training. For the first problem, there exist a number of optimization criteria, such as the traditional maximum likelihood (ML), maximum mutual information (MMI), minimum discrimination information (MDI) and so forth. Among these criteria, the most nature choice is the ML criterion that maximizes the following equation.
For ML criterion, the estimation of the parameters can be solved by the Baum-Welch re-estimation algorithm, an iterative procedure. The algorithm guarantees monotonic increase of the likelihood function for a given set of training samples.

The second problem is to find the character c v that had the highest probability P  X  k and the equality of a priori probabilities, it is equivalent to maximizing P  X  O j k
For a given k , an efficient method to find P  X  O j k  X  is the well known forward X  X ackward algorithm. To find which model is the most likely to produce the observations, it is necessary to calculate the probability of the observation sequence O given the model k . The calculation is done by defining the forward variable, a  X  i  X  X  P  X  o 1 o 2 ; ... ; o t ; q t  X  i j k  X  . This is the probability of the partial observation sequence o state i at time t , given the model k . The a t  X  i  X  can be inductively derived by the forward algorithm.
Step 1. Initialization:
Step 2. Induction: For t  X  1 ; 2 ; ... ; T 1 Step 3. Termination:
In practice, as t increases, the value of a t  X  i  X  could be very small and then an underflow may occur due to a digit cancellation. Therefore, normally a scaling procedure will be performed. Reversely, a similar computation is applied to calculate the backward variable b and backward variables are used for the training procedure.

As the third problem, a training procedure is made to find the most probable model parameters for a given training data. Using the ML function, given initial estimates for k  X  X  A ; B ; P  X  , the re-estimated estimation algorithm is useful for this purpose. This is a gradient descent algorithm to find optimal esti-mation. The re-estimation is repetitively held until the probability difference becomes very small according time t  X  1, given the observation sequence O and the model k . As another definition, the probability of being in state i at time t , given O and k , can be calculated by summing n over j as shown below.
Using these two definitions, the re-estimation formulas for P , A and B are 5. The recognition scheme
This section describes the whole process of the proposed recognition system. As shown in Fig. 4, the system is divided into four tasks: (1) preprocessing, (2) feature extraction, (3) training, and (4) recognition.
As the first task, each input raw character image is preprocessed in order to create an image that is suitable for the next step. This process utilizes binarization (two-level thresholding), noise reduction by medium filter, single-character extraction, size normalization and centering. These techniques are commonly used in pattern recognition. Secondly, a set of features is generated from the modified image. For this purpose, the proposed MDIBP method is applied to transform an image into a set of feature sequences (i.e., rfv )as shown in Section 3. At this point, three subprocesses involved are feature extraction, clustering and feature sequence generation as shown in Fig. 4.

The clustering reduces numerosity and the clustering result is used for transforming a rfv to a label, resulting in producing a sequence of labels (feature sequence). The clustering process is considered indi-vidually for each of four directions, horizontal, vertical and two diagonal ones. That is, clustering is sep-arately done for each direction, not all directions at the same time. The feature sequence generation transform a rfv of a direction based on the result clusters of that direction. Fig. 5 illustrates an example of transforming rfv  X  X  into a feature sequence vector, each element of which is a label, based on the clustering result in the horizontal direction.

In the training task, given a training set of character images for each character symbol, the extracted features of the character images are used for training the character symbol model. There are four models for the character symbol, corresponding to four directions. In this work, we consider two alternative types of statistical models; n -gram models and HMMs. The training task for an n -gram model is straightforward by counting frequencies of single, pair, and triple of consecutive features while that of a HMM is done by the Baum-Welch re-estimation algorithm (see Section 4).

The recognition task is to find the model that gains the highest probability given the features extracted for the character image we would like to recognize, and then select it as the recognition result. Concretely, after preprocessing, a character image in query is processed by extracting raw features and transforming them to a set of feature sequence vectors for each direction. To recognize the character, the probabilities of four models of each character are independently estimated. These probabilities are then equally combined together before comparing with the result from the models of other character symbols. Thus, the proba-bility calculation for n -gram is simply a multiplication of trigrams while that of HMM is calculated by using
Viterbi algorithm (see Section 4). 6. Experimental results 6.1. Data set &amp; model parameters
To investigate efficiency of the proposed approach, a data set is constructed with 78 Thai character symbols, including 44 consonants, 24 vowels, and 10 Thai numbers (the left part of Fig. 10 in Appendix A). As a characteristic of Thai characters, there are three possible levels of character positions: standard, upper and lower levels. Sixty-five out of 78 characters are located at standard position, 11 located at upper level and 2 located at lower level. In the process of data set construction, each of 25 subjects is requested to write 12 naturally-written characters (not so good and so bad) for each character symbol. Therefore, the data set contains totally 23,400 (78  X  25  X  12) character images of naturally-written characters. The evaluation is made under two different settings: OPEN-TEST and CLOSE-TEST. In the OPEN-TEST experiment, the data set is randomly split into three equal subsets beforehand, and then 3-fold cross validation is executed.
That is, two of three subsets are used for training a model, and the remaining one subset stands for evaluating the efficiency of the constructed model. This procedure repeats three times by swapping the training and testing subsets. Therefore, all character images are tested once. In the CLOSE-TEST exper-iment, the whole data set is used for both training and testing (evaluation). As another factor, two alter-native environments of writer-dependence (WD) and writer-independence (WI) are considered. In the WD environment, the written-character data of each writer are separately trained and evaluated whereas the whole data set is used for training and evaluating in the WI environment. For the latter, to be unbiased, the test set is formed by selecting the same number of characters from each writer. The settings of n -gram and
HMM are as follows. In n -gram models, the interpolation parameters for unigrams, bigrams and trigrams, preliminary experiments, these parameters gained good performance.

To implement the HMMs, the three important factors: (1) observation symbols, (2) the number of states and (3) the model type, are considered. In our implementation, the number of observable symbols M equals to the number of clusters in the feature extraction process. By default, it is set to 32. In the issue of the number of states, each character model is naturally designed to have the same number of states  X  N  X  , which is 32 by default. For the model type, a four-state-jumping left-to-right model which satisfies the following constraints, is used (Fig. 6).
Another factor associated with training HMM parameters via re-estimation algorithm is initial estimates for HMM parameters. The initial state transition probabilities are specified as follows: a a ij  X  0 : 10  X  j  X  i  X  1  X  , a ij  X  0 : 05  X  j  X  i  X  2  X  , a are adapted from Waleed and Nikola (1999). Moreover, the initial symbol probabilities are randomly assigned. The entrance to and the exit from the model are always the first and last states, respectively. In both n -gram and HMM, the probabilities gained from the four models, each corresponding to a direction, are combined using equal weights, i.e., 0.25. 6.2. Basic experiments
A number of basic experiments are performed to investigate the efficiency of the proposed method. The model of each direction and their combinations are evaluated. In the experiments, the number of clusters  X  M  X  and that of states  X  N  X  in HMM are both set to 32. The results of WD and WI are given in Tables 1and 2, respectively.

From the result, the model combination improves the recognition rate over the models of single directions. Vertical information tends to be more helpful for recognition than the others, and left diagonal information seems less significant. Not surprisingly, CLOSE-TEST gains higher accuracy than OPEN-
TEST. The performance difference between n -gram and HMM is not so dominant, but HMM is slightly better than n -gram. Moreover the accuracy of WI is lower than that of WD in all cases. For the OPEN-
TEST setting, the best performances for WD and WI are 90.46% and 85.10%, respectively. They become 99.89 and 97.24 for CLOSE-TEST. In the viewpoint of the model complexity, the numbers of parameters for n -gram and HMM are M 3  X  M 2  X  M and N 2  X  X  N M  X  , respectively. In the experiments, since M and
N are both set to 32, n -gram has more parameters than HMM. However, trigrams are not significant in the model because their weights are set to merely 0.05. This fact indicates that n -gram and HMM almost have the same number of parameters. 6.3. Comparison to other feature extraction methods
To perceive the advantage of the MDIBP, the method is compared to other existing feature extraction methods that were reported to achieve high accuracy in character recognition. To do this, we explore three methods that extract global features, namely (1) projection histogram (Glauberman, 1956), (2) regional projection contour transformation (RPCT) (Dehghani et al., 2001; Hee-Seon &amp; Seong-Whan, 1996) and (3)
Nafiz X  X  method (Nafiz &amp; Fatos, 1998). The projection histogram simply transforms 2-D data into 1-D data by projecting image pixels on some axes and then counting the number of pixels (see Fig. 11 in Appendix pattern are projected onto four projection bases in vertical, horizontal, horizontal X  X ertical and diagonal X  diagonal directions. Thereafter a contour chain is extracted from the pattern. These operations transform an image into a unique contour. By sampling points on the contour, we can find the sequence of a chain code for each direction of such contour and represent it as a feature sequence vector. The pictorial rep-resentation of the RPCT using an example image is shown in Fig. 12 in Appendix A. The Nafiz X  X  method transforms the 2-D image data into a 1-D data by the following procedure. First of all, the character image is considered in four directions, the same as the MDIBP. In each scanning line of the direction, the image is split transversely into four sub regions. Here, the number of pixels in each region is coded by the power of 2.
Next, in this scanning line, the medians of the inactive pixel (black) runs are identified. The code of regions where the median of runs are located, are summed up. Finally, by a clustering technique (vector quanti-zation), the features of 2-D image are embedded into a sequence of 1-D codes, selected from a codebook.
An example of this encoding is shown in Fig. 13. In this experiment, the 30-cluster is applied since it gains the highest accuracy among different numbers of clusters. The comparison of the MDIBP with three methods is made in the environment of OPEN-TEST and WI. Totally 9320 characters randomly selected from 10 subjects are used for evaluation. Fig. 7 shows the recognition result obtained from four feature extraction methods.

From the result, the MDIBP dominantly outperforms the other methods in both n -gram and HMM. It achieves up to 84 X 85% accuracy. A comparative method is the Nafiz X  X  method which is the best among the three baselines. This method gains approximately 71 X 72% accuracy. The highest accuracies for projection histogram and RPCT are 68% and 52% respectively. In conclusion, the result indicates that the MDIBP seems to provide more useful information for recognizing Thai characters than the others. Moreover, the
HMM seems trivially better than n -gram for all methods, except the projection histogram. 6.4. Effect of the number of clusters and states
An experiment is made to investigate how the number of clusters effects recognition accuracy of the proposed method in n -gram and HMM. Basically, clustering is useful for reducing the variations of raw feature vectors and probably resulting in improvement of recognition accuracy. However, having too many or too few clusters may cause the reduction in recognition rate. Determining the appropriate number of clusters is also one of the important tasks. Fig. 8 graphs the recognition accuracy against the number of clusters in both CLOSE-TEST (left) and OPEN-TEST (right) settings in the WI environment. The graphs of n -gram and HMM are similar in their shapes, even HMM slightly outperform n -gram, except the case of 12 clusters in CLOSE-TEST. That is, when the number of clusters increases, the recognition improves.
However, we can observe that the improvement in OPEN-TEST saturates when the number of clusters is 48. The experiments previously described in Section 6.2, apply the 32-cluster since it gains relatively high accuracy even though its accuracy is somewhat lower than those of 48 and 64 clusters, but the computation time is drastically lower.

Another parameter of HMM that affects the recognition rate is the number of states. We also investigate how it affects the accuracy in CLOSE-TEST. Table 3 shows the recognition accuracy with regard to dif-ferent numbers of states and clusters. Intuitively, increasing the number of states and clusters improves the accuracy in HMMs. However, the larger the number of states is, the more computation time it takes for the recognition task. By this reason, the 32-state is selected as the default in the previous experiments. 6.4.1. Application to English character recognition
As the proposed method is general, its efficiency on English written characters also is explored. To this end, an English data set is constructed with 35 character symbols, including 26 letters and 9 Arabic numbers as shown in the right part of Fig. 10 in Appendix A. Here, the zero  X 0 X  is excluded since it is extremely similar to the letter  X  X  X . In this task, each of 30 subjects was asked to write 12 naturally-written characters for each English character symbol. The default settings for this experiment are the same as those of experiments with Thai characters. The graphs in Fig. 9 plot the accuracy against the number of clusters in both CLOSE-TEST (left) and OPEN-TEST (right) settings in WI environments.

Similar to the results of Thai characters, HMM is slightly better than n -gram and increasing the number of clusters improves the accuracy. In the CLOSE-TEST, recognition of English characters is at most as good as that of Thai characters. In contrast, the result of OPEN-TEST shows higher recognition (up to 92% accuracy) in English than in Thai. It is not surprising since the number of characters in English (35 characters) is much smaller than that in Thai (78 characters). For more details related to HMM, Table 4 shows the recognition accuracy with regard to different numbers of states and clusters in the CLOSE-TEST. The accuracy increases when the numbers of states and clusters becomes larger. Due to the same reason as Thai CR, the 32-state is selected as the default.
 7. Summary and result analysis
This section gives a summary of and analysis to all experimental results. A single-directioned model, such as pure vertical, pure horizontal and two pure diagonal models, gained not so high accuracy but the combination of these models gives a good result, compared to projection histogram, RPCT and Nafiz X  X  method. Although the large numbers of states and clusters may increase the accuracy, too many states and clusters harm the recognition accuracy, especially in the OPEN-TEST setting. Applying the method to
English provides a similar result but it achieves higher accuracy for OPEN-TEST. At least three possible reasons for having higher accuracy in English than that in Thai are as follows. First of all, English has fewer character symbols. It is an easier task to pick up a correct answer from fewer candidates. Secondly,
Thai characters have a complex structure and then result in several writing styles of a character. Thirdly, several characters look similar to the others, i.e., shape similarity. Fig. 14 shows a set of similar characters in Thai and English. It is notable that the number of similar Thai character symbols is larger than that of
English character symbols. Moreover, comparing Thai and English written characters as shown in Fig. 10, one can observe that there is more similarity among Thai characters than English characters. As an error analysis, we investigate which characters are easily misrecognized. Fig. 15 shows the top 5 of Thai and
English characters that gain the highest and lowest accuracy in the proposed method. From the top to the bottom, the result is listed in the order of HMM (Thai), n -gram (Thai), HMM (English) and n -gram (English). The left part of the figure points out the characters with high accuracy while the right part indicates the characters with low accuracy as well as the characters to which the system misrecognizes.
Although there is a variation between HMM and n -gram, some characters are hard for both models. For example, in both cases of Thai and English characters, the first and second items of HMM also are hard to recognize in the n -gram. We observe that such cases are difficult for humans to classify. Note that some of the hard-to-be-recognized characters are the same as those indicated in Fig. 14. 8. Conclusion and future works
The local features are widely applied in several existing Thai OCR systems. In natural handwriting, these local features are often missed. Instead of using such local features, this paper presents a method to extract features from handwritten characters using a method called multi-directional island-based projection. To facilitate the recognition process, binarization, noise reduction by medium filter, single-character extrac-tion, size normalization and centering are employed. Four directions of island-based encoding of an character image are selected for creating features. Clustering is used for reducing numerosity. As the rec-ognition model, two statistical recognition approaches using interpolated n -gram model ( n -gram) and hidden Markov model (HMM) are introduced. In order to verify the effectiveness of the feature extraction and recognition methods, a relatively large set of naturally-written Thai characters with numerous varia-tions is gathered and used in the experiments. Encouraging results have been obtained using the proposed method. In situations where local features are hard to detect, both n -gram and HMM approaches gain up to 96 X 99% accuracy for CLOSE-TEST and 84 X 90% for OPEN-TEST. Experimental results showed that, the proposed method yields a high recognition rate compared with other feature extraction methods. Applying the method to English character recognition expresses an evidence that the method also works well. The error analysis makes us know the misrecognized characters which seem hard for humans to classify. Although the proposed scheme is a very promising approach for solving the problem of large-set of handwritten Thai character recognition, the following topics are needed for further exploration. The next step is to compare this method with other techniques, such as the neural network, the time-delay neural network and the deformable template. These methods will be used for comparing in the scope of the recognition rate and the computation time. Combining the method with a language model also is worth investigating.
 Appendix A. Discussion materials
An example of character images of all character symbols in Thai and English data sets is shown in Fig. 10. Examples of extracting features based on projection histogram, regional projection contour transfor-mation (RPCT) and Nafiz X  X  method are shown in Figs. 11 X 13, respectively. Fig. 14 shows a set of similar characters in Thai and English while the characteristics of misrecognized characters are shown in Fig. 15. References
