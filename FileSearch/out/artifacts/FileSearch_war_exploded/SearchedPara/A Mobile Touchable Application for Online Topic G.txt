 Today X  X  Web search is still dominated by a docu-ment perspective: a user enters one or more key-words that represent the information of interest and receives a ranked list of documents. This technology has been shown to be very successful when used on an ordinary computer, because it very often delivers concrete documents or web pages that contain the information the user is interested in. The following aspects are important in this context: 1) Users basi-cally have to know what they are looking for. 2) The documents serve as answers to user queries. 3) Each document in the ranked list is considered indepen-dently.

If the user only has a vague idea of the informa-tion in question or just wants to explore the infor-mation space, the current search engine paradigm does not provide enough assistance for these kind of searches. The user has to read through the docu-ments and then eventually reformulate the query in order to find new information. This can be a tedious task especially on mobile devices. Seen in this con-text, current search engines seem to be best suited for  X  X ne-shot search X  and do not support content-oriented interaction.

In order to overcome this restricted document per-spective, and to provide a mobile device searches to  X  X ind out about something X , we want to help users with the web content exploration process in two ways: 1. We consider a user query as a specification of 2. The user can interactively explore this topic
In the first step, the topic graph is computed on the fly from the a set of web snippets that has been collected by a standard search engine using the ini-tial user query. Rather than considering each snip-pet in isolation, all snippets are collected into one document from which the topic graph is computed. We consider each topic as an entity, and the edges between topics are considered as a kind of (hidden) relationship between the connected topics. The con-tent of a topic are the set of snippets it has been ex-tracted from, and the documents retrievable via the snippets X  web links.

A topic graph is then displayed on a mobile de-vice (in our case an iPad) as a touch-sensitive graph. By just touching on a node, the user can either in-spect the content of a topic (i.e, the snippets or web pages) or activate the expansion of the graph through an on the fly computation of new related topics for the selected node.

In a second step, we provide additional back-ground knowledge on the topic which consists of ex-plicit relationships that are generated from an online Encyclopedia (in our case Wikipedia). The relevant background relation graph is also represented as a touchable graph in the same way as a topic graph. The major difference is that the edges are actually labeled with the specific relation that exists between the nodes.

In this way the user can explore in an uniform way both new information nuggets and validated back-ground information nuggets interactively. Fig. 1 summarizes the main components and the informa-tion flow.
 The following screenshots show some results for the search query  X  X ustin Bieber X  running on the cur-rent iPad demo X  X pp. At the bottom of the iPad screen, the user can select whether to perform text exploration from the Web (via button labeled  X  X  X  GNSSMM X ) or via Wikipedia (touching button  X  X  X  MILREX X ). The Figures 2, 3, 4, 5 show results for the  X  X  X  X NSSMM X  mode, and Fig. 6 for the  X  X -MILREX X  mode. General settings of the iPad demo-app can easily be changed. Current settings allow e.g., language selection (so far, English and German are supported) or selection of the maximum number of snippets to be retrieved for each query. The other parameters mainly affect the display structure of the topic graph.
 We consider the extraction of a topic graph as a spe-cific empirical collocation extraction task . How-ever, instead of extracting collations between words, which is still the dominating approach in collocation extraction research, e.g., (Baroni and Evert, 2008), we are extracting collocations between chunks, i.e., word sequences. Furthermore, our measure of asso-ciation strength takes into account the distance be-tween chunks and combines it with the PMI (point-wise mutual information) approach (Turney, 2001).
The core idea is to compute a set of chunk X  pair X  X istance elements for the N first web snip-pets returned by a search engine for the topic Q , and to compute the topic graph from these ele-ments. 1 In general for two chunks, a single chunk X  pair X  X istance element stores the distance between the chunks by counting the number of chunks in X  between them. We distinguish elements which have the same words in the same order, but have different distances. For example, (Peter, Mary, 3) is different from (Peter, Mary, 5) and (Mary, Peter, 3).
 We begin by creating a document S from the N -first web snippets so that each line of S con-tains a complete snippet. Each textline of S is then tagged with Part X  X f X  X peech using the SVM-Tagger (Gim  X  enez and M ` arquez, 2004) and chun-ked in the next step. The chunker recognizes two types of word chains. Each chain consists of longest matching sequences of words with the same PoS class, namely noun chains or verb chains, where an element of a noun chain belongs to one of the extended noun tags 2 , and elements of a verb chain only contains verb tags. We finally ap-ply a kind of  X  X hrasal head test X  on each iden-tified chunk to guarantee that the right X  X ost ele-ment only belongs to a proper noun or verb tag. For example, the chunk  X  X /DT british/NNP for-mula/NNP one/NN racing/VBG driver/NN from/IN scotland/NNP X  would be accepted as proper NP chunk, where  X  X ompelling/VBG power/NN of/IN X  is not.

Performing this sort of shallow chunking is based on the assumptions: 1) noun groups can represent the arguments of a relation, a verb group the relation itself, and 2) web snippet chunking needs highly ro-bust NL technologies. In general, chunking crucially depends on the quality of the embedded PoS X  X agger. However, it is known that PoS X  X agging performance of even the best taggers decreases substantially when applied on web pages (Giesbrecht and Evert, 2009). Web snippets are even harder to process because they are not necessary contiguous pieces of texts, and usually are not syntactically well-formed para-graphs due to some intentionally introduced breaks (e.g., denoted by . . . betweens text fragments). On the other hand, we want to benefit from PoS tag-ging during chunk recognition in order to be able to identify, on the fly, a shallow phrase structure in web snippets with minimal efforts.

The chunk X  X air X  X istance model is computed from the list of chunks. This is done by traversing the chunks from left to right. For each chunk c i , a set is computed by considering all remaining chunks and their distance to c i , i.e., ( c i , c i +1 , dist ( c i , c i +2 , dist i ( i +2) ) , etc. We do this for each chunk list computed for each web snippet. The distance dist ij of two chunks c i and c j is computed directly from the chunk list, i.e., we do not count the position of ignored words lying between two chunks.

The motivation for using chunk X  X air X  X istance statistics is the assumption that the strength of hid-den relationships between chunks can be covered by means of their collocation degree and the frequency of their relative positions in sentences extracted from web snippets; cf. (Figueroa and Neumann, 2006) who demonstrated the effectiveness of this hypothe-sis for web X  X ased question answering.

Finally, we compute the frequencies of each chunk, each chunk pair, and each chunk pair dis-tance. The set of all these frequencies establishes the chunk X  X air X  X istance model CP D M . It is used for constructing the topic graph in the final step. For-mally, a topic graph T G = ( V, E, A ) consists of a set V of nodes, a set E of edges, and a set A of node actions. Each node v  X  V represents a chunk and is labeled with the corresponding PoS X  X agged word group. Node actions are used to trigger additional processing, e.g., displaying the snippets, expanding the graph etc.

The nodes and edges are computed from the chunk X  X air X  X istance elements. Since, the number of these elements is quite large (up to several thousands), the elements are ranked according to a weighting scheme which takes into account the frequency information of the chunks and their collo-cations. More precisely, the weight of a chunk X  X air X  distance element cpd = ( c i , c j , D ij ) , with D i,j { ( f req 1 , dist 1 ) , ( f req 2 , dist 2 ) , ..., ( f req is computed based on PMI as follows: where relative frequency is used for approximating the probabilities p ( c i ) and p ( c j ) . For log 2 ( p ( c we took the (unsigned) polynomials of the corre-sponding Taylor series 3 using ( f req k , dist k ) in the k-th Taylor polynomial and adding them up:
P M I ( cpd ) = ( The visualized topic graph T G is then computed from a subset CP D 0 M  X  CP D M using the m high-est ranked cpd for fixed c i . In other words, we re-strict the complexity of a TG by restricting the num-ber of edges connected to a node. In order to provide query specific background knowledge we make use of Wikipedia X  X  infoboxes. These infoboxes contain facts and important rela-tionships related to articles. We also tested DB-pedia as a background source (Bizer et al., 2009). However, it turned out that currently it contains too much and redundant information. For exam-ple, the Wikipedia infobox for Justin Bieber contains eleven basic relations whereas DBpedia has fifty re-lations containing lots of redundancies. In our cur-rent prototype, we followed a straightforward ap-proach for extracting infobox relations: We down-loaded a snapshot of the whole English Wikipedia database (images excluded), extracted the infoboxes for all articles if available and built a Lucene Index running on our server. We ended up with 1.124.076 infoboxes representing more than 2 million differ-ent searchable titles. The average access time is about 0.5 seconds. Currently, we only support ex-act matches between the user X  X  query and an infobox title in order to avoid ambiguities. We plan to ex-tend our user interface so that the user may choose different options. Furthermore we need to find tech-niques to cope with undesired or redundant informa-tion (see above). This extension is not only needed for partial matches but also when opening the sys-tem to other knowledgesources like DBpedia, new-sticker, stock information and more. For an initial evaluation we had 20 testers: 7 came from our lab and 13 from non X  X omputer science re-lated fields. 15 persons had never used an iPad be-fore. After a brief introduction to our system (and the iPad), the testers were asked to perform three different searches (using Google, i X  X NSSMM and i X  X ILREX) by choosing the queries from a set of ten themes. The queries covered definition ques-tions like EEUU and NLF , questions about persons like Justin Bieber , David Beckham , Pete Best , Clark Kent , and Wendy Carlos , and general themes like Brisbane , Balancity , and Adidas . The task was not only to get answers on questions like  X  X ho is . . .  X  or  X  X hat is . . .  X  but also to acquire knowledge about background facts, news, rumors (gossip) and more interesting facts that come into mind during the search. Half of the testers were asked to first use Google and then our system in order to compare the results and the usage on the mobile device. We hoped to get feedback concerning the usability of our approach compared to the well known internet search paradigm. The second half of the participants used only our system. Here our research focus was to get information on user satisfaction of the search results. After each task, both testers had to rate sev-eral statements on a Likert scale and a general ques-tionnaire had to be filled out after completing the entire test. Table 1 and 2 show the overall result. results first sight 55% 40% 15% -query answered 71% 29% --interesting facts 33% 33% 33% -suprising facts 33% --66% overall feeling 33% 50% 17% 4% results first sight 43% 38% 20% -query answered 65% 20% 15% -interesting facts 62% 24% 10% 4% suprising facts 66% 15% 13% 6% overall feeling 54% 28% 14% 4%
The results show that people in general prefer the result representation and accuracy in the Google style. Especially for the general themes the presen-tation of web snippets is more convenient and more easy to understand. However when it comes to in-teresting and suprising facts users enjoyed exploring the results using the topic graph. The overall feeling was in favor of our system which might also be due to the fact that it is new and somewhat more playful.
The replies to the final questions: How success-ful were you from your point of view? What did you like most/least? What could be improved? were in-formative and contained positive feedback. Users felt they had been successful using the system. They liked the paradigm of the explorative search on the iPad and preferred touching the graph instead of re-formulating their queries. The presentation of back-ground facts in i X  X ILREX was highly appreciated. However some users complained that the topic graph became confusing after expanding more than three nodes. As a result, in future versions of our system, we will automatically collapse nodes with higher distances from the node in focus. Although all of our test persons make use of standard search engines, most of them can imagine to using our system at least in combination with a search engine even on their own personal computers. The presented work was partially supported by grants from the German Federal Ministry of Eco-nomics and Technology (BMWi) to the DFKI The-seus projects (FKZ: 01MQ07016) TechWatch X  X rdo and Alexandria4Media.

