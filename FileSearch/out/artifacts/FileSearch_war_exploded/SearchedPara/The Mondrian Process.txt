 Relational data are observations of relationships between sets of objects and it is therefore natural to consider representing relations 1 as arrays of random variables, e.g., ( R i,j ) , where i and j index objects x i  X  X and y j  X  Y . Nonrelational data sets (e.g., observations about individual objects in X ) are simply one-dimensional arrays ( R i ) from this viewpoint.
 A common Bayesian approach in the one-dimensional setting is to assume there is cluster structure and use a mixture model with a prior distribution over partitions of the objects in X . A similar approach for relational data would na  X   X vely require a prior distribution on partitions of the product space X  X  Y = { ( x, y ) | x  X  X, y  X  Y } . One choice is to treat each pair ( x, y ) atomically, clustering the product space directly, e.g., by placing a Chinese restaurant process (CRP) prior on partitions of X  X  Y . An unsatisfactory implication of this choice is that the distribution on partitions of ( R i,j ) is exchangeable, i.e., invariant to swapping any two entries; this implies that the identity of objects is ignored when forming the partition, violating common sense.
 Stochastic block models 2 place prior distributions on partitions of X and Y separately, which can be interpreted as inducing a distribution on partitions of the product space by considering the product of the partitions. By arranging the rows and columns of ( R i,j ) so that clustered objects have adjacent indices, such partitions look like regular grids (Figure 1.1). An unfortunate side effect of this form of prior is that the  X  X esolution X  needed to model fine detail in one area of the array necessarily causes other parts of the array to be dissected, even if the data suggest there is no such structure. The annotated hierarchies described by Roy et al. (2007) generate random partitions which are not constrained to be regular grids (Figure 1.2), but the prior is inconsistent in light of missing data. Motivated by the need for a consistent distribution on partitions of product spaces with more struc-ture than classic block models, we define a class of nonparametric distributions we have named Mondrian processes after Piet Mondrian and his abstract grid-based paintings. Mondrian processes are random partitions on product spaces not constrained to be regular grids. Much like k d-trees, Mondrian processes partition a space with nested, axis-aligned cuts; see Figure 1.3 for examples. We begin by introducing the notion of partially exchangeable arrays by Aldous (1981) and Hoover (1979), a generalization of exchangeability on sequences appropriate for modeling relational data. We then define the Mondrian process, highlight a few of its elegant properties, and describe two nonparametric models for relational data that use the Mondrian process as a prior on partitions. The notion of exchangeability 3 , that the probability of a sequence of data items does not depend on the ordering of the items, has played a central role in hierarchical Bayesian modeling (Bernardo and Smith, 1994). A classic result by de Finetti (1931), later extended by Ryll-Nardzewski (1957), states that if x 1 , x 2 , ... is an exchangeable sequence, then there exists a random parameter  X  such that the sequence is conditionally iid given  X  : That is, exchangeable sequences arise as a mixture of iid sequences, where the mixing distribution is p (  X  ) . The notion of exchangeability has been generalized to a wide variety of settings. In this section we describe notions of exchangeability for relational data originally proposed by Aldous (1981) and Hoover (1979) in the context of exchangeable arrays. Kallenberg (2005) significantly expanded on the concept, and Diaconis and Janson (2007) showed a strong correspondence between such exchangeable relations and a notion of limits on graph structures (Lov  X  asz and Szegedy, 2006). Here we shall only consider binary relations X  X hose involving pairs of objects. Generalizations to relations with arbitrary arity can be gleaned from Kallenberg (2005). For i, j = 1 , 2 , ... let R i,j denote a relation between two objects x i  X  X and y j  X  Y from possibly distinct sets X and Y . We say that R is separately exchangeable if its distribution is invariant to separate permutations on its rows and columns. That is, for each n, m  X  1 and each pair of permutations  X   X  S n and  X   X  S m , in MATLAB notation. Aldous (1981) and Hoover (1979) showed that separately exchangeable relations can always be represented in the following way: each object i (and j ) has a latent represen-tation  X  i (  X  j ) drawn iid from some distribution p  X  ( p  X  ); independently let  X  be an additional random parameter. Then, As opposed to (1), the variables  X  i and  X  j capture additional dependencies specific to each row and column. If the two sets of objects are in fact the same, i.e. X = Y , then the relation R is a square array. We say R is jointly exchangeable if it is invariant to jointly permuting rows and columns; that is, for each n  X  1 and each permutation  X   X  S n we have Such jointly exchangeable relations also have a form similar to (3). The differences are that we have one latent variable  X  i for to each object x i , and that R i,j , R j,i need not be independent anymore: first impression from (5) is that joint exchangeability implies a more restricted functional form than separately exchangeable (3). In fact, the reverse holds X (5) means that the latent representations of row i and column i need not be independent, and that R i,j and R j,i need not be conditionally independent given the row and column representations, while (3) assumes independence of both. For example, a symmetric relation, i.e. R i,j = R j,i , can only be represented using (5). The above Aldous-Hoover representation serves as the theoretical foundation for hierarchical Bayesian modeling of exchangeable relational data, just as de Finetti X  X  representation serves as a foundation for the modeling of exchangeable sequences. In Section 5, we cast the Infinite Relational Model (Kemp et al., 2006) and a model based on the Mondrian process into this representation. The Mondrian process can be expressed as a recursive generative process that randomly makes axis-aligned cuts, partitioning the underlying product space in a hierarchical fashion akin to decision trees or k d-trees. The distinguishing feature of this recursive stochastic process is that it assigns probabilities to the various events in such a way that it is consistent (in a sense we make precise later). The implication of consistency is that we can extend the Mondrian process to infinite spaces and use it as a nonparametric prior for modeling exchangeable relational data. 3.1 The one dimensional case The simplest space to introduce the Mondrian process is the unit interval [0 , 1] . Starting with an initial  X  X udget X   X  , we make a sequence of cuts, splitting the interval into subintervals. Each cut costs a random amount, eventually exhausting the budget and resulting in a finite partition m of the unit interval. The cost, E I , to cut an interval I is exponentially distributed with inverse mean given by the length of the interval. Therefore, the first cut costs E [0 , 1]  X  Exp(1) . Let  X  0 =  X   X  E [0 , 1] . If  X  0 &lt; 0 , we make no cuts and the process returns the trivial partition m = { [0 , 1] } . Otherwise, we make a cut uniformly at random, splitting the unit interval into two subintervals A and B . The process recurses independently on A and B , with independent budgets  X  0 , producing partitions m A and m B , which are then combined into a partition m = m A S m B of [0 , 1] .
 The resulting cuts can be shown to be a Poisson (point) process. Unlike the standard description of the Poisson process, the cuts in this  X  X reak and branch X  process are organized in a hierarchy. As the Poisson process is a fundamental building block for random measures such as the Dirichlet process (DP), we will later exploit this relationship to build various multidimensional generalizations. 3.2 Generalizations to higher dimensions and trees We begin in two dimensions by describing the generative process for a Mondrian process m  X  a + B  X  b ) is drawn from an exponential distribution with rate the sum of the interval lengths. If  X  0 &lt; 0 , the process halts, and returns the trivial partition { ( a, A )  X  ( b, B ) } . Otherwise, an axis-aligned cut is made uniformly at random along the combined lengths of ( a, A ) and ( b, B ) ; that is, the cut lies along a particular dimension with probability proportional to its length, and is drawn uniformly then recurses, generating independent Mondrian processes with diminished rate parameter  X  0 on the number of cuts, with the process more likely to cut rectangles with large perimeters. The process can be generalized in several ways. In higher dimensions, the cost E to make an additional cut is exponentially distributed with rate given by the sum over all dimensions of the interval lengths. Similarly, the cut point is chosen uniformly at random from all intervals, splitting only that interval in the recursion. Like non-homogeneous Poisson processes, the cut point need not be chosen uniformly at random, but can instead be chosen according to a non-atomic rate measure  X  d associated with each dimension. In this case, lengths ( A  X  a ) become measures  X  1 ( a, A ) . The process can also be generalized beyond products of intervals. The key property of intervals that the Mondrian process relies upon is that any point cuts the space into one-dimensional, simply-connected pieces. Trees also have this property: a cut along an edge splits a tree into two trees. We denote a Mondrian process m with rate  X  on a product of one-dimensional, simply-connected domains  X  1  X  X  X  X  X   X  D by m  X  MP(  X ,  X  1 , ...,  X  D ) , with the dependence on  X  1 , ...,  X  D left implicit. A description of the recursive generative model for the conditional Mondrian (see Section 4) is given in Algorithm 1. This section describes a number of interesting properties of the Mondrian process. The most im-portant properties of the Mondrian is its self-consistency. Instead of representing a draw from a Mondrian as an unstructured partition of  X  1  X  X  X  X  X   X  D , we will represent the whole history of the generative process. Thus a draw from the Mondrian process is either a trivial partition or a tuple data structure), with the leaves of the tree forming the partition of the original product space. Conditional Independencies : The generative process for the Mondrian produces a tree of cuts, where each subtree is itself a draw from a Mondrian. The tree structure precisely reflects the condi-tional independencies of the Mondrian; e.g., the two subtrees m &lt; and m &gt; are conditional indepen-dent given  X  0 , d and x at the first cut.
 Consistency : The Mondrian process satisfies an important self-consistency property: given a draw from a Mondrian on some domain, the partition on any subdomain has the same distribution as if we sampled a Mondrian process directly on that subdomain.
 More precisely, let m  X  MP(  X ,  X  1 , ...,  X  D ) and, for each dimension d , let  X  d be a connected subdomain of  X  d . The restriction  X  ( m,  X  1 , ...,  X  D ) of m to  X  1  X   X  X  X   X   X  D is the subtree of cuts within  X  1  X   X  X  X   X   X  D . We define restrictions inductively: If there are no cuts in m , i.e. domains of m &lt; and m &gt; respectively. If x 6 X   X  d this implies that  X  d must be on exactly one side of x By integrating out the variables on nodes not contained in the restriction, it can be shown that the restriction  X  ( m,  X  1 , ...,  X  D ) is itself distributed according to a Mondrian MP(  X ,  X  1 , ...,  X  D ) . So far the construction of the Mondrian process assumes that each domain  X  d has finite measure. A consequence of this consistency property is that we can now use the Daniell-Kolmogorov extension theorem to extend the Mondrian process to  X  -finite domains (those that can be written as a countable union of finite domains). For example, from a Mondrian process on products of intervals, we can construct a Mondrian process on all of R D . Note that if the domains have infinite measure, the tree of cuts will be infinitely deep with no root and infinitely many leaves (being the infinite partition of the product space). However the restriction of the tree to any given finite subdomains will be finite with a root (with probability one).
 Mondrian Slices : One interesting specific case of consistency under restriction is worth mentioning. Suppose that our subdomains are  X  1 = { y } and  X  d =  X  d for d  X  2 . That is, we consider the restriction of the Mondrian to a slice of the space where the first coordinate takes on value y . The consistency property shows that the restriction  X  =  X  ( m,  X  1 , ...,  X  D ) onto these subdomains is distributed according to a Mondrian as well. But since  X  1 is non-atomic,  X  1 ( { y } ) = 0 thus  X  will not have any cuts in the first domain (with probability 1). That is, we can interpret  X  as a draw from a D  X  1 dimensional Mondrian with domains  X  2 , ...,  X  D . This is true of any lower dimensional slice of the Mondrian. One particular extreme is that since a one dimensional Mondrian is simply the break-and-branch generative process for a Poisson process, any one dimensional slice of a Mondrian gives a Poisson point process.
 Conditional Mondrians : Using the consistency property, we can derive the conditional distribution of a Mondrian m with rate  X  on  X  1  X  X  X  X  X   X  D given its restriction  X  =  X  ( m,  X  1 , ...,  X  D ) . To do so, we have to consider three possibilities: when m contains no cuts, when the first cut of m is in  X  , and when the first cut of m is above  X  . Fortunately the probabilities of each of these events can be computed easily, and amounts to drawing an exponential sample E  X  Exp( P d  X  d ( X  d \  X  d )) , and comparing it against the diminished rate after the first cut in  X  . Pseudocode for generating from a conditional Mondrian is given in Algorithm 1. When every domain of  X  has zero measure, i.e.,  X  ( X  d ) = 0 for all d , the conditional Mondrian reduces to an unconditional Mondrian.
 Algorithm 1 Conditional Mondrian m  X  MP(  X ,  X  1 , ...,  X  D |  X  )  X  =  X  d =  X  is unconditioned 1. let  X  0  X   X   X  E where E  X  Exp( P D d =1  X  d ( X  d \  X  d )) . 2. if  X  has no cuts then  X  00  X  0 else  X  d 0 , x 0 ,  X  00 ,  X  &lt; ,  X  &gt;  X  X  X   X  . 3. if  X  0 &lt;  X  00 then take root form of  X  4. if  X  has no cut then 5. return m  X   X  1  X  X  X  X  X   X  D . 7. return m  X  X  d 0 , x 0 ,  X  00 , MP(  X  00 ,  X  1 , . . . ,  X  &lt;x 0 d 0 , . . . ,  X  D |  X  &lt; ) , 9. draw a cut ( d, x ) outside  X  , i.e., p ( d )  X   X  d ( X  d \  X  d ) , x | d  X   X  d  X  10. return m  X  X  d, x,  X  0 , MP(  X  0 ,  X  1 , . . . ,  X  &lt;x d , . . . ,  X  D |  X  ) , Partition Structure : The Mondrian is simple enough that we can characterize a number of its other properties. As an example, the expected number of slices along each dimension of (0 , A )  X  (0 , B ) is  X A and  X B , while the expected total number of partitions is (1+  X A )(1+  X B ) . Interestingly, this is also the expected number of partitions in a biclustering model where we first have two independent Poisson processes with rate  X  partition (0 , A ) and (0 , B ) , and then form the product partition of (0 , A )  X  (0 , B ) . To illustrate how the Mondrian process can be used to model relational data, we describe two non-parametric block models for exchangeable relations. While we will only consider binary data and assume that each block is conditionally iid, the ideas can be extended to many likelihood models. Recall the Aldous-Hoover representation (  X ,  X  i ,  X  j , p R ) for exchangeable arrays. Using a Mondrian process with beta L  X  evy measure  X  ( dx ) =  X x  X  1 dx , we first sample a random partition of the unit square into blocks and assign each block a probability: The pair ( M,  X  ) plays the role of  X  in the Aldous-Hoover representation. We next sample row and column representations (  X  i and  X  j , respectively), which have a geometrical interpretation as x,y -coordinates (  X  i ,  X  j ) in the unit square: Let S ij be the block S  X  M such that (  X  i ,  X  j )  X  S . We finally sample the array R of relations: This model clusters relations together whose (  X  i ,  X  j ) pairs fall in the same blocks in the Mondrian partition and models each cluster with a beta-binomial likelihood model. By mirroring the Aldous-Hoover representation, we guarantee that R is exchangeable and that there is no order dependence. This model is closely related to the IRM (Kemp et al., 2006) and IHRM (Xu et al., 2006), where rows and columns are first clustered using a CRP prior, then each relation R ij is conditionally independent from others given the clusters that row i and column j belong to. In particular, if we replace Eq. (6) with then we recover the same marginal distribution over relations as the IRM/IHRM. To see this, recall that a Mondrian process in one-dimension produces a partition whose cut points follow a Poisson point process. Teh et al. (2007) show that the stick lengths (i.e., partitions) induced by a Poisson point process on [0 , 1] with the beta L  X  evy measure have the same distribution as those in the stick-breaking construction of the DP. Therefore, (11) is the product of two stick-breaking priors. In comparison, any one dimensional slice of (6), e.g., each column or row of the relation, is marginally distributed as a DP, but is more flexible than the product of one-dimensional Mondrian processes. We can also construct an exchangeable variant of the Annotated Hierarchies model (a hierarchical block model) by moving from the unit square to a product of random trees drawn from Kingman X  X  coalescent prior (Kingman, 1982a). Let  X  d be Lebesgue measure.
 Let S ij be the subset S  X  M where leaves ( i, j ) fall in S . Then Figure 4 shows some samples from this prior. Again, this model is related to the DP. Kingman shows that the partition on the leaves of a coalescent tree when its edges are cut by a Poisson point process is the same as that of a DP (Figure 4). Therefore, the partition structure along every row and column is marginally the same as a DP. Both the unit square and product of random trees models give DP distributed partitions on each row and column, but they have different inductive biases. The first data set was synthetically created using an actual painting by Piet Mondrian, whose grid-based paintings were the inspiration for the name of this process. Using the model defined by (10) and a uniform rate measure, we performed a Markov chain Monte Carlo (MCMC) simulation of the posterior distribution over the Mondrian,  X   X  X ,  X   X  X , and hyperparameters. We employed a number of Metropolis-Hastings (MH) proposals that rotated, scaled, flipped, and resampled portions of the Mondrian. It can be shown that the conditional distribution of each  X  i and  X  j is piecewise constant; given the conjugacy of the beta-binomial, we can Gibbs sample the  X   X  X  and  X   X  X . Figure 2 shows a sample after 1500 iterations (starting from a random initialization) where the partition on the array is exactly recovered. This was a typical attractor state for random initializations. While the data are sufficient to recover the partition on the array, they are not sufficient to recover the underlying Mondrian process. It is an open question as to its identifiability in the limit of infinite data. We next analyzed the classic Countries data set from the network analysis literature (Wasserman and Faust, 1994), which reports trade in 1984 between 24 countries in food and live animals; crude materials; minerals and fuels; basic manufactured goods; and exchange of diplomats. We applied the model defined by (10). Figure 3 illustrates the type of structure the model uncovers during MCMC simulation; it has recognized several salient groups of countries acting in blocs; e.g., Japan, the UK, Switzerland, Spain and China export to nearly all countries, although China behaves more like the other Pacific Rim countries as an importer. The diplomats relation is nearly symmetric, but the model does not represent symmetry explicitly and must redundantly learn the entire relation. Reflecting the Mondrian about the line y = x is one way to enforce symmetry in the partition. In our final experiment, we analyzed a synthetic social network consisting of nine university em-ployees: 3 janitors, 3 professors and 3 students. Given three relations (friends, works-with, and gives-orders-to), the maximum a posteriori Mondrian process partitions the relations into homoge-neous blocks. Tree structures around the MAP clustered the janitors, professors and students into three close-knit groups, and preferred to put the janitors and students more closely together in the tree. Inference in this model is particularly challenging given the large space of trees and partitions. While the Mondrian process has many elegant properties, much more work is required to determine its usefulness for relational modeling. Just as effective inference procedures preceded the popularity of the Dirichlet process, a similar leap in inference sophistication will be necessary to assess the Mondrian process on large data sets. We are currently investigating improved MCMC sampling schemes for the Mondrian process, as well as working to develop a combinatorial representation of the distribution on partitions induced by the Mondrian process. Such a representation is of prac-tical interest (possibly leading to improved inference schemes) and of theoretical interest, being a multidimensional generalization of Chinese restaurant processes.
 The axis-aligned partitions of [0 , 1] n produced by the Mondrian process have been studied exten-sively in combinatorics and computational geometry, where they are known as guillotine partitions . Guillotine partitions have wide ranging applications including circuit design, approximation algo-rithms and computer graphics. However, the question of consistent stochastic processes over guillo-tine partitions, i.e. the question addressed here, has not, to our knowledge, been studied before. At a high level, we believe that developing nonparametric priors on complex data structures from computer science may successfully bridge the gap between old-fashioned Artificial Intelligence and modern statistical approaches. Developing representations for these typically recursive structures will require us to go beyond graphical models; stochastic lambda calculus is an appealing option.
