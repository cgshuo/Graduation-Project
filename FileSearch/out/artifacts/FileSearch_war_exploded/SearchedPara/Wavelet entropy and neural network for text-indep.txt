 Khaled Daqrouq n 1. Introduction
Speaker identification issue has been studied for many years and various network models and digital signal processing tech-niques have been implemented for this problem. Speech features that are usually obtained via Fourier transforms, short time Fourier transforms (STFTs) or Linear Predictive Coding (LPC) techniques are exploited for some manner of Expert Speaker Identification (ESI). These methods allow signal stationarity within a certain time frame and may therefore lack the ability to analyze localized events fittingly.

Determining a functional and relevant subset of features from a bigger set is critical to develop the performance of speaker recognition ( Lung, 2007 ). A feature collection scheme is, there-fore, required to choose the most useful information from the complete feature space to shape a feature vector in a lower dimensionality, and eliminate any redundant and irrelevant information that may have disadvantageous effects on the classi-fication performance. To decide on an appropriate set of features, a criterion function can be used to provide the discriminatory authority of the individual features.

In general, a speaker identification system can be implemen-ted by observing the voiced/unvoiced components or through analyzing the energy distribution of utterances. a number of digital signal processing algorithms, such as LPC technique ( Adami and Barone, 2001; Tajima et al., 1997 ), Mel frequency cepstral coefficients (MFCCs) ( Mashao and Skosan, 2006; Sroka and Braida, 2005; Kanedera et al., 1999; Daqrouq and Al-Faouri, 2010 ), DWT ( Fonseca et al., 2007 ) and wavelet packet transform (WPT) are extensively utilized. In the beginning of 1990s, Mel frequency cepstral technique became the most widely used technique for recognition purposes due to its aptitude to repre-sent the speech spectrum in a compacted form ( Sarikaya and
Ansen, 2000 ). Actually, MFCCs simulate the model of humans X  auditory perception and have been proved to be very effective in automatic speech recognition system and modeling the individual frequency components of speech signals.

ESI has been under research by a large number of researches for about four decades ( Reynolds et al., 2000 ). From a commercial point of view, ESI is a technology with potentially large market due to the applications of frequent ranges from automation of operator-helped service to speech-to-text aiding system for hearing impaired individuals ( Reynolds et al., 2000 ).
The main mission of ESI is to take apart various speaker classes ( Evangelista, 1994; Kadambe and Boudreaux-Bartels, 1992;
Kadambe and Srinivasan, 1994; Mallat, 1989 ). In literature, a number of researchers have utilized wavelets to offer a more prosperous feature space ( Evangelista, 1993, 1994 ). However, there is slight evidence of common use of this technique ( Kadambe and Srinivasan, 1994 ). A wavelet is a  X  X  X mall wavy function X  X  of proficiently limited duration that has an average of zero. This wavelet is applied to develop the signal and the continuous wavelet transform (CWT) is obtained as a sum of all time signals multiplied by scaled and shifted version of the wavelet function. Nevertheless, it turns out that if we decide the scale and shifted version in a dyadic mode, i.e., based on powers of two, we can obtain a precise yet much more efficient transform. This is the DWT. A more comprehensive form of the standard wavelet transform is the wavelet packet, which decom-poses both the high and low frequency bands at each level. A pair of low-and high-pass filters is used to recognize two sequences capturing dissimilar frequency sub-band features of the original signal. These sequences are then decimated (dissembled by a factor of two). This process can be repeated to partition the frequency spectrum into smaller frequency bands for obtaining different features while detecting the temporal information. WPT features have better presentation than the DWT ( Lung et al., 2004 ). However, as the number of wavelet packet bases grows, the time required to appropriately classify the database will become nonlinear. Consequently, dimensionality decreasing becomes an important issue. Selecting a useful and relevant subset of features from a larger set is crucial to enhance the performance of speaker recognition ( Hyeon and Bang, 2000;
Haydar et al., 1998; Chen et al., 2002; Nathan and Silverman, 1994 ). A feature selection scheme is, therefore, needed to choose the most valuable information from the complete feature space to form a feature vector in a lower dimensionality, and take away any redundant information that may have disadvantageous effects on the classification quality. To select an appropriate set of features, a criterion function can be used to provide the discriminatory power of the individual features.
 created a new vocal interface to allow people, especially indivi-duals with motor impairments, to utilize many aspects of their voice to easily interact with computers or other devices ( Malkin et al., 2007 ).
 vocal tract. The air in the oral and nasal cavities vibrates at a range of frequencies in response to the vibratory movement of the vocal folds and air passing during the glottis. These resonant frequencies rely on the size and shape of the vocal tract and on the tongue and lip positions ( Gelfer and Mikos, 2007 ). Vocal tract resonances are often studied in terms of vowel formant frequencies. Because the male vocal tract is about 15% longer than the female vocal tract, the speech signals taken from men are predicted to have lower formant frequencies than those considered characteristic of women ( Bachorowski and Owren, 1999 ).
 speech, are recognized as formants that have valuable features for both automatic speech recognition and speech synthesis ( Huang et al., 2001 ). Researchers have used different methods for formant tracking: LPC spectral analysis ( Xia and Espy-Wilson, 2000 ),
HMM-based methods ( Acero, 1999 ), nonlinear predictors ( Deng et al., 2003 ) and Kalman filtering framework ( Deng et al., 2004 ). size and quality of training samples ( Visser et al., 2003 ). When the number of training data is small, not representative of the possibility space, standard neural network results are poor ( Kosko and Bart, 1992 ). Incorporation of neural fuzzy or wavelet techni-ques can improve performance in this case, particularly, by input matrix dimensionality decreasing ( Nava and Taylor, 1996 ).
Artificial neural networks (ANN) are known to be excellent classi-fiers, but their performance can be prevented by the size and quality of the training set. Fuzzy theory has been used success-fully in many applications ( Gowdy and Tufekci, 2000 ). These applications show that fuzzy theory can be used to improve neural network performance.

In this paper, author improves effective feature extraction method for text-independent system, taking in consideration that the size of ANN input is a very crucial issue. This affects quality of the training set. For this reason, the presented features extrac-tion method offers a reduction in dimensionality of features as compared with the conventional methods. Thirty Shannon entropy coefficients of WPT in conjunction with five formants of a speaker vowel are utilized. For classification of features extrac-tion coefficients, FFBPNN is proposed. 2. Features extraction by wavelet packet 2.1. Theoretical overview
The wavelet packet method is a generalization of wavelet decomposition that offers a richer signal analysis. Wavelet packet atoms are waveforms indexed by three naturally interpreted parameters: position and scale as in wavelet transform decom-position and frequency. In the following, the wavelet transform is defined as the inner product of a signal x  X  t  X  with the mother wavelet c  X  t  X  : c W c x  X  a , b  X  X  where a and b are the scale and shift parameters, respectively. The mother wavelet may be dilated or translated by modulating a and b .
The wavelet packets transform performs the recursive decom-position of the speech signal obtained by the recursive binary tree (see Fig. 1 ). Basically, the WPT is very similar to DWT but WPT decomposes both details and approximations instead of only performing the decomposition process on approximations. The principle of wavelet packet (WP) is that, given a signal, a pair of low-pass and high-pass filters is used to yield two sequences to capture different frequency sub-band features of the original signal. The two wavelet orthogonal bases generated to form a previous node are defined as c c where h  X  n and g  X  n denote the low-pass and high-pass filters, respectively. In Eqs. (3) and (4), c  X  n is the wavelet function. Parameters j and p are the number of decomposition levels and nodes of the previous node, respectively ( Wu and Lin, 2009 ). 2.2. Wavelet packet entropy
For a given orthogonal wavelet function, a library of wavelet packet bases is generated. Each of these bases offers a particular way of coding signals, preserving global energy and reconstruct-ing exact features. The wavelet packet is used to extract addi-tional features to guarantee higher recognition rate. In this study, WPT is applied at the stage of feature extraction, but these data are not proper for classifier due to a great amount of data length. Thus, we have to seek for a better representation for the speech features. Previous studies showed that the use of entropy of WP as features in recognition tasks is efficient. Avci and Akpolat (2006) proposed a method to calculate the entropy value of the wavelet norm in digital modulation recognition. In the bio-medical field, Behroozmand and Almasganj (2007) presented a combination of genetic algorithm and wavelet packet transform used in the pathological evaluation, and the energy features are determined from a group of wavelet packet coefficients. Kotnik et al. (2003) proposed a robust speech recognition scheme in a noisy environment by means of wavelet-based energy as a threshold for de-noise estimation. In Wu and Lin (2009) , the energy indexes of WP were proposed for speaker identification. Sure entropy is calculated for the waveforms at the terminal node signals obtained from DWT ( Avci, 2009 ) for speaker identification. Avci (2007) proposed features extraction method for speaker recognition based on a combination of three entropies types (sure, logarithmic energy and norm).

As seen above, the entropy of the specific sub-band signal may be employed as features for recognition tasks. In this paper, the Shannon entropy obtained from the WP will be employed for speaker identification. The Shannon wavelet packet features extraction method can be summarized as follows.

Before the stage of features extraction, the speech data are processed by a silence removing algorithm followed by the application of a pre-processed normalization on speech signals to make the signals comparable regardless of differences in magnitude. In the present work, the signals are normalized by using the following formula ( Wu and Lin, 2009 ):
S Ni  X  S i ^ S s  X  5  X  where S i is the i th element of the signal S , ^ S and s are the mean and standard deviation of the vector S , respectively, S Ni i th element of the signal series S N after normalization. Fig. 2 a shows the diagram of two speech signals before normalization and Fig. 2 b shows the diagram of two speech signals with normalization.

Decomposing the speech signal by wavelet packet transform at depth 4 (level 4), with Daubechies type (db1).

Calculating Shannon entropy for all 30 nodes at depth 4 for wavelet packet using the following equation: E 1  X  s  X  X  where s is the signal and s i are the WPT coefficients. Entropy is a common concept in many fields, mainly in signal processing ( Turkoglu et al., 2003 ). Classical entropy-based criterion describes information-related properties for a precise repre-sentation of a given signal. Entropy is commonly used in image processing; it posses information about the concentration of the image. On the other hand, a method for measuring the entropy appears as a supreme tool for quantifying the ordering of non-stationary signals. Fig. 3 a shows the Shannon entropy -0.8 -0.6 -0.4 -0.2 0.2 0.4 0.6 Signal Magnitude -8 -6 -4 -2 0 2 4 6 8 10 Signal Magnitude we can notice that the feature vector extracted by the Shannon entropy is more appropriate for speaker recognition. This conclusion has been obtained by interpretation of the follow-ing criterion: the feature vector extracted should possess the following properties ( Farooq and Datta, 2003 ): (1) vary widely from class to class, (2) stable over a long period of time and (3) should not have correlation with other features. 3. Features extraction by formants using PSD
Periodic excitation is seen in the spectrum of certain sounds, especially vowels. The speech organs form certain shapes to produce the vowel sound and therefore regions of resonance and anti-resonance are formed in the vocal tract. Location of these resonances in the frequency spectrum depends on the form and shape of the vocal tract. Since the physical structure of the speech organs is a characteristic of each speaker, differences between speakers can also be found in the position of their formant frequencies. The resonances heavily affect the overall spectrum shape and are referred to as formants. A few of these formant frequencies can be sampled at an appropriate rate and used for speaker recognition. These features are normally used in combi-nation with other features.

The vocal resonant frequencies during voiced speech, which are called formants ( F 0, F 1, y , F 4), are distinguishable for each person and therefore are proposed as the speaker features. For voiced speech, the glottic signal is periodic with a fundamental frequency (pitch) F 0. The variations in the fundamental frequency (pitch) during the duration of the utterance if followed would provide the contour, which can be used as a feature for speech recognition. The speech utterance is normalized and the contour is determined. The vector that contains the average values of pitch of all segments is thereafter used as a feature for speaker recognition. It is also well known that pitch is a successful determinant of gender. The pitch is sufficient for the human identification but has to be assisted by the first ( F 1, F 2 and F 3) formants for the best speaker recognition. These formants allow us to determine the melodic, physiological and even psychic state of the speaker. F 4 may be used as assistant formants ( Cherif et al., 2001 ).

The speech signal is an input to a power spectrum algorithm to identify the first five formants (extracted from one of the Arabic vowels speech signal). In this section, an investigation of a speaker identification system based on distinct acoustic features contained in logarithmic spectrum obtained from speech signals is presented. The formants may have distinct information about size, gender and vocal tract anatomical structure of speaker. Fig. 4 shows the five formants extracted for two speech signals of the same speaker. The five formants of the given signals are the same.
The PSD algorithm for determining the formants is based on two steps: first, the PSD ( P XX ) is estimated using the Yule X  X alker Auto-Regressive (AR) method. Then the local maxima are identi-fied (see Fig. 4 ). The Yule X  X alker method fits the AR linear prediction filter model to the signal by minimizing the forward prediction error in the least squares sense. This formulation leads to the Yule X  X alker equations, which are solved by the Levinson X  Durbin recursion. The spectral-estimate-returned by method is the squared magnitude of the frequency response of this AR model. Then M vector of the speaker X  X  PSD is represented by logarithmic scale ( F ): F Pxx  X  i  X  X 
F Pxx  X  i  X  returns P XX containing speaker and speech features in frequency domain. Once the PSD is estimated, the local maxima are calculated using the following equation: D  X  P XX  X  i  X  1  X  P XX  X  i  X  X  8  X 
The local maxima is identified by choosing the index where the difference goes from + to . The final results are then normalized: I  X  I = 128. 4. Classifications
This operation performs the intelligent classification by means of features obtained from feature extraction phase. In this study FFBPNN is utilized. The training specifications and the structure of the nnt used in this paper are tabulated in Table 1 . These were selected for the best performance, that is accomplished after several experiments, such as the number of hidden layers, the size of the hidden layers, value of the moment constant and type of the activation functions (transfer functions). 35 18 feature matrix, which is obtained in features extraction stage, is given to the input of the feed-forward networks consisting of many layers using the DOTPROD weight function, NETSUM net input function and the specified transfer functions. The weights of the first layer come from the input. Each network layer has a weight coming from the previous layer. All layers have biases. The last layer is the network output (target). In this paper target ( T ) is designed as a five binary digits for each features vector: T  X 
The mean square error of the ANN is obtained at the end of the training of the ANN classifier by means of Levenberg X  X arquardt backpropagation. Backpropagation is used to calculate the
Jacobian jX of performance with respect to the weight and bias variables X . Each variable is accustomed according to the
Levenberg X  X arquardt equation: jj  X  jX jX je  X  jX E dX  X  X  jj  X  I Mu  X  \ je  X  10  X  where E is all errors and I is the identity matrix. The adaptive value Mu is increased by 10 Mu increase factor until the above results are changed in a reduced performance value. The change is then made to the network and Mu is decreased by 0.1 Mu decrease factor. After training the 18 speaker features, imposter simulation is performed. The imposter simulation result (SR) is compared with each of the 18 patterns target ( P n , n  X  1,2, y ,18) in order to determine the decision by
C  X  100 100 where C n is the similarity percent between imposter simulation results and pattern target P n . The speaker is identified as a pattern of maximum similarity percent. 5. Results and discussion
A testing database was created from Arabic language. The recording environment is a normal office environment via
PC-sound card, with spectral frequency of 4000 Hz and sampling frequency of 16,000 Hz.
 These Arabic utterances are Arabic spoken digits from 0 to 14.
In addition, each speaker read ten separated 30 s different Arabic texts. Total 29 individual speakers (19 X 40 years old), including 19 individual males and 10 individual females, spoke these Arabic words and texts for training and testing phases. The total number of tokens considered for training and testing was 696.
The experiments were performed using a total of 696 Arabic utterances of total 29 individual speakers (19 male speakers and 10 female speakers). For each of these speakers, 24 speech signals were used. Six of these signals were used for training. All of these signals were used for testing the WPFNN expert system ( Fig. 5 ).
In this experiment, 91.09% correct classification was obtained by means of WPFNN among 29 different speaker signal classes. Logarithmic PSD
Testing results are tabulated in Table 2 . It clearly indicates the usefulness and the trustworthiness of the proposed approach for extracting features from speech signals for text-independent system.
 used in the experimental investigation for comparison. WPFNN,
DWT with twelve Shannon coefficients (at level 11) and first five formants feature sets with neural network (DWFNN), wavelet packet energy index distribution method (WPID) ( Wu and Lin, 2009 ) and genetic wavelet packet neural network (GWPNN) ( Engin, 2007 ) were investigated for comparison. The recognition rate of DWFNN reached the lowest value. The best recognition rate selection obtained was 91.09% for WPFNN.

For comparison, WPFNN, and benchmark feature extraction based methods: MFCC ( Ganchev et al., 2005 ) with feed-forward backpropagation neural network (MFCCNN), LPC with feed-forward backpropagation neural (LPCNN) ( Ganchev et al., 2005; Bennani and Gallinari, 1995 ) were investigated. The recognition rate of LPCNN reached the lowest value. The best recognition rates selection obtained was for WPFNN. Feature sets spaced in Mel scale had good performance on recognition rate, and they interpreted the achievements of Mel cepstral theory. The pro-posed formants and Shannon entropy of wavelet packet show better recognition rate than the conventional WPT and Mel scale or LPC. This is because the energy of speakers X  signal concentrates in some specific region, and the decomposition will be detailed on them.
 To improve the robustness of WPFNN to additive white Gaussian noise (AWGN), same wavelet packet decomposition process was applied to DWT approximation sub-signal via several levels instead of original imposter ( Daqrouq et al., 2010 ). After-wards, the features extraction was applied to each of the obtained wavelet packet decomposition sub-signals. After performing the proposed classification mechanism for each sub-signal of distinct DWT level, we can notice that at levels 3 and 4 the highest recognition rate was achieved (see Table 4 ). In this experiment it was found that the recognition rates were not improved on increasing the DWT level more than four.

The proposed future work of this research is to improve the capability of our system to work in real time. This may be performed by modifying the recording apparatus and a data acquisition system (such as NI-6024E), and interfacing online with written Matlab code that simulates the expert system. 6. Conclusion
In this paper, an expert system for speaker identification was proposed for the investigation of the speech signals using pattern identification. The speaker identification performance of this method was demonstrated on total 29 individual speakers (19 male speakers and 10 female speakers). Five formants in conjunction with the Shannon entropy of WP upon level four features extraction method were developed. For performing the classification process FFBPNN was investigated. The function of feature extraction and classification is performed using the WPFNN expert system. The declared results show that the proposed method can make an effectual analysis. The perfor-mance of the intelligent system was given in Tables 2 and 3 . The average identification rate was 91.09, better than the other methods published before. It was found that the recognition rates enhanced on increasing the number of feature sets (by higher WP levels). Nevertheless, the improvement implies a tradeoff between the recognition rate and extracting time. The proposed method can offer a significant computational advantage by redu-cing the dimensionality of the WP coefficients by means of entropy. DWT approximation sub-signal via several levels instead of original imposter had good performance on AWGN facing, particularly on levels 3 and 4.
 References
