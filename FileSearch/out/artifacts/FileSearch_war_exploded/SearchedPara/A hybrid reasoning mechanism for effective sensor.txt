 1. Introduction
Description Logic (DL) is a decidable fragment of First Order Logic (FOL) and constitutes the backgr ound for OWL-DL, the decidable fragment of the Web Ontology Language (OWL) ( Smith et al., 2003 ).
However, DL is not sufficient on its own to solve many real-life problems. For example, some rules may not be expressed in DL. In order to represent rules in an ontology, rule languages such as
Semantic Web Rule Language (SWRL) ( Horrocks et al., 2004 )have been proposed. In the design of Semantic Web languages, decid-ability has been one of the main concerns. To achieve decidability, these languages enforce limitatio ns on expressiveness. OWL ensures decidability by defining its DL equivalent subset; similarly we can ensure decidability of SWRL using only DL-safe rules ( Haase and
Motik, 2005 ). Existing reasoners such as Sirin et al. (2007) provide ontological reasoning services based on these restrictions. However, because of these limitations, many logical axioms and rules cannot be expressed using OWL-DL and SWRL ( Horrocks et al., 2004 ).
On the other hand, languages like Prolog ( Bratko, 2000 )provide very expressive declarative Log ic Programming (LP) frameworks. Unlike OWL and SWRL, Prolog adopts the closed-world assumption through negation as failure and enables complex data structures and arbitrary programming constructs ( Bratko, 2000 ). In this paper, we propose Ontological Logic Programming (OLP), 1 a novel approach that combines LP with DL-based ontological reasoning. An OLP programme can dynamically import various ontologies and use the terms (i.e., classes, properties, and individuals) in these onto-logies directly within an OLP programme. The interpretation of these terms is delegated to an ontology reasoner during interpretation of the OLP programme. By enhancing logic programming with ontological reasoning, OLP offers the following advantages: 1. Expressiveness : OLP combines the expressiveness of DL and LP.
Hence, the limitations of OWL-DL are compensated by the high expressiveness of LP. 2. Convenience : Many researchers and developers are more familiar with LP languages than with DL formalisms. OLP enables DL reasoning to be used transparently within a logic programme. 3. Reuse of domain knowledge : In logic programmes, domain knowledge is encoded within the programme, often in an ad-hoc manner. OLP enables domain knowledge to be defined in a set of ontologies in a standard way. These ontologies may then be easily used by different OLP programmes.
 4. Conciseness : OLP programmes are far more concise than equivalent standard logic programmes. This is because OLP programmes use domain ontologies to capture domain knowl-edge, while standard logic programmes require this domain knowledge to be encoded within the programme. Consider the rule a person can drive a vehicle only if he/she has a driving license . In a logic programme, in order to express this rule, semantics and facts about the terms person , transportation vehicle , driving , and driving license have to be formalised within the logic programme. This means that the programme has to be much longer than the rule to be expressed. On the other hand, an OLP programme simply imports appropriate ontolo-gies that contain domain knowledge about these terms, and expresses the rule concisely using these terms. 5. Reuse of logic programmes : Logic programming, notably Prolog, has been used for decades to develop many AI applications such as expert systems, planning systems, theorem provers, and so on. The proposed combination would allow  X  X  X egacy X  X  AI systems to take advantage of more recent Semantic
Web developments, namely, open standards for knowledge representation with publicly available ontologies, as well as efficient reasoning mechanisms, with minimal need for re-implementation.

The use of ontological reasoning within logic programmes was first discussed in Sensoy et al. (2011a) and the main idea of OLP presented in Sensoy et al. (2011b) . The current implementation of
OLP and the initial performance evaluation results were published in Sensoy et al. (2011) . The domain of application in which this document is based on was previously published in de Mel et al. (2009 , 2010) . In this document, we discuss how we have inte-grated various ideas from these previous publications to come up with an end-to-end solution for the effective resource selection for tasks in sensor networks.

The rest of the article is structured as follows. In Section 2 ,we present Ontological Logic Programming both in terms of its architecture and how OLP interacts with the underlying semantic knowledge. We also discuss the motivation for OLP and present performance evaluations of OLP with respect to different strate-gies for incorporating ontological reasoning into logic program-ming. We then present a detailed scenario from the sensor resource management domain in Section 3 .In Section 4 we discuss a formal domain model which allows us to effectively formulate the sensor-task assignment problem. Section 5 intro-duces a query formalism that uses the aforementioned ontology through OLP to select appropriate resources for tasks. Section 6 , presents some results of the proposed approach and in Section 7 we discuss relevant research from the sensor-task domain that has influenced our work. We present our conclusions in Section 8 . 2. Ontological Logic Programming
In this section, we introduce OLP. First, we present the relevant literature that motivated the need for OLP. We then introduce the
OLP stack and describe how OLP interprets logic programmes using semantic knowledge. We then discuss in detail how OLP modifies the underlying semantic knowledge and accesses semantic reasoning services and provides baseline performance results of OLP. 2.1. Related work
There are various extensions and combinations of logic pro-gramming with other programming paradigms. One such combi-nation is functional logic programming ( Antoy and Hanus, 2010 ) merging features of logic and functional programming, efficiently implemented in languages such as Hanus et al. (1995) , 2 and experiencing a revival due to its appeal to Web programming, notably for scripting purposes. Another extension with a potential wide appeal combines logic programming and object-oriented programming ( Piancastelli et al., 2008 ; Moss, 1994 ), making object-oriented programming features such as objects and inheri-tance available to Prolog programmes. 3 Prolog interpreters ( e.g. ,
SICStus 4 and Ciao 5 Prolog) now commonly allow the seamless running, from within a Prolog programme, of code implemented in languages such as C or Java. Although these cannot be seen as true extensions, they are very convenient to those wanting to combine functionalities implemented in disparate programming languages.

Rules play an important role in capturing and modeling important domain concepts. Therefore, a lot of effort has been invested in the development of rule languages and engines for reasoning on top of OWL ontologies. For example, SWRL enables
Horn-like rules to be combined with an OWL knowledge base ( Horrocks et al., 2004 ). SWRL aims at extending OWL-DL with semantic rules. Although SWRL does not support negation-as-failure, it implicitly supports classical negation through OWL-DL using class complements.

Jess ( Friedman-Hill, 2003 ) is a Java-based expert system shell that uses a RETE algorithm ( Forgy, 1990 ) for its forward chaining rule reasoning engine. Jess uses a LISP-like syntax to describe rules and facts. Note that Jess is implemented in Java, and so also has support for object-oriented representations. JessTab ( Eriksson, 2003 ) is a bridge between Prote  X  ge  X  ( Noy et al., 2000 ) and Jess. It enables Jess programmes to use and manipulate the knowledge from Prote  X  ge  X  knowledge bases. This is achieved by mapping Prote  X  ge  X  knowledge bases to Jess assertions. Originally,
JessTab was developed to support Prote  X  ge  X  -frames. Thus, JessTab includes only a limited support for handling OWL ontologies. For example, it does not support OWL restrictions and class expres-sions such as someValuesFrom restrictions while mapping OWL ontologies to Jess assertions. In addition to JessTab, there are some other RETE-based rule engines proposed to work with ontologies. Bossam ( Jang and Sohn, 2004 ) is one of these rule engines. It supports both negation-as-failure and classical nega-tion. It translates OWL documents into built-in list constructs.
Then, reasoning over these constructs is conducted using forward chaining (again, employing an implementation of the RETE algo-rithm). SweetJess ( Grosof et al., 2002 ) is a defeasible reasoning system based on the Jess expert system shell. Although it supports the Situated Courteous Logic Programmes extension of RuleML, it is restricted to simple terms (variables and atoms).
There are some other approaches based on Prolog. SweetPro-log ( Laera et al., 2004 ) is a Java-based system for translating rules into Prolog. It translates OWL ontologies and rules expressed in
RuleML into a set of facts and rules in Prolog. Then, the reasoning about these facts and rules is performed in Prolog. This approach uses JIProlog as a rule engine. Hence, it translates a OWL subset into simple Prolog predicates which a JIProlog engine can handle.
The main limitation of SweetProlog is its expressive power, as it uses Description Logic Programmes (DLP) to enable the integra-tion between ontology and rules. DLP is the intersection of DL and Horn logic programmes, so it is less expressive than both DL and
Horn logic programmes. DR-Prolog ( Bikakis and Antoniou, 2005 ) is a simple rule-based approach to reasoning with incomplete and inconsistent information. It is compatible with RuleML. It is based on the translation of ontological knowledge into Prolog. The system can reason with rules and ontological knowledge written in RDF Schema (RDFS) or OWL. This is achieved through the transformation of the RDFS constructs and many OWL constructs into rules. Note, however, that a number of OWL constructs cannot be captured. SWORIER ( Samuel et al., 2008 ) is a system that uses Prolog to reason about ontologies and rules in order to answer queries. It translates OWL-DL ontologies with rules in SWRL into Prolog using XSLTs (Extensible Stylesheet Language
Transformations). Then, query answering is done in Prolog using this translation. However, it supports only a subset of OWL-DL constructs.

In the approaches described above, ontological knowledge with rules is translated or mapped to Jess or Prolog assertions.
This violates one of the fundamental rules of logic representation  X  namely, mapping of open-world assumptions to closed-world assumptions. On the other hand, OLP keeps ontological knowl-edge separated from Prolog programmes and transparently dele-gates ontological reasoning to specialised DL reasoners such as
Pellet. Hence, it can use the full power of Prolog along with existing reasoners without any loss in the ontological knowledge and expressiveness. 2.2. Architecture
Fig. 1 shows the stack of technologies and components used to interpret OLP programmes. At the top of the stack, we have the
OLP interpreter, which sits on top of a LP layer. The LP layer is handled by a Prolog engine. The Prolog engine uses two different knowledge bases; one is a standard Prolog knowledge base of facts and clauses while the other is a semantic knowledge base composed of OWL-DL ontologies and SWRL rules. Pellet ( Sirin et al., 2007 ) has been used as a DL reasoner to interface between the Prolog engine and the semantic knowledge base.
 Our choice of LP language is Prolog and in this work, we use a
ISO compliant pure Java implementation, tuProlog ( Piancastelli et al., 2008 ). OLP is implemented by extending tuProlog and its associated IDE. The ontological reasoning was implemented as a tuProlog module. It is used within tuProlog by means of an OLP meta-interpreter. The OLP meta-interpreter is a Prolog interpreter with a set of OLP-specific predicates, described in Section 2.3 .
Fig. 2 shows a simplified version of the OLP meta-interpreter used to evaluate OLP programmes through the eval /1 predicate. While interpreting OLP programmes, the system behaves as if it is evaluating a standard Prolog programme until it encounters an ontological predicate. In order to differentiate ontological and conventional predicates, we use name-space prefixes separated from the predicate name by a colon, i.e.,  X  X : X  X . For example, if W3C X  X  wine ontology 6 is imported, we can directly use the ontological predicate vin:hasFlavor in an OLP programme without the need to define its semantics, where vin is a name-space prefix that refers to http://www.w3.org/TR/2003/PR-owl-guide-20031209/wine# . This name-space prefix is defined and used in the wine ontology.
The Prolog knowledge base does not have any knowledge about ontological predicates, since these predicates are not defined in Prolog, but described separately in an ontology, using DL ( Smith et al., 2003 ). In order to interpret ontological predi-cates, the OLP interpreter needs ontological reasoning services provided by a DL reasoner. Hence, we have a DL reasoning layer below the LP layer. The interpreter accesses the DL reasoner through the dl _ reasoner = 1 predicate as shown in Fig. 2 . This predicate is a reference to a Java method, which queries the reasoner and evaluates the ontological predicates based on ontological reasoning. OLP uses two disjoint knowledge bases. A Prolog knowledge base is used to store, modify and reason about non-ontological facts and clauses (e.g., rules), while a semantic knowledge base is used to store, modify and reason about ontological predicates and semantic rules. The semantic knowledge base is based on a set of OWL-DL ontologies, dyna-mically imported by OLP using import statements. Some rules are associated with these ontologies using SWRL ( Horrocks et al., 2004 ). Above the ontologies and the semantic rules, we have pellet ( Sirin et al., 2007 ) as our choice of DL reasoner. It is used to infer facts and relationships from the ontologies and semantic rules transparently.

During the interpretation of an OLP programme, when a predicate in prefix:name format is encountered, the DL reasoner below the LP layer in the OLP stack is queried to get direct or inferred facts about the predicate in the underlying ontologies. For example, when the meta-interpreter encounters vin:hasFla-vor ( D , R ) during its interpretation of an OLP programme, it queries the DL reasoner, because vin:hasFlavor is an ontological predicate. The hasFlavor predicate is defined in the wine ontology, so the reasoner interprets its semantics to infer direct and derived facts about it. Using this inferred knowledge, the variables D and R are unified with the appropriate terms from the ontology. Then, using these unifications, the interpretation of the OLP program is resumed. Therefore, we can directly use the concepts and proper-ties from ontologies while writing logic programs and the direct and derived facts are imported from the ontology through a reasoner when necessary. In this way, OLP enables us to combine the advantages of logic programming (e.g., complex data types/ structures, negation by failure and so on) and ontological reasoning.
 Namespaces play an important role in OLP. That is why, the OLP Application Programming Interface (API) and Integrated
Development Environment (IDE) provides various utilities to define new namespaces, list namespaces already defined in the imported ontologies, and search ontological predicates within these namespaces using regular expressions. Furthermore, OLP
IDE provides auto code completion capabilities to enhance the programming experience by providing lookahead features. Fig. 3 shows a snapshot of OLP IDE, with a simple program. The program starts with an import statement for the wine ontology.
Available namespaces can be listed in a new window using NS button on the menu. This window is shown just below the menu and can also be used to search for ontological terms within these namespaces using regular expressions. In the middle of the figure, an IntelliSense pop-up window is shown next to food:c ; it lists all ontological terms starting with c in the name-space food .
Lastly, it is important to explain the effects of Prolog X  X  back-tracking mechanism on our interpreter in Fig. 2 . The meta-interpreter undergoes backtracking in the standard fashion ( Apt, 1996 ), exhaustively attempting to find a solution to a query eval ( G ), trying different clauses in turn  X  the clauses, with the exception of complex ( G ), are mutually exclusive, due to the patterns they have in their head goals. Prolog also tries different ways to prove the goals in the body of a clause, backtracking when one of them fails, and attempting to prove the previous goal again (hopefully obtaining a different set of values for its variables), until a solution is found to the last goal of the clause X  X  body. We control the effects of backtracking on the invocation of the external DL reasoner, namely, the predicate dl _ reasoner (O:G) in the first clause. We rely on the termination properties of our reasoner, Pellet, and the limited expressiveness of DL (for instance, circular definitions cannot be expressed), to compute all possible solutions for O : G upon the first invocation of the predicate, and to produce these solutions one at a time upon backtracking. 2.3. Semantic knowledge and OLP
OLP not only uses the semantic knowledge within ontologies, but it may also modify this knowledge by importing new ontologies, and adding or removing concepts, roles, individuals and facts (i.e., RDF statements Smith et al., 2003 ). For this purpose, we provide OLP-specific predicates, some of which are listed in Table 1 . Here, we outline how OLP may be used to modify the semantic knowledge base:
Importing ontologies : In a classical Prolog program, domain knowledge is encoded as a part of the Prolog knowledge base.
To facilitate the reuse of standardised domain ontologies, OLP enables Prolog programs to directly use predicates defined in ontologies. An OLP program may import a number of ontolo-gies to access the domain knowledge encoded within them.
We provide two mechanisms to do this. First, at the beginning of an OLP program, lines starting with % import are interpreted as an instruction to import an ontology located at a specific
URI (note that these lines start with %, so they are regarded as comments by the Prolog engine). Second, the import _ ontology predicate can be directly used within an OLP program to dynamically import new ontologies.

Addition and removal of statements : As shown in Fig. 2 , the OLP interpreter evaluates assert and retract predicates differently depending on whether these are ontological and non-ontological facts. If assert is used with an ontological statement dicate is used by the interpreter to add this statement to the semantic knowledge base. That is, the semantic knowledge base is modified by declaring olp:x as an instance of the Wine concept. On the other hand, if assert is used with non-ontological predicates as in assert ( served ( v in : X  TaylorPort  X )), a new fact is added to the underlying Prolog knowledge base.
It should be noted that the addition of a new statement to the semantic knowledge base may make it inconsistent. For example, addition of the statement rdf : subConceptOf ( v in : X  Wine  X , food : X  Fruit  X ) results in an inconsistent semantic knowledge base, because Wine and Fruit concepts in the wine ontology are defined as disjoint. Therefore, before adding the statement, assert _ into _ ontology checks whether the addition would result in an inconsistency. If the addition would result in an incon-sistency, assert _ into _ ontology returns false without adding the statement. Otherwise, it modifies the knowledge base and returns true .The retract predicate works in a similar way: ontological facts are removed from the underlying semantic knowledge base using the retract _ from _ ontology predicate, while others are removed directly from the Prolog knowledge base.

Addition and removal of individuals : New individuals can be created using the create _ individual predicate. For example, create _ individual ( v in : X  SoftWine  X ) creates the individual Soft-Wine within the name-space vin as an instance of owl : Thing .
Then using assert ( v in : X  Wine  X ( v in : X  SoftWine  X )), we can declare that vin : X  SoftWine  X  is a wine. On the other hand, using the remove _ individual predicate, we can remove an individual and all statements about that individual from the semantic knowl-edge base (e.g., remove _ individual ( v in : X  SoftWine  X )).
Addition and removal of concepts : Through the create _ concept predicate, a new OWL-DL concept can be created based on a DL class description. If the described concept is not satisfiable, the predicate returns false without creating the concept; otherwise it returns true after creating the concept. A concept description is an OWL-DL class expression ( Smith et al., 2003 ), which can be a single concept name, a restriction on properties, or created using the intersection or the union of two class expressions or the complement of a class expression. A restriction on a property can be specified through someValues-
From , allValuesFrom , minCardinality , maxCardinality and exact cardinality restrictions ( Smith et al., 2003 ). The inverse of a property can also be used in a concept description. Moreover, a concept can be described by enumerating all of its instances; such classes are called enumerated classes ( Smith et al., 2003 ).
Table 2 shows examples of concept descriptions. OLP also allows the removal of concepts from the semantic knowledge base using remove _ concept predicate. When this predicate is used, not only the concept but also all statements about the concept are removed from the semantic knowledge base. In addition to the reasoning capabilities provided by Prolog,
OLP provides access to the ontological reasoning services pro-vided by the underlying DL reasoner. These are summarised as follows:
Ontology consistency checking : OLP enables consistency check-ing of the underlying semantic knowledge base through has _ consistent _ ontology predicate. This predicate returns true if the underlying semantic knowledge base is consistent; other-wise it returns false .

Concept satisfiability checking : In order to test the satisfiability of a concept description, is _ satisfiable _ concept predicate should be used; it returns true if the described concept is satisfiable; otherwise it returns false .

Concept subsumption checking : In order to test if a named concept c i subsumes another c j ( c j L c i ), the ontological pre-dicate rdfs:subClassOf ( c j , c i ) should be used. For example, when rdfs:subClassOf ( v in : X  Riesling  X , A ) is found, the OLP interpreter unifies A with the super-concepts of Riesling , such as food : X  PotableLiquid  X , vin : X  WhiteWine  X , vin : X  Wine  X , and so on.
Class equivalence checking : In order to check equivalence of two named concepts c i and c j , the ontological predicate rdfs: equivalentClass ( c i , c j ) should be used. For example, when the predicate rdfs:equivalentClass ( v in : X  Riesling  X , A ) is found, A is unified with the concepts equivalent to Riesling if any exist.
Class instance checking : OLP provides two different ways to reason about the instances of a specific concept. The first way is to use the class name as an ontological predicate; for example, when vin : X  Wine  X ( I ) is found, the OLP interpreter unifies I with instances of the Wine concept in the vin name-space. The second way is to use the ontological predicate rdf:type ; for example, when rdf:type ( I , vin : X  Wine  X ) is used, the OLP interpreter also unifies I with instances of Wine .
Having presented OLP, in the next section we analyse perfor-mance issues arising from its computations. 2.4. Performance of OLP In order to evaluate the computational properties of the OLP, in this section we execute a set of queries against W3C X  X  wine ontology. Queries are created randomly with increasing complexity (e.g., number of ontology predicates are increased continuously up to a particular threshold, negation of concepts and properties to compute statements such a wine which is not sweet and so on). All the experiments are run on a PC with 2.16 GHz Intel Core Duo processor and 2GB of RAM.
 As described in Section 2 , OLP works by communicating with a
DL reasoner whenever it encounters an ontological term in order to resolve it. We refer to this mode as online . Purely for evaluation purposes, we run OLP in another mode. In this second mode, using the reasoner, we load all of the direct and inferred facts from the ontology into the Prolog X  X  standard knowledge base and then execute the queries with respect to Prolog X  X  knowledge base instead of interacting with the reasoner during the execution; we refer to this mode as offline hereafter. It is important to note that, when offline mode is used, the Prolog knowledge base is popu-lated with all of the direct and inferred facts from the ontology before executing any query. We executed four random query sets against the wine ontology. In order to analyse offline and online modes for different ontology sizes, we extended the size of the wine ontology by introducing new properties and concepts. We analysed the online and offline modes in terms of load time , reasoner access time , and average query time . The load time is the time spent to load ontological facts into the Prolog knowledge base in offline mode. On the other hand, the reasoner access time is the time spent by the reasoner during the execution of queries in online mode. Lastly, query time for a query is the time spent by the Prolog engine within the OLP stack to answer the query and excludes load and reasoner access time . That is, the total time required to execute a query and retrieve all of its answers is load _ time  X  query _ time for offline mode, while it is reasoner _ access _ time  X  query _ time for online mode.

The graph in Fig. 4 (a) shows the average query time in each mode as the ontology size increases. Clearly, the online mode significantly outperforms the offline mode. Furthermore, the performance difference increases dramatically while the ontology size increases. This is mainly due to the fact that offline mode introduces redundancies by loading the whole ontological knowl-edge and as the size of its knowledge base increases, the performance of the Prolog engine decreases. We also analysed the effect of query complexity on query time for online and offline modes, and the results of this experiment are presented in
Fig. 4 (b). The figure demonstrates that the online mode always outperforms offline mode in terms of average query time.
Load time and reasoner access time may significantly affect the total time required to execute an OLP program in offline and online modes respectively. Therefore, in Fig. 4 (c), we demonstrate how load and reasoner access time change as ontology size increases. The graph shows that reasoner access time significantly exceeds the load time and this difference increases as the size of the ontology increases. This means that, execution of OLP pro-grams in online mode takes much more time than in offline mode, especially for large ontologies.

We have examined the huge gap between the load time and reasoner access time and revealed that, while an OLP program is being executed in online mode, the reasoner is accessed many times during Prolog X  X  backtracking. For example, during the execution of the conjunctive query shown in Fig. 5 the reasoner is accessed 4152 times and 609 solutions are produced at the end of the query execution. Because of the frequent access to the reasoner during backtracking, total time required to execute an
OLP program increases significantly in online mode. During backtracking, the reasoner is accessed repeatedly to retrieve direct or inferred facts about the same set of predicates. Hence, we can use caching mechanisms ( Godfrey and Gryz, 1999 )to store facts returned by the reasoner for a specific ontological predicate and next time we can use these cached facts instead of accessing the reasoner again for the same predicate. With the caching mechanism in place, whenever the OLP interpreter encounters an ontological predicate, first, it checks whether the predicate concerned is already resolved and stored in the cache. If so, it retrieves the appropriate facts from the cache; otherwise, it resolves the predicate by accessing the reasoner and locally caches the retrieved results for future use.

Fig. 4 (d) shows load time for offline mode and reasoner access time for cache enabled online mode 7 . The results show that online mode with a cache significantly outperforms offline mode (i.e., with caching enabled the  X  X  X pper X  X  line in Fig. 4 (c) gets shifted down to the  X  X  X ower X  X  line in Fig. 4 (d)). Hence, OLP with a cache can efficiently execute programs with low reasoner access and query time. In the next section we introduce a real-world problem domain and show how OLP has been used to provide an effective solution to it. 3. Case-study
In order to ground the description of OLP, in this section we introduce a comprehensive sensor-task assignment solution based on OLP and discuss the benefits one can obtain by using
OLP. The case-study has been explored within the research project  X  X  X nternational Technology Alliance in Network and Infor-mation Sciences X  X  (ITA). 8 The ITA programme was initiated by the
UK Ministry of Defence and the US Army Research Laboratory to focus on research problems related to mission-critical situational awareness in coalition operations. One of these research problems is the effective selection of sensing resources 9 (i.e., selection of appropriate sensing resources) for tasks. Effective selection of sensing resources (henceforth refereed to as resources) to tasks is an important but computationally hard problem to solve in the sensor networks domain ( Byers and Nasser, 2000 ). This is because only a subset of available resources are suitable to satisfy tasks due to the varying needs of those tasks. Thus, for many critical tasks like border monitoring or surveillance, selection of proper resources plays a crucial role in the success or failure of tasks. The difficulty of this problem is amplified in the intelligence, surveil-lance, target acquisition, and reconnaissance (ISTAR Defence Committee, 2008 ) domain, and especially in a coalition context. This is due to a variety of reasons:
The environments in which these resources are deployed may rapidly change yielding new requirements.

Demand placed on available resources typically exceeds the inventory in coalition operations.

Coalition members may share resources to improve the total utility of achievable tasks but, there could be policies govern-ing the assets which restrict partners of the coalition deploying some resources or accessing some particular information from resources.

Therefore, it is important to assign resources for tasks such that the assigned resources are effective (i.e., necessary and sufficient to cater for the needs of the tasks). Many communities have investigated different approaches to select resources for tasks and have proposed mechanisms that could be applied to solve the resource selection problem. Some of these approaches rely on having a  X  X  X uman in the loop X  X  to decide which resources are appropriate to satisfy the requirements of tasks ( Doll, 2004) whereas other approaches (especially from operations research) have tried to automate the assignment process ( Byers and Nasser, 2000 ). In dynamic environments, it is very difficult for a human to have a bird X  X -eye view of the available resources for tasks. Thus, having humans in the loop for resource selection in such envir-onments could have a negative effect on the performance of tasks with respect to the duration of the solution discovery process. Operations research approaches tend to focus on the physical aspects of the sensor network such as range, power, bandwidth and so on to optimally select resources for tasks. However, due to the lack of context-related information such as capabilities required to satisfy the needs of tasks, weather conditions, terrain, policies governing the resources and so on the assignment may not be effective. Below we provide an example to motivate our work.
 Example 1. Consider a hypothetical country which is infested with rogue militia. Recently, a United Nations-backed peace-keeping force has been deployed to assists in the on-going peace process. A major earthquake has struck the country and a humanitarian organisation wants to access the region to evacuate people and help the wounded. However, the humanitarian orga-nisation lacks means to detect and transport people to a safe location. The humanitarian organisation wants to collaborate with the peacekeeping force to acquire vehicles, but are not willing to use any vehicles with fire-power in order to keep its neutral status within the region. The peacekeeping force has prior knowledge of a landslide near the region to where the humani-tarian organisation wants access; thus, the peacekeeping force has to take this into consideration when proposing resources. Also, according to the policies of the peacekeeping force, they must perform constant surveillance over the area where the humanitarian organisation operates in order to protect them from the militia.

Considering the above example, it is apparent that in order to address the resource selection for tasks, an intelligent and auto-matic mechanism is needed. This is because, as it is stated earlier, it is impossible for humans to have a bird X  X -eye-view of a network which is rapidly changing. Such an approach should have the following properties: effective and efficient knowledge represen-tation so that the discovery of appropriate solutions could be done in a timely manner, sufficient expressive power (i.e., ability to represent complex concepts, rules, and queries in a meaningful way), and flexibility in the resource discovery process (i.e., ability to find different solutions for tasks with varying needs and constraints). Motivated by these requirements, in the next section we first propose knowledge-rich models based on the latest knowledge representation formalisms, and then a mechanism based on OLP to compute appropriate resources for tasks such that the identified resources can fully cater for the needs of those tasks. 4. An ontology for sensor-task assignment
In this section, we present a formalisation of a class of domains  X  namely those concerned with Intelligence, Surveillance, Target
Acquisition and Reconnaissance or ISTAR (27)  X  its semantics, and some important definitions. Our choice of language is Description
Logic (DL) ( Baader et al., 2007 ). This is because DL is more expressive than propositional logic and has more efficient deci-sion procedures than first-order predicate logic; both these features are very important in order to model and reason with a domain realistically and efficiently. 4.1. Syntax of the ISTAR ontology
Below we specify the syntax of the language to represent an ontology for sensor-task selection inspired by the ISTAR domain.
The language is based on Description Logic SHOIN  X  D  X  ( Horrocks and Patel-Schneider, 2004 ). Adhering to the canonical model of an ontology, we describe our ontology by means of a Tbox (i.e., terminological axioms), an ABox (i.e., assertional axioms), and an RBox (i.e., rule axioms). We shall denote this ontology for the ISTAR domain as O .

The TBox of the ontology contains a finite set of concept inclusions and role definitions. In this paper we shall use C and P to represent finite sets of concepts and properties respectively. A concept C A C denotes a set of individuals. For example, C  X f UAV , Sensor , ... g for our domain. This is because { GlobalHawk ,
Predator , ... } are individuals of UAV and { Ultra8500 , ... } are individuals of sensors. P defines a set of binary relationships among concepts/individuals in the domain; the property carry-Sensor ( GlobalHawk , Ultra8500 ) forges a relationship between
GlobalHawk and Ultra8500 to denote the fact that GlobalHawk may carry sensor Ultra8500 . Furthermore, TBox statements can introduce a name for a complex concept description. Given two concepts C , D A C and a property P A P , then following are also concepts: C u D , C t D , : C , 8 P : C , and ( P : C . Concept inclusion is defined using the general concept inclusion (GCI) operator follows: if C , D A C , then the GCI is defined as C L D if, and only if, all C are D . Furthermore, we use C 6 D when C L D , D L C , that is, a concept is defined to be equivalent to another concept if, and only if, concepts C and D subsume each other.

The ABox of the ontology contains a finite set of statements describing concrete individuals by stating their properties. For example, { GlobalHawk , Predator , Ultra8500 , y } are instances of
UAVs and infrared sensors in our domain. We shall use O to represent these individuals in our domain. The following defines the ABox of our domain ontology. 1. o : C , such that 8 o A O , ( C A C . That is, every concrete instance of a concept in the ontology O is an individual. 2. A role is asserted as  X  a , b  X  : P where a , b A O and P individuals are related by properties/roles in the ontology O .
The RBox has a set of domain rules which define new concepts or forge new relationships between existing individuals and concepts. We shall use R to represent this set of rules in the remainder of the document. These are DL safe rules ( Motik et al., 2005 ) and are of the form q  X  y !  X   X  V n i  X  0 p i  X  x ! either a concept description or a role definition with an appropriate arity.
 We formally represent our ISTAR ontology as O  X  / T , A , R where T is the TBox, A is the ABox, and R is the RBox. 4.2. Semantics of ISTAR ontology
The semantics of our ISTAR ontology follows the work described in Baader et al. (2007) . The semantics of the ontology is given by means of an interpretation defined as I  X  X  D I where 1. D
I represents the domain, i.e., a non-empty set of objects. 2. I represents an interpretation function.

This interpretation function maps all individuals, concepts, and roles of the ontology to the domain as follows: all individuals of the domain to an object in D I (i.e., 8 a A O , a I A D concept to a subset of D I (i.e., 8 C A C , C I D D I ), all property names to subsets of D I D I (i.e., 8 P A P , P I D D I D I ). Furthermore, we define the following semantics for more complex concept definitions. 1. The disjunction of two concepts is the union of the two concepts in the interpretation, i.e.,  X  C t D  X  I  X  C I [ D 2. The conjunction of two concepts is the intersection of the two concepts in the interpretation, i.e.,  X  C u D  X  I  X  C I \ D 3. The interpretation of a negated concept is the complement of the interpretation of the concept, i.e.,  X : C  X  I  X  D I \ C 4. The interpretation of  X 8 P : C  X  is such that all objects that satisfy the domain of the concept must only have a P relationship with an individual from the concept C , i.e.,  X 8 P : C  X  I f a
A D I 9 8 b ,  X  a , b  X  A P I -b A C I g . 5. The interpretation of  X  ( P : C  X  is such that all objects that satisfy the domain of the concept may have a P relationship with an individual from the concept C , i.e.,  X  ( P : C  X  I  X f a  X  a , b  X  A P I -b A C I g .

A rule in the RBox is satisfied by I if, and only if, every concept and property described above for the ontology O that satisfies the antecedent of the rule satisfies the consequent of the rule as well. We can then define a mapping function m such that  X  S
Having provided a semantic model for our domain, below, we provide formal definitions for important concepts and relation-ships we have encountered in the domain. 4.3. Definitions of ISTAR concepts In order to provide definitions we use the following subsets of
C . Sensor types are denoted by the set S C ; platforms are denoted by the set Plt C ; capabilities are denoted by the set
Cap C . Capabilities are further classified into sensor capabilities (i.e., SCap Cap ), platform capabilities (i.e., PCap Cap ), and hybrid capabilities (i.e., HCap Cap ). A hybrid capability  X  e.g.,
National Image Interpretability Rating Scales (NIIRS) as discussed in Irvine (2003)  X  is provided by a resource. We assume the following relations among the above sets. S \ Plt  X  | , that is, concepts of sensor and platform are disjoint. Furthermore,
SCap \ PCap  X  | , PCap \ HCap  X  | , SCap \ HCap  X  | , that is, sen-sor capabilities, platform capabilities, and hybrid capabilities are naturally disjoint. With these set definitions in place, we provide the formal definitions of the concepts sensor, platform, and sensing resource of our ontology.
 Definition 1. 8 S A S , S L ( ! hasSensingCapability.C , has Sensing Capability A P , C A SCap .

A sensor is an entity that provides exactly one sensing capabi-lity such as imagery, acoustic, seismic and so on. For example,
Ultra8500 is a sensor because it provides infrared sensing capability.

Definition 2. 8 P A Plt , P L ( hasOperationalCapability.C , hasOpera-tionalCapability A P , C A PCap .

A platform is an entity which provides some operational capabilities like range, power and communication capabilities to sensors, and so on for tasks. For example, a rocket is a platform that could provide capabilities such as range, payload, etc., to a task.

Definition 3. A sensing resource SR 6 ( ! hasPlatform.P u carriesSensor.S such that P A Plt
S A S , P L ( carriesSensor : S ( providesCapability.SR L SC t PC t HC , SC A SCap , PC A HC A HCap .

A sensing resource is a single platform with one or more sensors mounted on it. For example, a Global Hawk is a sensing resource because it is a platform that carries an optical sensor and radar sensor. We will be using SR to represent the set of all available sensing resources in our domain. We formally represent the capabilities provided by a sensing resource as a function l .
Definition 4. l : SR / 2 Cap , l  X  SR  X  X f C 1 , ... , C n
By.SR , C i A Cap ,1 r i r n , providedBy A P . We generalise l as resources.

In this work, we concentrate on sensing tasks (i.e., those that could be achieved by means of a sensor network). However, this can be extended to other domains by introducing appropriate knowledge extensions. Let us consider a situation in which the perimeter of a camp has to be monitored against enemy activity.
In order to achieve this goal, a number of sub-goals have to be executed. For example, detecting vehicle movement, identifying the vehicles once detected, human activity within the surround-ing area, etc. These tasks could be defined as a set of low-level sensing requirements or by using abstract requirement specifications.

Low-level task requirements are sensing capabilities such as electro-optical ( EOINT ), infrared ( IRINT ), acoustic ( ACINT ), etc., whereas abstract requirement specifications are tasks which describe the user intentions rather than specifying how to per-form tasks. For example, a task such as  X  X  X erimeter surveillance X  X  can be viewed as an abstract requirement because it states the user intention rather than specifying a capability to achieve the task (e.g., IMINT ). Abstract requirements are beneficial as means to specify the requirements in resource competitive domains such as sensor networks as they help users to identify more resources that could be used to satisfy the needs of tasks, thus, increasing the likelihood of achieving the tasks. For example,  X  X  X erimeter surveillance X  X  can be achieved by either imagery or acoustic resources. More details on abstract requirements can be found in de Mel et al. (2009) . Task requirements are satisfied by the capabilities provided by the resources. It is important to notice that a requirement could be satisfied by using many different capabilities, or combinations of capabilities. For example, an imagery requirement could be satisfied with EOINT or IRINT ; detection of a vehicle could be achieved with acoustic or IMINT capabilities. We formally relate requirements to a set of sets of capabilities using a function g as follows: Definition 5. g : Req / 2 2 Cap , maps a requirement onto a set of sets of capabilities. More specifically Req A Req , g  X  Req  X  X  f Sol 1 , ... , Sol n g such that Sol i  X f C 1 , ... , C m needsCapability . C j ,1 r j r m , needsCapability A P . We can further generalise g as g n  X f Req 1 , ... , Req n g X  X  S n i  X  1 g of requirements.

For example, a vehicle detection task could be achieved by means of acoustic ( ACINT ), infrared ( IRINT ), or radar ( RadarINT ). So { RadarINT }}. With these formalisms in place, in the next section we define a query language for ISTAR ontologies. 5. A query language and its semantic for requirement specification 5.1. Syntax of the query language
A query to our system contains a requirement specification of a task or a collection of tasks. We define the grammar of the query language as follows: Q  X  X  Q  X  9 Q 4 Q 0 9 Q 3 Q 0 9 : Q 9 C 9 P
Q and Q 0 represent subqueries and : Q represents a comple-ment of a query (e.g., resources with no fire-power). C could be an atomic concept or property from our ontology (e.g., istar:IMINT or istar:providesCapability ( istar: Ultra8500,istar:Infrared )) and P is an abstract requirement defined for the domain. It is important to note that a solution for a query in our case could contain more than one resource. This is because a task may not be satisfied with only one resource. For example, to achieve the goals of a task, audio and visual information may be needed but there is no single resource to satisfy both requirements. This yields the need to have a mechanism to combine resources such that the collective capabilities provided by these resources cater for the needs of the task. Since a solution may contain more than one resource, we refer to a solution collectively as a resource package. Definition 6. Given a set of requirements Req D Req with an associated set of sets of capabilities g n  X  Req  X  X f C 0 , ... , C resource package RPkg is a set of resources (i.e., RPkg D such that, for at least one C i ,0 r i r n , C i L l n  X  RPkg  X  which means that each capability C 0 A C i , C A l  X  RPkg  X  , C 0 L C . Furthermore, for any proper subset of a resource package RPkg 0 RPkg there exists no C i , 0 r i r n , C i L l  X  RPkg 0  X  .

The above definition represents the individually necessary tions (i.e., C i L l n  X  RPkg  X  ) for a resource package for a given task. Consider, again Example 1 . The commander of the peacekeeping forces wants to detect human activity in the surrounding area to ensure the security of the camp. Detection of human activity could be done by detecting people movements, identifying vehicles and so on. Assume that the peacekeeping force has access to three resources SR 1  X f GlobalHawk , SAR g , SR 2  X  f IGNAT , SAR g , and SR 3  X f Reaper , EOCamera g available to carry out tasks. Due to the nature of the resources, SR 1 and SR 2 could be used to detect people while SR 1 and SR 3 could be used for vehicle identification and so on. Thus, the possible resource packages to satisfy the human detection task are { SR 1} and f SR 2, SR 3 g . This is because SR 1 can be used to detect humans and for vehicle identification while SR 2 and SR 3 together can meet needs of the task (i.e., SR 2 for human detection and SR 3 for vehicle identification).

The focus of the work presented here has been to identify suitable resources types based on the high level capabilities provided by the resources. Thus, in this paper, we have not discussed in detail how these solutions could be ranked. However, the solutions could be ranked manually or by means of an intelligent process. For example, the work presented by Doll (2004) discusses a semi-automatic mechanism that utilises a resource look-up table created by subject matter experts to select resources for tasks sorted by availability and the capabilities of the resources, whereas Sensoy et al. (2009) have discussed how willingness to share resources could be used to rank solutions in a coalition context. 5.2. Semantics of the query language
As the output of a query Q , we expect a set of resource packages (i.e., set of sets of resources). These solutions should be sufficient and necessary; i.e., individual resource of a given solution should be necessary and together they should suffice to achieve the given task(s). We define a function t that express the query execution. The function takes a query Q and an ontology O , and produces a finite set of resource packages (i.e., a set of RPkg ).
Definition 7. The answer of a query is defined using the function t such that t :  X  Q , O  X  /  X  2 2 SR  X  where SR is a sensing resources. Regarding our query language definition, we have identified following cases of the function t . is the intersection of the result of each individual query. is the union of the result of each individual query. 3. t  X : Q  X  X  SR \ t  X  Q  X  , that is, a negated query is the complement of the non-negated query Q . 4. t  X  C  X  X  A , such that, A D SR , Req i A 8 hasRequirement : C , c
A g  X  Req i  X  , c D l n  X  A  X  , that is, if the query is made up of a low level requirement, its mapping is a set of sets of sensing resource types such that there exists some resource type which provides some capability which subsumes the required capability. 5. t  X  P  X  X  A , such that, A D SR , c A g  X  P  X  , c D l n  X  A  X  , 8 c 0
That is, if the query is an abstract requirement, it yields to a set of sets of sensing resource types such that the hybrid capabil-ities provided by each and every resource subsumes the required capability to achieve the abstract requirement. 5.3. ISTAR matchmaking with OLP
In order to ground our descriptions and semantics of the above query formalism, below we provide some example instances of it using the OLP notations with an extended version of the ISTAR ontology ( Gomez et al., 2008 ). Fig. 6 depicts the ISTAR ontology in its original form. The Asset concept represents the resources that could be allocated to tasks. The Platform and System concepts are both assets, but systems may be attached to platforms. Sensors are a specialisation of systems. A sensor needs to be mounted on a platform to work properly. On the other hand, not all platforms can mount every type of sensors. For example, to be used, a radar sensor must be mounted on Unmanned Aerial Vehicles (UAVs), however, only specific UAVs such as Global Hawk can mount this type of sensors. A task may require capabilities, which are provided by the assets. In order to achieve a task, we need to deploy specific assets that provide the required capabilities.
Capability requirements of a task are divided into two categories: the first concerns operational capabilities provided by the platforms, and the second concerns intelligence capabilities provided by the sensors attached to a platform.

Fig. 7 depicts our extensions to the ISTAR ontology. We have introduced the notion of sensing resource to the ISTAR ontology, which in turn gets assigned to tasks through the assignedTo property. As described earlier in Section 4.3 , a sensing resource has one platform and can carry one or more sensors. We have further augmented the ISTAR ontology by introducing a set of abstract requirement specifications and a set of capabilities based on the NIIRS knowledge corpus. The abstract requirements have three main concepts Detect, Distinguish, and Identify ( Detect
Distinguish L Identify ) whereas the NIIRS capability hierarchy has nine levels. As shown in Fig. 7 , each task has two main properties: hasObservation, requiresNIIRS which describe what is being observed at a particular NIIRS rating. A NIIRS rating is a hybrid capability provided by a resource (i.e., a capability jointly pro-vided by a sensor and a platform) and assigned to a resource by the property providesNIIRS . Below we describe an implementation of an abstract requirement  X   X  X etection of an object X  using the extended ISTAR ontology and OLP. detect  X  R , Object  X  :-istar: X  X ensingResource X (R) , istar: X  X rovidesNIIRS X (R,NIIRS) , istar: X  X etect X (T) , istar: X  X equiresNIIRS X (T,NIIRS) , istar: X  X asObservable X (T,Object) .

The OLP programme first retrieves a resource and checks for the NIIRS capability of the resource. It then selects an abstract requirement  X  X etect X  which can be satisfied with the identified
NIIRS capability. If the range of the hasObservable property subsumes the users intention, then the selected resource is a candidate for the task. It is important to note that due to the subsumption relations among the abstract requirements, Distin-guish and Identify concepts will also be considered while checking for Detect ; this is desirable and intentional for the domain.
Example 2. Assume that a user wants to detect vehicles and wants to find out what kind of resources could be used to satisfy the task. The user could utilise the above implementation as follows to obtain the required resources. detect  X  R , istar :  X  Vehicle  X   X  .

Example 3. The user wants to detect a vehicle and knows that he/she only has access to some acoustic sensors. However, the user has got no prior knowledge about the capabilities required to achieve the task. Then a query could be formulated by adding a constraint to the implementation of  X  X etection X  such that the returned solutions are pruned to restrict the solutions to acoustic resources. detect  X  R , istar :  X  Vehicle  X   X  , istar :  X  providesCapability  X   X  R , istar :  X  ACINT  X   X  :
Example 4. A humanitarian organisation is planning a mission to evacuate people from a troubled region. However, the organisa-tion lacks means to detect people and transport people to a safe location. The humanitarian organisation is willing to collaborate with a military organisation to acquire the vehicles, however, it is not willing to use any vehicles with firepower in order to keep its neutral status within the region. Such requirements could easily be modelled as follows:
The above OLP programme select resources which can detect people and ferry them to safety (i.e., istar : X  providesCapability  X  ( R , istar : X  Mobility  X )). It also rules out any resources with Firepower capability which is the intention of the humanitarian organisation. In the next section, we demonstrate the benefits one can obtain by using OLP in resource-task selection domain. 6. Evaluation
The evaluation is two-fold: first, we show that OLP can complement existing resource selection approaches by identify-ing a subset of available resources which can meet the needs of tasks. We then show how an OLP-based resource selection mechanism can out-perform a set covering approach for resource-task selection. We have designed a set of ontologies that conforms to the proposal of Section 4 in terms of syntax and semantics. We have then implemented an application which uses this ontologi-cal knowledge to select appropriate resources for tasks. We deployed 15 different resources using a sensor fabric ( Wright et al., 2009 ) and these resources were annotated semantically using the ISTAR ontology described in Section 4 . A set of tasks were deployed to utilise these resources. The tasks were created by randomly picking requirement descriptions from the ISTAR ontology. For the sake of simplicity, we have only considered tasks that can be satisfied with one resource. At the beginning of the experiment there were 10 tasks and during each time frame, the number of tasks were increased by 10. The aim of the detect  X  R , istar :  X  People  X   X  , not  X  istar :  X  providesCapability  X   X  R , istar :  X  FirePower istar :  X  providesCapability  X   X  R , istar :  X  Mobility  X   X  : experiment was to analyse the number of resources an assign-ment algorithm must consider in order to determine the best fit of resources to tasks. Note that the best fit in our problem is defined as the set of sensing resources whose capabilities fulfill the minimum requirements of tasks (i.e., any capability that sub-sumes the intended requirement). Note that we were not evalu-ating the actual allocation of resources in this experiment; we are computing the number of resources the algorithm must consider.
We considered three different assignment algorithms and their details are as follows: 1. Naive : The algorithm consults all the resources deployed in the fabric irrespective of the capabilities provided by those resources to compute the possible resources for a given task.
This computation could be based on the distance to a target, available battery power of the resources and so on. 2. Ontology based : The algorithm uses OLP-based queries to obtain resources from the fabric stack such that the resources fully cater for the needs of tasks. 3. Resource sharing : In this case, all the tasks are willing to share the resources, thus, the algorithm uses subsumption relation-ships among the resources to further prune the OLP query results.

Fig. 8 depicts the results obtained in our experiments. In the naive approach, all the resources in the area were consulted for each task in order to compute the best resources for them.
However, when the ontology-backed algorithm is deployed, it first computes the types of resources that can satisfy the needs of tasks and only retrieves those types of resources from the sensor network for the assignment purpose. Thus, as shown in the figure, the approach greatly reduces the number of resources the assign-ment algorithm had to consult. For example, when the number of tasks are 70, the naive approach considers 1050 resources while the ontology backed approach only considers 467 resources. In the resource sharing approach, we assumed that all the tasks in the area were willing to share the resources. In this case, the results obtained using the system were further pruned by removing the resources which were subsumed by other resources for a set of tasks. For example, when the number of tasks are 70, the ontology backed approach had to consider 467 resources whereas sharing enabled approach only considered 325 resources.

For our second evaluation criteria, we evaluate the perfor-mance of an OLP based application with Sensor Assignment for
Missions (SAM) tool ( Gomez et al., 2008 ). SAM uses a minimal set covering algorithm to compute deployable configurations for an
ISTAR task. The algorithm enumerates all possible sets of asset types so that each set has at most n members. Then, a set is regarded as a deployable configuration of the task if it satisfies all the requirements. This approach is based on an exhaustive search algorithm and implemented in Java using Pellet for DL reasoning.
We have implemented an OLP based program shown in Fig. 10 to compute deployable configurations. The OLP program uses the getConfigurations predicate to compute deployable configurations for a specific task. Each sensor must be carried by a deployable resource that provides all of the operational requirements of the task (e.g., constant surveillance). If a sensor cannot be carried by a resource, there is no point in considering deployable configura-tions with that sensor type. Using this knowledge, a tailored and efficient matchmaker can be employed. This matchmaker first identifies the deployable platforms that meet the requirements of the task. Once the many possibilities are narrowed down by determining deployable platforms, the sensor types that provide the intelligence capabilities required by the task are determined incrementally so that those sensors can be mounted on the deployable platforms.

We have compared the OLP-based matchmaker with the exhaustive search approach in terms of time consumption.
For this purpose, we randomly created 908 tasks using the ISTAR ontology. Fig. 9 shows our results, where the x-axis is the maximum number of items in deployable configurations and y-axis is the average time consumed by each approach to find all of the deployable configurations of a task. When the maximum size of deployable configurations increases, the OLP-based approach outperforms the exhaustive search approach signifi-cantly; time consumption of the exhaustive search increases exponentially while that of the proposed approach is almost linear within the bounds of the experiment. These results are intuitive because the OLP program in Fig. 10 is based on the idea that the search space can be significantly reduced using domain knowledge (i.e., dependencies between sensors and platforms; not every type of sensors can be used with a specific type of platform). Using this principle, at each iteration, it rules out many combinations and significantly reduces the time required to compute deployable configurations.
 7. Discussion
Our ontology design has been inspired by the various ontol-ogies described in the literature. OntoSensor ( Goodwin and
Russomanno, 2006 ) and MMI ( Bermudez et al., 2006 ) are two well-known examples. OntoSensor does not meet our require-ments because it was created primarily for data fusion, where the emphasis is on modelling sensor data. We, in contrast, are interested in modelling the capabilities of resources, be they platforms (e.g. autonomous aerial vehicles) or sensors (e.g. day-light cameras). The MMI platform ontology is limited to marine platforms but we are interested in a wider range of platforms. Recent activities such W3C Semantic Sensor Network Incubator
Group 10 aim to create ontologies that define the capabilities of sensors and sensor networks but its work is still at an early stage.
The work proposed by Gomez et al. (2008) employs an ontology-based reasoning mechanism to compute solutions for resource-task assignment based on a minimal set covering algo-rithm. We believe that the approach described here significantly improves that research in two ways. First, the work described by
Gomez et al. (2008) does not support rules to capture the crucial domain knowledge. This makes the approach less flexible in capturing complex domain concepts. The work described here supports rules, thus it assists in better representation of domain ( de Mel et al., 2009 ). Second, the query specification in Gomez et al. (2008) is simply a collection of low-level requirements, whereas we provide a more expressive query formalism (i.e., logical relationships among the predicates and variables) to represent complex requirements.

Sensoy et al. (2011a) have proposed an ontology and logic based approach for resource-task matching. The core of the approach is a set of logic-based programs which make use of a set of interlinked ontologies that describes the domain to find appropriate resources. Tasks are considered to be atomic. There-fore, a solution for a task is a set of resources, each of which satisfies the needs of the task. Complex task specifications for resource allocation is not possible, and the user is expected to have the ability to breakdown a complex task into manageable subtasks. We address these issues in our system by providing a expressive query language.

Many operations research approaches have proposed utility-based solutions with heuristics-b ased enhancements. For example, Byers and Nasser (2000) propose a framework to solve the assign-ment problem based on energy conservation to maximize the utility of a sensor network while keeping the cost of the assignment per task under a pre-defined budget. Johnson et al. (2008) propose an energy-aware schema to select assets for tasks in both static and dynamic environments. In the static setting, a user of a sensor network is granted total control over it for a particular duration in order to carry out a set of simultaneous tasks. Energy conservation is the priority of this model. Therefore, each task is assigned a pre-defined budget (in terms of the energy consumed) so that it constrains the number of assets a task can use even if using more assets could increase the profit of the task. In the dynamic setting, the trade-off between cost (in terms of energy) versus task profit is considered. This is because in dynamic environments constraints keep on changing (i.e., the tasks start at different times, durations resulting in changing the assets conditions) and an approach based on a fixed budget would be too restrictive to select assets. Pizzocaro et al. (2011) have suggested using a look-up table created by a knowledge-based reasoning framework to effectively and efficiently allocate resources for tasks while minimising the distance between tasks and resources. 8. Conclusions In this paper, we have proposed a novel tool that combines
Logic Programming with Ontological Reasoning. Unlike similar approaches in the literature, our approach delegates interpreta-tion of ontological predicates to an ontology reasoner during the execution of logic programs. Hence, it takes full advantage of both ontological reasoning and logic programming without any compromise in expressiveness. We have empirically shown that the frequent access to the reasoner during backtracking is a performance bottleneck for the proposed approach and we have solved this problem using caching. Further, using a real-world case-study, we have demonstrated how the proposed approach can be used to solve mission-critical situational awareness problems in an efficient and practical way.
 Acknowledgements This research was sponsored by the U.S. Army Research
Laboratory and the U.K. Ministry of Defence and was accom-plished under Agreement Number W911NF-06-3-0001. The views and conclusions in this document are those of the author(s) and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Army Research Laboratory, the U.S. Government, the U.K. Ministry of Defence or the U.K.
Government. The U.S. and U.K. Governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon.

We acknowledge ITMAS 2011 as the forum in which the main ideas behind this paper were preliminary discussed.
 References
