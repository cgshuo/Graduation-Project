 ORIGINAL PAPER Emanuele Salerno  X  Anna Tonazzini  X  Luigi Bedini Abstract This paper reports some of the results obtained by applying statistical processing techniques to multispectral images of the Archimedes palimpsest. We focused on the possibilities of extracting the faint and highly degraded underwritten text, which constitutes the most ancient source for several treatises by Archime-des. Assuming each image to be generated by a linear mixture of different patterns, characterized by differ-ent emissivity spectra, the specific difficulty in separat-ing the underwriting is that the mixture coefficients are unknown. To solve this problem, we rely on statistical techniques that maximize the information content of the processed images. In particular, we assessed the per-formances of the principal component analysis (PCA) and the independent component analysis (ICA) tech-niques. On the basis of 14 hyperspectral views of part of the palimpsest, we succeeded to extract clean maps of the primary Archimedes text, the overwritten text, and the mold pattern present in the pages. This goal was not reached in all the cases, because of the non-perfect adherence of the data model to reality. In most cases, however, PCA and ICA produced a significant enhancement of the underwritten text.
 1 Introduction The Archimedes palimpsest is an ancient Byzantine manuscript codex now kept at the Walters Art Museum in Baltimore, Maryland. This book is the most ancient source for several treatises by Archimedes, the great Greek philosopher, and was deemed lost until it was sold, in 1998, to a private collector who entrusted the museum with its restoration and study. As one of the results of its extremely tortuous history, it is also known as the Euchologion of Mar Saba ,or Codex C (Codex rescriptum Metochii Constantinopolitani S. Sepulchri Monasterii Hierosolymitani 355). Indeed, the Archi-medean text was originally written on parchment in Constatinople, as early as in the tenth century. Dur-ing the thirteenth century, the book was taken apart, erased, and overwritten with a Greek liturgic text, a Euchologion. For centuries, it has been a property of the Greek Patriarcate of Jerusalem and was probably kept in the monastery of Mar Saba, near Jerusalem, and in Constantinople, in the daughter house (metochion) of the Holy Sepulchre monastery of Jerusalem 1 . Part of the original text, barely visible under the Euchologion, was transcribed and published by Johan Heiberg between 1906 and 1915 [4,5]. We do not know exactly what happened of the palimpsest between 1920 and 1998, save that it absorbed much humidity, which made the ancient ink to become corrosive, thus eat-ing the parchment, and favored the formation of molds. By the effect of humidity, the parchment also tends to assume the three-dimensional shape of the original skin, thus suffering heavy geometrical distortions. More-over, an unknown forger re-erased four pages to paint gold miniatures of the Gospels on them. The manu-script is now being physically restored. In the same time [3,8,9], teams of imaging and image processing special-ists are trying to get as much information as possible from the book, in order to help the interested scholars, who, rather than working on the physical manuscript, are carrying out their studies on the digital material.
The disciplines and the scholars involved in a com-plete study of this book are very diverse, and all of them need support from diverse technological branches. Both texts are of interest to paleographers, and both need to be transcribed. The Archimedes text needs to be ana-lyzed by historians of mathematics, while the Eucholo-gion needs to be analyzed by Byzantine liturgists. Some of the parchment used for the Euchologion does not come from the Archimedes original, as it contains non-Archimedes texts, which also need to be identified and studied. Moreover, the provenance of the palimpsest needs to be researched by historians.

Transcription and translation are not the only issues of interest in the palimpsest. A database as complete as possible should be ready by the time when the original will be returned to the owner and only digital data will remain available to the public. This is a common issue with ancient manuscripts, which cannot easily be han-dled physically. Furthermore, for many reasons, most of our (even recent) archival heritage would take advan-tage of digital storage techniques. In this respect, the dig-ital restoration of document images could well be useful for accessibility and further study. For example, translat-ing a text in machine-readable form for remote access or search by content is a task that can be greatly accelerated by optical character recognition systems. The latter im-prove dramatically their performances when input with  X  X lean X  digital images [16,20], where the geometrical distortions, the possible interfering texts and the other degradations present in the original pages are removed as much as possible.

We experimented a number of techniques to digitally restore document images from data captured at different spectral bands [17,18]. One such data set can obviously be obtained from single color images, by separating the red, green and blue channels, or from specialized imag-ing systems, such as multispectral or hyperspectral cam-eras, or high-resolution imaging spectrophotometers. In some cases, our approach is not only able to clean the text from the interfering patterns, but also to separate each single pattern from the others, so as to obtain, e.g., a clean main text image, the interfering text pattern, the mold pattern, the parchment pattern, and so forth.
Our data model provides a linear mixture of differ-ent classes, each characterized by a different emissivity spectrum. Each of these classes represents one of the different patterns present in the page, and is considered to have an average value in each component (channel) of the data. These values form a (usually unknown)  X  X ix-ing X  matrix. Each pixel in one of the images contains the contribution from the local intensities of all the clas-ses, multiplied by the relevant mixing elements. Owing to the simplicity of our model, the separation methods that can be derived from it do not reach good results in all the cases. However, although separation is not always allowed, in many cases we obtained very inter-esting results.

The main difficulty with the separation problem is that the mixing matrix is unknown. Thus, we should rely on  X  X lind X  techniques to recover the different classes. Principal component analysis (PCA) [2] is one of the approaches we used to process our image data. It ex-ploits the eigenvalue decomposition of the data covari-ance matrix to produce mutually orthogonal outputs characterized by maximum variance in each principal direction. This can be seen as a different color space rep-resentation of the document, where the new colors are spatially decorrelated from each other. From the obser-vation that the classes are much less correlated than the observed reflectivity maps, we can intuitively expect that each color in the new representation could be a map of one individual class. A further step is the so-called inde-pendent component analysis technique, or ICA [6], in which, besides decorrelation, mutual independence be-tween the output channels is required. When the source classes are actually independent of each other, ICA tech-niques ensure the recovery of both the spatial distribu-tion of the classes and their mean reflectance indices (the mixing coefficients), with no need for any further information.

Early in 2004, the Archimedes project management invited us to contribute the ADITUP conference 2 .After some experimentation on the palimpsest images that were made available, we proposed to use our techniques to separate the Archimedes text. The digital images were captured either by an ordinary color camera, under visi-ble or ultraviolet illumination, or by a hyperspectral sys-tem equipped with a set of glass filters and a narrowband liquid-crystal tunable filter. Our results with the hyper-spectral images were encouraging, since an enhanced version of the Archimedes text was always obtained. For this reason, our opinion is that statistical process-ing can be used to extract the underwriting from ancient palimpsests (seealso[19]). Thepresent priority, however, is the transcription and the edition of the Archimedes text [10 X 13]. To perform their task, the scholars do not need very sophisticated image processing, but very accu-rate copies of the original, where ideally no detail is lost. In fact, pseudo-color images containing ultraviolet flu-orescence components are also being used, since they help in distinguishing the ancient text from the Euchol-ogion. Conversely, no attempt made to isolate the orig-inal text has been accepted by the scholars so far, since they perceive the risk of loosing useful details. Although the techniques proposed here will not be used for pro-duction imaging in the Archimedes project, we think that they can be of interest in palimpsest image process-ing, either to provide complementary information or to serve other documentation and archival purposes.
The main weakness of our approach is at present the linear data model, which is too simple to account for the complex phenomena that cause the peculiar dis-tortions often affecting ancient documents. In devising more physically sound data models, however, it is to con-sider that these should not be too complicated, in order to avoid excessive computational needs . This is one of our future research topics.

The paper is organized as follows. In Sect. 2, we for-malize the problem, introducing our data model and our solution strategies. In Sect. 3, we present some of our experimental results with Archimedes images. Some remarks are given in the concluding section. 2 The problem A multispectral scan of a document page is a registered vector image captured from the original by illuminat-ing it with light at different wavelengths and filtering the scattered light on different bands. This definition contains both the case of ordinary color pictures and the cases of multichannel acquisitions in the visible and non-visible ranges. The acquisition, in turn, can be made by reflection, transmission, or fluorescence. Each pixel of our scan (of index t in a total of T ) has a vector value x ( t ) with N components, where N is the total number of observation channels.

The information contained in any multispectral scan comes from the different patterns appearing in the page. To illustrate by an example, let us look at the image in Fig. 1. This is part of a color image taken from leaf 017 r of the Archimedes palimpsest, where different patterns are identifiable. The Euchologion text is quite evident in the foreground. Rotated 90  X  with respect to the Euchol-ogion, the Archimedes text is barely visible in the upper and lower-right parts of the picture. The two different texts are orthogonal to each other because the original text was written, double-column, on pages measuring approximately 19 cm  X  28 cm. When the parchment was reused, these pages were rotated, folded and rebound, and the Euchologion was written single-column on the new pages, measuring approximately 14 cm  X  19 cm. The Euchologion text now appears brown, while the rem-nants of the erased text appear ochre. Other typical pat-terns interfering with the texts can be noted in the image. Some molds are clearly visible in the right-hand side of the image and, with some magnification, the typical skin pattern of the parchment would also be apparent. Moreover, a third text pattern is visible; this is related to the red-ink rubrication added to the Euchologion in relatively recent times: the  X  X  X  that can be seen at the lower-left corner is a part of this rubrication. Hereaf-ter, we refer to these component patterns as  X  X ource images X .

The multispectral scan will be the result of some kind of combination of the different sources. In building our data model, we make two strong assumptions about our source images and the way they combine to form the observed images:  X  The source images related to each component pat- X  In each observed channel, the sources simply add The algorithms that can be derived from these assump-tions are very simple and, although the hypotheses are not strictly verified, the results are often impressive.
Let us suppose that a certain multispectral scan contains contributions from M distinct sources. Let the M -vector s ( t ) represent the collection of the source spatial templates at pixel t , and let A ij be the spectral signature of the i th source in the j th channel. From our first assumption, the contribution of the i th source to pixel t of the j th channel image will be:  X  s ( t ) = A where A ij does not depend on t . Strictly speaking, the i th source at each pixel should be specified by functions  X  s ( t ) for all j . By virtue of relation (1), however, this can be done by means of a single s i ( t ) . From our second assumption, the observed value at the t th pixel in the j th channel is given by the summation over i of the M values of type (1). In matrix form, we have: x ( t ) = A s ( t ) , t = 1, 2, ... , T .(2) Equation (2) suggests that our data set can be viewed as a collection of T samples from a random N -vector x , which is generated by linearly and instantaneously mixing the components of a random M -vector s through an N  X  M mixing matrix A . Estimating s ( t ) from x ( t ) when A is also unknown, is referred to as a problem of blind source separation. In general, a more complete, yet linear, model should be convolutive rather than instan-taneous, and should contain a noise contribution. This model is appropriate for some degradations often found in document images [15], but we neglected these aspects in the present application. Assuming a linear mixing is another rough approximation. To mention just one aspect, the colors of the two texts do not compose line-arly in the zones where they overlap, since the Euchol-ogion practically hides the underwriting. In these zones, the patterns reconstructed from our model may show significant gaps. Furthermore, many molds have totally eaten the parchment, and no linear combination of, say, text and molds can be expected where this has hap-pened. Attempting to derive more realistic models is anything but trivial. On one hand, indeed, such models would probably depend strongly on the particular docu-ment treated: as an example, in [15], a nonlinear model is only derived for the show-through distortion. On the other hand, complicated models are likely to require complicated processing.

Let us come back to our linear model. When an ordi-nary RGB scan is available, vector x ( t ) has size N = 3. By using multispectral or hyperspectral sensors, instead, the  X  X olor X  vector can assume any size. To solve the sep-aration problem in the case of the Archimedes palimp-sest, we should first identify a number of spatial patterns whose pixels are characterized by the same spectral sig-natures. In order to reach our goals by using the data model described above, the original Archimedes text and the Euchologion text should constitute two sepa-rate sources. Also, we tentatively assumed the parch-ment and the mold patterns as two additional sources. These assumptions can be justified by observing that the colors associated to the different patterns are approx-imately uniform across the document. Our choice can also be justified on statistical grounds, to be detailed elsewhere in this paper.

If no additional assumption is made, solving (2) is an underdetermined problem, since any full-rank matrix A can give an estimate of s ( t ) that accounts for the evidence x ( t ) . However, Equation (2) represents a collection of T linear systems. Provided that they form a statistically significant sample, they can be treated statistically. We applied this principle to several problems in document image analysis and restoration, taking the due peculiar-ities into account [17 X 21]. The theoretical bases of blind source separation can be found in [1,2,6,7], among oth-ers. In this paper, we focus on our specific application, and the theoretical foundations are just summarized.
Although the linear model is not fully justified, it is well known that linear data processing can help to re-store color text images. One can try to maximize the information content in each component of the data vec-tor by decorrelating the observed image channels. This gives a representation of the data in a sort of transformed color space, where the now uncorrelated components can coincide with the single classes. As an example, in [14], the authors compare the effect of many fixed linear color transformations on the performance of a recur-sive segmentation algorithm. They argue that the linear transformation that obtains maximum-variance compo-nents is the most effective. They thus derive a fixed combination that, for a large class of images, approx-imates the Karhunen X  X oeve transform, which is known to give orthogonal maximum variance output vectors. The Karhunen X  X oeve approach is also called PCA, and one of its purposes is to find the effective dimensionality of a set of variables [2].

To avoid cumbersome notation, and with no loss of generality, let us assume we have zero-mean data vec-tors. To decorrelate our data, we should find a linear transformation y ( t ) = W x ( t ) such that y i y j = 0 for all i = j , where W is an M  X  N matrix and the notation  X  means expectation. Our N  X  N data covariance matrix is: R Since the data are correlated, matrix R xx will be non-diagonal. The covariance matrix of vector y is: R To obtain a vector y whose components are mutually orthogonal, R yy should be diagonal. Let us perform the eigenvalue decomposition of matrix R xx , and call V x its eigenvector matrix, and x the diagonal matrix of its eigenvalues, sorted in decreasing order. It is easy to verify that the choice W yields R yy = x .Matrix W o realizes the above-mentioned PCA approach. The variables x i , however, are not uniquely orthogonalized by W o : a simple scaling still gives orthogonal vectors. For example, matrix W gives orthogonal vectors whose covariance matrix is the N  X  N identity ( whitening ,or Mahalanobis transform ). Furthermore, any rigid rotation of an orthonormal set still gives an orthonormal set. Thus, matrix W is still a whitening matrix, with the additional property of being symmetric.

Calculating the eigenvalues of R xx can also be useful to determine a posteriori the number of sources present in the data images. Indeed, if the size of the data vector is larger than the number of classes (i.e., N &gt; M ), then a number K &lt; N of eigenvalues will be dominant on the others, all the remaining having a magnitude compara-ble to the noise. Any further processing on the K prin-cipal components, that is, on the eigenvectors related to the K dominant eigenvalues, should be equivalent to processing the entire data set. In other words, the pres-ence of K dominant eigenvalues allows us to infer either that the data contain K different sources, or that any possible additional source has a negligible energy.
Let us suppose now that, besides being uncorrelated, the sources are mutually independent, and their statis-tical distribution is nongaussian. In this case, the ICA principle [1,7] assures that both A and s can be esti-mated from x . The independence assumption can be enforced through a factorized joint prior density for s : P ( s ( t )) = To find a matrix W ICA such that vectors W ICA x ( t ) are approximately copies of s ( t ) , we should maximize the joint density in (8), subject to the constraint x = A s . Several strategies have been devised to perform this optimization, or some equivalent task. Observing that a set of independent variables are also mutually uncorre-lated, it is apparent that the ICA solution corresponds to a further rotation of the set obtained from matrix (6) or matrix (7).

When M = N ,matrix W ICA is an estimate of A  X  1 , up to arbitrary scale factors and column permutations. Hence, being w i the i th row of matrix W , each vector  X  s = w scale factor. However, since there is no apparent phys-ical reason why our sources should be independent, no ICA-based algorithm is assured to achieve separation. The procedures outlined above can be applied routinely to many types of documents. However, the lack of a physically sound data model implies that their ultimate validation must be experimental. 3 Experimental results We started to test the techniques proposed here with the most classical instance of a multispectral scan, namely, an RGB image. In Fig. 2a, we show a color photomi-crograph taken in the small area of leaf 017 r that is outlined in Fig. 1 (rotated by 90  X  counterclockwise). We applied operator W ICA to the three channels available. The results are shown in Fig. 2b X  X . As can be seen in Fig. 2b, the letter  X   X   X , which is barely visible in the orig-inal, is highly enhanced. In the second output, the mold pattern has been isolated and, in the third output, we note the parchment pattern and the pitted zone on the right of the  X   X   X  due to the combined corrosive effects of humidity and ink.

Thus, this is a case where independent component analysis has proved to be very effective with color im-ages from the Archimedes palimpsest. As already dis-cussed, however, there are at least two reasons why blind separation techniques can fail with document images. One is the highly approximated data model; the other is the insufficient number of data channels. The RGB images that have been shown so far, in particular, could carry insufficient information to separate more than three sources. Indeed, we already mentioned the pres-ence of at least four sources in the palimpsest pages. To overcome this difficulty, a richer data set should be cap-tured. Before showing some results obtained from one such data set, let us observe that source separation is not always a requirement. In our case, at present, the main concern is in enhancing the readability of the Archi-medes text. The analysis of the data has shown that the emissivity spectra of the Archimedes and Euchologion inks are such that the related patterns fade in the red and infrared regions. Archimedes ink, however, fades faster than Euchologion ink. Then, if we take the red channel from a color image, we do not see almost any Archimedes text, since its emissivity is approximately the same as the one of the parchment. The Euchologion text, instead, is still visible (see, e.g., Fig. 3a, taken from leaf 016 v -017 r of the palimpsest). If we illuminate the document by ultraviolet light (wavelength 365 nm) and take the blue channel from the fluorescence image, both texts will appear, as in Fig. 3b. This fact has been ex-ploited by the imaging teams at the Rochester Institute of Technology and at the Johns Hopkins University to build pseudo-color images where the two texts appear in different colors [3]. Any human observer can easily  X  X ecorrelate X  the different texts from such an image, without loosing the possibility of examining all the rele-vant details. Indeed, the two texts are seen overlapped, but are easily distinguishable. Applying the methods we are proposing here to the same data set means to decor-relate the two patterns numerically, and also to remove one of them from the output. In Fig. 3c, we show one of the outputs obtained by applying PCA to the two input images described above. A very effective enhancement of the erased text and of the diagram in the middle-lower part of the page is apparent.

The procedure we followed consists in suitably select-ing the available data images in view of the desired result. We also tried this strategy to obtain a clean Euchologion text from the hyperspectral data set avail-able. This was obtained by using a liquid crystal tun-able filter with 14 10-nm-wide channels centered at 400, 425, 450, 475, 500, 525, 550, 575, 600, 625, 650, 675, 700, 800 nm. On the basis of the observed difference between the Archimedes and Euchologion spectra, we selected a number of images where the Archimedes text was almost invisible, in the red X  X nfrared end of the spec-trum. In Fig. 4a, we show an image taken from leaf 28 v at a wavelength of 625 nm. The Archimedes text is hardly detectable. We chose this image, along with the images at 675 and 800 nm, as the input data set for a 3  X  3 symmetric orthogonalization (7). The results are shown in Fig. 4b, c. The output shown in panel (b) appar-ently represents the mold pattern, whereas the output in panel (c) is a clean Euchologion text, which can be further improved by postprocessing, as shown in panel (d). This is a sort of ad hoc strategy that can be useful to extract some particular pattern from the mixture data. Conversely, when no particular source is to be selected, we can devise a standard procedure that takes all the available data into account. In summary, the procedure is the following:  X  Find the spectrum of matrix R  X  Compute the principal component transform with  X  Apply ICA source separation on the transformed Provided that the number of observed channels is larger than the number of sources, K should equal the num-ber of sources that are above the noise level. Note that, normally, the actual source number M is not known.
In the available data set, both texts are present, as well as strong interferences from molds. We first ana-lyzed our data by applying PCA. From the spectral anal-ysis of the covariance matrix, we found that the first five eigenvalues were dominant on the others, the magnitude of the sixth eigenvalue being less than one hundredth of the largest eigenvalue. We then found the five princi-pal components of the data, by multiplying our x ( t ) by the first five rows of matrix W o defined in (5). Instead of working with the full 14-channel data set, we then applied a 5  X  5matrix W ICA to these five principal com-ponents. The results are shown in Fig. 5a X  X . In Fig. 5f, we show the result obtained by adjusting the contrast and the look-up table of the ICA output reproducing the Archimedes text. Qualitatively, it can be observed that this is a fairly clean result. The gaps that affect the characters are caused by both missing ink and over-lapped Euchologion characters. The other ICA outputs still show residual mixtures, save, perhaps, for Fig. 5c, d, which suggest, respectively, the mold and the parchment patterns.
In summary, we can say that linear statistical pro-cessing techniques promise to give good results when applied to the Archimedes palimpsest, as well as in other cases where individual patterns characterized by specific spectral signatures are to be extracted. The the-ory suggests us that a minimum-size data set with maxi-mum information content can be obtained by a spectral analysis of the covariance matrix estimated from all the observed data. However, if some specific feature is to be extracted, as we have shown with the results in Figs. 3 and 4, there can be specific strategies to choose the most appropriate data set. On the other hand, the chances to choose a good input set rely on having as many observa-tions as possible at one X  X  disposal. Hence, in our opinion, the multispectral acquisition should be made on as many narrowband channels as possible, on a wavelength range as wide as possible. Other analytical techniques, such as X-ray fluorescence, invasive chemical analysis, and so on, could also be needed to complement the optical data where necessary. 4 Conclusions The aim of our work was to assess the potential advan-tages of statistical processing on the readability of the Archimedes palimpsest. Independently of the present priorities, the usefulness of exploiting many narrow-band images on a spectrum extending beyond the visible range has been fully recognized even without further processing. In fact, new modalities of image capture are now being studied in order to help recovering those parts of the manuscript that are in the worst state, such as the areas where the parchment is strongly distorted, or where the texts are hidden under the gold paint of the forgeries. To see through gold is a problem for which new imaging approaches will be required. To extract the max-imum information from the palimpsest, a great amount of data is needed. Some of them will be best appreciated by human experts, but this does not exclude the useful-ness of processed images, as has already happened with composite visible X  X ltraviolet images. Statistical signal processing can be a powerful tool to mine the relevant information from the expectedly large data sets in this application as well as in many others.

A further aspect of the problem is to partly auto-mate the reading and transcription tasks. This cannot be intended as a substitution of the human experts in a task where they perform better than any presently con-ceivable numerical strategy, but as an acceleration of the human work. We have seen that the Archimedes text can be separated from the other classes, but several gaps do appear where this text has been covered by the overwrit-ing. Filling these gaps would be extremely useful to im-prove the readability of the text, both by humans and by automatic systems. Automatic reading absolutely needs a preliminary processing intended to remove noise and interfering material. Techniques based on pattern rec-ognition and artificial intelligence could be used to help filling the gaps and recovering partially lost words. As far as we know, studies in this direction are already under way.
 References
