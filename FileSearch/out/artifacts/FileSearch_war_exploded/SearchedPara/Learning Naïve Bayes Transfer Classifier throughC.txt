 Text classification is a well-known problem for various appli-cations. For last decades, it is beleived that a large corpus is one of the most important aspects for better classifica-tion. However, even though a great number of documents is available for training a classifier, it is practically impos-sible to achieve an ideal performance, since the distribu-tions of labeled and unlabeled documents are often differ-ent. To overcome this problem, this paper describes a novel Na  X   X ve Bayes classifier for text classification under distribu-tion difference between training and test data. The pro-posed method approximates test distribution by weighting labeled documents to cope with the distribution difference. Unlike other transfer learning which estimates the weights of labeled documents, the proposed method considers both the documents and their estimated class labels. Therefore, the proposed method naturally combines the advantages of semi-supervised learning with those of transfer learning. I.2.7 [ Artificial Intelligence ]: Natural Language Process-ing Algorithms, Performance, Verification Text classification, Distribution Difference, Kullback-leibler divergence
Text classification is a well-known problem with various applications such as information retrieval, recommendation, and so on. For the last decades it has been believed that a large corpus is one of the most important aspects for im-proving classification performance. Accordingly, there have been proposed various approaches to expand corpora for text classification.

Nigam et al. showed that the accuracy of text classifiers can be improved by augmenting a small number of labeled documents with a large pool of unlabeled documents [2]. In this work, a Na  X   X ve Bayes classifier is trained using an EM algorithm to adopt unlabeled documents. Though they showed semi-supervised learning is appealing in text classi-fication, it is assumed that the distribution of labeled docu-ments is identical to that of unlabeled documents. However, even though a great number of documents in a corpus is used for text classification, it is practically impossible to achieve ideal performance with the corpus if the distributions of labeled and unlabeled documents are different which is a common phenomenon due to the characteristics of natural languages.

Dai et al. proposed Na  X   X ve Bayes Transfer classifier (NBTC) to relax the assumption of identical distribution [1]. NBTC shows higher performance than ordinary supervised and semi-supervised algorithms under distribution difference. How-ever, it focuses on transferring the Na  X   X ve Bayes classifier to the distribution of unlabeled documents. That is, transfer-ring between the distributions is separated from training the model. Thus it does not use class-conditional probability of unlabeled documents which is one of the most importance information in semi-supervised learning.

Assume that labeled documents D l = { ( d l 1 ,y l 1 ) , ( d ..., ( d l | D l | ,y l | D l | ) } from a training distribution P labeled documents D u = { d u 1 ,d u 2 ,...,d u | D u | } distribution P 2 are given where d i is a document, y i  X  its class label, and C denotes the class label set. The trans-fer learning algorithms including NBTC estimate just P 2 ( d ) even if P 2 ( d, y ) is a key factor to estimate the weights of training examples. On the other hand, the semi-supervised learning algorithms consider P 1 ( y | d ), but they assume P P ( y | d ).

This paper proposes a novel Na  X   X ve Bayes classifier for text classification to solve distribution difference between train-ing and test data. The influence of difference between dis-tributions can be alleviated by weighting training examples according to their importance to the test distribution [3]. Thus, in order to estimate P 2 ( d, y ), both class labels of test examples and the weights of training examples should be estimated since they are not given in the data. An EM al-gorithm is used to find the (sub-)optimal parameters for the Na  X   X ve Bayes classifier with missing class labels and weights.
Learning the Na  X   X ve Bayes classifier is approached by max-imizing its a posteriori likelihood. The parameter set,  X  , of the Na  X   X ve Bayes classifier consists of P ( c j )and P ( w That is, if the parameters are grouped into sets of  X  c j {  X 
The log-likelihood is given as since the goal is to achieve t he best performance under P If P 2 (  X  ) is assumed to be uniform, log P (  X  |D l , D only on log P 2 ( D l , D u |  X  ). Log of P 2 ( D l , D u + To compute log P 2 ( D l , D u |  X  ), P 2 ( c j )and P 2 ( d D l should be defined. In this equation, P 2 ( c j )and P 2 are estimated with the weight  X  ( d )sothat for all ( d, y )  X  X  l .
 The EM algorithm is able to find a local maximum of Equation (1) where the weights  X  and the class label of test set are unknown. In E-step, Z ( k +1) and  X  ( k +1) at the ( k +1)-th time are expected using the parameter  X  ( k ) at the k -th time.
 Here,  X  is a function which estimates the weight of d  X  X  l and will be explained below.

In M-step, the parameter  X  ( k +1) is updated using Z ( k and  X  ( k +1) obtained in E-step. where D and W are defined as
The weights  X   X  X  of labeled documents are determined by a function  X  as shown in Equation (3), where  X  computes how similar P 1 ( d )isto P 2 ( d ). These weights are determined under the assumption that the density of a labeled document which shares high similarity with all documents in D u will be high even in the test distribution. From this intuition, the weight for a given labeled document d is defined as where K ( d, d u ) is a kernel function to compute a similar-ity between d and d u  X  X  u ,and  X  d u is a parameter which represents how important d u is in P 2 ( d ). Equation (6) com-putes the weight of a document d without considering its class label.

Assuming that classes are independent each other,  X ( d, D can be computed independently for each class. That is, for aclass c j  X  C , X ( d, D u ) is rewritten as where D u ( c j ) is a subset of D u of which estimated class is c .Theoptimal  X  is obtained from where KL [ P 2 |  X   X  P 1 ] is an empirical Kullback-Leibler diver-gence. Equation (8) can be converted as  X  =argmax where N c j is the number of unlabeled documents in c j .
P D u ( c j ) is a probability density function for c j . Therefore, it should meet With an additional constraint,  X  ( d u )  X  0for  X  d u  X  X  u Table 1: Synthetic tasks from 20-Newsgroup consid-ering distribution difference the optimization problem to find  X  is arg max In this paper, the solution of the optimization problem is ob-tained using Kullback-Leibler Importance Estimation Pro-cedure [4].
The proposed method is evaluated with two well-known corpora: 20-Newsgroups 1 and Reuters-21578 2 . First of all, six tasks are generated from 20-Newsgroups. Using these tasks, the performance of the proposed method under distri-bution difference between training and test data is assessed. However, the ordinary 20-Newsgroup is not designed to eval-uate under distribution difference. Accordingly, a data gen-eration process used in [1] is applied to constructing tasks from 20-Newsgroup. Table 1 shows six tasks used in the experiments.

For the evaluation of the proposed method in normal text classification environment in which distribution change is not artificially forced, both 20-Newsgroup and Retuers-21578 are used. For 20-Newsgroup, the same six tasks with Table 1 are prepared, but training and test data in each task are divided as described in the data set.

For Reuters-21578, the most widely used  X  X odApte X  is employed in this paper. Among more than one hundred topics, only five major topics earn, acq, money-fx, grain , and crude are used for the experiments. Compared with 20-Newsgroup data set, Reuters-21578 has more training documents and similar test documents, which implies that Reuters-21578 has larger labeled data than 20-Newsgroup.
Figure 1 depicts if distributions of training and test data are actually different. In this figure, the dashed lines denote probabilities of words appeared in training data for a topic  X  comp  X , while the solid lines show those in test data for the same topic. The X-axis presents the index of words and the Y-axis is their probability.
 Figure 1(a) shows the word probabilities in ordinary 20-Newsgroup, while Figure 1(b) depicts those in synthetic 20-Newsgroup in Table 1. As shown in these figures, the word http://people.csail.mit.edu/jrennie/20Newsgroups http://www.daviddlewis.com/resources/testcollections Figure 2: Performances on synthetic 20-Newsgroup. probabilities of training and test data are different for both data sets. However, it can be also noted that the distribu-tion difference in Figure 1(b) is more severe than that in Figure 1(a). This is because the synthetic 20-Newsgroup data set is artificially designed to have much difference be-tween training and test distribution.

Figure 2 shows the experimental results on the synthetic 20-Newsgroup. The proposed method is compared with the ordinary Na  X   X ve Bayes classifier (specified as  X  X B X ).a semi-supervised Na  X   X ve Bayes classifier (specified as  X  X NB X ),and the Na  X   X ve Bayes transfer classifier which does not estimate class labels of test data (specified as  X  X SNB X ).  X  X SNB X  and the proposed method are also semi-supervised Na  X   X ve Bayes classifiers. but they consider distribution difference. The only difference between the proposed method and  X  X SNB X  is that the proposed method uses Equation (7) to estimate and update  X  , while  X  X SNB X  uses Equation (6) to estimate  X  before train a Na  X   X ve Bayes classifier. In  X  X SNB X , the same kernel with the proposed met hod, a gaussian kernel with a kernel width of two is used.

As shown in this figure, the proposed method outperforms others for all six tasks. The F-measures of the proposed method and  X  X SNB X  are generally higher than those of  X  X B X  and  X  X NB X . This implies that it is beneficial to cope with distribution difference when evident difference exists in dis-tributions between training and test data. In addition, from the fact that the performance of the proposed method is higher than that of  X  X SNB X , it is inferred that it is also im-portant to consider the class labels of test data in training Na  X   X ve Bayes classifier.

As shown in Figure 1(a), distribution difference between training and test data exists even in ordinary 20-Newsgroup data set. Therefore, it is important to cope with the differ-ence even in normal text classification. Figure 3 improves this is true. As shown in this figure, the proposed method outperforms others in four out of six tasks.
 Table 2 shows the results on the Reuters-21578 data set. The proposed method achieves the best performance for earn and acq . On the other hand, SNB shows slightly better performance than the proposed method when the size of labeled documents is small. The proposed method trains aNa  X   X ve Bayes classifier focusing on the labeled documents which share great similarity with unlabeled documents of Figure 3: Performances on ordinary 20-Newsgroups test data. Therefore, when there is small number of labeled documents, the proposed method fails to improving its per-formance.
This paper has shown a Na  X   X ve Bayes classifier which con-siders distribution difference between training and test data. The distribution difference is solved by weighting the la-beled documents in training data where the weights are set to minimize difference between actual test distribution and the test distribution estimated from training distribution for all test data. When enough number of labeled documents are available in training the Na  X   X ve Bayes classifier, the class labels estimated by it is reliable and useful. To employ the estimated class labels of test data in learning the Na  X   X ve Bayes classifier, the class-wise estimation of test distribu-tion is used. Through a series of experiments, the proposed shows superior performance comparing with supervised and semi-supervised Na  X   X ve Bayes classifies which do not consider distribution difference.
 This research was supported by the Converging Research Center Program through the National Research Foundation of KOREA (NRF) funded by the Ministry of Education, Science and Technology (2009-0082262).
 [1] W. Dai, G. Xue, Q. Yang, and Y. Yu. Transferring na  X   X ve [2] K. Nigam, A. Mccallum, S. Thrun, and T. Mitchell. Text [3] H. Shimodaira. Improving predictive inference under [4] M. Sugiyama, S. Nakajima, H. Kashima, P. B  X  unau, and
