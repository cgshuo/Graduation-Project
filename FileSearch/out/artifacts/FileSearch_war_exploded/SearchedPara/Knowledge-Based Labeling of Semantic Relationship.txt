 As our command of NLP techniques has grown over the decades, the tasks which we can accom-plish have become more useful and complex: we can (to an increasing extent) answer questions, cre-ate summaries, and even create new knowledge by extracting and merging facts from large text cor-pora. To make our systems reach their potential on these tasks, we need to extend our analysis of text into deep semantics, often grounded in world knowledge. In this work, I explore the semantic relationships in several styles of English text using knowledge-driven NLP techniques as well as a novel graphical tool for the navigation of knowledge bases (KBs, or ontologies). I begin by describing a system based on aug-mented LFG-style grammar rules, appropriate for the domain-limited sentences that are required for knowledge entry by knowledge base engineers. In a subsequent system for interpreting nominal com-pounds, I rely more heavily on the knowledge al-ready stored in the knowledge base to guide a heuristic search for meaning (Tribble and Fahlman, 2006). These systems demonstrate how a knowledge base can contribute to NLP performance. During development of the systems, knowledge acquisi-tion and organization became important sub-topics. In response I began work on a graphical tool, SconeEdit (Tribble, Lambert, and Fahlman, 2006). SconeEdit allows users to navigate the semantic concepts and relations in a text corpus, guided by the rich, grounded features of these concepts in a knowledge base. With this interface as a scaffold, future work en-tails improving the analysis systems for noun com-pounds and full sentences, and incorporating these systems in a comparative evaluation of the graphi-cal and NLP-based methods for exploring semantic relationships in domain-restricted text. In addition, I will use this framework to evaluate a knowledge-based approach for the task of retrieving labeled images from a collection. One of the motivating goals of this work is to lev-erage the power of NLP tools to ease the burden of knowledge engineers who develop ontological re-sources. By converting English sentences into a semantic representation automatically, a system provides an intuitive input method for adding new knowledge. The context for this work is the Scone Knowledge Representation (KR) Project (Fahlman, 2005). The Scone KR System encompasses an inference en-gine along with a set of upper-level domain on-tologies. As with other large KR systems along the lines of CYC (Lenat, 1986), knowledge engineers create much of the upper-level KB content by hand. 
To develop a system that would address the needs of these engineers, I collected a corpus of English sentences covering the six core structure-building tasks in Scone: The resulting corpus displayed a high degree of semantic cohesion, as expected, but with a wide degree of syntactic variation. To transform these sentences automatically into the Scone KR, I developed a set of semantic interpretation functions and added them as callouts in an existing LFG-style syntactic grammar. The resulting augmented English grammar is applied to new sentences using the LCFlex parser of Ros X  and Lavie (2000). In this way, every parse constituent can be conditioned on queries to the knowledge base, allowing not only flat semantic features (e.g.  X  X s the noun animate? X ) but rich structural knowledge ( X  X oes this person own a pet? X ) to be applied during the parse. The new grammar rules produce output in the Scone KR formalism. As a result, the output can be read as the knowledge-grounded meaning of an input sentence, and it can also become additional input to the Scone inference engine, adding to the store of background knowledge or making a new query. However, the appeal of this design is limited by the fact that, as in many grammar-based systems, the rules themselves are costly to write and maintain. For this reason, I modified the approach and examined the effectiveness of a few general  X  X reference X  rules, based on syntax. In contrast with the grammar system, the search for interpretations can now be driven, rather than pruned, by domain knowledge. I tested this approach on the interpretation of noun compounds, where the lack of syntactic cues requires heavy reliance on semantic interpretation (Tribble and Fahlman, 2006). I found that a majority of compounds, even in a new textual domain, could be analyzed correctly using the new set of rules along with an appropriate domain-specific KB. While the cost of grammar writing can be reduced with updated algorithms, developing and maintaining large knowledge repositories is one of the key challenges in knowledge-based NLP: the knowledge acquisition  X  X ottleneck X . My hypothesis is that a natural-language (NL) interface is an important tool for easily modifying and adding knowledge in a complex KR system like Scone; language is an intuitive way for users to express what they want from the knowledge base. In the course of developing NL tools for the Scone Project, I also recognized the need to view domain text, domain knowledge, and the semantic relationships that they share in a  X  X napshot X . Inte-grating textual and graphical exploration gives us-ers a comfortable handle on the knowledge base, even when they don X  X  know exactly what they want. I designed the SconeEdit knowledge-and text-browsing tool (Tribble, et al. 2006) in response to this need. The tool provides an annotated view of text chosen by the user, allowing him to see what concepts and vocabulary from the text are currently in the KB. Alongside this Text View, SconeEdit provides a navigable snapshot of the knowledge base (KB View), centered on concepts that appear in the text. This unified browser establishes a principled, coverage-driven way to  X  X urf X  the KB and add new knowledge. A screenshot of SconeEdit, recently updated to view images as well as text, is shown in Figure 1. 
The SconeEdit tool has already been used by groups outside the Scone Project, for the purpose of qualitatively evaluating knowledge bases for use in new subdomains. My goal for the conclusion of this work is to synergize the lines of research described so far, building our English analysis tools into the SconeEdit interface. With the resulting tool I can run a detailed evaluation of my English analyzers, as well as shed light on the usability of text-based versus graphical knowledge entry. To bring this work to bear in a task-based evaluation, I have also started developing a system for labeled image retrieval. To retrieve images of interest from large collections, traditional systems rely on matching between a high-level query and low-level image features, or on matching the query with an unordered bag-of-words that has been at-tached to each image. In current work I am inves-tigating sentence fragments, which retain some syntactic structure, as a useful style of image anno-tation that is complementary to the current bag-of-words style. Analysis of 2,776 image titles downloaded from the web establishes that frag-ment-style labels are intuitive, discriminative, and useful. 
These labels can be used to retrieve images from a collection in the following way: first, a typed query is given to the system (e.g.  X  X eople petting their dogs X ). An English analyzer, using im-provements to the techniques described in Section 2, produces the Scone semantic representation of this query (a semantic graph). Next, the Scone inference engine is used to match the query against pre-computed semantic representations of the im-age labels. The system retrieves the image whose label matches best. Figure 2 is an example re-trieved for this query by Google Image Search. In order to train the functions that measure a  X  X atch X  in the knowledge base, as well as to im-prove the English-to-Scone analysis, I need train-ing data in the form of images, their fragment-style labels, and one or more query that matches each image and its label. 
I collected one corpus of images with their fragment-style labels from the publicly available collection on Flickr (http://www.flickr.com). A second corpus of fragment-labeled images has been provided by one the authors of von Ahn and Dabbish (2004). In many cases, a single image has multiple fragment-style labels. To convert this data into the format I need, I can use the redundant labels as substitute  X  X ueries X , under the assumption (which should be validated experimentally) that image-retrieval queries often take the form of sen-tence fragments, as well. 
An evaluation that uses these labels for image retrieval will proceed as follows: A subset of the labeled images which were not seen or used in previous work will be reserved as test data. Re-maining images with their labels and queries will be used to improve the English-to-Scone analysis system and the semantic similarity functions within Scone. Finally, the queries for the test set will be submitted to the retrieval system, and system re-sults will be compared to the  X  X orrect X  images given by the test set. Precision and recall can be calculated under a variety of conditions, including one-image-per-query and several-images-per-query. Comparison to shallow techniques for label matching, as used with bag-of-words style labels, will also be a feature of this evaluation. 
In summary, I have presented a body of work on exploring and labeling the deep semantic relation-ships in English text. A grammar-based system for sentences and a heuristic search system for noun compounds explore the role of domain knowledge in tools for syntactic and deep semantic analysis. In addition, I designed and demonstrated graphical tool for exploring rich semantic features in text, grounded in a knowledge base or ontology. The tool has been used by our own knowledge engi-neers as well by other research teams at CMU. 
I will build on this work in the coming months as I prepare for two evaluations: a study on the usability of natural language and graphical tools for navigating a knowledge base, and a task-based evaluation on labeled image retrieval. These evaluations should bring closure to the work as a contribution in the field of semantic analysis of text. 
