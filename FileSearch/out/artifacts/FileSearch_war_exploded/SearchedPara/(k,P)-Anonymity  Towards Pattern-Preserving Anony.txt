 The challenges with privacy protection of time series are mainly due to the complex nature of the data and the queries performed on them. We study the anonymization of time series while try-ing to support complex queries, such as range and pattern similar-ity queries, on the published data. The conventional k-anonymity cannot e ff ectively address this problem as it may su ff tern loss. We propose a novel anonymization model called (k,P)-anonymity for pattern-rich time series. This model publishes both the attribute values and the patterns of time series in separate data forms. We demonstrate that our model can prevent linkage attacks on the published data while e ff ectively support a wide variety of queries on the anonymized data. We also design an e ffi cient algo-rithm for enforcing (k,P)-anonymity on time series data.
Time series has long been considered one of the most impor-tant types of data available in both nature and human society. The publicity of time series data on the Internet has nurtured the most creative applications ranging from financial analysis to social com-munity tracking and partner matching. However, such massive data also implies vast amount of privacy, which, if not appropriately pro-tected, may become exploited as a source for abuses and crimes.
Inconsistently, the problem of privacy protection in time series data publishing has not yet been well studied to date. The chal-lenges are mostly due to the complex nature of the data and the way that they are used. In particular, the spectrum of frequently-used  X  X omplex X  queries on time series covers not only range queries on the attribute values at specified time instants but also pattern sim-ilarity queries which treat each sequence more globally. Unfortu-nately, it is no trivial task to support such variety of queries without disclosing the sensitive information of individuals.

Specifically, we consider an essential problem of anonymizing time series while trying to support the queries mentioned above. For example, in a de-identified database of monthly sales of com-panies, users may issue query for companies (each as a time series) that perform well by specifying 1. Range queries which specify value conditions, such as  X  X he 2. Pattern similarity queries which specify pattern conditions,
Meanwhile, it is critical to ensure that no identifiers of these companies will be disclosed. However, the time-sensitive attribute values and their patterns can be used as strong quasi-identifiers (QI) to launch linkage attacks which re-identify some of the records (time series).

The conventional solution to prevent linkage attacks is to enforce k-anonymity on the published database. Although conventional k-anonymity can be used to resist linkage attacks, it cannot e preserve the patterns, which are critical for performing queries on time series. A few previous studies [3, 4] have proposed methods to anonymize sequences or trajectories by k-anonymity. In [3] Nergiz et al. proposed a method called perturbation-driven k-anonymity. As this method publishes data by firstly enforcing k-anonymity and then reconstructing randomly a trajectory from the anonymization, it is prone to significant pattern loss. Another work in [4] proposed the so-called pattern-preserving k-anonymity for sequences of a fi-nite item set, and employed a prefix tree to realize anonymization. However, the pattern similarity that this work considers is only lim-ited to exact string match. It is therefore not applicable for more general time series data. In summary, we believe that no previous work has adequately addressed the anonymization of time series, considering even the most frequently-used (range and similarity) queries to answer for in the published database.

We advocate an approach which explicitly preserves and pub-lishes the patterns of time series in a separate form of data, namely pattern representations (PRs). This approach will inevitably intro-duce a series of new problems, such as the definition, generaliza-tion, representation, and measurement of patterns. It is even more important to observe that pattern representations, too, may be used for linkage attacks. Thus we need to consider the possible attacks after publishing the PRs. And the probability of privacy breach af-ter the anonymization and the information loss during this process must be re-examined. Intuitively, the objective of our approach is to constrain the breach probab ility under a specified value while trying to minimize the information loss.
By segregating the patterns, we propose a novel model called (k,P)-anonymity, which ensures anonymity on two levels. On the first level, k-anonymity is required for time series in the entire database. On the second level, P-anonymity is required for the pat-tern representations associated with each record in a same group. As a result, the (k,P)-anonymity model is able to resist unified at-tacks based on both the attribute values and the patterns of the time series, with a worst disclosure probability of 1 / P .

Our contributions are summarized as following:
The conventional k-anonymity of time series assumes that each original time series (record) r in a database T contains the following three parts of data: (1)an identifier id ; (2)a set of quasi-identifier (QI) attributes at n di ff erent but typically consecutive time instants, denoted by A 1 , A 2 ,..., A n ; (3)a set of sensitive attributes which is denoted by A S as an entirety.
 During the anonymization, all records are de-identified, and each QI attribute A i is generalized into a value range R i = [ r creats in e ff ect a number of anonymization envelopes on the QI at-tributes. Each envelope, lower-bounded by sequence ( r  X  1 records. Records belonging to the same envelope are called an anonymity group . To avoid confusion we use term k-group to refer to such anonymity group.

We now illustrate how the conventional k-anonymity fails to pro-vide support for queries by pattern conditions. Table 1 and 2 show a micro data set of personal income and its anonymized version (The tuple ID of table 2 is deliberately kept for clarity). We regard the income of the past six years as the QI attributes, and that of the current year as the sensitive attribute. For a user interested in the correlation of the income of consecutive years, she may want to find out whether the income of 2005 is higher than that of 2004 for all records. She will sadly find the published data useless because the value ranges of year 2004 and 2005 significantly overlap each other on each record. In this particular case, the correlation among di ff erent QI attributes are not preserved.

Motivated by this example, we attempt to preserve and publish time series patterns in a separate form of data in our approach. Ap-parently, this objective depends on the proper definition and repre-sentation of patterns.
According to [1], patterns of time series include trends and sea-sonalities. In whatever forms, a pattern can be taken as a set of features. Given a number of attributes of time series, denoted by A ,..., A attributes. where Y is a domain of any arbitrary values. For example, one feature might be a function checking if the second attribute value is greater than the first one. In such case the feature is f ( A its possible values are  X  &gt;  X ,  X  &lt;  X , or  X  =  X .

A pattern of a time series r is a feature vector of m correlation functions where m is a system parameter. The patterns of two time series are said to be similar / equal , if their respective feature vectors are similar / equal.

The above definition to pattern is very generic. In one special case, a pattern can be the time series itself if we define f i = 1 ,..., n . Therefore, we believe that such definition can virtu-ally capture almost all kinds of correlations among the attributes of time series. We note that our definition of time series patterns is consistent with the one given in a more generic background [5].
In practice, however, it may not be possible for data owners to define a set of correlation functions for describing the patterns ap-pearing in each time series. Thus, we need more concise formats to describe patterns and they are called pattern representations .For-mally, given the m correlation functions defined for patterns, a pat-tern representation (PR) of a time series is an entity which 1. can be obtained by a transformation M (  X  ) from the time se-2. can be transformed to a pattern determinedly.

The second item of the above ensures that a pattern can be recon-structed from its PR. Given a time series r , we denote by PR [ r ] M ( r ) its pattern representation. There may certainly be informa-tion loss, specifically called pattern loss , caused by the transforma-tion M (  X  ). As a result, the reconstructed pattern might be distorted. Therefore, a key requirement for the PR transformation M ( minimize the pattern loss PL , which is measured by the distortion after pattern reconstruction.

In the literature, there exist a great many well-known pattern rep-resentations for pattern similarity matching, including SAX, PAA, APCA, and PLA etc. As the reader will see, one of the greatest advantages of our approach is that it can potentially adopt any of these PRs in the published data.
Before introducing our anonymity model, we shall look at both the data that we try to publish and the possible attacks based on such data. Generally, each record r  X  in the published database T contains three parts,
Subsequently, the background knowledge of an adversary may come from (1) the values of the QI attributes, denoted by K the whole QI pattern or part of it, denoted by K p . Thus, we are able to derive three linkage attacks, from the two types of background knowledge, as following:
The quantitative measure of privacy attacks relies on the notion of privacy bre ach pr obability . Regarding the above three linkage attacks, the privacy breach probability is defined as following. D efinition 1. (Privacy breach probability) For one time series Q being considered as a target in database T, the privacy breach probability fo r Q, denoted by P breach [ Q ] , is the probab ility that an adversary can infer from T  X  that Q . id becomes associated to the value of Q . A S based on the background knowledge K v K p P privacy of Q is breached.

Therefore, the problem that we tackle is to generate a T  X 
In this section, we introduce the (k,P)-anonymity model to ad-dress the problem described in Section 2.3. We also look at the characteristics of the proposed model and an algorithmic frame-work to enforce it.
We now present the (k,P)-anonymity model first. Our approach assumes that each time series is published in three components, namely the generalized QI attributes ,the QI pattern representation , and the sensitive information . For clarity of presentation, the (k,P)-anonymity model can be described as a conceptual extension of the conventional k-anonymity. Nevertheless, the algorithm to enforce (k,P)-anonymity does not rely on the conventional k-anonymity al-gorithm.

As Figure 1 illustrates, our model ensures anonymity on two lev-els. On the first level, the QI attributes are generalized to fulfill the conventional k-anonymity, regardless of the QI pattern repre-sentation. The results of the generalization contain a number of partitions known as the k-groups . We note that the generalized QI attributes are analogous to those in conventional k-anonymity. The second-level anonymity considers records in each k-group. For any record r in a k-group, if there exist at least P  X  1 other records
Figure 1: The k-groups and P-subgroups of (k,P)-anonymity which have the same pattern representation as r , we say that P-anonymity is enforced for this k-group. As a result, we can parti-tion the k-group further into subgroups, each of which contains at least P records having the identical PR.
 A generalized database T  X  is said to satisfy (k,P)-anonymity if P-anonymity is enforced on all k-groups. (k,P)-anonymity can be defined as following:
D efinition 2. ((k,P)-anonymity) Let T be a database of time se-ries, and A 1 ,..., A n being the QI attributes. A published database T containing the generalized QI attributes is said to satisfy (k,P)-anonymity, if T  X  meets the following two requirements:
Table 3 illustrates one possible output scheme conforming to (k,P)-anonymity for the running example. In the published data set, there is a PR column which adopts an alphabetic string repre-sentation.

So far our model is still based on the most primitive k-anonymity model which enforces no constraints on the distribution of sensitive attribute values. In the future work, we will discuss the technique to adapt our model to l-diversity based on data transformation.
The utility of (k,P )-anonymity model should be measured on two aspects: the privacy breach probability and the information loss. The breach probability (Definition 1) of the (k,P)-anonymity model is evaluated under the assumption that the sensitive attribute infor-mation A S is unique across each k-group. This is a strong assump-tion similar to the l-diversity constraint. Under such assumption, for the three attacks defined in Section 2.3, the worst-case privacy breach probab ilities of (k,P)-anonymity are all 1 / P .Due to space limit, the proof of this result is not given in this paper.
Now we forward to discuss the information loss. When publish-ing data conforming to (k,P)-anonymity, we can observe two types of information loss, namely the instant value loss ( VL ), and the pattern loss ( PL ).

A few models have been proposed to measure the instant value loss, such as discernibility model, normalized average equivalence class size metric, and normalized certainty penalty. In this paper we decide to adopt a loss measure based on the anonymization en-velope of each group. For a time series Q belonging to QI group G , the anonymization envelope of G has a lower bound ( r  X  1 therefore given by For database T , VL ( T ) is obtained by summing up the instant value losses of all its members.
The pattern loss metric should be defined based on the feature vector p (  X  ) as we proposed in Section 2. For any time series Q ,we can obtain its feature vector p ( Q ), which represents the pattern in-formation embodied in the original time series. Meanwhile, we can obtain from PR [ Q ] the reconstructed feature vector p  X  represents the pattern information preserved in PR [ Q ]. Therefore, the pattern loss can be measured by the distance between p ( Q )and p ( Q ), namely where distance (  X  ) is a distance measure defined in the feature vector space of patterns. In our paper we use the cosine distance to calculate the pattern loss. For a whole database T , PL ( T )is obtained by summing up the pattern loss of all its members.
Now we will look at the method to enforce (k,P)-anonymity on an arbitrary micro dataset. Generally, given k and P, four steps are needed to enforce (k,P)-anonymity on a dataset: 1. Extract PR from micro data, which can fulfill P-anonymity 2. Form P-subgroups based on PRs; 3. Further divide P-subgroups whose size is larger than 2 4. Cluster resulting P-subgroups to form first level k-groups.
In the above steps, Step 1 is a challenging task and it is highly dependent on the PR being used. Di ff erent PRs may lead to very di ff erent implementations of this step. In the following, we will present a particular implementation of the framework based on the SAX [2] representation of time series.

SAX is a well-known technique for the representation of time series. Generally, a time series can be converted to an alphabet sequence, such as "baabccbc", using the SAX technique. It must be mentioned that there is a parameter level controlling in e the granularity of the SAX representation. As a result, the mapping function M (  X  ) is determined by level . If we denote by containing the first level alphabets, then the alphabets in the output sequence are all from  X  level . Now we give a formal definition of pattern described by SAX.

D efinition 3. (SAX-represented pattern of time series) For a time series r, we will get an alphabet sax qi i (sax qi i  X   X  level by SAX from r . A qi i (  X  i, 1  X  i  X  j), the SAX-represented pattern of r, denoted as PR sax [ r ] , is the alphabet sequence sax
For maximally preserving patterns, we allow di ff erent time series to have their PR sondi ff erent granularity levels. The algorithm can be divided into the following three phases. Due to the space limit, we omit the pseudo code in this paper.

Split node phase . In this phase, we aim to choose appropriate granularity level of PR for each time series in T under the constraint of P. First we will treat the whole T as the root node for split and set level = 1. Then each node will be split by gradually increasing level . Whether a node should be split or not based on its level and the node size. At the end of this phase, we put all leaf nodes in a list, denoted as leaf -list . For each leaf node, if it contains less than P time series, we call it bad -leaf , otherwise, we call it good -leaf .
Recycle bad leaf phase . The detailed implementation of this phase is shown as follows: (1) Get the highest level of all bad -leaf nodes and denote it as max -level . (2) Gradually decrease max -level until the number of all time series contained in bad -leaf nodes less than P. If any bad -leaf nodes can merge, merge them as a new node, denoted as leaf -merge .If leaf -merge contains no less than P time series, mark it as good -leaf ,elsemarkitas bad -leaf .(3) Suppress all time series still contained in bad -leaf nodes from T After this phase, all leaf nodes are marked as good -leaf . Each good leaf is actually a P-subgroup.

Group formation phase . In this phase, we aim to form k-groups based on the P-subgroup list, denoted as PGL . To minimize the instant value loss of group partition results, we perform this phase in the following steps: (1) For each P-subgroup that size split it by top-down clustering based on instant value loss. (2) If any P-subgroup contains no less than k time series, remove it from PGL and put it in the group list GL . (3) Find the P-subgroup whose internal value loss is minimal, mark it as group G . (4)Keep merging most similar P-subgroup to G with G until | G | X  k , remove all P-subgroups in G from PGL , put G in GL . (5) Repeat step 3-4 until the total number of time series contained in PGL is less than k. Merge each rest P-subgroup to the nearest group in GL .
Although k-anonymity has been widely applied on the relational data, it has drawbacks when applied on time series because gener-alization will cause pattern distorted. Until now no existing work readily remedy this drawback. We proposed a novel anonymity model, (k,P)-anonymity, relying on a generic pattern definition. Our model could e ff ectively prevent three linkage attacks and mean-while support a wide variety of queries on the anonymized data. The disclosure probability and information loss metrics for our model were also analyzed. Finally, an e ffi cient algorithm was pro-posed for enforcing (k,P)-anonymity. [1] D. Gunopulos and G. Das. Time series similarity measures. In [2] J. Lin, E. J. Keogh, S. Lonardi, and B. Y. chi Chiu. A [3] M. E. Nergiz, M. Atzori, and Y. Saygin. Perturbation-driven [4] R. G. Pensa, A. Monreale, F. Pinelli, and D. Pedreschi. [5] S. Theodoridis and K. Koutroumbas. Pattern Recognition .
