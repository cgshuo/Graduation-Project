 Ranking plays an important role in information retrieval system. In recent years, a kind of research named  X  X earning to rank X  becomes more and more popular, which applies machine learning technology to solve ranking probl ems. Lots of ranking models belonged to learning to rank have been proposed, such as Regression, RankNet, and ListNet. Inspired by this, we proposed a novel learning to rank algorithm na med GPQ in this paper, in which genetic programming was em ployed to directly optimize Q-measure evaluation metric. Experimental results on OHSUMED benchmark dataset i ndicated that our method GPQ could be competitive with Ranki ng SVM, SVMMAP and ListNet, and improve the ranking accuracies. H.3.3 [ Information Search and Retrieval ]: Retrieval Models Algorithms, Experimentation, Theory Information Retrieval; Learning to Rank; Q-measure; Genetic Programming 
Learning to rank became a more popular research area in this decade, which employs machine learning technology to solve ranking problems in information re trieval. Many learning to rank algorithms are proposed in recent years. These methods could be graded into three categories: the Pointwise approach, the Pairwise approach and the Listwise appro ach. The experimental results on Letor3.0 indicates that listwise approach generally performs better than pointwise approach and pairwise approach[1]. The input space of the Listwise approach is an entire group of a query and is more similar with the real ranking. It could be divided into two categories. The first category measures the difference between the denotes irrelevant). If the document at position r is relevant, then a gain is generated which is denoted by g ( r ) =gain ( J ( r )), else 0. 
The cumulative gain at position r in the search result list is denoted as follows: Let cg * ( r ) denotes the cumulative gain at position r in an ideal ranked list, and then AWP is defined as follows: The AWP evaluation metric seems like an extension of Average Precision, but it suffers from a serious problem. After Rank R (the number of relevant doc uments), the cumulative gain cg ( r ) in an ideal list becomes a constant. This leads to a problem that AWP could not distinguish between system A that has a relevant document at position r X  ( r X  &gt;R). In fact, system A is better than system B in terms of ranking performance. However, according to equation (2), the evaluation metric AWP could not tell the difference between the two systems. To tackle this problem, Sakai [6] proposed an evaluation measure Q-measure, which introduced the notion of bonused gain at position r : bonused gain at position r is denoted as: number of relevant documents from position 1 to r in the ranked list which could be denoted as follows. Then, the value of Q-measure evaluation metric at cutoff l is: 
The value of Q-measure is equa l to 1 when the ranked list is ideal. The parameter  X  is a persistence parameter for Q-measure. If  X  is set to zero, then Q-measure is reduced to Average Precision. Here we set  X  to 1. Since the Q-measure evaluation metric has these excellent properties, we employ genetic programming to optimize Q-measure. In the next Section, we will give the detail description of our method GPQ. 
The Genetic Programming (GP) is an evolutionary algorithm-based methodology inspired by biological evolution to find computer programs that perform a user-defined task. In Genetic Programming, a population will be initialized at first which consists of a group of individua ls. Then the whole evolution process is a series of iterative operations. At each iteration, three genetic operations will be applied to individuals in the population, named selection, crossover and mutation. The fitness is evaluated by a user-defined metric and is used to measure whether the potential solution is good or not. The genetic programming will eventually produce an individual with the best fitness. The Genetic Programming has been applied to many areas, such as Combinatorial Optimization, Machine Learning, and Image Processing. In this paper, we proposed a novel ranking algorithm GPQ in which G enetic P rogramming was employed to directly Average Precision and the multigrade relevance capability of Average Weighted Precision and could be used to multi-level relevant degrees evaluation. In the rest of this paper, we use letter  X  X  X  to denote the evaluation metric Q-measure. Hence, we take it as the fitness function in our GPQ method. When a fitness calculation process begins, we firs t decode the individual to the weights of ANN. Then training data (validation data) are inputted to the ANN and ANN gives the score of each document. Finally the value of Q-measure is calculated as the fitness over the whole queries. 
In this section, there are thr ee kinds of evolution operations, namely crossover, mutation and se lection. In crossover process, for every two individual, we execute crossover with probability Pcrossover . We utilize arithmetic crossover to generate new individuals. For original individua ls A and B, new individuals C and D, the crossover process is denoted as follows: 
The parameter  X  is a real number between 0.0 and 1.0. The new individuals generated by cr ossover will be added to the original population. In mutation process, for each original individual, we execute mutation with probability Pmutation . If an individual meets the mutation condition, a new weight will be set to a random position of the individua l. By contrast, the selection operation is very simple. The first Psize individuals will be kept. 
When select the best individual over training set S and validation set V , besides calculate the fitness of all individuals on S , we also calculate them on V . This paper uses simple sum of the value of Q-measure on S and V : 
We perform the GPQ method on the benchmark learning to rank dataset OHSUMED in LETOR3.0 released by MSLR [8]. The OHSUMED is a subset of ME DLINE, a database on medical publications, which consists of 348,566 records from 270 medical journals during the years of 1987-1991. A query set with 106 queries is used on the OHSUMED dataset, which contains 11303 irrelevant documents, 4837 relevant documents and 45 dimensions of features. The relevance degrees of the documents with respect to each query fall into three levels: definitely relevant, partially relevant or irrelevant. 
Table 1 described the parameters of GPQ which are set empirically in the experiments. The experimental results are compared with the state-of-the-art learning to rank algorithms, such as Ranking SVM, ListNet, and SVMMAP. The experimental results are listed as follows. Table 1. The parameters for the proposed algorithm GPQ Fig. 3 . The Average NDCG@k Curve on OHSUMED dataset Table 3. The t-test results on OHSUMED in terms of P@K (P@1-From Table 3, we observed that both of GPQ-Avg and GPQ-Bst significantly improve the ranking performance when compared to Ranking SVM. In terms of compared to ListNet, GPQ-Bst get a significant improvement, however GPQ-Avg didn X  X  perform well. In addition, GPQ-Avg obtaine d improvements over SVMMAP (p-value=0.0096) and GPQ-Bst also made a significant improvement compared to SVMMAP. Table 4 also gives the similar observation. For the evaluation measure NDCG, both of GPQ-Avg and GPQ-Bst significantly improve the ranking performance when compared to the baseline algorithms. 
Table 4. The t-test results on OHSUMED in terms of NDCG@K p -value Ranking SV M ListNet SVMMAP GPQ-Avg &lt;0.00001 0.0005 &lt;0.00001 
GPQ-Bst &lt;0.00001 0.00002 &lt;0.00001 
The experimental results presente d in Section 4.2 indicated that the proposed algorithms GPQ could improve the ranking performance, the reasons of this phenomenon contains two aspects at least. One hand is owed to th e excellent properties of Genetic Programming. Genetic Programming is a random global search and optimization algorithm. GP algorithm takes the encoded parameters of a ranking model as the operated object, and could break through the limitation of traditional constraints, such as continuity and monotonicity. Be sides, GP algorithm only uses objective function to search without other auxiliary information. Another good property is GP algorithm could directly optimize any evaluation measure. On th e other hand, the GPQ ranking algorithm employs the novel evaluation metric Q-measure to measure the individual (ranking model). The Q-measure is a graded version of Average Precision which inherits the reliability of Average Precision and the multigrade relevance capability of Average Weighted Precision. Hence employing Genetic Programming to directly optimize Q-measure improved the ranking performance. In addition, the time cost of ranking algorithm GPQ in each iteration mainly comes from the evolution 
