 In recent years, all kinds of information a re in rapid expansion and the texts on the Internet have grown exponentially. The text similarity computing and text search have become important information retrieval technologies.

Text search includes two main parts: text representation model and text sim-ilarity metric. Currently, there are many common text representation models [4,1,5]. However, all these methods do not consider the semantic correlation of the words in the text.

There are also many text similarity metrics [3,6]. Traditional text similarity metrics use BOW (bag of words) method which gets the words from text and statistics the frequency of each word appears in the text (such as TF-IDF). The vector space model (VSM) [4] is generally used to represent text, and then the Cosine similarity is applied to calculate the similarity between texts. However, traditional BOW-based text search methods have some disadvantages: first, the traditional methods consider that the words in the text are independent, ignore the correlation among the words; second, if two texts use two different sets of words to describe the same topic, traditional methods would get a small similarity, which cannot indicate the real text similarity.

The problem is that given a collection of texts D , a query text q , and a knowl-edge base, find a good semantic text search model, including semantic-based text representation and text semantic similari ty metric, which can represent the texts semantically and search the texts matching with the query accurately.
In this paper, we propose a new similar text search method based on Wikipedia, which considers the semantic correlation among the words in the text. This paper presents a new correlation-based semantic text similarity model, which considers not only the word frequency in the text vector, but also considers the semantic correlation among words. 2.1 Framework of Correlation-Based Semantic Text Search The framework of our method for leveraging semantic correlation among the words in the texts by Wikipedia to improve text search is presented in Fig. 1.
Firstly, we transform the texts to vector space representation (we use 2-dimension to illustrate). As the words in the texts could be semantic connected in Wikipedia, we use Wikipedia to compute the semantic correlation among the words in the texts and the query text. Then we can get a semantic correlation matrix which records the semantic corre lations between the text and the query text. Using the semantic correlation-based text Similarity metric, we could com-pute the similarity among text vectors. Finally, we can get semantic-based text search results.
 2.2 Semantic Correlation amon g Words Exploiting Wikipedia Given two words w 1 and w 2 ,let W 1 and W 2 be the sets of words that w 1 and can w 2 connect to in Wikipedia, respectively. Let Category ( w 1 )and Category ( w 2 ) be the sets of categories that w 1 and w 2 belong to in Wikipedia. We use the following formula to compute the semantic correlation between w 1 and w 2 . correlation ( w 1 ,w 2 )=(
As each text is a collection of words, the semantic correlation of two texts can be represented by a sema ntic correlation matrix M . M is a m  X  mmatrix.We use r ji to indicate the semantic correlation between w i and w j , m to indicate the total number of words in these two text. 2.3 Correlation-Based Semantic Text Similarity Model In this section, we introduce our new correlation-based semantic text similarity model (CSM). Given two texts s and t , a semantic correlation metric M ,the semantic correlation-based text similarity metric is define as follows, The s M is equivalent to s multiplying a weight matrix M . The weight matrix M associates with both s and t . We have conducted experiments on NYTimes news articles real dataset which in-cludes 300,000 documents, and the number of words in the vocabulary is 102,660. We compared our CSM approach with the TF-IDF-based Cosine (COS) and Wikepedia enhances method (WEM)[2]. We manually constructed five queries ( Q 1 ,Q 2 , ..., Q 5 ).

Fig. 2 shows the effectiveness of precision and recall when k =10.
For these five queries, WEM is a little better than Cosine method both on top-k precision and recall. But WEM so metimes has poor precision, it is be-cause WEM introduces the concepts in the Wikipedia, this may bring noise and ambiguous information. Our CSM approach performs best. Our approach CSM approach can achieve more than 0.8 top-10 precisions for these five queries. We could get both high top-10 precision and top-10 recall.

Fig. 3 demonstrates the precision and recall with different k .Asshownin Fig. 3(a), with the change of k , our CSM approach is better than COS and WEM. We can see that with different k , CSM can get high precision and recall. Our CSM approach can achieve more than 0.8 precisions and recalls.
We can also get similar results on th e precision and recall with different threshold query. In this paper, we study semantic-based similar text search. We propose a novel semantic correlation-based text search approach, which considers the Wikipedia-based semantic correlation among the words in the texts and the query text.
