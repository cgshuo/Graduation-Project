 Sampling is a standard approach in big-graph analytics; the goal is to efficiently estimate the graph properties by consulting a sample of the whole population. A perfect sample is assumed to mirror ev-ery property of the whole population. Unfortunately, such a perfect sample is hard to collect in complex populations such as graphs (e.g. web graphs, social networks), where an underlying network connects the units of the population. Therefore, a good sample will be representative in the sense that graph properties of interest can be estimated with a known degree of accuracy.

While previous work focused particularly on sampling schemes to estimate certain graph properties (e.g. triangle count), much less is known for the case when we need to estimate various graph properties with the same sampling scheme. In this paper, we pro-pose a generic stream sampling framework for big-graph analytics, called Graph Sample and Hold (gSH), which samples from mas-sive graphs sequentially in a single pass, one edge at a time, while maintaining a small state in memory. We use a Horvitz-Thompson construction in conjunction with a scheme that samples arriving edges without adjacencies to previously sampled edges with prob-ability p and holds edges with adjacencies with probability q . Our sample and hold framework facilitates the accurate estimation of subgraph patterns by enabling the dependence of the sampling pro-cess to vary based on previous history. Within our framework, we show how to produce statistically unbiased estimators for various graph properties from the sample. Given that the graph analytics will run on a sample instead of the whole population, the runtime complexity is kept under control. Moreover, given that the estima-tors are unbiased, the approximation error is also kept under con-trol. Finally, we test the performance of the proposed framework (gSH) on various types of graphs, showing that from a sample with  X  40 K edges, it produces estimates with relative errors &lt; 1 %. G.2.2 [ Graph Theory ]: Graph Algorithms; H.2.8 [ Database Ap-plications ]: Data Mining Network Sampling, Graph Streams, Statistical Estimation
A large percentage of the world X  X  population routinely use on-line applications (e.g., Facebook and instant messaging) that allow them to interact with their friends, family, colleagues and anybody else that they wish to. Analyzing the various properties of these interconnection networks is a key aspect in managing these appli-cations; for example, uncovering interesting dynamics often prove crucial for either enabling new services or making existing ones better. Since these interconnection networks are often modeled as graphs, and these networks are huge in practice (e.g., Facebook has more than a billion nodes), efficient big-graph analytics has recently become extremely important.

One key stumbling block for enabling big graph analytics is the limitation in computational resources. Despite advances in dis-tributed and parallel processing frameworks such as MapReduce for graph analytics and the appearance of infinite resources in the cloud, running brute-force graph analytics is either too costly, too slow, or too inefficient in many practical situations [33, 28]. Fur-ther, finding an  X  X pproximate X  answer is usually sufficient for many types of analyses; where the extra cost and time in finding the ex-act answer is often not worth the extra accuracy. Sampling there-fore provides an attractive approach to quickly and efficiently find an approximate answer to a query, or more generally, any analysis objective [4, 3].

Many interesting graphs in the online world naturally evolve over time, as new nodes join or new edges are added to the network. A natural representation of such graphs is in the form of a stream of edges, as some prior work noted [4]. Clearly, in such a streaming graph model, sampling algorithms that process the data in one-pass are more efficient than those that process the data in an arbitrary order. Even for static graphs, the streaming model is still applica-ble, with a one-pass algorithm for processing arbitrary queries over this graph typically more efficient than those that involve arbitrary traversals through the graph.
In this paper, we propose a new sampling framework for big-graph analytics, called Graph Sample and Hold (gSH). gSH es-sentially maintains a small amount of state and passes through all edges in the graph in a streaming fashion. The sampling probability of an arriving edge can in general be a function of the stored state, such as the adjacency properties of the arriving edge with those al-ready sampled. For example, if an arriving edge has no adjacencies to previously sampled edges we sample it with probability p , but if the edge has adjacencies we hold it with probability q . (This can be seen as an analog of the manner in which standard Sample and Hold [15] samples packets with a probability depending on whether their key matches one already sampled). Since any graph analysis algorithm involves processing only a sample of edges (and thus, nodes), gSH helps to keep runtime complexity under check. gSH provides a generic framework for unbiased estimation of the counts of arbitrary subgraphs. By varying the dependence of sampling probabilities on previous history, one can tune the esti-mation of various properties of the original graph efficiently with arbitrary degrees of accuracy. For example, simple uniform sam-pling of edges at random may naturally lead to selecting a large number of higher-degree nodes since higher-degree nodes appear in more number of edges. For each of these sampled nodes, we can choose the holding function to simply track the size of the de-gree for these specific nodes, of course accounting for the loss of the count before the node has been sampled in an unbiased manner. Similarly, by carefully designing the sampling function, we can ob-tain a uniformly random sample of nodes (similar to the classic node sampling [4]), for whom we can choose to hold an accurate count of number of triangles each of these nodes is part of.
Our framework uses the Horvitz-Thompson construction [19] in which the count of any sampled object is weighted by dividing by its sampling probability. In gSH this is realized by maintaining along with each sampled edge, the sampling probability that was in force when it was sampled. The counts of subgraphs of sampled edges are then weighted according to the product of the selection probabilities of their constituent edges. Since the edge sampling probabilities are determined conditionally with respect to the prior sampling outcomes, this product reflects the dependence structure of edge selection. The sampling framework also provide the means to compute the accuracy of estimates, since an unbiased estimator of the variance of the count estimator can be computed from the sampling probabilities of selected edges alone. More generally, the covariance between the count estimators of any pair of subgraphs can be estimated in the same manner.

In this paper, we demonstrate applications of the gSH frame-work in two directions. Firstly, we formulate a parameterized fam-ily gSH(p,q) of gSH sampling schemes, in which an arriving edge with no adjacencies with previously sampled edges is selected with probability p ; otherwise it is sampled with probability q . Secondly, we consider four specific quantities of interest to estimate within the framework. These are counts of links, triangles, connected paths of length two, and the derived global clustering coefficient. We also provide an unbiased estimator of node counts based on edge sampling. Note that we do not claim that these lists of exam-ples are by any means exhaustive or that the framework can accom-modate arbitrary queries efficiently. gSH for big-graph analytics bears some resemblance to the clas-sic Sample and Hold (SH) approach [15], versions of which also ap-peared as Counting Samples of Gibbons and Matias[18], and were used for attack detection by Smitha, Kim and Reddy [31]. In SH, packets carry a key that identifies the flow to which they belong. A router maintains a cache of information concerning the flows of packets that traverse it. If the key of an arriving packet matches a key on which information is currently maintained in the router, the information for that key (such as packet and byte counts and timing information) is updated accordingly. Otherwise the packet is sam-pled with some probability p . If selected, a new entry is instantiated in the cache for that key. SH is more likely to sample longer flows. Thus SH provides an efficient way to store information concerning the disposition of packets across the small proportion of flows that carry a large proportion of all network packets. gSH can be viewed as an analog of SH in which the equiva-lence relation of packets according to their keys is replaced by ad-jacency relation between links. But this generalization brings many differences as well. In particular, many graph properties involve transitive properties (e.g., triangles) that are relatively uninterest-ing in networking measurements (and hence, under explored). For many of these properties, it is important to realize that the accuracy of the analytics depends on the ordering of edges to some extent, which was not the case for the vast majority of network measure-ment problems considered in the literature.
In Section 2, we describe our general graph sampling framework and show how it can be used to provide statistically unbiased es-timates of the counts of subgraph patterns. We also show how unbiased estimates of the variance of these estimators can be ef-ficiently computed within the same framework. In Section 3, we show how counts of specific types of subgraph (links, triangles, paths of length 2) and global clustering coefficient can be esti-mated. In Section 4, we describe the specific gSH(p,q) graph Sam-ple and Hold algorithms. In Section 5, we evaluate our method on a number of real world networks. We estimate the counts described in Section 3 and show that the resulting sampling distributions are centered and balanced over the actual values of interest, with low relative errors and tight error bounds as the sample size increases. We also compare with prior work and show orders of magnitude improvement in relative error with small(er) use of memory. We discuss the general relation of our work to existing literature in Sec-tion 6 and conclude in Section 7.
Let G = ( V,K ) be a graph. We call two edges k,k 0  X  K are adjacent, k  X  k 0 , if they join at some node. Specifically: Without loss of generality we assume edges are unique; otherwise distinguishing labels that are ignored by  X  can be appended.
The edges in K are arriving in an order k : [ | K | ]  X  K . For k,k 0  X  K , we write k  X  k 0 if k appears earlier than k 0 order. For i  X  | K | , K i = { k  X  K : k k i } comprises the first i arrivals.
We describe the sampling of edges through a random process { H i } = { H i : i  X  [ | K | ] } where H i = 1 if k i is selected, and H i = 0 otherwise. Let F i denote the set of possible outcomes { H 1 ,...,H i } ; We assume that an edge is selected according to a probability that is a function of the sampling outcomes of previous edges. For example, the selection probability of an edge can be a function of the (random) number of previously selected edges that are adjacent to it. Thus we write where p i  X  (0 , 1] is the random probability that is determined by the first i  X  1 sampling outcomes 1 .
In this paper, we are principally concerned with estimating the frequency of occurrence of certain subsets of K within the sample. Our principal tool is the selection estimator b S i = H i link k i , which indicates the presence of k i in K . It is uniquely defined by the properties: (i) b S i  X  0 ; (ii) b S i &gt; 0 iff H (iii) E [ b S i |F i  X  1 ] = 1 , which we prove in Theorem 1 below. We recognize b S i as a Horvitz-Thompson estimator [19] of unity.
The idea generalizes to indicators of general subsets of edges with K . We call a subset J  X  K an ordered subset when written in the increasing arrival order J = ( j i 1 ,j i 2 ,...,j i &lt;  X  X  X  &lt; i m . For an ordered subset J of K we write with the convention that H (  X  ) = P (  X  ) = 1 . We say that J is selected if H ( J ) = 1 . The selection estimator for an ordered subset J of K is which is our main structural result concerning the properties of b S ( J ) .

T HEOREM 1. (i) E [ b S i |F i  X  1 ] = 1 and hence E [ b S (ii) For any ordered subset J = ( j i 1 ,...,j i m ) of K , (iii) Let J,J 0 be two ordered subsets of K . If J  X  J 0 (iv) Let J 1 ,...,J ` be disjoint ordered subsets of K . Let q be a (v) Let J,J 0 be two ordered subsets of K with J  X  J 0 be their (vi) b S ( J ) b S ( J )  X  1 is an unbiased estimator of Var( (ii) is a corollary of (i) since
Formally, {F i } is the natural filtration associated with the process { H i } , and { p i } is previsible w.r.t. {F i } ; see [35]. (iii) When J  X  J 0 =  X  , then by (ii) (iv) Is a direct corollary of (iii) (v) Unbiasedness: The case J  X  J 0 =  X  follows from (iii). Oth-erwise, E [ b C ( J,J 0 )] = E [ b S ( J ) b S ( J 0 )]  X  E [ b since E [ b S ( J )] = E [ b S ( J 0 )] = 1 . Nonnegativity: ( H ( J  X  J 0 ) /P ( J  X  J 0 ))( H ( J  X  J 0 ) /P ( J  X  J J ) /P ( J  X  J 0 ))(1 /P ( J  X  J 0 )  X  1)  X  0 , since H ( A ) H ( B ) = H ( A ) when B  X  A . (vi) is a special case of (v) with J = J 0 .
We now describe in more detail the process of estimation, and computing variance estimates. The most general quantity that we wish to estimate is a weighted sum over collections of subgraphs; for brevity, we will refer to these as subgraph sums . This class includes quantities such as counts of total nodes or links in G , or counts of more complex objects such as connected paths of length two, or triangles that have been a focus of study in the recent lit-erature. However, the class of more general quantities in which a selector is applied to all subgraphs of a given type (e.g. triangles) or only subgraphs fulfilling a selection criterion (e.g. based on labels on the nodes of the triangle) are to be included in future work. To allow for the greatest possible generality, we let K = 2 denote the set of subsets of K , and let f be a real function on K . For any subset Q  X  X  , the subset sum of f over Q is Here Q represents the set of subgraphs fulfilling a selection crite-rion as described above. Let b Q denote the set of objects in Q that are sampled, i.e., therefore J = ( k i 1 ,...,k i m )  X  Q for which all links are selected. The following is an obvious consequence of the linearity of expectation and Theorem 1
T HEOREM 2. (i) An unbiased estimator of f ( Q ) is (ii) An unbiased estimator of Var( b f ( Q )) is Note that the sum in (14) can formally be left unrestricted since terms with non-intersecting J,J 0 are zero due to our convention that P (  X  ) = 1 .
As before K denotes the edges in G ; let b K denote the set of sampled edges. Then is an unbiased estimate of the unique edge count N K = | K | . An unbiased estimate of the variance of b N K is
Let T denote the set of triangles  X  = ( k 1 ,k 2 ,k 3 ) in G , and the set of sampled triangles. Then is an unbiased estimate of N T = | T | , the number of triangles in G . Since two intersecting triangles have either one link in common or are identical, an unbiased estimate of Var( b N T ) is
X where e (  X , X  0 ) is the common edge between  X  and  X  0
Let  X  denote the set of connected paths of length two L = ( k 1 ,k 2 ) in G , and b  X  the subset of these that are sampled. Then is an unbiased estimate of N  X  = |  X  | , the number of such paths in G . Since two non-identical members of  X  may have one edge in common, an unbiased estimate of Var( b N  X  ) is X where e ( L,L 0 ) = L  X  L 0 is the common edge between L and L
The global clustering coefficient of a graph is defined as  X  = 3 N
T /N  X  . While we use b  X  = 3 b N T / b N  X  as an estimator of  X  , it is not unbiased. However, the well known delta-method [29] suggests using a formal Taylor expansion. But we note that a rigorous ap-plication of this method depends on establishing asymptotic prop-erties of b N T and b N  X  for large graphs, the study of which we defer to a subsequent paper. With this caveat we proceed as follows. For a random vector X = ( X 1 ,...,X n ) a second order Taylor expan-sion results in the approximation where v = (  X  f )( E [ X ]) and M is the covariance matrix of the X . Considering f ( b N T , b N  X  ) = b N T / b N  X  we obtain the following approximation. For computation we replace all quantities by their corresponding unbiased estimators derived previously: Following Theorem 1, the covariance term is estimated as
Node selection is not directly expressed as a subgraph sum, but rather through a polynomial of the type treated in Theorem 1(iv). Let K ( x ) denote the edges containing the node x  X  V . Now ob-serve x remains unsampled if and only if no edge in K ( x ) is sam-pled. This motivates the following estimator of node selection: The following is a direct consequence of Theorem 1(iv)
L EMMA 1. b n x = 0 if and only if no edge from K ( x ) is sam-pled, and E [ n x ] = 1 .
We now turn to specific sampling algorithms that conform to the edge sampling model of Section 2.2. Graph Sample and Hold gSH ( p,q ) is a single pass algorithm over a stream of edges. The edge k is somewhat analogous to the key of (standard) sample and hold. A matching edge is sampled with probability q . If there is not a match, the edge is stored with some probability p . An edge not sampled is discarded permanently. For estimation purposes we also need to keep track of the probability with which a selected edge is sampled. We formally specify gSH ( p,q ) as Algorithm 1.

Algorithm 1: Graph Sample and Hold: gSH ( p,q ) b
K  X  X  X  ; while new edge k do
In some sense, gSH samples connected components in the same way the standard sample and hold samples flows, although there are some differences. The main difference is a single connected component in the original graph may be sampled as multiple com-ponents. This can happen, for example, if omission of an edge from the sample can disconnect a component. Clearly the order in which nodes are streamed determines whether or not such sampling dis-connection can occur.

Clearly, gSH would admit generalizations that allow a more com-plex dependence of the sampling probability for a new edge on the current sampled edge set. This can be achieved by adapting the flexible holding function. Consequently, the details of the sam-pling scheme (holding function) should allow certain subgraphs to be favored for selection. In this paper, we do not delve into this matter in great detail, rather we look at a simple illustrative modi-fication of gSH that favor the selection of triangles X  called gSH gSH T is identical to gSH except that any arriving edge that would complete a triangle is selected with probability 1; see Algorithm 2. Obviously gSH ( p, 1) and gSH T ( p, 1) are identical. We use a simple example of a path of length 3 to illustrate that in Graph Sample and Hold gSH ( p, 1) , the distribution of the random graph sample depends on the order in which the edges are pre-sented. The graph G = ( V,K ) comprises 4 nodes V = a,b,c,d 0 0 0 0 0 0 0 1 /p 0 1 /p 1 /p 1 /p 1 /p 1 /p 0 0 0 0 0 0 0 1 /p 1 1 /p 1 /p 1 /p + 1 1 /p + 1 1 /p 0 0 0 0 0 0 0
Algorithm 2: Graph Sample and Hold for Triangles: gSH T ( p,q ) b
K  X  X  X  ; while new edge k do connected by 3 undirected edges K = { ( a,b ) , ( b,c ) , ( c,d ) } which are the keys for our setting. There are 6 possible arrival orders for the keys, of which we need only analyze 3 , since the other orders can be obtained by time reversal. These are displayed in the "Or-der" columns in Table 1. For each order, the possible selection out-comes for the three edges by the check marks X , followed by the probability of each selection. The adjusted weights for each out-come is displayed in "Weights" followed by corresponding estimate of the node degree, i.e., the sum of weights of edges incident at each node. One can check by inspection that the probability-weighted sums of the weight estimators are 1 , while the corresponding sums of the degree estimators yield the the true node degree.
We test the performance of our proposed framework (gSH T ) as described in Algorithm 2 (with r = 1 for edges that are closing triangles), on various social and information networks with 250 K X  7 M edges. For all network datasets, we consider an undirected graph, discard edge weights, self-loops, and we generate the stream by randomly permuting the edges. Table 2 summarizes the main characteristics of these graphs, such that n is the number of nodes, N K is the number of edges, N T is the number of triangles, N is the number of connected paths of length two,  X  is the global clustering coefficient, and D is the graph density. 1. Social Facebook Graphs . Here, the nodes are people and Table 2: Statistics of datasets. n is the number of nodes, N number of edges, N T is the number of triangles, N  X  is the number of connected paths of length 2,  X  is the global clustering coefficient, and D is the density. 2. Web Graphs 2 . Here, the nodes are web-pages and edges are We ran the experiments on MacPro 2 . 66 GHZ 6 -Core Intel proces-sor, with 48 GB memory. In order to test the effect of parameter settings (i.e., p and q ), we perform 100 independent experiments and we consider all possible combinations of p and q in the follow-ing range, Our experimental procedure is done independently for each p = p ,q = q i as follows: 1. Given one parameter setting p = p i ,q = q i , we obtain a 2. Using b K , compute the unbiased estimates of the following 3. Compute the unbiased estimates of the variance of the quan-Note that the estimation of the count of unique edges b N essary when the graph stream is not simple (i.e., edges may occur more than once). Table 3: Estimates of expected value and relative error, when sample size  X  40 K edges, with sampling probability p,q = 0 . 005 for web-BerkStan, and p = 0 . 005 ,q = 0 . 008 otherwise. First column shows the statistics of the full graph, SSize is the num-ber of sampled edges, and LB / UB are the 95 % lower and upper bounds respectively.

We proceed by first demonstrating the accuracy of the proposed estimators for the different graph statistics we discuss in this paper across various social and web networks. Given a sample b (collected by gSH T Algorithm 2), we consider the absolute relative statistic from the actual graph statistic of interest, where E[ est ] is the mean estimated value across 100 independent runs. Table 3 provides the estimated values in comparison to the actual statis-tics when the sample size is  X  40 K with p,q = 0 . 005 for web-BerkStan and p = 0 . 005 , q = 0 . 008 otherwise. We summarize below our main findings from Table 3:
Having selected a sample that can be used to estimate the actual statistic, it is also desirable to construct a confidence interval within which we are sufficiently sure that the actual graph statistic of inter-est lies. We construct a 95 % confidence interval for the estimates of edge ( N K ), triangle ( N T ), connected paths of length two ( N counts, and clustering coefficient (  X  ) as follows, where the estimates  X  X st X  and  X  Var( est )  X  are computed using the equations of the unbiased estimators of counts and their variance as discussed in Section 3. For example, the 95 % confidence interval for the edge count is, where UB = b N K +1 . 96 q Var( b N K ) , LB = b N K  X  1 . 96 are the upper and lower bounds for the edge count respectively.
Table 3 provides the 95 % upper and lower bounds (i.e., UB , LB) for the sample when the sample size is  X  40 K edges. We observe that the actual statistics across all different graphs lie in between the bounds of the confidence interval (i.e., LB  X  Actual  X  UB). Note that the sample is collected using gSH T Algorithm 2.
Additionally, we study the properties of the sampling distribution of our proposed framework (gSH) as we change the sample size. Figure 1 shows the sampling distribution as we increase the sam-ple size (for all possible settings of p,q in the range 0 . 005  X  0 . 1 as described previously). More specifically, we plot the fraction (represented by blue diamond symbols in the figure), where E[ est ] is the mean estimated value across 100 independent runs. Further, we plot the fractions UB Actual , and LB Actual (represented by green circle symbols in the figure). These plots show the sampling distribution of all statistics for socfb-UCLA, and socfb-Wisconsin graphs. We now summarize the findings that we observe from Figure 1: all possible samples with p,q in the range 0 . 005  X  0 . 1 . Diamonds (Blue): Actual . Circles (Green): Figur e 2: Sampling Fraction ( SSize N
Table 4: Coverage Probability  X  for 95 % conf. interval socfb-Wisconsin 0.95 0.95 0.96 0.95 Table 5: The relative error and sample size of Jha et al. [20] in comparison to gSH T for triangle count estimation web-Stanford  X  0 . 07 40K 0.0023 14.8K web-Google  X  0 . 04 40K 0.0029 25.2K web-BerkStan  X  0 . 12 40K 0.0063 39.8K Note that in Figure 1, we use a square (with orange color) to refer to the sample reported in Table 3. We also found similar obser-vations for the rest of the graphs (plots are omitted due to space constraints).

In addition to the analysis above, we compute the exact coverage probability  X  of the 95 % confidence as follows,
For each p = p i ,q = q i , we compute the proportion of samples in which the actual statistic lies in the confidence interval across 100 independent sampling experiments gSH T ( p i ,q i ) . We vary p,q in the range of 0 . 005  X  0 . 01 , and for each possible combination of p,q (e.g., p = 0 . 005 ,q = 0 . 008 ), we compute the exact coverage probability  X  . Table 4 provides the mean coverage probability with p,q = { 0 . 005 , 0 . 008 , 0 . 01 } for all different graphs. Note  X   X 
T ,  X  N  X  , and  X   X  indicate the exact coverage probability of edge, triangle, paths of length two counts, and clustering coefficient re-spectively. We observe that the nominal 95 % confidence interval holds to a good approximation, as  X   X  95 % across all graphs.
We compare to the most recent research done on triangle count-ing by Jha et al. [20]. Jha et al. proposed a Streaming-Triangles al-gorithm to estimate the triangle counts. Their algorithm maintains two data structures. The first data structure is the edge reservoir and used to maintain a uniform random sample of edges as they streamed in. The second data structure is the wedge (path length two) reservoir and used to select a uniform sample of wedges cre-ated by the edge reservoir. The algorithm proceeds in a reservoir sampling fashion as a new edge e t is streaming in. Then, edge e gets the chance to be sampled and replace a previously sam-pled edge with probability 1 /t . Similarly, a randomly selected new wedge (formed by e t ) replaces a previously sampled wedge from the wedge reservoir. Table 5 provides a comparison between our proposed framework (gSH) and the Streaming-Triangles algorithm proposed by Jha et al. [20]. Note that we compare with the results reported in their paper.

From Table 5, we observe that across the three web graphs, our proposed framework produces a relative error that is orders of mag-nitude smaller than the error produced by the Streaming-Triangles algorithm proposed in [20], and also uses a small(er) overhead storage (in most of the graphs). We note that Jha et al. [20] com-pares to other state of the art algorithms and shows that they are not practical and produce a very large error; see Section 6 for more details.

We have also compared to the work of Pavan et al. [25] and found their algorithm needs to store estimators, each of which stores at least one edge (  X  36 bytes per estimator). Their algorithm also needs at least 128 estimators to obtain good results. On the other hand, gSH T used orders of magnitude less storage to achieve even a better performance (results were omitted due to space constraints).
While Figure 1 shows that the sampling distribution of the pro-posed framework is unbiased regardless the choice of p,q , the ques-tion as to what effect the choice of p,q has on the sample size still needs to be explored. In this section, we study the effect of the choice of parameter settings on the fraction of edges sampled from the graph.

Figure 2 shows the fraction of sampled edges using gSH T Al-gorithm 2, as we vary p,q in the range of 0 . 005  X  0 . 1 for two web graphs and two social Facebook graphs. Note that the graphs are ordered by their density (see Table 2) going from the most sparse to the most dense graph. We observe that when q  X  0 . 01 , regard-less the choice of p , the fraction of sampled edges is in the range of 0 . 5 %  X  2 . 5 % of the total number of edges in the graph. We also observe that as q goes from 0 . 01 to 0 . 03 , the fraction of sampled edges would be in the range of 2 . 75 %  X  5 %. These observations hold for all the graphs we studied.

On the other hand, as q goes from 0 . 03 to 0 . 1 , the fraction of sampled edges depends on whether the graph is dense or sparse. For example, for the web-Google graph, as q goes from 0 . 03 to 0 . 1 , the fraction of sampled edges goes from 5 % to 15 %. Also, for the web-Stanford graph, as q goes from 0 . 03 to 0 . 1 , the fraction of sampled edges goes from 5 % to 25 %. However, for the most dense graph we have in this paper (socfb-CMU), the fraction of sampled edges goes from 5 % to 31 %. Note that when we tried q = 1 , regardless the choice of p , more than 80 % of the edges were sampled.

Since p is the probability of sampling a fresh edge (not adjacent to a previously sampled edge), one could think of p as the probabil-ity of random jumps (similar to random walk methods) to explore unsampled regions in the graph. On the other hand, q is the prob-ability of sampling an edge adjacent to previous edges. Therefore, one could think of q as the probability of exploring the neighbor-hood of previously sampled edges (similar to the forward probabil-ity in Forest Fire sampling).

From all the discussion above, we conclude that using a small p,q settings (i.e.,  X  0 . 008 ) is better to control the fraction of sam-pled edges, and also recommended since the sampling distribution of the proposed framework is unbiased regardless the choice of p,q as we show in Figure 1 (also see Section 2). However, if a tight confidence interval is needed, then increasing p,q helps to reduce variance. In practice, statistical variance estimators are costly to compute. In this paper, we provide an efficient parallel procedure to compute Table 6: Computation time (in seconds) of graph statistics for the full graph versus the sample output of gSH T graph Time Graph size Time SSize web-Stanford 19.68 1.9M 0.13 14.8K web-Google 5.05 4.3M 0.55 25.2K web-BerkStan 113.9 6.6M 1.05 39.8K the variance estimate. As an example, we illustrate this for the task of computing the variance of the triangle estimate ( V ar ( Section 3.3). Consider any pair of triangles  X  and  X  0 . Assuming  X  and  X  0 are not identical, the covariance of  X  and  X  0 is greater than secting in one edge e (  X , X  0 ) . Since two intersecting triangles have either one edge in common or are identical, we can find intersect-ing triangles by finding all triangles incident to a particular edge e . In this case, the intersection probability of the two triangles is P (  X   X   X  0 ) = P ( e (  X , X  0 )) . Note that if  X  and  X  0 the computation is straightforward. The procedure is very simple as follows,
Since, the computation of each edge is independent of other edges, we parallelize the computation of the variance estimators. Moreover, since the computation of triangle counts and paths of length two can themselves be parallelized, we compare the total elapsed time in seconds used to compute these counts on both the full graph and a sampled graph of size  X  40 K edges. Table 6 pro-vide the results of this comparison for the three web graphs. Note that in the case of the sampled graph, we report the sum of the to-tal computations of both the variance estimators and expected val-ues of the triangle and paths of length two count statistics. Also, note that we use the sample reported in Table 3 for these computa-tions. The results show a significant reduction in the time needed to compute triangles and paths of length two counts. For example, consider the web-BerkStan graph, where the total time is reduced from 113 seconds to 1 . 05 seconds. Note that all the computations of Table 6 are performed on a MacPro laptop 2.9GHZ Intel Core i7 with 8GB memory.
In this section, we discuss the related work on the problem of large-scale graph analytics and their applications. Generally speak-ing, there are two bodies of work related to this paper: (i) graph analytics in the graph stream setting, and (ii) graph analytics in the non-streaming setting (e.g. using M AP R EDUCE ). In this paper, we propose a generic stream sampling framework for big-graph ana-lytics, called Graph Sample and Hold (gSH), that works in a single pass over the stream. Therefore, we focus on the related work for graph analytics in the graph stream setting.

Before exploring the literature of graph stream analytics, we briefly review the literature in data stream analysis and mining that may not contain graph data. For example, for sequence sam-pling ( e.g. , reservoir sampling) [34, 6], for computing frequency counts [24], and for mining concept drifting data streams [16]. Ad-ditionally, the idea of sample and hold (SH) was introduced in [15] for unbiased sampling of network data with integral weights. Sub-sequently, other work explored adaptive SH, and SH with signed updates [11, 12]. Nevertheless, none of this work has considered the framework of sample and hold (SH) for social and information networks. In this paper, however, we propose the framework of graph sample and hold (gSH) for big-graph analytics.

There has been an increasing interest in mining, analysis, and querying of massive graph streams as a result of the proliferation of graph data ( e.g. , social networks, emails, IP traffic, Twitter hash-tags). For example, to count triangles [20, 25, 7, 10, 8, 21], finding common neighborhoods [9], estimating pagerank values [27], and characterizing degree sequences in multi-graph streams [13]. In the data mining field, there is the work done on clustering and outlier detection in graph streams [1, 2].

Much of this work has used various sampling schemes to sam-ple from the stream of graph edges [4]. Surprisingly, the majority of this work has focused primarily on sampling schemes that can be used to estimate certain graph properties (e.g. triangle counts), while much less is known for the case when we need a generic ap-proach to estimate various graph properties with the same sampling scheme with minimum assumptions.

For example, the work done in [10] proposed an algorithm with space bound guarantees for triangle counting and clustering esti-mation in the incidence stream model where all edges incident to a node are arriving in order together. However, in the incidence stream model, counting triangles is a relatively easy problem, and counting the number of paths of length two is simply straightfor-ward. On the other hand, it has been shown that these bounds and accurate estimates will no longer hold in the case of adjacency stream model , where the edges arrive arbitrarily with no particular order [20, 25].

Another example, the work done Jha et al. in [20] proposed a practical, single pass, O ( cally for triangle counting and clustering estimation with additive error guarantee (as opposed to other algorithms with relative error guarantee). Although, the algorithm is practical and approximates the triangle counts accurately at a sample size of 40 K edges, their method is specifically designed for triangle counting. Nevertheless, we compare to the results of triangle counts reported in [20], and we show that our framework is not only generic but also produces errors with orders of magnitude less than the algorithm in [20], and with a small(er) storage overhead in many times.

More recently, Pavan et al. proposed a space-efficient stream-ing algorithm for counting and sampling triangles in [25]. This algorithm works in a single pass streaming fashion with order O ( N K  X  /N T ) -space, where  X  is the maximum degree of the graph. However, this algorithm needs to store estimators (i.e., wedges that may form potential triangles), and each of these estimators stores at least one edge. In their paper, they show that they need at least 128 estimators (i.e., more than 128 K edges), to obtain accurate results (i.e., large storage overhead compared to those in this paper).
Other semi-streaming algorithms were proposed for triangle count-ing, such as the work in [8], however, they are not practical and produce large error as discussed and analyzed by the work in [25].
Horvitz-Thompson estimation was proposed for social networks by Frank [17], including applications to subgraph sampling, but limited to a model of simple random sampling of vertices without replacement.
We briefly review other research for graph analysis in non-streaming setting (i.e., static). For example, exact counting of triangles with runtime O ( N K 3 / 2 ) [28], or approximately by sampling edges as in [33]. Although not working in a streaming fashion, the algo-rithm in [33] uses unbiased estimators of triangle counts similar to our work. Moreover, other algorithms were proposed based on wedge sampling and proved to be accurate in practice, such as the work in [30]. More recently, the work done in [26] proposed a parallel framework for finding the maximum clique.

Finally, there has been an increasing interest in the general prob-lem of network sampling. For a detailed survey and comparison, see [4]. For example, to obtain a representative subgraph [22, 4], and to preserve the community structure [23], and other sampling goals [14, 5].
In this paper, we presented a generic framework for big-graph analytics called graph sample and hold (gSH). The gSH frame-work samples from massive graphs sequentially in a single pass , one edge at a time, while maintaining a small state typically less than 1 % of the total number of edges in the graph. Our contribu-tions can be summarized in the following points:
In future work, we aim to extend gSH to other graph properties such as cliques, communities, and others.

