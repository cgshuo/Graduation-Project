 Web search engines are often implemented as centralized systems. Designing and implementing a Web search engine in a distributed environment is a challenging engineering task that encompasses many interesting research questions. However, distributing a search engine across multiple sites has several advantages, such as utiliz-ing less compute resources and exploiting data locality. In this pa-per we investigate the cost-effectiveness of building a distributed Web search engine. We propose a model for assessing the total cost of a distributed Web search engine that includes the computa-tional costs and the communication cost among all distributed sites. We then present a query-processing algorithm that maximizes the amount of queries answered locally, without sacrificing the quality of the results compared to a centralized search engine. We simulate the algorithm on real document collections and query workloads to measure the actual parameters needed for our cost model, and we show that a distributed search engine can be competitive compared to a centralized architecture with respect to real cost.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Design, Performance Web search, distributed systems, query processing, cost model
Distributed architectures for search engines are a potential so-lution to the scalability problem of Web search. As data centers hosting search engine servers have limited capacity, it is critical to have a system design that can cope with the growth of the Web, and that is not constrained by the physical limitations of a data center.
On the other hand, single-site systems are attractive from an eco-nomic point of view. It is often the case that companies select the location for a new data center based on the cost of land, la-bor, and public utilities, in particular power. By considering only such factors, system architects might be overlooking the potential advantages for having many smaller data centers close to the end users [14].

Suppose that we are to design a new system for Web search for users across a number of countries. A typical solution is to use a single, centralized site, since it is a simple and competitive so-lution. However, the preference for a centralized solution often comes from a lack of understanding of the benefits and the draw-backs of a distributed solution, as it is not clear whether the benefits of a distributed architecture compensate its overheads.

An example of an important benefit of a distributed solution is the proximity of the search engine to Web data and its users. Being closer to data might impact positively the performance of crawlers, since the Web connections are shorter and fetching documents is faster (the time to download a document increases linearly with round-trip time [12]). Consequently, longer connections reduce the throughput of crawlers and front-end servers that host Web servers interacting with users. Additionally, distributing the overall work-load mitigates the problem of network bandwidth saturation, and enables redundancy and fault tolerance employing less costly con-figurations [14, 37]. A distributed architecture also enables the ser-vice to exploit the potential local properties of the workload. Lo-cality might improve the ranking by using local features.
We hence provision a site to process locally a fraction of the queries, ideally all local query traffic. In practice, achieving the goal of processing all queries locally is difficult. Some queries, called non-local queries , might require multiple sites to process them. The additional communication increases the total latency of query processing, and hence the latency for non-local queries is higher. On the other hand, local queries are processed faster. We use local queries to denote queries that can be processed by the site to which they are submitted to. We then call locality the fraction of the queries that are processed locally. Thus, if we can process many queries locally, we may be able to reduce the average latency of query processing. In addition to locality, we also look at the volume of queries for which the distributed system retrieves more or fewer clicked documents than a centralized system, assuming that a user click is an indication of relevance.

The sites that comprise the distributed Web search engine may be connected via a simple network topology, such as star, ring or clique. The algorithms we discuss in this paper assume that each site is able to communicate with each other site, possibly using a path of intermediate sites. For our experiments we use a simple star topology, which has a minimal number of connections and requires at most two hops between any pair of sites, but any other network topology is feasible, and in fact part of the design space to explore. Our contributions. In this paper we assess the feasibility of dis-tributed Web search engines comprising geographically dispersed sites. We propose a detailed cost model that includes operational costs, and enables us to answer questions of the following flavor: We use illustrative, yet realistic examples to demonstrate that a dis-tributed search engine can be more cost effective than a centralized one, assuming that there is sufficient locality in the query work-load. To our knowledge, we are the first to propose such a model to assess the operational costs of multi-site Web search systems.
We then design a query-processing algorithm that maximizes the amount of locally-processed queries, without sacrificing the qual-ity of the results. We have implemented this query processing al-gorithm, and we use this implementation in the emulation of a dis-tributed search system. Different from federated search [9], queries are processed based on geographical distance in a single site. Also, in our setting all the search sites are homogeneous and under the control of the search engine. We propose modifications to our algorithm to improve the amount of locality, and consequently performance, such as replicating documents retrieved frequently across sites. We use real document collections and real query work-loads to measure the actual parameters needed by our cost model, and show that a distributed search engine can be competitive with respect to a centralized one and at the same time be less expensive.
Building a distributed search engine involves designing and op-timizing a large number of different components. We do not claim to provide a complete solution to the problem of building a dis-tributed search engine. Our contribution instead is an evaluation of a distributed retrieval solution with respect to the utilization of important system resources such as power and network bandwidth. To our knowledge, no previous work has performed such an eval-uation. Our goal hence is not to be comprehensive, but instead to provide insight on the feasibility of distributed retrieval solutions when considering resource utilization.
 Roadmap. The organization of the paper is as follows: We discuss related work in Section 2, and introduce our basic distributed set-ting in Section 3. In Section 4 we present our cost model, and in Section 5 we provide an analysis that bridges our cost model with the query-processing algorithm that we present in Section 6. In Sections 7 and 8 we present results from simulating our algorithm on a real data set. We finish with conclusions and future research directions in Section 9.
Designing an operational distributed Web search engine presents several challenges [2]. There has been work on several pieces of the problem that we study in the context of cluster-based central-ized search engines. Brin and Page [8] describe an early version of the Google search engine. Barroso et al. [4] also discuss issues related to the architecture, cost and electrical power for the search clusters of the Google search engine. Orlando et al. [31] describe the design of a parallel and distributed search engine, and compare the performance of task parallelization, data parallelization, and a combination of the two. Risvik et al. [32] also propose an architec-ture for a multi-tier search engine, aiming to increase the capacity of a cluster by placing documents in different tiers. Also called distributed retrieval in some articles.
 There has been a number of publications on large scale crawling. Cho and Garcia-Molina look at the issues of overlap, quality and network bandwidth for parallel crawlers [13]. The design of high performance crawlers, distributed in LANs, is discussed in [21, 34]. Recently, Lee et al. reported on the implementation of a crawler running on a single machine and collecting 6 billion pages [23].
Melnik et al. [25] study the construction of a large-scale dis-tributed index, optimizing the storage and distribution of files, as well as the pipeline of reading data from disk, processing and then flushing data back to disk. Tomasic and Garcia-Molina [36] in-vestigate the organization of the inverted index for query process-ing in distributed search engines. Moffat et al. [28] compare the throughput of query processing with document partitioning, term partitioning, and pipelined query processing with term partitioning. Load-imbalance issues in term and document partitioned search ar-chitectures are discussed in [27] and [1], respectively. Bender et al. [6] explore the design space of cluster architectures for large scale search engines, and compare the cost of hardware needed, considering index partitioning, distribution of the index partitions, and the technology used for storage.

We use caching as part of our solution. Caching for search en-gines has been studied extensively in the literature [18, 33, 3].
Exposto et al. try to find the optimal locations for several Web crawlers considering the data volume and the time spent crawl-ing [17]. Li et al. study the feasibility of P2P Web search engines in terms of network bandwidth and storage space on the peers [24], and conclude that Web search using P2P technology still requires an order of magnitude more resources than available, despite a range of considered performance optimizations. Zhang and Suel combine top-k query processing with bloom filters in a P2P setting with a term-partitioned index and use bandwidth to model the cost of query processing [38]. Cambazoglu et al. use cost models to in-vestigate the benefits of distributed multi-site Web search engines in terms of relevance gains and crawling coverage [11].

None of the papers discussed above considers the real cost of crawling or searching in a multi-site configuration given by the power consumption in each site and the local network costs. Cras-well et al. [15] compare the cost of different architectures ranging from a centralized search service to a metasearch service, which forwards queries to other independent search services. The devel-oped cost model, however, refers to the search service running on a single site. For modeling the real cost of systems, we use the results on the cost of electrical power in data centers from [19].
We note that our distributed search setting is closer to tiering than to federated search [9] or metasearch [26]. As discussed in Section 1, a site processes any local query first, and only if neces-sary other sites process such a query. Federated search systems first rank sites [10, 35] and then send queries to top-ranked sites.
Our distributed query-processing algorithm uses score thresh-olds so that sites can decide when there is no need to request partial results from other sites. Ntoulas and Cho [29] have used a similar idea for pruning inverted indexes in a two-tiered architecture.
We also replicate documents frequently retrieved as top results in previous queries. The frequency with which documents have been retrieved in the past has been used for efficient query processing to sort posting lists [20].
In this section we outline the basic assumptions for our dis-tributed system and we introduce some of the notation that we will use throughout the paper. We consider the problem of de-signing a distributed Web search engine over n remote sites S = { S 1 ,...,S n } . We assume that site S i is associated with geograph-ical regions ( e.g. , states, countries, group of countries, continents), but they could also represent other types of entities (e.g., languages, domain names, network clusters, etc.). The organization of the sites does not need to be flat, and sites may have special roles. For in-stance, we can organize them hierarchically such that sites have distinct roles. Also we assume that the sites communicate with each other via some network topology, such as a star-shaped topol-ogy. Deciding the optimal network topology to use is also part of the design parameters of the distributed system architecture. We assume a collection of documents D over a set of terms T . We assume that the documents D are partitioned into two subsets: local ( L ) and global ( G ). Global documents are present in all sites, whereas local documents are further partitioned disjointly among the sites of S . That is, site S i contains the documents D such that D i  X  D j = G , for all i 6 = j and S i D i = D . We also assume that the search engine serves a set of users U , who are also assigned disjointly to the sites of S . That is, site S i U  X  X  , with U i  X  U j =  X  , for all i 6 = j , and S i U i = U .
We note that the partitioning of documents to local and global sets, as well as the partitioning of users to disjoint sites is only as-sumed here for simplicity of exposition. In practice the documents and the users may be assigned to sites in any other way and the cost model as well as the query-processing algorithm we present can extend to these cases in a straightforward way.
In real systems, a site is a data center hosting a number of racks, where a rack hosts servers and networking equipment. The total cost of ownership (TCO) of a data center is the sum of its capital costs (Capex) and operational costs (Opex). Following the model of Barroso and H X lzle [5], Capex is given by the capital costs of the data center ( e.g. , construction) and servers, both of them in cost per watt. As the capital cost of constructing a data center scales roughly linearly with the number of watts the data center has been designed for, we assume for simplicity that the total cost for the same number of watts is independent of the number of sites. We also assume that the server cost per watt is constant across site. Such costs include depreciation and interest.

For Opex, we also assume that the data center operational cost per watt is the same across sites. Although differences are likely to exist, modeling such costs is highly complex, and we instead focus on the cost of running the infrastructure as with the model of [5]. As for the operational cost of servers, electricity is the main component, in particular given the trend of higher electricity costs and server power consumption. Consequently, we concentrate on electricity costs.

As we consider settings with multiple data centers, we also in-clude the cost of communicating by looking at bandwidth costs. It is important to observe that under the stated assumptions, look-ing at the cost of electricity and bandwidth enables us to compare directly the costs of configurations using different numbers of sites.
The cost of a multi-site system is the sum of the individual costs of each site over some period of time. As we mentioned before, the cost of ownership is represented here by the power consumption. We use W ( t,i ) to denote the power consumption of site S t , and C w ( X  t,i ) to be the cost of power consumption for site S over time  X  t . Hence: We compute the cost of power consumption of a site: and u w is the cost per watt. To account for different functionality, we further split the power cost into different classes, according to the functionalities of the system: W ( t,i ) = P f W f ( t,i ) , where f is a functionality of the system, such as crawling and query pro-cessing. To estimate the power consumption of each function, we use the following: where TOPS ( i ) is the target number of operations per second ( e.g. , queries processed, Web pages fetched) that site S i performs at time t ; ` f ( i ) is the target latency to perform an operation at site S is the capacity in number of simultaneous operations for a server or a cluster, depending on the functionality f ; e f ( t,i ) estimates the power consumption per server or cluster at time t . To estimate such a value, we use the models of Fan [19] based on CPU utilization: e f ( t,i ) = m i  X  ( W idle + ( W busy  X  W idle )  X  cpu ( OPS ( t,i )) , (1) where m i is the size of a group of servers, W idle and W power utilization of a server when the CPU is idle and busy, re-spectively, and cpu ( OPS ( t,i )) evaluates to the CPU utilization of a server at time t in site S i . Note that the CPU utilization is a function of the workload at time t given by OPS ( t,i ) .

We use TOPS ( i ) , ` f ( i ) , and c f ( i ) to estimate the number of servers or clusters necessary for a particular function. We use a server when the processing unit is server. For example, for crawl-ing, we assume that each server crawls individually. For query pro-cessing, however, we assume that the processing unit is a cluster because typically systems use document or term partition to in-crease parallelism when processing a query. Although both docu-ment and term partition can potentially cause load imbalance across the servers of a cluster [1, 27], we do not address such issues here, and simply assume that e f ( t,i ) evaluates to the total amount of power used at time t .

In practice, the values of TOPS ( i ) , ` f ( i ) , and c mated from demand. For example, practitioners can determine that a given cluster of machines is able to process simultaneously c operations keeping the average latency at ` f ( i ) , and estimate that the total traffic of a site will be on average TOPS ( i ) . Also note that e ( t,i ) implicitly introduces the current traffic, since the amount of watts depends on the current traffic.

Specializing equation W f ( t,i ) to crawling and query process-ing, we have The rationale for the above equations is the following. For crawl-ing, a server at site S i can only have a given number of connections open at a time given by c c ( i ) . Given the number of pages TPPS ( i ) crawled and the average amount of time to fetch a page ` c determine the total number of servers necessary to crawl. By multi-plying by the average amount of power a server uses, we determine the total amount of power necessary for crawling at site S
For query processing, we have a similar derivation. To estimate the total amount of power, we multiply the total number of servers in a query processing cluster and the average amount of power a server uses according to Equation 1. To determine the total number of clusters, we estimate the target arrival rate of queries ( TQPS ( i ) ) and divide by the number of queries per second a cluster can pro-cess ( c q ( i ) /` q ( i ) ). There are different ways to determine the num-ber of servers per cluster. In Section 8, for example, we fix a frac-tion of the index, and each server holds such a fraction.
In a multi-site system, we also have to add the cost of commu-nicating the sites. As the rates of network circuits and services vary, we measure such a cost using the total number of bytes that we need to transfer over a period of time, and assume a function that converts such a requirement for bandwidth into currency. Typ-ically, the cost of bits per sec (bps) decreases as the total amount of aggregated bandwidth increases. That is, the price of bandwidth often increases sublinearly with the bandwidth contracted.
We then assume that the cost of bandwidth C bw ( t,i ) is a function of the total number of bytes that site S i transfers at time t . The total cost then becomes: Suppose we have two systems: System 1: System 1 has one site S 11 , and its Web collection com-System 2: System 2 has five sites { S j 2 : j  X  X  1 , 2 , 3 , 4 , 5 }} . The
We use W c i ( t,j ) to denote W c ( t,j ) for system i , and ` denote ` c ( j ) for system i . We then have that the power consump-tion to crawl all P pages with System 1 at a rate p r = P/  X  t ,  X  t being an interval of choice, is: where X represents the computation of all other variables. For simplicity, we assume that the power utilization is the same for all servers across all sites. For System 2, we have: W 2 ( t ) = p r  X  X  X   X   X  ` c 2 (1) + X
For the sake of simplicity, we assume that System 2 has been and equal to ` o , ` o &lt; ` c 1 (1) . We have that the difference is W 1 ( t )  X  W 2 ( t ) = p r  X  X  X  ( ` c 1 (1)  X   X   X  ` c 2 (1)  X  (1  X   X  )  X  ` we have that W 1 ( t ) &gt; W 2 ( t ) .

As we reduce the latency of fetching pages, we also reduce the power consumption of servers used for crawling. For example, if then the difference W 1 ( t )  X  W 2 ( t ) is 0 . 56 of W 1 a reduction of over 50% in power consumption.

Note that this simple computation does not include potential costs that might arise from having to communicate crawlers in different sites. It does show, though, that if one builds a crawler distributed across a number of sites, and that requires negligible communi-cation among crawlers in different sites, then such a crawler is cheaper compared to a centralized one.
In this section we show how our cost model enables assessing the query-processing cost of a distributed architecture. In particu-lar, we analyse a simple scenario that employs a particular network topology and makes other simplifying assumptions. Nevertheless, we believe that our analysis is illustrative and it motivates the algo-rithm we present in Section 6.
 We assume a fully-distributed system in which we have n sites. Users submit queries to the closest site, and the site either processes them locally, or it sends to all other sites. A user request is there-fore classified as either local or global, depending on the sites that process the query. Site S i is able to resolve a query it receives from a user with probability x i . In this example, we assume that x the same across all sites, and we use x to denote the fraction of the total query volume resolved locally.

Following the model of Section 4.1, we have that the cost is the sum of power costs and bandwidth costs, ignoring initial costs and remaining costs of ownership. As each site processes a fraction x of the query traffic received locally, and the remainder is processed by all other sites, we have: where:
Note that W q ( t ) is a value independent of t in this case, and therefore we simply use W q instead. We hence have that the cost of power considering only the cost of query processing is: where u w is the cost of energy given in units of currency per watt-hour ($ / Wh ) 2 . If  X  t = 30  X  24 (number of hours in a month), then we have:
The amount of traffic increases linearly with the number of global queries, and with the number of sites. We hence represent the cost
We use $ to denote the unit of a given currency, e.g. , dollars or euros. of network bandwidth as follows:
C bw ( X  t ) = X where b is the average number of bits for each request; u cost of bandwidth in $ per Mbps per month ; and  X  t is time in number of months. For this particular example, we have that T (1  X  x ) , q j = QPS n , and  X  t = 1 month: Adding the terms, we have that the total cost is given by: Cost ( 1 month ) = C w ( 1 month ) + C bw ( 1 month )
Figure 1 plots Cost ( t ) assuming that QPS = 1 (cost of one query per second). It shows how the cost varies for different fractions of locality x , assuming that u w /u bw is 0 . 01 Mbps  X  month/KWh . Fig-ure 2 shows the optimal number of sites given a ratio and a value of locality x .

In the figures, a centralized architecture corresponds to the point with value n = 1 . Inspecting the graphs we observe that, as the cost of bandwidth decreases, the distributed engine has a lower over-all cost. If instead we increase the cost of bandwidth relatively to energy, the cost of a distributed architecture becomes higher, and at some point for no value of the locality parameter a distributed engine has lower costs. In fact, the optimal number of nodes is C cels out the unit of u w u above. Hence, the optimal number grows when locality increases and when the fraction u w /u bw increases as Figure 2 shows.
It is important to note, though, that the average ratio for main western european countries changed from near 0.02 in 2007 to 0.03 in 2008 (see Figure 1), using industrial power prices from Eurostat [16] and high-end broadband prices from a UK study [30]. As the price per Mbps for large customers is smaller compared to the price for home broadband, we use a transformation factor of 100. This difference causes the ratio of u w /u bw to increase, which coupled with the fact that bandwidth becomes cheaper while electricity does not, impacts positively on the cost of distributed architectures.
As we have shown in the previous section, a distributed Web search engine can be more cost-effective than a centralized one if it can process a significant fraction of the user queries locally. To achieve this, we propose a query-processing algorithm for a dis-tributed Web search engine, which aims to maximize the number of local queries without loss in retrieval precision. Furthermore, we explore the trade-off between further increasing locality of query processing and small changes in the quality of results.
Given a query q =  X  t 1 ...t | q |  X  , represented by a set of terms, we assume a scoring function s ( d | q ) that assigns a score to each document d  X  X  that contains all terms of the query q . The ranking function we consider consists of two components. The first one Figure 1: Cost of processing with a fully-distributed architec-ture, u w /u bw = 0 . 01 Mbps  X  month/KWh . Figure 2: Optimal number of sites for different cost ratios in Mbps  X  month/KWh . is a query-independent term f ( d ) , which may combine PageRank score, other link-analysis measures, spam scores, etc. The second component consists of query-dependent terms g ( d | t j ) that measure the relevance of each document d  X  D with respect to the query terms t j , and it may combine scores such as TF-IDF, BM25, etc. For a query q =  X  t 1 ...t | q |  X  , we consider the ranking function: where w f and w g are weights for functions f and g , respectively.
We assume that higher values of the functions f , g , and s in-dicate more relevant documents. For every document d that does not contain all terms in q we define s ( d | q ) to be equal to 0 (con-junctive interpretation of queries). Notice that we do not assume anything on the class of functions to be used, f and g can be ar-bitrarily complex functions, such as neural nets, decision trees, or other, and they can combine an arbitrary number of features ex-tracted from the documents. On the other hand, the general form of ranking function in Equation (2) has some limitations, for instance it does not capture proximity of query terms in the documents. We intend to extend our algorithm for more general classes of ranking functions in our future work.

To answer a query, the search engine needs to find the docu-ments that contain all terms of the query, then evaluate the ranking function on those documents and rank the documents in decreas-ing order of their score. The top-k documents are returned as an answer to the query.

It is also interesting to consider ranking functions whose second term is the sum of query-dependent terms, instead of the average. The algorithm we propose can be extended to such ranking func-tions, even though the extension is not completely straightforward; and due to space limitations we omit the details in this version.
We first give an overview of our multi-site query processing pro-tocol and in the next three sections we describe in detail the three main phases of the protocol: indexing, propagation and query-processing. The main idea of the protocol is as follows.

In the first phase of the protocol, the index-construction phase, each site S i builds an index on the set of documents D i to it. In addition, a numeric value called threshold is computed for each term t of the documents in D i . This threshold is an upper bound on the contribution of the term t to the ranking function for a query that contains the term t . Before computing the thresholds, we assume that all sites have consistent global document frequencies so that the computed scores are comparable.

We also assume that a subset G  X  X  of good-quality documents is replicated and indexed in all sites (that is, we use partial replica-tion). We refer to the set G as the set of z globally best documents in D . We select the set G to be the documents that appear more frequently as results to the queries submitted by users (which can be computed using past logs). We note here that the thresholds computed during the index-construction phase are relative to all documents in D i except those documents that belong in the set G .
In the second phase of the protocol, the propagation phase, all sites communicate with each other and exchange information about the thresholds computed at the index-construction phase. As a re-sult, each site acquires complete information about the thresholds of all the terms in all the other sites.

The first two phases of the protocol are performed offline. The third phase is the actual online query-processing phase. Each site S handles the queries it receives by first computing the matching set of documents from its local index and ranking them according to the ranking function s . Then the site S i uses the thresholds of the other sites for the query terms to decide whether the results already computed at S i are identical to the results that would have been obtained by a centralized system.

The main idea is that using properly defined thresholds we can obtain guarantees on the quality of the partial results computed lo-cally at S i . If the guarantees are satisfied the query can be answered directly at S i without any further communication. If the quality guarantees are not satisfied, then S i needs to propagate the query to other sites to obtain partial results from those sites, and merge all partial results to a single list. In either case, the results returned to the user for all queries are identical to the results obtained by a centralized system that would have access to all the documents. Next we discuss the three phases of the protocol in more detail.
Let G be the set of globally best documents among all sites, as defined in the previous section. For a site S i and a term t the documents in the set D i  X  G that contain the term t j let D 0 ij be the documents in the set D i \ G that contain the term t . The documents in D ij are organized in an inverted-index data structure. Also for each term t j at a site S i we define the upper bound on the scoring function In other words, we build the index at S i over the documents of D G , and compute the upper bound thresholds over the documents of D \ G . For computing the thresholds b ij , we assume that the scores g ( d | t j ) are computed using the same global document frequencies for all sites S .
In the propagation phase all sites exchange information about their upper bound thresholds b ij for all terms t j . That is, each site S gets to know the upper bound thresholds b i 0 j for all other sites S 0 and all terms t j . Notice that a site must keep upper bound thresholds even for terms that are not in its documents, but storage needs are negligible if compared to the size of the inverted index.
Consider a query q =  X  t 1 ...t | q |  X  submitted at site S we want to compute the top-k documents over the whole collec-tion D . The query-processing algorithm works as follows.
First the query results are computed locally for S i . Let D the documents in T | q | j =1 D ij , that is, all the local documents in S (documents in D i plus globally best documents in G ) that contain all terms of the query q . The documents in D i ( q ) are ranked ac-cording to the ranking function s ( d | q ) , and let s i,k of the k -th document.

Now, site S i computes (locally) an upper bound b i 0 ( q ) with re-spect to each other site S i 0 , i 0 6 = i , as This is an upper bound of the score of any document residing at site S 0 that could be an answer for the query q . If at least one term is missing from the sum in Equation (3) (meaning that in site S is no document containing the corresponding term), then b of any document residing at any site other than S i that could be an answer for the query q .

Now we can test the quality of results computed at S i with re-spect to the results of a centralized system by comparing the local score s i,k ( q ) against the  X  X on-local X  upper bound b  X  Local queries. If s i,k ( q )  X  b  X  i ( q ) , then we can guarantee that there is no document in D with better score than the documents already found in S i . So S i can just return the documents computed locally. The proof of the following Lemma is simple enough and is omitted from this version of the paper.

L EMMA 1. For a query q =  X  t 1 ...t | q |  X  , a site S i ranking function s , assume that s i,k ( q )  X  b  X  i ( q ) . Then there is no document d  X  D with score higher than s i,k ( q ) that it is not returned in the list of results computed locally at site S Non-local queries. If s i,k ( q ) &lt; b  X  i ( q ) , then there is no guarantee that there are no other better documents for q in other sites. In this case, the query needs to be propagated to other sites, which in turn evaluate the query on their own local indices and return a list of partial results to site S i . The site S i should then merge all partial results and return the best k documents to the user.

We observe here that large values of b  X  i ( q ) could be due to only one (or just few) sites, while for many other sites S i 0 ual upper bounds b i 0 ( q ) might still be small. In such a case, the guarantee of Lemma 1 still holds so that no better documents can should not be propagated to such sites.
Our algorithm takes advantage of the above observation and com-pares the minimum score s i,k ( q ) with each upper bound threshold b site S i 0 and partial results are requested from that site, otherwise, the query is not propagated to site S i 0 .
 Notice that the amount of communication between sites is small. The query q propagated from S i to S i 0 is a string of typically very few bytes. The response of each site S i 0 to S i is a list of the best k results for the query q at site S i 0 . Each item in the list contains the url or other id for a document, the value of the ranking function for that document, and possibly a snippet. Also, k can be thought as a small number, say 10.
 Approximate answers. One way of reducing the amount of inter-site communication is by returning local documents, which are not the same as the results of a centralized system, but have scores that are close enough to the scores of the documents matched by a cen-tralized system. Such approximations can be implemented using the same upper bound thresholds. The idea is to relax the condition s i,k ( q )  X  b  X  i ( q ) with the condition s i,k ( q )  X  b carefully selected value of . If s i,k ( q )  X  b  X  i ( q )(1  X  ) is satisfied the query is answered from the local documents. Otherwise the query is propagated to sites S i 0 for which s i,k ( q ) &lt; b and local results are merged with the results from those sites.
This scheme guarantees that the documents returned to the query q have scores with relative difference no more than than any other document in D that it is possibly not returned by the algorithm. The value of reflects how much we are willing to sacrifice in the quality of the results as a trade-off of answering the query without inter-site communication. The value of can be site-dependent and it can be learnt from user evaluations via a machine learning algorithm; we leave this extension as a study for our future work. Phrase queries. A phrase query occurs when a user submits a query with more than one terms, and he/she expects the query to be handled as a whole phrase rather than a set of terms. Exam-ples include  X  X ew York X ,  X  X arner brothers X   X  X all for papers X , etc. Our approach to handling phrase queries is to apply a frequent-itemset mining algorithm and extract from the query log the most frequently submitted multi-term phrases. The resulting phrases are added in the vocabulary as they were singletons and are indexed in all the sites, thresholds are computed for them, etc. During query processing, it is checked if the query contains indexed phrases, and if it does, those phrases are handled as singleton terms. If the user specifies explicitly that the query should be handled as a phrase query (for instance by using double-quotes), and the phrase is not indexed, the local site propagates the query to all other sites. The number of indexed multi-term phrases controls how often queries are propagated to all sites with the tradeoff of a larger index.
We describe here a set of experiments we conducted to evaluate the algorithms introduced in the previous section for the processing of queries in a distributed search engine.
 Dataset. We consider a setting where the search engine is dis-tributed over five geographic regions and it only receives queries from those same five regions. The i -th region has exactly one site S which receives queries from users in the same region.

Our proprietary dataset comprises a real workload from the Ya-hoo! Web search engine, where we consider a random sample of 1% of the queries submitted by users in the five regions during a day, and a random sample of 102 million Web documents from the same five regions. Both the queries and the Web pages have been collected during the same period of time. In Table 1, we show the fraction of documents | D i | / |D| assigned to site S i , and the frac-tion of user query volume Q i received at site S i . Site S largest index with 43.11% of the documents, while site S 1 43.55% of the total query volume we have considered.
 Algorithms. We implemented the distributed algorithm described in Section 6, and we experimented with the following variants: B : Our baseline approach is a straightforward application of the BC : The second approach introduces a cache of query results in BCG : The third approach introduces replication of a set of doc-BCG : The last approach introduces the slackness parameter , which
For the functions f ( d ) and g ( d | t ) , we employ scores based on hyperlinks and text content, respectively. Before combining f ( d ) the standard deviation is 1. Initially, the scores are combined with equal weights w f = w g = 1 for f ( d ) and g ( d | t ) , respectively. As discussed later, we also look at different values for w f Metrics. We evaluate the performance of the different variants of the distributed algorithm with the following metrics: x : the fraction of the query volume across all sites that are resolved x : the fraction of the query volume for which the clicked retrieved T : the fraction of the query volume in S i that are forwarded to E : the fraction of the query volume for which the computed top-10 Cl g and Cl ` : the fraction of the query volume for which a cen-Cl i and Cl
We note here that all of the above metrics refer to the online query-processing part of the algorithm. An important part of the al-Figure 3: The fraction x of the volume of queries for which the top-k documents are retrieved locally. gorithm refers to the offline phases of index construction and prop-agation of thresholds. The costs of those offline phases depend on the dynamics of the document collection and on the degree with which the search engine wishes to serve fresh results. We leave this part to further investigation. We choose to use query volume rather than unique queries after caching because the consumed bandwidth in the distributed setting depends on the volume of exchanged data.
We also note that our error measure E is highly conservative. In particular, we count as errors even the cases in which the returned top-10 list differs from the top-10 results of a centralized search en-gine even by one document. In practice, even if the list is different, the returned list may consist of other relevant documents, or doc-uments that local users are clicking on. While clicks are a biased indication of relevance [22], we use them as a simple indication of the quality of results. Hence, we obtain a different indication of the quality of search results by looking at the fraction of the volume of queries which retrieve among the top-10 documents a higher ( Cl and Cl + ` ) or a lower number ( Cl  X  g and Cl  X  ` ) of clicked documents. The fractions are computed relative to the fraction of the query vol-ume Cl g and Cl ` , respectively, for which the centralized system retrieves at least one clicked document among the top-10 ranked documents. The clicks were collected from the logs of the Yahoo! Web search engine for the same queries submitted by users in the regions we consider in this work.
 Results and discussion. Figure 3 shows the locality x achieved by each of the variants of the distributed query processing algorithm, as a function of the number of top-ranked documents that a site re-turns for a query. The straightforward application of the algorithm (baseline B ) has the lowest locality among all the variants we used. Adding a cache of results in each site ( BC ) results in x &gt; 0 . 20 for all choices of k  X  20 . The replication of documents with BCG provides further improvement in x with a notable increase in x for small values of the rank k . The slackness parameter in BCG im-proves x as increases. For example, when = 0 . 9 , more than 70% of queries are resolved locally when requesting top 10 doc-uments, with a possible loss of precision. Note that if the latency for non-local queries is c times the latency for local queries due to network, then latency will be on average x + c (1  X  x ) times higher.
Table 2 provides more information on how different values for affect locality x and error E at rank k = 10 . As increases, we can see that locality x increases, but at the same time, error E increases too. Moreover, using the set of globally best docu-ments G improves x and reduces significantly E (bold values in columns x and E of Table 2). For all values of , Cl g = 0 . 0671 and Cl ` = 0 . 0604 , because Cl i depends on the ranking of a cen-tralized engine, and hence, on the weights w f and w g of the hy-perlinks and text content scoring functions, respectively. The fact that the values of Cl g and Cl ` are similar suggests that users from a given geographic region are likely to click on documents from the same region in the search engine results. Regarding the frac-tion of the volume of queries with more or fewer clicks among the top-10 ranked documents, we see that both Cl + i and Cl  X  as increases. The increase in Cl + i is due to the sites S S , while the decrease in Cl  X  i is mainly due to S 1 lar, BC matches more clicked documents among the top-10 docu-ments, either global ( Cl + g ) or local ( Cl + ` ), than BCG (bold values in columns Cl + g and Cl + ` of Table 2). In addition, Cl than Cl  X  g because the query processing algorithm with slackness forwards fewer queries to other sites, and hence, local documents are ranked higher.

In addition, our experiments have shown that the fraction x higher than 0.50 for all variants of the distributed query process-ing algorithm. For instance, x ` ranges from 0.54 to 0.95 for B and BC 0.9, respectively. BCG 0.5 also achieves x ` = 0 . 94 . These results show that the distributed query processing algorithm is suc-cessful at retrieving the local documents that users click on. Table 2: Fraction x of queries resolved locally, error E , and fraction of queries with more ( Cl + g and Cl + ` ) and fewer clicks ( Cl  X  g and Cl  X  ` ) in the top-10 ranked documents, for different values of in BCG .

We gain further insight on the performance of the evaluated ap-proaches by looking at the query traffic between different sites. In Table 3 we consider the case of BCG , where we observe that all sites send most of their traffic to the largest site S 2 (see Table 1). Since S 2 is the largest site, it is more likely to have documents that rank high for queries submitted to any other site, and respectively, high thresholds. Hence, the algorithm forwards more queries to site S
Table 4 shows the effect of varying the weights w f and w functions f ( d ) and g ( d | t ) , respectively. We can see that locality x is stable in the cases when w g &gt; w f , but E increases signifi-cantly as the weight w f of the hyperlink scores decreases, because slackness has a greater impact on the text similarity scoring func-tion g ( d | t ) . We obtain the highest Cl g = 0 . 0710 when w and w g = 1 . 0 . In that case, for more than 97% of the query volume with at least a clicked document among the top-10 ones, there is no change in the results between a centralized and distributed system using our algorithm. If we further decrease the weight w f then we observe a small decrease in Cl g , but also a small increase in Cl + g , which is mainly due to the higher number of clicked docu-ments for queries submitted to the smaller sites S 3 , S 4
Overall, we showed that our algorithm results in improved lo-cality. Moreover, the algorithm successfully retrieves the locally clicked documents in each site. When exploring different values for the weights w f and w g , we have seen that there is a trade-off between higher locality obtained when w f  X  w g and retrieving more clicked documents when w g &gt; w f . Table 3: The query traffic T ij sent from site S i to S BCG . For example, S 4 sends 60 . 96% of its query volume to S Table 4: Fraction x of queries resolved locally, error E , frac-tion of query volume Cl with at least one clicked document in the top-10 rank documents, and fraction of query volume with more ( Cl + ) and fewer clicks ( Cl  X  ) in the top-10 ranked docu-ments, for different weights w f and w g in BCG with = 0 . 5 .
The variants of the algorithm in the previous section are char-acterized by the locality x i of site S i and pairwise communication T . In this section we express the cost of query processing of a centralized versus a distributed system for thirty days of operations, using the model of Section 4. We show our results in Table 5.
We estimate the costs of power C w and communication C bw using system parameters (CPU utilization, capacity, etc.) that cor-respond to reasonable design choices, and prices according to what we discuss in Section 4. Energy prices are expressed in $/KWh and cost of bandwidth in $/ Mbps  X  month .

To simplify calculations, we assume a uniform distribution of queries in time ( QPS ( i ) ) and a constant latency ` q ; the latter mo-tivated by the fact that each node in a site S i holds an equal portion of the index. Thus the formulas in section 4 can be re-written as where W q ( i ) = QPS ( i )  X  ` q c  X  e q ( i ) ,  X  t = 30  X  24 is expressed in hours, capacity c and power consumption per node are equal for both centralized and distributed settings.

For communication costs, we now assume a star topology of n sites with center at site S c , and a full-duplex channel between S and S c ; such an architecture has n  X  1 links as opposed to the 2 of a fully connected architecture, thus allowing significant savings in network costs on large deployments.

The virtual traffic between two non-adjacent nodes is projected culated over this flow. For a full-duplex link we then model the rate of bits through each physical channel with center S c following formula:
B cj = max ` X where  X  s j is the average number of bits per second for queries sent to S j , and r is the bits per second for responses including snippets.
The optimal center is the one producing the minimum value in Figure 4: The byte flow from S j to S i goes through the physical links that have one end in the center S c of the star.
 Table 5: Costs for different settings of the distributed system with respect to the cost of a centralized system. the multiplication between B and a symmetric matrix C , where C ij represents the cost of a Mbps of bandwidth for a link between sites S i and S j , and C ii = 0 : C bw ( X  t ) = min  X   X  i :  X  i = ` X
Next we apply our cost model to the variants of the distributed algorithm of Section 6 with weights w f = w g = 1 for the hy-perlinks and text content scoring functions, respectively. The esti-mated costs in Table 5 are expressed relative to the estimated cost of a centralized system, located in the site with the most favorable en-ergy prices. C rel expresses the ratio of the total cost of a distributed system over the total cost of a centralized system, thus equal to one in centralized settings. Note that we do not consider caching of re-sults for local queries. Such a cache should have a similar impact in both kinds of architecture, since we expect a distributed system to have as many misses as a centralized one (we assume that the same query coming different regions is effectively a different query). It is subject of future work to evaluate the impact of caching further.
It is worth observing that exact values depend on the local cost of power and bandwidth, and a comprehensive market analysis is also out of the scope of this paper. Nonetheless, a trend where the cost of network infrastructure decreases in time is always favorable to our proposed model.

As we apply the variants of the query processing algorithm that increase locality x using caching, replication and the slackness pa-rameter , the relative cost of the distributed architecture becomes more competitive with respect to that of the centralized architec-ture. In fact, starting from the variant BCG 0 . 3 distributed architecture is increasingly lower (Table 5). We also see that increase in locality improves not only the communication cost, but power consumption as well. The reason is that increasing locality reduces the average number of sites that process a query.
In all cases, the central site S c of the star topology was the site with the highest volume of queries submitted by users, namely S This result is expected because if S c 6 = S 1 the traffic from and to S 1 would have to be routed through S c , thus increasing the total communication cost. 3
For a given load of forwarded queries the power consumption on each site remains constant and only the communication flow im-pacts the selection of the optimal center.
Distributed search engines yield important benefits such as us-ing less compute resources and exploiting locality to deliver results faster. Our results in this paper indicate that distributed engines are practical and can potentially reduce the costs of query processing. Using a realistic scenario, we have shown that a fully-distributed architecture can reduce costs as the cost of bandwidth decreases faster than the cost of power. To make our argument more concrete, we have proposed and discussed an algorithm for query processing and variants that increase the locality of the system by replicating and allowing to retrieve different results compared to a centralized engine. When evaluating with a real query log, our distributed ar-chitecture outperforms a centralized one in costs for reasonable ap-proximation values. More concretely, our results show that the cost reduction can be as high as 15% compared to the centralized case for practical locality levels of 50%. Such a cost reduction comes in addition to other clear benefits such as shorter response time to queries. Also, for most of the queries, we have seen that our algo-rithm returns the same number of local clicked documents, and in some cases, it may return even more clicked local documents.
Instead of a self-contained set of results, our effort should be viewed as a first step towards the design of realistic distributed Web search engines. As such, it leaves several open questions, which we intend to address in our future work. First we need to investigate the components that were left unspecified: a full implementation of the crawling and indexing phases, the frequency of the threshold propagation phase, etc. In our experiments, we used a star network topology, but as we already mentioned, the optimal choice is one of the parameters of the design process that can be optimized. There are also possible extensions to the query-processing algorithm, en-abling it to handle more complex ranking functions, such as one that captures proximity of the query terms in the documents. Fi-nally, we believe that there is potential in using clicks to choose the subset G of global documents more effectively. A better choice of set G might lead to further improvements in the locality of queries.
