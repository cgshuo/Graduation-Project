 We use data mining and mac hine learning techniques to pre-dict upcoming perio ds of high utilization or poor perfor-mance in enterprise systems. The abundan t data available and complexit y of these systems de es human characteriza-tion or static mo dels and mak es the task suitable for data mining techniques. We form ulate the problem as one of classi cation: given curren t and past information about the system's beha vior, can we forecast whether the system will meet its performance targets over the next hour? Using real data gathered from sev eral enterprise systems in Hewlett-Packard, we compare sev eral approac hes ranging from time series to Bayesian net works. Besides establishing the predic-tive power of these approac hes our study analyzes three di-mensions that are imp ortan t for their application as a stand alone tool. First, it quan ti es the gain in accuracy of mul-tivariate prediction metho ds over simple statistical univ ari-ate metho ds. Second, it quan ti es the variations in accu-racy when using di eren t classes of system and workload features. Third, it establishes that mo dels induced using com bined data from various systems generalize well and are applicable to new systems, enabling accurate predictions on systems with insucien t historical data. Together this anal-ysis o ers a promising outlo ok on the dev elopmen t of tools to automate assignmen t of resources to stabilize performance, (e.g., adding serv ers to a cluster) and allo w opp ortunistic job scheduling (e.g., bac kups or virus scans).
 Categories and Sub ject Descriptors: K.6.4 System Man-agemen t; C.4 Performance of Systems -Mo deling techniques; I.5.1 Mo dels -Statistical General Terms: Managemen t, Performance Keyw ords: performance forecasting, enterprise systems This work was conducted during an internship with HP Labs.

Today's large-scale net work services exhibit complex be-haviors stemming from the interaction of workload, soft ware structure, hardw are, trac conditions, and system goals. To trac k performance (and availabilit y) in these systems, there are various monitoring tools, both commercial and freew are, that pro vide measuremen ts on the various comp onen ts that mak e up the enterprise systems (e.g. [9, 10]). In partic-ular, there are tools that pro vide measuremen ts on the ap-plication performance, suc h as average resp onse time trans-action coun ts, and transaction rates (throughput). Other tools measure system utilization, suc h as CPU, memory , disk and net working utilizations at regular interv als. Per-vasiv e instrumen tation and query capabilities are necessary elemen ts of the solution for managing complex systems. In large installations, the num ber of features being measured can num ber in the hundreds or thousands, dep ending on the num ber of systems and level of detail de ned by the user (e.g., CPU utilization can be brok en up into sev eral features, suc h as CPU utilization of every application or pro cess running on the system). In fact, it is widely rec-ognized that the complexit y of deplo yed systems surpasses the abilit y of humans to diagnose and resp ond to problems rapidly and correctly [6, 12]. Yet, there is great need for tools to accomplish this. As large enterprises try to reduce their IT systems and infrastructure costs, they demand bet-ter tools to ecien tly manage their capacit y and at the same time pro vide optimal qualit y of service to their clien ts. The complexit y of the systems, prev enting static mo dels of be-havior, and the availabilit y of monitored data, has inspired researc hers to apply statistical learning techniques to induce the mo dels automatically . These approac hes assume little or no domain kno wledge; they are therefore generic and have poten tial to apply to a wide range of systems and to adapt to changes in the system and its environmen t. For example, there has been much recen t progress on the use of statistical analysis tools to infer comp onen t relationships from histo-ries of interaction patterns (e.g., from pac ket traces) [3, 4] (further examples and comparisons to the work in this pap er are explored in detail in Section 4).

In this work, we concen trate on the performance of the applications running on the enterprise system. This perfor-mance is de ned so as to meet business objectiv es or service level objectiv es (SLO). A typical SLO in e-commerce sites is a threshold on the maxim um transactions average resp onse time, as the resp onse time for transactions have a direct link to customer satisfaction (e.g., studies sho wed that re-sponse time higher than 10 seconds can lead to abandon-men t of the website by consumers). Successful forecasting could both alert operators of incoming crises and enable the optimal scheduling of prev entive main tenance, updates, and lower priorit y jobs suc h as bac kups or virus scanning. Other SLOs include thresholds on the utilization of particular re-sources, suc h as storage, CPU, or net work bandwidth. For both types of objectiv es, the task is then to predict whether it is likely that there would be many violations in the next hour. It is imp ortan t to be able to predict both the occur-rence and the intensit y of these events, so that the trade-o s involved in performing a resource reallo cation (suc h as adding a new cpu | whic h may imply den ying the extra computing power for other task) may be evaluated.

We form ulate the problem as a classi cation one: given curren t and past information about the system's beha vior, can we forecast whether the system will meet its target per-formance levels over the next hour? We compare sev eral ap-proac hes ranging from time series to Bayesian net works for classi cation. We ran these exp erimen ts on real data gath-ered from sev eral enterprise systems in Hewlett-P ackard, that handle both e-commerce applications and administra-tive workloads. To the best of our kno wledge this is the rst time researc h with suc h wide characterization of forecasting in the con text of enterprise IT systems, and using pro duc-tion data, has been published. We analyzed over 60,000 runs in order to try and answ er three main questions: 1. Is multiv ariate analysis necessary? This is imp ortan t 2. Are features characterizing the demand in the system 3. Are the mo dels transferable? This is crucial for jump
The rest of the pap er is organized as follo ws: Section 2 describ es the approac hes we compared in the exp erimen ts, including feature selection. Section 3 presen ts our analysis and results. Section 4 goes through the relev ant existing literature, and Section 5 presen ts our conclusions and de-scrib es future work.
Our objectiv e is to nd metho ds that accurately predict whether the num ber of SLO violations in the next hour will exceed a speci ed threshold. We applied and compared a num ber of metho ds from the mac hine learning and statis-tics comm unities with some variations to t this setting. In particular, we tested the use of auto-regressiv e metho ds from the time series analysis literature [2], multiv ariate re-gression metho ds [16], and sev eral instan tiations of Bayesian net work classi ers [7]. As a baseline and sanit y chec k for the accuracy of any of our mo dels, we also include the simplest possible mo del, whic h we will refer to as the `presen t rule'. The `presen t rule' predicts for the next hour the curren t (kno wn) state. In the rest of this section, we will describ e how we applied eac h of these metho ds to our problem before presen ting empirical results.

Auto-regressiv e metho ds. We estimate the coecien ts of an AR lter and use those to predict the value of the series in the next time, y [ n +1] = a 0 y [ n ]+ a 1 y [ n 1]+ ::: + a In our setting, we have two choices for choosing y . We could set y to be the feature on whic h the SLO is de ned, suc h as average resp onse time, and use its predicted value and the SLO threshold to determine the state in the next hour. An alternativ e, whic h we found work ed much better in practice, is to set y to be the actual num ber of violations occurring in an hour. We used the Levinson-Durbin algorithm [14] for estimating the AR coecien ts given an auto correlation sequence deriv ed from the sets of consecutiv e training data. We also exp erimen ted with sev eral other metho ds includ-ing the Yule-W alker algorithm, and metho ds minimizing for-ward or bac kward prediction error, but found no substan tive di erence in performance in any of our exp erimen ts. We did nd that both the choice of lter length, p , and the level of aggregation in the data (e.g. 5 min ute averages versus 15 min ute averages) had a ma jor impact on the accuracy . In order to select the prop er parameter we calculated a range of values and selected the mo del with the values that attained the highest accuracy on the training data.

Multiv ariate regression metho ds. While we can hop e that the AR metho ds can nd patterns in the history of vi-olations, this approac h ignores the large volume of other information about the application and system state that is available when making predictions. The rst metho d we tested for using this multiv ariate information was multiv ari-ate linear regression metho ds [16], using a least squares t for transforming the feature space into a prediction of the num ber of violations in the next hour.

Bayesian net work classi ers. The third class of meth-ods we considered was building Bayesian net work mo dels of the feature space for performing classi cation. Bayesian net work classi ers mo del the join t distribution of the class and the features, P ( C; ~ F ), represen ting indep endencies and causal relationships among the variables graphically [17]. We focus on a restricted set of Bayesian net work classi ers, Naiv e Bayes (NB) and Tree-augmen ted naiv e Bayes (TAN) classi ers [7], both used extensiv ely in man y domains. In the Naiv e Bayes classi er, features are assumed to be inde-penden t of eac h other given the class variable. While this assumption is often unrealistic, the NB classi er has nev er-theless been applied successfully in man y settings and is the sub ject of numerous studies explaining its success (e.g., [5]). The TAN [7] classi er extends the Naiv e Bayes mo del by relaxing the indep endence assumption so that the features are connected to eac h other as a tree.

Feature selection metho ds. Unfortunately , the large num ber of features, well over 100 for sev eral problems, is now a liabilit y, as any of our multiv ariate mo dels (regres-sion, NB and TAN) are likely to over t peculiarities of the violations in the available training data. In order to com-pensate for this we performed an additional feature selection step using one of two greedy metho ds. The rst is a forw ard greedy searc h, in whic h we rst test all mo dels using a single feature and select the one with the best training accuracy and then iterativ ely add individual features that maximally increase the training accuracy . We also tested a mo di ca-tion of this pro cedure that additionally considers remo ving a single feature at eac h step instead of adding one, kno wn as the forw ard-bac kward algorithm [13]. As a practical obser-vation we found that if we determine the nal set of features by selecting the set that achiev es the highest cross-v alidation accuracy for the training data, we avoided over tting to the data without taking a high computational performance hit (as would happ en if cross validation was done during ev-ery stage of the searc h). Selecting a subset of the features also o ers practical adv antages by reducing the size of the mo dels and decreasing the memory and pro cessing resources required to implemen t the mo dels on a running system.
Data transformations. With the abilit y to handle large num bers of features, we also deriv ed mo dels using multi-ple perio ds of data to predict the num ber of violations and transformations of the data. These other perio ds and trans-formations were then added to the set of features prior to the selection pro cess. In particular, we noticed that for some features we would often achiev e better mo dels by training on the logarithms of the data values or by remo ving the outliers by constraining all values to lie in the 5th to 95th percen tiles of the data. We also considered adding a feature capturing the trend for eac h feature by using the slop e from the linear mo del that was the least squares t for the fea-ture's values over the last k time steps. In addition, some metho ds, notably the auto-regressiv e ones, performed bet-ter when using aggregated versions of the data as features. For example, using 15 min ute averages of the features may pro duce better predictions than using the original 1 min ute averages available in some settings.

In our exp erimen ts we tested all three metho ds with di er-ent settings; varying feature selection metho ds, data trans-formations, and algorithm dep enden t parameters.
In this section we focus on addressing eac h of the three questions posed in section 1 in turn. In the course of this investigation we implemen ted and ran a vast num ber of ex-perimen ts, varying both the parameters of the algorithms and the SLO violation de nitions for some of the individual settings. As discussed earlier, eac h of the metho ds we've de-scrib ed can be parameterized by up to four indep enden t set-tings: the level of aggregation of the input data, the num ber of perio ds of data to use when training, the transformations that are applied to the training data (logs, clipp ed values, and trends), and the feature selection metho d. Com bined with the large scale of some of the pro duction systems we investigated, this yielded a database of well over 60,000 sep-arate runs after consuming sev eral thousand hours of CPU time. After brie y describing the di eren t exp erimen tal set-tings, we dra w on the results of individual exp erimen ts from this reserv oir in order to address eac h of the three questions.
We tested the metho ds using data collected from three sets of systems running di eren t applications eac h with dif-feren t performance targets.
The rst set of data was collected from 20 HP-UX sys-tems running a variet y of internal HP applications. For eac h serv er, we collected 30 days of system data, tak en at ve min ute interv als, describing the utilization of resources suc h as CPU, memory , disk and net work, among others. For these mac hines, we used eac h of the metho ds to train mo dels for predicting when the mac hine will exp erience a sustained perio d of high resource utilization. There were four system resources for whic h non-acceptable utilization were de ned (SLOs): CPU, memory , IO and net work. These were de-ned by the system administrator in order to categorize past performance problems and iden tify whic h serv ers should be targeted for hardw are upgrades. We adapted those SLO de nitions in our exp erimen ts.

To be concrete, all four violations are de ned as occurring during the next hour if the individual thresholds given below are exceeded in more than 10% of the time interv als (or 50% of the interv als for sev ere violations):
The frequency of the di eren t classes of errors across all mac hines in eac h setting is sho wn in table 1.

The second set of data was collected from the pro duc-tion environmen t of an HP supp ort application. As an im-portan t supp ort application, it has availabilit y targets and service level objectiv es (SLOs) for di eren t transactions, de-ned in a service level agreemen t con tract with the appli-cation owner. We obtained a mon th of data collected at four serv ers hosting the application, serving requests at dif-feren t regions of the world. The data was collected by the HP Op enView Performance agen t tool, whic h aggregates all raw data to ve min ute interv als. The data consisted of both system-lev el utilization features (CPU, memory , paging, IO, etc.) and application-lev el features, including average trans-actions resp onse times, num ber of transactions and num ber of transactions violating their SLOs. There were overall 49 measuremen ts describing both the system utilization and the application-lev el demand and state.

We used a single application-lev el service level objectiv e by thresholding the percen tage of transactions that are in violation of their SLO during the ve min ute time interv al.
Finally , our third set of data was collected from an exp er-imen tal three-tier testb ed hosting PetStore, an e-commerce application freely available from The Middlew are Compan y. Suc h a three-tier system is the most common con guration for medium and large Internet services. The rst tier is the Apac he 2.0.48 Web serv er, the second tier is the application itself, and the third tier is an Oracle 9iR2 database. Our workloads sim ulated the day to day operation of a large online web application. Eac h tier runs on a separate ma-chine instrumen ted with HP Op enView to collect a total of 186 system-lev el features from the three systems whic h are com bined with 45 workload features and aggregated to one min ute interv als. We applied stresses to the system with a workload generator called http erf [15] to generate perio ds of SLO violations. In these exp erimen ts we categorize eac h min ute with a mean resp onse time above 100ms as a viola-tion. The prediction task is then to determine at any point in time whether the subsequen t hour will con tain 20 or more min utes of violations.

The adv antages of using the testb ed are that it gives us ac-cess to a wider spectrum of features about the system (more features than in the rst two sets of data) and it allo ws us to exercise con trol over the workload in order to test di er-ent asp ects of the problem. The other two pro duction data sources verify that results obtained on the testb ed generalize to pro duction systems.
For eac h of these settings we have a series of features span-ning a perio d of time and binary lab els indicating whether the system will exceed its SLO threshold in the coming hour. We evaluate eac h metho d by dividing the data into ve equal-sized temp orally con tiguous regions and testing on eac h of these regions in turn using the data from the remaining four to train the mo del. We then aggregate the performance on eac h region to get an overall measure of ac-curacy . In all of our graphs we have chosen to plot balanced accuracy instead of straigh t prediction accuracy . Prediction accuracy is less informativ e in settings in whic h one of the target classes is rare. For example, if only 5% of the time pe-riods exceed the threshold for a violation, the metho d that nev er predicts a violation would achiev e 95% accuracy but we would be hesitan t to judge it a good predictiv e mo del. The balanced accuracy metric weigh ts the performance of the mo del on eac h of the two classes equally , regardless of their size. In practice eac h of our implemen tations allo ws us to adjust this metric to matc h the actual costs incurred by positiv e and negativ e errors and therefore striv e to minimize the overall cost of mispredictions. In deplo yed systems, fail-ing to detect violations may be substan tially more exp ensiv e than generating false alarms, since the former may result in lost customers or con tractual penalties.
Our exp erimen ts strongly suggest that multi-v ariate anal-ysis is necessary for robust prediction results across a wide variet y of environmen ts. In the course of this investigation we were forced to wrestle with the challenges of mo del se-lection in order to choose from among the man y possible parameter settings for eac h approac h. We found that we could nd nearly optimal parameter settings for the auto-Figure 1: Average balanced accuracy obtained by a se-regression metho d by selecting the settings with the high-est training accuracy . In con trast, the multi-v ariate meth-ods sho wed signi can t sensitivit y to their parameter settings and neither training accuracy nor cross-v alidation training accuracy correlated well with performance on the actual test data. Even without the abilit y to select the optimal param-eters for eac h environmen t, the multi-v ariate metho ds main-tained a consisten t adv antage in performance. Furthermore, we are encouraged that even the simple metho ds we've cho-sen to test can achiev e good performance without relying on any domain kno wledge, allo wing easy deplo ymen t to new environmen ts.

Figure 1 sho ws the performance for eac h metho d across our di eren t pro duction environmen ts. Eac h point in the graph re ects the balanced accuracy attained by the indi-cated metho d averaged over all of the mac hines compris-ing the environmen t. For example, in the test on the HP mac hines, the gure sho ws the average across 20 di eren t mac hines for eac h of the four SLO de nitions, and since eac h test includes all thirt y days of data, eac h point is the average of over 100,000 separate predictions, giving strong statistical signi cance to the results sho wn. Throughout all of the exp erimen tal settings, the multiv ariate classi ers consisten tly exhibit the best average performance. While the auto-regressiv e metho ds impro ve on the baseline perfor-mance of the presen t rule, they ignore the information avail-able about the other features of the system. The parameter settings for the ve metho ds sho wn are: Figure 2: The e ectiv eness of using training accuracy
An additional challenge in this setting is the dicult y of mo del selection. The results sho wn so far were averaged across man y mac hines. When we look at individual ma-chines, we observ e very high variance in accuracy dep end-ing on the exact choice for parameters, suc h as the num ber of perio ds of data to use or the types of transformations to include. For the auto-regressiv e metho ds, we found that by running a variet y of parameter settings for eac h mac hine and using the parameters with the best training accuracy we were able to consisten tly select mo dels with close to optimal performance. In gure 2, we compare the results for this au-tomatic parameter selection metho d with the optimal per-formance attained by alw ays choosing the parameters that maximize testing accuracy on eac h individual mac hine. The third line sho ws the imp ortance of dynamically adjusting the parameters for eac h system, since it represen ts the best performance that could have been achiev ed by using any single parameter setting throughout all of the exp erimen ts.
In con trast, the mo del selection task pro ved much more dicult for metho ds that relied on feature selection. In g-ure 3, we see that substan tial further gains could poten tially be attained by a more successful mo del selection algorithm. The `Ba yes-Optimal' line sho ws the best performance that could be attained if we selected the best possible parameters for eac h individual mac hine. The `Ba yes-Fixed' sho ws the best possible accuracy that could be obtained when using iden tical parameters for all tests. The `Selected Parame-ters' corresp onds to the results sho wn previously in gure 1 and were selected since they had performed well in previous exp erimen ts not discussed in this pap er. `Ba yes-T raining' and `Ba yes-T raining CV' selected the parameters for eac h mac hine on the basis of training accuracy or 5-fold cross-validation accuracy , resp ectiv ely, and o ered little adv an-tage over even a random selection. It is imp ortan t to point Figure 3: A comparison of various metho ds of selecting out that even though we are unable to obtain the best mo del parameters for any given mac hine, the average performance is still signi can tly above that of the AR metho ds. A more successful mo del selection algorithm would allo w us to im-pro ve on this performance even more signi can tly.
The question of how best to handle mo del selection for this application seems an imp ortan t focus for future work. We had hop ed that the addition of the forw ard-bac kward metho d of feature selection migh t reduce this variance, but failed to observ e any noticeable or consisten t impact. It is particularly striking that the cross-v alidation training accu-racy did not impro ve the selection. In fact, in man y cases the testing accuracy even seemed to be negativ ely correlated with the cross-v alidation accuracy . The most likely cause for this is the fact that our data is not truly a random selec-tion from our target function. Since we train and test on separate time perio ds, it is quite possible that the beha vior of the system is qualitativ ely di eren t in eac h of the two regions, indicating concept drift.
A concern in actual systems is that we may not have ac-cess to the full set of features we were able to acquire in some of our environmen ts. A natural question arises as to whether there migh t exist some subset of the features that are critical for making accurate predictions. We found that this did not seem to be the case when we restricted the sets of features the mo dels were allo wed to consider. Simi-lar performance was attained using various subgroups of the features. Focusing on our testb ed environmen t for whic h we have the largest set of available features, we sho w results using three subsets of the features in gure 4. The `System' set of features con tains only information available about the physical system, suc h as memory usage, cpu utilization or net work trac. The `Workload+R Ts' set con tains the infor-mation that would be available to users of the application, namely a breakdo wn of types of requests made by users and the resp onse times of calls to di eren t portions of the appli-cation. The `Workload' set uses only the breakdo wn by type of the num ber of requests. Eac h of the two main categories of features app ear to con tain sucien t information to main-tain accuracies comparable to those attained using all of the Figure 4: Results for the three-tier testb ed using di er-features. In addition to being more resilien t to systems with incomplete logging information, if we can mak e accurate pre-dictions based on only the workload characteristics of an application we would have the basis of a system that could predict performance on hypothetical systems. This forms an imp ortan t comp onen t of an online system for dynamically con trolling the resources allo cated to an application. When determining resource allo cation, we are not just interested in whether violations would occur in the curren t con gu-ration but also whether violations would be likely to occur in alternate con gurations, suc h as when we wish to deter-mine if we can safely reallo cate computation resources of a running system. While there is a noticeable drop in perfor-mance when using only the workload features, we are able to main tain overall accuracies near 70% with some of the metho ds. Note that in this setting we receiv e no informa-tion about the performance of the system we're interested in predicting during testing, prev enting us from applying any of the time series metho ds. Any performance above 50% is a gain in information over our baseline in this case. While these initial results seem promising, further exp erimen ts will be needed on an actual system with the capabilit y to reas-sign resources in order to determine what level of prediction is necessary . In addition, we are curren tly acquiring more detailed workload information for the HP supp ort setting in order to test how predictiv e pure workload features are in a deplo yed system.
In the systems we observ ed, man y categories of viola-tions were quite rare, occurring less than 2% of the time in a large num ber of individual mac hines. In these situa-tions the mon th of training data we had for the HP-IT ma-chines environmen t was insucien t to dev elop robust mo d-els. Unfortunately for our metho ds, this is likely to be a common situation in a smo othly operating system. We ide-ally want mo dels that will achiev e reasonable accuracy on a new mac hine without requiring long perio ds of observ ation rst. One possibilit y is to transfer mo dels trained on similar systems to a new mac hine with the hop e that the learned mo dels generalize across di eren t systems. In order to test this hypothesis, we trained mo dels to predict violations on a mac hine while only receiving training data from di eren t mac hines. While the new mo dels don't fare as well as the mo dels that are able to observ e training data when there Figure 5: A comparison of balanced accuracy for TAN are numerous violations, they perform well in the settings with rare violations. Figure 5 sho ws a comparison of per-formance on individual mac hines for the task of predicting memory violations. The mac hines have been sorted from left to righ t in decreasing order of the frequency of viola-tions. We can see that training on other mac hines tends to help on the mac hines with the few est violations. We are cur-ren tly investigating how best to dev elop hybrid mo dels that adapt a default mo del formed from data from other systems with the available training data for a given mac hine. It is also imp ortan t to note that in the HP-IT mac hines environ-men t the mac hines are actually running a variet y of di eren t applications and therefore the generalization task requires predicting performance for new applications and hardw are con gurations, not just di eren t perio ds of time.
A recen t spate of promising initial results has fuelled inter-est in applying data mining and mac hine learning metho ds to forecast, iden tify and localize system failures and per-formance problems [8, 18, 11, 1, 3, 4]. Probabilistic and mac hine-learning-based mo dels have been successfully used in diagnosis and planning tasks, suc h as performance debug-ging [1], capacit y planning, attributing performance prob-lems to speci c low-lev el system features [4], among others.
There have been few er works concen trating on forecasting of system resource utilizations and performance. Among these works, Hellerstein et al. [8] use time series analysis to forecast normal workloads in web serv ers and then use change point detection as a way to detect possible problems. In another work, Saho o et al. [18] apply time series mo dels and Bayesian net works to predict system utilization (suc h as CPU) and Bayesian net works to forecast rare events (ex-tracted from system error logs) on a large IT system using system instrumen tation data and event logs.

Our work di ers from the above in various ways, with the di erences in domain precluding a straigh tforw ard com-parison of ecacy . First, we forecast events (SLO viola-tions) that are de ned by application owners or system ad-ministrators, thus they pro vide the system/application ad-ministrators information they need to main tain their sys-tem/application at the desired performance targets. Sec-ond, we forecast durations of performance problems, with time scales that relate to the abilit y to tak e remedial actions using curren t tools. Third, our extensiv e analysis, including data from numerous IT-systems, characterize the di eren t approac hes in terms of the three dimensions that are relev ant for their use as a tool for system managemen t: univ ariate vs. multiv ariate metho ds for forecasting, forecasting with di eren t subset of features (demand and system utilization features), and the transferabilit y of forecasting mo dels be-tween di eren t setups.
The short term forecasting of perio ds of high-lo w utiliza-tion and performance is crucial for the ecien t managemen t of resources in curren t IT enterprise systems. This capa-bilit y will enable the dynamic reallo cation of resources for meeting surges in demand, the e ectiv e scheduling of low priorit y items and prev entive main tenance, and the opti-mal utilization of the excess capacit y. The complexit y of these systems challenges the creation of pre-built mo dels based on mathematical closed-form form ulation of the sys-tem's beha vior. This and the fact that there are man y commercial systems available for monitoring and collect-ing sev eral features about the performance of these systems, points to a more empirical-based approac h suc h as one based on data mining, mac hine learning, and pattern recognition techniques. In this pap er we have rep orted on the applica-tion of suc h techniques to the problem of short-term fore-casting of an imp ending performance problem, and its inten-sity. The intensit y of the problem, as expressed for example in terms of duration, is imp ortan t in order to establish what is the best possible course of action.

Our exp erimen ts and analysis go beyond comparing the accuracy of di eren t approac hes. They aim at characteriz-ing other asp ects of the problem involved in creating stand alone tools for real systems. The rst issue we investigated relates to quan tifying the bene ts (in terms of accuracy) of using multiv ariate approac hes fusing the information of other signals besides the one being forecasted. Our exp er-imen ts supp ort the conclusion that metho ds suc h as those based on Bayesian net work classi ers and multiv ariate re-gression perform better (on average) for a variet y of tasks over univ ariate auto-regression metho ds. The second issue we rep ort on is the quan ti cation of the loss of using only fea-tures that relate to the demand on the system (workload). Ideally , for purp oses of dynamic resource allo cation, suc h as adding new CPUs to the system, we would like a sort of transfer function from workload to performance. This transfer function is easier to main tain over di eren t con g-urations since its features are constan t across changes. Our results indicate that although the results are in general ro-bust to subsets of the data, there is indeed a loss in accu-racy when relying only on the features from the workload. Further work will be required to determine if the resulting accuracy is sucien t for dynamic allo cation. Finally , we quan ti ed the generalization power of the mo dels induced from data aggregated from groups of mac hines in terms of the application to di eren t mac hines in the system. This is imp ortan t because it will enable bootstrapping in systems where data about SLO violations is scarce. To the best of our kno wledge this is the rst time that these issues have been investigated in this setting.

There are sev eral open issues for future researc h. As dis-cussed in Section 3.3.1 better metho ds for mo del selection brings the promise of further impro vemen ts in the accuracy of the Bayesian net works based classi ers. One approac h we would like to investigate is the one describ ed in [19], whic h is based on main taining an ensem ble of mo dels. Finally , we would like to extend the forecasting objectiv e of the algo-rithms to include predicting whic h resource will be scarce as a consequence of the performance problem.
Man y thanks to Joe Fitszgerald and Tom Henessy for nu-merous discussions about applying these techniques to re-source allo cation and capacit y managemen t. George Forman pro vided commen ts on a previous version of this pap er.
