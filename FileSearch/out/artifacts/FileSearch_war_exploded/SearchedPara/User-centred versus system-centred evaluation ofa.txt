 1. Introduction
Information retrieval or information filtering systems are usually evaluated using a set of criteria that are independent of the users for which they are intended. Some of the most popular measures  X  recall and preci-sion  X  are based on a set of relevance judgments that are not usually obtained from the final users of the system, but rather from one or several experts in the domain. A typical instance of this method is provided by the TREC 3 conferences on information retrieval. This type of evaluation is more oriented to the system than to the user, in fact, the participation of users is not essential.

These expert judgments are an approximation of the reality, since the relevance of the documents associated to a query performed by a user depends on the specific context in which it is carried out. Other aspects of sys-tem use should be taken into account, such as the user experience, his preferences, the aim of the search, the use of the received information, etc. In fact, the concept of relevance has been discussed in a great extent in the bibliography with different interpretations ( Barry &amp; Schamber, 1998; Greisdorf, 2003; Mizzaro, 1997; Spink, Howard, &amp; Bateman, 1998 ).

On the other hand, there is a more recent tendency towards user-oriented evaluation, in which the user X  opinions about the use of the information retrieval system are collected, in an effort to obtain the impressions of the users about the system from their own point of view. This kind of evaluation may be aimed at collecting both qualitative and quantitative measures (i.e. recall and precision), but in all cases the participation of the users is always essential.

The work presented in this paper focuses on discussing the problem of user-centred versus system-centred evaluation of a Web content personalization system, with a dual goal: to present a case of how multi-faceted evaluations can be conducted, and to show how the combination of system and user centred evaluations can provide more insightful views in the examination of a system than each of them separately.

Web contents appear in many forms over different domains of application, but in most cases the form of presentation is the same for all users, that is, the contents are static in the sense that they are not adapted to each user. Content personalization is a technique that tries to avoid information overload through the adap-tation of web contents to each type of user.

Section 2 describes previous relevant work on user-centred and system-centred evaluation in information seeking environments and outlines an existing personalization system that is used as subject of observation in this paper. Section 3 describes the evaluation methodology, experimental setup and results obtained using user-centred and system-centred evaluations in an experiment performed with the personalization system described in Section 2 . In Section 4 the combined use of both types of evaluation is discussed. Finally, Section 5 outlines the main conclusions. 2. Previous work
The evaluation method proposed in this paper relies on previous studies about evaluation in information seeking environments and it is exemplified over an existing personalization system that combines a particularly broad selection of the features of such systems. 2.1. Evaluation in information seeking environments
The idea of applying a double evaluation (user-centred and system-centred) follows the approach of Ing-wersen and Ja  X  rveling (2005) in as much as it aims to evaluate an information system  X  in this case a person-alized information system  X  without leaving aside a global comprehension of the search process and the real information needs of the users potentially involved.

Below are presented the main ideas covered in existing studies about user-centred evaluation and system-centred evaluation. 2.1.1. User-centred studies
Recent years have seen an increase in the number of information retrieval research efforts that explore new ways of addressing the evaluation of information systems. The appearance of a cognitive and a social ten-dency, together with an increase in the number of user-centred information seeking works ( Beaulieu, 2003;
Borrego, 1999; Dalrymple, 2001; Fidel, 1993; Kuhlthau, 2005; Martzoukou, 2005; Rieh, 2004 ) constitute a good example of this.

The social approach, with a smaller projection, focuses on context and its interrelation with the users of infor-mation systems ( Harris, 1986; Hj X rland &amp; Albrechtsen, 1995;  X rom, 2000 ). On the other hand, a cognitive research school has also appeared ( Ellis, 1996; Ford, 2004; Wilson, 1997 ). An approach in process of construction that tries to promote a human view opposed to a technical andtraditional outlook, including different aspects such ments of information seeking, and the influence of individual characteristics or behaviour patterns. This research school proposes different theoretical models ( Beaulieu, 2003; Ja  X  rveling &amp; Wilson, 2003;
Kuhlthau, 2005; Vargas-Quesada, de Moya, &amp; Olvera, 2002 ): (a) the Ingwersen global model of poly-repre-sentation ( Ingwersen, 1996 ), that makes special emphasis on different aspects about requests, information problem and work task levels; (b) the model of Belkin (1990) , that points out interactions between the user and the system during each phase; (c) the stratified model of Saracevic (1996) , that tries to improve previous proposals, identifying information search processes in order to incorporate them to system design; (d) the interactive feedback model ( Spink, 1997 ), where the key is located in the effects of different types of feedback in information retrieval. Besides, this perspective relies on different research methodologies ( Caro-Castro,
Cedeira, &amp; Travieso, 2003; Martzoukou, 2005 ) such as recorded transactions, verbal questionnaires, inter-views as well as discussion groups and empirical observation. With reference to the analytical tasks, both quantitative and qualitative methods are usually used.

Some of these user-centred works pay attention to personalization of information access. It is necessary to underline the work made ( Spink, 2002 ) in the context of human interaction with search engines in Web, based on changes and actions that take place during episodes of information seeking. Another work in this direction is carried out by Salampasis and Diamantaras (2002) or by Kelly and Belkin (2002) and Kelly (2003) that pre-sents a naturalistic user study to understand how an individual X  X  online information behaviour can be used as implicit evidence for the construction and maintenance of a personalized user model. 2.1.2. System-centred studies
In this type of studies the comparison between systems or algorithms is based on the similarity between the relevance values assigned to each document by the system and the relevance judgments usually pre-assigned by experts (i.e. TREC conferences).

There are many metrics originating from information retrieval that can present evaluation results in the form of a curve, based on two values or on a single value. These metrics can be grouped into several categories depending on the type of relevance and the type of retrieval that are being considered ( Mizzaro, 2001; Salton &amp; McGill, 1983 ). In particular, normalized recall and normalized precision (nR and nP) ( Rocchio, 1971 )com-pare binary relevance with retrieval in the form of a ranking. Plotting recall or precision against the levels of the ranking, these metrics measure the effectiveness of the ranking in terms of the area of the graph delimited by the best possible solution, on one hand, and the solution generated by the system under evaluation, on the other. These metrics are calculated using formulas (1) and (2) , where REL is the number of relevant docu-ments, RANK i represents the position in the ranking of the i th relevant document, and N is the total number of documents in the collection.
 2.2. Personalization system for news services
A personalization system is based on three main functionalities: content selection, user model adaptation choice of the particular subset of all available documents that will be more relevant for a given user, as rep-1996 ) is built upon the interaction of the user with the system, which provides the feedback information used to evolve the profile. Results presentation involves generating a new result web document that contains, for each selected document, a personalized extract considered indicative of its content.

The evaluation processes will be applied in the frame of reference of a personalization system for a digital cesses and their evaluation. Their main characteristic is that every day a separate collection of new documents is made available that have to be personalized and distributed by means of an e-mail received by all users in the early hours of the morning. The choice of the particular system to be subjected to the evaluation was based on the fact that it integrates a broad number of the available technologies for specifying information needs.
This allows the consideration over a single system of evaluation procedures that are applicable to a large num-ber of systems, independently of the technologies that are being used for specifying information needs. 2.2.1. User model
The user model proposed consists of the combination of two types of user interests: long term and short time. The short-term model reflects the changes on these needs through the feedback of the user.
In the long term model, the first tier of selection corresponds to the sections of the digital newspaper. The user can assign a weight to each section ( S su ). For the second tier, the user enters a set of keywords, with an associated weight, to characterize his preferences ( k u ). For the third tier the user must choose, and assign a weight to them, a subset of the 14 categories in the first level of Yahoo! Spain ( C resented as term weight vectors ( c ) by training from the very brief descriptions of the first and second level of
Yahoo! Spain categories entries. In the fourth tier, short-term interests are represented by means of feedback 2.2.2. Multi-tier content selection and results presentation
Documents are downloaded from the web of a daily Spanish newspaper as HTML documents. For each document, title, section, URL and text are extracted, and a term weight vector representation for a document ( Salton &amp; McGill, 1983 ).

Each document is assigned the weight associated with the corresponding section associated to it in the par-ticular user model, which represents the similarity between a document d, belonging to a section s , and a user model u  X  s s du  X  . The similarities between a document d and a category c ( s keywords of a user model u  X  s k du  X  , and between a document d and the feedback terms of a short-term user model u  X  s f du  X  are computed using the cosine formula for similarity within the vector space model ( Salton &amp; McGill, 1983 ):
The similarity between a document d and the categories of a user model  X  s c formula:
The results are integrated using a particular combination of tiers of selection. The similarity between a doc-ument d and a user model u ( s du ) is computed as: categories, keywords, and feedback terms, respectively. To ensure significance, the relevance obtained from each tier must be normalized.

The format of the new document generated during the results presentation process is: a title with the date and the name of the user, a brief description of the interests of the user, a link to the user model edition, the selected documents ordered by relevance and for each document: title, author, section, source, relevance, feed-back icons and automatically generated summary adapted to the user.

Three phrase-selection methods are used to build summaries. The two first methods are generic: position and thematic words. The third one is based on the personalization of the summary using the information from the user model ( D X   X  az &amp; Gerva  X  s, 2007 ). 3. User-centred and system-centred evaluation of a personalization system
This section presents the evaluation methodology used in the user-centred and system-centred evaluations, the experimental setup, and the results obtained with both types of evaluations. 3.1. Methodology The methodology presented here has been designed to cover a large number of the approaches discussed in
Section 2.1 . The particular choice of sample system to evaluate has been chosen to ensure a broad coverage of these various approaches. 3.1.1. User-centred evaluation
This evaluation is based on the use of evaluation questionnaires that try to obtain explicit user opinions about different functionalities of the system. In particular, we propose the use of two evaluation question-naires, one to be filled in before using the system and the other to be filled in after using the system. The need for the two questionnaires arises from our interest in measuring the degree to which the system has fulfilled the initial expectations of each user.

The evaluation questionnaires contain questions that are grouped under the following headings: interface, user model, summaries, selection and adaptation, measurement of news relevance, global estimation, open questions and comments (see Appendix for more details). The questionnaires are composed mostly of closed questions, where answers are indicated by means of a rank of five levels (very high, high, regular, low, very low) or by means of the duality Yes/No. Additionally, there is also the possibility of answering open questions regarding system performance.

An initial group of questions (questions 1 X 6) asks about the degree of satisfaction with more important graphical components of the system, the degree in which the system is attractive for users, the facility to use the system and its friendliness, as well as questions on contents management and help facilities. These questions appear both in the initial and in the final questionnaires.

A second group of questions considers the different parts of the user model, that is, sections, categories and keywords. Regarding sections and categories (questions 7 X 10), users are asked about their suitability in order to reflect user information needs. In this sense, users are also required to answer whether they would introduce new sections or categories to reflect their information needs. On the other hand, in the final evaluation users are asked to what extent documents selected because they belong to sections or categories preferred by the user appear before documents that are not relevant. Finally, questions 13, 14, 16 and 17 enquire about possible changes in the use of sections or categories as personalization methods, as well as identifying the moments in time in which those changes took place. Regarding keywords, the questions try to discover if this option is relevant for specifying information needs (question 11). In the final evaluation (questions 18 X 24) users are asked to what extent the system is capable of showing news corresponding to selected keywords before news that do not contain selected keywords, and the extent to which documents retrieved according to intro-duced keywords correspond to information needs. Users are also asked about the clarity that the system offers at time of retrieving documents based on keywords, or about possible changes to their selection of keywords resulting from system use.

There is another group of questions (25 X 28) in the final evaluation that addresses the information selection and adaptation of the system through time. The following aspects are analysed: the validity of news rankings from the selected profile, the system adaptation with respect to user information needs and judgments, and the changes produced in user information needs.

Another set of questions (29 X 36) addresses opinions about summaries as a way to present the results to the users. Users are asked to what extent the summaries are well constructed, and about their coherence and clar-ity. In the same way, questions related to possible redundancies in the summaries or informative elements missing from the summaries are included. These questions appear in the final evaluation when the users have received the messages with the summaries.

The next group of questions serves to determine the criteria by which a user understands if an item is rel-evant or not. Thus, before using the system (question 12), each user is asked to indicate criteria that will be applied at the time of making this decision. After using the system (question 37), users reply to questions about the criteria they actually used. Similarly, before using the system users are also asked (question 13) about their degree of interest in the information that they are going to receive. On the other hand, in the final evaluation (question 39) users were asked about their real interest in the information received, and about (question 38) which particular elements they have consulted to decide if news were relevant or not: headline, section, rele-vance, summary or complete item.

The last issue addressed in the final questionnaire concerns a global evaluation of the system in terms of both the level of satisfaction and the confidence that users reach after working with it. This interest translates into questions (40 X 42) about the extent to which their information needs are solved and the degree of person-alization of the system. The users are also asked about the way that they prefer to define their profile (question 43).

Finally, both questionnaires finish with a set of open questions and comments. 3.1.2. System-centred evaluation
The results to be obtained are a ranking of documents for each user, obtained from the application of the selection process by means of formula (5) , where different combinations of tiers can be used giving different values to the parameters d , e , / , and c .

These results must be compared with binary relevance judgments collected previously. Evaluation collec-tions for personalization such as the one described in this paper present a major difficulty when compared with evaluation collections for other tasks: they require different relevance judgments for each and every one of the users for every particular day. This is because the tasks to be carried out in each case is to select the most rel-evant documents for each user on each day, and each user has different information needs (as featured in his user model) and these information needs may vary over time as the user becomes aware of new information.
These relevance judgments could either be generated artificially by a human expert by cross checking each user model with the set of documents for a given day (very much in the way the system is expected to do), or they can be established each day for the given documents by the real user who created the user model. This second option is more realistic, since real users determine the relevance of the given documents with respect to their interests at the moment of receiving them, therefore using their current information needs. In existing evalu-they are generated by a human expert that does not know what the particular information needs may be for different users involved in carrying out different tasks at different times. In our case the relevant judgments between each document and each user model are assigned by the proper users during the normal running of the system for several days.

The comparison between a ranking of documents and binary relevance judgments suggests the use of nor-malized to recall and precision metrics  X  formulas (1) and (2) . This is justified because rankings of documents rather than groups of documents are compared: one does not simply observe whether the first X documents are relevant or not, but rather their relative order in the ranking.

For evaluating summarization, the effect of selection (formula (5) ) over the different types of summaries is measured. This involves checking what results are obtained, as compared with user judgments, if instead of selecting news items based on their full text they are selected based on the summaries as input data. Then, the metrics used are again normalized recall and precision ( D X   X  az &amp; Gerva  X  s, 2007 ). 3.2. Evaluation setup
As an example of web documents for experimentation we have chosen the web pages of the digital edition of a Spanish newspaper. Experiments are evaluated over data collected for 106 users and the news items cor-responding to three weeks  X  14 working days  X  of the digital edition of the ABC Spanish newspaper. The aver-age number of news items per day is 78.5, obtained from the main seven sections of the newspaper. Out of 106 users, 90 filled in the initial evaluation form, whereas only 38 completed the final evaluation.
These different numbers are justified because the final questionnaire was provided after the last day and many users left the system before. The main reason why the users abandoned the experiment was the large quantity of news items that they had to judge everyday (78.5 news item per day on average).

In the end, 35 users filled both in the initial and the final evaluations. The user-centred evaluation has been applied to this set of users in order to obtain more significant results. With respect to these users, 60.0% were students, 31.4% were university lecturers (mainly in computing) and 8.6% were other professionals. The largest group of students was studying journalism (28.6% of the total number), followed by audiovisual communica-tion (20.0%) and computing (11.4%). In conclusion, the group is big and heterogeneous enough to allow the extraction of significant conclusions on its behaviour.

On the other hand, the system-centred evaluation has been applied to those users that have provided a sig-nificant number of judgments along the 14 working days. The final collection employed for system-centred evaluation has 395 different sets of relevance judgments. 3.3. Results
The evaluation results are presented separately for user-centred and system-centred evaluations in the next sections. As the number of users considered is different in each type of evaluation, the number of respondents associated with each percentage is indicated in each table. 3.3.1. User-centred evaluation results
With respect to the interface evaluation ( Table 1 ), it can be concluded that the initial impressions of the users about the interface were positive enough. In all cases similar trends were repeated in both evaluations, with a small increase in the scores for users X  opinions about the graphics components, usability and friendli-ness. However, a small decrease was also apparent in the scores for content management and system help facilities.

With respect to the user model ( Table 2 ), in the initial evaluation the users considered that keywords reflect better their information needs followed by sections and categories. Moreover, these high results confirm the three tiers of selection of the long term model as adequate for reflecting the users X  information needs. On the other hand, in the final evaluation, the users preferred sections, followed by keywords and categories, but with a small difference between all of them. However, a decrease is observed for all the methods.

On the other hand, it is important to note that a great decrease is observed for keywords. This is due mostly to the fact that keywords chosen by the user are in general few and very specific, making it very difficult for the system to find matches for them in the news items. Nonetheless, whenever they do appear in some news item, they lead to very high user satisfaction when that item is selected. A possible additional problem associated with keywords is their potential for polysemy. This does not occur frequently due to the high specificity of the words chosen by the users.

The validity of the set of sections and categories is also studied by asking the users whether they would introduce new sections or categories ( Table 3 ). For both sections and categories, users showed less need for introducing new elements after using the system than they had shown before using the system.

Users were also asked in the final evaluation whether the system selected documents corresponding to sec-tions, categories and keywords proposed by the users rather than documents not related to them ( Table 4 ).
Most users consider that sections allow a more adequate selection of documents. Slightly lower results are given to categories, but still with mostly positive results. In contrast, users are less convinced about keywords. Again, this can be related either to the high specificity of keywords or to possible problems of polysemy.
In the final evaluation some additional questions concerning keywords were included ( Table 5 ). It is clear that the use of keywords on their own for defining a user profile would have led to much less satisfaction in the use of the system, even though for a great quantity of the users the performance of keywords was satisfactory.
Approximately the majority of the users recognize the usefulness of some utility to show words related to their input so as to be able to refine their user profile.

Finally, users were asked in the final evaluation for their preferences with respect to a particular method for the selection using keywords, users feel that they are still the best way for defining their information needs.
This is probably due to the fact that it provides a very specific tier of selection as opposed to sections or cat-egories, where the definition of interests is very broad.

With respect to the users X  estimations on the efficiency of the selection and adaptation processes, as given in the final evaluation ( Table 7 ), users consider that the system adapts better to their relevance judgments than to their information needs, even though these adaptations are satisfactory for less than the half of the users. On the other hand, most users do not change their information needs throughout their use of the system. Finally, users judge that they receive news items they are interested in more than news items that they are not interested in. This suggests that the selection and adaptation processes are in most cases judged positively.
With respect to the summaries ( Table 8 ), most users consider that the summaries are of high quality, coher-ent, and clear, and that they reflect the content and the main ingredients of the corresponding document. Most of them also consider, though to a lesser degree, that the summaries contain no redundancies and that they are well adapted to user profile and user needs. This positive evaluation indicates that the method of sentence selection for the construction of summaries is a valid approach for results presentation in the face of possible problems of clarity, coherence and redundancy.

The criteria employed to decide about the relevance of a document seem to match more or less from the initial to the final evaluation. The criteria selected more often were: relation with information needs and sub-ject of interest, relation with user profile, usefulness and novelty. The criteria selected less often were: style, proximity and degree of motivation from an emotional point of view, proximity and familiarity with the con-tent, and, finally, proximity and familiarity with the language employed. With respect to the part of the news item used to establish the relevance ( Table 9 ), it can be concluded that the summary becomes an important element for defining the relevance of a news item, justifying the proposed schema for presentation of results.
Finally, most users value the system positively. The great majority is satisfied and confident, and thinks that the system solves his information needs directed at a daily online newspaper. On the other hand, they consider the system offers an appropriate way of personalization ( Table 10 ).
 3.3.2. System-centred evaluation results
To carry out the evaluation, judgments from the user are required as to which news items are relevant or not for each of the days of the experiment. Because the evaluation is based on these judgments, significant results can only be obtained for those users that have provided judgments over and above a minimum thresh-old in terms of number of judgments per day. As the evaluation process involved an effort for the users, only 37.4 users per day actually provided judgments. Additionally, some users only perform judgments for less than 10 news item per day. These users have been eliminated for the evaluation in order to obtain more significant results. The final collection employed for evaluation presented, on average, 28.6 users per day, which repre-sents 395 different judgments.

For the multi-tier selection process ( Table 11 ), the best results are obtained using a combination of a long model based on sections, categories and keywords, together with a short term model (L(SeCaKe)S). The rela-tive order for the rest of combinations of long and short term models is: sections and categories (L(SeKe)S), sections and keywords (L(SeKe)S), categories and keywords (L(CaKe)S), only sections (L(Se)S), only catego-ries (L(Ca)S) and only keywords (L(Ke)S). The worst result appears when only the short term model is used (S).
For the evaluation of the summaries ( Table 12 ), it can be concluded that personalized summaries (Ps) that use a combination of long and short term models are better than other types of summaries in terms of nor-malized precision and recall. Complete news item (C) offer only a slight improvement against personalized summaries, which seems to indicate that the loss of information for the user is very small with this type of summary.

More specific details of these evaluation results are given in D X   X  az and Gerva  X  s (2004, 2007) . 4. Comparison and discussion
The opinions about each method do suffer significant changes between the initial and final evaluations. Ini-tially, the users prefer keywords followed by sections and categories. At the end, the users prefer sections, cat-egories and keywords, but with similar grades. When the users are asked for the degree in which the system shows documents related with the selected items for each tier of selection before documents that are not related, they value better the sections, followed by categories, and a poor last, keywords. This matches with the results obtained in the system-centred evaluation where the frameworks that offer better results in normal-ized precision and recall are the sections, followed by categories and keywords. This evaluation already showed the preponderance of category-based methods over keywords. This affects specially the combination of long and short term models, which improves significantly in all cases except where keywords are used ( D X   X  az &amp; Gerva  X  s, 2004 ).

As can be observed, the impressions about the keywords have a particular behaviour that cannot be detected in a system-centred evaluation. The users decrease their view about the suitability of the keywords erence to determine by themselves their interests in the more specific way.

With respect to the measurement of news relevance, users show a special preference for criteria reflecting interest, that is, that the news item was relevant to the user, followed by novelty criteria. On the other hand, the style, the depth and the proximity have been the criteria less applied by the users. The related criterion of whether the news item added new knowledge showed an increase of 10% after system use, probably due to the fact that the collection included several streams of documents about the same subject. Stated preference for depth and quantity of information as selection criteria decreased by 32%, possibly because users faced with periodic collections of documents shift their preference from more verbose towards more concise alternatives of presentation.

With respect to system generated summaries, user-centred evaluation underlines the idea that offering users a summary of each news item is a good solution that reduces information overload. Additionally, the fact that users claim to have used mainly the summaries to determine if a given news item was relevant for them allow us to conclude that user adapted summaries are a useful tool to assist users in a personalization system. This aspect cannot be detected with the system-centred evaluation.

The evaluation method proposed here is designed to cover a range of means of specifying information needs that captures most general trends in current information systems. This makes it possible to apply for evaluating personalization systems irrespective of whether they employ domain-specific sections, keywords, categories, or omit the parts of the evaluation method that concern those that do not feature. On the other hand, for the type of system used in this paper, based on multi-tier selection, the system oriented evaluation of each method car-ried out independently may be overridden by significantly contrasting results in the user-based evaluation. For instance, a large proportion of replies stating preference for one method of specifying information needs over another may lead to a decision to select one in favour of the other irrespective of their measured efficiency.
The introduction of objective metrics in the field of information retrieval had a very positive effect in the development of efficient algorithms and the identification of the most successful techniques. However, it also brought about a secondary effect of side-lining issues of usability or user satisfaction with the methods being introduced. System-centred evaluations tend to focus on efficiency issues on abstract terms, as related to a sin-gle system run over an evaluation collection with set standard results. The range of variation between the results obtained for the metrics is not necessarily large, and very small improvements are considered significant based only on statistical information. This may be a good alternative for guiding the development of algo-rithms, but it is a poor approach for the guiding the development of systems designed for human users.
The motor car industry has long since accepted that the refinements and tuning possibilities that can make a Formula (1) prototype maximally efficient at the racing track need not be the kind of feature that a user wants in the car he drives to work everyday, irrespective of the objective data presented in the dashboard or provided by the stopwatch. Yet the evaluation methods generally employed for information systems still tend to concentrate mainly in the objective numerical metrics rather than on collecting the impressions of X  X sers in the street X . 5. Conclusions
The results obtained in the evaluation of a Web content personalization system, with 106 users during 14 working days, show general satisfaction on various aspects of the system and they indicate that user percep-tions agree with the objective system oriented evaluation. Additionally, user centred evaluation provides valu-able data concerning the behaviour of the users with respect to issues such as document relevance or the relative importance attributed to different ways of personalization. In particular, the analysis of the different methods of selection has shown that sections, categories and keywords are useful as means of specifying infor-mation needs for different goals. Sections are more appropriate when users want to identify a general interest on documents that belong to a prefixed section in newspapers. Keywords are more useful when a user wants to define a more specific interest. Categories provide users with a more intuitive and general procedure beyond the rigid selection connected to sections. For an application of personalization, to use a combination of tiers of selection allows users to define information needs from different points of view.

With respect to the relative merits of the two evaluation methods that have been applied, it seems clear that the combination of both methods provides more information about the real performance of a system than either one on its own. If only system-centred evaluation is applied, the information obtained concerns only what the best configuration of the evaluated system is in terms of efficiency, but no impressions are gathered about user opinion. On the other hand, if only a user-centred evaluation is used, impressions and efficiency measures for specific runs of the system are collected, but such data may not be extrapolated to other config-urations or sets of techniques.

The work undertaken in this paper, in what concerns user-centred evaluation, has taken into account the corresponding theoretical and conceptual models, though they have not been applied formally. Additionally, the evaluation employed combines the different perspectives followed in user-centred studies. It considers the most relevant aspects in terms of users information needs, degree of satisfaction, behaviour, efficiency, utility, friendliness and relevance. In this way, it goes beyond the evaluation of a specific system architecture. For the type of system under evaluation, a personalized system, existing literature shows a shortage of studies that combine user-centred and system-centred evaluation. In subsequent studies, research might focus on propos-ing and validating new metrics, on identifying and modelling user motivation and expectations, or on relating information tasks with the different types of user information needs.
 Acknowledgements
This research has been partially funded by the Spanish Ministerio de Ciencia y Tecnolog X   X  a (TIN2006-14433-C02-01) and by the Universidad Complutense de Madrid (AE5/06-15073).

Appendix. A sample questionnaire of the kind described in Section 3.1.1 is presented below. It corresponds to the final questionnaire, which also includes all the questions given in the initial questionnaire (question num-bers in brackets).

Final Questionnaire ( 1 ) Interface evaluation ( 2 ) User model ( 3 ) Selection and adaptation ( 4 ) Summaries ( 5 ) Measurement of news relevance ( 6 ) Global estimation ( 7 ) Open questions ( 8 ) Comments References
