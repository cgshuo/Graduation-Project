 In this paper we tackle the problem of recommendation in the scenarios with binary relevance data, when only a few ( k ) items are recommended to individual users. Past work on Collaborative Filtering (CF) has either not addressed the ranking problem for binary relevance datasets, or not specifically focused on improving top-k recommendations. To solve the problem we propose a new CF approach, Col-laborative Less-is-More Filtering (CLiMF) . In CLiMF the model parameters are learned by directly maximizing the Mean Reciprocal Rank (MRR), which is a well-known in-formation retrieval metric for measuring the performance of top-k recommendations. We achieve linear computational complexity by introducing a lower bound of the smoothed reciprocal rank metric. Experiments on two social network datasets demonstrate the effectiveness and the scalability of CLiMF , and show that CLiMF significantly outperforms a naive baseline and two state-of-the-art CF methods. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Collaborative filtering, learning to rank, less is more, matrix factorization, mean reciprocal rank
Collaborative Filtering (CF) [1] methods are at the core of most recommendation engines in online web-stores and social networks. The main underlying idea behind CF meth-ods is that users that shared common interests in the past  X 
Part of this work was conducted when the first author was an intern at Telefonica Research, Barcelona.
 would still prefer similar products/items in the future [22]. While a lot of the CF literature has been devoted to recom-mendation scenarios where explicit user feedback is present (i.e., typically ratings), CF has also shown to be very valu-able in scenarios with only implicit feedback data [12], e.g., the counts of a user watching a TV show, the counts of a user listening to songs of an artist. These counts can be interpreted as a measure of preference and thus a proxy to explicit feedback.

However, in some scenarios even the  X  X ount X  information is not available, while only binary relevance data exists, e.g., the friendship between users in a Online Social Network, the follow relationship between users (or between a user and an event, etc.) in Twitter 1 or the dating history in online dat-ing sites [20]. Specifically, in these scenarios, we use  X 1 X  for a given user-item pair to denote that the user has an interaction (e.g., friendship, follow) with the item, and  X 0 X  otherwise. Typically the observed interactions are regarded as positive signals (i.e., indicating relevant items), and al-though not all items without observed interactions are irrele-vant it is safe to assume the vast majority of these items will be irrelevant for the user. In other words, for a given user, the signal  X 0 X  indicates an item set containing unobserved items that could be relevant, but are most likely irrelevant. One of the most typical CF methods for those scenarios is item-based CF [9, 15], in which an item-item similarity ma-trix is first computed, and users are recommended items that are most similar to their past relevant items. However, item-based CF approaches typically require expensive com-putations in order to construct the similarity matrix. They are thus not a sound solution for large scale scenarios.
Bayesian Personalized Ranking (BPR) [21] has been re-cently proposed as a state-of-the-art recommendation algo-rithm for situations with binary relevance data. The opti-mization criterion of BPR is essentially based on pair-wise comparisons between relevant and a sample of irrelevant items. This criterion leads to the optimization of the Area Under the Curve (AUC). However, the AUC measure does not reflect well the quality of the recommendation lists, since it is not a top-biased measure [34], i.e., the position at which the pairwise comparisons are made is irrelevant to the con-tribution to the loss: mistakes at the lower ranked positions are penalized equally to mistakes in higher ranked positions, which is not the desired behavior in a ranked list. http://twitter.com/
In view of the drawbacks of previous work, we propose a new CF approach, Collaborative Less-is More Filtering (CLiMF) , that is tailored to recommendation domains where only binary relevance data is available. CLiMF models the data by means of directly optimizing the Mean Reciprocal Rank (MRR) [29], a well-known evaluation metric in Infor-mation Retrieval (IR). Given the analogy between query-document search and user-item recommendation, we can define the Reciprocal Rank (RR) for a given recommenda-tion list of a user, by measuring how early in the list (i.e. how highly ranked) the first relevant recommended item is ranked. The MRR is the average of the RR across all the recommendation lists for individual users. MRR is a par-ticularly important measure of recommendation quality for domains that usually provide users with only few but valu-able recommendations (i.e., the less-is-more effect [7]), such as friends recommendation in social networks where top-3 or top-5 performance is important.

Taking insights from the area of learning to rank and in-tegrating latent factor models from CF, CLiMF directly op-timizes a lower bound of the smoothed RR for learning the model parameters, i.e., latent factors of users and items, which are then used to generate item recommendations for individual users.

Our contributions in this paper can be summarized as:
The paper is organized as follows. In Section 2 we discuss the related work and position our paper with respect to it. Section 3 presents in detail the proposed CLiMF model. Our experimental evaluation is described in Section 4, followed by a summary and conclusions in Section 5.
The work presented in this paper closely relates to the research on ranking-oriented CF and learning to rank. In the following, we briefly review related work.
A large portion of the Recommender Systems literature has been devoted to the rating prediction problem, as de-fined in the Netflix prize competition 2 . Latent factor mod-els and in particular Matrix Factorization (MF) techniques, have been shown to be particularly effective [2, 13, 23] for this problem. The main idea underlying MF is to extract latent factor U i , V j vectors for each user and item in the dataset so that the inner product of these factors f  X  U i ,V j  X  fits the observed ratings.

Several state-of-the-art ranking-oriented CF approaches, that extend upon MF techniques, have been recently pro-posed. These approaches typically use a ranking oriented objective function to learn the latent factors of users and http://www.netflixprize.com/ items, e.g., CofiRank [31], collaborative competitive filter-ing (CCF) [33], and OrdRec [14]. The CLiMF model pre-sented in this paper can also be regarded as an extension to conventional MF, while it introduces several new charac-teristics that are presented in Section 3.4, compared to the state-of-the-art.

A ranking-oriented CF that extends memory-based (or similarity-based) approaches has been proposed in Eigen-Rank [16]. Moreover extensions to probabilistic latent se-mantic analysis [11] that optimize a ranking objective have been proposed in pLPA [17]. However, these methods are all designed for recommendation scenarios with explicit graded relevance scores from users to items.

For the use scenarios with only implicit feedback data, one of the first model-based methods was introduced in [12], where an extension of MF is proposed by weighting each factorization of user-item interaction proportionately to the count of the interactions. A similar approach, one-class col-laborative filtering [19], was also proposed to exploit weight-ing schemes for the factorizations of missing data, which are taken as non-positive examples. However, the computa-tional cost of that work could be inflated due to the large number of non-positive data. In this paper, we study the problem of generating recommendations for the scenarios with only binary relevance data, i.e., where even the count of user-item interaction is not available. In addition, our work directly takes into account an evaluation metric, MRR, when developing the recommendation model, which is also substantially different from the work of [12, 19].

The most similar work to ours is Bayesian personalized ranking (BPR) [21], since it also optimizes a ranking loss (AUC) and deals with binary relevance data. The main benefits of using CLiMF lies in its performance in terms of top-k recommendations (i.e., the fraction of relevant items at the top k positions of the list), an issue not addressed by the BPR model. Note that we also leave the detailed discussion of the relationship between CLiMF and BPR to Section 3.4, after the presentation of the CLiMF model.
Learning to Rank (LTR) has been an active research topic in Machine Learning, Information Retrieval [18] and Rec-ommender Systems [3, 25, 31]. The work in this paper is closely related to one branch of LTR that focuses on direct optimization of IR metrics, for which the main difficulty lies in their non-smoothness with respect to the predicted rel-evance scores [4]. The approaches proposed in this branch of LTR approximate the optimization of IR measures ei-ther by minimizing convex upper bounds of loss functions that are based on the evaluation measures [5, 31, 32], e.g., SV M MAP [34], or by optimizing a smoothed version of an evaluation measure, e.g., SoftRank [28] and generalized SoftRank [6].
 In this paper, we also propose to approximate the Mean Reciprocal Rank (MRR) with a smoothed function. How-ever, our work is different from aforementioned work not only in that we target the application scenario of recommen-dation rather than query-document search, but also in that we propose an algorithm (CLiMF) that makes the optimiza-tion of the smoothed MRR tractable and scalable. We also provide insights about the ability of CLiMF to recommend relevant items in the top positions of a recommendation list.
In this section, we present the CLiMF , Collaborative Less-is-More Filtering, algorithm. We first introduce a smoothed version of Reciprocal Rank by building on insights from the area of learning to rank. Then, we derive a lower bound of the smoothed reciprocal rank, and formulate an objec-tive function for which standard optimization methods can be deployed. Finally, we discuss the characteristics of the proposed CLiMF model and its relation to other state-of-the-art recommendation models.
The definition of reciprocal rank of a ranked list for user i , as defined in information retrieval [29], can be expressed as: in which N is the number of items, Y ij denotes the binary relevance score of item j to user i , i.e., Y ij = 1 if item j is relevant to user i , 0 otherwise. I ( x ) is an indicator function that is equal to 1, if x is true, otherwise 0. R ij denotes the rank of item j in the ranked list of items for user i . Note that the items are ranked in a descending order according to their predicted relevance scores for user i . Clearly, RR is dependent on the rankings of relevant items. The rank-ings of the relevant items change in a non-smooth way as a function of the predicted relevance scores and thus, RR is a non-smooth function over the model parameters. The non-smoothness of the RR measure makes it impossible to use standard optimization methods  X  X uch as gradient-based methods X  to directly optimize RR i . Inspired by recent de-velopments in the area of learning to rank [6], we derive an approximation of I ( R ik &lt; R ij ) by using a logistic function: where g ( x ) = 1 / (1 + e  X  x ), f ij denotes the predictor func-tion that maps the parameters from user i and item j to a predicted relevance score. The predictor function that we use in our model is the basic and widely-used factor model, expressed as: where U i denotes a d -dimensional latent factor vector for user i , and V j a d -dimensional latent factor vector for item j . Even though a sophisticated approximation for the item rank was proposed in [6], it has not been deployed in prac-tice. Notice that in the case of RR i in Eq. (1), only 1 /R is actually in use. We thus propose to directly approximate 1 /R ij by another logistic function: which makes the basic assumption that the lower the item rank, the higher the predicted relevance score, i.e., 1 /R would approach to 1. Substituting Eq. (2) and (4) into Eq. (1), we obtain a smooth version of RR i : Notice that although Eq. (5) is a smooth function with re-spect to the predicted relevance scores and thus the model parameters U and V , optimizing this function could still be practically intractable, due to its multiplicative nature. For example, the complexity of the gradient of Eq. (5) with respect to V j (i.e., only for one item) is O ( N 2 ): the compu-tational cost grows quadratically with the number of items N and for most recommender systems N is typically large. In the following, we present a lower bound of an equivalent variant of Eq. (5), for which we derive a computationally tractable optimization procedure.
Suppose that the number of relevant items for user i in the given data collection is n + i . Given the monotonicity of the logarithm function, the model parameters that maxi-mize Eq. (5) are equivalent to the parameters that maximize ln( 1 U ,V = arg max
Based on Jensen X  X  inequality and the concavity of the log-arithm function, we derive the lower bound of ln( 1 as below: = ln  X  1 = 1 Note that in the derivation above we make use of the defini-1 /n + i in the lower bound, and obtain a new objective func-tion as: L ( U i ,V ) = We can take a close look at the two terms within the first summation. The maximization of the first term contributes to learning latent factors that promote relevant items. How-ever, given one relevant item, e.g., item j , maximizing the second term contributes to learning latent factors of all the other items (e.g., item k ) in order to degrade their relevance scores. In sum, the two effects come together to promote and scatter the relevant items at the same time, the main char-acteristic of the proposed CLiMF . In other words, CLiMF will lead to a recommendation where some but not all rel-evant items are at the very top of the recommendation list for a user. We notice that this behavior of CLiMF corre-sponds to the analysis of MRR optimization for a search result list [30], i.e., optimizing MRR results in diversifying ranked documents.

Taking into account the regularization terms that usually serve to control the complexity of the model (i.e. in order to avoid overfitting), and all the M users in the given data collection, we obtain the objective function of CLiMF : in which  X  denotes the regularization coefficient, and k U k denotes the Frobenius norm of U . Note that the lower bound F ( U,V ) is much less complex than the original objective function in Eq. (5), and standard optimization methods, e.g., gradient ascend, can be used to learn the optimal model parameters U and V .
We use stochastic gradient ascent to maximize the objec-tive function in Eq. (9), i.e., for each user i , we optimize F ( U i ,V ). The gradients of the objective for user i with respect to U i and V j can be computed as below: where g 0 ( x ) denotes the derivative of g ( x ). Note that we have used a property of g ( x ), namely, g (  X  x ) = g 0 ( x ) /g ( x ), in the derivation of Eq. (10) and (11) above to simplify the computation.

The learning algorithm for the CLiMF model is outlined in Algorithm 1. We analyze the complexity of the learning process for one iteration. By exploiting the data sparse-ness in Y , the computational complexity of the gradient in Eq. (10) is O ( d  X  n 2 M + dM ). Note that  X  n denotes the average number of relevant items across all the users. The complex-ity of computing the gradient in Eq. (11) is O ( d  X  n 2 Hence, the complexity of the learning algorithm in one it-eration is in the order of O ( d  X  n 2 M ). In the case that  X  n is a small number, i.e.,  X  n 2 &lt;&lt; M , the complexity is linear to the number of users in the data collection. Note that we have  X  nM = S , in which S denotes the number of non-zeros in the user-item matrix. The complexity of the learning algorithm is then O ( d  X  nS ). Since we usually have  X  n &lt;&lt; S , the com-plexity is O ( dS ) even in the case that  X  n is large, i.e., being linear to the number of non-zeros (i.e., relevant observations in the data). In sum, our analysis shows that CLiMF is suitable for large scale use cases. Note that we also em-pirically verify the complexity of the learning algorithm in Section 4.4.
We discuss the relationship between the proposed CLiMF and other state-of-the-art recommendation models, and present the insights that highlight the contribution of CLiMF to the area of CF when compared to other models.

Relation to CofiRank : CofiRank [31] was the first work that introduced learning to rank to address CF as a ranking problem. CofiRank makes use of structured estimation of a ranking loss based on NDCG, and learns the recommenda-tion model by minimizing over a convex upper bound of the loss function. The major differences between CLiMF and CofiRank lie in two aspects: First, due to its foundation on the measure of NDCG, CofiRank suits scenarios where graded relevance data, e.g., ratings, are available from users to items, but it might not be appropriate for the scenarios with only binary relevance data, for which CLiMF is tai-lored. Second, CofiRank and CLiMF root in different classes of methods to achieve learning to rank [18, 32], such as the difference between SV M MAP [34] and SoftRank [28]. Cofi-Rank exploits a convex upper bound of the structured loss function based on the evaluation metric NDCG, and then optimizes the upper bound. However, CLiMF first smooths the evaluation metric RR, and then optimizes the smoothed version of the metric via a lower bound.

Relation to CCF : Collaborative competitive filtering (CCF) [33] was proposed as an algorithm that not only ex-ploits rated items from users, but also the candidate items (or opportunities ) that were available for the users to choose. The key constraint introduced in CCF is that the utility (or relevance) of a rated item should be higher than any items that are in the candidate set but not rated/selected. CLiMF is similar to CCF in the sense that it also considers the rel-ative pair-wise constraints in learning the latent factors, as shown in the second term with the summation in Eq. (8). However, CLiMF only requires relevant items, while CCF requires all the items in the candidate set, which are not usually available. In practice, CCF needs to include some unrated items together with the rated items to form the candidate set. In addition, CCF is not directly related to any evaluation metrics, while CLiMF is designed for MRR optimization.

Relation to OrdRec : OrdRec [14] is an ordinal model that formulates the probability that a rating predictor (a function of the model parameters, such as the latent fac-tors) is equal to a known rating as the probability that the rating predictor falls in the interval of two parameterized scale thresholds corresponding to two adjacent rating val-ues. OrdRec has a point-wise nature, i.e., it does not re-quire any pair-wise computation between any rated/unrated items. Hence, it enjoys the advantage of a computational complexity that is linear to the data size, the same advan-tage attained by CLiMF . However, although OrdRec gener-ally suits to scenarios with implicit feedback data,  X  X ount X  information is necessary to extract the ordinals, i.e., the or-dered preferences of users. For this reason, OrdRec may not be suitable for the scenarios with only binary relevance data. In addition, OrdRec has no direct relation to the ranking-oriented evaluation metrics.

Relation to BPR : BPR [21] models the pair-wise com-parisons between positive and negative feedback data (in the scenarios with binary relevance data), and optimizes an objective that corresponds to Area Under Curve (AUC) op-timization. BPR is similar to CLiMF in the sense that it also directly optimizes a smoothed version of an evaluation metric for binary relevance data, there are though two main differences. First, BPR requires a sampled set of negative feedback data, i.e., a set of unobserved items to be assumed as irrelevant to the users. However, CLiMF only requires the relevant items from the users. Second, while BPR aims at promoting all the relevant items, CLiMF particularly fo-cuses on recommending items that are few in number, but relevant at top-k positions of the recommendation list, a goal which is attained by promoting and scattering relevant items at the same time, as shown in Eq. (8). Since BPR shares a close relationship with CLiMF in terms of model-ing and application scenarios, we choose BPR as the main baseline to compare against in the experiments.
In this section we present a series of experiments to evalu-ate CLiMF . We first describe the datasets used in the exper-iments and the setup. Then, we compare the recommenda-tion performance of CLiMF with two baseline approaches in terms of providing only a few but relevant recommendations at the top positions of the recommendation list. Finally, we analyze the effectiveness and the scalability of the proposed CLiMF model.

We designed the experiments in order to address the fol-lowing research questions: 1. Does the proposed CLiMF outperform alternative state-2. Is the learning algorithm of CLiMF effective for in-3. Is CLiMF scalable for large-scale use cases?
We conduct experiments using two social network datasets from Epinions 3 and Tuenti 4 . The Epinions dataset is pub-licly available 5 , and it contains trust relationships between 49288 users. The Epinions dataset represents a directed so-cial network, i.e., if user i is a trustee of user j , user j is not necessary a trustee of user i . Most microblogging social net-works are also directed, such as Twitter. For the purpose of our experiments, we exclude from the dataset the users who have less than 25 trustees. The second dataset collected from Tuenti, one of the largest social networks in Spain, represents an undirected social network, containing friend-ship between 50K users. Similar to the Epinions dataset, we also exclude the users with less than 25 friends. Note that in these two datasets, friends or trustees are regarded as  X  X tems X  of users. The task is to generate friend or trustee recommendations for individual users. Statistics on the two datasets used in our experiments are summarized in Table 1.
We separate each dataset into a training set and a test set under various conditions of user profiles. For example, the condition of  X  X iven 5 X  denotes that for each user we randomly selected 5 out of her trustees/friends to form the training set, and use the remaining trustees/friends to form the test set. The task is to use the training set to generate recommendation lists for individual users, and the perfor-mance is measured according to the holdout data in the test set. We repeat the experiment 5 times for each of the dif-ferent conditions of each dataset, and the performances re-ported are averaged across 5 runs. Again, we emphasize that in this work we only consider the observed items as being relevant to the user. Although this setting would underes-timate the power of all the recommenders, the comparative results are still useful, since they can be regarded as the approximation of the lower limit of each recommender.
The main evaluation metric that we use in our experi-ments to measure the recommendation performance is MRR, the measure that is optimized in our model. In addition, we also measure the performance by precision at top-ranked items, such as precision at top-5 (P@5), which reflects the ratio of the number of relevant items in the top-5 recom-mended items. In order to emphasize the value of  X  X ess-is-more X  recommendations, we also use the measure of 1-call at top-ranked items [7]. Specifically, 1-call at top-5 recommen-dations (1-call@5) reflects the ratio of test users who have at least one relevant item in their top-5 recommendation lists.
Finally, as revealed in recent studies from different rec-ommender domains, it is possible that popular items could http://www.epinions.com http://www.tuenti.com http://www.trustlet.org/wiki/Downloaded Epinions dataset Figure 1: Effectiveness of the learning algorithm for CLiMF under the  X  X iven 5 X  condition for both datasets. heavily dominate the recommendation performance [8, 26, 27]. We also notice this effect in our experiments, namely, recommending the most popular friends or trustees (i.e., those have the most friends or trusters) could already result in a high performance. For this reason, in our experiments we consider the top three most popular items as being irrel-evant in order to reduce the influence from the most trivial recommendations [8, 26]. In other words, recommending any of the top three popular friends/ trustees has no contribu-tion to any of the evaluation metrics.
We use one fold of randomly generated training-test sets of each dataset under the condition  X  X iven 5 X  for the purpose of validation, which is used to tune parameters in CLiMF. The values of the parameters that yield the best performance on the validation set are: the regularization parameter  X  = 0 . 001, the latent dimensionality d = 10 and the learning rate  X  = 0 . 0001.
We compare the performance of CLiMF with three base-lines, PopRec, iMF and BPR, which are described below:
The recommendation performances of CLiMF and the baseline approaches on the Epinions and the Tuenti datasets are shown in Table 2 and Table 3, respectively.
 Three main observations can be drawn from the results: First, the proposed CLiMF model significantly outperforms the three baselines in terms of MRR across all the condi-tions and the two datasets. Note that in our experiments, the statistical significance is measured based on the results from individual test users, according to a Wilcoxon signed rank significance test with p &lt; 0.01. This result corroborates that CLiMF achieves the goal that was designed for and optimizes the value of the reciprocal rank for the recom-mendations to the individual users. Notice that it is not possible to compare the results in Table 2 and Table 3 across conditions, since different conditions involve a different set of test items, containing different numbers of items. Sec-ond, CLiMF also achieves a significant improvement over the baselines in terms of P@5 and 1-call@5 across all the conditions and the two datasets. The improvement of P@5 indicates that by optimizing MRR, CLiMF also improve the quality of recommendations among the top-ranked items. In addition, the improvement of 1-call@5 supports that CLiMF particularly contributes to providing valuable recommenda-tions at the top-k positions, i.e., raising the chance that users would receive at least one relevant recommendation among just a few top-ranked items. Compared to BPR, where AUC is optimized, CLiMF succeeds in enhancing the top-ranked performance by optimizing MRR, the top-biased metric. As can be also seen from the results, iMF performs worse than both BPR and CLiMF in all the conditions of the Epinions dataset and in most of the conditions of the Tuenti dataset. The reason might be that iMF is particularly designed for implicit feedback datasets with the  X  X ount X  information as mentioned in Section 2, while it may not be suitable for the scenarios with only binary relevance data. Third, in cases in which users have a lower number of friends/trustees (i.e., the case of  X  X iven 5 X ) the improvement achieved by CLiMF over the alternative approaches is relatively larger than the improvement achieved in cases in which users have a higher number of friends/trustees (i.e., the case of  X  X iven 20 X ). This result suggests that CLiMF X  X  key mechanism of scattering relevant items could be particularly beneficial for scenarios under very high data sparseness. Hence, we give a positive answer to our first research question.
The second experiment investigates the effectiveness of the proposed learning algorithm for CLiMF , as presented in Sec-tion 3.3. Figures 1 (a) and (b) show the evolution of MRR with each iteration  X  X s measured in both the training and the test sets X  under the  X  X iven 5 X  condition for the Epin-ions and Tuenti datasets, respectively. We can see that both MRR measures gradually increase with each iteration and convergence is reached after a few iterations, i.e., nearly af-ter 20 iterations on the Epinions dataset and 30 iterations on the Tuenti dataset. This observation indicates that CLiMF effectively learns from the training set latent factors of users and items that optimize reciprocal rank, which consequently also contributes to improving MRR in the test set. With this experimental result, we give a positive answer to our second research question.
The last experiment investigates the scalability of CLiMF , by measuring the training time that is required for the train-ing set at different scales. First, as analyzed in Section 3.3, the computational complexity of CLiMF is linear in the number of users in the training set when the average number of friends/trustees per user is fixed. To demonstrate the scal-ability, we use different numbers of users in the training set under each condition: we randomly select from 10% to 100% users in the training set and their known friends/trustees as the training data for learning the latent factors. The results on the Epinions dataset and the Tuenti dataset are shown in Fig. 2(a) and 2(b), respectively. We can observe that for both datasets, the computational time under each condition increases almost linearly to the increase of the number of users. Second, as also discussed in Section 3.3, the computa-tional complexity of CLiMF could be further approximated to be linear to the amount of known data (i.e., non-zero en-tries in the training user-item matrix). To demonstrate this, we examine the runtime of the learning algorithm against different scales of the training sets under different  X  X iven X  conditions. For example, under the  X  X iven 5 X  condition of the Epinions dataset, there are 5  X  4718=23590 non-zeros in the training set. The result is shown in Fig. 3, from which we can observe that the average runtime of the learning algo-rithm per iteration increases almost linearly as the number of non-zeros in the training set increases. The observations from this experiment allow us to answer our last research question positively. In this paper we have presented a new CF approach, CLiMF , that learns latent factors of users and items by di-rectly maximizing MRR. CLiMF is designed to improve the performance of top-k recommendations for usage scenarios with only binary relevance data. We have demonstrated in our experiments that CLiMF offers significant improve-ments over a naive and two state-of-the-art baselines in two social network datasets. We have also experimentally vali-dated that CLiMF X  X  learning algorithm is effective for MRR optimization, and has linear computational complexity to the size of the known data, and thus is scalable for large scale use cases.

Future work involves a few interesting directions. First, we would like to extend our CLiMF model to suit domains with explicit feedback data, e.g., ratings. Second, it is also interesting to experimentally investigate the impact of CLiMF on the recommendation diversity, by exploiting external in-formation resources, such as the categories of items. Third, we are also interested in investigating recommendation mod-els that optimize other evaluation measures, such as mean average precision [24], and in exploring the impact of opti-mizing different measures on various aspects of recommen-dation performance [30]. This work is funded, in part, as part of a Marie Curie Intra European Fellowship for Career Development (IEF) award (CARS, PIEF-GA-2010-273739) held by Alexandros Karatzoglou. Figure 3: Scalability analysis of CLiMF in terms of the scale of the training data [1] G. Adomavicius and A. Tuzhilin. Toward the next [2] D. Agarwal and B.-C. Chen. Regression-based latent [3] S. Balakrishnan and S. Chopra. Collaborative ranking. [4] C. J. C. Burges, R. Ragno, and Q. V. Le. Learning to [5] S. Chakrabarti, R. Khanna, U. Sawant, and [6] O. Chapelle and M. Wu. Gradient descent [7] H. Chen and D. R. Karger. Less is more: probabilistic [8] P. Cremonesi, Y. Koren, and R. Turrin. Performance [9] M. Deshpande and G. Karypis. Item-based top-n [10] Z. Gantner, S. Rendle, C. Freudenthaler, and [11] T. Hofmann. Latent semantic models for collaborative [12] Y. Hu, Y. Koren, and C. Volinsky. Collaborative [13] Y. Koren, R. Bell, and C. Volinsky. Matrix [14] Y. Koren and J. Sill. Ordrec: an ordinal model for [15] G. Linden, B. Smith, and J. York. Amazon.com [16] N. N. Liu and Q. Yang. Eigenrank: a ranking-oriented [17] N. N. Liu, M. Zhao, and Q. Yang. Probabilistic latent [18] T.-Y. Liu. Learning to rank for information retrieval. [19] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, [20] L. Pizzato, T. Rej, T. Chung, I. Koprinska, and [21] S. Rendle, C. Freudenthaler, Z. Gantner, and S.-T. [22] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [23] R. Salakhutdinov and A. Mnih. Probabilistic matrix [24] Y. Shi, A. Karatzoglou, L. Baltrunas, M. A. Larson, [25] Y. Shi, M. Larson, and A. Hanjalic. List-wise learning [26] Y. Shi, P. Serdyukov, A. Hanjalic, and M. Larson. [27] H. Steck. Item popularity and recommendation [28] M. Taylor, J. Guiver, S. Robertson, and T. Minka. [29] E. M. Voorhees. The trec-8 question answering track [30] J. Wang and J. Zhu. On statistical analysis and [31] M. Weimer, A. Karatzoglou, Q. Le, and A. Smola. [32] J. Xu, T.-Y. Liu, M. Lu, H. Li, and W.-Y. Ma. [33] S.-H. Yang, B. Long, A. J. Smola, H. Zha, and [34] Y. Yue, T. Finley, F. Radlinski, and T. Joachims. A
