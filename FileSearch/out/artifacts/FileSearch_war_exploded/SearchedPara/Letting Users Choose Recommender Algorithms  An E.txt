 Recommender systems are not one-s ize-fits-all; different algo-rithms and data sources have di fferent strengths, making them a better or worse fit for different users and use cases. As one way of taking advantage of the relative me rits of different algorithms, we gave users the ability to change the algorithm providing their movie recommendations and studied how they make use of this power. We conducted our study with the launch of a new version of the MovieLens movie recommender that supports multiple recommender algorithms and allows users to choose the algorithm they want to provide their recommendations. We examine log data from user interactions with this new feature to understand whether and how users switch among reco mmender algorithms, and select a final algorithm to use. We also look at the properties of the algorithms as they were experienced by users and examine their relationships to user behavior. We found that a substantial portion of our user base (25%) used the recommender-switching feature. The majority of users who used the control only switched algorithms a few times, trying a few out and settling down on an algorithm that they would leave alone. The largest number of users prefer a matrix factorization algorithm, followed closely by item-item collaborative filtering; users selected both of these algorithms much more often than they chose a non-personalized mean r ecommender. The algorithms did produce measurably different recommender lists for the users in the study, but these differences were not directly predictive of user choice. H.1.2[ User/machine systems ]: Human factors; H.3.3[ Information storage and retrieval ]: Retrieval models Human Factors, Algorithms Recommender systems; e xperiment; field study Recommender systems generally keep their algorithms  X  X ehind the scenes X  and do not offer users a choice of algorithm. In this paper, we report on a field study where we deployed a recom-mender that offered users the choice of different algorithms. In this study, we investigate both how users explore and/or switch among algorithms and the preferences they reveal when given the chance to experience multiple algorithms. This experiment takes place in the context of the release of a new version of the MovieLens movie recommendation service new release adds support for multiple recommender algorithms and gives users the ability to switch their algorithm. Users are randomly assigned to one of the algorithms as their initial condi-tion. This gives us the opportunity to study three things: the ways in which users take advantage of the ability to switch the algo-rithm providing their recommenda tions, the algorithm or algo-rithms users prefer, and the impact of the assigned algorithm on user behavior. Within this setting, we seek to answer several research questions: 1. Do users take advantage of a means to switch recommend-2. What algorithm(s) do users prefer to use? Is there a clear 3. How do users explore the algorithm options? 4. How stable are user selections ? Do they experiment for a 5. How do the recommendations users receive from the algo-6. Can we predict the user X  X  choice of algorithm, or do we 7. Does the algorithm with which a user starts affect their use We use three primary algorithms in this study: a baseline using user and item mean ratings, an item-item collaborative filter, and a matrix factorization recommender. These were selected for broad usability (the baseline recommender), continuity with the system X  X  previous behavior and widely-d eployed algorithms (item-item CF) and to have an algorithm representative of the current state of the art in collaborative filteri ng (matrix factorization). In the remainder of this paper, we describe our experimental set-up, our key findings, and conclu sions and lessons for the design and deployment of r ecommender applications. http://movielens.org It is well-understood that different recommender algorithms, even ones that have quantitatively similar behavior on common accura-cy metrics, produce recommendations that differ in ways that users can perceive [7, 18] and that may impact their ability to meet different user needs, or the needs of different users. One way of making use of the adva ntages of different algorithms to improve recommendation for part icular users is through hybrid recommenders [2]. Hybrids can blend the strengths of different approaches, even tuning the blen d on a per-user or per-item basis to use each algorithm the most where it has the most to offer [27], or attempting to detect the best algorithm for each user [9]. We can view the goal of such hybrids as that of building a meta-recommender , identifying the particular algorithm (or combina-tion of algorithms) that will best meet the needs of a particular user in a particular context. Another approach, which we explore in this paper, is to involve the users in the process of selecting their recommender. Many recommenders take explicit feedback from their users to form the basis of the recommendations [23], or to set up an initial context for new users [5, 17, 24]. Relevance feedback incorporates user responses  X  either explicit or implicit  X  into a feedback loop to improve future iterations of the recommender [1, 13]. In this work, we take a very basic approach to incorporating users X  ex-plicit feedback into the recomme nder selection process: we invite users to try different recommender algorithms and pick the one they want to use. This is sim ilar to the work of Dooms, where users were given some control over their recommendations [6]; some results in that work parallel ours. Many previous studies have examined the impact of different recommendation techniques on users X  subjective perceptions of recommendations [7, 14, 25], and it is common practice in indus-trial applications to measure the impact of recommendations on user behavior using A/B trials and similar experimental models [15]. In this work, we examine us er response to different recom-mendation approaches when the action they can take is to switch recommender algorithms, rather than simply to accept or reject algorithms or discontinue use of th e service. Our motivations are similar to those behind the idea of user studies: providing ratings and other actions in response to a single recommendation ap-proach is an inadequate expression of the user X  X  thoughts and preferences as to how their re commendations should be provided, not just optimizing the system for particular user responses that we the system X  X  creators and analysts deem indicative of useful-ness. In user studies, we solicit users X  subjective impressions and stated preferences with regards to an algorithm; in this work, we examine the choices users make when they can select the recom-mender suggesting movies to them. There has been previous work on providing users with insight into, and in some cases control over, the system X  X  model of their preferences [4, 12]. Some co mmercial recommenders support some version of this, through explicit interest profiles often used in a new user onboarding process (exemplified by Twitter or Mi-crosoft Cortana) or by allowing th e user to view and correct pro-file information that will feed into their recommendations (a mod-el adopted by Amazon.com). One of the goals of recommender explanation is also to provide some transparency to users into the source of their recommendations [28]. Ziegler et al. proposed a user-adjustable control for the amount of diversification applied to a recommendation list [30], and the retrieval models of Tapestry were entirely user-guided [10]. But there is compar atively little work on allowing users to control what algorithm provides their recommendations, as opposed to refining the algorithm X  X  input data or re-tuning a structurally static algorithm. We studied the behavior of users of MovieLens, a non-commercial movie recommendation service, as they interacted with the recommender switching capabilities deployed as a part of an overhaul of the service. The new version of the service sup-ports multiple recommender algorithms, selectable on a per-user basis, and gives users a control to pick the algorithm that they are using. When an existing user signed in to the new version of the service, or returned to it after the feature was deployed, they were randomly assigned one of the algor ithms as their initial condition. They were also shown a brief interstitial informing them that the service now supports multiple algorithms, and pointing to the control for changing algorithms. In this study, we only consider previously-existing users who signed in to the new site. 2 We consulted with our IRB on this study, and they determined that the research was exempt and did not require specific user consent beyond users X  general a greement to use our service and acceptance of its terms of use. The service supports four algorithms. Each algorithm was identi-fied to users using a code name, derived from common role-playing character classes, so that they could be memorable but would not disclose to users exactly what algorithm they were using; a very brief description accompanied each algorithm name. New users who first signed up with the new site participated in a different experiment, so they could not be considered in the data analysis for this study.  X  The Baseline algorithm predicts ratings using a user-item  X  The Pick-Groups recommender is an item-item collaborative  X  The Item-Item recommender [26], called the Warrior and de- X  The SVD recommender, called the Wizard and also described All algorithms are built with the LensKit toolkit [8]. To compute top-N lists, the algorithm X  X  predicted rating is the primary ranking factor, but it is blended w ith the popularity of the item:  X  the last 365 days; and  X  X  X  X  X  X  X  X  normalizes its input to a rank, smallest value. This blending is the result of empirical evidence that balancing popularity with pr ediction rank leads to greater satisfaction with top-N recommendation lists. Full LensKit configurations for each algorithm are available as a supplement in the ACM Digital Library. Once in the system, users could change their algorithm by click-effect immediately; once the user selected a different recommend-er, the system would reload the list of movies on the current page (if they were viewing a movi e recommendation page) and show the results from the freshly-selected recommender. The system X  X  interface is organized ar ound three major functions: 1. Movie recommendations: the defa ult view shows a set of 2. Movie details: clicking on a movie image brings up more 3. Search: a keyword-based search feature, with additional The user X  X  choice of recommender algorithm persisted throughout the application, affecting all use of predictions for display or mov-ie ranking. This means that it would only recommend items for whom it could find a neighborhood with a total similarity of at least 0.1. Our reporting here is based on logs of the feature X  X  use from its deployment in November 4, 2014 through March 31, 2015. Table 1 summarizes the data we coll ected. 3005 users used the system, of which 748 changed recommenders at least once; the median account age upon signing in to the new system was 1653 days (min 0, max 6086). Our logs have 11,423 change events. In addition to using the logs of us er interactions, we also used the ratings database to run an offlin e evaluation to measure the accu-racy of the algorithms on each user X  X  recent history prior to enter-ing the experiment. Starting with a current dump of the ratings database, we put all ratings from all users not in our experiment into a training set. For each user in our experiment, we did the following:  X  Discarded all ratings after entering the experiment  X  Put the 5 most recent ratings prior to entering the experiment  X  Put the user X  X  remaining ratings into the training set We then ran each algorithm (with the exception of Pick-Groups ; it is difficult to do historical recreations of that algorithm outside of a running instance of the recommendation service) and measured the following:  X  Prediction accuracy (RMSE) for the test ratings.  X  Top-N accuracy (Recall) for finding the user X  X  recent ratings  X  Diversity (intra-list similarity [30], with cosine similarity  X  Popularity (mean popularity rank , where 1 is the most popu-We used 24 items for each recommendation list because that is the length of a single page of re commendations in the recommender application X  X  web interface. In this section, we describe our findings from this study. We have organized this section in order of our research questions, though more than one question may be addressed in a section. We also measured reciprocal rank and average precision, but the recommenders found users X  rated items so infrequently that these did not provide very mean ingful comparisons. They effec-tively compare how well less than a third of the algorithms/user pairs do at ranking items for the user. Whether the algorithm was able to find one (or more) of the user X  X  items is a question that can be meaningfully answered for all algorithm/user pairs. Users switching at least once 748 (24.9%) Recommender change events 11,423 Median changes per user w/ at least 1 change 3 Median account age 1653 days
Median ratings per user (at end of study) 354 Of the 3005 users in our study, 748 (24.9%) changed recommend-ers at least once. This does no t count the 31 users whose only interaction with the control was to select their current recom-mender. These users X  activity was likely the result of an interface artifact; the control indicated the user X  X  current algorithm (with a filled radio button) but did not disa ble that algorithm, and some users may have thought that clicking the algorithm would provide more information on it. While the feature was certainly not used universally, it was tried by a significant fraction of user s. 539 users (72.1% of the users who tried the control) settled on a different algorithm than they had been assigned. This answers RQ1 in the affirmative: users did make use of the ability to change recommenders. Of the users who entered the experiment before March 1, 2015 (so we have data on them for at le ast a month since they entered), users who switched recommenders we re more likely to sign in again at least a week later (83.4% vs. 54.5%; p&lt;0.001). This is not necessarily a causal relationship, but may indicate that more ac-tive users in the system are more particularly interested in the recommender-switching feature. This finding is consistent with those of Dooms [6]. Among users who tried different algorithms, SVD was the most favored algorithm, followed by Item-Item and finally the Pick-Groups and Baseline recommenders. Figure 2 shows how many users who switched recommenders at least once selected each of the algorithms as their final choice (their active recommender as of close of data collection). We can see that users clearly favor the personalized algorithms over the baseline, and over the group-based recommender. Since users knew that the baseline was non-personalized, and that the pick-groups recommender was base d on movie groups, we cannot infer from this data that users preferred the recommendations provided by the personalized algorithms (as opposed to the idea of personalization). We can , however, observe that, given the choice, most users will choose to use r ecommendations they know (or at least believe) to be personalized. This resu lt is not surprising, but does provide more data to support the idea that users believe the work of recommender systems to be useful. Users who were assigned to the non-personalized condition were more likely to try other recommenders. Item-item users were the next most likely to use the switcher. Figure 3 shows the fraction of users in each initial algorithm condition who tried a different recommender; all differences are significant ( , with Bonferroni correction for multiple tests). Analyzing this result shares the confound discussed previously: users knew that the baseline algorithm was non-persona lized. They did have to access (but not necessarily use) the control in order to obtain this infor-mation, but all logging is server-side, so we do not have log data on how many users viewed the switcher control but did not use it. Integrating users X  final choices an d whether they switched at all indicates that more users find the SVD-based recommendations to be most satisfactory; item-item the next most satisfactory; and finally the baseline algorithm. each algorithm at similar rates irrespective of the algorithm they started with. The only measurable impact of initial algorithm on final choice was via its impact on whether users experimented with different algorithms in the first place. In addition to refining our answer to RQ2 (users are most satisfied with SVD, followed by item-item, we make two observations with respect to RQ7: the initial algorithm affects the likelihood that a user will try other recommenders, but once they decide to experi-ment, it has little bearing on their final choice. The vast majority (97.3%) of users switched recommenders no more than 20 times (although on e user recorded 7296 transitions). Most users switched just a few times; only 21.4% switched more than 5 times. Figure 4 shows th e distribution of user transition counts (for users switching no more than 20 times). The most common switching patterns were for a user to switch away to a different algorithm, or try two or three algorithms and then settle down. The median number of transitions is 3, after which there is a marked drop-off; this is enough transitions for a user to try each of the personalized algorithms and return to their favorite. We examine the transitions in more detail, looking to see the rela-tive likelihood of different stat e transition sequences. Table 2 shows the common transition patterns among users who switched at least once. Percentages are the percentage of users who started with that algorithm and transitione d at least once. Patterns not shown appeared less than 5% of the time. Transition chains are complete: II  X  SVD means that the user started with item-item, transitioned to SVD, and did not switch recommenders again. Users generally experimented w ith the personalized algorithms, trying each at most once and sometimes returning to an earlier good algorithm. Behavior of users starting with the baseline was somewhat more diffuse than users starting with one of the person-alized algorithms; the most users switched from the baseline to one of the personalized recommenders (29.6%, evenly split be-tween the two of them), with an additional 7.9% trying both and staying with SVD, and 6.5% tryi ng both and selecting item-item. II  X  SVD 52 21.1% 21.1% II  X  SVD  X  II 23 9.3% 30.4% SVD  X  II 30 15.2% 15.2% SVD  X  II  X  SVD 21 10.0% 25.2% BL  X  II 45 14.8% 14.8% BL  X  SVD 45 14.8% 29.6% BL  X  II  X  SVD 24 7.9% 37.5% BL  X  II  X  SVD  X  II 12 3.9% 41.4% 
BL  X  SVD  X  II 8 2.6% 44.0% 26.2% of users who switched recommenders only did so within their first hour of using the new system. The median user per-formed their first transition in the first 10 minutes or 16 logged actions 5 (viewing a page, changing recommenders, or taking an action on a movie or a tag), and their last transition within the first 18 hours. We also broke user actions down into sessions , considering a session to end when the user is inactive for at least 60 minutes [11]. As implied by the timing data in the previous paragraph, the median user first switched reco mmenders in the first session. 44.1% of users only switched recommenders during their first session; these users had a median of 2 and mean of 9 further ses-sions after the one in which they changed recommenders. 63% of users only switched recommenders in a single session, even if it was not their first, and 80.7% of users only switched recommend-ers in 2 different sessions. Users also interacted with the recommender changer without very many intervening events. They would change recommenders, see the results, and if they switched recommenders again, they usually did so quickly. The median user viewed one page between rec-ommender changes within a single session. To answer RQs 3 and 4, users tended to experiment with the rec-ommender switching control early in their use. Most users flipped the switch a small number of times, usually in one or two distinct sessions and without much other inte rvening activity, and then left the recommender setting alone. These 16 actions are not counting the 2 actions at the beginning of every user X  X  logged data: view ing the interstitial and the ap-plication X  X  front page. Our offline simulation of the recommenders the users interacted with allow us to examine how different the output of the different recommender algorithms are in terms of various objectively measurable characteristics. In ad dition to providing insight for interpreting user behavior, these results also provide some meas-urement of the recommendations that are seen by actual active users in the system, rather than the mix of inactive and active users seen in typical offline evaluations over entire data sets. This does not take into account changes resulting from users adding ratings to the system after joining the experiment, but captures the behavior of the recommender immedi ately before they entered the study. 374 of the users participating in our study did not have sufficient joining the experiment), so they are excluded from the analysis in this section. First, the algorithms did produce different lists of items. The three recommenders (baseline, item-item, and SVD) produced an aver-age of 53.8 unique items per user (out of a maximum of 72 for three 24-item lists). Figure 5 shows the Jaccard similarity of each pair of recommendation lists for each user. Baseline and item-item were the most similar, with SVD producing results that were more divergent from them. The algorithms also had differing prediction and recommendation accuracy (measured against the user X  X  5 most recent ratings prior to entering the experiment), shown in the left side of Figure 6. The patterns in objective accuracy track with those in user preference, with SVD being the most accurate, followed by item-item and finally baseline. The second shows Boolean recall, the fraction of users for which each algorithm produced at least one of the user X  X  test ratings in the first 24 recommendation results. This metric tracks differently from user X  X  choice of algorithms : even though item-item found the user X  X  rated item for more ite ms, more users preferred the SVD recommender. We recognize that the effects of recall can be difficult to interpret; low recall may suggest that an algorithm that is not successfully finding the us er X  X  most preferred items, while high-recall may suggest that an algorithm is not recommending enough new and unfamiliar content. Figure 7: Popularity and Diversity of Recommendation Lists Figure 7 shows the popularity a nd diversity of recommendations achieved by each recommender. SVD produced the most novel (least popular) recommendations. Item-item produced the most diverse recommendations, with SVD having the greatest variance in diversity, although the differ ences in diversity are small. The charts so far have all considered the performance of the algo-rithms without accounting for their relative performance within the user experience. For any particul ar user, it is unlikely to matter whether one algorithm tends produce more diverse recommenda-tion lists than another; rather, when comparing algorithms, they will notice if one algorithm produces more or less diverse results than another for them . To address this question, Figure 8 shows the relative performance of the two personalized algorithms, nor-malized to the performance of the baseline algorithm on each user. For example, an RMSE of 0.03 for a user means that the algorithm in question had an RMSE that was 0.03 better than that of the baseline algorithm for that pa rticular user. We averaged the relative performance across all users, and show the results with fraction of relevant items retrieve d, rather than Boolean recall. We note significant differences in algorithm performance on all metrics. These differences are trend-consistent with the overall differences previously, but allow us to see how much difference in e.g. diversity each algorithm is lik ely to make for an individual user. The differences in diversity are quite small, while the differ-ences in popularity and accuracy are bigger and more likely to be noticeable (particularly the popularity difference). Our offline metrics do not predict which algorithm users will pre-fer, or if they will switch algorithms in the first place, beyond the predictive power of the algorithm X  X  identity. That is, the populari-ty of a recommender X  X  results is no more powerful of a predictor of user switching and selection behavior than  X  X s the algorithm SVD? X . The most-preferred recommender  X  SVD  X  produces less popular (and therefore more likely to be novel) results than the other recommenders, but do not have direct evidence that this difference in novelty is the reason that users prefer SVD. The fact that the relative popularity of recommendations from the three algorithms is rank-consistent with users X  tendency to choose those algorithms, whereas their relative di versity is not, suggests that popularity or novelty may play a larger role in user preference than diversity, at least as we ha ve measured it here, but is not conclusive evidence. We built logistic regressions to attempt to predict switching be-havior. The most significant predictor of whether a user would try a different algorithm was the algorithm they started with. The significant differences in metrics between algorithms induced multicolinearities that made a single regression incorporating both identity and metrics infeasible. To work around this problem, we bu ilt separate logistic regression models for users starting with each algorithm. With these models, we found that for users starting with the baseline algorithm, in-creased diversity in the list of recommendations increased the likelihood that they would try another algorithm ( ), and users starting with item-item were more likely to try another if the list of recommendations was more novel ( ). We have similarly been unable to predict the user X  X  final choice of recommender beyond the fact that it is a particular recommender. Comparing the popularity of the items recommended by user X  X  initial and final recommenders, we saw that users tended to choose final recommenders with less popular items, but that seems to be linked to the fact that they tended to prefer SVD. We also examined several properties of users to look for predic-tors of either behavior or of final preferred algorithm, but did not find any significant predictors. We considered the user X  X  account age, the number of ratings they had provided, and the diversity of the movies they had rated, but none were effective for predicting the user X  X  activity. As noted in section 4.2.1, the user X  X  initial recommender influ-enced whether or not a they changed algorithms, but did not di-rectly affect their final choice of algorithm. In section 4.1, we noted that users who make use of the recom-mender switching control were more likely to come back to the site. We also examined whether, for users who did not switch recommenders, the initial recommender condition affected reten-tion, but found no effect. The initial recommender the user en-countered in the new site did not, for our experiment, affect the user X  X  likelihood to continue using the service. To summarize our answer to RQ7, the primary effect of initial algorithm that we could observe was that it influenced whether the user would use the recommender selection control. Users used the recommender-switching feature, and often changed to a different recommender than their initially-assigned one, even if they were already using a personalized recommender. While we have not seen any conclusive effect on user retention in our sys-tem, and do not have significant qualitative feedback on from users on the recommender-switching feature, it seems to have enough use to warrant continued in clusion and development. Oth-er systems may also want to consider allowing the user to have more control over the way in which their recommendations are computed. Users in the user forums did express interest in knowing what algorithms were used, or understa nding the difference between the Wizard and Warrior recommenders; this information was with-held for experimental purposes, but we will be considering how best to present more information about the meaning of the user X  X  choice. Users who made use of the reco mmender selection control usually and then left it set for the duration of their usage. They also came back for multiple sessions after leaving it set, suggesting some degree of satisfaction with their choice. user study [7]. In that study, users did not have a measurable pref-erence between item-item and SVD, in the context of reviewing a single 10-item recommendation list. Our results here suggest that more users do prefer SVD when they have the opportunity to interact with the algorithms in a longer-term context. However, many users still preferred the item-item recommender; there was no clear (near-unanimous) winner. Fu rther, while we have noted a strong correlation between novelt y and the user X  X  preference (stronger than diversity), as was found in the aforementioned user study, the directionality of this correlation is reversed: users were more likely to stick with the algorithm that was also more novel (recommended less popular items). This provides additional evi-dence that negative impact of nove lty is primarily concentrated in users X  initial reactions, and that after they gain experience it may even be a positive influence in the user X  X  satisfaction. We tried several differe nt ways to predict whether the user would switch from properties of the recommendations produced by their initial algorithm, and properties of the user (user account age, rating count, diversity of their rated items), but found very few significant predictors. If there are identifiable characteristics of users that predict the usefulness of different algorithms for provid-ing their recommendations, we have yet to find them (or at least to demonstrate conclusively that identifiable differences are, indeed, the reason for particular user preferences). We have reported on an experiment in which we gave users the ability to select the algorithm that would be providing their rec-ommendations in a movie recomme nder application. We found that users made use of the contro l, typically experimenting with the different options to find a satisfactory recommender early on and keeping their choice for the remainder of their use of the sys-tem. We also found that SVD is the most preferred algorithm, followed somewhat closely by item-item, and finally the baseline and group-based recommenders. This shows that users do have a preference for personal recommendations, and while the prefer-ence between item-item and SVD was close, SVD was preferred by more users. We also observe a correlation between users taking advantage of the feature and long-term user retention. Giving users choice may promote their long-term use of the system. This is an initial investigati on of the dynamics of giving users control of the means by which their recommendations are com-puted. Previous systems have given users some control of their recommendations, such as Amazon X  X  feature whereby users can indicate that they want certain items excluded from the data Ama-zon uses to provide recommendati ons. However, we are not aware of other services that allow end users to switch the entire recom-mender algorithm, or published research on how users interact with such a feature, aside from the implied abilit y to re-shop rec-ommendation techniques in decentrali zed architectures such as the original GroupLens architecture [23]. There are a number of things needed to build on this work and carry it forward. First, it should be examined in other domains: do users benefit from the ability to select recommenders in other types of applications, such as book recommenders or tools for finding health information? Second, we would like to consider more effective tools for allow-ing users to preview the recommendations. In our application, users could switch recommenders , but could not view recommen-dations side-by-side or  X  X ry out X  a recommender other than by selecting it and switching back. Us ers may use the feature in dif-ferent ways if they can directly compare the output of different recommenders. Thirdly, our switching mechanism was very course, allowing the user to swap out one recommender for another. But choice of recommender algorithm does not need to be an either-or decision, and there are many more nuanced decisions that could be made. There could be great potential in an interface that allows users to adjust the blend between differe nt algorithms, and tweak the be-havior of algorithms in other wa ys (e.g. adjusting the minimum neighbor count for a k-NN collaborative filtering, making it more or less conservative in its recomme ndations). Ziegler et al. [30] suggested a knob to allow users to adjust the amount of diversity they wanted added to their recommendations; we envision a panel of options that allow users to fine-tune their recommendations, ideally viewing the impact of these changes in real time. In order to make this feasible, we will not only need to develop useful interfaces, but identify the user-visible impact of different rec-ommender tweaks so that the controls can be labeled in a manner that is understandable to end users, rather than  X  X umber of Latent Features X . Providing users with control over the recommendation has the potential to significantly improve the user experience, and the sense of investment that users feel in the system, leading to better user retention and engagement. Th e control, and sense of trans-parency that comes with it, may also make users more comforta-ble with the system. A current popular complaint about recom-mender systems is that they are opaque algorithms with limited transparency and accountability for their outputs. User push-back against such algorithms changing and affecting their experience has been particularly pronounced in reactions to the Facebook emotional contagion study [16], or in concerns about the potential isolating effects of personalized information filtering [21]. Even if such concerns are not well-founded or even contrary to available tem, and that trust may be da maged. Providing opportunities for the user to inspect and/or control the means by which their rec-ommendations are computed may be valuable tool for the system to build and maintain their trust. This pap er represents our initial investigation into what happens when we give users the ability to control their recommendations. We look forward to further results, from our own work and that of others, on how to provide compe lling, customizable recommenda-tion experiences. This work was supported by the National Science Foundation under grants IIS 0808692 and IIS 1017697. [1] Balabanovi  X  , M. and Shoham, Y. 1997. Fab: content-based, [2] Burke, R. 2002. Hybrid Recommender Systems: Survey and [3] Chang, S., Harper, F.M. and Terveen, L. 2015. Using [4] Cook, R. and Kay, J. 1994. Th e justified user model: a view-[5] Cremonesi, P., Garzottto, F. and Turrin, R. 2012. User Effort [6] Dooms, S. 2014. Dynamic Generation of Personalized Hy-[7] Ekstrand, M.D., Harper, F.M., Willemsen, M.C. and Kon-[8] Ekstrand, M., Ludwig, M., Kons tan, J.A. and Riedl, J. 2011. [9] Ekstrand, M. and Riedl, J. 2012. When recommenders fail: [10] Goldberg, D., Nichols, D., Oki, B.M. and Terry, D. 1992. [11] Halfaker, A., Keyes, O., Kluver, D., Thebault-Spieker, J., [12] Kay, J. 2006. Scrutable Ad aptation: Because We Can and [13] Kelly, D. and Belkin, N.J. 2001. Reading Time, Scrolling [14] Knijnenburg, B., Willemsen, M. , Gantner, Z., Soncu, H. and [15] Kohavi, R., Longbotham, R., Sommerfield, D. and Henne, [16] Kramer, A.D.I., Guillory, J.E. and Hancock, J.T. 2014. Ex-[17] Levi, A., Mokryn, O., Diot, C. and Taft, N. 2012. Finding a [18] McNee, S., Kapoor, N. and Konstan, J.A. 2006. Don X  X  Look [19] Netflix Update: Try This at Home: 2006. [20] Nguyen, T.T., Hui, P.-M., Harper, F.M., Terveen, L. and [21] Pariser, E. 2011. The Filter Bubble: How the New Personal-[22] Paterek, A. 2007. Improving regularized singular value de-[23] Resnick, P., Iacovou, N., Suchak, M., Bergstrom, P. and [24] Rich, E. 1979. User modeling via stereotypes. Cognitive [25] Said, A., Fields, B., Jain, B.J. and Albayrak, S. 2013. User-[26] Sarwar, B., Karypis, G., Kons tan, J. and Reidl, J. 2001. Item-[27] Sill, J., Takacs, G., Mackey , L. and Lin, D. 2009. Feature-[28] Tintarev, N. 2007. Explanations of recommendations. In [29] Vig, J., Sen, S. and Riedl, J. 2012. The Tag Genome: Encod-[30] Ziegler, C.-N., McNee, S. , Konstan, J.A. and Lausen, G. 
