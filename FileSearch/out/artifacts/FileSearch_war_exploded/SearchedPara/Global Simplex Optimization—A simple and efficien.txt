 Akbar Karimi, Patrick Siarry n 1. Introduction
Unconstrained global optimization of a continuous function f aims at finding its global optimum without being trapped into one of its local minima, where function f depends on a set of continuous decision variables or design parameters y  X  ( y and is assumed to be subject to only box type constraints, i.e. each variable is limited only by a lower and upper bound. Among the mathematical algorithms in the literature dedicated to the subject, one might see a special interest in Evolutionary Algorithms (EAs) and their main branches, including Genetic Algorithms (GAs),
Genetic Programming (GP), Evolution Strategies (ESs), and Evolu-tionary Programming (EP). Their principal mode of operation is based on the same genetic concepts, a population of competing candidate solutions, random combinations and alterations of potentially useful structures to generate new solutions and a selection mechanism to increase the proportion of better solutions.
The different approaches are distinguished by the genetic struc-tures that are adopted and the genetic operators that are utilized in generating new candidate solutions.

Many  X  X ybrid X  algorithms have been proposed in the literature combining a global optimization algorithm with a classical  X  X ill-climbing X  algorithm in order to gain performance improvements. A subset of these works, dealing with the integration of EAs with the classical Nelder X  X ead simplex method ( Nelder and Mead, 1965 ), has drawn interest in recent years. Simplex method is a robust, easy to be programmed and fast local search algorithm, which also shows the feature of making no use of the derivatives of the objective function at hand. These characteristics have made the classical simplex method and its modifications an interesting choice for cooperation with EAs in developing hybrid global optimization schemes.
Many attempts have been made to hybridize GAs with the classical simplex methods, some of them have been published by
Chelouah and Siarry (2003) , Hedar and Fukushima (2003) , Musil et al. (1999) , Yen et al. (1998) , Yang and Douglas (1998) , and
Renders and Bersini (1994) . The remarkable features underlying these hybrid methods are global exploration and parallelism performed with GA, and local exploitation with a classical or modified simplex method. A multi-parent recombination operator for real-coded genetic algorithms, called simplex crossover (SPX), has also been proposed and investigated ( Higuchi et al., 2000 ; Tsutsi et al., 1999 ).

Beside these GA X  X implex hybrids, there exist few works deal-ing with the hybridization of the simplex method with other branches of EAs. We are only aware of the works published by Malaek and Karimi (2008, 2006) , Luo and Yu (in press) , and
Sotiropoulos et al. (2002) , which are shortly described in subse-quent paragraphs. However, it should be noted that, here, only the algorithms incorporating elements from two (or more) methods into a single unified scheme are considered; and as a consequence, a common practice in which a local search method, like simplex method, is employed to refine a preliminary solution obtained by an EA is naturally excluded from our consideration. Sotiropoulos et al. (2002) proposed an EA called Simplex Evolution (SE) based on a deterministic evolution operator, called
Simplex Operator that is actually equivalent to one cycle of the classical Nelder X  X ead simplex method. An iteration of SE starts by setting the first individual from the current population as the base point, randomly selecting n  X  1 other individuals from the current population to form a simplex, and performing Simplex
Operator on the selected simplex to generate a new individual and put it into the new generation. The iteration continues by selecting the next individual as the base point and so forth. Once the new generation grows to a fixed population size, the algo-rithm proceeds to the next iteration by setting the new genera-tion as the current population.
 Malaek and Karimi (2008, 2006) proposed an EA, called Global
Simplex Search (GSS), based on the stochastic modifications of the reflection and expansion operators of the simplex method. The method has been independently developed to efficiently find accurate solutions for the constrained optimization problem arising from a typical MDM (Mass Distribution Management) problem ( Malaek and Karimi, 2008 ), following the failure of the appropriately modified versions of the algorithms CGA and CHA ( Chelouah and Siarry, 2003, 2000 ) in delivering such capabilities.
The reflection and expansion operators of the classical simplex method with random reflection and expansion factors have been employed as the recombination operators of GSS, together with a low mutation rate. The authors have recognized the impact of the lower and upper reflection factor limits on the performance of the algorithm and used them as control parameters. The concept of generation does not exist in GSS; this allows for smooth decrease of the population from an initial size to a final one; which also proves to have an impact on the performance of the algorithm, at least against the specific MDM problem for which it was designed.

An algorithm combining the Differential Evolution (DE) ( Price et al., 2005 ; Storn and Price, 1997 ) and the classical Nelder X  X ead simplex method called  X  m -simplex evolution X  has recently been proposed by Luo and Yu (in press) . The method is a population set based EA incorporating stochastic reflection and contraction operators of the classical Nelder X  X ead simplex method with an additional step, in which an individual not attaining at least the average fitness of the overall population will take a deterministic step toward the best individual or away from the worst one, in an attempt to increase its fitness or at least increase the population diversity. The main feature of this method is the use of so-called  X  X ow dimensional X  simplexes consisting of m individuals, where 2 o m o n  X  1. For cases where n is much larger than m , the method has been called Low-Dimensional Simplex Evolution (LDSE), which has been claimed to exhibit better performances, compared to Full-Dimensional Simplex Evolution (FDSE). The authors have also provided numerical results comparing a special case of m -simplex evolution, called Triangle Evolution (TE) (i.e. m  X  3), with an enhanced DE method.

This paper presents the results of recent research aimed at further enhancement of the original GSS algorithm and presenting it as a general continuous global optimization method. The resulting algorithm, renamed to Global Simplex Optimization (GSO), to reflect the distinctions it has with the original GSS, can be viewed as a generalization of the traditional Nelder X  X ead Simplex method to global optimization. The paper is organized as follows. Section 2 is devoted to the detailed presentation of the algorithm. Section 3 presents the experimental setup used to compare the algorithm to other methods, and some words of conclusion make up Section 4 . 2. Global Simplex Optimization
In this section a brief review of the Nelder X  X ead simplex method is presented, followed by the detailed presentation of our new algorithm. 2.1. Nelder X  X ead simplex method
The Nelder X  X ead simplex algorithm is a very powerful classi-cal local descent algorithm, making no use of the objective function derivatives. A  X  X implex X  is a geometrical figure consisting, taken as the origin, the n other points define vector directions that span the n -dimensional vector space. Through a sequence of elementary geometric transformations (reflection, contraction, expansion and multi-contraction), the initial simplex moves, expands or contracts (see Fig. 1 ). To select the appropriate transformation, the method only uses the values of the function to be optimized at the vertices of the simplex considered. After each transformation, a better one replaces the current worst vertex. Trial moves shown in Fig. 1 are generated according to the following basic operations: reflection: x r  X  X  1  X  a  X  x a x w expansion: x e  X  g x r  X  X  1 g  X  x contraction: x c  X  b x w  X  X  1 b  X  x where x b and x w denote the best and worst vertices of the current simplex, respectively; x is defined by x  X  X  1 = n  X  P n i  X  1
Contraction Multi X  X ontraction and b are the reflection, expansion, and contraction constants factors, and are set typically to 1.0, 2.0, and 0.5, respectively.
The algorithm begins by generating the image of the least preferred vertex of the current simplex ( x w ) with respect to the centroid of the remaining vertices  X  x  X  . This operation is the reflection. If the reflected point is better than all other points, the method expands the simplex in this direction (expansion); otherwise, if it is at least better than the worst, the algorithm performs again the reflection with the new worst point. The contraction step is performed when the worst point is at least as good as the reflected point, in such a way that the simplex adapts itself to the function landscape and finally surrounds the opti-mum. If the worst point is better than the contracted point, the multi-contraction is performed. At each step, we check that the generated point is not outside the allowed solution space. 2.2. Detailed presentation of GSO In this section a detailed description of the algorithm is given.
The general framework of the algorithm including a tentative mutation operator (the dashed rectangle) is illustrated in Fig. 2 .
We will show in Section 3 that this operator can be removed from the algorithm without any significant penalty. The following subsections describe the main steps of the algorithm in detail. 2.2.1. Initialization
The algorithm starts by setting the control parameters and any other internal variable. In general, GSO has six control para-meters: the minimum and maximum reflection factor values, denoted by a min and a max , the initial and final population sizes, denoted by N ip and N fp , the type of the mutation operator used, and the mutation rate, denoted by r m . However, as it is shown in
Section 3.1 , the number of actual control parameters to be tuned for any specific problem reduces to two. 2.2.2. Generation of the initial population
In GSO we care for the diversity and uniformity of the distribution in the initial population as a factor affecting the performance of the algorithm. Therefore, a randomly generated individual will not be accepted and added to the initial pool unless it maintains a minimum distance, d min , with all the other members already in the initial population. The value of d given by Eq. (1), where n is the problem dimension and L l
L ( i ) are the lower and upper limits of the i th design variable, respectively. d  X  2.2.3. Selection and recombination
An iteration of the algorithm starts by randomly selecting n  X  1 distinct individuals among the c urrent population to form a non-degenerate simplex, defined as one with mutually different vertices according to the precision of the machine on which the algorithm is running. However, since the pop ulation members gradually get closer to each other as the search pr ogresses, selecting non-repeat-ing individuals will not guarantee the non-degeneracy of the resultant simplex; therefore, the selected simplex must undergo a separate non-degeneracy check before it is used.

The next step is the application of the recombination operator to the selected simplex to obtain offspring. A weighted stochastic operator consisting of one or more reflection steps, depicted in
Fig. 3 , serves as the recombination operator of GSO. The procedure begins by reflection of the worst vertex of the simplex with respect to the weighted centroid of all the vertices, x given by Eq. (2), where F i is the local fitness of the i th vertex defined by
F  X  f ( x w ) f ( x i ) assuming a minimization problem. The worst vertex gets a fitness value of zero and therefore gets excluded from the centroid calculation. x  X 
The first generated point is given by x r  X  X  1  X  a  X  x a x is the instantaneous reflection factor, randomly drawn from the during the initialization stage. The newly generated point is evaluated and if it is better than the best simplex vertex, i.e. f ( x ) o f ( x b ), a further move is performed, in which the worst vertex, x w , is reflected with respect to the previously generated ensure that the two successively generated points are sufficiently apart so that they do not adversely affect the diversity of the population. The new point, denoted by x e 1 is evaluated and if f  X  x
 X  o f  X  x r  X  , a further step is taken in which x w is reflected with respect to the last generated point, x e 1 , resulting in a new individual x e 2 . This pattern of successive reflections goes on until no further improvement of the objective function is observed, i.e. f  X  x
 X  Z f  X  x e i 1  X  , or the new point falls outside the search space; in the latter case, the point is replaced with the intersection of the reflection direction with the boundaries of the hyper-rectangular search space. Once finished, this weighted multi reflective recom-bination operator returns a set of newly generated points f x , x 1 , x e 2 , ... , x e m g , which are then passed to the next step of the algorithm as the intermediate offspring individuals.
 x 2.2.4. Mutation
In order to investigate the effect of mutation on the perfor-mance of the algorithm, a mutation step was also included in our experiments. In EA context, the mutation operator affects the individuals obtained from the recombination step and returns the final offspring individuals. Three different mutation operators, as described below, were tested, each controlled by a single para-meter, the mutation rate ( r m ).

Per Component Mutation: for each component of the indivi-0 and 1. If r o r m , then the component is replaced with the new mutated value, x 0 ( i ) given by Eq. (3) x 0  X  i  X  X  x  X  i  X  X  N  X  0 , s m  X  X  3  X  where N (0, s m ) denotes a random number generated using a
Gaussian probability distribution with a mean value of zero and a standard deviation of s m . s m is called the mutation strength and its value is fixed to 0.25( L u ( i ) X  L l ( i )).

Per Individual Mutation: a random number r is generated between 0 and 1. If r o r m , then all of the components of the individual undergo the alteration process given by Eq. (3).
Mixed Mutation: a random number r is generated between 0 and 1. If r o r m , then each component will or will not undergo the alteration process of Eq. (3) based on a constant probability of 0.5. This mode is in between of Per Component and Per Individual Mutations.

Fig. 4 represents a schematic view of the mutated locations possible with each mode and their associated probabilities. It should be noted that all the dimensions on these graphs are mutually different, as each component of an individual is altered independently of the others. 2.2.5. Updating the population and stopping criteria
The population is updated simply by addition of the offspring individuals to the current population to make an intermediate pool of N p  X  m individuals from which the top N p individuals are selected to form the next population; where N p and m designate the current population size and the number of generated off-spring, respectively.

In GSO, the population size gradually decreases as the search progresses. Using Eq. (4), the reduction in the population size mically mapped into the decrease of the current error value, e , from its initial value in the initial population, e 0 , to its final value, e f .

N  X  N ip  X 
The error values can be computed based on the coordinates of the individuals present in the population. In this case, the error is defined as the maximum distance between the best point and the other members of the population, i.e. e  X  max( : x i i  X  1, y , N p . For problems where the analytical optimum of the function is known a priori, it is also possible to define the error value simply as the gap between the current best objective function value and the known optimum, i.e. e  X  9 f min f opt
The algorithm stops when a predefined number of function evaluations is reached or the current error becomes less than or is satisfied, the algorithm returns the best member of the population and exits; otherwise, if required, the population is resized to the updated value from Eq. (4) by eliminating some worst members and the algorithm proceeds to the next iteration. The value of e f controls the level of accuracy required for the solution; i.e. the higher e f , the higher the number of function evaluations the algorithm will perform before it exits and the more accurate the returned solution will be. 3. Experimental setup and results
This section presents the results of the numerical experiments made with GSO. The first subsection deals with the optimal values for the control parameters of the algorithm and the next subsec-tion is devoted to the comparison of GSO to other continuous global optimization methods. 3.1. Parameter setting
As mentioned in Section 2.2.1 the complete framework of GSO presented in the previous section requires six control parameters. However, as it will be shown later in this section, some of these parameters can be given constant  X  X  X ptimal X  X  values independent of the problem at hand, reducing the number of control para-meters to two, which are to be tuned for a specific problem.
In order to find the optimal values of the control parameters, the solutions obtained for a set of standard test problems listed in the Appendix A , with different parameter settings, were studied. For each setting, the algorithm was applied to the test functions in 100 different runs. Moreover, instead of the final population size, we used a new parameter called  X  X opulation reduction factor X  and defined as the ratio of the final to initial population sizes, N The different settings were formed by various combinations of quantified control parameter values. The settings were then given ranks according to their performance against each test function (primarily based on the success rates and secondarily according to the numbers of function evaluations). The most promising set-tings, i.e. those having high ranks against all test problems, were then compared to each other to come at a final decision. Finally, the optimal parameter values were found as follows: (1) Popula-tion reduction factor can be given an optimal value of 0.75 regardless of the problem dimension. (2) Setting the value of maximum reflection factor to unity ( a max  X  1) seems to be optimal for all problems considered. (3) For a majority of the test problems, the algorithm performs equally well with or without a mutation operator, while for a few cases, a slight improvement in robustness associated with a decrease in efficiency is observed. However, considering the complexity of implementing a mutation operator and, more importantly, effectively setting its associated parameters, it seems a good idea to completely remove it from the original GSO to arrive at a mutation-free algorithm. (4) Finally, the optimal values for the two remaining control parameters, the initial population size and the minimum reflection factor ( a are obtained as in Table 1 , where three optimal sets are given based on the problem dimension, n . 3.2. Comparison with other methods
The performance of GSO has been compared to some other metaheuristics listed in Table 2 using a set of standard test functions given in Appendix A . Implementations of the methods in MATLAB language have been used, which were obtained from their original authors (CMA X  X S, TCACS and DE) or re-implemen-ted according to the source publications (TE and SE). In case of
CMA X  X S and DE, we have used the most recent implementations of these methods with the latest improvements and features, available from their respective web pages. 1
For each method, we have tried different settings for the control parameters and have obtained an optimal set of control parameters for each problem dimension. Table 3 presents the performance statistics for these methods against each test pro-blem with the optimal parameter settings. The results for all methods have been obtained using 100 independent executions of the algorithms against each problem. Each single run stops when a maximum allowed number of function evaluations or a maximum acceptable objective function value is reached. The maximum allowed number of function evaluations, designated by
MaxFE , for each test function is given in Appendix A . The acceptable objective functions value is defined as f  X  9 f known  X  10 6 9 , where f known is the known global optimum value of the function. Any execution of the algorithm leading to an objective function value as good as or better than f stop considered to be successful. For each problem, two numbers are reported: the rate of successful minimizations (robustness index) and the average number of function evaluations (efficiency index) computed for successful minimizations only.

The cells in Table 3 corresponding to the three best results obtained for each problem are shaded according to the rank of each method compared to the others; the darkest shaded cell corresponds to the best performance. In cases where there are no clear winners, the relative differences robustness and efficiency indices have been compared to each other to determine the rankings of each method. However, It should be noted that this method of ranking may not be exact and should be considered only as a basic indicator since there may be argued that the robustness and efficiency indices should not be given equal weights, especially in cases where there exist considerable difference in success rates.
 It can be observed from Table 3 that TCACS, GSO, CMA X  X S, and
TE yield the most promising results. GSO is the only algorithm among the six methods that ranks among the top three against all of the problems and in many cases, ranks as the best or the second best. It also exhibits an overall performance much better than that of the two other simplex-based methods, i.e. TE and SE.
Another interesting point about GSO is that it tackles all of the problems reasonably well and without any obvious cases of dropped performance particularly in terms of robustness, while there exist such cases for the other top-ranked methods. For example, TCACS totally fails against 10-dimensional Rosenbrock function ( R 10 ) and CMA X  X S yields poor robustness against four-variable Shekel functions ( S 4,5 , S 4,7 and S 4,10 ). It should also be particularly noted that GSO, SE and TE are considerably simpler algorithms than TCACS and CMA X  X S. In summary, it seems reasonable to conclude that the results obtained by GSO are very promising and among the best methods tested in this experimental setup.

In spite of its promising performance, there are potential areas of improvement in the current GSO algorithm. The most notable issue, which happens to many algorithms, regards the sensitivity of the algorithm to its control parameters and the need for parameter tuning to reach the best possible performance in solving a particular problem. In fact, although the suggested set of optimal control parameters leads to satisfactory results, this may not be the best the method can perform. Comparison of the performance of the algorithm against the 10-dimensional Zakharov function ( Z 10 ) under the nominal parameter setting of
Table 1 to those obtained under other settings listed in Table 4 makes the point clearer. As it is seen, the algorithm can tackle this problem with performance levels much higher than that reported in Table 3 . However, in order to be able to efficiently solve a large range of different problems, including some more challenging ones like the 10-dimensional Rosenbrock function ( R 10 ), where due to a saddle point it is very difficult to find the optimum, we have been forced to use the conservative parameter setting of Table 1 . This conservative parameter setting may in turn lead to non-optimal performance levels for some other problems. In fact, the problem R 10 could not be efficiently and robustly solved with min values less than 0.6 or values of N fp / N ip less than 12; whereas, Z 10 could be easily optimized with N fp / N ip of 10 and a as low as 0.4. This implies the lack of necessary self-tuning mechanisms to instantaneously adjust the control parameters according to the current function landscape. Such mechanisms can both make the algorithm much easier to be used in practice and improve its performance level when applied to different problems. 4. Conclusions
In this paper, an extension of the Nelder X  X ead simplex method to continuous global optimization was proposed. The method called Global Simplex Optimization (GSO) is an Evolu-tionary Algorithm incorporating a weighted stochastic recombi-nation operator inspired from the reflection and expansion operators of the traditional simplex method. Numerical results demonstrated that, despite its particular simplicity, the resulting method shows promising performance levels compared to other algorithms particularly the other extensions of simplex method to global optimization. This promising efficiency, how-ever, invites for further research work on weakness areas, including the design of appropriate self-adaptation mechanisms for the algorithm, so that it can adjust itself to the function landscape in real-time.
 Appendix A
List of test functions 1. Branin RCOS (RC) (2 variables):
 X  X  10 ; 2. B 2 (2 variables): 3. Easom (ES) (2 variables): 4. Goldstein and Price (GP) (2 variables): 5. Shubert (SH) (2 variables): SH  X  x 1 , x 2  X  X  6. De Joung (DJ) (3 variables):
DJ  X  x 1 , x 2 , x 3  X  X  x 2 1  X  x 2 2  X  x 2 3 ; 7. Hartmann (H 3,4 ) (3 variables): search domain: 0 o x j o 1, j  X  1, y ,3; 4 local minima: p )  X  i th local minimum approximation; f (( p i )) E c i ; 1 global minimum: x *  X  (0.11,0.555,0.855); H 3,4 ( x * )  X  3.862779787332663 8. Shekel ( S 4, n ) (4 variables):
S , a , a 3 functions S 4,n were considered: S 4,5 , S 4,7 and S 4,10 local minimum approximation; S 4,n (( a i T )) E 1/ c i ;
S
S
S 4 , 10 n  X  10 10 minima with 1 global minimum : S 4 , 10 9. Hartmann ( H 6,4 ) (6 variables): search domain: 0 o x j o 1; j  X  1, y ,6; 4 local minima: p ,p )  X  i th local minimum approximation; f ( p i ) E c i ; 1 global minimum: H 6,4 ( x * )  X  3.322368011415516 p 10. Rosenbrock ( R n )( n variables): o 10, j  X  1,..,n , several local minima (exact number unspecified in 11. Zakharov ( Z n )( n variables): o 10, j  X  1 ,.., n , several local minima (exact number unspecified in MaxFE values Func. RC B 2 ES GP SH R 2 Z 2 DJ H 34 S References
