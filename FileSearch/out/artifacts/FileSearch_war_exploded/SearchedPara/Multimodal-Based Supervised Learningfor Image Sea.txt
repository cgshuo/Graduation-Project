 Thanks to the growth of image sharing Web sites, such as Flickr, image retrieval textual information of images, e.g., the titles, surrounding texts and the URL of the web pages containing the images, to retrieval the images. However, a picture is worth a thousand words, those textual information lack the discriminative power to deliver visually search results. Due to the mismatch between images and to reorder the images in the initial list returned by text-based search engine to enhance the performance of search engine.
 the performance of reranking methods varies a lot when the methods employ with is not effective for some queries. Therefore, we employ multimodal features which mean the multiple visual features extracted from images.
 Two most popular methods using multimodal features are early fusion and employ late fusion which utilizes multimodal features to develop a set of query-independent reranking features and integrates them within a short feature vec-tor. Then a supervised method is used to learn the weight of each feature. The main difficulties of our method lie in what reranking features we should develop and what supervised method we should utilize. In our method, we develop two different features for each modality, namely, PageRank Pseudo Relevance Feed-back and Density Feature, and develop Initial Ranking Score Feature for initial list (presented in Section 3.2 ) and integrate them into 19-dimensional feature vector. We employ Rank SVM (presented in Section 3.1 ) to learn the weight of each feature.
 The main contributions of this paper are described as below:  X 
We propose a multimodal-based supervised learning for image search rerank-ing.  X  To exploit the query-independent features for each modality, we design
PageRank Pseudo Relevance Feedback and Density Feature.  X 
Each modality has its own character, we introduce different strategies for different modality to obtain the similarity between a couple of images.  X 
We conduct experiments on the MSRA-MM Dataset[ 3 ] and the results demonstrate the improvement in robust and effectiveness of the proposed method.
 The rest of this paper is organized as follows: In Section 2 , we review some related works on image search reranking. In Section 3 , we explain the detail of the proposed multimodal-based supervised learning method. In Section 4 , we illustrate our experimental results conducted on MSRA-MM Dataset. The conclusion and future work are presented in Section 5 . The existing image search reranking methods can be divided into two categories: supervised methods and unsupervised methods.
 Supervised methods usually first exploit a feature vector. Then they employ a part of data in dataset for training to learn the weight of each feature while the rest of data is for testing. Nowadays, there are various training methods. The most common method that the researchers employed is Rank SVM [ 4 ]. The groundtruth they usually use is the relevance between query and corresponding images which is annotated by volunteers. After obtaining the weight of each feature, they test their methods on the rest of data. Finally they rerank the images in the test data by the predicted score which is obtained by the product of the weight vector and feature vector. Different methods vary mostly in which features they use. In [ 5 ], the features are exploited from the initial list and contextual information which are based on the whole image. Yang et al. [ 6 ] argued that it is too rigid to operate on the whole image, by reason that there may be some noises on the background. Therefore, they proposed a bag-of-objects-retrieval model which is based on the object extracted from the images. visual features of images and calculate relevance between images. Then they construct a similarity graph where they set the images as nodes and the edges between nodes are weighted by the visual similarity. After that, the random walk is applied to the graph until the tolerance converges to a very small number. Through random walk, the nodes spread their visual information to the other images in the whole network. [ 8 ] is based on both textual and visual features. Tian et al. treat the textual features which are detected by the initial ranking list as a good baseline to do the image search reranking. With those features, they construct a model with Bayesian framework. Before presenting the proposed image reranking method, we give some definitions. which is defined as: using Kullback-Leibler divergence (KL divergence) computed by Eq ( 2 ): where r i is the ranking number of i -th image in the reranking list r , q is the given query, d refers to the image collection returned by search engines. where  X  q is a constant which can be ignored for reranking and P ( r modeled using Supervised Model[ 5 ]: where  X  are the functions which can master of the feature extraction processes and w is the weight for each function. Hence, the solution of reranking optimiza-tion Eq ( 1 ) can be solved by: The performance of Supervised Model varies a lot from query to query. The query. Therefore, in our method, we employ multimodal features which mean the multiple visual features extracted for the images.
 Fig. 1 briefly describes the framework of the proposed multimodal-based of each query-independent feature. The training data is submitted to the Fea-ture Generating Model (FGM). When a query is submitted, FGM presents the query to a search engine which returns a initial list L and a image set D . Then, we detect six visual features which are detailed in Section 3.2 and calculate six different similarity metrics for each image in D based on each visual fea-ture. For calculating query-independent reranking features (i.e., PPRE, DF), we construct six different similarity graphs which nodes are images. The difference between six similarity graphs is the weight of each edge which is measured by the similarity between images. After that, exploiting the similarity graphs and the initial list, the query-independent features (i.e., PPRE, DF, IRS) are calculated and the groundtruth, the weight for each feature is learned by Rank SVM which is recommended in Section 3.1 . In practice, after the query committed to the search engine, a query-independent feature vector is exploited by FGM. With the product of features and weight, the reranking process is conducted and the reranking list is returned. More detail of the proposed method for the practical image search reranking is shown in algorithm 1 . 3.1 Rank SVM Rank SVM [ 4 ] turns the ranking problem into a classification problem by using pair-wise classification SVM. where w is the weight for each feature and C is a trade-off. k X is ranked before image Y.
 Minimal Optimization) [ 9 ] and cutting-plane algorithm [ 10 ]. In this paper, we employ the system designed by Thorsten Joachims [ 11 ]. 3.2 Feature Generation We employ the visual features presented below. And on this basis, we exploit two types of features, i.e. , PageRank Pseudo Relevance Feedback(PPRF) and Den-sity Feature(DF). PPRF is extracted by assuming top m images in the PageRank list are relevant images while lowest-ranked images are irrelevant. The score of PPRF is calculated based on relevance and irrelevance feedback. DF is extracted from the density of image calculated by Kernel Density Estimation(KDE) [ 12 ]. At last, we employ the initial list to develop a initial score.
 Visual Features. Visual features are low-level features used in image search reranking. A range of visual features can be extracted from the images: color others. In this paper, we utilize the following visual features:  X  Block-wise Color Moment (BCM) BCM is a simple but effective char- X  HSV Color Histogram (HCH) HCH is a kind of color histogram on HSV Algorithm 1. SMRModel( D , L , f ) its own wavelength range of the light spectrum. Through merely counting the number of pixels on the image for each bin, the histogram is obtained.
HCH is a representation of the distribution of colors in a HSV image. In this paper, we use 64D HSV Color Histogram.  X 
RGB Color Histogram (RCH) The same as HCH, RCH is a kind of color histogram on RGB color space. RCH can be implemented in exactly the same way as HCH. In this paper, we use 256D RGB Color Histogram.  X  Color Correlogram (CC) Different from the traditional color histogram,
CC builds the histogram by the distance between different colors. The first step of CC is the same as HCH. After that CC choose different distance criterions d 1 ,d 2  X  X  X  d m . Then for each distance and each pair of bins, we count the number of pairs whose spatial distance between bins is d dimensions of feature vector d = n  X  n  X  m . In this paper, we use 144D Color
Correlogram.  X 
Edge Distribution Histogram (EDH) EDH is the textural feature of image. First, EDH detects image edge by Sobel operator, Canny operator, and so on. Based on the image edge we get, the EDH is constructed and normalized. In this paper, we use 75D Edge Distribution Histogram.  X 
Wavelet Texture (WT) WT is a global texture feature. First, WT needs to choose a mother wavelet function. Based on this function, at each level, it decomposes the image into four part. Finally, for each part at each level we calculate mean and standard deviation of the energy distribution to develop the feature vector. In this paper, we use 128D Wavelet Texture.
 PageRank Pseudo Relevance Feedback (PPRF). PRF [ 13 ] is widely adopted today to do the image retrieval. PRF assumes top-ranked images in the initial list are relevant to the query. Then a majority of PRF methods rerank the images according to the relevance of top ranked images. Due to the very top-ranked results are not always meeting the users intention, so we design the PPRF to convert the image reranking into identifying the  X  X uthority X  nodes in the similarity graph. First, we employ PageRank [ 7 ] to obtain the  X  X uthority X  of nodes. By ordering the authority of images, the PageRank list is obtained. Then we assume top-ranked images in the PageRank list are relevant to the query while lowest-ranked images are irrelevant. Finally, we use relevance and irrelevance feedback to compute the rerank score for images. Duplicate voting is adapted to do the relevance and irrelevance feedback.
 where m is the number of images we used to feedback. dup ( detection function elected from [ 14 ].
 Density Feature (DF). Density Feature is based on the density assumption which means relevant images should have higher density than irrelevant images. It is confirmed by [ 1 ]. KDE is employed to calculate the density of image x positive function that integrates to one. A range of kernels are commonly used: uniform, normal, triangular, and others. In this paper, the Gaussian kernel is employed.
 Initial Ranking Score Feature (IRS). Initial ranking list is a good baseline for the  X  X est X  ranking list. Though noisy, we should discard the dross and select the essence as well. However, most of the search engines only provide the ranking paper, we pick the equation ( 14 ) to do the work mentioned above. 3.3 Initial Ranking Score Initial ranking score s i is the ranking score of image X most direct way to get this score is to use the score returned by text-based search engines. However, in most cases, this score is hard to obtain and the transform ranking number to score. Many alternative strategies are proposed by [ 8 ][ 15 ]:  X 
Ranking Number (RN) RN employs the difference between the number of total images and the ranking number of the image to obtain the ranking score s i . where N is the number of total images in the initial list and r number of i -th image in the initial list.  X 
Normalized Ranking Number (NRN) Based on RN, NRN uses the total number N to normalize the RN.  X 
Initial Relevance Estimation (IRE) IRE investigates the relationship between ranking score s i and the ranking number r i with all queries. where means all the queries in the dataset. E q  X  is the expectation on the is labeled to be 0, 1 or 2. A heuristic way to obtain E q  X  relevance score rel ( q, r i ) on the query set . 3.4 Image Similarity returned by text-based search engine and edges are established between a couple of similar images. The similarity between images are calculated by:  X 
Jensen-Shannon divergence (JSD) JSD is based on the Kullback-Leibler divergence[ 16 ].
 where h q [ m ] is the value of m  X  th bin in the histograms for image q .  X 
Radial basis function kernel (RBF) The value of RBF merely depends on the distance from the origin. The norm radial function is usually Euclidean distance.
 where x q is the feature vector of image q and  X  is the scaling parameter.  X 
Histogram Intersection Method(HIM) HIM [ 17 ] exploits a average sim-ilarity of images.
 similarity between images. The different features have different characteristics, and for some features, another policy works better. For the feature of Color Histogram, i.e., HSV Color Histogram and RGB Color Histogram, Histogram Intersection Method ( 17 ) is employed while for Color Correlogram, the Jensen-tion kernel ( 16 ). In this section, we first describe the experimental settings that we will use in the aforementioned Multimodal-based Supervised learning method. Then we will present the performance of our method compared with several existing methods. 4.1 Experimental Settings Dataset. In our experiment, we evaluate our method on MSRA-MM dataset. In this dataset, there are 68 representative queries which are selected from the query log of Microsoft Live search and then for each query they collect about 1000 images. So there are a total of 65443 images. For each image, they provide a set of features. In order to evaluate the result, they also provide a vector of relevance score which is construct between the query and the corresponding images returned by text-based search engine. The relevance score is in The score { 0 } means that the image is irrelevant to the corresponding query. The score { 1 } means that the image is relevant to the corresponding query. The score { 2 } means that the image is very relevant to the corresponding query. Evaluate. We employ widely used Normalized Discounted Cumulative Gain ( NDCG ) to evaluate the performance of our method. The NDCG for a given query is calculated as follow: where top n images to calculate the NDCG @ n . IDCG @ n is a regularization factor which is computed in a ideal way. First, we sort the images on basis of the rele-vance score, then we employ the equation ( 19 ) to compute it. It is the maximum value of DCG @ n . We utilize mN DCG @ n (mean of NDCG @ n on all queries) to evaluate our methods on all of the queries. 4.2 Performance on All Queries In this section, to demonstrate the effectiveness of the proposed multimodal-based supervised learning method(SM), we compare it with the methods using merely one modality (i.e., BCM, HCH, RCH, CC, EDH, WT) and three state-of-the-art approaches. The baseline includes Supervised Reranking (SR) [ 5 ], Pseudo Relevance Feedback Reranking (PRF) [ 13 ], Bayesian Visual Reranking (BVR) [ 8 ]. For SR, the Rank SVM [ 4 ]is used to train the model to gain the weight of features. For PRF, we treat top-10 images as positive samples to do the relevance feedback. For BVR, according to the suggestion presented by Tian et al. , the wise ranking distance is adopted to measure the ranking distance. Fig. 2 shows the performance of aforementioned three baseline methods and proposed SM in the light of mN DCG @20, mN DCG @40 and mN DCG @60. From Fig. 2 , we can obvious see that SM can outperform the baseline methods. Even though the SM with only one modality, the baseline methods are less effective than it. As position of mN DCG n increases, the performance of three baseline methods certainly fall a great deal while the proposed method makes only a small dent. It demonstrates the effectiveness of our method. 4.3 Performance on Different Initial lists include the following components:  X 
Perfect initial list (Perfect): This list orders the images based on their rele-vance score. All very relevant images are ordered on the top of list while all the irrelevant images are ordered on the bottom of list.
  X  Random initial list (Random): Images are ordered randomly. Fig. 3 compares the three baseline methods and the proposed method on different initial lists. For the result, we can see that PRF and BVR are sensitive to the initial list. A possible reason is that PRF assumes the top-ranked images which are in the initial are pseudo relevant images. If we use the worst initial list to do PRF reranking, most of the pseudo relevant images will be irrelevant images have a higher rank than relevant images. In the opinion of Bayesian visual multimodal method does a good job on both perfect initial list and worst initial list. In the learning step of our model, we use Rank SVM to learn the weight of each features we construct. When using worst initial list, the weight of features the features which are about perfect initial list. In this way, whether using the perfect initial list or not, our method puts up a good performance. In this paper, we propose a novel model to do image search reranking, multimodal-based supervised learning for image search reranking. This model employs multiple modalities to exploit the query-independent features. Evalua-tions on MSRA-MM dataset demonstrate the effectiveness and stability of the proposed method.
 In the future, we can concentrate on the following respects:  X 
In this paper, we only design two features for each modality. We can dig through more effective query-independent features.  X 
The proposed method does not take the diversity into consideration. After reranking, we can append with a step to realize the diversity.

