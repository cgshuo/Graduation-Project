 Chronic diseases, such as Alzheimer X  X  Disease, Diabetes, and Chronic Obstructive Pulmonary Disease, usually progress slowly over a long period of time, causing increasing burden to the patients, their families, and the healthcare system. A better understanding of their progression is instrumental in early diagnosis and personalized care. Modeling disease pro-gression based on real-world evidence is a very challenging task due to the incompleteness and irregularity of the ob-servations, as well as the heterogeneity of the patient condi-tions. In this paper, we propose a probabilistic disease pro-gression model that address these challenges. As compared to existing disease progression models, the advantage of our model is three-fold: 1) it learns a continuous-time progres-sion model from discrete-time observations with non-equal intervals; 2) it learns the full progression trajectory from a set of incomplete records that only cover short segments of the progression; 3) it learns a compact set of medical con-cepts as the bridge between the hidden progression process and the observed medical evidence, which are usually ex-tremely sparse and noisy. We demonstrate the capabilities of our model by applying it to a real-world COPD patient cohort and deriving some interesting clinical insights. H.2.8 [ Database Management ]: Database Applications-Data mining Bayesian network, Markov jump process, disease progression modeling, medical informatics
Chronic diseases usually progress slowly over time. For example, Chronic Obstructive Pulmonary Disease (COPD) can take well over 10 years to evolve from (according to the GOLD criteria [6]) Stage I (mild) to Stage IV (very severe). It may also take 10 years for Congestive Heart Failure (CHF) to progress from Stage I (mild) to Stage IV (severe). Late detection and intervention for such chronic diseases signif-icantly increases the burden on both the patients and the healthcare system. Being able to detect the development of chronic diseases at an early stage is instrumental to preven-tive care and personalized medicine.

Disease Progression Modeling (DPM) [11], the modeling of the progression of a target disease with computational meth-ods, is an important technique that can help with the early detection and management of chronic diseases. By char-acterizing the entire disease progression trajectory, DPM also facilitates disease prognosis improvement, drug devel-opment, and clinical trial design. There have been a few ex-isting work on DPM that targets a specific domain. For ex-ample, Jackson et al. [9] presented a general Hidden Markov Model for simultaneously estimating the transition rates and the probabilities of stage misclassification. Ito et al. [8] con-ducted a meta analysis to model the longitudinal changes of patients with mild to moderate Alzheimer X  X  disease. Zhou et al. [17] proposed a fused group lasso approach for disease progression modeling with known biomarkers. Exarchos et al. [5] developed a dynamic Bayesian network based tech-nique to model the progression of Coronary Atherosclero-sis. Some difficulties of applying these existing methods to general-purpose evidence-based disease progression model-ing include:
To address these challenges, we propose an unsupervised disease progression model. As show in Figure 1, our model is composed of three layers: The top layer is a Markov Jump Process which captures the continuous-time diseases state transitions. The middle layer is a set of Markov chains capturing the relationship between the hidden state tran-sitions and the onset pattern of a set of comorbid conditions (comorbidities). The third layer is a noisy-or network [14] (Figure 2) capturing the relationship between those comor-bidities and the observed clinical evidence. Note that in-stead of linking the clinical observations directly to the dis-ease progression states, we  X  X roup X  them into comorbidities, which tend to evolve coherently with the progression of dis-ease. This abstraction also makes the learned DPM more ro-bust and interpretable. An Expectation-Maximization (EM) based algorithm is presented to estimate the parameters as well as the hidden variables. We apply our model to a real-world COPD patient cohort to demonstrate its capabilities.
It is worthwhile to highlight the following aspects of the proposed model:
Disease progression modeling is an important topic in medical informatics [11]. Existing work on disease progres-sion models have been proved effective for drug develop-ment and early intervention. For example, Post et al. [12] proposed a family of models to describe the progression of degenerative diseases (such as type 2 diabetes and Parkin-son X  X  disease) as a function of disease process and treatment effects. De Winter et al. [3] developed a mechanism based technique for modeling the progression of diabetes mellitus by tracking the interaction between several key indicators. Ito et al. [8] presented a model based on literature meta-analysis to describe the longitudinal changes of patients with Figure 1: The outline of our model: S are progres-sion state variables, X are comorbidity variables, and O are observed clinical findings.
 Figure 2: The noisy-or Bayesian network (also known as QMR-DT network). The clinical findings can be activated by a present comorbidity, or by the always-on leak term. The starred finding ( O 1 ) is an anchor, which means it can only be activated by a specific comorbidity ( X 1 in this case). mild to moderate Alzheimer X  X  disease. These papers from the medical field tend to be specific to a single target disease. They require substantial domain knowledge on the progres-sion, mechanism, and key indicators/measurements for the target disease. This is not the case for our model because we aim to learn a general-purpose model for any chronic dis-ease based on a general input data type: Electronic Health Records. We do not assume prior knowledge of either the ground truth progression stages or the key indicators that signify the stage transitions.

Another line of efforts, to which our approach belongs, model the progression of disease using machine learning and statistical techniques based on observational data, also re-ferred to as evidence based modeling. For example, Jack-son et al. [9] developed a multistage Hidden Markov Model and applied it to an aneurysm screening study. Sukkar et al. [15] applied Hidden Markov Model to Alzheimer X  X  dis-ease. Cohen et al. [2] performed hierarchical clustering of 45 physiological, clinical, and treatment variables collected every minute in an intensive care unit to identify patient states. They used these clusters to visualize individual pa-tient states over time, with each state obtained by assigning the corresponding data point to a cluster. Zhou et al. [17] proposed a fused group lasso formulation for disease progres-sion modeling with known biomarkers. Zhou et al. modeled disease progression using a multi-task learning framework [18]. As pointed out by Yang et al. [16], if we model patient records as time sequences, disease progression stages can also be captured by joint time sequence segmentation. The dif-ference between these existing techniques and our approach includes: 1) Unlike the discrete-time HMM based models, our model is continuous-time, which is a more natural way to handle the irregular time intervals between patient visits; 2) Some existing work were dealing with synchronous time sequences, i.e. there are explicit or implicit correspondence between the timestamps of different patients. This assump-tion is not true for our model where a patient record could start and end at any point of the progression path.
We model the progression of a target disease based on the longitudinal clinical findings of a cohort of patients who have developed, or are at risk developing, such disease. First of all, we use a Markov Jump Process to model the transition of disease stages/states, which implies 1) the progression is continuous-time; 2) the transition probability to the future state only relies the current state and the time span.
Second, we use the onset pattern of comorbidities to drive the transitions of the Markov Jump Process. Generally speaking, a comorbidity is a disease or syndrome that co-occurs with the target disease. For example, hypertension is a common comorbidity of diabetes and osteoporosis is a com-mon comorbidity of COPD. Since the onset of a new comor-bidity often signifies the exacerbation of the target disease, we use the onset pattern of multiple comorbidities to col-lectively capture the state transitions of the target disease. We assume the comorbidities are conditionally independent given the state of the target disease. This is a mild assump-tion in our case because medically meaningful comorbidities are by definition mutually independent diseases.

Finally, in order to infer the presence of the comorbidities from the observed clinical findings, we use a bipartite noisy-or Bayesian network [7, 14] (Figure 2). Simply speaking, given a set of comorbidities and a set of clinical findings, we assume an observed clinical finding was  X  X ctivated X  by the presence of any of the comorbidities with a certain activation probability ; it is also possible that none of the comorbidities is present and the finding was activated by an always-on hid-den cause with a leak probability . Such structure is especially well suited to our setting due to its flexibility in modeling sparse and noisy observations.

Our overall model is illustrated in Figure 1. Some no-tations that are used throughout the rest of the paper are listed in Table 1.
We assume that there are K different comorbidities un-derpinning the progression of the target disease, D different clinical findings, and M different progression states. We have N different patients and each patient n has T n visits, with timestamps  X  1 ,..., X  T n . We introduce the following A ( X ) Transition probability matrix over time span  X  variables for our model:
The underlying patient state is assumed to evolve ac-cording to a continuous-time Markov process. However, we only observe evidence about the patient at specific times  X  ,..., X  T n when the patient interacts with the healthcare system (e.g. visits a doctor or fills a prescription). The random variables S n,t and X k,n,t for t = 1 ,...,T n denote the patient X  X  disease state and comorbidities, respectively, at these discrete times. X k,n,t = 1 means patient n has comorbidity k at visit t , and is 0 otherwise. In our gen-erative model, the presence or absence of comorbidity k at time t , i.e. X k,n,t , depends on whether the patient had the comorbidity in the previous time step, X k,n,t  X  1 as well as the patient X  X  progression state. Associated with each visit is a set of observed clinical findings, O d,n,t , which we assume to be conditionally independent given the disease X  X  current state of progression and the comorbidities. We model these using a noisy-or bipartite network, shown in Figure 2 and discussed further in Section 3.4.
The continuous-time Markov process is parameterized by an M  X  M transition generator matrix Q that drives the transition between M states. The transition probability from state i to j with a time span  X  is defined as: where expm(  X  ) is the matrix exponential.

The M  X  1 initial state probability  X  is defined as:
The disease progression is manifested through a number of comorbidities, which we model as binary random variables. The state of each comorbidity variable at time t , X k,n,t decided by the current disease state S n,t as well as the state of the same comorbidity variable at the previous time step, X k,n,t  X  1 . We further constrain that a comorbidity onset can only happen when there is a state transition from S n,t  X  1 S n,t (which means the overall condition of the patient has changed). This conditional distribution is parameterized by a K  X  M  X  2 comorbidity onset probability B : B a  X  { 0 , 1 } . We assume that B is homogeneous with time t and independent of the particular patient n . For what follows, we define the shorthand: At t = 0, the initial onset probability B 0 is defined as:
What remains is to describe how we generate the observed findings (e.g., the diagnosis codes) given the disease and co-morbidity states. For this part of the model we use a bipar-tite noisy-or Bayesian network. Such networks have been previously used for medical diagnosis, a prominent example being the Quick Medical Reference (QMR-DT) [14]. How-ever, rather than having a single diagnosis model per patient, we use a new one for each visit, tying them together by hav-ing the prior distribution for the comorbidities (the top-level in Figure 2) depend on the state of the comorbidities in the previous visit and on the overall disease state.

We have one parameter Z k,d for the activation proba-bility of comorbidity k and finding d . The larger Z k,d the more likely observation O d,n,t is to be 1 whenever X is 1. If none of the comorbidity variables are active, an ob-servation O d,n,t still has the chance to be activated by an unknown cause, assumed to always be on, with the leak probability L d , p ( O d,n,t = 1 | P K k =1 X k,n,t = 0). Overall, O d,n,t follows a noisy-or distribution. We define  X ( O d,n,t as a shorthand for:  X ( O d,n,t | X ) , 1  X  (1  X  L d )
Only O is observable. X and S are hidden, and  X  , Q , B , L , Z are parameters to estimate. We give the progression model parameters B,L and Z Beta priors and perform marginal inference over both the latent variables and the model parameters using Gibbs sam-pling. Estimation of the Markov Jump Process is challenging in our setting due to incomplete observations nonequidistant in time [10], and for computational reasons it is preferable to perform Maximum Likelihood Estimation of the parameters of the continuous-time Markov chain, i.e. max  X ,Q p ( O ;  X ,Q ). We use Expectation-Maximization to find a local optimum of the likelihood. The overall learning algorithm is summa-rized in Algorithm 1.

We omit details of the Gibbs sampling and EM algorithm that are standard, instead focusing our description on esti-mation of the continuous-time Markov model and on other aspects that are special to our setting.
 Algorithm 1: Our Algorithm Input : Clinical findings O
Output : Transition generator matrix Q , initial state
Initialize S , X ,Q, X ,B,Z,L ; repeat 3 repeat 4 Gibbs sampling from p ( S , X ,B,L,Z | O ;  X ,Q ); 5 until Convergence ; 6 Use samples to estimate p ( S n, 0 = i | O ;  X ,Q ) and 9 repeat 10 Compute E [ N ij ( X ) | k,l,Q ] and E [ R i ( X ) | k,l,Q ] 11 Update Q  X  12 until Convergence ; until Convergence ;
The complete log-likelihood is log p ( O , S ,S (  X  );  X ,Q ). Both the discrete states S and the continuous process S (  X  ) are hidden, so in the E-step we take their expectation with re-spect to the posterior distribution over S and S (  X  ) using the current parameter setting  X  0 ,Q 0 :
The second term in Eq. (6) can be written as (see [10] for detailed derivation): E where we define C ij ( X ) , and for which we need to compute N kl ( X ) is defined as the number of transitions from state k to l during the time interval  X . R k ( X ) is the amount of time spent in state k during the time interval  X . Note that these are auxiliary latent variables that we introduce to help us learn the continuous-time Markov process. We will later describe how to estimate their expectations. The posterior distribution for B , Z , and L can be obtained in closed-form since the Beta distribution is conjugate for the Bernoulli. To perform Gibbs sampling of these continuous parameters (with range [0,1]), we use a fixed set of discrete values. For instance, we can sample from 0.01 to 0.99 with 0.01 increment; finer sampling granularity can be chosen at the cost of longer runtime (the complexity is linear to the number of values).

We perform block sampling of both X and S , substan-tially improving the mixing time of Gibbs sampling at the cost of only double the running time per iteration. For fixed n and k , we sample X k,n,t ,t = 1 ,...,T n from the joint dis-tribution: in which p ( X k,n,t = i |  X  , O ) and p ( X k,n,t = j,X ( X  X  k , S ,B,Z,L ).

Define  X  i ( t ) , p ( O d,n, 0 ,...,O d,n,t ,X k,n,t = i |  X ) . It can be updated sequentially as
Also define  X  i ( t ) , p ( O d,n,t +1 ,...,O d,n,T n | X It can be updated sequentially as  X  i ( T n )  X  1 and  X  i ( t  X  1)  X  X Then it is easy to show [13] that: Therefore the forward sampling probability for X k,n,t is:  X   X  j ( t + 1) The  X   X  X  cancel out in Eq. (10), so we do not actually need to compute them (other than  X  i (0)). A similar forward sam-pling procedure can be derived for S n,t , t = 0 ,...,T n details are omitted due to space limitations.
In the M-step we update two parameters:  X  and Q . Up-dating  X  i is straightforward:
We update Q using the closed-form solution based on eigendecomposition introduced in [10]: Q U  X  U  X  1  X  Q (eigendecomposition)  X  pq ( X )  X  E [ R i ( X ) | S ( X ) = l,S (0) = k ; Q 0 ] E [ N ij ( X ) | S ( X ) = l,S (0) = k ; Q 0 ] Recall that A kl ( X ) is the transition probability from state k to l given the time span  X  (Eq. 1).

In our implementation, instead of returning to Gibbs sam-pling over S immediately after Q is updated, we first repeat the above procedure until Q converges (i.e., only recomput-ing expectations of S (  X  ) with respect to the new parame-ters), and then go back to the Gibbs sampling step. This is an approximation based on the assumption that a small change in Q will not lead to a significant change in the marginal distribution of S .
In the Gibbs sampling step, we need to repeatedly evalu-ate the likelihood of the noisy-or network given the current parameter and variable assignments: i  X  X  0 , 1 } , for a given n and t .

To compute this likelihood in its original form, the com-plexity is proportional to D , the total number of findings, which is typically very large (tens of thousands for EHR data). However, notice that we do not need to evaluate this over all possible findings: When we sample a specific X k,n,t , most terms in the last line of the above equation, corresponding to the negative findings, cancel out. Consequently the ratio between the two likelihoods can be simplified to: Q Q = Y Q
With this improvement, the complexity of evaluating  X  is only proportional to the number of positive findings, which is far smaller than the total number of findings. More specifically, let N be the number of patients, M the num-ber of progression states, T the number of visits (assuming each patient has the same number of visits), K the num-ber of Comorbidities, and D the number of clinical find-ings. The cost of sampling X is reduced from O ( NTK 2 D ) to O ( NTK 2 D + ), where D + D is the number of pos-itive findings for an individual patient. The cost of sam-pling L , which benefits from the same optimization, is re-duced from O ( NTKD + NTMD ) to O ( NTKD + + NTMD ); the cost of sampling Z is reduced from O ( K 2 D 2 NT ) to O ( K 2 D + DNT ). The cost of sampling B remains O ( KMNT ).
In this section we apply our model to COPD, one of most prevalent chronic diseases worldwide. It is a particularly in-teresting target for a disease progression study because it has a prolonged progression path and is associated with a range of well-studied comorbidities [1,4]. Understanding the progression trajectory of COPD is crucial for early interven-tion and personalized care plan management.

We tested our model on a real COPD cohort to demon-strate that our model can automatically discover medically meaningful comorbidities among COPD patients. We present the COPD progression stages as identified by our model, which help explain the medical characteristics of COPD at different stages and the key medical events that trigger ex-acerbation. We showcase a typical application of the learned model, which is to infer the progression trajectories of indi-vidual patients based on their clinical observations. We also demonstrate the convergence behavior of our model and the importance of incorporating anchor findings.

Note that there are some existing clinical evaluation cri-teria for the progression/severity of COPD, such as GOLD and BODE index [6]. The progression trajectories defined by these criteria, which are mainly focused on the deteriora-tion of respiratory function, are fundamentally different from the progression trajectories defined by our model, which are the onset patterns of various comorbidities. In practice our model is complementary to these existing standards in of-fering the medical practitioners a comprehensive character-ization of the patients X  condition. Our data came from a real-world longitudinal Electronic Medical Record (EMR) database of over 300,000 patients over the course of 4 years. For each patient encounter, a set of International Classification of Diseases -Version 9 (ICD-9) codes were recorded to indicate what medical conditions that patient had at that time point. Other information, such as drug prescription, lab test results, were also recorded. Note that in our database we did not have the lab measure-ments needed by either the GOLD or BODE criteria.

We first consulted our medical experts to identify the pa-tients who were confirmed of having COPD at any time point during the record. The criteria we developed were the occurrence of at least one ICD-9 code that is related to COPD and the prescription of at least one COPD-related medication. Based on this selection criteria, we were able to identify 3,705 confirmed COPD patients from the database. For these patients, we extract their records in terms of ICD-9 codes. In total we had 5,263 unique ICD-9 codes asso-ciated with these patients. We removed infrequent ICD-9 codes that appeared for fewer than 200 patients, leaving us with 264 distinct codes (our findings). Considering the rela-tive slow progression of COPD, we further decrease the time granularity of the original record. We segmented the time dimension into disjoint 90-day windows and combined all the observations within each window, viewing it as one en-counter. In the end we had 34,976 encounters with 189,815 positive observations. Notice that the observations were very sparse: on average each patient had 10 encounters and 5.4 positive observations (ICD-9 code assignment) per en-counter. The average record span of a patient was 816 days and the largest span was 1,094 days. Notice that this time span is significantly shorter than the span of regular COPD progression, which makes our setting very challenging.
Setting Anchors for Comorbidities: Our model in-fers the disease progression through the onsets of the co-morbidities. Therefore the validity and relevance of the comorbidities have a great impact on the interpretability of our model. On the one hand, our model can be fully unsupervised and learn the comorbidities from the clinical findings. On the other hand, if we already have some do-main knowledge on the important comorbidities, our model can incorporate such knowledge via setting anchor findings and produce comorbidities in alignment with the domain Comorbidity Representative Conditions (Anchor ICD-9 Codes) Asthma Asthma (493) Lung Infection Pneumonia (481, 485, 486) Diabetes Diabetes with Different Types and Complications (250) Psychological Anxiety (300), Depression (296, 311) Obesity Morbid Obesity (278) our model. * means anchor findings.
 .45 Chronic Airway Obstruction* .40 Asthma* .05 Chronic Bronchitis with Exacerbation* .07 Allergic Rhinitis .04 Emphysema* .05 Cough .04 Chronic Bronchitis without Exacerbation* .04 Acute Bronchitis .03 Respiratory Abnormalities .03 Acute Upper Respiratory Infections .30 Benign Essential Hypertension* .30 Pneumonia* .25 Unspecified Essential Hypertension* .10 Shortness of Breath .15 Atrial Fibrillation* .10 Respiratory Abnormalities .10 Congestive Heart Failure* .10 Cough .10 Hyperlipidemia .06 Abnormal Findings of Lung .15 Cancer of Other Parts of Bronchus or Lung* .10 Hyperlipidemia .15 Lumbago* .20 Chronic Kidney Disease, Moderate* .15 Pain in Limb* .15 Anemia .10 Osteoporosis* .10 Chronic Kidney Disease, Unspecified* .06 Myalgia and Myositis* .08 Urinary Tract Infection .04 Acquired Hypothyroidism .08 Chronic Kidney Disease, Severe* .15 Depression, Unspecified* .25 Obesity, Unspecified* .15 Anxiety* .10 Morbid Obesity* .04 Other Malaise and Fatigue .03 Pure Hypercholesterolemia .04 Major Depression, Recurrent Episode* .02 Edema .03 Major Depression, Single Episode* .02 Sleep Apnea
Pure Hypercholesterolemia .03 knowledge. The study of COPD belongs to the latter case since COPD has some well-studied comorbidities, and dis-covering the progression of these designated comorbidities in terms of the progression of COPD is of great practical significance. We reviewed the literature with our medical experts and identified nine important COPD comorbidities (or comorbidity groups): asthma, cardiovascular diseases, lung infection, lung cancer, diabetes, musculoskeletal disor-ders, kidney diseases, psychological disorders, and obesity. In Table 2 we list these comorbidities along with the ICD-9 codes we used to anchor them. We also created an addi-tional comorbidity to track the target disease itself, which was anchored by the ICD-9 codes we used to confirm COPD. Following the notions introduced in [7], if feature d is anchor of comorbidity k , we set Z k 0 ,d to 1 e  X  6 for any k 0 chose this small value instead of 0 to avoid numerical under-flow).

Constraining Progression Trajectory: For the re-sults in the next section, we add a constraint to the transi-tion generator matrix Q enforcing that we learn a linear pro-Table 4: An example comorbidity identified without anchors. Although important conditions were iden-tified, they were mixed together with no coherent medical interpretation (comparing to Table 3). .35 Benign Essential Hypertension .30 Type II Diabetes without Complication .25 Mixed Hyperlipidemia .20 Coronary Atherosclerosis Of Native Coronary Artery .20 Pure Hypercholesterolemia .15 Type II Diabetes without Complication, Uncontrolled .08 Coronary Atherosclerosis Of Unspecified Type .08 Chest Pain .06 Anemia .06 Chronic Ischemic Heart Disease, Unspecified gression trajectory: we disallowed transitions from a later state to an earlier state by setting Q ij = 0,  X  j &lt; i . This constraint could be relaxed in many different ways, allowing us to learn a non-linear progression trajectory and/or multi-ple progression trajectories simultaneously. Such extensions will be discussed at the end of the paper.

Setting the Parameters: In order to learn a more sparse noisy-or network (thus better interpretability), we set the priors for Z to Beta(0 . 1 , 1). Thus our model will sup-press the influence of findings that are loosely connected to the underlying comorbidities. We did not impose any such preference on L and B and set their priors to Beta(1 , 1). We sample Z from 0.01 to 0.1 with 0.01 increment and from 0.1 to 0.95 with 0.05 increment; we sample B and L from 0.01 to 0.99 with 0.01 increment. Since most of our model X  X  comor-bidities are chronic and their presence is expected to be per-1) = 1. This implies that once a comorbidity is turned on, it cannot be turned off in the future. We also introduce a monotonicity constraint on B 0 enforcing that the initial probability of comorbidity onset is higher for patients who at t = 0 are at a later progression stage than those at an earlier progression stage. After introducing this constraint, we up-date B 0 in the outer EM loop (together with  X  and Q ) using a standard convex optimization procedure to maximize the likelihood subject to the monotonicity constraint. Finally, we set the number of states to M = 6 and the number of comorbidities to K = 10.
First we present the comorbidities as well as the leak term learned by our model (Table 3). For each comorbidity we list the top-5 ICD-9 codes in terms of activation/leak prob-ability ( Z k,d and L d ). All the comorbidities have clear and coherent clinical interpretations: the top findings either de-scribe the main conditions corresponding to the comorbidity (e.g. Diabetes and Kidney), or are the common symptoms caused by those conditions (e.g., Lung Infection).

We contribute such interpretability to the anchor findings (starred entries in Table 3). As a comparison, we trained our model using the exact same settings but without the anchors. As a result, conditions from different comorbidities were mixed into one (see Table 4). This is natural from the model X  X  perspective because these conditions frequently co-occur (thus the name comorbid) and no extra knowledge indicates they should be separated into different groups.
It is important to point out that our model was guided, but not fixed, by the anchor findings. For instance, there were anchor ICD-9 codes that did not appear in the top findings because the model did not consider them indicative enough; there were also some ICD-9 codes that were not anchored but ranked highly in relevant comorbidities (e.g.  X  X ump in Chest X  for Lung Cancer and  X  X rinary Tract In-fection X  for Kidney). Rhinitis and Acute Bronchitis showed up in the Asthma group because they are among the top burdens of asthma patients.
Next we characterize the progression trajectories learned by our model from the COPD patient cohort. Given the gen-erative nature of our model, we used it to generate 10,000  X  X irtual patients X . We chose virtual patients over real pa-tients because the patient records we had were only 4 years long and cannot cover the entire progression path of COPD. To generate a virtual patient, we assume the patient comes in at timestamp 0 in State 1. Then we used the learned model to generate the patient X  X  subsequent states and the comorbidity onsets corresponding to those states until the patient reached State 6 (the last state). We averaged over the 10,000 records we generated and computed the average holding time for each state as well as the prevalence of differ-ent comorbidities at each state, as summarized in Figure 3.
Figure 3 gives us an intuitive view of how our trained model depicts the average progression trajectories of con-firmed COPD patients. First, comparing different comor-bidity groups across all progression stages, COPD has the highest prevalence (this is expected because we had a COPD case cohort); other highly prevalent comorbidities include cardiovascular diseases and musculoskeletal disorders; lung cancer is the rarest comorbidity. Next, we can observe that State 1 is the  X  X ealthy X  state where the prevalence of all comorbidities are low. The transition from State 1 to 2 is driven by the onset of COPD, cardiovascular diseases, and musculoskeletal disorders. Starting from State 3, the preva-lence of COPD is already 100% while the prevalence of other comorbidities rise steadily. The sudden increase in the onset rate of diabetes, kidney diseases, and lung infections at later stages of COPD conform well to previous studies in the med-ical literature. The onset rates of lung cancer, asthma, psy-chological disorders, and obesity are relatively stable across all progression stages.
Next we showcase how to use our model to infer the pro-gression trajectory of an individual patient based on the existing medical evidence. We picked two representative patients from our cohort and used MAP inference to in-fer their most likely progression stages and comorbidity on-sets at each timestamp, respectively. Specifically, given the trained model, we repeatedly sample X and S conditioned on the observations from the query patient 1,000 times ini-tialized by 10 different random seeds. We illustrated the results with maximum posterior probability in Figure 4.
We can see that patient (a) was correctly diagnosed by our model with musculoskeletal disorder and psychological disorder at the beginning and was assigned to the least se-virtual patients generated by our model. Figure 4: Inference of the progression trajectory and comorbidity onset of individual patients. Predicted stages are at the top of each plot; gray bars indi-cate predicted comorbidity onset; and stars denote the occurrence of relevant ICD-9 codes in the data (descriptions are on top of the timeline). vere stage. After 6 months, our model diagnosed this pa-tient with cardiovascular disease. The patient was subse-quently moved into Stage 2 and stayed there throughout the record span. Note that the patient had a single occurrence of COPD related diagnosis code in the record. However, our model decided this was not enough evidence to turn on the COPD comorbidity; as a result, it was explained by the leak term (for all anchor findings we assigned a fixed leak probability of 10  X  6 ). In contrast to patient (a), patient (b) exhibited a quick exacerbation of COPD. The patient started with cardiovascular disease and musculoskeletal dis-order (Stage 1), followed by COPD and diabetes onset soon afterward (Stages 2 and 3), then eventually developed psy-chological disorder and obesity (Stage 4). We use these two representative patients to demonstrate the potential of in-corporating our model into clinical decision support systems to provide medical practitioners with evidence based predic-tion and recommendation.
In Figure 5 we show the convergence behavior of the learn-ing algorithm in terms of the relative change in Q as well as the complete data log-likelihood. We did 10 Gibbs sampling updates before first updating Q and  X  . We repeated the outer EM iterations 100 times. Despite the small number of Gibbs sampling updates, our model converged quickly thanks to the use of anchors. We implemented our algo-rithm in Python. With parallelization and aforementioned optimizations, each full Gibbs sampling update took about 3 minutes on a 24-core 2.6 GHz machine.
The techniques presented in this paper open the door to many new applications of disease progression modeling. When paired with visualization tools, clinicians could use these models to better understand the evolution of chronic illnesses, optimize treatments, and design clinical guidelines.
Our empirical study focused on the problem of discov-ering a single disease progression model for COPD. Thus, we constrained the continuous-time Markov model to allow only forward transitions. However, for many diseases it is unlikely that there is a single disease trajectory that most patients follow, but rather a set of common trajectories. We can modify our algorithm to learn a mixture of disease tra-jectories simply by partitioning the state space and enforcing forward transitions within each partition.

Our proposed approach for learning disease progression models is flexible and can easily accommodate new sources of data and/or domain knowledge. For example, we could include lists of medications prescribed or procedures per-formed in the set of clinical findings to complement diagno-sis codes. Because we use a generative model, it is trivial to marginalize over clinical findings that are unobserved on a specific visit. We could also introduce patient-specific global variables, either latent or observed. For example, the distri-bution over the initial disease state could be parameterized to be a function of age, gender, and family history. The rate matrix for the continuous-time Markov process could depend on factors such as whether the patient has stopped smok-ing, which might decrease the rate of progression. Going a step further, each specialist (e.g., endocrinologist versus a gynecologist) is likely to have a different distribution of diagnosis codes that they are likely to assign. Thus, if the specialist is provided in the data, the model could make the activation probabilities for clinical findings be different for each specialist.

An interesting question for follow-up work is whether it is possible to use non-case patients to learn disease progression models. In our experimental results we used only patients that were diagnosed with COPD. However, this limits the amount of training data. At a minimum, it may be possible to use the non-case patients to initialize the distribution of clinical findings for each comorbidity. [1] F. Baty, P. M. Putora, B. Isenring, T. Blum, and [2] M. Cohen, A. Grossman, D. Morabito, M. M.
 [3] W. De Winter, J. DeJongh, T. Post, B. Ploeger, [4] M. Decramer, W. Janssens, and M. Miravitlles.
 [5] K. Exarchos, T. Exarchos, C. Bourantas, [6] G. I. for Chronic Obstructive Lung Disease. Global [7] Y. Halpern and D. Sontag. Unsupervised learning of [8] K. Ito, S. Ahadieh, B. Corrigan, J. French, [9] C. H. Jackson, L. D. Sharples, S. G. Thompson, S. W. [10] P. Metzner, I. Horenko, and C. Sch  X  utte. Generator [11] D. Mould. Models for disease progression: new [12] T. M. Post, J. I. Freijer, J. DeJongh, and M. Danhof. [13] L. Rabiner. A tutorial on hidden markov models and [14] M. A. Shwe, B. Middleton, D. Heckerman, M. Henrion, [15] R. Sukkar, E. Katz, Y. Zhang, D. Raunig, and B. T. [16] J. Yang, J. J. McAuley, J. Leskovec, P. LePendu, and [17] J. Zhou, J. Liu, V. A. Narayan, and J. Ye. Modeling [18] J. Zhou, J. Liu, V. A. Narayan, and J. Ye. Modeling
