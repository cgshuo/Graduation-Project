 Predicate-argument structure analysis is a process of assigning who does what to whom , where , when , etc. for each predicate. Arguments of a predicate are assigned particular semantic roles , such as Agent , Theme , Patient , etc. Lately, predicate-argument structure analysis has been re-garded as a task of assigning semantic roles of arguments as well as word senses of a predicate (Surdeanu et al., 2008; Haji  X  c et al., 2009).
Several researchers have paid much attention to predicate-argument structure analysis, and the fol-lowing two important factors have been shown. Toutanova et al. (2008), Johansson and Nugues (2008), and Bj  X  orkelund et al. (2009) presented importance of capturing non-local dependencies of core arguments in predicate-argument structure analysis. They used argument sequences tied with a predicate sense (e.g. AGENT-buy.01/Active-PATIENT) as a feature for the re-ranker of the system where predicate sense and argument role candidates are generated by their pipelined archi-tecture. They reported that incorporating this type of features provides substantial gain of the system performance.

The other factor is inter-dependencies between a predicate sense and argument roles, which re-late to selectional preference, and motivated us to jointly identify a predicate sense and its argu-ment roles. This type of dependencies has been explored by Riedel and Meza-Ruiz (2008; 2009b; 2009a), all of which use Markov Logic Networks (MLN). The work uses the global formulae that have atoms in terms of both a predicate sense and each of its argument roles, and the system identi-fies predicate senses and argument roles simulta-neously.

Ideally, we want to capture both types of depen-dencies simultaneously. The former approaches can not explicitly include features that capture inter-dependencies between a predicate sense and its argument roles. Though these are implicitly in-corporated by re-ranking where the most plausi-ble assignment is selected from a small subset of predicate and argument candidates, which are gen-erated independently. On the other hand, it is dif-ficult to deal with core argument features in MLN. Because the number of core arguments varies with the role assignments, this type of features cannot be expressed by a single formula.

Thompson et al. (2010) proposed a gener-ative model that captures both predicate senses and its argument roles. However, the first-order markov assumption of the model eliminates abil-ity to capture non-local dependencies among ar-guments. Also, generative models are in general inferior to discriminatively trained linear or log-Figure 1: Undirected graphical model representa-tion of the structured model linear models.

In this paper we propose a structured model that overcomes limitations of the previous ap-proaches. For the model, we introduce several types of features including those that capture both non-local dependencies of core arguments, and inter-dependencies between a predicate sense and its argument roles. By doing this, both tasks are mutually influenced, and the model determines the most plausible set of assignments of a predi-cate sense and its argument roles simultaneously. We present an exact inference algorithm for the model, and a large-margin learning algorithm that can handle both local and global features. Figure 1 shows the graphical representation of our proposed model. The node p corresponds to a predicate, and the nodes a 1 ,...,a N to arguments of the predicate. Each node is assigned a particu-lar predicate sense or an argument role label. The black squares are factors which provide scores of label assignments. In the model, the nodes for ar-guments depend on the predicate sense, and by in-fluencing labels of a predicate sense and its argu-ment roles, the most plausible label assignment of the nodes is determined considering all factors.
In this work, we use linear models. Let x be words in a sentence, p be a sense of a predicate in x , and A = { a n } N 1 be a set of possible role label assignments for x . A predicate-argument structure is represented by a pair of p and A . We define the score function for predicate-argument struc-tures as s ( p, A ) = set of all the factors, F k ( x ,p, A ) corresponds to a particular factor in Figure 1, and gives a score to a predicate or argument label assignments. Since we use linear models, F k ( x ,p, A ) = w  X   X  k ( x ,p, A ) . 2.1 Factors of the Model We define four types of factors for the model. Predicate Factor F P scores a sense of p , and does not depend on any arguments. The score function is defined by F P ( x ,p, A ) = w  X   X  P ( x ,p ) . Argument Factor F A scores a label assignment of a particular argument a  X  A . The score is deter-mined independently from a predicate sense, and is given by F A ( x ,p,a ) = w  X   X  A ( x ,a ) . Predicate-Argument Pairwise Factor F
P A captures inter-dependencies between a predicate sense and one of its argument roles. The score function is defined as F
P A ( x ,p,a ) = w ference from F A is that F P A influences both the predicate sense and the argument role. By introducing this factor, the role label can be influenced by the predicate sense, and vise versa. Global Factor F G is introduced to capture plau-sibility of the whole predicate-argument structure. Like the other factors, the score function is de-fined as F G ( x ,p, A ) = w  X   X  G ( x ,p, A ) . A pos-sible feature that can be considered by this fac-tor is the mutual dependencies among core argu-ments. For instance, if a predicate-argument struc-ture has an agent (A0) followed by the predicate and a patient (A1), we encode the structure as a string A0-PRED-A1 and use it as a feature. This type of features provide plausibility of predicate-argument structures. Even if the highest scoring predicate-argument structure with the other factors misses some core arguments, the global feature demands the model to fill the missing arguments. The numbers of factors for each factor type are: F
P and F G are 1 , F A and F P A are grating the all factors, the score function becomes s ( p, A ) = w  X   X  P ( x ,p ) + w  X   X  G ( x ,p, A ) + w  X   X  2.2 Inference The crucial point of the model is how to deal with the global factor F G , because enumerating possible assignments is too costly. A number of methods have been proposed for the use of global features for linear models such as (Daum  X  e III and Marcu, 2005; Kazama and Torisawa, 2007). In this work, we use the approach proposed in (Kazama and Torisawa, 2007). Although the ap-proach is proposed for sequence labeling tasks, it can be easily extended to our structured model. That is, for each possible predicate sense p of the predicate, we provide N-best argument role as-signments using three local factors F P , F A and F
P A , and then add scores of the global factor F G , finally select the argmax from them. In this case, the argmax is selected from |P l | N candidates. 2.3 Learning the Model For learning of the model, we borrow a funda-mental idea of Kazama and Torisawa X  X  perceptron learning algorithm. However, we use a more so-phisticated online-learning algorithm based on the Passive-Aggressive Algorithm (PA) (Crammer et al., 2006).

For the sake of simplicity, we introduce some notations. We denote a predicate-argument struc-ture y =  X  p, A X  , a local feature vector as  X 
L ( x , y ) =  X  P ( x ,p ) +  X 
P A ( x ,p,a ) local and global features as  X  L + G ( x , y ) =  X  L ( x , y ) +  X  G ( x ,p, as  X  y L + G , the argmax using  X  L as  X  y L . Also, we use a loss function  X  ( y , y 0 ) , which is a cost func-tion associated with y and y 0 .
 The margin perceptron learning proposed by Kazama and Torisawa can be seen as an optimiza-tion with the following two constrains. (A) is the constraint that ensures a sufficient margin  X  ( y ,  X  y L + G ) between y and  X  y L + G . (B) is the constraint that ensures a sufficient margin  X  ( y ,  X  y L ) between y and  X  y L . The necessity of this constraint is that if we apply only (A), the al-gorithm does not guarantee a sufficient margin in terms of local features, and it leads to poor quality in the N-best assignments. The Kazama and Tori-sawa X  X  perceptron algorithm uses constant values for the cost function  X  ( y ,  X  y L + G ) and  X  ( y ,  X  y
The proposed model is trained using the follow-ing optimization problem. l L + G is the loss function for the case of using both local and global features, corresponding to the constraint (A), and l L is the loss function for the case of using only local features, correspond-ing to the constraints (B) provided that (A) is sat-isfied. 2.4 The Role-less Argument Bias Problem The fact that an argument candidate is not as-signed any role (namely it is assigned the la-bel  X  X ONE X ) is unlikely to contribute pred-icate sense disambiguation. However, it re-mains possible that  X  X ONE X  arguments is bi-ased toward a particular predicate sense by F P A (i.e. w  X   X  P A ( x ,sense i ,a k =  X  X ONE 00 ) &gt; w  X   X 
P A ( x ,sense j ,a k =  X  X ONE
In order to avoid this bias, we define a spe-cial sense label, sense any , that is used to cal-culate the score for a predicate and a roll-less argument, regardless of the predicate X  X  sense. We use the feature vector  X  P A ( x ,sense any ,a k ) if a k =  X  X ONE 00 and  X  P A ( x ,sense i ,a k ) other-wise. 3.1 Experimental Settings We use the CoNLL-2009 Shared Task dataset (Haji  X  c et al., 2009) for experiments. It is a dataset for multi-lingual syntactic and semantic dependency parsing 1 . In the SRL-only challenge of the task, participants are required to identify predicate-argument structures of only the specified predicates. Therefore the problems to be solved are predicate sense disambiguation and argument role labeling. We use Semantic Labeled F1 for evaluation.

For generating N-bests, we used the beam-search algorithm, and the number of N-bests was set to N = 64 . For learning of the joint model, the loss function  X  ( y t , y 0 ) of the Passive-Aggressive Algorithm was set to the number of incorrect as-signments of a predicate sense and its argument roles. Also, the number of iterations of the model used for testing was selected based on the perfor-mance on the development data.

Table 1 shows the features used for the struc-tured model. The global features used for F G are based on those used in (Toutanova et al., 2008; Johansson and Nugues, 2008), and the features Table 3: Predicate sense disambiguation and argu-ment role labeling results (average). used for F P A are inspired by formulae used in the MLN-based SRL systems, such as (Meza-Ruiz and Riedel, 2009b). We used the same feature templates for all languages. 3.2 Results Table 2 shows the results of the experiments, and also shows the results of the top 3 systems in the CoNLL-2009 Shared Task participants of the SRL-only system.

By incorporating F P A , we achieved perfor-mance improvement for all languages. This results suggest that it is effective to capture local inter-dependencies between a predicate sense and one of its argument roles. Comparing the results with F
P + F A and F P + F A + F G , incorporating F G also contributed performance improvements for all lan-guages, especially the substantial F1 improvement of +1 . 88 is obtained in German.

Next, we compare our system with top 3 sys-tems in the CoNLL-2009 Shared Task. By in-corporating both F P A and F G , our joint model achieved competitive results compared to the top 2 systems (Bj  X  orkelund and Zhao), and achieved the better results than the Meza-Ruiz X  X  system 2 . The systems by Bj  X  orkelund and Zhao applied feature selection algorithms in order to select the best set of feature templates for each language, requiring about 1 to 2 months to obtain the best feature set. On the other hand, our system achieved the com-petitive results with the top two systems, despite the fact that we used the same feature templates for all languages without applying any feature en-gineering procedure.

Table 3 shows the performances of predicate sense disambiguation and argument role labeling separately. In terms of sense disambiguation re-sults, incorporating F P A and F G worked well. Al-though incorporating either of F P A and F G pro-vided improvements of +0 . 13 and +0 . 18 on av-erage, adding both factors provided improvements of +0 . 50 . We compared the predicate sense dis-ambiguation results of F P + F A and ALL with the McNemar test, and the difference was statistically significant ( p&lt; 0 . 01 ). This result suggests that combination of these factors is effective for sense disambiguation.

As for argument role labeling results, incorpo-rating F P A and F G contributed positively for all languages. Especially, we obtained a substan-tial gain ( +4 . 18 ) in German. By incorporating F
P A , the system achieved the F1 improvements of +0 . 54 on average. This result shows that cap-turing inter-dependencies between a predicate and its arguments contributes to argument role label-ing. By incorporating F G , the system achieved the substantial improvement of F1 ( +1 . 91 ).

Since both tasks improved by using all factors, we can say that the proposed joint model suc-ceeded in joint learning of predicate senses and its argument roles. In this paper, we proposed a structured model that captures both non-local dependencies between ar-guments, and inter-dependencies between a pred-icate sense and its argument roles. We designed a linear model-based structured model, and de-fined four types of factors: predicate factor, ar-gument factor, predicate-argument pairwise fac-tor and global factor for the model. In the ex-periments, the proposed model achieved compet-itive results compared to the state-of-the-art sys-tems without any feature engineering.

A further research direction we are investi-gating is exploitation of unlabeled texts. Semi-supervised semantic role labeling methods have been explored by (Collobert and Weston, 2008; Deschacht and Moens, 2009; F  X  urstenau and La-pata, 2009), and they have achieved successful outcomes. However, we believe that there is still room for further improvement.

