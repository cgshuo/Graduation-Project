 A central goal of collaborative filtering (CF) is to rank items by their utilities with respect to individual users in order to make personalized recommendations. Traditionally, this is often formulated as a rating prediction problem. However, it is more desirable for CF algorithms to address the rank-ing problem directly without going through an extra rating prediction step. In this paper, we propose the probabilistic latent preference analysis (pLPA) model for ranking predic-tions by directly modeling user preferences with respect to a set of items rather than the rating scores on individual items. From a user X  X  observed ratings, we extract his pref-erences in the form of pairwise comparisons of items which are modeled by a mixture distribution based on Bradley-Terry model. An EM algorithm for fitting the correspond-ing latent class model as well as a method for predicting the optimal ranking are described. Experimental results on real world data sets demonstrated the superiority of the pro-posed method over several existing CF algorithms based on rating predictions in terms of ranking performance measure NDCG.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval X  Information Filtering Algorithms, Experimentation Collaborative Filtering, Ranking, Latent Class Model
With the explosive growth of easily accessible informa-tion on the web, technologies for helping people efficiently sift through huge amount of information is becoming indis-pensable in order to overcome the resulted information over-load problem. Recommender system is a promising technol-ogy that aims to automatically generate item recommenda-tions from a huge collection of items based on users X  past feedback. Broadly speaking, existing technologies underly-ing recommender systems fall into either of the following two categories: content-based filtering versus collaborative filtering . Content-based filtering approach analyzes the con-tent information associated with the items and users such as product descriptions, user profiles etc., in order to represent users and items using a set of features. To recommend new items to a user, content-based filters match their representa-tions to those items the user has expressed interests on. In contrast, the collaborative filtering(CF) approach does not require any content information about the items, it works by collecting ratings on the items by a large number of users and make recommendations to a user based on the prefer-ence patterns of other users. The CF approach is based on the assumption that a user is often interested in those items that have been selected by some users with similar tastes. Besides avoiding the need for collecting extensive informa-tion about items or users, the CF approach does not require domain knowledge and can be easily adopted in different recommender systems.

A very important function of most recommender systems is the generation of the Top-N item list for each user in order to make personalized recommendations, which essen-tially involves solving a ranking problem. To rank items, most collaborative filtering algorithms formulate this as a rating prediction problem in which a user X  X  potential rat-ings on the items are first predicted and then used to order the items. However, there are several drawbacks with such rating prediction based framework. Firstly, the rating pre-diction accuracy, which has been optimized in most existing methods, is not always consistent with ranking effectiveness. Suppose the true ratings on a pair of items are 3 and 4 re-spectively and the predicted ratings by method A are 2 and 5 while method B X  X  predictions are 4 and 3. In terms of rat-ing prediction accuracy as measured by the absolute devia-tion from the true ratings, the two methods are indifferent. However, the resulted ranking of the two items based on method B X  X  predictions is incorrect while method A can still ensure the correct order of the two items. So models that solely focus on improving rating prediction accuracies may be suboptimal for ranking applications. Secondly, ratings are often predicted independently for each item while rank-ings are inherently about relations among multiple items. For example, one common form of such relations is a pair-wise preference which indicates which one of a pair of items is more preferred by the user. This form of relational infor-mation is clearly more relevant to task of ranking than the rating scores. Therefore, it is more desirable for a model to explicitly take such interdependencies into account and conduct collective inference which computes the ranking as a function of the whole set of items. Finally, in many in-teractive applications such as web search, explicit user feed-backs in the form of ratings are often unavailable while it is very easy to collect abundant implicit feedbacks such as user click-throughs, from which one can often extract pair-wise preferences regarding items[12, 19]. Therefore models for preferences are much more general and can handle both implicit and explicit user feedbacks.

In this paper, we propose a ranking prediction based ap-proach to collaborative filtering named probabilistic latent preference analysis (pLPA), which directly addresses the item-ranking problem without going through the interme-diate step of rating prediction. The pLPA model is a latent class model that simultaneously captures user preferences as well as the user community structures. Unlike previous memory based methods[14], the pLPA model is based on a compact statistical model of the data, which allows learning and inference to be efficiently conducted on large scale data sets.
Generally speaking, there are two common approaches to collaborative filtering. One is the memory-based approach and the other is the model-based approach.
Memory-based approach conducts certain forms of nearest neighbor search in order to predict the rating for particular user-item pair. A most common method is the user-based model, which estimate the unknown ratings of a target user based on the ratings by a set of neighboring users that tend to rate similarly to the target user. A crucial component of the user-based model is the user-user similarity for de-termining the set of neighbors. Popular similarity measures include the Pearson Correlation Coefficient(PCC)[21, 6]and the vector similarity(VS)[2].

One difficulty in measuring the user-user similarity is that the raw ratings may contain biases caused by the different rating behaviors of different users. For example, some users may tend to give high ratings. To correct such biases, differ-ent methods have been proposed to normalize or center the data prior to measuring user similarities. [21, 2] showed that by correcting for user-specific means the prediction quality could be improved. Later, Jin et al. proposed a technique for normalizing the user ratings based on the halfway accu-mulative distribution[11].

Another difficulty in user-based models arises from the fact that the known user-item ratings data is typically highly sparse, which makes it very hard to find highly similar neigh-bors for making accurate predictions. To alleviate such spar-sity problem, different techniques have been proposed to fill in some of the unknown ratings in the matrix such as di-mensionality reduction[5] and data-smoothing methods[24, 15].

An alternative form of the neighborhood-based approach is the item-based model[22, 13]. Here the item-item simi-larity is used to select a set of neighboring items that have been rated by the target user and the ratings on the unrated items are predicted based on his ratings on the neighboring items. Since the number of items is usually much less than the number of users in most applications, item-item similari-ties are less sensitive to the data sparsity problem. Sarwar et al.[22] recommended using the adjusted cosine similarity to compute the item-item similarity and found that the item-based model could obtain higher accuracy than the user-based model, while allowing more efficient computations.
EigenRank[14] is a recently proposed memory based method which also views CF as a ranking problem rather than a regression problem(i.e., rating prediction). It adapts tradi-tional user-based model by measuring user similarity using rank correlations and using user dependent rank aggrega-tion methods to produce rankings by fusing the preferences of a user X  X  neighbors. It was empirically demonstrated that such ranking oriented approach can produce better rank-ings than traditional rating prediction methods. However, like any memory based methods, it requires nearest neigh-bor search in the entire rating database at prediction time, which is very time consuming on large data sets.
Memory based methods became popular because they are conceptually simple and intuitive. However, there are sev-eral shortcomings with these methods. First, the accuracies of memory-based methods are often suboptimal. Secondly, while memory-based methods can produce prediction, they do not involve much learning, thus little knowledge or in-sights about the users or items can be gained from the data. Thirdly, memory-based methods often require direct manip-ulation the full ratings database at prediction time, which can be very computationally expensive. Finally, without a proper model, it is hard to adapt memory-based methods to optimize different objectives associated with specific tasks or application domains.

The model-based approach to CF uses the observed user-item ratings to train a compact model that explains the given data so that ratings could be predicted via the model instead of directly searching in the rating database as the memory-based approach does. Models in this category in-clude matrix factorization[17], probabilistic latent semantic analysis[8] and Bayesian networks[18].

Model based methods can effectively address the limita-tions of memory based methods. They are often found to yield superior performance. By compressing the full data into a very compact statistical model, predictions can be made in constant time although there involves an additional model building stage that can be done off-line. Besides mak-ing predictions, a model also has well defined semantics and structures that can capture useful information such as user communities. Moreover, by designing appropriate loss func-tions and optimization procedures, models can be systemat-ically tuned to suit task-dependent objectives.

In this work, we also take the model based approach con-sidering its many attractive properties described above. In the following sections, we will first review several existing model based methods for rating prediction and then describe our probabilistic latent preference analysis model for rank-ing prediction.
The general problem setting for collaborative filtering is as follows. Suppose we are given a set of m users and a set of n items. Each observed rating record is a triple ( u, i, r denoting the rating assigned to item i by user u , where the and the rating values r ui  X  R . We assume each user can rate each item only once so all the ratings can be arranged into an m  X  n matrix R whose ui -th entry equals r ui . If a user has not rated an item, the corresponding entry in R is unknown. We let R denote the set of all ( u, i ) pairs associated with the observed ratings. Typically, |R| is much smaller than m  X  n since each user only rate very few items, this is commonly known as the sparsity problem
The goal of matrix factorization (MF) techniques is to approximate the observed rating matrix R as the product of two low-rank matrices: where U is an k  X  m matrix, V is an k  X  n matrix. The parameter k controls the number of latent features for each user and movie which is typically much smaller than m and n .

Under this model, each user u is represented by a k -dimensional feature vector u u  X  R k , the u -th column of U , while each item i is modeled by v i  X  R k , the i -th column of V . The predicted rating on item i by user u is equal to the inner product of the corresponding user and item features:
Once the matrices U and V have been learnt, each predic-tion can be made in just O ( k ) time. The parameter matrices U and V can be found by solving the following optimization problem: where k . k 2 F denotes the Frobenius 2-norm, (i.e., k U k P regularization in order to avoid over-fitting. The problem (3) can be solved using an EM like algorithm[23], where we update U and V alternately while holding the other ma-trix fixed. When U (or V ) is fixed, minimizing L over V (or U ) simply involves solving an unconstrained quadratic optimization problem which can be done very efficiently.
Compared with matrix factorization methods, statistical models are able to capture the complex dependencies among different factors such as user clusters, item clusters and rat-ings using well-defined probabilistic semantics. They are thus much easier to interpret in order to gain insights about the data and can also rely on rich existing statistical tech-niques for doing learning and inferences.

Probabilistic latent semantic analysis (pLSA)[7] is a widely used latent variable model for co-occurrence data based on mixture distributions. To apply the pLSA framework to col-laborating filtering applications, Hofmann [8] proposed to introduce a hidden state variable z for each observed rating r ui the distribution of which is decomposed as: where the sum over z runs over all latent classes and k is a parameter controlling the number of latent classes. The latent classes can capture the user communities while the mixing proportions P ( z | u ) capture the strength of a user X  X  membership in each community.

For rating values that are of numeric scale, the Gaussian distribution can be used to model the rating value for each item i in each latent class z by introducing a mean parameter  X  ki  X  R and a variance parameter  X  2 ki  X  R + , so the model defined in (4) becomes a gaussian mixture model:
To make predictions, we can compute the expected rating that would be assigned to item i by user u : which again can be computed in O ( k ) time.

The model parameters in (5) thus consist of n  X  k means  X  zi , n  X  k variances  X  2 zi and the m  X  k user dependent mix-ing proportions P ( z | u ). Using the maximum likelihood ap-proach, we can estimate these parameters by maximizing the log-likelihood of all the observed ratings: where the expansion follows equation (5) and (6).
The above loss function can be optimized using the EM algorithm which alternates between a expectation step and a maximization step. Let there be a latent variable z asso-ciated with each observed rating ( u, i )  X  X  . In the expecta-tion step, the posterior probabilities of the latent variables are computed: In the maximization step, the parameters  X  zi ,  X  2 zi and P ( z | u ) can be obtained by maximizing the expected com-plete log-likelihood E [ L c ]: E [ L c ] = When class conditional rating distributions are modeled by gaussian distributions, the above optimization problem can be readily solved by introducing an additional Lagrange multiplier to enforce that user specific mixing proportions P ( z | u ) sum to 1 and solve the resulting constrained opti-mization problem, which has the following closed form solu-tions: The expectation and maximization are alternated until a termination condition is met, for example, by checking the convergence of the log-likelihood defined in (4) is reached. In the experiments, we found that 30-50 iterations are often sufficient. Figure 1: Graphical model representation of (a) probabilistic latent semantic analysis and (b) prob-abilistic latent preference analysis
Both matrix factorization (MF) and probabilistic latent semantic analysis (pLSA) are based on models of the under-lying mechanism of how a user would assign a particular rat-ing score to an item. However as we argued in the previous sections, a more important goal of collaborative filtering is to rank items correctly. Therefore we propose a new latent class model named probabilistic latent preference analysis (pLPA) for modeling user X  X  preferences regarding the items rather than the ratings scores. In particular, we focus on modeling user preferences in the form of paired comparisons which are binary responses that indicate whether a user likes an item more than another. In contrast to pLSA, which em-ploys a Gaussian distribution for the rating on each item for each latent class, pLPA uses the Bradley-Terry model for each latent class X  X  preferences on pairs of items.
Consider the situation when there is a set of n items which are compared to each other in pairs to yield binary outcomes  X  ij which is equal to 1 if i is preferred to j and 0 otherwise. The Bradley-Terry model for the probability distribution of  X  ij with parameters  X   X  R + n : where the  X  i  X  X  are nonnegative item parameters indicating the utility of an item such that the higher  X  i is compared to  X  the more likely item i will be preferred to j .

The Bradley-Terry model for paired comparisons can be used to define a probability distribution over rankings[9, 16]. Let P n denote the set of all possible permutations on the set of integers from 1 to n . A vector  X   X  P n defines a ranking for a set of n items such that  X  i = 1 means that item i is ranked first. Given a ranking  X  , we can define a variable  X  ij with respect to  X  such that  X   X  ij = 1 if  X  i &lt;  X  j otherwise. The probability distribution over the set of all possible rankings P n is therefore: where C (  X  ) = ization constant that guarantees it is a probability measure on P n , the set of valid ranking with no ties. Inserting (14) into (15) yields where C  X  (  X  ) = C (  X  ) factor not depending on  X  . From (16), we can easily see that under a Bradley-Terry model there is a single most probable ranking  X   X  = arg max  X  P (  X  ;  X  ) that is equal to arg sort(  X  ), which orders { 1 , 2 , ..., n } by the corresponding  X   X  X  into decreasing order.
In collaborative filtering, given a user X  X  observed ratings r , we can extract his preferences on item pairs by defining Note that  X  u ij is unknown if either r ui or r uj is unknown or r ui = r uj . We let Q denote the set of ( u, i, j ) triples for which the preference is  X  u ij is observed.

Similar to pLSA, we model each observed pairwise pref-erence by a mixture distribution: The graphical model representations for both pLSA and pLPA are depicted in Figure 1. In pLPA, we designate a Bradley-Terry Model with parameter  X  z  X  R + n to model P (  X  u ij | i, j, z ): The parameters of the pLPA model thus consist of n  X  k item parameters  X  zi and m  X  k user mixing proportions P ( z | u ). Like pLSA, we can use the EM algorithm to obtain maxi-mum likelihood estimates of the parameters by maximizing the log-likelihood of the observed user pairwise preferences  X   X  X . In the expectation step, the posterior probability of the latent variable for each observed pairwise preference is computed: For the maximization step, we first derive the expected com-plete log-likelihood E [ L c ]: Optimizing E [ L c ] with respect to P ( z | u ) while enforcing the normalization constraint ing update equations for P ( z | u ):
Unfortunately, unlike in pLSA, there is no closed form solutions for the parameters  X  zi in the maximization step for pLPA. We therefore has to resort to numeric methods to obtain maximum likelihood estimates of  X  zi  X  X . To estimate the parameter vector  X  z for each latent class z , the only relevant part in (20) is: where w z ij = of times item i is preferred to item j in latent class z . Each L (  X  z ) could be maximized separately to obtain estimates of  X  z in the current maximization step.

We use a recently proposed iterative algorithm for obtain-ing maximum likelihood estimates of parameters in Bradley-Terry models known as the minorization-maximization (MM) algorithm[9], which has guaranteed convergence to the unique maximum likelihood estimator. Suppose  X  ( t ) z is the estimate at the t -th iteration. Fix  X  ( t ) z , we can define the function: Q (  X  z ) = Utilizing the strict concavity of the logarithm function, which implies for positive x and y that  X  log x  X  1  X  log y  X  ( x/y ). We can show that the function Q t (  X  z ) is a minorization of L (  X  z ) at point  X  ( t ) z such that Q t (  X  z )  X L c z (  X  ity only if  X  z =  X  ( t ) z , As a result, we can easily verify that Q (  X  z )  X  Q t (  X  ( t ) z ) implies L c z (  X  z )  X  L c z erty suggests an iterative algorithm in which we maximize Q (  X  z ) at each iteration and let  X  t +1 z be the maximizer of Q (  X  z ), which yields the following update equation: where W z i =
The above algorithm for fitting Bradley-Terry Models does not require any second-order information like the Newton algorithm does, thus each iteration can be computed very efficiently. In the experiments, we have found it normally takes 30-50 iteration to converge to the maximum likelihood estimations.
Following the pairwise decomposition approach in (15), the pLPA model can be used to obtain the following proba-bility distribution over rankings  X   X  P n : where C ( u ) is a user-dependent normalization constant. Un-like rating scores, a ranking  X  is a discrete combinatorial structure, thus we could not take expectations of  X  as in (7). Instead we need to find the ranking with the maximum a posteriori (MAP) probabilities under (26): However, unlike the case of a single Bradley-Terry model, (26) is a mixture of Bradley-Terry models each of which has its respective MAP ranking determined by  X  z . So the MAP ranking has to be obtained by performing combinato-rial search in the set P n . Taking the logarithm of P (  X  | u ) and remove all factors not dependent on  X  , the MAP rank-ing  X   X  is the ranking that maximizes the following function: where  X  u ij = log P (  X  ij = 1 | u ). Roughly speaking, we want to obtain the ranking that maximizes the probabilities of a higher ranked item being more preferred to those items ranked lower. Unfortunately, finding the optimal ranking to maximize a function of the form in (27) turn out to be a NP-complete problem, which can be shown via reduction from the cyclic-ordering problem[4].

In the following, we describe a strategy for efficiently pro-ducing a ranking for the pLPA model inspired by the rank aggregation problem in meta search. In the meta search scenario, there are multiple judges each of which provides a list of ranked results and the goal of rank aggregation is to effectively combine the individual judges X  scores to produce a good overall ranking. Most methods for rank aggregation rely on the following information: (i) the scores assigned to each item by different judges; and/or (ii) the ordinal ranks of each item in different result lists. Different methods have been proposed to compute an overall score for each item based on the original scores, ranks or some transformation of these values so that items could be ordered by the overall scores[20]. To apply rank aggregation to produce rankings from the pLPA model, we consider the Bradley-Terry model of each latent class, P (  X  ij ;  X  z ), as a judge which assigns the scores  X  z 1 , ...,  X  z 2 to the n items accordingly. Here the item parameters  X  zi are a natural measure for ranking since items with higher  X  zi values are more likely to be more preferred under the Bradley-Terry model. To produce user dependent rankings, we also consider user-dependent weights on each of the judges using the mixing proportions P ( z | u ). This leads to the following formula for item scores used for ranking: which can be computed in O ( k ) time, the same as the time complexity of making predictions using the rating oriented pLSA model.
Note that we can also first perform normalization on the raw values of the item parameters  X  zi in different Bradley-Terry models before combining them. However, in the ex-periments, this was not found to yield any improvement over just using the raw scores. This is probably because in the pLPA models all the parameters  X  zi are learnt jointly based on the data so the different scales of the  X  zi  X  X  are actually capturing certain useful properties of the data rather than being a kind of bias associated with different judges that needs to be corrected like in the meta search setting.
The pLPA and pLSA models are closely related as both are latent class models with different choice of the mixture component distributions. pLSA focuses on modeling the rat-ing scores, which makes gaussian distribution a natural use. pLPA is designed to capture relative ordering of items, for which Bradley-Terry model is more appropriate. One ad-vantage for the pLPA model over the pLSA model is that it can handle both explicit feedback in the form of ratings as well as implicit feedback such as click-through, etc. Many previous works have shown how pairwise preferences regard-ing item-pairs may be derived from implicit user feedbacks such as click-throughs[12]. The pLPA model can be natu-rally applied to analyze such pairwise preference data. In contrast, the pLSA model as well as most existing CF algo-rithms are not able to handle implicit feedback data which contains no numeric ratings.
 The training time complexity of pLPA is higher than pLSA. The E-step of pLPA involves doing the computation in 19 on every pair of rated items by the same users, which re-quires O ( knm 2 ) time while for pLSA the E-step only takes O ( knm ). The M-step of pLSA has closed form solutions while pLPA involves running numerical optimization to find the maximum likelihood parameters. At prediction time, both pLSA and pLPA can efficiently generate scores for all items in O ( mk ) time.

EigenRank[14] is another ranking oriented algorithm for collaborative filtering. Unlike pLPA, it is memory based and have high complexity at prediction time. After determining the n nearest neighbors of a target user, it first needs to compare every pair of rated items by each neighbor to esti-mate the user X  X  pairwise preferences on the set of m items and then applies a random walk model to obtain the item scores, which would requires O ( m 2 ) time complexity, much higher than the O ( mk ) complexity of pLPA since m  X  k . This makes EigenRank impractical for applications that re-quires computing recommendation list in real time.
We evaluated the proposed model on two real world movie ratings data sets: EachMovie and Netflix. The EachMovie data set consists of about 2.8 million ratings made by more than 72 thousand users on 1628 movies. The Netflix data set contains over 100 million ratings from over 480 thousand users on around 18000 titles. The EachMovie data contains 6 rating classes from 1 to 6 while the Netflix ratings fall into 5 rating classes from 1 to 5. For the experiments in this work, we only used the ratings on the 1000 and 2000 most frequently rated movies in the EachMovie and Netflix datasets respectively.
We compared the proposed pLPA algorithm with 5 exist-ing algorithms. For memory based methods we implemented the item based model using vector similarity (IVS)[22] and the user based model using Pearson Correlation Coefficient (UPCC)[2]. We also implemented the two model based methods in section 3 including matrix factorization (MF)[17] and the probabilistic latent semantic analysis using gaus-sian rating model (pLSA)[8]. We also compare pLPA with another recently proposed algorithm, EigenRank (ER)[14], which adapted the memory-based methods for ranking ori-ented collaborative filtering.
Traditionally, collaborative filtering algorithms are evalu-ated by the accuracy of their predicted ratings. One com-monly used performance metric for rating accuracy is the Mean Absolute Error (MAE):
However, as we argued previously, ranking effectiveness is a more suitable criterion for evaluating CF algorithms. Therefore, we choose the Normalized Discounted Cumula-tive Gain (NDCG) [10] as the performance measure, which is widely used for evaluating ranked results in information re-trieval when the documents are assigned graded rather than binary relevance judgements. To use it for collaborative fil-tering, we simply treat the ratings on the items assigned by users as graded relevance judgements.

The NDCG is evaluated over some number k of the top items on a ranked item list. Let Q be the set of users in-cluded in the test data and R ( u, p ) be the rating assigned by u to the item at the p -th position on the ranked list pro-duced for user u . The NDCG at the k -th rank position with respect to the set of users Q is: where Z u is a normalization factor calculated so that the NDCG of the optimal ranking has a value of 1. The value of NDCG ranges from 0 to 1 with a higher value indicates bet-ter ranking effectiveness. An attractive property of NDCG is that it is more sensitive to the ratings of the items at higher rank positions, which is consistent with requirements in real recommender systems where only few items can be recommended each time.
From both data sets, we randomly picked a set of 10600 users with the most ratings from both data sets. In or-der the better assess ranking effectiveness, we computed the variance of the observed ratings for each user and chose the 500 users with highest rating variances from both data sets to form the testing data since the NDCG on these data are more sensitive to item ordering. For the remaining 10100 users, we use 10000 as the training data and the other 100 for parameter tuning. For the 500 active users, we use 5-fold cross-validation to evaluate different algorithm X  X  per-formance, where in each run a user X  X  model is trained using 80% of his ratings and tested on the remaining 20%.
The evaluation results on both EachMovie and Netflix data sets are shown in Table 2 (a) and (b) respectively, where all the performances are calculated via 5-fold cross validation. On both data sets, we vary the amount of train-ing users from 2,000 to 10,000 to study the performances of different algorithms under different sparsity conditions. For each method, we measure the NDCG values at the 5th, 10th and 20th positions respectively. We also report the MAE for the 4 rating prediction algorithms.

Based on the results, we have made the following inter-esting observations: 1. For the 4 rating prediction algorithms, it is interesting 2. The two ranking oriented methods ER and pLPA gen-
As noted in the analysis in section 4.4, the time complexity of the prediction operation using the EigenRank algorithm is much higher than that of pLPA. In this set of experiments, we measured the amount of time that it takes to generate rankings for all the 500 test users in both EachMovie and Netflix datasets under different parameter settings. The re-sults are shown in Table 1. We have varied the number of nearest neighbors, denoted by n , in EigenRank from 100 to 400 and the number of latent classes, denoted by k , in pLPA model from 10 to 40, which are the typical ranges for n and k . We can clearly see that making predictions using pLPA is several orders of magnitude more efficient than using Eigen-Rank.
Figure 2 shows the ranking performances of pLPA on test data as a function of the number of latent classes when trained on the 5000 users datasets for EachMovie and Net-flix. The graphs show that the optimal performances are ob-Table 1: Prediction Time Comparison between EigenRank and pLPA (in seconds) tained with k equals 6 and 8 on the EachMovie and Netflix data sets respectively after which the performances on test data tend to degrade, which indicates that the model suffers from overfitting when the number of parameters increases. To address over-fitting, one possible solution is to introduce hyper-prior distributions over model parameters for regular-ization as in the latent Dirichlet allocation model[1]. We will leave this for our future work. Figure 2: Performance of pLPA as a function of the number of latent classes
In this paper, we propose the probabilistic latent prefer-ence analysis model for ranking-oriented collaborative filter-ing. The pLPA model addresses the item ranking problem directly by modeling pairwise preferences on items using a latent class model based on the Bradley-Terry Model for paired comparisons. Experimental results show that our ap-proach can effectively improve the ranking performance.
For future work, we would like to investigate several ex-tensions of the current pLPA model. Firstly, in addition to modeling pairwise preferences, we would also consider prob-ability models on listwise preferences such as the Placket-Luce models for ranked data[3]. Thirdly, we will consider introducing hyper-prior distributions over model parameters for regularization. Finally, we also plan to test the pLPA model on implicit user feedback data such as query logs from which pairwise preferences of items can be extracted. [1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [2] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [3] Z. Cao and T. yan Liu. Learning to rank: From [4] W. W. Cohen, R. E. Schapire, and Y. Singer. [5] K. Y. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [6] J. Herlocker, J. A. Konstan, and J. Riedl. An [7] T. Hofmann. Probabilistic latent semantic analysis. In [8] T. Hofmann. Latent semantic models for collaborative [9] D. R. Hunter. MM algorithms for generalized [10] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [11] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative [12] T. Joachims. Optimizing search engines using [13] G. Linden, B. Smith, and J. York. Amazon.com [14] N. N. Liu and Q. Yang. Eigenrank: a ranking-oriented [15] H. Ma, I. King, and M. R. Lyu. Effective missing data [16] J. I. Marden. Analyzing and Modeling Rank Data . [17] A. Paterek. Improving regularized singular value [18] D. M. Pennock, E. Horvitz, S. Lawrence, and C. L. [19] F. Radlinski and T. Joachims. Query chains: learning [20] M. E. Renda and U. Straccia. Web metasearch: Rank [21] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [22] B. M. Sarwar, G. Karypis, J. A. Konstan, and [23] N. Srebro and T. Jaakkola. Weighted low-rank [24] G.-R. Xue, C. Lin, Q. Yang, W. Xi, H.-J. Zeng, Y. Yu,
