 A standard approach for determining a Dirichlet smooth-ing parameter is to choose a value which maximizes a re-trieval performance metric using training data consisting of queries and relevance judgments. There are, however, sit-uations where training data does not exist or the queries and relevance judgments do not reflect typical user informa-tion needs for the application. We propose an unsupervised approach for estimating a Dirichlet smoothing parameter based on collection statistics. We show empirically that this approach can suggest a plausible Dirichlet smoothing pa-rameter value in cases where relevance judgments cannot be used.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval]: Retrieval Models General Terms: Algorithms, Measurement, Experimenta-tion Keywords: Dirichlet smoothing, unsupervised approach, parameter estimation
Dirichlet smoothing is known to be one of the most effec-tive smoothing techniques for the language modeling-based retrieval framework [5]. This smoothing technique has a free parameter, i.e. the Dirichlet smoothing parameter. A stan-dard approach for determining this parameter is to choose a value which maximizes a retrieval performance metric us-ing relevance judgments. We call this supervised approach metric-based estimation of Dirichlet smoothing parameters.
We do not, however, always have relevance judgments as given by TREC standard test collections. For example, we may use new document collections where there are no rele-vance judgments. Even when we have relevance judgments for a collection, we may be addressing different search tasks from those for which relevance judgments are made. Fur-thermore, the characteristics of actual user queries can be different from the queries associated with relevance judg-ments used for training the smoothing parameter. For ex-ample, if most queries used in relevance judgments are long, while real queries are short, then the trained value may not work well because the smoothing parameter is sensitive to query lengths as well as document lengths [2]. In such cases, we cannot use metric-based estimation.

To tackle these situations, we propose an unsupervised estimation approach. This method estimates a Dirichlet smoothing parameter from collection statistics, specifically, a variance of multinomial parameters associated with each term. Therefore, this estimation is independent of specific queries or relevance judgments. Note that if a test collection with relevance judgments is available, we cannot say that our unsupervised approach can produce a better smoothing parameter than the supervised approach. In this work, we intend to introduce an estimation technique which can be used when the supervised approach cannot be used.
There are few formal studies for determining Dirichlet smoothing parameters for retrieval models in an unsuper-vised manner. However, the average document length of a collection is sometimes used as the parameter value [1, 6, 4]. Also, in the Machine Learning literature, Minka [3] has presented maximum likelihood estimation for Dirichlet dis-tributions.
Dirichlet smoothing assumes that a document can be rep-resented by a multinomial distribution, Multi(  X  1 , X  2 ,  X  X  X  , X  where N is the size of vocabulary of collection C .Intro-mean of the posterior distribution as a smoothed document representation given by p ( i | D )=( tf i,D +  X  i ) / ( | D | where D is a document, i is an index corresponding to a unique term, and  X  0 = j  X  j . A typical choice for  X   X  X  is  X  i =  X   X  m i ,where m i = cf i / | C | . Then, the mean of the Dirichlet prior, E[  X  i ]=  X  i / j  X  j = m i , is independent of  X  . On the other hand, the variance of the Dirichlet prior, Var[  X  i ]=[  X  i (  X  0  X   X  i )] / [  X  2 0 (  X  0 +1)]= m i is closely related to the choice of  X  . Therefore, the variance can be parameterized by  X  .

Assuming that a smoothing parameter should reflect col-lection statistics well, we choose  X  which minimizes the fol-lowing squared error of variances. e (  X  )= where  X  V i is the sample variance.

Via de (  X  ) d X  = 0, a closed form solution is obtained by  X  V i can be computed by Table 1: Average query lengths of split topic sets and four Dirichlet smoothing parameters.  X  short and  X  long are parameters trained for short queries and long queries, respectively.  X  avgdl is the average doc-ument length.  X  est is estimated by our proposed method.
  X  short 0.1359 0.1097 0.2255 0.1840 0.1532 0.1367  X  long 0.1344 0.1114 0.2206 0.1853 0.1456 0.1479  X  avdl 0.1304 0.1030 0.2107 0.1769 0.1466 0.1479  X  est 0.1344 0.1109 0.2235 0.1847 0.1477 0.1477 Table 2: Retrieval results for short queries and long queries according to different Dirichlet smoothing parameters. A number is a MAP score. p
ML ( i | D ) is the maximum likelihood estimator of a language model, i.e. tf i,D / | D | . However, since computations crossing all terms and all documents are required, this is practically infeasible in case of large collections. Therefore, we use a sampling and approximation approach. First, we randomly sample T terms from a collection and consider only these terms instead of all terms in vocabulary. Then, we exploit the fact that each term occurs very sparsely in documents. That is, in many cases, tf i,D = 0. Accordingly, we consider an approximation,  X  V i  X  m 2 i . Using this approach, Equa-tion (1) can be easily computed. We call this unsupervised approach variance-based estimation of Dirichlet smoothing parameters.
We conducted experiments to evaluate our unsupervised estimation method. We used three standard TREC collec-tions: AP (topic 51-150), WSJ (topic 51-150) and GOV2 (topic 701-800). Each document is stemmed by the Krovetz stemmer and stopped by a standard stopword list. To sim-ulate situations where the characteristics of training queries are different from those of test queries, we split the topics into two subsets with the same size according to the num-ber of terms in the topic titles, i.e. short queries and long queries. Figure 1: Estimated Dirichlet smoothing parame-ters ( y -axis) according to the numbers of sample terms ( x -axis) on the AP collection.

For each collection, we considered four Dirichlet smooth-ing parameters. Two of them are values which maximize mean average precision (MAP) for short queries and long queries, respectively. To find the values, we swept [500 , with stepsize 100. Another is the average document length of each collection that is often used as an unsupervised heuris-tic for Dirichlet smoothing parameters. The last one is a value computed by our proposed method (with T = 3000). Table 1 shows these values. As you see, even though rel-evance judgments are built on the same collection, there is a substantial divergence between the Dirichlet smooth-ing parameters trained for diff erent types of queries. While the average document length does not appear close to the trained values, a parameter estimated by our unsupervised approach appears between two trained values. That is, this method seems to produce a plausible value.

We evaluated retrieval performance of these smoothing parameters for short queries and long queries. Table 2 shows the results. The average document length produces consis-tently poor performance. Also, parameters trained with a specific type of query (  X  short and  X  long ) do not generalize well to different types of queries. This shows that when mak-ing relevance judgments, accurate prediction of the charac-teristics of actual user queries is necessary so that the super-vised approach is effective. On the other hand, parameters estimated by our unsupervised method, while not the best, do produce reasonable (i.e., the second best) performance regardless of the type of query for all collections.
To see how our method depends on the number of sample terms T , we tried various T  X  X  as shown in Figure 1. This shows that the Dirichlet smoothing parameter value appears stable after T = 3000. That is, the dependence on T is not substantial when a sufficient number of terms are used.
We proposed an unsupervised estimation approach for de-termining Dirichlet smoothing parameters. This method was shown empirically to be able to produce a plausible parameter. Furthermore, this method is relatively stable and robust in that it is independent of the characteristics of queries and relevance judgments. Therefore, it can be ap-plied to cases that relevance judgments cannot be used or are not applicable.
 Acknowledgments : This work was supported in part by the
