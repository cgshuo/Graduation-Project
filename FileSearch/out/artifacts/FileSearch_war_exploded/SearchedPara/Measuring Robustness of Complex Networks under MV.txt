 Measuring robustness of complex networks is a fundamental task for analyzing the structure and function of complex networks. In this paper, we study the network robustness under the maximal vertex coverage (MVC) attack, where the attacker aims to delete as many edges of the network as possible by attacking a small fraction of nodes. First, we present two robustness metrics of complex networks based on MVC attack. We then propose an efficient randomized greedy algorithm with near-optimal performance guarantee for computing the proposed metrics. Finally, we conduct extensive experiments on 20 real datasets. The results show that P2P and co-authorship networks are extremely robust under the MVC attack while both the online social networks and the Email communication networks exhibit vulnerability under the MVC attack. In addition, the results demonstrate the efficiency and effectiveness of our proposed algorithms for computing the corresponding robustness metrics. H.2.8 [ Database management ]: Database applications X  Data mining ; G.2.2 [ Discrete mathematics ]: Graph the-ory X  Graph algorithms Algorithm, Theory, Experimentation Network robustness, FM sketch, Submodular function, MVC attack,
Networks are ubiquitous. Many practical systems in na-ture and society can be characterized by the network. Ex-amples include (online) social networks, computer networks, Internet, biological networks, transportation networks, and so on. After the seminal work by Watts and Strogatz [20] and Barab  X  asi and Albert [2], complex networks have at-tracted increasing attention in both industry and research communities in the last decade. The studies on complex network theory mainly focus on investigating the underly-ing organizing principles, the function, and the dynamics of the network.

In general, the function and performance of a network de-pend on its robustness [1, 21], i.e., the ability of a network to tolerate the nodes or links error. For example, in an airline network, the robustness reflects its operational abil-ity given certain airports are closed. In a computer network, the robustness denotes its communication capacity provided some computers in the network crash. In P2P networks, the robustness represents the ability of a network to still work well when some peers depart from the network. In online social networks, the robustness signifies the ability of a net-work to connect well when some users withdraw from the network. In co-authorship networks, the robustness stands for the ability of a network that the co-authorship does not significantly reduce when some scholars leave the research community.

When we measure a network, a fundamental problem is how to assess its robustness. Due to a large number of ap-plications, measuring robustness of a network receives grow-ing attention. Early works on robustness measurement are based on the connectivity of a network. In the literature, there are a considerable number of connectivity metrics. Ex-amples include the algebraic connectivity [9], super connec-tivity [3], conditional connectivity [13], and isoperimetric number [16]. However, the connectivity-based robustness measures only consider the topological structure of the net-work, but they ignore the concrete node or link error process. This may result in some networks with lage connectivity but they are easily attacked by intended node or link attack. To address this problem, Albert et al. [1] study the robustness of a network by considering some statistical properties of the network after the deletion of a small fraction of nodes. Many subsequent studies [5, 4, 6] follow this framework to study the robustness of the network. However, most of them focus on the analytical solution of the robustness metric on the basis of some specific random graph models. More recently, Schneider et al. [19] present a robustness metric based on the size of the giant connected component. However, they do not provide a detailed algorithm for computing their metric, and the complexity for calculating their metric is unknown. To summarize, the potential challenges for measuring the ro-bustness of complex network include: (1) how to define a reasonable and intuitive robustness metric, and (2) how to develop an efficient and effective algorithm for calculating the robustness metric.

To address these challenges, in this paper, we study the robustness of the complex network from an attacker X  X  point of view. Specifically, we measure the robustness of a net-work based on the minimal number of residual edges after removing a small fixed budget of k nodes of the network. The number of residual edges is a very natural and intuitive metric for measuring the function and performance of the network. Intuitively, after the removal of k nodes, the net-work with a large number of residual edges implies that the function and performance of the network are not extensively damaged. As a consequence, the larger number of residual edges suggest the better robustness of a network. On the other hand, from the attacker X  X  point of view, the attacker wants to maximize the number of edges that are deleted after attacking a budget of k nodes. This problem is equivalent to the maximal vertex coverage (MVC) problem on networks [12]. We refer to such type of attack as the MVC attack. There are many practical applications that can suffer from such MVC attack. For instance, in computer networks, the hacker may want to attack k workstations so as to minimize the number of surviving links in the network. In online so-cial networks, the attacker may want to target k users by providing some incentives to persuade them to leave the so-cial network so as to minimize the number of residual social ties of the network. Consequently, it is very important to measure the robustness of a network under the MVC attack.
Based on the MVC attack, we present two new robustness metrics of the network, namely k -robustness and cumulative k -robustness. More specifically, the k -robustness is defined by the minimal fraction of the residual edges after remov-ing k nodes, and the cumulative k -robustness is the average k -robustness from k =1to k . To compute the two pro-posed robustness metrics, we propose a randomized greedy algorithm with near-optimal approximation guarantee for calculating our robustness metrics efficiently. To the best of our knowledge, our work is the first work for measuring robustness of complex networks under the MVC attack. We conduct extensive experimental studies on 20 real datasets. The results show that the P2P and co-authorship networks are extremely robust under the MVC attack, whereas the on-line social networks, the Email communication networks, as well as the web graph are shown to be very vulnerable under the MVC attack. Also, the results confirm the effectiveness and efficiency of the proposed algorithms for computing the corresponding robustness measures.
Consider an undirected and unweighted network G =( V,E ), where V denotes a set of nodes and E denotes a set of undi-rected edges between the nodes. Let n = | V | and m = | E be the number of nodes and the number of edges in G ,re-spectively. The problem that we address in this paper is to measure the robustness of the network from an attacker X  X  perspective.

We consider the following setting. Assume that there is an attacker who wants to attack a network, and the attacker has a budget of k nodes to attack. If a node is attacked by the attacker, then the node and its incident edges will be removed from the network. Th e attacker aims to maximize some utility functions by attacking k nodes. From the ro-bustness point of view, our goal is to evaluate the robustness of the network under such attack.

In this paper, we introduce a utility function for the at-tacker. That is, the number of edges that are removed by attacking k nodes. In other words, the goal of the attacker is to maximize the number of edges that are removed af-ter deleting k nodes. Note that this problem is equivalent to the maximal vertex coverage (MVC) problem [12] which aims to select k nodes that cover as many edges as possible. Therefore, we refer to such an attack as the MVC attack. Formally, let S ( S  X  V )beasetofnodes,and F ( S )bethe number of edges that are removed after deleting the nodes in S . Then, the MVC attack problem can be formulated as Let F  X  ( S ) be the optimal solution for Eq. (1). Then, we define the k -robustness of a network G as follows. Definition 2.1: Given a network G =( V,E ), the k -robustness of G is  X  k =1  X  F  X  ( S ) /m .

By Definition 2.1, the k -robustness (  X  k ) denotes the frac-tion of residual edges after removing k nodes. Intuitively, after removing k nodes, the larger the fraction of residual edges is, the more robust the network is. In addition, it can be seen that  X  k falls into the interval [0, 1]. If  X  k =0,wesay a network is completely collapsed. We refer to the minimal k that causes  X  k = 0 as the collapsed point denoted by  X  Clearly,  X  k equals to the minimum vertex cover number of a network. Note that  X  k measures the point-wise robustness of a network. Naturally, we define the cumulative k -robustness as follows.
 Definition 2.2: Given a network G =( V,E ), the cumula-tive k -robustness of G is  X   X  k =( k i =1  X  i ) /k . Unlike the k -robustness, the cumulative k -robustness evalu-ates the average point-wise robustness. According to Defini-tions 2.1 and 2.2, large  X  k and  X   X  k indicate a high robustness of the network. Note that the key subroutine to compute the cumulative k -robustness (  X   X  k ) is to calculate the k -robustness (  X  k ). In the following section, we focus on how to compute  X  k efficiently.
Given a network G , the key issue to evaluate the k -robustness of G is to solve the MVC attack problem (Eq. (1)). Unfor-tunately, finding the MVC on general networks has been known to be NP-complete [7]. Hence, there is no hope to exactly compute  X  k in polynomial time. In this section, we present a randomized greedy algorithm with near-optimal performance guarantee for computing  X  k efficiently. First, we briefly describe the concept of nondecreasing submodular set function. Let A be a finite set. A set function F defined on the subsets of A is a nondecreasing submodular function if the following condition holds. For any subsets B and C such that B  X  C  X  A , and for any element j/  X  C ,wehave  X  ( B )  X   X  j ( C )  X  0, where  X  j ( B ) represents the marginal gain and it is defined as  X  j ( B )= F ( B  X  X  j } )  X  F ( B ).
It is easy to check that F ( S ) is a nondecreasing mono-tone submodular set function. Based on this, there exists a greedy algorithm for solving the MVC problem (Eq. (1)) efficiently. In particular, the greedy algorithm works in k rounds. At each round, the algorithm finds the node with the maximal marginal gain (  X  j ( S )) and adds it into the opti-mal node set S ,where S is initialized to be an empty set. By a celebrated result [17], this greedy algorithm can achieve a 1  X  1 /e approximate ratio. The time complexity of the greedy algorithm is O ( km ), because the algorithm needs to visit all the edges to find the node with the maximal marginal gain in the worst case. Below, we will propose a more efficient randomized greedy algorithm using the well-known Flajolet-Martin (FM) sketch [10].

The FM sketch is a probabilistic counting data structure and it can be utilized to estimate the cardinality of a multi-set [10]. Let N be the cardinality of a multi-set A . Then, the FM sketch only uses log N + c bits for estimating N accurately, where c is a small constant. In particular, the FM sketch is a bitmap with size l =log N + c .Thereexists a hash function h : A  X  X  1 ,  X  X  X  ,l } , mapping an element a ( a  X  A )toabit i ( i  X  X  1 ,  X  X  X  ,l } ) in the bitmap with prob-ability Pr( h ( a )= i )=1 / (2 i +1 ). At the beginning, all the bits in the bitmap are set to 0. Then, for processing an ele-ment a ( a  X  A ), we set the corresponding h ( a )-th bit of the bitmap to 1. Finally, an asymptotically unbiased estimator for the cardinality N can be obtained by 2 z / 0 . 77351, where z denotes the position of the least-significant zero bit in the bitmap. Another important property of the FM sketch is that it can be easily used to estimate the cardinality of the union of two multi-sets if these two multi-sets come from the same domain. Specifically, we construct two FM sketches with the same size for two multi-sets respectively. To es-timate the cardinality of the union of two multi-sets, we only need to do a bitwise-OR between the two FM sketches, and then estimate the cardinality based on the resulting FM sketch. To enhance the estimation accuracy, we can make use of multiple hash functions. For convenience, we only consider one hash function to describe our algorithm.
The key idea of our algorithm is described as follows. For each node u ,wecreateanFMsketchtosketchtheincident edges of u and use it to estimate F ( { u } ). Then, for any set S , F ( S ) can be calculated by where E ( { u } ) denotes the set of incident edges of node u . Note that E ( { u } ) can be represented by an FM sketch. As aresult,foranyset S , we can estimate F ( S )byperforming |
S | times bitwise-OR operation. Our algorithm is described in Algorithm 1. Firstly, Algorithm 1 creates an FM sketch for each node v i  X  V (line 2-5). In particular, for each node v , we initialize a bitmap FM[i], i.e., set all the bits of FM[i] to 0 (line 3). For all the incident edges of node v i ,wein-sert them into the bitmap FM[i] by setting the corresponding bits to 1 (line 4-5). Secondly, Algorithm 1 greedily chooses k nodes based on their approximate marginal gain (line 6-22). Specifically, we create two FM sketches CFM and OFM and use them to estimate the current optimal solution and the current marginal gain, respectively. Algorithm 1 works in k rounds. At each round, it selects the node with the maximal approximate marginal gain (line 12-19). To compute the ap-proximate marginal gain of node v i (denoted by  X   X  i ), we only need to do a bitwise-OR between the FM sketches CFM and FM[i] (line 13), which results in the FM sketch OFM. Then, we can use the standard unbiased estimator to estimate  X   X  for node v i (line 14-15). After finding the node with the maximal approximate marginal gain, we need to update the Algorithm 1 The Randomized Greedy Algorithm 2: for each node v i  X  V do 3: Initialize a BITMAP FM[i]  X  0; 4: for each incident edge e of v i do 5: Set the h ( e )-bit of FM[i] to 1; 6: S  X  X  X  ; 7: Create two FM sketches CFM  X  0, OFM  X  0; 8: F  X  0; 9: for iter = 1 to k do 10: max  X  X  X  1; 11: Idx  X  0; 13: OFM  X  (CFM) bitwise-OR (FM[i]); 14: Let z be the position of the least-significant 0 bit in 17: max  X   X   X  i ; 18: Idx  X  i ; 20: CFM  X  (CFM) bitwise-OR (FM[ Idx ]); 21: Let z be the position of the least-significant 0 bit in CFM; 23: return S and 1  X  F/m ; answer set S and the FM sketch CFM. Note that we only need to do a bitwise-OR between the FM sketches CFM and FM[ Idx ] to update the CFM (line 19-22). Here FM[ Idx ] denotes the FM sketch of the node v Idx which achieves the maximal approximate marginal gain. Finally, Algorithm 1 outputs the answer set S and the approximate  X  k (line 23). Notice that to calculate the cumulative k -robustness  X   X  do not need to invoke Algorithm 1 k times, but invoke Algo-rithm 1 with parameter k only once. Because we can record all the F (line 22) obtained in each round and compute the cumulative k -robustness. Additionally, we can use the so-called CELF framework [15] to accelerate both the original greedy algorithm and our randomized greedy algorithm.
Theoretically, by a similar analysis as in [11], Algorithm 1 can achieve a 1  X  1 /e  X  approximate ratio with high proba-bility for computing the  X  k on general networks. The reason is because the FM sketch estimates the marginal gain  X  i ( S ) of any set S within an error bound with high probability [10]. The time complexity of Algorithm 1 is O ( kn + m ). First, Algorithm 1 takes O ( m ) time to initialize the FM sketches for every node (line 2-5). Second, Algorithm 1 uses O ( kn ) time to compute the  X  k . The rationale is that the bitwise-OR (line 13) and the estimation step (line 14-15) can be done in constant time [18]. We emphasize that O ( kn + m ) is more efficient than O ( km )when k cannot be ignored. An-other advantage of Algorithm 1 is that the FM sketches for every node can be built offline. Assume that we have built the FM sketches for every node of a given network G . Then, for any given k , Algorithm 1 can compute the corresponding  X  k in O ( kn ) time. However, the original greedy algorithm still needs O ( km ) time complexity for computing  X  k .Forthe space complexity, Algorithm 1 needs to store the network G which takes O ( m + n ) space complexity. In addition, Algo-rithm 1 maintains O ( n ) FM sketches which take O ( n log m ) bits, because each FM sketch only takes O (log m )bits.The size of O ( n log m ) bits can be dominated by the O ( m + n ) graph size. So putting it all together, the space complexity of Algorithm 1 is O ( n + m ), which is the same as the original greedy algorithm.
In this section, we conduct extensive experiments on 20 real datasets to evaluate the effectiveness and efficiency of our approaches. In the following, we first describe our ex-perimental setup and then report our findings. Datasets: The network datasets used in our experiments are given in Table 1. These networks can be classified into six categories. (1) The co-authorship networks: we collect 5 physics co-authorship networks which are GrQc, Astroph, HepTh, HepPh, and CondMat from Stanford network data collections [14]. These 5 physics co-authorship networks rep-resent the co-authorship over 5 different areas in physics respectively. DBLP ( http://www.informatik.uni-trier. de/~ley/db/ ) is a computer science bibliographic dataset. We built a co-authorship graph from a subset of the DBLP data with 78,649 authors. (2) Online social networks (OSNs): we download the Delicious ( http://delicious.com/ )and Douban ( http://www.douban.com/ ) from ASU social com-puting data repository [22] and download the Epinions ( http: //www.epinions.com ) and two Slashdot datasets ( http:// slashdot.org/ ) from Stanford network data collections [14]. (3) Location-based social networks (LBSNs): the Brightkite and Gowalla are two notable LBSNs. We download these two datasets from Stanford network data collections [14]. (4) Communication networks: we download two Email commu-nication networks (EmailEnron and EmailEuAll) from Stan-ford network data collections [14]. (5) P2P networks: we em-ploy four P2P networks (Gnutella04, Gnutella05, Gnutella06, and Gnutella08) which are originally collected from Gnutella [14]. (6) Web graphs: we download a web graph dataset from Stanford network data collections [14], which is origi-nally collected from University of Notre Dame.
 Parameter settings and experimental environment: There are two parameters in Algorithm 1: the number of hash functions and the size of the bitmap. In all of our experiments, we set the number of hash functions and the size of the bitmap to be 100 and 30, respectively. We conduct our experiments on a Windows Server 2007 with 4xDual-Core Intel Xeon 2.66 GHz CPU, and 128G memory. All the algorithms are implemented by Visual C++ 6.0.
Here we report our experimental results on 20 general net-work datasets. For the directed networks, we consider them as the undirected networks by ignoring the direction of the edges. We use our k -robustness and cumulative k -robustness as two metrics. Notice that the budget of an attacker, i.e., k , is typically very small in practice. Hence, we mainly fo-cus on measuring the robustness of a network under a small budget k . Table 2 reports our results when k =0 . 1%  X  n and 0 . 2%  X  n ,where n = | V | . In the following, we concentrate on analyzing the result on k =0 . 1%  X  n and similar results can be obtained when k =0 . 2%  X  n .

As can be seen in Table 2, the P2P networks are more robust than other types of networks. For example, in the Gnutella05 dataset, after removing 0 . 1% of nodes, the k -robustness and cumulative k -robustness by the Greedy al-gorithm are 0 . 9838 and 0 . 9898, respectively. That is to say, there are only 1.62% of edges being deleted after removing 0 . 1% of nodes in the worst case. This observation indicates that removing a small fraction of peers from the P2P net-work does not significantly affect the number of links be-tween the peers. Similarly, the co-authorship networks (first 6 rows in Table 2) are shown to be very robust. For in-stance, in the DBLP network, the k -robustness and cumu-lative k -robustness by the Greedy algorithm are 0 . 9618 and 0 . 9783 after removing 0 . 1% of nodes, respectively. These re-sults suggest that a small number of  X  X mportant researchers X  leaving the research community will not significantly affect the co-authorship between the scholars. In general, the on-line social networks (rows 7-11 in Table 2) and the location based social networks (rows 12-13) show poor robustness. Taking the Gowalla dataset as an example, the k -robustness and the cumulative k -robustness by the Greedy algorithm are 0 . 8329 and 0 . 8788 when k =0 . 1%  X  n ,respectively. In other words, after removing 0 . 1% of nodes, 16 . 7% of social ties in the Gowalla network will be deleted. Also, the ro-bustness of the Email communication networks, especially the EmailEuAll network, is very poor. In the EmailEuAll network, the k -robustness and cumulative k -robustness (for k =0 . 1%  X  n ) by the Greedy algorithm are 0 . 4404 and 0 . 6408, respectively. In other words, after deleing 0 . 1% of nodes, the number of residual edges in the EmailEuAll network are only 44 . 04% of the original edges. This ob-servation suggests that the Email communication networks may be very vulnerable under the MVC attack. In addi-tion, we find that the NotreDame web graph is not very robust w.r.t. the MVC attack, as the k -robustness and cu-mulative k -robustness (for k =0 . 1%  X  n ) by the Greedy al-gorithm are 0 . 8337 and 0 . 8835, respectively. This result is consistent with the previous results on the  X  X obust yet frag-ile X  nature of the Internet [8], which means that the Inter-net is robust to random errors but it is vulnerable w.r.t. the intended node attacks. Over all the datasets, we find that the k -robustness and cumulative k -robustness by the RGreedy algorithm are very close to the k -robustness and cumulative k -robustness by the Greedy algorithm, respec-tively. More specifically, for the k -robustness and cumulative k -robustness when k =0 . 1%  X  n , the maximal absolute dif-ferences between the RGreedy algorithm and the Greedy al-gorithm are only 0.0452 (appearing in the Delicious dataset) and 0.0303 (appearing in the EmailEuAll dataset) over all the datasets, respectively. When k =0 . 2%  X  n , the maximal absolute differences for the k -robustness and cumulative k -robustness are 0.0499 and 0.0497 (both appearing in the Delicious dataset), respectively. These results imply that our RGreedy algorithm is as effective as the Greedy algo-rithm. The detailed performance analysis of the RGreedy algorithm is deferred to the full version of this paper. The work was supported by grant of the Research Grants Council of the Hong Kong SAR, China No. 419109 and 411211.
