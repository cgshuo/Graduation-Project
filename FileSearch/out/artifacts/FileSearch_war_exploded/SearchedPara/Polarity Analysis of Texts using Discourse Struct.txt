 Sentiment analysis has applications in many areas and the exploration of its potential has only just begun. We propose Pathos, a framework which performs document sentiment analysis (partly) based on a document X  X  discourse struc-ture. We hypothesize that by splitting a text into important and less important text spans, and by subsequently making use of this information by weighting the sentiment conveyed by distinct text spans in accordance with their importance, we can improve the performance of a sentiment classifier. A document X  X  discourse structure is obtained by applying Rhetorical Structure Theory on sentence level. When con-trolling for each considered method X  X  structural bias towards positive classifications, weights optimized by a genetic algo-rithm yield an improvement in sentiment classification ac-curacy and macro-level F 1 score on documents of 4.5% and 4.7%, respectively, in comparison to a baseline not taking into account discourse structure.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Linguistic processing ; I.2.7 [ Artifi-cial Intelligence ]: Natural Language Processing X  Discourse Algorithms, Experimentation, Performance Discourse Structure, Linguistics, Polarity, Sentiment, RST
Sentiment analysis is a rather young research area focus-ing on how to determine the attitude or subjectivity of a text. It has many applications, such as mining social me-dia like Facebook and Twitter for consumer opinions about products and brands. For companies, sentiment analysis on data obtained from stakeholders can provide highly valu-able information. The importance of sentiment analysis in specific areas has been indicated in [1, 5, 15, 16, 18], for fi-nancial markets, politics, organizations, brand management, and economic systems, respectively.

The goal of sentiment analysis is typically to determine the polarity of a piece of natural language text. Sentiment analysis methods are mainly rooted in, among others, natu-ral language processing, computational linguistics, and text mining. Several research directions are explored in recent literature, including word sentiment scoring (i.e., learning sentiment scores of single words), subject/aspect relevance filtering (i.e., determining the relevant subject and/or as-pect for a sentiment-carrying word), sentiment negation and amplification, and subjectivity analysis (i.e., determining whether sentences are subjective or objective) [12].
A typical approach to sentiment analysis is to use fre-quencies of positive and negative words in order to deter-mine whether a document is predominantly positive or neg-ative [26, 31]. Such an approach ignores structural aspects of a document, whereas these aspects may contain valuable information [14, 26, 30]. Yet, using knowledge obtained from structural elements in texts is a relatively unexplored direc-tion in sentiment analysis. When capturing a text X  X  dis-course structure, this knowledge could be used to improve sentiment analysis (e.g., by assigning different weights to conclusions and footnotes, as conclusions may be more im-portant for the overall sentiment of a text than footnotes).
A popular model for analyzing a text X  X  discourse struc-ture is the Rhetorical Structure Theory (RST) [19]. RST describes how to split a text into spans, each representing a meaningful part of the text. These spans can be either a nucleus or a satellite. A nucleus is considered to be the span with the highest degree of importance with respect to its related spans. Satellites support the nuclei and can there-fore be seen as less important spans. By splitting a text into important and less important parts, we can treat these parts differently from each other when determining the over-all sentiment. We hypothesize that by weighting text spans in accordance with their importance for the overall docu-ment sentiment, the detected document sentiment can be more reliable. We aim to investigate whether the use of discourse structure in sentiment analysis has a significant added value. For this purpose, we propose Pathos, a sen-timent analysis framework that can interpret a text using RST, and use this information to classify the text X  X  polarity.
The paper is structured as follows. Section 2 presents the related work. Subsequently, Section 3 elaborates on our pro-posed sentiment analysis framework, after which we present the results of our evaluation in Section 4. In Section 5, we draw conclusions and propose directions for future work.
In a recent literature survey on sentiment analysis, Pang and Lee [25] attribute the recent surge of research interest in systems that deal with opinions and sentiment to the fact that, despite today X  X  users X  hunger for and reliance upon on-line advice and recommendations, explicit information on user opinions is often hard to find, confusing, or overwhelm-ing. As sentiment analysis tools may be particularly useful in analyzing, e.g., reviews, a widely used corpus for assessing sentiment analysis approaches is a collection of 2 , 000 English movie reviews, annotated for sentiment [23].
In many existing sentiment analysis approaches, a docu-ment is represented as a bag of words, i.e., an unordered collection of the words occurring in a document. Such an approach allows for vector representations of documents, en-abling the use of machine learning techniques like Support Vector Machines for classifying documents. Features in such representations may be for instance words or parts of words. A binary representation of documents, indicating the pres-ence or absence of specific words, has proven to be an effec-tive approach, yielding an accuracy of 87 . 2% on the movie review data set [23]. Later research has focused on adding other features to the vector representations of documents. For instance, Whitelaw et al. [32] added features represent-ing semantic distinctions between words based on the Ap-praisal Theory [20], thus yielding an accuracy of 90 . 2% on the movie review data set. Paltoglou and Thelwall [22] re-port a leave-one-out accuracy of 96 . 9% on this data set, ob-tained by using tf-idf -based weights for word features rather than using a binary representation of documents.

However, even though classifiers like the ones mentioned above may perform very well in the domain that they have been trained on, their performance drops tremendously when they are used in a different domain. In this light, lexicon-based methods, operating at a deeper level of analysis by incorporating the semantic orientation of individual words, can be used as an alternative [29]. A sentiment lexicon typi-cally contains words and their associated sentiment, possibly differentiated by Part-of-Speech (POS) and/or meaning. A relatively straightforward lexicon-based sentiment analysis framework has been shown to have an accuracy up to 59 . 5% on the full movie review data set [11]. A more sophisticated lexicon-based sentiment analysis approach has been shown to have an accuracy of 59 . 6% to 76 . 4% on 1 , 900 documents from the movie review data set, depending on the sentiment lexicon used [29]. The latter lexicon-based approach is pre-sented as a well-performing method, which is robust across domains and texts. Approaches like the one proposed by Taboada et al. [29] enable a more thorough linguistic analy-sis to be incorporated in the process of analyzing sentiment in natural language text. Yet, rather than just looking at semantic orientation of individual words or groups of words, one may also consider analyzing the role these textual ele-ments play in conveying the overall sentiment by applying discourse analysis.
 Figure 1: Example of an RST-structured sentence.
According to UsingEnglish ( http://www.usingenglish. com ), discourse analysis can be defined as  X  X he area of lin-guistics that is concerned with how we build up meaning in the larger communicative rather than grammatical units; meaning in a text, paragraph, conversation, etc., rather than in a single sentence X . In our current endeavors, we apply dis-course analysis in order to determine the parts of the text that are most relevant to the overall document sentiment. Intuitively, by splitting the text into parts with different lev-els of importance, sentiment analysis can be more reliable when weighting sentiment of parts of a text in accordance with their associated impact on a document X  X  sentiment.
One of the leading discourse theories is RST [19], which can be used to split a text into spans which are rhetorically related to each other. There are two forms of relations: hy-potactic and paratactic relations. In a hypotactic relation, one span is classified as nucleus, whereas the other spans are classified as satellite. RST claims nuclei to be more signif-icant than satellites with respect to understanding and in-terpreting a text. In a paratactic relation, spans are equally significant, thus resulting in all spans to be classified as nu-clei. RST identifies the smallest text spans that can hold rhetorical relations as Elementary Discourse Units (EDUs). Together, multiple EDUs can form a new text span, which again holds a rhetorical relation to another text span, thus yielding in a hierarchical structure of the text. RST also dis-tinguishes several types of relations (e.g., elaboration, attri-bution, contrast, etc.). The authoritative paper on RST [19] defines 23 types of relations. In our framework, we differ-entiate among relation types by assigning them weights ac-cording to their importance, which we hypothesize to have a significant influence on the polarity of a document.
Figure 1 shows an example of an RST-structured sentence, where the text  X  X lthough it was great to see Brad Pitt fall off a cliff, the movie was terrible. X  is split into two segments. The first span is classified as a satellite and is related to the other span, the nucleus. The relation type is  X  X ontrast X , which indicates that the satellite segment of the sentence provides a contrast with the nucleus segment.
 A human would typically interpret the specific sentence of Figure 1 as a negative review for the movie, as he would see the second span (the nucleus) as the most important span. However, in a classical (word-counting) sentiment analysis approach, all words would contribute equally to the total sentiment. Accordingly, a computer would count  X  X reat X  as very positive, and  X  X errible X  as very negative, which summed up makes a neutral review. When we exploit the information contained in the RST structure, the nucleus can be given a higher weight than the satellite, thus shifting focus to the nucleus segment. In this case, a higher weight for the nucleus and a lower weight for the satellite would probably lead to a negative sentiment score for this sentence. By using the knowledge obtained from the RST structure, we can thus get a more reliable sentiment score.
In order to exploit a document X  X  discourse structure and in an analysis of the sentiment conveyed by the text, one needs to first identify the discourse structure. Manual anno-tation of discourse structure is typically cumbersome, time-consuming, and not easily scalable, thus rendering auto-matic discourse parsing an attractive alternative. There are several discourse parsers publicly available which can parse an RST structure from a document. One of them is Sentence-level PArsing of DiscoursE (SPADE) [28], which creates RST trees for every sentence in a document. SPADE has been trained and tested on the train and test set of the RST Discourse Treebank (RST-DT) [7], where an F 1 score of 83 . 1% is reached on identifying the right rhetorical relations and their right arguments [28].
 Another publicly available discourse parser is the HIgh-Level Discourse Analyzer [13] (HILDA), which applies sta-tistical machine-learning techniques [8] to parse discourse structures from documents using the Rhetorical Structure Theory. In contrast with SPADE X  X  sentence-level parsing, HILDA offers document-level parsing. HILDA has also been trained and tested on RST-DT, and achieved an F 1 score of 94 . 1% on identifying relations [13].
Taboada et al. present an RST-based sentiment analysis approach with the Sentiment Orientation CALculator (SO-CAL) [30]. The assumption is that certain parts of a text are more relevant than others with respect to the overall senti-ment expressed. Two methods are proposed to extract the relevant sentences: (1) extract nuclei within sentences using the SPADE discourse parser, and (2) extract sentences that are considered on-topic using a decision tree based on the ID3 algorithm [27]. Both approaches have proven to con-tribute to SO-CAL X  X  performance in classifying sentiment.
However, SO-CAL merely differentiates between core el-ements of a text (nuclei) on the one hand, and any type of less important (satellite) element on the other hand. Yet, we hypothesize that the contribution of text elements to the overall sentiment of a document depends on their respective positions within the overall discourse structure and hence their relation to other elements. For instance, a contrasting text span may play a different role in conveying the over-all sentiment than an elaboration on information in nuclei does. Therefore, we propose a more elaborate approach to utilizing RST in sentiment analysis by taking into account hypotactic relations between nuclei and satellites.
We present Pathos, a sentiment analysis framework that is able to interpret a text in terms of its discourse struc-ture, and use this information to classify the text X  X  polarity. First, we provide an overview of all components used in our framework. Then, we discuss the design of our sentiment classifier. Finally, we discuss the approaches to discourse parsing supported by this classifier.

The proposed framework consis ts of three parts, depicted in Figure 2. The central part is the sentiment classifier which classifies documents as either positive or negative. In order to do this, our framework first identifies the POS and the lemmas of all words and performs Word Sense Disambigua-tion (WSD). The positioner can employ a discourse parser (SPADE) to transform the input text into EDUs which are used to assign a weight to each individual word. The overall sentiment of a document is then computed as a weighted av-erage of individual word scores, retrieved from a sentiment lexiconwhichdifferentiatesonPOSandwordsense X  X en-tiWordNet 3.0 [3, 9] (SWN), which has proven to be very useful for this purpose [11]. Such a lexicon-based sentiment scoring approach is in accordance with the work by Taboada et al. [30].
To investigate the merits of taking into account struc-tural aspects of content in sentiment analysis, we propose a lexicon-based sentiment analysis approach, taking into ac-count adjectives, adverbs, verbs, and nouns. Scoring a doc-ument for sentiment involves aggregating word-level senti-ment scores, retrieved from a sentiment lexicon, after having initially determined each word X  X  POS and lemma. A senti-ment lexicon can contain entries for different senses for an ar-bitrary POS of an arbitrary word. In order to determine the appropriate sense of a word in a particular sentence, we use a similarity function proposed by Baazaoui Zghal et al. [2] and inspired by the Lesk algorithm [17]. We apply this algorithm because it is an unsupervised algorithm, able to compute ad-equate senses in a relatively small amount of time. Other unsupervised algorithms as SSI [21] and Lesk [17] require more computations which make the WSD a slow process.
Algorithm 1 : Word Sense Disambiguation.
In our applied WSD algorithm (described in Algorithm 1), the word sense with the highest semantic similarity to the word X  X  context is selected. Here, the similarity sim ( S of a set S i , denoting the semantic neighborhood of sense i of the word to be disambiguated, with the word X  X  context I (i.e., the set denoting the sentence lexical neighborhood of the word to be disambiguated) can be defined as: S i contains the word to be disambiguated and all the syn-onyms, hyponyms, hypernyms, and gloss words of the Word-Net synset. Furthermore, I contains all the words in the sentence without the word to be disambiguated. The set which has the highest similarity to I is then selected, and gives the most similar sense i . If there are more sets with the same similarity, the set S i which has the maximum number of elements is chosen.

When having determined each word X  X  POS, lemma, and its associated word sense, the score eval ( d )ofadocument d can be computed as the sum of the scores of the individual sentences:
Algorithm 2 : Scoring a document. where score ( s i ) is the score of the i th sentence s i score of sentence s i is computed by aggregating all sentiment scores score ( w j )ofallwords w j  X  s i , multiplied with their respective weights weight ( w j ): where the weights are computed differently for our three po-sitioners in accordance with the methods explained in Sec-tion 3.3. Here, word-level sentiment scores score ( w j )are assumedtobeintherange[  X  1 , 1] (anywhere in between negative and positive, respectively).

Using (2), the classification class ( d )ofadocument d can finally be determined as follows: where 1 denotes a positive document, and  X  1 denotes a neg-ativedocument. Theoffsetcorrectsapossiblebiasinthe sentiment scores caused by people X  X  tendency to write nega-tive reviews with rather positive words, which can lead to a small negative sentiment scor e or sometimes even a positive score for a negative document, whereas a positive document usually gets a high positive sentiment score [30]. The off-set can be calculated by taking the average sentiment scores of both positive and negative documents in the training set and subsequently computing the equidistant point of these scores.

Algorithm2isusedtoscoreadocument. Eachsentence is scored separately and its score is added to the overall document sentiment score. Sentence scores are essentially weighted averages of the sentiment scores of their individual words. The calculation for each word in a sentence (only non-stopwords) consists of five steps: (1) determining the POS, (2) retrieving the lemma of the word based on its POS-type, (3) determining which meaning of a word to use (using the WSD process described in Algorithm 1), (4) retrieving the score of the word from the sentiment lexicon, and (5) assigning a weight in accordance with the word X  X  position in the document X  X  discourse structure. Pathos supports sev-eral methods for parsing a document X  X  discourse structure and assigning corresponding weights to individual words, as further detailed in Section 3.3.
Algorithm 3 : Simple positioner.
Existing work suggests that sentiment analysis may bene-fit from a better understanding of discourse in texts [14, 26, 30]. Hence, we propose a discourse parsing module that first retrieves the discourse structure of a document and subsequently assigns discourse-based weights to sentiment-carrying words using a so-called positioner. Our framework supports three ways of accounting for discourse structure when determining a document X  X  polarity.

A simple example of a discourse structure found in most sentiment-carrying documents (e.g., movie reviews) is the distinction of  X  X ntroduction X ,  X  X rguments X , and  X  X onclusions X . Intuitively, one would think that an author typically puts his final and most important opinion towards the end of the text. To test this intuition, Pathos is able to assign weights to each word of a document, based on their respective posi-tion. The words are weighted uniformly in the range [0 , 1], where the first word is assigned a weight of 0, and the last word is assigned a weight of 1. This Simple positioner ap-proach is described in Algorithm 3.
 In order to obtain a more advanced discourse structure, Pathos uses SPADE [28] to extract sentence-level RST struc-tures from texts. Subsequently, Pathos is able to assign a weight to each word based on its position in an RST struc-ture. Table 1 shows all RST relation types handled by Pathos. These relations are a subset of the 23 standard re-lations defined in [19], encompassing only the relation types occurring in at least 10% of our considered set of reviews (see Section 4 for more details on our corpus).

Taboada et al. [30] hypothesize that adjectives found in nuclei of a document are more important for the overall sen-timent, while adjectives found in satellites potentially inter-fere with the overall sentiment  X  the latter adjectives may be tangential or even irrelevant for a document X  X  overall sen-timent. Pathos can handle the notion of discourse structure thus introduced to the sentiment mining process by means of
Algorithm 4 : SPADE positioner. the SPADE positioner algorithm (Algorithm 4), which tags the words in the top-level nuclei of each sentence as nuclei, and the words in all other top-level elements as satellites. If a sentence only consists of a single text span, all words in that span are tagged as nuclei. Each word can be given a weight based on the RST element in which it resides. Fol-lowing Taboada et al. [30], we consider two sets of weights for nuclei and satellites: (1) 1 and 0, and (2) 1 . 5and0 . 5, respectively. Yet, rather than only analyzing adjectives, we additionally handle adverbs, verbs, and nouns.

Building on the idea that some text spans can be more im-portant for the overall sentiment of a document than other text spans, we propose a third approach which further ex-plores satellites and their relation to the nuclei. We hypoth-esize that a hierarchy exists between the satellite relation types  X  some satellite relation types may contribute differ-ently to the overall sentiment than others. By employing the SPADE Extended algorithm, shown in Algorithm 5, Pathos can give specific weights to the words in satellite elements based on their RST relation type. In addition to the posi-tive weights considered by Taboada et al. [30] for their RST elements, we consider negative weights, as some text spans (e.g., contrasting text spans) may contribute negatively to the overall sentiment of a document. In order to be able to additionally intensify sentiment in certain text spans, we assume the weights to be in the range [  X  2 , 2]. These weights can be optimized by means of a Genetic Algorithm (GA).
To this end, the sum of sentiment scores in the span of each RST relation type in a document (e.g.,  X  X ucleus X  in the case of a nucleus span, or  X  X ttribution X ,  X  X laboration X , etc. in case of satellites) is firs t calculated. Subsequently, a set of potential solutions  X  chromosomes  X  can be gen-erated, where each chromosome represents a set of weights for all considered RST relation types. These chromosomes are then subject to a process of simulated biological evo-lution according to the principle of survival of the fittest.
Attribution Clauses containing reporting verbs or cog-
Background Information helping a reader to sufficiently
Elaboration Rhetorical elements containing additional
Enablement Rhetorical elements containing informa-
Explanation Justifications or reasons for situations pre-
Algorithm 5 : SPADE Extended positioner. To optimize the weights, the GA applies tournament selec-tion, one-point crossover, and two mutation functions, i.e., changing the sign for a random weight in the chromosome and switching weights in the chromosome.

The fitness of a chromosome is computed in terms of its performance in classifying document polarity, which is as-sessed as follows. For both the positive documents and the negative documents in our data set, we first compute pre-cision, recall, and the F 1 measure. Precision is the propor-tion of the positively (negatively) classified documents which have an actual classification of positive (negative). Recall is the proportion of the actual positive (negative) documents which are also classified as such. The F 1 measure is the harmonic mean of precision and recall, i.e., The performance of a chromosome on the full corpus can then be assessed by means of the macro-level F 1 measure, which is the average of the F 1 scores of the positive and negative documents.
In this section, we evaluate our different approaches to de-termine the polarity of texts. Evaluation is done by assess-ing the processing times, accuracy, precision, recall, and F score of the different positioners for the sentiment analysis framework. We have evaluated our framework on a data set provided by Pang and Lee [24], which was introduced in [23]. The set is a collection of 1 , 000 positive and 1 , 000 negative movie reviews, which have been extracted from movie review websites. From the original set, we have extracted a subset of 500 positive and 500 negative reviews, because SPADE was not able to process all reviews due to problems with syntax in over 800 documents.

We have randomly split the dataset into a training and test set, consisting of 60% and 40% of the documents, respec-tively, with both sets encompassing a proportional number of occurrences of each considered relation type. Thus, our training set contains 300 positive reviews and 300 negative reviews, whereas the test set contains 200 positive reviews and 200 negative reviews. The training set is used to train the GA for the SPADE Extended positioner, as well as to compute an offset value for each individual positioner. The test set is used to measure and compare the performances of all approaches.
 For running our experiments, we have built a Graphical User Interface (GUI), enabling us to select different options for an experiment as well as to select the directories contain-ing positive and negative documents. This GUI also displays the results of an experiment, as demonstrated in Figure 3.
To evaluate Pathos X  processing performance of a single document, we have created another GUI, which is depicted in Figure 4. The GUI offers the possibility to evaluate all positioners which have been implemented in Pathos. Addi-tionally, this GUI provides insight into the sentiment analy-sis process. For example, in Figure 4, a document processed by the SPADE Extended positioner is shown. In our GUI, words are colored depending on their sentiment score (a pos-itive word is colored green, and a negative word is colored red), and the underlying information about a word (lemma, score, weight, POS, RST relation) can be requested by se-lecting the word.
To test the performance of the considered positioners, we have evaluated them in our sentiment analysis framework, the core of which acts as a document processing pipeline (see Section 3.1). In this pipeline, we first determine the POS of words by using the OpenNLP [4] POS tagger, which has an accuracy of 98 . 7% [6]. We then determine the lemmas of words by means of a third pa rty lemmatizer, based on WordNet using the Java WordNet Library (JWNL) API. Its estimated prediction accuracy is about 98%.

In order to subsequently determine which sentiment score of a word to select from our sentiment lexicon, we addition-ally employ a WSD algorithm (see Algorithm 1). A baseline for this would be always selecting the first sense from Word-Net (which is the most common sense) for each word. We have evaluated our WSD algorithm on a test set of 100 sen-tences extracted from our corpus. The senses of the words in these sentences have been manually evaluated and anno-tated by three experts until they reached agreement. Our al-gorithm obtains an accuracy of 68% on this test set, whereas taking the first sense from Wo rdNet yields an accuracy of 44%.

For each non-stopword, the POS, lemma, and sense thus determined are used for retrieving the associated sentiment score from the SentiWordNet 3.0 [3, 9] sentiment lexicon. SentiWordNet is based on WordNet [10], which is a (se-mantic) lexical resource, organized into sets of synonyms  X  synsets  X  which can be differentiated based on their POS type. Each synset expresses a distinct concept and is linked to other synsets through different kinds of relations (e.g., synonymy, antonymy, hyponymy, or meronymy). In Senti-WordNet, each WordNet synset  X  has been assigned scores in the range [0 , 1] on objectivity Obj (  X  ), positivity Pos (  X  ), and negativity Neg (  X  ), the sum of which always equals 1. In our framework, we use SentiWordNet to compute the word sentiment score as a single number computed by subtracting Neg (  X  )from Pos (  X  ), which results in a real number in the interval [  X  1 , 1], representing sentiment scores in the range from negative to positive, respectively.

The key of our framework is in weighting the retrieved word-level sentiment scores in accordance with the place of these words in the discourse structure of a document. As a baseline, we first assess the performance of our framework on our test set without any positioner (i.e., all words in the document are considered to equally contribute to the overall sentiment). An additional baseline is the Simple positioner, which weights the sentiment of words in accordance with their respective positions in the text. Then, we introduce two additional baselines derived from existing work [30] by evaluating the SPADE positioner with different weights for nucleus and satellite, i.e., 1 and 0 (SPADE I), and 1 . 5and 0 . 5 (SPADE II), respectively. Finally, we assess the use of weights for distinct RST relation types, optimized by a GA, and compare the performance of this positioner (SPADE Ex-tended) with the other considered approaches in an attempt to assess how information conveyed by rhetorical structure can be utilized in sentiment analysis of natural language texts.
The optimal set of weights for the different RST elements in our training set is presented in Table 2. With an asso-ciated weight of 0 . 771,  X  X ucleus X  elements appear to con-tribute relatively much to the overall document sentiment in our training set. Yet, some satellite elements turn out to play an important role in conveying the overall document sentiment as well.
 Table 2: Frequencies in training set of and optimized weights for relation types handled by Pathos.

For instance,  X  X laboration X  elements receive an even higher weight of 1 . 400, thus indicating that  X  in our training set  X  writers of reviews typically tend to express their sentiment in a more apparent fashion in elaborations on their core message. To a lesser extent, this also holds for rhetorical el-ements with a purpose of increasing a reader X  X  potential abil-ity of performing actions presented in the core of a review, as  X  X nablement X  elements are associated with a weight of 0 . 956. The information presented in  X  X ttribution X ,  X  X ondition X , and especially  X  X ackground X  elements is clearly less relevant for the overall sentiment in reviews, as these elements receive weights of 0 . 451, 0 . 304, and 0 . 017, respectively.
Conversely, the sentiment conveyed by elements present-ing matters contrasting with the information presented in the core of a review is typically inverted with a weight of  X  0 . 660. The sentiment conveyed by  X  X ause X  and  X  X xplana-tion X  elements is slightly inverted as well, as these elements receive respective weights of  X  0 . 271 and  X  0 . 099. These mi-nor inversions may however be artifacts of the relatively low frequencies of these elements in our training set, as they occur in only 89 and 134 out of 600 documents, respectively.
Tables 3 and 4 present the results for all considered ap-proaches, respectively without and with offset, on our test set of 400 documents. Table 3 shows that the baseline ap-proach has an overall accuracy of 0 . 585 and a macro-level F 1 of 0 . 569. The Simple positioner exhibits the largest im-provement with respect to these measures, i.e., 3 . 9% and 4 . 8%, respectively. Two out of three considered SPADE po-sitioners show an improvement in terms of these measures as well, albeit to a lesser extent. With respect to the base-line, SPADE I exhibits no change in overall accuracy and a 1 . 2% decrease in macro-level F 1 . Conversely, applying dis-course parsing by means of the SPADE II positioner yields a2 . 1% increase in both accuracy and macro-level F 1 .Yet, the best performing SPADE positioner is the SPADE Ex-tended positioner using the weights presented in Table 2. This positioner exhibits an increase in overall accuracy and macro-level F 1 of 2 . 6% and 2 . 1%, respectively.
Yet, Table 3 clearly shows that all considered position-ers exhibit a structural bias towards positive classifications. When controlling for each positioner X  X  structural bias, the respective positioners exhibit a less biased performance, as detailed in Table 4. The baseline approach now yields an overall accuracy of 0 . 688 and a macro-level F 1 of 0 . 687. Compensation for the structural bias causes the Simple po-sitioner, the SPADE I positioner, as well as the SPADE II positioner to perform below baseline. With respect to the baseline, overall accuracy and macro-level F 1 decrease with 5 . 8% and 5 . 5% for the Simple positioner, 1 . 9% and 1 . 8% for the SPADE I positioner, and 0 . 4% and 0 . 4% for the SPADE II positioner, respectively. Conversely, the SPADE Extended positioner exhibits a 4 . 5% increase in overall ac-curacy and a 4 . 7% increase in macro-level F 1 with respect to the baseline when controlling for each positioner X  X  structural bias.

These results indicate that information contained in dis-course structure of documents can improve the classification of sentiment conveyed by these documents. Additionally, the use of offsets improves the overall performance of each con-sidered method, thus confirming the hypothesis of Taboada et al. [30] that a possible structural bias caused by neg-ative documents carrying much positive sentiment can be corrected by applying an offset in the calculation of senti-ment scores for documents. Moreover, we improve on ex-isting work due to our more elaborate, optimized weighting scheme, which assigns distinct rhetorical elements different roles in conveying a document X  X  overall sentiment. Our re-sults indicate that both nuclei and satellites play an im-portant role in conveying sentiment, whereas satellites have until now been deemed predominantly irrelevant.

However, these observed performance improvements come at a cost of increased processing time. On a standard 2,400 GHz Intel Core 2 Duo system with 2 , 048 MB physical mem-ory, the average processing time for the baseline approach is approximately 2 , 786 milliseconds per document in our test set, with a standard deviation of approximately 1 , 176 mil-liseconds. Our Simple positioner has a similar performance, as it takes on average approximately 2 , 585 milliseconds to process a single document, with a standard deviation of about 1 , 121 milliseconds. Conversely, the SPADE position-ers inspired by existing work [30], i.e., SPADE I and SPADE II, need on average about 45 , 862 milliseconds to process a document, with a standard deviation of 22 , 457 milliseconds. As the SPADE Extended positioner ignores less frequently occurring RST elements, it needs slightly less time than the SPADE I and SPADE II positioners for processing a document. On average, the SPADE Extended positioner processes a document in approximately 37 , 943 milliseconds, with a standard deviation of about 16 , 556 milliseconds.
The SPADE positioners spend a considerable amount of their processing time on a computationally intensive pro-cess of document parsing by means of the freely available SPADE discourse parser [28]. When considering only the time spent on activities other than using the SPADE dis-course parser, the SPADE I and SPADE II positioners show an average document processing time of approximately 2 , 559 milliseconds, with a standard deviation of 1 , 062 millisec-onds, whereas the SPADE Extended positioner needs on av-erage about 2 , 571 milliseconds to process a document, with a standard deviation of 1 , 066 milliseconds. These results in-dicate that a major challenge lies in finding principal ways of efficiently and effectively extracting discourse structure from natural language texts.
While most research in sentiment analysis focuses on the main components of a sentiment classifier (e.g., word sen-timent scoring, topic classification, negation, and intensi-fiers), little research has been done on analyzing the dis-course structure of texts in order to identify text spans that are more important for the overall sentiment in a document. We compare three methods for dividing texts into impor-tant and less important parts. One method is based on the position of a word in a text. The other two methods exploit discourse structure in natural language text, either by dis-tinguishing between (sentence-level) nuclei and satellites, or by identifying and exploiting (sentence-level) RST relation types. The objective of this paper is to give insights into how information can be harvested from structural aspects of content in order to improve the state-of-the art in senti-ment analysis. Our results show that our method exploit-ing sentence-level RST relation types is the best perform-ing approach, outperforming the baseline with a sentiment classification accuracy increased with 4 . 5% and a macro-level F 1 score increased with 4 . 7%, when controlling for each method X  X  structural bias towards positive classifications. Precision Recall F 1 Accuracy Macro F 1 Precision Recall F 1 Accuracy Macro F 1
A major bottleneck when accounting for discourse struc-ture is the processing time required for identifying discourse structure in natural language text. Therefore, as future work, we aim to further explore other, scalable methods of identifying the discourse structure of texts. In addition, we would like to explore the applicability of our results in other types of sentiment mining approaches, e.g., methods mak-ing use of Support Vector Machines rather than sentiment lexicons. Furthermore, our currently used discourse parser SPADE only retrieves the RST structure on a sentence level, so it would be interesting to investigate the performance of a document level RST structure. Additionally, we aim to evaluate the performance of our methods on different cor-pora, which may contain other relation types or exhibit a different relation of discourse structure to the overall senti-ment. Another interesting direction for future work would be to summarize a text and evaluate this summary using our sentiment classifier. Last, we would like to investigate how to best present a sentiment analysis system X  X  results in order to suit a typical user X  X  needs. [1] I. Arnold and E. Vrugt. Fundamental Uncertainty and [2] H. Baazaoui Zghal, M. Aufaure, and N. Ben [3] S. Baccianella, A. Esuli, and F. Sebastiani.
 [4] J. Baldridge and T. Morton. OpenNLP, 2004.
 [5] D. Baron. Competing for the Public through the News [6] E.Buyko,J.Wermter,M.Poprat,andU.Hahn.
 [7] L. Carlson, D. Marcu, and M. Okurowski. Building a [8] D. duVerle and H. Prendinger. A Novel Discourse [9] A. Esuli and F. Sebastiani. SentiWordNet: A Publicly [10] C. Fellbaum. WordNet: An Electronic Lexical [11] B. Heerschop, A. Hogenboom, and F. Frasincar. [12] B. Heerschop, P. van Iterson, A. Hogenboom, [13] H. Hernault, H. Prendinger, D. duVerle, and [14] A. Hogenboom, F. Hogenboom, U. Kaymak, [15] C. Holton. Identifying Disgruntled Employee Systems [16] B. Jansen, M. Zhang, K. Sobel, and A. Chowdury. [17] M. Lesk. Automatic Sense Disambiguation Using [18] S. Ludvigson. Consumer Confidence and Consumer [19] W. Mann and S. Thompson. Rhetorical Structure [20] J. Martin and P. White. The Language of Evaluation: [21] R. Navigli and P. Velardi. Structural Semantic [22] G. Paltoglou and M. Thelwall. A study of Information [23] B. Pang and L. Lee. A Sentimental Education: [24] B. Pang and L. Lee. Polarity dataset v2.0, 2004. [25] B. Pang and L. Lee. Opinion Mining and Sentiment [26] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up? [27] J. Quinlan. Induction of Decision Trees. Machine [28] R. Soricut and D. Marcu. Sentence Level Discourse [29] M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and [30] M. Taboada, K. Voll, and J. Brooke. Extracting [31] P. Turney. Thumbs Up or Thumbs Down?: Semantic [32] C. Whitelaw, N. Garg, and S. Argamon. Using
