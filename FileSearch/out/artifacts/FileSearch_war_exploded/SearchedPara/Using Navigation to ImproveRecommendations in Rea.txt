 Implicit feedback is a key source of information for many rec-ommendation and personalization approaches. However, us-ing it typically requires multiple episodes of interaction and roundtrips to a recommendation engine. This adds latency and neglects the opportunity of immediate personalization for a user while the user is navigating recommendations.
We propose a novel strategy to address the above problem in a principled manner. The key insight is that as we observe a user X  X  interactions, it reveals much more information about her desires. We exploit this by inferring the within-session user intent on-the-fly based on navigation interactions, since they offer valuable clues into a user X  X  current state of mind. Using navigation patterns and adapting recommendations in real-time creates an opportunity to provide more accurate recommendations. By prefetching a larger amount of con-tent, this can be carried out entirely in the client (such as a browser) without added latency. We define a new Bayesian model with an efficient inference algorithm. We demonstrate significant improvements with this novel approach on a real-world, large-scale dataset from Netflix on the problem of adapting the recommendations on a user X  X  homepage.
Recommender systems are particularly important for ser-vices with large numbers of items. They rely on the promise that through effective algorithmic use of collected data, they can help the user discover novel content by presenting per-sonalized, relevant items to the user [18 ]. Recommendation is fundamental to many places, such as news readers [5 , 8], blogs [ 10], homepages [4 ], search engines [12 ], and streaming video [ 11]. Click models are often used to model the viewing behaviors and estimate intrinsic relevance [ 12 , 5].
A key challenge in such approaches is that a user X  X  in-tention can vary significantly between sessions in ways that cannot be captured by prior knowledge. For instance, movie consumption preferences are context-dependent: whether a viewer watches alone, with friends, with a romantic love in-terest, or with children. Likewise, they are situation de-pendent (dedicated viewing vs. background entertainment during a chore), depend on the available time (short episode vs. full movie) and can even depend on mood.

Context-aware recommendation approaches try to address this problem by leveraging supplemental information such as time of day or (geo)location to provide insight about the potential per-session user intent [ 20, 3]. However, contex-tual recommendations do not fully address the problem since they only offer a prior over the likely attributes using ob-servable context prior to the start of a session. Likewise, the use of multiple viewer profiles such as those offered by Netflix, only captures a small facet of this information.
In short, it is difficult to predict a user X  X  intention when recommendations are typically generated  X  before their ses-sion has begun. We argue that the problem of understanding intent is inherent to recommendation, that it is compounded in cold-start situations, and that observable context can only partially mitigate it. We propose a way to overcome this problem by using navigation behavior as instant implicit rel-evance feedback.
 A wide variety of user interaction signals have been consid-ered to understand user intent. For example, [14 ] studies interactions on touch-enabled devices, [ 19] studies model-ing of mouse cursor movements, and [26 ] uses text selection events in search. In particular, recent work has studied eye gaze positions and mouse cursor movements, and shows that they are able to indicate user preference or attention [ 15, 16 , 13 , 23 ]. However, all work uses such data to infer a poste-riori what the user X  X  intent and interests might have been, rather than using it immediately.

In contrast to search systems, understanding the current user intent and using it effectively is even more pertinent in lean back recommendation experiences (e.g. Android TV, Playstation, Apple TV, Roku) where the primary mode of interaction is to navigate and select items. In contrast, in search, the user can rewrite queries if the results did not match their current intent, e.g. by specializing  X  X pple X  to  X  X pple tree X . The analysis of query chains [ 7] has been used extensively to improve relevance. Augmenting a page of rec-ommendations on the fly in the way described in this paper gives the recommender system designer a chance to infer the current user intent, and thereby guide them towards items that better match their current desires.

Recently, the search engine Surf Canyon offered an exten-sion that is able to alter the result page dynamically based on user X  X  interaction with the page. Based on clicks in pre-vious search queries, the system is able to alter results for future queries in the same session. [17] shows that with the dynamic adaptation users consume more results and spend a longer time searching. This strategy is natural for search engines since people can search multiple times for the same goal, and previous queries thus give valuable information.
We push this strategy to its logical conclusion  X  rather than waiting for a click to expand and clarify results, we can do this while the user is still exploring a page, i.e. we propose to dynamically modify the result page, based on a user X  X  behavior on that page.
 Using context is a popular strategy for recommendation. Factorization-based linear models, for example, are among the most effective and popular recommendation approaches [21, 24 ]. A rich line of work has been proposed in jointly modeling multiple sources of information to alleviate these problems, such as ratings and item meta-data [ 1], text fea-tures [ 2], and reviews [9 ].

On the other hand, joint models of content consumption and navigation signals are still lacking in recommender sys-tems. One challenge is that navigation signals are usually very noisy [23 ]. The data is also usually not publicly avail-able. By working with a proprietary dataset from Netflix containing a large amount of logged navigation events, we are able to show that updating a page of recommendations based on within-session navigation behavior has the capabil-ity to help users find items of interest more effectively. Such updates can be done with negligible latency by computing within a browser without a roundtrip to a backend server.
Specifically, we propose to supply additional relevant rec-ommendations by reordering rows of items, since each row typically contains a thematically coherent set of recommended content. Many online services use rows of recommendations to organize content and facilitate user navigation [6 ], though the technique can be adapted to other displays.
 Probabilistic user model. Our model jointly captures nav-Hybrid Inference. The algorithm uses both offline infer-Cold-start Experiments. We provide empirical validation We support the model design through insights we obtained from the datasets in question. They make a clear case for Figure 1: The user interface deployed on the Sony PS3 in the Netflix app in 2015. Note the distinct rows of movies in the UI. Each row is thematically or contextually coherent. advanced session modeling to improve user satisfaction and engagement. Our contributions are both conceptual in the form of instant navigation-based relevance feedback and also statistical in the form of a novel user interest model. Both are justified experimentally and can be used individually.
Netflix is an online video streaming service that provides (e.g. on its homepage) a personalized collection of videos. In this paper, we consider the problem of optimizing the positions of these videos. The specific user interface (UI) considered is illustrated in Figure 1. A page is composed of a list of rows, each of which is composed of a list of videos. Videos in a row are topically or contextually coherent to ease user navigation (e.g.  X  X V Comedies X  or  X  X opular on Netflix X ). The UI has one row in focus at a time. A user can either scroll vertically to see other rows, scroll horizontally to see more videos in a row, or select a video to play. Depending on the device, typically one or more rows are displayed above or below the current selection.

We assume that we have a base recommender system that selects about 40 rows from all possible rows types, and each of which selects 75 personalized candidate videos from our full catalog. Our goal is to optimize the ranking of the rows and also the ranking of videos within each of them. While users navigate within a page, we want to model the nav-igation signals and perform real-time adaptation online to further improve the ranking of the rows.

While we conduct experiments on a dataset of homepages generated for a specific device UI, our model is completely general and can be directly applied to homepages on many devices, including websites, tablets, smartphones, and smart TVs. This model can also be applied to other applica-tions that have similar structure to the row layout, such as Google Shopping, Google Express, YouTube, and Ama-zon.com. Also note that it is not our goal to design a novel UI layout but rather to demonstrate that implicit feedback from navigation can be incorporated in a principled fashion within a given, real-world UI.
We now design a statistical model that addresses many aspects of user interaction with an online content recom-mendation service: First and foremost we need to predict play probabilities (Section 3.1 ). This is followed by a per-session user intent model (Section 3.2 ) and finally the full graphical model (Section 3.3 ). The ranking procedure is de-scribed in Section 3.4 . We also discuss some domain-specific user behavior we found (e.g. fatigue) and how to incorporate them for improved accuracy (Section 3.5 ).

Note that the choice of the model is largely independent of the function class . That is, we could use inner product rec-ommenders, factorization machines, deep networks, decision trees or anything else. Instead, the model is tightly coupled with the UI design , since we aim to encode the way a user in-teracts with an application in quantifiable terms. Moreover, the insight of instant implicit feedback can be used in any model where the entire interface does not fit on a single dis-play (e.g. maps, search results, messages) and the model can incorporate navigation data. We use the following symbols below:
An accurate estimate of the play probability of each video is essential to optimizing pages full of video recommenda-tions. We begin by considering the problem of estimating play probabilities of videos in one row at a time. Subse-quently we generalize this model to incorporate user intent model on multiple rows. Some of our design choices are in-spired by the  X  X air and Balanced X  model of [5 ]. That is, we use the notion of submodularity to estimate the relevance of any term, given the previously presented results. Note that a function f defined on a set X is submodular if it satisfies f ( X  X  X  A } )  X  F ( X )  X  f ( X 0  X  X  A } )  X  F ( X 0 ) for X In other words, the benefit from adding A to X is less than or equal to when we add it to a subset X 0 . Whenever equal-ity holds throughout, we call f modular (i.e. linear in the parameters). In the context of movies this means that the added benefit from recommending a movie is not determined in isolation but in terms of how novel it is relative to the previous recommendations. This models typical user brows-ing behaviors to achieve diversity and personalization at the same time. To convert scores into probabilities we employ a logistic transform  X  ( x ) = 1 1+ e  X  x : Here the coordinates of q are given by where h is a suitably chosen concave function. The vectors  X  and  X   X  denote modular and submodular parameters respec-tively. Each q j is a submodular function of a set of videos that captures the diminishing returns effect of feature j . In-tuitively, we assume users become  X  X ired X  of a certain feature if they see it in many videos. Taking this into consideration, maximizing play probability leads to a page that has diver-sity. Each  X   X  j models the strength of the diminishing return in each feature j .
 Unlike [ 5], we have full access to a user X  X  viewing behavior: Since the viewport of our user interface consists of only 5 titles, users can easily glance at all of them. Hence we do not need to model views as latent variables, which can be computationally costly.

For the purpose of personalization and to share statistical strength, we adopt a hierarchical decomposition of parame-ters:  X  =  X  0 +  X  u +  X   X , 0 +  X   X ,u , where the the terms denote shared, user-specific, row-specific, and { row, user } -specific latent factors respectively. We use a similar decomposition for the submodular parameters  X   X  .
While users generally have relatively stable tastes, they often have different intents in different sessions. This un-observed aspect is hard to estimate from general behavior but is much easier once the user interacts with a service. Failing to consider variations in user intent can lead to in-accurate recommendations, even when they match a user X  X  overall taste profile. Here we describe our model that jointly models plays, navigation signals and user intents. A key dis-tinction in this work is the ability to infer and respond to a specific user X  X  preferences without any meaningful penalty in terms of latency and computational cost.

We assume that in each session a user is only interested in some subset of rows. We use I s,r  X  { 0 , 1 } to indicate a user X  X  interest in row r of session s . As before we use a logistic transform to define a probability: Here  X  w,f r  X  is linear with features f r and parameters w R , and  X  v,v  X   X  is factorization-based with row-type  X  based latent factors v  X  and v . This captures latent co-consumption patterns that are not captured by features. Again, we de-compose w = w 0 + w u + w s , where w 0 is shared, w u is user-specific, and w s is session-specific parameters, and similarly for v = v 0 + v u + v s .

We focus on horizontal scrolls as navigation signals. Fig-ure 2 shows the play probability of a row, given different numbers of horizontal scrolls on that row. The fact that the play probability is increasing as a function of scrolls within a row suggests that scrolls are a rich source of information about user intent. The fact that the biggest increase occurs between zero and one scroll means that a binary scrolling indicator might suffice to capture most of the information about whether a user is interested in a row. We thus in-troduce S s,r  X  { 0 , 1 } , which indicates whether a row r was scrolled. As before, we use a logistic transform to connect probabilities to scores: Note that P ( S s,r = 1 |I s,r = 0 , X   X  r ) = 0 by definition since users won X  X  click on something they are not interested in ( I s,r = 0). We use  X  r to denote the row type of r and  X   X  governs the likelihood of scrolling on each row type. Similarly, the play probability of the i -th video of r follows Figure 2: Play probability within a row as a function of videos scrolled to on that row. Each line represents a differ-ent row type. Remarkably the conditional play probability increases as the user delves into the list. To protect propri-etary data we rescaled the numbers [0 , 1] so that only the relative magnitudes can be compared. and likewise P ( C s,r,i = 1 |I s,r = 0 ,  X ) = 0. Here g ( t is as defined in Equation (2 ). Again, we assume users only play videos from the rows that they are interested in.
Our design choices are best illustrated in the graphical model of Figure 3. Throughout we assume that all the pa-rameters are drawn i.i.d. from normal distributions, since they are merely auxiliary latent variables used to capture the randomness in the observed user behavior. The generative process is as follows: 1. Sample v 0  X  X  (0 , X  v I ) and w 0  X  X  (0 , X  w I ). 2. For each row type  X  , 3. For each user u , Figure 3 provides the plate notation of this model. For con-ciseness we set  X  (  X  ) := v (  X  ) ,w (  X  ) . The plates inside a session are understood to be rows, and the plates inside the rows correspond to videos. In other words, we have a prin-cipled mapping of the user interface hierarchy directly into a graphical model.
Our goal is to optimize both positions of rows on a page and videos within a row such that the user finds interesting content with minimal effort. It follows from ( 1) that the play probability is maximized when g ( t 0: i ,  X ) is maximized. Thus, our goal is to find the set of videos that maximizes total gain P i g ( t 0: i ,  X ). Note that by telescoping with (2 ), Figure 3: User interaction model. Shaded circles correspond to observed variables, namely play indicators and scroll indi-cators. For clarity of illustration we omitted the associated hyperparameters from the diagram.  X  models interest and  X  models the play probabilities. we can see that this sum is a submodular function. Here we use a greedy procedure to optimize this sum: where T r is the set of candidate videos in a row. Properties of submodularity tell us that this greedy procedure guarantees (1  X  1 e )-optimality. 1
Similarly, to ease navigation we rank the rows according to the probability of play for any of the videos in the row. So the j -th row is selected by r j = argmax where R s is the set of rows preselected for session s .
Since we cannot predict user intent beforehand, we infer it on the fly as we observe navigation signals online to update our estimation of session parameters in real time. That is, we first present the page with  X  s sampled from prior, and keep updating the posterior as we observe more navigation signals for session s . From ( 7), we can see this in turn updates P ( I r = 1 | v,w ) and thus the rank of the rows. A detailed description about updating v s and w s is presented in Section 4.2 .

Users expect a video to be fixed in a position once they see it. Similar behavior can also be found in the informa-tion retrieval literature: [ 25] shows that change of search results can hinder users finding what they are looking for. Therefore, to provide a consistent experience to users, we fix a row once it is seen and only rearrange the rows that a user has yet to see. This still provides great opportunity for improvement since when a user has not played any videos in the observed portion, the user is likely to consume from the unobserved part. Experiments show that already after
Note that the gain is transformed by a logistic function, hence submodularity of click probabilities is not guaranteed. That said, maximizing the total gain is efficient in practice. observing navigation signals from only 2 rows, online adap-tation can improve the result quality considerably.
We believe that dynamic result adaptation is widely appli-cable. Firstly, the computation tends to be fairly lightweight and can be carried out on a client device. Hence it does not add any meaningful latency caused by another roundtrip to a server. Moreover, the same strategy could be applied to retrieving and presenting search results, or to games, where the environment is being generated dynamically in accor-dance to the player X  X  interest and abilities.
Beyond a generic relevance and diversity model for rec-ommendation, we also need to take into account impression fatigue and repeated plays. That is, we need to control for the fact that a user might have seen a recommendation pre-viously or watched the movie before on the service.
We observe significant impression fatigue in our dataset, similar to what is described in [ 3]. That is, the more a video is presented to a user, generally the less likely the user plays it (when ignoring repeated plays): Repeated display is not causal in reducing the play probability, as is evident from the fact that previous plays are a conditioning variable.
As can be seen in Figure 4, most videos have stronger than exponential fatigue effects. It is also worth noting that for less popular videos, e.g. the lowest two curves in Figure 4, repeated impressions initially do increase play probability. We conjecture that it is due to  X  X dvertisement X  effects: as we repeatedly present a less-known video to a user, a user becomes aware of and possibly even interested in the video. For already well-known videos, this effect is relatively mi-nor and dominated by fatigue effects. Also, most curves can be approximated by piecewise linear functions in log-probability space. We thus add the following term to (2 ): Here a t ,b t ,d t  X  R control slope, offset and secondary slope of the fatigue function. k  X  Z + determines the position of the slope change, and x t is the number of previous impressions. As before we can decompose a t (similarly for b t ,d a u,t + a 0 ,t to prevent overfitting.
 Also of interest is the high probability of repeated play. This applies to both episodic content (e.g. TV shows), for which many users continue watching subsequent episodes af-ter watching some of them and , quite surprisingly, to stan-dalone videos (e.g. movies). See Figure 5 for details.
Nonetheless, the curves clearly form two groups, one for episodic videos (with a higher repeated-play probability) and one for standalone ones. The curves within each group are very similar. This suggests that binary indicators of pre-vious play and episodic videos are sufficient (see Section 5.4 ).
Given this rather complex statistical model, we need to de-sign efficient inference algorithms for both offline and online adaptation of the model. In particular, the online updates need to be very lightweight to run on consumer devices.
We choose the negative log-posterior of the data such that we can obtain a maximum-a-posteriori (MAP) estimate. Here the first term maximizes the likelihood while the second term is a regularizer that penalizes complex models.
P Unfortunately the summation over inspection states is in-side the logarithm, rendering the problem non-convex. For tractability, we design an efficient EM procedure using vari-ational inference.
The key to offline training is that if I s,r is known then the full model decomposes nicely. Thus, we propose a stochastic EM algorithm to efficiently solve this inference problem. In the E-step we estimate I s,r with all other parameters fixed, and in the M-step we optimize all parameters with I s,r fixed. E-step Here we estimate the posterior probability of I with M-step Next we optimize  X ,  X , and  X  with I s,r weighted We can view the updates with regard to  X  as videos being weighted by Q ( I s,r ) j . This matches intuition: a play/non-play decision made on videos from a row that a user is in-terested in should be more important than a decision made on other rows. For example, when a user is looking for an exciting movie, we should not penalize a video from  X  X ids X  Movies X  too much when it is not played. Experiments show that by modeling interests, we are able to obtain a more accurate estimates of play probabilities.
We now proceed to describe the updates in a per-session context. Note that online does not refer to online learning in the traditional sense but rather to an online response and parameter update due to user behavior in the current Figure 4: Novel-play probability as a function of non-play impressions for 10 videos. With exception of some rather unpopular videos the log-popularity decreases piecewise lin-early. We renormalize them to provide relative magnitudes (the absolute numbers are proprietary).
 Figure 5: Play probability as function of number of previ-ous plays. Episodic refers to content with multiple episodes, Standalone defaults to a single video (or movie). As be-fore, probabilities are renormalized to protect proprietary information. session. When a user scrolls or skips to the next row without scrolling we update the MAP estimate of  X  s accordingly:
P ( X  s | rest)  X  Y Here R seen is the set of displayed rows. We adopt a similar EM strategy. The E-step remains unchanged, while in the M-step we make an update with gradient  X   X  s J ( Q,  X  ,  X  , X  ) =  X   X  s X Once we update our estimation on  X  s and in turn I s,r , we can then adapt the page. This is computationally inexpen-sive because we only need to reorder a small (typically &lt; 40) subset of rows. This is easily feasible by most modern browsers and devices. Most of the terms in ( 12) and (13 ) can be precomputed, and computing (and updating) P ( I s,r only involves a logarithm and an inner product of sparse feature vectors.
We use a real-world dataset from Netflix and show that: 1. Online adaptation improves recommendations at a row 2. Our model is able to address cold-start. Even for users 3. Modeling impression fatigue and repeated play behav-Comparing the performance with other production systems or other sophisticated models is out of the scope of this paper, since after all, our goal is to investigate the possibility of real-time online updates and to explore new methods to jointly model plays and navigation signals. The dataset consists of homepage sessions, collected by Netflix for a particular type of playback device from 57,386 distinct profiles pre-computed for members from a single country. For each video on the page, the dataset also con-tains an indicator about whether the video was displayed to the user, and whether it was played. The dataset consisted of sessions collected over a three-month period in 2015. Ses-sions from April and May are used for training, while those from June are split into validation (for hyperparameter tun-ing) and test sets (to report performance).

We are interested in cases where users are navigating the page to discover new content to watch instead of continuing to watch previously watched shows. We thus filter out ses-sions where users choose from Continue Watching , Recently Watched or My List rows. This leaves approximately 294k training and 59k testing sessions.

Each homepage in the dataset consists of 40 rows that were chosen according to a production personalized recom-mender system that selects and orders the rows in a person-alized fashion for each profile. Thus, for this dataset, the method in this paper already has the space of rows filtered down to a set that are deemed to be relevant. Each row con-sists of up to 75 videos placed horizontally in the row. The videos are placed in what appears to be a two-dimensional grid, but, in fact, a page is a series of rows on which the user has the ability to scroll individually in a horizontal fashion. When a row comes into the viewport, five videos appear horizontally. In light of this, we only consider a row to be scrolled on when a user has viewed more than five videos horizontally in that row.

While a comparison using publicly available datasets would be ideal, there are no such datasets available that form a page of recommendations that are comparable to the one described above. Instead, the purpose of this paper is to present a novel method and show the improvement in rele-vance metrics with the online adaptation strategy.
We examine the contribution of the online adaptation F igure 6: Gains in MRR (left) and Precision@5 (right) as a function of the number of rows visited. We see a clear improvement even just after 2 rows. The Factorization Ma-chine baseline is provided for reference.
 F igure 7: Gain in MRR (left) and Precision@5 (right) com-pared to offline-only model. For users with few training ses-sions, the benefit gained from online update is the greatest. strategy. We first generate pages with the model trained using only previous sessions. During testing, we simulate the online adaptation procedure by looking at one row at a time, and update the page according to navigation signals (scroll or no scroll). To control the causal effects, we must use navigation signals from rows in the order from the orig-inal page instead of the reordered page. We thus evaluate using the following procedure: only use navigation signals up to a certain row (the 10th row in experiments) on a page, and only reorder the rows below that row. We then compare the adapted pages with the pages without adaptation.
We evaluate performance by two standard metrics: mean reciprocal rank (MRR) and precision at 5 (P@5). MRR measures how early we place the relevant (played) rows on a page. P@5 measures the fraction of relevant rows in the next 5 rows. Figure 6 shows MRR and P@5 vs. number of rows observed. We see on both metrics that online adap-tation provides a significant improvement over non-adapted pages. Not surprisingly, as we observe more rows, online adaptation provides greater improvements. We already see improvements with only 2 rows. This means users only need to scroll 2 rows to have a benefit from this strategy, which is often the case when users are exploring for new videos.
Without a known row ordering baseline, we compared against ordering the rows on the page via Factorization Ma-chines (FMs) using libFM [22 ]. The FM was trained and tested on the same data as our model. For features we used: user ID and row type identifier; we sampled played rows as positives and unplayed rows within one row of the played rows as negatives. The best FM model was trained with MCMC optimization and latent dimension 15. We show rel-ative MRR and P@5 metrics in Figure 6.
The coldstart problem is the bane of many recommender systems. It occurs whenever a new user or a new video comes to the service. In such cases, we have relatively little data to infer the preferences of the user or the properties of the video: For new users we often only have basic context information such as device type and location. This makes recommending an initial set of videos exceedingly difficult, yet it is this first impression that matters a lot when it comes to convincing a new user to continue using a service.
Our online adaptation strategy helps alleviate the user coldstart problem. Figure 7 shows MRR and P@5 scores as a function of the number of training sessions available. We see that users with fewer training sessions (coldstart users) benefit most from online adaption. Quite remarkably, it works well even for users with no previous sessions. This opens a new avenue to address the coldstart problem: even when there is no previous data and using no context infor-mation, with online modeling navigation signals, we are able to personalize recommendations within the first page. We are effectively observing the user in a live environment and adjusting recommendations to reduce the amount of naviga-tion needed to find something interesting to watch.
We discussed the importance of impression fatigue and repeated viewing in Section 3.5 . To illustrate the effect we examine the horizontal MRR and P@5 within a row to eval-uate the play probability estimates. Relative improvements compared to the model without them are shown in Figure 8. We can see that each provides clear improvement and using a combination is best. This gain is achieved by only using a small number of model parameters.
We proposed inferring user intent through in-session navi-gation information and then updating pages of recommenda-tions based on that intent. To accomplish this, we defined a probabilistic model capable of incorporating current session navigational information as well as logged navigation and consumption data. The model infers interest in candidate rows of recommended items based on homepage navigation to a certain point on the page, and can populate the remain-ing rows on the page with more relevant content that reflects the current likely intent as predicted by the model.
This is the first work of its kind that performs online up-dating of recommendations based on user navigation within a single page. Thus, it is the intention of this paper to demonstrate feasibility of such a method, which we do on real-world dataset from Netflix. The model not only im-proves the relevancy of future recommendations on the page, but also helps to alleviate the user coldstart problem by us-ing navigation information, yielding improved recommenda-tions even within the first page. For users without any offline training sessions, i.e. with online navigation signal alone, we are able to provide personalized recommendations. We ar-gue that this approach addresses the coldstart problem in a more effective manner than traditional approaches, though could be combined with them as well.

This work opens a new avenue for future work on online page adaptation. While we use binary horizontal scrolls in experiments, the online adaptation strategy is completely general. We can easily change the emission function of nav-igation signals to fit navigation signals in many domains, such as mouse hover, section expansion, or text selection. Figure 8: Gain in MRR (Top) and Precision@5 (Bottom) ob-tained by modeling impression fatigue and repeated plays. Performance compared to the model without modeling im-pression fatigue and repeated plays.
 Extending it to model multiple sources of signals is also straightforward. Also, while we focus on reranking rows, a similar model could also be applied to reranking items within each row. It can likewise be adapted to model other UI designs. [1] D. Agarwal and B.-C. Chen. Regression-based latent [2] D. Agarwal and B.-C. Chen. FLDA: matrix [3] D. Agarwal, B.-C. Chen and P. Elango.
 [4] D. Agarwal, B.-C. Chen, P. Elango, N. Motgi, S.-T. [5] A. Ahmed, C.-H. Teo, S.V.N. Vishwanathan, and A. [6] C. Alvino and J. Basilico. Netflix tech blog: Learning [7] P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis, [8] A. Das, M. Datar, A. Garg, and S. Rajaram. Google [9] Q. Diao, M. Qiu, C.-Y. Wu, A.J. Smola, J. Jiang, and [10] K. El-Arini, G. Veda, D. Shahaf, and C. Guestrin. [11] C.A. Gomez-Uribe and N. Hunt. The Netflix [12] F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor, [13] Q. Guo and E. Agichtein. Beyond dwell time: [14] Qi Guo, H. Jin, D. Lagun, S. Yuan, and E. Agichtein. [15] J. Huang, R. White, and G. Buscher. User see, user [16] J. Huang, R. White, and S. Dumais. No clicks, no [17] J.Y. Kim, M. Cramer, J. Teevan, and D. Lagun. [18] J.A. Konstan and J. Riedl. Recommender systems: [19] D. Lagun, M. Ageev, Q. Guo, and E. Agichtein. [20] H. Lieberman and T. Selker. Out of context: [21] S. Rendle. Factorization machines. In ICDM , pages [22] S. Rendle. Factorization Machines with libFM. Trans. [23] K. Rodden, X. Fu, A. Aula, and I. Spiro. Eye-mouse [24] R. Salakhutdinov and A. Mnih. Bayesian probabilistic [25] J. Teevan, E. Adar, R. Jones, and M.A. Potts. [26] R.W. White and G. Buscher. Text selections as
