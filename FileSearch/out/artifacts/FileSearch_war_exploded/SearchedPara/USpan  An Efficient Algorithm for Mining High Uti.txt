 Sequential pattern mining plays an important role in many applications, such as bioinformatics and consumer behavior analysis. However, the classic frequency-based framework often leads to many patterns being identified, most of which are not informative enough for business decision-making. In frequent pattern mining, a recent effort has been to incorpo-rate utility into the pattern selection framework, so that high utility (frequent or infrequent) patterns are mined which ad-dress typical business concerns such as dollar value associ-ated with each pattern. In this paper, we incorporate utility into sequential pattern mining, and a generic framework for high utility sequence mining is defined. An efficient algo-rithm, USpan, is presented to mine for high utility sequential patterns. In USpan, we introduce the lexicographic quan-titative sequence tree to extract the complete set of high utility sequences and design concatenation mechanisms for calculating the utility of a node and its children with two ef-fective pruning strategies. Substantial experiments on both synthetic and real datasets show that USpan efficiently iden-tifies high utility sequences from large scale data with very low minimum utility.
 H.2.8 [ Database Applications ]: Data mining Algorithms High utility sequential pattern mining, Sequential pattern mining  X  Author for correspondence.

Sequential pattern mining has emerged as an important topic in data mining. It has proven to be very essential for handling order-based critical business problems, such as behavior analysis, gene analysis in bioinformatics and we-blog mining. For example, sequence analysis is widely em-ployed in DNA and protein to discover interesting struc-tures and functions of molecular or DNA sequences. The selection of interesting sequences is generally based on the frequency/support framework: sequences of high frequency are treated as significant. Under this framework, the down-ward closure property (also known as Apriori property )[1] plays a fundamental role for varieties of algorithms designed to search for frequent sequential patterns [10, 14, 5].
In practice, many patterns are identified by frequent se-quential pattern mining algorithms. Most of them may not be informative to business decision-making, since they do not show the business value and impact. In some cases, such as fraud detection, some truly interesting sequences may be filtered because of their low frequencies. For exam-ple, in retail business, selling a car generally leads to much higher profit than selling a bottle of milk, while the fre-quency of cars sold is much lower than that of milk. In on-line banking fraud detection, the transfer of a large amount of money to an unauthorized overseas account may appear once in over one million transactions, yet it has a substantial business impact. Such problems cannot be tackled by the frequency/support framework.

This brings about an interesting question: how to mine sequential patterns of business interest? In the related area, utility is introduced into frequent pattern mining to mine for patterns of high utility by considering the quality (such as profit) of itemsets. This has led to high utility pattern min-ing [13], which selects interesting patterns based on mini-mum utility rather than minimum support. Let us use a toy example to illustrate. Table 1 shows the items and their respective weights or profit (quality) appearing in an on-line retail store. Table 2 collects several shopping sequences with quantities; each transaction in the sequence consists of one to multiple items, and each item is associated with a quantity showing how many of this item were purchased. For instance, the first sequence ( e, 5)[( c, 2)( f, 1)]( b, 2) shows three itemsets ( e, 5), [( c, 2) ( f, 1)] and ( b, 2), and the quan-tity purchased of item, e.g. the quantity of e is 5. Following the high utility pattern mining concept, a possible calcula-tion of utility of an itemset is to consider its total profit. Accordingly, the utility of a single item can be defined as its purchased quantity times its profit. The utility of an itemset is the sum of the utilities of all its items. Since each item in a sequence may have multiple utility values, the utility of a sequence may have multiple values. For in-stance, the utility of ea in sequence 2 is { (6  X  1+1  X  2) , (6  X  1+2  X  2) } = { 8 , 10 } . The utility of ea in the database is utility in each sequence and add them together to represent the maximum utility of the sequence in a given sequence database. The maximum utility of ea is 10+16+15 = 41. A sequence is of high utility only if its utility is no less than a user-specified minimum utility . Following the high util-ity pattern mining approach, our goal is to mine for highly profitable sequential purchasing; the identified shopping pat-terns are more informative for retailers in determining their marketing strategy.

High utility sequential pattern mining is substantially dif-ferent and much more challenging than high utility itemset mining. If the order between itemsets is considered, e.g. ( e, 5), [( c, 2)( f, 1)] and ( b, 2) in record sid = 1 occurring sequentially, it becomes the problem of mining high utility sequential patterns. This is substantially different and much more challenging than mining frequent sequences and high utility itemsets. First, as with high utility itemset mining, the downward closure property does not hold in utility-based sequence mining. This means that most of the existing al-gorithms cannot be directly transferred, e.g. from frequent sequential pattern mining to high utility sequential pattern mining. Second, compared to high utility itemset mining, utility-based sequence analysis faces the critical combina-tional explosion and computational complexity caused by sequencing between sequential elements (itemsets).
So far, only very preliminary work has been proposed to mine for high utility sequential patterns [2, 4, 11]. It is in a very early stage since there is no systematic problem state-ment available. The proposed algorithms are rather specific and focus on simple situations, and still need substantial effective scanning and pruning strategies to improve perfor-mance. Basically, we can see that this is a new and promising area expecting much substantial exploration from problem definition to algorithm development and applications.
In this paper, we formalize the problem of high utility sequential pattern mining, and propose a generic framework and an efficient algorithm, USpan, to identify high utility sequences. Substantial experiments on both synthetic and real datasets show that the proposed framework and the USpan algorithm can efficiently identify high utility sequences from large scale data with very low minimum utility.

The paper is organized as follows. Section 2 reviews the re-lated work. Section 3 proposes a sequence utility framework and defines the problem of mining high utility sequential patterns. Section 4 details the USpan algorithm. Exper-imental results and evaluation are presented in Section 5. Section 6 concludes the work.
Utility itemset mining, also generally called utility pat-tern mining, was first introduced in [13]. Every item in the itemsets is associated with an additional value, called inter-nal utility which is the quantity (i.e. count) of the item. An external utility is attached to an item, showing its quality (e.g. price). With such a utility-based database, high utility itemsets (patterns) are mined, including those satisfying the minimum utility. Mining high utility itemsets is much more challenging than discovering frequent itemsets, because the fundamental downward closure property in frequent itemset mining does not hold in utility itemsets.

Several algorithms are available. UMining was proposed in 2004 for mining high utility patterns, but it cannot ex-tract the complete set of them. A transaction-weighted downward closure property was introduced in [8], in which a two-phase algorithm was proposed with a pruning strat-egy, which makes it faster and more efficient than UMining. IHUP [3] maintains the high utility patterns in an incre-mental environment; since it avoids multiple scans of the database, its efficiency is far better than [8]. UP-Growth [12] also uses a tree structure, UP-Tree, to mine high utility patterns. Compared to IHUP, UP-Growth is more efficient, since it further reduces the number of promising patterns which cannot be pruned in IHUP.

The above algorithms can only handle utility itemsets, and do not involve the ordering relationships between items. The addition of ordering information in sequences makes it fundamentally different and much more challenging than mining utility itemsets.
Frequent sequential pattern mining is a very popular topic [1, 9], with quite a few algorithms, such as SPADE [14], Pre-fixspan [10] and SPAM [5], proposed on the support/frequency framework. Algorithms for mining frequent sequences often result in many patterns being mined; most of them may not make sense to business, and those with frequencies lower than the given minimum support are filtered. This limits the actionability [6] of discovered frequent patterns.
The integration of utility into sequential pattern mining aims to solve the above problem and has only taken place very recently. In total, we found only three papers in the literature. UMSP [11] was designed for mining high util-ity mobile sequential patterns. Each itemset in a sequence is associated with a location identifier. With this feature, the utility of a mobile sequential pattern is also a single value. UMSP searches for patterns within a structure called MTS-Tree, which is efficient. However, due to the specific constraint on the sequences, this algorithm can only handle specific sequences with simple structures (single item in each sequence element, and a single utility per item).
In [2], an algorithm is specifically designed for utility web log sequences. The utility of a pattern can have multiple val-ues, and the authors choose the utility with maximal values to represent a pattern X  X  utility with two tree structures, i.e. UWAS-tree and IUWAS-tree. However, sequence elements with multiple items such as [( c, 2)( b, 1)] cannot be supported, and the scenarios considered are rather simple, which limit the algorithm X  X  applicability for complex sequences.
UI and US [4] extends traditional sequential pattern min-ing. A pattern utility is calculated in two ways. The utili-ties of sequences having only distinct occurrences are added together, while the highest occurrences are selected from se-quences with multiple occurrences and used to calculate the utilities. However, the problem defintion in [4] is rather spe-cific. No generic framework is proposed which has a clear process to transfer from sequential pattern mining to high utility sequence analysis.

It is obvious that mining high utility sequences is a very open and challenging area. Substantial research topics rang-ing from problem definition to algorithm development and applications are worthwhile to explore.
Let I = { i 1 ,i 2 , ..., i n } be a set of distinct items .Eachitem i  X  X  (1 k n ) is associated with a quality (or external utility ), denoted as p ( i k ), which may be the unit profit or price of i k .A quantitative item ,or q-item , is an ordered pair ( i, q ), where i  X  X  represents an item and q is a positive num-ber representing the quantity or internal utility of i ,e.g.the purchased number of i .A quantitative itemset ,or q-itemset , consists of more than one q-item, which is denoted and de-fined as l =[( i j 1 ,q 1 )( i j 2 ,q 2 ) ... ( i j n ,q n q-item for 1 k n . For brevity, the brackets are omit-ted if a q-itemset has only one q-item. Since the items in a set can be listed in any order, without loss of generality, we assume that q-items are listed in alphabetical order. A quantitative sequence ,or q-sequence , is an ordered list of q-itemsets, which is denoted and defined as s = l 1 l 2 ... l where l k (1 k m ) is a q-itemset. A q-sequence database S consists of sets of tuples sid, s ,where sid is a unique identifier of s , which is a q-sequence.

We use the examples in Table 1 and Table 2 to illustrate the concepts, to show items and corresponding qualities and q-sequences respectively. In sid = 1 q-sequence, ( e, 5), ( c, 2), ( f, 1) and ( b, 2) are q-items; [( c, 2) ( f, 1)] is a q-itemset with two q-items. For convenience, in this paper,  X  X equence X  refers to ordered itemsets without quantities, i.e. the same meaning in sequence analysis; similarly,  X  X tem X  and  X  X tem-set X  do not involve quantity either. We use  X  X - X  to name the object associated with quantity. We denote the sid =1q-sequence in Table 2 as s 1 ; other q-sequences are numbered accordingly. We use the following definitions to construct the sequence utility framework.

Definition 1. (Q-itemset Containing) Given two q-itemse-q ) ... ( i b m ,q b m )], l b contains l a iff there exist integers 1 j  X  j 2  X  ...  X  j n  X  m such that i a 1  X  k  X  n , denoted as l a  X  l b .

For example, q-itemset [( a, 4)( b, 1)( e, 2)] contains q-itemse-tain [( a, 2)( e, 2)] or [( a, 4)( c, 1)].

Definition 2. (Q-sequence Containing) Given two q-sequ-ences s = l 1 ,l 2 , ..., l n and s = l 1 ,l 2 , ..., l n contains s or s is a q-subsequence of s iff there exist integers 1  X  j 1  X  j 2  X  ...  X  j n  X  n such that l k  X  l j denoted as s  X  s .

For example, ( b, 2) , [( b, 2)( e, 3)] , [( b, 2)][( e, 3)]( a, 2) are the q-subsequences of q-sequence s 5 ( sid = 5), while [( b, 4)( e, 3)] and ( b, 2)( b, 6) are not.

Definition 3. (Length and Size) A (q-)sequence is called k-(q)sequence i.e. its length is k iff there are k (q-)items in the (q-)sequence; the size of a (q-)sequence is the number of (q-)itemsets in the (q-)sequence.

For example, ( e, 5)[( c, 2)( f, 1)]( b, 2) is a 4-q-sequence with size 3. ea is a 2-sequence with size 2.

Definition 4. (Matching) Given a q-sequence s = ( s 1 ,q 1 ( s 2 ,q 2 ) ... ( s n ,q n ) and a sequence t = t 1 t 2 ...t t iff n = m and s k = t k for 1  X  k  X  n , denoted as t  X  s .
Due to the variety of quantities, two q-items can be dif-ferent even though their items are the same. That is, there could be multiple q-subsequences of a q-sequence matching a given sequence. For example, if we want to find the q-subsequences in q-sequence s 4 ( sid =4)inTable2which matches the sequence b ,weobtain ( b, 2) in the first q-itemset and ( b, 1) in the third q-itemset. Sometimes, two q-items can be exactly the same and appear in one q-seque-nce. For example, q-item ( e, 2) appears in both the first and third q-itemsets in q-sequence s 4 .

Definition 5. (Q-item Utility) The q-item utility is the where f u i is the function for calculating q-item utility.
Definition 6. (Q-itemset Utility) Q-itemset utility is the utility of an q-itemset l =[( i 1 ,q 1 )( i 2 ,q 2 ) ... ( i noted and defined as u ( l ): f is is the function for calculating q-itemset utility.
Definition 7. (Q-sequence Utility) For a q-sequence s = l l 2 ...l m , the q-sequence utility is u ( s ): where f u s is the utility function for q-sequences.
Definition 8. (Q-sequence Database Utility) For a utility-oriented sequence database S = { sid 1 ,s 1 , sid 2 ,s 2 , ..., sid ,s r } , the q-sequence database utility is u ( S ): f db is the function for aggregating utilities in the database. In the above, utility functions f u i , f u is , f u s and f application-dependent, which may be determined through collaboration with domain experts.

Definition 9. (Sequence Utility) Given a utility-oriented database S and a sequence t = t 1 t 2 ...t n , t  X  X  utility in q-sequence s = l 1 l 2 ...l m from S is denoted and defined as v ( t, s ), which is a utility set: The utility of t in S is denoted and defined as v ( t ), which is also a utility set:
For example, let sequence t = ea , t  X  X  utility in the s 4 ( a, 4) ) } = { 16 , 10 } . t  X  X  utility in S is v ( t )= there may be multiple utility values for a sequence within the utility sequence framework. For instance, t = ea has 2 utility values 16 and 10 for s 4 . This is very different from frequent sequential pattern mining, in which there is only one support associated with a sequence.
In the utility Definitions 5-8, we did not provide the utility and then state the problem of high utility sequential pattern mining. Although there may be various ways, we here define the above functions as
Definition 10. (High Utility Sequential Pattern) Because a sequence may have multiple utility values in the q-sequence context, we choose the maximum utility as the sequence X  X  utility. The maximum utility of a sequence t is denoted and defined as u max ( t ): Sequence t is a high utility sequential pattern if and only if where  X  is a user-specified minimum utility . Therefore, given a utility sequence database S and the minimum utility  X  , the problem of mining high utility sequential patterns is to extract all high utility sequences in S satisfying  X  . Here we illustrate the utility definitions in Section 3.1 and the above utility functions through their use in the retail business. In Tables 1 and 2, the utility of a shopped item (q-item) is its profit, equal to the unit profit (weight or quality) of the item times the quantity of the item shopped. The profit (q-itemset utility) of a series of purchased items (q-itemset) is the sum of the profits of all items. Similarly, we can calculate the profit (utility) for a shopping sequence and for a shopping database. For example, for s 1 , the utility of q-item ( e, 5) is u ( e, 5) = 5  X  1 = 5, which is also the utility of the first itemset X  X  utility. Similarly, the utility of s 1 and S are u ( s 1 )= u ( e, 5) + u ( c, 2) + u ( f, 1) + u ( b, 2) = 5  X  1+2  X  4+1  X  1+2  X  5 = 24 and u ( S )= u ( s 1 )+ respectively. The utility of sequence ea is u max ( ea )= 10 + 16 + 15 = 41. If the minimum utility is  X  = 40, then the shopping sequence s = ea is a high utility sequential pattern since u max ( s )=41  X   X  .

The utility Definitions 5-9 and the utility functions defined in Equations (7)-(10) define the problem of utility sequence mining. The high utility sequential pattern mining specifi-cation defined in Equations (11) and (12) is a special case of utility sequence mining. Based on different definitions of sequence utility calculation, other metrics can be defined for selecting high utility sequences. In fact, the traditional frequent sequence mining problem can also be viewed as a special case of the above utility-based framework. Suppose we set the quantity of all items as 1, and define the utility functions in Equations (7)-(10) as then the sequence utility is equal to its support. We can also prove that the specific algorithms proposed in the re-lated work [4, 11, 2] are special cases of our proposed utility sequence mining framework.
Here we specify and present an efficient algorithm, USpan, for mining high utility sequential patterns. USpan is com-posed of a lexicographic q-sequence tree, two concatenation mechanisms, and two pruning strategies. For utility-based sequences, we adapt the concept of the Lexicographic Sequence Tree in [5] to the characteristics of q-sequences, and come up with the Lexicographic Q-sequence Tree (LQS-Tree) to construct and organize utility-based q-sequences.

Suppose we have a k-sequence t , we call the operation of appending a new item to the end of t to form (k+1)-sequence concatenation .Ifthesizeof t does not change, we call the operation I-Concatenation . Otherwise, if the size increases by one, we call it S-Concatenation . For example, ea  X  X  I-Concatenate and S-Concatenate with b result in e ( ab ) and eab , respectively. Assume two k-sequences t a and t b are concatenated from sequence t ,then t a &lt;t b if i) t a is I-Concatenated from t ,and t b is S-Concatenated ii) both t a and t b are I-Concatenated or S-Concatenated ( ab ) d and ( ab )( de ) &lt; ( ab )( df ) .

Definition 11. (Lexicographic Q-sequence Tree) An lexi-cographic q-sequence tree (LQS-Tree) T is a tree structure satisfying the following rules:
Additionally, if we set  X  = 0, then the complete set of the identified high utility sequential patterns forms a complete-LQS-Tree , which covers the complete search space. Figure 1: The Complete-LQS-Tree for the Example in Table 2
Figure 1 is an example of LQS-Tree. The root is an empty q-sequence, while the nodes in the black boxes such as ( abe ) are leaves in the LQS-Tree. The bold lines and the light lines represent I-Concatenation and S-Concatenation, respectively. Nodes within the same parent are arranged in increasing order. The utilities of the sequences are in the bottom of the respective boxes.

Given a sequence t and a sequence database S ,calculating v ( t )in S is easy without any prior knowledge. For example, if we want to calculate v ( ea ), we simply find all the q-subsequences in each q-sequence that match ea , and calcu-late and aggregate the utilities of those q-subsequences. We obtain v ( ea )= {{ 8 , 10 } , { 16 , 10 } , { 15 , 7 }} and u = 41. Once we have u max ( ea ), a very natural question is,  X  X an any ea  X  X  child X  X  maximum utility be calculated by simply adding the highest utility of the q-items after ea to u max ( ea )? X . Unfortunately, the answer is no.

In frequent sequential pattern mining, the downward clo-sure property serves as the foundation of pattern mining al-gorithms. However, this property does not hold in the high utility pattern mining problem. In Table 2, u max ( ea )= 41, but u max ( e )=5+6+2+2+3=18,whichislower than its super-pattern. Thus, any frequent sequential pat-tern mining algorithms built on this property, such as pre-fixspan [10] and SPADE [14], cannot mine for high utility sequences. What is more, if we check the maximum utilities of a path in the complete-LQS-Tree, we find that the util-ities of the sequential patterns ( ae ) , ( ae ) a , ( ae )( ab ) , ( ae )( abc ) and ( ae )( abc ) a are 49, 33, 41, 25 and 29 re-spectively. There is no such property as anti-monotonicity in the maximum utilities. Therefore, it is not surprising that given  X &gt; 0, the high utility sequences may not form an complete-LQS-Tree. For example, for  X  = 60, the high util-ity sequential patterns are { ( be ) a ( ab ) } , { ba ( ab ) and { ( be ) ab } . Obviously, these four patterns cannot form an complete-LQS-Tree.

USpan consequently uses a depth-first search strategy to traverse the LQS-Tree to search for high utility patterns. As shown in Figure 1, USpan first generates the children of the root. It then takes a as the current node, checks whether a is a high utility pattern, and scans for a  X  X  possible children. If a  X  X  first children, i.e. ( ab ) , are not taken as the current node, the same operations will apply to ( ab ) . This procedure will be recursively invoked until there is no other node in the LQS-Tree to visit.
 Three important things about USpan need to be addressed. First, knowing the utility of a node, how can we generate the node X  X  children X  X  utilities by concatenating the correspond-ing items? The answer is provided in Section 4.2. Second, how can we avoid checking unpromising children? We dis-cuss this in Section 4.3. Finally, when should USpan stop the search of deeper nodes? This is discussed in Section 4.4.
At this point, we discuss how to generate the children X  X  utility based on the utility of its parent, in other words, through I-Concatenation and S-Concatenation. We intro-duce a utility matrix to represent the utility of a q-sequence. Table 3 is the utility matrix of q-sequence s 4 in Table 2. Each element in the matrix is a tuple; the first value shows the utility of the q-item, and the second is the utility of the remaining items in the q-sequence; we call it remaining utility , which will be discussed in Section 4.4. The items that do not appear in the q-sequence are given zero util-ity value. We illustrate the concatenations with q-sequence s ; other sequences can be conducted in the same way. Let us look at the record for item b in Table 3. Clearly, q-Table 3: Utility Matrix of Q-sequence s 4 in Table 2 subsequences ( b, 2) and ( b, 1) match the sequence b ,so v ( b ,s 4 )= { 10 , 5 } . Items can either I-Concatenate or S-Concatenate to an existing pattern.

We start from the I-Concatenation. In the example, only items larger than b can be I-Concatenated, i.e. entries in the rectangle from d 1(meaning d in itemset 1) to e 3 are possible items. More precisely, only itemsets 1 and 3 have b ,soitems corresponding to e 1=(2 , 38) to e 3=(2 , 0) can be used to form the q-subsequences that match the sequence ( be ) . The utilities of ( be ) are the utilities of u ( b ,s 4 )plusthe newly added q-items X  utilities e 1=(2 , 38), e 3=(2 , 0), i.e. v ( ( be ) ,s 4 )= { 10 + 2 , 5+2 } = { 12 , 7 } . Similarly, we have v ( a ,s 4 )= { 14 , 8 } , and utilities for its I-Concatenated se-quences v ( ( ab ) ,s 4 )= { 13 } , v ( ( ad ) ,s 4 )= { 23 s )= { 10 } ,etc.

S-Concatenation is a little more complicated. We con-tinue with ( be ) . As we can see from the utility matrix, there is no other literal that can be I-Concatenated to ( be ) . Q-items that can be S-Concatenated to the q-subsequences are located in the rectangle region from a 1to e 3. Thus, sequences such as ( be ) a , ( be ) b , ( be ) d and ( be ) e are the candidates. [( b, 2)( e, 2)]( a, 7) and [( b, 2)( e, 2)]( a, 4) match sequence ( be ) a , whose utilities are v ( ( be ) a ,s { 12+14 , 12+8 } = { 26 , 20 } .Wealsohave v ( ( be ) b ,s 4 { 17 } , v ( ( be ) d ,s 4 )= { 21 } , v ( ( be ) e ,s 4 )=
From the above two examples, we conclude that a se-quence X  X  children X  X  utilities can be calculated in terms of the utility of a sequence and the positions of the last q-items of q-subsequences that match the sequence. For example, to generate the utility of ( be ) a based on ( be ) in s 4 only need to know the following information from ( be ) :i) e 1and e 3 are the two last q-items of q-subsequences which match the sequence ( be ) , and ii) the utilities are 12 and 7 respectively. As for which q-items matches b ,thisisnot important. Additionally, we call e 1 pivot , because it is the first place where the q-subsequences that match ( be ) end. Itemsthataresimilarto e 3 are called ending q-items .
Figure 2 presents the data representation in USpan. Every sequence is stored in the memory in the form of a utility matrix. We omit the entries in the figure for simplicity. The pivot in q-sequence 1 is the black dot; other ending q-items are the black solid boxes on the right side of the dot.
The above section discusses how to concatenate items to a sequence, a remaining issue is what kind of items are qual-ified to be concatenated. This section presents the scanning function of USpan, and proposes a width pruning strategy to further select the promising items.

As shown in Figure 2, those located at the left side of the pivot (inclusive) are called projected q-items . Clearly, it is not possible to concatenate these projected q items. The qualified items are at the right side of the pivot. They are I-Concatenation items right under the pivot and the end-ing q-items, and S-Concatenation q-items are on the right side of the pivot. For each sequence in S ,thoseitems should be scanned and inserted into the corresponding I-Concatenation and/or S-Concatenation lists.

Not every qualified item is a promising item. For example, f is qualified to concatenate to several sequences, but it appears once only in the whole database, i.e. ( f, 1) in q-sequence 1. The maximum utility of any sequence containing f will be no more than the utility of q-sequence 1, so any sequence concatenating with f will, if it can, make itself a low utility pattern.

To avoid selecting the unpromising items, we propose a width pruning strategy for the scanning subroutine. This is based on the sequence-weighted downward closure property (SDCP), which is similar to the transaction-weighted down-ward closure property (TDCP) in [8]. Before introducing SDCP, we give a definition to the sequence-weighted utiliza-tion (SWU) of a sequence.

Definition 12. (SWU) SWU of a sequence t in S is de-noted and defined as SWU ( t ) For example, SWU ( f )= u ( s 1 ) = 24 and SWU ( ea )= u ( s 2 )+ u ( s 4 )+ u ( s 5 ) = 41 + 50 + 37 = 128.
Theorem 1. (Sequence-weighted Downward Closure Prop-erty) Given a utility-based sequence database S ,andtwose-quences t 1 and t 2 ,where t 2 contains t 1 ,then
Proof. Let s 2  X  s j  X  X  be a subsequence matching the sequence t 2 .Since t 2 contains t 1 ,weknowthattheremust be a subsequence s 1  X  s 2 matching t 1 . Therefore, a se-quence containing subsequences such as s 2 is a subset of that containing s 1 , i.e We derive, and obtain SWU ( t 2 ) SWU ( t 1 ).
Based on Theorem 1, we define whether an item is X  X romis-ing X . Imagine we have a k-sequence t ,anewitem i concate-nates to t and results in a (k+1)-sequence t .If SWU ( t )  X  ,wesayitem i is a promising item to t . Otherwise, i is called an unpromising item . In the implementation, to test whether an item is promising, we do not have to generate the new sequence to test whether an item is promising. We simply add the utilities of all the sequences; this is equal to the SWU of the new sequence.
The width pruning strategy avoids constructing unpromis-ing patterns into the LP-Tree; a depth pruning strategy stops USpan from going deeper by identifying the leaf nodes in the tree. Imagine the following scenario: the pivots are approaching the end of q-sequences; meanwhile, the maxi-mum utility of the sequence is much less than  X  . The gap is so large that even if all the utilities of the remaining q-items are counted into the utility of the sequence, the cumulative utility still cannot satisfy  X  . In this situation, we use the depth pruning strategy to backtrack USpan instead of wait-ing to go deeper and returning with nothing.

We use the notation u rest ( i, s ) to refer to the remaining utility at q-item i (exclusive) in q-sequence s . In the utility matrix, the remaining utility appears in the second element in each entry, as shown in Table 3, e.g. u rest ( b 1 ,s 4 u rest ( d 2 ,s 4 ) = 15.

Theorem 2. Given a sequence t and S , the maximum utilities of t and t  X  X  offsprings are no more than where i is the pivot in s of t , i  X  s and s  X  s .
Proof. Suppose we have the utility of sequence t in S ,we can divide each sequence s  X  X  into two parts from the piv-ots, where the pivots are in the left part. Assume s  X  s and pivot i  X  s , in other word, s is the far left subsequence in s that matches t . t  X  X  offsprings can be only concatenated from the right side of the pivot. Correspondingly, it is easy to understand that the maximum utilities of the concatenated items are no more than u rest ( i, s ). Hence, the utility of any item concatenated from s is no more than u rest ( i, s )+ u ( s ). Similarly, the highest utility of other sequences in S can be calculated in the same way. Thus, the theorem holds.
Based on Theorem 2, if the utility upper bound, i.e. the sum of remaining utilities and utilities of far left subse-quences, is less than  X  , we can simply stop USpan from going deeper and backtrack the search procedure.
The USpan algorithm is illustrated in Algorithm 1. The input for USpan is a database S and a minimum utility threshold  X  ; the output includes all the high utility patterns.
Lines 1 describes the depth pruning strategy. A node is judged as a leaf or not based on the comparison between the value of Equation (21) and  X  ;ifitislowerthan  X  then it returns to its parent nodes. Lines 2 to 4 are the scanning subroutine with the width pruning in Line 5. Once the con-catenation items are collected, the unpromising items are omitted from the respective lists. Lines 7 and 12 construct the I-Concatenation and S-Concatenation children respec-tively. It invokes the concatenation to generate the utilities of sequences; the positions are also maintained. USpan then outputs the high utility sequences if qualified, and recur-sively invokes itself to go deeper in the LQS-Tree. Algorithm 1 USpan( t, v ( t )) Input: Asequence t , t  X  X  utility v ( t ), a utility-based se-Output: All high utility sequential patterns 1: if p is a leaf node then return 2: scan the projected database S ( v ( t )) once to: 3: a).put I-Concatenation items into ilist ,or 4: b).put S-Concatenation items into slist 5: remove unpromising items in ilist and slist 6: for each item i in ilist do 7: ( t ,v ( t ))  X  I-Concatenate( p , i ) 8: if u max ( t )  X  then 9: output t 10: USpan( t , v ( t )) 11: for each item i in slist do 12: ( t ,v ( t ))  X  S-Concatenate( p , i ) 13: if u max ( t )  X  then 14: output t 15: USpan( t , v ( t )) The USpan algorithm was implemented in C++ of Visual Studio 2010. All experiments were conducted on a desktop computer with Intel Core 2 CPU of 2.80GHz, 4GB memory and Windows XP Professional SP3. Both real and synthetic datasets are used to evaluate the efficiency of USpan.
Four source datasets are used for the experiments. They include two synthetic datasets DS 1 ,DS 2 generated by the IBM data generator [1].
 DS1 is C10T2.5S4I2.5DB10kN1k.
 DS2 is C8T2.5S6I2.5DB10kN10k.

The parameters in DS1(DS2) mean that the average num-ber of elements in a sequence is 10(8), the average number of items in an element is 2.5(2.5), the average length of a maximal pattern consists of 4(6) elements and each element is composed of 2.5(2.5) items average. The data set contains 10k(10k) sequences, the number of items is 1000(10k). We also test two real datasets DS 3 ,DS 4.

DS3 is a real dataset consisting of online shopping trans-actions. Each customer has a sequence of records containing the information about product ID, the amount of the prod-ucts and its unit price. There are 811 distinct products, 350,241 transactions and 59,477 customers in the dataset. The average number of elements in a sequence is 5. The max length of a customer X  X  sequence is 82. The most popu-lar product has been ordered 2176 times. We test USpan by selecting online shopping sequences with high sale turnover.
DS4 is a real dataset that includes mobile communica-tion transactions. The dataset is a 100,000 mobile-call his-tory from a specific day. There are 67,420 customers in the dataset. The maximum length of a sequence is 152.
We conduct intensive experiments to evaluate the perfor-mance of USpan in terms of computational cost, memory usage, number of high utility patterns, and length of pat-terns on different datasets.

The execution times of mining high utility sequential pat-terns by USpan on DS 1to DS 4 are shown in Figure 3; the figure also includes the number of patterns. When the minimum utility threshold decreases, more execution time is required since we can obtain many more high utility sequen-tial patterns. The results also show that USpan can extract high utility sequences under very low minimum utility (for instance, 0.0006 for DS 1 and 0.0002 for DS 2).

Figure 4 shows the distribution of the high utility sequen-tial patterns discovered in terms of pattern length. It shows that the maximum length of identified high utility sequences increases dramatically with the decrease of minimum utility. It is also clear that high utility sequential pattern mining shows a very different trend of pattern distribution against minimum utility from that of frequent sequential pattern mining against minimum support, e.g. when the pattern length is 11, we find the largest number of identified utility sequences in DS 2. This shows that the Apriori property does not hold in utility sequence mining.
We test the computational costs of the two proposed prun-ing methods on DS 1and DS 2. Three type of pruning strate-gies are evaluated. The first only uses depth-pruning, the second only uses width-pruning, and the third uses both depth and width pruning. The results of these three strate-gies are shown in Figure 5.

On both datasets, the depth-pruning method is very sen-sitive to the minimum utility. When the threshold is high, the pruning is very effective, because it only goes deeper when there is a higher remaining utility value. It can greatly ignore invalid searches by pruning patterns whose pivots ap-pear at the end of sequences. However, when the threshold decreases, the search space in LQS-Tree grows exponentially. In contrast, width pruning is more stable with the decrease of the threshold. The reason is that width pruning always prevents unpromising items from getting into the concate-nation lists. It can control the width of the trees very well, however it cannot control whether the current sequence is promising until it reaches the very end of the LQS-Tree. The combination of both width and depth pruning strategies leads to extremely improved efficiency compared to either of them, and result in up to eight times the difference in exe-cution time, because the two kinds of pruning strategies can compensate for the shortcomings of each other. In addition, since the high utility sequential pattern mining algorithm in [4] is essentially based on width-pruning, the experimental results indirectly show that USpan is much more efficient.
The scalability test is conducted to test USpan X  X  perfor-mance on large-scale datasets. Figure 6 shows the results on datasets DS 1and DS 2 in terms of different data sizes: 50K to 200K sequences are extracted from DS 1and DS 2, by setting  X  =0 . 006 on DS 1and  X  =0 . 003 on DS 2.
On both datasets, the execution time and memory usage are exactly linear with the number of transactions, as shown in Figure 6. USpan stores the whole dataset, and the run-ning time is directly related to the size of the LQS-Tree.
This experiment tests the utility difference between the patterns identified by USpan and that the patterns identified purely by frequent sequential pattern mining. Figure 7: High Utility vs. Frequent Sequential Pat-terns
Figure 7(a) shows the utilities of two groups of identified patterns, one by prefixspan and the other by USpan. The x axis refers to the top n number of frequent vs. high-utility patterns selected from the two groups, while the y axis shows the sum of the utilities of the top n patterns. Figure 7(b) shows the average utilities of patterns with different lengths from prefixspan and USpan. The x axis refers to the lengths of patterns; while the y axis shows the average utilities per pattern. The results show that USpan can identify higher utility patterns more efficiently, and it can extract top pat-terns with higher average utility per pattern.
Frequent sequential pattern mining leads to patterns which do not show business value and impact, and thus are not actionable for business decision-making. In this paper, we have provided a systematic statement of a generic frame-work, and an efficient algorithm, USpan, for mining high utility sequential patterns. Substantial experiments on both synthetic and real datasets have shown that USpan can ef-ficiently identify high utility sequences in large-scale data with low minimum utility. For USpan, the metrics in Equa-tion (11) can be changed to some other proper metrics such as minimum or average utility. The corresponding functions in lines 8 and 13 will be modified as well to fit the new frame-works, and the complexities are in the same level. In fact, USpan stores the positions and utilities of the candidates, a range of different functions can be applied on them with different purposes in such a framework. Our future work is on designing algorithms for even bigger datasets and better pruning strategies. This work is sponsored in part by Australian Research Council Discovery Grant (DP1096218) and ARC Linkage Grant (LP100200774). [1] R. Agrawal and R. Srikant, Mining sequential [2] C. F. Ahmed, S. K. Tanbeer and B. Jeong, Mining [3] C. F. Ahmed, S. K. Tanbeer, J. Byeong-Soo and L. [4] C. F. Ahmed, S. K. Tanbeer and B. Jeong, A Novel [5] J. Ayres, J. Flannick, J. Gehrke and T. Yiu, [6] L. Cao, P. Yu, C. Zhang and Y Zhao. Domain Driven [7] Y. Li, J. Yeh and C. Chang, Isolated items discarding [8] Y. Liu, W. Liao and A. Choudhary, A two-phase [9] N. R. Mabroukeh and C. I. Ezeife, A taxonomy of [10] J. Pei, J. Han, B. Mortazavi-Asl, J. Wang, H. Pinto, [11] B. Shie, H. Hsiao, V. S. Tseng and P. S. Yu, Mining [12] V. S. Tseng, C.-W. Wu, B.-E. Shie and P. S. Yu, [13] H. Yao, H. J. Hamilton and C. J. Butz, A [14] M. J. Zaki, SPADE: An Efficient Algorithm for
