 Recommender systems suggest to users items that they might like (e.g., news articles, songs, movies) and, in doing so, they help users deal with information overload and enjoy a per-sonalized experience. One of the main problems of these systems is the item cold-start, i.e., when a new item is in-troduced in the system and no past information is available, then no effective recommendations can be produced. The item cold-start is a very common problem in practice: mod-ern online platforms have hundreds of new items published every day. To address this problem, we propose to learn Local Collective Embeddings : a matrix factorization that exploits items X  properties and past user preferences while enforcing the manifold structure exhibited by the collective embeddings. We present a learning algorithm based on mul-tiplicative update rules that are efficient and easy to im-plement. The experimental results on two item cold-start use cases: news recommendation and email recipient recom-mendation, demonstrate the effectiveness of this approach and show that it significantly outperforms six state-of-the-art methods for item cold-start.
Recommender systems are aimed to help users of online platforms to deal with the large volumes of information and to provide them a personalized experience. This is achieved by suggesting items of interest to the users based on their ex-plicit and implicit preferences. Recommender systems use a number of different technologies, but may be broadly classi-fied into two groups: content-based and collaborative filter-ing systems. Content-based systems examine the properties of the items and recommend items which are similar to the ones the user preferred in the past. They model the taste of a user by building a user profile based on the properties of the items the user liked, and use the profile to compute the similarity with new items. Items which are most sim-ilar to the user X  X  profile are recommended. Collaborative filtering systems, on the other hand, ignore the properties of the items and base their recommendations on community preferences. They recommend items that users with simi-lar tastes and preferences liked in the past. Two users are considered similar if they have many items in common.
One of the main problems for recommender systems is the cold-start problem, i.e., when a new item or user is intro-duced in the system. In this study we focus on the problem of producing effective recommendations for new items: the item cold-start. Collaborative filtering systems suffer from this problem as they rely on the previous ratings of the users. Content based approaches, on the other hand, may still pro-duce recommendations using the description of the items and are the default solution to the item cold-start. How-ever, they tend to achieve lower accuracy and, in practice, they are seldom the only choice.

The problem of item cold-start is of great practical im-portance because of two main reasons. First, modern online platforms publish hundreds of new items everyday and effec-tively recommending them is essential for keeping the users continuously engaged. Second, collaborative filtering meth-ods are at the core of most recommendation engines, as they tend to achieve the state-of-the-art accuracy [1]. However, to produce recommendations at the expected accuracy they require that items are rated by a sufficient number of users. Therefore, it is crucial for every collaborative recommender to reach this state as soon as possible. Having methods that produce accurate recommendations for new items will allow enough feedback to be collected in a short amount of time, making effective collaborative recommendations possible.
Recently, matrix factorization techniques have been exten-sively used in the recommendation systems and topic mod-elling literature. Many collaborative filtering systems ap-proximate the collaborative matrix by applying techniques such as Singular Value Decomposition (SVD) or UV de-composition [20]. Similar matrix factorization techniques have been used to discover topics in document collections by decomposing the content, i.e., document-term matrix. Non-negative Matrix Factorization (NMF) is one such ap-proach that factorizes the document-term matrix in two non-negative, low-rank matrices, where one matrix corresponds to the topics in the collection and the other represents the ex-tent to which documents belong to these topics. Due to the non-negativity constraints, NMF produces a so-called  X  X d-ditive parts-based X  representation of the data that increases the sparsity and interpretability of the hidden factors [22].
In this paper, we propose a new hybrid recommendation approach that exploits both the properties of the items and the similarity of the user preferences. We introduce Local Collective Embeddings (LCE), a collective matrix factor-ization technique that collectively decomposes the content and the collaborative matrices in a common low-dimensional space while preserving the local geometrical structure of the data.

Given the description of a new item (e.g., the content of a news article), we may project it on the common low-dimensional space and infer the users that are most likely to be interested in it. By doing so, we are able to overcome the item cold-start problem. Moreover, LCE provides a nat-ural way of explaining the recommendations  X  in terms of user X  X  affinity to topics. Finally, we perform an extensive ex-perimental evaluation of the models on two item cold-start use cases: email recipient recommendation (based on explicit feedback) and news recommendation (based on implicit feed-back). We show that the proposed models outperform six state-of-the-art baseline approaches.

Our contributions in this paper can be summarized as follows:  X  We introduce a new method for recommendation, LCE,  X  We propose a simple and efficient learning algorithm,  X  We conduct an extensive experimental study and we
In this section, we briefly describe several hybrid recom-mender systems that can handle the item cold-start scenario.
Soboroff [28] proposed a technique based on Latent Se-mantic Indexing (LSI) for combining the collaborative fil-tering input and the document content for recommendation of textual items. The method builds a content profile for each user, as a linear combination of the preferred docu-ments, and applies LSI to discover topics in the collection and implicitly learn commonalities among the user profiles. Incoming documents are projected on the LSI space and compared to the user profiles. The documents are recom-mended to the users with the most similar profiles. The author argues that applying LSI on the user profiles instead of the documents allows one to take into account the collabo-rative input and consequently improves the recommendation performance. However, the system is not evaluated in the cold-start scenario. In section 5, we compare this technique against the method we propose.

Schein et al. [25] propose a probabilistic model for cold-start recommendations that is very similar to the one pro-posed by Soboroff. Their approach extends the work of Hoff-man and Puzicha [18] which models the joint distribution of users and items through an aspect model that clusters users and items in a latent space. In order to deal with new items, instead of modelling the joint distribution of users and items, the authors propose to model the joint distribution of users and content features. At query time a  X  X olding-in X  X  tech-nique [17] is used to embed new items into the latent space so that items can be recommended. After careful analysis one may notice that the technique essentially boils down to building user profiles and applying pLSA to discover la-tent factors. Taking into account that previous studies have shown the correspondence between pLSA and NMF [16], one may clearly distinguish between this approach and our pro-posal. Instead of explicitly building user profiles and finding latent features, we discover a latent space common to both the content and collaborative information that allows us to link one to the other.

Singh and Gordon [27] propose the idea of collective ma-trix factorization, a general framework for multi-relational factorization models. They subsume models on any number of relations as long as their loss function is a twice differen-tiable decomposable loss. In their work, they address both rating prediction and item recommendation. The matrix factorization approach proposed in this work is based on a similar idea of collective factorization. However, we en-force non-negativity constraints on the factorization to ob-tain sparse and interpretable factors, and we consider the specific scenario of cold-start recommendations.

Shmueli et al. [26] consider a similar scenario of news rec-ommendation (Section 5.3), i.e., predicting the articles a user is most likely to comment on. They combine content-based and collaborative filtering approach using a latent fac-tor model. The odds that a user will comment an article are estimated as the inner product of the user and article factors, where the article factors are represented as the sum of the la-tent factors associated with the textual content (tags X  X amed entities) and the commenters. A modification of the model for real-time scenarios is presented in [4]. The authors show that the recommendation accuracy grows as the number of commenters grows. However, in an item cold-start scenario articles are not yet associated with commenters, thus an ar-ticle can only be represented with the latent factors of the textual tags.

Exploiting the local geometric structure of the data to dis-cover better low-dimensional representations has been inves-tigated by Cai et al. [11]. Inspired by the success of using the nearest neighbor graph for label propagation in semi-supervised learning, they propose a clustering technique. The algorithm favours factorizations for which similar in-stances have similar low-dimensional representations. The authors show that, by imposing this constraint, they outper-form classical clustering and factorization techniques. In this work, we impose such geometrical constraints but for col-lective factorization for which we can handle multiple data sources, i.e., the content and collaborative data matrices.
Finally, it is worth noting the 2011 ECML-PKDD Discov-ery Challenge which focused on cold-start recommendations of video lectures [5].
In this section we formally define the item cold-start prob-lem, we explain the intuition behind learning local collective embeddings, and finally we show how such embeddings can be learnt and used for prediction.
The scenario we consider is the item cold-start recommen-dation, where we would like to suggest new items  X  for which no interests has been expressed so far  X  to potentially inter-ested users. Given a new item, its corresponding description and the patterns of past activities of the users, we want to retrieve the users who are most likely to manifest interest in this item. More formally, we can define the problem as fol-lows. At training time, we are given a collection of n items described by: (1) a set of m properties stored in a matrix X s  X  R n  X  m , where a row corresponds to an item and a col-umn to an item property; and (2) a set of u users stored in a matrix X u  X  R n  X  u , where a cell ( i,j ) indicates if the user j has shown interest in item i . At test time, we are given a new item q with description q s  X  R 1  X  m , and our goal is to predict q u  X  R 1  X  u , i.e., to score how likely is a user to show interest in the new item.
Given the problem defined, items are associated with a description and a set of users who consumed them. In the case of news, each news article is described by the set of words it contains and by all the users that commented on it. This information is then represented with two matrices, a document-term matrix X s  X  R n  X  v , and a document-user matrix X u  X  R n  X  u , where n is the number of documents, v is the vocabulary size and u is the number of users. The document-term matrix ( X s ) may be a boolean matrix or may represent the TF-IDF scores of the words in the docu-ment. On the other hand, the entries of the document-user matrix ( X u ) reflect whether a given user commented on a given article. If we factorize X s in two lower-dimensional matrices, we will discover the topics that appear in the doc-uments and the extent to which each document belongs to these topics. Similarly, factorizing X u leads to the discov-ery of user communities and the extent to which each doc-ument triggers interest within the communities. However, if factorized independently each factorization will represent a different latent space and there will be no correspondence between the topics and the communities. The idea of LCE is that both, documents and users, should be represented in a common latent space. In other words, each factor can be described by a set of words (i.e., a topic) but also by a set of users (i.e., a community). To achieve this, we collec-tively factorize X s and X u and enforce a low-dimensional representation in a common space. Additionally, to achieve an additive effect we impose non-negativity constraints that lead to interpretable and sparse latent representations.
More formally, given the matrices X s and X u , we define the following optimization problem: min : J = 1 The first two terms correspond to the factorization of the matrices X s and X u . The common latent space representa-tion is achieved by using the same matrix W in the decom-positions of both X s and X u .  X   X  [0 , 1] is a hyper-parameter that controls the importance of each factorization. Setting  X  = 0 . 5 gives equal importance to both factorizations, while values of  X  &gt; 0 . 5 (or  X  &lt; 0 . 5) give more importance to the factorization of X s (or X u ). The remaining terms are Tikhonov (Frobenius norm) regularization of W , H u , and H s , controlled by the hyper-parameter  X   X  0. It is used to enforce smoothness of the solution and avoid overfitting.
When performing collective factorization, as in Eq. (1), we attempt to find a common low-dimensional space that is optimized for the linear approximation of the data from both views. We make an implicit assumption that the data from both views is drawn from a common distribution. One may hope that additional knowledge of this distribution can be exploited to discover a better low-dimensional space. A natural assumption could be that: if two data points x i x , in any view, are close in the intrinsic geometry of the dis-tribution, then their representations in the low-dimensional space should also be close to each other. This assumption is commonly referred to as the manifold assumption and plays an essential role in algorithms for dimensionality re-duction [8] and semi-supervised learning [9].

In reality the geometric structure of the distribution is not known and cannot be directly used. However, recent studies on spectral graph theory [12] and manifold learning [7] have shown that the local geometric structure can be effectively modeled through a nearest neighbor graph on a scatter of data points. Consider a graph with n nodes where each node represents a data point. For each point we find the p nearest neighbors and we connect the corresponding nodes in the graph. The edges may be binary (1 if one of the nearest neighbors, 0 otherwise) or may be weighted (e.g., cosine similarity). This results in a matrix A which can later be used to measure the local closeness of two points x and x j .

Recall that the collective factorization maps each data point x i into a low-dimensional representation w i (a row of the matrix W ). A natural way to measure the distance be-tween two low dimensional representations, given the choice of a loss function, is to compute the Euclidean distance: || w i  X  w j || 2 . Using the above defined weight matrix A we may measure the local smoothness of the low dimensional representation as: where D is a diagonal matrix whose entries are the row sums of A (or column, as A is symmetric), i.e., D ii = P i L = D  X  A is called the Laplacian matrix of the graph [12] and Tr(  X  ) is the trace operator.
Given the above, we modify the formulation of in Eq. (1) as to enforce locality when discovering the factors. This leads to the following optimization problem: min : J = 1 where L is the Laplacian matrix of the graph, and  X  is a hyper-parameter which controls the extent to which locality is enforced. The hyper-parameters  X  and  X  have the same semantics as in Eq. (1).
The optimization problem defined above is non-convex in terms of all parameters ( W , H s , H u ) together. Thus, it is unrealistic to expect an algorithm to find the global min-imum. In what follows, we derive an iterative algorithm based on multiplicative update rules which can achieve a stationary point.

The partial derivatives of J w.r.t. W , H s , and H u are:  X 
W J =  X  WH s H s T  X   X  X s H s T + (1  X   X  ) WH u H u T  X   X 
H s J =  X  W T WH s  X   X  W T X s +  X  H s (4)  X  H u J = (1  X   X  ) W T WH u  X  (1  X   X  ) W T X u +  X  H u (5)
Applying the Karush-Kuhn-Tucker (KKT) first-order op-timality conditions to J [13], we derive:
W  X  0 , Hs  X  0 , Hu  X  0 , (6)  X  W J  X  0 ,  X  H s J  X  0 ,  X  H u J  X  0 , (7)
W  X  W J = 0 , Hs  X  H s J = 0 , Hu  X  H u J = 0 , where corresponds to the element-wise matrix multiplica-tion operator.

Substituting the derivatives of J from Equations (3), (4) and (5) in Equation (8) leads to the following update rules: W  X  W [  X  X s H s H H where  X   X  denotes the element-wise matrix division operator. We define the following theorem:
Theorem 1. The objective function J in Equation (2) is nonincreasing under the update rules in Equations (9) , (10) , and (11) . The objective function J is invariant under these updates if and only if H u , H s and W are at a stationary point of the function.

A detailed proof of the above theorem is provided as sup-plement material 1 .
Once the model has been trained to learn W , H s and H u , we can use these factors for prediction. For instance, given the bag-of-words vector of a new news article q s , we can predict the users that are most likely to post a comment, i.e., q u . To do so, we project the document vector q s common latent space by solving the overdetermined system q s = wH s using the least squares method (with a projection to 0 of the negative values, see [10]). The vector w , com-puted online, captures the factors  X  in the common latent space  X  that explain the observed news article q s by using this low dimensional vector w we may infer the missing part of the query: q u  X  wH u . Each element of q u represents a score of how likely it is that the user will comment the new article. Then, given these scores, we may rank the users. https://github.com/msaveski/LCE/blob/master/ Th1Proof.pdf
Good recommendations are not only accurate but also transparent, i.e., supported with explanations. This allows the end users to understand the reasoning behind the recom-mendations and helps them build trust towards the system.
LCE provides a natural way of explaining recommenda-tions in terms of users X  affinity to topics. To obtain the topical interest profile for a user i we can construct a vector x u  X  R 1  X  u ( u is the number of users), where all elements are equal to zero except [ x u ] i = 1, and solve for w in x u every element of w quantifies the user X  X  affinity to a specific topic. Topics may be presented using the top-k terms or by automatic annotation (e.g., [21]). Furthermore, by com-puting x s  X  wH s ( x s  X  R 1  X  m ), we obtain the association between the user and every word in the vocabulary; we may present this information to the user, e.g., using a word cloud.
To debug and track down the source of unexpected be-haviour of the system one may examine the link between topics and communities (e.g., by looking at the top words and users). This link may also be exploited in other ap-plications, such as advertising, where advertisers can easily identify target users based on their topical interests.
In this section we present a series of experiments to evalu-ate the performance of LCE in the item cold-start scenario. We first describe the baselines and then we compare them with LCE in two item cold-start use cases: email recipi-ent recommendation and news recommendation. Finally, we analyse the parameter settings and the running times.
We compare LCE to six other approaches: pure content-based recommender, content-topic-based recommender, LSI applied on the author profiles, author topic-model, learning attribute-to-feature mappings, and fLDA.
 for each user based on the properties of the items preferred in the past. Experimentally we find that weighting each item inversely proportional to the number of users that in-teracted with the item leads to an improved performance. Thus, in the user profile, very popular items are given less importance, while less popular items are given more im-portance. More formally, a user profile U is defined as: U = P i  X  I ( ~v i /freq i ), where I is the set of items the user interacted with in the past, ~v i is the description of item i and freq i is the number of users that interacted with i . At test time, we rank the items by computing the cosine simi-larity between the new items and the user profiles. topics from the content of the items by applying NMF and we describe each item as a mixture of the topics extracted. We then build a topical profile for each user based on the top-ics of the items the user interacted with in the past. At test time, we infer the topics of the new items and we rank the items based on the cosine similarity between the item X  X  top-ics and the users X  topical profiles. The CTB recommender allows us to investigate the importance of performing joint factorization of both the content and collaborative matrix, instead of factorizing only the content matrix. recommendation system proposed in [28] (see Section 2). The approach combines the content and collaborative in-formation by building user profiles and applying Latent Se-mantic Indexing (LSI) to discover latent factors. At test time, the new items are projected in the latent space and compared to the user profiles. Finally, the items are recom-mended to the users with the most similar profiles. is a generative probabilistic model which extends LDA to in-clude authorship information. It associates each author with a multinomial distribution over topics, and each topic with multinomial distribution over words. As the authors point out, the model may not only be used to find the topics as-sociated with the authors, but also to predict the authors of unobserved documents. In the email recipient recommenda-tion experiment we model the recipients as authors, while in the news recommendation scenario we model the users as authors. As recommended, we set the parameters as:  X  = 50 /k , where k is the number of topics,  X  = 0 . 01, and we perform 500 iterations of the Gibbs Sampler.
 This method [15] handles the cold-start in two steps: (1) factorizing the collaborative matrix to learn latent factor representation of the users and items, (2) learning a map-ping between the user/item attributes and the corresponding latent factors. When a new user/item arrives in the system, the mapping from (2) is used to infer the factors from the attributes, and then the factors are used to make predic-tions. As proposed by the authors, we used Bayesian Per-sonalized Ranking (BPR) to factorize the collaborative ma-trix. To learn the mappings we used the K-Nearest-Neighbor and BPR optimization; however, the kNN mapping was su-perior in all cases and thus we report the results for only for kNN mapping. This is consistent with their experimen-tal results. We test with different number of latent factors k  X  X  100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 } . extension of the Regression Based Latent Factor model [2] for applications where  X  X ag-of-words X  representation of items is natural. The main idea is regularizing the user and item factors simultaneously through the user features and the words associated with the items. The user ratings are mod-elled as user X  X  affinity to the item X  X  topics, where the user X  X  affinity to topics and topic assignments to items are learned jointly in supervised fashion. In our experiments we only use the item feature as user features are not available. As recommended by the authors, we run 20 EM iterations with 100 samples, drawn after 10 burn-in samples. In the email recommendation experiment, we test for k  X  { 10 , 25 , 50 } factors, while for the news recommendation experiment we test only k = 10 due to the long running times.
When people write emails they do not necessarily start by filling in the recipient address (i.e., the  X  X o X  field), but may start by writing the body of the message. Given the content of the message and the messaging habits of the user, i.e., with whom the user exchanged messages with similar content in past, we would like to predict the most likely recipients of the new message. In this experiment, we test Figure 1: Comparison of the different methods on the Enron dataset. the accuracy of the recipient recommendations produced by LCE against the six baseline techniques.
 during investigation of the Federal Energy Regulatory Com-mission against the Enron Corporation. We consider the 10 largest mailboxes and within each mailbox the emails sent by the owner. There are 36,010 emails sent to 4,984 recipients. The size of the vocabularies for each mailbox ranges from 12,375 to 56,193 unique tokens. The messages have been preprocessed by removing the headers (from/to/cc fields), converting all tokens to lower case and removing numbers, stop-words and infrequent tokens (appearing &lt; 5 times). ranking of the past recipients of how likely they are to be recipients of the new email. The feedback from the users is explicit, i.e., we have ground truth of who are the recipients of the mail as specified by the user. To evaluate the ranking produced by each algorithm we use the state-of-the-art met-rics from Information Retrieval: Micro and Macro F1, Mean Average Precision (MAP), and Normalized Discounted Cu-mulative Gain (NDCG) [6].
 by time we sort the 10 mailboxes chronologically. We divide the messages in 80% training and 20% testing, resulting in 10 independent train/test subsets. Only the recipients that appear in the training period are considered as potential re-ceivers. We tune the hyper-parameters of the methods on independent validation set, 10% of the training set. Finally, we evaluate the statistical significance of the differences in performance by using a Wilcoxon signed rank test [14]. method across the 10 mailboxes. LCE performs better than the other methods in all measures with differences ranging from 5%-15%. All differences are statistically significant (Wilcoxon signed rank test, p &lt; 0 . 05). Imposing locality leads to small performance improvements in some measures, however the differences are not statistically significant. This indicates that nearest neighbor graph does not bring addi-tional information in the case of emails. One explanation may be that emails are user generated content and as such contain a lot of noise, such as misspellings or informal ex-pressions, that leads to inaccurate nearest neighbor graphs.
To improve the user experience, online news platforms allow users to engage with articles by posting comments. Moreover, to encourage user engagement on the platform the users are recommended articles that they may be interested in. We consider the item cold-start scenario, i.e., when a new article is published and none of the users have commented on it yet. Thus, given the content of the new articles and the past commenting patterns we would like to recommend to the users the articles that they are most likely to comment. the corresponding comments posted on the Yahoo! News website in a period of 40 days. The dataset contains  X  41K articles,  X  3.5M comments posted by  X  650K users. The size of the vocabulary is  X  60K (i.e., unique tokens in all articles) and  X  9M tokens in total. The content of the articles is preprocessed such that all tokens are converted to lower case, and stop-words, digits, punctuation, short ( &lt; 3 characters) and infrequent (appearing &lt; 3 times) tokens are removed. the output of each algorithm is a ranking. In this experi-ment, however, we do not have an explicit feedback of which news articles were undesired by the users. While, comment-ing an article is an evidence of the user X  X  interest in it, the absence of a comment is not an indication that the article was undesired, as not commenting may stem from multi-ple different reasons. Therefore, we adopt the average per-centile ranking, a measure proposed in [19] and widely used to evaluate ranking based on implicit feedback (e.g., [24]). We define rank u,i as the percentile ranking of article i in the ranked list of articles for the user u ; if rank u,i then the article i is predicted to be the most interesting for u , while rank u,i = 100% implies that the article is predicted to be the least interesting. Our quality measure is then the total average percentile ranking of an article: where comment u,i is an indicator function that equals to: 1 if the user u commented on article i ; and 0 otherwise. The lower rank , the better the quality of the ranking. For ran-dom predictions, the expected value of rank is 50%. Thus, if rank &lt; 50%, then the algorithm is better than random. To ease illustration, we convert the percentile ranking into ranking accuracy (RA). That is 1 (best/ideal predictions), if the percentile ranking is 0%; and it is 0 (random predic-tions), if the percentile ranking is 50%: We evaluate the Ranking Accuracy (RA) at different posi-tions: 3, 5, 7 and 10.
 we produce train/test subsets by shifting a time window. We train using the past 30 days and we predict the comments on the next day, shifting for one day at a time, resulting in 10 independent folds. We also restrict our test set to those users who have commented at least once in the train-ing period. We tune the hyper-parameters of each method Figure 2: Comparison of the different methods on the Yahoo! News dataset. on an independent validation set, 10% of the training set, and we evaluate the statistical significance of the differences in performance by using Wilcoxon signed rank test [14]. testing days and we compute the average performance (Fig-ure 2). All algorithms perform better then random, i.e., RA &gt; 0%. LCE outperforms all other methods with statistically significant differences (Wilcoxon signed rank test, p &lt; 0 . 05). Imposing locality leads to better ranking accuracy in all po-sitions, however, the effect diminishes as we consider larger lists. The difference is statistically significant only for RA@3 and RA@5 (Wilcoxon signed rank test, p &lt; 0 . 05). This in-dicates that exploiting the manifold structure of the data allows the algorithm to push the relevant items towards the top of the list. As users are usually presented a short list of recommendations, making accurate recommendations on the top of the list is crucial for improving the satisfaction of the users.
The LCE model has three essential parameters: k , num-ber of latent variables, i.e., topics/communities;  X  , weight of the content versus the collaborative information; and  X  , controlling the smoothness of the solution. Figure 3 shows a typical behaviour of the algorithm for different values of the parameters. The results are averaged over 10 runs of all algorithms on one mailbox from the Enron dataset.
 The parameter k controls the complexity of the model. Small values of k , i.e., simple models under-fit whereas large values of k over-fit the data and lead to poor performance (Figure 3, left). Thus, one has to find a balance between the two that fits best the problem at hand. Furthermore, balancing the importance of the content versus the collab-orative information, i.e.,  X   X  0 . 5 tends to achieve the best performance. Figure 3 (middle) suggests that giving slightly more importance to the collaborative information (e.g.,  X   X  [0 . 2 , 0 . 5]) may be helpful. Finally, adding the Tikhonov reg-ularization helps; however, large values of  X  , oversimplify the model and decrease performance. Setting  X   X  (0 , 1) leads to stable and high performance (Figure 3, right).

The nearest neighbor graph ( A ) in LCE may be con-structed using the content or the collaborative information. The weights associated with the neighbors may be binary or the cosine similarity between the documents. We find that imposing the graph regularization based on the collaborative information leads to better performance (Figure 4). The bi-nary weighting scheme is more sensitive to the number of nearest neighbors ( p ) and works better for small p , while the cosine weighting scheme, as expected, is less sensitive to the choice of p .

The parameter  X  behaves similarly to  X  and setting  X  = 0 . 25 leads to higher performance (for brevity we do not re-port results for different values of  X  ).
In this section, we measure the CPU time required by the methods under different settings of the model complexity. All models are comparably fast at inference time, as they require only simple operations such as projections in the la-tent space or computing similarities. Hence, we only report the running times needed to train the models.

For this experiment, we consider one mailbox from the En-ron dataset (4K messages, 500 recipients, 18K unique terms) on which we perform 10 runs of each method under different values of the hyper-parameter k . The averaged CPU times are reported in Figure 5. Due to the long computation time required, we test the author-topic model up to k = 500 and fLDA up for k  X  { 10 , 25 , 50 } . In the case of UP-LSI k is bounded by 500 due to the rank of the matrix.

The content-based recommender (CB) takes least time for training as it only requires building the user profiles. Little time is also required by the UP-LSI method relying on a fast sparse SVD implementation. ATM and fLDA are computa-tionally most expensive; ATM requires between 3 and 35 hours to train, and fLDA requires between 5 and 46 hours to train even for small values of k . The LCE (with  X  = 0, i.e., without building kNN graph) and BPR-kNN have sim-ilar running times. The LCE with  X  = 0 . 25, on the other hand, is slightly slower than other methods, except for ATM and fLDA. LCE is reasonably fast and requires 25 minutes to train for the highest values of k , suggesting that frequent updates of the model are possible.
The Matlab implementations of the LCE are made pub-licly available at: https://github.com/msaveski/LCE . As Figure 4: Different ways of constructing the nearest neighbor graph in LCE. The results are averaged over 10 runs on Tana Jones X  mailbox. discussed in Section 5.4, the parameters may be set as:  X  = 0 . 5,  X  = 0 . 25, and  X  = 0 . 5, while the parameter k depends on the data and needs to be tuned. A Matlab implementa-tion of the Author-topic Model is publicly available as part of the Matlab Topic Modeling Toolbox at: http://psiexp. ss.uci.edu/research/programs_data/toolbox.htm . An R and C/C++ implementation of fLDA is available at: https: //github.com/beechung/Latent-Factor-Models . An im-plementation of BPR-kNN is available at: https://github. com/zenogantner/MyMediaLite . Finally, the Enron dataset is available at: https://www.cs.cmu.edu/~enron/ . In the experiments, we consider the 10 largest mailboxes owned by: Steven Kean, Vince Kaminski, Jeff Dasovich, Sally Beck, Tana Jones, Mark Haedicke, Sara Shackleton, Mark Taylor, John Lavorato, and Louise Kitchen. To overcome the item cold-start, in this work we have pro-posed LCE, a recommender system that combines content and collaborative information in a unified matrix factoriza-Figure 5: CPU times required to train each method, averaged over 10 runs on Tana Jones X  mailbox. tion framework. Our proposed algorithm outperforms exist-ing item-cold start recommenders. Interestingly, in case of rich content (e.g., news articles) imposing locality to exploit the manifold structure of the data improves the ranking ac-curacy in the top positions of the rankings which is crucial for improving the user satisfaction on news platforms. desired that the models are updated as new data arrive. In such context, time plays an important role in modeling user preferences. In this line of research, recently, Vaca et al. [29] introduced a temporal regularization for learning evolving representations in an NMF framework. To our knowledge none of the existing  X  X ime-aware X  approaches have been ap-plied to item cold-start recommendations. As a future work we consider extending our models to close this gap.
