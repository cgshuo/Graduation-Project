 In this paper, we consider the entity resolution(ER) problem, which is to identify objects referring to the same real-world entity. Prior work of ER involves expensive similarity comparison and clustering approaches. Additionally, the quality of entity resolution may be low due to insu fficient information. To address these problems, by adopting contex t information of data objects, we present a novel framework of entity resolution, context-based entity description (CED), to make context information help entity CEDs. During entity resolution, objects are only compared with CEDs to determine its corresponding entity. Additionally, we propose efficient algorithms for CED discovery and CED-based entity resolution. We experiment ally evaluated our CED-based ER algorithm on the real DBLP datasets, and the experimental results show that our algorithm can achieve both high precision and recall as well as out perform existing methods. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  Clustering, Information filtering. Algorithms. entity resolution, context-based, data cleaning Entity resolution (ER) is the process of identifying objects that refer to the same real-world entity. ER is one of the most important problems in data cleaning and arises in many applications. For example, in pub lications, two identical author names may represent different pe rsons and an author may have different name spellings; same address might have multiple entries due to different spelling; a person can have quite different descriptions on web. 
Because of its importance, ER has attracted general attention in the literatures. Most algorithms and frameworks of ER involve two steps. One is similarity comparison between objects [1], the other is clustering objects [5-7], in which objects in the same cluster represent the same en tity. Even though existing methods can perform ER effectively in many cases, these ER approaches have the following limitations.  X  Lack of consideration of updating. In many systems, the  X  Expensive Time Complexity. Computing the similarity  X  Order dependent. Since the similarity relationships are not  X  Sensitive to training data. For learning-based strategies of  X  Monotonicity assumption of similarity functions. The We use Example 1 to illustrate the limitations of prior work. Example 1. In Table 1, there are 9 objects o 1 -o publications of authors named  X  X e i Wang X . For the interests of space, we omit some other coauthors and conferences. Even though these objects are all named "Wei Wang", they do not refer to the same author. From the information obtained from the UNC , denoted as e 1 ; o 3 -o 5 represent the author in UNSW , denoted e . It is a natural way to measur e the similarity between object cases that are not coincident to the truth.  X  Sim ( o 1 , o 2 ) = 0 , Sim ( o 1 , o 6 ) = 1 , where o  X  Sim ( o 6 , o 7 ) = Sim ( o 6 , o 8 ) = Sim ( o 6 , o  X  Sim ( o 5 , o 7 ) = Sim ( o 5 , o 8 ) = Sim ( o
In this example we observe that, parts of the matching pairs have lower similarities than non-matching pairs. Additionally, pair-wise ER requires comparison between each object pair. Even though similarity join algorithms [8-9] can accelerate the processing in database, for new-coming object, such comparisons are still required. In contrast, if we have the rule-based entity descriptions for e 1 -e 3 shown in Table 2, as Sim(o, e) by counting the number of rules of e been matched by o , i.e., for object o 1 , &lt;coauthor&gt;Qi Zhang  X  o Zhang  X  X  X  &lt;coauthor&gt;Baile Shi of e 1 , so Sim ( o cost of comparison between rule and object is much smaller than the cost of object comparison. 
Therefore based on the feature descriptions of entities, the ER problem can be reduced to a pair-wise matching problem between object and entity descriptions. Since entity descriptions are highly extracted information from the objects representing the same entity, thus comparing objects with entity descriptions has a lower cost than object comparison; the result accuracy will also be better, since entity descriptions include more comprehensive information than object. Thus the pair-wise matching between object and entity will be more efficient, scalable and effective than pair-wise matching between objects. Moreover, the pair-wise matching between object and entity has advantages of both pair-wise matching and clustering, such as easy to implement; amenable to incremental and distributed processing; and accurate of result. Contributions We propose a novel tool, Context-based Entity Description (CED), to describe entity features based on contexts of objects representing identical entity and we formalize the ER problem based on CEDs (Sect. 2.1). Properties of entity description rules are also been discussed (Sect. 2.2). Based on the definition of entity description rules, we present an efficient ER algorithm by comparing objects with entity description rules (Sect. description rules are discovered. Based on these conditions, we develop an entity description rule discovery algorithm (Sect. 3.2). Extensive experiments verified the effectiveness and efficiency of our algorithms on real data sets (Sect. 4). As discussed in Section 1, cont ext information may help more Context-based Entity Description (CED). 
An instance of an entity is called an object . For structured data, an object is a record; for unstructured data, an object is a phrase; while for semi-structured data such as XML, an object is an element. 
The information related to an object is called the context of the context of an object is the text near the phrase. For XML data, the context of an object o can be defined as the set of elements satisfying, where dis(a, b) is the distance between elements a and b , LCA(a, b) is the least common ancestors of a and b and K is a predefined threshold. 
By the extraction of values and their position information from context, an object o can be represented as follows, 
In the description of an object o , each &lt;a i &gt;b i a feature element , where a i is a place constraint and b appear in value of the attribute author . 
Similarly, by discovering common feature elements of the feature elements. With the consideration of distinguishing from other entities, the conjunctions and negations will enhance the express power of the descripti on. Based on the discussion, we define the Context-based Entity Description (CED). 
Definition 1(CED) a CED r is defined recursively,  X  a feature element t is a CED  X  if r is a CED, then  X  r is a CED  X  if r 1 is a CED and r 2 is a CED, then r 1  X  r 2 is a CED  X  if r 1 and r 2 are CEDs, then r 1  X  r 2 is a CED Examples of CEDs on various da ta types are shown as follows. 
Example 2. We denote the entity of Wei Wang in Fudan as e the entity of Wei Wang in UNC as e 2 . The CEDs for e follows:  X  r 1 = &lt;author&gt; X  X aile Shi X   X  r 2 = &lt;author&gt; X  X i Zhang X   X   X  ( &lt;author&gt; X  X aile Shi X  ) r and r 2 are instances of CEDs on semi-structured or structured data and r 3 is an instance of CED on unstructured data. For a CED r , the length of r , denoted as |r| , is the number of feature elements in r , i.e. in Example 2, |r 1 |=|r 3 |=1, |r 2 |=2 . 
Based on the CED and feature-base d description of objects, the judgment of whether an object o matches a CED r is represented as a Boolean function match rule M(o, r) . M(o, r) returns true when o matches r , otherwise M(o, r) returns false . And the matching condition between o and r is defined recursively as following where t is an atom feature description,  X  if r=t , o matches r if and only if t  X  o ,  X  if r =  X  r 1 , o matches r if and only if o does not match r  X  if r = r 1  X  r 2 , o matches r if o matches r 1  X  if r = r 1  X  r 2 , o matches r if o matches r 1 Considering the difference of importance of attributes, different CEDs may have different weights. We further describe an entity e with a set R of CEDs and a cost function W, denoted by e=(R, W) , represents e . 
For simplicity, in the following of the paper, we use entity instead of entity description . The possibility of an object referring to an entity is computed with similarity function described as following. 
Definition 2(similarity function) For a given entity e=(R, W ) and an object o , the similarity function of o , e is defined as: 
Given two objects o 1 , o 2 , if they have identical or similar representations, they are an ambiguous object pair . Given a set O of objects, if  X  o i  X  O ,  X  o j  X  O satisfying o ambiguous object pair, we call that O is an ambiguous object set . entities can be distinguished directly, we focus on the ER problem object sets.

Definition 3 (CED-ER model) Given a set O of objects, a set E of entities and a similarity threshold  X  , a valid classification result C = CED-ER(R) satisfies that, for  X  object o i  X  O ,  X  if maximal { Sim(o, e j )} &lt;  X  then C(o i ) =  X  ,  X  Otherwise, C(o)=argmax { Sim(o, e j )}.
 matches o most and if Sim(o,e) is larger than present e , otherwise, o is not similar enough to any entity. As defined in Definition 1, each atom element in a CED is a bool variable and each CED is represented as a Boolean expression. Thus the problem of determining whether  X  object o , satisfying o matches a CED p is reduced to a satisfiable problem of the Boolean expression by truth assignment as the judgment of the atom feature element. 
For two CEDs p and q , we say p dominate s q (denoted as p  X  q ) then we say p strongly dominate s q , denoted as p &lt; q . 
Proposition 1 For two satisfiable CEDs p and q, if p dominates p=q  X  p X .

For two satisfiable CEDs p and q , we say p conflict s with q if p  X  q is unsatisfiable . 
Proposition 2 For two satisfiable CEDs p and q, if p conflicts with q, then  X  CED p X  satisfying that p =  X  q  X  p X .

We say a set R of CEDs satisfies the independency property if there is no conflict and no domination in R , which means R should satisfy:  X  there is no feature element t satisfying that  X  r i , r  X  there is no two CEDs r i , r j  X  R, r i  X  r j , satisfying r
We define an entity e=(R, W) as a logical valid entity if R satisfies the independency property . Given a set E of entities, E is a logical valid entity set if each entity is a logical valid entity and there is no domination between CEDs, which means E should satisfy:  X   X  e i  X  E , e i is a logical valid entity,  X   X  e i , e j  X  E , e i = ( R i , W i ), e j = ( R j In order to guarantee a good performance of ER problem, CED-ER enforces the following two conditions:  X  Each entity should be a logical valid entity.  X  An entity set should be a logical valid entity set. 
For the interest of space, the proofs of the following propositions are eliminated. 
Proposition 3 Given an entity e=(R, W)  X   X  r  X  R, there is a disjunctive normal form(DNF) r X  which is equivalent with r. 
Proposition 4  X  entity e=(R, W) can be converted to an equivalent (R X , W X ) with R X  as a DNF set. 
According to Proposition 4, for an entity e=(R, W) , we can logical OR(  X  ), thus p can be written as p = t 1  X  ...  X  t Therefore in the following paper, the CEDs we discussed all do not contain logical OR. 
Proposition 5 We have the following time complexity results.  X  The time complexity of checking whether there is a  X  The time complexity of checking whether there is a  X  The time complexity of logical valid judgment for an  X  For a set E of entities, the worst time complexity of In this section , we present U-CED algorithm of using CEDs to perform ER. The pseudo code of U-CED is shown in Algorithm 1. U-CED is a pair-wise matching strategy between object and entity based on CEDs. The algorith m has two phrases. First, for each object o i , we compute the similarity between o The function FindMatch ( o ) is to find entity e satisfying, Sim(o, e) = maximal{Sim(o,e j )} 1  X  j  X  |E|. Complexity We suppose the maximal length of a CED is l max maximal number of CEDs in an entity is R complexity of Algorithm 1 is O(| O |*| E |* l max * R max training data for CED discovery can be obtained by manually labeling on objects or by extracting from reliable data sources such as Wikipedia, personal homepages, databases and so on, by utilizing IR techniques. Before the introduction of CED discovery problem, we introduce some notati ons used in this subsection. The goal of CED discovery is to find valid CED sets. Therefore, we discuss what are valid CED sets. For a CED r of can only be matched by the objects representing e . We define this property of valid CED as uniqueness property . For a CED r , the number of objects in object set O which matches CED r is the  X  pCED r , | r | is no more than 2, besides, there is no  X  in r . A CED r is an nCED if r is in the form of t  X  X  X  t 1  X  X  X  t 2 t as feature elements. Based on above concepts, the valid entity set is defined as follows. 
Definition 4 (valid entity set) Given a set O of objects, a satisfies the following conditions: 1. E is a logical valid entity set; 2.  X  e = ( R , W )  X  E satisfies that  X  r  X  R is a valid CED of e 3 and condition 4 are explained as follows. however, when we can not discover enough feature elements to distinguish an entity from others, n CEDs have to be used. The reason of limiting the maximal length of CED is to guarantee that the feature elements we picked is representative enough. Actually, the longer the rule is, th e less representative the rule is. 
Condition 4 guarantees the correctness of the CEDs generated by Algorithm 3. Otherwise, th e uniqueness property of valid CED will be violated. classification C of O and a threshold  X  , the valid result of CED-discovery is an entity set E satisfying:  X  E is a valid entity set on O  X   X  e=(R, W)  X  E satisfies  X  pCED r  X  R, frq(r)  X   X 
We can see that, p CED is the core rules which describes entity features, however n CED is just a complementary of p CED. In order to generate p CEDs, finding the feature elements in p CEDs are the key problem of CED discovery. 
In order to discover useful feature elements for p CED, we define two metrics of relevance between feature element t and entity e . Based on the properties and inspired by TF/IDF model in IR, we use two parameters GF and ITF defined as follows to measure the relevance between feature element and entity. 
Given an object set O and an entity set E , for an entity e a feature element t , we have, where w(t, o i ) = 1 if and only if o i matches t , otherwise, w(t, o )=0 . where u(t, e i )=1 if and only if  X  o j , o j  X  O( e otherwise, u(t, e i )=0 . 
According to the definitions, GF(t, O(e)) is the frequency of t on O(e) . ITF(t) is the inverse frequency of t on entity set. Thus for O(e)) and ITF(t) are, the more relevant t is to e . Then we formalize the problem of generating Candidate Feature Element(CFE) s of p CED as follows. 
Definition 6 (CFE discovery model) Given a set O of objects, a classification C of O , a threshold  X  of GF, and a threshold of ITF,  X 
ITF , the valid result is a set T of CFEs satisfying:  X   X  feature element t  X  T , ITF( t )  X   X  ITF
Based on this model, we present the GenCFE algorithm of discovering CFEs for p CEDs in Algorithm 2. In lines 1-3, we initialize T and Cla , where T stores the feature element set of each entity at first, and Cla is a family with each set C compute the values of TF and GF and stores them in TF and GF . 10 Return ( T, GF, TF, I );
In Algorithm 2, the function Split(o) is to transform object o into a feature element set. Complexity analysis We suppose the maximal number of feature as a constant, thus the time comple xity of Algorithm 2 is linear to the size of data. Then we present GenCED, the CED generation algorithm with CFEs generated by GenCFE. Th e pseudo code is shown in Algorithm 3. In this algorithm for generating p CEDs, we consider how to combine CFEs in order to satisfy the uniqueness property of CEDs. If a CFE t already satisfies uniqueness property, t becomes a p CED directly; otherwise, we should identify whether valid combinations should be found in this way. 
As a complementary of p CEDs, once a p CED in the form of We use Example 3 to illustrate the relationship between n CEDs and p CEDs. 
Example 3. There are three entities e 1 , e 2 and e 3 share a CFE t . 
The p CEDs of e 1 -e 3 are as follows: 
Then the corresponding n CEDs of e 1 -e 3 are as follows: 
The flow of GenCED is as follows: In line1 we run GenCFE to the possible p CEDs and corresponding n CEDs containing t are checks whether there is a dominate relationship, the dominated rules are excluded from the results; in lines 7-11, n CEDs are stored in R . Complexity analysis We suppose the maximal length of n CEDs is l n , the maximal number of CFEs in an entity is l e , the maximal complexity of Algorithm 3 is O(| E |* l e 2 * gf max ) in the worst case. CED optimization strategy As mentioned before, there are two ways of obtaining CEDs. No matter the CEDs are obtained manually or by learning from training data, CEDs can never capture the full feature information of entities due to continuously new-coming objects. Taking author identification as an example, people may change their research areas or teams. Due to lack of new feature descriptions, running U-CED directly on the new-coming object set can hardly achieve good performance. However, the classification resu lt of U-CED can provide us new feature information of entities. Based on this classification, we can discover new entity descrip tion rules using GenCED, which leads to a better accuracy. Experimental Setting Our experiments we re run on a 2.67 GHz Intel(R) Core 2 processor with 4GB of RAM. The operation system is Microsoft Windows 7. Since author identification is one of the most difficult ER problems, and current ER approaches we discussed in section 1 result in the low accuracy and efficiency in author identification problem. Thus we evaluate our algorithm P-CED with CED optimization stra tegy involved on DBLP[11]. For simplicity, for a given name s, we use pub(s) to denote the set of effectiveness of our algorithms, we select 10 representative author names shown in Table 3 .

In our experiments, we randomly choose n i = maximal {1, 20%*#pub} publications from the test data as the training data. Measures Similar to [10, 5], we measure the accuracy of P-CED by precision, recall and f-score. 
As far as we know, GHOST[5] is the best author identification algorithm both in accuracy and efficiency. Therefore, we compare our algorithm and the comparison results are shown in Table 4, in which we use PC to denote P-CED for short. We can make the following observations from these results. We can see that GHOST shows a slight boast in precision. However, the result shows P-CED is more robust than GHOST. Besides, P-CED achieves a bette r performance of precision in average. P-CED offers considerably better recall than GHOST. As mentioned in [5], inadequate relationship may result in low similarity of two tuples, which may cause them to be separated into two clusters by GHOST. Howe ver, we can see this situation can hardly affect the recall result of P-CED. This shows how robust P-CED is again. We can see that P-CED can be executed significantly more efficiently than GHOST. The time complexity of GHOST is O(| O |*log| O |), while our algorithm is approximate linear to | O |. pick two names, "jian zhang" a nd "ping zhang". By the default result and "ping zhang" gets the best result. From Figure 1 we observe that, for both names, the accuracy result can reach a high value even when the size of training data is small. With the growth of the training data size, the recall increases gradually, while precisions are insensitive to the training data size. In Figure 2, we test the impact of number of tuples on efficiency. In order to vary the values of numbers of publications of each name, we pick 14 names with publication numbers varying from approximately linear to the number of objects. This result is in accordance with our time complexity analysis in section 2. 
From the experimental results, we can draw following conclusions. 
P-CED is flexible than GHOST. P-CED neither care about whether the authors having the same name unlikely have similar research area nor assume authors seldom change their research teams or labs. 
P-CED is insensitive to the size of the training data. Due to the contribution of new CEDs been discovered, P-CE D only requires small, P-CED can get a high accuracy. 
P-CED has both good scalability and high efficiency. The experiments show that with the increase of size of data, the runtime of PC increase approximately linearly. Current ER approaches mostly based on object comparison and comparison between objects on ER, and developed a strategy based on comparison between object and entity. We present a context-based entity description rule (CED) to describe the features of entity. Thus the ER pr oblem is reduced to that for each object, to identify the entity which is most similar with the object. We develop a CED-based algorithm for ER problem and present a CED discovery strategy. We experimentally evaluated our algorithm on real data set, and the experimental results show that our algorithm can achieve a good performance in accuracy and outperforms existing algorithm both in efficiency and accuracy. Thanks for the help on experiments by Jianyong Wang in Tsinghua University. [1] N. Koudas, S. Sarawagi, and D. Srivastava: Record linkage: [2] W. W. Cohen: Integration of heterogeneous databases [3] S. Chaudhuri, B.-C. Chen, V. Ganti, and R. Kaushik: [4] A. Arasu, S. Chaudhuri, and R. Kaushik: Learning string [5] Xiaoming Fan, Jianyong Wang, Xu Pu, Lizhu Zhou, Bing [6] Bansal, N., Blum, A., Chawla, S.: Correlation clustering. In: [7] Chaudhuri,S., Ganjam, K., Gan ti, V., Motwani, R.: Robust [8] Chuan Xiao, Wei Wang, Xuemin Lin, Jeffrey Xu Yu: [9] Chuan Xiao, Wei Wang, Xuemin Lin, Haichuan Shang: Top-[10] Xiaoxin Yin, Jiawei Han, Philip S. Yu: Object Distinction: [11] http://dblp.uni-trier.de/
