 This poster paper summarizes our solution for mining max frequent generalized itemsets (g-itemsets), a compact repre-sentation for frequent patterns in the generalized environ-ment.
 Categories and Subject Descriptors: H.m Information Systems: Miscellaneous General Terms: Algorithms.
 Keywords: data mining, max frequent itemsets.
Mining generalized frequent patterns is a well-motivated existing problem [2, 3]. Here, generalized itemsets (or pat-terns) employ a taxonomy of items, rather than a flat list of items. This produces more natural frequent itemsets such as (meat, milk) instead of (beef, milk), (chicken, milk), etc.
We address the problem of mining max generalized fre-quent itemsets: those without frequent supersets. This is an extremely compact representation of all generalized fre-quent itemsets. This compact representation solves a stan-dard dilemma in mining patterns: with a small threshold for frequency, the user is overwhelmed by the hordes of identi-fied patterns; but with a large threshold for frequency, some interesting patterns fail to be identified.
The set of all items form a taxonomy T , which is a tree structure. An example is shown in Figure 1(a). Think of leaf items A as apple , B as banana , and C as candy . And think of non-leaf items W as fruit and Y as food . A transactional database D is a list of transactions, each of which containing some items from the leaf level of T .

Definition 1. Given a taxonomy T , a generalized item-set , or g-itemset in short, is a non-empty set of items from T , where no two of the items have an ancestor-descendant relationship in T .

Hence, the set { apple, fruit } is not considered a g-itemset since it is not compact. (The equivalent compact itemset is { apple } .) Given an item i  X  X  and a g-itemset S , we say i belongs to S with respect to T , denoted as i  X  T S , if  X  j  X  S such that i = j or i is an ancestor of j in T . Intuitively, any trans-action that contains apple is considered to contain fruit . Therefore fruit  X  T { apple } .

Given two g-itemsets S 1 and S 2 , we say S 1 is a subset of S 2 with respect to T , denoted as S 1  X  T S 2 , if  X  i  X  S i  X 
T S 2 . We also have the proper subset notation (  X  T ) with its obvious meaning.

The support of a g-itemset S is the percentage of trans-actions in D that are supersets of S with respect to T . A g-itemset is frequent if its support is above a given threshold minsupport .

Definition 2. Given a taxonomy T , a transactional database D , and a threshold minsupport , a max frequent g-itemset is a frequent g-itemset without a frequent proper superset with respect to T .

We are interested in efficiently mining the set of all max frequent g-itemsets.
The classification-based solution has two components. Sec-tion 3.1 defines a conceptual classification tree. Section 3.2 describes the algorithm MFGI class which dynamically gen-erates the needed part of the tree, while pruning entire branches using three pruning techniques.
This section provides a conceptual classification tree. Ev-ery g-itemset corresponds to exactly one leaf node in the tree. An index node also corresponds to a g-itemset, which is a superset of all g-itemsets in the sub-tree. An example of a classification tree is shown in Figure 1(b).
In particular, every node in our classification tree has three components, ( S 1 )( S 2 )( S 3 ). Any g-itemset in the sub-tree must-literally-have-all-of the g-items in S 1 , must-have-part-or-all-of the g-items in S 2 , and may-have-part-or-all-of the g-items in S 3 . For instance, let the root of the taxon-omy be Y . The root of the classification tree is ()( Y )(). Any g-itemset in the subtree must contain some g-items in the sub-taxonomy of Y .

The children of the classification tree node will be: ()( W )( C ), ( C )()() and ( Y )()(). The first sub-tree corre-sponds to the g-itemsets that contain some g-item in the sub-taxonomy of W . The second sub-tree corresponds to the g-itemsets that contain some g-item in the sub-taxonomy of C but not any g-item in the sub-taxonomy of W . And ( Y )()() is a leaf node in the classification tree, which corre-sponds to a single g-itemset { Y } .
The algorithm MFGI class dynamically generates the classification tree as defined in Section 3.1, with pruning techniques to prune unnecessary branches. This section fo-cus on the pruning techniques.

Every index node in the classification tree has a corre-sponding g-itemset , which is the smallest superset of all g-itemsets in the sub-tree. For example, the corresponding g-itemset for ( W )()( C ) is WC , and the corresponding g-itemset for ()( Y )() is ABC . As an example, at node ()( Y )(), we check the frequency of W and C . Suppose W is not frequent, we know no g-itemset that contains W or descendants of W in T can be frequent. So to generate the child nodes, we should imagine W does not exist, and Y has a single child C in T . Thus only two child nodes should be generated: ( C )()() and ( Y )()().
There is no existing algorithm to directly compare with our new algorithm MFGI class , simply because this is the first work that mines max frequent g-itemsets. We instead compare with BASIC [2]. Note that BASIC was proposed to find all frequent g-itemsets. So we give MFGI class the additional handicap of producing all frequent g-itemsets from the set of identified max frequent g-itemsets.
The algorithms were implemented in Sun Java 1.5.0, and executed on a Sun Blade 1500 with 1 GB of memory running SunOS 5.9. The experimental data were generated using the widely used Quest Synthetic Generator with the following parameters. The taxonomy has 1000 g-items. The database contains 10,000 transactions with average size being 5.
We choose to compare with BASIC because it has been widely used as a baseline algorithm and it has a clear, stan-dard implementation whose speed will not be greatly bi-ased by the implementation. But since Srikant and Agrawal also presented Cumulate and EstMerge [2] and reported that they are 2 to 5 times faster than BASIC, in Figure 2 we in-clude a band of a factor of 5 in the speed of BASIC (the  X  X revious best X  line was manually generated by taking 1/5 of the execution time of BASIC).
Figure 2 demonstrates that MFGI class is exponentially faster than BASIC as the number of levels of the taxonomy increases. The huge speedup over BASIC that we achieve especially for taxonomy levels of 4 and above are far beyond what is achieved by other algorithms for mining frequent g-itemsets. [1] R. J. Bayardo Jr. Efficiently Mining Long Patterns [2] R. Srikant and R. Agrawal. Mining Generalized [3] K. Sriphaew and T. Theeramunkong. Fast Algorithms
