 We need better ways to query large linked data collections such as DBpedia. Using the SPARQL query language re-quires not only mastering its syntax but also understanding the RDF data model, large ontology vocabularies and URIs for denoting entities. Natural language interface systems ad-dress the problem, but are still subjects of research. We de-scribe a compromise in which non-experts specify a graphical query  X  X keleton X  and annotate it with freely chosen words, phrases and entity names. The combination reduces ambi-guity and allows the generation of an interpretation that can be translated into SPARQL. Key research contributions are the robust methods that combine statistical association and semantic similarity to map user terms to the most appropri-ate classes and properties in the underlying ontology. H.3 [ Information Systems ]: Information Storage and Re-trieval; H.5.2 [ Information Interfaces and Presenta-tion ]: User Interfaces Algorithms, Languages schema-free query, question answering, ontology mapping DBpedia [2], an RDF representation of information extracted from Wikipedia, is the key Linked Open Data (LOD) in-tegrating component. It provides an open domain ontol-ogy in which each ontology class, property and instance is referenced by a unique URI that is trivially mapped to a Wikipedia article, faciliating linking data across domains and systems such as Freebase. and Facebook X  X  Open Graph.
However, it is still difficult for typical Web users and even experts to query DBpedia with the standard RDF query language SPARQL. Since Wikipedia infoboxes are designed by different communities and edited by individuals, infobox names and attributes are largely heterogeneous. This het-erogeneity is also a problem for the DBpedia ontology where terms with similar meaning are used in different contexts. For example, the property locatedInArea is used for moun-tains and location for companies. A second challenge comes from the large number of DBpedia vocabulary terms: cur-rently 320 classes, 1,650 properties and several million in-stances. It is infeasible for users to be familiar with so many artificial terms. Finally, using SPARQL also requires mas-tering its complex syntax and semantics.

Allowing users to express queires in their own natural lan-guages could help. Providing Natural Language Interfaces (NLIs) to structured data has been studied for more than four decades. Work in the 1970s and 1980s focused on de-veloping NLIs to Databases (NLIDB) [1] and more recently on access to RDF [7]. The advantage of NLIs is that they do not require users to learn artificial syntaxes and vocabu-laries. However, there are two major obstacles for NLI sys-tems to be widely adopted. First, current NLP techniques are still brittle when dealing with the ambiguity and com-plexity of Natural Language (NL) in general [1, 3]. Second, it requires extensive domain knowledge for interpreting NL questions. Domain knowledge typically consists of a lexi-con , which maps user vocabulary to ontology vocabulary or logical expressions in NLIDBs, a language model with statis-tical information for parsing and sense disambiguation, and a world model specifying the relationships between the vo-cabulary terms such as subclass and the constraints on the types of properties arguments. Developing these can be very expensive, both for broad or open domains like DBpedia or a narrow domain like tax law.

We introduce a Schema-Free Query (SFQ) interface in which users specify a graphical X  X keleton X  X or a query and an-notate it with freely chosen words, phrases and entity names. An example is shown in Figure 1. The SFQ interface is a compromise between SPARQL and NLI. By asking users to specify semantic relations between entities in a query and the types of the entities, we avoid the difficult problem of relation extraction [3] from NL sentences. While the full ex-pressive power of human language is not supported, people can use familiar vocabulary terms in composing a query. Figure 1: A Schema-Free Query for  X  X here was the a uthor of the Adventures of Tom Sawyer born? X .
We use fully automatic approaches to obtain necessary d omain knowledge for interpreting SFQs. Instead of a man-ually maintained lexicon, we employ a computational seman-tic similarity measure for the purpose of locating candidate ontology terms for user input terms. Semantic similarity measures enable our system to have a broader linguistic cov-erage than that offered by synonym expansion by recogniz-ing non-synonymous terms that have very similar meaning. For example, the properties author of and college are good candidates for the user terms  X  X rote X  and  X  X raduated from X , respectively. Semantic similarity measures can be learned from a domain-dependent large corpus.

We know birds can fly but trees cannot and that a database table is not kitchen table. Such knowledge is essential for human language understanding. We refer to this as Concept-level Association Knowledge (CAK). Domain and range def-initions for properties in ontologies, argument constraint definitions of predicates in logic systems and schemata in databases all belong to this knowledge. However, manu-ally defining this knowledge for broad or open domains is a tedious task at best. In this paper, we introduce an ap-proach to automatically learn this knowledge from semanti-cally marked-up instance data.

With the learned CAK and semantic similarity measures, we present a straightforward but novel approach that dis-ambiguates a SFQ and maps it to a corresponding SPARQL query to produce an answer. Our approach has a unique feature that it resolves mappings only using information in concept space, i.e., at the schema level. This makes it much more scalable than those that directly search into both in-stance and concept space for possible matches since concept space is much smaller than instance space. We learn Concept-level Association Knowledge statistically from instance data (the  X  X BOX X  of RDF triples) and thus avoid expensive human labor in building the knowledge man-ually. However, instead of producing  X  X ight X  assertions such as those used in RDF property domain and range defini-tions, we generate the degree of associations . Classical logics that make either true or false assertions are less suited in an open-domain scenario, especially those created from hetero-geneous data sources. For example, what is the range of the property author ? Both Writer and Artist are not appropri-ate because the object of author could be something other than Writer or Artist , e.g., Scientist . Specifying Person for the range is too general to be useful. Thus we use no a fixed range for the author property but a weighted set of classes capturing the likelihood of each being the type of an object.
Computing statistical association requires information on the number of occurrences of single terms and the num-ber of co-occurrences of multiple terms in the universe. For DBpedia, the universe is represented by the dataset Ontol-ogy Infobox Properties , which contains RDF triples describ-ing all relations between instances, and the dataset Ontol-ogy Infobox Types , which provides all type definitions for the instances. Figure 2 shows how we count term occur-rences and co-occurrences by observing one relation in the universe. On the figure X  X  left, is an RDF triple describing a relation and the type definitions for its subject and ob-ject and on the right are the resulting occurrences and co-occurrences of terms. We consider direction in counting co-occurrences between classes and properties. The directed co-Figure 2: This example shows how we count term ( co-)occurrences in an RDF knowledge base. Figure 3: The top-25 most associated proper-ties/classes from DBpedia X  X  CAK or five examples. occurrences are indicated by the arrow character  X  between two terms, for example Book  X  author . The occurrences of directed classes (e.g. Book  X  ) are counted separately from the occurrences of undirected classes (e.g. Book ).
After both occurrence and co-occurrence counts are avail-able, we employ a statistical measure, Pointwise Mutual In-formation (PMI) [4, 6], to compute two types of associations: (i) directed association between classes and properties and (ii) undirected association between two classes.

Figure 3 shows examples of top-25 lists of most associ-ated properties/classes for five terms along with their PMI values. Examples 1 to 4 present, in order, outgoing and in-coming properties for two classes Writer and Book . Note that datatype properties are indicated by starting an initial  X  X  X  to distinguish them from object properties. Example 5 shows the classes that could be in domain or range of the property author . Terms ending and starting with  X  are potential domain and range classes, respectively.
In the first four examples, top properties are the most in-formative, such as @pseudonym and notableWork for Writer and @isbn and @numberOfPages for Book . More lowly ranked properties tend to be less related to the classes. Example 2 shows that both a uthor and writer can be incoming proper-ties of Writer though author is more related. On the other hand, the third example shows that only author , not writer , can describe Book . In the DBpedia ontology, author and writer are used for different contexts and author is used for books. The reason the class Writer has both author and writer as incoming properties is that writers can write some-thing other than books, such as films and songs. Example 5 illustrates the DBpedia ontology X  X  heterogeneity via the property author , which is loaded with multiple senses (e.g., book author, Web site creator). Noisy data in DBpedia can result in some abnormal associations, as shown in example 4, where author can be an incoming property of Book . For-tunately, the degree of these associations is typically low. In this section, we give the main steps in mapping terms in a SFQ to DBpedia ontology terms. The approach focuses on vocabulary or schema mapping, which is done without involving entities. For each SFQ concept or relation, we generate a list of the k most semantically similar candidate ontology classes or properties. (See [5] for our semantic similarity computa-tion). A minimum similarity threshold, currently experi-mentally set at 0.1, is used to guarantee that all the terms have at least some similarity. For a relation that has very general meaning, such as  X  X n X ,  X  X as X  and  X  X rom X , we generate the k 2 on tology properties most semantically similar to each of its connected concepts because the semantics of a default relation is often conveyed in one of its connected concepts. We also generate k 4 on tology properties that are most seman-tically similar to the words locate and own on the behalf of  X  X n X  and  X  X as X , respectively. Finally we assemble these into a list of 3 2 k on tology properties. The selection of a value for k is a compromise between the translation performance and the allowed computation time and depends on the degree of heterogeneity in the underlying ontologies and the fitness of the semantic similarity measure.

In the example in Figure 4, candidate lists are generated for the five user terms in the SFQ, which asks Which author wrote the book Tom Sawyer and where was he born? . Can-didate terms are ranked by their similarity scores, which are displayed to the right of the terms. Each combination of ontology terms, with one term coming from each candidate list, is a potential query interpretation, but some are reasonable and others not. Disambiguation here means choosing the most reasonable interpretations from a set of candidates.

An intuitive measure of reasonableness for an interpreta-tion is the degree to which its ontology terms associate in the way that their corresponding user terms connect in the SFQ . For example, since  X  X lace X  is connected by  X  X orn in X  in Fig-ure 4, their corresponding ontology terms can be expected to have good association. Therefore, the combination of Place and birthPlace makes much more sense than that of Place and @cylinderBore because CAK tells us that a strong asso-ciation holds between Place and birthPlace but not @cylin-derBore . As you can see, we use the degree of association from CAK to measure reasonableness. As another example, C AK data shows that both the combinations of Writer + writer and Writer + author are reasonable interpretations of the SFQ connection  X  X uthor  X  wrote X . However, since only author not writer has a strong association with the class Book , the combination of Writer , author and Book produces a much better interpretation than that of Writer , writer and Book for the joint SFQ connection  X  X uthor  X  wrote  X  Book X .

We select two types of connections in a SFQ for comput-ing the overall association of an interpretation. They are the connections between concepts and their relations (e.g.,  X  X uthor X  and  X  X rote X ) and the connections between direct connected concepts (e.g., X  X uthor X  X nd X  X ook X ). We exclude indirect connections (e.g., between  X  X ook X  and  X  X orn in X  or between X  X ook X  X nd X  X lace X ) because they do not necessarily entail good associations.

If candidate ontology terms contained all the substitutable terms, we could rely solely on their associations for disam-biguation. However, in practice many other related terms are also included and therefore the similarity of candidate ontology terms to the user terms is an important feature to identify correct interpretations. We experimentally found that by simply weighting their associations by their similar-ities we obtained a better disambiguation algorithm.
To formalize our approach, suppose the query graph G q has m edges and n nodes. Each concept or relation x i in G q has a corresponding set of candidate ontology terms Y i Our interpretation space H is the Cartesian product over the sets Y 1 , ..., Y m + n .
 Each interpretation h  X  H also describes a function h ( x ) that maps x i to y i for i  X  X  1 , ..., m + n } .

We define a fitness function  X  ( h, G ) that produces the fitness score of an interpretation h on a query graph or sub-graph G . We seek the interpretation h  X   X  H that maximizes the fitness on the query graph G q , which is computed as the summation of the fitness on each link L i in G q , i from 1 to m . More specifically, where link L i is a tuple with three elements: subject concept s , relation r i and object concept o i . Formula 2 achieves joint disambiguation b ecause the joint concepts of different links should be mapped to the same ontology class.
 X  ( h, L i ) is the linear combination of three pairwise asso-ciations: the directed association from subject class h ( s property h ( r i ), the directed association from property h ( r to object class h ( o i ), and the undirected association between subject class h ( s i ) and object class h ( o i ), all weighted by se-mantic similarities between ontology terms and their corre-sponding user terms. We need resolve the direction of h ( r before we compute  X  ( h, L i ) because h ( r i ) and r i may have opposite directions. For approach details, please refer to [5].
If each candidate list contains k semantically similar terms, the computation complexity of a straightforward disambigua-tion algorithm is O ( k n + m ) because the total number of in-terpretations is k n + m . We can significantly reduce this com-plexity by exploiting locality. The optimal mapping choice of a property can be determined locally when the two classes it links are fixed. Thus we need only iterate on all combina-tions of classes, which have a total number k n . Moreover, we can iterate in a way such that the next combination dif-fers from current combination only on one class with other classes remaining unchanged. This enables us to re-compute only for the links in which the changed class participates and reuse previous computations on other links. The average number of links in which a class participates is 2 m n . On the other hand, finding the property that maximizes the fitness of a link requires going through all k choices in the candidate list, resulting in O ( k ) running time. Put them together, the total computation complexity can be reduced to O ( k n m n Further optimization can be achieved by decomposing the graph into subgraphs. After users terms ar e disambiguated and mapped to ap-propriate ontology terms, translating a SFQ to SPARQL is straightforward.
 Figure 5 shows the SPARQL query pro-duced from the SFQ in Figure 4. Classes are used to type the instances, such as ?x a dbo:Writer , and properties used to connect instances as in ?0 dbo:author ?x . The bif:contains property is a built-in text search function which find literals containing specified text. The named entities in the SFQ can be disambiguated by the constraints in the SPARQL query. In this example, Tom Sawyer has two constraints: it is in the label of some book and is written by some writer. To evaluate ontology-based Question Answering systems, the 2011 Workshop on Question Answering over Linked Data [8] provided 50 training and 50 test questions over DBpedia 3.6 along with their ground truth answers. Of the 50 test questions, we selected 33 that could be answered using only the DBpedia ontology, i.e., without the additional assertions in the YAGO ontology.

Three computer science graduate students who were unfa-miliar with DBpedia and its ontology independently trans-lated the 33 test questions into SFQs. We first familiarized the subjects with the SFQ concept and its rules and then trained them with ten questions from the training dataset. Finally, we asked each subject to draw SFQs for the 33 test questions. None of the subjects had difficulty in construct-ing the SFQs and all finished within half an hour.
Three versions of 33 SFQs were given to our system which automatically translated them into SPARQL queries. The queries were then run on public SPARQL endpoints to pro-duce answers. The answer of each query was evaluated for standard precision and recall. The average precision and recall of 33 queries on three versions were 0.754 and 0.832, respectively. The average time to translate a SFQ was only two seconds. Please refer to [5] for evaluation details. The schema-free structured query approach allows people to query the DBpedia dataset without mastering SPARQL or acquiring detailed knowledge of the classes, properties and individuals in the underlying ontologies and the URIs that denote them. Our system uses statistical data about lexical semantics and RDF datasets to generate plausible SPARQL queries that are semantically close to schema-free queries. An evaluation using an independently developed set of natural language queries showed that non-expert users were able to write effective SFQ queries for them with good accuracy. This research was partially supported by MURI award FA9550-08-1-0265 from the Air Force Office of Scientific Research. [1] I. Androutsopoulos, G. Ritchie, and P. Thanisch. [2] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, [3] R. Bunescu and R. Mooney. A shortest path [4] K. Church and P. Hanks. Word association norms, [5] L. Han, T. Finin, and A. Joshi. Gorelations: Towards [6] L. Han, T. Finin, P. McNamee, A. Joshi, and Y. Yesha. [7] V. Lopez, V. Uren, M. Sabou, and E. Motta. Cross [8] 1st workshop on question answering over linked data.
