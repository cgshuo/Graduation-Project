 MIGUEL LEZCANO and JUGAL KALITA , University of Colorado In an increasingly fast-paced and digitally connected world, being able to input text and input it quickly is important to all users. Many efficient physical keyboards have been designed and developed for standard Roman-alphabet based languages although in practice, they have been discarded in favor of the familiar QWERTY keyboard. Thus, the standard physical keyboard that comes with computers around the world is almost always the QWERTY keyboard, which has its origins in the 1800s. Noyes [1983] and Yamada [1980] provide detailed developmental histories of English physical keyboards and of the QWERTY keyboard in particular.

The QWERTY keyboard is unsuitable for Brahmic scripts, which are the modern descendants of the Brahmi script [Coulmas 1991], used widely in countries of the Indian sub-continent and other parts of East Asia. This is evident in India where there are several different extant Brahmic scripts 1 [Salomon 1998] used by all the major languages belonging to Indo-European, Dravidian, and other families [Wagner et al. 1999, 24]. The scripts include Devanagari, Eastern Nagari, Gujarati, Gurmukhi, Telugu, Kannada, Malayalam, and Tamil. Scripts for languages such as Tibetan (Tibeto-Burman, Tibet), Burmese (Tibeto-Burman, Myanmar), Sinhala (Indo-European, Sri Lanka), Balinese and Javanese (Austronesian, Indonesia), Thai (Austro-Thai, Thailand), Khmer and Lao (Laos, both Mon-Khmer) belong to the same script class, which have similar, and sometimes additional, issues. There is no easy and widely acceptable text entry method for most of these languages, especially those in the Indian subcontinent. This is true even in the case of Hindi, which is used natively by between 182 and 366 million people, and Bengali, which is used by between 181 and 207 million people 2 . These two languages are the fourth and sixth most commonly spoken languages in the world, surpassing languages such as Russian (between 144 and 167 million), German (between 90 and 100 million), and French (between 68 and 78 million).

Most widely spoken Indic languages have had typewriters for some time, but the typewriters have been used almost exclusively for press and bureaucratic needs. However, records of how these typewriter k eyboards were created are very difficult to find. In addition, such typewriters, and hence the associated keyboards, never achieved any significant level of usage outside printing presses and government offices. While researchers have designed physical k eyboards for Brahmic scripts for use with computers [Joshi et al. 2004], usually the efficiency of input has not been a major concern in these designs, and such keyboards are typically unavailable outside of a few research labs. In a country like India, where only 4% [Kachru 1986] to 10% the population can perform adequately in English, almost everyone else relies on their native language for everyday activities. However, the small percentage of people who can perform well in English control most professions and these are the only people who have frequent and reliable access to digi tal technologies that require reading text and inputting text. Thus, one of the problems that has made the use of computers and other digital devices in their native language very difficult is the lack of adequate text entry methods. This perpetuates a severe but unacknowledged form of digital divide (e.g., [Joshi et al. 2004; Ko and Yoshiki 2005; Hosken and Lyons 2003]) for a large segment of the world X  X  population. Typically, computer or typewriter text entry in Indian languages using physical keyboards is done by professional typists who have had months of training or by dedicated individuals. Typing is almost impossible for most common folk, which is in stark contrast with America and Western Europe where the vast majority of people are able to type. The recent introduction of mobile phones has spread across the socio-economic layers of India X  X  population. While this development has greatly increased the access that many people have to information, it has also increased the need for soft keyboards in the native languages. Soft keyboards allow a user to input text without the use of a physical keyboard. Kolsch and Turk [2002] define a soft keyboard as a typing device with no physical manifestation. Soft keyboards are versatile because they allow data to be input through mouse clicks or by touching an onscreen keyboard. With the recent surge in popularity of touchscreen technology, well-designed soft keyboards are becoming even more important everywhere. The market for English language soft keyboards is already dominated by the familiar and ubiquitous QWERTY layout, even though it is not the most efficient keyboard ever made, and many more efficient soft keyboards have been designed. However, languages for which there are no entrenched keyboard designs (and in fact no soft keyboards for Brahmic languages have been made beyond the basic alphabetic ones and QWERTY-based designs, which have not been optimized for text input performance), designing and developing soft keyboards for the emerging and rapidly expanding touchscreen market may be very helpful in reducing the almost complete inaccessibility of digital devices, including computers, for those who natively speak Brahmic languages. Some preliminary work has been done in this field, but there is still much room for improvement. Ghosh et al. [2011] has done work on Bengali input systems for mobile devices, and Jalihal [2010] has proposed a Hindi input system that maps characters to the standard nine buttons of a cell phone keypad.
Brahmic scripts have more characters and ligatures than what can usably fit on a standard keyboard. A soft keyboard allows any language to have custom layouts based on the frequency of character and ligature use within that language. The development and spread of soft keyboards would allow the use of an easier to learn and more efficient keyboard. Web se rvice providers such as Google developed soft keyboards for Brahmic scripts, but these are simply an alphabetical listing of letters, and thus not optimized.

In this article, we discuss the design and development of optimized soft keyboards for Indian languages. The article is organized as follows. Section 2 introduces Brahmic scripts. Section 3 discusses related research in soft keyboard design. Section 4 presents an initial keyboard design for an Indic language in which we attempted to provide an exhaustive coverage of all possible characters and character combinations. Section 5 describes the development of various keyboard layouts for an exemplar language using genetic algorithms. We use Assamese as an exemplar language for our discussions. This section focuses on the optimization techniques implemented to improve the input speeds of soft keyboards for the exemplar language. Section 6 describes the development of similar keyboards for several other languages using techniques discussed in Section 5. These languages include Bengali, Hindi, Gujarati, Punjabi (with Gurmukhi script), Oriya, Telugu, and Kannada. Section 7 provides information regarding the development of soft keyboards for mobile devices. Section 8 discusses the use of multi-objective Pareto optimization for soft keyboard generation. Section 9 concludes the article. According to Coulmas [1991, 184], the Brahmi script and Brahmi-derived (Brahmic) scripts have the following characteristics.  X  Word initial vowels are written explicitly in these scripts.  X  Every basic consonant when written alone is assumed to have the inherent vowel @ (almost like schwa in English) following it.  X  Non-initial vowels are represented by modifying the respective consonant with a diacritic mark.  X  Consonant clusters are represented by ligatures, all but the last consonant elements of which lose their inherent vowel.  X  The inherent vowel @ can be muted by a special diacritic called hasanta (also called halant ).

There are two main classes of Brahmic scri pts: Northern and Southern. Each group encompasses several scripts. All these scripts are built on the same principles and some are almost isomorphic, but they are not similar enough to enable one who has learned one to read the others [Coulmas 1991, 186].

The Devanagari script (see Naik [1971] for a book on typography of Devanagari) is the most widely used script in India since it is used for Hindi, the main official language of modern India. It is used by other Indo-European languages such as Nepali, Marwari, Kumaoni, and Marathi. It is also used by many non-Indo-European languages such as Mudari-Ho (Austo-Asiatic), Gondi (Dravidian), and Bodo (Sino-Tibetan). Another important Brahmic script is Assamese-Bengali otherwise known as Eastern Nagari, which is used by Bengali (about 200 million native speakers), Assamese (15 million native speakers and more than 30 million total number of speakers), Meitei (1.5 million native speak ers), and Bishnupriya Manipuri (0.5 million native speakers) speakers as well as speakers of other Tibeto-Burman languages. There is an almost one-to-one isomorphism between the Devanagari script and the Eastern Nagari script. million people.

The Assamese variant of the Eastern Nagari script has 11 vowels, 37 consonants, several special signs, and a few punctuation marks. The Assamese variant is used by Assamese, Bishnupriya Manipuri, and Karbi and has been used in the past by Bodo, Khasi, and other languages. In contrast, the Devanagari script has 13 vowels and 35 consonants [Coulmas 1991, 186]. Each Brahmic script, however, has a standard matrix grouping for its basic characters and a standard sort order used in text books and dictionaries. A matrix grouping is an organization of characters into a number of rows based on certain properties in which each row contains a more or less fixed number of characters. The number of characters in a script is considered subjective and thus, in our work, to determine the number of characters for a specific language, we use the expertise of native speakers as well as the usage of characters in language-specific corpora.

In all Brahmic scripts, consonant clusters are represented by ligatures. The ligatures have to be learned separately because in many cases their sound value is hard to infer based on the graphical composition of the complex letter sign [Coulmas 1991, 188]. From another perspective, the same idea can be expressed in the following way: sometimes a glyph substitution occurs in the construction of ligatures, and the consonant cluster ligature may have little visual similarity with the constituent consonant glyphs. Ligatures are often formed by adding one or more distinct strokes (derived from the constants that lose their inherent vowel) to the letter that keeps its inherent vowel, but there are many exceptions to this general scheme.

In the Eastern Nagari script, there are at least 240 ligatures. We have counted a total of at least 315 unique character forms i n the Assamese variant of Eastern Nagari. If all consonant-medial vowel and ligature-medial vowel combinations were provided for direct input, we would need approximate 3,000 character forms or combinations (See the end of Section 4 for an approximate calculation). This is the largest number of potential character forms or combinations a soft keyboard may need to provide. The minimum set of characters needed contains the basic vowels (11 in number), consonants (41 in number as given in the standard matrix learned by elementary school children), vowel diacritics (11, including the single starting quote, which is frequently used as a vowel marker), the dari or sentence-ending period, and the hasanta diacritic used to form ligatures; this m akes for a total of 65 character forms, even without the 10 digits. In practice, a soft keyboard may want to provide some number of character forms in between the two extremes. Some ligatures occur with a higher frequency than individual characters. Examples include , , , , ,and . In fact, our frequency analysis shows that almost 120 ligatures occur more often than the vowel and that 130 of them ouccur more often than the vowels and . It is possible that adding several of the most common ligatures would improve the performance of a typist by decreasin g the number of extra characters required when typing ligatures. How many ligatures should be provided in a soft keyboard and in what configuration remains an open question. Other Indic languages face similar issues.
 There is still a lot of confusion among font designers for Indian languages that use Brahmic scripts. Most extant Brahmic fonts in India use font encodings that are not standard. In other words, the font designers create their own numerical codes for characters that need to be printed, ignoring the two standard encodings: ISCII and Unicode. Indian Script Code for Information Interchange 6 in 1991 with the aim of providing a unified scheme for encoding the Indian languages using Brahmic scripts. The Unicode encoding for Indian languages using Brahmic fonts is derived from the ISCII encoding. Both ISCII and Unicode encodings provide only the basic characters and require an extra layer of processing to produce the myriad surface forms that are actually printed. Recently Unicode has been adopted by some websites. The Wikipedia articles provided in Indian languages are written in Unicode, although the number of articles is small compared to the number of speakers of these languages (not only because computers are not as commonplace, but also due to the lack of easy text entry schemes). Beyond the Wikipedia articles, substantial content in Unicode is difficult to find. Among the exceptions is a large website containing all the writings of Nobel Laureate Rabindranath Tagore While efficient soft keyboards have not been widely developed for Brahmic scripts, there has been a lot of research concerning techniques for the development of soft keyboards for English. In most keyboard optimization problems, the goal is to maximize the typing speed of the keyboard. The most commonly used metric for typing speed is words per minute (wpm), which is the mean number of words a user can type in a given minute. A word is generally defined to be a collection of characters separated by a space (or punctuation) on either side of the collection of characters, and the mean length of a word in a given language is used when calculating the wpm score of a typist or keyboard. When evaluating a soft keyboard, it is common to estimate the maximum wpm that can be achieved on the keyboard rather than an average.

Early layouts for English soft keyboards consisted of either alphabetic ordering or the traditional QWERTY layout. While these are still the most commonly used keyboards, great enhancements have been made in the area of optimization. In order to definitively determine the optimal placement of characters in a given layout, an exhaustive O ( n ! ) search, where n is the number of keys (26, for English) would be necessary. However, this search is impossible even for single-layer layouts in English keyboards. Instead, researchers have used different layouts, optimization techniques, and heuristics to search the space of all possible keyboard layouts and to find local minima. Additionally, researchers have focused on soft keyboards, on which typists generally use only one or two fingers/stylus for typing. In these systems, the total travel distance required for one or two fingers is much more easily calculated. The goal in such designs is to minimize the travel distance between characters so that inputting wordsandphrasesisasfastaspossible.Th e related work done for English discussed in the next several paragraphs focuses on soft-keyboard design for single-stylus input.
The first step toward optimization was taken by MacKenzie and Zhang [1999], who designed a software-based keyboard layout for single-stylus input based on character frequency. They used Fitt X  X  Law (discussed in Section 5.2) and the trial-and-error hand-placement of frequently occurring bigraphs to develop the OPTI keyboard. Zhai et al. [2000] used optimization techniques to design optimal soft keyboard layouts. Zhai et al. [2000] designed and implemented two physics-based techniques to search for the optimal virtual keyboard. The goal of their techniques was to both design a layout (placement and size of the soft keys) and optimally place characters in that layout using character frequencies from a corpus. Their first method was based on Hooke X  X  Law and the second on a Monte Carlo optimization algorithm called the Metropolis algorithm, which is widely used in statistical physics to search for minimum energy states [Binder and Heermann 1988]. The keyboard layout produced by the Metropolis algorithm, which used  X  X nergy X  computed using Fitt X  X  Law, had a predicted upper bound performance of 43.1 wpm according to reported calculations. This is a 40% improvement over QWERTY and a more than 10% improvement over an improved version of the OPTI keyboard. The results of Zhai et al. [2000] were only theoretical, though, as they performed no experiments with real users.
 Genetic algorithms were first used as an optimization technique by Raynal and Vigouroux [2005] who used genetic algorithms based on the MacKenzie model [MacKenzie and Zhang 1999] to place characters in a predetermined soft keyboard layout. Although, in theory, their method can be applied to any language, the experiment they report concerns the design of a keyboard for English. Each iteration, or generation, of their genetic algorithm evaluated the fitness of each of the 20,000 individuals in the population. They defined an individual to be a specific placement of all the characters in the layout. The fitness of an individual was inversely proportional to the average time in seconds required to type a single character. The genetic algorithm does not change the layout of the keyboard, but only positions the character set on a given layout. Raynal and Vigouroux [2005] produced two keyboards, GAG I and GAG II, which have a 10% larger theoretic upper bound on typing speed than the OPTI keyboard, and thus theoretically outperform it. In a similar vein, ant colony optimization strategies have been applied to virtual keyboards designed to make text input easier for people with disabilities [Colas et al. 2007].

Most Brahmic soft keyboards are currently organized in traditional alphabetic or consonant-vowel groups. The designs involve mostly the manual placement of characters based on certain principles, heur istic placement, or prior observation of other researchers. Alphabetic keyboards are easy to learn, of course, but all authors who have worked with keyboard optimization in English have shown that theoretical and practical input speeds increase when c haracter and bigram frequencies are taken into consideration. Although learnability is usually not taken into consideration from a cognitive and psychological perspective, it has been shown that input speed increases and stays high for average users. We believe that there is no evidence the same will not happen for Indic languages.
 Due to the large number of characters, incl uding diacritics, in Indic alphabets, many Brahmic keyboard designers have opted for layered keyboards. A layered keyboard has multiple characters residing in the same location that are accessible by either hitting a button that toggles between layers [Rathod and Joshi 2002] or rolling over base characters to reveal others [Shanbhag et al. 2002]. Shanbhag X  X  keyboard has a combination of these effects, with multiple layers that can be toggled between as well as a layer that has consonants grouped together and accessible by rolling over the group icon [Shanbhag et al. 2002]. Mukherjee et al. [2005] develop a soft keyboard with word prediction for people with neuro-motor disorders; the keyboard was alphabetically organized. Bhattacharya et al. [2006] change this keyboard nominally while theoretically and practically evaluating it with disabled users. Varma and Sowmya [2008] develop and evaluate three soft keyboards for Telugu. The organization of the keys were mostly alphabetical as well.

In addition to optimization, a technique used to decrease the necessary number of keys on a keyboard is the use of gestures on the keyboard. In a gesture keyboard, the user draws any necessary diacritics for each c haracter as they select it [Krishna et al. 2005]. Gesture based Indic keyboards have taken some of their ideas from English gesture-based keyboards such as T-Cube, in which a user selects different characters by flicking their mouse or stylus in different directions [Venolia and Neiberg 1994].
These optimizations and other techniques have the potential to increase the input speed of the user by decreasing the search ti me for characters and possibly decreasing the necessary distance to travel between characters. However, no theoretic input speeds have been calculated for any one of the Indic keyboards. In addition, the techniques stand to benefit by reordering the keyboard by unigraph and bigraph frequency rather than alphabetically.

The work done by Gong and Tarasewich [2005] regarding the oprimization of English keyboards for cell phones involves the idea of putting multiple letters on each key. Letters are selected either by pressing a key multiple times or by using a word-prediction program to allow the selection of possible words from a given combination of key-presses on a nine-key keypad. MacKenzie and Soukoreff [2002] developed a model of two-thumb input that gives an estimated input speed on mobile keyboards. His model has been the basis of several other research projects such as those by Clarkson et al. [2007] and Patel et al. [2009].
 Jung et al. [2011] prototype a Brahmic soft keyboard for a touchscreen mobile phone. The keyboard had an alphabetic layout in order to make it easy to learn, but also because text input performance was not one of their design goals. Joshi et al. [2011] designed and evaluated Devanagari virtual keyboards for touchscreen mobile phones, and found that the Swarachakra alphabetical keyboard layout performed better than the Inscript layout (a QWERTY-based design and government standard in India), which concentrates high frequency charac ters in the center of the keyboard and puts low frequency characters more towards the periphery. They found that an alphabetical (or logical) layout is easy to use for beginning users and is less error prone, however, they had no conclusive, long-term results regarding whether or not a logical layout or frequency based layout would be better. Kumar et al. [2009] develop a logically structured Hindi keyboardi for touchscreen phones. When a user types a consonant, the vowel keys in the first two columns change to the diacritic marks. They found that this makes the keyboard more learnable when compared with standard alphabetic onscreen keyboards.

Finally, an important and usually undiscussed issue is standardization of keyboard layouts. As we have pointed out earlier, QWERTY is not an optimized layout. However, it is ubiquitously used today and, arguably, without any significant drawbacks. Unfortunately, for Indian languages, there has not been any single standard layout for computer keyboards. This has led to further confusion and has hampered the popularization and adoption of any standard input methods for Indic scripts. Thus, there are issues beyond the optimization of the layout that are of significance to the final utility of a keyboard. In spite of this problem of standardization, we definitely believe that there is ample usefulness in carrying out optimization experiments on keyboards. As a first attempt in designing a soft keyboard, we took what we call a brute-force approach. We decided to implement a three-level pop-up menu based soft keyboard for Assamese. The first level provided an individual key for each consonant (see Figure 1). It also had a single key for each of the following sets of characters: vowels, vowel diacritics, digits, and special punctuation marks. The text box was placed above the keyboard. The keyboard was organized in two long rows with a vertical space in between them to show the second and third level menus that appeared as one hovered over or clicked on characters in the menu as discussed below.

The second level of keys was organized as follows. When the cursor hovers over or clicks on the first vowel, , a horizontal pop-up menu with the other 10 vowels appears. Similarly, when one presses on the first vowel diacritic , the diacritics for the other 10 vowels ( , , , , etc.) appear in a horizontal pop-up menu. Also, when one presses on any of the consonants at the first level, e very combination of the consonant with vowel diacritics ( , , , , , etc.) and every ligature (e.g., , , , , , , , , , etc.) for which the consonant is the first character appears. The second-level menus are rectangular. An example of the menu that pops up for the consonant is shown in Figure 2. There are 10 combinations of with vowel diacritics, 15 ligatures created with as the first consonant, and a few other combinations of for a total of 28 items in the second level menu.

There is a third level of menus as well. Each ligature in the second layer has a sub-menu of all the vowel diacritics that can b eaddedtoit.Thethirdlevelmenuforthe ligature (containing , , , , ,  X  X  X  )isshowninFigure3.

Thus, in our three-level menu system, we provide direct access to every vowel, vowel diacritic, digit, special punctuation mark, consonant, consonant-vowel diacritic combination, and every ligature-vowel combination. However, this made for an unwieldy keyboard with access to more than 3,000 character combinations in which it is possible to type anything that can appear in print by menu traversal only.
Table I provides a summary of the numbers of pop-up menus at various levels. The number of pop-ups varies from 2 to 43 at the second level. The mean number of pop-ups at level 2 is 18. Out of 34, 42 characters, that is, 81% have second-level pop-ups. The third-level pop-ups are for the vowel d iacritic marks and a few other diacritics.
Our limited one-time experiment with five volunteers led to a speed of 30 characters per minute or about five words per minute. The volunteers were native Assamese speakers in the U.S. with graduate degrees. They were all male. All the volunteers were accustomed to typing Assamese using soft keyboards made available by Google and Wikipedia. The subjects took the typing tests at their own home or work place, and thus the testing environment was in their control. No training was provided beyond describing how the keyboard works. The individuals were provided a URL where the software keyboard was available for typing. A few simple stories were provided for them to type. The wpm we obtained is actually better than the mean speed of 3.49 wpm [Varma and Sowmya 2008] obtained with the three soft keyboards they designed, implemented, and evaluated for Telugu, a Dravidian language from South India that uses a Brahmic script. This is true even when considering that Telugu has approximately two more characters per word than Assamese (see Table II). Varma and Sowmya achieve a typing speed of approximately 28 characters per minute, while our subjects achieved a typing speed of approximately 30 characters per minute. While we believe that our wpm results are very respectable for a new keyboard for an Indic language, there were a few issues. For example, we were unable to perform a theoretical analysis of this keyboard since we could not fit any existing theoretical models to our design.

Our limited evalutation and analysis of the current design revealed that the menus become large in many cases, and the exclusive use of rectangular menus that are wide and short, caused some menu displays to interfere with other menus at various levels. For example, during the navigation of a short but fairly wide third-level menu, items from the first level in the border areas would become highlighted and these menus would become activated. These new menus would need to be deactivated to restart the interrupted traversal of the third level menu. However, our goal in the development of this soft keyboard was to have exhaustive coverage, aiming for the extreme case in which all 3,000+ character forms and character combinations would be available directly by menu traversal 8 . Our conclusion is that it is not necessary to use the extreme case of providing every possible character combination in the soft keyboard. Quite importantly, we also found that after continuous use for an hour or more, the keyboard would cause physical pain in the hand of the typist; this was reported by several subjects.

As a result of this initial work, we looked for ways to develop smaller, more intelligent designs of keyboards. The rest of the article discusses our approach. The rest of this article attempts to address the problems of Brahmic script text input by applying a combination of techniques previously used for the development of English keyboards. We look at two approaches for improving input potential that have not yet been used with Brahmic scripts: layouts based solely on character frequency and the use of machine learning and optimization techniques for character placement.
Keyboard layouts based on alphabetical ordering make the initial learning of the keyboard simpler but are a trade-off for efficient input. Based on the improvements gained in English keyboards by organizing layouts by unigraph and bigraph frequency, we theorize that a similar approach will be equally beneficial for Brahmic script keyboards. We used Wikipedia dumps of Bengali, Hindi, Gujarati, Gurmukhi, Oriya, Kannada, and Telugu to develop the corpora needed. The number of articles in the Assamese Wikipedia was too small (355 as of May 11, 2011) to use as a corpus, and therefore the Emille Corpus was used instead [Baker et al. 2003]. The Assamese Emille Corpus contains 2.62 million words and was originally gathered by the Institute of Applied Language Sciences in Bhubaneswar, India. The corpora were used to develop tables of unigraph, bigraph, and trigraph frequencies for each of the languages. Details of the corpora sources for the languages used are given in Table II. In creating soft keyboards, we made several design choices that may affect both experimental and theoretic user input speed. Some of these are discussed here. The initial keyboard design assumes the use of a single finger or stylus-based input. In Section 7.3 we discuss the extension of these optimization techniques to include input on mobile devices with two input points.

In all of the keyboards designed, the space bar is fixed below the grid of characters and spans the width of the keyboard. This was done purely because it is the traditional location of the space bar, and we anticipate that it will improve the learnability of the keyboard. When determining the distance between a bigraph that contains a space, the center of the space bar is used as the location the user would choose when typing. Although optimum input speed is obtained when the user always chooses the shortest path, this cannot be expected. Zhai et al. [2000] estimated that given the choice of four space bars users chose the optimum space bar only 38% X 47% of the time. Therefore, in order to have a conservative estimate of the upper-bound for input time, a single, non-optimum location for the space bar was chosen. In addition, this decision avoids underestimates in movement calculations from  X  X ree-warping X  in which the stylus enters a space bar in one location and leaves it in an unrelated location, a common error in soft keyboard evaluation [Zhai et al. 2000].

In addition, we have chosen to create rectangular grid keyboards in which each character occupies a square. This is the most common layout. However the Metropolis Keyboard [Zhai et al. 2000] and select others use hexagon keys and irregular, honeycomb shapes for the keyboard. Our decision to use a rectangular layout for all of our designs is a desire to have a similar layout among all stages of development in order to have a meaningful comparison from one stage of development to the next. We believe that rectangular layered menus will be most efficient because square hierarchical menus have been shown, both theoretically and empirically, to be the most efficient type of menu selection [Ahlstrom et al. 2010]. A desire to have a rectangular keyboard with square keys at one stage necessitates the need for a similar layout and key shape at all stages. Genetic algorithms are an iterative optimization technique in machine learning derived from the principles of natural selection [Goldberg 1989; Haupt et al. 2004; Sivanandam and Deepa 2007; Whitley 1994]. A genetic algorithm is composed of three major parts: a population of potential solutions, a fitness function which evaluates those solutions, and a method for reproducing and changing the population of potential solutions over time. For a given iteration (referred to as a generation), each individual within the current population of potential solutions is evaluated by the fitness function and given a score. The higher an individual X  X  score, the more fit, or closer to the optimum solution it is considered to be. A new population of potential solutions is then created, in which the most fit individuals continue to survive and new individuals are created from the fit individuals of the previous generation. These new individuals may be a combination of previous individuals or can be developed by mutating previous individuals. Many iterations of the evaluation and reproduction steps occur until the solution, or an approximation of it, is found. Figure 4 describes the evolutionary cycle for a generic genetic algorithm. We first describe the design of the soft keyboards for Assamese in detail. We follow it with a brief description of the soft keyboards we have developed for the other languages.

In developing a genetic algorithm for soft keyboards, we chose to define an individual in the population, called a chromosome, to be a valid keyboard layout. A valid keyboard layout is one that includes each character in the alphabet once and only once (each gene in the chromosome is unique). Thus, each chromosome contains a number of genes equal to the number of characters in the alphabet being considered. Our initial genetic algorithm sought to optimize a simple, one-layer, rectangular keyboard. Each chromosome was given a score by the fitness function. We chose to use a fitness function that represented the inverse of the mean time to type a character as determined by Fitt X  X  Law [Fitts 1954], which will be discussed later. Thus, chromosomes with lower mean times were given higher fitness scores. The fastest layouts were kept for the next generation, and chromosomes were randomly chosen for gene mutations (swapping the locations of two characters) and combinations with other chromosomes (in which part of one layout was adopted by another layout) with likelihood of being chosen proportional to their fitness. These newly created chromosomes as well as the best performi ng chromosomes became the population to be evaluated in the next round.

The crossover heuristic used was Ordered Crossover (OX), which controls crossover to ensure that each character in the alphabet appears once and only once in each chromosome. OX selects a substring of characters from the first parent and creates a child chromosome that contains that substring in the same location. The characters in this substring are then deleted from the se cond parent X  X  chromosome. The remaining characters in the second parent are then inserted into the unfixed positions in the new child chromosome in the order they appear in the parent [Davis 1985].

In our genetic algorithms, we allowed the population of keyboards to continue evolving until a single layout was considered the most fit in the population for a predetermined number of consecutive generations.

There are many parameters in genetic algorithms that can be adjusted, including but not limited to: the number of chromosomes in a population, the number of generations for which the genetic algorithm runs, the number of required stable generations (one chromosome is consistently the most fit), the chance of mutation, and how many chromosomes were preserved between generations. There are too many parameters to fully evaluate all possibilities. When determining what values to use for the chance of mutation, we tested a range of percentages between .001 and .15 and found that our best results occur with a chance of approximately .08. This is a higher mutation rate than what many genetic algorithms use. We also chose to preserve approximately 10% of each population.

We chose to focus our attention on varying the number of chromosomes in a population and the number of required stable generations. For each keyboard designed using a genetic algorithm we varied the population size between 10 and 1000 chromosomes. As expected, the best performing keyboards were developed with larger populations, although there were a few minor exceptions. The number of required stable generations were varied between 10 and 100. Several initial tests were run with a stable generation requirement of 250 and 500 and the results were no better than the lower requirements. Most of the best performing keyboards had a stable generation requirement between 15 and 35. Although many tests were run for each type of keyboard developed, only the best keyboards from each category are reported in this article. We note the number of chromosomes used to develop that keyboard as well as the number of stable generations required. We performed more extensive evaluations with other languages and saw similar results. In particular, we provide some graphs of these results in the context of Bengali in Section 6.1. 5.2.1. Flat GA-Based English Soft Keyboards. The keyboards previously designed for Brahmic scripts have two downfalls in comparison with our keyboards: they have only been evaluated by human volunteers, and there has been little attempt to optimize them. As a result, in order to determine that the techniques we use to design keyboards are indeed resulting in theoretically efficient layouts, English keyboards were designed and evaluated in parallel with Brahmic keyboards. This allowed us to evaluate whether our techniques create keyboards that are competitive in a language where much research for optimization has taken place. If these techniques create keyboards that are theoretically competitive in English, we hypothesize that applying the same techniques to the Brahmic keyboard development will also result in competitive and efficient layouts even though no work on theoretic analysis of input speed has previously been performed.

Fitness Function Used: Fitt X  X  Law. Fitt X  X  Law [Fitts 1954] is the most common technique used for evaluating a theoretic upper-bound of words per minute in stylus-based input systems. While Fitt X  X  Law has been widely used for evaluation of soft keyboards in English, it has not previously been applied to Brahmic script keyboards. It calculates the mean time in seconds to type a character, which can then be used to determine wpm [Zhai et al. 2000].

Fitt X  X  Law predicts the mean time needed to type two characters in succession using a finger or stylus. It does this by performing a calculation of the time required to type each pair of letters i and j in an alphabet (this is equivalent to asking how long it will take to type a j after typing i ) and then averaging these times. To calculate the time to move between a character i and a character j in an alphabet with n characters, the Cartesian distance between the characters, D ij , is used, as well as the frequency with which that bigraph occurs in text, P ij . In order to determine the Cartesian distance between characters, the keyboard is aligned with a standard 2D coordinate graph where each character lies at an x , y coordinate. The distance between the coordinates is calculated using the standard distance equation and multiplied by the width of a key. Given a width W j for each key j , and an index of performance IP , the mean time in seconds to type a character is as follows. Previous work in the field uses an IP of 4.9 [MacKenzie and Zhang 1999; Raynal and Vigouroux 2005; Zhai et al. 2000]. In order to maintain consistency in evaluation, our calculations also use this value.

In the typing tests performed on the designed English keyboards, the standard of five characters per word is used in our computations. Thus, given the mean time in seconds,  X  t , for typing a character, the calculation for wpm is wpm
Fitt X  X  Law assumes a perfect knowledge of where the next character is located and perfect movement towards it. Therefore, the resulting wpm predictions are an upper bound for typists experienced with the keyboard and much higher than the speed with which a novice would type.

Evaluation. The only soft keyboards developed by us for English were made using a genetic algorithm that employed Fitt X  X  Law as the fitness function. These keyboards were designed to parallel the most basic Brahmic keyboard in which only one layer is used. While our designed English keyboard is not the fastest existing English keyboard according to Fitt X  X  Law, it is competitive with other keyboards. Although its theoretic upper-bound is less than 40 wpm, as compared with 43.1 wpm [Zhai et al. 2000] and 46.4 wpm [Raynal and Vigouroux 2005], there is a considerable enhancement over using a standard QWERTY layout as a soft keyboard. We hypothesize that the reason why our keyboard is slower is because we used a fixed space-bar at the bottom of the keyboard rather than a central button [Zhai et al. 2000] or including multiple space buttons [Raynal and Vigouroux 2005]. This results in an increase in the average travel distance to and from the space-bar, which is the most frequently occurring character.
A typing test with human volunteers was carried out to show that the typing trend was approaching the expected words per minute as predicted by Fitt X  X  Law. Ten volunteers typed random phrases on the keyboard during ten minute sessions over a period of a week. The phrases used were from the published collection of MacKenzie and Soukoreff [2003]. This evaluation was not intended to determine input speed of long-term users, but to determine whether or not the keyboard could be easily learned and to show that the input speed could approach the predicted speed. The results suggest that a user X  X  typing speed does increase and will continue to increase after long term use (see Figure 6). Experiments in software keyboard design usually perform typing tests for a limited number of sessions, with a limited number of users and then extrapolate to obtain an estimate of expert user speeds (see, for example, MacKenzie and Zhang [1999] and MacKenzie and Soukoreff [2002], two of the most salient articles in soft keyboard design).

Therefore, we claim that the genetic algorithm used to design this keyboard and using Fitt X  X  law to evaluate it are valid for developing and evaluating soft keyboards; thus we will also apply them to Brahmic scripts. 5.2.2. Flat GA-Based Assamese Keyboard. As a basis for comparing the results of our genetically designed keyboards, we first evaluated a flat, rectangular, alphabetic keyboard containing all the alphabetic characters, diacritic marks, and basic punc-tuation symbols. We call it flat because it contains all of the necessary characters in one level. In order to make the results co mparable, the diacritics were also added to the keyboard. Several layouts, which varied in number of columns and rows, were evaluated using Fitt X  X  Law. In addition, the placement of the diacritics was adjusted. In all trials, the vowels and consonants were kept in alphabetic order, and the diacritics were kept in a group. This is what soft keyboard designers for Telugu [Varma and Sowmya 2008] and Bengali [Bhattacharya et al. 2006; Mukherjee et al. 2005] have done as well. Varma and Sowmya [2008] had placed the diacritic marks for Telugu in a block in the center of the keyboard. We decided not to do so since such placement interferes with the alphabetical layout making it complex and difficult to remember. However, the keyboard X  X  theoretic input speed was evaluated with the diacritics appearing before the vowels, after the vowels, and after the consonants. The fastest resulting alphabetic keyboard, shown in Figure 7(a), was an 8 diacritics appearing after the consonants. An evaluation using Fitt X  X  Law predicts an input speed of 25.06 wpm.

The first Brahmic script keyboard designed using genetic algorithms was a simple, single-layer keyboard for Assamese. The keyboard maintained the 8 64 consonants, vowels, and diacritics that was used in analyzing an alphabetically organized keyboard. As with all our keyboards, the spacebar was fixed below the characters, and a single point in the middle of the spacebar was used for calculating the travel distance between it and other characters. In addition to the described alphabetic keyboard, this keyboard also serves as a benchmark for evaluating adjustments to the single-layer design such as layering and gestures. It is an improvement on the alphabetic keyboard as its design considers the bigraph frequencies of Assamese and attempts to minimize the travel distance between characters in frequently occurring bigraphs. It was designed using a population of 1,000 layouts that were allowed to evolve until a single keyboard had been the  X  X ost fit X  for 25 generations. The resulting keyboard has an expected input speed of 34.23 wpm according to Fitt X  X  Law, a promising initial result. When designing GAG1 and GAG2 used populations of 20,000 chromosomes and continued their algorithm until a single keyboard had been the most fit for 500 generations [Raynal and Vigouroux 2005].
To determine words per minute for Assamese soft keyboards, several measurements were obtained. The Emille Corpus for Assamese was used to calculate frequencies for all unigraphs and bigraphs. In addition, it was used to obtain the average number of characters per word in Assamese, which was calculated to be approximately six [Baker et al. 2003]. A character was considered to be a single Unicode character if it was typed as a single keystroke. Thus each consonant, vowel, and diacritic was counted as a character, and ligatures were considered to be made of several characters. The number of characters per word varies in every language and was calculated accordingly using this definition of character. 5.2.3. Hierarchical GA-Based Assamese Keyboard. The initial use of genetic algorithms for designing soft keyboards for Brahmic scripts based on character frequency shows very promising results. Our next approach to improving input speed was the development of multi-layer keyboards. A multi-layered keyboard allows menus or extra keys to be placed on top of an original keyboard. Genetic algorithms have previously been shown to produce high efficiency in the development of hierarchical menus [Matsui and Yamada 2008]. While hierarchical menus and layered keyboards have some differences in design, the techniques used to evaluate them are similar. For example, a two-layer keyboard in which the second layer is accessible by rolling over characters in the first layer can be represented by a two-level menu.

Diacritic Menu as Second Layer. In an attempt to reduce the number of keys on the screen and improve input speed, the technique of adding a vowel diacritic menu to each consonant was tried. When a consonant on the main level of the keyboard is selected by pressing the mouse button, a diacritic menu appears around the selected consonant. The menu appears immediately after the mouse is pressed. The user can either release the mouse button on the chosen consonant to type a bare consonant, or they can drag the mouse and release it abo ve one of the diacritics to add the chosen diacritic to the consonant. In both scenarios, the diacritic menus disappear as soon as the mouse is released. This extends to touch-screen interfaces where contact with the screen is considered a mouse press and broken contact is equivalent to a mouse release.

In Assamese, the diacritic menu allows for the selection of the 12 most frequently occurring diacritics. They were hand-placed into the diacritic menu by frequency as calculated using the Emille Corpus (shown in Table IV). The four most frequent diacritics appear immediately above, below, and to the side of the selected consonant. The next four most frequently occurring dia critics appear in the location immediately diagonal to the selected consonant. This is intended to allow for the fastest possible selection time. Future work may include using optimization techniques to place the vowels rather than hand-placing them.

The diacritics appear in the same location for each consonant regardless of the frequency with which they are used together. This is anticipated to facilitate faster learning of the diacritic menu by minimizing the visual search time for each consonant and decreasing the number of locations that must be memorized by the beginner in order to become an expert.

Diacritic submenus are not new, they have been widely used to decrease the number of visible keys. However, to improve upon this idea, we combined the ideas of diacritic menus and organizing consonants and vowels onto a base layer by character frequency. We designed a genetic algorithm that took into account the diacritic layer with its fixed diacritic locations. The idea behind the algorithm is that if there is a frequently occurring trigraph abc with a diacritic as the central cha racter, then the best location for the third character, c , is as close as possible to the location on the keyboard where the diacritic b will appear in the menu that pops up when a is pressed. If b falls on the exact same location on the screen, but in the second layer as c , which is located in the first layer, then once the mouse is released and b is typed, the mouse will not need to be moved in order to type c after typing b .

Our genetic algorithm was run with a population of 500 individuals until a single keyboard was the most fit for 15 generations. The resulting keyboard, seen in Figure 8(b), has an expected theoretic input speed of 40.24 wpm. This is a significant improvement over the single layer, alphabetically organized Assamese keyboard.
For comparison, a diacritic layer was added to the alphabetic keyboard. The resulting keyboard had an expected input of 33.94 wpm.

Vowel Menu. The use of Assamese free vowels (non-diacritic) is infrequent with the most frequent character occurring only 1.33% of the time. Table V provides frequencies of explicit occurrence of vowels in Assamese. Because of this, we hypothesized that the input speed could be increased by placing all of the vowels in a separate vowel menu. A single button that includes all of the vowels is a common organization technique in previous Brahmic keyboards. This technique has the benefit of reducing the number of characters on the board to be memorized as well as allowing the remaining characters to be closer together. Immediately, it seems that it would improve the theoretic input speed. To test this, the vowels were placed in set positions, based on frequency just like the diacritic menu within their own menu on the bottom left of the screen as shown in Figure 9.

A genetic algorithm was designed and run to create a keyboard with only consonants in the base layer, a second layer of diacritics attached to each consonant, and a vowel menu button. The keyboards designed using this algorithm were evaluated with the same methods used to evaluate the diacritic menu. However, the best keyboards developed using the vowel menu had, on average, an expected input rate that was 5 wpm less than those expected for the keyboards that had no vowel menu. The keyboard with the fastest expected input rate that included a vowel menu was 35.6 wpm. It may be that, although infrequently used, the long distance that must be traveled to type any vowel is significant enough to greatly decrease the expected speed. Alternatively, it is possible that the vowels are typed before and after a wide variety of consonants, and so it is impossible to arrange the keyboard with the consonants that frequently occur with a vowel all within the lower left of the keyboard. While further research into different layouts of the vowel menu and different locations for it may create a keyboard that has an input expectation similar to those without a vowel menu, 5 wpm is a significant gap to bridge.

Fitness Function Used for Multi-level Indic Language Keyboards. While an appli-cation of Fitt X  X  Law was an effective fitness function for a single-level soft keyboard, multi-level keyboards need a modified one. Multiple layers means that traversal time between layers needs to be taken into account, both in evaluation and in determining the most fit keyboards. In order to do this, we applied the ideas from the evaluation of hierarchical menus performed by Ahlstrom et al. [2010]. They built on a technique for analyzing the search and selection time of items in a hierarchical menu from Cockburn et al. [2007] that combines Fitt X  X  Law and the Hick-Hyman Law and applies it to hierarchical menus in which each menu and sub-menu is a grid of the available options. The rectangular, multi-level soft keyboards we designed are an application of a rectangular hierarchical menu, and so their techniques for evaluation were used in the fitness function of our genetic algorithms [Cockburn et al. 2007].

Hick-Hyman X  X  Law [Hick 1952; Hyman 1953] predicts the amount of time a person will take to make a decision given the number of choices they have. The user X  X  reaction time is modeled by the following equation.
 where n is the number of choices and p i is the probability of that choice being chosen. A user must make a decision about what character to press when their selection changes. The Hick-Hyman law can be applied to the original, base-layer of the keyboard as well as to the diacritic second layer. The Hick-Hyman Law takes into consideration the amount of time needed by a novice to make a decision. We can ignore the contribution of Hick-Hyman Law for experts. Thus, the use of Hick-Hyman Law gives us a lower bound for the text input speed.

The goal of the fitness function used in the development of Assamese soft keyboards with layers is to minimize the sum of the time spent searching for the next character (Hick-Hyman X  X  Law) and moving between locations (Fitt X  X  Law). The fitness function calculates the mean time to type a character by summing three different types of transitions that can happen when a pair of characters are typed.

There are two types of characters that can b e typed: base characters and diacritic menu items. Base characters reside in the bottom layer of the keyboard and diacritics appear in the second level. In the languages considered in this article, almost all of the base characters with diacritic menus are consonants. We have one ligature, viz., in the base level. It is possible that other commonly used ligatures should be placed at this level in the future or in other languages. The three types of transitions between one character to the next that must be taken into account are the following.  X  A base character typed aft er another base character . This happens when we type two consonants one after the other as in typing the Assamese word , the first name of this article X  X  last author. Consider the last two characters of this word: , the consonant followed by a second consonant . . To input these two characters, we type the first character in the base level, make a decision regarding the next character to type, and finally move to the next character menu appears briefly when the mouse clicks on , it disappears as soon as the mouse button is released. Let us call the transition time from a base level character to another base level character  X  t bb .  X  A base character followed by a diacritic character . This happens when we type the first character (actually a character followed by a diacritic on top) in the word above. We click on first. As soon as we click on it, the diacritic layer shows up, and a decision is made regarding the diacritic character to type ( )thenwemovetothis diacritic character. Let us call the transition time from a base level character to a diacritic level character  X  t bd .  X  A diacritic character followed by a base character . This happens when we type the diacritic mark ( ), the second component in the first character and then type the second letter in the example word above. It involves simply letting the diacritic menu go away (it disappears as soon as the mouse is released on the the diacritic) and then moving to next character at the base level. Let us call the transition time from a diacritic level character to a base level character The goal of the fitness function, as before when the average time was computed only with  X  t bb , is to reward chromosomes that have smaller transition time values after considering all three cases of transition.
 The three averages are computed as follows.  X  t bb is the sum of the time predicted by Hick-Hyman X  X  Law for choosing the next character at the base level and Fitt X  X  Law for movement from the first character to the second in the base layer. time predicated by Hick-Hyman X  X  Law to select the correct diacritic mark and by Fitt X  X  Law to move to the correct diacritic layer character.  X  t regarding which base level character to move (Hick-Hyman Law) and then moving there again with Fitt X  X  Law. 5.2.4. User Evaluation of the GA-Based Assamese Keyboard. To evaluate our GA-based Assamese keyboard, we contacted 25 individuals who were native Assamese speakers, 11 of whom agreed to experiment with the keyboard. Six of the subjects were in the US and the rest in Assam, India. Everyone had at least a Bachelor X  X  degree in a technical area. Each individual claimed to be an expert typist in English and is very familiar with computers. The individuals ranged in age from their early 20s to their early 50s. All the subjects were male. The experiment environment was not controlled, although the individuals were requested to not multi-task during the typing tests and to take the tests in a quiet environment. The typing tests were performed on a password-protected web site, where a large text box was shown with the keyboard being evaluated shown below it. Each typing test session was 10 minutes long. Six children X  X  stories by well-known authors were chosen as the text to type. Each sentence of the stories appeared one at a time, being replaced by the subsequent sentence when it had been successfully typed by the users. Although a backspace key was provided, typists were discouraged to use it. The texts used were chosen because of their simplicity and use of common words, similar to the texts used during the typing tests of English keyboards [MacKenzie and Soukoreff 2003]. Once the 10 minute period was over, the session finished automatically. Individuals were requested to participate in seven typing tests over a period of 15 days, not taking more than one test a day.

The results of the evaluation are shown in Figure 10. The average wpm is shown with the assumption that the average word has six characters. Even though each of the subjects is a native speaker of Assamese and has been educated in Assamese, we believe that the starting wpm is much lower than the wpm for English because most, if not all, of these individuals usually never type in Assamese. Fundamental differences in the languages such as differences in characters per word and number of letters in the alphabet are also factors in the lower wpm.

It is clear that the typing speed increases progressively over a period of seven typing sessions. The average initial typing speed was 1.66 wpm, which improved to 6.58 over seven sessions. The graph in Figure 10 shows how the average typing speed improves over the sessions. We believe that the typing speed will continue to increase as the number of sessions increases. Although we have predicted a high limit on the speed, the speed that an individual achieves will depend on various factors such as experience and comfort with computers and text entry in addition to physical traits of the individual such as finger dexterity.

Our claim that the speed of text entry has increased for the subjects after several sessions is somewhat validated by our results, but further, long-term studies are necessary to determine how well our proje cted optimal wpm compares to the actual achievable speed of the typists. Additionally, studies on the other important issues in designing soft keyboards for Indic languages, such as learnability, would improve our understanding of what an ideal soft keyboard should be like. In this section, we discuss the results we have obtained while developing soft keyboards for several other Indian languages. The languages we worked with were Bengali, Hindi, Gujarati, Punjabi, Oriya, Kannada, and Telugu. Of all the languages we have used in this article, the scripts used by Assamese, Bengali, Hindi, Gujarati, Punjabi, and Oriya belong to the Northern branch of the Brahmic scripts. Assamese and Bengali use two variants of the Eastern Nagari script. Hindi uses the Devanagari script. Punjabi uses the Gurmukhi script, although it can be written using the Shamukhi script as well. Gujarati and Oriya have their own individualized scripts. Two of the languages, Kannada, and Telugu use scripts that belong to the Southern branch of the Brahmic scripts. Each of these languages has its own script.
For each language, we develop alphabetically sorted keyboards: a flat GA-based soft keyboard and a layered GA-based soft keyboard using the techniques we used for Assamese. For Bengali, each alphabetic layout tested for wpm results listed the vowels before the consonants in alphabetical order. The ro w and column ordering of three alphabetic layouts were evaluated as follows: one with the diacritics listed after the vowels and consonants, one with the diacritics listed in between the vowels and consonants, and one with the diacritics listed before the vo wels and diacritics. Row ordering means that each of the characters was listed alphabetically left to right from the top row to the bottom row. Column ordering means that each of the characters was listed from the top to the bottom from the far left column to the far right column. Therefore, six different alphabetic arrangements were evaluated altogether for Bengali. The best arrangement was row ordered and listed the diacritics after the vowels and consonants, which yielded an expected input speed of 22.19 wpm.

The best results of our genetically designed Bengali flat keyboard yielded a theoretical input speed of 30.35 wpm as predicted by Fitt X  X  Law. This was an 8 x 8 square keyboard constructed with the following genetic algorithm parameters: a population of 100 and 100 stable generations.

As discussed earlier in the article, greater improvements to input speeds can be achieved through the use of layered keyboards. Thus for Bengali, we kept the consonants and vowels on a base layer and a diacritic menu as a second layer that could come up whenever a user clicked on a consonant as done earlier for Assamese. The best genetically designed layered keyboard for Bengali had a base layer of dimensions 7 x 6 and was genetically constructed from a population of 500 and 15 stable generations. It yielded an expected input speed of 36.13 wpm. Adding a vowel menu in addition to the diacritic menu for the layered keyboard made very little difference for the layered keyboard. For Bengali, taking the vowels out of the base layer of consonants and putting them in their own separate menu decreased the expected speed by only 0.04 wpm.

For each of the languages, we experimented with parameter values for the genetic algorithm to get the best results. In Figures 12, 13, and 14, we show how the wpm results change for Bengali with changes in values of the parameters. Similar observations apply to all other languages with which we have worked. For Hindi, the same six alphabetic layout arrangements as in Bengali were evaluated with Hindi characters. The layout with the best expected input speed, which was 22.04 wpm, listed the diacritics before the vowel s and consonants and was column ordered.
The best theoretical input speed generated from the genetically designed Hindi flat keyboards was 29.01 wpm as predicted by Fitt X  X  Law. This was also an 8 x 8 square keyboard constructed with a population of 100 and 100 stable generations.
The same diacritic menu was made for the Hindi layered keyboard using Hindi characters. The best genetically designed layered keyboard for Hindi had a base layer of dimensions 7 x 5 characters and was genetically constructed from a population of 500 and 25 stable generations. It yielded an expected input speed of 37.03 wpm. Both of these layered keyboards offered an average 6.9 wpm improvement over the expected wpm scores of the flat keyboard layouts and an average 14.47 wpm improvement over the wpm scores of the alphabetic layouts. For Hindi, having a vowel menu decreased the expected input speed by only 0.7 wpm.

Future research may include evaluating the layered keyboard layouts with and without a vowel menu on actual users to determine whether a separate vowel menu can significantly improve or worsen the efficiency of a layered keyboard for the Bengali and Hindi languages.
 We generated soft keyboards for five additional languages. Each language was evaluated with four different keyboard arrangements. Our first step was to evaluate keyboards with an unoptimized, alphabetic arrangement as a basis for comparison. These keyboards were developed with both flat and layered designs. We then used the genetic algorithm to develop optimized flat and layered keyboards. Refer to Table V through Table VIII.

To justify the organization of the diacritic menu in the various languages, we collected frequencies of occurrences of vowel d iacritics. Table VII shows the frequencies based on analysis of our corpora. Table VIII provides the upper bounds in predicted wpm and seconds per character (SPC) that we obtain for the various languages. The upper bounds were computed using Fitt X  X  Law only by ignoring decision times as if the typist happened to be an expert. We provide both wpm and SPC because the number of characters per word varies from language to language based on our calculation in the context of the corpora that we used. The number of characters per word for the various languages we have studied are given in Table III. The lower bounds for the typing speeds for the various languages in terms of wpm and SPC are given in Table IX. Images of these keyboards are provided in the appendix.

In analyzing these results, we were able to draw a few basic conclusions regarding the optimization process. Looking at the numbers, we notice that Oriya shows the greatest improvement after optimization, giving the lowest time per character, while the improvement for Gujarati was somewhat less significant. One explanation for these results considers the relative frequencies of characters in the two languages. The most frequently occurring character in Oriya has a relative frequency of approximately 8.6%. In Gujarati, the most frequent character has a relative frequency of 5.9%. Considering the Gujarati keyboard shown in the appendix, we can see that the optimized keyboard has the most frequent characters clustered together near the center. Our conclusion is that languages with a small number of high frequency characters have a greater potential to be optimized. It can be surmised that languages with characters that have nearly equal frequencies require the user to travel a greater average distance between each character.

Additionally, it can be seen that Gujarati has a smaller improvement between its layered and flat layouts when compared to the other languages. One reason for this could be the higher frequency of the diacritics in this language. Kannada, which showed the highest improvement in its layered layout, also has the lowest frequency of diacritics. Essentially, the smaller number of diacritics means less use of the menu, which makes the layering more effective.

Other than these minor variations, the results from the optimization tests of these languages are all very similar in their progress. Plotting the results of the evaluations all of the languages show very similar improvement over an increasing number of generations. One of our objectives in designing, developing, and evaluating soft keyboards is to create them for mobile devices as well. Mobile devices, including ones with large screens, are becoming popular around the world including places in which Indic languages are widely used. We have several choices of platform: Apple iOS, Android, and Windows Mobile. Our current effort, reported in this article, is geared toward the Android platform, since it is gaining market share everywhere.

As we worked to develop Android soft keyb oards from our optimized layouts, we had several challenges to overcome first. Our first step was to find a suitable format for installing the keyboards on the Android phone. Once we had evaluated the keyboards in their basic form, we performed several experiments in an attempt to modify the designs for more practical use on the actual device. The development framework we used was the AnySoftKeyboard app application that provides a means for developing new plug-ins for languages. Using this tool allows us to quickly evaluate our keyboard layouts and make them available online. Below, we discuss our experience in creat ing an AnySoftKeyboard plug-in for the Assamese language 10 . We base our effort on the keyboards generated using the genetic algorithms discussed earlier.

The keyboard was designed to be used with a diacritic layer (see Figures 17(a) and 17(b)). This diacritic layer is implemented as a menu that pops up when a consonant key is held down. Our initial design implemented the most efficient keyboard designed for a PC directly onto the Android device. These designs were functional on Android Nexus S One, a recommended development platform.

In trying to optimize the keyboards specifically for the mobile devices, there were some additional factors to be taken into consideration. The primary concern was that the keyboard designs needed to be functional in both the horizontal and vertical orientations of the phone. The dimensions of the initial keyboard design resulted in obstructing parts of the text entry field in the horizontal orientation.
In an effort to make the keyboard more practically usable, we tried several different variations in the dimensions of the keyboard. The best layout we found consisted of a longer, more narrow format.

Our original design consisted of a nearly square layout of 8 the genetic algorithm and evaluated a layered keyboard with dimensions of 5 The results showed only a minimal reduction in typing speed, but the ease of using the keyboard was greatly improved. Running the algorithm over 500 generations with a population of 1,000, we got results of 36.9 wpm for the rectangular keyboard, which compared with the 40.2 wpm of the square layout.

The main side-effect of this layout is the key-size in this format. In order to position the keys in this layout, we had to reduce their size. This is likely to result in more errors as users type. We intend to explore the issue of key size and error in input in the future. The assumption in all previous designs was that text entry takes place with a single finger or a stylus, but on larger devices, people are more comfortable using two fingers. Hence, after running tests with rectangular keyboards, we experimented with modifying the genetic algorithm program to optimize for text input with two fingers.
In order to optimize keyboards for two thumb input, it was necessary to first develop a variation of the fitness function that takes this into consideration. We based our fitness function on a simplification of the model of two-thumb input developed by MacKenzie and Soukoreff [2002]. This model has been used as a basis for several other research projects in this field including Clarkson et al. [2007] and Patel et al. [2009]. Our approach involves combining this model of input with our bigraph-based implementation of Fitt X  X  Law. In our evaluation model, we used a layered keyboard design.

The basic layout we chose consisted of a long rectangular shape. Using a method similar to that used by MacKenzie and Soukoreff [2002], we made the assumption that each finger or input point will occupy an essentially square section of the keyboard. The logic behind the implementation of the genetic algorithm relies on the assumption that each input point is only used in its square. In earlier research, Clarkson et al. [2007] propose a more complex model that takes into consideration a section in the middle of the keyboard shared by both thumbs. However, for the scope of this project, we chose to use only the most basic form of the model to allow for comparison with the results from MacKenzie and Soukoreff [2002].

There are essentially two cases to be considered in the calculation of the fitness function: first, the case of bigraphs that consist of two characters in the same square, andsecond,thecaseofbigraphswherethec haracters occur in different squares. The diacritic menu is the same as that used for the single input keyboards.

To take care of the first case, the fitness function uses Fitt X  X  Law to calculate an average time per character for each input point in each square. This is essentially the same calculation that we used to find the input speed of our single input keyboards.
In the second case, the first step is to find a number representing the average time required to press a given key twice with the same thumb. The model for two thumb input relies on the assumption that, as the two thumbs alternate, the average time per character will be half of the time required to press a key twice. The equation for this model then becomes the following. For our estimated time to repeat a character, t REPEAT , we use a value of 178 ms as used by Silfverberg et al. [2000]. Thus our time between thumbs, t Using this algorithm, we were able to develop a two input keyboard for Assamese. The calculated upper-bound of input speed for this keyboard is 53.41 wpm. Theoretically, this is much higher than the upper bounds we have found for single finger entry (see Table VIII).

A preliminary evaluation of this keyboard can be made by looking at the locations of the most frequent characters. In Figure 20, we can see two clusters of high-frequency characters being formed in the location of the two input points. Additionally, there seems to be a nearly equal number of high frequency characters on each side.
These results are consistent with a comment made in Zhai et al. [2005]. They mention that the QWERTY keyboard is most effective when used for two-handed input due to the frequency of alternation between the two hands. The algorithm that we implemented gives a higher score to keyboards that more frequently alternate hands.
In evaluating the effectiveness of our algorithm, we compared our results to those reported by earlier research. MacKenzie and Soukoreff [2002] report an input speed of 60.74 wpm for the QWERTY keyboard. If we recalculate our input speed to assume five character words the same as English, our number becomes 64.09 wpm. This comparison shows that, despite having three times the number of characters, the Assamese keyboard developed using the genetic algorithm is able to achieve input speeds similar to those of English keyboards.

The optimized keyboards that we generated for the Android phone performed considerably better than the alphabetic alternatives. However, even after adding the diacritic layer, the number of keys is simply too large for the size of the Android phone. An area for future research would be to experiment with putting multiple characters on each key. It would be desirable to be able to optimize keyboards given a physically constrained number of keys. This might be the best option for creating effective cell phone keyboards for languages with large numbers of characters.

Another area for continued research would be to investigate the development of keyboards optimized for the specific needs of other devices such as the iPad and the iPhone. The approach of designing soft keyboards via optimization using genetic algorithms provides fruitful results but lacks flexibility. For example, consider the situation in which we want to obtain the most efficient soft keyboard for a range of device sizes under a set of user-specific constraints. The device size and the user constraints can be considered as parameters for the main problem of maximizing text input speed. With our current approach, all problem parameters must be fixed before optimization starts. Thus, the optimization has to be carried out separately for each combination of parameters.

Instead, we would like to simultaneously optimize all of our criteria at once, optimizing without setting the secondary parameters at optimization time. Multi-objective optimization provides a method for handling these underdetermined problems. We encode all salient characteristics as independent objectives and optimize over all of them at once. The running time for the generalized problem is comparable to running a single instance of the problem. The result is that we can defer the forcing of trade-offs between characteristics until we have elicited the relevant constraints for specific cases. At the heart of this problem of accommodating various needs is the problem of optimizing with respect to multiple objectives. It is possible to combine the objectives into a single one, dictating at the outset how trade-offs among the different objectives should be made. As previously noted, we take a more flexible approach that optimizes all the objectives simultaneously with respect to the Pareto ordering on the solution space.

Formally, consider a sequence of objectives f 0 , ... , f solutions x , y  X  S .Wesay x Pareto dominates y ( x y )ifforall0 objective, and x is strictly better than y for at least one f  X  X ree lunch X  to be had when moving from y to x : We can improve at least one objective while doing just as well in all the others. Therefore, we can unequivocally say that x is better than y : this conclusion does not require that we make trade-offs between the different objectives at all.

This partial order induces the natural equiv alence relation, where x and y x .If x  X  y , there is some trade-off between the objectives incurred when moving from x to y . With this equivalence relation, we may then partition the solution space into ordered equivalence classes. We call the optimal class the Pareto front .The algorithm we employ in this article for multi-objective optimization returns the Pareto front for a given multi-objective optimization problem [Deb et al. 2002].
Once we have identified the Pareto set, the majority of the computational work has been completed. Later, when specific preferences have been elicited with respect to the allowed size on a device, for example, the optimal solution for this specific case can be read out from within the previously comput ed Pareto set. This balance between design and run time allows us to use powerful, but static, optimization approaches such as multi-objective genetic algorithms while deferring design choices until later.
We illustrate with an example where we have two objectives: maximization of input speed and maximization of available device space usage. We apply the same method of evaluation for the resulting keyboards as the previous sections to our multi-objective approach. The main difference is in the fitness functions. In addition to Fitt X  X  law for evaluating theoretical speed, we also consider the size of the keyboard designed. This set of objectives is particularly relevant in the case of mobile devices, for example, where screen space is at a premium and all available space must be well-used.
In this example of optimizing keyboards with respect to their size and speed of use, the optimization X  X  Pareto set represents the fastest keyboards over varying sizes. Note that this set could be obtained by simply running the single objective genetic algorithm many times with different fixed sizes, but the benefit of the multi-objective approach is that we obtain the entire set at once.

To interface our keyboard problem with the multi-objective optimization program, we encode a keyboard over a set of n characters as a permutation of the list along with a single floating point number at the end to indicate how much of the device X  X  vertical screen space the encoded keyboard uses. Therefore, we aim to maximize the keyboard X  X  speed of use as well as the negative of the screen space used. We implemented this approach using the NSGA-II algorithm [Deb et al. 2002] that follows the typical pattern of genetic algorithms but uses a special non-dominated sort to quickly resolve the Pareto condition for the current population.

The algorithm was implemented in Python using the EC S P Y algorithm library. We ada pted a differential crossover strategy from the EC library, which required a bounder function to ensure the resulting chromosome was a valid permutation. Finding an appropriate crossover operator was a difficulty that we faced, as the O ( n ! ) search space required fairly aggressive exploration.
The NSGA-II formed an approximation of the Pareto optimal set for the design of an efficient keyboard under size constraints for Assamese, our exemplar language for this article. When plotted, the trade-off between typing speed and size was roughly logarithmic, as seen in Figure 21. Upon the computation of this set, we can quickly identify the optimal solution with respect to an arbitrary size constraint relative to the mobile device considered.
We found that, in the case of generating Assamese keyboards, relaxing the size constraint past one half of the device X  X  size did not improve keyboard performance significantly. Thus, we include two keyboards in Figure 22: one with a size constraint of 0.5 and another with a constraint of 0.3. Our keyboards are flat ones, in terms of the terminology used earlier in this article.

As a second example, running the same optimization on Gujarati yielded similar results. As with the results from Assamese, the Pareto front was surprisingly well behaved, with a smooth, convex logarithmic relation. As before, the size constraint did not become binding until it was decreased beyond 0.5, so we present two keyboards within this constraint from the Pareto set in Figure 23.

Thus, multi-objective optimization provides a convenient approach for generalizing the single objective optimization described earlier in this article to other design concerns. Instead of starting the optimization process anew with each parameter change, the multi-objective approach allows the user to simultaneously meet all the demands of the keyboard at once. We intend to further explore the use of multi-objective optimization for flexible design of keyboards and other user interfaces in the future. Soft keyboards have the benefit of not being limited to a specific layout as physical keyboards are. They can be designed in varying shapes and sizes and can potentially be designed to be most efficient for whoever is using them. Theoretic analysis using techniques such as Fitt X  X  Law and Hick-Hyman X  X  Law can be used to analyze various layouts as we have done in this article.

In this article, we have shown that efficient and learnable soft keyboards can be designed for Indic languages with simple genetic algorithms and have presented an algorithm for creating optimal keyboards that is independent of language. We have shown that using bigram frequencies for organization improves the expected performance of typists, as does creating layered keyboards. We also adapted the soft keyboards for a mobile device for several Indic languages. Finally, we used multi-objective optimization using Pareto optimization to create efficient keyboards that can accommodate additional constraints s uch as device size. Our work using Pareto optimization can be extended so that we can adapt solutions to individual users.
Our future work will include development of soft keyboards for additional devices, working further on Pareto optimization experiments incorporating additional constraints, and working on adapting soft keyboards to various user abilities. Also, in particular for Indic languages, we want to investigate into how at least some ligatures can be incorporated into the keyboards and whether it will be beneficial to do so. Additionally, we see future work in the realm of text-prediction to enhance typing speed, as explored nominally in Hinkle et al. [2010].

We also want to develop soft keyboards for all Brahmic scripts and other languages that have less used scripts and make them available on the web. Our long-term objective is to decrease the digital divide that is due to the absence of efficient and learnable soft keyboards for speakers and users of a large number of the world X  X  languages by making such soft keyboards available widely on computers, tablets, and smart phones. Since smart phones and their progeny devices are destined to be widespread all over the world in the future, even in poorer countries, availability of soft keyboards for a wide variety of devices and languages will help chisel away at this important barrier to entry to the modern digital era for many people.
 We include images of the layered keyboards generated for the Gujarati, Punjabi, Oriya, Kannada, and Telugu languages. These keyboards were generated using 5,000 generations with populations of 1,000.

