 Lexical databases are invaluable sources of knowledge about words and their meanings, with numerous applications in areas like NLP, IR, and AI. We propose a methodology for the automatic con-struction of a large-scale multilingual lexical database where words of many languages are hierarchically organized in terms of their meanings and their semantic relations to other words. This resource is bootstrapped from WordNet, a well-known English-language re-source. Our approach extends WordNet with around 1.5 million meaning links for 800,000 words in over 200 languages, drawing on evidence extracted from a variety of resources including exist-ing (monolingual) wordnets, (mostly bilingual) translation dictio-naries, and parallel corpora. Graph-based scoring functions and statistical learning techniques are used to iteratively integrate this information and build an output graph. Experiments show that this wordnet has a high level of precision and coverage, and that it can be useful in applied tasks such as cross-lingual text classification. H.4 [ Information Systems Applications ]: Miscellaneous; I.2.4 [ Artificial Intelligence ]: Knowledge Representation Formalisms and Methods; I.2.6 [ Artificial Intelligence ]: Learning Algorithms
Motivation. With the increasing degree of Internet penetration all over the world, the English language represents a constantly de-creasing fraction of the Web. China and the EU each have greatly surpassed the U.S. in the number of Internet users, and other re-gions are expected to follow. Multilingual knowledge bases ad-dress this development by capturing relationships between words and concepts and hence making the semantic connections between words in different languages explicit. Lexical information of this sort can be useful for various forms of natural language process-ing [20], information retrieval (e.g. query expansion [18], cross-lingual IR [13], and question answering [33]), knowledge man-agement (e.g. ontology construction [36] and ontology mapping [22]), artificial intelligence (e.g. textual entailment [3] and visual object recognition [27]), as well as human consultation. For ex-ample, knowing that the French words  X   X tudiant  X ,  X   X l X ve  X ,  X   X col-ier  X  are synonymous can aid in query expansion, and knowing that  X  lyc X e  X ,  X   X cole  X ,  X  universit X   X ,  X  acad X mie  X  are all specific types of educational institutions is helpful for question answering.
Contribution. In this paper, we present new methods for auto-matically creating a large-scale multilingual lexical database that organizes over 800,000 words from over 200 languages in a hi-erarchically structured semantic network, providing over 1.5 mil-lion links from words to word meanings. This universal wordnet ( UWN ) is bootstrapped from the Princeton WordNet, a well-known lexical database for the English language [14] that we shall simply refer to as  X  WordNet  X , in contrast to the generic term  X  wordnet  X . WordNet consists of about 150,000 terms (words or short phrases) and about 120,000 word senses (concepts). It links terms with the senses that they denote (their meanings), thus providing a fairly comprehensive database of synonymy and polysemy . Additionally, it connects senses by semantic relationships like hypernymy , which is similar to the subclass relation and hence induces a hierarchi-cal organization, as well as meronymy (part/whole relation), etc. For instance,  X  high school  X  is a hyponym of  X  educational institu-tion  X , and  X  classroom  X  is a meronym (part) of  X  schoolhouse  X . Sim-ilar wordnets do exist for about 50 different languages, but none of them are nearly as complete as the original English WordNet  X  many are small and unmaintained. Moreover, for many actively used languages, no such lexical databases exist at all. Our work ad-dresses this gap and goes beyond the notion of monolingual word-nets by constructing an integrated multilingual wordnet that maps terms (words, phrases) of many languages to their meanings in the language-independent space of senses (concepts). This allows, for example, finding Greek hypernyms of the German word  X  Schul-geb X ude  X  ( X  school building  X ). This level of semantic connections and support for IR and AI tasks can never be reached by a mere translation dictionary between two languages.

Overview. Our method for building UWN starts with a limited number of existing (monolingual) wordnets to derive a large set of senses , i.e., possible word meanings, represented in a graph G terms and senses. This graph is extended by extracting informa-tion from a range of sources like (mostly bilingual) translation dic-tionaries, (monolingual) thesauri, and parallel corpora, as well as applying automatic procedures. Statistical methods are then used to link terms in different languages to adequate senses (the words X  meanings) by analysing this graph, as illustrated in Figure 1. The left side depicts the input graph created from monolingual word-nets and translation dictionaries. The right side shows the output graph where several words in different languages have been con-nected to the sense nodes that represent their possible meanings. The difficulty is determining which senses apply to which transla-tions, e.g. a simple English word such as  X  class  X  has 9 senses listed in WordNet,  X  form  X  has 23 senses, and there are extreme examples such as the word  X  break  X , for which 75 different senses are enu-merated. We attempt to discern disambiguation information in a series of graph refinements. To this end, we construct a rich set of numeric features for assessing the validity of a graph X  X  edges. We train a support vector machine (SVM) over this feature space with a small number of hand-labelled edges. Then the SVM can automat-ically discriminate edges that are likely to be valid from spurious ones. The algorithm runs iteratively, i.e. several graphs G constructed, each refining the previous graph G i  X  1 by recomputing features and re-applying the SVM learner.
 The rest of the paper is organized as follows. Section 2 reviews WordNet and related work. Section 3 describes the initial graph construction phase. Section 4 presents the feature space and learn-ing model for graph refinement. Section 5 shows experimental re-sults that confirm the high recall and precision of our method, and demonstrates the benefit for cross-lingual text classification.
The original WordNet [14] was manually compiled at Prince-ton University to evaluate hypotheses about human cognition, but rapidly became one of the most widely used lexical resources for English natural language processing.

WordNet has sparked a number of endeavours aiming at sim-ilar databases for other languages, most importantly perhaps the EuroWordNet [40] and BalkaNet projects [39] that targeted many European languages. Individual institutes have made similar efforts for further languages, often under the auspices of the Global Word-Net Association. Unfortunately, the work on such resources has not resulted in a unified multilingual wordnet, as there are different sense identifiers, formats, licences, etc.

Previous attempts to address this situation are still in their in-fancy. Marchetti et al. [26] proposed a Semantic Web tool for managing and interlinking wordnets in order to create a multilin-gual grid, however they do not focus on the problem of actually populating this grid. Another ambitious project started in 2006, the Global Wordnet Grid [15], only contains very limited sets of concepts for English, Spanish, and Catalan, as of August 2009.
A central problem in establishing wordnets is the laborious man-ual compilation process, which typically leads to insufficient cov-erage for practical applications. Several authors have attempted to automatically or semi-automatically construct a wordnet for a not yet covered language using existing wordnets [29, 2, 7, 16, 11, 21]. Our approach adopts some of the basic ideas of their work, but goes beyond simple heuristics by computing more sophisticated features that can account for very subtle differences between correct and in-correct terms-sense mappings. Prior approaches have not been able to produce both high coverage and high precision. Many of them experienced difficulties with polysemous terms and were applied to nouns only, while our technique works particularly well for com-monly used polysemous terms. Isahara et al. [21] attempted to use multiple existing wordnets to combine information from multiple translation dictionaries, however with precision scores of 54% at best. None of these studies have explored the ideas of letting au-tomatically established mappings for different languages reinforce each other or of exploiting evidence from multilingual translation graphs. Finally, none of the previous approaches have been applied to the task of building a large-scale multilingual wordnet.
There are not many alternative approaches to multilingual lexical databases. The PANGLOSS ontology [24] was built in the 1990s to facilitate machine translation. Interesting linking heuristics were used; however no learning techniques were employed, and the final coverage was limited to around 70,000 entities in two languages. Cook [6] created a semantic network that incorporates WordNet and links nouns in three languages to wordnet nodes based on sim-ple heuristics as well as manual work. The heuristics yield high-quality results but apply to monosemous nouns only and hence fail to account for most commonly used words, as these tend to be pol-ysemous. A much larger lexical resource has been presented by Etzioni et al. [13], who use translation dictionaries and two ver-sions of Wiktionary to create a very large translation graph, which is then exploited for cross-lingual image search. Their central aim, however, is to derive a translation resource rather than construct-ing a semantic network with terms and senses equipped with ad-ditional relations like hypernymy, meronymy, etc. More recently, Adar et al. [1] have shown how to utilize the cross-linkage between Wikipedia articles in different languages for aligning Wikipedia infoboxes. This task is concerned with individual named entities (persons, organizations, etc.) only; it does not address general ter-minologies and term-sense mappings.
Lexical knowledge bases can be treated as labelled graphs. We consider weighted labelled multi-digraphs G = ( V,A,`,  X  ` Node labels are taken from the following sets: a) T  X  L : for term nodes representing words or expressions, b) S  X  C : for sense nodes representing meanings, where S is Arc labels are taken from: a) { translation } X  C  X  C : for term-to-term arcs that con-b) { meaning } X  N  X { 0 , 1 } : for arcs representing links from c) { lexicalization } : for arcs that connect sense nodes d) { related } : for term-to-term arcs that provide generic in-e) { hypernymy } : for arcs between two sense nodes n 1 , n Figure 1: Arcs in the input graph G 0 (left) and the desired output graph G f) { meronymy , antonymy ,... } : for other lexico-semantic For brevity, we shall use  X  i ( n,A ) = { n 0 | X  l,w : ( n A } to denote the in-neighbourhood, and  X  o ( n,A ) = { n ( n,n 0 ,l,w )  X  A } for the out-neighbourhood of a node, given a set of arcs A . In the following, we will work with multiple graphs of the form just described. The initial input graph G 0 will be the result of an extraction and synthesis of data from existing sources, while further graphs G i ( i  X  1 ) constructed later on will extend G 0 with statistically derived information that eventually yield the multilingual UWN graph.
The initial graph G 0 = ( V,A 0 ,` 0 ,  X  ` ) is populated by extract-ing information from a range of different sources. Most imported arcs have a weight of 1 , while a large number of so-called candidate arcs will be established with a weight of 0 .

Existing Wordnet Instances. To bootstrap the construction, we rely on existing wordnets to provide term-to-sense meaning arcs for a limited set of languages, as well as sense-to-sense arcs (e.g. hypernymy ) as described earlier. Apart from Princeton WordNet 3.0, such information is also taken from the Arabic, Catalan, Esto-nian, Hebrew, and Spanish wordnets 1 , as well as from the human-verified parts of MLSN [6]. Edges have a weight of 1 except in some cases where mappings between different versions of Word-Net [8] are applied to obtain uniform sense identifiers. Sense fre-quency information for the sense-annotated SemCor corpus [14] is incorporated as an annotation into meaning arc labels. Such in-formation reveals to us how often for example the word  X  school  X  was used to refer to a school building in the corpus.

Translation Dictionaries. A considerable number of term-to-term translation arcs with weight 1 are imported from over 100 open-source translation dictionaries that are freely available on the Web 2 . As only few such resources consist of well-structured XML, making their information amenable to machine processing frequently requires custom preprocessing steps. These involve sep-arating the actual terms from annotation information such as part-of-speech (e.g. adverb ), semantic domain (e.g. chemistry ),
See http://www.globalwordnet.org/
For example from the FreeDict project, etc. We treat translation information as n : n relationships between words, adding source or target part-of-speech labels to the transla-tion arcs whenever they are given.

Wiktionary. The community-maintained Wiktionary project offers a plethora of lexical information but relies on simple text-based mark-up rather than an explicit, precise database schema. We thus use rule-based information extraction techniques to mine translation and other arcs from eight different language ver-sions of Wiktionary.

Multilingual Thesauri and Ontologies. Translations are also obtained from concept-oriented resources such as the GEneral Mul-tilingual Environmental Thesaurus (GEMET 4 ), OmegaWiki 5 as from OWL ontologies [4]. For each sense (concept) C , we con-sider its set of label terms T ( C ) in the resource, and then add a translation arc to the graph for each t i ,t j  X  T ( C ) ( i 6 = j ) , unless they are from the same language, in which case we create a related arc instead.

Parallel Corpora. Text from conventional multilingual corpora, translation memories, film subtitles, and software localization files can be word-aligned to harness additional translation information for many language pairs. We make use of GIZA++ [28] and Uplug [37] to produce lexical alignments for a subset of the OPUS cor-pora [38], which includes the OpenSubtitles corpus. Since word alignments tend to be unreliable, we compile alignment statistics and add translation arcs to the graph between pairs of nodes where the respective term pair is encountered with a high frequency (above a specified threshold).

Monolingual Thesauri. Monolingual thesauri from the OpenOf-fice software distribution 6 provide related arcs between the terms of a single language, revealing e.g. that  X  college  X  is semantically related to  X  university  X .

Manually Classified Arcs. As our approach is based on super-vised learning, we also depend on a limited amount of manually classified meaning arcs from terms to senses, obtained via a col-laborative Web editing environment. Such arcs are either labelled as positive (correct, adequate) or negative (incorrect, inadequate).
After the initial information extraction, we apply additional pre-processing heuristics to the input graph.

First of all, we assume the translation relation is symmetric and add inverse translation arcs to ensure such links are reciprocal. Additionally, while the relation is not transitive, we use so-called triangulation heuristics to reduce the sparsity of translations. For instance, when the Italian word  X  scuola  X  has an English transla-tion  X  school  X  and a French translation  X   X cole  X , and the latter two both have a Malay translation  X  sekolah  X , then we can infer that this Malay word is also a likely translation for the Italian term. Trans-lation arcs between two term nodes n 1 , n 2 are added when where m min = 5 was chosen empirically for high accuracy.
Subsequently, the graph is pruned by merging duplicate and near-duplicate arcs as follows. We define a partial ordering  X  labels that captures when an arc label is considered more specific than another one. We assume that specific labels should be pre-ferred over generic ones, e.g. when we have two translation arcs, one without and one with lexical category information, we choose to keep only the latter although the translation might also hold for other lexical categories. This then allows us to iterate over all arcs a = ( n 1 ,n 2 ,l,w )  X  A 0 , discarding a whenever there exists an-other arc a 0 = ( n 1 ,n 2 ,l 0 ,w 0 ) with l  X  ` l 0 , w  X  w As a final preprocessing step that concludes the construction of G , we create a large set of zero-weighted arcs that denote poten-tial relationships between words and meanings that will later be evaluated. As candidate meanings we consider all senses of trans-lations of a given term. We determine all 2-hop paths of the form { ( n 0 ,n 1 ,l,w ) , ( n 1 ,n 2 ,l 0 ,w 0 ) }  X  A 0 , where n the arc label l is a translation one, and n 2 is a sense node. For each such path, a new candidate arc ( n 0 ,n 2 ,l m , 0) is created, linking a term to one of its potential senses, where l m identifies the arcs as zero-weighted meaning ones and as candidates. For in-stance, in Figure 1, the Italian word  X  piatto  X  has a translation arc to  X  course  X , which in turn has four outgoing meaning arcs in G so four candidate arcs will be created for  X  piatto  X . The arc to the sense described as  X  part of a meal  X  would be an adequate candidate arc for  X  piatto  X  that should later receive a higher weight, while the other senses, e.g.  X  academic course  X  are inadequate, and should no longer be present in the final output graph.
In each iteration, a new graph G i = ( V,A i ,` i ,  X  structed that is topologically identical to G i  X  1 and thus to G However, the weights of all candidate meaning arcs are re-assessed to reflect a refined measure of confidence in them being correct. To this end, our approach is to learn a statistical model for assessing the validity of candidate arcs. We employ a supervised classifier that is trained by the small set of hand-labelled arcs included in G , which are labelled either as correct (positive training samples) or incorrect (negative training samples). For a given candidate arc, it predicts a weight in [0 , 1] that represents the degree of confidence in the respective arc being correct, given the previous graph G The classifier operates over an appropriately defined feature space. In our approach, the feature space is recomputed with each new graph G i of the refinement process. This is in the spirit of relax-ation labelling methods and belief propagation methods for graph-ical models [17]. Directly applying standard relational learning al-gorithms to the huge graph in our task would face tremendous scal-ability problems, since we need to capture certain non-straightforward dependencies between different arcs and nodes even when they are several hops apart. Therefore, we embed information about the neighbourhood of an arc into its feature vector. In the ideal case, the weight of an arc, given its feature vector, will then be conditionally independent of the weights of other arcs, allowing us to use a more traditional learner. In each iteration i , the previous graph G used as the basis to derive a feature vector x  X  R m for each candi-date arc in G i (where m is the number of features). Details will be given in Section 4.1.

Using the feature vectors for the hand-labelled training set, we train an RBF-kernel SVM classifier. SVMs are based on the idea of computing a separating hyperplane that maximizes the margin be-tween positive and negative training instances in the feature space or in a high-dimensional kernel space [12]. For each feature vector x , SVM classification yields values f ( x )  X  R , which correspond to distances from the separating hyperplane in the kernel space. To obtain arc weights, we adopt Platt X  X  method of estimating poste-rior probabilities using a sigmoid function w := P ( w = 1 | x ) = 1+exp( af ( x )+ b ) , where parameter fitting for a and b is performed using maximum likelihood estimation on the training data [30, 25]. This allows us to obtain new arc weights in w  X  [0 , 1] for all can-didate arcs from term to sense nodes, concluding the construction of the new graph G i .
For each candidate meaning arc ( n 0 ,n 2 ,l,w ) in G i , we quan-tify evidence from the graph as an m -tuple of numerical scores x = ( x 1 ( n 0 ,n 2 ) ,...,x m ( n 0 ,n 2 ))  X  R m , such that the learn-ing algorithm be able to assess whether the arc should be accepted. We expect to see strong evidence for this arc if n 2 , a sense node, denotes one of the senses of n 0 , a term node. Given the previous graph G i  X  1 , we compute scores x i ( n 0 ,n 2 ) as listed in Table 1. In Equation 1, two nodes are directly compared by means of a cosine-based context similarity score, which will be explained in Subsec-tion 4.1.3. The underlying idea for Equations 2 and 3 (where  X   X  ,  X  are arc and path weighting functions) is that a word X  X  most likely senses can be determined by considering likely senses n its translations and related terms n 1  X   X  o ( n 0 ,A i  X  1 2 considers each successor node n 1 , and looks at how similar the successors of n 1 are to n 2 . For instance, in the simplest case, if we use an identity test as a similarity function for comparing those suc-cessors n 0 2 to n 2 , then this score effectively computes a weighted count of the number of two-hop paths from n 0 to n 2 . For example, in Figure 1, there are multiple paths from the German word  X  Kurs  X  to the  X  academic course  X  sense node. Equation 3 is similar, but normalizes with respect to the number of alternative choices in the denominator. In the simplest case, the dissim function will simply count how many alternative senses there are, so if n 1 has n of its senses, and 4 other senses, it would return 4 , and lead to a summand of 1 1+4 for n 1 , which reflects the probability of reaching n 2 from n 1 . Equation 3 is also applied in the opposite direction to quantify reachability information from a sense node to a term node.
More sophisticated scores are obtained by applying additional weighting and normalization. The scores depend on a number of auxiliary formulae, in particular combinations of arc weighting func-tions  X  1 ,  X  2 , as described in Section 4.1.1, path weighting func-tions  X  , described in Section 4.1.2, and measures of semantic relat-edness, described in Section 4.1.3. For example, in Equation 3 we may wish to not count all alternative senses, instead producing a weighted score where alternative senses are not fully considered if they are very similar or if their lexical category tags do not match.
The different versions of  X  1 listed in Table 2 estimate the rele-vance of a connection from a term n 0 to a translation or related term n . Equation 6 filters out related arcs, while Equation 7 consid-ers the size of the out-neighbourhood of n 0 , counting the number of terms that have outgoing meaning arcs. Equation 8 is similar to Equation 3 and normalizes with respect to a weighted in-degree of n 1 for terms from the same language.

Instantiations of  X  2 estimate the relevance of connections from translations or related terms n 1 to sense nodes n 2 . For this, Equa-tion 10 considers the weights of meaning arcs, while Equation 11 uses sense corpus frequencies. Equations 9 and 12 are helper functions.
Several features described in Table 1 integrate a function  X  that assigns weights to paths in the graph. Apart from the trivial choice of setting it to a constant value, we use  X  lc as a version that consid-ers lexical categories (part-of-speech tags) associated with nodes in the graph. Many of the previous studies on automatically build-ing wordnets dealt with nouns exclusively, whereas all lexical cate-gories are respected in our approach, so some means of preventing, for example, a noun from being mapped to a verb sense is required.  X  lc ( n 0 ,...,n k ) is supposed to estimate whether the nodes along the path from n 0 to n k have the same or at least compatible lexical categories. It is computed as Here,  X  c ( n i ,n i +1 ) estimates whether a local transition from n n i +1 is possible with category c  X  C with the following heuristics. 1. In some cases, there may be a translation arc with match-2. When this fails, we compare possible categories of n 3. If this fails, we attempt to use learnt models for surface prop-4. If none of the aforementioned steps apply, a default score of
The surface form learning is carried out by growing a C4.5 deci-sion tree [12] with the following features: 1. Prefixes and suffixes of a word up to a length of 10 (with-2. Boolean features for first character capitalization and com-The reliability of the decision tree depends largely on the language. For each lexical category and language, we evaluated on the re-spective validation set, obtaining F 1 -scores between 0.03 and 0.99. Later on, for a given term to be analysed, we use the confidence es-timate c from the decision tree X  X  leaves only in the following cases: 1. the F 1 -score on the validation set was high 2. c &gt; 0 . 5 and the precision on the validation set was high 3. c &lt; 0 . 5 and the recall on the validation set was high
The feature vector computation also uses a set of different se-mantic relatedness measures. To see the potential benefit of this technique, consider the following example. The single sense of  X  schoolhouse  X  is related to the educational institution sense of the word  X  school  X , but not to the sense of  X  school  X  that refers to groups of fish. So, if a term node has translation arcs to both  X  school  X  and  X  schoolhouse  X , their semantic relatedness tells us that the educa-tional senses of  X  school  X  are much more likely to be correct than the one referring to fish. We consider four different measures of semantic relatedness.
Our iterative learning procedure makes use not only of the small set of manually classified meaning arcs supplied as training in-stances, but also benefits from the enormous numbers of originally unlabelled instances. There is often some form of mutual reinforce-ment of correct and highly weighted (but not known to be correct) arcs and there is some gradual down-weighting of incorrect arcs in the course of the iterations. Thus, our method can be seen as a form of semi-supervised learning. As a stopping criterion, we use either a withheld validation set of manually classified arcs (not used for training) or apply cross-validation with the training data, and check if a loss function L ( G i ) shows a reduction L ( G i  X  1 (where epsilon may also be slightly negative). In practice, we ob-served that 2-4 iterations suffice to stabilize the precision and recall measures on the graph.

Having determined the most profitable iteration i  X  = arg max L ( G i ) with a loss function L 0 (possibly different from L ), we can transform G i  X  into the final UWN graph G 0 i  X  using the following steps: Table 1: Feature computation formulae, where sim  X  n 0 , X  ) ,n )  X  2 ( n 1 ,n 0 2 ) sim( n 2 ,n 0 2 ) (4) ,n )  X  2 ( n 1 ,n 0 2 )(1  X  sim( n 2 ,n 0 2 )) (5) freq( n 1 ,n 2 ) yields the frequency of term n 1 with sense n lexical categories.
 ( 1  X  ( n 1 ,n 2 ,l,w )  X  A i  X  1 : l 6 = related 0 otherwise |{ n sim ( 1 ` i  X  1 ( n 0 ) , ` i  X  1 ( n 0 0 ) provide same language code 0 otherwise ( 1  X  ( n 1 ,n 2 ,l,w )  X  A i  X  1 : w &gt;  X  0 otherwise ( 1 ` i  X  1 ( n 2 ) , ` i  X  1 ( n 0 2 ) provide same lexical category 0 otherwise (i) We retain from G i  X  only arcs whose labels designate them as (ii) Optionally, we threshold using two parameters w min (iii) Finally, we remove all nodes of degree 0 .

Omitting step (ii) leads to a statistical form of lexical database where edge weights provide the degree of confidence of a link. Weighted edges can be useful in certain application settings. In-cluding this step yields a more conventional, unweighted lexical database where only high quality links are retained. Our specific choices of loss functions and thresholds are given in the section on experimental results.
We used the Java programming language to develop a platform-independent knowledge base processing framework. For efficiency reasons, the weighted labelled multi-digraphs were stored in cus-tom binary format databases, with optimized index and data caching as well as Bloom filtering for reduced disk access, i.e. avoiding un-necessary reads when no data is available. This framework allowed us to flexibly plug together information extraction modules, knowl-edge base processors, as well as exporters and analysis modules into knowledge base processing pipelines. Our graph refinement procedure is integrated as a link processor that assesses links be-tween two entities and produces new weights. For statistical learn-ing, it relies on the LIBSVM implementation [5] using an RBF kernel K ( x,y ) = exp(  X  1 m || x  X  y || 2 ) where m is the number of features. Table 3: Iterations of algorithm with validation set scores (for w min = 0 . 7 ,  X  w min = 0 . 6 )
Graph Precision Recall F 1 # accepted G 0 N/A 0.00% 0.00% 0 G 1 83.96% 67.42% 74.79% 1,540,206 G 2 83.70% 68.48% 75.33% 1,594,652 G 3 83.89% 68.64% 75.50% 1,595,763 G 4 83.90% 67.88% 75.04% 1,573,395 Dataset Sample French 311 89 . 23%  X  3 . 39% German 321 85 . 86%  X  3 . 76% Mandarin Chinese 300 90 . 48%  X  3 . 26%
Following Section 3, G 0 was constructed with 448,069 existing meaning arcs (from the input wordnets, mainly English, Spanish, Catalan), 10,805,400 translation arcs (from the dictionaries, Wiktionary, thesauri and parallel corpora), and 10,343,601 candi-date meaning arcs (generated following Section 3.3, on average 7.7 per term node). It contained roughly 129,500 sense nodes and 1.3 million term nodes with candidate arcs (5 million overall). We added 2,445 human-classified meaning arcs for training, out of which 610 were positive examples. The training set was compiled by manual annotation of candidate meaning arcs as either positive or negative for randomly selected French and German terms, rather than for randomly selected instances. This means that the risk of overfitting is reduced and the learner is channelled to focus explic-itly on the distinction between negative and positive examples for a given word rather than coincidental differences between different words. We used a validation set of 2,901 French/German candidate meaning arcs, classified manually as positive or negative using the same methodology, and selected F 1 scores for this validation set on the output graph for w min = 0 . 6 ,  X  w min = 0 . 5 as the loss function.
The algorithm ran for four iterations until it failed to improve the F 1 -score, as shown in Table 3. The input graph G 0 cover any of the validation arcs, and thus has a recall and F of 0%. English is the most widely represented language within the input graph, both with respect to the input wordnets and for the translations, so the first iteration provided for the most significant gains and already delivered excellent results. In the next iteration, G 1 served as the input graph, leading to an improved F 1 -score for G 2 because a larger range of terms are equipped with non-zero meaning arcs in G 1 compared to G 0 . These improvements de-crease very quickly, since the additional amount of information available to the feature computation process, compared to previous iterations, keeps diminishing.

At this point, we have the choice of preferring high precision, e.g. G 2 has 91.59% precision at 44.55% recall for w min = 0 . 9 ,  X  w min = 0 . 75 , or high recall, e.g. G 3 gives us 73.92% precision at 80.30% recall for w min = 0 . 3 ,  X  w min = 0 . 25 . Our loss func-tion balances precision and recall, making G 3 the most profitable graph. Figure 2 shows the tradeoff between precision and recall on G 3 . For the final UWN output graph, we chose w min = 0 . 6 , Figure 2: Precision-Recall curve on validation set for G 3 w  X  w min = 0 . 5 as it provided good coverage at a reasonable pre-cision. Figure 3 provides an excerpt from this graph, highlight-ing how words in different languages have been disambiguated to link to the appropriate senses of the English word  X  school  X , e.g., in French, the term  X  banc  X  is used to refer to a school of fish. We recruited human annotators for three languages, and asked them to evaluate randomly chosen arcs in the respective language from this output graph, relying on Wilson score intervals to generalize ble 4. These randomly chosen arcs are not related to the training or validation sets, which moreover did not contain any Mandarin Chinese terms, so the results show that our learning approach ap-plies cross-lingually. It must be pointed out that it is not possible to reliably evaluate the accuracy of a wordnet using pre-existing wordnets, as they do not fulfil the closed world assumption, i.e. a term-sense arc not occurring in an existing wordnet does not war-rant the conclusion that the link is false. This is particularly true for current non-English wordnets, which often have limited coverage and sense inventories based on older versions of WordNet.
Table 5 shows the coverage of the output graph. Keeping in mind that the final UWN graph retains only candidate meaning arcs, these figures do not include any meaning arcs imported from the in-put wordnets, and only count term nodes that are connected to sense nodes via these new candidate meaning arcs. There are terms in more than 200 languages in UWN. The most well-represented lan-guages result quite directly from the selection of translations in the Figure 3: Excerpt from UWN graph with meaning arcs from terms to three sense nodes Table 5: Coverage of final UWN graph with respect to accepted candidate meaning arcs as well as terms.
 Language Meaning Arcs Distinct Terms Overall 1,595,763 822,212 By Language German 132,523 67,087 French 75,544 33,423 Esperanto 71,247 33,664 Dutch 68,792 30,154 Spanish 68,445 32,143 Turkish 67,641 31,553 Czech 59,268 33,067 Russian 57,929 26,293 Portuguese 55,569 23,499 Italian 52,008 24,974 Hungarian 46,492 28,324 Thai 44,523 30,815 Others 795,782 427,216 By Lexical Category Nouns 1,048,003 589,536 Verbs 221,916 88,189 Adjectives 289,328 147,257
Adverbs 36,095 26,254 input graph G 0 . We found that terms with translations to many lan-guages had high chances of being included. Our approach thus ad-dresses a long-standing problem in automatic construction of word-nets, namely that of insufficient coverage of commonly used words, which tend to be more polysemous. Using sophisticated features, it carefully benefits from cross-lingual evidence to find meanings of such terms, while previous approaches had trouble coping with the polysemy of commonly used words. The break-down by part-of-speech shows that the majority of terms are nouns. The terms in UWN have meaning links to a total of 80,620 distinct sense nodes. Table 6 shows average degrees with respect to meaning arcs for term nodes (out-degree) and sense nodes (in-degree), re-vealing the level of polysemy of terms according to UWN. The middle column shows average out-degrees when term nodes with only one meaning arc are excluded. We further evaluated to what extent relationships imported from Princeton WordNet apply to UWN. The intuition is that relations between senses, e.g. hypernymy , apply independently of the lan-guage of the terms associated with the respective senses. For sev-eral types of relations, at least 100 randomly selected links between two senses were assessed, where both senses have associated Ger-man language terms (linked via meaning arcs). Table 7 shows that the overall precision is high. Incorrect relationships resulted almost entirely from incorrect meaning arcs.

In addition to relations between senses, WordNet also provides relations between specific words with respect to senses of those words. Such relations cannot be applied directly to UWN, how-ever, in some cases, we can infer from them more generic relation-ships between senses. For instance, when WordNet tells us that the word  X  scholastic  X  is derivationally related to the word  X  school  X , we can interpret this as a generic indicator of semantic relatedness. Antonymy relationships between words such as between  X  good  X  and  X  bad  X  are re-interpreted as a generic form of semantic opposi-tion between senses. These, too, were evaluated in Table 7. Table 6: Average degree with respect to meaning arcs of term nodes (out-degree) and sense nodes (in-degree) Nouns 1.78 3.20 12.76 Verbs 2.52 4.24 16.12 Adjectives 1.96 3.63 15.19 Adverbs 1.37 2.53 9.97 Total 1.94 3.38 13.56 hypernymy 87.1%  X  4.8% instance 89.3%  X  4.4% similarity 92.0%  X  3.8% category 93.3%  X  4.5% meronymy (part-of) 94.4%  X  4.1% meronymy (member-of) 92.7%  X  4.0% meronymy (substance-of) 95.6%  X  3.5% antonymy (as sense opposition) 94.3%  X  3.9% derivation (as semantic similarity) 94.5%  X  4.0% We studied semantic relatedness assessment as an application of UWN in conjunction with Princeton WordNet X  X  sense relations and descriptions. The objective is to automatically estimate the degree of relatedness between two words, producing scores that correlate well with the average ratings by human evaluators. For instance,  X  curriculum  X  is much more closely related to a word like  X  school  X  than  X  water  X . Given two term nodes t 1 , t 2 , we estimate their relat-edness as rel( t 1 ,t 2 ) = max using semantic relatedness measures for sense nodes described in Section 4.1.3 and w ( t,s ) denoting the meaning arc weight. Three German-language datasets are compared with state-of-the-art scores obtained for GermaNet, the manually compiled German wordnet, and Wikipedia, as reported by Gurevych et al. [19]. In Table 8, the first row lists the inter-annotator agreement between different hu-man evaluators and the number of term pairs rated for each dataset. The following rows show that UWN can be more useful than hand-crafted resources, with respect to both the correlation with human judgments (Pearson product-moment correlation coefficient) and the coverage (the number of term pairs from the dataset where both terms are found in the respective lexical database).
Another applied task we considered was cross-lingual text clas-sification. This is a very challenging task, where text documents are supposed to be classified, usually by topic, given only class-labelled training documents for a completely different language.
We preprocess a document by removing stop words and per-forming part-of-speech tagging as well as lemmatization using the TreeTagger [34]. In addition to the original term frequencies, we map each term to the respective sense nodes listed by UWN or by Princeton WordNet (for English words), embracing a rather sim-Table 9: Cross-lingual text classification in terms of micro-averaged precision, recall, and F 1 -score.
 English-Italian Terms only 69.90% 66.81% 68.32% Terms and senses 83.24% 70.49% 76.34% English-Russian Terms only 57.86% 46.67% 51.66% Terms and senses 67.87% 74.94% 71.23% Italian-English Terms only 71.97% 77.06% 74.43% Terms and senses 76.59% 79.67% 78.10% Italian-Russian Terms only 59.65% 57.15% 58.37% Terms and senses 68.03% 79.26% 73.21% Russian-English Terms only 68.36% 66.34% 67.34% Terms and senses 73.56% 80.29% 76.78% Russian-Italian Terms only 67.85% 57.48% 62.24%
Terms and senses 71.38% 72.21% 71.79% ple approach that foregoes disambiguation: For every single oc-currence of a term t , we take all sense nodes n s with a matching part-of-speech tag, and normalize by dividing by the sum of their meaning arc weights. Thus, if a term has four equally relevant sense nodes in UWN, then each receives a local weight of 1 ditionally, these senses pass on their weight to neighbouring nodes immediately connected via hypernymy arcs. Summing up the weights of local occurrences of a token t (either an original doc-ument term or a sense node) within a document d , one arrives at document-level occurrence scores n ( t,d ) , from which one can then compute TF-IDF feature vectors using the following formula: where D is the set of training documents.

This approach was tested using a cross-lingual dataset derived from the Reuters RCV1 and RCV2 collections of newswire arti-cles [31, 32]. These articles are mostly business related, and have topical class labels such as  X  accounts/earnings  X ,  X  economic perfor-mance  X  or  X  funding/capital  X . For several pairs of languages, we created independent datasets by randomly selecting 10 topics cov-ered by both languages in order to arrive at ` 10 2  X  = 45 separate binary classification tasks, each based on 150 training documents in one language, and 150 test documents in a second language, like-wise randomly selected with balanced class distributions.
Table 9 compares the standard bag-of-words TF-IDF represen-tation for terms (using only genuine term frequencies as n ( t,d ) in Equation 13) with the extended representation that includes map-pings to sense nodes as frequencies. The scores shown were pro-duced with linear kernel SVMs using the SVMlight implementa-tion in its default settings, which are known to work well for text classification [23]  X  LIBSVM produced similar margins between the two approaches but overall slightly lower absolute scores. Since many of the Reuters topic categories are business-related, using only the original document terms, which include names of com-panies and people, already works surprisingly well. By consider-ing sense nodes, both precision and recall are boosted significantly. This shows e.g. that English terms in the training set are being mapped to the same senses as the corresponding Russian terms in the test documents. The margins could be boosted even further by invoking more intelligent word sense disambiguation strategies or using more advanced sense expansion strategies. [10].
We have presented a novel approach to building a large-scale universal wordnet (UWN) that contains 1.5 million meaning rela-tionships from over 800,000 terms in over 200 languages. UWN is available at http://www.mpi-inf.org/yago-naga/uwn/ . Our experiments have shown that UWN is useful in applied tasks. In addition to the existing applications of WordNet, such as question answering, text classification, semantic relatedness assessment, and so on, which are now possible for a greater range of languages, we also anticipate UWN being used for tasks that explicitly make use of multilingual connections in the network, e.g. cross-lingual in-formation retrieval or cross-lingual text classification.
We have created a public querying and editing website for UWN that in the long run may allow us to address issues such as correct-ing inaccurate arcs and adding new senses to cope with language-specific subtleties (in particular lexical gaps, incongruence). Since the confidence estimates derived from the learnt models correlate quite well with the evaluated precision on the arcs, manual efforts could be channelled to focus explicitly on arcs with borderline con-fidence values and terms without accepted meaning arcs. An update submitted to the Web interface or an additionally imported transla-tion dictionary for one language can subsequently lead to a suffi-cient amount of accumulated evidence to sway the model towards accepting mappings in entirely different languages. Hence, it is safe to expect continued growth and refinement in the future.
Finally, we envision new data-driven techniques that automati-cally expand the sense inventory of UWN. Snow et al. [35] have shown that this is feasible by extending WordNet using monolin-gual corpora. Using our universal wordnet as the underlying core, improved algorithms are conceivable. [1] E. Adar, M. Skinner, and D. S. Weld. Information arbitrage [2] J. Atserias, S. Climent, X. Farreres, G. Rigau, and [3] J. Bos and K. Markert. Recognising textual entailment with [4] P. Buitelaar, T. Eigner, and T. Declerck. OntoSelect: A [5] C.-C. Chang and C.-J. Lin. LIBSVM: a library for support [6] D. Cook. Automatic translation for MLSN. In [7] J. Daud X , L. Padr X , and G. Rigau. Mapping wordnets using [8] J. Daud X , L. Padr X , and G. Rigau. Making wordnet mappings [9] M. Davis and M. D X rst. Unicode normalization forms, Rev. [10] G. de Melo and S. Siersdorfer. Multilingual text [11] G. de Melo and G. Weikum. A machine learning approach to [12] R. O. Duda, P. E. Hart, and D. G. Stork. Pattern [13] O. Etzioni, K. Reiter, S. Soderland, and M. Sammer. Lexical [14] C. Fellbaum, editor. WordNet: An Electronic Lexical [15] C. Fellbaum and P. Vossen. Connecting the universal to the [16] D. Fi X er. Using multilingual resources for building SloWNet [17] L. Getoor and B. Taskar. Introduction to Statistical [18] Z. Gong, C. W. Cheang, and L. H. U. Web query expansion [19] I. Gurevych, C. M X ller, and T. Zesch. What to be? -[20] S. M. Harabagiu, editor. Proc. Workshop Usage of WordNet [21] H. Isahara, F. Bond, K. Uchimoto, M. Utiyama, and [22] Y. R. Jean-Mary and M. R. Kabuka. Asmov: Results for [23] T. Joachims. Making large-scale support vector machine [24] K. Knight and S. K. Luk. Building a large-scale knowledge [25] H.-T. Lin, C.-J. Lin, and R. C. Weng. A note on Platt X  X  [26] A. Marchetti, M. Tesconi, F. Ronzano, M. Rosella, and [27] M. Marsza X ek and C. Schmid. Semantic hierarchies for [28] F. J. Och and H. Ney. A systematic comparison of various [29] A. Okumura and E. Hovy. Building Japanese-English [30] J. C. Platt. Probabilistic outputs for support vector machines [31] Reuters. Reuters Corpus, vol. 1: English Language, [32] Reuters. Reuters Corpus, vol. 2: Multilingual Corpus, [33] N. Schlaefer, J. Ko, J. Betteridge, M. Pathak, E. Nyberg, and [34] H. Schmid. Probabilistic part-of-speech tagging using [35] R. Snow, D. Jurafsky, and A. Y. Ng. Semantic taxonomy [36] F. M. Suchanek, G. Kasneci, and G. Weikum. YAGO: A [37] J. Tiedemann. Combining clues for word alignment. In Proc. [38] J. Tiedemann. The OPUS corpus -parallel &amp; free. In Proc. [39] D. Tufi  X s, D. Cristea, and S. Stamou. BalkaNet: Aims, [40] P. Vossen, editor. EuroWordNet: A Multilingual Database
