 We propose a domain-dependent/independent topic switch-ing model based on Bayesian probabilistic modeling for mod-eling online product reviews that are accompanied with numerical ratings provided by users. In this model, each word is allocated to a domain-dependent topic or a domain-independent topic, and the distribution of topics in an on-line review is connected to an observed numerical rating via a linear regression model . Domain-dependent topics utilize domain information observed with a corpus, and domain-independent topics utilize the framework of Bayesian Non-parametrics , which can estimate the number of topics in pos-terior distributions. The posterior distribution is estimated via collapsed Gibbs sampling. Using real data, our proposed model had smaller mean square error and smaller average mean error with a small model size and achieved conver-gence in fewer iterations for a regression task involving on-line review ratings, outperforming a baseline model that did not consider domains. Moreover, the proposed model can also tell us whether the words are positive or negative in the form of continuous values. This feature allows us to extract domain-dependent and -independent sentiment words. I.2.7 [ Arti cial Intelligence ]: Natural language process-ing X  text analysis Algorithms, Experimentation Online reviews with numerical ratings; Sentiment Analysis; Hierarchical Dirichlet Process; Domain-Dependent/Independent Topic Switching Model;
Online reviews for products often take the form of writ-ten descriptions (texts) together with numerical ratings pro-vided by users. Users X  opinions and sentiments towards products are often included in online reviews, and text min-ing has been applied to extract this knowledge. This has huge potential for allowing companies to improve their prod-ucts and detect problems with their products. Hence, there have been many studies on online reviews.

The field of Bayesian probabilistic modeling for online re-views is also active. Supervised Latent Dirichlet Allocation (sLDA)[2] has been proposed to model texts with numeri-cal ratings, such as online reviews. sLDA is based on La-tent Dirichlet Allocation (LDA)[3], which is often used in text mining to analyze texts that lack numerical ratings. LDA assumes that each text is described by a probability distribution over latent topics, and moreover, topics are de-scribed by a probability distribution over a vocabulary of words. LDA can discover latent structures and topics in a corpus by an inference algorithm such as collapsed Gibbs sampling[7], Variational Bayes[3], or collapsed Variational Bayes[16]. sLDA is similar to LDA except that a response variable associated with each text is added. This response variable corresponds to a rating in an online review.
Although the words used in online reviews are different in each domain, like BOOK, CD, DVD, and ELECTRONICS, the domains are not considered in sLDA. Take the domains CD and ELECTRONICS as examples. In the domain CD, words such as  X  X usic X ,  X  X ock X ,  X  X lassical X , and  X  X op X  will be ob-served. In the domain ELECTRONICS, words such as  X  X e-frigerator X ,  X  X amera X ,  X  X ony X ,  X  X omputer X , and  X  X attery X  will be observed. We call such words domain-dependent words. This means that the frequencies over a vocabulary of words will be different among domains. On the contrary, domain-independent words also exist in online reviews for products; for example, these include  X  X ustomer support X ,  X  X elivery X ,  X  X amage X ,  X  X cratched X , and  X  X uality X . Therefore, the model for online reviews should consider both domain-dependent and -independent words, and this approach may improve some text mining tasks, such as sentiment regression, which predicts numerical ratings from texts that lack numerical ratings.
 Our proposed model, called the Domain-Dependent/Independent Topic Switching Model (DDITSM), considers domain -dependent and -independent w ords to handle online reviews that are accompanied with numerical ratings provided by users in multiple domains. DDITSM is based on sLDA, but DDITSM differs in that is considers four additional factors: observed domain labels, such as BOOK, CD, DVD, and ELECTRONICS; domain-dependent topics; infinite domain-independent topics; and switch variables that are used to decide whether each word belongs to the domain-dependent topics or the infinite domain-independent topics.
 Our contribution is four-fold: 1. DDITSM introduces four new factors into sLDA: ob-2. Domain-dependent topics can utilize domain labels, 3. Because the number of domain-independent topics is 4. By using real online review data for products in mul-Figure 1 outlines the concept of DDITSM.

The rest of the paper is organized as follows. Section 2 introduces related work. Section 3 presents our proposed model, DDITSM. Section 4 discusses inference in DDITSM. Section 5 gives experimental results and some discussion. Section 6 concludes this paper.
Some topic models for online reviews with numerical rat-ings have been proposed in the past. As previously ex-plained, Supervised LDA [2] (sLDA), a model combining LDA and linear regression, can handle documents with rat-ings, like customer reviews containing ratings of products, movies, and so on. Multilingual Supervised LDA[5] (ML-SLDA) is a model based on supervised LDA for treating multilingual text resources. This model suggests that use Fi gure 1: The concept of domain-dependent topics, in nite domain-independent topics, and switch vari-able in generative process of a word. (top) A word is generated using domain-dependent or -independent topics. A switch variable decides whether domain-dependent or -independent topics are used. (mid-dle) Example of generative process for the word 'mu-sic' in the domain 'CD'. (bottom) Example of gen-erative process for the word 'good' in the domain 'CD'. of multilingual text resources is valid for sentiment analy-sis. For modeling multiple ratable aspects in reviews, Multi-Grain LDA (MG-LDA)[18] and the Multi-Aspect Sentiment Model (MAS) [17] have been proposed. MG-LDA intro-duced global topics and local topics. Global topics detect types of reviewed items, like reviews of iPod or reviews of WALKMAN in reviews of MP3 players. Local topics de-tect ratable aspects like battery , memory , and sound quality . MAS considers numerical ratings of reviews in addition to the ratable aspects considered in MG-LDA.

Our framework for integrating domain information is based on topic models for a labeled corpus because we as-sume domain information as labels. DiscLDA[9] has a vari-able that denotes document categories in each document. Labeled LDA[12] can handle documents with labels by set-ti ng a one-to-one correspondence between topics and la-bels. An extension of Labeled LDA called Partially Labeled Dirichlet Allocation (PLDA)[14] assumes a fixed number of topics in each observed label. Multi-Multinomial LDA (MM-LDA)[13] can handle observed labels in documents, like a bag-of-words. DiscLDA handles documents with a single label, whereas Labeled LDA, MM-LDA, and PLDA handle documents with multiple labels. In [1], constraints called topic-in-set knowledge are introduced into collapsed Gibbs sampling for LDA. This method gives hard constraints to latent variables in LDA. These constraints are similar to the method of Labeled LDA explained in a later sec-tion. Labeled LDA restricts latent variables at the document level. On the other hand, LDA with introduced topic-in-set knowledge restricts them at the word level. Interestingly, these two methods were proposed independently. An exten-sion of PLDA called the Partially Labeled Dirichlet Process (PLDP)[14] decides the number of topics in each label by utilizing Bayesian Nonparametrics .
 Our model can also handle polarities of topics and words. The Joint Sentiment-Topic Model (JST)[10] and the Aspect and Sentiment Uni cation Model (ASUM)[8] model senti-ments (polarities of words or sentences) and topics by in-troducing latent variables for polarities. The Joint As-pect/Sentiment model (JAS)[20] also has latent variables for polarities and considers reviewable aspects, such as in [8], and aspect-specific opinion words. These models do not consider domains, in contrast to our proposed model, which utilizes domain information as labels and handles domain dependence and independence.

Yoshida et al. [21] proposed a model that considers do-main labels, domain dependence/independence, and word polarities. They focus on transfer learning[11], whereas our approach starts with how to incorporate side information provided together with documents, like Labeled LDA. The model in [21] assumes that one document has one domain label, but our proposed model can handle multiple domain labels in one document. Some reviews often have multiple domain labels, like a review of a biography of a musician, which has domain labels MUSIC and BOOK . In addition, the models in [10, 8, 20, 21] have discrete polarities, like negative, positive, and neutral, whereas our proposed model assumes that the polarities take continuous values.
Therefore, our proposed model is different from the other models mentioned in this section, because it can handle texts, numerical ratings, domain labels, domain depen-dence/independence, and polarities as continuous values si-multaneously. The Domain-Dependent/Independent Topic Switching Model (DDITSM) is an extension of Latent Dirichlet Alloca-tion (LDA), which is widely used to identify the latent topics in a collection of documents. In this model, each document is represented as a mixture of latent topics whose number is fixed, and topic are described by a probability distribution over a vocabulary of words. T is the fixed number of topics. V is the size of the vocabulary. D is the number of docu-ments. N d is the number of words in the d -th document. w di is the i -th word in the d -th document. z di is the latent topic allocated to word w di . d is a probability vector whose size is T . This vector is the parameter of the multinomial distribution that describes the mixture of latent topics in the d -th document. t is a probability vector whose size is V . This vector is the parameter of the t -th topic X  X  multinomial distribution that describes the probability distribution over a vocabulary of words. Dirichlet distributions are placed as priors on d and t , with d Dir ( ) and t Dir ( ). is a T -dimensional hyperparameter vector, and is a V -dimensional hyperparameter vector.

Online reviews for products often belong to a domain, like  X  X OOK X  or  X  X D X , and contain domain-dependent words. In addition, there are domain-independent words, such as  X  X us-tomer support X ,  X  X elivery X ,  X  X amage X ,  X  X cratched X , and  X  X ual-ity X . DDITSM considers whether each word w di is a domain-dependent or -independent word. In the generative process, if the word w di is a domain-dependent word, it is gener-ated from the domain-dependent topic DD d , and if it is a domain-independent word, it is generated from the domain-independent topic DI d . To decide whether words are gener-ated from domain-dependent or -independent topics, latent switch variables x d , taking a value of f 0,1 g , are introduced in DDITSM. If x di = 0, word w di is generated from the domain-dependent topic DD d , and if x di = 1, word w di is generated from the domain-independent topic DI d .
To model domain-dependent topics DD , DDITSM uti-lizes Labeled Latent Dirichlet Allocation (Labeled LDA), which is built on LDA. Labeled LDA assumes a collection of observed labels  X  and handles a collection of labeled doc-uments. In Labeled LDA, latent topics and observed labels correspond one-to-one, and each document is described by using latent topics constrained by an observed label set in the document. DDITSM views domains as labels, and the dimension of DD d equals the number of domains. In this paper,  X  denotes a collection of  X  d that denotes observed domains of the d -th document and that is formed as a bit mask vector.  X  dt denotes the t -th element of  X  d , and DD denotes the t -th element of DD d . If observed domains in a corpus are BOOK, CD, DVD, and ELECTRONICS, the dimension of DD d is four. Then, if the domain of a d -th online review text is CD,  X  d is (0, 1, 0, 0), and the text is described by DD d taking values where  X  dt = 1. In this case, value. This approach enables us to handle multiple domains and to extract domain-dependent words by inferring proba-bility distributions over a vocabulary of words corresponding to domain-dependent topics.

To model domain-independent topics DI , DDITSM uti-lizes Hierarchical Dirichlet Process Latent Dirichlet Alloca-tion (HDP-LDA). The number of domain-dependent topics equals the number of observed domains; however, the num-ber of domain-independent topics is unknown. Deciding the number of domain-independent topics generally needs cross-validation, but this takes a long computational time. In particular, as the number and variety of parameters in the model increase, a longer computational time is needed. An alternative framework is to consider the HDP[15] for pri-ors, where domain-independent topics are automatically es-timated. The HDP is composed of a hierarchy of Dirichlet Processes (DPs)[6]. In the generative process of HDP, a global distribution G 0 is drawn from DP ( ; H ), where de-notes a concentration parameter, and H denotes a base dis-tribution. Then, each distribution f DI d g D d =1 is drawn from DP ( G 0 ; 0 ) with base distribution G 0 and concentration pa-ra meter 0 . Next, a parameter of the model is drawn from d , and individual data w di are generated from the model. As just described, the number of topics is assumed to be infinite to apply HDP to LDA.

To model numerical ratings of online reviews, DDITSM utilizes Supervised Latent Dirichlet Allocation (sLDA), which is a model combining LDA and a linear regression model. In sLDA, the numerical rating comes from a normal distribution whose mean is the dot product of a regression weight parameter and counts of topics in a document. The regression weight parameter is a vector whose size is the number of topics. In DDITSM, the numerical rating y d of the d -th document comes from a normal distribution whose mean is the dot product of a regression weight parameter ! and counts of domain-dependent and -independent top-ics  X  z d . ! is a vector whose size is the sum of the number of domain-dependent and -independent topics. Because the number of domain-independent topics is infinite, the dimen-sion of ! is also infinite. In addition, ! shows whether the topic is positive or negative in the form of a continuous value. For example, if ! t 0 that denotes the t 0 -th element of ! takes a lower value, the t 0 -th topic is a negative topic. Then, the head of the probability distribution over a vocabulary of words corresponding to the t 0 -th topic will tend toward negative words.

The generative process of DDITSM is summarized in Ta-ble 1, and the graphical model is depicted in Figure 3. Ex-planations of symbols are summarized in Table 2. Figure 2 also shows the manner of handling numerical ratings in DDITSM. Step 5(a) and 5(b) in Table 1 follow the gener-ative process of Labeled LDA[12].  X  t is a parameter for generating domain labels  X  dt . L d is the projection matrix of size M d T , where M d is the number of observed domain labels in document d , and T is the number of domains in the corpus. T equals the number of domain-dependent topics. For each row i = 1 ; :::; M d and column j = 1 ; :::; T , L defined as: Here, index ( X  d ) denotes a collection of indices t , where  X  dt = 1. L d is used to make DD d of size M d as follows: d generated in this manner is used as a parameter of the prior for DD d , and as a result, DD d is constrained by  X  we have described previously. More details can be found in [12].
Here we describe the collapsed Gibbs sampling scheme in which DD , DI , DD , DI , and are integrated out for DDITSM. The collapsed Gibbs sampling scheme consists of two steps. The first step is sampling the topic z di , which al-locates words w di to latent topics, and sampling the switch variable x di . We jointly sample the topic z di and switch variable x di from the posterior distribution conditioned on all of the other allocated topics z di and switch variables x di in the corpus. Since z di is selected from finite domain-dependent topics or infinite domain-independent topics, we must consider a standard Gibbs sampling scheme, as in La-Fi gure 2: The manner of handling numerical ratings in DDITSM. beled LDA, and a direct assignment scheme, as in HDP-LDA. The sampling equations are derived as follows: p ( z di = t; x di = 0 j w di = v; w di ; z di ; x di ; !; y; p ( z di = k; x di = 1 j w di = v; w di ; z di ; x di ; !; y; 8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; : Here, 1 is a vector of size T 0 in which all elements take the value 1. Detailed notations are described in Table 3. The direct assignment scheme involves sampling m and : p ( m jk = m j z; m jk ; ) / Here, in the metaphor of a Chinese restaurant franchise[15], m jk denotes the number of tables in restaurant j serving dish k , and m k denotes the number of tables serving dish k . s ( n; m ) are unsigned Stirling numbers of the first kind, defined as s ( n + 1 ; m ) = s ( n; m 1) + ns ( n; m ), provided s ( n; m ) = 0 for m &gt; n . The number of topics increases if z di = k new , and the topic k is deleted if the count of words assigned to topic k equals zero.
The second step is sampling regression weight parameter ! . We infer ! using Gibbs sampling: p ( !
N where ! t 0 denotes the t 0 -th element of ! ; ! t 0 denotes the elements other than the t 0 -th element; N ( ) denotes a Gaus-sian distribution that has the mean as the first argument and the variance as the second; and  X  z dt 0 and  X  z dl counts of the t 0 -th and l -th topics in the d -th document nor-malized by the number of words in the d -th document.
After sufficiently iterating the first and second step alter-nately in the collapsed Gibbs sampling scheme above, the distributions of DD d , DI d , DD t , DI k , and d can be esti-mated from the following equations:
Here, n d denotes the number of words in the d -th docu-ment; d 0 and d 1 denote elements of the Bernoulli distribu-tion X  X  parameter d in Table 2; and d 0 and d 1 correspond to a switch variable of 0 and a switch variable of 1 in the d -th document, respectively.
For our experiments, we used the Multi-Domain Senti-ment Dataset[4], which contains online customer reviews with ratings f 1,2,4,5 g and 21,169 documents from four domains:  X  X ooks X ,  X  X VDs X ,  X  X lectronics X , and  X  X itchen X . We defined eight domains:  X  X ooks-positive X ,  X  X ooks-negative X ,  X  X VDs-positive X ,  X  X VDs-negative X ,  X  X lectronics-positive X ,  X  X lectronics-negative X ,  X  X itchen-positive X , and  X  X itchen-negative X , so that the size of  X  d and the number of domain-dependent topics are both eight. Reviews with ratings of 1 or 2 are defined as  X  X egative X , and reviews with ratings of 4 or 5 are defined as  X  X ositive X . For example, for a review with a rating of 1 in the  X  X ooks X  domain, its ob-served domain is defined as  X  X ooks-negative X . These settings are also used in [21] and enable us to control the polari-ties of domain-dependent topics. Incidentally, it is possible to observe whether topics are positive or negative without defining  X  X ositive X  and  X  X egative X  in continuous values.
The number of iterations for sampling z di was set to 100, and the number of iterations for sampling regression weight parameter ! in each iteration was set to 200. These numbers of iterations may appear to be too small, but they were decided on the basis of the experimental results described in Subsection 5.3.
We calculated the mean square error and average mean error for predicting numerical ratings of online customer re-views. 10% of the dataset was used as a test dataset and the rest was used as a training dataset. The training dataset was used for inference under the settings described in Section 5.1. Numerical ratings and domain information in the test dataset were removed, and the removed ratings were treated as correct ratings. After inference, to predict ratings, we sampled z 0 di in the d 0 -th document in the test dataset 100 times and adopted every tenth sample, as given by the fol-T able 1: The generative process of the Domain-Dependent/Independent Topic Switching Model. 1 . Draw G 0 DP ( ; H ) 2. For each domain-dependent topic t , draw domain-3. For each domain-independent topic k , draw domain-4. For each domain-dependent and -independent topic 5. For each document d , lo wing equation: Here, w 0 d 0 i denotes the i -th word in the d 0 -th document in the test dataset. The range of t 0 is 1 t 0 T + K ; and n v includes the count in the inference step. In addition, we adopted the last 100 samples of regression weight pa-rameter ! in the inference steps and calculated the d 0 -th 100 samples of ! . The average of these 100 ratings for the d -th document was treated as a predicted rating. Then, we calculated the mean square error and average mean er-Table 2: Notations of Domain -Dependent / Inde-pendent Topic Switching Model
S ymbol Desc ription ror using predicted ratings and the correct ratings. We ran 10-fold cross-validation.

The mean square error and average mean error are shown in Figure 4, which also shows the results for sLDA[2], a baseline model that is a joint model of LDA and a linear regression model, for comparison. The sLDA model does not consider domain-dependency information. In the sLDA result, K denotes the number of topics. sLDA needs to de-cide K , but our proposed model, DDITSM, does not need to decide the number of topics because the number of domain-dependent topics is decided by the observed domains auto-matically, and the number of domain-independent topics is also decided automatically by utilizing the HDP prior. In terms of mean square error and average mean error, our proposed model outperformed sLDA, when K ranged from 15 to 60. If K takes a value larger than 60, it is difficult to execute the program because an excessively long com-putational time is required to complete the inference. Fig-
S ymbol Desc ription u re 5 shows computational times. In DDITSM, the number of topics, including domain-dependent topics and domain-independent topics, eventually became about 20. Taking information about domains and polarities into topics was effective, and as a result, the errors were reduced with a small model size.
We compared our proposed model with sLDA in terms of the mean square error for the test dataset after 5, 10, 50, 100, and 200 iterations of collapsed Gibbs sampling for z . 10% of the dataset was used as the test dataset, and the rest was used as a training dataset. We ran 10-fold cross-validation in this experiment. Figure 6 shows the results. In terms of the mean square error, the results suggest that 200 iterations of collapsed Gibbs sampling with this dataset is enough for the error to converge. Moreover, 100 iterations is enough for comparing DDITSM with sLDA, and this is the basis on which we decided the settings described in Section 5.1.

In addition, the mean square error of DDITSM took lower values starting from earlier iterations. The part correspond-ing to domain-dependent topics constrained by domain in-formation converged rapidly because of the strong constraint given by  X  d . This caused the regression weight parame-ter ! corresponding to domain-dependent topics to converge rapidly, and as a result, the mean square error took lower values starting from earlier iterations. The settings for mak-ing domain labels described in Section 5.1 were also effective. After the early iterations, the reduction of the mean square error was caused by convergence of domain-independent top-ics and their corresponding regression weight parameter ! . Fi gure 4: Mean square error (left) and average mean error (right) of 10-fold cross-validation experiments in Multi-Domain Sentiment Dataset. Fi gure 5: Computational times of the proposed model and sLDA.
 The convergence of domain-independent topics utilizing the HDP prior needs more time than that of domain-dependent topics that have a strong constraint.
We examined the regression weight parameter ! after the experiment described in Section 5.2. Figure 7 shows values of elements of the weight regression parameter ! . ! con-sists of parts corresponding to domain-dependent topics and domain-independent topics. In this experiment, the number of elements corresponding to domain-dependent topics was eight because of the settings described in Section 5.1. In Fig-ure 7, the first eight bar graphs from the left correspond to domain-dependent topics, the last one denotes bias, and the others correspond to domain-independent topics whose num-ber was automatically decided by utilizing HDP. The bias was approximately equal to the average rating in the whole corpus. The parts of ! taking positive values suggest that their corresponding topics are positive topics, and those tak-ing negative values suggest that their corresponding topics are negative topics, because the ratings are decided by y !
T  X  z d . Figure 7 suggests that the domain-dependent top-ics  X  X ooks-positive X ,  X  X VDs-positive X ,  X  X lectronics-positive X , Fi gure 6: Mean square error after 5, 10, 50, 100, and 200 iterations. and  X  X itchen-positive X  are factors tending to make y d pos-itive, and the factors  X  X ooks-negative X ,  X  X VDs-negative X ,  X  X lectronics-negative X , and  X  X itchen-negative X  are factors tending to make y d negative. In this way, examining ! makes it possible to tell whether each topic is positive or negative in continuous values. By introducing domain information and polarities into  X , like the settings in Section 5.1, it is pos-sible to control the polarities of domain-dependent topics. On the contrary, the polarities of domain-independent top-ics without the  X  constraints are not controlled. In Figure 7, the parts of ! corresponding to domain-independent topics almost all take negative values. This means that domain-independent topics in this dataset almost all have negative polarities. The parts of ! taking a value around zero mean that the topics corresponding to those ! are neutral top-ics. Some domain-independent topics are neutral, and these topics work effectively because words that are irrelevant to predicting rating y d should be clustered in neutral topics.
We checked some word distributions corresponding to domain-dependent topics and some domain-independent topics. We removed some stop words and some typical words in the topics, as shown in Table 4. Words in italic typeface are considered positive words. Words in bold typeface are considered negative words. Words in normal typeface are considered neutral domain-dependent words.

Neutral domain-dependent words are at the head of the word distributions in domain-dependent topics, regardless of the polarities. In  X  X ooks-positive X  and  X  X ooks-negative X , the neutral domain-dependent words  X  X ook X ,  X  X ead X ,  X  X uthor X ,  X  X ages X , and so on are observed.

In terms of polarities, take  X  X VD-positive X  and  X  X VD-negative X  as an example. Some words in the domain  X  X VD-positive X , namely,  X  X reat X ,  X  X ood X ,  X  X est X , better X ,  X  X unny X ,  X  X ice X ,  X  X onderful X , etc. are guessed as being positive words in general. On the contrary, the negative words  X  X orst X ,  X  X aste X ,  X  X oor X ,  X  X oring X ,  X  X rong X , and  X  X errible X  are observed Fi gure 7: The regression weight parameter. The last element, taking the largest positive value, is a bias weight. in the domain  X  X VD-negative X . Some positive words, such as  X  X ood X ,  X  X ike X ,  X  X unny X , and so on, are observed; however, negations like  X  X idn X  X  X ,  X  X o X , and  X  X ever X  are also observed. This may be because many sentences include both positive words and negative words, such as  X  X  didn X  X  like this DVD. X .
In the domain  X  X itchen X , there are some typical positive words that are considered to be domain-dependent. For ex-ample,  X  X turdy X ,  X  X harp X , and  X  X asy X  are considered to be pos-itive words in the domain  X  X itchen X , but not many other domains would handle these words as positive words.
We defined domain-independent topics corresponding to ! domain-independent negative words gave us an impression of complaints about the e-commerce cite, customer support, and delivery. This means that negative complaints about e-commerce cites, customer support, and delivery are domain-independent content. This is the one of the key features of DDITSM. This result could not be obtained without model-ing domain-dependent and -independent topics. In neutral domain-independent words, proper nouns like  X  X arold X ,  X  X in-cent X ,  X  X oxanne X ,  X  X anhattan X  frequently occur. This suggest that proper nouns are almost unconcerned with the ratings of reviews. In this paper, we propose the Domain-Dependent/Independent Topic Switching Model (DDITSM), which can handle online reviews with nu-merical ratings in multiple domains. Our contribution is four-fold. First, DDITSM can handle domain-dependent words and domain-independent words to utilize observed domain information and introduce switch variables. Second, DDITSM also makes it possible to tell whether each topic is positive or negative in the form of continuous values. By applying this easy technique, we can control the polarities of domain-dependent topics. Third, a Hierarchical Dirichlet b ook read author writing character page novel story no don't never nothing doesn't few didn't bad wrong disappointed great interesting best actor music cast no never didn't wrong terrible funny interesting pro duct speaker work sound phone player software dvd radio tv device printer button headphones nothing waste never didn't cannot problem disappointed doesn't p roduct water coffee steel tank kitchen maker design machine work vacuum filter didn't never problem few broke less disappointed poor cheap nothing no good great better nice service customer quality warranty support manufacturer damage matter poor scratched blame wrong problem defective Pro cess is utilized for domain-independent topics, and we can also determine whether those topics are positive or negative in the form of continuous values. Fourth, we showed that DDITSM outperforms the baseline model that does not consider domain dependence in the sentiment regression task, predicting numerical ratings from reviews or texts that lack ratings.
 The experimental results showed two interesting findings. First, DDITSM converged more rapidly than the baseline model because of the strong constraint due to observed domain information. Second, domain-independent topics had positive, negative, and neutral polarities in the form of continuous values. Neutral domain-independent topics included proper nouns, and this means that proper nouns ma y be unconcerned with ratings of online reviews. Neg-ative domain-independent topics included negative words that gave an impression of complaints about e-commerce sites, customer support, and delivery. This means that their contents do not depend on domains like  X  X ook X ,  X  X VD X , and so on. In domain-dependent topics, there were some typical positive words like  X  X turdy X ,  X  X harp X , and  X  X asy X  in the domain  X  X itchen X . These results suggest that domain-dependent topics constrained by observed domain labels, domain-independent topics utilizing HDP, and a regression weight parameter worked effectively. We would compare the performance of our model with the state of the art sentiment prediction methods using various datasets.

Our future goals include applying our model to large-scale data, incorporating more observed information, and mod-eling latent structures like reviewable aspects[8, 10]. Our model will need to be applied to distributed algorithms in large-scale data, and one key idea may be to employ paral-lel Markov chain Monte Carlo for HDP without introducing approximations[19]. Our model does not handle only text data, but also domain labels and numerical ratings simul-taneously. This approach is based on our concept that ob-served information should be used aggressively. Therefore, information about reviewers, the time when the reviews were written, and so on will also be incorporated into our model.
We thank late Tomohiko Suzuki for his helpful discussion. [1] D. Andrzejewski and X. Zhu. Latent dirichlet [2] D. M. Blei and J. D. McAuliffe. Supervised topic [3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [4] J. Blitzer, M. Dredze, and F. Pereir. Biographies, [5] J. Boyd-Graber and P. Resnik. Holistic sentiment [6] T. S. Ferguson. A bayesian analysis of some [7] T. L. Griffiths and M. Steyvers. Finding scientific [8] Y. Jo and A. Oh. Aspect and sentiment unification [9] S. Lacoste-Julien, F. Sha, and M. I. Jordan. Disclda: [10] C. Lin and Y. He. Joint sentiment/topic model for [11] S. J. Pan and Q. Yang. A survey on transfer learning. [12] D. Ramage, D. Hall, R. Nallapati, and C. D. Manning. [13] D. Ramage, P. Heymann, C. D. Manning, and [14] D. Ramage, C. D. Manning, and S. Dumais. Partially [15] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. [16] Y. W. Teh, D. Newman, and M. Welling. A collapsed [17] I. Titov and R. McDonald. A joint model of text and [18] I. Titov and R. McDonald. Modeling online reviews [19] S. A. Williamson, A.Dubey, and E. P. Xing. Parallel [20] X. Xu, S. Tan, Y.Liu, X. Cheng, and Z. Lin. Towards [21] Y. Yoshida, T. Hirao, T. Iwata, M. Nagata, and
