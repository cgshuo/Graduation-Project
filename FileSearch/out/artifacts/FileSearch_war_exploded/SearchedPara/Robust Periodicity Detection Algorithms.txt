 Periodicity detection is an important pre-processing step for many time series algorithms. It provides important informa-tion about the structural properties of a time series. Fea-ture vectors based on periodicity can be used for clustering, classification, abnormality detection, and human motion un-derstanding. The periodicity detection task is not difficult in case of simple and uncontaminated signal. Unfortunately, most of the real datasets exhibit one or more of the following properties: i) non-stationarity, ii) interlaced cyclic patterns and iii) data contamination, which makes the period de-tection extremely challenging. A seemingly straightforward solution is to develop individual specialized algorithms for handling each case separately. However, determining if a time series is non-stationary or is contaminated in itself is an extremely difficult task. In this article, we propose generic algorithms which can detect periods in complex, noisy and incomplete datasets . The algorithm leverages the frequency characterization and autocorrelation structure inherent in a time series to estimate its periodicity. We extend the methods to handle non-stationary time series by tracking the candidate periods using a Kalman filter. We also ad-dress the interesting problem of finding multiple interlaced periodicities.
 Categories and Subject Descriptors: G.3 [PROBABIL-ITY AND STATISTICS]: Time series analysis H.2.8 [Data-base Applications ]: Data mining General Terms: Algorithms, Experimentation, Design. Keywords: Time Series, Periodicity, Pre-processing, Non-stationary time series, Interlaced periodicity
Existing periodicity detection algorithms can be broadly classified in two groups: time domain methods and fre-
This work is f unded by NSF gran ts NGS-0326386, ACI-0234273 and Career Award IIS-0347662. Contact email: srini@cse.ohio-state.edu quency domain methods. Time domain methods make use of autocorrelation functions while frequency domain methods make use of spectral density functions. Time domain meth-ods are useful and efficient in detecting periodicities when the time series is approximately characterized by a sinusoid uncontaminated by noise. However, for other signals, the performance degrades rapidly. Although, frequency based methods mitigate some of these drawbacks, power loss of the impulsive frequencies due to spectral leakage pose a se-rious problem. To address the limitations of the individual methods, our algorithms utilize information from both, time-frequency and autocorrelation analysis simultaneously. Figure 1: Determination of the period of a wide-band signal. (a) Spectrogram of a motor current signal (best viewed in color). (b) The correspond-ing summed autocorrelation. (c) A pulse train cor-responding to the detected period overlaid.

Periodicity in Stationary Time Series: Awide-sense stationary random process z ( t )issaidtobebemean-square periodic, if  X  T&gt; 0 such that R zz (  X  )= R zz (  X  + T where R zz (  X  ) is the autocorrelation function corresponding to z ( t ). The period of this process is then defined to be the smallest such T . A 256-point discrete Fourier trans-form (DFT) is computed on successive 256 length windows of the signal. Consecutive windows are shifted by 1 sample. The outputs from the short-time Fourier transform analysis are then used to compute the corresponding spectrogram. A spectrogram plot for the motor current signal is shown in Figure 1(a). The x-axis is time in increasing order and y-axis is frequency in increasing order. The darker the color in the spectrogram, the more the signal X  X  power at that frequency. It can also be seen from Figure 1(a) that the fine-shift along the time dimension causes the spectrogram to retain the pe-riodicity property along its time axis too. This occurs across different frequencies. To exploit this property, the evolution of each DFT coefficient across time is considered to form a time series. Then, for each such series the discrete-time autocorrelation is computed. The resulting autocorrelations are summed across different frequencies. Figure 1(b) shows the plot of the summed autocorrelations for the motor cur-rent data. The various peaks in Figure 1(b) denote the integer multiples of the period. For verification, Figure 1(c) shows the original signal overlaid with a pulse train at the detected periods given by the dotted lines.

Periodicity in Non-Stationary Time Series: We con-sider the particular case of non-stationary random processes that possess time-varying periods. A random process z ( t non-stationary, if  X  n  X  Z + such that the n th order prob-ability distribution function changes across time. The top graph in Figure 2(a) shows one such dataset where different periodicities are observed at distinct time intervals. Even though the periodicity varies globally, it remains unchanged locally. We apply a sliding rectangular window of length M with an overlap of length o between adjacent windows to discover change in periods over time. Within each window one can use the stationary version of the algorithm, to find theperiodicity. Sincethepointwherethechangeinperiod occurs is unknown, we will get some windows within which the data generated will encompass different periods. To ad-dress this problem, we smooth the results using a Kalman Filter. The time-variation of periods is modeled as an auto-regressive (AR) process. Due to the overlap between consec-utive windows, we expect a smooth change in the detected period. The vertical lines in Figure 2(a) show the result of the algorithm; we found 4 different periods. Figure 2(b) shows the detected period in the second segment [200 , 320]. Similarly, figure 2(c) shows the result on the next segment [340 , 500]. Please note that periodicity was not detected on a priori segmented signals. The segmentation is by-product of our algorithm when dealing with non-stationary signals Figure 2: Non Stationary dataset  X  X lutter X  contain-ing different periodicities detected in different parts.
Multiple Interlaced Periodicities: Thus far, we have presented algorithms for cases when there is only one period in whole or parts of a time series. However, many data sets have interlaced periods occurring simultaneously. To handle such cases, we adopt a sequential detection and pruning ap-proach. We use the existing algorithm to find the primary period. Thisperiodisusedtodesignacombfilter. Acomb filter is a filter that resonates a  X  X elected X  frequency and all the harmonics of that frequency. We set the  X  X elected X  frequency to be the inverse of the detected period, thereby constructing a filter which will only let pass the harmonics corresponding to the detected period. The transfer function period detected. This filter is used to  X  X elect X  those har-monic components of the signal that occur at integer mul-tiples of 1 /p . The is accomplished by: S ( l )= z  X  P ( then subtract the comb filtered version S ( l ) from the original signal, z ( t ) and re-run the algorithm on the resulting data. This process is continued iteratively until the comb filtered signal X  X  power is no more than 10% of the original signal X  X  power. Figure 3 shows the ori ginal signal and the primary period of 132 months (top plot). The next plot shows the signal after the frequencies corresponding to the primary pe-riod are removed. The detected period is 120 months. The bottom plot shows the final period (540 months), detected after filtering the frequency components associated with the secondary period. Kanjilal et al. [2] also reported periods of 11 and 10 years on this dataset.
Figure 3: Interlaced Periodicities for Sunspot data
Due to space constraints, we are unable to provide de-tailed algorithms and exhaustive results on several other datasets including noisy and incomplete datasets. All the re-sults are available in the extended technical report [3]. Our results on all the stationary datasets with a single period are consistent with the ones reported by Vlachos et.al [1]. Interestingly, a simple FFT based algorithm also performs equally well for most of these datasets. This can be at-tributed to the fact that most of these signal are sinusoidal-like. Other complex datasets including ( Sunspot and Flut-ter ) presented display non-stationarity or include multiple periods. The existing algorithms [1, 2] are not designed to handle these issues.
