 c Institute of Computer Scie nce, Foundation for Re search and Technol ogy, Hellas, Greece 1. Introduction
Support Vector Machines (SVM) and kernel methods in general have been proven very successful methods for standard binary classi fi cation problems. A polynomial SVM is typically formulated as the linear combination of the Lagrange multipliers ( a function speci fi ed: where K ( x , x )=( x  X  x +1) d is the (full) polynomial kernel of degree d . This representation allows for ef fi cient computation of, but is unsuitable for a human modeler to gain an understanding of, the over an SVM classi fi er.

The SVM model however, can also be represented as an af fi ne function composed with a mapping,  X  , from input variable space x  X  R m to feature space R f : Here w is a weight vector in R f and multinomial notation is used to index the feature space. Feature space is then spanned by monomials of the form  X  and for further feature selection.

Unfortunately, while potentially helpful, it is time-prohibitive to compute the explicit representation for large models. The number of features, f , for a model with m variables (input components of the training vectors) and kernel of degree d is f = m + d Kernel representation to an approximation of the explicit representation calculated by the r top-weighted Q
This approach is to fi rst construct a polynomial SVM, then to identify the top-weighted features in order to gain understanding into the domain. In contrast, other typical approaches are to either (i) use classi fi ers that produce easy-to-understand models or (ii) reduce the number of variables (in contrast feasible, these approaches often have the following disadvantages:  X  Finding a variable selection method that adequately reduces the number of variables without de-
Learning tasks that are particularly problematic to understand are those where a group of variables has with Y . For example let Y be the parity function of X { X  1 , +1 } ,then Y = X subset has any association with Y . This means most variable selection methods that are based on some kind of pairwise association of each variable with Y will fail to identify any of { X Greedy wrapper methods such as forward variable selection will also fail, as adding any of { X does not affect the performance of the model. Thus, only a method that simultaneously examines the three variables together can safely hone in on the feature. Notice that a polynomial SVM of degree the preceding discussion, the new method should be mostly suitable for problems de fi ned thusly. De fi nition 1 Problems of Interest. This work is directed at problem domains with the following proper-ties:  X  the SVM model is sparse, that is, the weight vector w either has relatively few components that  X  and the problem is too large to allow a brute force calculation of w .
 Under these assumptions we expect those features with large magnitude weights to be identi fi ed as important features of the SVM model. When the model re fl ects the domain understanding (large sample), the features with large magnitude weights are important to the problem domain.
 largest change of the model output). Note, with polynomial kernels we are looking at combinations of and the weights are not explicitly comparable. However, as we will show in the experimental results, the methods based on this idea work well in practice.
 Two heuristic algorithms are presented and empirically compared that take as input a polynomial SVM model in Kernel representation, the number of weights and features to return, r , and the number of features that may be searched, p , to identify the top-weighted features. Suf fi cient conditions are provided for the heuristic algorithms to correctly return the top r weights. Even when the suf fi cient conditions fail, empirically the returned weights closely approximate the true set of r top-weighted features when only examining a very small portion of the feature space p m + d method has a time complexity in terms of multiplications of  X ( dms 2 + sdp ) ,where m is the number of variables, d is the degree of the kernel, s is the number of support vectors, and p is the number of  X ( sdf )= X ( sd m + d presented, showing that the algorithm can convert SVM models to human readable form, help interpret them and provide domain knowledge.

The paper is presented as follows; Section 2 reviews the basic theory of Support Vector Machines and introduces the notation used in this paper. The following Subsections 2.1 and 2.2 describe the properties of the polynomial kernel exploited to create scores to assess the importance of a speci fi cvariableto for the heuristic method (Section 3.4).

Section 5 describes the experiments performed and reveals the behavior of both the brute force calculations and the heuristic methods on several simulated and real data sets. How this new approach compares to contemporary research on variable selection and feature extraction is described in a section on related work (Section 5.1.3). Finally, a discussion reviews the new approach including: limitations of the method, relationships to other approaches, and implications for future research. 2. Support Vector Machines
In orderto setnotation, we brie fl y review soft-margin SupportVectorMachines (SVM)with polynomial kernels [5,17]. We let D = { x denote a mapping from S into the  X  X eature X  space R f . Later  X  will assumed to be a polynomial mapping whose components are multivariate monomials in the components of x . Then a weight vector w  X  R f and offset b  X  R are found by solving the following constrained optimization problem: subject to the constraints y One may associate with  X  the kernel K de fi ned by for x , x  X  S . By considering the Wolfe dual formulation of minimization problem (Eq. (1)) one may express the weight vector w in the form for constants a denote the number of support vectors. Then h can be written in the form showing that the SVM can be constructed using the kernel K evaluated at the data samples and  X  need there is some  X  (not unique) such that Eq. (3) holds. In many cases, and particularly for the polynomial kernel that we focus on in this work, the kernel function K is easily computable while  X ( x ) may be too large to explicitly compute and/or store.
 2.1. Polynomial kernel properties
The polynomial kernel of full degree d is given by K ( x , x )=( x  X  x +1) d and the homogenous polynomial kernel of degree d is given by H
We use the following multinomial notation. Let Q q 1 ,...,q m x an ordering of Q where we index a vector in R f using Q the Multinomial Theorem that Consider an example: a data set consisting of 2 variables and a polynomial kernel with a degree of 2 results in 6 features. If we order Q the data space, x = x
We now develop scores to assess the importance of a speci fi c variable to classifying using Eq. (2). A variable participates in more than one features (in the above example x q 1 &gt; 0 Speci fi cally, we show how to ef fi ciently calculate w v to monomials of exactly degree l containing variables v .

Consider the following quantities to be calculated from the weight vector. For v =1 ,...,m , x  X  S features not containing x and so, providing an ef fi cient means to compute the norm of w \ v . We next consider the weight vector w v of features that do contain variable v and is de fi ned as w v = w  X  w \ v .Since w v and w \ v vanish on complimentary subsets of features space, we have w v  X  w \ v =0 and hence by the Pythagorean theorem, we have
The weight vector may be further decomposed by the degree of the features considered. Consider a vector z in R f ,let z variables do not have degree exactly l to zero, i.e., the q th component of z Similarly, w degree exactly l and the norm of this vector is Arranging features by degree forms a partition of feature space and so l that do not contain variable v , may be written as and the norm of the weights of the features of degree l that do contain variable v is
The number of weights being summe d into the norm quantities grows exponentially as the number of variables grow (similar to how the number of features grow). Speci fi cally, the norm of the weights of the features that contain variable v , w v ,isasumof m +( d  X  1) sum of norm of the weights of the features of degree l is m +( l  X  1) in the sum of the weights of features of a degree l that contain variable v is m +( l  X  2) 2.1.1. Methods to partition the fe atures and weights
The previous de fi nitions in this section have focused on examining subsets of the weight vector features (and their corresponding weights) de fi ned over subsets of the variables. For a given subset of variables V  X  X  1 ,...,m } ,wede fi ne the following subsets of features: That is, the set of features, F V , includes all features where some variable v  X  V is in each feature. F consisting solely of variables v  X  V .

To construct the calculations for the norm of the weight vector over these sets we will revisit the v =1 ,...,m , x  X  S ,and z  X  R f ,let x \ V denote the vector, the vector obtained from z by settin g each of the components i nvolving variables v  X  V to zero. From this the other sum of the squares of the weights over the different feature sets may be calculated, namely, For instance if V = { v F
V that contain both variable u and v , F { u,v } . The norm of the weight vector for these features is denoted as w { u,v } through the following equation norm of the weights over the features F V is equivalent to the norm over the features F \ V C . 2.2. Ef fi cient computation of the weight norms
In the algorithms to follow, we compute w v how to perform this computation ef fi ciently. Let us denote with X  X  [ s  X  m ] the matrix with support vectors as rows, and a the row vector of  X  where we use X .d to denote element-wise exponentiation and 1 denotes a matrix of the same size as X with elements all 1. The computation requires  X ( s 2 ( m + d )) multiplications and additions, and for d&lt;m this becomes  X ( s 2 m ) . Similarly, by using Eq. (15) we obtain: Now, regarding w \ v x k the factor x k,v x j,v .Byde fi ning the row vector X v as the values of the support vectors of the v variable, we can write the above in matrix format: we fi nally obtain Once again the time-complexity of this computation is  X ( s 2 m ) . Calculating w v for high-dimensional problems. Let us assume however, that we compute XX T and X T variable and cache the results. Both of these operations require a cost of s 2 m respectively. Now, once we have computed w v with s 2 multiplications: ( XX T )  X  ( XX T ) ,where  X  is the element-wise multiplication. Similarly, the calculate all w v 3. Methods for identifying the top-weighted features
In this section, we present the brute force and two heuristic methods for identifying the weights, i.e., components of a weight vector w , that are largest in magnitude. The heuristic approaches introduced here avoid the expensive explicit construction of the entire weight vector, by using condensed information of the weights. Speci fi cally, the heuristic methods conduct a search for the top weights of the SVM model, guided by the norm of the weights summed over various subsets of features described in Section 2.1. All methods are currently implemented in Matlab. 1 Brie fl y, the three methods presented are:  X  Brute Force, Section 3.1 : Explicitly calculate the weight vector w and identify the largest in magnit- X  Heur1, Section 3.2 : Rank variables according to the sum of weights in all features they participate  X  Heur2, Section 3.3 : Calculate s ( v, l )= w v The heuristic methods rely on the using the quantities w v 2 and w v features) to guide the search in constructing features to identify a few individual features with large magnitude weights. Note, that t hese quantities are an upper bound on the largest (in magnitude) weight
Each method is detailed in the following sub-sections (Sections 3.1 X 3.3) with a complexity analysis of the methods X  concluding each portion of the paper. This section concludes with a discussion of the suf fi cient conditions for the heuristic method (Section 3.4). 3.1. Brute force search
To identify each feature  X  q and its corresponding weight w q we use Eqs (7) and (13): This brute force method is currently implemented in Matlab to maximize speed rather than space in the mapping to feature space. Consequently it is memory that limits the brute force calculation of the weight vector (using an ordinary PC the scope of the problems is limited to  X  &lt; 700 variables with a degree 2 kernel, and  X  &lt; 50 variables with a degree 4 kernel). However, an alternative method optimized for space is considered using iterations of for-loops to consider each feature X  X  weight. This approach has also been coded into Matlab, however the for-loop construction of this method does not take advantage on a degree 2 problem with 200 variables to construct the 20,301 elements of the weight vector takes over 45 seconds). An implementation in C could be f aster in execution time yet is still limited by the overall complexity requirements of the method.

Even these straight-forward approaches will eventually also run into memory limitations of keeping the data, weight vector, and Q matrix of corresponding feature in memory (the size of the weight vector alone for a 10,000 variable, degree 3 problem is over 150 GB). Because we are looking at identifying the top weights, the brute force method may be implemented such that only the top r weights are kept and returned (similar to the heuristic methods). Therefore, rather than just place each weight in turn in a vector as it is created, a sorted list of the top weights will be constructed and maintained. This memory-saving implementation will add complexity to the algorithm to keep the sorted list no matter what data structures used.

Complexity analysis : Calculating x q exponents in q ); calculating w q requires another s additions, where s is the number of support vectors. We consider the calculation of the constants c q = d a small number of different values of these constants (the number of different c q  X  X  is the number of time-complexity is  X ( sdf ) ,where f the total number of features, equal to: The explosive growth does not allow all features ( and weights ) to be calculated for large data sets and d&gt; 1 . Sorting and obtaining the largest r weights (and corresponding features) requires another  X ( f log f ) time. Notice that  X ( f )= X ( m + d becomes  X ( sdf + f log f )  X  O ( sdm d ) . 3.2. Heuristic one: Select top-ranked variables then exhaustive search selection using the variable ranking score of non-linear RFE, that is using only the fi rst iteration of v according to w v .Thetop k variables are selected and all features and weights among those variables are explicitly constructed.

This method is presented in Algorithm 1 where the inputs are the support vectors SV , alpha values  X  and two parameters p the number of features to construct and r the number of features to return. The parameter p determines how many features constructed and weights calculated and consequently determines the number of variables considered. The number of variables for which all features are constructed, k , is maximized so that, For each variable, a score is calculated as the norm of the weight vector for all features involving that variable, w v 2 (line 3 X 5). The top k ranked variables are selected and stored in the subset V (line 6). All features involving solely variables in V are constructed ( F V ) and weights calculated (line 7 X 10). output from Heur1 .
 Complexity analysis : The overall time complexity of this method is  X ( dms 2 + sdp ) multiplications. The complexity is broken down as follows: the cost to calculate the score for each variable is  X ( dms 2 ) O ( m log m ) and O ( p log p ) for each item respectively; however, the main computational time of the method is dominated by the weight and score calculations. 3.3. Heuristic two: Guided search to construct top features
The second heuristic method, referred to as Heur2 , uses the norm of the weight vector decomposed by (among variables V at that level) and their weights are calculated. The weights found are subtracted from corresponding sums s ( v, l ) and the next level and variables are selected; repeating this process until a speci fi ed number of features are constructed.

If a variable v participates in only one feature at degree level l with a non-zero weight w q then either case, the quantity w v calculate the weights of suspected top features.

This method takes the same inputs as Heur1 : the support vectors of the SVM model SV , the alpha description of the implementation is presented in Algorithm 2. The method begins with the construction of the d  X  m contributions matrix s where s [ l ][ v ]= w v heuristic search loops through the following 3 sub-procedures: (1) select the next level and variable(s) to focus construction, (2) explicitly construct the features and calculate their weights for the selected variables and level, and (3) update the bounds of the contribution matrix. Once the search procedure with the maximum value. The second method normalizes the contributions matrix by the number of selected manually; this option allows for the method to select the top features at each level. The set of variables from which the features will be constructed uses the contributions information at the selected in features at this level is V is not in V
The second sub-procedure explicitly constructs (calculates) the features (weights) for the selected level and variable sets found (line 8 X 12, Algorithm 2). The construction of new features includes all combinations of any variables already constructed at the selected level, V v . Initially, V algorithm continues combinations of variables are considered.

The fi nal sub-procedure updates the bounds on the top weight (lines 13 X 15, Algorithm 2), consequently the contributions matrix is updated b y any weights explicitly calculated. For example, if the feature variables in this feature.

The three sub-procedures reside in a loop that continues until the list of features (and their weights) has at least p items.
 sdp ) , with s support vectors, m variables, d the degree of the kernel, and p the number of features to sub-procedure requires either no numeric calculations for determining the level or the  X ( dm ) divisions for the version which does a normalization. In addition, the procedure requires fi nding the maximum value for each level or  X ( dm ) look-ups.

The cost of the second sub-procedure is  X ( sd ) multiplications. This procedure does not require the storage of all previously created features, rather just the variables at each level. A look-up just identi fi es the next variable that may be used for a given level. When developing this heuristic several implementations were considered that slightly altered the order of constructing new features and what information was stored between iterations. However, the fi nal method described here was simple and each feature to update the bounds.

Complexity analysis summary : In general, the heuristic methods require initial calculations above and beyond the brute-force approach (the heuristic methods construct the contribution matrix in  X ( dms 2 ) ). for small problems, with f&lt;p + ms , the brute force approach is expected to more ef fi cient; see the memory requirements for the calculation rather than the ef fi ciency of the method (although more memory ef fi cient implementations are possible, as discussed in Section 3.1). In contrast, the heuristic method is quite scalable. The method has been run on data sets consisting of over 100,000 variables with a degree 2 kernel completing the calculations in less than 2 hours. 3.4. Suf fi cient conditions for heuristic methods to return top r weights We next present suf fi cient conditions on w and p for the heuristic methods to return the top r weights. of p depends on the computational resources available to a user).
 Lemma 1. Let V  X  X  1 ,...,m } denote the set of k variables selected in Heur1 and let Q  X  Q denote the set of r features returned by Heur1 .Let w then Heur1 returns the top r weighted features, that is, | w q | | w q | for all q  X  Q and all q  X  Q Proof. Suppose Eq. (35) holds. Let w the variables in V .If q  X   X  Q \ Q ,then | w q | w largest magnitude weights. If q  X   X  Q then q completes the proof.
 Lemma 2. Let Q  X  Q  X  X ontributions X  matrix. Let w then Heur2 returns the top r weighted features, that is, | w q | | w q | for all q  X  Q and all q  X  Q
These suf fi cient conditions for stopping for both Heur1 and Heur2 methods may be loose bounds in practice. The parameter p will be used in the experimental evaluation to facilitate comparisons between the methods. 4. Related work
The heuristic method presented is unique in its design to return the top-weighted features involved in the classi fi cation of a SVM model. Consequently, there is not a direct comparison between the heuristic methods presented here and other algorithms. However while this approach is unique, the idea can be classed as a variation of a variable selection method. Variable selection (or feature selection) methods can be generally described as approaches that return a subset of the input variable set that best relate to mention how variable selection relate to this approach on the problems of interest.
Recall, the problem space of interest to this work (described in De fi nition 1) is problems where a group of variables has a high-multivariate association with the class Y , but every strict subset of the group has no association with Y . Variable selection methods based on pair-wise association with Y will fail. For example, variable ranking methods that select the top k variables using a ranking based on any pairwise criteria with Y will fail. Example criterion include Pearson correlation,  X  2 , mutual information, among others. Also, variable selection methods based on Markov-based approaches will also fail. Generally, these methods rely on some initial measure of association to allow variable to be returned (e.g., HITON [3], IAMB [1,2], Koller-Sahami [13], etc.). Additionally, variable selection wrapper methods that are greedy (such as forward selection) will also not succeed in this proglem area.
There are several variable selection methods that use SVM models. The Recursive Feature Elimination method (RFE) ranks each variable by removing each variable from consideration in turn to construct a score, removes the lowest ranked variable(s), and iterates through this process [9]. Other methods that rank the variables by scaling factors, where scaling factors are added into the kernel and are optimized in the training of the model [19].

Recently, several methods for constructing SVMs with sparse weight vectors have been developed (cf. l developed for linear SVMs. In [18], the authors tangentially describe minimizing the zero-norm with non-linear kernels to identify components of the weight vector (the majority of the paper deals with linear kernels and selection of kernels). This paper is unique in also mentioning the problem addressed here. The authors note the dif fi culty in looking at the components of the resulting weight vector and only consider an exemplar problem of suf fi ciently small size that permits the exhaustive examination of all weights (10 variables, degree 2).

RFE is a method that can identify the subsets of variables in our problem space of interest. Also, as described in Section 3.2, RFE X  X  scoring metric is the same as the metric used in the Heur1 method. Therefore, we present a comparison of our approach to RFE on the simulated data in the experimental results (Section 5.1.3). 5. Experimental results
The experimental evaluation consists of two sections; the fi rst uses simulated data (the data-generating model is known, Section 5.1) and the second involves data from real-world domains (the underlying model is unknown, Section 5.2). On the simulated data, the ability of the brute force and heuristic methods are compared at identifying the largest weights of the SVM model. The results emphasize: (1) the ability of the heuristic methods to identify the features with the large st magnitude weights for features provide insight into the functionality of the SVM model. Of the two heuristics methods, Heur2 outperforms Heur1 in terms of ability to identify the top-weighted features (especially as the size of the problem increases) while only a exhibiting a small decrease in time ef fi ciency. This method is then matched against RFE on additional simulated data (Section 5.1.3). Additionally, we show the heuristic real data sets only the heuristic method Heur2 was used. Here the results demonstrate the ability of the provide new or corroborate existing domain knowledge. 5.1. Simulated data results
On the simulated data, a short description of the problem domains, common parameters, and issues with the simulated data are discussed. Then, the two heuristic methods are compared to determine which (if either) method is preferred (Section 5.1.1). Next, the dominant method is compared to the brute force approach in Section 5.1.2). Also, the dominant heuristic method is compared against the RFE algorithm discussion are available in an online appendix at http://www.cs.mtu.edu/  X  lebrown/IDA2011/. Problem descriptions : Three simulated problem domains referred to as Circle, Double-XOR, and Checkerboard are considered. For the Circle problem, the classi fi cation is determined by the function on [  X  1 , 1] . For the Double-XOR problem, the data was sampled from the Bayesian Network shown in Fig. 1. The variable T determines the classi fi cation of a sample. For the Checkerboard problem, was sampled from a uniform distribution on [  X  1 , +1] . For each problem, the number of input variable sizes was varied and is speci fi ed for each simulation. Data sets of 50, 100, 500, and 1000 training instances were sampled for each problem and input variable size. It is know in the large sample limit have a weight that goes to zero (this statement is also observed in practice with the data sets) [10].
SVM parameters : In general, a user does not know the optimal parameters to create an SVM model; for a polynomial SVM the degree of the kernel and C soft-margin parameter must be selected. In practice, is performed to optimize the selection of the SVM model parameters, with the expectation that the degree work is not how best to optimize parameters for a SVM model, but on selecting the top features once an SVM model has been trained. For the rest of the simulated experimental section, the degree of the SVM kernel is selected to match the classi fi cation function (i.e, the Circle and Double-XOR problem use a degree 2 kernel and the Checkerboard problem uses a degree 3 kernel) and the C parameter is set to 10 3 .
Binary data encoding : For problems consisting of binary data, the manner in which the binary data is encoded may have an effect on the learned SVM model. Consider the case of learning an XOR relationship of two variables with a degree 2 polynomial kernel. The features X X hyperplane. When a binary 0/1 encoding is used, one arithmetic expression that is equivalent to XOR to separate the data is X expression  X  X therefore affected by the encoding of the data, where one encoding may be preferred over another due to the simplicity of the learned function. However, when faced with a problem with a unknown underlying distribution it is impossible to select the best encoding a priori.

Regardless of which of these two encodings are selected, when the input data to the SVM is binary the features of the SVM model are redundant in their representation for polynomial kernels with d&gt; 1 .For example, when the input data is using a 0/1 encoding, any variable raised to a higher power is equivalent to the original variable. Figure 2(a) shows several such equivalencies, e.g., X When the input data uses  X  1 / +1 encoding, a different set of redundancies emerge. In this case, any variable raised to a even power becomes the constant 1 while any variable raised to an odd power is equivalent to the original variable. For example, X 2
In addition to the redundancy among the features, the two encodings may results in the features interpreted in different manners. For instance, consider the feature X and (2b) shows the behavior of this feature with respect to its base variables. With the 0/1 encoding the feature is re fl ecting an AND relationship among its constituent variables. When the -1/+1 encoding is considered, the feature has an exclusive OR relationship among its constituent variables. In either case, on the encoding.

The heuristic method is developed to be a general purpose procedure that does not differentiate its behavior depending on the type of input data and its supplied encoding. Consequently, the redundancies features is processed to remove redundant features. For the case of binary data, all possible features are expressed with exponents of either zero or one (i.e., x q = x q 0 search (the procedure may be designed as an anytime algorithm to achieve this goal). 5.1.1. Comparison of heuristic methods
The two heuristic methods described in Sections 3.2 and 3.3 are compared in terms of the time summarized in Table 1.
Problem description : For this comparison, the size for each problem domain is as follows: 400, 500, 600, and 700 variables for Circle, 337, 448, 559, and 707 variables for Double-XOR, and 70, 80, 100, and 125 variables for the Checkerboard problem. The Heur1 and Heur2 method were both run to construct p = { 50 , 100 , 500 , 1000 , 5000 } features.

Time metric : The running time ratio of the two methods is calculated for the different values of p , problem domain, problem size (number of variables), and sample size. For each domain, the time ratio portion of results table). A time ratio of greater than one indicates Heur1 taking longer than Heur2 while a ratio of less than one indicates Heur2 taking longer than Heur1 .

Timing results :The Heur1 method is in general faster than Heur2 . This observation meets expecta-tions because the Heur1 method requires less overhead than Heur2 . The results also reveal a general pattern that the speed gains of between the two methods are affected by the number of samples in the data. The sample size of course plays an important part in calculating the weights for both methods of the components of the weight vector (see Figs 3(a X  X )). As sample size increases (across the row), the distribution of weights becomes more concentrated in a few important features. The change in the weight (top 25 weights) for the Circle problem (the other problems show similar results and are presented in how new features are constructed in the search process and may explain this timing difference between the two heuristic methods.

Quality metric : The quality metric is de fi ned as the norm of the r features returned by each method relative to the norm of the true top r features sorted from the complete weight vector. That is, if the method is asked to return 100 features, the norm of those 100 features is compared to the norm of the 100 top-weighted features found in the entire weight vector.

In terms of the quality metric, the results are presented as a ratio of Heur1 over Heur2 , where a ratio of greater than one indicates Heur1 increased ability to return the top-weighted features (less than one indicates Heur2 is better at returning the top-weighted features). The quality ratio was measured for problem size (top portion of table) or sample size (bottom portion of table).

Quality results : Heur2 shows equal or better ability to return the top-weighted features in all cases (the method exhibits equal ab ility on the Double-XOR problem, and improved ability on the other two problems). Another trend to observe is that as the size of the problem gets larger the Heur2 method improves over the Heur1 method.

Summary : There are tradeoffs between the two method, with no method showing dominance in both the top-weighted features. Therefore of the two heuristic methods the Heur2 will be used in future comparisons to the brute force approach and on real data sets. 5.1.2. Comparison of brute force to heuristic method
The brute force approach is compared to the Heur2 heuristic method in terms of the execution time to complete each procedure (the execution time does not include the time to learn the SVM model -which is necessary and equal for both procedures) and quality. Table 2 summarizes the comparison of the two approaches. Further visualizations of these results can be examined in online Appendix B.
Problem description : For this comparison, the problem size for each problem is as follows: 250, 350, and 450 variables for Circle, 226, 337, and 448 for Double-XOR, and 50, 70,and 80 variables for Checkerboard problems (the smaller data problem sizes were used in order for the brute force approach to run and produce all features). The heuristic method was run for increasing values of p (number of features the method should construct) while the brute force approach constructed all features.
Time metric : The timing results are presented as the ratio of brute force over Heur2 . A time ratio of greater than one indicates the brute force approach taking longer than Heur2 . The timing ratio was the heuristic approach), problem domain, problem size (number of variables), and sample size. For each problem, the time ratio was averaged over values of p (the brute force approach remains the same over
Timing results : Several trends in terms of the timing of each method individually and in comparison are observed from the table and graph in Appendix B. First, in almost all of the problems presented the brute force approach requires more time than the heuristic method (only for the smallest Circle and Double-XOR problem with 1000 samples is this not the case, see fi gures of Appendix B.1). This observation is expected as the brute force is constructing all the features compared to a portion of the features and weight vector. Second, both the brute force and heuristic methods increase in time as the sample size increases for each problem (this is expected, with increasing sample the number of support vectors will likely increase causing an increase in the number of calculations for each method). Also, both methods increase in time as the size of the problem (number of variables, number of features) increase. For the heuristic method, the time results increase as the number of the weights to calculate increases (i.e., the value of p increases). However, the heuristic time increase is small as p increases compared to the increase in time for an increase in sample size or problem size for all but the smallest Finally, the difference between the brute force and heuristic method grows as the size of the problem increases and the difference decreases as the sample size of the data increases.

Quality metric : The quality is presented as a ratio of brute force over Heur2 . The brute force approach better the heuristic method is at constructing all the top-weighted features. Since the heuristic method levels) it is expected that the returned features will have low weight features among them. The quality metric will therefore diverge from ideal as a number of low weighted feature are created. To counteract this situation, the two parameters, p -the number of features constructed and r -the number of features returned are both used where r p .Whena r is selected that is less than p , then those lower weighted features are removed from consideration. The heuristic method with different values of the number was compared to the brute force for the different problems, problem sizes, and sample sizes. For each problem also shown in Table 2, the quality ratio was averaged over values for p , r , and either problem under the different parameter values are shown in Appendix B.2.

An additional quality measure compares the classi fi cation performance of the full SVM model (brute force approach) to the returned features of the heuristic method (measured as AUC). This quality ratio is presented as a ratio of brute force over Heur2  X  X  classi fi cation performance. A ratio of less than one indicates the heuristic method has a higher classi fi cation performance (a ratio of greater than one indicates the full SVM model has better classi fi cation performance).
 Quality results : From Table 2 and the appendix several comments on the quality metric can be made. In general, the heuristic method diverges from the ideal quality metric of one as r increases. This observation can be explained by looking at the distribution of the weights. In Figs 3(a) and (3b), the weight distribution of the SVM model is shown. Focusing on Fig. 3(b), the Circle problem with 400 variables and 1000 samples is given in subplot showing only the top 25 weights. For this problem, two features hold the top weights after a gap in magnitude of the weights there exists a long tail of slowly diminishing weights. The heuristic method performs well to identify the top weights (the top two features). However, after identifying those top two features, the next highest weights are equal or close to the same value for many of the following features. The heuristic method does not perform as well in the top weights is required in the worst-case constructing all features and weights which degrades to the brute force approach. As with many other methods, there exist a trade-off between spending additional time searching and stopping the search with achieving a lower ideal in terms of fi nding all of the top weights.
 problem size (left portion of table) or sample size (right portion of table). In all but two cases with the Checkerboard problem and small sample, Heur2 achieves better classi fi cation than the brute force method. As the number of sample increase, Heur2  X  X  performance generally improves. There is no consensus pattern for comparing the two methods as problem size increases. 5.1.3. Comparison with a related method
The identi fi cation of the top-weighted features does not appear as a standard problem in the literature therefore there is no direct related work comparison (as discussed in Section 4). Consequently, the heuristic method is compared with the following approach: construct all features among the variables selected by a variable selection method (here we use the RFE as the variable selection method). RFE was run on the simulated data sets using a 1-fold 80/20 split on the data sets in order to train and test the performance of the SVM model. RFE was run using both linear (often the standard in practice) and polynomial kernels; for the polynomial kernel, the same kernel parameters as the heuristic method were used. Each iteration of the RFE algorithm eliminated the lowest ranked feature.

Problem description : For this comparison, the problem size for each problem is as follows: 150, 250, and 350 variables for Circle, 152, 226, and 337 for Double-XOR, and 40, 60,and 80 variables for Checkerboard problems.
Timing metric and results : The focus of this comparison is quality therefore complete timing results size data sets. RFE requires many iterations of learning a SVM model to select the variables whereas,
Quality metric : The features constructed by the RFE variables are compared to the top-weighted features of entire weight vector. A comparison is also made with the Heur2 method, where the same number of features that are created from the RFE variables are selected from the top Heur2 features list (letting p = 5000) and also compared to the top-weighted features from the entire weight vector. The quality is assessed as the norm of the features X  weights made with RFE or Heur2 divided by the norm of the same number of top weighted features of the entire weight vector.

Quality results : The features constructed from linear RFE variables performs poorly across all three data sets and is therefore excluded from further consideration. This result is not unexpected; the three simulated data problems all ha ve non-linear decision surfaces. The quality metric is pl otted for the different problems and sample sizes for the heuristic method and polynomial RFE in Fig. 4. In general, the features of Heur2 represent more of the top weights. 5.1.4. Motivating example problem
In the introduction, the problem area of interest is described in De fi nition 1. One particular problem where these properties are all true is the general parity problem. We have run our identi fi cation top weights method on 4-parity problems with variable of 250 variables (over 1 . 6  X  10 8 features) where we top-weighted features does not have a signi fi cant magnitude weight above the other features in order to a L0 or L1-norm SVM in order to create extremely sparse weight vectors that may be better suited to selection methods fail to detect this type of multivariate relationship (our method may be able to reveal new information for a domain). 5.2. Real data sets
In addition to the simulated data analysis, the heuristic method was run on several diverse, real world data sets. In these domains, the true classi fi cation function is unknown and the problems have high-dimensional data sets that do not allow the brute force approach to be run. Therefore, the method is evaluated in several indirect aspects.

Experimental design : First, the features returned by the method are used to build a linear SVM performance of this model is compared to that of a SVM model using all variables, and the variables selected by two methods: RFE and HITON [1 X 3]. RFE was run with a linear kernel eliminating half of top features are compared with the variables selected by RFE and HITON. Finally, the top features are detailed and compared against other published information on the data sets.

Domain descriptions : The characteristics of the data sets are given in Table 4. The fi rst real-world to thrombin [12]. This data set illustrates the ability of our technique to scale to a very large number of variables (over 100,000) and present new information to the domain. The second task is diagnosis of lung cancer from oligonucleotide gene expression array data, speci fi cally determining squamous versus adenocarcinoma types of cancer [4]. The fi nal task is to identify splice sites from a genomic sequence [16]. For this task, we spend additional time relating the returned features found to other biological knowledge on this subject in the literature. The results and details on the evaluation are presented in each of the following sections. 5.2.1. Thrombin data
A fi rst experiment was performed on a very high-dimensional real data set  X  the Thrombin data set initially presented in KDD Cup 2001. The data set consists of 139,351 binary variables and a binary (measured as AUC) by training on train set and testing on the validation set. The heuristic method was then run on a SVM model with the optimal parameters trained on the train set to return the top 100 features. A new SVM classi fi er was trained on the train+validation set of the top 100 features; the performance is reported on the test set. The performance of the classi fi er was compared to a SVM model created using all variables and variable subset selected by two common feature selection methods HITON and RFE. The results of each method is reported in Table 5. All methods achieve similar performances AUCs from 0.919 X 0.928.

The top 100 features returned by the heuristic method consisted of mainly features of pairs of variables (e.g., X variables (see Appendix C for detailed listing). The heuristic method returns many unique variables where of the 16 variables returned three are also returned by RFE (which returns over 8000 variables). None of the 16 variables are selected by HITON (returns 32 variables). 5.2.2. Lung cancer
The lung cancer data set is used to classify gene expression samples between squamous and adenocar-cinoma types of cancer. The data was split following a nested 5-fold cross validation design [3] in order to estimate the performance of the model and optimize SVM parameters from the sets d = { 1 , 2 , 3 , 4 } and C =10 i ,i = { X  8 ,..., 3 } .
 The classi fi cation performance of the different methods on this data set are summarized in Table 6. using only the top 1000 features (involving 18 variables). While the performance of the models using the subsets of variables selected by RFE (19 variables) and HITON (16 variables) is also similar but slightly lower.

The top features returned by the heuristic method are listed in Appendix D as well as the variables returned by RFE and HITON. The features involve several variables not considered by HITON (zero variables intersect between the two sets) and RFE (two variables intersect between the two sets). In about the selected variables is given in the appendix to allow further explorations by biologists and researchers in this domain. 5.2.3. Splice data to intron, non-coding regions or intron to exon) from DNA sequences. Typically, the intron is marked by two consensus dinucleotides of GT at the 5 X  end (the donor site) and AG at the 3 X  end (the acceptor consensus dinucleotide AG. The prediction of many genetic markers and signals have been studied using many supervised learning algorithms (see [11] for reviews and references).

For this analysis, sequence data from Arabidopsis thaliana is used to construct the data set as described in [8,16]. Each data sample consists of 50 nucleotides upstream and 50 nucleotides downstream of the consensus acceptor site. The nucleotides are converted to 400 binary features. The training data set consists of 1000 positive and 1000 negative instances. A testing set has 281 positive and 7643 negative instances.

Model parameters were selected via 10-fold cross validation from the sets degree = { 1 , 2 , 3 , 6 , 9 } results). The best model parameters were selected via cross-validation by maximizing AUC and found to be degree 6 kernel with C =0 . 05 . With the parameters of the model selected, a fi nal SVM model was created on the training data set to examine the top features and weights for each problem. The heuristic method was run on this model asking for the top p = 100000 (or total number of features) at each level a small subset of feature space. A new model was trained on the mapped data and compared against the SVM classi fi er on the original data. The classi fi cation performance was calculated for an SVM model using all variables, the variables selected by RFE, HITON, and the top 1000 features determined by the heuristic method and shown in Table 7. The top features returned by the heuristic method are able to accurately classify the test data with slightly lower performance than the full model but many fewer components to the model. Therefore, we shall more closely examine the features returned by the method.
The constituent variables of the top features and t he variables selected by the other methods are splice site machinery; several other papers using this same data set have made similar observations. In Appendix E.1.
 selection of the top features is in Appendix E.2). The next largest-weighted features consists of either pairs, triplets, and quartets of variables involving 1, 2, or 3 groupings of the upstream T X  X  and the C or pairs, triplets, and quartets of the upstream T X  X  alone. These results are again consistent with other the most frequent at this position (over 60%). Additionally, the many features involving combinations of the upstream T X  X  is corroborated. In A. thaliana (and also humans), the presence of a small subset of pentamers applies a large contribution to splice site recognition. The pentamers associated with A. thaliana are all heavily based on sequences of T X  X , e.g., TTTTT, TCTCT, TTCTT, TTTTA, etc. These short sequences are not dependent on relative position to the splice site.

Another observation can be made on the features receiving positive or negative weights. A negative weight suggest that this feature when active indicates that there is not a splice site present, while an C splice site. 5.2.4. Summary of real data sets
The method of selecting the top features are compared to variable selection through the indirect measure of classi fi cation performance. The features are used to create a linear SVM model, while alternative SVM models are build using all variables, and the variables selected by RFE and HITON. The number of variables returned by the variable selection method (and the number of variables involved in the top providing additional information about the top features (combinations of variables) that may be important to a domain.
 6. Discussion
In this paper, we present an ef fi cient, heuristic method for identifying the largest magnitude weights of a polynomial support vector machine model. This algorithm provides a new ability to understand polynomial SVM models. Prior to this work in order to understand how an SVM model decides on a selection method would be applied to identify a smaller subset of the  X  X est X  variables (where best can be becomes intractable for many problems that SVM models are aimed at. Whereas, a particular variable selection method may not provide any new insight into the functionality of the SVM model.
The experimental results presented here are over several different problems involving continuous and discrete data. However, the scope of the experiments is still limited and several questions in the application of this new method are not fully addressed in the work. First, the choice of the kernel parameters is set for the simulated data sets so that the minimal degree kernel is selected to include by cross validation classi fi cation performance (a standard technique in many experimental designs). However, it should be noted that as the degree of the kernel de fi nes the features of the SVM choosing for the algorithm to parse.

Also, the heuristic method developed here is general purpose restricted only to the polynomial kernel and does not consider the speci fi cs of the data type or how it is encoded. We employ the standard practices of typically normalizing continuous data to a mean of zero and standard deviation of 1 and encoding binary data as 0/1. The choice of the input to train the SVM does not affect how the heuristic method is run, however, it may impact the SVM model trained and consequently the feature list returned. For instance, the effect of different binary encodings is described in Section 5.1. Future iterations of redundancy in the search procedure.

In addition to the practical application of the procedure there are theoretical questions raised. For instance, the heuristic method returns the top-weighted features however, when are the most  X  X elevant X  features guaranteed to be the highest weighted? Are there distributions where the features important for Questions such as these are outside the scope of this work, but are important for the understanding and application of SVM models to speci fi c domains. 6.1. Future directions
We consider this research a fi rst step in attempting to identify the top-weighted features of an SVM model; there are many future directions of this work, several of which will be discussed here. First, the SVM models used the standard L2 SVM models learned via the widely-used LibSVM package [7]. Please note that the L2 norm tends to spread the weighting across the features. In the future, we plan to investigate the use of L1 or L0 SVMs which may provide more sparsity in the weight vector allowing for easier searching by the heuristic method.

The search procedure itself can be extended and explored. Here, the search was guided by groupings weight vector over those features. Additional subsets of features where the grouping is by both variable v , degree of the feature l , and speci fi c exponent p of variable v can be constructed:
Another direction is to extend the process here of selecting the top weighted features with Markov-blanket based variable selection algorithms. A new algorithm Feature Space Markov Blanket (FSMB) attempts to combine these approaches [6]. The main idea of FSMB is to identify the Markov Blanket of T in feature space instead of in the original variable space where multivariate associations become pairwise associations. FSMB employs an SVM to dictate which features may have pairwise association with T in feature space. To avoid explic itly computing all features, FSMB uses the heuristic method described here to identify the top features. A subset of the top-weighted features returned are selected the new feature space data set is passed to a Markov Blanket identi fi cation method (MMMB, HITON, PCMB, etc.) to select the Markov Blanket in feature space.

This new approach has been run on several of the real data sets used here and shown to have ability to return features that have good classi fi cation performance. For instance on the lung cancer data set, the classi fi cation AUC for the SVM with all variables, variables selected by RFE and variables selected by HITON is 0.991, 0.986, and 0.978 respectively. FSMB returns 4 features that provide a classi fi cation performance of 0.979. For the Thrombin data set, RFE selected over 8000 variables, HITON selected 32 variables, FSMB selects 5 features while providing the following classi fi cation performances respectively 0.919, 0.926, 0.939.

The FSMB method works well compared to many MB-based feature selection on a particular class of problems. This class of problems involves distributions where the combinations of the variables have high association with the target but each variable alone has low association with the target. The example of the general parity problem is of this class. On this class of problems, traditional MB-based variable to the target. 7. Conclusions
Support Vector Machines (SVMs) models have been widely used to classify data. However, the reasoning behind the classi fi cation is complex, and previously unavailable to the user. This paper examines a method to explicitly determine the deci sion function used to classifydata for polynomial SVMs. In particular, a heuristic method was designed to identify the highly weighted features of this decision function. These features may give insight into how the SVM classi fi es data and provide information on the features and variables relevant to the target class.
 References
