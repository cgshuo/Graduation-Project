 Collaborative filtering algorithms attempt to predict a user X  X  inter-ests based on his past feedback. In real world applications, a user X  X  feedback is often continuously collected over a long period of time. It is very common for a user X  X  interests or an item X  X  popularity to change over a long period of time. Therefore, the underlying rec-ommendation algorithm should be able to adapt to such changes accordingly. However, most existing algorithms do not distinguish current and historical data when predicting the users X  current in-terests. In this paper, we consider a new problem -online evo-lutionary collaborative filtering , which tracks user interests over time in order to make timely recommendations. We extended the widely used neighborhood based algorithms by incorporating tem-poral information and developed an incremental algorithm for up-dating neighborhood similarities w ith new data. Experiments on two real world datasets demonstrated both improved effectiveness and efficiency of the proposed approach.
 H.3.3 [ Information Systems ]: Information Search and Retrieval X  Information Filtering Algorithms, Experimentation Collaborative Filtering, Ranking, Latent Class Model
Collaborative filtering (CF) is a popular technology for recom-mender systems. It does not rely on any content information about the items that need to be recommended. Given large amount of user feedbacks such as ratings, clicks, purchases, etc, CF algorithms work by discovering the correlation between users and items, and predict unobserved ratings based on the observed ratings associated with similar users and items. In real world recommender systems, user feedback data are accumulated over time as users interact with the system, the data instances can be naturally ordered by the time they are collected. Most existing approaches often ignore the di-mension of time and assume that the users X  and the items X  charac-teristics are static. While such assumption is acceptable for rela-tively short time periods such as days or weeks, it becomes rather unreasonable for longer time periods during which important fac-tors affecting recommendation decisions such as a user X  X  interests or a movie X  X  popularity can vary significantly. There are many causes of such changes. Firstly, a user X  X  interests or tastes often change over time. Secondly, external events such as holidays could lead to abrupt increase in the popularity of certain items such as comedies. Thirdly, as time goes by, the recommender system it-self may went through changes such as reorganizing its catalogue or introducing new search or linking features, which may improve the accessibility of some items. Finally, a user X  X  behavior often exhibit temporal locality . For example, if a person enjoyed a par-ticular movie, he will often try to find related movies by the same directors/actors or of the same genre.

One emerging trend in various modern Web 2.0 based recom-mendation services is that user X  X  interactions with the systems are becoming highly dynamic. For news recommendation services such Digg, users generally generate feedbacks on a daily basis and one X  X  interests are mostly event driven and drift very quickly. Similarly, for internet radio such as Last.fm or video services such as Youtube, user feedbacks are generated almost continuously. For these appli-cations, it is crucial for the underlying recommendation algorithm to be capable of dynamically tracking users X  interests and provid-ing very fast responses in order to ensure high quality interactive experiences. In order to achieve such a goal, a straightforward strategy would be to adopt any existing CF algorithm and simply repeatedly rebuild the model using both old and new data. How-ever, as most algorithms typically need to go through a very lengthy training stage, the computational complexity of this naive approach would not be affordable for applications requiring fast responses. It is therefore necessary to develop incremental algorithms that can efficiently adapt existing model using the new data.

In this paper, we propose an online evolutionary collaborative filtering framework for making recommendations based on user feedback data collected over time. Our contributions are two folds: first, we proposed several effective instance weighting techniques to incorporate temporal information into the widely used neigh-borhood based prediction algorithm so as adapt to changes in both user and item characteristics over time. Secondly, we developed an incremental algorithm for efficiently updating neighborhood simi-larities as new data are generated at each time step. Therefore, we name our framework as online evolutionary collaborative filtering, as it is capable of both coping with the temporal dynamics of the data and incrementally updating the underlying model with mini-mal cost. We have validated our approach on real world data sets from two different application domains. The results demonstrated significant improvements of our methods in terms of both effective-ness and efficiency.
The goal of collaborative filtering is to suggest new items to users by predicting a score of a particular item for a particular user based on his feedback on some old items as well as the feedback from other users with similar tastes. User feedbacks may be expressed explicitly such as via assigning numeric rating to the items, or im-plicitly such as via clicking, tagging or linking, etc.
The prediction tasks in collaborative filtering can be broadly cat-egorized into two types: rating prediction and choice prediction. The most extensively studied task is that of rating prediction, which attempts to estimate the rating score that a user may assign to an item. This is generally evaluated by holding out certain amount of user ratings and comparing the predicted ratings with the true ratings. Since the rating scores indicate the extent to which a user favors an item, the performance of rating prediction reflects an al-gorithm X  X  ability at capturing user X  X  preference over items.
The choice prediction task is concerned about predicting which users would rate what items, and is often based on implicit user feedbacks. The "Who Rated What task" of KDDCUP 2007 [2] is an example of choice prediction. Collaborative filtering on implicit feedback [11, 16] can also be viewed as choice prediction. Implicit feedback are often not in the form of numeric ratings but binary responses. Examples of such binary response may be whether or not a user has rated a movie, clicked a page or played a TV pro-gramme. So the performance of choice prediction reflects an algo-rithm X  X  ability at capturing the items X  relevance to the users. In this work, when dealing with movie ratings dataset such as Netflix, we treat rating prediction and choice prediction as two separate tasks. The original ratings data are used as input to the algorithms for rating prediction, while for choice prediction, we transform the ratings data into binary responses indicating whether a user has rated a movie. We believe that relevance and prefer-ence are two different aspects of user behavior we want to capture in order to improve recommendation quality. For example, it is very common for a user to assign low ratings to some "blockbuster" movies but that does not mean the same user do not want to watch these movie. Also as we will show in our results, the temporal dy-namics tend to have much stronger influence on users X  choices than on their ratings.
In evolutionary collaborative filtering, we observe the ratings on a set of m users U = { u 1 ,u 2 , ..., u m } on a set of I = { i 1 ,i 2 , ..., i n } over time, where the value and time of the rat-ings are stored in a matrix R  X  R m  X  n + and a matrix T  X  R m  X  n respectively, where r ui and t ui are the value and time of the rating by user u on item i .Let I t u denotes the set of items that before time t and let U t i denote the set of users who have rated before time t .

Traditional neighborhood based CF algorithms including both user and item based models generally consists of three steps(in the remaining part of this paper, we will use item based models as ex-amples). 1. Similarity Computation : Compute the item-item similari-2. Neighborhood Computation : For each item i ,findthe k 3. Score Prediction : Predict he unobserved ratings by averag-
In traditional neighborhood methods, these steps are conducted without considering the temporal information. In this section, we introduce our evolutionary collaborative filtering framework, which is able to utilize temporal information in both the similarity com-putation and score prediction steps via weighting each rating with its temporal relevance .
Central to our evolutionary collaborative filtering framework is the notion of temporal relevance f  X  ui ( t ) , which measures the rel-evance of each observed rating r ui for making recommendations at time t based on parameter  X  . f  X  ui ( t ) should decrease with the amount of time that has passed since the rating r ui was inputted (i.e., t  X  t ui ) based on the assumption that older ratings are gen-erally less correlated with a user X  X  current interests or an item X  X  current characteristic. We therefore use the following function to assign a weight for each rating depending on the amount of time that has passed since the rating date: where the parameter  X  controls the decaying rate. By setting 0, we would ignore the evolutionary nature of the data and sim-ply assign a constant temporal relevance value of 1 to all observed ratings at all time.

A nice property of the temporal relevance function is that it can be recursively computed: where the constant  X  = e  X   X  denotes the constant decay rate.
Under the setting of evolutionary CF, the item-item similarity is a function of time, denoted by S ij ( t ) , which measures the similarity between two items based on their ratings on the set of users they are both rated up until time t .

To measure item similarities by incorporating temporal informa-tion, we modify the well known cosine similarity as follows:
Incorporating the temporal relevance into the similarity compu-tation as in (5) places more emphasis on the recent ratings of both items and is inclined to identify nearest neighbors, whose linked users are not only correlated but also synchronized in the sense that they are assigned similar ratings by the same set of users around time t .
Let N t i denote the set of nearest neighbors of item i at time the item-based model generates rating predictions as a weighted average of the ratings on the subset of i  X  X  nearest neighbors which have been rated by u (i.e., N t i  X  X  t u ):
Note that for the score prediction step, we have designated a dif-ferent temporal relevance function f  X  ui ( t ) with decaying rate con-trolled by  X  to determine each rating X  X  weight when making score predictions. Using separate temporal relevance functions for sim-ilarity computation and score prediction allows us to study the ef-fect of temporal dynamics on neighborhood similarity and rating prediction independently.

For the choice prediction task, the item based model would com-pute the weighted proportion of nearest neighbors who have been rated by a user: where the sum is over all neighbors in N t j rather than over as in (6).

Note that in all the formulas above, each rating X  X  weight not only depends on the neighbor similarities S uv ( t ) or S ij ( temporal relevance f  X  ui ( t ) , which is a new factor not considered by traditional neighborhood based model, in order to emphasize more on recent ratings.
In the previous section, we illustrated how temporal informa-tion can be incorporated in the evolutionary collaborative filtering framework via the temporal relevance based weighting schme. In this section, we address another challenge posed by the evolving nature of data, the problem of efficiently updating the model as new data arrives over time in large volumes. In particular, we de-velop incremental algorithms for the similarity computation and neighborhood computation step, which are the performance bot-tlenecks of neighborhood based al gorithms. The ability to support both temporal dynamics and incremental computation lead us name our overall framework online evolutionary collaborative filtering .
Given m items and n users, the time complexity of computing all user-user and item-item similarities are O ( n 2  X  m respectively, where  X  m is the average number of ratings per user while  X  n is the average number of ratings per item. For evolutionary collaborative filtering, the neighbor hood similarities will need to be recomputed repeatedly at each time step using all the ratings, which is highly computationally expensive.

We note that the item-item similarity defined in (5) can be rewrit-ten into the following form: where
We will show that the functions P ij ( t ) and Q i ( t ) can both be in-crementally updated, thus allowing S ij ( t ) to be incrementally com-puted. Let  X  U t i denote the set of users who newly rated step t (i.e.,  X  U t i = U t i \U t  X  1 i ). By definition, all u  X   X  U t and P ij ( t  X  1) by decomposing P ij ( t ) as follows: where we have absorbed the first three summations into the term  X 
P ij ( t ) and related the fourth summation with P ij ( t equality (4).

Therefore by caching P ij ( t  X  1) , we can efficiently obtain the value of P ij ( t ) by only focusing on the computation of  X  It is easy to see that the time complexity of the three summations involved in computing  X  P ij ( t ) is bounded by O ( |  X  U t By contrast, computing P ij ( t ) non-incrementally using (9) has a complexity of O ( |U t i  X  X  t j | ) . Within one time step, especially for very short time steps, |  X  U t i | , the amount of new ratings for a item, tend to be much smaller compared with |U t i | , the amount of all its ratings so far. Threfore the complexity of computing  X  P ij also be much smaller compared to the complexity of computing P ij ( t ) . Moreover, |U t i | , the amount of all ratings is a quantity that grows with time, while |  X  U t i | , the amount of new ratings in a step, is a relatively stable quantity. So the efficiency improvement of the incremental approach over the non-incremental approach tends to increase with time as we would show in section 6.
 Similarly, we can obtain the following recursive relation for And it is easy to see that the incremental computation of only requires computing  X  Q i ( t ) , which has a complexity while the complexity of the non-incremental method in (10) is
Next we would compare the space complexity of the incremen-tal vs. non-incremental algorithms to similarity computation. In the non-incremental approach, the user-user similarity matrix is what need to be stored, which has a space complexity of O In the incremental algorithm, caching P ij ( t ) and Q i ( quire O ( n 2 ) and O ( n ) space respectively. But using equation (8), S ij ( t ) can be generated from P ij ( t ) and Q i ( t ) on the fly, there is thus no extra storage needed for the similarity matrix. So the in-cremental algorithm only requires an additional O ( n ) storage for the caching the Q i ( t ) values compared with the non-incremental algorithm, which is a very modest increase in space requirement compared with the O ( n 2 ) space complexity of the non-incremental algorithm.

Similarly, we can obtain incremental algorithms for computing the user-user similarities, which we will not show in detail due to space limitation. Finally, it is easy to see that this incremental al-gorithm also works for the case of static neighborhood based al-gorithm (i.e., without using temporal relevance function), in which case one only needs to make the constant  X  equal to 1 in the updat-ing formulas for P ij ( t ) and Q i ( t ) .
To determine the k nearest neighbors, one needs to conduct par-tial sort based on user-to-user or item-to-item similarities. The typ-ical way to do partial sort is to first use the quickselect algorithm algorithm to find the k neighbors that are most similar to the tar-get user or item, and then use quicksort algorithm to order the nearest neighbors. The time complexity of this partial sort oper-ation is O ( n + k log( k )) ,where n and k are the total number of users/items and neighborhood size re spectively. To repeat the par-tial sort from scratch at every time step can be very expensive, our strategy to incrementally maintain the neighborhood is based on the observation that the neighborhoods for each user or item often do not drastically change from one time step to the next, especially when updates are performed frequently. To exploit this effect in or-der to more efficiency maintain neighborhoods, we first resort the k nearest neighbors from previous time step based on their newly updated similarities, the complexity of the resort is generally much smaller than O ( k log( k )) in practice, given that the relative order of the nearest neighbors is rather stable. Then for the remaining neighbors, we would only invoke quickselect to insert it into the neighborhood if if its sim ilarity to the target u ser/item exceeds the current k -th nearest neighbor. Empirically, we found this simple heuristic strategy can reduce the neighborhood computation time by nearly an order of magnitude.
Algorithms for collaborative filtering can generally be divided into two categories: memory based algorithm vs. model based al-gorithm. The memory based algorithms need to manipulate the en-tire user-item rating databases in order to generate prediction. The most common form of memory based algorithm is the user based model[9], which predicts the unknown ratings of a target user based on the ratings by the set of most similar users. An alternative form of the neighborhood based approach is the item based model[19], which predicts a user X  X  rating on an item based on his ratings on the similar items.

In contrast to the memory based algorithms, the model based al-gorithms work by building a compact parametric model from the the observed user item ratings and allows predictions to be made efficient using the learnt model. Different types of models have been proposed for collaborative filtering including matrix factor-ization[8, 20, 18, 1], probabilistic mixture models [10, 12] and bayesian networks [17].

Despite much existing work on collaborative filtering, as far as we know, few works have addressed the issue of utilizing tem-poral information and incremental learning in the context of col-laborative filtering. [5] is an early attempt to exploit time stamps of ratings. They adapt the item based approach by incorporating time based weights in the score prediction stage but did not adapt similarity computation. Another work[14] considers temporal in-formation only by varying neighborhood size overtime. The most recent work by Koren[13] on the Netflix prize competition devel-oped a matrix factorization model that considers changes in user and item X  X  characteristics over time. Their model has very high complexity due to the use of large number of time dependent pa-rameters. All the above methods are non-incremental algorithms and have only evaluated for rating but not choice predictions. To the best of our knowledge, our work is the first to propose an incre-mental collaborative filtering algorithm that is capable of modeling temporal dynamics.

Data stream mining is a closely related research problem, which focuses on dealing with data instances ordered by time. [6, 7] stud-ied how to build classifier from data streams whose underlying con-cept may drift over time. It was shown that historical data could hurt performance when used blindly and thus should be selected with care[6]. However, most of the se works[6, 7] are on data clas-sification, which are very different from collaborative filtering. [3] adapted spectral clustering to the evolutionary setting in which the relations between data points are not static. [15] developed a non-incremental algorithm for decomposing 3D tensors. [21] developed techniques for efficiently doing principal component analysis over streams of data vectors. The problem setting of evolutionary col-laborative filtering is very different from these problems in that we have a set of items and users that are active through out the entire time period but whose characteristics may change over time. Figure 1: Growth of number of movies, users and ratings growth in the Netflix dataset
Our experiments were based on the Netflix prize dataset 1 contains over 100 million rati ngs from around 480 , 000 users on 17 , 000 movies collected over a period of nearly 296 weeks. The long time span of the data makes it the ideal choice for evaluat-ing evolutionary collaborative filtering as users X  interests are very likely to have drifted over such a long time. We measure the age of a movie and a user by the difference between the date of its first rating and the date of the evaluation period. In order to study the algorithm X  X  ability to cope with temporal dynamics, we removed all users and movies with age less than 1 year and then selected a subset formed by the 35,000 most active users and 4,000 most pop-ular movies as measure by their associated number of ratings. The final dataset contains around 10 m illion ratings. In addition to this set of ratings, we also selected another set of rating by 2000 users as validation set for tuning the various parameters such as number of neighbors k , and weight decay rate  X  and  X  .

In our experiments, we make the duration of each time step to be one week. In Figure 1, we plot the number of new movies, users and ratings introduced at each time step in the Netflix data set. From the top plot, we can see that a significant number of these most popular movies since the very beginning of the time pe-riod. This is reflected by the left most pike of the movie growth http://www.netflixprize.com plot, after which the rate of the growth of number of movies be-came quite stable. The middle plot shows that the number of users experienced significant growth in the later half of the time period whereas the bottom plot shows that the number of ratings had a steady growth over time since the number of users and movies con-stantly increased over time.

We then did some more detailed analysis on the dataset to further study the temporal dynamics in relation to user and movie ages. In particular, we examined how a user and a movie X  X  rating value and rating frequency changes overtime. In Figure 2, the top plot showed that average rating values in the entire dataset gradually increased over time and had a sudden jump around week 200, which was con-sistent with the findings on the entire Netflix dataset[13]. The mid-dle plot of Figure 2 showed that the early ratings were often high probably because they are most voted by the most enthusiastic fans, and then suddenly drops to a normal level and started to slowly in-crease over time. The slow increase was probably because very old movies that got rented were often classics and therefore more likely to receive high ratings. Finally, the bottom plot in Figure 2 revealed an interesting pattern which was that while the average rating value of a user appeared to stay around 3.55 overtime, the variance of his ratings tended to increase over time. This was probably because new users are mostly neutral and as they watched more and more movies, they became more adept at expressing their personal pref-erences using the ratings and were more likely to cast very high and very low ratings.

In addition to study the temporal dynamics regarding rating val-ues, we also examined how the rating frequency were changing over time. The top plot of Figure 3 showed the proportion of rat-ings in each time step, from which we can observe a fast growth after week 150 when a large number of new users joined Netflix. The middle plot showed the proportions of a movie X  X  ratings in each week since its release, which steadily increased in the first few weeks and then gradually drops to a normal level and remained sta-ble. The increase in rating proportion after week 150 was mostly due to the large number of new users who joined Netflix after week 150. The bottom plot showed a clear pattern that a user tended to rate many more movies when he joined Netflix and became less and less active over time. This implied that an old user would in general be much less likely to rate movies compared to a new user.
Rather than splitting the data into a training and a test portion, we scan through the entire dataset by time and at each time step t , a user X  X  ratings collected on and before time step t  X  1 are used as training data and ratings in time step t are used as test data for evaluation. So the evaluation period in our experiments covers a extended time period spanning nearly 300 weeks, which is ideal for evaluating an algorithm X  X  ability to cope with changes in user and item characteristics over time.

The rating prediction accuracy of different algorithms are mea-sured by the Root Mean Squared Error(RMSE). For a set of test ratings, the RMSE is computed as: So the RMSE measure evaluates algorithm based on how close their predicted ratings are to the true ratings with a lower RMSE value indicating higher rating prediction accuracy.

For the choice prediction task, we treat the movies rated by a user as being relevant and irrelevant if otherwise. Since the re-sponses are all binary, we use the commonly adopted ranking per-formance measure Mean Average Precision (MAP) to evaluate the algorithm X  X  performance.
 where N is the number of users in the test data, r u is the num-ber of relevant items to user u and Prec u @ k is the precision value at the k -th position in the ranked item list for u . According to the MAP measure, an algorithm is therefore more effective if it can rank more relevant (rated) items in front of irrelevant (unrated) items. A higher MAP thus indicates better choice prediction per-formance.

In the following experiments for evaluating our online evolution-ary collaborative filtering framework, we only report the perfor-mance of the item based model but not the user based model as it is not feasible to maintain a user-user similarity matrix given the great number of users but a much smaller number of items in the Netflix dataset.
Our first set of experiments studied whether the use of temporal relevance weighting could help improve prediction accuracy. Re-call that the parameter  X  and  X  control the rate of weight decay for the temporal relevance function f  X  ui and f  X  ui used in the simi-larity computation (eq. 5) and score prediction(eq. 6 and 7) step respectively. When both  X  and  X  are equal to 0, we would obtain the standard nearest neighbor (SNN) algorithm, which ignores the temporal information. Otherwise, we could adjust the values of and  X  to obtain evolutionary nearest neighbor (ENN) algorithm, which takes into account temporal dynamics. Figure 4: The effect of  X  and  X  on rating prediction quality
To study the extent to which temporal relevance weighting can help improve prediction quality of ENN, we measured the perfor-mances of ENN as we increased the value of  X  or  X  from 0 while holding the other parameter at 0. The effects of  X  and  X  on rat-ing prediction quality as measured by RMSE were plotted in Fig-ure 4. As we can see from the left plot, emphasizing more on re-cent ratings by increasing  X  when comparing item-item similarities could reduce the RMSE value, this showed that temporal relevance weighting can effectively cope with the changing average rating ef-fect on movies observed in Figure 2. On the contrary, the right plot indicated that adopting temporal relevance weighting in score prediction had actually led to higher errors. Via analyzing the re-sults, we found this was due to that in the item-based algorithm, the predicted scores are obtained by averaging a target user X  X  very few observed ratings on the nearest neighbors and given the very limited size of this set of ratings, temporal relevance weighting X  X  effect to further reduce the contribution of old ratings would make the prediction less robust. Figure 5: The effect of  X  and  X  on choice prediction quality
The effects of  X  and  X  on choice prediction quality as measured by MAP were plotted in Figure 5, in which we observed some dif-ferent effects from rating prediction. Firstly, increasing proved the MAP value though the optimal  X  is smaller than that for rating prediction. Secondly, on the contrary to rating prediction, increasing  X  to emphasize more recent ratings in score prediction was highly effective. Such a difference implied that there could be very different temporal dynamics governing which movies a user would choose and what ratings he would assign to a chosen movie. The results on choice prediction seemed to indicate that a user X  X  choice in movies appeared to have strong temporal locality in the sense that he is much more likely to rent movies similar to those movies he had just rented very recently.

For the ENN method, we did some further analysis of its perfor-mance in order to understand on what kinds of users and items does ENN achieve the largest improvement over SNN. For this purpose, we formed different age groups of users and items based on the date of their first rating and measure the performance improvements on users and items in each age group, the results for rating predic-tion were plotted in Figure 6. We can observe that ENN was able to achieve consistent improvements over both old and new movies, but it appeared to be more effective for new users than for old users. One reason for this is that the exponentially decaying temporal rel-evance function tend to assign very small weights for very old rat-ings which tend to have stronger effect on old users when making predictions at later time steps. In the future, we would investigate how to refine the temporal relevance function to avoid such nega-tive effects.

The detailed performance within each age group for choice pre-diction were shown in Figure 7. We can see that improvements on new items are more significant, which could be due to the following two reasons. Firstly, the cosine similarity tends to favor old movies over new movies as old movies have received more ratings on them and their cosine similarity with other movies tend to be higher in general, the temporal relevance weighting can reduce the weights of past ratings on old movies thus reducing this kind of bias in sim-ilarity computation. Secondly, the prediction based on temporal relevance would consider how similar a rated item is to the current item as well as how recent a rating is, which could better reflect Figure 6: RMSE of SNN and ENN within each age group of movies and users Figure 7: MAP of SNN and ENN within each age group of movies and users user X  X  current interest. Similar to the rating prediction results, we observed again more significant improvements on old users than on new users. This is consistent with the intuition that it is more likely for the tastes of old users to have drifted over time, so the incor-poration of temporal relevance appeared to be highly effective in modeling items X  relevance with respect to users X  current interests given both his most recent and more historical ratings.
In this section, we conducted experiments to compare the effi-ciency of the incremental and non-incremental algorithms for sim-ilarity computation. We measure the amount of time that was spent on building the neighborhood model using non-incremental and in-cremental algorithms in each time step, which were plotted in Fig-ure 8. It is clear that the computational cost of the non-incremental algorithm increased very rapidly with time while the run time of the incremental algorithm remained stable over time. This proved that the incremental algorithm was much more efficient in updating the similarities and nearest nei ghbors in the presence of continu-ously growing data. For the last few time steps, we can see that the incremental algorithm was almost 15-20 times faster than than the non-incremental algorithm.
 Figure 8: Run time at each time step for the incremental and non-incremental algorithms
Our incremental algorithm for the neighborhood model consists of two operations. One is to incrementally compute neighborhood similarities, the other is to incrementally maintain the k neighbors. To show that our incremental algorithm can save com-putational time on both operations, we further decomposed the over-all run time into similarity computation time and neighborhood computation time for both incremental and non-incremental algo-rithms, which were shown in Figure 9. It could be seen that for both incremental and non-incremental algorithms, the majority of computational time are spent on computing the nearest neighbors. Moreover, the incremental algorithm was nearly 10 times and 5 times faster than the non-incremental algorithm for the similarity computation and neighborhood computation respectively.
 Figure 9: Detailed Efficiency Comparison between Incremental and Non-Incremental Algorithms
Model based algorithms such as matrix factorization have been demonstrated to achieve state of the art prediction performance on the Netflix dataset[13]. However, a problem for many model based methods is that they all require a lengthy training period. In this set of experiments, we compared our simple ENN algorithm with pop-ular matrix factorization and probabilistic models in terms of both run time and prediction accuracy to show the trade off between ef-ficiency and effectiveness. In particular, we chose the time-aware matrix factorization model (TimeSVD)[13] as a baseline for rat-ing prediction and the probabilistic latent semantic analysis (PLSA) method[4] used for recommending news stories based on click data as a baseline method for choice prediction.

The issue of incremental training of these models was not ad-dressed in the original papers, simply retraining the model from scratch at every time step will be too slow. In our experiments, we adopted the following simple strategy to incrementally main-tain the TimeSVD and PLSA model at each time step given new ratings, which used the parameters in the most recent model to ini-tialize the training of the next model. This is based on the intuition that given a small amount of new data, the optimal parameters for the old dataset should not be very far from the optimal parameters for the new dataset. In practice, we found this could significantly reduce the number of iterations needed to reach convergence when refitting the models at later time steps. To control how frequently the models are updated, we also introduce an extra parameter such that the model is retrained every t d steps.

The performance comparisons for rating prediction and choice prediction are shown in Table 1 and 2 respectively. We can see that the models TimeSVD and PLSA can indeed outperform our ENN method given that they were updated at every time step(i.e. t =1) although their run time at such update frequency were al-most 10 times longer than the simple ENN method. Moreover, as the update frequency of TimeSVD and PLSA reduced, their perfor-mance tended to deteriorate significantly and became much worse than ENN while they still took much longer run time than the ENN. This demonstrated that the although the ENN method yielded sub-optimal prediction quality, it was nevertheless the most efficient method, which was nearly an order of magnitude faster than the more complicated models. In the mean time, a more frequently updated ENN could be more accurate than a less frequently up-dated TimeSVD or PLSA model. For applications in which the user feedback data are generated at a very high speed, we often could not afford to update complicated models such as TimeSVD and PLSA frequently to achieve optimal prediction accuracy and the ENN model would be ideal in terms of both efficiency and ef-fectiveness.
 Table 1: Rating Prediction Performance and Run Time Com-parison between ENN and TimeSVD Table 2: Choice Prediction Performance and Run Time Com-parison between ENN and PLSA
Here we summarize some of our keys findings: 1. The use of temporal relevance weighting could lead to more 2. A detailed analysis reveals that our algorithm can most effec-3. The proposed algorithm is simple and fast enough to cope
In this paper, we proposed the temporal relevance measure for ratings at different time steps and developed online evolutionary collaborative filtering algorithms by incorporating this measure into nearest neighbor algorithms and incrementally computing neigh-borhood similarities. Experimental results on large real world data sets demonstrated that our algorithm can both significantly improve prediction accuracy and save computation time in repeatedly build-ing models. In the future, we would consider more complex models for the temporal dynamics of user feedbacks by incorporating more advanced time series analysis and modeling techniques.
We thank the support of RGC/NSFC Project N_HKUST 624 / 09 and funding from NEC China Lab. [1] J. Abernethy, F. Bach, T. Evgeniou, and J.-P. Vert. A new [2] J. Bennett, C. Elkan, B. Liu, P. Smyth, and D. Tikk. Kdd cup [3] Y. Chi, X. Song, D. Zhou, K. Hino, and B. Tseng.
 [4] A. S. Das, M. Datar, A. Garg, and S. Rajaram. Google news [5] Y. Ding and X. Li. Time weight collaborative filtering. In [6] W. Fan. Systematic data selection to mine concept-drifting [7] J. Gao, W. Fan, J. Han, and P. S. Yu. A general framework [8] K. Y. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [9] J. Herlocker, J. A. Konstan, and J. Riedl. An empirical [10] T. Hofmann. Latent semantic models for collaborative [11] Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for [12] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative filtering [13] Y. Koren. Collaborative filtering with temporal dynamics. In [14] N. Lathia, S. Hailes, and L. Capra. Temporal collaborative [15] M. W. Mahoney, M. Maggioni, and P. Drineas. Tensor-cur [16] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, [17] D. M. Pennock, E. Horvitz, S. Lawrence, and C. L. Giles. [18] J. D. M. Rennie and N. Srebro. Fast maximum margin matrix [19] B. M. Sarwar, G. Karypis, J. A. Konstan, and J. Riedl. [20] N. Srebro and T. Jaakkola. Weighted low-rank [21] J. Sun, D. Tao, and C. Faloutsos. Beyond streams and graphs:
