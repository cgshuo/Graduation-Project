 The research described in this paper forms the backbone of a service that enables the faceted search experience of the Yahoo! search engine. We introduce an approach for a machine learned ranking of entity facets based on user click feedback and features extracted from three different ranking sources. The objective of the learned model is to predict the click-through rate on an entity facet. In an em-pirical evaluation we compare the performance of gradient boosted decision trees (GBDT) against a linear combina-tion of features on two different click feedback models using the raw click-through rate (CTR), and click over expected clicks (COEC). The results show a significant improvement in ranking performance, in terms of discounted cumulated gain, when ranking entity facets with GBDT trained on the COEC model. Most notably this is true when evaluated against the CTR test set.
 H.3.3 [ Information Retrieval ]: Information Search and Retrieval; H.3.5 [ Information Retrieval ]: On-line Infor-mation Services Experimentation, Measurement, Performance ranking entity facets, click feedback, GBDT
The major Web search engines are gradually changing the search experience. Most notably this is visible through the introduction of semantic search assistants, the enrich -ment of the search results shown to the user and other components that try to predict the user intent. Key to enriching the search experience is the wide-scale availabi l-ity of user-generated content and other knowledge bases such as Wikipedia, the Internet Movie Database (IMDB),
The research presented here is part of the faceted search experience of the Yahoo! Web and Image search engines [4]. tend to be less focussed on, for instance, celebrity entitie s. For every source, we extract different unary, symmetric and asymmetric features such as query frequency, conditional probability, KL divergence, etc. [4]. For the initial launc h of the faceted search experience, we constructed a ranking function that is a linear combination of the conditional pro b-abilities extracted from the three ranking sources .
The main contribution of this paper is a machined learned approach for ranking entity facets based on user click feed-back. We propose to learn a ranking using the full set of features extracted from the ranking sources that will pre-dict the click-through rate (CTR) on an entity facet [1]. For that purpose we introduce two click models: raw click-through rate on the facets, and the click over expected click (COEC), which is claimed to be more robust towards the position-bias on a click as users tend to click more on those results shown high in the ranking [3].

The click-feedback is used as the ground truth for our training, development and test sets. We have experimented with various learners, but for the experiment reported here we limit ourselves to the discussion of the performance usin g stochastic gradient boosted decision trees (GBDT) [2]. We used least squares regression as our loss function.
Next we collected the user click feedback on the facets over a period of three months, based on which we compute the click-through rate and click over expected click for eac h entity facet pair that was shown at least 25 times to a user. The latter constraint is to ensure that the CTR and COEC values are stable enough to be used as the labels for our training, development, and test sets. We join the feature set with the CTR and COEC sets, using the entity facet pair as the key. Next we split the collection into training, development and test sets. When splitting, we ensure that an entity can only occur in one of the three collections.
The objective of the experiment is to measure the predic-tion accuracy based on the click-through rate of an entity facet pair. We first present the setup of the experiment, followed by a discussion of the results of the evaluation. ranking strategies: (1) Baseline . A linear combination of the conditional probabilities. (2) GBDT ctr . GBDT trained on the CTR click model and (3) GBDT coec . GBDT trained on the COEC click model.
 containing the same 100 entities and their 10+ facets that have not been used for training or parameter tuning. For a fair comparison of the performance between queries we have normalized the CTR and COEC values for each of the facets of the 100 selected entities to be in the range of [0 , 1]. test collection, we adopt Discounted Cumulative Gain (DCG) as our metric. DCG is an effectiveness measure that is used frequently for information retrieval tasks, and allows for the use of a graded relevance scale.
 two GBDT models is reported in Table 1. For each of the two test sets, CTR and COEC, the mDCG and mnDCG is included. The performance of all strategies, independent o f
