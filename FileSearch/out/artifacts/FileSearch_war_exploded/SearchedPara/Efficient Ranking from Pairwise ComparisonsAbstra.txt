 Fabian L. Wauthier flw@cs.berkeley.edu Michael I. Jordan jordan@cs.berkeley.edu Nebojsa Jojic jojic@microsoft.com Microsoft Research, Redmond, WA 98052, USA Ranking from binary comparisons is a ubiquitous problem in modern machine learning applications. Given a set of n objects and set of (possibly incon-sistent) binary comparisons between pairs of objects (such as  X  X layer i won against player j , X  or  X  X he cus-tomer bought book i instead of j  X ), the task is to infer a total order over objects that aggregates the given measurements. Common settings for this prob-lem allow binary comparisons to be measured either actively (Ailon, 2012; Ailon et al., 2011; Jamieson &amp; Nowak, 2011; Braverman &amp; Mossel, 2009; Giesen et al., 2009), repeatedly (Negahban et al., 2012; Am-mar &amp; Shah, 2011; Feige et al., 1994), or assume that all n ( n  X  1) / 2 comparisons are known up to some noise (Braverman &amp; Mossel, 2008; 2009). We believe that in many challenging applications, these assump-tions are unrealistic: (1) Active measurements are of-ten infeasible, either because measurements must be made passively (e.g., from click-through data, purchas-ing preferences), or because pairwise comparisons are too time consuming to measure in series (e.g., measur-ing protein-protein interactions). (2) Repeated mea-surements are not practical if comparisons are derived from the outcomes of sports games or the purchasing behavior of a customer (a customer typically wants to purchase a product only once). (3) The O ( n 2 ) growth of comparisons between n objects usually prohibits ex-haustive measuring when n is large.
 Since a total order can be uniquely determined by sort-ing distinct object  X  X cores, X  it is common to formalize the problem as follows: Given a subset of (possibly noisy) binary comparisons  X  c i,j between n objects, we desire a scoring function  X   X  : { 1 ,...,n }  X  R so that  X  c the training data as possible. Traditional optimiza-tion losses targeting this objective are intuitive (e.g., count the number of inversions between the training data and the scoring function,) but discontinuous and non-convex. The substantial literature on learning to rank can be specialized to this setting by learning scor-ing functions that only depend on the object identity. This approach suggests ways to approximately solve the optimization problem by relaxing the intractable loss to convex surrogates (Dekel et al., 2004; Freund et al., 2003; Herbrich et al., 2000; Joachims, 2006). Although some of these methods (e.g., the SVM) can achieve an  X ( n ) lower bound on a certain sample com-plexity, we feel that optimization-based approaches may be unnecessarily complex in this situation. The question arises whether simpler algorithms could be equally effective. In this paper we demonstrate that two very simple algorithms achieve the same  X ( n ) lower bound without solving an explicit optimization problem. Furthermore, given slightly more measure-ments, we can show interesting differences between the two algorithms: The first predicts rankings with ap-proximately uniform quality across the ranking, while the second predicts the true ranking with higher qual-ity near the top of the ranking than the bottom. Ad-ditionally, we view the simple form of the algorithms as a significant asset which makes them much easier to extend. As a demonstration, we discuss extensions to online and distributed learning, and highlight impor-tant benefits over traditional alternatives.
 The paper is organized as follows: We first introduce some notation and quality measures in Section 2. In Section 3 we discuss related research and background. Section 4 presents two simple ranking algorithms and analyzes their performance in terms of the expected Kendall tau distance as well as high probability bounds on rank displacements. In Section 5 we evaluate and validate our theoretical findings. We touch on exten-sions to online and distributed ranking in Section 6, before concluding with final thoughts in Section 7. The complete proofs for all propositions, lemmas and the-orems are collected in the supplementary material. Throughout the paper we denote the true permutation we wish to recover by  X   X   X  S n . We use the notation  X  ( i ) to indicate the position of object i in permutation  X  . Without loss of generality, let  X   X  = (1 , 2 ,...,n ), so that  X   X  ( j ) = j . We will reveal to an algorithm a subset of binary comparisons, chosen among the n ( n  X  1) / 2 available pairs. Specifically, each comparison is mea-sured independently with probability m ( n ) /n , so that on average O ( nm ( n )) measurements are made. Each comparison can be measured only once (i.e. we mea-sure without replacement) 1 . The function m ( n ) is a key quantity; we will characterize various sample com-plexities in terms of bounds on its growth. For some results we will find that m ( n )  X   X (1) suffices, while in others we need m ( n )  X   X (log( n )). We will always assume that m ( n )  X  o ( n ). Noiseless binary compar-isons are denoted by c i,j = 1 (  X   X  ( i ) &lt;  X   X  ( j )). A com-mon observation model is to assume that each binary comparison is independently flipped with probability 1  X  p , where p &gt; 1 / 2 (Braverman &amp; Mossel, 2008; Feige et al., 1994). To capture the overall measurement pro-cess, we introduce binary variables s i,j which indicate whether c i,j was measured, and let  X  c i,j be the (possibly noisy) measurement that was made. We will assume throughout that s j,i = s i,j and if s j,i = s i,j = 1, then  X  c In this paper we analyze the quality of the proposed algorithms in two ways. The first counts the number of inverted binary comparisons of the predicted per-mutation  X   X  relative to  X   X  . That is, we use the loss This quantity is also known as the Kendall tau dis-tance . Using results in Fulman (2004), one can show that if  X   X  is chosen uniformly at random in S n , then inv( X   X  ) concentrates around (1 / 2)( n ( n  X  1) / 2). To be interesting we will thus require our algorithms to have expected risk E (inv( X   X  ))  X  (  X / 2)( n ( n  X  1) / 2) for some 0 &lt;  X  &lt; 1. We note that another common comparison metric is Spearman X  X  footrule As shown in Diaconis &amp; Graham (1977), inv( X   X  ) is re-lated to dis( X   X  ) as inv( X   X  )  X  dis( X   X  )  X  2inv( X   X  ). Our results on the expected Kendall tau distance thus di-rectly transfer to Spearman X  X  footrule. We also ana-lyze the prediction  X   X  by how far individual objects are displaced relative to  X   X  . When appropriate, we will bound the largest displacement However, in some cases the recovery is not uniform, warranting a detailed inspection of the set of displace-ments {|  X   X  ( j )  X   X   X  ( j ) | : j = 1 ,...,n } . Several threads of research aim to give various sam-ple complexities in the active ranking setting. Ailon et al. (2012), for example, give an active algorithm which produces a permutation with small loss rela-tive to the optimal loss (which may be zero). This result was refined by Ailon et al. (2011) to show that if the true scoring function is linear, one can find a scoring function with small loss (relative to the opti-mal loss) using O ( n log 4 ( n )) active queries. Braver-man and Mossel (2009) give an active algorithm with query complexity O ( n log( n )) for noisy binary com-parisons that produces a ranking in time that is with high probability polynomial. Agarwal (2005) has de-veloped a comprehensive theory for bipartite ranking. Here, instead of receiving binary comparisons, we re-ceive binary labels (e.g., relevant/irrelevant) for each object, and the goal is a scoring function which orders negative before positive examples.
 A number of recent papers have analyzed lower bounds for the demanding task of exact score recovery. Jamieson and Nowak (2011), for example, consider the case when the true scoring function reflects the Euclidean distance of object covariates from a global reference point. If objects are embedded in R d , then any algorithm that exactly identifies the true ranking must sample at least O ( d log( n )) comparisons. While this bound can be achieved by an active algorithm, any algorithm that uses only random measurements must see almost all pairwise comparisons in order to exactly predict the true ranking. Gleich and Lim (2011) sup-pose that the true score differences (i.e.,  X   X  ( j )  X   X  or functions thereof) can be measured. Given an in-complete matrix of such measurements they use low rank matrix completion to estimate the true object scores. If the measurements are in fact score differ-ences, their algorithm recovers the true scores with high probability exactly using between O ( n log 2 ( n )) and O ( n 2 log 2 ( n )) random measurements (depending on the shape of the true scores). Although their work considers random measurements, their theory does not apply when binary comparisons are measured in lieu of score differences. Mitliagkas et al. (2011) focus on exactly recovering the preferences expressed by a pop-ulation of r users. Each user X  X  preferences are recorded by a permutation over objects, which can be queried (either actively or by random sampling) through pair-wise comparisons between objects. The randomized sampling result is not helpful in our setting (where r = 1) since it then requires O ( n 2 log( n )) measure-ments (with replacement) for exact recovery.
 SVM Ranking. It is well-known that the SVM could be used to learn a linear scoring function in the setting of Section 2: For each observed comparison  X  c i,j create a feature vector x i,j = e j  X  e i (where e i is a bi-nary indicator vector with a 1 at the i -th coordinate) and associate with it the label  X  y i,j = 2  X  c i,j  X  1. Learning a scoring function now reduces to inferring a separat-ing hyperplane w so that the function sign( w &gt; x best predicts the labels  X  y i,j on training data. The predicted permutation  X   X  follows from sorting the el-ements in w . Statistical learning theory shows that in the noiseless case ( p = 1), the sample complexity for inferring a w which with high probability induces a Kendall tau distance of at most (  X / 2)( n ( n  X  1) / 2) is small. Indeed, using results of Radinsky et al. (2011) one can show the following proposition, which we prove in the supplementary material Proposition 3.1. There is a constant d , so that for any 0 &lt;  X  &lt; 1 , if we noiselessly measure dn/ X  2 nary comparisons, chosen uniformly at random with replacement, and n &gt; n 0 is large enough, the SVM will produce a prediction  X   X  , which satisfies The proposition highlights that the SVM needs to sample  X ( n/ X  2 ) examples with replacement for an ex-pected risk of at most (  X / 2)( n ( n  X  1) / 2). Some algebra then reveals that this amounts to an average of O ( n ) distinct samples. As the following proposition, a sum-mary of results of Giesen et al. (2009), demonstrates, the sample complexity of Proposition 3.1 is tight up to constants.
 Proposition 3.2. For  X  &lt; 1 , any randomized, comparison-based algorithm that produces for all  X   X  a prediction  X   X  with an expected risk of must on expectation use at least  X ( n ) comparisons in the worst case.
 The proposition is proved in the supplementary mate-rial for completeness. Although the SVM is effectively optimal in this setting, we feel that its direct applica-tion is overly heavy handed. The goal of this paper is to exhibit two much simpler algorithms which also achieve the above sample complexity, while being eas-ier to extend to novel applications. In this section we present two simple rank estimators using the randomized data collection framework out-lined in Section 2. 4.1. Balanced Rank Estimation We begin this paper by analyzing BRE, which esti-mates an object X  X  score as the relative difference of the number of items preceding and succeeding it. Balanced Rank Estimation (BRE):
Measure each binary comparison independently with probability m ( n ) /n . Define the scores
Predict  X   X  by the ordering  X   X  of the estimated scores, breaking ties randomly.
 Our first result concerns the expected number of in-versions of  X   X  relative to  X   X  .
 Theorem 4.1. For any 0 &lt;  X  &lt; 1 there is a con-stant c ( p, X  )  X   X (1 / ((2 p  X  1) 2  X  2 )) so that if m ( n ) /n  X  c ( p, X  ) /n , and n &gt; n 0 is large enough, BRE satisfies To give some intuition for this theorem, we briefly sketch the proof. Since we assumed  X   X  = (1 ,...,n ), the expected Kendall tau distance is The score difference  X   X ( i )  X   X   X ( j ) can be written as a sum of 2 n  X  3 independent random variables. By con-trolling their mean, variance and magnitude, if n &gt; n 0 is large the following bound can be derived for i &lt; j : Applying this to Eq. (7), we bound E (inv( X   X  )) by  X   X  Matching this upper bound with the target quantity In the noiseless case ( p = 1), Theorem 4.1 guaran-tees that for any 0 &lt;  X  &lt; 1, BRE in expectation has the same sample complexity as the SVM in Proposi-tion 3.1. In particular, BRE also achieves the  X ( n ) lower bound of Proposition 3.2. This may seem at first surprising. However, a similar algorithm was re-cently shown to have favorable properties in a different context (Coppersmith et al., 2010).
 More informative statements can be made if a slightly larger number measurements is available. As the fol-lowing theorem shows, given an average of  X ( n log( n )) measurements, BRE predicts permutations with uni-form quality across the entire permutation.
 Theorem 4.2. For any c &gt; 0 and 0 &lt;  X  &lt; 1 , if each comparison is measured with probability m ( n ) /n = c log( n ) /n , then BRE predicts with probability at least where a n is a sequence with a n  X  1 .
 The crux of the argument is that the estimated scores  X   X ( j ) concentrate around their expectation  X   X   X  ( j ) , E (  X 
 X ( j )) = aj/n + b , where a = (2 p  X  1) and b  X  R (as before we assume  X   X  = (1 ,...,n )). If all scores concentrate uniformly well, they will reveal the true permutation up to local displacements. Using a similar analysis as in Theorem 4.1, our proof first establishes the following Bernstein concentration: to which we then apply a union bound (introducing the log( n ) factor) Thus, the relative ordering of two objects that are far apart in the  X   X  (large t ) should be harder to confuse than that of nearby objects (small t ). Indeed, using the following intuitive lemma, the uniform concentration of scores translates into a uniform bound on displace-ments |  X   X  ( j )  X   X   X  ( j ) | .
 Lemma 4.3. For any a &gt; 0 , and b  X  R , if  X  j , we have |  X   X ( j )  X  ( aj/n + b ) |  X  t , then we have that  X  j , |  X   X  ( j )  X   X   X  ( j ) | X  2 tn/a .
 The lemma applies to the union bound with a = (2 p  X  1). The proof is then completed by setting t = (2 p  X  1)  X / 2 and simplifying Eq. (17).
 The following corollary immediately follows from The-orem 4.2 and highlights for what constants c the prob-ability in Theorem 4.2 converges.
 Corollary 4.4. For 0 &lt;  X  &lt; 1 , there is a constant c = so that for BRE P (max j |  X   X  ( j )  X   X   X  ( j ) | X   X n )  X  1 . 4.2. Unbalanced Rank Estimation In many situations, we are not interested in learning the entire permutation accurately but only care about the highest (or lowest) ranked objects. The well-known discounted cumulative gain (J  X arvelin &amp; Kek  X al  X ainen, 2002), for example, captures this notion and has been important in the information retrieval literature. More recently, Rudin (2009) proposed p -norms for ranking losses that penalize errors near the top more severely than in the tail of the list. The approach has been taken to the  X  -norm limit by Agarwal (2011). When n grows, the number of top elements we are interested in will typically also grow; in many natural phenom-ena, for example, we expect more extreme examples to appear as we make more observations. Suppose then, that for some 0 &lt;  X  &lt; 1 we wish to recover the placement of the first  X n elements in the permutation with fairly good accuracy, but care less about the re-maining (1  X   X  ) n elements. Surprisingly, a very slight modification of the Balanced Rank Estimation Algo-rithm yields a method that is useful in this situation. Furthermore, it still only requires a random subset of pairwise comparisons. The new algorithm, URE, es-timates an object X  X  score by the fraction of measured items preceding it.
 Unbalanced Rank Estimation (URE):
Measure each binary comparison independently with probability m ( n ) /n . Define the scores
Predict  X   X  by the ordering  X   X  of the estimated scores, breaking ties randomly.
 To begin, we first establish that this algorithm in ex-pectation still achieves the  X ( n ) lower bound given in Proposition 3.2.
 Theorem 4.5. For any 0 &lt;  X  &lt; 1 , there is a con-stant c ( p, X  )  X   X (1 / ((2 p  X  1) 2  X  2 )) so that if m ( n ) /n  X  c ( p, X  ) /n , URE satisfies Similar to Theorem 4.1, the proof relies on a tail in-equality for the difference  X   X ( i )  X   X   X ( j ). Supposing that  X   X  = (1 ,...,n ), we show in the proof that for i &lt; j As in Theorem 4.1 we can use this to bound the Kendall tau distance as
E (inv( X   X  ))  X  Finally, equating this upper bound with (  X / 2)( n ( n  X  1) / 2) allows us to solve for m ( n )  X   X (1 / ((2 p  X  1) 2  X  2 )). Theorem 4.5 guarantees in the noiseless case ( p = 1) that for any 0 &lt;  X  &lt; 1, URE in expectation achieves the same  X ( n/ X  2 ) sample complexity as the SVM in Proposition 3.1.
 Our main interest in URE, however, is encapsulated in the following theorem which shows that predicted per-mutations are much more accurate near the top than the bottom if an average of  X ( n log( n )) measurements Theorem 4.6. For any c &gt; 0 , and 0 &lt;  X  &lt; 1 , if each comparison is measured with probability m ( n ) /n = c log( n ) /n , URE predicts with probability at least a permutation  X   X  with |  X   X  ( j )  X   X   X  ( j ) | X  The proof parallels that of Theorem 4.2 and shows that  X   X ( j ) concentrates around its expectation  X   X   X  ( j ) , E (  X 
 X ( j )) = aj/n + b , with a = (2 p  X  1) and b  X  R (again, we assume  X   X  = (1 ,...,n )). However, while in Theorem 4.2 the tail bound was identical for each j , here the scores  X   X ( j ) have variances that depend on j . To build intuition, in the noiseless case ( p = 1), since the first element j = 1 in  X   X  has no items preceding it (i.e.,  X  i 6 = j  X  c i,j = c i,j = 1 ( i &lt; j ) = 0), the estimated score  X   X ( j ) will always be zero and have zero variance, regardless of how many elements we measure. For remaining elements, the mean of the estimated scores will progressively increase down the permutation, as will their variance. The increase in variance brings a decrease in their predictive accuracy, which is reflected in the theory. Specifically, one can show that Before applying a union bound to the above bounds, it is convenient to first eliminate the j -dependence of the upper bounds. To do this, we define the following set of increasing deviation events Some algebra then gives, for all j ,
P ( A j )  X  2 exp which yields the following union bound: As in Theorem 4.2, we turn this concentration result into a bound on the rank displacement using a lemma. Lemma 4.7. For a &gt; 0 , 0 &lt;  X  &lt; a 2 and b  X  R , if  X 
 X ( j )  X  then |  X   X  ( j )  X   X   X  ( j ) | X  4  X n/a 2 if j &lt;  X n/a 2 The proof of the lemma shows that even if a sorting algorithm breaks ties in the least favorable way, the final rank positions cannot differ too much from the true positions in  X   X  . The main difficulty for this argu-ment lies in a suitable definition of the sets A j , which translates into the preconditions used for this lemma. As before, the lemma applies with a = (2 p  X  1). The result follows if for any 0 &lt;  X  &lt; 1 we set t = a the definition of sets A j ,  X  =  X a 2 in Lemma 4.7, sim-plify Eq. (28) and then substitute  X   X  ( j ) for j where appropriate.
 The following corollary, highlighting suitable constants c , follows immediately from Theorem 4.6.
 Corollary 4.8. For any 0 &lt;  X  &lt; 1 , there is a con-stant c = c ( p, X  ) with 2 p/ ((2 p  X  1) 2  X  ) + 2(1  X  p ) / ((2 p  X  1) 2  X  2 )  X  c ( p, X  )  X  3 p/ ((2 p  X  1) 2  X  ) + 2(1  X  p ) / ((2 p  X  1) 2  X  2 ) , so that as n  X   X  the displacement bounds of Theorem 4.6 hold with probability 1.
 Discussion. In both Theorems 4.2 and 4.6 the size of the bins into which we correctly place objects can be decreased by increasing the number of measurements. If we consider the noiseless case ( p = 1), Corollary 4.8 predicts that to place elements j with  X   X  ( j ) &lt;  X n/ 2 into bins half the current size, URE needs on average twice as many comparisons. To correctly place objects j with  X   X  ( j )  X   X n into bins of half the size URE needs on average four times as many measurements. From Corollary 4.4, we see that the behavior of the BRE is rather different. There, a four-fold increase is required to halve the bin sizes uniformly across the permuta-tion. The cost of URE X  X  improved performance near the top, however, is that for the same amount of data, the bin sizes in the tail are typically larger than those of BRE. Thus, if only the top elements are of interest, URE should be preferred. If a more uniform recovery is desired, BRE should be chosen. We will highlight this tradeoff in Section 5 with an example. An advantage in this regard is that the algorithm can be chosen after the data has been collected since BRE and URE work with the same type of input data. This fact could be exploited by combining the score estimators in various ways to further improve over the individual prediction results. To begin, we empirically validate Theorems 4.2 and 4.6 in the noiseless case ( p = 1). The theorems show that if each comparison is measured with probability c log( n ) /n , for some constant c , then the deviations |  X   X  ( j )  X   X   X  ( j ) | can be controlled with some probability that depends on c . In Figures 1(a) and 1(b) we show for particular choices of  X  in solid the empirical proba-bilities that the displacement bounds of the theorems hold, as a function of the constant c . Additionally, we show the theoretical lower bounds on these probabili-ties, as given in Theorems 4.2 and 4.6. Notice that  X  is four times smaller in Figure 1(b) than in Figure 1(a) so that Theorems 4.2 and 4.6 predict the same upper bounds on |  X   X  ( j )  X   X   X  ( j ) | for j s.t.  X   X  ( j )  X   X n . Em-pirically, we see that in this case BRE requires more measurements than URE. To highlight the difference in prediction quality, we evaluated both algorithms on an 8000-object permutation. For each of 500 simula-tion runs, both algorithms saw exactly the same set of comparisons. In Figure 1(c) we show the median displacement |  X   X  ( j )  X   X   X  ( j ) | across the 500 runs, as a function of  X   X  ( j ). Additionally, the error bars show 1 / 2 times the standard deviation of the displacements. For  X   X  ( j ) &lt; 2000 URE predicts the correct position with higher accuracy and smaller variance than BRE. However, for large  X   X  ( j )  X  2000 BRE outperforms. An important benefit of BRE/URE over active meth-ods is that data collection can be trivially parallelized: Comparisons can be collected from independent pro-cesses, each measuring within a pre-assigned block of object pairs. Furthermore, the structure of the score estimators makes it easy to extend BRE/URE to sev-eral interesting settings. For one, we see applications in online ranking where we wish to grow rankings over n to n + 1 objects as data streams in. Online ver-sions of BRE/URE are easy to derive, yet lead to similar guarantees as those in Section 4. In contrast, the solutions of optimization-based methods can be non-trivial to update when the problem is slightly per-turbed. Cauwenberghs and Poggio (2000), for exam-ple, show that the exact update to an SVM solution requires careful bookkeeping of dual coefficients. The simple structure of BRE/URE also makes them use-ful in distributed settings where costly coordination and communication among multiple processors can be avoided. We will now explore this extension. 6.1. Distributed Ranking In many situations, the number n of objects being compared is large. For instance, online retailers can easily offer millions of products for sale among which comparisons could be made. In such situations the objects (data points) are often stored on a fixed num-ber K of machines, so that each machine stores about f = n/K data points. A consequence of this dis-tributed storage is that the O ( nm ( n )) comparisons are likely to be collected on distinct machines. A na  X  X ve centralized ranking algorithm would collect the indi-vidual comparisons at a server for learning, incurring a communication cost of O ( nm ( n )). This cost is pro-hibitive if, relative to n , m ( n ) is large 3 . Distributed, iterative SVM-type algorithms have been developed for such situations (Hazan et al., 2008; Graf et al., 2004) however, their application is typically compli-cated by the need for running multiple iterations which must be coordinated by locking protocols. As a result, the efficiency of these methods can rapidly deterio-rate if a single machine fails. A favorable property of BRE/URE is that their simple form lends them much more naturally to distributed extensions, which can avoid locking protocols altogether. The main idea is that the BRE/URE object scores can also be com-puted from partial scores rather than from individ-ual comparisons. If the number of binary comparisons O ( nm ( n )) is large, then communicating partial scores can be much more efficient. We analyze this setting. To compute comparisons, any algorithm must start by exchanging object encodings between the K ma-chines. Let the data points allocated to machine k be D k . There are K ( K  X  1) / 2 machine pairs ( k &lt; l ) that need to exchange f = n/K data points from one computer to the other. Overall, this leads to n ( K  X  1) / 2  X  O ( nK ) = O ( n 2 /f ) data points being ex-changed. Once the O ( nm ( n )) comparisons have been computed (in distributed fashion), we aggregate them into partial scores. Specifically, denote the set of bi-nary comparisons created by a machine pair k  X  l by Because  X  c j,i = 1  X   X  c i,j if s j,i = s i,j = 1, the set can easily be computed from  X  C k,l . In the following we will assume that  X  C l,k has been implicitly computed in this way whenever necessary. For BRE, use  X  C k,l compute for each pair k,l the following partial scores This amounts to a total of K 2 f = n 2 /f partial scores. The partial scores for URE follow a similar strategy. To complete the algorithm, the partial scores must be communicated to a central machine at cost O ( n 2 /f ). If l ( j ) is the machine index l  X  { 1 ,...,K } so that j  X  D l , we combine the partial scores as The overall communication time is O ( n 2 /f ). In com-parison, a na  X  X ve centralized algorithm requires com-munication time O ( nm ( n )). If m ( n )  X  O (1 / ((2 p  X  1) 2  X  2 )) K then our proposed algorithm significantly reduces the communication time. For practical appli-cations, the number of machines K is typically less than 100. In this case the our algorithm should be a viable alternative to centralized optimization schemes with  X  as large as  X  = 0 . 1. This paper analyzed two simple algorithms for rank-ing n objects from a random sample of binary compar-isons. We showed that the algorithms in expectation achieve a lower bound on the sample complexity for predicting a ranking with fixed expected Kendall tau distance. As such, they are competitive alternatives to the SVM, which also achieves the lower bound. By giving the algorithm slightly more measurements, we showed that interesting displacement bounds between  X   X  and  X   X  can be derived.
 Because the algorithms rely only on a random subset of pairwise comparisons, data collection can be trivially parallelized. The simple structure of the scoring func-tions makes them easy to adapt to new situations, such as online or distributed ranking. We showed that in the latter case the communication cost of a traditional centralized optimization approach can be substantially reduced if (2 p  X  1) 2  X  2 is sufficiently small. This paper has exclusively considered scoring functions  X ( j ) that only depend on the object identity. However, BRE and URE can act as a useful performance base-line even for learning parametric scoring functions, as frequently considered: If the in-sample empirical per-formance of such parametric ranking functions is worse than that predicted by Theorems 4.1 and 4.5, the func-tion class may need to be redesigned or more data collected. Moreover, the two algorithms can be used as quick, general-purpose preprocessing algorithms for conventional ranking methods: A small subset of pair-wise comparisons can be approximately completed us-ing BRE or URE, irrespective of the true (possibly parametric) ranking function that generated them. This larger set of comparisons could then be useful in learning an improved parametric ranking function. Agarwal, S. A Study of the Bipartite Ranking Prob-lem in Machine Learning . PhD thesis, University of Illinois at Urbana-Champaign, 2005.
 Agarwal, S. The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list. In Proceedings of the SIAM International Conference on Data Min-ing , 2011.
 Ailon, N. An active learning algorithm for ranking from pairwise preferences with an almost optimal query complexity. Journal of Machine Learning Re-search , 13:137 X 164, 2012.
 Ailon, N., Begleiter, R., and Ezra, E. A new ac-tive learning scheme with applications to learning to rank from pairwise preferences. arXiv CoRR , abs/1110.2136, 2011.
 Ammar, A. and Shah, D. Ranking: Compare, don X  X  score. In Proceedings of the 49th Annual Allerton
Conference on Communication, Control and Com-puting (Allerton) , pp. 776 X 783. 2011.
 Braverman, M. and Mossel, E. Noisy sorting without resampling. In Symposium on Discrete Algorithms , pp. 268 X 276, 2008.
 Braverman, M. and Mossel, E. Sorting from noisy information. arXiv CoRR , abs/0910.1191, 2009.
 Cauwenberghs, G. and Poggio, T. Incremental and decremental support vector machine learning. In Leen, T.K., Dietterich, T.G., and Tresp, V. (eds.),
Advances in Neural Information Processing Systems 13 (NIPS) , pp. 409 X 415. MIT Press, 2000.
 Coppersmith, D., Fleischer, L., and Rudra, A. Order-ing by weighted number of wins gives a good rank-ing for weighted tournaments. ACM Transactions on Algorithms , 6(3):55:1 X 55:13, 2010.
 Dekel, O., Manning, C., and Singer, Y. Log-linear models for label ranking. In Thrun, S., Saul, L., and Sch  X olkopf, B. (eds.), Advances in Neural Infor-mation Processing Systems 16 (NIPS) . MIT Press, 2004.
 Diaconis, P. and Graham, R. L. Spearman X  X  footrule as a measure of disarray. Journal of the Royal Statis-tical Society. Series B (Methodological) , 39(2):262 X  268, 1977.
 Feige, U., Raghavan, P., Peleg, D., and Upfal, E. Com-puting with noisy information. SIAM Journal on Computing , 23(5):1001 X 1018, 1994.
 Freund, Y., Iyer, R., Schapire, R. E., and Singer, Y.
An efficient boosting algorithm for combining pref-erences. Journal of Machine Learning Research , 4: 933 X 969, 2003.
 Fulman, J. Stein X  X  method, Jack measure, and the Metropolis algorithm. Journal of Combinatorial Theory. Series A , 108(2):275 X 296, 2004.
 Giesen, J., Schuberth, E., and Stojakovi  X c, M. Approx-imate sorting. Fundamenta Informaticae , 90(1-2): 67 X 72, 2009.
 Gleich, D. F. and Lim, L. Rank aggregation via nu-clear norm minimization. In Proceedings of the 17th
ACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining , pp. 60 X 68, 2011. Graf, H. P., Cosatto, E., Bottou, L., Durdanovic, I., and Vapnik, V. Parallel support vector machines: The cascade SVM. In Saul, L.K., Weiss, Y., and Bottou, L. (eds.), Advances in Neural Information Processing Systems 17 (NIPS) . MIT Press, 2004. Hazan, T., Man, A., and Shashua, A. A parallel de-composition solver for SVM: Distributed dual as-cend using Fenchel duality. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR) , pp. 1 X 8, 2008.
 Herbrich, R., Graepel, T., and Obermayer, K. Large margin rank boundaries for ordinal regression. In Advances in Large Margin Classifiers , pp. 115 X 132. MIT Press, 2000.
 Jamieson, K. G. and Nowak, R. Active ranking using pairwise comparisons. In Shawe-Taylor, J., Zemel, R.S., Bartlett, P., Pereira, F.C.N., and Weinberger,
K.Q. (eds.), Advances in Neural Information Pro-cessing Systems 24 (NIPS) , pp. 2240 X 2248. MIT Press, 2011.
 J  X arvelin, K. and Kek  X al  X ainen, J. Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems , 20(4):422 X 446, 2002.
 Joachims, T. Training linear SVMs in linear time.
In Proceedings of the 12th ACM SIGKDD Interna-tional Conference on Knowledge Discovery and Data Mining , pp. 217 X 226, 2006.
 Mitliagkas, I., Gopalan, A., Caramanis, C., and Vish-wanath, S. User rankings from comparisons: Learn-ing permutations in high dimensions. In Proceedings of the 49th Annual Allerton Conference on Commu-nication, Control and Computing (Allerton) , 2011. Negahban, S., Oh, S., and Shah, D. Iterative rank-ing from pair-wise comparisons. In Bartlett, P., Pereira, F., Burges, C., Bottou, L., and Weinberger,
K. Q. (eds.), Advances in Neural Information Pro-cessing Systems 25 (NIPS) , pp. 2483 X 2491. MIT Press, 2012.
 Radinsky, K. and Ailon, N. Ranking from pairs and triplets: Information quality, evaluation methods and query complexity. In King, I., Nejdl, W., and
Li, H. (eds.), Fourth ACM International Conference on Web Search and Data Mining (WSDM) , pp. 105 X  114. ACM, 2011.
 Rudin, C. The p -norm push: A simple convex rank-ing algorithm that concentrates at the top of the list. Journal of Machine Learning Research , 10:
