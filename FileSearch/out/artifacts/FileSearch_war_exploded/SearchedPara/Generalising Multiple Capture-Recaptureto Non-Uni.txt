 Algorithms in distributed information retrieval often rely on accurate knowledge of the size of a collection. The  X  X ultiple capture-recapture X  method of Shokouhi et al. is one of the more reliable algorithms for determining collection size, but it relies on samples with a uniform number of documents. Such uniform samples are often hard to obtain in a working system.

A simple generalisation of multiple capture-recapture does not rely on uniform sample sizes. Simulations show it is as accurate as the original method even when sample sizes vary considerably, making it a useful technique in real tools. H.3.4 [ Information Storage and Retrieval ]: Systems and Software X  distributed systems Experimentation, Measurement Size estimation
Tools in distributed information retrieval (DIR) use knowl-edge of a collection X  X  size as a proxy for coverage and com-pleteness, and as important input to algorithms for server selection and language modelling.

Although in some instances servers may report the num-ber of documents they index, many servers do not report a size, and when they do it may be inaccurate or deliber-ately misleading. DIR tools therefore must generate their own estimates, based on samples of documents acquired with techniques such as query-based [2] or multiple-query [5] sampling.
The  X  X ultiple capture-recapture X  method (MCR) of Shok-ouhi et al. [4] builds on Liu et al. X  X   X  X apture-recapture X  [3]. The central idea for both algorithms is to estimate, given a number of samples from a collection, the expected number of Figure 1: Relative errors in estimation from mul-tiple capture-recapture (MCR), with 100 samples of 100 documents, and generalised MCR (GMCR), with 100 samples of varying size. Figure 2: Relative errors in estimation from MCR and GMCR as T , the number of 100-document sam-ples, increases. Bars are  X  one standard error. sample sizes (normally distributed with  X  n = 100 and  X  = 20). A two-sided t test showed no significant difference in mean relative error; we can conclude that GMCR is as accurate as (although no more accurate than) MCR in this situation. As MCR is one of the best current algorithms, this suggests GMCR is also competitive.

Experiments also examined how the algorithms fared as T , the number of samples, increased. Again, MCR was given 100 documents per sample and GMCR was given a varying number (  X  n = 100,  X  = 20); T was varied from 50 to 100 with 100 runs at each step. As illustrated in Figure 2, GMCR matched MCR very closely.
 Finally, a third set of experiments considered how sensitive GMCR is to variation in sample size. Figure 3 plots rela-tive error, again with 100 samples of a 1,000,000 document collection, as sample sizes become more variable (  X  n = 100,  X  = 1 X 40). There is no significant correlation between vari-ability in sample size and relative error, and it appears that GMCR remains equivalent to MCR even if variance in n is high.
