 User data is becoming increasingly available in multiple domains ranging from phone usage traces to data on the social Web. The analysis of user data is appealing to scientists who work on popula-tion studies, recommendations, and large-scale data analytics. We argue for the need for an interactive analysis to understand the mul-tiple facets of user data and address different analytics scenarios. Since user data is often sparse and noisy, we propose to produce labeled groups that describe users with common properties and de-velop IUGA, an interactive framework based on group discovery primitives to explore the user space. At each step of IUGA, an ana-lyst visualizes group members and may take an action on the group (add/remove members) and choose an operation (exploit/explore) to discover more groups and hence more users. Each discovery operation results in k most relevant and diverse groups. We formu-late group exploitation and exploration as optimization problems and devise greedy algorithms to enable efficient group discovery. Finally, we design a principled validation methodology and run extensive experiments that validate the effectiveness of IUGA on large datasets for different user space analysis scenarios. Categories and Subject Descriptors: H.2.8 [ Database manage-ment ]: Database Application; Data Mining.
 General Terms: Algorithms.
 Keywords: User Data; Interactive Analysis; Validation.
One of the major applications of data-driven research is the anal-ysis of user data . User data is the conjunction of a profile made of several attributes (e.g., age, occupation, location), and of user in-terests via activity data (e.g., application usage on smartphones, re-searchers X  publications, movie ratings, exercise and eating habits). Building labeled user groups instead of focusing on individual data enables new findings and addresses issues raised by the peculiar-ities of user data such as noise and sparsity. 1 The discovery of user groups bears similarities to the redescription mining prob-c  X  2015 ACM. ISBN 978-1-4503-3794-6/15/10 ...$15.00 lem [21]: one wants to find groups of users that have identical values for some profile attributes (e.g. gender = female  X  coun-try = US ) and that exhibit common activity data (e.g. keywords = { databases, social networks } and publish_in = { WWW, VLDB }). The large number of possible groups hinders user data analysis. In this paper, we advocate an exploratory navigation of the space of groups and develop IUGA, an interactive user data analysis framework that provides analysts with the ability to incre-mentally discover user groups efficiently.

There exist numerous approaches that could be used for the dis-covery of user groups, many of which are based on pattern mining such as frequent itemset discovery [2] or subspace clustering [1]. The main limitation of those approaches is that, on real data, they can output millions of labeled groups inside which it is hard to know a priori which ones are of interest to the analyst. To alleviate that, a large body of work has been dedicated to providing knowl-edgeable analysts with the ability to specify constraints on groups of interest [6, 7]. However, that is not adapted to exploratory sce-narios where only limited knowledge is available on the dataset and the analyst does not necessarily know which subset of the data is of interest. The same argument applies to expressing queries on raw data, e.g. using SQL [10]. SQL being declarative in nature, it is difficult to use it to express an exploration scenario which is iterative in nature: e.g., finding a set of groups with a SQL query then asking to find  X  X elated X  groups. Other work proposed to re-duce the output of a pattern mining algorithm to a representative pattern set of limited size (typically tens of labeled groups) [23]. However, resulting groups may be too coarse and miss groups that contain users of interest. Group granularity may be reduced with parameter relaxation but the number of resulting groups is bound to increase and quickly become hard to manage by the analyst.
When faced with the daunting task of analyzing large amounts of user data, an analyst may have different goals in mind. In this paper, we focus on helping analysts find one or several users of interest by exploring relevant groups until she reaches her target users. More specifically, an analyst may want to discover and gather several users who may be scattered in different groups of interest. An ana-lyst may also be interested in finding a specific group member , i.e., a user, for whom she remembers some but not all information. We illustrate these variants in the following two realistic examples. Chair looking to build a program committee formed by geograph-ically distributed male and female researchers with different se-niority levels and different expertise. Figure 1 shows a simplified scenario for the W EB DB 2014 2 PC.

As is often the case, PC chairs think of a set of potential mem-bers first. In this case, G. Fletcher, M. Theobald, S. Michel and X.
DB 2014 Program Committee) Xiao are 4 initial members. Martin decides to use S. Michel and X. Xiao as seeds because they are junior and prolific (high frequency of annual publications). The action of keeping those 2 researchers is followed by an exploration which delivers 3 groups each of which containing one of S. Michel or X. Xiao (Step1). He then decides to keep the highlighted one: prolific , high publications and publishing at SIGMOD (with which W EB DB is associated.) The selected group contains 29 researchers out of which 4 geo-graphically distributed (L. Popa, A. Doan, M. Benedikt, S. Amer-Yahia). In order to find more users related to that group, Mar-tin decides to perform an action that removes the predicate high publi , because it has been investigated before.
 Step 2 is explores the resulting group and outputs 3 diverse groups. Martin ignores the first group because he has already seen enough male candidates. He notices that the highlighted group contains 119 highly senior researchers who published in PVLDB (which is related to W EB DB ). Therefore, he decides to get more information about that group by first adding the predicate data integration to specialize it and asking to split it into 3 groups. Step 3 shows the result of this exploitation operation. In particular, the group la-beled with query processing , PVLDB and ICDE contains 26 senior researchers out of which 8 are of interest to the PC chairs (J. Wang, F. Bonchi, K. Chakrabarti, P. Fratenali, D. Barbosa, F. Naumann, Y. Velegrakis and X. Zhou). At this stage, Martin covered 80% of the W EB DB PC. 2 person she met at last night X  X  party in Cole Valley, San Francisco, but she doesn X  X  remember his name and has lost his phone number. She only knows that he lived in the same neighborhood as Mike, the party host, and works as an engineer. Nicole asks Mike to have ac-cess to his social network which contains some of his friends X  infor-mation: job title(s), company, location, birth year, and hobby(ies).
Mike is an avid Facebook user and has over 800 friends, most of which are computer engineers and live in San Francisco (SF). Thus no querying mechanism could lead Nicole directly to the per-son she is looking for. Also, advanced search tools (e.g., Facebook Graph Search 3 ) can only show similar people based on an input query. Nicole needs a tool for her navigational analysis of Mike X  X  friends. She first uses the query loc:SF and title:engineer which returns 3 different user groups among Mike X  X  friends that are highly related to her query (Step 1 in Figure 2). Nicole remem-bers that the person was talking about  X  X ebsite design X , thus he shouldn X  X  be working for 3Degrees which is a renewable energy certificate provider. She also remembers that he mentioned he only likes  X  X hooting X  computer games thus he should not belong to the group labeled with Sims , a life simulation computer game. So she prefers to select the group labeled loc:SF , title: engineer , title:market manager and hobby: soccer as a seed. As Nicole doesn X  X  remember any discussion about sports, she prefers to remove the attribute hobby:soccer to widen her navigation scope. The tool then finds 3 other groups in Step 2.

Nicole is sure the person she met is at least 30 years old. This eliminates the first group with birth:1987 . Also, she herself works for TerraPass and knows the person does not work there. Also being a fan of shooting games, the group with hobby:laser tag and company:Google would be the best choice. Now, the tool returns 3 other user groups in step 3. The title  X  X enior Soft-ware Engineer X  captures her attention as she remembers he said he was a manager. This group contains 3 users among whom Kevin Systrom, co-founder of Instagram and Mike X  X  friend, is the one she was searching for. 2
Acknowledging the limitations of previous solutions, a recent line of work based on interactive data mining is being developed. Such work is based on providing operations on the result of pattern mining in order to help the analyst navigate in the space of labeled groups and find groups and group members she is most interested in [5]. Existing work in this area is mainly a description of sys-tems that have been designed to show the potential of interactive approaches. In this paper, we propose two important contributions to further advance the state of the art of interactive data mining with a focus on interactive user data analysis: 1. IUGA, a formalization of interactive user data analysis based 2. A principled validation methodology. To the best of our
IUGA is an optimization-based interactive framework where an-alysts are free to select any group of interest at each step and use it as a seed for further optimization. It is based on 3 key principles: P1: The analyst must be able to explore different groups and not be overwhelmed with analysis options. The analysis process is broken into successive steps during which an analyst chooses a seed group, examines the users it contains, takes actions such as remove/add users, and continues with a group discovery operation. P2: Groups offered to the analyst must be of high quality. The analysis process must help the analyst cover the space of groups of interest. We propose a  X  X olistic X  measure that finds k groups that are relevant to the seed group and are as diverse as possible. P3: The train of thought of the analyst must not be lost. Each interactive group discovery step must be fast.

Our examples show that with simple group discovery operations, an analyst can navigate a good proportion of the space of users of interest. In this work, we formalize two such operations: opEx-plore() that finds groups outside of the seed group , and opExploit() that finds groups inside. The examples also show that before ap-plying group discovery operations to a seed group, an analyst may want to transform that group using actions that remove or add spe-cific users (in our example by modifying group labels).

Devising an efficient multi-step group discovery approach is a challenge due to the large number of available groups. We hence propose to formulate group exploration and exploitation as opti-mization problems that find relevant and diverse groups at each step of the interaction. Both operations discover k diverse groups that have some relevance to the seed group, i.e., users in common. In the case of exploration, diversity aims to cover as many different users as possible outside of the seed group. For exploitation, diver-sity aims to cover the seed group while providing distinct options inside that group. We show that both problems are NP-complete by reductions from the M AXIMUM E DGE S UBGRAPH P ROBLEM and the M AXIMUM C OVERAGE P ROBLEM respectively. We design G ROUP D ISCOVERY , a greedy algorithm to solve those problems.
Our last challenge is to devise a principled methodology that val-idates the need for an interactive multi-step group discovery ap-proach. In particular, since our focus is to solve the multi-target and single-target search questions, we validated IUGA on two real use cases, namely, Program Committee (PC) formation by build-ing a dataset from DBLP, and a single target scenario by building a synthetic dataset. Our results show that IUGA leads analysts to their target(s) in a small number of steps regardless of their starting points and their level of expertise.

The outline of the paper is as follows: in Section 2 we give neces-sary definitions and formalize the G ROUP D ISCOVERY operations as well as the Interactive User Group Analysis problem. In Section 3 we describe the IUGA algorithm. Section 4 presents detailed experiments. The related work is provided in Section 5. Last, we conclude and give some perspectives for future work in Section 6.
We model user data as a set of users U , a set of items I , and a database D of tuples  X  u,i  X  where u  X  U and i  X  I . A tuple  X  u,i  X  represents the action of u (such as authored , recorded , rated , purchased , tagged , voted , etc.) on i .

Each user u is also described with attributes drawn from a set of attributes A representing demographics information such as gender and age . We refer to each attribute in A as a i and to its values as v . The domain of values of attribute a i is D a i with D A For example, if we use a 1 to refer to gender , it takes two values v and v 1 2 representing male and female respectively.
 A large number of datasets could be modeled in this manner. In the case of scientists, items are conferences they publish in and keywords they contribute on. For online collaborative rating sites, items are movies or restaurants they rate. The choice of what con-stitutes a user attribute or a user action depends on the application and does not affect our problem and solution.

Due to the sparsity of user data, we propose to analyze it based on forming user groups and providing a framework to the analyst to discover groups in a step-by-step fashion. We first define the notion of user group followed by the G ROUP D ISCOVERY Problem and finally, IUGA, our interactive user data analysis framework.
D EFINITION 1. User Group . A user group g , is a subset of U to which is associated a label l g = [ P g ,I g ] where P tion of predicates on user attribute ( a 1 = v 1 j )  X  ...  X  ( a and I g  X  I a set of items. Each user in g must satisfy P an action on each item in I g . More formally,  X  u  X  g,P and  X  u  X  g,  X  i  X  I g ,  X  u,i  X  X  X  D .

In the case of a movie rating site, the group of reviewers defined by the label [( age = 25 )  X  ( occupation = student ), { Terminator 2 , The Matrix }] is the set of 25-year old students who rated both movies. Similarly, [( seniority = junior )  X  ( gender = female )  X  ( pub rate = productive ), { Algorithms , Data Mining }] is the set of junior young female researchers who are productive and have expertise in algorithms and data mining.

To simplify readability, we will use a simplified representation for labels in the remainder of the paper. For example, [( age = 25 )  X  ( occupation = student ), { Terminator 2 , The Matrix }] becomes [ 25 , student , Terminator 2 , The Matrix ].

We use G to refer to the set of all user groups formed by predi-cates on A and items in I . G is very large even with a small number of attribute values and items.
We now introduce our formalization of group discovery oper-ations and actions that form building blocks of IUGA. We first define the exploration operation that allows to  X  X avigate the group space in an outward way X  starting from a set of users, it discovers groups containing new users.

D EFINITION 2. Group Exploration . We define a function gExplore ( U , G , X  ) that takes a set of users U  X  U and finds all groups in G that overlap with U with at least  X  , a given threshold. More formally, gExplore ( U , G , X  ) = { ( g, overlap ( U , g )) | g  X  X  X  g 6 = U  X  overlap ( U , g )  X   X  } where overlap ( U , g ) = Jaccard similarity coefficient).

The overlap condition provides a progressive exploration of the space, which helps the analyst build an understanding of the un-derlying data. Figure 1 illustrates several steps in IUGA used to build the W EB DB 2014 PC. At the beginning, the analyst (here a PC chair) has two  X  X eed members X  in mind: S. Michel and X. Xiao. She then performs an exploration step over these two re-searchers, which produces (among other) three groups: a group of 46 researchers labeled as [ junior , high publi ], a group of 13 researchers labeled as [ prolific , high publi , ACM ], and a group of 29 researchers labeled as [ prolific , high publi , SIGMOD ]. All these groups lead to different research communities, the third one is most adapted to a database workshop.

When an interesting group is found, another important operation is exploitation , i.e., an operation that  X  X rills down X  into the most interesting subgroups contained in a seed group.

D EFINITION 3. Group Exploitation . We define a function gExploit ( U, G ) that takes a set of users U  X  X  and finds all groups in G that are contained in U . More formally, gExploit ( U, G ) = { g  X  X | g  X  U } .

Figure 1 shows the result of applying gExploit() on the group la-beled [ highly senior , PVLDB , data integration ] (Step 3). That results in 3 subgroups: one formed by 26 experts in query processing who publish in ICDE, the other by 14 prolific researchers who publish in TKDE, and the last one by 7 male re-searchers who work on uncertainty in databases. All 3 groups con-tain solely highly senior researchers who publish in PVLDB and work in the area of data integration. This example clearly illus-trates that 32 out of 36 users of the selected group are covered.
The discovery of new groups relies on the two functions, gEx-plore() and gExploit() (Definitions 2 and 3 respectively), that are applied to a seed set of users. In order to comply with principles P1 and P2 , the number of groups returned to the analyst at each step must be limited, and output groups must exhibit diversity. Hence, we define the G ROUP D ISCOVERY Problem as follows: given a set of users U  X  U , an overlap threshold  X  , the G ROUP D ISCOVERY Problem returns k groups in G , referred to as G U and is expressed either as an exploration or an exploitation problem depending on an analyst X  X  needs.

For exploration, we define opExplore ( U, G , X ,k ) that must sat-isfy the following conditions: 1. G U  X  gExplore ( U , G , X  ) 2. |G U | = k 3. diversity ( G U ) is maximized. where diversity ( G U ) is defined as follows:
In exploration, the aim is to start from a seed set of users of in-terest U , and find k groups that have some relevance to U , using gExplore ( U, G , X  ) , and that have maximal diversity (as little over-lap as possible with each other).

For exploitation, we define opExploit ( U, G ,k ) that must satisfy the following conditions: 1. G U  X  gExploit ( U , G ) 2. |G U | = k 3. divCoverage ( G U ) is maximized. where divCoverage ( G U ) is defined as follows:
In exploitation, the aim is to find k groups that maximize cov-erage of the seed set U . Choosing k groups that have the highest coverage may potentially cause high overlap between those groups. Figure 3 left illustrates that, with k = 2 and two highly overlap-ping groups g i and g j . Therefore, in the case of exploitation, we revisit the definition of diversity in a way that it prioritizes k di-verse groups which cover as many users as possible in U . In [16], it is shown that there does not exist a unique optimal solution for both diversity maximization and coverage maximization. There-fore, the diversity formula is modified by adding ( | S g  X  G (see Equation 1). For example, in Figure 3, diversity ( { g diversity ( { g i ,g m } ) = 1 . Thus for opExplore() , both g can be chosen with g i . However, for opExploit() , g m is preferred because divCoverage ( { g i ,g m } ) &gt; divCoverage ( { g
IUGA builds on the G ROUP D ISCOVERY operations letting an analyst apply one of opExplore() or opExploit() on a set of users U and obtain k groups that constitute further analysis options. Fig-ure 4 illustrates that process. In order to comply with principle P3 , IUGA introduces a time limit parameter. Each step of IUGA solves the G ROUP D ISCOVERY Problem and returns the best possi-ble k groups within a given time limit.

In addition to opExplore() and opExploit() , the analyst is pro-vided with a set of actions that could be performed on a chosen group to transform it according to his/her needs. The analyst exam-ines the set of k groups at each step and chooses a new seed group on which one of 3 actions could be performed: actKeepUsers( U , U actModifyLabel( U , l ) , and actUndo() to undo the previous step. Ta-ble 1 summarizes each action. actKeepUsers( U , U 0 ) allows the ana-lyst to mark which users to keep for the next step. actModifyLabel( U , l ) is used to remove/add predicates or items to l U , the label of U , re-sulting in new seed users.

The ability to  X  X anipulate group membership X  using actions on a seed group, provides additional flexibility at each step. For ex-ample, as illustrated in Figure 1, in order to narrow down the set of 119 senior researchers who publish in PVLDB, the analyst adds the predicate data integration and obtains 36 researchers as the new seed set to analyze. Also in Figure 2, the analyst removes the predicate hobby:soccer to direct the navigation towards her preferences.
Our G ROUP D ISCOVERY Problem requires to develop an effi-cient algorithm for dynamically finding and comparing user groups. We have proved that G ROUP D ISCOVERY Problem is NP-complete by reductions from the M AXIMUM E DGE S UBGRAPH Problem [12] for opExplore() and from the M AXIMUM C OVERAGE Problem [17] for opExploit() . Proofs are available in [19].

Our overall approach operates in two steps: an off-line process to produce initial user groups G and an online iterative process during which the analyst chooses a selected group for which k groups are discovered.
 In the off-line process, a set of groups G are generated using the LCM closed frequent pattern mining algorithm [24] given a mini-mum support  X  . Each frequent pattern corresponds to a user group, which has at least  X  users. To feed LCM, we convert predicates in group labels into an item. For instance, the predicates ( gender = male ) and ( gender = female ) become two independent items. In addition, in order to speedup computing group relevance, we pre-compute an inverted index for each user group g  X  G (as is commonly done in Web search). Each index L g stores all other groups in G in decreasing order of their overlap with g . Thanks to the parameter  X  , we only partially materialize the indices. In the case of datasets we used in our experiment, we only materialize in average 10% of the whole index size.

Algorithm 1 summarizes a single greedy procedure that solves the G ROUP D ISCOVERY Problem, be it exploration or exploitation. It is called at each step of IUGA (as described in Figure 4). The al-gorithm admits as input a user group g , an operation op ( gExplore() or gExploit() ), an overlap threshold  X  , k , and a time limit tlimit , and returns the best k groups denoted G g . Line 1 selects the most overlapping groups with g by simply retrieving the k highest rank-ing groups in L g . Function getNext ( L g ) (Line 2) returns the next group g in in L g in sequential order. Lines 3 to 11 iterate over the inverted indices to determine if other groups should be considered to increase diversity while staying within the time limit and not vi-olating the overlap threshold with the selected group. Since groups in L g are sorted on decreasing overlap with g , the algorithm can safely stop as soon as the overlap condition is violated (or if the time limit is exceeded).
 Algorithm 1: G ROUP D ISCOVERY Algorithm Input : g  X  X  , op ,  X  , k , tlimit
Output : G g
G g  X  top k ( L g ) g out  X  getNext ( L g ) while ( tlimit not exceeded  X  overlap ( g,g out )  X   X  ) do 4 for g in  X  X  g do 5 if betterDiv ( G g ,g out ,g in ,op ) then 7 break 8 end 9 end end return G g
The algorithm then looks for a candidate group g out  X  X  g place in order to increase diversity. The boolean function betterDiv () (Line 5) checks if by replacing g out by g in in G U , the overall diver-sity of the new G U increases. Obviously, the diversity of a group set G k depends on the operation op .

The number of diversity improvement loops (lines 3 to 11) is |L g | = |G| in worst case. For each group g in  X  G g , we verify if the diversity score is improved by betterDiv () , hence O ( k time complexity of the algorithm is then O ( k 2 . |G| ) . Attribute Description &amp; Values
Seniority Number of years since the author X  X  first # publications With values  X  X ery few X  (3 to 14),  X  X ew X  (15
Publication rate Average number of publications per year
Venues set of all conferences and journals where
Topics Set of topics extracted from the author X  X 
Gender Based on matching the author X  X  first name
Our experiments aim to validate the usability and efficiency of interactive analysis and the quality of discovered groups at each step. All experiments are implemented in C on a 2.4GHz Intel Core i5 machine with an 8GB main memory, running OS X 10.9.2. Summary of Results: In our first experiments, we observe that IUGA leads a knowledgable analyst to cover most PCs of major data management conferences in 12 steps (multi-target scenario). We also show that IUGA arrives sooner to target than its competi-tors (single-target scenario). Our second experiment is a user study of the quality of groups found by G ROUP D ISCOVERY in each step of IUGA. We find that most participants prefer IUGA to other op-tions mainly because it helps them better understand the landscape of user groups. We use 2 real datasets for our experiments: DM-A UTHORS and M
OVIE L ENS and one synthetic dataset with the same characteris-tics as M OVIE L ENS . DM-A UTHORS and the synthetic dataset are used to validate the interactive analysis and M OVIE L ENS validate group quality.

The M OVIE L ENS 1M dataset 5 contains 1,000,209 ratings of 3,952 movies by 6,040 users. For each user, gender, age-group, occupa-tion and zip-code are also provided. DM-A UTHORS contains 4907 researchers who have at least 3 publications in WWW, KDD, SIG-MOD, CIKM, ICWSM, EDBT, ICDM, ICDE, RecSys, SIGIR or VLDB. Authors were crawled in October 2014 from DBLP 6 for years between 2000 and 2014. For each researcher, we compute the attributes summarized in Table 2. Values of the first 3 attributes are discretized using equal-frequency binning [13].

Table 3 summarizes the real datasets. It contains the number of user groups ( |G| ) with at least  X  users. For DM-A UTHORS is set to a very low value because smaller groups are of interest (e.g., 976 researchers are associated to high publi predicate, but only 28 researchers have published both in WWW and in CIKM ). For M OVIE L ENS , we set  X  to 7% of all users in order to obtain an adequate number of groups for our group quality validation. In both datasets, we set  X  in a way that each group overlaps with 10% of groups in G , hence pruning around 90% of inverted indices.
Our synthetic dataset is generated by initializing a binary matrix of users and items M with 0 and then randomly adding some initial groups G initial , i.e., rectangles in M that are completely filled with 1 . For each group in G initial , we randomize its number of users (between 10 and 2000) and items (between 5 and 50 items). Then we mark |G target | groups as target. We mine M with a minimum support threshold  X  to obtain the group set G . More details are presented in Table 4. All parameters are chosen in a way to mimic M
OVIE L ENS with a larger number of users.
We validate the effectiveness of our interactive analysis IUGA by addressing the two motivating scenarios described in Section 1. We first verify the utility of IUGA for building a program com-mittee on DM-A UTHORS (multi-target). Then, we describe a thor-ough validation of IUGA using our synthetic dataset that mimics M
OVIE L ENS (single-target). In both cases, tlimit is set to 20 ms .
We study the effectiveness of IUGA with a realistic task of in-teractively building the PC of major conferences/workshops in data management. We first start with an experiment with many PCs then we delve into the details of W EB DB 2014.

Figure 6 illustrates the results of interactively building the PCs of the following conferences in 2014: SIGMOD, VLDB 8 , WebDB and CIKM 9 . For a given PC, we start from 5% of its members and use IUGA to find the remaining ones. Target PC members should be discovered in user groups proposed in different steps of IUGA. The figure reports the number of steps to discover 50% and 80% of PC members as the average of 50 runs of IUGA for each PC.
We can observe that any PC selection can be done in 12.04 steps on average. CIKM X  X  PC is the hardest to discover and WebDB X  X  the easiest. Our conjecture is two key factors influence that: PC size and PC diversity . Indeed, the PCs of VLDB, CIKM and SIGMOD contain over 100 members while WebDB is smaller. This is why the former require a higher number of steps to cover 50% of their members (6.7, 6.5 and 5.9 steps respectively). In addition, the av-erage pairwise Jaccard similarity 10 between PC members of CIKM is 7.35 . This high diversity results in more steps to reach 80% of their PCs (8.3 and 8.1 steps respectively). SIGMOD has the least heterogeneous PC which leads to 4.8 steps to reach 80% of its PC. We now have a closer look to the W EB DB 2014 PC selection. Our detailed illustration will show the following facts: F1 : how the analysis of user groups is more useful than analyzing individual users; F2 : how our actions and operations (defined in Section 2) are adequate and necessary in interactive analysis; F3 : which users are reachable or not, depending on their similarity to other users; F4 : how relevance and diversity contribute to the analysis.

We characterize different scenarios based on the analyst X  X  exper-tise and the analysis starting points . We assume 5 virtual analyst summarized in Table 5. To measure the effect of expertise, we consider two cases where the analyst is knowledgeable about PC selection and the case where she is a novice PC chair . We also examine different starting points to build the PC: a subset of the final PC, a subset of the previous year X  X  PC (i.e., W EB DB 2013), or a set of arbitrary researchers outside the PC. Figure 6 shows that the average number of steps to cover 80% of the PC is 9.4. At each analysis step, k = 3 . Figures 7 and 8 illustrate the results. Notation is simplified by replacing actKeepUsers() with keep and actModifyLabel() with add/remove .
 N ON E XPERT O UT Non-expert Outside W EB DB
In the K NOW I N scenario (Figure 7), a knowledgeable analyst starts with a subset of the final PC, i.e., G. Fletcher, M. Theobald, S. Michel, and X. Xiao, and selects the last two as a seed group (because they are prolific young researchers with a high number of publications.) Exploring this group results in 3 groups out of which the one labeled with SIGMOD (the conference that hosts W EB DB) contains 4 researchers of interest (L. Popa, A. Doan, Benedikt and S. Amer-Yahia). This already shows the advantage of user group analysis (fact F1 ) where in one single step, 4 PC members are retrieved. The analyst then uses actModifyLabel() to replace the predicate high publi with data integration (i.e., the W EB DB main theme in 2014) and decides to exploit the resulting group. In step D , the analyst keeps only P. Fraternali and F. Naumann among 12 group members using actKeepUsers() ac-tion. This action makes it easier to reach groups containing items like SIGMOD (P. Fraternali and F. Naumann have 9 and 6 SIG-MOD publications respectively) and ICDE (e.g., F. Naumann has 14 ICDE publications). This shows the necessity of actions, con-firming fact F2 . Up to step E , the analyst is able to find 14 out of 15 PC members. The missing PC member is Jian Li. We compare Li X  X  word cloud in Figure 5 containing all his publication title words, conferences and journals, with the cloud for all W EB DB 2014 PC members. This shows that Li X  X  research areas differ significantly. This is an observation of the fact F3 that shows the limitation of interactive analysis.
 In K NOW O UT (Figure 7), the knowledgeable analyst starts with J. Leskovec and A. Siebes, two researchers outside the final W PC. The opExplore() operation first finds k related groups that ex-pand possible candidates. In step H , the analyst encounters the same group as in step A of scenario K NOW I N . This shows that in this case, a knowledgeable analyst only needs 2 more steps to reach relevant groups from a random departure point. Step H is also an illustration of fact F4 and shows that all 3 returned groups are rele-vant and diverse leading the analyst to pick the group labeled with SIGMOD .

We verified another scenario K NOW 13 where the analyst starts from a subset of the W EB DB 2013 11 PC which has 10 researchers in common with 2014. Due to lack of space, we do not illustrate it. We observed that K NOW 13 is very similar to K NOW I N .
In N ON E XPERT I N (Figure 8), we consider a junior PC. The aim is to observe the effect of analyst expertise by comparing this sce-nario with K NOW I N . We will see that in the case of poor expertise, the analysis is done mostly by exploration. We also observe a ten-dency to manipulate group labels rather than group membership (specific researchers in groups). The analyst starts with 4 given researchers and applies opExplore() to expand the analysis scope. The analyst finds a group of 138 researchers labeled with query processing , SIGMOD and ICDE , and decides to expand that group by removing query processing . The analyst then nav-igates up to step L , where she does not find any helpful group. Thus she commands an actUndo() action. Up to step O , she finds 12 out of 15 PC members. Compared to K NOW I N , the number of useless steps (without any PC member discovery) has increased.

Finally, in N ON E XEPERT O UT , we examine the case where a non-expert analyst starts with researchers outside the final PC. In this scenario, the analyst may abandon a path and start again with different groups. She may need to repeat that until a satisfying start-ing point is found. In our experiment, a non-expert analyst jumps 4 times to land at step K , the first step of N ON E XEPERT
The previous experiment showed how effective our interactive analysis is in building a program committee by  X  X athering X  mem-bers of interest along the way during the analysis. In this experi-ment, we focus on validating the effectiveness of IUGA in finding a single target as described in Example 2 in Section 1. We use our synthetic dataset that was generated to scale up M OVIE Our dataset is a matrix M with 3  X  10 7 cells, where squares with at least 10 users (i.e., minimum support  X  ) filled with 1, represent user groups. We propose a measure called A VERAGE T ARGET RIVAL (ATA), i.e., the average number of iterations to reach a group containing a target group starting from a non-target group. We ran-domly mark 50 groups as targets and compute ATA for those groups (we refer to target groups as G target ). We compare IUGA with two different baselines: unsupervised and interactive . Briefly, if m and m 2 are two different methods and ATA( m 1 ) &lt; ATA( m m 1 is considered faster. Note that the concept of ATA differs sig-nificantly from finding the shortest path. For the latter, we assume the starting and target points are known, while this is not the case in the interactive analysis.
 Algorithm 2: Experimental ATA Protocol ATAalg Input : G , G target , k ,  X  , g , len , method , maxlen
Output : length of navigation path if g  X  X  target then return len if len &gt; maxlen then return -1 // lost path
G k  X  choose ( opExplore ( g, G , X ,k,method ) , opExploit ( g, G ,k,method )) foreach g  X  X  k do 5 ATAalg ( G , G target ,k, X ,g, len + 1 ,method, maxlen ) end
Algorithm 2 illustrates how ATA is computed. We designed 200 different sessions each of which has a different synthetic dataset and is repeated 100 times for each method. Hence, we compute 20,000 ATA values for each one of the interactive analysis meth-ods we defined. For a random group g rnd , k groups are returned using method , and a random choice between opExplore() and op-Exploit() (the algorithm starts always with an opExplore() ). Each of the k groups becomes the new seed. This depth-first recursive call terminates either when one group in G target is found or when a path of length 50 has been built ( maxlength in Table 4). These recursive calls form paths inside the group space. A path is called valid if its last group belongs to G target . The ATA is computed as the average of valid path lengths for each method.
 This experiment compares IUGA to a variant of k -M EANS with Jaccard as the distance measure. k -M EANS is the representative of offline clustering algorithms with a constraint on the number of clusters ( k ). At each step, both IUGA and k -M EANS groups while respecting timelimit . Any number of iterations is allowed for k -M EANS within timelimit . We then report ATA for both methods. For k -M EANS , we randomly add/remove attributes at each step i so that a new set of k clusters is obtained in step i + 1 . Presence or absence of an attribute changes the clusters X  member-
Figur e 9: IUGA Comparison with Clustering Algorithm ship, as the Jaccard distance between users varies. For instance, adding a specific value of age reduces the distance between two users having the same age.
 Figure 9 illustrates ATAs for IUGA and k -M EANS in log scale. We vary k from 2 to 40 and observe how ATA for both algorithms evolves. While k -M EANS performs better for very small values of k , IUGA outperforms it by two orders of magnitude for higher values of k . When k is very small, clusters are huge. Thus most of the time, there exists a cluster that contains all users of a target group. For larger values of k , more clusters with smaller size are generated and more steps are needed to finally reach the target. We can conclude that the superiority of IUGA over unsupervised methods comes from the use of diversity at each step in order to cover as many users as possible.
 We compare IUGA with some interactive analysis baselines: D IV R AND , R ANDOM , E XHAUSTIVE and ILP. At each step, D
R AND randomly generates as many sets of k groups as possi-ble within tlimit and returns the one with the highest diversity. R
ANDOM navigates randomly in the space of groups and does not respect tlimit . E XHAUSTIVE generates all possible k among n groups in G , i.e., C n r and chooses the one with the highest diver-sity. ILP returns k groups with maximal diversity using an integer linear programming formulation (using C HOCO 3.0 solver 12
Table 6 illustrates ATA and execution times for IUGA and opti-mal methods. Since both E XHAUSTIVE and ILP generate optimal paths, their ATA are very close. However, their execution times are different. This experiment shows that IUGA is faster than E HAUSTIVE and ILP (3.49 minutes faster than ILP) while maintain-ing a comparable ATA. Figure 10 illustrates ATA for all heuristic-based methods: IUGA, D
IV R AND and R ANDOM by varying k from 2 to 40, and varying # groups from 50,000 to 1,000,000. Optimal methods (E XHAUS TIVE and ILP) do not terminate for this experiment. In general, we observe that IUGA has much lower ATA for k  X  16 and k  X  30 . This simply shows that considering relevance and diversity at each step reduces ATA by an average of 15.91 steps.

For k  X  [16 , 30] , D IV R AND and IUGA have close results. This shows that although the relevance component, i.e., the difference between D IV R AND and IUGA, is shown to be very useful in gen-eral, it is less effective for large values of k . In [5, 25], it is shown that in a context with too many options and no hint for further nav-igation, long jumps are preferred to short jumps. In our case, rel-evance tends to favor short directed jumps in the space of groups while D IV R AND does not. This is why when few options are avail-able, IUGA performs better and D IV R AND performs as well as IUGA for larger values of k . In another research 13 , it has been shown that people faced with numerous choices, whether good or bad, find it difficult to stay focused on a task. Choosing a small value of k is hence better both for performance and effectiveness.
We observe that increasing the number of groups has a huge ef-fect on D IV R AND . When the number of groups increases, the tar-get groups are more likely to be diverse. Thus, precision (ratio of valid paths over all navigated paths) decreases for all methods, while thanks to relevance, the decrease is negligible for IUGA.
Our last experiment focuses on a single step of IUGA by evaluat-ing the quality of obtained groups at each iteration of G COVERY . We ask participants in a user study to compare the top 5 groups obtained by G ROUP D ISCOVERY with some competitive methods. We use M OVIE L ENS because people are usually familiar with movies and their attributes. We setup a questionnaire which was answered anonymously by 35 participants. The evaluation consists of a comparative evaluation where results of competitive methods are evaluated together, and an individual evaluation where each set of top 5 groups is evaluated separately.
In the comparative evaluation, we compare the top-5 groups ob-tained by G ROUP D ISCOVERY with those returned by 4 baselines: Largest Groups , Most Overlapping , Least Overlapping and Most Concise (groups which have the shortest description). Those base-lines were designed using interestingness measures commonly used in pattern evaluation [14]. Each question contains an input group (e.g. [ Total Recall , Star Wars IV ] in MovieLens dataset) and sets of top-5 groups corresponding to each method. Partici-pants chose the method that offers the most satisfying top-5 groups. Also, participants were instructed to select a justification for their preferred method: it helps better understand who does what , it helps to discover new users , it helps to discover new group labels .
Figure 11 illustrates the average percentages of responses for each analysis option. In this part, participants have mostly pre-ferred the results of G ROUP D ISCOVERY followed by Most Concise groups. Also, they have mostly justified their responses as it helps better understand who does what (52.75%). The choice of Most Concise groups reveals that people prefer groups with short labels.
Preference (%)
In the individual evaluation, we compare each of top 5 groups of G ROUP D ISCOVERY with Most Overlapping and Least Overlap-ping groups, i.e. two extremes. Participants have preferred groups of G ROUP D ISCOVERY in 51.79% of cases, Most Overlapping in 33.12% and Least Overlapping in 15.09%. They justified their re-sponses as follows: Justification 1 : understand the selected group , Justification 2 : discover new users or Justification 3 : understand the whole data . Whenever our solution was selected, Justification 1 was chosen by 56% of participants on average, followed by Jus-tification 2 (34.22%). In general, 63% of participants mentioned that their preferred group helps better understand the selected group ( Justification 1 ), followed by 28% who believe the preferred group helps discover new users ( Justification 2 ).
To the best of our knowledge, no approach has proposed and for-malized an interactive group analysis framework. Recent studies have shown an interest in reporting statistics about pre-defined groups, as opposed to our work where we look to discover users. Our work does relate to a number of others in functionality, interac-tivity/visualization and diversity.
 Constrained-based Mining: IUGA bears similarity to constrained mining [6, 7], but the latter heavily relies on the analyst having some knowledge about the underlying data to be able to formalize constraints, as opposed to our data-driven work where relevant and diverse options are suggested to the analyst.
 Interactive and Visual Analysis: Interactive pattern analysis ap-proaches [3, 5] focus on learning the subjective measure in the mind of the analyst to guide pattern exploration. For example, O
NE C LICK [5] is a personalized interactive navigation approach that learns an interestingness function based on patterns that were liked or unliked by the analyst in previous steps. In IUGA, we adopt an approach based on exploration or exploitation and let the analyst choose which operation to apply at each step. The ability to personalize the navigation as in O NE C LICK is an interesting di-rection for future work. Semi-automatic PC construction has been addressed in [8]. The proposed approach requires the definition of quality and cost values for each researcher. This is a subjective and challenging task that assumes full knowledge of researchers X  profiles which is not always the case in out analysis tasks.
While visualization [22, 18] and interactive exploration differ in focus, there exist a few efforts that combine both. Few examples are data mining suites like R APID M INER , K NIME , and MIME [15]. These approaches develop a toolbox to manipulate and visualize patterns according to preferences specified by the analyst at each step. In MIME, analysts can refine discovered patterns on the fly by selecting additional items. These methods do not provide semantics for exploration or exploitation nor do they rely on an optimization framework to cover the space of patterns.
 Diversity: Diversity is a widely studied subject that finds its roots in Web search with a goal similar to ours. In [9], the concept of di-versity in text retrieval and summarization is introduced to balance document relevance and novelty. Most approaches fall into two cases: content-based (e.g. [9]) and intent-based [11]. Our algo-rithm, G ROUP D ISCOVERY , is based on a greedy approach similar to content-based diversification.
We introduced IUGA, the first interactive user data analysis frame-work that is based on a simple and intuitive optimization formula-tion: the G ROUP D ISCOVERY Problem that finds the k most diverse and relevant user groups a seed group. IUGA relies on two group discovery operations: exploration and exploitation. We prove the hardness of our problem and devise greedy algorithms to help ana-lysts navigate in the space of groups and reach one or several target users. Our extensive experiments on real and synthetic datasets show the utility of relevance and diversity in group discovery and in finding users of interest in different scenarios. We are currently pursing two improvements: (i) expressing group discovery as a multi-objective optimization problem and (ii) incorporating the ab-straction operator defined in [20] to better summarize found groups. Acknowledgments. Parts of this research was supported by grants PEPS FAAAWS and ANR-13-CORD-0020. [1] R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. [2] R. Agrawal, T. Imielinski, and A. N. Swami. Mining [3] M. Bhuiyan, S. Mukhopadhyay, and M. A. Hasan.
 [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [5] M. Boley, B. Kang, P. Tokmakov, M. Mampaey, and [6] F. Bonchi, F. Giannotti, A. Mazzanti, and D. Pedreschi. [7] C. Bucila, J. Gehrke, D. Kifer, and W. M. White. Dualminer: [8] C. C. Cao, J. She, Y. Tong, and L. Chen. Whom to ask?: jury [9] J. G. Carbonell and J. Goldstein. The use of MMR, [10] U. Cetintemel, M. Cherniack, J. DeBrabant, Y. Diao, [11] O. Chapelle, S. Ji, C. Liao, E. Velipasaoglu, L. Lai, and S.-L. [12] U. Feige, G. Kortsarz, and D. Peleg. The dense k -subgraph [13] N. Friedman, M. Goldszmidt, et al. Discretizing continuous [14] L. Geng and H. J. Hamilton. Interestingness measures for [15] B. Goethals, S. Moens, and J. Vreeken. Mime: A framework [16] P. Indyk, S. Mahabadi, M. Mahdian, and V. S. Mirrokni. [17] D. S. Johnson. Approximation algorithms for combinatorial [18] A. Leuski and J. Allan. Strategy-based interactive cluster [19] B. Omidvar-Tehrani, S. Amer-Yahia, and A. Termier. [20] B. Omidvar-Tehrani, S. Amer-Yahia, A. Termier, A. Bertaux, [21] L. Parida. Redescription mining: Structure theory and [22] C. K. sang Leung, P. P. Irani, and C. L. Carmichael. [23] A. Siebes, J. Vreeken, and M. van Leeuwen. Item sets that [24] T. Uno, M. Kiyomi, and H. Arimura. Lcm ver. 2: Efficient [25] R. West and J. Leskovec. Automatic versus human
