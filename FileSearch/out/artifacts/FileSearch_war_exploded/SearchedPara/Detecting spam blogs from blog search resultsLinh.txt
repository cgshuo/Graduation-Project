 1. Introduction 1.1. Motivation
Blogging has now become a popular media for people to express themselves, share information, and communicate among each other. According to Technorati, 1 a popular commercial blog search engine, the number of blogs doubles about every six months. Such an exponential growth of blogs could be partly explained by a few factors, such as the ease of publishing and the free hosting services (e.g., blogspot.com, livejournal.com and others). However, all these factors have also greatly contributed to a cost reduction of creating and maintaining spam blogs (or splogs). Formally defined in Lin, Sundaram, much attention from research.
 Three types of splog detection methods have been proposed in literature (see Section 7 for a more detailed discussion).
Content-based detection methods aim to identify features which could distinguish splogs from authentic blogs, such as from snapshots of either the home page or all published posts of a blog. However, given the dynamic nature of blogs (e.g., publishing new posts and hence changing homepages frequently), content-based splog detection technique becomes in 2007 X 2008 performed worse on the data collected in 2008 X 2009, compared to the test data collected in the same period
However, as stated in Agarwal and Liu (2008) , although web models seem to be an appropriate choice for modeling the blogosphere but there exists certain key differences. For example, web graph is usually quite dense due to the large number
Varlamis, 2006). Moreover, in social media (e.g., blogs, comments, and forums), readers have unprecedented freedom to cre-from users and the reported spam blogs are shared within a network of trust. 1.2. Research objectives and contributions
In this work, we study the problem of splog detection by monitoring on-line search results. We aim to detect splogs that particular, we propose a technique that exploits the user search queries and their results returned from search engines to single query for splog detection. The proposed solution therefore has to sample a small subset of queries that are more likely to be spammed than other queries. In other words, a set of queries that are more likely to direct traffic to splogs need to be determined and then monitored and analyzed. This reduces the computational and storage costs of splog detection.

Blog temporal behavior monitoring . Due to the dynamic nature of blogs, a splog may behave normally for some time but later shows its true color to the search engine. The proposed solution therefore has to profile blogs with their temporal behavior and determine the splogs based on their temporal behaviors.

Flexibility and complexity . Moreover, the solution shall be generic and be able to work on top of existing blog search engines without modification to them. In our case, the proposed solution would only take information from the search
At the same time, as splog detection analyzes the results of blog search engines, both the time and space complexities become major design issues.

Prior to the discussion of our solution, we describe two key assumptions that we have made: (i) among the blogs indexed by a search engine, the number of authentic blogs always dominates the number of splogs, i.e., we always assume that a blog of their targeted queries ( k = 50 throughout this paper). Justifications of these two assumptions are given in Section 3 .
To address the aforementioned issues, we have proposed a framework for splog detection. Our proposed framework mainly consists of two modules, namely, spam-post detection and splog detection . The spam-post detection module computes summarize the contributions of this research: 1. We have proposed a splog detection framework which is capable of detecting splogs online without involving training 2. We have proposed the notion of blog profile . A blog profile records the temporal behavior of a blog with a sequence of 1.3. Paper organization
The remainder of the paper is organized as follows. In Section 2 , we present the observations made from popular blog search queries and their results. Section 3 presents our framework for detecting spam blogs. Sections 4 and 5 discuss the work of spam blog detection. We conclude the paper in Section 8 . 2. Observations on blog searches queries 3 largely represent the common interests of web users and are heavily searched, spammers may subscribe the popular queries and generate fresh spam content containing the popular keywords. Their posts could easily appear among the top search results as recency is an important ranking factor in blog search. Similar assumptions were also made in Katayama in the sequel, the popular queries are not as dynamic as expected, making it even simpler for the spammers to subscribe. In first set was a manually compiled list of 323 keywords, each of which led to spam three major search engines. The second set was the 5000 most-bid keywords from an authentic ads syndication program. Nev-ertheless, both sets are not publicly accessible.

In the following, we report statistics derived from the popular queries and their search results to support our decision on monitoring popular queries. From 08 Nov 2006 1am to 31 Mar 2008 10pm, we crawled the top-15 most popular que-ries published by Technorati at the frequency of every three hours. Each of the 15 popular queries was submitted to Tech-norati and the top-50 results were obtained through Technorati X  X  search API. Note that the same query keyword may be popular at various time points and hence has been evaluated multiple times, as the search results could be different each ries is 2301.

Observation 1. Many popular queries have not been dynamic. In addition, a small set of queries tends to be popular for a long period of time.

A heavily searched query (hence becoming popular query) at a given time often represents the information needed by a large number of users at that time. One may expect that the popular queries at a given time are often related to some events or hot topics; hence, expect that all popular queries are rather dynamic. Observation 1 states the opposite.

Fig. 1 plots the popular query distribution. We define query frequency to be the number of times that a query appears in into three categories. Many popular queries are website names and person names. That is, the spammers could improve its visibility in search results by simply targeting on those extremely popular queries.
 Observation 2. Among the top search results of the popular queries, a few blogs appear much more frequently than others.
Fig. 2 plots the distribution of blogs which ever appeared in top-50 results of any popular query. The plot again shows a blogs which appeared more than 100 times. From this observation, we argue that splog detection does not need to keep track splog only appears once or twice a year in the search results. The damage of such a splog to the search engine X  X  user expe-not necessarily require a large storage space. Observation 3. Blogs appearing in many top search results do not imply they may attract a large number of inblogs.
As part of the search results by Technorati X  X  search API, ther analysis. The number of inblogs is defined by the number of blogs each having one or more links to the current blog. namely inblog increment , in our dataset. Fig. 3 plots the averaged inblog increment against the number of times a blog ap-peared in top search results. It shows that when blogs do not appear frequently in top search results (e.g., fewer than 100 times), their inblog increment grows linearly. However, for those blogs that frequently appear in top search results, most we therefore use temporal inblog increment as a feature for splog detection.

In summary, we have presented some observations derived from real data collected from a commercial blog search en-ing to spam-posts appearing in top search results for these queries. observations further motivate our work on splog detection and also provide some hints on the features that can be exploited in splog detection. 3. Splog detection framework Prior to our discussion on our framework for splog detection, we present two assumptions made, as discussed earlier in
Section 1 . 3.1. Assumptions and justifications Assumption 1. Splogs always try to inject their posts into top search results of the targeted queries.
One main objective of splogs is to attract traffic from blog search engines so as to promote themselves and/or affiliated sites. To achieve this, spammers may exploit search engine optimization techniques to place their posts among the top search results, which have a higher chance to be viewed by users. On the contrary, if the posts from splogs could not fre-becomes less critical. Based on this assumption, we monitor those blogs whose posts frequently appear in top search results of selected queries (i.e., popular queries in our setting).

Assumption 2. Among the blogs indexed by a search engine, the number of authentic blogs always dominates the number of splogs.
 2005 ). We therefore assume that blog search engines have already done a reasonable job in splog filtering and thus most of at that time, it may be reasonable to further assume that the posts from authentic blogs, among the top search results, are splogs, from top search results, using classical outlier detection techniques. 3.2. Splog detection framework
Illustrated in Fig. 4 , the proposed framework consists of two main modules: spam-post detection and splog detection . The spam-post detection module detects those blog posts that are likely from splogs from the search results of popular queries. points. The splog detection module computes a score for each blog based on its blog profile with the scoring functions pre-sented in Section 5 . Other than blog profiles, the proposed framework also maintains spam-post seeds which are represen-tative spam-posts detected from the search results. The spam-post seeds are used to enhance the spam-post detection, as some spam-posts may be similar to each other. We remark that both blog profiles and spam-post seeds are initially empty and incrementally and automatically maintained with outputs from the spam-post detection module. To sum up, we outline our framework in Algorithm 1 .

Algorithm 1. Splog detection 4. Spam-post detection
In this section, we describe the technical details of the spam-post detection. Our main technique is to formulate the problem as an outlier detection problem, based on our earlier discussions. The main technical issue of detecting outliers among posts is to derive a set of features to describe each post and a distance measure between posts. These features are then used to compute the distance between a pair of posts, which is required by the outlier detection algorithm. 4.1. Post features and distance measure
Given a query q issued at time t to a blog search engine, the set of the top-ranked blog posts returned is denoted by R (i.e., snippet or summary in top search results) of each post respectively. They are: the length of the title (content) in terms of the number of words; the number of query words matched in the title (content); and the average word length in the title (content).

We propose two additional features that are derived from a post graph  X  which is inspired by spam webpage detection ( Kurland &amp; Lee, 2005; Kurland &amp; Lee, 2006 )  X  with all the posts in R post p i 2 R q , t . An edge from post p i to post p j is created if and only if p given similarity measure ( k = 20 in our experiments). The similarity from p ing edge, is defined as follows: the title and content of post p i ( Ponte &amp; Croft, 1998 ). Note that, KL divergence is directional and w ( p general.
 The two features, namely, weighted out-going degree and clustering coefficient and then derived from the post graph. proximity of the post to the imprecise ground truth (i.e., all posts in R query, it is expected that the posts from authentic blogs have higher weighted out-going degrees than that from splogs.
Clustering coefficient of a post p i , denoted by c i , is computed in the following equation:
In this equation, N i is the set of 20 neighbor posts of p YouTube ( Benevenuto, Rodrigues, Almeida, Almeida, &amp; Gon X alves, 2009).
 All these eight features are normalized independently with respect to the corresponding maximum value from all posts in
R q , t (i.e., L-infinity norm). With the 8 features, the distance between p cosine similarity measure. be ad-hoc, they have shown their effectiveness in our experiments. Other than the 8 features described above, in our exper-ness of presentation, we opt not to report the use of content features. 4.2. Incremental spam-post detection Algorithm 2. spam-post-detect
The proposed spam-post detection can be summarized as follows: Given the set of top-ranked posts R query q at time t , the first step is to detect the outliers among them, based on the assumption that posts from splogs are in case the outlier detection algorithm missed some spam-posts. In web spam detection, it is found that many spams share seeds are then maintained with some of the newly detected spam-posts with high scores. In the sequel, we further elaborate the details of spam-post detection and spam-post seeds below. 4.2.1. Spam-post detection
For easy discussion of spam-post-detect shown in Algorithm 2 , we assume that a set of spam-post seeds S is already determined. 6 Given S and R q ; t as input, the algorithm returns a set of spam-posts P as output.
In Line 1, a distance-based outlier detection algorithm outlier
Scott (2004). The algorithm takes the set of posts in R q ; t posts (i.e., Eq. (3) in our setting) as input and returns the outliers in R distances derived from the given set of objects, i.e., R q ; t spam-post-detect first sets the outliers detected to be spam-posts (Line 1) and then computes a score for each spam-post (Lines 2 X 3). Next, in Lines 5 X 13, those spam-posts that might have been missed by likely to be a spam. To identify those posts, the minimum distance between a spam-post seed to each outlier is computed include p in the spam-post. In Line 10, the spam score for p is updated. We call our algorithm incremental as the spam-post seeds are continuously updated and maintained with newly detected spam-posts discussed in the next subsection. 4.2.2. Spam-post seeds
The spam-post seeds play an important role in the spam-post detection. As discussed in post seeds are used as pseudo-relevance feedback to detect spam-posts. Note that in our problem, enumerating all spam-the set of spam-post seeds are a set of non-redundant spam-posts; and (ii) the seeds should be representative. In another words, for every spam-post not reported in the set of spam-post seeds, we want it to have a representative similar to it in spam-post seeds; (iii) the seeds should be a set of fresh posts that reflect to the current spammer X  X  tactics. Algorithm 3. spam-seed-select In response to these, we propose spam-seed-select , shown in Algorithm 3 . It takes a set of newly detected spam-posts
P (e.g., from the top hits of a search), the current spam-post seeds S and two thresholds / and a as input and produces the next spam-post seeds as output. Initially, S is empty. As the blog search engine is monitored by period of time, S becomes non-empty and incrementally maintained by the latest search.

To maintain the spam-post seeds, the set of spam-post seeds S dated posts among the seeds are replaced with fresh spam-posts. More specifically, in Line 2, all candidate out-dated seeds from S that could be removed are identified since some fresh posts from P will be inserted into S score of the spam-posts in P is computed, where the spam score has been assigned by Algorithm 10). Spam-posts from P with high spam scores are then added into the spam-post seeds (Line 5). Next, those out-dated seeds that are similar to the newly included spam-posts are removed. That is, we find if there is a seed in S removed. Hence, Line 8 removes the previous seed from S 0 5. Blog profiles and splog detection order to pass any spam filters. 5.1. Blog profile when a post p appears in the top search results of a monitored query q at time t , a blog state tuple h t ; X ; p : ated and inserted into its corresponding blog profile, where  X  is the number of inblogs the spam-post score assigned to p if p is a spam-post (see Section 4 ), and p :
As the most recent behavior of blogs are more critical for splog detection, we only store the state tuples within a time window W (e.g., one month) with respect to the current time. That is, a state tuple h t ; X ; p : W period, and the third blog profile is dropped since no post from the blog appears in the top hits of any monitored query.
With such a time window, only those blogs having posts recently appear in top hits of the monitored queries need to be maintained. Moreover, as each blog state tuple stores three numerical values only, the storage overhead incurred by blog profiles is small. 5.2. Splog scoring functions
Given a blog profile, we have defined 4 scoring functions, denoted by SF
SF 1 : The inblog increment over time. Based on a recent study on evolving graph data, we assume links among authentic
SF 2 : Correlation between the number of posts appearing in top search results and inblog increment. As shown in Fig. 3 ,itis
SF 3 : Average spam-post score. This scoring function is defined based on the spam-post scores obtained from spam-post
SF 4 : Blog URL length . Reported in Fetterly, Manasse, and Najork (2004), URL length had been surprisingly effective in spam
From their definitions, the above 4 SF scoring functions each estimates the likelihood of a blog being a splog from one context of the blog (e.g., how many other blogs recommend this blog). The difference is that SF quency of the blog X  X  appearance in top search results, but SF blog posts returned for the monitored queries). Compared to the first three scoring functions, SF fast computation enables real-time splog detection whenever a blog state tuple is inserted into a blog profile.
To aggregate the efforts of the four proposed scoring functions in splog detection, there could be many different ways. A straightforward approach is to linearly combine the scores a blog received from the four scoring functions as shown in Eq. (5) , where w i  X  1 6 i 6 4  X  is the weight of the corresponding scoring function and algorithm (EA) ( Holland, 1992; Ingo, 1971; Evolutionary, 1996 ) to learn the weights, with 200 manually labeled blogs. The learned weights is w = [0.254, 0.245, 0.265, 0.236]. 6. Experiments
We designed two sets of experiments to evaluate (i) the effectiveness of scoring functions, and (ii) the impact of varying the parameters including time window size W , age threshold a , and post distance threshold / . The two sets of experiments and the performance measures used in our experiments. 6.1. Dataset and performance measure
The proposed splog detection framework was evaluated using real data collected from Technorati (see Section 2 for the
Nov 06 to Mar 08. For each query, the top-50 results were retrieved in XML format through Technorati API. The collected results were parsed and processed using Lucene 10 with KStem detection framework were implemented in Java.

To measure the effectiveness of the proposed technique, we selected 3000 blogs with the highest frequencies (blog fre-quency P 65) for manually labeling. The labeling was done by two undergraduates from business school and the students have no knowledge on the algorithms to be evaluated on the labeled dataset. Among the 3000 blogs, 444 were no longer in operation at the time of labeling. In addition, 1102 blogs containing many non-English blog posts. As the result, we ob-tained 699 splogs from the remaining 1454 blogs that are in English. We call the set of 699 splogs SplogSet-1 (or SS1 for short). Stated in Liu, Cen, Zhang, Ma, and Ru (2008), many blogs frequently change their blogs, with the assumption that all the non-operational blogs were splogs. Nevertheless, we understand that it is a strong assumption and the results on SS2 are therefore mainly for the completeness of the experiments. Our discussion on the splog-hits, 10 of them are also among the top 20 retrieved most number of search results. This partially supports our Assumption 1 such that splogs target on those popular queries frequently.

Precision and recall are the most commonly used measures in various prediction problems. In our setting, precision is the percentage of true splogs among all blogs detected to be splogs; and recall is the percentage of splogs detected among all true splogs (that should be detected). However, precision and recall are threshold-dependent. In our work, we therefore re-of the precisions obtained after each true splog is obtained in the ranked list. 6.2. Effectiveness of scoring functions time window size for blog profiles at W  X 1 for all scoring functions. For SF SS1 and SS2 respectively. APs of the five scoring functions are reported in Table 3 .

From Fig. 6 a and Table 3 , clearly the aggregated scoring function SF computed the precisions obtained after each true splog is obtained. Our paired t -test on the precision values showed that
SF f SF 2 ; SF 3 gf SF 1 ; SF 4 g , where denotes significantly better with p -value &lt;0.05. Despite SF by a search engine. That is, SF 3 could be implemented solely based on the search results of any blog search engine. SF detects splogs purely based on URL length, achieved only better precision than random guess. SF that the inblogs increase along time, only managed to achieve better precision than SF possible reason is that most blogs are personal online diaries. They do not reach many readers and do not gain large inblog increment along the time. So the difference in inblog increment from them and the splogs is marginal. operation during the data collection period, hence gained low inblog increment.

In the above experiments, the scoring functions involving inblogs (i.e., SF splogs are already filtered out, and (ii) Technorati does not index comments where links to splog commonly appear in Sifry (2005) . 6.3. Impact of varying parameters This set of experiments aims to find out the impact of varying various parameters to the splog detection performance.
Based on the earlier results, we only report the performance of SF performer. 6.3.1. Window size W
While fixing all other parameters, we studied the impact of varying window size W (see Section 5 ). We varied window size W from 1 day to 1 and report the PR-Curves and APs of SF paired t -test shows that f W  X 1 ; W 31 days g W 15 days W improvement on the results with a larger W than W 31 . Recall that many blogs in SS2 were no longer in operation. Once
W means more blog state tuples to be maintained in the detection process. In our following experiments, we set W to be 31 days. 6.3.2. Post-age threshold a and post-distance threshold /
Next, we studied the impact of varying seed-post age a in spam-post seed selection (see Algorithm 3 ) while fixing W =31 days and /  X  0 : 2. Fig. 8 plots the PR-Curves with a varying from one day to two weeks and the corresponding APs are re-would result in poorer splog detection accuracy. In specific, our significant test shows that f a 10 days achieved the best precision in the experiment. Such results partially unveil the temporal phenomena in the blog ference in the detection performance.

Similarly, fixing W = 31 days and a  X  10 days, the impact of varying post-distance threshold / (see Algorithm 3 ) is re-ported in Fig. 9 and Table 6 for PR-Curves and APs respectively. The best performance was achieved when /  X  0 : 2. 6.4. Spam-post seed accuracy
Recall that in the proposed splog detection framework (see Fig. 4 ), a set of spam-post seed is maintained, during the detection process, to facilitate the detection of spam-posts for SF the spam-posts detected and maintained by Algorithm 3 .

As the set of spam-post seeds is updated through the detection process, we report the averaged detection accuracy (e.g., the percentage of the blog posts that are from splogs) for one run with fixed parameters. Fixing the spam-post seed age the detected spam-post seeds have a decent quality. The paired t -test gives the following / where the subscripts are the values evaluated, and means significantly better with p -value &lt;0.05. Next, fixing distance threshold /  X  0 : 2, we compared the accuracy of spam-post seeds with varying seed age from one day to two weeks, as value &lt;0.05. Keeping the spam-post seeds with the age of about 10 days achieved the best detection accuracy in the experiment. 6.5. Summary
To summarize, our experiments showed that splogs can be detected from search results with a fairly high accuracy by monitoring popular search queries. We would like to further highlight the following three points.
The data used in our experiments was collected through 120 searches to the blog search engine each day. Given the fact engines.
The proposed scoring functions are simple and easy to implement on top of any existing search engine. In particular, our proposed spam-post detection based scoring function SF 3 even requires no inblog information to be provided in the search results. The small computation and storage requirements facilitate online splog detection in real-time.
In our experiments, we monitored the popular queries. However, the proposed framework is generic and can be used to monitor any set of queries that are likely to be targeted by spammers. To evaluate the splog detection accuracy of using other sets of queries is part of our future work. 7. Related work
To-date, spam blog detection is still in its infancy where few previous work has been proposed. Here, we highlight some from email spam detection ( Han et al., 2006 ). This method relies on some manual spam identification. Then, the method shares such spam information to others in a network of trust. Mishne et al. proposed a comment spam detection approach guage model of the blog posts and that of the related comments and other posts linked by comments. The score range of authentic comments is then derived by sampling and subsequently used to detect spam comments. There is another stream of work on applying supervised machine learning technique for spam-blog detection. Katayama et al. (2009) examined sev-learning technique. In Salvetti and Nicolov (2006) , the authors proposed a splog filtering technique based on the temporal information is not explicitly utilized in splog detection.

Only few work has utilized temporal information on splog detection. In Lin et al. (2008) , a method is proposed to extract acteristics of 50 pre-defined keywords contained in the blogs. The keywords are those of public concern (e.g., related to from the homepages of blogs were manually examined and the relationship between these features and the selected key-to be a splog.

Our technique is different from the existing approaches in two ways: (i) Most of the existing work analyzes the entire over, our proposed technique does not require more information than that already provided in the search results.
Besides the few spam blog detection discussed above, a large number of spam website detection has been proposed. Web-page spammers often introduce a link farm to boost the PageRank ( Brin &amp; Page, 1998 ) of the spam webpages and thus the link to good webpages but not spam webpages. Hence, their approach ranks the pages that have a good connectivity to good
BadRank proposes an algorithm to generate a set of bad seed pages. Their observation is that pages in a spam link farm are densely connected to each other. A ranking function is defined to identify the spam webpages based on such link structures.
Spam mass ( Gyongyi, Berkhin, Garcia-Molina, &amp; Pedersen, 2006) derives a score from PageRank and TrustRank to determine are two pioneer works that consider ranking of webpages over a period of time. Shen et al. (2006) defines a set of temporal energy associated with each link will gradually decrease as time passes by. This method also requires a set of trusted web-tained by their own classifier to improve the web spam detection. Similar to other spam detection approaches, it has a base classifier to label spam and non-spam blogs. Propagation algorithms are then proposed to smooth spam detection. The label of the neighbors of a blog is propagated to the blog. This propagation continuously affects spam detection. 8. Conclusions and future works
Being the first effort in splog detection by monitoring on-line search results, our work has demonstrated that splogs could be detected from search results through their temporal behavior. We have proposed a framework for splog detection con-sisting of spam-post detection and splog detection modules. For recording temporal behavior of blogs, we propose the notion cussed in our experiments, the proposed technique could be implemented on top of any existing blog search engine without modification to them. The insignificant computational and storage costs of the proposed approach make it ideal for online splog detection in real-time.
 better ways of aggregating the scoring functions for more effective splog detection. As we have shown that some popular we are also interested in finding out whether the proposed techniques can be adopted for tag spam detection. Acknowledgement
This work was supported by A STAR Public Sector R&amp;D, Singapore. Project Number 062 101 0031. The work of the third author is partly supported by FRG/07-08/I-59, Hong Kong Baptist University.
 References
