 Electronic retailers and content provid ers offer a huge selection of products for modern consumers. Matching consumers with products they like is very impor-tant for user X  X  satisfaction on the web. Recommendation systems, which provide personalized recommendation for users , become a very important technology to help users to filter useless i nformation. Through automatically identifying rele-vant information by learning users X  tastes from their behavior data in the system, recommendation systems greatly improve users X  experience on the web. Inter-net leaders like Amazon, Google, Netflix an d Yahoo increasingly adopt different kinds of recommendation systems, whic h generate huge profits for them.
Recommendation systems are usually divided into two classes: content-based filtering and collaborative filtering. Content-based filtering approaches use the content information of the users and items (products) to make recommenda-tions, while collaborative filtering approaches just collect users X  ratings on items to make recommendations. Recommendati on has been treated as a rating pre-diction task for a long time. Two successful approaches to rating prediction task are neighborhood model and latent factor model. Neighborhood models predic-tion a target user X  X  rating on an item by (weighted) averaging the item X  X  ratings of her/his k-nearest neighbors, who have the similar rating pattern with the target user. Latent factor models tra nsform both items and users to the same latent factor space and predict a user X  X  rating on an item by multiplying the user X  X  latent feature with the item X  X  latent feature. The combination of neighbor-hood model and latent factor model successfully completes the rating prediction task [1].

However, in many recommendation systems only the top-K items are shown to users. Recommendation is a ranking problem in the top-K recommenda-tion situation. Ranking is more about predicting items X  relative orders rather than predicting rating on items and it is broadly researched in information re-trieval. The problem of ranking documents for given queries is called Learning To Rank(LTR) [2] in information retrieval. If we treat users in recommendation systems as queries and items as docume nts, then we can use LTR algorithms to solve the recommendation problem. A key problem in using LTR models for recommendation is the lack of features. In information retrieval, explicit features are extracted from ( query, document ) pairs. Generally, three kinds of features can be used: query features, document fe atures, and query-document-dependent features. In recommendation system, use rs X  profiles and items X  profiles are not easy to be represented as explicit featur es. Extracting efficient features for rec-ommendation systems is emerged and a lsoveryimportantforlearningagood ranking model.

Some work tries to extract features for user-item pairs [3,4] etc. In [3], the authors extract features for a given ( u, i )pairfromuser u  X  X  k -nearest neighbors who rated item i . They use rating-based user-user similarity metric to find neigh-bors for a target user. However, in some e -commerce systems users X  preferences to items are perceived by tracking users  X  actions. A user can search and browse an item page, bookmark an item, put an item to the shopping cart and purchase an item. Different action indicates differ ent preference to the item. For example, if a user u purchased item i and bookmarked item j , we can assume that user u prefers item i to item j . Mapping the user actions into a numerical scale is not natural and trivial. So it is hard to accurately compute the user-user similarity in e-commerce systems where users X  f eedbacks are non-numerical scores.
In this paper, we argue that using ranking-based neighbors to extract features for user-item pairs is more suitable than using rating-based neighbors, because we are facing and completing a ranking task. Choosing neighbors through a ranking-based user-user similarity metric is natural and much closer to the essence of the ranking. Neighbors with the similar preference over items with the target user will give more accurate ranking information on items than rating-based neighbors. Moreover, We can also easily use ranking-based user-user similarity metric to find neighbors for a target user even that the users X  feedbacks are no-numerical scores. Our contributio ns in the paper can be summarized as: 1. We use ranking-based neighbors to extract features for user-item pairs and 2. The feature extraction method we used can be applied to recommendation The paper is organized as follows: In Section 2 we discuss notations and related works. The algorithm framework is pre sented in Section 3. Our experimental steps and experimental results are disc ussedinSection4.InSection5,wesum-marize our work and discuss the future work. In this section, we briefly discuss the notations used in the paper and some related topics. 2.1 Notations In recommendation system, we are given a set of m users U = { u 1 ,u 2 , ..., u m } and a set of n items I = { i 1 ,i 2 , ..., i n } .Wealsouse u, v to represent any user and use i, j to represent any item for conveni ence. The users X  ratings on the items are represented by an m  X  n matrix R where entry r u,i represents user represents all the ratings of user u . 2.2 Collaborative Filtering There are two kinds of collaborative filtering algorithms: user-based and item-based [5]. Given a user-item pair ( u, i ), user-based neighborhood model estimates the rating on item i based on the ratings by a set of neighbors who have the sim-ilar rating pattern with u . Possible choices for user-user similarity s u,v include the Vector Space Similarity (VSS), Adjusted Cosine Similarity (ACS) and Pear-son Correlation Coefficient (PCC). For ex ample, the VSS similarity represents a user as a vector in a high dimensional vector space based on her/his ratings. The cosine of the angle between two users X  ratings is used to measure their similarity: Since different users and items have different bias, PCC and ACC are proposed to relieve the bias problem. An alternative form of the neighborhood-based approach is the item-based model. Item-item similarity can also be computed like user-user similarity. Given a user-item pair ( u, i ), item-based neighborhood model estimates the rating on item i basedonthe k most similarity items that have been rated by u . PCC, ACC and VSS are rating-based similarity metric. The similarity is computed purely based on rating vector, and it ignores the ex-plicit preference over items. In [6], th e similarity between users is computed by Kendall Rank Coefficient [7] and a ranking neighborhood-based approach is used to make recommendations. The major problem with the neighborhood-based ap-proaches is that the rating matrix R is highly sparse, making it very difficult to find similar neighbors reliably. Matrix Factorization approach is better than neighborhood-based approaches at minimizing rating prediction error. Matrix Factorization approximates the observed rating matrix R as the inner product of two low rank matrices. The prediction rating on item i by user u is equal to the inner product of the corresponding user and item features. Classical matrix factorization approach is more about rating prediction, but in many recommen-dation systems only the top-K items are shown to user and ranking becomes more important than rating prediction. 2.3 Collaborative Ranking We will introduce ranking algorithms in recommendation system in this part. In [8], by considering the missing entries as zeros, the authors perform conventional SVD on sparse matrix R and make top-K recommendation based on the value of the test items in the reconstruct matrix. Overfitting on training dataset is avoided by only keeping high singular values. The algorithm shows good per-formance (precision/recall) than SVD++ [1], which is a famous model based on matrix factorization.

Some collaborative ranking algorithms are proposed based on LTR and matrix factorization. Ordrec [9] is an ordinal rank algorithm based on ordinal regression and SVD++. It models user X  X  rating via SVD++ and aims at minimizing an or-dinal regression loss. It brings the advantage to estimate the confidence level in each individual prediction and can also handle user X  X  non-numerical feedbacks. In [10], the authors present a generic optimization criterion (Bpropt) for person-alized ranking that is the maximum poste rior estimator derived from a Bayesian analysis of the ranking problem. Bpropt optimizes the measure of the Area Un-der the ROC Curve (AUC) based on matrix factorization and adaptive KNN. It uses stochastic gradient descent with bootstrap sampling to update parameters and converges very fast. PMF-co [4] uses pairwise learning to rank algorithm to solve recommendation problem, both user-item features and the weights of the ranking function are optimized during learning. ListRankMF [11] aims at minimizing the cross entropy between the predict item permutation probability and true item permutation probability. In [6], the authors propose a probabilistic latent preference analysis model for ranking prediction by directly modeling user preferences by a mixture distribution b ased on Bradley-Terry model. Some col-laborative ranking work tries to direct ly optimize evaluation measures. TFMAP [12] uses tensor factorization to model implicit feedback data with contextual in-formation, and directly maximizes mean average precision under a given context. In CLiMF [13] , the model parameters are learned by directly maximizing the Mean Reciprocal Rank and in CofiRank [14], the authors fit a maximum margin matrix factorization model to minimize the upper bound of NDCG. In [3], the authors extract features for a given ( u, i )pairfromuser u  X  X  k -nearest neighbors who have rated item i . They use rating-based user-user similarity metric (e.g. Vector Space Similarity) to find neighbors for a target user. Their work has some drawbacks. First, they can not well define user-user similarity when user X  X  feedbacks are not numerical scores. Second, they choose neighbors by rating-based user-user similarity metric, which is not corresponding to the ultimate goal of ranking. Our work is different from their work. We choose neighbors with similar preference pattern rather than rating pattern. The problem with rating oriented approaches is that the focus has been placed on approximating the ratings rather than the rankings, but ranking is a more important goal for modern recommender systems. In this section, we will discuss our ranking-based collaborative ranking frame-work. Since users and items are not easy to be represented in term of explicit features, we should design new method to extract efficient feature for ranking. We extract features from neighbors of a target user to capture the local infor-mation from the neighborhood. 3.1 Neighborhood Models In some movie recommendation systems, us ers rate movies with non-numerical values, e.g., A, B, ..., F . There is no direct resemblance this kind of feedback to numerical or binary values. Furthermore, we argue that even when the feedback is related to absolute numbers, taking the scores as numerical may not reflect the users X  intentions well. Different user s tend to have different internal scales. For example, taking star ratings as numeric will put the same distance between 3 stars and both 4 stars and 2 stars. However, one user can take 3 stars as similar to 4 stars, while another user strongly relates 3 stars to low quality, being similar to 1-2 stars. Computing user-user similarity is difficult in this scene. Moreover, the rating-oriented neighborhood models focus on rating prediction rather than ranking. Since we should complete a collaborative ranking task, we prefer a ranking-based user-user similarity metric to choose neighbors for users. In the ranking-oriented approach, two users with similar preferences over the items are more close. The preference is reflected by their ranking of the items. We modify the Kendall Tau Correlation Coefficient [6,7] to qualify the user-user similarity. We define the user-user similarity as: where The similarity is defined as the ratio between the number of concordant pairs M with the number of dis-concordant pairs N uv and its value is in the range of [0 , 1]. We can compute the user-user simila rity even that the users X  feedbacks are non-numerical scores from the definition. From the ranking-based user-user similarity definition, we can see that if two users assign on four items with ratings { totally different ranking-based preference. While the user-user cosine similarity between the two users is 0.77, they will be treated as very similar users. We can see that ranking-based user-user similarity is very different from rating-based user-user similarity. Choose neighbors from ranking-based neighborhood is more close to the essence of ranking. Given a target user u , we should carefully choose neighbors for her/him, and those users who have high rating-based similarity and low ranking-based similarity with the target user should not be put into u  X  X  neighborhood. The ranking-based neighbors can give more significant and accurate ranking information about items and contribute more information for feature extraction. 3.2 User-Item Feature Extraction In this section, we use the ranking-based neighbors to extract the features for user-item pairs. A feature vector  X  ( u, i ) for a user-item pair ( u, i ) is extracted basedonthe K nearest ranking-based neighbors K ( u, i )= { u k } K k =1 of user u who have rated i . The features are descriptive statistics information of the ranking of item i .Everyneighbor u k of user u has her/his opinion on the ranking of item i . For every item j ( j = i )in u k  X  X  profiles, u k has her/his preference over item i and item j . We aggregate K neighbors X  opinions and extract statistics information from their opinions as features. We summarize the preference for i into three K  X  1 matrices W ui ,T ui and L ui : The three matrices describe the relative preference for i across all the neighbors of u . Then we summarize all matrices with a set of simple descriptive statistics. where  X  is mean function,  X  is the deviation function, max and min are the maximize and minimize function. The last term counts the number of neighbors who express any preference towards i . We convert neighbors X  ratings on i to pref-erence descriptive features in this way. A fter concatenating the three statistics features we have the last feature representation for ( u, i ): The features are descriptive statistics information for the ranking of item i . Since these feature are statistics of neighbors X  opinions on the ranking of items and our experiment show that they are very robust. It is obvious that ranking-based neighbors will give more significant and accurate ranking information than rating-based neighbors in this feature extraction setting. After we have extracted features for every user-item pairs, we can use any learning to rank algorithm to learn a ranking model and make recommendation. We will introduce the procedure in the next part. 3.3 Learn and Prediction We use a simple linear function as our prediction function. The output of the pre-diction function indicates the relative position of items. The prediction function is: where w and w 0 is the ranking model parameters to be learned ( w 0 is the offset term). I [ K ( u, i )=  X  ] = 1 if there are no neighbors who rate item i (corresponding to  X  ( u, i ) = 0). The bias term b 0 provides a base score for i if i does not have enough ratings in the training dataset and we can X  X  find neighbors who have rated item i . We can apply any LTR algorithm to learn the ranking model, and we use LambdaRank in our experiment because we evaluated our rank quality by NDCG. We omit the details of LambdaRank due to the lack of space and refer the reader to [15] for details description. Given a user u , we predict every item i in user u  X  X  test dataset by: where w  X  and w  X  0 is the learned ranking model. Only ratings in the training dataset are used to select the neighbors, and make predictions for the items in the validating and testing dataset. After all unrated items X  prediction ratings are computed, we can order them based on the prediction rating value and make top-K recommendation. We can see that the rating is not on a scale of 1 to 5 anymore and it represents the relative p osition of the items. Moreover, based on the ranking-based neighbor X  X  statistical feature and the personalized ranking  X  r u,i &gt;  X  r u,k . The prediction function keeps the symmetric attribute on items, so we don X  X  need use a greedy algorithm to infer the final ranking list like [6]. 4.1 Evaluation Measure Since recommendation systems often show several items to the user, a good ranking mechanism should put relevant impressions in the very top of a ranking list extremely well. So we choose Normalized Discount Cumulative Gain (NDCG) [16] metric in information retrieval as the evaluation measure, because it is very sensitive to the ratings of the highest ranked items, making it highly desirable for measuring ranking quality in recommendation system. A ranking of the test items can be represented as a permutation  X  : { 1 , 2 , ..., N } X  X  1 , 2 , ..., N } where  X  ( i )= p denotes that the ranking of the item i is p and i =  X   X  1 ( p )istheitem index ranked at p -th position. Items in test dataset are sorted based on their prediction ratings. The NDCG value for a given user u is computed by: We assume that  X   X  is a permutation over the test items that are sorted on the true ratings and MDCG@K is DCG@K value corresponding to permutation  X   X  . We can see that a perfect rank X  X  NDCG value is equal to one. We set k to be 10 in all our experiments like [11,14,4] 1 . We report the macro-average NDCG@K across all users in our experiment results. 4.2 Datasets We use two well known movie ratings datasets in our experiment: Movielens100K and Movielens1M 2 . Most of the state-of-the-art ranking-based collaborative ranking algorithms also use them. The Movielens100K dataset consists of about 100K ratings made by 943 users on 1682 movies. The Movielens1M dataset consists of about 1M ratings made by 6040 users on 3706 movies. Since users in the two datasets rate at least 20 rating, the cold start users won X  X  appear. The ratings for Movielens100K and Movielens1M are on a scale from 1 to 5. Table 1 gives statistics information associated with the two datasets.

We divide the whole dataset into training dataset and Testing dataset. We randomly sample a fixed number N of ratings for every user for training test on the rest data. We sample 10 ratings from training dataset for validating and after we found the best hyper parameters, we put validating dataset into training dataset and retrain the model, then we report the rank performance on testing dataset. In our experiment, we set N as 20, 30, 40 and 50, so users with less than 30, 40, 50 and 60 ratings are removed to ensure that we can compute NDCG@10 on the testing dataset. The number of users and items after filtering for different N are reported in Table 1. 4.3 Parameters and Baselines We train our algorithm (RankWLT) using user-wise stochastic gradient descent. We update parameter with learning rate in { 1 , 0 . 1 , 0 . 01 , 0 . 001 } .Inourexperi-ment, the test performance is the best when learning rate is 0.01. Our neigh-borhood size is chosen in range [10 , 500]. We filter neighbors who have very low similarity with the target user with threshold t =0 . 05, so these users won X  X  appear in the target user X  X  neighborhood. When the neighborhood size becomes too large, no performance gain are observed.
 We compare our algorithm with Probability Matrix Factorization (PMF) and PureSVD [8]. Since TOPK-ListMLE is state-of-the-art learning to rank algo-rithm, so we also extend TOPK-ListMLE to recommendation systems based on the framework proposed by [11]. For PureSVD algorithm, the dimension of the singular value matrix  X  is 10. The user and item latent dimension size D in TOPK-ListMLE and PMF are chosen from { 5 , 10 , 15 , 20 , 50 } by cross validation We report the best rank performance of TOPK-ListMLE and the rank per-formance of PMF aiming at minimizing RMSE. We also report the best rank performance for PMF aiming at maximizing NDCG@10 (We call it RankPMF model). The user latent factor and item latent factor in TOPK-ListMLE, PMF and RankPMF are initialized as a random positive value in range [0 , 0 . 1] (we find that initializing the latent factors with positive values converges faster than initializing them with random values). 4.4 Experiment Results The experiment results are listed in Table 2 and Table 3.

We have some intuitions from the experiment results: 1. NDCG@10 increases when the sample number N increases in most of the 2. Surprisingly, PureSVD performs non-competitively compared to other meth-3. Since improvements in RMSE (Root Mean Square Error) often don X  X  trans-4. The results demonstrate the robust of the statistical features. Our algorithm 5. We have better NDCG@10 than other approaches. We have many informa-In this paper, we propose a new collaborative ranking approach. We use the statistical information of the rankings of item from user X  X  nearest neighbors as the feature representation for user-it em pairs. We use Kendall Rank Coefficient as similar metric to choose neighbors an d experimentally de monstrate the effec-tiveness of our method. Interestingly, we can address scenarios where assigning numerical scores to different types of users X  feedbacks would not be easy.
There are some future work based on this work. Since classical collaborative filtering algorithm ignores the social connections between users, but in real-world user often asks her/his friends for recommendations and user X  X  taste is influenced by friends X  taste on the social network. I ncorporating social effects in our collab-orative ranking framework is our next work. Different users in recommendation systems may vary largely. For example, the influence of neighbors on different users are very different. Considering the large difference between users, it is not the best choice to use a single ranking function to deal with all users. So we also plan to investigate how to design personalized collaborative ranking algorithm in the future.
 Acknowledgement. We thank the anonymous reviewers for helpful comments. This work is supported by the program of the National Natural Science Foun-dation of China (NSFC) under grant 60973003.

