 Behavioral targeting (BT), which aims to sell advertisers those behaviorally related user segments to deliver their advertisements, is facing a bottleneck in serving the rapid growth of long tail advertisers. Due to the small business nature of the tail advertisers, they generally expect to accurately reach a small group of audience, which is hard to be satisfied by classical BT solutions with large size user segments. In this paper, we propose a novel probabilistic generative model named Rank Latent Dirichlet Allocation (R ANK LDA) to rank audience according to their ads click probabilities for the long tail a dvertisers to deliver their ads. Based on the basic assumption that users who clicked the same group of ads will have a higher probability of sharing similar latent search topical interests , R ANK LDA combines topic discovery from users X  search behaviors and learning to rank users from their ads click behaviors together. In computation, the topic learning could be enhanced by the supervised information of the rank learning and simultaneously, the rank learning could be better optimized by considering the discovered topics as features. This co-optimization scheme enhances each other iteratively. Experiments over the real click-through log of display ads in a public ad network show that the proposed R ANK LDA model can effectively rank the audience for the tail advertisers. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  retrieval models General Terms: Algorithms, Economics, Experimentation User ranking, behavioral targeting, display ads This work was done when the first, fourth and fifth author were visiting Microsoft Research Asia. Behavioral targeting (BT) [4, 5, 9, 11] is one of the mainstream forms in online advertising. It aims to deliver the right advertisements to the right audience according to their online behaviors such as searching a nd browsing histories. Display advertising [12], which is one of the major ads delivery channels nowadays, generally appears on the Internet in the form of graphical ads, including text, images, logos, flashes, videos, etc. Due to the well-known semantic gap and the limited textual information involved in display ads, behavioral targeting is playing an important role in targeting the display ads to the right audience. The classical behavioral targeting solutions [11] pre-divide users into user segments, i.e. user cate gories, within each of which users are assumed to share similar interests. Each segment is labeled with keywords to indicate the intere sts of the users in the segment. For example, a segment labeled with  X  X ar buyer X  indicates the users in this segment may want to buy cars. For advertisers, they buy one or more user segments for their ads delivery based on the keyword descriptions of the user segments. Recently, with the rapid growth of online Customer to Customer (C2C) business, there is an emerging market of the long tail advertisers. These long tail advertisers have a co mmon characteristic: they have limited budget for their ads delivery. However, even a single user segment produced by classical be havioral targeting solutions, which has little consideration to the long tail advertisers, may have a large number of users a nd hence it is generally too large for these advertisers, who cannot afford to reach such a large number of targeted users. Thus if only by adopting classical behavioral targeting solutions, the long tail advertisers, who consist a huge and underexplored mark et in display ads, cannot be satisfied. This motivates us to study the problem of user ranking (audience ranking) according to their click probabilities over the given group of ads. Then those l ong tail advertisers may select arbitrary number of top ranked users according to their budget for ads delivery. The classical ranking algorithms , which calculate the relevance between display ads and users and then ranking according to the relevance score, are not applicable for the user ranking problem since the display ads contain little textual information. Instead, we propose to learn to rank users from their ads click behaviors, and it only relies on user features. Sp ecifically, we proposed a novel generative model RankLDA for lear ning to rank users according to their ads click probabilities from their ads click behaviors. Based on the basic assumption that users who clicked the same group of ads will have a higher probability of sharing similar latent search topical interests, the RankLDA model combines the topic discovery from users X  search behaviors and learning to rank users from their ads click behaviors together. By combining the two procedures together, on one hand, the topic discovery can benefit from the supervised inform ation of rank learning, namely users X  ads click behaviors; on the other hand, the discovered topics can serve as good features in the process of learning to rank users. Thus the two processes are mutually enhanced. Experiments with a real word search engine log with corresponding ads click through demonstrate the superiority of the R ANK LDA model over the baselines both in audience ranking and topic discovery. Furthermore, by comparing the weights of the topics, we can understand what beha viors of users tend to lead to ads clicks in the target domain. Behavioral targeting [4, 5, 9, 11] has attracted much research attention recently in online adve rtising community, especially for display advertisement. It does not rely on the contextual information of Web pages for ad delivery. Instead, it enables advertisers to target the advertisements to the right audience by leveraging users X  recent online activities such as their search queries in search engines, page views in some special Websites. For example, if we observe a user often searches queries about cell phone or visits websites about cell phone, then this user may want to buy a cell phone recently and we may deliver the ads about cell phone to him. Classical behavioral targeti ng methods [11] generally segment users into multiple user interest segments, within each of which users are assumed to share similar interests. Each segment is labeled with keywords and corre sponds to a product domain. For example, suppose there is a user segment labeled as  X  X ar buyer X , then the users are grouped into this segment because they have shown behaviors related with buying a car. Then based on the keyword descriptions of the user segments, the advertisers buy one or more user segments for their ads delivery. However, even a single user segment may have a la rge number of users, and those long-tail small advertisers cannot a fford an entire user segment. Instead, they may only want to buy a small portion of users who are most interested in their ads. Thus this results in a user ranking problem, which ranks users according to their probabilities of interest in the target ads. rank methods, which will be used in our proposed algorithms and compared baselines. The general pairwise ranking criterion is to minimize the expected empirical risk, which is the average loss over the whole training pairs. In order to overcome the over fitting problem, regularization is incorpor ated. As a result, the general criterion for pairwise ranking methods is to minimize the following objective function: where  X   X   X , X   X  is the empirical risk over all the preference pairs in the training data  X  : (  X   X ,  X  ),  X , X  X  X   X   X  X  X  X   X   X   X  is the prediction function, and  X  is the corresponding feature weight vector. C is a parameter to tradeoff between minimizing empirical risk and finding a simple model,  X  X  X   X  is the  X   X  -norm of vector  X  . 
Topic models such as Latent Dirichlet Allocation (LDA) [1] are used to extract latent semantic topics within a corpus. Most of the existing models built on LDA are unsupervised methods, which all rely on the co-occurrence of words, and don X  X  rely on any supervised information. Recently, some models that combine the unsupervised process in LDA and supervised information together are proposed [2, 6]. In [2], Blei et al. proposed a supervised topic model (sLDA), in which each docume nt is paired with a response. In sLDA, for each document, the wo rds are generated in the same manner as that in the classic LDA, and then a response variable is generated based on the topics of the document. The goal of sLDA is to jointly discover the latent topics in documents and infer latent topics predictive of the re sponse. The most similar work with R ANK LDA model is the relational topic model (RTM) [3], which models the generation of documents and the links between them. However, RTM is a pure unsupervised model and focuses on link prediction while R ANK LDA integrates supervised information from users X  ads click behaviors and focuses on ranking, which is different from ex isting variants of LDA model. In this section, we descri be our model for learning to rank audience. We first formally fo rmulate the audience ranking problem and then introduce a novel model, which is named Rank Latent Dirichlet Allocation (R ANK LDA), for ranking users domain. 
The audience ranking problem aims to rank users according to their ads click probabilities. Specifically, we formally defined the problem as below: Given a group of ads in the target domain and a collection of users that viewed one of these ads at least once, each user u is represented with a feature vector x , which is extracted from his search behaviors, including search queries and the titles of the clicked URLs. Audience ranking aims to rank users according to a ranking score  X   X   X   X   X  X   X   X  , where  X  is the feature weight vector. 
In order to learn to rank audien ce, we collect training data from their ads click behaviors. Given a group of ads, if two users  X   X  both viewed the ads, but  X   X  clicked the ads and  X   X  did not click Additionally, we associate each user preference pair with a confidence score  X   X  X  X  , which is used to measure the confidence that  X  is more interested in this group of ads than  X   X  , and is defined as: where  X  X  X  X  X   X  and  X  X  X  X  X  X   X  are the number of clicks and logistic function  X   X   X   X   X  X  X  X  X 1/ X 1 X  X xp  X  X  X  . training data P can be formally defined as: In this subsection, we describe the proposed R ANK LDA model for user ranking, which is a probabilistic generative model that jointly models topic di scovery from users X  search behaviors and learning to rank users from their ads click behaviors. The Notations to be used is summarized in Table 1. Notation Description Our R ANK LDA model combines topi c discovery from users X  search behaviors and learning to rank users from their ads click behaviors together. The intuition that combines the two processes together is that users who both clicked the same group of ads have a higher probability of sharing similar search topical interests, thus the topic discovery from users X  search behaviors can benefit from their ads click behaviors; meanwhile, the learning of user ranking can also be better opt imized by using the discovered topics as users X  features. Specifically, the model consists of two parts: the modeling of topic discovery from users X  search behaviors and the learning to rank users from their ads click behaviors. For the topic discovery, each user i with search profile  X  is generated as the manner in the classic LDA model [1]; for the user ranking, a response variable y  X  X  X   X 1 is generated for each the domain and user j did not. The graphical representation of R ANK LDA is presented in Figure 1, and the detailed generative process is summarized as: where  X   X   X   X / X 1  X   X   X   X  X   X   X   X  X  X  X  ,  X   X   X   X   X  X  X  X  X 1/ X 1 X  X xp  X  X  X  is the logistic function ,and  X   X  X  X   X  X   X   X   X   X   X  X   X   X   X   X  . Given model parameters , X  X  X  X  X   X   X   X   X   X  X  X  X   X  , X  X  X  , the joint probability of the observed and hidden variables is: The learning process for R ANK LDA is to maximize the log likelihood of the observed variables logP X   X   X   X   X   X  X  X  X   X  In order to maximize this objective function, we adopt Expectation Maximization (EM) al gorithm, which is composed of two key steps: E-step and M-step. In the E-step, we aim to calculate the posterior distribution of the latent variables. In the M-step, we aim to maximize the expectation of the log complete likelihood over the distribution calculated in E-step. However, as its counterpart in the conventional LDA learning [1], in the E-step, the posterior distribution of latent variables is computational intractable. Thus we resort to the variational inference method, which tries to minimize the KL-divergence between the approximated and the true posterior distribution of latent variables. Specifically, we adopt the mean-field variational inference [8], which is generally used in the classical LDA model. The mean-field variational inference forms a factorized distribution over the latent variables, which is expressed as:  X  X Dirichlet  X   X   X   X ,  X   X  X  X  X  X  X  X  X  X  X  X  X  X  X   X   X  . So the objective is to find the optimum  X  X , X  X  X  such that q  X   X , X  |  X , X   X  can be the best approximation of conditional distribution  X  X , X | X ,P X  X  X  . Based on the Jensen inequality [7], we can find a lower bound of the log likelihood. Besides, the difference between the log likelihood and the lower bound is th e KL divergence between the variational posterior pr obability and the true posterior probability, i.e. where L  X   X , X ;  X   X  is the lower bound of the log likelihood and can be calculated as below: 
L  X   X , X ;  X   X   X  X   X   X  X og X   X   X   X   X ,  X  , X   X   X   X  X  X  X   X   X  X ,  X  X  X   X  For the last five terms on th e right-hand side of above equation, we can calculate them as the way introduced in standard LDA [1], so we only need to focus on calculating the first term, in which  X   X   X c  X  X  X   X  X  X  X  X  X   X  X  X   X  X  X 1 X   X   X   X ,  X   X  , X  X  X  X  X  X c  X  X  X   X   X   X  X  X  X  X  X  X   X   X  To calculate the expectation, we adopt the method introduced in [10], which uses the variational method again with the following variational bound [8]: where  X  is the free variational parameter, and g  X   X   X   X  X  X   X  In order to minimize the KL-divergence between the variational maximize L  X   X , X ;  X   X  with respect to  X  X  X  X   X  X  X   X , X , X  X  X  . We omit some derivations here and just lis t the final update equations: For user i who clicked ads:  X   X  X  exp X   X  c  X  X  X  For user j who did not click ads:  X   X  X  exp X   X  c  X  X  X  where  X  X  X  means the element-wise product between  X  and  X  . For the learning of R ANK LDA, the variational EM algorithm is adopted, the detail updating equations are summarized as below: Update equation for  X  : The updated equations for the parameters , X   X   X  same as in the classic LDA [1]. Given a set of users together with their search behaviors, how should we rank these users with the estimated model  X  ? Firstly, for each user with profile  X  , we need to estimate the topic proportion of the user. Thus we approximate the posterior distribution of latent variables  X  X , X | X ,P X  X  X  with factorized distribution q  X   X , X  |  X , X   X  and by minimizing the KL divergence between the two distributions we can estimate the optimum  X , X  . Then the ranking score  X  X  X  X  for user with profile  X  is calculated as: In this section, we elaborate on the experiments for audience ranking. We first introduce the dataset used, and then describe the evaluation metrics. For the performance of user ranking, we compare R ANK LDA with pairwise learning to rank methods with BOW features and topics discovered by LDA respectively. Our dataset is an integration of two data sources. One is the query log of a commercial search engine, which records the search behaviors of search engine users. The other data source is the advertisement click-through log in corresponding ad network using the display ads as the ads delivery channel. The two datasets have overlapped user IDs for us to identify the unique users. To avoid the privacy issues, only the abstract user IDs are used and no other user inform ation such as demographic and geographic are used. In other wo rds, the dataset contains both users X  ad click information in a di splay ads X  ad network and users X  search behaviors in corresponding search engine of the ad network. The advertisements we used for research purpose are a group of ads in the  X  X uto insurance X  domain. There are 43 different ads in this group. Our dataset is preprocessed in three steps. First, we extract all the users that viewed any ads in this group at least once range from 20 th to 26 th of September 2010 and extract the number of clicks and impressions for each user from display ads click through log. S econd, we extract the search behaviors of these users between 13 th to 19 th of September 2010, including search queries and the clicked URLs, from a corresponding commercial search engi ne query log. We filter out users that did not have any behaviors during this period. Finally, we extract the titles of all the we bpages that have been clicked by these users. Through this way we get a total number of 1,935,534 unique users with 5,294,484 ad impressions in display ads and 1,912 ad clicks. Thus the average cl ick through rate (CTR) for this group of ads is 0.036% and the ratio of user who clicked ads is 0.090%. With respect to users X  search behaviors, the number of average queries and clicked URLs for each user is 6.6 and 6.1 respectively. The evaluation aims to measure the effect of improving average user CTR for advertisers who only buy a small part of users that are most likely to click the ads. We evaluate the performance of the improvement of users X  average CTR. Firstly, based on the ranking result, we calculate the average CTR of users who are ranked in the top 20%, denoted by CTR@20%, i.e., where  X  X  X   X  is the CTR of user u, which is calculated by: and  X  X  X  X  X   X   X  X  X  X  X  X ,  X  are the number of clicks and impressions for user u respectively, and  X , X  are the average number of users X  clicks and impressions respec tively, which are the smoothing coefficients that are defined globally for all users as done in [5]. In our dataset,  X 9.88 X 10  X   X  X   X 2.74  X  and . The definition of CTR@40%, CTR@60%,..,CTR@100% can be defined similarly. In order to calculate the CT R improvement after user ranking, we compare CTR@20% with the average CTR of the whole users, i.e., CTR@100%. We define: By observing the value of Impr@20%, we can see how much average user CTR can be improved if the advertisers only buy the segment of users who are ranked in top 20%. The pairwise learning to ra nking method introduced in Section 2.2 can be used to rank users directly with any kinds of user features. We provide two kinds of user features:  X  X ag-of-words X  (BOW) and topic discovered by classic LDA with the corresponding topic weight as f eature value. We summarize our baselines as below: dataset with our R ANK LDA model. Figure 2 shows the average results. We can see that after user ranking, users ranked in higher positions have higher ads CTR, whic h proves that user ranking is effective in ranking users accordi ng to their ads click probabilities and hence can help find better small user segments. 
Figure 2: Average user CTR with different percent of top Table 2 lists the result of audience ranking with Impr@20% metric. We can see that no matter how many topics we choose, the performance of R ANK LDA or Topic+Pairwise ranking method is consistently better than that of BOW+Pairwise ranking. This proves that topics can serve as better features than  X  X OW X . Furthermore, the performance of R ANK LDA is much better than the Topic+Pairwise ranking method. As mentioned previously, R ANK LDA combines the topic discovery from users X  search behaviors and learning to rank users from their ads click behaviors together, and the two proce sses are mutually enhanced. In Table 3, we compare the topics that discovered by Topic+Pairwise ranking and the R ANK LDA model respectively. For both models, we have a weigh ting vector associated with the features, i.e., the topics. The weight of each topic reflects its importance in influencing users X  ad s click behaviors, and thus we rank the discovered topics according to their weights in descending order, and finally we choose the topics ranked in the top three positions. The discovered topics with both models in  X  X uto insurance X  domain are listed in Table 3. The topics discovered by Topic+Pairwise ranking are quite general, such as  X  X ar X ,  X  X nsurance X , and  X  X ravel X . On the contrary, R ANK LDA integrates supervised information which are users X  ads click behaviors and the topics are much more specific. For example, the topic  X  X ar insurance X  is a self -contained topic discovered by R ANK LDA, while the baseline met hod treats it as two separate topics:  X  X ar X  and  X  X nsurance X . The discovered topics tell us that people who pay attention to car insurance, travel, and health &amp; kids are most likely to click the ads in  X  X uto insurance X  domain. In this paper, we investigated the problem of learning to rank audience for behavioral targeti ng in display ads. By ranking audience according to their probabilities of interest over the given appropriate portion of top ranked users for their ads delivery. We proposed a novel audience rank mode l referred to as Rank Latent Dirichlet Allocation (R ANK LDA). R ANK LDA well integrates the process of topic discovery from users X  search behaviors and also learning to rank audience from their ads click behaviors. By the joint process, the two tasks are mutually boosted. We performed a large scale evaluation study based on a commercial search engine log and also the corresponding display ads click through log. The experimental results well demonstrated that the R ANK LDA model outperforms the baselines both in audience ranking and topic discovery. [1] D. Blei and J. Lafferty. Latent dirichlet allocation. In Journal [2] D. Blei and J. Lafferty. Supervised topic models. In [3] J.Chang and D. Blei. Relation topic models for document [4] T. Chen, J. Yan, G.Xue, and Z. Cheng. Transfer learning for [5] Y. Chen, D. Pavlov, and J. F. Canny. Large-Scale Behavioral [6] X. Gu, S. Yang, and H. Li. Na med entity mining from click-[7] M. Jordan, editor. Learning in Graphical Models. MIT Press, [8] T. Jaakkola. Variational methods for inference and [9] N. Liu, J. Yan, D. Shen, D. Chen, Z. Chen, and Y. Li. [10] Y. Liu, A. Niculescu-Mizil, and W. Grys. Topic-Link LDA: [11] J. Yan, N. Liu, G. Wang, W. Zhang, Y. Jiang, and Z. Chen. [12] Wikipedia. http://en.wikipedia .org/wiki/Display_advertising
 Behavioral Targeting (BT) is a recent trend of online advertising market. However, some classical BT solutions, which predefine the user segments for BT ads deli very, are sometimes too large to numerous long-tail advertisers, who cannot afford to buy any large user segments due to budget consideration. In this extend abstract, we propose to rank users according to their probability of interest in an advertisement in a learning to rank framework. We propose to extract three types of features between user behaviors such as search queries, ad click history etc and the ad content provided by advertisers. Through th is way, a long-tail advertiser can select a certain number of top ranked users as needed from the user segments for ads delivery. In the experiments, we use a 30-days X  ad click-through log from a commercial search engine. The results show that using our propos ed features under a learning to rank framework, we can well rank us ers who potentially interest in an advertisement. Categories and Subject Descriptors: H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  retrieval models ; H.4.m [ Information Systems Applications ]: Miscellaneous. General Terms: Economics, Experimentation Keywords Online Advertising, Behavioral Targeting, Learning to Rank In recent years, user-targeted ad vertising is booming in industrial circles by collecting and analyzing user data in many aspects such as online behavior, demographi c and geographic information. Among various sources of user data , the richest user behavioral data exhibit the biggest potential for further exploitation. Many major search engines are providing Behavioral Targeting (BT) [1] solutions to advertisers through acquiring BT companies or bringing behavioral targeting technique into their existing products. Generally speaking, the output of many BT solutions is hundreds of user segments, within each of which users are believed to have similar interests. Then, each segment is given a snippet or name like  X  X ports ent husiasts X  for advertisers to judge which segments they should buy for ads delivery. However, in this way, the relatedness between the user segment and the advertiser is assessed by human experience rather than from data mining directly. Moreover, since a single user segment can have millions of users, long-tail advertisers may not have enough budgets to buy a complete segment. They are supposed to know which part of users in a segment is the best audience desired by them, which results in a user ranking problem. In this paper, we propose to rank users according to their potential interests on a given advertisement. Similar to the learning to rank problem in the field of inform ation retrieval for document ranking, we consider our proble m in the same framework by treating  X  X ds X  as  X  X ueries X  and  X  X sers X  as  X  X ocuments X . We propose three types of features based on the user behavioral data and the ad content. The behavioral data include users X  query history and ad click history. The first type of features reflects the direct content matching between user s X  behavioral data and the ad content. For the second type of features, we map both user behaviors and ads contents into high-level topics and then compute their topic similarity. Finally, the third type of features gives some priori user behavioral statistics, e.g. global ad click-through rate (CTR), a high value of which indicates that the user may have habit to view ads and perform clicks. Using these user behavior oriented features, we us e a subset of ads together with users who ever viewed or clicked these ads as training data to learn a user ranking model. The experimental results show that using our proposed features under a learning to rank framework, we can well rank users who potentially interest in an advertisement. Suppose an advertiser from a certain industry wants to run his ad campaigns online and comes to an online ad publisher (e.g. a search engine or an ad netw ork). He knows much about his products which are going to be advertised, but has no idea about the online audience. There are billions of people on the Internet, and hence it is impossible and unaffordable to deliver his ads to all of them. Although he may buy so me predefined user segments with descriptions from the BT companies, the number of user could be large for many long-tail advertisers. The cost of buying user segments will exceed his budget. To make efficient use of his budget, he wants to find a smaller part of best audience within a user segment, and only displays ads to them during online activities. To address this prob lem, we propose a user ranking mechanism according to the advertiser X  X  ad campaigns. Analogous to learning to rank documents in document retrieval [2], in the user ranking problem, there should be queries, document repository, relevance label definition and feature set. In terms of learning to rank audience, the  X  X uery X  is the advertisement a . An online user u is treated as a  X  X ocument X , with the label l representing whether this user has viewed or clicked the given ad, where l =-1 stands for the user u has never viewed a , l =0 stands for u has viewed a but did not click it, and l =1 stands for u has viewed a and clicked it. In this work, we make use of two types of behavioral data: user search query history and user ad click history. Features are extracted from the ad and these behavioral data simulta neously. We list the description of all three types of features we propose to use in Table 1. Using this set of features, which are represented by a feature vector x , for each model under the learning to rank framework. And then, for any new ad and all candidate users, we can rank the audience according to their probability to click the given ad. No. feature name description After surveying existing learning to rank methods, we choose Ranking SVM [2] as our main me thod due to its proven efficacy in prior research. Running Ranking SVM is equivalent to solving the following optimization problem. where the subscripts i and j are used to distinguish different feature vectors extracted from be haviors of different users. Suppose the solution of this optimization problem is *  X  and a series of For experiments, we use a data set comes from a commonly used commercial search engine which last s for a full month. It contains the fields such as user ID, query text of user, the displayed ad to user, the clicked ad by user etc. We select 100 frequently clicked ads from the ad repository for demonstration. We only consider the users who have viewed and/or clicked these 100 ads for ranking. To label users for experiment s, if a user clicked an ad, he is labeled as relevant to the ad; the users who have been displayed the ad but did not click are labele d as irrelevant. For all users correlate to the 100 ads, we cr eate the profile for each user, including the user query history and ad click history. Then, for each ad, we extract the 14 features defined in Table 1to train the ranking model. We rando mly divide the whole user dataset into 5 folds and we run the experiments for 5 times. In each round, 1 fold is used as testing dataset an d others are used for training. Figure 1 shows the normalized distributions of relevant users in the ranking list. The x-axis indicates positions in the ranked list. The y-axis indicates the proportion of relevant users in a specific position over the 100 ads. From the figure we can see that through using our audience ranking solu tion, more relevant users are ranked to higher positions. Over the 100 ads and all related users in our dataset, the averaged ad CTR is about 2.02%. After ranking, at the first position of each ad, CTR of ad is as high as 16.7% and 11.2% at the second position. This means we can well rank users who potentially interest in an advertisement. In this paper, we propose a novel user ranking problem to answer  X  X hom to deliver ads X  for online advertisers. We utilize the user behavioral data including user search query history and ad click history to create the user profile. 14 features are defined and extracted between user profile a nd the content of a given ad. We then embed the user ranking problem into the learning to rank framework and employ Ranking SVM to obtain the ranking model. Experimental results show that our approach can effectively rank the relevant users on top. [1] J. Yan, N. Liu, G. Wang, W. Zhang, Y. Jiang, and Z. Chen. [2] R. Herbrich, T. Graepel, and K. Obermayer. Large margin 
