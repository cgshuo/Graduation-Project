 Texture learning and synthesis are important tasks in computer vision and graphics. Recent attempts can be categorized into two different styles. The first style emphasizes the modeling and understand-ing problems and develops statistical models [1, 2] which are capable of representing texture using textons and their spatial layout. But the learning is rather sensitive to the parameter settings and the rendering quality and speed is still not satisfactory. The second style relies on patch-based rendering techniques [3, 4] which focus on rendering quality and speed, but forego the semantic understanding and modeling of texture.
 This paper aims at texture understanding and modeling with fast synthesis and high rendering qual-ity. Our strategy is to augment the patch-based rendering method [3] with nonparametric Bayesian modeling and statistical learning. We represent a texture image by a 2D Hidden Markov Model (2D-HMM) (see figure (1)) where the hidden states correspond to the cluster labeling of textons and the transition matrix encodes the texton spatial layout (the compatibility between adjacent textons). The 2D-HMM is coupled with the Hierarchical Dirichlet process (HDP) [5, 6] which allows the number of textons (i.e. hidden states) and the complexity of the transition matrix to grow as more training data is available or the randomness of the input texture becomes large. The Dirichlet pro-cess prior penalizes the model complexity to favor reusing clusters and transitions and thus regular texture which can be represented by compact models. This framework (HDP-2DHMM) discovers the semantic meaning of texture in an explicit way that the texton vocabulary and their spatial layout are learnt jointly and automatically (the number of textons is fully determined by HDP-2DHMM). Once the texton vocabulary and the transition matrix are learnt, the synthesis process samples the latent texton labeling map according to the probability encoded in the transition matrix. The final image is then generated by selecting the image patches based on the sampled texton labeling map. Here, image quilting [3] is applied to search and stitch together all the patches so that the boundary inconsistency is minimized. By contrast to [3], our method is only required to search a much smaller set of candidate patches within a local texton cluster. Therefore, the synthesis cost is dramatically reduced. We show that the HDP-2DHMM is able to synthesize texture in one second (25 times faster than image quilting) with comparable quality. In addition, the HDP-2DHMM is less sensitive to the patch size which has to be tuned over different input images in [3].
 We also show that the HDP-2DHMM can be applied to perform image segmentation and synthesis. The preliminary results suggest that the HDP-2DHMM is generally useful for further applications in low-level vision problems. Our primary interest is texture understanding and modeling. The FRAME model [7] provides a principled way to learn Markov random field models according to the marginal image statistics. textures due to lack of spatial modeling. Zhu et al. [1, 2] extend it to explicitly learn the textons and their spatial relations which are represented by extra hidden layers. This new model is parametric selection which might be unstable in practice, is needed to avoid overfitting. Therefore, the learning is sensitive to the parameter settings. Inspired by recent progress in machine learning, we extend the nonparametric Bayesian framework of coupling 1D HMM and HDP [6] to deal with 2D texture image. A new model (HDP-2DHMM) is developed to learn texton vocabulary and spatial layouts jointly and automatically.
 Since the HDP-2DHMM is designed to generate appropriate image statistics, but not pixel intensity, a patch-based texture synthesis technique, called image quilting [3], is integrated into our system to sample image patches. The texture synthesis algorithm has also been applied to image inpainting [8].  X   X 
 X  ... Malik et al. [9, 10] and Varma and Zisserman [11] study the filter representations of textons which are related to our implementations of visual features. But the interactions between textons are not explicitly considered. Liu et al. [12, 13] address texture understanding by discovering regularity without explicit statistical texture modeling.
 images which also tend to model appearance and spatial layouts jointly. The major difference is that their models, which are parametric, cannot grow automatically as more data is available. Our method is closely related to [16] which is not designed for texture learning. They use hierarchical Dirichlet process, but the models and the image feature representations, including both the image filters and the data likelihood model, are different. The structure of 2DHMM is also discussed in [17]. Other work using Dirichlet prior includes [18, 19].
 Tree-structured vector quantization [20] has been used to speed up existing image-based rendering algorithms. While this is orthogonal to our work, it may help us optimize the rendering speed. The meaning of  X  X onparametric X  in this paper is under the context of Bayesian framework which differs from the non-Bayesian terminology used in [4]. 3.1 Image Patches and Features A texture image I is represented by a grid of image patches { x i } with size of 24  X  24 in this paper where i denotes the location. { x i } will be grouped into different textons by the HDP-2DHMM. We begin with a simplified model where the positions of textons represented by image patches are pre-determined by the image grid, and not allowed to shift. We will remove this constraint later. Each patch x i is characterized by a set of filter responses { w l,h,b i } which correspond to values b of image filter response h at location l . More precisely, each patch is divided into 6 by 6 cells (i.e. image filter responses which include the 17 filters used in [21], Difference of Gaussian (DOG, 4 filters), Difference of Offset Gaussian (DOOG, 12 filters ) and colors (R,G,B and L). w l,h,b i equals one if the averaged value of filter responses of the 4*4 pixels covered by cell l falls into bin b (the response values are divided into 6 bins), and zero otherwise. Therefore, each patch x i is represented the index of the responses of visual features.
 It is worth emphasizing that our feature representation differs from standard methods [10, 2] where k-means clustering is applied to form visual vocabulary first. By contrast, we skip the clustering step and leave the learning of texton vocabulary together with spatial layout learning into the HDP-2DHMM which takes over the role of k-means. 3.2 HDP-2DHMM: Coupling Hidden Markov Model with Hierarchical Dirichlet Process A texture is modeled by a 2D Hidden Markov Model (2DHMM) where the nodes correspond to the image patches x i and the compatibility is encoded by the edges connecting 4 neighboring nodes. denote the four neighbors, left, upper, right and lower, respectively. We use z i to index the states of node i which correspond to the cluster labeling of textons. The likelihood model p ( x i | z i ) which specifies the probability of visual fetures is defined by multinomial distribution parameterized by  X  where  X  z For node i which is connected to the nodes above and on the left (i.e. L ( i ) 6 =  X  and T ( i ) 6 =  X  ), the connected nodes. The distribution has a form of multinomial distribution parameterized by  X  where  X  z For the nodes which are on the top row or the left-most column (i.e. L ( i ) =  X  or T ( i ) =  X  ), the distribution of their states are modeled by Multinomial (  X  z can be considered as simpler cases. We assume the top left corner can be sampled from any states according to the marginal statistics of states. Without loss of generality, we will skip the details of the boundary cases, but only focus on the nodes whose states should be determined by their top and left nodes jointly.
 To make a nonparametric Bayesian representation, we need to allow the number of states z i count-ably infinite and put prior distributions over the parameters  X  z by tying the 2DHMM together with the hierarchical Dirichlet process [5]. We define the prior of  X  z as a conjugate Dirichlet prior: where  X  is the concentration hyperparameter which controls how uniform the distribution of  X  z is (note  X  z specify weights of visual features): as  X  increases, it becomes more likely that the visual features have equal probability. Since the likelihood model p ( x i | z i ) is of multinomial form, the posterior distribution of  X  z has a analytic form, still a Dirichlet distribtion.
 The transition parameters  X  z where we first draw global weights  X  according to the stick-breaking prior distribution GEM (  X  ) . The stick-breaking weights  X  specify the probability of state which are globally shared among all nodes. The stick-breaking prior produces exponentially decayed weights in expectation such that simple models with less representative clusters (textons) are favored, given few observations, but, there is always a low-probability that small clusters are created to capture details revealed by large, complex textures. The concentration hyperparameter  X  controls the sparseness of states: a larger  X  leads to more states. The prior of the transition parameter  X  z process DP (  X  0 ,  X  ) which is a distribution over the other distribution  X  .  X  0 is a hyperparameter which controls the variability of  X  z state transitions become more regular. Therefore, the HDP makes use of a Dirichlet process prior to place a soft bias towards simpler models (in terms of the number of states and the regularity of state transitions) which explain the texture.
 The generative process of the HDP-2DHMM is described in figure (3).We now have the full repre-sentation of the HDP-2DHMM. But this simplified model does not allow the textons (image patches) to be shifted. We remove this constraint by introducing two hidden variables ( u i , v i ) which indicate the displacements of textons associated with node i . We only need to adjust the correspondence between image features x i and hidden states z i . x i is modified to be x u features located at the position with displacement of ( u i , v i ) to the position i . Random variables ( u i , v i ) are only connected to the observation x i (not shown in figure 2). ( u i , v i ) have a uniform prior, but are limited to the small neighborhood of i (maximum 10% shift on one side). In a Bayesian framework, the task of learning HDP-2DHMM (also called Bayesian inference) is because of their uniform prior. For simplicity, we skip the details of sampling u, v . Here, we present an inference procedure for the HDP-2DHMM that is based on Gibbs sampling. Our procedure global weights  X  . Given fixed values for z,  X  , the posterior of  X  can be easily obtained by aggregating statistics of the observations assigned to each state. The posterior of  X  is Dirichlet. For more details on Dirichlet processes, see [5].
 We first instantiate a random hidden state labeling and then iteratively repeat the following two steps. Sampling z . In this stage we sample a state for each node. The probability of node i being assigned state t is given by: observations of feature w q with state t . f  X  x i t ( x i ) is calculated by: where  X  q is the weight for visual feature w q .
 generating state t is given by: where  X  t refers to the weight of state t . This calculation follows the properties of Dirichlet distribu-tion [5].
 in a similar form as equation (8).
 Sampling  X  . In the second stage, given the assignments z = { z i } , we sample  X  using the Dirichlet distribution as described in [5]. Figure 4: The color of rectangles in columns 2 and 3 correspond to the index (labeling) of textons which Once the texton vocabulary and the transition matrix are learnt, the synthesis process first samples the latent texton labeling map according to the probability encoded in the transition matrix. But the HDP-2DHMM is generative only for image features, but not image intensity. To make it practical for image synthesis, image quilting [3] is integrated with the HDP-2DHMM. The final image is then generated by selecting image patches according to the texton labeling map. Image quilting is applied to select and stitch together all the patches in a top-left-to-bottom-right order so that the boundary inconsistency is minimized . The width of the overlap edge is 8 pixels. By contrast to [3] which need to search over all image patches to ensure high rendering quality, our method is only required to search the candidate patches within a local cluster. The HDP-2DHMM is capable of producing high rendering quality because the patches have been grouped based on visual features. Therefore, the synthesis cost is dramatically reduced. We show that the HDP-2DHMM is able to synthesize a texture image with size of 384*384 and with comparable quality in one second (25 times faster than image quilting). 6.1 Texture Learning and Synthesis We use the texture images in [3]. The hyperparameters {  X ,  X  0 ,  X  } are set to 10, 1, and 0.5, respec-tively. The image patch size is fixed to 24*24. All the parameter settings are identical for all images. The learning runs with 10 random initializations each of which takes about 30 sampling iterations to converge. A computer with 2.4 GHz CPU was used. For each image, it takes 100 seconds for learning and 1 second for synthesis (almost 25 times faster than [3]).
 Figure (4) shows the inferred texton labeling maps, the sampled texton maps and the synthesized texture images. More synthesized images are shown in figure (5). The rendering quality is visually comparable with [3] (not shown) for both structured textures and stochastic textures. It is interesting to see that the HMM-HDP captures different types of texture patterns, such as vertical, horizontal and grided layouts. It suggests that our method is able to discover the semantic texture meaning by learning texton vocabulary and their spatial relations. 6.2 Image Segmentation and Synthesis We also apply the HDP-2DHMM to perform image segmentation and synthesis. Figure (6) shows several examples of natural images which contain mixture of textured regions. The segmentation results are represented by the inferred state assignments (the texton map). In figure (6), one can see that our method successfully divides images into meaningful regions and the synthesized images look visually similar to the input images. These results suggest that the HDP-2DHMM framework is generally useful for low-level vision problems. The last row in figure (6) shows a failure example where the texton is not well aligned. This paper describes a novel nonparametric Bayesian method for textrure learning and synthesis. The 2D Hidden Markov Model (HMM) is coupled with the hierarchical Dirichlet process (HDP) which allows the number of textons and the complexity of transition matrix grows as the input tex-ture becomes irregular. The HDP makes use of Dirichlet process prior which favors regular textures by penalizing the model complexity. This framework (HDP-2DHMM) learns the texton vocabu-lary and their spatial layout jointly and automatically. We demonstrated that the resulting compact representation obtained by the HDP-2DHMM allows fast texture synthesis (under one second) with comparable rendering quality to the state-of-the-art image-based rendering methods. Our results on image segmentation and synthesis suggest that the HDP-2DHMM is generally useful for further applications in low-level vision problems.
 Acknowledgments. This work was supported by NGA NEGI-1582-04-0004, MURI Grant N00014-06-1-0734, ARDA VACE, and gifts from Microsoft Research and Google. Thanks to the anonymous reviewers for helpful feedback. [1] Y. N. Wu, S. C. Zhu, and C.-e. Guo,  X  X tatistical modeling of texture sketch, X  in ECCV  X 02: [2] S.-C. Zhu, C.-E. Guo, Y. Wang, and Z. Xu,  X  X hat are textons? X  International Journal of [3] A. A. Efros and W. T. Freeman,  X  X mage quilting for texture synthesis and transfer, X  in Siggraph , [4] A. Efros and T. Leung,  X  X exture synthesis by non-parametric sampling, X  in International Con-[5] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei,  X  X ierarchical dirichlet processes, X  Journal [6] M. J. Beal, Z. Ghahramani, and C. E. Rasmussen,  X  X he infinite hidden markov model, X  in [7] S. C. Zhu, Y. Wu, and D. Mumford,  X  X ilters, random fields and maximum entropy (frame): [8] A. Criminisi, P. Perez, and K. Toyama,  X  X egion filling and object removal by exemplar-based [9] J. Malik, S. Belongie, J. Shi, and T. Leung,  X  X extons, contours and regions: Cue integration in [10] T. Leung and J. Malik,  X  X epresenting and recognizing the visual appearance of materials us-[11] M. Varma and A. Zisserman,  X  X exture classification: Are filter banks necessary? X  IEEE Com-[12] Y. Liu, W.-C. Lin, and J. H. Hays,  X  X ear regular texture analysis and manipulation, X  ACM [13] J. Hays, M. Leordeanu, A. A. Efros, and Y. Liu,  X  X iscovering texture regularity as a higher-[14] N. Jojic, B. J. Frey, and A. Kannan,  X  X pitomic analysis of appearance and shape, X  in In ICCV , [15] A. Kannan, J. Winn, and C. Rother,  X  X lustering appearance and shape by learning jigsaws, X  in [16] J. J. Kivinen, E. B. Sudderth, and M. I. Jordan,  X  X earning multiscale representations of natural [17] J. Domke, A. Karapurkar, and Y. Aloimonos,  X  X ho killed the directed model? X  in IEEE [18] L. Cao and L. Fei-Fei,  X  X patially coherent latent topic model for concurrent object segmenta-[19] X. Wang and E. Grimson,  X  X patial latent dirichlet allocation, X  in NIPS , 2007. [20] L.-Y. Wei and M. Levoy,  X  X ast texture synthesis using tree-structured vector quantization, X  [21] J. Winn, A. Criminisi, and T. Minka,  X  X bject categorization by learned universal visual dictio-
