 This pap er presen ts a unifying probabilistic framew ork for clustering individuals or systems in to groups when the a v ail-able data measuremen ts are not m ultiv ariate v ectors of xed dimensionalit y . F or example, one migh tha v e data from a set of medical patien ts, where for eac h patien t one has a set of of observ ed time-series, eac h time-series of p oten tially di eren t length and di eren t sampling rate. W e prop ose a general mo del-based probabilistic framew ork for cluster-ing data typ es of this form whic h are non-v ector in na-ture and ma y v ary in size from individual to individual. The Exp ectation-Maximization (EM) pro cedure for clus-tering within this framew ork is discussed and w e discuss ho w it b e applied in a general manner to clustering of se-quences, time-series, tra jectories, and other non-v ector data. W e sho w that a n um b er of earlier algorithms can b e view ed as sp ecial cases within this unifying framew ork. The pap er concludes with sev eral illustrations of the metho d, including clustering of red blo o d cell data in a medical diagnosis con-text, clustering of proteins from curv es of gene expression data, and clustering of individuals based on their sequences of W eb na vigation.
 Clustering, Mixture Mo dels, EM Algorithm Clustering is a fundamen tal and widely applied metho dol-ogy in understanding and exploring large data sets. Clus-tering algorithms are typically applied to v ector measure-men ts of xed dimension. F or example, w e ma y ha v e d measuremen ts on a set of medical patien ts and w e repre-sen t the measuremen ts on individual i as a d -dimensional v ector. F or suc h data there are a w ealth of di eren t clus-tering tec hniques a v ailable, b oth mo del-based metho ds (e.g., F raley and Raftery , 1998) and distance-based metho ds (e.g., Jain and Dub es, 1986).
 In this pap er w e are in terested in the problem of cluster-ing individuals giv en observ ed data ab out the individuals, where the observ ed data do es not naturally o ccur in v ec-tor form (w e elab orate on this b elo w). W e use the w ord \individuals" in a broad sense; it can encompass h umans, animals, organisms, organizations, natural phenomena, me-chanical systems, and so forth. Sp eci c examples include clustering individuals based on their observ ed W eb bro ws-ing b eha vior (Cadez et al., 2000), clustering animals giv en b eha vioral observ ations (Haccou and Meelis, 1992), cluster-ing extra-tropical cyclones based on their temp oral ev olution (Blender et al., 1997), and clustering genes from expression data (Eisen et al., 1998). Clearly there is a notion of eac h individual in a sense represen ting a dynamic system and w e wish to cluster these systems based on observ ations of their dynamic b eha vior.
 Standard v ector-based clustering tec hniques are not directly applicable to this t yp e of clustering problem since the data arises in non-v ector form (as sequences, time-series, tra jec-tories, etc.) and w e can ha v e di eren t amoun ts of observ ed data for di eren t individuals. T able 1 sho ws an example of suc h data. The data represen t categorized page requests from traces of W eb na vigation for di eren t individuals. Eac h individual is c haracterized b y di eren t sessions (di eren t se-quences) and eac h of these sequences v aries in length. W e w ould lik e to b e able to cluster individuals in to groups based on their observ ed na vigation b eha vior|but it is not ob vious ho w one w ould go ab out this in a principled manner. Our goal in this pap er is to form ulate a general mo del-based clus-tering framew ork for clustering individuals when the data are non-v ector of nature and di eren t \sizes" for di eren t individuals, as in this example. One approac h to clustering in this con text is the \feature-v ector" approac h, namely , to reduce the observ ed data to feature v ectors of xed dimensionalit y and use standard m ul-tiv ariate clustering tec hniques to cluster individuals giv en this represen tation. F or example, Blender et al (1997) rep-resen t extra-tropical cyclones as a concatenation of 3 da ys w orth of ( x; y ) latitude-longitude pairs, spaced at 6-hour in-terv als, to yield a 24-dimensional represen tation of eac h cy-clone. The k -means clustering algorithm w as then applied in
Permission to make digital or hard copies of part or all of this work or permission and/or a fee.

KDD 2000, Boston, MA USA  X  ACM 2000 1 -58113 -233 -6/00/0 8 ...$5.00 this 24-dimensional space to nd clusters of cyclones. Simi-larly , Eisen et al. (1999) represen t gene expression data from di eren t time-course exp erimen ts as xed-dimensional v ec-tors. Agglomerativ e hierarc hical clustering is then applied to nd clusters of genes using a v ector distance measure. Al-though in teresting scien ti c insigh ts w ere pro duced in b oth of these cases, w e argue that this \v ector metho dology" is not necessarily appropriate or adequate for clustering dy-namic b eha vior. In particular, for sequen tial or temp oral data, the con v ersion to v ector form necessarily incurs a loss of information (e.g., in the examples ab o v e the temp oral ev o-lution of cyclones and genes (resp ectiv ely) is not explicitly retained in the v ector represen tation).
 Another general approac h to this problem is to de ne pair-wise distances b et w een all individuals in some manner (e.g., edit-distance for sequences) and then use distance-based clus-tering metho ds (e.g., hierarc hical). Di X culties here arise with de ning e ectiv e distance measures for complex prob-lems. F or example, if di eren t individuals ha v e di eren t amoun ts of data (e.g., v arying n um b ers of sequences p er in-dividual) there ma y b e no principled w a y to directly accoun t for this m ultiplicit y of information via a distance function. F urthermore, the hierarc hical metho ds scale as O ( N 2 ) where N is the n um b er of individuals, whic hma y b e quite imprac-tical for large N data sets.
 W e prop ose instead a general probabilistic metho dology for handling these issues, based on the framew ork of gener ative mixtur emo dels . This probabilistic framew ork is particularly useful for problems of this t yp e since it allo ws us to directly address the t w o problems men tioned ab o v e of (1) mo deling non-v ector data in its \nativ e" form, and (2) handling m ul-tiplicities of data sizes and data t yp es across individuals. Sp ecial cases of the mo del-based probabilistic framew ork presen ted in this pap er ha v e b een dev elop ed earlier for sp e-ci c classes of data t yp es and cluster mo dels. In partic-ular, the concept of using a generativ e mo del for cluster-ing non-v ector data has b een indep enden tly pursued in sev-eral di eren t con texts. F or example, in clustering sequences, P oulsen (1990) in tro duced a particular form of Mark o v mix-tures and an EM algorithm for mo deling heterogeneous b e-ha vior in consumer purc hasing data. More general v ersions of Mark o v mixtures w ere subsequen tly indep enden tly dev el-op ed b y b oth Sm yth (1997, 1999) and Ridgew a y (1997), in-cluding an EM framew ork for learning in this con text. Clus-tering of regression curv es has b een in v estigated b y Spath (1979), DeSarb o, Oliv er, and Rangasw am y (1989), W edel and Steenk amp (1991), and in a more general non-parametric form b y Ga ney and Sm yth (1999).
 The w ork presen ted here represen ts a generalization of all of the ab o v e ideas within a single uni ed framew ork. Our w ork is more general than the earlier w ork in the sense that w e explicitly discuss the case when di eren t individuals ha v e di eren t amoun ts of data, whic h is an imp ortan t factor in man y practical applications. W e note that once w e de ne a prop er lik eliho o d o v er the data of in terest, then sp eci-cation of an y sp eci c EM algorithm (for an y particular t yp e of mo del) follo ws in a direct manner from the general principles of EM (e.g., Dempster, Laird, and Rubin, 1977; McLac hlan and Krishnan, 1997). In fact the resulting EM algorithm is quite similar to the EM algorithm used tra-ditionally in mo del-based clustering with the the exception that di eren t individuals ha v e di eren t e ects on the estima-tion pro cess dep ending on ho w man y observ ations there are for eac h individual (it is somewhat in tuitiv e that this should b e so). Th us, the EM discussions in this pap er will b e quite straigh tforw ard to an y readers familiar with EM in general| for these readers w e wish to emphasize the generalit y of the approac h as evidenced b y the div erse applications (Section 5). F or readers less familiar with mo del-based clustering and EM in general, the goal of the pap er is to demonstrate that a large n um b er of non-trivial clustering problems can b e el-egan tly handled within this mo del-based EM framew ork. W e prop ose the follo wing generativ e framew ork for mo del-based clustering: As a simple (but concrete) example consider the case where for eac h individual w eha v e a set of discrete-v alued sequences, i.e., D i = f s 1 ; s 2 ;::: ; s n a di eren t length. F or example, eac h sequence could repre-sen t the observ ed record of page requests for individual i at a particular W eb site, and the di eren t sequences represen t di eren t sessions for that individual. W e can use the frame-w ork ab o v e to mo del the o v erall data-generating pro cess as follo ws: The mo del ab o v e allo ws us to mo del heterogeneous data across di eren t individuals in a fairly general framew ork. Using the mo del, our goal will b e to estimate the k (cluster parameters) and cluster w eigh ts p ( c k ) giv en only observ ed data D = f D 1 ;:: : ;D N g .
 As w e will see later in the pap er, this probabilistic frame-w ork has some distinct adv an tages o v er alternativ e metho ds for clustering individuals. F or example, clustering sequences of di eren t lengths is not problematic. The k ey idea is that ob jects are de ned to b e similar in terms of common simi-larit y to a mo del, expressed through the lik eliho o d function p ( D i j k ). Tw o ob jects are considered similar if they b oth ha v e higher lik eliho o d under one particular mo del than un-der an y other mo del. F or example, consider t w o clusters, eac h mo deled b y a Mark o v mo del, Mo del A fa v oring short runs of a 's and b 's, Mo del Bfa v oring longer runs. In this con text, a short sequence abaabab and a longer sequence baababbabbabaabaab could b oth b e considered similar rela-tiv e to the short-run mo del (A), i.e., giv en the t w o mo dels A and B there is a m uc h higher probabilit y that the t w o se-quences originated from the same short-run mo del (Mo del A) than the long-run one (Mo del B).
 W e will sho w that w e can learn the cluster mo del parameters from a data set D = f D 1 ;::: ;D N g describing N individ-uals, using an algorithm based on the EM pro cedure. W e will further sho w that this algorithm generalizes the stan-dard \v ector-based" EM algorithm for mixture mo dels in t w o directions that are en tirely in tuitiv e: (1) mem b ership probabilities are asso ciated with individuals rather than in-dividual measuremen ts, and (2) individuals with more (or less) data ha v e more (or less) in uence on the parameter estimation pro cess. In this section w e pro vide a general description of an EM algorithm that can b e applied to mixture-mo del clustering of individuals. The mo del that w e consider here is actually a sp ecial case of a Ba y esian hierarc hical framew ork for this class of clustering problems, but due to space limitations w e do not pursue this Ba y esian viewp oin t further in this pap er (see Cadez and Sm yth, 1999, for more details).
 W e use notation similar to that in tro duced in the previ-ous section. Sp eci cally , let there be N individuals and let there b e a data set D i asso ciated with eac h individual (note that w e sometimes refer to the data set D i itself as an individual ). Eac h data set D i consists of n i observ a-tions d ij ; 1 j n i , where eac h \observ ation" represen ts another smaller data subset. The data set for all individu-als is denoted D = f D 1 ;D 2 ;::: ;D N g ; with individual data D i = f d i 1 ;d i 2 ;::: ;d in i g . According to the generativ e clus-ter mo del eac h individual is assigned to a single cluster c (1 c i K ) and has an asso ciated probabilit y densit y function of: where represen ts parameters for all the clusters: = f 1 ; 2 ; ::: ; K g and where c i ,1 c i K is the cluster iden tit y of the i th individual.
 W e further assume that the observ ations are conditionally indep enden t giv en the mo del parameters, so that w e can write the probabilit y of the individual (or an individual's data), giv en that the individual b elongs to the cluster c This is equiv alen t to assuming in a W eb-bro wsing scenario (for example) that an individual's W eb na vigation patterns in an y one session are indep enden tof their patterns from previous sessions, giv en the o v erall parameters go v erning that individual. While this is an appro ximation to what is really going on (there ma y in fact b e some sequen tial session-to-session e ects) w e conjecture that it will b e a reasonably accurate and useful assumption in practice.
 W e are in terested in learning the maxim um-lik eliho o d (ML) or maxim um a p osteriori (MAP) parameter estimates giv en the data D , i.e., ML = arg max f p ( D j ) g ; and MAP = arg max f p ( D j ) p () g ; where under the usual assumption that data from di eren t individuals are conditionally inde-p enden t giv en the underlying mo del w eha v e kno wn as the lik eliho o d.
 The EM algorithm is a general tec hnique for nding ML or MAP parameters when some asp ect of the data is con-sidered \missing." In a mixture con text, the missing data consists of the cluster lab els c i for eac h individual: if w e knew these lab els then parameter estimation w ould b e quite straigh tforw ard. The EM algorithm can b e view ed as op-erating in t w o steps. In the E step one calculates class-conditional probabilities p ( c i j D i ; ) for eac h individual un-der eac h of the K cluster mo dels using the curren t v alue of the parameters . In the M step one up dates parame-ters b yw eigh ting eac h individual according to their class-conditional probabilit y . This yields a v ery in tuitiv e algo-rithm that is guaran teed to lead to a sequence of 's whic h ha v e non-decreasing lik eliho o d or p osterior probabilit y , i.e., under fairly broad conditions it will nd at least a lo cal maxim um of the ML or MAP ob jectiv e function.
 In the next section w e illustrate ho w this algorithm can b e applied to the case when w eha v e di eren t amoun ts of data for di eren t individuals. As a sp eci c example of this general framew ork, w e revisit in more detail the problem discussed in Section 3 of clustering discrete-v alued sequences, taking v alues from 1 to M . W e will assume that w e are using a mixture of Mark o vc hains mo del. Eac h individual i can ha v e n i sequences (e.g., dif-feren t observ ed sessions of W eb na vigation b eha vior). The generativ e mo del has the general mixture form describ ed in Section 4, where the comp onen t mo del for eac h observ ation in eac h cluster, p ( d ij j k ) in Equation 4, tak es the form of a Mark o v mo del p ( s j k ). W e could of course use an y sequen-tial mo del that de nes a densit y on p ossible sequences, but c ho ose the Mark o v mo del for simplicit y of illustration. The mo del parameters for eac h Mark o v cluster k consist of an initial state probabilit yv ector k ( s ) and an M M transition matrix T k ( s 2 j s 1 ), where s; s 1 ;s 2 denote discrete states, 1 s; s 1 ;s 2 M . In addition, there is a set of w eigh ts k that de nes the mixing prop ortions of the com-p onen t mo dels (previously denoted as p ( k )). The in tuition is that di eren t clusters will ha v e di eren t Mark o v b eha vior and w e wish to learn these di eren t b eha viors from observ ed sequences.
 W e follo w the general approac h outlined in Section 3 to de-ne a lik eliho o d and in Section 4 to deriv e an asso ciated EM algorithm. An imp ortan t p oin t is that this pro cedure is quite general|one simply enco des one's assumptions ab out the generativ e nature of the mo del via the lik eliho o d, and the asso ciated EM algorithm follo ws directly .
 individual, where s i;j is the j th sequence observ ed for this individual (from b efore, s i;j corresp onds to d ij , the j th sub-set of data (or observ ation) for an individual i ). F rom the de nition of a Mark o v c hain w e can de ne the lik eliho o d of an y particular sequence s i;j , conditioned on a particular cluster c i with parameters c where s i;j;l denotes the l th elemen t of the j th sequence for individual i , and L i;j is the length of the j th sequence for individual i .
 Th us, the probabilit y of all of the data D i from individual i , conditioned on cluster c i , can b e written as: in accordance with Equation 4. In the results preseneted in this pap er w e do not explicitly mo del the distribution on n , i.e., w e do not imp ose a distributional mo del on ho w man y sequences are pro duced b y mem b ers of cluster c i e ect this is equiv alen tto assuming a uniform ( at) prior on n i . In general of course one could mo del this v ariabilit y and incorp orate it in to the o v erall probabilistic mo del. Since w e do not kno w a priori whic h cluster individual i came from, the marginal probabilit y for i , giv en the mo del parameters, can then b e written in mixture mo del form as: and where the full lik eliho o d p ( D j ) can be written as a pro duct of these terms o v er i as in Equation 5.
 Equations 6, 7, 8, and 5 completely sp ecify our generativ e mo del for the observ ed data D . In this manner, a full lik e-liho o d for all of the observ ed data can b e constructed in a straigh tforw ard systematic manner b y building up rst from a mo del of an individual sequence (Equation 6), to a mo del of ho w a set of sequences are generated for an individual (Equations 7 and 8), to a mo del of ho w data for a set of individuals is generated (Equation 5).
 Once the lik eliho o d is de ned in this manner, the EM pro-cedure is relativ ely straigh tforw ard to de ne. The E-step is de ned as: p ( c i = k j D i ; ) = p ( D i via the lik eliho o d terms de ned ab o v e. The M-step b ecomes: This equation states that the new mixing prop ortions are prop ortional to the mem b ership probabilities, while the new initial state probabilities and transition probabilities are ob-tained b y coun ting initial states and transitions and w eigh-ing them b y the mem b ership probabilities. The term r s represen ts the coun t of transitions from state s 1 to state s in all the sequences asso ciated with individual i . The time complexit y of this algorithm at a high-lev el is the same as the standard m ultiv ariate EM algorithm for mix-tures, i.e., linear in the total n um ber N of individuals, in the total n um b er of observ ations b er of iterations of the EM algorithm. Within eac h iteration, for eac h observ ation, the computation of the M-step and the E-step will b e mo del-dep enden t. F or Mark o v mixtures, for example, the time complexit y is linear in the sum of the lengths of all sequences (i.e., linear in the total n um ber of discrete sym b ols observ ed), and th us the o v erall algorithm retains its linearit y . F or more complex comp onen t mo dels, the complexit y could b e higher, dep ending on the sp eci c mo del form.
 The EM algorithm as outlined ab o v e di ers in certain re-sp ects from the more commonly-used approac hes to mixture mo deling (e.g., F raley and Raftery (1998)). F or example, individuals (sets of observ ations) are clustered rather than v ectors. In the E-step of Equation 9 the mem b ership w eigh ts are asso ciated with individuals i rather than with data ob-serv ations d ij . This is quite in tuitiv e: w e can view this as ha ving the mem b erships of eac h data observ ation d ij tied to a single probabilit y mem b ership distribution for in-dividual i . This \t ying" ma y not alw a ys b e appropriate for all applications, but it is useful to b e able to enforce this if desired.
 On a related note, in the M-step, if one individual has more observ ations than another (e.g., either more sequences and/or longer sequences), then that individual's data D i will get more w eigh t in parameter estimation through the r terms in Equation 10, i.e., one individual can con tribute more e ectiv e coun ts to the estimation of parameters for group k than another individual for whic hw eha v e less data. Although it is in tuitiv e that this should be the case, it is w orth p oin ting out that the probabilistic framew ork tak es care of this issue of di eren t amoun ts of data for di eren t individuals (via the lik eliho o d mo del) in an automatic and consisten t fashion. In a non-probabilistic framew ork there is no ob viously consisten t framew ork for handling this issue. Note also that an alternativ e mo del-based clustering ap-proac h to that presen ted ab o v e is is to t parameters (for a particular mo del) to eac h individual separately . In this man-ner one obtains a p -dimensional v ector of p oin t estimates of the parameters for eac h individual. One can then p erform some form of v ector clustering (e.g., k -means or mixture den-sit y mo deling) in this p -dimensional parameter space. This approac h will in e ect treat eac h individual equally during clustering (since eac h individual is represen ted b y a single parameter v ector), despite the fact that for individuals with v ery small amoun ts of data (e.g., v ery short sequences) w e ma y get v ery noisy p oin t estimates (i.e., there will implic-itly b e relativ ely high v ariance in the parameter estimates for certain individuals). The EM approac h on the other hand estimates the group mem b erships and the parameters for eac h group at the same time, with eac h data observ ation e ectiv ely getting equal w eigh t in the estimation pro cedure (via the lik eliho o d equation). Th us, individuals with short sequences are in e ect \p o oled" during estimation with in-dividuals with longer sequences who are lik ely to be from the same group. T able 1 sho ws a small fraction of actual W eb session data obtained from a large commercial soft w are compan y . De-tails of the data are proprietary but can be c haracterized in the follo wing manner. P age-requests from a W eb-bro wser are recorded on individual's clien t mac hines and do wnloaded nigh tly to a cen tral arc hiv e. Sessions are de ned (somewhat arbitrarily) as an y set of page requests where the gap be-t w een successiv e requests do es not exceed 30 min utes. P age requests are automatically categorized in to 10 di eren t cat-egories, based on the nature of the W eb site from whic h the page is requested.
 W ein v estigated the use of Mark o v mixtures for this prob-lem. Th us, for this particular data set, w eha v e the follo wing instan tiation of our general approac h: Figure 2: This picture sho ws the actual gene expres-sion data. Note that only one-fth of the data set is displa y ed.
 The data set con tains 7,845 individuals with a total of 13,082 sessions (sequences). Eac h sequence consists of page re-quests categorized in to 10 categories (states). In the results presen ted here w e clustered the data in to k = 20 clusters. Figure 1 sho ws three join t{transition matrices summarizing three in teresting clusters. Eac h square in the gure repre-sen ts the join t probabilit y of a transition s i &gt; s information not only tak es in to accoun tho w lik ely it is that a user will go from state s i to state s j , but also ho w often the user is in state s i . The rst cluster con tains users that mostly sta y within a single category (high self transition probabilit y). The second cluster sho ws users that tend to na vigate among three di eren t categories but sta y sligh tly longer in the rst t w o. The third cluster sho ws users that mostly sta y in a single state, but o ccasionally mak e a short visit to another state.
 Viewing transition matrices is one w a y to visualize the re-sultan t clusters. F or a larger-scale study and additional re-sults with a similar t yp e of data see Cadez et al. (2000). A notable feature of the results in Cadez et al. (2000) is that clustering on sequences directly pro duced mo dels with b etter out-of-sample predictiv e po w er, than clustering on v ector-based feature represen tations (i.e., histograms). Gene expression data pro vides another direct application for our clustering framew ork. In an e ort to classify and understand the b eha vior of the h uman genome, scien tists emplo y tin y DNA microarra ys whic h a ord the placemen tof thousands of distinct genes in a compact rectangular arra y . The microarra ys allo w scien tists to test the resp onses (or expressions) of a set of v arious genes under sp eci c stim uli. At ypical gene expression data set con tains a set of sequences whose v alues measure the lev el of resp onse for a certain set of genes o v er time. F or example, a data set migh t con tain 1000 sequences measuring the resp onses of 1000 di eren t genes o v er a 24 hour p erio d. This data set migh t con tain 20 resp onse measuremen ts in eac h sequence, yielding 20,000 measuremen ts in total.
 Scien tists nd it useful to b e able to cluster a set of genes in to di eren t groups, in whic h eac h group con tains genes evincing similar b eha vior. Armed with suc h a clustering, scien tists ma y b e able to more easily prob e the functional purp ose or role for whic h these \sup er-groups" are resp onsible. The results in this section w ere obtained from a gene ex-pression data set con taining 517 sequences, eac h consisting of 12 measuremen ts. The measuremen ts w ere tak en o v er a 24 hour p erio d. The details are as follo ws.
 Eisen et al. (1998) describ e this data set in greater detail and pro vide a clustering using standard hierarc hical (a v erage-link age) clustering.
 Here w e sho w that it is a simple matter to cluster this data using our uni ed framew ork. W ec hose to mo del this data with a mixture mo del con taining k ernel regression mixture comp onen ts. This t yp e of mo del seems more natural than emplo ying a standard hierarc hical approac h(v ector-based) since one is explicitly mo delling a gene's expression dep en-den t on time. See Ga ney and Sm yth (1999) for a more detailed discussion of k ernel regression mixture mo dels. Figure 2 sho ws a picture of a p ortion of the data set. The y-axis sho ws the lev el of resp onse and the x-axis simply indexes time. Figure 3 sho ws 5 of the clusters that w ere returned when the data w as analyzed. The returned clusters matc h those found b y Eisen et al. (1998) rather closely . Red blood cell cytograms are t w o-dimensional histograms of red blood cells' v olume and hemoglobin concen tration. They are routinely obtained from o w-cytometric mac hines a v ailable in medical lab oratories. Understanding the prop-erties of the join t distribution of the v olume and hemoglobin concen tration is an imp ortan t diagnostic to ol in disco v ering patien ts with some t yp es of blo o d disorders suc h as iron de -cien t anemia (ID A) (McLaren, 1996). Ev en more imp ortan t scien ti c insigh ts can b e obtained b y examining a p opula-tion of individuals, where eac h individual can b e represen ted b y one or more cytograms. F or example, this analysis can rev eal v ariabilit y among individuals, v ariabilit y of a single individual o v er time, or it can b e used to classify new pa-tien ts. the join t probabilit y p ( s i ;s j ) , where s i and s j higher probabilit y . In an earlier study (Cadez et al., 1999) w e sho w ed ho w eac h cytogram can b e c haracterized as an 11{dimensional v ector. This w a y , in general eac h individual has one or more 11{ dimensional v ector data p oin ts asso ciated with him or her. In the exp erimen ts presen ted here w e sp eci cally lo ok at 2 cytograms per individual, the so called \duplicates." Du-plicates exist since eac h blo o d sample is t ypically analyzed t wice with a 15 min ute in terv al in b et w een. The red blo o d cell data set consists of 90 con trols (health y individuals) and 82 patien ts with ID A. Figure 4 sho ws the 2 most imp ortan t dimensions (out of 11 a v ailable) that can b e view ed as an appro ximation to the cytogram mean. Eac h dot represen ts a single duplicate, so there are t wice as man y dots as there are individuals. The upp er gure sho ws the true classi ca-tion, while the lo w er gure sho ws results of our clustering (using 2 11{dimensional v ectors p er individual and with the class lab els remo v ed). The lo w er gure also sho ws di eren t duplicates with di eren t sym b ols rev ealing the v ariabilit yof individual data.
 T o summarize, this data set and mo del can b e describ ed as: W e presen ted a unifying probabilistic framew ork for clus-tering individuals or systems in to groups when the a v ailable data measuremen ts are not m ultiv ariate v ectors of xed di-mensionalit y . a. W e presen ted a general EM algorithm for clustering this t yp e of data and demonstrated its usefulness on three applications. Ak ey idea in this pap er is the fact that one is able to plug in an appropriate mo del for a data set and apply it within this general framew ork to generate parameter estimates and cluster mo dels in a straigh tforw ard and consisten t manner. This allo ws the data analyst to tak e full adv an tage of all of the a v ailable data on an individual without ha ving to resort to ad ho c metho ds for com bining di eren t non-v ector data t yp es and data sets of di eren t sizes.
 The w ork describ ed in this pap er w as supp orted b y the Na-tional Science F oundation under Gran t IRI-9703120. The authors gratefully ac kno wledge the con tributions of Chris-tine McLaren in pro viding the red blo o d cell data.
Blender, R., F raedric h, K., and Lunk eit, F. (1997) Iden ti -
Cadez, I. V., and Sm yth P . (1999) Probabilistic clustering
Cadez, I. V., C. E. McLaren, P .Sm yth, and G. J. McLac h-Cadez, I. V., Hec k erman, D., Meek, C., Sm yth, P ., White,
Dempster, A. P ., Laird, N. M., and Rubin, D. B. (1977),
DeSarb o, W., Oliv er, R. L., and Rangasw am y , A. (1989), Eisen, M. B., Sp ellman, P . T., Bro wn, P . O., and Botstein,
F raley , C. and A. E. Raftery , `Ho w man y clusters? Whic h
Ga ney , S., and P . Sm yth, `T ra jectory clustering using
Haccou, P . and Meelis, E. (1992) Statistic al A nalysis of Be-Jain, A. and Dub es, R. (1988) A lgorithms for Clustering
Krogh, A., Bro wn, M., Mian, I. S., Sjolander, K., and Haus-
McLac hlan, G. J., and Krishnan, T., The EM A lgorithm
McLaren, C. E. (1996) `Mixture mo dels in haematology: a
P oulsen, C. S. (1990). Mixed Mark o v and laten t Mark o v
Rabiner, L. R., C. H. Lee, B. H. Juang, and J. G. Wilp on, Ridgew a y , G., `Finite discrete Mark o v pro cess clustering,'
Sm yth, P ., `Clustering sequences using hidden Mark o vmod-
Sm yth, P ., `Probabilistic mo del-based clustering of m ul-
Spath, H. (1979) `Clusterwise linear regression,' Comput-
W edel, M. and Steenk amp, J. B. (1991) `A clusterwise re-
W edel, M. and Kamakura, W. A. (1998) Market Se gmen-
