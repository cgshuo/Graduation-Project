 Along with the explosion of information resource, searching on the web is becoming the best way to obtain valuable knowledge. While not all the users are professional, they may not know how to exactly describe what they want and sometimes they type a wrong word users don X  X  want or even no result at all. Such a query is called failed query by us. Some-times the case emerges, especially for web databases. Since web databases only provide Web access interfaces to users, and their data and schema information are transparent to them. 
Query relaxation aims to modify the failed query to obtain more satisfying results. Al-avoid the occurrence of failed query. In other words, no matter what the user inputs, the system will always return a nonempty result set. 
This paper focuses on query relaxation on the deep web and an effective query relaxa-ently to return better results to users without manual intervention. 
The main contributions of the paper are: (1) An effective query relaxation solution is proposed, in which, DRG is provided to organize the candidate databases. Based on DRG, it is easy to specify the order of relaxing a failed query. (2) An optimization strategy on DRG is presented to enhance the efficiency of query relaxation further. (3) Experiments manifest the efficiency and feasibility of our solution. When a query fails, it is more cooperative to identify the causes, rather than just to report in both IR and DB areas, but most of the researches [1-7] focus on query relaxation in the local database which can provide enough information to assist the query relaxation. And it is not necessary to consider about the time cost of network transmission. 
In deep web environment, all the data sources we faced are autonomous web data-bases, and there is no way to access data from them except to query through their query priate here. The methods presented by Muslea and Nambiar are the familiar query relaxa-tion methods for web databases. 
Ion Muslea [8] [9] respectively used Decision Tree and Bayesian Network on the data samples of target databases to get candidate queries. The candidate queries are similar to the original query, and they are sure to get nonempty results because the candidate que-ries are actually some tuples in the data samples. The shortcoming of this method is that it will execute the complex data mining algorithm on every data sample for each arriving query, so its time cost is too high. 
Ullas Nambiar [10] [11] employed approximate functional dependency to get the im-portant degree of the schema attributes in a database, according to which the order of the relaxed attributes is specified, and the data samples used to compute the important degree are chosen randomly. Nambiar just thought there was only one autonomous web database and generated a query relaxation plan for this single data source. 
The problem we faced is to make a query relaxation plan for multiple target databases, so it is necessary to improve the primary method. Generally, there are two kinds of methods to relax a query: value relaxation and attribute autonomous database on the web, in addition, not only the cost of query probing usu-lower accuracy. Moreover, the data in web databases may be changed frequently. Therefore the method of value relaxation is not a good choice for the deep web. ment. But it may bring more inaccurate results. However, the deficiency can be compen-attribute relaxation method is chosen to relax query on the deep web by us. failed queries are relaxed in the following two ways. matically, and the more than one relaxed queries containing more attributes than an inter-much time and waste system resources. whose attributes satisfy the query completely. In this way, we can get the relaxed results, but lots of databases out the subset satisfying the query may be excluded. relaxed query will be accessed. (4) Since a query sometimes need to be relaxed in many times and the cost of finding the eligible databases is higher for each time, it is better to the database schema and the query. And then the order of databases to be relaxed is easy the specific databases. A Deep web data source is a website that is composed of a web query interface and an page which are called input schema and output schema respectively. In the process of input schema of i ds . 
Most underlying databases of the deep web sites are relational databases, so in the model is denoted as 112 2 { , ,..., } mm Qaxax a x == = = . 
Given a deep web grid system G and a user query 0 Q , many data sources i ds (1 im  X  X  X  ) providing query services are registered in G, including their accessing ad-schemas to the global schema g S . The system G provides a user interface in terms of the global schema, and the user query 0 Q is composed of attribute-value pairs. the user with lower cost. How much a result tuple t satisfying a query Q depends on the query to the actual data sources. The similarity degree and the time cost will be discussed in details in Section 5. 5.1 Preprocessing Before the query relaxation, the system need to know the important degree of the attrib-utes involved in the query. We call the phase of getting the attribute important degree as preprocessing phase. The attribute important degree is calculated based on the deep web query probing. 5.1.1 Data Sampling Via query-based sampling [12] [13], we can get the data samples from autonomous data-bases on the web. To manifest the data characteristics, the probing process is adopted by us as follows: Firstly, an initial query with a single-attribute query is chosen and executed in some databases, and the returned results are as part of data samples. Secondly, a new pling process on other web databases until the termination condition is satisfied. The data samples obtained are better for summarizing the data in a specific domain. 5.1.2 Attribute Important Degree Analysis the database attributes, and the concepts about approximate functional dependency are as follows. satisfy the relationship to the number of all the tuples. X. Let error(X) be the minimal fraction of tuples that need to be removed from relation r for X to be a key. The error rate error(X) is the ratio of the number of the tuples that need to be removed to the number of all the tuples. Huhtala X  X  method TANE [14], then the AK with the maximum support rate is obtained, except AK. Where A is the set of all the AFDs X  decide attributes including the attribute k, ' k is an attribute that doesn X  X  appear in A. Where A is the set of all the AFDs X  decide attributes including the attribute j. 5.2 Query Execution It is obviously unreasonable to send the query to all the databases registered on the sys-tem, especially for the databases whose schemas do not match with the query. Therefore, candidate databases each time for executing the relaxed query dynamically. 5.2.1 Databases Selection Firstly, the candidate databases whose schemas satisfy the query are chosen from all of the deep web databases in the registry of system G, and the formula to calculate the matching score of a database is as follow: 5.2.2 Databases Relationship Graph (DRG) Construction acyclic graph as databases relationship graph. bases have the same interface schema, and we call them databases candidate groups. Then mation about which nodes it contains directly and which nodes are directly contained by it. ranged in the reverse order in terms of their matching scores, and the parent nodes of i n are the ones directly containing i n . in the candidate groups which totally match 1 Q based on DRG. The above procedure will be processed repeatedly until some results are obtained. 
The DRG is constructed as follow: if there is no candidate group corresponding to this node. Example 1: Let a query include 5 attributes denoted as a, b, c, d, e, and there are some on the intersections between each candidate database attribute set and the attribute set of the query, suppose these databases are divided into 10 candidate groups and organ-ized as figure 1 according to the above construction rules, and s0 is the initial node, s11, s12, s13 are the child nodes of s0 in descending order of their matching scores. 5.2.3 Query Relaxation The whole query relaxation can be summarized as two aspects: moving the pointer to traverse the DRG and sending the query to the proper nodes. node. If i n is the initial node, the pointer X  X  next position is its first child node. include all the attributes in i Q , and it is possible to get some results from those nodes even though they have been traversed before by the query with more constraints. Example 2: let the query user inputs be (a=10, b=20, c=15, d=30, e=20) and the cho-sen candidate databases be divided into 10 candidate groups, then the candidate groups construct a DRG as Fig. 1, so the process of query relaxation is as follows: result. then the query is relaxed as (a=10, b=20, d=30, e=20), and send it to (a, b, d, e) and (a, b, c, d, e), and there is no result. and (a, b, c, d, e). There is no result. b, c, d, e), and there is no result. 
Step 5: The query is relaxed as (a=10, d=30, e=20), and send it to (a, d, e), (a, b, d, e), (a, c, d, e) and (a, b, c, d, e), now there are some results, and the process of query relaxation is terminated. 
If the whole DRG has been traversed and there is no result, go back to the phase of relaxation continues until there are enough results or time out. the user inputs a query 1 Q and there is no result until the (a, d, e) has been traversed, so the times of sending and executing the query is 1+2+2+2+4=11. According to the DRG, if we relax the query to the node which has the weakest constraint and send it to all the nodes in the graph, in this way, it also takes 10 times to send the query only, Is that better? 
Analysis: During query relaxation, the cost mainly comes from the network trans-time cost T again. In a way, the number of the result pages returned decides the time node with the weakest constraint, the time cost is much more than 10T. 5.2.4 Optimization directly, such as node (a, d, e), and sent the query to all the nodes contain (a, d, e) to decrease the time cost. However, it is diffic ult to reach the right node without travers-ing the graph. tive important degree of each node to the query is proposed, which is defined as: Where n is the number of attributes in the query and m is the number of attributes in a node, and i w is the important degree of the th i attribute. first node whose relative important degree is less than 0 R W as the start node. sults are sufficient or not, and two methods are adopted to deal with the large quantity of results returned. One is to execute the strict local query further, and the other is to tighten the relaxed query again. 5.3 Result Selection The goal of this section is to choose the most similar results from the result set to the user. The similarity degree between a tuple t and a query Q is denoted as follow: Where the max ple. If | . . | ii Qa ta  X  is more than max
Qa ta  X  to update max Where the max is more than max date max (3) If the attribute i a is Boolean, then the similarity degree between two values is 1 if they are the same, otherwise it is 0. our solution. In the experiment, 100 data sources are used, each of which is described by at most 7 attributes, and 100 queries are defined. All the tests run on a computer with Intel(R) Core(TM) 2 CPU with 1G RAM. 
Nambiar X  X  AIMQ [10] [11] is an existing query relaxation method for autonomous multi-databases environment, the intuitive opinion is to apply it on each of databases and to integrate the results from them. The query relaxation on each database is inde-pendent. We call this method as intuitive method. We compare the relaxing perform-ance by using both DRG and intuitive method to data sources. 
Fig. 2 shows the average query times of DRG and intuitive method with different defined in 5.2.3. It demonstrates that the DRG method is more efficient than the intui-method no matter what the number of candidate databases is. 
Fig. 3 shows the average similarity degree between the query request and the re-databases. It demonstrates that DRG method is more available than the intuitive method, since the similarity degree of the results returned by DRG is bigger than the intuitive method. 
Fig. 4 shows the average query times of optimized DRG and plain DRG with 30 candidate databases and different relative important degree. If 10 is the average query time of the plain DRG with 30 candidate databases, while the average query times of the optimized DRG are less than 10, so it de monstrates that the optimized method is more effective. In this paper, we present a query relaxation solution to enlarge quantity of heteroge-degree of the attributes are obtained by employing the approximate functional de-pendence. Secondly, some of the candidate databases which match the user X  X  query are chosen and organized into a database relationship group (DRG) to implement query relaxation. Thirdly, the results are ra nked from the results returned according to efficiency of the solution. 
Next, we will focus on the optimization measures of query relaxation further to de-crease the cost further. 
