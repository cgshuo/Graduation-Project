 We present a document routing and index partitioning scheme for scalable similarity-based search of documents in a large corpus. We consider the case when similarity-based search is performed by finding documents that have features in com-mon with the query document. While it is possible to store all the features of all the documents in one index, this suffers from obvious scalability problems. Our approach is to par-tition the feature index into multiple smaller partitions that can be hosted on separate servers, enabling scalable and par-allel search execution. When a document is ingested into the repository, a small number of partitions are chosen to store the features of the document. T o perform similarity-based search, also, only a small number of partitions are queried. Our approach is stateless and incremental. The decision as to which partitions the features of the document should be routed to (for storing at ingestion time, and for similarity based search at query time) is solely based on the features of the document.

Our approach scales very well. We show that execut-ing similarity-based searches over such a partitioned search space has minimal impact on the precision and recall of search results, even though every search consults less than 3% of the total number of partitions.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Indexing methods ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Search process ; H.3.4 [ Information Storage and Retrieval ]: Systems and Software X  Distributed Systems  X  This research was done while the author was a Research Associate at Hewlett Packard Labs, Palo Alto Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00. Algorithms, Management, Performance similarity-based search, scalability, index partitioning, dis-tributed indexing, document routing
Finding textually similar files in large document reposito-ries is a well researched problem, motivated by many practi-cal applications. One motivation is the need to identify near duplicate documents within the repository, to eliminate re-dundant or outdated files and improve user experience [15]. Archival systems [26, 35] need to identify content overlap between files to save storage space by using techniques such as delta-compression [2, 11]. Other applications arise in in-formation management: similarity based retrieval can be used to find all versions of a given document, e.g. for com-pliance, security, or plagiarism detection purposes. Notice that in this paper we are concerned with textual document similarity, where two documents are deemed to be similar if they share significant stretches of text. This is in contrast to natural language based approaches where the linguistic structure of the document is taken into account.

The operation that is the object of our study is similarity based retrieval . Here, a query document Q is presented to the system. The aim is to find all the documents D 1 ,D 2 ,...,D in the repository that are similar to Q , the most similar documents being presented first.

While finding textually similar documents can in princi-ple be achieved by a pairwise comparison of the query doc-ument with each one of the documents in the repository using a program such as unix diff, this is clearly very inef-ficient. To solve this problem, the following framework is commonly used: from every document, a set of features are extracted, such that if two documents are similar, their sets of features overlap strongly, and if they are dissimilar, their sets of features do not overlap. Thus, the problem of docu-ment similarity is reduced to one of set similarity. Then, an inverted index [30, 31] is created mapping features to doc-uments. Upon the presentation of the query document Q , its features are extracted, and used to query the inverted index. The result is a set of documents that share some features with Q ; these are then ranked with the document sharing most features coming first. Various authors have de-veloped techniques for extracting features from a document: Manber [22], Broder et al. [5, 6], Kulkarni et al. [18] and For-man et al. [15]. All these approaches generate very specific features: when two documents share even a single feature, they share a relatively large stretch of text (tens of char-acters). As a result, when the inverted index is consulted, relatively few documents are returned. This is in contrast with techniques such as bag of words analysis, where most documents are expected to share at least a few words.
A single feature index becomes a bottleneck as the size of the repository gets very large, and the index needs to simul-taneously handle a large number of updates and queries. Such a situation is typical of document management sys-tems for large enterprises, as well as archival systems deal-ing with large, continuous streams of documents. One solu-tion is to partition the feature index into a number of sub-indices, placing each partition on a different server, so that the servers can be updated and queried in parallel. The par-titioning scheme used must be such that only a small frac-tion of the partitions need to be accessed for each update and query. Here, the most obvious schemes, such as using a Distributed Hash Table (DHT) [28, 29, 33, 36] to store the feature,Document pairs fail. In this scheme, the parti-tioning of the index is based on the hash of the individual features. For example, given 2 k servers, each hosting a hash table, and the pair feature,Document that needs to be added to the index, the first k bits of the hash of the fea-ture are used for identifying the server that this particular pair needs to be added to. The problem is that there is no locality of reference for the individual feature hashes: each one of the document features is routed independently, most likely to a different server. As a result, a large number of servers will need to be accessed for each document update and query.

In this paper we present an alternative index partition-ing and document routing scheme; one that does not route each individual feature of every document independently, but rather routes all the features in a document together. The outline of our scheme is as follows:
This situation has been depicted in Figure 1. Notice that the choice of which servers to contact, both at ingestion and query time, is entirely based on the contents of the docu-ment;atnotimedowehavetohaveaninteractionwiththe partitions to determine which one should be chosen. This sets us apart from approaches which apply a clustering al-gorithm [16, 25, 32] to all the documents in the repository; these approaches need to use knowledge of the existing clus-ters to route the new document. Our approach, by contrast, is incremental and stateless: only the contents of the docu-ment are used to decide which partitions it should be routed to. As a result, we have a very lightweight, client based rout-ing capability.
As stated above, our work assumes the existence of a mechanism to extract features from documents, such that document similarity is reduced to set similarity. We use the Jaccard index as a measure of set similarity. Let H be an algorithm for extracting features from documents, where H ( f ) stands for the set of features extracted by H from doc-ument f . Then, the similarity measure of two documents f and f 2 according to Jaccard index is
There are a number of feature extraction algorithms in the literature that satisfy the requirements above. Shin-gling [4] is a technique developed by Broder for near du-plicate detection in web pages. Manber [22], Brin et al. [3] and Forman et al. [15] have also developed feature extraction methods for similarity detection in large file repositories.
For the experiments reported in this paper, we used a modified version of the chunk based feature extractor de-scribed by Forman et al. [15]. This algorithm is described below.
Content-based chunking, as introduced in [24], is a way of breaking a file into a sequence of chunks so that chunk boundaries are determined by the local contents of the file. The Basic Sliding Window Algorithm is the prototypical content-based chunking algorithm. This algorithm is as fol-lows: an integer, A , is chosen as the desired average chunk size. A fixed width sliding window is moved across the file, and at every position k , the fingerprint, F k ,ofthecontents of this window is computed. This fingerprint is calculated using a technique known as Rabin X  X  fingerprinting by ran-dom polynomials [27]. The position k is deemed to be a chunk boundary if F k mod A = 0. We actually use the TTTD chunking algorithm [13], a variant of the basic algo-rithm that works better. See [15] for details.

The rationale for using content-based chunking for simi-larity detection is that if two files share a stretch of content larger than the average chunk size, it is likely that they will share at least one chunk. This is in contrast to using fixed size chunks, where inserting a single byte at the beginning would change every chunk due to boundary shifting.
We use the characteristic fingerprints of chunks (see be-low) as the features of the file. Again, the intuition is that if two files are similar, they share a large number of chunks, and thus their feature sets overlap strongly; if they are dis-similar, they will not share any chunks, and thus their fea-ture sets will be disjoint.
 Here is the feature extraction algorithm in more detail. This algorithm uses a hash function, h , which is an approx-imation of a min-wise independent permutation (see sec-tion 3.2 below). There are three steps in our feature extrac-tion algorithm: 1. The given file is first parsed by a format specific parser. 2. The document text is divided into chunks using the 3. For each chunk, a characteristic fingerprint is com-
To summarize, the features of the document are the char-acteristic fingerprints of the chunks of the document. This algorithm has been demonstrated to produce good features for document similarity. We will not discuss its properties further here, since it is not the subject of this paper.
In this section, we describe the structure of the feature indices, be they a monolithic feature index for all the docu-ments in the repository, or one of the indices corresponding to a partition of the bigger index.

Figure 2 depicts one of the possible designs of a feature in-dex. The index key is the feature itself. Each feature points to the list of files that it occurs in. This design is analogous to that of an inverted keyword index [30, 31] used com-monly in Information Retrieval Systems. This index con-tains lookup information for every file that has been routed to it at ingestion time.
When a new file, f n , needs to be added to the repository an entry for each feature in H ( f n ) must be added to the fea-ture index. For every feature in H ( f n ), if an entry already exists in the feature index, th en the detail for that entry is appended with f n . If no entry is found then a new entry for that feature is inserted. If f n is routed to multiple parti-tions this process is repeated at every one of the destination partitions.
When a feature index needs to be accessed to find files in the repository similar to a query file, f q , then the index is queried using each feature in H ( f q ). The set of files similar to f q is the set where I ( h i )isthesetofallthefilesthat h i points to in the feature index I . Each file in the result set is ranked based on its Jaccard similarity index with respect to f q .
If multiple partitions need to be queried for f q then the above querying process is carried out for every partition. The results obtained from each partition are collated such that the set of all the files similar to f q is given by where the set R is the set of all the partition numbers that were queried for f q .
As mentioned before, our main interest in this paper is to partition the index I into a number of sub-indices I 1 ,I while preserving the following properties:
We first describe the document routing algorithm and then provide the justification for why it works.

The input to the algorithm is
We assume that m&lt;K ,and | H ( f n ) | X  m .Thefea-ture extraction algorithm, H , extracts features using a min-wise independent hash function as explained in section 2.1. The routing algorithm computes a set of integers R = { r 0 ,r 1 ,...,r m  X  1 } where 0  X  i&lt;m . r 0 ,r 1 ,...,r m partitions to which the document will be routed. The doc-ument routing algorithm is as follows: 1. Compute bot m ( H ( f n )) where bot m is a function that 2. For every hash h in bot m ( H ( f n )) compute ( h mod
The routing algorithm has been depicted in Figure 3. The routing algorithm is based on a generalization of Broder X  X  theorem [5]. Broder X  X  theorem relies on the no-tion of a min-wise independent family of permutations .The following definition and theorem are from [5].

Definition 1. Let S n be the set of all permutations of [ n ] . The family of permutations F  X  S n is min-wise inde-pendent if for any set X  X  [ n ] and any x  X  X ,when p is chosen uniformly and at random from F we have
In practice, truly min-wise independent permutation are expensive to implement. Practical systems use hash func-tions that approximate min-wise independent permutations.
Theorem 1. Consider two sets S 1 and S 2 ,with H ( S 1 ) and H ( S 2 ) being the corresponding sets of the hashes of the elements of S 1 and S 2 respectively, where H is chosen uni-formly and at random from a min-wise independent family of permutations. Let min ( S ) denote the smallest element of the set of integers S .

Broder X  X  theorem states that the probability that the two sets S 1 and S 2 have the same minimum hash element is the same as their Jaccard similarity measure.

Now, consider two files f i and f j ,andlet m = 1, i.e. we route each file to only one partition. According to the theo-rem above, and the definition of similarity measure between two files, the probability that H ( f 1 )and H ( f 2 )havethe same minimum element is the same as the similarity mea-sure of the two files. In other words, if the two files are very similar, the minimum elements of H ( f 1 )and H ( f 2 )arethe same with high probability. But if the minimum elements are the same, the two files will be routed to the same parti-tion, since the partition number to which they are routed is the minimum element modulo K , the number of partitions.
While the probability of being routed to the same parti-tion is high when the two files are very similar, the probabil-ity drops significantly when the degree of overlap between the two files goes down. For example, if half the features of the two files are the same, and the two files have the same number of features, the Jaccard similarity measure of the two files is 1 / 3, i.e. there is only one third chance that they would be routed to the same partition.

To overcome this problem, we route the files to more than one partition, i.e. we choose m&gt; 1. The intuitive justifica-tion for using the bottom m features for routing is that if by chance a section of a file changes such that the minimum feature is no longer in the set of features, the second least feature will now become the minimum feature with good probability. Our experiments and the theorem below show that with m a modest number (less than 5), we have a very good chance that two files with a fair degree of similarity will be routed to at least one common partition.

To formalize our intuition, we can generalize the Broder theorem as follows:
Lemma 1. Let S 1 and S 2 be two sets. Let I = | S 1  X  S 2 and U = | S 1  X  S 2 | .Let B 1 = bot m ( H ( S 1 )) and B bot m ( H ( S 2 )) ,where H is a min-wise independent hash func-tion. Then
P ( B 1  X  B 2 =  X  )  X  ( Let s = I/U , i.e. s is the Jaccard similarity measure between S 1 and S 2 . A good approximation of the above, when m is small and U is large, is is a small error factor in the order of 1 /U .

When we translate this lemma to the case of documents, we get the following:
Corollary 1. Let f 1 and f 2 be two documents with sim-ilarity measure s . When they are each routed to m partitions using the algorithm above, the probability that there will be at least one partition to which both of them are routed is at least 1  X  (1  X  s ) m
Now, consider the case where the document f 1 has been ingested into the system, and we now wish to use f 2 as the query document to do similarity based retrieval. Let us say that the similarity measure of f 1 and f 2 is 1 / 3, and m routing factor, is 4. Since the same routing algorithm is used for ingestion and query processes, and for the query to succeed it suffices that at least one partition be in com-mon between the two files, the probability that we find the document f 1 when we query with f 2 is better than 80%. Contrast this with the case where m = 1, when the proba-bility of finding f 1 is only 33%.

The following sections discuss the experimental setup and results.
The experimental data set consisted of 179874 files. These were Hewlett Packard X  X  internal support documents in HTML format. There were 1504984 unique features extracted from this set. A randomly selected subset, F q , of 332 files was chosen from the original corpus to be used as query files. The rest of the files, the set F d , was our document repos-itory. Our goal was to find for every file f q  X  F q the files in
F d that were highly similar to f q . The similarity mea-sure between two files was calculated using their features as explained in section 2.

Since F d was our document repository every file f d  X  F d was used to build the partitions using the document routing algorithm as explained in section 2.3. Every file in F q then used to query the partitions as explained in section 2.4 to find similar files to itself in F d . The number of partitions, K , were varied from 1 through 128. The routing factor, m , used to route every file in F d (for building the partitions) and in F q (for querying the partitions) was also varied from 1 through 10.

The result set for every query in F q using a single non-partitioned index was then used as a standard to judge the quality of results produced when the index was partitioned. Figure 4: Effect of the routing factor on the average similarity measure
In the first set of experiments we have compared the qual-ity of results obtained when using a single monolithic feature index ( K = 1) to search for similar files with those obtained when we had multiple partitions ( K&gt; 1). First, a mono-lithic feature index was built using every file in F d .Next, for every query file f q  X  F q the set of files similar to it were identified by querying the monolithic feature index. Each file, f r , in the result set for every query f q was then ranked based on its Jaccard similarity index with f q . The file with the highest similarity measure was the file that was most similar to the query file and hence, the best result. The best result, thus calculated, was recorded for every query file. The average similarity measure, calculated as the aver-age of the best results for all f q , was then calculated for the entire query set F q .

The next round of experiments was conducted with in-creasing number of partitions, K&gt; 1. For every value of the routing factor, m for every file in F d and F q was varied from 1 through 10. Once again, the first step was to build the partitions using F d for the appropriate values of K and m .Usingthe same values for K and m files in F q were used to query the partitions. The results obtained from the respective partitions were collated and the best result was recorded for every f q  X  F q . The average similarity measure, for every K and m combination, was then calculated for F q
Figure 4 shows the effect of increasing the number of parti-tions, K , and the routing factor, m , on the average similarity measure of F q . In the figure, the data point corresponding to
K =1 and m = 1 corresponds to the average similarity measure for F q with one monolithic index. This value is 0 . 342. We can see that for K = 128 and m = 1 this value is less than 0 . 27. This is because with increasing number of partitions while using only the minimum feature ( m =1) to route the query file it is possible to not find the best match, or the file with the highest similarity measure. When m =1 even a single change that affects the minimum feature of the query file can prevent us from finding the best match as has been explained in section 3.2. The overall average similarity measure for F q , thus, reduces. However, as we increase we improve our chances of finding the best result because we now route every file f d  X  F d and f q  X  F q to multiple partitions. We can see that even with m =3 there is a sig-nificant improvement in the average similarity measure of F q for all values of K .For K = 128 ,m = 3 this value is more than 0 . 33. This means that for a large percentage of query files we are being able to find the file in F d that shares the highest content overlap with them. For m&gt; 4 the average similarity measure for all values of K is 0 . 342 which means that for every query file we were able to find the best match. Figure 5: Effect of the number of partitions on the overall recall
Figure 5 depicts the average recall obtained for all the queries for increasing values of m and for K = 128. The recall for every query was calculated as the fraction of the size of the result set obtained when K&gt; 1 with respect to the original size of results with K = 1. The ideal recall, thus, is 1. Figure 6: Identical and disjoint top-2 lists, 128 par-titions The graph in figure 5 depicts the average recall for K = 128 for increasing values of m in two forms. The first form is the overall recall which takes into account the complete result set obtained for every query. The second form is the recall for only a subset of the result set  X  specifically the top-20 results in the result set. In this case we retained only the top-20 results for every query. We can see that for m =3 the overall recall is 24% whereas the recall for the corresponding top-20 results is 73%. This result shows us that though with K = 128 and m = 3 we were able to fetch only 24% of the total result set on an average, this subset contained most of the highest ranking results. This means that we were able to retain and produce the strong resemblances between documents.

We may have lost some of the weak similarity relation-ships but this loss is acceptable given the gain in scalability. Moreover, for many applications, only the documents with the strongest similarity to the query are of interest, and the low-similarity hits may not be of interest or get filtered out. For example, in the case of a standard search engine users are interested in only the the top few results of their query or the first page of results returned by the search engine. In such a situation the recall achieved by our routing algorithm with respect to the top-20 results is sufficient. However, if an application requires that every similar document to a query be found, then one can easily adopt a policy of querying each and every partition instead of just m out of K . Such a scheme will preserve the original recall of every query as was the case when there existed just one index( K =1).
Figure 6 shows us exactly how many of the top-2 results with K = 128 were identical or disjoint when compared to those with K = 1. This data was obtained using tech-niques developed by Fagin [14]. Identical results were those in which the contents of results were preserved with K = 128. Disjoint results were those in which none of the contents of the original top-2 results with K = 1 were preserved when K = 128. The rest of the top-2 results for K = 128 contained at least one of the original top-2 results. We can see that as m increases, even with m = 3, more than 70% of the top-2 lists were identical and less than 10% were disjoint. This means that overall more than 90% of the queries returned at least one of their top results.

Figure 7 depicts the average partition sizes as compared with the size of the monolithic index for increasing values Figure 7: %Average partition sizes for increasing values of the routing factor of m . The average partition sizes have been shown as a percentage of the size of the monolithic index. The partition size is the number of keys in the partition  X  the number of features indexed at every partition. This size does not take into account the list of files that every feature occurs in. Even if we had accounted for it we would observe the same trend as has been shown in the figure. We can see that with K = 128 and m = 3 the average partition size is less than 3% of the size of the monolithic index.
 We have already seen from our previous results that with K = 128 and m = 3 we obtain very good average similarity for our queries (Figure 4) more than 70% of the queries re-turned their top-2 results identical to when K = 1 and more than 90% of the top-2 results contained at least one of the original top-2 results. We can clearly see that our routing algorithm has performed very well while reducing the in-dividual partitions to more manageable sizes, enabling the parallel execution of similarity based searches while at the same time has not compromised the quality of our results.
Routing keyword queries to promising sources of informa-tion has been an active area of research in the field of dis-tributed information retrieval and peer-to-peer networks [7, 8, 10, 21]. Cooper [8] and Lu et al. [21] use past information about query results to guide queries to promising sources in peer-to-peer and federated information systems. Dis-tributed Hashing has also been studied widely. Litwin et al. [20] proposed Scalable Distributed Data Structures based on lin-ear hash tables for parallel and distributed computing. Dis-tributed Hash Tables(DHT) have also been widely used in the area of peer-to-peer systems to distribute and locate content without having to flood every node in the system with content and queries. Content Addressable Network (CAN) [28], Chord [33], Pastry [29] and Tapestry [36] are some of the DHT implementations used in a distributed en-vironment. Manku [23] has categorized the DHT routing methods into deterministic and randomized. Oceanstore [17] is an infrastructure that provides access to data stored across a large-scale globally distributed system and uses the Tapestry DHT protocol to route queries and place objects close to their access points with the objective of minimizing latency, preserving reliability and maximizing the network bandwidth utilization. PAST [12] is an internet scale global storage util-ity that uses Pastry X  X  routing scheme. PAST routes a file to be stored to k nodes within the network such that those node identifiers are numerically closest to the file identifier. Pas-tiche [9] is a peer-to-peer data backup facility that aims to reduce the storage overhead by identifying nodes that share common data at a sub-file granularity. Pastiche aims to con-serve storage space by identifying overlapping content using techniques introduced in the Low-Bandwidth Network File System [24]. In order to route data to appropriate nodes, Pastiche needs to access and maintain an abstract of the file system X  X  contents.
The document routing algorithm is an effective method for scalable and parallel similarity-based searches. The doc-uments are routed based solely on their contents to only a small fraction of the total partitions while still being able to preserve the precision of the results. We conclude that this algorithm is a good scalable solution.

Similarity-based searches in large scale repositories is only one of the applications for our document routing algorithm. Besides archival systems our document routing algorithm can be used to distribute and locate content in peer-to-peer cooperative storage and backup systems [9, 12, 19] and dis-tributed storage systems [1, 17]. Such systems can save stor-age space by routing documents to nodes that are expected to store similar content. The recipe for a document [34] con-sisting of the feature hashes can be used to locate it without having to consult a large number of indices.

The future work in this direction would consist of evalu-ating schemes that allow the dynamic growth in the number of partitions. We will investigate methods to divide those partitions that become overloaded and the effects of such a scheme on the quality of our results. We will also investigate the efficacy of our partitioning scheme for large scale archival systems that need to identify similar files within their repos-itories with the intention of conserving storage space. What we gain by partitioning the feature indices, used primarily for the de-duplication of archival data, and using our parti-tioning method may cost us some storage space as we miss identifying the files with high similarity. Future work will consist of quantifying our losses in the form of storage space and finding out if our gain, in the form of better bandwidth utilization and throughput, outweighs this loss. The authors would like to thank Vinay Deolalikar of Hewlett Packard Labs, Palo Alto for contributing the lemma in sec-tion 3.2. The authors would also like to thank Jaap Suer-mondt and Mark Lillibridge of Hewlett Packard Labs, Palo Alto for their comments. [1] A. Adya, W. J. Bolosky, M. Castro, G. Cermak, [2] M. Ajtai, R. Burns, R. Fagin, D. D. E. Long, and [3] S. Brin, J. Davis, and H. Garc  X   X a-Molina. Copy [4] A. Z. Broder. On the resemblance and containment of [5] A. Z. Broder, M. Charikar, A. M. Frieze, and [6] A. Z. Broder, S. C. Glassman, M. S. Manasse, and [7] J. J. Chua and P. E. Tischer. Strategies for [8] B. F. Cooper. Guiding queries to information sources [9] L.P.Cox,C.D.Murray,andB.D.Noble.Pastiche: [10] P. B. Danzig, J. Ahn, J. Noll, and K. Obraczka. [11] F. Douglis and A. Iyengar. Application-specific [12] P. Druschel and A. Rowstron. PAST: A large-scale, [13] K. Eshghi and H. K. Tang. A framework for analyzing [14] R. Fagin, R. Kumar, and D. Sivakumar. Comparing [15] G. Forman, K. Eshghi, and S. Chiocchetti. Finding [16] A. K. Jain, M. N. Murty, and P. J. Flynn. Data [17] J. Kubiatowicz, D. Bindel, Y. Chen, P. Eaton, [18] P. Kulkarni, F. Douglis, J. LaVoie, and J. M. Tracey. [19] M. Lillibridge, S. Elnikety, A. Birrell, M. Burrows, [20] W. Litwin, M.-A. Neimat, and D. A. Schneider. LH* [21] J. Lu and J. Callan. User modeling for full-text [22] U. Manber. Finding similar files in a large file system. [23] G. S. Manku. Routing networks for distributed hash [24] A. Muthitacharoen, B. Chen, and D. Mazi` eres. A [25] Z. Ouyang, N. D. Memon, T. Suel, and [26] S. Quinlan and S. Dorward. Venti: A new approach to [27] M. O. Rabin. Fingerprinting by random polynomials. [28] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and [29] A. Rowstron and P. Druschel. Pastry: Scalable, [30] G. Salton. Automatic Text Processing .
 [31] G. Salton and M. J. McGill. Introduction to Modern [32] H. Sch  X  utze and C. Silverstein. Projections for efficient [33] I.Stoica,R.Morris,D.Karger,M.F.Kaashoek,and [34] N. Tolia, M. Kozuch, M. Satyanarayanan, B. Karp, [35] L. L. You, K. T. Pollack, and D. D. E. Long. Deep [36] B. Y. Zhao, L. Huang, J. Stribling, S. C. Rhea, A. D.
