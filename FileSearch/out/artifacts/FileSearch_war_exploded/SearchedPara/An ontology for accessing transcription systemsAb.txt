 Steven Moran Abstract This paper presents the design and implementation of the Ontology for Accessing Transcription Systems (OATS), a knowledge base that supports inter-operation over disparate transcription systems and practical orthographies. OATS uses RDF, SPARQL and Unicode to facilitate resource discovery and intelligent search over linguistic data. The knowledge base includes an ontological description of writing systems and relations for mapping transcription system segments to an interlingua pivot, the IPA. It includes orthographic and phonemic inventories from 203 African languages, which were mined from the Web. OATS is motivated by four use cases: querying data in the knowledge base via IPA, querying it in native orthography, error checking of digitized data, and conversion between transcription systems. The model in this paper implements each of these use cases.
 Keywords Linguistics  X  Interoperability  X  Knowledge base  X  Ontology  X  Transcription system  X  Orthography 1 Introduction The World Wide Web has emerged as the predominate source for obtaining linguistic field data and language documentation in textual, audio and video formats. A simple keyword search on the nearly extinct language Livonian [liv] 1 returns numerous results that include text, audio and video files. As data on the Web continue to increase, including material posted by native language communities, researchers are presented with an ideal medium for the automated discovery and analysis of linguistic data, e.g. Lewis ( 2006 ). However, resources on the Web are not always accessible to users or software agents. The data often exist in legacy or proprietary software and data formats. This makes them difficult to locate and access.

Interoperability of linguistic resources has the ability to make disparate linguistic data accessible to researchers. It is also beneficial for data aggregation. Through the use of ontologies, applications can be written to perform intelligent search (deriving implicit knowledge from explicit information). They can also interoperate between resources, thus allowing data to be shared across applications and between research communities with different terminologies, annotations, and notations for marking up data.

A simple example of non-interoperability is illustrated by documentation from three genetically related, yet mutually unintelligible languages, spoken in Northern Ghana. Although the languages share nearly the same phonemic inventories, the field linguists X  documentation of each is encoded in slightly different practical orthographies. The orthographies represent affricates, vowels, and tone with different graphemes and to different degrees (for example tone is not always represented). A typologist or historical linguist interested in undertaking a comparative study of these languages would not only have to locate the documents that define this knowledge, they would have to correlate and track the mapping relations between phonemes and their corresponding grapheme forms when querying across electronic databases, lexicons and texts. A more desirable approach is to allow the researcher to query in the system of their choice to retrieve results from relevant documentation, regardless of the transcription system. For example, a linguist undertaking a cross-linguistic study on affricates may wish to query in IPA across dictionaries written in different orthographies (see Sect. 5.2 ).
OATS is a knowledge base, i.e. a data source that uses an ontology to specify the structure of entities and their relations. It includes general knowledge of writing systems and transcription systems that are core to the General Ontology of Linguistic Description (GOLD) 2 (Farrar and Langendoen 2003 ). Other portions of OATS, including the relationships encoded for relating segments of transcription systems, or the computational representations of these elements, extend GOLD as a Community of Practice Extension (COPE) (Farrar and Lewis 2005 ). OATS provides interoperability for transcription systems and practical orthographies that map phones and phonemes in unique relationships to their graphemic representations. These systematic mappings thus provide a computationally tractable starting point for interoperating over linguistic texts. The resources that are targeted also encompass a wide array of data on lesser-studied languages of the world, as well as low density languages, i.e. those with few electronic resources (Baldwin et al. 2006 ).
This paper is structured as follows: in Sect. 2 , linguistic and technological definitions and terminology are provided. In Sect. 3 , the theoretical and techno-logical challenges of interoperating over heterogeneous transcriptions systems are described. The technologies used in OATS and its design are presented in Sect. 4 .In Sect. 5 , OATS X  implementation is illustrated with linguistic data that was mined from the Web, therefore motivating the general design objectives taken into account in its development. Section 6 concludes with future research goals. 2 Conventions and terminology 2.1 Conventions Standard conventions are used for distinguishing between graphemic \[ , phonemic / / and phonetic representations [ ]. 3 For character data information, I follow the Unicode Standard X  X  notational conventions (The Unicode Consortium 2007 ). Character names are represented in small capital letters (e.g. LATIN SMALL LETTER SCHWA ) and code points are expressed as  X  X + n  X  where n is a four to six digit hexadecimal number (e.g. U+0256), which is rendered as \  X  [ . 2.2 Linguistic definitions In the context of this paper, a transcription system is a system of symbols and rules for graphically transcribing the sounds of a language variety. A practical orthography is a phonemic writing system designed for practical use by speakers already competent in the language. The mapping relation between phonemes and graphemes in practical orthographies is purposely shallow, i.e. there is a faithful mapping from a unique sound to a unique symbol. 4 The IPA is often used by field linguists in the development of practical orthographies for languages without writing systems. An orthography specifies the symbols, punctuation, and the rules in which a language is correctly written in a standardized way. All orthographies are language specific.

Practical orthographies and transcription systems are both kinds of writing systems . A writing system is a symbolic system that uses visible or tactile signs to represent a language in a systematic way. Differences in the encoding of meaning and sound form a continuum for representing writing systems in a typology whose categories are commonly referred to as either logographic, syllabic, phonetic or featural (Sampson 1985 ; Daniels and Bright 1996 ). A logographic system denotes symbols that visually represent morphemes (and sometimes morphemes and syllables). A syllabic system uses symbols to denote syllables. A phonetic system represents sound segments as symbols. Featural systems are less common and encode phonological features within the shapes of the symbols represented in the script.

The term script refers to a collection of symbols (or distinct marks) as employed by a writing system (Sproat 2000 ). The term script is confused with and often used interchangeably with  X  X riting system X . A writing system may be written with different scripts, e.g. the alphabet writing system can be written in Roman and Cyrillic scripts (Coulmas 1999 ). A grapheme is the unit of writing that represents a particular abstract representation of a symbol employed by a writing system. Like the phoneme is an abstract representation of a distinct sound in a language, a grapheme is a contrastive graphical unit in a writing system. A grapheme is the basic, minimally distinctive symbol of a writing system (Sampson 1985 ; Coulmas 2003 ). 5 A script may employ multiple graphemes to represent a single phoneme, e.g. the graphemes \ c [ and \ h [ when conjoined in English represent one phoneme in English, \ ch [ pronounced /  X  / (or /k/). The opposite is also found in writing systems, where a single grapheme represents two or more phonemes, e.g. \ x [ in English is a combination of the phonemes /ks/.

A graph is the smallest unit of written language (Coulmas 1999 ). The electronic counterpart of the graph is the glyph. Glyphs represent the variation of graphemes as they appear when rendered or displayed. In typography glyphs are created using different illustration techniques. These may result in homoglyphs , pairs of characters with shapes that are either identical or are beyond differentiation by swift visual inspection. When rendered by hand, a writer may use different styles of handwriting to produce glyphs in standard handwriting, cursive, or calligraphy. When rendered computationally, a repertoire of glyphs makes up a font .
A final distinction is needed for interoperating over transcription systems. The term scripteme refers to a grapheme within a writing system with the particular semantics (i.e. pronunciation) it is assigned within that writing system. The notion scripteme is needed because graphemes may be homoglyphic across scripts and languages, and the semantics of a grapheme is dependent on the writing system using it. For example, the grapheme \ p [ in Russian represents a dental or alveolar trill; /r/ in IPA. However, \ p [ is realized by English speakers as a voiceless bilabial stop /p/. Another example is the grapheme \ x [ and its myriad of pronunciations in different languages: [  X  ] in Albanian, [x] in Basque, [z] in English, [gz] in French, [ks] in German, [ (Coulmas 2003 , p. 95). The issue is complicated by the fact that graphemes often have several different phonetic interpretations within the same language, e.g. in English \ x [ is pronounced [z] only in word initial position and is either [ks] or [gz] otherwise ( X  X xcellent X  vs.  X  X xist X ). The defining of scripteme is necessary for interoperability because it provides a level for mapping a writing system specific grapheme to the phonological level, allowing the same grapheme to represent different sounds across different transcription and writing systems. 2.3 Technological definitions A document refers to an electronic document that contains language data. Each document is associated with metadata and one or more transcription systems or practical orthographies. A document X  X  content is comprised of a set of scriptemes from its transcription system. A mapping relation is an unordered pair of a scripteme in a transcription system and its representation in IPA.
OATS first maps scriptemes to their grapheme equivalent(s). Graphemes are then mapped to their character equivalents, so that the path through the RDF graph goes scripteme  X  grapheme  X  character(s)  X  code point(s), and vice versa. A character in OATS is a computational representation of a grapheme. Character encodings represent a range of integers known as the code space .A code point is a unique integer, or point, within this code space. An abstract character is then mapped to a unique code point and rendered as an encoded character and typographically defined by the font used to render it. A set of encoded characters is a character set and different character encodings encode characters as numbers via different encoding schemes. 3 Interoperating over transcription systems Section 3.1 uses the Sisaala languages to illustrate interoperability challenges posed by linguistic data. Section 3.2 addresses technological issues including encoding and ambiguity. 3.1 Linguistic challenges Three genetically related languages spokens in Northern Ghana, Sisaala Pasaale [sig], Sisaala Tumulung [sil] and Sisaala Western [ssl], differ slightly in their orthographies for two reasons: they have slightly divergent phonemic inventories and their orthographies may differ graphemically when representing the same phoneme (see Table 1 ).
 The voiceless labial-velar phoneme /kp/ appears in both Sisaala Tumulung and Sisaala Pasaale, but has been lost in Sisaala Western. There is a convergence of the allophones [d] and [r] into one phoneme /d/ in Sisaala Pasaale (Toupin 1995 ). 6
These three orthographies also differ because of their authors X  choices in assigning graphemes to phonemes. In Sisaala Pasaale and Sisaala Western, the phonemes /  X  / and /  X  / are written as \ ky [ and \ gy [ . In Sisaala Tumulung, however, these sounds are written \ ch [ and \ j [ . Orthography developers may have made these choices for practical reasons, such as ease of learnability or technological limitations (Bodomo 1997 ). 7 During the development of practical orthographies for Sisaala Pasaale and Sisaala Western, the digraphs \ ky [ and \ gy [ were chosen because children learn Dagaare [dga] in schools, so they are already familiar with these sounds in the Dagaare orthography (Mcgill et al. 1999 ; Moran 2008 ).
 Another difference lies in the representation of vowels. Both Sisaala Pasaale and Sisaala Western represent their full sets of vowels orthographically. These orthographies were developed relatively recently, when computers, character encodings, and font support, have become less problematic. In Sisaala Tumulung, however, the phonemes /i/ and /  X  / are collapsed to \ i [ , and /u/ and /  X  /to \ u [ (Blass 1975 ). Sisaala Tumulung X  X  orthography was developed in the 1970s and technological limitations may have led its developers to collapse these phonemes in the writing system. A comparable example is the lack of an individual grapheme \  X  [ for the phoneme /  X  / for Dagaare, cited in the Ghana Alphabet Committee X  X  1990 Report. This difficulty of rendering unconventional symbols on typewriters once posed a challenge for orthography development (Bodomo 1997 ).
 Tone is both lexically and grammatically contrastive in Sisaala languages. In Sisaala Pasaale X  X  official orthography tone is not marked and is not used in native speaker materials. On the other hand, in linguistic descriptions that use this orthography, tone is marked to disambiguate tonal minimal pairs in lexical items and grammatical constructions (McGill 2004 ). In the Sisaala (Tumulung)-English dictionary, tone is marked only to disambiguate lexical items (Blass 1975 ). In linguistic descriptions of Sisaala Western, non-contrastive tone is marked. When tone is marked, it appears as acute (high tone) and grave (low tone) accents over vowels or nasals.

Language researchers would quickly pick up on these minute differences in orthographies. However, what first seem to be trivial differences, illustrate one issue of resource discovery on the Web X  X ithout methods for interoperability, even slightly divergent resources are difficult to discover, query and compare. How would someone researching a comparative analysis of /  X  / sounds of languages in Northern Ghana discover that it is represented as \ ky [ and \ ch [ without first locating the extremely sparse grammatical information available on these languages? Furthermore, automatic phonetic research is possible on languages with shallow orthographies (Zuraw 2006 ), but cross-linguistic versions of such work require interoperation over writing systems. 3.2 Technological challenges The main technological challenges in interoperating over textual electronic resources are: encoding multilingual language text in an interoperable format and resolving ambiguity between mapping relations. These are addressed below.
Hundreds of character encoding sets for writing systems have been developed, e.g. ASCII, GB 18030 8 and Unicode. Historically, different standards were formalized differently and for different purposes by different standards committees. A lack of interoperability between character encodings ensued. Linguists, restricted to standard character sets that lacked IPA support and other language-specific graphemes that they needed, made their own solutions (Bird and Simons 2003 ). Some chose to represent unavailable graphemes with substitutes, e.g. the combination of \ ng [ to represent \  X  [ . Others redefined selected characters from a character encoding to map their own fonts to. One linguist X  X  redefined character set, however, would not render properly on another linguist X  X  computer if they did not share the same font. If two character encodings defined two character sets differently, then data could not be reliably and correctly displayed.

To circumvent these problems, OATS uses the Unicode Standard 9 for multilin-gual character encoding of electronic textual data. Unicode encodes 76 scripts and includes the IPA. 10 In principle this allows OATS to interoperate over IPA and all scripts currently encoded in Unicode. However, writing systems, scripts and transcriptions are often themselves encoded ambiguously.

Unicode encodes characters, not glyphs, in scripts and sometimes unifies duplicate characters across scripts. For example, IPA characters of Greek and Latin origin, such as \  X  [ and \ k [ are not given a distinct position within Unicode X  X  IPA character block. The Unicode code space is subdivided into character blocks, which generally encode characters from a single script, but as is illustrated by the IPA, characters may be dispersed across several different character blocks. This poses a challenge for interoperation, particularly with regard to homoglyphs. Why use the \ a [ cyrillic small letter a at code point U+0430 for IPA transcription, instead of \ a [ latin small letter a at code point U+0061, when visually they are indistinguishable and the former is input directly from the Russian keyboard?
Homoglyphs come in two flavors: linguistic and non-linguistic. Linguists are unlikely to assign any semantic difference between an open back unrounded vowel
Another challenge is how to handle ambiguity in transcription systems and orthographies. In Serbo-Croatian, for example, the digraphs \ lj [ , \ nj [ and \ dz [ represent distinct phonemes and each is comprised of two graphemes, which themselves represent distinct phonemes. Words like \ nadzivjeti [  X  X o outlive X  are composed of the morphemes \ nad [ , a prefix, and the verb \ zivjeti [ . In this instance the combination of \ d [ and \ z [ does not represent a single digraph \ dz [ ; they represent two neighboring phonemes across a morpheme boundary. Likewise in English, the grapheme sequence \ sh [ can be both a digraph as well as a sequence of graphemes, as in \ mishmash [ and \ mishap [ . When parsing words like \ mishit [ and \ mishear [ both disambiguations are theoretically available. Another example is illustrated by \ h [ , \ t [ , and \ th [ . How should \ t [ be interpreted before \ h [ when English gives us both /t  X  m  X  s/  X  X homas X  and /  X  ioudor/  X  X heodore X ? The Sisaala Western word \ niikyuru [  X  X aterfall X  could be parsed as /niik.yuru/ instead of /nii.  X  uru/ to speakers unfamiliar with the \ ky [ digraph of orthographies of Northwestern Ghana.

These ambiguities are due to mapping relations between phonemes and graphemes. Transcription systems and orthographies often have complex graph-eme-to-phoneme relationships and they vary in levels of phonological abstraction. The transparency of the relation between spelling and phonology differ between languages like English and French, and say Serbo-Croatian. The former represent deep orthographic systems where the same grapheme can represent different phonemes in different contexts. The latter, a shallow orthography, is less polyvalent in its grapheme-to-phoneme relations. Challenges of ambiguity resolution are particularly apparent in data conversion. 4 Ontological structure and design 4.1 Technologies In Philosophy, Ontology is the study of existence and the meaning of being. In the Computer and Information Sciences, ontology has been co-opted to refer to a data model that represents concepts within a certain domain and the relationships between those concepts (Gruber 1993 ). At a low level an ontology is a taxonomy and a set of inference rules. At a higher-level, ontologies define a given domain in terms of a set of entities and the formalized relationships that hold between them (Sowa 2000 ). To represent meaning in formal structures, some type of logic formalism is needed. The class of logical formalisms known as Description Logics (DL) provide a knowledge representation formalism that is computationally tractable (Baader et al. 2003 ; Baader and Sattler 2001 ; Calvanese et al. 2001 ). This provides the basis for automated reasoning by computer software, where content is given meaning in the sense of interpreting data and disambiguating entities. This is the vision of the Semantic Web, 11 a common framework for integrating and correlating linked data from disparate resources for interoperability (Beckett 2004 ). The General Ontology for Linguistic Description (GOLD) is grounded in the Semantic Web and provides a foundation for the interoperability of linguistic annotation to enable intelligent search across linguistic resources (Farrar and Langendoen 2003 ). Several technologies are integral to the architecture of the Semantic Web, including Unicode, XML, 12 and the Resource Description Framework (RDF). 13 OATS has been developed with these technologies and uses SPARQL 14 to query the knowledge base of linked data.

The Unicode Standard is the standard text encoding for the Web, the recommended best-practice for encoding linguistic resources, and the underlying encoding for OATS. XML is a general purpose specification for markup languages and provides a structured language for data exchange (Yergeau 2006 ). RDF is needed as the syntax for representing information about resources on the Web and it is itself written in XML and is serializable. RDF describes resources in the form subject-predicate-object (or entity-relationship-entity ) and identifies unique resources through Uniform Resource Identifiers (URIs). In this manner, RDF encodes meaning in sets of triples that resemble subject-verb-object constructions. These triples form a graph data structure of nodes and arcs that are non-hierarchical and can be complexly connected. Numerous algorithms have been written to access and manipulate graph structures. Since all URIs are unique, each subject, object and predicate are uniquely defined resources that can be referred to and reused by anyone. URIs give users flexibility in giving concepts a semantic representation. However, if two individuals are using different URIs for the same concept, then a procedure is needed to know that these two objects are indeed equivalent. A common example in linguistic annotation is the synonymous use of genitive and possessive. By incorporating domain specific knowledge into an ontology in RDF, disambiguation and interoperation over data becomes possible. GOLD addresses the challenge of interoperability of disparate linguistic annotation and termsets in morphosyntax by functioning as an interlingua between them. In OATS, the interlingua between systems of transcription is the IPA. 4.2 IPA as interlingua OATS uses the IPA as an interlingua (or pivot) to which elements of systems of transcription are mapped. The IPA was chosen for its broad coverage of the sounds of the world X  X  languages, its mainstream adoption as a system for transcription by linguists, and because it is encoded (at least mostly) in Unicode. The pivot component resides at the Character ID entity, which is in a one-to-one relationship with a Unicode Character. The Character ID entity is provided for mapping characters to multiple character encodings. This is useful for mapping IPA characters to legacy character encoding sets like IPA Kiel and SIL IPA93, allowing for data conversion between character encodings. The IPA also encodes phonetic segments as small feature bundles. Phonological theories extend the idea and interpretation of proposed feature sets, an area of debate within Linguistics. These issues should be taken into consideration when encoding interoperability via an interlingua, and should be leveraged to expand current theoretical questions that can be asked of the knowledge base. Phonetic features could also provide a pivot for interoperability, but this approach would be difficult to implement because feature theories differ considerably, e.g. compare Jakobson et al. ( 1952 ), Chomsky and Halle ( 1968 ), Sagey ( 1986 ) and Clements and Hume ( 1995 ). Consider the competing geometric models in Clements ( 1985 ), Sagey ( 1986 ), McCarthy ( 1988 ) and Avery and Rice ( 1989 ), or the question of whether distinctive features are binary, unary or other. Thus the segments in the IPA provide a pivot to which different feature systems X  features can be mapped to. The IPA is also designed to provide full coverage of the sounds of the world X  X  languages, whereas most feature sets do not.
Character semantics also require consideration (Gibbon et al. 2005 ). Glyph semantics provide implicit information such as a resource X  X  language, its language family assignment, its use by a specific social or scientific group, or corporate identity (Gibbon et al. 2007 ). Documents with IPA characters or in legacy IPA character encodings provide semantic knowledge regarding the document X  X  content, namely, that it contains transcribed linguistic data. 4.3 Ontological design OATS consists of the following ontological classes: Character, Grapheme, Document, WritingSystem, and Scripteme, illustrated in Fig. 1 . WritingSystem is further subdivided into OrthographicSystem and TranscriptionSystem. 15 Each Document is associated with the OLAC Metadata Set, 16 an extension of the Dublin Core Type Vocabulary 17 for linguistic resources. This includes uniquely identifying the language represented in the document with its ISO 639-3 three letter language code. Each Document is also associated with an instance of WritingSystem. Each TranscriptionSystem is a set of instances of Scripteme. Every Scripteme instance is in a mapping relation with its IPA counterpart. The Grapheme class provides the mapping between Scripteme and Character. The Character class is the set of Unicode characters and contains the Unicode version number, character name, HTML entity and code point. Finally, a mapping between scriptemes and the IPA provides a relationsip for querying the knowledge base from IPA to orthographic instances or vice versa. An illustration is provided in Fig. 2 . Querying on /  X  / will return the languages Dagaare [dga] and Sissala [sil] and their orthographic representations of the voiced post-alveolar affricate, \ gy [ and \ j [ , respectively. 5 Implementation 5.1 Data The African language data used in OATS were mined from Syste ` mes alphabe  X  tiques des langues africaines, 18 an online database of Alphabets des langues africaines (Hartell 1993 ). The data on the website contain several errors and these were corrected by vetting the extracted data against the original resource. Additional languages were added by hand by extracting and tabulating the data from primary resources, and then importing them into the knowledge base. Currently, OATS includes 203 languages from 23 language families. Each language contains its phonemic and orthographic inventories. A snippet of data is provided in Table 2 . 5.2 Query Linguists gain unprecedented access to linguistic resources when they are able to query across disparate data in standardized notations regardless of how the data in those resources is encoded. Currently OATS contains two phonetic notations for querying: IPA and X-SAMPA. To illustrate the querying functionality currently in place, the IPA is used to query the knowledge base of African language data 19 for the occurrence of two segments. The first is the voiced palatal nasal /  X  /. The results are captured in Table 3 .

The voiced palatal nasal /  X  / is accounted for in 136 languages, or roughly 67% of the 203 languages queried. Orthographically the voiced palatal nasal /  X  /is represented as \ ny [ , \ n  X  [ , \  X  [ , \ ni [ , and interestingly as \  X  [ . The two languages containing \  X  [ , Koonzime [ozm] and Akoose [bss] of Cameroon, both lack a phonemic /  X  /. In these languages X  orthographies, both \ ny [ and \  X  [ are used to represent the phoneme /  X  /. With further investigation, one can determine if they are contextually determined allographs like the \ d [ and \ r [ in Sisaala Pasaale.

The second simple query retrieves the occurrence of the voiced post-alveolar affricate /  X  /. Table 4 displays the results from the same sample of languages. The voiced post-alveolar affricate /  X  / is accounted for in 92 languages, or 45%, of the 203 languages sampled. The majority, over 92%, use the same grapheme \ j [ to represent /  X  /. Other graphemes found in the language sample include \ dz [ , \ gy [ , \ dj [ , \  X  [ ,and \ g  X  [ .The \ g  X  [ stands out in this data sample. Interestingly, it comes from Sudanese Arabic, which uses Latin-based characters in its orthography. It contains the phonemes /g/, /  X  /, and /  X  /, which are graphemically represented as \ g [ , \ gh [ and \ g  X  [ .

These are rather simplistic examples, but the graph data structure of RDF, and the power of SPARQL provides a complex system for querying any data stored in the knowledge base and relationships as encoded by its ontological structure. For example, by combining queries such as  X  X hich languages have the phoneme /gb/ X  and  X  X f those languages which lack its voiceless counterpart /kp/ X , 11 results are found from this sample of African languages, as outlined in Table 5 . 5.3 Querying for phonetic data via orthography The ability to query the knowledge base via a language-specific orthography is ultimately the same task as querying the knowledge base via the pivot. In this case, however, a mapping relation from the language-specific grapheme to IPA is first established. Since all transcription systems X  graphemes must have an IPA counterpart, this relationship is always available. A query is then made across all relevant mapping relations from IPA to languages within the knowledge base.
For example, a user familiar with the Sisaala Western orthography queries the knowledge base for languages with \ ky [ . Initially, the OATS system establishes the relationship between \ ky [ and its IPA counterpart. In this case, \ ky [ represents the voiceless post-alveolar affricate /  X  /. Having retrieved the IPA counterpart, the query next retrieves all languages that have /  X  / in their phonemic inventories. In the present data sample, this query retrieves 99 languages with the phonemic voiceless post-alveolar affricate. If the user then wishes to compare the graphemic distributions of /  X  / and /  X  /, which was predominately \ j [ , these results are easily provided. They are displayed in Table 6 .

The 97 occurrences of /  X  / account for five more than the 92 languages sampled in Sect. 5.2 that had its voiced post-alveolar affricate counterpart. Such information provides statistics for phoneme distribution across languages in the knowledge base. OATS is a powerful tool for gathering such knowledge about the world X  X  languages. 5.4 Code There were two main steps in the implementation of OATS. The first was the design and creation of the OATS RDF model. This task was undertaken using Protege, 20 an open source ontology editor developed by the Stanford Center for Biomedical Informatics Research. The use of Protege was primarily to jump start the design and implementation of the ontology. The software provides a user interface for ontology modeling and development, and exports the results into RDF. After the architecture was in place, the second step was the development of a code base in Python 21 for gathering data and working with RDF. This code base includes two major pieces. The first was the development of a scraper, which was used to gather phonemic inventories off of the Web by downloading Web pages and scraping them for relevant contents. Each language was collected with its ISO 639-3 code, and its orthographic inventory and the mapping relation between these symbols and their IPA phonemic symbols. The second chunk of the code base provides functionality for working with the RDF graph and uses RDFLib, 22 an RDF Python module. The code includes scripts that add all relevant language data that was scraped from the Web to the OATS RDF graph, it fills the graph with the Unicode database character tables, and provides SPARQL queries for querying the graph as illustrated above. There is also Python code for using OATS to convert between two character sets, and for error checking of characters within a document that are not in the target set. 6 Conclusion and future work OATS is a knowledge base that supports interoperation over disparate transcription systems. By leveraging technologies for ontology description, query, and multilin-gual character encoding, OATS is designed to facilitate resource discovery and intelligent search over linguistic data. This has advantages over other approaches such as pure string search for searching data or relational database models to structure data. For example, by encoding data in RDF graph data structures, different data sources can be easily merged and queried because the knowledge base X  X  structure is defined by its ontological statements, which can be of any type (and not by, say, a relational database schema that is limited to one kind of relationship, the foreign key). Each component of the ontological statement, the subject, predicate and object, contains a unique URI. Therefore, when two different datasets contain the same URI, their two graphs can be merged at that point. For example, the data in OATS could be queried at the level of distinctive features by creating another RDF graph that defines features and links them to the IPA segment URIs used in OATS. 23
The current knowledge base includes an ontological description of writing systems and specifies relations for mapping segments of transcription systems to their IPA equivalents. IPA is used as the interlingua pivot that provides the ability to query across all resources in the knowledge base. OATS X  data source includes 203 African languages X  orthographic and phonemic inventories.

The case studies proposed and implemented in this paper present functionality to use OATS to query all data in the knowledge base via standards like the IPA. OATS also supports query via any transcription system or practical orthography in the knowledge base. Another outcome of the OATS project is the ability to check for inconsistencies in digitized lexical data. The system could also test linguist-proposed phonotactic constraints and look for exceptions in data. Data from grapheme-to-phoneme mappings, phonotactics and character encodings can provide an orthographic profile/model of a transcription or writing system. This could help to bootstrap software and resource development for low-density languages. OATS also provides prospective uses for document conversion and development of probabilistic models of orthography-to-phoneme mappings. The OATS RDF/OWL file is available under Attribution-NonCommercial-ShareAlike 3.0 Unported license. 24 References
