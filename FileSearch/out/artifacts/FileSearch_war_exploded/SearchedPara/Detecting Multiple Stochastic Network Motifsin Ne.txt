 Network motifs, also known as simple building blocks of complex networks, are defined as patterns of interactions tha t appear in different parts of a network more frequently than those found in randomized networks. With the network represented as a graph, network motifs can be interpreted as the over-represented subgraph patterns embedded in the graph. Since the pioneering work by Shen-Orr et. al [1], there have been a lot of research works on detecting network motifs in biological networks [4,5,6] with the objective to gain insights on the relationship between the network struct ural properties and the functions they possess. Milo et al. [2,3] generalized the idea to c haracterize a broad range of networks, including ecosystem food webs, neuronal networks, World Wide Web, etc. Recently, network motif detection h as also been applied to social network analysis. For example, an email based social network can be well characterized by the Z-score distribution of embedded 3-node subgraph patterns [8,9].
Most of the existing works on network motif detection assume that the net-work motif is deterministic, which means that the corresponding subgraph patterns either appear completely or are missing totally. Deterministic net-work motif detection methods could give i naccurate results if the motifs exhibit stochastic properties. The corresponding stochastic network can be modeled as a mixture of a background random ensemble and families of mutually similar but not necessarily identical i nterconnection patterns represented by a stochas-tic network motif [6] (which is also called probabilistic motif in [5]). Stochastic motif detection can then be casted as a mi ssing-value inference and parameter es-timation problem under a Bayesian framework. Expectation-Maximization(EM) algorithm and Gibbs sampling can readily be adopted [6,10].

Recently, Liu et al. [11] applied the finite mixture model to analyze social media but with the assumption that there is only one stochastic motif. This paper generalizes this work to model stochastic network as a finite mixture model with k components ( k  X  1) and adopt the Bayesian approach for detecting the optimal set of multiple stochastic motifs. The paper is organized as follow. Section 2 presents the problem formulation. Evaluation results obtained via experiments performed based on both synthesis and benchmark datasets are reported in Section 3. Section 4 concludes the paper with future research directions. Analyzing triads embedded in networks have long been found important in con-ventional social network analysis. However, local interaction patterns (or termed as  X  X ies X  in social network analysis community) which are salient for characteriz-ing the overall structure of the networks could appear with stochastic variations. It makes conventional motif detection methods problematic as demonstrated in [11]. For large online networks which contain interactions of millions of different individual entities, the incorporation of stochastic models becomes especially es-sential for more robust motif detection. This is analogous to the need of hidden Markov Model (HMM) for more robust speech recognition and that of condi-tional random field (CRF) for information extraction. For stochastic motif de-tection, the target of detection is the embedded network motifs (foreground) and the other links are modeled as the random background.

Relationships or interactions among N elementary units in a population could be represented as a graph G with N nodes and a set of edges denoted by an ad-jacency matrix A =( a ij ) N  X  N . For directed graphs, a ij = 1 if there is a directed edge pointing from node i to node j , and 0 otherwise. For undirected graphs, a ij = 1 if node i and node j are connected, and 0 otherwise. Subsets of nodes in G with only the local connectivity considered define subgraphs of G . A sub-graph S with n nodes can be described by an adjacency matrix X S =( x ij ) n  X  n , where x ij is either 0 or 1 to indicate its connectivity. By sampling subgraphs of a relatively small size (say, triads) from G , the frequency distribution of their appearance can characteriz e the local structural properties of the graph. To ex-tend from this, a set of subgraphs with  X  X tructurally similar X  adjacency matrices defines a stochastic network subgraph pattern which if over-represented defines a stochastic network motif M .
 2.1 Canonical Forms of Subgraphs for Modeling Stochastic Motifs Enumerating or sampling subgraphs from a network is the pre-processing step needed before related stochastic models can be applied. A well-known problem is the handling of subgraph isomorphism. Intuitive speaking, structurally equiva-lent subgraph instances could have their nodes labeled in different orders, making those equivalent subgraphs associated wi th very different adjacency matrices. Identifying subgraph isomorphism itself is NP-complete in general [13]. Some heuristic computational tricks could be applied to reduce the computational complexity issue on average. In this work, an efficient graph/subgraph isomor-phism testing algorithm Nauty [12] is used to check for structurelly equivalent subgraphs and relabel them based on a canonical one so that their appearances can be well aggregated and the stochastic model learning can be accurate.
The remaining question is the choice of the canonical forms. Existing meth-ods for detecting deterministic motifs assume that the motifs are independent and the choices of the canonical forms for the isomorphically equivalent groups of subgraph instances can just be independently considered. However for stochastic motifs, one should expect a stochastic motif model which gives a high proba-bility value to the canonical form of a subgraph pattern A should give also a relatively high value to that of a subgraph pattern B which is a subgraph of A . In other words, the canonical forms for the different isomorphically equivalent subgraph patterns should be chosen in such a way that one being the subset of another should be  X  X ligned X  as reflected in their node labeling orders. With this considered, we carefully derived the set of canonical subgraph patterns for subgraphs with 3 nodes as shown in Figure 1. For subgraphs with more than 3 nodes, we are currently studying the possibility of building the corresponding canonical forms efficiently by joining a nd/or extending the canonical adjacency matrices of 3-node subgraphs [14]. 2.2 Finite Mixture Model With the assumption that a stochastic network can be modeled as a mixture of families of independent foreground stochastic motifs embedded in a background random ensemble, each subgrah in the stochastic network can be regarded as either generated from the background or from one of the foreground motifs. In this paper, we extend from the mixture model in [6,11] that multiple stochastic motifs can be detected and the number of motifs required can be estimated.
Assuming there exist k stochastic motifs M f = { M 1 ,  X  X  X  ,M k } which are represented as a set of probability matrices  X  f = {  X  1 ,  X  X  X  , X  k } , with  X  h = (  X  from node i to j in the h -th motif. The background ensemble M 0 is characterized by a family of randomized networks generated from a given stochastic network which contain the same number of nodes and edges, and the same statistics for the nodes X  in/out degrees.

Moreover, let { S 1 ,  X  X  X  ,S W } denote a set of subgraph instances sampled from a given network, X = { X 1 ,  X  X  X  , X W } denote the adjacency matrices correspond-ing to the subgraph instances (observed data) where X w =( x w ij ) n  X  n and x w ij = { 0 , 1 } , Z w h denotes an indicator variable taking the value of 1 if subgraph instance S w comes from the model M h or 0 otherwise, and thus the missing data of the problem, where Z w =( Z w 0 ,  X  X  X  ,Z w k ) T . The probability that X w comes from M h is given as Also, let  X  =(  X  0 ,  X  X  X  , X  k ) be the mixing portion of the mixture model which also denotes the prior probabilities of Pr( Z w =1) ,w = { 1 ,  X  X  X  ,W } .
The stochastic motif detection pro blem can thus be casted as a maximum likelihood estimation problem for  X  = {  X  f ,  X  } where the log-likelihood function for the complete data is given as l (  X  ) = log p ( X , Z |  X  )= The EM algorithms for estimating  X  f and  X  will be presented in the next section.
For the background model, we are interested in the probability of observing the subgraph instance S w in the background model p ( X w |  X  0 ) instead of  X  f .As in [6,11], the background model is estimated by counting the subgraph instances in randomized networks. We first generat e a set of randomized networks. For each randomized network describ ed by an adjacency matrix A =( a ij ) N  X  N ,weran-domly choose pairs of connections and repeatedly swap the target of them until the network is well randomized, while keeping the incoming and outgoing degrees of each node remain unchanged, i.e., keeping the summation of each row and each column in the adjacency matrix unchanged. Subgraphs are then sampled from the randomized networks. p ( X w |  X  0 ) is estimated as N w /N total ,where N w is the num-ber of the subgraph S w sampled from the ensemble of the randomized networks and N is the total number of subgraphs sampled with the same size with S w . 2.3 Basic EM Algorithm For learning probabilistic models with missing data (unknown motifs for our case), the Expectation-Maximization (E M) algorithm [15] is typically used for obtaining the Maximum Likelihood (ML) estimates of the model parameters. The EM algorithm produces a sequence of estimates by alternatingly applying the E-step and M-step until it converges.  X  E-step: Compute the complete da ta expectation of log-likelihood E [ l (  X  )]  X  M-step: The model parameters are esti mated by maximizing the expectation Note that p ( X w |  X  0 ) is estimated based on the subgraph statistics in the ensem-ble of randomized networks as explained in the previous section. 2.4 Learning the Optimal Number of Motifs To determine the optimal number of stochastic motifs automatically, we adopt the Component-wise EM for Mixture (CEM 2 ) which was proposed to integrate both the model parameter estimation and model selection steps into one single EM algorithm [16]. The general idea of CEM 2 is to update the parameters of each component one by one so that the co mponent with very low support by the data can be pruned. CEM 2 starts from all possible k -component mixtures and prunes the died components(  X  h = 0) sequentially at each EM iteration.
CEM 2 implements the minimum message length (MML) criterion [17] to select the number of components. The best par ameter estimate for the mixture model is the one minimizing the message length L [  X  , X ], which is given by where L [  X  ] is the minimum message length for prior information, and L [ X |  X  ]is the minimum message length for data which can be estimated as  X  log p ( X |  X  ). As in [16], the final cost function (message length) L [  X  , X ]isgivenby L [  X  , X ]= where k nz is the number of components with non-zero probability, and N is the number of parameters specifying each component. The detailed steps of CEM 2 to motif detection can be found in Algorithm 1. Algorithm 1. CEM 2 Algorithm In this section, we present e xperimental results to demo nstrate first the correct-ness of the detected stochastic motifs using synthetic datasets. Then, we further present the results of applying the stochastic motif detection algorithm to some real datasets and provide interpretation of the results obtained. 3.1 Results on Synthetic Networks We generated a set of synthesized networks for correctness evaluation. Each network is generated by 1) creating a group of subgraphs coming from a known set of reference stochastic motifs as foreground models and 2) adding random links among the subgraphs to generate random background. In particular, we chose the subgraphs commonly found in many real networks, e.g., id is 38, 46, 166, 174, and 238 (see Fig. 1) as the reference motifs. We then applied our method to the synthetic networks we generated. In order to avoid the EM algorithm being trapped into local optima, we ran the EM algorithm several times with different initializations to report the best  X  in terms of the likelihood value.
Figs. 3(a) -3(e) show the stochastic motifs obtained by the multiple motif detection method in the synthetic netwo rks. According to Fig. 2(a), the value of E [ l (  X  )] increases a lot when the motif number varies from 1 to 5. There is a sharp drop in the increasing rate for the value of E[ l (  X  )] when k =5 , 6 , 7. This is consistent to the fact that there are 5 reference motifs used for generating the synthetic networks. A similar conclusion can be drawn by referring to Table 1. 3.2 Results on Benchmark Datasets We have also applied the stochastic motif detection algorithm to large-scale social network datasets named  X  X mazon X ,  X  X iki-Vote X ,  X  X lashdot X  and  X  X pinions X  which are obtained as described in [18,19]. The dataset  X  X mazon X  considers the Customers Who Bought This Item Also Bought feature of the Amazon website. If a product A is frequently co-purchased with product B , the graph contains an directed edge from node A to node B .  X  X iki-Vote X  is a network consisting of voting interaction for Wikipedia admin candidates. The link refers to a vote from a user to an admin candidate represented a user agree or disagree the promotion of the admin candidate.  X  X lashdot X  is a social network of technology blog. The links in this network are the designations of  X  X riends X  or  X  X oes X .  X  X pinions X  is atrustnetwork,wherewecanknowthetru st or distrust relations of the users from the directed links between each othe r. Table 2 lists the statistics of these four datasets. These networks have order of tens to hundreds of thousands of nodes and hundreds of thousands to millions of edges. In each network, we know the directions of all the edges.

Figs. 2(b) -2(e) show the expected maximum log likelihood values E[ l (  X  )] of the mixture models with different component numbers in the four datasets. Here we can determine the best number of motifs by visual inspection to identify the points where the increase of E[ l (  X  )] starts to slow down. Also, by referring to tables 3 -6, the values of  X  with different motif numbers in these four datasets also hint us the best optimal number to choose from (as marked with bold face in the tables). For instance, for Amazon network, when the number of motifs k is set to 6, the value of  X  6 is very small. This hints that the 6-th motif is only  X  X upported X  by a very limited number of subgraph instances and thus 5 stochastic motifs could be enough. Similar results were obtained for Wiki-Vote, Slashdot and Epinions networks.

Fig. 3 shows the stochastic motifs detected in the datasets we used. Similar to [11], one can make interpretations on the networks of study based on the motifs extracted, which can in turn be validated by related domain experts. For instance, we made the following observations which seems revealing some local structural properties of the networks:  X  By referring to the results obtained based on the Amazon dataset (Figs.  X  From the results obtained based on the Wiki-Vote dataset (Figs. 3(k) -3(m)),  X  All the motifs detected in these social n etworks consist of a basic feed-forward As inspired by [18], we plan to make ref erence to different social psychology theories developed in social science to va lidate and gain further insights and thus explanation on the underlying social behaviors embedded in the social media. 3.3 Effectiveness of CEM 2 in Estimating Optimal Number of Motifs Fig. 4 shows how the cost functions L (  X  , X ) evolve throughout the CEM 2 itera-tions. Starting from the maximum possible number of motifs ( k nz =13formotif size is 3), the cost function decreases as the CEM 2 iterations proceed. When some components are prune d as described in the algorithm, the value of the cost function would increase to some extent. After some iterations, the remaining motifs will then be learned to better fit to the data, and thus the cost function decreases again. The number of motifs is automatically estimated by choosing with the one which gives the lowest cost function value. For synthetic data, the mixture model with 5 motifs gives the lowest cost function value, which is consis-tent to that estimated using the basic EM. In the four social networks we used, the cost functions have the lowest values when the motif numbers become 3, 3, 3 and 5 respectively, which are also consistent to the results observed in Section 3.2, but here we need to run CEM 2 only once. Fig. 5 shows the evolution of motifs annihilation by taking the Wiki-Vote network as an example. Figs. 5(a) -5(e) are the motifs when the number of motifs is 5. With the iteration continues until convergence, the number of motifs becomes to 3, the corresponding motifs are listed in Figs. 5(f) -5(h). 3.4 Computational Complexity The overall complexity include those for subgraph sampling, generating of ran-dom networks, and the parameter estimation via the EM algorithms.
 The complexity of sampling subgraphs of n nodes in a network is R S = O ( N s K n  X  1 n n +1 ), where K is a small constant value corresponding to the aver-age node degree in the network, and N s is the number of subgraphs sampled. The background model is simulated by randomized networks which generated by the switch method as in [2,11], where many rounds of  X  X witchings X  of two edges randomly selected from the real network are conducted while keeping the in/out degree of each node fixed. In so doing, the complexity of generating a random network is O ( T s N e ) (the number of switches), where T s is the switch times per edge (a random number in the range of 100  X  200) and N e is the num-ber of edges in the real network. Overall time complexity for pre-processing is
For the basic EM algorithm, the complexity of each iteration is O ( n 2 N s ). So, the total complexity of EM algorithm together with pre-processing is O ( N s  X  K EM algorithm and k is optimal number of motifs. For CEM 2 , it is only slightly computationally heavier than the basic EM algorithm due to the multiple E-steps to recompute E [ Z w h ] [16]. As updating E [ Z w h ] needs only full computation of Eq.(4) for j = h .For j = h ,theterms( X w |  X  h ), which could contribute a lot to the computational cost of E-step, remain unchanged and thus only need to be computed once per sweep, like in the basic EM. However, the basic EM should be run several times with different motif numbers. CEM 2 is needed to run only once. So, the overall time complexity of CEM 2 is lighter than basic EM.
For further speedup, as the data are assumed independent and identically distributed ( i.i.d ) and thus can be partitioned into multiple subsets, our method can also take the advantage of parallel computing on GPUs [20] so as to be more scalable to large-scale datasets. Motif detection provides an important tool to assist the study of structural prop-erties in network data for domains like bioinformatics and on-line social media. We proposed the use of the finite mixture model to detect multiple stochastic motifs in network data and a related CEM algorithm for automatically deter-mining the optimal number of motifs embedded and the model parameters of the motifs. We applied the method to both synthetic and several benchmark datasets and discussed how the obtained motifs could be used to gain an in-depth understanding of the underlying stochastic local interaction patterns.
Our method works well for analyzing the n etwork structural properties based on small motifs (i.e., 3 or 4 nodes). For future work, more scalable (possibly parallel) implementation will be needed if the analysis is to be carried out for motifs of various sizes. From the perspective of further improving modeling and thus the analysis power, related research directions include: 1) extending the method to take into consideration the sign of the edges, and 2) incorporating the timing information on edges to detect temporal motifs as a family of similar interaction patterns which over-repre sented throughout the period of time. Acknowledgments. This work was supported by the General Research Fund (HKBU210410) from the Research Grant Council of the Hong Kong Special Administrative Region, China.

