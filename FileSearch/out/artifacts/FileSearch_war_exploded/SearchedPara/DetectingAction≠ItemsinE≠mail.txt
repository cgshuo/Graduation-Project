 Categories and Subject Descriptors: H.3.3 [Inf ormation Stor -age and Retrie val] : Information Search and Retrie val; I.2.6 [Ar -ticial Intelligence] : Learning; I.5.4 [Patter n Recognition] : Ap-plications General Terms: Experimentation Keyw ords: Text classication, e-mail, n -grams, SVMs
E-mail users have a dif cult time managing their inbox es in the face of mounting challenges. These include prioritizing e-mails from a variety of senders, ltering junk e-mail, and quickly tak-ing action on items that demand the user' s attention. Automated action-item detection tar gets the third of these problems by detect-ing e-mails which requir e an action or response, and within those e-mails, highlighting the specic text that indicates the request.
In contrast to action-item detection which aims at locating ex-actly where the action item requests are contained within the email body , typical text cate gorization (TC) merely assigns a topic label to the entire message  X  whether that label corresponds to an e-mail folder or an inde xing vocab ulary [8]. In further contrast to TC, action-item detection attempts to reco ver the sender' s intent, i.e. whether she means to elicit response or action on the part of the recei ver. Whereas TC by topic [5, 6, 9], TDT [1], and even genre-classication [7] work well using just indi vidual words as features, we belie ve that action-item detection is the rst TC task where we clearly must mo ve beyond bag-of-w ords  X  albeit not too far, as bag-of-n -grams seems to suf ce.

While Cohen et al. [3] describe an ontology of  X speech acts X  that subsumes action-items, their methods only mak e use of human judgments at the document-le vel. In contrast, we consider whether accurac y can be increased by using ner -grained human judgments that mark the specic sentences and phrases of interest. Corston-Oli ver et al. [4] consider detecting items in e-mail for a  X To-Do List X  using a single classier; howe ver, the y do not explicitly com-pare what if any benets ner -grained judgments offer .

In contrast to pre vious work, we focus on the benets that ner -grained (more costly) sentence-le vel human judgments offer over coarse-grained document-le vel judgments. Additionally , we con-sider multiple standard text classication approaches and analyze the dif ferences of a document-le vel vs. a sentence-le vel approach.
To pro vide better end-user benet, a system would both detect an action-item document and indicate the specic sentences which contain the action-items. Therefore, there are three basic problems: document detection , document ranking , and sentence detection .
The labeled data can come in one of two forms: a document-labeling pro vides a yes/no label for each document as to whether it contains an action-item; a phr ase-labeling pro vides a yes label for each action-item. Ob viously , it is straightforw ard to generate a document-labeling consistent with a phrase-labeling by labeling a document  X yes X  if and only if it contains at least one  X yes X  phrase.
To train classiers, we can tak e one of two approaches related to the form of the labeled data. The document-le vel vie w treats each e-mail as a learning instance with a class-label. In the sentence-level vie w, after automatic sentence-se gmentation, each sentence is treated as a learning instance with an associated class-label. Repr esentation and Implementation Ov erview For this study , only the body of each e-mail message was used. We compare a standard bag-of-w ords or unigr am representation to a bag of n -grams. We also retain sentence-ending punctuation as a tok en. For the bag of n -grams, beginning-of-sentence and end-of-sentence mark ers are included. Finally , for the sentence-le vel classiers using n -grams, we also code the position of the sentence relati ve to the e-mail in octiles. For feature selection, we use chi-squared and choose the number of features that yield the optimal document-le vel F1 for that classier during nested cross-v alidation.
In order to compare the document-le vel to the sentence-le vel ap-proach, we compare predictions at the document-le vel. We use the RASP parser [2] to automatically segment the text of the e-mail, and then treat any sentence that contains at least 30% of a mark ed action-item segment as an action-item.

We applied a variety of standard TC algorithms: k -NN (s-cut), multinomial na  X  ve Bayes, and SVMs. Once a sentence-le vel classi-er mak es a prediction for each sentence, we combine these predic-tions into a document-le vel prediction and a document-le vel score. We use the simple polic y of predicting positi ve when any of the sentences is predicted positi ve. For ranking, the document score is the length normalized sum of the sentence scores abo ve threshold.
To compare the performance of the classication methods, we use F1 and accurac y. We perform standard 10-fold cross-v alidation on the set of documents. For the sentence-le vel approach, all sen-tences in a document are either entirely in the training set or en-tirely in the test set for each fold. For signicance tests, we use a two-tailed t-test to compare the values obtained during each cross-validation fold with a p-v alue of 0 : 05 .

Our corpus consists of e-mails obtained from volunteers at our uni versity . After eliminating duplicate e-mails, the corpus contains 744 e-mail messages. To balance cogniti ve load in the user studies (omitted here) and pre vent chronological taints of cross-v alidation, the studies reported here are performed with a version of the corpus after quoted material is remo ved by hand.

Two human annotators labeled all the messages and identied each segment of the e-mail which contained action-items. At the document-le vel, the kappa statistic for inter -annotator agreement is 0 : 85 and 0 : 82 at the sentence-le vel. After reconciling the judg-ments there are 328 e-mails containing action-items.
The primary hypothesis is that n -grams are critical for this task at the document-le vel. Examining Table 1, the y impro ve performance for every classier except na  X  ve Bayes. Na  X  ve Bayes is hurt by the n -gram representation because of excessi ve double-counting. The signicance results for comparing n -gram impro vement with a x ed classier are summarized on the left of Table 2 (F1 signif-icance in bold, Accurac y with a y ). N -grams sho w signicant im-pro vement at the document-le vel and the best performance overall. kNN Ngram Ngram Sentence Sentence na  X  ve Bayes Unigram Ngram Sentence Sentence Table 2: Summary for n -grams versus unigrams ( left ) and sentence-le vel classiers vs. document-le vel classiers ( right ).
As would be expected the dif ference between the sentence-le vel n -gram and unigram representations is small. This is because the windo w of text is so small that the sentence-le vel unigram represen-tation implicitly picks up on the power of the n -grams. Therefore, the ner -gr ained sentence-le vel judgments allo w a unigram repre-sentation to succeed but only when performed in a small windo w  X  beha ving as an n -gram representation for all practical purposes.
Since the sentence-le vel classier approach would not be pos-sible without these costly ne-grained judgments, we now turn to the question of whether the sentence-le vel classiers produce bet-ter document detection than a document-le vel classier . In order to answer this question, we compare the best sentence-le vel result with the best document-le vel result on the right of Table 2 (signif-icance in bold). The sentence-le vel approach wins entirely across the board  X  lacking signicance only for F1 for SVMs. Sentence detection results are presented in Table 3 for completeness.
The effecti veness of sentence-le vel detection argues that label-ing at the sentence-le vel pro vides signicant value. Document-level detection using sentence-le vel classiers works surprisingly well given most researchers' expectations of low recall for a single sentence. Our empirical analysis has demonstrated that n -grams are of key importance to making the most of document-le vel judg-ments. When ner -grained judgments are available, then a standard bag-of-w ords approach using a small (sentence) windo w size can produce results almost as good as the n -gram based approaches. This material is based upon work supported by DARP A under Con-tract No. NBCHD030010. An y opinions, ndings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reect the vie ws of DARP A or DOI-NBC.
We would also lik e to extend our sincerest thanks to Jill Lehman whose efforts in data collection were essential in constructing the corpus. Finally , we gratefully ackno wledge Scott Fahlman for his encouragement and useful discussions on this topic.

