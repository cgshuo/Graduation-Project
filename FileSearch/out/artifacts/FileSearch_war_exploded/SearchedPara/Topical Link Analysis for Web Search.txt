 Traditional web link-based ranking schemes use a single score to measure a page X  X  authority without concern of the com-munity from which that authority is derived. As a result, a resource that is highly popular for one topic may dominate the results of another topic in which it is less authoritative. To address this problem, we suggest calculating a score vec-tor for each page to distinguish the contribution from dif-ferent topics, using a random walk model that probabilis-tically combines page topic distribution and link structure. We show how to incorporate the topical model within both PageRank and HITS without affecting the overall property and still render insight into topic-level transition. Experi-ments on multiple datasets indicate that our technique out-performs other ranking approaches that incorporate textual analysis.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Algorithms, Performance Keywords: Web search engine, link analysis, HITS, PageRank
The use of link analysis techniques to estimate the impor-tance of a page made web search engines useful, and was central to the meteoric rise of Google as the leading com-mercial engine. Today, however, traditional web link anal-ysis is necessary, but insufficient: Google presently claims more than one hundred factors in calculating the results of a query [7]. One possible reason for this is that in tradi-tional web link analysis, a page X  X  authority is measured by the summation of incoming authority flows, without concern for the community from which that authority is derived. As a result, a resource that is highly popular for one topic may dominate the results of another topic in which it is less au-thoritative. For example, a popular news website will be Copyright 2006 ACM 1-59593-369-7/06/0008 ... $ 5.00.
The remainder of this paper is organized as follows: the background and related work will be introduced in Section 2, with a focus on combining text and link analysis. The topical link analysis model is then detailed, with the novel generalizations of well-known link analysis techniques and additional issues that affect topical approaches. The exper-iments and results will be shown in Section 4. We conclude with a discussion and future work.
Much research has considered the union of text and link analysis and some even consider the issue of topicality. We review them here.

We start by introducing some notation:
While at IBM Research, Jon Kleinberg proposed [11] that web documents had two important properties, called hub-ness and authority, as well as a mechanism to calculate them. Pages functioning as good hubs have links pointing to many good authority pages, and good authorities are pages to which many good hubs point. Thus, in his Hyperlink-Induced Topic Search (HITS) approach to broad topic in-formation discovery, the score of a hub (authority) depended on the sum of the scores of the connected authorities (hubs): Kleinberg didn X  X  calculate these scores globally; instead, he used the subset of the web that included top-ranked pages for a given query, plus those pages pointed to and were pointed by that set, the union of which he called the base set. When first introduced, HITS was able to work with the existing search engines (which were mostly textually based) and generate results (at least for broad topics) that were comparable to hand-compiled information in directo-ries such as Yahoo.

HITS uses the results of a search engine query to make its analysis query-specific, but sometimes the topical focus of the base set can drift to a broader or more popular topic. In addition, the one-step expansion can bring in unrelated yet popular pages that can end up with high ranks. A number of improvements have since been proposed.

CLEVER improvements to HITS. IBM X  X  CLEVER [9, 5] project extended HITS. The ARC algorithm [6] ex-pands the core set with nodes up to two steps away, and weights links by the similarity between the query and the text surrounding the hyperlink.
 Bharat and Henzinger X  X  improvements to HITS.
 Bharat and Henzinger [2] proposed a number of improve-ments to HITS. The first change is an algorithm called imp , selecting among the possible destinations equally, the surfer chooses using a probability distribution generated from the relevance of the target to the surfer X  X  query.

Thus, for a specific query q , page j  X  X  query-dependent score can be calculated as IS q ( j )= d Since it is not feasible to calculate this query-specific PageRank at run-time, term-specific PageRanks are gener-ated in advance for all terms, and in the case of a multi-term query, the resulting page scores are combined using the weights of the terms from the query.
In this section, we argue that every aspect of reputation has a context within which it is interpreted, and that in-corporating that context into automated analyses of rep-utation can potentially provide more accurate models. In some cases, it can provide features not otherwise possible. This view is broad, and certainly encompasses many of the approaches we have described above.

In the rest of this section, we will start by providing an overview of the topical link analysis approach that we use, and then apply it to the two well-known traditional link analysis frameworks: PageRank and HITS.
The basic idea of topical link analysis is to incorporate topic distribution into the representation of each web page as well as the importance score of each page. Therefore, there are at least two vectors associated with each page: the content vector and the authority vector.
 ability distribution used to represent the content of u ,in which each component represents the the relative contribu-tion from each topic within the content of u to the content of u as a whole. This vector is static and solely determined by the content. We can use a textual classifier to provide such a soft classification for each document (or query) across T predefined topics. As shown in Figure 1, a page X  X  content is represented by the corresponding content vector in the topic level. This vector is normalized such that the sum of the probabilities is 1. Since a query can also be viewed as a short document, query q can also have an associated content vector C q , which may be generated by a textual classifier, to represent its relevance to each topic.

In contrast, we assign each page u an authority vec-where A ( u k ) denotes page u  X  X  importance score on topic k . (In the HITS version, besides the authority vector, there is a corresponding hubness vect or as well.) This vector is ob-tained from the proposed topical ranking algorithm, which is dynamic during authority propagation. From Figure 1, we can tell that the summation A ( u )= to the original non-topical importance score, e.g., the score obtained by the PageRank algorithm, and a page X  X  author-ity distribution may differ from its content distribution in the topic level.

When the authority vector for each page is ready, a query-specific importance score can be calculated for each query the probabilities to  X  J J  X  X rom v 1 to x 1 , x 2 , x 3 are dC ( x 1 ), dC ( x 2 ), dC ( x 3 ) respectively.

In summary, at each step of the random walk, the surfer may take any one out of the following three atomic actions: jumping to a random page and focusing on a random topic in the target page (action J J ); following a hyperlink and staying in the same topic (action F S ); following a hyperlink and jumping to any topic in that page (action F J ). Thus, the surfer X  X  behavior can be modeled by a set of conditional probabilities.
 And the probability to arrive at topic i in target page u by the above actions can be described as
The probabilistic model can be used to compute the prob-ability that surfer is on page u for topic i , i.e., A ( u i ). A ( u i )= Let A ( v ) denote the probability that a surfer at any time is browsing page v ,with: Then Equation 3 can be simplified as:
After the propagation converges, each component A ( u i ) authority score of page u on topic i . A ( u )istheoverall authority score. It can be proved that the sum of the topical authority scores A ( u i ) is identical to the one calculated by original PageRank algorithm. In other words, if the details of topic transitions are hidden, the model will reduce to the original PageRank.
 The only difference between normalized HITS and original HITS is that a node X  X  authority (hubness) will be distributed among its in-coming links (out-going links) to its parent (child) during propagation, while in original HITS, every in-coming link (out-going link) will get the entire authority (hubness) from the node.
In the above model,  X  is the probability of the surfer to keep his interest when following an outgoing link, which is a tunable constant in experiment. However, a more reasonable consideration is that the decision about whether to keep a topic is usually dependent on the content of the current page. If this page is irrelevant to the topic of interest, the surfer is more likely to shift interest to another topic when entering a new page. In this case,  X  canbemeasuredbytherelevance of the topic to the the current content as C ( v k ), which is an variable instead of a constant. In the experimental section, we will check both options for  X   X  X  setting.

Furthermore, hyperlinks can be divided into two types, intra-domain links and inter-domain links. The links that link two pages in the same domain are called intra-domain links, otherwise, they are called inter-domain links. Accord-ing to the analysis in [10], the intra-domain links play less value than the inter-domain links when computing pages X  reputation. We will investigate this issue by varying the relative weight of intra-domain links to inter-domain links (from 0 to 1) in our model.
To understand how the topical model works, we take a initial look at a small web made up of six pages, as shown in graph 2(a). Each page is assigned a content vector across three pre-defined topics: Arts (A), Sports (S) and Business (B).

Interestingly, we assume page 5 doesn X  X  contain any con-tent, and as a result, a textual classifier generate a nor-malized distribution of (0.3,0.3,0.3) assuming such page X  X  relevance to three topics are equal. Obviously such an as-signment does not reflect the page X  X  real topicality; however, our approach can help determine what the page is known for by using topical link analysis. As shown in Table 2(b), after running Topical PageRank, page 5 will obtain an authority vector 0.167, 0.065, 0.052, which means it is voted as the most authoritative page in the  X  X rts X  category. Since there are two  X  X rts X  pages (page 3 and page 4) cite page 5, it is reasonable to consider page 5 a good page about  X  X rts X  instead of a page irrelevant to any topic. Similarly, page 6 is classified as a  X  X ports X  initially, but the  X  X rts X  page link-ing (page 4) to it grants it some authority in  X  X rts X . As a result, the topicality of page 6 will be a mixture of its static topicality and inherited topicality.
To evaluate the behavior of our proposed topical link anal-ysis algorithms, we compare the retrieval performance of well-known ranking algorithms versus the proposed topical link analysis algorithm. Comparisons are conducted among PageRank schemes and HITS schemes separately.
In their work on link spam identification, Wu and Davi-son [19] selected twenty queries from those used by previ-
In this section, we compare our Topical HITS (T-HITS with imp re-weighting) to traditional HITS [11], Bharat and Henzinger X  X  imp (IMP) [2] and CLEVER X  X  ARC weighting (ARC) [6] on the 20 query-specific datasets. Since our ap-proach adopted out-link/in-link normalization in the calcu-lation of authority/hubness, we also apply this hyperlink weight normalization on the above three approaches, gen-erating the corresponding variations: normalized HITS (N-HITS), normalized IMP (N-IMP) and normalized ARC (N-ARC). As a result, there are seven approaches involved in the comparison.
Since there is no standard evaluation benchmark for the 20 query-specific datasets, the relevance between query and search results had to be inspected manually.

In our evaluation system, the top ten search results gener-ated by various ranking algorithms were mixed together. To evaluate the performance, we enlisted a total of 43 partic-ipants, to whom a randomly chosen query and a randomly selected set of ten results (of those generated for the given query) were shown. The subjects were asked to rate each result as quite relevant, relevant, not sure, not relevant, and totally irrelevant, which were internally assigned the scores of 2, 1, 0, -1, -2, respectively. A page is marked as good if its average score across participants is greater than 0.5.
In this way, we can calculate the overall average precision (P@10) for each approach X  X  top 10 results for 20 queries; in addition, the overall average score (S@10) is calculated to further explore the quality of retrieval since precision cannot distinguish top pages from merely good ones. We used these two metrics to compare the performance of various ranking approaches introduced above.
Performance comparisons using precision and score are shown in Figures 3(a) and 3(b), respectively. With a preci-sion of 80% and an average score of 1.12, our approach out-performs the other six. The second best is N-ARC, which gets 76% precision, with an average score of 1.08. N-IMP is ranked third with a precision of 71.5% and an average score of 0.94. Furthermore, we performed single-tailed t-tests to compare our T-HITS to N-ARC and N-IMP separately to study whether these improvements are statistically signifi-cant. The tests indicate that the improvement of T-HITS over N-IMP is significant (p-value=0.0005) while over N-ARC is not significant (p-value=0.26).

We noted that out-link/in-link normalization played a key role in boosting retrieval performance. This is because HITS-based approaches are vulnerable to link spam and the TKC effect [12], which will push pages within a tightly-knit community to high rankings even though the pages are not relevant, or pertaining to just one aspect of the topic. Such effect may derail HITS-based approaches and prevent them from finding relevant authorities. Normalizing link weights can alleviate such effects, thus providing better results.
In the above experiment, we show that our model works well on query-specific datasets. In this experiment, we find out whether the topical model retains its superiority when applied to global datasets as well. Figure 4: Combination of IR and importance scores. the final outputs. Apparently, the parameter  X  will impact performance; thus for each method, we tune  X  to achieve the best performance.
Figure 4 shows the precision@10 as  X  is varied for the four approaches described above. As can be seen, T-PR curve is almost always above other curves in the graph, showing that Topical PageRank generally outperforms other approaches. T-PR combined with BM2500 gets the highest performance when  X  is 0.89 with P@10 of 0.148. The TSPR combination gets the best result of 0.136 when  X  is 0.96. Both PR and IS achieve their best performance when  X  is 0.98, with P@10 of 0.134 and 0.124 respectively. All the curves converged to the baseline when  X  is 1, which corresponds to the per-formance of BM2500 (P@10=0.118) weighting scheme. As can be seen from this figure, all ranking algorithms achieve higher performance than the baseline, which confirms that link analysis can improve performance on TREC data.
Figure 5 shows the overall perf ormance comparison, where we selected the best result of P@10, MAP and Rprec for each approach. Topical PageRank exceeds other approaches on all of the metrics. An observation is that both TSPR and IS do not work well on TREC, as TSPR shows slight improvement over traditional PageRank, and IS performs even more poorly.

To determine whether these improvements are statisti-cally significant, we performed several single-tailed t-tests. Table 2(a) shows the comparison of various approaches with the BM2500 baseline; only Topical PageRank performed sig-nificantly better than the baseline on all metrics at a 95% confidence level. For completeness, we also compared Top-ical PageRank to all other approaches. Even though the results, listed in Table 2(b), show that Topical PageRank only outperformed IS on the metrics of MAP and Rprec, we note that it is difficult to seek significant performance im-provements given a topic distillation task where only a few relevant documents (10.32 on average) are associated with each query.
In this section, we study how the parameters affect the performance of our proposed algorithms, where all parame-ters were tuned on TREC dataset. Figure 6 shows the vari-ance of Topical PageRank X  X  P@10 with different parameter settings.
 topic when following a link, which can be either set as a constant within [0,1] or a variable measured by the topic X  X  Naive Bayes score in the current page, as discussed before. An alternative explanation is that a page X  X  topicality came from two factors, the contents of neighboring pages and its own contents, which are combined by  X  . From the graph, we can tell that such combination is necessary, since good result is always achieved in someplace between 0 and 1. Moreover, most curves get their best performance when  X  is set as the variable rather than a fixed constant.

In summary, our algorithm achieved the best result when  X  is set as the variable and  X  is 0.1, we used this setting in all of our experiments.
An alternative interpretation of our work is that the per-node topical distributions with which we start and which is generated by link analysis is simply a representation in a re-duced dimensionality space (equal to the number of topics). We start with vectors of length unity, but scale them based on link analysis authority calculations, and further adjust them via topical flows.

To examine this interpretation, we considered the per-formance of a simplified system X  X ne that calculated, for a page u , a Static Topical PageRank score of ST-PR( u ) =PR( u ) C u and a Static Topical authority score of ST-HITS( u ) = N-HITS( u ) C u . We tested this formulation on the TREC dataset, and found that ST-PR achieved P@10 of 13.6%, which while not as good as our Topical PageRank score of 14.8%, still exceeded or matched all prior tech-niques.Similarly, ST-HITS achieved P@10 of 76.5% com-pared to our Topical HITS precision of 80%.

Therefore, we draw the conclusion that the topic distri-bution is an effective dimensionality reduction technique for content, but also that the flow of topicality in our topical link analysis techniques is necessary for top performance.
We have proposed a topical random walk model that probabilistically combines page topic distribution and link structure. We demonstrated how to incorporate this topical model within both PageRank and HITS without affecting the overall authority (or hub) score, and still provide a dis-tribution of the authority across topics. Experiments on multiple data sets indicate that our algorithm outperforms a number of existing ranking approaches (both HITS-based and PageRank-based).

In the future, we expect to further study the effects of link weights (as in [9, 5, 4]). This is to include models of which links are more likely to be followed, or are of more value, or to assign a topic distribution to the links as well. We would also like to consider different kinds of topic dis-tributions, e.g., fine-grained distributions (such as terms), coarse distributions (including binary classification such as spam/not-spam, or business versus educational), abstract distributions (like those formed as a result of dimension re-duction).
 We thank Baoning Wu for providing the twenty query-specific datasets. This material is based upon work sup-ported by the National Science Foundation under Grant No. 0328825.
