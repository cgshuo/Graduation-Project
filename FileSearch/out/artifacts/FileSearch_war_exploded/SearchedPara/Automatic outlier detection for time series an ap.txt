 REGULAR PAPER Sabyasachi Basu  X  Martin Meckesheimer Abstract In this article we consider the problem of detecting unusual values or outliers from time series data where the process by which the data are created is difficult to model. The main consideration is the fact that data closer in time are more correlated to each other than those farther apart. We propose two varia-tions of a method that uses the median from a neighborhood of a data point and a threshold value to compare the difference between the median and the observed data value. Both variations of the method are fast and can be used for data streams that occur in quick succession such as sensor data on an airplane.
 Keywords Time series  X  Outliers  X  Jaccard coefficient  X  Simulation  X  Sensor data 1 Introduction Time series data are observations collected sequentially over time. Consider as manufacturing plant, the hourly yield from a chemical process, the altitude of an airplane every second, and so on. In all these instances, a measure (stock price, number of defects, etc.) is associated with a time stamp (day, hour, minute, etc.) as it is collected. When observations are collected at frequent time intervals, large data sets in the form of time series are generated. The analysis of time series per-mits extracting information from the data and gaining insight into the dependence of observations. Efficient data processing and extraction of relevant information from these data are needed in many businesses. For example, in the area of fi-nancial services, large amounts of data are used to monitor credit card usage and detect fraudulent activity. In the manufacturing sector, data are used to detect ma-chine failure and process shifts and trends. An important example from the auto-motive and aerospace industries is the use of data to detect abnormal operating conditions of a vehicle or an aircraft and improve safety.
 need to be processed and synthesized efficiently to provide relevant information to engineers, researchers, accident investigators, operators, and many other users. This becomes complicated if the behavior of the series varies over time. How-ever, for most time series, the values close together in time are more correlated with each other than those that are separated in time. It is important to take into consideration the fact that time series observations are often affected by unusual events or disturbances that create spurious effects in the series and result in ex-traordinary patterns. These unusual values (or outliers) in the data have adverse effects on understanding the properties of the time series. Identification of outliers is very important in many fields that deal with time series data since they can con-tain information that may lead to an intervention of a process and prevent failures or abnormal operating conditions. Thus, there is a need for effective and efficient methods for outlier detection in real time.
 data are used to monitor aircraft systems. Information extracted from these data is used by maintenance engineers to prevent failures and by investigators to deter-mine the causes of an accident. The data are obtained in the form of signals that are captured by hundreds of sensors with different time stamps at various sam-pling frequencies. These signals may be correlated and noisy; in addition, missing data points as well as unusual values are common. In order to supply engineers, pilots, and other users with efficient analysis tools, there is a need to extract high quality information from these data. For this purpose, the signal from the sensor must be preprocessed to obtain data in form of a time series (that is, a sequence of observations with a time stamp). Then, analysis and modeling strategies are ap-plied to detect and treat  X  X nusual X  values, identify changes in phase, and analyze unaligned correlation. Figure 1 provides a global picture of the model building and model usage stages of the process. The ultimate goal is to extract a signature from a clean data set (model building) and use this signature for detection of anomalies of a process or system (model usage). Zhang et al. [ 5 , 6 ] point out the need for information enhancement of low quality data for analysis.
 missing values. The sequence of tasks involved in extracting information from a signal is illustrated in Fig. 2 .
 cleaning method that will facilitate the analysis and modeling of signals obtained from multiple sensors.
 on time series analysis and give an overview of the common methods for detect-ing outliers in time series. In Sect. 3, we describe an automated method for data cleaning that does not rely on a specific time series model. In Sect. 4, we discuss an experiment to evaluate the data cleaning method based on two FDR signals, and in Sect. 5 we draw conclusions from this study and point to further research ideas. 2 Time series analysis 2.1 Definitions A time series is a set of observations collected sequentially in time. A time series of N successive observations y 1 , y 2 ,..., y N can be regarded as a sample realiza-tion from an infinite population of such time series generated by a stochastic pro-cess, which can be stationary or nonstationary. The understanding of the structure and dependence of observations of a single ( univariate ) or several ( multivariate ) from time series analysis can be applied to forecasting, process control, outlier detection, and other applications, such as those mentioned in the introduction. In general, a univariate time series may be decomposed into two parts: the signal variables. The basic general linear time series model can be written as where k is the lag, or the distance between two observations, and  X  are the weights of the model. For this basic model, a weakly stationary time series has the follow-ing properties: (a) E ( y t ) =  X  is constant for all t , (b) Var ( y t ) =  X  2 is constant for all t ,and (c) Cov ( y t  X  k , y t ) =  X  k depends only on the separation lag k and not on t . In words, these properties describe a time series that is not subject to significant changes due to different process phases and can therefore be modeled with the please refer to Box et al. [ 1 ]. 2.2 Outliers in time series caution.
 outlier is a measurement error at time T ,1  X  T  X  N , caused by factors outside the system. For example, a machine breakdown or human error when recording the data could result in an additive outlier; an additive outlier does not affect the trend of a process. Another type of outlier is the innovative outlier , which is caused by some change in a process or system. The main difference between an additive and an innovative outlier is that the latter indicates the beginning of a new trend in the process, which will eventually return to normal. Finally, level shifts imply a permanent change in the process mean (a change from stationary to non-stationary process). For example, a change of system state such as a change from climb to cruise of an aircraft. It is important to consider the possibility of different outlier types occurring at the same period. For an observed process, there may be one or more of these outliers present which makes the task of detecting them even more difficult.
 fying the time of occurrence, which may not be known, as well as recognizing the type of outlier. Chang et al. [ 2 ] proposed an approach for outlier detection outlier at each data point in the time series. Once an outlier has been detected, [ 4 ].
 corporates the outlier can be estimated. This may not always be practical when highly nonstationary in which case a model-dependent implementation for out-lier detection may not be applicable, since there is no standard model that will fit the entire time series. In addition, time series obtained from signals may be extremely noisy due to inaccurate sensor readings. Finally, it may be desirable to perform analysis of the signal in real time to monitor a process, detect changes, and make adjustments. Therefore, there may not be time to fit a model to incorporate outliers.
 that relies on a generic method (model independence) and is computationally in-expensive (for real-time analysis). In the following sections we describe a method that can be applied to remove noise from data obtained from sensor data that are collected in quick succession. The method removes outliers (or signal noise, in this case) from the signal, which can then be used for more accurate real time process analysis.
 3 Data cleaning A method for cleaning data involves two aspects. The first aspect is identifying which data points in a time series are outliers (outlier detection). The second as-pect addresses the issue of what to do with a data point that has been identified as an outlier. This can include data imputation which refers to the replacement of these identified outliers with reasonable values. It is important to take into consid-eration the fact that an outlier may have two interpretations: it can either be noise in the signal, or it can be an indication of an anomaly for a specific reason. In the present study, we are concerned with detecting outliers that are anomalous to its neighboring values regardless of the reason. Two variations of the method are presented in the following subsections. 3.1 Two-sided median method for cleaning noisy data The proposed approach for cleaning noisy data obtained from a sensor signal is to use the median value of a neighborhood of data points to determine whether a particular data point is an outlier. Given a time series y 1 , y 2 ,..., y N ,definea size of the neighborhood window, starting at t  X   X  and ending at t +  X  .Inorderto clean the data, compute the median in the neighborhood of points, m ( X ) t ,andcom-pare the median to y t . Then calculate the absolute value of the difference between m t and y t and compare it to a specified threshold, if | y is illustrated with a simple example in Fig. 3 with a neighborhood window width of  X  = 3. We will label this method as the two-sided median method .
 hood of points and would be replaced by the median value m ( 3 ) 7 for analysis and modeling of the time series. Note that Pearson [ 3 ] used a similar method but used the median from the whole dataset and not a local median to obtain the limits. ular point in time delays detection of these outliers until  X  more data points are observed. 3.2 One-sided median method for cleaning noisy data If we want to identify outliers with only past data, we can use a simple modi-fication of the two-sided median method and look at the first difference of the | y there are  X  outliers in a row, it may mean that the process has changed at first oc-currence of these consecutive outliers and needs to be investigated. We will label this method as the one-sided median method .
 series. Note that the window width and threshold values are determined somewhat arbitrarily and may depend on the signal. In some cases, the window width and threshold values may vary for different parts of the signal. One might also use information from the actual signal or process to determine appropriate values for window width and threshold (for example, the percent deviation from the mean signal level). However, this may not always be possible, in particular when dealing with a non-stationary process. In Sect. 4, we discuss a computational study to gain more insight into this aspect of the data cleaning method. 3.3 Sample signals In order to illustrate the data cleaning methodology we selected two different sig-nals obtained from a flight data recorder (FDR): altitude of the aircraft, roll angle. The following paragraphs illustrate what the two signals look like before and after applying the data cleaning methods. There have been many studies on the analysis and interpretation of FDR data. A partial list of references is given at the end the article. However, these studies assume that the data are free from any nonsensical outlier, and the only anomalies are due to real phenomena. For all the data clean-ing methods, we used  X  = 3. The value of  X  was determined based on engineering knowledge. 3.3.1 Altitude The signal for altitude of the aircraft (see Fig. 4 ) is obtained from a sensor that measures the altitude in feet. The recording begins at a time zero with the air-craft in a climb. We observe six landings and five takeoffs and five distinct cycles with takeoff, climb, cruise, approach and landing. Although the different phases of flight are clearly distinguishable, there is a considerable amount of noise and erroneous data present in the signal, which may be due to inaccurate sensor read-ings.
 and  X  = 25. Results for the two-sided and one-sided methods are shown in Fig. 5 . and threshold values for different parts of the signal, corresponding to different flight stages. For instance, during take-off or landing altitude changes more rapidly than during cruise. Also, during cruise a change in altitude similar to one that is normally observed during take-off and landing, may indicate an outlier. Therefore, a larger threshold value is more appropriate for take-off and landing. 3.3.2 Roll angle The signal for roll angle (see Fig. 6 ) is obtained from a sensor that records the movement of an aircraft about its longitudinal axis.
 angle is quite different from the altitude signal we can still identify the same cy-cles as before, since more variation in the signal can be observed during initial climb and final approach for each of the five distinct cycles, as the pilot makes more adjustments immediately after takeoff and before landing. Note that there are several data points that are clearly outliers, since roll angles of  X  100  X  are not realistic. Figure 7 shows the clean signal for roll angle using  X  = 3and  X  = 5 using the two-sided and one-sided median methods. Again, the resulting (cleaner) signal captures the changes in the roll angle and deletes the outliers using both methods.
 ues. The choice of method may be determined by the application at hand. If we want to perform real time detection, then the one sided method may be more appropriate. On the other hand, if the analysis is performed at a later time, then the two sided method may be more appropriate. 4 Data cleaning experiment The two FDR signals shown in the previous section illustrate that the data cleaning methods are promising, and can successfully remove a considerable amount of noise from the signal. However, we also note that there are several factors that must be taken into account when applying the proposed data cleaning methods to these signals. As we observed, data from multiple sensors can look very different and requires the data cleaning methods to be flexible and adaptable. In addition, some valid data points may have been detected as outliers and imputed in error. The objective of the computational experiment described in this section is to test areas of improvement. For this experiment, we use the two signals introduced in the previous section. For the experiment, we will only discuss the method where we look at both sides of a point in time to determine outlying values. (a) The window width (  X  ) of the median method, which controls how many neigh-(b) The threshold (  X  ) for classifying a data point in the signal as an outlier. The the two signals:  X  Total altitude: any value outside a range from 0 to 40,000 ft.  X  Roll angle: any value outside a range from  X  45 to + 45  X  .
 being non-outlier if it is within the range and an outlier if it is outside the range. This is a simplification for the purpose of the experiment and we understand that we may mislabel some of the values. For example, in the altitude data, if the value at a given time is 1,000 ft and at the next time point which is a second later is 30,000 ft, then one of them is obviously an outlier. But, in the above designation, none of them will be designated as an outlier. This may lead to more false positives by identifying an outlier, when the  X  X ruth X  as defined above will not call the value an outlier.
 the above assumptions, we can classify the results from our experiment into four categories (see Table 1 ).
 experimental run, which consists of using the two-sided median method with a particular combination of window width (  X  ) and threshold value (  X  ). Category A is equivalent to an ideal situation in which a signal is free of noise and/or erroneous data. Categories B and C are undesirable, because the two-sided median method is not able to distinguish between noise and signal.
 method correctly identifies outliers (Category D ) and minimizing the number of points false positives (Category B ) and false negatives (Category C ). To achieve this, Jaccard X  X  coefficient can be used to assess the performance of the two-sided median method by counting the number of data points in each category. The mea-sure of goodness is computed using the following expression: We include only categories B , C ,and D , since the clean data points ( A ) outnumber the other categories by a large factor, and this would not allow us to observe any the false detection and directly proportional to the correct detection of the outliers. However, it puts equal cost for both false negatives and false positives. For this ex-periment, the larger the coefficient, the higher the effectiveness of the two-sided median method, because we want to both maximize the number of correctly iden-tified outliers and minimize the number of false positive and false negatives. Note that because of the definition of an outlier for this experiment, we may have larger number of observation in category B , thus underestimating the Jaccard coefficient. computational experiments, where coefficient J ( X , X  ) corresponds to one combina-tion of window width (  X  ) and threshold value (  X  ).
 coefficients for a wider range of threshold values can be made for all two signals. For example, in Fig. 8 we observe that high Jaccard coefficients are obtained for a large range of values. However, the general trend indicates that the narrower the window width (say,  X  ={ 3 , 5 } ) the wider the range of threshold values that still result in high coefficient values. This is useful when the threshold value for the signal is not well known.
 negatives for the roll signal. The main reason for observing false negative counts for the altitude signal was that there were long series of negative altitudes values with the difference of consecutive altitude values being within the threshold. The two-sided median method may correctly identify the first few outliers (at most 2  X  ), but then may not be able to detect any differences after that. Since there are fewer (or no) consecutive outliers in the other three signals, there are fewer (or no) false negative counts. In general, we expect that:  X  Reducing the threshold value reduces the number of false negatives (that is,  X  Reducing the window width (  X  ) will lead to more false negatives and less false 5 Simulation experiment To understand the effect of the degree of correlation and the effect of window size and threshold values, we performed a small simulation experiment. For the simulation, we generated time series from an AR(1) model [ 1 ] where  X  is the first order autocorrelation parameter and  X  t are iid with mean 0 Cor ( Y t , Y t  X  k ) =  X  k .If  X  is zero, then Y  X  X  are uncorrelated. case where nearby values are similar, a typical situation we observe in real data. The different parameters that we varied in the simulation experiment are:  X 
Va l u e o f  X  which ranged from 0.0 (0.1) 0.9  X 
Threshold value (  X  ) from 2.0 (0.5) 6.0  X  Window width (  X  ) from 3 (1) 6.
  X 
Va l u e o f Va r ( X  t ) =  X  2  X  = 1  X 
Length of the time series = 1000  X 
Number of Outliers: 30 groups of 2 consecutive outlying values  X  Number of Simulations for each combination: 100  X 
Generate a time series of length 1000 using the appropriate value of  X   X 
Generate a random number, x , between  X  0.5 and 0.5 by generating a random number between 0 and 1 and then subtracting 0.5  X 
Calculate x 1 = exp ( 3  X  abs ( x )) + 3  X  where mod is the modulo operator and sign( x ) = sign of x . Note that we use 30 in the mod operator because it generated the required number of outliers. the simulation. Figure 10 a shows the original time series and Fig. 10 b shows how the series looks after the 60 outliers were added.
 window size and cutoff value for  X  = 0 . 5. Note that the values do not change for different window sizes and it is similar for all values of  X  . Therefore, results sided method. The coefficients increase at first as the window size increases, but then the coefficients decrease after a certain window width.
 one and two sided methods. The averages were computed over 100 simulation medium value of  X  , around 4, leads to the highest values of the Jaccard coeffi-cient for both the methods. This leads to the conclusion that the proper choice of the cutoff value is critical for a balance of false positives and false negatives, the contribution of both are reflected in the Jaccard coefficient. 6 Summary and conclusions The objective of this article was to investigate efficient data cleaning methods that will facilitate the analysis and modeling of signals obtained from multiple sensors. Data cleaning is especially important for the analysis of sensor data, which can contain a significant amount of noise. We proposed one-sided and two-sided me-dian methods that provide fast, automated, and model independent outlier detec-tion and can be used for signal data cleaning. We then performed a computational study using two FDR signals to understand the effects of threshold and window width parameter values that are required by the method. We also looked at a small simulation study from an AR(1) model with different autocorrelation structure, window widths and threshold values. The results indicate that the proposed data cleaning methods are promising but offer room for improvement. In particular, the data cleaning methods need to be improved to account for situations in which a series of outliers occur in the data. When this happens, the current implementation detects the first few outliers correctly, but cannot detect a string of outliers longer than the window width, since it confuses the sequence of outliers of same value from the actual signal. Furthermore, it is important to keep in mind that removing important information about the process or system. These methods can be used to identify unusual values and the expert can decide whether the detected unusual value is an outlier or an anomaly that is a real phenomena. Finally, we observed that the proposed methods are sensitive to the selection of an appropriate threshold value; it is therefore required to have some knowledge about the signal. Based on our computational experiments, we recommend using a small window width to maximize the efficiency of the proposed data cleaning methods, especially for cases in which there is little information about how to set the threshold value. References
