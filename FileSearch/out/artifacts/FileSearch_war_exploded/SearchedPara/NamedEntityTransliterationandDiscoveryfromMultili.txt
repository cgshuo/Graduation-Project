 Named Entity recognition has been getting much attention in NLP research in recent years, since it is seen as a significant component of higher level NLP tasks such as information distillation and ques-tion answering, and an enabling technology for bet-ter information access. Most successful approaches to NER emplo y machine learning techniques, which require supervised training data. Ho we ver, for man y languages, these resources do not exist. Moreo ver, it is often dif ficult to find experts in these languages both for the expensi ve annotation effort and even for language specific clues. On the other hand, compa-rable multilingual data (such as multilingual news streams) are increasingly available (see section 4).
In this work, we mak e two independent observ a-tions about Named Entities encountered in such cor -pora, and use them to develop an algorithm that ex-tracts pairs of NEs across languages. Specifically , given a bilingual corpora that is weakly temporally aligned, and a capability to annotate the text in one of the languages with NEs, our algorithm identifies the corresponding NEs in the second language text, and annotates them with the appropriate type, as in the source text.

The first observ ation is that NEs in one language in such corpora tend to co-occur with their coun-terparts in the other . E.g., Figure 1 sho ws a his-togram of the number of occurrences of the word Hussein and its Russian transliteration in our bilin-gual news corpus spanning years 2001 through late 2005. One can see several common peaks in the two histograms, lar gest one being around the time of the beginning of the war in Iraq. The word Russia , on the other hand, has a distinctly dif ferent temporal signature. We can exploit such weak synchronicity of NEs across languages as a way to associate them. In order to score a pair of entities across languages, we compute the similarity of their time distrib utions.
The second observ ation is that NEs are often transliterated or have a common etymological origin across languages, and thus are phonetically similar . Figure 2 sho ws an example list of NEs and their pos-Figure 1: Temporal histograms for Hussein (top), its Russian transliteration (middle), and of the word Russia (bottom). sible Russian transliterations.

Approaches that attempt to use these two charac-teristics separately to identify NEs across languages would have significant shortcomings. Translitera-tion based approaches require a good model, typi-cally handcrafted or trained on a clean set of translit-eration pairs. On the other hand, time sequence sim-ilarity based approaches would incorrectly match words which happen to have similar time signatures (e.g. Taliban and Afghanistan in recent news).
We introduce an algorithm we call co-r anking which exploits these observ ations simultaneously to match NEs on one side of the bilingual corpus to their counterparts on the other . We use a Discrete Fourier Transform (Arfk en, 1985) based metric for computing similarity of time distrib utions, and we score NEs similarity with a linear transliteration model. For a given NE in one language, the translit-eration model chooses a top rank ed list of candidates in another language. Time sequence scoring is then used to re-rank the candidates and choose the one best temporally aligned with the NE. That is, we at-tempt to choose a candidate which is both a good transliteration (according to the current model) and is well aligned with the NE. Finally , pairs of NEs Figure 2: Example English NEs and their transliter -ated Russian counterparts. and the best candidates are used to iterati vely train the transliteration model.

A major challenge inherent in disco vering transliterated NEs is the fact that a single entity may be represented by multiple transliteration strings. One reason is language morphology . For example, in Russian, depending on a case being used, the same noun may appear with various endings. An-other reason is the lack of transliteration standards. Again, in Russian, several possible transliterations of an English entity may be acceptable, as long as the y are phonetically similar to the source.
Thus, in order to rely on the time sequences we obtain, we need to be able to group variants of the same NE into an equi valence class, and col-lect their aggre gate mention counts. We would then score time sequences of these equi valence classes. For instance, we would lik e to count the aggre gate number of occurrences of Herze govina, Her cegov-ina on the English side in order to map it accu-rately to the equi valence class of that NE X  s vari-ants we may see on the Russian side of our cor -pus (e.g.

One of the objecti ves for this work was to use as little of the kno wledge of both languages as possible. In order to effecti vely rely on the quality of time se-quence scoring, we used a simple, kno wledge poor approach to group NE variants for Russian.
 In the rest of the paper , whene ver we refer to a Named Entity , we imply an NE equi valence class. Note that although we expect that better use of lan-guage specific kno wledge would impro ve the re-sults, it would defeat one of the goals of this work. There has been other work to automatically disco ver NE with minimal supervision. Both (Cucerzan and Yaro wsk y, 1999) and (Collins and Singer , 1999) present algorithms to obtain NEs from untagged cor -pora. Ho we ver, the y focus on the classification stage of alr eady segmented entities , and mak e use of con-textual and morphological clues that require kno wl-edge of the language beyond the level we want to assume with respect to the tar get language.
The use of similarity of time distrib utions for in-formation extraction, in general, and NE extraction, in particular , is not new. (Hetland, 2004) surv eys recent methods for scoring time sequences for sim-ilarity . (Shin yama and Sekine, 2004) used the idea to disco ver NEs, but in a single language, English, across two news sources.

A lar ge amount of pre vious work exists on transliteration models. Most are gener ative and con-sider the task of producing an appropriate translit-eration for a given word, and thus require consid-erable kno wledge of the languages. For example, (AbdulJaleel and Lark ey, 2003; Jung et al., 2000) train English-Arabic and English-K orean generati ve transliteration models, respecti vely . (Knight and Graehl, 1997) build a generati ve model for back-ward transliteration from Japanese to English.
While generati ve models are often rob ust, the y tend to mak e independence assumptions that do not hold in data. The discriminati ve learning frame work argued for in (Roth, 1998; Roth, 1999) as an alter -nati ve to generati ve models is now used widely in NLP , even in the conte xt of word alignment (Taskar et al., 2005; Moore, 2005). We mak e use of it here too, to learn a discriminati ve transliteration model that requires little kno wledge of the tar get language. In essence, the algorithm we present uses temporal alignment as a supervision signal to iterati vely train a discriminati ve transliteration model, which can be vie wed as a distance metric between and English NE and a potential transliteration. On each iteration, it selects a set of transliteration candidates for each NE according to the current model (line 6). It then uses temporal alignment (with thresholding) to select the best transliteration candidate for the next round of training (lines 8, and 9).

Once the training is complete, lines 4 through 10 are executed without thresholding for each NE in to disco ver its counterpart in . 3.1 Time Sequence Generation and Matching In order to generate time sequence for a word, we divide the corpus into a sequence of temporal bins, and count the number of occurrences of the word in each bin. We then normalize the sequence.

We use a method called the F-inde x (Hetland, 2004) to implement the on line 8 of the algorithm. We first run a Discrete Fourier Transform on a time sequence to extract its Fourier expansion coef ficients. The score of a pair of time sequences is then computed as a Euclidian dis-tance between their expansion coef ficient vectors. .

Algorithm 1: Co-ranking: an algorithm for it-erati ve cross lingual NE disco very . 3.1.1 Equi valence Classes
As we mentioned earlier , an NE in one language may map to multiple morphological variants and transliterations in another . Identification of the en-tity X  s equi valence class of transliterations is impor -tant for obtaining its accurate time sequence.
In order to keep to our objecti ve of requiring as lit-tle language kno wledge as possible, we took a rather simplistic approach to tak e into account morpholog-ical ambiguities of NEs in Russian. Two words were considered variants of the same NE if the y share a prefix of size five or longer . At this point, our al-gorithm tak es a simplistic approach also for the En-glish side of the corpus  X  each unique word had its own equi valence class although, in principle, we can incorporate works such as (Li et al., 2004) into the algorithm. A cumulati ve distrib ution was then col-lected for such equi valence classes. 3.2 Transliteration Model Unlik e most of the pre vious work to transliteration, that consider gener ative transliteration models, we tak e a discriminative approach. We train a linear model to decide whether a word eration of an NE . The words in the pair are partitioned into a set of substrings and up to a particular length (including the empty string ). Couplings of the substrings sets produce features we use for training. Note that couplings with the empty string represent inser -tions/omissions.

Consider the follo wing example: ( , ) = (po well, pauel). We build a feature vector from this example in the follo wing manner:
We use the observ ation that transliteration tends to preserv e phonetic sequence to limit the number of couplings. For example, we can disallo w the coupling of substrings whose starting positions are too far apart: thus, we might not consider a pair -ing ments, we paired substrings if their positions in their respecti ve words dif fered by -1, 0, or 1.
We use the perceptron (Rosenblatt, 1958) algo-rithm to train the model. The model acti vation pro-vides the score we use to select best transliterations on line 6. Our version of perceptron tak es exam-ples with a variable number of features; each ex-ample is a set of all features seen so far that are acti ve in the input. As the iterati ve algorithm ob-serv es more data, it disco vers and mak es use of more features. This model is called the infinite attrib ute model (Blum, 1992) and it follo ws the perceptron version in SNoW (Roth, 1998).

Positi ve examples used for iterati ve training are pairs of NEs and their best temporally aligned (thresholded) transliteration candidates. Ne gati ve examples are English non-NEs paired with random Russian words. We ran experiments using a bilingual comparable English-Russian news corpus we built by cra wling a Russian news web site ( www.lenta.ru ).
 The site pro vides loose translations of (and pointers to) the original English texts. We col-lected pairs of articles spanning from 1/1/2001 through 12/24/2004. The corpus consists of 2,022 documents with 0-8 documents per day . The corpus is available on our web page at http://L2R.cs.u iuc.edu/ The English side was tagged with a publicly available NER system based on the SNoW learning architecture (Roth, 1998), that is available at the same site. This set of English NEs was hand-pruned to remo ve incorrectly classified words to obtain 978 single word NEs.

In order to reduce running time, some limited preprocessing was done on the Russian side. All classes, whose temporal distrib utions were close to uniform (i.e. words with a similar lik elihood of occurrence throughout the corpus) were deemed common and not considered as NE candidates. Unique words were grouped into 15,594 equi valence classes, and 1,605 of those classes were discarded using this method.

Insertions/omissions features were not used in the experiments as the y pro vided no tangible benefit for the languages of our corpus.

Unless mentioned otherwise, the transliteration model was initialized with a subset of 254 pairs of NEs and their transliteration equi valence classes. Ne gati ve examples here and during the rest of the training were pairs of randomly selected non-NE English and Russian words.

In each iteration, we used the current transliter -Figure 3: Proportion of correctly disco vered NE pairs vs. iteration. Complete algorithm outperforms both transliteration model and temporal sequence matching when used on their own. ation model to find a list of 30 best transliteration equi valence classes for each NE. We then computed time sequence similarity score between NE and each class from its list to find the one with the best match-ing time sequence. If its similarity score surpassed a set threshold, it was added to the list of positi ve examples for the next round of training. Positi ve ex-amples were constructed by pairing each English NE with each of the transliterations from the best equi v-alence class that surpasses the threshold. We used the same number of positi ve and negati ve examples.
For evaluation, random 727 of the total of 978 NE pairs matched by the algorithm were selected and check ed by a language expert. Accurac y was com-puted as the percentage of those NEs correctly dis-covered by the algorithm. 4.1 NE Disco very Figure 3 sho ws the proportion of correctly disco v-ered NE transliteration equi valence classes through-out the run of the algorithm. The figure also sho ws the accurac y if transliterations are selected accord-ing to the current transliteration model (top scor -ing candidate) and sequence matching alone. The transliteration model alone achie ves an accurac y of about 47%, while the time sequence alone gets about Figure 5: Proportion of the correctly disco vered NE pairs for various initial example set sizes. Decreas-ing the size does not have a significant effect of the performance on later iterations. 41%. The combined algorithm achie ves about 66%, giving a significant impro vement.

In order to understand what happens to the transliteration model as the algorithm proceeds, let us consider the follo wing example. Figure 4 sho ws parts of transliteration lists for NE for syth for two iterations of the algorithm. The weak transliteration model selects the correct transliteration (italicized) as the 24th best transliteration in the first iteration. Time sequence scoring function chooses it to be one of the training examples for the next round of train-ing of the model. By the eighth iteration, the model has impro ved to select it as a best transliteration.
Not all correct transliterations mak e it to the top of the candidates list (transliteration model by itself is never as accurate as the complete algorithm on Fig-ure 3). That is not required, howe ver, as the model only needs to be good enough to place the correct transliteration anywhere in the candidate list.
Not surprisingly , some of the top transliteration candidates start sounding lik e the NE itself, as train-ing progresses. On Figure 4, candidates for for syth on iteration 7 include fross and fossett . 4.2 Rate of Impr ovement vs. Initial Example We ran a series of experiments to see how the size of the initial training set affects the accurac y of the model as training progresses (Figure 5). Although the performance of the early iterations is signifi-cantly affected by the size of the initial training ex-ample set, the algorithm quickly impro ves its perfor -mance. As we decrease the size from 254, to 127, to 85 examples, the accurac y of the first iteration drops by roughly 10% each time. Ho we ver, starting at the 6th iteration, the three are with 3% of one another .
These numbers suggest that we only need a few initial positi ve examples to bootstrap the translitera-tion model. The intuition is the follo wing: the few examples in the initial training set produce features corresponding to substring pairs characteristic for English-Russian transliterations. Model trained on these (fe w) examples chooses other transliterations containing these same substring pairs. In turn, the chosen positi ve examples contain other characteris-tic substring pairs, which will be used by the model to select more positi ve examples on the next round, and so on. We have proposed a novel algorithm for cross lin-gual NE disco very in a bilingual weakly temporally aligned corpus. We have demonstrated that using two independent sources of information (transliter -ation and temporal similarity) together to guide NE extraction gives better performance than using either of them alone (see Figure 3).

We developed a linear discriminati ve translitera-Figure 6: Example of correct transliterations disco v-ered by the algorithm. tion model, and presented a method to automatically generate features. For time sequence matching, we used a scoring metric novel in this domain. As sup-ported by our own experiments, this method outper -forms other scoring metrics traditionally used (such as cosine (Salton and McGill, 1986)) when corpora are not well temporally aligned.

In keeping with our objecti ve to pro vide as lit-tle language kno wledge as possible, we introduced a simplistic approach to identifying transliteration equi valence classes, which sometimes produced er-roneous groupings (e.g. an equi valence class for NE lincoln in Russian included both lincoln and lin-colnshir e on Figure 6). This approach is specific to Russian morphology , and would have to be al-tered for other languages. For example, for Arabic, a small set of prefix es can be used to group most NE variants. We expect that language specific kno wl-edge used to disco ver accurate equi valence classes would result in performance impro vements. In this work, we only consider single word Named Entities. A subject of future work is to extend the algorithm to the multi-w ord setting. Man y of the multi-w ord NEs are translated as well as transliter -ated. For example, Mount in Mount Rainier will probably be translated, and Rainier -transliterated. If a dictionary exists for the two languages, it can be consulted first, and, if a match is found, translitera-tion model can be bypassed.

The algorithm can be naturally extended to com-parable corpora of more than two languages. Pair -wise time sequence scoring and transliteration mod-els should give better confidence in NE matches.
It seems plausible to suppose that phonetic fea-tures (if available) would help learning our translit-eration model. We would lik e to verify if this is in-deed the case.

The ultimate goal of this work is to automatically tag NEs so that the y can be used for training of an NER system for a new language. To this end, we would lik e to compare the performance of an NER system trained on a corpus tagged using this ap-proach to one trained on a hand-tagged corpus. We thank Richard Sproat, ChengXiang Zhai, and Kevin Small for their useful feedback during this work, and the anon ymous referees for their help-ful comments. This research is supported by the Adv anced Research and De velopment Acti vity (ARD A) X  s Adv anced Question Answering for Intel-ligence (AQUAINT) Program and a DOI grant under the Refle x program.

