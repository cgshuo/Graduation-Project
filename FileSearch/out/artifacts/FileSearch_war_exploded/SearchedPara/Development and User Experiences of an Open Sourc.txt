 Record linkage, also known as database matching or entity resolution, is now recognised as a core step in the KDD process. Data mining projects increasingly require that in -formation from several sources is combined before the actua l mining can be conducted. Also of increasing interest is the deduplication of a single database. The objectives of recor d linkage and deduplication are to identify, match and merge all records that relate to the same real-world entities. Be-cause real-world data is commonly  X  X irty X , data cleaning is an important first step in many deduplication, record link-age, and data mining projects.
 In this paper, an overview of the Febrl (Freely Extensible Biomedical Record Linkage) system is provided, and the re-sults of a recent survey of Febrl users is discussed. Febrl in-cludes a variety of functionalities required for data clean ing, deduplication and record linkage, and it provides a graphic al user interface that facilitates its application for users w ho do not have programming experience.
 Categories and Subject Descriptors: H.2.8 [Database applications]: Data mining General Terms: Algorithms, Experimentation Keywords: data linkage, database matching, data stan-dardisation, open source software, Python, GUI. A crucial requirement for successful data mining projects i n many application areas is the linking of records from severa l heterogeneous databases [10; 23]. Related to record linkag e is the deduplication of a single database [16]. Record linka ge and deduplication are aimed at matching all records that relate to the same real-world entities. These entities can, for example, be patients, customers, tax payers, travellers, o r even businesses, publications, patents, or genome sequenc es. Record linkage and deduplication can be used to improve data quality and integrity, to allow re-use of existing data for new studies, to enable data analysis and mining at levels of details not otherwise possible, and to reduce costs and efforts in data acquisition.
 In the health sector, for example, linked data can contain information that is required to improve health policies, an d that traditionally has been collected with time consuming and expensive survey methods. Linked data can also help in health surveillance systems to enrich data that is used for detection of suspicious patterns, such as outbreaks of contagious diseases. Businesses routinely deduplicate an d link their databases to compile mailing lists for customer analytics purposes, while taxation offices and departments of social security use record linkage to identify people who register for benefits multiple times, or who work and col-lect unemployment money at the same time. Another area where record linkage has gained increased interest in recen t times is crime and terror detection. Security agencies and crime investigators increasingly rely on the ability to qui ckly bring up files for a particular individual, which may help to prevent crimes or terrorism by early intervention. A variety of commercial record linkage and deduplication systems are available. From a user X  X  perspective, the vast majority of these systems are a  X  X lack box X , because the details of the technology implemented within the linkage engine of these systems are normally not accessible. Addi-tionally, many of these systems are specialised to a certain domain, for example the linking of business data, or the cleaning or deduplication of customer mailing lists. For many applications, the record linkage or deduplication process is quite complex, because it involves data from het-erogeneous sources, possibly from different domains and col -lected at different points in time. Therefore, a significant amount of customisation or additional programming is com-monly required before a commercial linkage system can be successfully used for a certain application. A record linka ge application is often limited by the functionality offered by the commercial linkage system employed.
 Record linkage is a complex process that requires the user to understand, up to a certain degree, various technical detai ls. For example, it is important that a user appreciates how approximate string comparison functions work on name and address values, because they will significantly influence th e quality of the final matched data. Similarly, understanding the trade-offs of using certain record fields (attributes) in the linkage process, or setting parameters to certain value s, is crucial. On one hand a specific parameter choice might result in poor linkage quality, while on the other hand a different choice might result in too many records pairs being compared, thus making a linkage not feasible.
 Several smaller record linkage systems are available for fr ee or at affordable prices. However, they are commonly limited in their ability to deal with different types of data, only con -tain a limited amount of functionality (for example imple-ment only a small number of commonly used string compar-ison functions), or they can only link small data sets. Large -Figure 1: The general record linkage process. The blocking / indexing step generates candidate record pairs, and the output of the record pair comparison step are weight vectors that contain numerical similarity values. scale record linkage and deduplication systems, on the othe r hand, are usually very expensive, require powerful comput-ing and large storage environments, and are therefore only affordable by large organisations.
 It is important that users of record linkage systems, as well as researchers working in this area, have access to free (or at least affordable) tools that allow them to learn about and experiment with record linkage techniques. Such tools should include both traditional and novel techniques (to al -low users to understand their advantages and limitations), they should be flexible and contain a variety of different linkage techniques, and they should allow a multitude of configuration options for a user to conduct a variety of ex-perimental linkages. To facilitate this, the source code of the linkage engine of such systems should be available for inspection, modification and improvement. On the other hand, because many users of record linkage systems have limited programming experience, a graphical user interfac e should be provided to facilitate the use of record linkage techniques without the need of any programming.
 This lack of flexible record linkage systems, that allow acce ss to their source code and include a variety of linkage tech-niques, is addressed by the Febrl (Freely Extensible Biomed-ical Record Linkage) system presented in this paper. To the best of the author X  X  knowledge, Febrl is the only freely avail-able data cleaning, deduplication and record linkage syste m with a graphical user interface.
 This paper is an extended version of a demonstration paper presented at ACM KDD X 08 [7]. In the following Section 2, a general overview of the record linkage process is provided . The background of the Febrl project is given in Section 3, and in Section 4 the structure and functionality of the Febrl software is explained in detail, and illustrated with scree n-shots of an example record linkage project. Then, in Sec-tion 5, the results of a recently conducted survey of Febrl users is discussed. The paper is concluded in Section 6 with an outlook to future development plans for Febrl . As shown in Figure 1, the linkage process consists of five ma-jor steps: cleaning and standardisation, indexing / blocki ng, comparison, classification, and evaluation / review. Figure 2: Example weight vector generated when comparing records A and B.
 Because common unique entity identifiers (or keys) are often not available in the databases to be linked or deduplicated, the linkage process is usually based on the available record fields (attributes), which in many cases contain personal de -tails such as names, addresses, and dates of birth. The val-ues in these fields, however, often contain noisy, incomplet e and incorrectly formatted information. A lack of good qual-ity data can be one of the biggest obstacles to successful record linkage and deduplication [13], because records mig ht not be compared with each other if they contain incorrect or missing information. Data cleaning and standardisation are therefore an important first step for successful record linkage and deduplication. Their objective is the conversi on of the raw input data into well defined, consistent formats; and the resolution of inconsistencies in the way informatio n is represented and encoded [12].
 When linking two databases, potentially each record in one database needs to be compared with all records in the other database, because there is no way to know prior to the comparison step if two records are matching or not. This comparison process is therefore of quadratic complexity [1 0]. The maximum number of true matches, however, cannot be larger than the number of records in the smaller of the two databases to be linked. Similarly, when deduplicating a sin -gle database, each record potentially needs to be compared with all other records, while the maximum number of poten-tial duplicates is always smaller than the number of records in a database. To improve the scalability of the linkage process, the potentially very large number of record pairs that are to be compared has to be reduced. This can be ac-complished through some form of indexing (called  X  X locking  X  in record linkage [2]), that splits the databases into block s (or clusters). Only records that are in the same block are compared with each other. For example, if a postcode field is used for blocking, then only records that have the same postcode value are compared with each other.
 The candidate pairs generated in the blocking step are com-pared using comparison functions appropriate to the conten t of the record fields (attributes). Approximate string com-parison functions, which take variations and typographica l errors into account, are commonly used on name and ad-dress fields [3; 14], while comparison functions specific for date, age, and numerical values are used for fields that con-tain such information. Each comparison function returns a numerical similarity value, often called a matching weight , that is commonly normalised, such that 1 corresponds to two exactly matching values, and 0 to two completely dif-ferent values. Two values that are somewhat similar (such as the two name strings  X  X ail X  and  X  X ayle X ) will result in a similarity value somewhere between 0 and 1. Several fields of each candidate record pair are normally compared, and a weight vector is formed that contains all matching weights calculated for a record pair. Figure 2 shows two example records (made of title, given name, middle name and sur-name fields) and a corresponding weight vector.
 Based on these weight vectors, the next step in the linkage process is to classify the compared candidate record pairs into matches , non-matches , and possible matches (depend-ing upon the decision model used) [10; 19]. Record pairs that were removed in the blocking step are classified as non-matches without being compared explicitly. Various clas-sification techniques have been developed in the past four decades, ranging from basic threshold-based [17; 23] to com -plex machine learning based approaches [5; 6; 15]. The final step in the linkage process is to evaluate the qualit y of the generated matches and non-matches. A variety of evaluation measures can be used for this, however, due to the normally imbalanced distribution of matches versus non -matches, care needs to be taken to prevent over-optimistic accuracy results [10]. If a classification technique has bee n used that classified record pairs as possible matches [23], then a manual clerical review step is required to decide the final linkage status of these record pairs. The Febrl software has been developed since early 2002 as part of a collaborative research project conduced by the Aus -tralian National University in Canberra and the New South Wales Department of Health in Sydney, Australia. The ob-jectives of this project are to develop novel techniques for improved data cleaning and standardisation, deduplicatio n and record linkage. While the focus of this research is on the cleaning and linking of health related data, the techniques developed and implemented in Febrl are general enough to be applicable to data from a variety of other domains. Since its first publication in early September 2002, the Febrl software has been hosted on the Sourceforge.Net open source software repository, and it is available from: Febrl is written in the Python 1 programming language. Py-thon provides an ideal platform for rapid prototype develop -ment. It includes data structures like sets, lists and assoc ia-tive arrays (called  X  X ictionaries X ) that allow efficient han dling of very large data sets. It also contains many modules that offer a range of functionalities, including string handling , database access, Web programming, numerical capabilities , and GUI (graphical user interface) development. http://www.python.org Figure 3: Monthly Febrl download numbers from the Sourceforge.Net repository. The total number of downloads on 8th May 2009 was 13,234.
 Febrl is published under an open source software licence that allows maximum flexibility for users by permitting them to integrate Febrl into other, non open source, software. This is not possible with other open source licenses, such as the GNU General Public License. An overview of the release history of the Febrl software can be seen in Table 1. To the best of the author X  X  knowledge, Febrl is the only open source software that includes a GUI and allows data cleaning and standardisation, deduplication and record linkage. As can be seen in Figure 3, the download numbers per month have significantly increased since the initial release of Febrl . Note that downloads before April 2003 are not available due to a change in the Sourceforge.Net statistics system at that time. Some of the outliers (peak download numbers) co-incide with the release of major new Febrl versions (0.3 in April 2005 and 0.4 in November 2007), while others (like the peaks in June 2005 and November 2008) are not correlated to any specific event (such as publications or presentations ) that increased the publicity of Febrl .
 Due to the availability of its source code, Febrl is suitable for the rapid development, implementation, and testing of nove l data cleaning, record linkage and deduplication technique s, 2 For details see: http://www.opensource.org/licenses as well as for both new and experienced users to learn about, and experiment with such techniques. The current Febrl version includes the source code, several example data sets (some taken from the SecondString toolkit 3 ), and a data set generator [11]. The documentation contains a set of papers that describe the techniques implemented in Febrl , and a manual that includes several step-by-step tutorials. Compared to earlier versions, Febrl since its 0.4 release in-cludes a graphical user interface (GUI), which facilitates the application of Febrl for users who do not have any Python programming experience. Feedback received from users sinc e 2002 indicated that a GUI was one of the most desired fea-tures for Febrl . The GUI was developed using the PyGTK 4 In the following, the structure of the Febrl GUI and its func-tionality are described in detail, and illustrated using a s eries of screen-shots that show an example linkage of the  X  X ensus X  data set, which was taken from the SecondString repository and is provided with the Febrl software. This small data set is made of 841 records in total. It is split into two sub-sets with 449 and 392 records, respectively, and contains arti-ficial census data made of name and address fields. Each record includes an identifier field, which has the same value if two or more records from the two data sets refer to the same person. Record pairs that have the same identifier value therefore correspond to true matches, while pairs tha t have different identifier values are non-matches. This allow s measuring the accuracy of a linkage [10].
 The main Febrl GUI after start-up is shown in Figure 4. The basic idea of the GUI is to have a  X  X abbed X  window, similar to tabs in modern Web browsers. This follows the approach taken by the Rattle open source data mining tool [22]. There is one tab for each of the major steps in the record linkage process. On each tab, the user can set a variety of parame-ter settings for the corresponding step of the linkage proce ss. A click on the  X  X xecute X  button will validate the chosen set-tings, and if any of them are invalid an error window will ap-pear that describes which setting has to be corrected. Once http://secondstring.sourceforge.net http://www.pygtk.org http://glade.gnome.org Figure 5:  X  X ata X  tab for a record linkage project after both  X  X ensus X  input data sets have been initialised and validate d. all settings on a tab are valid, Febrl Python code for the corresponding step in the linkage process will be generated and shown in the  X  X og X  tab. This is the code that will be executed when the actual standardisation, deduplication o r linkage is being started on the  X  X utput/Run X  tab, as will be described in Section 4.7.
 Initially, the only two tabs visible are  X  X ata X  and  X  X og X . Other tabs will appear once the input data set has, or sets have, been initialised. In the middle top part of the Febrl GUI, the user can select the type of project she or he wants to conduct: the  X  X tandardisation X  of one data set, the  X  X edu -plication X  of one data set, or the  X  X inkage X  of two data sets. All tabs will be described in more detail and illustrated wit h corresponding screen-shots in the following sections. When a user selects the type of project to be conducted, the  X  X ata X  tab will show either one or two input data set areas. The user now needs to select the file name(s) of the input data set(s) to be used. So far, Febrl supports three types of text file formats: CSV (comma separated values), TAB (tabulator separated values), and COL (column ori-ented values with fixed-width fields). Access to databases is of the many features left for future work.
 Once a file has been selected, the content of its first few lines will be shown. This allows a user to check the selected parameter settings (such as using a header line, stripping whitespaces from values, setting missing values, and using a record identifier field), or modify them if required. When satisfied, a click on  X  X xecute X  will validate the chosen set-tings, and provide an error window if any is not valid. As can be seen in the top part of Figure 5 for the  X  X ensus X  data sets, once the input data has been initialised and vali-dated, additional tabs will become visible. The  X  X xplore X  t ab will become visible in any case, other visible tabs however depend upon the selected project type.
 Figure 6: Data exploration tab showing summary analysis of record fields (attributes, columns). The  X  X xplore X  tab allows a user to conduct basic data ex-ploration of the input data set(s) in order to get a better understanding of the content of the selected data. The in-put files will be read and a variety of statistics collected fo r each field (attribute). This includes the number of differ-ent values, the alphabetically smallest and largest values , the most and least frequent values, the quantiles distribu-tion of field values, the number of records that have missing (or empty) values in each field, as well as a guess of the type of each field (if it contains only digits, only letters, o r is of mixed type). It is possible to sample a percentage of records to be analysed in order to speed-up the exploration of large data sets. Figure 6 shows a summary table of the information collected from one of the  X  X ensus X  data sets. Currently, the cleaning and standardisation of a data set us -ing the Febrl GUI is done separately from a record linkage or deduplication project, rather than as a first step in the linkage process (as shown in Figure 1). A user can clean and standardise her or his data set(s), and they are then written into new file(s), which in turn can be used in a dedupli-cation or record linkage project. When a user selects the  X  X tandardisation X  project type, and has initialised a data set on the  X  X ata X  page, she or he can define one or more com-ponent standardisers on the  X  X tandardise X  page, as shown in Figure 7. Currently, Febrl contains standardisers for names, addresses, dates, and telephone numbers.
 The standardisation for simple names (those made of one given-name and one surname only) is done by applying a rule-based approach, while for more complex names a prob-abilistic hidden Markov model (HMM) based approach [12] is used. The standardisation of addresses is fully based on a HMM approach [8]. The training of HMMs at the moment needs to be done outside of the Febrl GUI using separate Febrl programs. The standardisation of dates, such as dates Figure 7: Example date and telephone number standardisers (for a synthetic Febrl data set). of birth, is based on a list of parsing format strings that provide the most likely date formats that are expected in a record field. Telephone numbers are standardised using an approach that combines look-up tables and rules.
 As can be seen in Figure 7, each standardiser requires the user to select one or several input fields from the input data set (shown on the left side in the GUI), which are to be cleaned and standardised into a number of output fields (six for names, 27 for addresses, three for dates, and five for phone numbers), as shown on the right side in the GUI. Each component standardiser also requires various parameters t o be set, as shown in the middle column of the GUI. It is possible to define more than one standardiser for each component type. For example, for a health data set, one date standardiser might be used for dates of birth and an-other for hospital admission dates. Once all parameter set-tings for the defined component standardisers are initialis ed, they can be validated with a click on  X  X xecute X . On the  X  X ut-put/Run X  tab (which will be described in Section 4.7), the name of the standardised output file needs to be provided, and then a standardisation project can be started by clickin g on the  X  X xecute X  button. Blocking or indexing is applied in the record linkage pro-cess to reduce the number of record pair comparisons to be conducted [2]. The  X  X ndex X  tab allows the user to select one of seven possible indexing methods, as shown in Figure 9 (a). The most simple approach is the  X  X ullIndex X , which will compare all record pairs and thus has a quadratic complexity (making it not scalable!). The standard  X  X lockingIndex X  [2 ] approach, as implemented in most traditional record link-age systems, inserts each record into a single block, and only compares records within the same block.
 Febrl also contains five recently developed experimental in-dexing methods:  X  X ortingIndex X , which is based on the sorte d neighbourhood approach [20];  X  X GramIndex X , which uses sub-strings of length q to improve approximate matching [2];  X  X anopyIndex X , which is based on overlapping canopy clus-tering and uses the TF-IDF or Jaccard similarity to cheaply calculate the similarities between records [15];  X  X tringM apIn-dex X , which maps the index key values (more on this below) Figure 8: Example indexing definition using the  X  X lockingIn -dex X  method and two index definitions. into a multi-dimensional space and performs canopy cluster -ing on the objects in this space [21]; and  X  X uffixArrayIndex X , which generates suffix strings of the index key values and inserts them into a sorted array, with the aim to enable efficient access to these values during the record pair com-parison step [1].
 When conducting a linkage and using one of the indexing methods  X  X lockingIndex X ,  X  X ortingIndex X  or  X  X GramIndex X  , the BigMatch [24] approach can be activated in the GUI (as can be seen in Figure 8). With this approach, the smaller of the two input data sets is loaded and an index data struc-ture is built in main memory. It will include all record fields required in the comparison step. Each record of the larger input data set is then read, its index key values are ex-tracted, all records in the same block from the smaller data set are retrieved from the main memory index, and they are compared with the current record from the larger data set. This approach performs only a single pass over the large data set and does not require indexing, sorting or storing of any of its records. This can significantly reduce the run time if two data sets of different sizes are to be linked. Similarly, for the deduplication of a single data set, the in -dexing step can be performed in an overlapping fashion with the field comparison step. An inverted index data structure is built in memory while records are read from the input data set, and their index key values are extracted and in-serted into this index. At the same time, the current record is compared with all previously read and indexed records that have the same index key value. This approach can be selected by ticking the  X  X se Dedup indexing X  box. Once an indexing method has been selected, the actual index keys have to be defined and their various parameters have to be set. Index keys consist of one field (attribute) or a concatenation of several fields. Phonetic encoding functio ns can be used to group similar sounding values into the same block. The encoding functions implemented in Febrl [3] are listed in Figure 9 (b).
 Figure 8 shows an example Febrl  X  X ndex X  tab for the  X  X ensus X  data sets. As can be seen, a user has selected the standard  X  X lockingIndex X  method and has defined two index keys. (a) Indexing (b) Encoding Figure 9: Available methods for indexing (a), phonetic en-coding (b), field comparison (c), and weight vector classifi-cation (d). These are the pull-down menus from the corre-sponding Febrl GUI tabs.
 The first will generate key values from the  X  X URNAME X  field encoded with the Double-Metaphone algorithm [3]. The sec-ond index key will be generated by concatenating values from the  X  X IPCODE X  field with the first three characters of the Soundex [3] encoded  X  X IVENNAME X  field. Records that have the same value in either of these two index key defini-tions will be inserted into the same block and compared in the record pair comparison step. On the  X  X omparison X  tab, the functions used to compare the field values of record pairs can be selected. Febrl contains 26 similarity functions, including twenty approximate str ing comparators [3], as listed in Figure 9 (c). Every comparison requires the user to select a comparison function, as well as the two fields that will be used in this comparison. While normally fields with the same content will be compared (for example surnames with surnames), it is feasible in Febrl to compare different fields, for example to accommodate for swapped given-and surname values. While most of the comparison functions implemented in Febrl are variations of approximate string comparisons [3; 14], special functio ns are available that allow the user to compare fields that con-tain date, age, time or numerical values.
 Figure 10: An example of three field comparison function definitions.
 All comparison functions return a raw similarity value be-tween 0 (total dissimilarity) and 1 (exact match). There is no limit to the number of comparison functions that can be initialised. Because similarity functions can be comput a-tionally quite expensive, especially when longer strings a re compared, it is possible to cache the compared field values together with their similarity value. This will speed-up th e comparison step for all subsequent comparisons of the same two field values. Caching is especially useful for fields that contain a small number of longer string values, such as sub-urb, business or company names, or article titles. The example comparison functions shown in Figure 10 ap-ply the Winkler [3] approximate string comparator on the  X  X URNAME X  fields, a q -gram based approximate string com-parator on the  X  X UBURB X  fields, and the key-difference com-parison function (which counts the number of different char-acters) on the  X  X IPCODE X  fields. For each compared record pair, a weight vector with three matching weights will be generated to be used to classify that pair. The last major step that needs to be initialised (before a linkage or deduplication can be started) is the selection of the method used to classify the weight vectors generated in the comparison step. Febrl currently offers six classification techniques, as listed in Figure 9 (d).
 With the  X  X ellegiSunter X  classifier, all matching weights i n a weight vector are summed, and two manually set thresholds are used to classify record pairs [17]. Those pairs that have a summed weight above the upper threshold are classified as matches, pairs with a matching weight below the lower threshold as non-matches, and pairs with a matching weight between the two thresholds as possible matches.
 The  X  X ptimalThreshold X  classifier requires the true match status of all compared record pairs to be known (i.e. it is a supervised classifier). Then, an optimal threshold can be calculated based on the summed weight vectors. Another su-pervised classifier is  X  X uppVecMachine X , which implements a support vector machine (SVM). Several SVM parameters,
Figure 11: Example  X  X wo-Step X  weight vector classifier. including the kernel function used, can be set in the GUI. For both supervised classifiers, the match status of record pairs is determined through an exact comparison of one of the fields in the data set(s). For example, the  X  X ensus X  data sets contain the  X  X DENTIFIER X  field. For two records that refer to the same person, an exact comparison on this field will result in a similarity value of 1, because they will have the same identifier value. On the other hand, all compar-isons between different people (that have different identifie r values) will result in a similarity value of 0. These similar ity values can then be used as class indicator variable, which allows supervised classification.
 The  X  X arthestFirst X  [18] and  X  X Means X  classifiers are both unsupervised clustering approaches. They cluster weight vectors into matches and non-matches. Several methods can be selected for centroid initialisation, and different dist ance measures are available. It is possible to sample the weight vectors in order to reduce the computational requirements of the clustering process. Both classifiers also allow the se -lection of a  X  X uzzy region X , which will classify the record p airs in the area half-way between the match and non-match cen-troids as possible matches, as described in [19]. Finally, the unsupervised  X  X woStep X  classifier, shown in Fi g-ure 11, is based on the idea of selecting in a first step weight vectors that with high likelihood correspond to true matche s and true non-matches, and to use these vectors in a second step as training examples for a binary classifier [4; 5; 6]. Several methods are implemented in Febrl on how to select the training examples in the first step, and for the second step k -means clustering or a SVM classifier can be selected. Experiments have shown that in certain cases this unsuper-vised two-step approach can achieve linkage quality result s almost as good as supervised classification [4]. On the  X  X utput/Run X  tab, a user can select various settings of how the weight vectors, the match status, the matched record pairs, and the matched files can be saved into output files. It also allows setting several other parameters relat ed to running a project, such as setting a length filter (i.e. re-moving candidate record pairs if their lengths, as concate-nated strings, differs by at least a certain percentage value ), or setting a cut-off threshold to reduce the number of weight vectors that are stored in memory.
 Figure 12:  X  X utput/Run X  tab with options for running a linkage project and writing of output files.
 Figure 12 shows an example  X  X utput/Run X  tab for the  X  X en-sus X  linkage project. With a click on  X  X xecute X , the Febrl GUI will ask the user if the current project should be saved as a Febrl Python file, that can later be execute indepen-dently from the GUI; and if the project should be run within the GUI now. Once started, a small window will appear that shows a progress bar as the project is being run. As can be seen in Figure 13, the  X  X valuate X  page visualises the results of a deduplication or linkage as a histogram of the summed matching weights of the compared record pairs. If the true match and non-match status of record pairs is available (as discussed in Section 4.6), the quality of the conducted linkage or deduplication will be shown using the measurements accuracy, precision, recall and F-measure (o r F-score) [10]. Additional measures that show the complexit y of a deduplication or linkage project are the reduction rati o, pairs completeness and pairs quality [10]. They are based on the number of compared record pairs, the total number of possible pairs (i.e. if each record would have been compared with all others), and if these pairs are true matches or not. This tab shows the Febrl Python code generated when click-ing  X  X xecute X  on other GUI tabs. An example is shown in Figure 14, where the code generated for a k -means record pair classifier can be seen. This allows an experienced Febrl user to verify the correctness of the generated code, and also enables copying pieces of code into other Febrl Python programs outside of the GUI. In order to get a feel of how and by whom Febrl is being used, in early 2009 the author sent out an e-mail questionnaire to forty Febrl users that are currently registered on the Febrl Sourceforge.Net mailing list, and to an additional 37 users who had e-mail contact with the author in the past two years. Of these 77 e-mails, eight were bounced with an error message, mostly because an e-mail did not exist anymore. Of the 69 e-mails sent successfully, 22 users responded to the questionnaire, corresponding to a 32% response rate. Figure 13: Evaluation tab showing the matching weight his-togram and quality and complexity measures for a linkage. Of the respondents, 27% indicated they worked in industry, 18% in government, and the remaining 55% in academia. A large variety of application areas, were the respondents worked in, was given. Most common were the health sec-tor (four respondents), computer science research and the census (three respondents each), and business (two respon-dents). Other areas included demographics, security, tele -communication, data warehousing and social research. 4.6% 13.7% 9% 4.6% 9% 18.2% 40.9% The year when the respondents became aware of Febrl is shown in Table 2. Fifteen respondents (77%) indicated that they have been using Febrl since they became aware of it, however only nine (40.9%) indicated that they are currently using it. The roles in which Febrl is being used is listed in Table 3. Note that a respondent could select several of these roles. As can be seen, learning about record linkage and experimental linkages were the two most common roles Febrl is being used for. Interestingly, more than a quarter of all respondents replied that they are, or were, using Febrl within production linkage projects. Exactly half of the re-spondents also indicated that they only used some of Febrl  X  X  functionality (such as its string comparison or phonetic en -coding modules, or the Febrl data generator), for example in their research.
 Nearly 70% of the respondents (15 of 22) were using or ex-ploring other record linkage systems besides Febrl . These included other open source systems ( Kettle by Penthao, the Link King , and Sun X  X  Mural ), various commercial products, Figure 14: Log tab showing the Febrl Python code generated for an example  X  X Means X  classifier. as well as specific solutions developed in-house. More than three-quarters of the respondents (77%) affirmed that their choice of Febrl was influenced by it being open source soft-ware. The justifications for this answer ranged from strong believers in the open source philosophy, to the more prag-matic views of no costs involved, or that it was important to have access to the source code in order to be able to compare record linkage algorithms for research.
 One of the biggest improvements in Febrl version 0.4 was the addition of a GUI. Surprisingly, however, only a bit more than half (53%) of all respondents replied that the inclusio n of the GUI made a big difference in their appreciation of Febrl . This can partially be explained by the fact that nearly half of all respondents have used Febrl before the GUI was released (November 2007), and they were therefore used to configure it by modifying or writing Python programs. As Febrl  X  X  advantages, respondents listed: being well doc-umented and its references to published research ( Febrl is not based on trade secrets); being highly configurable and extendible; the availability of its source code; the variet y of techniques implemented for all steps of the record linkage process; and the inclusion of a data generator.
 On the other hand, according to the respondents, Febrl  X  X  major disadvantages include its poor scalability; its requ ire-ment of large amounts of memory for large data sets; its slowness (because it is implemented in Python); missing handling of linked data (merging of linked records); error messages that are not always clear; the small community which means help is not easy to get; a complex installation procedure (no one-in-all installer available); the requir ement of Python skills to configure Febrl ; no direct database ac-cess; and only limited support from the developers. Overall, most respondents were pleased about this freely available data cleaning, deduplication and record linkage system. Febrl gave them the opportunities to learn more about the techniques used for these tasks, and allowed them to conduct practical experimental linkages, something tha t would not have been possibly without Febrl . From a developer X  X  point of view, the Febrl project has been  X  and still is  X  an interesting experience. On one hand, the development of software that can be published requires a much increased effort compared to writing research proto-type software that is only used for experimental evaluation s. The development of the Febrl GUI especially was a very time consuming effort. On the other hand, the feedback received from users, and the contacts gained with record linkage re-searchers and practitioners worldwide, would not have been possible without Febrl .
 The Febrl software has made an impact in the areas of data cleaning, deduplication and record linkage. However, mea-suring the impact of such an open source project is not sim-ple. Download numbers on one hand, and the number of users registered on a mailing list on the other hand, seem to be the two ends of the impact spectrum (one might be too high, the other too low). For application oriented software such as Febrl , which is primarily used by people other than computer science researchers, the feedback received from users can be very limited.
 If open source software like Febrl is used within organisa-tions for experimental or even for production linkages, the n commonly this is not acknowledged by the organisation in reports that present results of such linkage projects, or on their corresponding Web sites. This can be quite frustratin g from the point of view of an academic who needs to be able to prove the impact of her or his research (besides academic citation numbers), in order to successfully progress in her or his academic career.
 Ease of installation on all popular operating systems is lik ely to be a major critical factor that can make or break the success of an open source application software. If poten-tial users cannot install open source software in the same way as commercial software, they will likely become easily frustrated and abandon the installation process ( Febrl cur-rently requires manual installation of various Python mod-ules). Users outside of the computer science and informa-tion technology domains, for example people working in the health sector or the social sciences, might not have the skil ls required for a complicated installation process, and there -fore might quickly give up on using software that does not provides a simple and automatic installation procedure. Re -quests to support and help with installation on different sys -tems can be outside of the expertise of the developers. Besides reports on bugs in the Febrl software, a common topic of feedback by users to the Febrl developers is the question of when and if certain features will be added to the software. While most of such features would be of general interest and some are already in Febrl  X  X  to-do list (such as completing the GUI functionalities or adding clerical revi ew support), other requests are specific to a certain domain (e. g. the health sector), country (like providing country specifi c look-up files for data cleaning), or application area (for ex -ample special field comparison functions for business relat ed data). Due to the limited resources (mainly time) of the Febrl developers, it is unlikely that such features will ever be added, unless significant resources will become availabl e to the developers, or parts of the development are taken over by other individuals or organisations.
 As mentioned in the previous paragraph, there is a long (wish) list of features that should be added to the Febrl software at some stage. Completing the functionality of the GUI, and including the data generator and the HMM training modules into the GUI are three major pieces of de-velopment that are required. Adding further quality mea-sures, such as ROC curve or AUC, and an interactive feature that allows manipulation of a classification threshold on th e histogram shown on the  X  X valuate X  tab, would be a major benefit. It would allow users to play with the classification threshold and immediately see the resulting changes in link -age quality measures. Another major addition to the GUI would be a  X  X eview X  tab which allows users to view and man-ually classify record pairs as matches or non-matches that were originally classified as possibly matches. The manuall y classified record pairs can then be used as training examples , by feeding their match status back to the classifier (as shown in Figure 1), facilitating the improvement of the deduplica -tion or linkage quality.
 Apart from the GUI, additional output options should be added to Febrl that allow flexible merging of the linked records into a linked output data set. Providing access to SQL and ODBC databases, in order to load input data from a database and write the linked output data back into a database, would allow the integration of Febrl into a variety of database environments. Implementing additional meth-ods for field comparison, classification and indexing would extend Febrl  X  X  utility as an experimental platform. Another avenue of work that would make Febrl more versa-tile and applicable for practical use will be to improve the performance of the core modules, and at the same time re-ducing the amount of memory required when deduplicating or linking larger data sets. Performance can be increased by replacing the core comparison functions and indexing data structures, currently written in Python, with correspondi ng C code. Given the increasing availability of multi-core par -allel computing platforms, an orthogonal way of increasing performance will be to develop parallel versions of all core Febrl modules (note that version 0.3 of Febrl did include some experimental parallelisation approaches [9]). This research has been supported by the Australian Re-search Council (ARC) under Linkage Project LP0453463. It was partially funded by the New South Wales Department of Health, Sydney, with additional funding provided by the Australian Partnership for Advanced Computing. The au-thor would like to thank everybody who has contributed to the Febrl project over the years, and also thank all Febrl users who responded to the questionnaire.
