 Finite-state models constitute an important frame-work both in syntactic pattern recognition and in language processing. Specifically, stochastic finite-state transducers (SFSTs) have proved to be useful for machine translation tasks within restricted do-mains; they usually offer high speed during the de-coding step and they provide competitive results in terms of error rates (Mohri et al., 2002). Moreover, SFSTs have proved to be versatile models, which can be easily integrated with other finite-state mod-els (Pereira and Riley, 1997).

The article (Casacuberta and Vidal, 2004) ex-plored an automatic method to learn an SFST from a bilingual set of samples for machine translation pur-poses, the so-called GIATI ( Grammar Inference and Alignments for Transducers Inference ). It described how to learn both the structural and the probabilistic components of an SFST making use of underlying alignment models.

A multi-target SFST is a generalization of stan-dard SFSTs, in such a way that every input string in the source language results in a tuple of output strings each being associated to a different target language. An extension of GIATI that allowed to in-fer a multi-target SFST from a multilingual corpus was proposed in (Gonz  X  alez and Casacuberta, 2006). A syntactic variant of this method (denoted as GI-AMTI) has been used in this work in order to infer the models from training samples as it is summa-rized in section 3.

On the other hand, speech translation has been al-ready carried out by integrating acoustic models into a SFST (Casacuberta et al., 2004). Our main goal in this work is to extend and assess these method-ologies to accomplish spoken language multi-target translation. Section 2 deals with this proposal by presenting a new integrated architecture for speech-input multi-target translation. Under this approach spoken language can be simultaneously decoded and translated into m languages using a unique network. In section 4, the performance of the system has been experimentally evaluated over a trilingual task which aims to translate TV weather forecast into two languages at the same time. The classical architecture for spoken language multi-target translation involves a speech recogni-tion system in a serial architecture with m decoupled text-to-text translators. Thus, the whole process in-volves m + 1 searching stages, a first one for the speech signal transcription into the source language text string, and further m for the source language translation into the m target languages. If we re-placed the m translators by the multi-target SFST, the problem would be reduced to 2 searching stages. Nevertheless, in this paper we propose a natural way for acoustic models to be integrated in the same net-work. As a result, the input speech-signal can be simultaneously decoded and translated into m target languages just in a single searching stage.
Given the acoustic representation ( x ) of a speech signal, the goal of multi-target speech translation is to find the most likely m target strings ( t m ); that is, one string ( t i ) per target language involved ( i  X  X  1 , . . . , m } ). This approach is summarized in eq. (1), where the hidden variable s can be in-terpreted as the transcription of the speech signal: c
Making use of Bayes X  rule, the former expression turns into: Empirically, there is no loss of generality if we as-sume that the acoustic signal representation depends only on the source string: i.e., that P ( x | t m , s ) is in-dependent of t m . In this sense, eq. (2) can be rewrit-ten as: Equation (3) combines a standard acoustic model, P ( x | s ) , and a multi-target translation model, P ( t m , s ) , both of whom can be integrated on the fly during the searching routine. Nevertheless, the outer maximization is computationally very expensive to search for the optimal tuple of target strings t m in an effective way. Thus we make use of the so called Viterbi approximation, which finds the best path. Given a multilingual corpus, that is, a finite set of multilingual samples ( s , t 1 , . . . , t m )  X   X   X   X   X   X   X  X  X  X   X   X  m , where t i denotes the translation of the source sentence s (formed by words of the input vo-cabulary  X  ) into the i -th target language, which, in its turn, has a vocabulary  X  i , the GIAMTI method can be outlined as follows: 1. Each multilingual sample is transformed into a 2. Once the set of multilingual samples has been 3. The extended symbols associated with the
In this work, the first step of the algorithm (as described above), which is the one that handles the alignment and segmentation routines, relies on statistical alignments obtained with G IZA ++ (Och, 2000). The second step was implemented us-ing our own language modeling toolkit, which learns stochastic k-testable in the string-sense gram-mars (Torres and Varona, 2001), and allows for back-off smoothing. 4.1 Task and corpus We have implemented a highly practical application that could be used to translate on-line TV weather forecasts into several languages, taking the speech of the presenter as the input and producing as output text-strings, or sub-titles, in several languages. For this purpose, we used the corpus MET EUS (see Ta-ble 1) which consists of a set of trilingual sentences, in English, Spanish and Basque, as extracted from weather forecast reports that had been published on the Internet. Basque language is a minority lan-guage, spoken in a small area of Europe and also within some small American communities (such as that in Boise, Idaho). In the Basque Country it has an official status along with Spanish. However both languages differs greatly in syntax and in semantics. The differences in the size of the vocabulary (see Table 1), for instance, are due to the agglutinative nature of the Basque language.

With regard to the speech test, the input consisted of the speech signal recorded by 36 speakers, each one reading out 50 sentences from the test-set in Ta-ble 1. That is, each sentence was read out by at least three speakers. The input speech resulted in approx-imately 3 . 50 hours of audio signal. Needless to say, the application that we envisage has to be speaker-independent if it is to be realistic.

Table 1: Main features of the MET EUS corpus. 4.2 System evaluation The experimental setup was as follows: the multi-target SFST was learned from the training set in Ta-ble 1 using the GIAMTI algorithm described in sec-tion 1; then, the speech test was translated, and the output provided by the system in each language was compared to the corresponding reference sentence. Additionally, two mono-target SFST were inferred from the same training set with their outputs for the aforementioned test to be taken as baseline. 4.2.1 Computational cost
The expected searching time and the amount of memory that needs to be allocated for a given model are two key parameters to bear in mind in speech-input machine translation applications. These values can be objectively measured based on the size and on the average branching factor of the model displayed in Table 2. Table 2: Features of multi-target model and the two decoupled mono-target models (one for Spanish to Basque translation, referred to as S2B, and the sec-ond for Spanish to English, S2E).

Adding the states and the edges up for the two mono-target SFSTs that take part in the decoupled architecture (see Table 2), we conclude that the de-coupled model needs a total of 185 , 216 edges to be allocated in memory, which represents an increment of 13% in memory-space with respect to the multi-target model.

On the other hand, the multi-target approach of-fers a slightly smaller branching factor than each mono-target approach. As a result, fewer paths have to be explored with the multi-target approach than with the decoupled one, which means that searching for a translation can be faster. In fact, experimental results in Table 3 show that the mono-target archi-tecture works %11 more slowly than the multi-target one. Table 3: Time needed to translate the speech-test into two languages.

Summarizing, in terms of computational cost (space and time), a multi-target SFST performs bet-ter than the mono-target decoupled system. 4.2.2 Performance
So far, the capability of the systems have been as-sessed in terms of time and spatial costs. However, the quality of the translations they provide is, doubt-less, the most relevant evaluation criterion. In order to assess the performance of the system in a quan-titative manner, the following evaluation parameters were computed for each scenario: bilingual evalua-tion under study (BLEU), position independent er-ror rate (PER) and word error rate (WER).

As can be derived from the Speech-input trans-lation results shown in Table 4, slightly better re-sults are obtained with the classical mono-target SF-STs, compared with the multi-target approach. From Spanish into English the improvement is around 3 . 4% but from Spanish into Basque, multi-target ap-proach works better with an improvement of a 0 . 8% . Table 4: Speech-input translation results for Spanish into Basque (S2B) and Spanish into English (S2E) using a multi-target SFST or two mono-target SF-STs.

The process of speech signal decoding is itself introducing some errors. In an attempt to measure these errors, the text transcription of the recognized input signal was extracted and compared to the input reference in terms of WER as shown in Table 5. Table 5: Spanish speech decoding results for the multi-target SFST and the two mono target SFSTs. A fully embedded architecture that integrates the acoustic model into the multi-target translation model for multiple speech translation has been pro-posed. Due to the finite-state nature of this model, the speech translation engine is based on a Viterbi-like algorithm. The most significant feature of this approach is its ability to carry out both the recogni-tion and the translation into multiple languages inte-grated in a unique model.

In contrast to the classical decoupled systems, multi-target SFSTs enable the translation from one source language simultaneously into several target languages with lower computational costs (in terms of space and time) and comparable qualitative re-sults.

In future work we intend to make a deeper study on the performance of the multi-target system as the amount of targets increase, since the amount of pa-rameters to be estimated also increases.
 This work has been partially supported by the Uni-versity of the Basque Country and by the Spanish CICYT under grants 9/UPV 00224.310-15900/2004 and TIC2003-08681-C02-02 respectively.

