 Department of Computer Oriented Statistics and Data Analysis, University of Augsburg, Augsburg, Germany 1. Introduction
The increased use of data to inform policy and improve practice requires a renewed emphasis on making, priority setting, and ongoi ng monitoring of programs and policies. Poor quality of data can exception mining are also found. According to [4], observations which appear to be inconsistent with the rest of the dataset are outliers or potential anomalies.
 manually.

The aim of our work was to develop a method for automatically detecting unusual and erroneous 2. Data quality
Accurate data are a fundamental requirement of good information systems. And yet most information data is an important dimension of information quality  X  the most important dimension [5]. Today the basic concepts behind data and informatio n quality are well understood, c.f. [17 X 19].
Data quality is a complex and essentially unstructured concept. Many disciplines have taken one-shot approaches addressing simpler abstract versions of the real problem. A major challenge in devising and validation for the data cleaning process.
 size of datasets analysed has increased from megabytes to gigabytes and even terabytes. This makes un-zoomed plot (for details see [20,21,23]). The cells with red borders are censored cells.
Erroneous cases are indicated by arrows. Arrow 1 points to unmarried people whose relation to the head of household is son/daughter (married), which is inconsistent. Arrow 2 points to married people are married to the head of household but whose marital status is divorced or widowed. Using censored zooming in a fl uctuation diagram we can identify unusual combinations which should not arise in the data.

Another fl uctuation diagram of educational level by current enrolment in an educational institution have had no education but are now enrolled in a nursery.

Though erroneous cases revealed by fl uctuation diagrams are easy to understand, they still require domain knowledge about the meanings of variables. In this paper we present an approach to overcome this disadvantage. Erroneous data are automatically detected without having domain knowledge. A experimental results of applying these methods to a real world dataset are described. 3. Basic idea rule is an implication of the form X  X  Y ,where X  X  X  , Y  X  X  are itemsets, and X  X  Y = {} .From D we test its consistency with the generated rules. Consider a rule, age group (  X 11 X 15 X  )  X  marital aged between 11 and 15. The support 0.2026 means that 20.26% people in the dataset D are aged 11 X 15 and never married. The con fi dence 0.996 means that 99.6% of the people in the dataset D have never data point contradicting this rule must be a possible anomaly.

A case becomes more and more suspicious, the more rules it violates. For example, a person may violate a rule with lower con fi dence current education enrolment (  X  X asters X  )  X  educational For example, if the same people also violate the rule current education enrolment (  X  X asters X  )  X  marital status (  X  X ever married X  )ofcon fi dence 0.98, then the combination of violating both rules suggests that this is an erroneous case and  X  X urrent education enrolment X  is probably the error.
Since anomalies or erroneous cases are always small in number, we will drop the rules for which the a hierarchical structure in that a simple rule X  X  Y can be viewed as a parent rule of { X, V } X  Y . on the number of rules they violate. 4. Association rules basket analysis have been generalized to include statistical datasets and relational databases. of association rules and we will also use this term.
 itemset X with respect to dataset D is called the support of X : where |D| is the total number of transactions in dataset D .
 frequent itemset, where 0 s 1 .
 The collection of frequent itemsets in D with respect to s is denoted by An association rule is an implication of the form X  X  Y ,where X  X  X  , Y  X  X  are itemsets, and X  X  Y = {} . X is called the body or antecedent, and Y is called the head or consequent of the rule. The support s of an association rule X  X  Y in D , is the support of both X and Y i.e., X  X  Y in D . That is, Y contained in a transaction, given that X is contained in that transaction: 0  X  1 .
  X  is denoted by: De fi nition 3. ( Support Monotonicity ) Given a transaction database D over I ,let X, Z  X  I be two itemsets. Then, closed with respect to set inclusion.

An itemset X is closed in a database D if there exists no proper super-itemset Z such that Z has the same support count as X in D .
 X is a maximal frequent itemset in set D if X is frequent, and there exists no super-itemset Z such regarding the frequent itemsets [11].
 Then, 5. Proposed framework
In this section, a framework for the detection of erroneous cases based on association rules will be variables and then the economic variables.
 5.1. Step 1. Preprocessing
First of all, depending on the underlying data it might be necessary to discretize data values. Dis-is available then it should be used, otherwise the equal binning method can be used. columns with the exact number depending on how many intervals have been chosen for each attribute. Table 2 shows a mapping table with sample intervals chosen for each attribute. 5.2. Step 2. Rule generation
Find maximal closed itemsets at low minimum support value (see [2,3]). Anomalies are far less
Using selected rules R  X  , select the cases which violate these rules. Let R  X  be a set of required an association rule with body ( r )= X and head ( r )= Y . Let the mapping violates that determines whether a case T  X  X  violates a rule r  X  X   X  be de fi ned as: 5.3. Step 3. Rule pruning
Anomalies or erroneous cases are always small in number. Therefore we will drop the rules for which follows: So we will drop the rules which have rule score &gt; X  . Therefore the set of rules for selecting the erroneous cases reduces from R  X  to R  X  ,and 5.4. Step 4. Redundant rules
Association rules can have a hierarchical structure in that a simple rule X  X  Y can be viewed as a parent rule of { X, V } X  Y ,where { X, V } X  Y is a child rule of that rule. In usual association reduce from R  X  to R final . 5.5. Step 5. Data ranking Now we assign a rank to all cases by summing the number of violated rules from rule set R final . Ranks will be calculated as follows: case rank . More potentially erroneous cases will come on top of the output. than a speci fi ed threshold value. 6. Algorithm of proposed framework The algorithm of the proposed framework is given below.
 Input
D :adataset { t 1 ,t 2 ,...,t n } , with k items (or variables) and n transactions (or cases) arm : an association rule mining algorithm  X  : minimum con fi dence value s : minimum support value  X  : threshold for rule violation score Output Out : a set of erroneous cases Procedure for each item k  X  X  endfor for each itemset i  X  X  T endfor for each closed itemset use algorithm arm and generate association rules endfor for each rule i  X  ruleset endfor for each rule i  X  X   X  endfor for each rule i  X  X   X  endfor for each rule i  X  X   X  endfor for each transaction i  X  X  T endfor
Output Out contains erroneous cases sorted by case rank . 7. Experimental evaluation closed rules from 80 binary variables on a normal personal computer. However, the pruning step i.e., this step ef fi cient and pruning time is reduced from a few hours to a few minutes. the demographic part of the Pakistan Labour Force Survey dataset for 2003 X 04. This section contains 42 binary variables.

According to the minimum support condition given in step 2 of the framework, the minimum support Apriori algorithm [2], implemented in the contributed package arules by [10] in the R programming language [22], closed itemsets are generated from the entire dataset under this minimum support con-773 rules.

In the pruning step, the number of violated cases is calculated for each rule and rules whose number 139123 cases violated some rules from R final .
  X  X elow middle X  and are reported as  X  X lliterate X  will be identi fi ed by this rule.
Rules 3, 5 and 8 show associations between relation to head and marital status . Rule 3 shows that Fig. 1.
 these attribute associations we can identify erroneous cases. The sequence obtained from sorting the cases based on the assigned rank orders the cases by their degree of error.
 minimum support. If minimum support is chosen too small, we run the risk of treating some unusual cases as normal. On the other hand higher minimum support might not cover some of the itemsets. The assigned to them. The threshold value  X  is associated with support and con fi dence. has worked on). 8. Conclusion
In this paper, we propose a framework based on association rules for the data cleaning process. This framework is a semiautomatic process, through which we can fi nd erroneous cases. The basic idea is small set of rules is presented to an analyst.

This framework provides very good results with little domain knowle dge and even can be used with no domain knowledge. The framework is very effective for a dataset with many variables, especially when dataset has been performed and found very effective in revealing erroneous cases. Acknowledgments
The authors gratefully acknowledge helpful comments by the referees. This research was funded by the Higher Education Commission of Pakistan (HEC) and the DAAD. Th e authors are also thankful to References
