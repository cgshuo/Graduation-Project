 srangan@qualcomm.com Estimating a vector x  X  R n from measurements of the form estimators for x is the maximum a posteriori (MAP) estimate the m measurements in the vector y .
 x complex problems where many other methods had previously fa iled [3]. x appropriate limits with large deviations arguments.
 analysis, will be called the Replica MAP Claim.
 of in practice, these algorithms are difficult to analyze preci sely. ratios k/n , n/m and SNR . a diagonal matrix of positive scale factors, y knowing the measurement matrix A and scale factor matrix S . The components x p be defined later.
 x estimator should be captured in the distribution of x . follows:  X  X ostulated X  prior distribution p the true values p where p noise variance specified as parameters after the semicolon: where C is a normalization constant.
 Given &gt; 0 , let p where  X  ( ) is the Gaussian distribution The distribution p q ( x ) from an observation of the form Also, given two distributions, p true distribution x  X  p x  X  p 1 ( x ) and noise level = 1 .
 MPMSE estimator based on a postulated prior p n effective noise levels  X  2 problem, a component x  X  p surement z . The additive noise variance is =  X  2 estimator  X  x ( z ; p The effective noise levels  X  2 (12). Note that  X  2 via the terms and minimizer of a certain Gibbs X  function [6]. the form almost all y .
 verified that  X  x map ( y ) is the MAP estimate where p where f ( x ) = P estimators show that Replica MMSE Claim, we can then extrapolate the behavior of t he MAP estimator. To state the claim, define the scalar MAP estimator z . We also assume that the limit exists where  X  x =  X  x map Assume: IV] for additional discussion of technical assumptions. be some deterministic component index with j ( n )  X  X  1 , . . . , n } . Then: the noise-corrupted version. f prior for x for numerical evaluations of asymptotic performance. the cost function With this cost function, the scalar MAP estimator in (16) is g iven by The Replica MAP Claim now states that there exists effective noise levels  X  2 for any component index j , the random vector ( x ( x, s,  X  x ) where x  X  p 0 ( x ) , s  X  p S ( s ) , and  X  x is given by where v  X  N (0 , 1) ,  X  component x yield the estimate  X  x (17) is given by Hence, where we have use the fact that  X  fixed-point equations where the expectations are taken with respect to x  X  p numerically given distributions of x and s . regularized estimation where k x k achievable by practical algorithms.
 this problem, we can consider an approximation of (28), the details in taking the appropriate limits.
 With f ( x ) given by (28), the scalar MAP estimator in (16) is given by noise levels  X  2 converges in distribution to the vector ( x, s,  X  x ) where x  X  p where v  X  X  (0 , 1) ,  X  rupted by some effective noise level  X  2  X  .
 The fixed-point equations for the effective noise levels  X  2 where the expectations are taken with respect to x  X  p (32). These fixed-point equations can be solved numerically . show the actual median SE over 1000 Monte Carlo simulations. Bernoulli X  X aussian process. Specifically, is 10 dB. Each set of trials is represented by its median squar ed error in Fig. 1. method to quantify the precise performance losses of practi cal algorithms. of the probability of sparsity pattern recovery. nique is sufficiently general to study effects of dynamic ran ge.
