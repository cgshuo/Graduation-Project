 Several information organization, access, and filtering systems can benefit from different kind of document representations than those used in traditional Information Retrieval (IR). Topic Detection and Tracking (TDT) is an example of such an application. In this pa-per we demonstrate that named entities serve as better choices of units for document representation over all words. In order to test this hypothesis we study the effect of words-based and entity-based representations on Story Link Detection (SLD) -a core task in TDT research. The experiments on TDT corpora show that entity-based representations give significant improvements for SLD. We also propose a mechanism to expand th e set of named e ntities used for document representation, which enhances the performance in some cases. We then take a step further and analyze the limitations of us-ing only named entities for the document representation. Our stud-ies and experiments indicate that adding additional topical terms can help in addressing such limitations.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering ; H.3.4 [ Information Storage and Retrieval ]: Systems and Software X  Performance evaluation (efficiency and effectiveness) Measurement, Performance, Experimentation Topic Detection and Tracking, Story Link Detection, Document representation, Named Entities
Document representation is one of the most common and crucial stages of an information organization and access system. Several methods and models of document representation have been pro-posed based on the target application. Examples include word-based [7], language models [6], and graph-based [3]. Some of them are general enough to be applicable to almost any IR-based appli-cation. However, some tasks demand a different approach to doc-ument representation. Topic Detection and Tracking (TDT) [1] is one such domain.

Loosely speaking, since TDT deals with information that is tightly related to certain event happening at certain places and/or with certain people or organization, it makes sense to explicitly con-sider such terms, also called named entities, while representing documents. In this paper we argue that using named entities -the names of people, places, organizations, etc. -is more suitable than using all words for document representation in TDT. In order to demonstrate this, we use some examples and extensive experimen-tation on TDT corpora with the Story Link Detection (SLD) task as the focus. SLD deals with finding if two news stories are on the same topic or not, which is at the core of almost all the tasks in TDT. Our experiments and analysis demonstrate that a named en-tity based representation brings down the detection cost by a signif-icant amount, and thus improves the performance of a SLD system.
Our experiments reported in this paper were carried out on TDT3 and TDT4 corpora available from NIST. 1 One set of experiments were performed splitting the TDT3 corpus in two almost equal parts for training and testing, whereas for another set of experiments we used the entire TDT3 corpus for training and the TDT4 corpus for testing. The evaluation of the SLD system is done using the mea-sure given by NIST: C where P Miss = No. of missed detection/No. of targets, P Fa No. of false alarms/No. of non-targets, C miss and C Fa are the costs of a missed detection and a false alarm respectively, and are pre-specified, P Target is the apriori probability of finding a tar-get. 2 This detection cost is then normalized as given below. ( C
This section describes our baseline as well as a set of methods that make use of named entities in various ways. http://www.nist.gov
TDT evaluation script predefines P Target to be 0.02, however, we calculate its value from the corpus that we are experimenting on. Due to this change, the scores that we obtain would be different than the ones obtained by the scripts that TDT provides. However, they reflect merely the change of scale and not the relative perfor-mances of various systems. TFIDF based representation of documents is widely used in many IR applications [7]. We construct vectors for each document using TFIDF weighting and then find the cosine between two vectors. This score becomes the similarity measurement for the given doc-uments. If this score is above the threshold, then the given pair of stories are said to be on the same topic. Later we shall see how to derive this threshold from the training data.
As we discussed in the previous section, making use of named entities in case of a task such as SLD makes more sense than using all the words. One simple approach of putting this in effect is to use traditional TFIDF technique on named entities. We used BBN X  X  Identifinder [2] to extract the named entities and threw away the rest of the words from the documents. Thus, the extracted named entities became the representation of the documents. We executed the similar process on them as a regular vector space model with TFIDF term weighting and found the corresponding vectors. These vectors were compared with the cosine similarity measure to find the similarity between the documents.
We realized that in the above technique we were throwing away a lot of information. What remained was indeed the information with high content, but in some cases it may not be sufficient to match two documents. In such cases when the original named entities are not enough, we may want to introduce some more information. We do this by augmenting the original documents, represented as a col-lection of named entities, with related named entities. In order to do this, we created a graph G with named entities from the train-ing corpus as the nodes. We connected two nodes with an edge if the named entities that they represent occur together at least in one document. Now, while comparing two documents, we extend the original set of named entities by a dding their imme diate neighbors from G . After adding such related named entities, we use the same procedure as the above method to perform matching.

The basic idea of this technique is to expand the original set of named entities that we extracted with some related entities. This approach may sound similar to various query expansion techniques in IR like Relevance Model [5], however, it is to be noted that we are not performing any retrieval here. The expansion is done over the named entities a nd based on past knowle dge about their inter-connections.
In the above proposed method, we added the related named enti-ties with full confidence giving them equal importance as the orig-inal set of named entities. We also did not disti nguish among the newly added named entities for their relative importance to the doc-uments in which they were added. We address this issue by finding the strength of the connections among the named entities. In other words, instead of considering an unweighted graph, we now try to find weights on each edge. Among many possibilities of quanti-fying the strength of the connection between two entities, we find mutual information more appropriate for out task. The mutual in-formation between two entities e i and e j was calculated using where p ( e i ) and p ( e j ) respectively are the probabilities of entities e and e j occurring in the corpus and p ( e i ,e j ) is the probability of entities e i and e j occurring together in the same document. When we add an entity e j to the existing set of entities because it is related to entity e i (already present in the document), we add it with the confidence MI ( e i ,e j ) . The rest of the process of matching two documents is the same as that of the above method.
The results from our experiments on the two different data-sets are summarized in Table 1. The results obtained by techniques 2 and 4 were found statistically significant with respect to the base-line using two-tailed paired t -test as well as McNemar X  X  statistical significance test [4] (a non-parametric test, which is more appro-priate for this task). Since lower cost is better, we can say that techniques 2 and 4 demonstrated significant improvements over the baseline.
 Table 1: Normalized detection cost for two sets of experiments: TDT3 split for training and testing, and entire TDT3 for train-ing and TDT4 for testing. Lower cost is better. # Technique TDT3-TDT3 TDT3-TDT4 1 TFIDF on words (Baseline) 0.7964 0.8764 2 TFIDF on entities 0.7374 0.4860 3 Unweighted expansion 0.8723 0.8854 4 Weighted expansion 0.4937 0.7759 In the work reported here, we identified the uniqueness of Topic Detection and Tracking (TDT) tasks. We showed that using named entities for representation in case of TDT is a better idea than using a word-based technique. In order to demonstrate this, we worked with Story Link Detection (SLD), which is at the core of the TDT. Our experiments on various TDT corpora revealed that our pro-posed representation is indeed very effective. In some additional experiments not reported here, we also tried to test the limits of named entities. Our experiments and analysis showed that named entities lack e nough information in some cases. We discovered that augmenting the named entities with some additional topical terms helps in addressing this limitation. This work was supported in part by the Center for Intelligent Information Retrieval and in part by NSF grant #IIS-0527159. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor.
