 Constantine Caramanis CMCARAM @ ECE . UTEXAS . EDU Inderjit S. Dhillon INDERJIT @ CS . UTEXAS . EDU University of Texas at Austin, Austin, TX 78712 Minimizing the rank of matrices restricted to a convex set is an important problem in the field of optimization with numerous applications in machine learning. For instance, many important problems like low-rank kernel learning, feature efficient linear classification, semi-definite embe d-ding (SDE), non-negative matrix approximation (NNMA), etc., can be viewed as rank minimization problems over a polyhedron with additional convex constraints such as a Frobenius norm constraint and/or a semi-definiteness con-straint. Even though there has been extensive work on the specific problems mentioned above, the general problem of rank minimization over polyhedral sets is not well un-minimization when there are a large number of trace con-straints along with a few convex constraints that are rela-tively  X  X asy X  in a precise sense defined below.
 We now formulate the rank minimization problem we study. Let A following optimization problem which we refer to as RMP (for Rank Minimization over Polyhedron): The set C will represent the  X  X asy X  constraints in the sense that for such a set C , we assume that RMP with a single trace constraint can be solved efficiently. This holds for many typical convex sets C , e.g., the unit ball under any or Frobenius norm, the semi-definite cone, and the inter-section of the unit ball with the p.s.d. cone. Furthermore, low-rank kernel learning, SDE and NNMA can all be seen as instantiations of the above general formulation. The general RMP problem as stated above is non-convex, NP-hard and, as we prove, cannot be approximated well unless P = N P . Due to the computational hardness of the problem, much of the previous work has concentrated on providing heuristics, with no guarantees on the quality of the solution. We remark that the recent trace-norm based approach of (Recht et al., 2007) does guarantee an optimal solution for a simplified instance of RMP where only well-conditioned linear equality constraints are allowed. How-ever, it is not clear how to extend their guarantees to the more general RMP problem.
 We now list the main contributions of this paper:  X  We show that for the RMP problem, the minimum fea- X  We provide an algorithm for RMP based on the Multi- X  We provide an algorithm for RMP based on the frame- X  For a practical application, we apply our methods to We empirically evaluate our methods on synthetic instances of
RMP , where the constraints are chosen randomly. We compare them with the trace-norm heuristic of (Fazel et al., 2001; Recht et al., 2007) and the log-det heuristic of (Fazel et al., 2003), and our experimental results indicate that ou r methods are significantly faster and give comparable rank solutions to existing methods. We also evaluate the per-formance of our methods for low-rank kernel learning on UCI datasets. On all the datasets, our algorithms improve the accuracy of the baseline kernel while also significantly decreasing the rank. Most existing methods for rank minimization over convex sets are based on relaxing the non-convex rank function to a convex function, e.g., the trace-norm (Fazel et al., 2001; (Fazel et al., 2003). Unfortunately, these heuristics do no t have any guarantees on the quality of the solution in gen-eral. A notable exception is the work of (Recht et al., 2007), which extends the techniques of (Cand`es &amp; Tao, 2005) for compressed sensing to rank minimization. (Recht et al., 2007) show that minimizing the trace-norm guarantees an optimal rank solution to a special class of RMP where only well-conditioned linear equalities are allowed. Thus thei r approach is limited in its applicability and it is not clear how to extend it to general RMP . We also remark that mini-mizing the trace-norm is computationally expensive, which further limits its applicability. (Barvinok, 2002) (Chapter V) describes an approximation algorithm for RMP based on random projections and a gen-eralization of the Johnson-Lindenstrauss Lemma, with an approximation guarantee similar to the one provided by our MW algorithm (Section 4.1). However, this approach works only for a special case of RMP where only linear equalities described by p.s.d. matrices are allowed. Fur-thermore, this approach needs to solve the relaxed RMP problem without the rank constraint which involves solving a large semi-definite programming problem. This maybe undesirable for various real-world applications such as th e low-rank kernel learning problem. In contrast, our ap-proaches can be used for a larger class of convex sets and are considerably more scalable.
 Several specific instances of the general RMP problem have been widely researched in the machine learning com-munity. Examples include low-rank kernel learning, SDE, sparse PCA and NNMA. Most methods for these problems can be broadly grouped into the following two categories: a) methods which drop the rank constraint and use the top k eigenvectors of the solution to the relaxed optimization problem e.g., (Weinberger et al., 2004); b) methods which factor the matrix X in RMP into AB T and optimize the re-sultant non-convex problem e.g., (Lee &amp; Seung, 2000; Kim et al., 2007). However, typically these methods do not have any provable guarantees.
 We apply our algorithms for the general RMP problem to the low-rank kernel learning problem(Bach &amp; Jordan, 2005; Kulis et al., 2006). Existing methods for this prob-lem do not provide any provable guarantees on the solution begin with. In contrast, a straight forward application of our general RMP framework gives algorithms with prov-able guarantees on the rank of the learned kernel. Further-more, we demonstrate that our algorithms can be used to initialize existing methods to obtain better solutions. Our approaches to RMP are based on two online learning methods -the generalized experts framework as abstracted in (Arora et al., 2005b) and the online convex programming (Zinkevich, 2003), which we now review briefly. 2.1. Multiplicative Weights Update Algorithm The Multiplicative Weights Update algorithm (MW algo-rithm) is an adaptation of the Winnow algorithm (Little-stone &amp; Warmuth, 1989) for a generalized experts frame-framework was implicitly used by (Plotkin et al., 1991) for solving several fractional packing and covering problems and was formalized and extended to semi-definite programs in (Arora et al., 2005a). Throughout this work we will fol-low the presentation of the generalized experts framework as abstracted in (Arora et al., 2005b).
 In the generalized experts (GE) framework there is a set of n experts, a set of events E , and a penalty matrix M such j  X  X  . The penalties are assumed to be bounded and lie GE framework is to formulate a prediction algorithm that chooses a distribution D t = ( p t at time step t , so that the total expected loss incurred by the prediction algorithm is not much worse than the total loss incurred by the best expert. Formally, the goal of the prediction algorithm is to minimize Note that the distribution in round t , D t , must be chosen without knowledge of the event j t chosen at time step t . At every step t , the MW algorithm has a weight w t expert i , and sets the distribution D t = ( p t p = w t i / P j w t j . The MW algorithm then proceeds analo-gously to the Winnow algorithm and updates the weights at time step t +1 to w t +1 0 is a parameter provided to the algorithm. For our analysis we will use the following theorem.
 Theorem 2.1 (Corollary 4 of (Arora et al., 2005b)) . Sup-pose that for all i and j  X  X  , M ( i, j )  X  [  X   X ,  X  ]  X  &gt; 0 be an error parameter and let  X  = min {  X  4  X  average expected loss of the MW algorithm 2.2. Online Convex Programming The online convex programming (OCP) framework (Zinke-vich, 2003; Kalai &amp; Vempala, 2005; Hazan et al., 2006) models various useful online learning problems like indus-trial production and network routing. The OCP framework involves a fixed convex set K and a sequence of unknown cost functions f decision maker must choose a point z cost f the knowledge of z without knowing f rithm after T steps equals P is to minimize the regret as defined below: (Zinkevich, 2003) has shown that in the case when the func-tions f dient, one can achieve a regret of O (  X  T ) . Let max z f ( z ) k , where kk denotes the Euclidean norm (or Frobe-nius norm if the set K is defined over matrices). Also, as-point z . Under the above assumptions (Zinkevich, 2003) proposed a Generalized Infinitesimal Gradient Ascent algo-rithm which achieves a regret of O (( G 2 + k K k 2 ) function GIGA in Algorithm 2 describes a slightly modi-fied version of (Zinkevich, 2003) X  X  algorithm that achieves the following improved regret bound.
 Theorem 2.2 (Adaptation of Theorem 1 of (Zinkevich, GIGA sub-routine of Algorithm 2 after T rounds, Proof sketch: Using the modified step-size in Algorithm 2, the theorem follows from Zinkevich X  X  original proof. As was mentioned in the introduction, RMP is NP-hard in general. Further, by a reduction to the problem of support minimization over convex sets, and using hardness of ap-proximation results from (Amaldi &amp; Kann, 1998) we prove the following hardness result for RMP. A full proof of the following theorem appears in (Meka et al., 2008). Theorem 3.1. There exists no polynomial time algorithm for approximating RMP within a logarithmic factor unless P = NP. Further, assuming NP * DTIME ( n poly log n ) , RMP is not approximable within a factor of 2 log 1  X   X  n for every  X  &gt; 0 ; and RMP is not approximable within a factor of | b | : 1  X  i  X  m } 1 .
 In view of the above hardness result we introduce a weaker notion of approximation. We believe the relaxed notion of approximation to be of equal use, if not more, as the stan-dard notion of approximation in practice. For an instance of where b = ( b
F ( A 1 , . . . , A m , b , C ) = { X : X  X  X  , Tr ( A i X )  X  b Definition 3.1. Given a function c : R  X  R a matrix X is a ( c (  X  ) ,  X  ) -approximate solution to RMP the following hold:  X  X  X  F ( A 1 , . . . , A m , b  X   X  1 , C ) rank (  X  X )  X  c (  X  ) min { rank ( X ) : X  X  F ( A there exists a polynomial time algorithm that given inputs A 1 , . . . , A m , b ,  X  to RMP .
 Thus, along with approximating the minimum feasible rank we also allow a small violation, quantified by  X  , of the con-straints. Note that for  X  = 0 , we recover the normal notion of approximation with an approximation factor of c (0) . Our approaches to RMP rely on the fact that even though RMP is hard in general, it is efficiently solvable for certain convex sets C when there is a single trace constraint. For instance, when C = { X : k X k with a single trace constraint can be solved efficiently usin g a singular value decomposition of the constraint matrix. In our approach, we assume the existence of an oracle O that solves the following RMP problem with a single trace constraint, and returns an optimal X or declares the prob-lem infeasible: As discussed above, for certain convex sets C , oracle solves a non-convex problem. In both our approaches, we where the trace constraint Tr ( AX )  X  b is obtained by a weighted combination of the original trace constraints. Th e trick then is to choose the combinations in such a way that after a small number of iterations, we can find a low-rank Based on the above intuition, we give two approaches to solve the RMP problem -one based on the Multiplicative Weights Update algorithm and the other based on online convex programming.
 Before we describe our algorithms, we need to intro-duce additional notation. For an instance of RMP speci-fied by matrices A vex set C , let D = max {k X k sume, without loss of generality, that D  X  1 . Recall that F (( A denote the feasibility sets as defined in (3) and max {k A i k F + | b i | : 1  X  i  X  m } . Further, let k the rank of the optimal solution to RMP . That is, Algorithm 1 RMP-MW (Multiplicative Updates) Require: Constraints ( A Require: Oracle O ( A, b ) which solves 1: Initialize: w 1 2: repeat 3: Set ( A t , b t ) = P 4: if Oracle O ( A t , b t ) declares infeasibility then 5: return Problem is infeasible 6: else 7: Obtain X t using Oracle O ( A t , b t ) 8: Set M ( i, X t ) = Tr ( A i X t )  X  b i 9: Set  X  = max i M ( i, X t ) 11: end if 12: Set t = t + 1 13: until t &gt; T 14: return X = P 1: Set  X  = min {  X  2: for all 1  X  i  X  m do 3: if M ( i, X t )  X  0 then 5: else 7: end if 8: end for 4.1. Rank Minimization via Multiplicative Weights In this section we present an approach to RMP based on the generalized experts (GE) framework described in Sec-tion 2.1. To adapt the GE framework for the RMP prob-lem, we first need to select a set of experts, a set of events and the associated penalties. We associate each RMP con-straint Tr ( A respond to elements of C . The penalty for expert i corre-sponding to the i -th constraint and event X is then given by Tr ( A fied constraint, we penalize it. This strategy is motivated by the work of (Plotkin et al., 1991; Arora et al., 2005a) and is similar to boosting, where a distribution is skewed towards an example for which the current hypothesis made an incorrect prediction.
 We assign weight w t and initialize the weights w 1 ation we query the oracle O with ( A t , b t ) = P to obtain a solution X t +1  X  X  . We then use the Multi-plicative Weights Update algorithm as described in func-tion MultUpdate of Algorithm 1 to compute the weights w multiplicative update based algorithm for RMP . In the fol-lowing theorem we prove approximation guarantees for the solution output by Algorithm 1.
 Theorem 4.1. Given the existence of an oracle O to solve the problem (4) , Algorithm 1 outputs an ( O (  X  2 D 2 log n approximate solution to RMP .
 Proof. Observe that, if the oracle declares infeasibility at Hence, we assume that the oracle returns a feasible point X t at time-step t , for all 1  X  t  X  T .
 Now, | Tr ( A the penalties Tr ( A Since Algorithm 1 uses multiplicative updates to update the weights 2 as in Theorem 2.1, for T = 16( X  D ) 2 log n/ X  2 , we have where p t LHS  X  0 . Thus, for X = P t X t /T we have We now bound the rank of X compared to the optimal value. Let t be such that X among X convex combination of ( A (5) we have that X  X  F (( A solution to RMP .
 The running time of Algorithm 1 is O (  X  2 D 2 log n mn 2 )) , where T O denotes the oracle X  X  running time. 4.2. Rank Minimization via OCP convex programming described in Section 2.2 to obtain an approximate solution to RMP . The intuition behind this approach is similar to that of Section 4.1; in fact this ap-proach can be viewed as a generalization of the approach of Section 4.1.
 In the OCP framework one generally associates the convex set K with a feasible region and the cost functions with penalty functions. In our application of OCP to RMP we Algorithm 2 RMP-OCP ( Online Convex Programming) Require: Constraints ( A Require: Oracle O ( A, b ) which solves 2: Set K = { P 3: repeat 4: if Oracle O ( A t , b t ) declares infeasibility then 5: return Problem is infeasible 6: else 7: Obtain X t using Oracle O ( A t , b t ) 8: Define function f t ( A, b ) = Tr ( AX t )  X  b 10: end if 11: Set t = t + 1 12: until t &gt; T 13: return X = P function z t +1 =GIGA( z t , f t ( z ) , K, t ) 1: Set  X  t =  X  2: Set z t +1 =  X  K z t  X   X  t  X  f t ( z t ) , where  X  K repre-flip this view and choose K to be the space of convex com-with feasible points of RMP . In particular, we set K  X  i.e., Given a matrix X , we define a cost function f by f We initialize A 1 = P ( A t , b t )  X  K for the t -th iteration, we query the oracle O with ( A, b ) = ( A t , b t ) to obtain a solution X We then set the cost function f t ( A, b ) = f Tr ( AX t )  X  b and use the OCP algorithm (Zinkevich, 2003) as described in function GIGA of Algorithm 2 to com-2 describes our OCP based algorithm for RMP . In the fol-lowing theorem we prove approximation guarantees for the output of Algorithm 2.
 Theorem 4.2. Given the existence of an oracle O to solve the problem (4) , Algorithm 2 outputs an ( O (  X  2 D 2 approximate solution to RMP .
 Proof. As in Theorem 4.1 we assume that the oracle re-turns a feasible point at all time steps. Note that using the terminology of Theorem 2.2, G = max f ( z ) k X  D and k K k X   X  . Thus, using Theorem 2.2 we have X Note that the above LHS  X  0 since oracle returns a feasible X t ,  X  t . Thus, for T =  X  2 D 2 / X  2 and X = P for all ( A, b )  X  K . In particular, we have for every Tr ( A i X )  X  b i  X   X  . We now bound the rank of X compared to the optimal value. Let t be such that X rank, say k, among X k , and so we have rank ( X )  X  kT  X  O (( X  D ) 2 k  X  / X  2 Also, from (6) we have that X  X  F (( A  X  1 , C ) . Thus by Definition 3.1, X is a ( O (( X  2 D 2 ) / X  approximate solution to RMP .
 The running time of Algorithm 2 is O (  X  2 D 2 mn 2 )) , where T O denotes the running time of the oracle, and T GIGA algorithm of Theorem 2.2. 4.3. Discussion Oracle : The oracle for solving problem (4) plays a crucial role in both our approaches. As discussed previously, for typical cases of C , like the unit ball under an L nius norm etc., (4) can be solved by the singular value de-composition of A . Further, in the case when the set C in-volves a quadratic or ellipsoid constraint we can use the S -procedure (Rockafellar, 1970) to solve (4).
 Comparison of the approaches : Our approach to RMP based on Multiplicative Weights Update has a slightly weaker guarantee than the approach based on OCP. This is also confirmed by our experiments where OCP gives better results than the MW approach. However, the MW approach is computationally less intensive as the approach based on OCP involves a projection onto the convex set K . Thus, MW can be used for large scale problems.
 Limitations : A drawback of our methods is the depen-dence on  X  ,  X  in the bounds of Theorems 4.1 and 4.2. This limits the applicability of our methods to problems, such as NNMA, with a large number of non-negativity constraints rithms can be used as a heuristic for such problems and can be used to initialize other methods which require a good low-rank solution for initialization. Also, the lower boun ds for the experts framework and boosting suggest that the de-pendence on  X  ,  X  in our bounds may be optimal for the general RMP problem (Arora et al., 2005b). In this section we apply both our rank minimization algo-rithms to the problem of low-rank kernel learning, which involves finding a low-rank positive semi-definite (p.s.d.) from labeled data. Due to the rank constraint, this problem is non-convex and is in general hard to solve. As described below, both our online learning approaches can be applied naturally to this problem. We provide provable guarantees on the rank of the obtained kernel.
 Formally, the low-rank kernel learning problem can be cast as the following optimization problem: where S is a set of pairs of points from the same class that are constrained to have distance less than  X  . Similarly, a set of pairs of points from different classes that are con-strained to have distance greater than u , with  X   X  u . For a similarity constraint matrix S The dissimilarity constraint matrices D similarly. Assuming k K as: where  X  is a function of r and can be computed using bi-nary search. Note that (8) is a special case of RMP with the convex set C being the intersection of the p.s.d. cone and the unit Frobenius ball. Hence, we can use RMP-MW and RMP-OCP to solve (8). Given ( A, b ) the oracle for both the methods solves: min and let  X  be a diagonal matrix with just the positive entries of
 X  . Then the minimum k s.t. q P k i =1  X ( i, i ) 2  X  b is the solution to (9). This follows from elementary linear algebra. Note that for the oracle solving (9), T Now, D = 1 and  X  = O (1 + l 2 + u 2 ) as k S k D j k F = 2 . Using Theorem 4.1, the RMP-MW algo-rithm obtains a solution with rank r  X  O ( 1+ u 2 + l 2 where r  X  is the optimal rank. Similarly, RMP-OCP ob-tion 6.2, we present empirical results for RMP-MW and RMP-OCP algorithms on some standard UCI datasets. We empirically evaluate and compare our algorithms to ex-isting methods for general RMP as well as low-rank ker-nel learning. For general RMP , we use synthetic examples to compare our methods against the trace-norm heuristic (Recht et al., 2007) and the log-det heuristic (Fazel et al., 2001). The trace-norm heuristic relaxes the rank objective to the trace-norm of the matrix, which is given by the sum of its singular values. Note that the trace-norm of a matrix is a convex function. The log-det heuristic relaxes the rank objective to the log of the determinant of the matrix. For the application of RMP to low-rank kernel learning, we use standard UCI datasets. All the presented results represent the average over 20 runs. 6.1. Synthetic Datasets First we use synthetic datasets by generating random ma-trices A matrices. We also generate a random positive semi-definite matrix X X The convex set C is fixed to be the intersection of the p.s.d cone and the unit ball under the Frobenius norm. We fix the number of constraints to be 200 and the tolerance  X  for RMP -MW and RMP -OCP to be 5% . We use SeDuMi to implement the trace-norm and log-det heuristics. In Table 1, we compare the ranks of the solutions obtained by our algorithms against the ones obtained by the trace-norm and log-det heuristics. For small n , both trace-norm and log-det heuristic perform better than RMP -MW and RMP -OCP . Note that since the constraint matrices stricted isometry property used in the analysis of (Recht et al., 2007). However, RMP -OCP outperforms trace-norm heuristic for large n (Table 1, n = 100 ) and RMP -MW performs comparably. We attribute this phenomenon to the Frobenius norm constraint for which the theoretical guar-both trace-norm and log-det heuristic scale poorly with the problem size and fail to obtain a result in reasonable time even for moderately large n . In contrast, both our algo-rithms scale well with n , with RMP -MW in particular able to solve problems of sizes up to n = 5000 . 6.2. Low-rank Kernel Learning We evaluate the performance of our methods applied to the problem of low-rank kernel learning, as described in Sec-tion 5, for k -NN classification on standard UCI datasets. We use two-fold cross validation with k = 5 . The lower and upper bounds for the similarity and dissimilarity con-Dataset \ Method GK MW OCP BK of the observed distribution of distances between pairs of points. We randomly select a set of 40 c 2 pairs of points for constraints, where c is the number of classes in the dataset. We run both RMP -MW and RMP -OCP for T = 50 itera-tions. Empirically our algorithms significantly outperfor m the theoretical rank guarantees of Theorems (4.1) and (4.2) . Table 2 shows the accuracies achieved by the baseline Gaussian kernel (with  X  = 0 . 1 ), RMP -MW , RMP -OCP and the Burg divergence (also called as LogDet diver-gence) based low-rank kernel learning algorithm (BurgK-ernel) of (Kulis et al., 2006). It can be seen from the ta-ble that both RMP -MW and RMP -OCP obtain a signifi-cantly lower rank kernel than the baseline Gaussian kernel. Further, RMP -MW and RMP -OCP achieve a substantially higher accuracy than the Gaussian kernel. Our algorithms also achieve a substantial improvement in accuracy over the BurgKernel method. Note that we iterate our algorithms for fewer iterations compared to the ones suggested by the theoretical bounds, hence few of the constraints maybe un-maybe noisy constraints and have small effect on the gen-eralization error. We leave further investigation into gen er-alization error of our methods as a topic for future research . Note that the BurgKernel method needs to be initialized with a low-rank kernel. Typically, a few top eigenvectors of the baseline kernel are used for this initialization. Howev er, initial kernel, especially if the rank of the initial kernel is high. This can further lead to poor accuracy for the BurgK-ernel method, as indicated by our experiments. Instead, the kernels obtained by our algorithms could be used to initial-ize the BurgKernel algorithm. For example, for the case of the Heart dataset, initialization of BurgKernel algorit hm with the low-rank solution obtained by RMP -OCP method achieves an accuracy of 94 . 29 compared to 83 . 91 achieved when initialized with the top eigenvectors of the baseline Gaussian kernel. Note that this also improves upon the ac-curacy achieved by RMP -MW and RMP -OCP . In this paper, we address the general problem of rank min-imization over polyhedral sets and in particular the prob-lem of low-rank kernel learning. We show that the prob-lem is hard to approximate within a factor of 2 log 1  X   X  Theorem 3.1). Further, we introduce a relaxed notion of approximation and present two novel approaches for solv-ing RMP with provable guarantees. Our first approach is based on the multiplicative weights update framework and provides an ( O (  X  2 D 2 second approach is based on online convex programming and provides a tighter bound of O (  X  2 D 2 the obtained matrix.
 For future work, it would be interesting to see if the hard-ness of approximation factor of Theorem 3.1 can be im-proved; we believe it can be improved to O ( X  2 ) . Another question of interest is whether the dependence on  X  in the bounds of Theorems 4.1 and 4.2 can be improved.
 The regret bounds of (Zinkevich, 2003) were improved in (Hazan et al., 2006). However, the algorithms of (Hazan et al., 2006) require stronger convexity properties which a re not satisfied in our application of OCP to RMP . It would be interesting to see if the linear constraints in RMP can be perturbed to satisfy the strong convexity properties, so th at the improved regret bounds of (Hazan et al., 2006) can be used to achieve better bounds for RMP .
 Our algorithms to RMP are motivated from an online learn-ing perspective. However, for an optimization problem such as RMP an understanding of the algorithms from an optimization perspective would be highly desirable. In par -ticular, intuitively there seems to be a correspondence be-tween our methods and a primal-dual approach but we were unable to obtain a rigorous connection. We believe that such an understanding would be of importance in obtaining new applications of the online learning approach to solving optimization problems.

