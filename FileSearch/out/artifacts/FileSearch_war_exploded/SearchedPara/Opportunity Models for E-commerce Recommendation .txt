 Most of existing e-commerce recommender systems aim to recommend the right product to a user, based on whether the user is likely to purchase or like a product. On the other hand, the effectiveness of recommendations also depends on the time of the recommendation. Let us take a user who just purchased a laptop as an example. She may purchase a replacement battery in 2 years (assuming that the laptop X  X  original battery often fails to work around that time) and purchase a new laptop in another 2 years. In this case, it is not a good idea to recommend a new laptop or a replacement battery right after the user purchased the new laptop. It could hurt the user X  X  satisfaction of the recommender system if she receives a potentially right product recommendation at the wrong time. We argue that a system should not only recommend the most relevant item, but also recommend at the right time.

This paper studies the new problem: how to recommend the right product at the right time? We adapt the propor-tional hazards modeling approach in survival analysis to the recommendation research field and propose a new opportu-nity model to explicitly incorporate time in an e-commerce recommender system. The new model estimates the joint probability of a user making a follow-up purchase of a par-ticular product at a particular time. This joint purchase probability can be leveraged by recommender systems in various scenarios, including the zero-query pull-based recom-mendation scenario (e.g. recommendation on an e-commerce web site) and a proactive push-based promotion scenario (e.g. email or text message based marketing). We evaluate the opportunity modeling approach with multiple metrics. Experimental results on a data collected by a real-world e-commerce website(shop.com) show that it can predict a user X  X  follow-up purchase behavior at a particular time with descent accuracy. In addition, the opportunity model signif-icantly improves the conversion rate in pull-based systems and the user satisfaction/utility in push-based systems. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Design, Experimentation Recommender System; Opportunity Model; E-commerce
As online shopping becomes popular, e-commerce recom-mendation is an increasingly important business tool for pro-moting sales. Researchers and industry practitioners are looking for all possible approaches to improve the recom-mendation performance. Even a minor improvement could lead to a big business return.

Traditional recommender systems focus on finding the right item to recommend. Major approaches include content-based methods, collaborative filtering methods and hybrid methods. For example, if a user viewed or purchased some camera(s) in the website, the system recommends more sim-ilar items (e.g. similar cameras) to the user. Recent re-search [19] proposed that recommender systems should rec-ommend items that maximize the users X  marginal utility, instead of only items that a user likes. As the marginal util-ity of a camera decreases immediately after a user purchased a camera, a system X  X  follow-up recommendation should in-clude camera accessories instead of similar cameras.
On the other hand, the user satisfaction/utility depends on both the relevance and the time of the recommendation. While an irrelevant recommendation results in a negative utility, the opportunity cost of recommending a relevant item at the wrong time could also be high, as we wasted the space while giving the user a negative impression. This is especially a problem for email or message based recom-mendations, as it wastes a user X  X  time and effort to receive product recommendation emails/messages that are full of products she does not need to purchase at the time. In the long term, the user may have negative impression about the company, unsubscribe from the marketing email list, label the emails as spams, or uninstall the message application.
To address these issues, recommender systems need to an-swer the following question: when is the right time for the system to make recommendations of the right product(s) ? For example, after a user purchased a camera, whether and when should the system recommend related accessories in-cluding camera lenses, batteries, digital photo frames, etc.?
Multiple heuristic approaches [18, 24] have been proposed to tackle this problem. In this paper, we propose a theoreti-cal model to learn the probability of a user making a follow-up purchase at a particular time. The model is inspired by the hazards model in survival analysis in statistics. The purchase time would be influenced by multiple factors, such as the user X  X  characteristics, the user X  X  purchase history, the product promotion information, the global environment and so on. Thus we propose to leverage the proportional haz-ards modeling approach which incorporates related factors as covariates(i.e., features). We further extend the model with the hierarchical Bayesian framework to handle the data sparsity issue. The new model is denoted as the Opportunity Model in this paper. It predicts the joint purchase proba-bility, i.e., the probability of a user purchasing a product at a particular time. It helps to promote a right item at the right time which further enhances the user satisfaction. Ex-perimental results are performed with a dataset from a real-world e-commerce website. Detailed analysis shows that the opportunity model could help to significantly improve the conversion rate and the user satisfaction.

The major contribution of this paper includes:
To provide recommendations to a user, recommendation systems usually predict a user X  X  ratings for each item or probability of purchasing, then rank all items in the de-scending order. There are two major recommendation ap-proaches: content-based filtering and collaborative filtering. Content-based filtering [12]assumes that descriptive features of an item indicate a user X  X  preferences. Thus a recom-mender system estimates the score of each item based on descriptive features of other items the user likes or dislikes. Usually, the system recommends items that are similar to what the user liked before. On the other hand, collabora-tive filtering [7, 18, 13, 5] assumes that users with similar
In the pull-based scenario, a user comes to the website and views some recommendation. In the push-based scenario, a system sends promotion emails or messages to the user. tastes on some items may also have similar preferences on other items. Thus the main idea is to use the behavior his-tory from other like-minded users to provide the current user with good recommendations. Research on collaborative fil-tering algorithms reached a peak due to the 1 million dollar Netflix movie recommendation competition. Factorization-based collaborative filtering approaches [3, 9, 19, 17], such as the regularized Singular Value Decomposition, performed well on this competition. A common characteristic of these models is the introduction of user latent factors and/or item latent factors to solve the data sparsity issue. In the field of recommender systems, the effect of time [10, 18, 24] has re-ceived some research attention recently. One focus is about the drift of the user X  X  preference over time [10, 23, 15]. Ko-ren [10] revamped two popular collaborative filtering meth-ods by modeling the time drifting factor of user preferences. Rendel et al. [15] proposed a factorized personalized model that subsumes both a common Markov chain and the normal matrix factorization model.

Recommendation in the e-commerce domain is a topic that has been studied in the IR community [8, 20]. Several methods have been tried in this domain, including neighborhood-based method, graph models [6], MDP-based methods [16], multi attribute utility theory based methods [11] and so on. In general, most of these existing methods, directly or indi-rectly, only estimate whether a user would like an item or purchase an item. Some recent work studied modeling the time interval between purchase orders in the e-commerce domain [18, 24]. Wang et al. [18] discovered different post-purchase behavior in different time windows after purchas-ing. Zhao et al. [24] used the purchasing time interval to im-prove the temporal diversity of recommendations [15]. The time interval and the corresponding purchase probability is modeled inside the framework of a utility-based recom-mender system [19]. The hybrid system takes the time in-terval into consideration when ranking all candidate items. Compared to the prior work about time, our work explicitly models the joint probability of purchasing the product at the time based on a solid theoretical foundation. We explicitly model the conditional probability as a white box by leverag-ing Weibull distribution with various covariates to estimate the time-based probabilistic density. These covariates enable us to capture various time-dependent patterns such as local changes, cyclic behavior, seasonable pattern, general trend of follow-up purchase behaviors, which are not captured by the prior work. Besides, the joint probability of product and time enables us to improve the recommendation accuracy.
To recommend the right product at the right time, we exam each candidate product for each user at a particular decision time. We propose to build an opportunity model to estimate the probability of a user purchasing the prod-uct at a particular time interval (i.e. ( y,y + X  t ]). That is the joint probability P ( p product, T  X  ( y,y + X  t ]), where T is the purchasing time. Let P ( p product ) represent the probability of the user purchasing the product, and P ( T ( y,y + X  t ] | p product ) represent the conditional probability of the user purchasing the product at a particular time pe-riod conditioned on that the user will purchase the product. Based on the chain rule, we have the joint probability: We propose to adapt hazards models in survival analysis to estimate P ( T  X  ( y,y + X  t ] | p product ), and adapt existing recommendation algorithms to estimate P ( p product ).
Survival analysis is a heavily studied topic in statistics, which is named as duration modeling in economics or reli-ability analysis in engineering. One major part of survival analysis is to estimate the time of an event, such as when a machine fails to work or when a patient fails to survive. In the e-commerce domain, we can view the task of conditional opportunity model as predicting the time of the follow-up purchase event of the product. Follow-up purchases may in-clude repurchases that happen regularly or new purchases that are triggered by the previous purchase. Given the sim-ilar nature of survival analysis and our e-task, we propose to use the hazards model in survival analysis to estimate p ( y | p product )inthispaper.
 Let us review basic hazards models in survival analysis. Let p ( y ) denote the density function of the time distribution of an event. Let y be a value of time and T be a random variable representing the event time. The cumulative distri-bution function is denoted as P ( y )= Pr ( T  X  y ) and sur-vival function is denoted as S ( y )= Pr ( T&gt;y )=1  X  P ( y ). stantaneous potential per unit time for the event to occur at time y given that the event has not occurred up to time y .

The survival analysis further extends the model with co-variates. Covariates are features that would affect the sur-vival time. For example, if a product is on promotion, it might shorten the time before a user waits to purchase it. The covariates could include different types of features, in-cluding time independent variables (user age, gender, house-hold income, product brand etc.), time dependent internal variables (time since last purchase of the same product, re-cent user search queries or clicks etc.) and time dependent external variables (global economy, seasonal index, day of the week, etc.). There are two common approaches to in-corporate covariates x (a vector of features) in a hazards model. The first approach is the Cox proportional hazards model [14]. It assumes that covariates are multiplicatively related to the hazards. The second approach is the Accel-erated life model [22]. It assumes that covariates are multi-plicatively related to the survival time. Research in statistics discovered that the Weibull distribution satisfies assump-tions in both directions. The density function of the basic Weibull distribution is shown in Equation 2 [21]. where  X  is sometimes called the shape parameter and held fixed. If  X  = 1, the Weibull model reduces to the exponential model and the hazard is constant. If  X &gt; 1, the hazard in-creases as time increases. If  X &lt; 1, the hazard decreases over time.  X  is the scale parameter and can be re-parameterized based on a regression parameter  X  and covariates x as fol-lows: Figure 1: Illustration of the relationship of variables. The user first makes a series of product purchases before timestamp t m . Then the user makes a pur-chase of item j m in category m at timestamp t m .This follow-up purchase in category m is the i th observa-tion in category m . Suppose that the purchase of j m is triggered by item j s at timestamp t s .Purchase time y m,i = t m  X  t s is the time gap between t m and t s An observation i is associated with two major vari-ables: 1) purchase time y m,i and 2) covariates x m , i (which is not shown in the figure). where exp {  X  T x } represents the new scale parameter  X  .This density function represents the basic proportional hazards model that models the event time with associated covari-ates. The corresponding hazards function is simply h ( y )=
Here we describe notations in the e-commerce domain in this paper. The relationship between different variables is shown in Figure 1.
In this paper we propose to adapt the Cox proportional hazards model to the e-commerce domain and use it to esti-mate P ( T  X  ( y,y + X  t ] | p product ). To do that, we learn the conditional opportunity model p ( y | p product ), which is the density function/model of the purchasing time. We can ei-ther learn one model per product or one model per product category. Without loss of generality, we describe the model by assuming one model per category in this paper.
In the real world, a small number of categories are of-ten purchased while most categories have few purchases. To solve the data sparsity issue, we follow a common practice and extend the conditional opportunity model with a hier-archical Bayesian framework as illustrated in Figure 2. This framework helps the category with few observations by bor-rowing information from other categories through a common prior for parameters of all proportional hazards models.
For each category m ,  X  m is sampled from a Gaussian dis-tribution:  X  m  X  N (  X   X  ,  X   X  )and  X  m is sampled from the Gamma distribution:  X  m  X  Gamma ( a  X  ,b  X  ). We denote  X  =(  X   X  ,  X   X  , a  X  , b  X  ). For each i th observation in category m with its observed covariates x m , i , its purchase time y is sampled from the conditional opportunity model Consider that data D consists of a series of observations from all categories. Purchase times in the observations are gen-erated by using a set of hidden variables  X  = {  X  1 , X  2 ...,  X  (  X  m = {  X  m , X  m } ). The likelihood can be written as a func-tion of  X  =(  X   X  ,  X   X  , a  X  , b  X  ). We use y m to represent ..., y m,i , ..., y m,N m } , i.e., observation times in category m . Figure 2: Illustration of dependencies of variables in the hierarchical conditional opportunity model. It shows the i th observation of category m . y m,i is the purchase time which is dependent on the condi-tional opportunity model  X  m = {  X  m , X  m } of category m , as wells the observed covariates x m , i of this pur-chase. Each category m has its own parameters of the conditional opportunity model  X  m , X  m .Modelsof each category share information through the prior,  X  =(  X   X  ,  X   X  , a  X  , b  X  ) .
There is no closed-form solution for the estimation of the model parameters. We follow the variational Bayesian method[1] for constrained (approximate) optimization to de-rive an iterative process to find the approximate solution. Maximizing the likelihood in Equation 5 is equivalent to maximizing the log likelihood L (  X  ).
 L (  X  )=ln p ( D |  X  )= We can simplify the problem by introducing an auxiliary distribution q (  X  m ) for each hidden variable  X  m [1]. In the variational approach, we constrain q (  X  m ) to be a particu-lar tractable form for computational efficiency. In partic-ular, we assume that q (  X  m )= N (  X   X  m ,  X   X  m )and q (  X  Gamma ( a  X  m ,b  X  m ). The process to infer parameters is to iterate between the following E-step and M-step until con-vergence.
In the E-step , we infer the posterior distributions over hidden variables  X  m given the current parameter setting  X  . There is no closed-form solution. Instead, we find a tractable approximation of the posterior distribution of  X  m given  X  (i.e, q (  X  m ) that maximizes L (  X  )).
To maximize L (  X  ), it is the same as minimize the following equation to find each distribution q (  X  m ):
The first part in Equation 8 is the KL-divergence between the posterior distribution q (  X  m ) and the prior distribution p (  X  m |  X  ).
 The KL-divergence between two Gaussian distributions is The KL-divergence between two gamma distributions is where  X (  X  ) is the digamma function.

The second part in Equation 8 is to maximize the data likelihood of y m = { y m, 1 , ..., y m,i , ..., y m,N m } rent  X  m = {  X  m , X  m } .
 The expectations in the above equation are
We can combine the above derivations with Equation 8, then find q (  X  m ) using the conjugate gradient descent method. In the M-step , the goal is to maximize F ( q (  X  1 ) , ..., q (  X  in Equation 6 with respect to  X  given all  X  m .Itissameas to maximize the following quantity: The optimal  X  at this step can be estimated with the fol-lowing closed form: where  X   X  1 (  X  ) is the inverse digamma function.
At a time y , we can decide whether to recommendation a particular product in category m to a particular user or not based on the following estimation: whether a user is likely to purchase the product in the near future (i.e. between time y and time y + X  t ), given that the user has not purchased the product since a triggering time point. To do so, we need to estimate P ( p product = yes, T  X  ( y,y + X  t ]) = P ( p product = yes ) P ( y&lt;T  X  y + X  t | T&gt;y,p product = yes ), where where: The approximation is used because there is no closed-form solution of the integration for calculating the expectation.
To estimate P ( p product = yes ), i.e., the probability of the user purchasing the product, we can use any existing recommender systems through the logistic regression model: where x is a vector of features that are associated with the purchasing, which includes the score/output of the existing recommender system(such as SVD), as well as other features that might help to predict the user X  X  purchase probability. f is a vector of coefficients that can be learnt by maximizing the likelihood of the training data.
The purchase time y m is determined by the purchase times-tamp of product j m and that of the triggering product j s The triggering product is not necessarily the product in the most recent purchase. There are multiple heuristic ap-proaches to find the triggering item j s in the user X  X  pur-chase history. Here we leverage the transition probability P ( j s ,j m ) in Equation 13.
 where # ( j a ,j b ) is the number of follow-up purchases of j that happened after j a . #( j a ,  X  )isthenumberoffollow-up purchases after j a . J is the number of products and  X  is the smoothing factor, which is set as 0 . 1.

We first rank all items { j 1 , ..., j s , ..., j m  X  1 } less than k t days before j m and have P ( j s ,j m ) &gt;Thres Then we use the top one as the triggering item. Other ap-proaches can be explored in the future work. Although other not treated as the triggering item, they are incorporated into the opportunity model as covariates x m , i .

In this paper, we use the following covariates for each purchase of product j m made by user u at timestamp t m : whether user u purchased any product in category m in time bin t b 1 , ..., t bk ; how many times the user u purchased any product in category m in time bin t b 1 , ..., t bk ; whether the user purchased the product j m in time bin t b 1 , ..., t many times the user u purchased the product j m in time bin t , ..., t bk ; which season t m is in, whether t m is in the holiday season, etc. Time bins t b 1 , ..., t bk are set as one day, one week, one month, two months, three months, six months, one year, etc. We choose these covariates to show the effect of incorporating covariates in the conditional opportunity model. These covariates capture the change of the time distribution with the user X  X  purchase history, the seasonal change, the cyclic pattern, etc. All covariates are normalized in the scale of [0 , 1].
As we are studying a new problem of recommending the right product at the right time, there is no standard evalu-ation methodology. We design various experiments to eval-uate the performance of the opportunity model. Major re-search questions that we aim to answer are: Predictability of the conditional opportunity model Predictability of the opportunity model Is the joint pur-
It is a relatively new research topic to predict the purchase time and evaluate the performance of such model. We intro-duce the following two metrics to evaluate the performance of the conditional opportunity model.

The first metric is the perplexity of the model. It is mo-tivated by the perplexity metric used to evaluate language models and speech recognition [2]. The perplexity measures how well a model predicts the testing data. It is defined as follows: perplexity = where P ( T  X  ( y,y + X  t ] | p product ) is defined in Equation 11, and i is the index for a testing data point. A better model tend to give a higher data likelihood to the actual follow-up purchase time in the testing data, thus they have lower perplexity , which means they are less surprised by the test-ing data.

The second metric focuses on the difference between the estimated time y m,i and the actual time  X  y m,i . After a model predicts the distribution p ( y m,i | p purchase ) of the purchase time, we use the median of the distribution as the esti-mated purchase time  X  y m,i . The median of the distribu-ing data can then be used to analyze and compare. The smaller the error, the better the model. Here we use three types of errors: mean absolute error(MAE), mean squared error(MSE) and mean absolute percentage error(MAPE =
In our experiments, we compare the following four condi-tional opportunity models.
 Uniform assigns a uniform distribution to all time. p ( y O-One is a conditional opportunity model that fits a sin-O-Dest is a hierarchical conditional opportunity model that O-DestCov further incorporates covariates into O-Dest .In All models smooth the conditional probability estimation P ( T  X  ( y,y + X  t ] | p product )=max( P (minThres ,T  X  ( y, Table 1: The utility set of the recommender sys-tem. There are four types of utilities, depending on whether the system recommends the item to the user and whether the user purchases the item. y + X  t ] | p product )) to avoid having a probability that is too low (such as when there is no triggering item before the purchase). minThres is set as 0 . 001.  X  t in Equation 11 is set as 7 (i.e., 7 days) for all models during the prediction step. The threshold for the transition probability to consider the an item j s as the triggering item is set as 0 . 01.
Here we evaluate the predictability of the opportunity model with the joint purchase probability in two scenarios. 1) [Zero-query pull-based scenario] assumes the user comes to the site to look for products to purchase without issuing any search query. In this scenario, the goal is to dis-cover products that the user would purchase and recommend them to the user proactively. The system ranks all products by their joint purchase probability and recommends top K products to the user.

The evaluation metric in this scenario is the conversion rate which reflects whether a user receives at least one good recommendation. Each testing time corresponds to the time when a user comes to the site and makes purchases. Let S purchased contain all unique products in the order. Let C purchased contain all unique categories in the order. Let S
K,recommended contain top K unique product recommen-dations. Let C K,recommended top K unique category recom-mendations. CR product is the conversion rate at the product level and CR category is the conversion rate at the category level. Significance level of 0.05 with the paired two-tailed t-test is used to compare two models.
 2) [Push-based email promotion scenario] assumes that recommender systems send email/message proactively to a user regularly regardless of whether the user comes to the site or not.

The evaluation metric in this scenario is the average util-ity/user satisfaction. The utility for each type of recommen-dations is shown in Table 1. The utility g for each email of recommendations is calculated by Equation 15. I is the indicator function where I  X  =1if  X  is true. Unlike traditional metrics such as conversion rate@K, the utility metric considers both the positive effect for good recommen-dations and the negative effect for bad recommendations. The higher the utility, the better the model.

To achieve a better utility, the system with a filtering component should send emails only if the expected utility of adding the product is higher than zero (i.e. the joint probability is higher than the threshold). The recommenda-tion threshold is automatically determined by the following
We don X  X  have a real push-based email promotion system for a user study. Instead, we create an evaluation dataset with the purchase data from a pull-based e-commerce web-site. The goal is to evaluate each model X  X  predictability of discovering the X  X eal opportunity X  X nd avoiding the X  X ake op-portunity X  X n the email marketing. For each purchase at time t in the testing dataset, we let each model consider two op-portunities: sending a recommendation email the weekend right before t and sending an email on some other random weekend before t . Since existing models can not tell whether to send an email or not, they always send an email with top K recommendations for each opportunity. The opportunity model with a filtering component will add a product to the email if the expected utility of adding the product is higher than zero. If no product is added to the email, the opportu-nity model would skip this opportunity and do not send an email. Recommendations in the email are compared with actual products that the user purchases in the week after the email is sent. Assume that there are G opportunities to send recommendation emails in the testing period. The average utility/user satisfaction utility can be calculated as
We choose the following recommendation models to com-pare: TopPop recommends most popular products to the user. SVD is a widely-used recommendation algorithm with a SVD.util is the state-of-art recommendation algorithm in Regression.Model is an alternative new approach to pre-Conditional.Opportunity.Model recommends products Opportunity.Model recommends products based on the Opportunity.Model.Filtering adds a filtering component
The purchase history from 2004-01-01 to 2009-03-08 col-lected on a real-world e-commerce website, shop.com, is used for our experiments. We use all purchases that have category information of the product. Tail users that made less than 5 product purchases are filtered out in the training data, which follows the similar pre-processing in related work [19, 24]. In addition, 10 possible spam users that made more than 200 product purchases are filtered out as well. The remaining data contains 11,351 users and 67,291 products. There are 105,550 unique (user, product) pairs. This user-product matrix is quite sparse, with only 0.014% density. There are 380 categories in total.

To evaluate the conditional opportunity model as in Sec-tion 4.1, 10-fold cross validation is used. To evaluate the opportunity model with the joint purchase probability as in Section 4.2, we sort all purchase history by time. The first 90% is used as the training data (data before 2008-11-24) and the last 10% is used as the testing data (data after 2008-11-24). There are 7,014 testing cases in total. At the product level, there are 1,143 repurchase cases(16.29%) and 6,269 new purchase cases(89.37%). At the categorical level, there are 2,850 repurchase cases(i.e. 40.63% cases with purchase from the same category) and 4,850 new purchase cases(i.e. 69.14% cases with purchase from a new category).
To train the regression model with SVD as one of the fea-tures, the first half training data is used to train the SVD model and the second half training data is used to learn coef-ficients in the regression model. The number of latent factors for all SVD-related models is set to 50. In the recommenda-tion step, all models recommend top K (K=5) products to the user. To save the computation time, Regression.Model , Conditional.Opportunity.Model and Opportunity.Model ra-nk among top N recommendations from SVD and selects top K to recommend, where N = 100 and K =5.

The time density plots of some common transitions from products in the Baby | Feeding category to the target item j m are shown in Figure 3. This supports our motivation of identifying triggering items in the user history. For exam-ple, users who purchased from Baby | Feeding would purchase items in other Baby related categories in the future. The purchase time of the follow-up purchase does follow differ-ent distributions for different products or different covariates (take the triggering product as a covariate). For example, users who purchased from the Baby | Feeding category would purchase products from this category again in one month. Later on when the baby grows up, they would purchase prod-ucts from Toys | Board, Card&amp;Dice Games . The perplexity of all conditional opportunity models in Section 4.1.2 are compared in Table 2. All conditional op-portunity models have lower perplexity than the baseline model Uniform . This demonstrates that conditional oppor-tunity models have better predictability of the time-based purchase probability in the data. Among all conditional op-Figure 3: Density plot of the purchase time between different follow-up purchases from Baby | Feeding Table 2: Perplexity of different conditional oppor-tunity models in 10-fold cross validation.
 portunity models, O-DestCov achieves the lowest perplexity, followed by O-Dest ,and O-One . O-DestCov incorporates related covariates in addition to fitting parameters of a con-ditional opportunity model for each category m .Itshows the importance of considering covariates when modeling the purchase time of a follow-up purchase.

To further analyze the effect of covariates, we compare the perplexity of all models in the repurchase data and the new purchase data in Table 2. As expected, the major gain is in reducing the perplexity of repurchases. More feature exploration would be useful to improve the prediction of new purchases in the future.

Now we compare the estimated purchase time with the ac-tual time of a follow-up purchase in Table 3. All conditional opportunity models perform better than the baseline model Uniform . O-DestCov gives the most accurate estimation of the purchase time, followed by O-Dest ,and O-One . Accord-ing to MAE, the estimated purchase time from O-DestCov Table 3: Error between the estimated purchase time and the actual purchase time. MAE stands for mean absolute error. MSE stands for mean squared error. MAPE stands for mean absolute percentage error.
 Table 4: Conversion rate of recommendation models in the zero-query pull-based scenario. Numbers in bold are significantly better than the corresponding value in baseline models.
 is 77 days away(higher or lower) from the actual time. It is a decent performance given that the total time range is 500 days. Further analysis shows that O-DestCov predicts more accurately in both the repurchase and the new pur-chase data.
Now we evaluate the performance of the opportunity model with the joint purchase probability. The conversion rate of different recommendation models in the zero-query pull-based scenario is compared in Table 4.

The opportunity model achieves higher conversion rate at both the product level and the category level. Further analysis shows that the contribution of the conditional op-portunity model is mainly at the category level. It is not surprising because the model is designed at the category level. Product-level models can be explored in the future. The key challenge is to solve the sparsity and scalability issues.

We further analyze the performance of the conversion rate in different purchase scenarios. In Table 4, we show the con-version rate of repurchases and new purchases. It is clear that the major contribution of the opportunity model is in the repurchase scenario. The observation is consistent with the evaluation of the conditional opportunity model in Sec-tion 5.1: the conditional opportunity model predicts more accurately in repurchases.
Now we evaluate all models in the push-based scenario. In the Opportunity.Model.Filtering model, a product is rec-ommended only if its joint purchase probability is higher than the threshold. We evaluate the model with three sets of utility at both the product level (i.e. true positive means that the user purchased the exact product) and the category level (i.e. a true positive means that the user purchased a product in same category as the recommendation). The re-sults are shown in Table 5. There are 3,014 email oppor-tunities in the testing period. 55% of them have follow-up Table 5: Average utility of email recommendations in the push-based scenario. Coverage is the percent-age of emails that are sent among all possible oppor-tunities. Rec count is the average number of unique recommendations in a email when the email is sent. purchases in the following week. Among those with follow-up purchases, the average number of purchases is 2.227.
In the first utility set, the utility u TP for a good recom-mendation that the user purchases is set to 3. When the sys-tem shows a product and the user does not purchase it, the utility u FP is  X  1. The resulting filtering threshold is 0.25. In this case, Opportunity.Model.Filtering has a better utility than other models by filtering out many false alarms. The average utility at the category level is higher, which is ex-pected. It rewards a recommendation if it matches the user X  X  purchase at the category level, which is an easier task. In general, the model with higher conversion rate in the pull-based scenario has high utility in the push-based scenario.
In the second utility set, the utility u TP is set to 10, indi-cating that the user is more tolerant to bad recommenda-tions. Thus the threshold is lower, being 0.09. The coverage of Opportunity.Model.Filtering increases while the aver-age utility drops. There is a tradeoff between the utility and the recommendation coverage, which can be tuned in a real-world application by a user or the system designer.
In the third utility set, u FN is set to  X  1. It is the penalty for not recommending a product that would be purchased by the user in the following week. Thus the coverage of Opportunity.Model.Filtering is higher to avoid missing good recommendations with the threshold being 0.02. It still achieves the highest utility among all models.
In this paper, we propose to develop the opportunity model to predict the probability of a user purchasing a product at a particular time. This is achieved by modeling the joint probability of time and product, which can be calculated by combining a proportional hazards model and a logistic regression model. The joint probability guides the system to make the right product recommendation at the right time.
This is just the first step to tackle the research problem of capturing the time-based recommendation opportunity. Besides Weibull distribution, other distributions such as Ex-ponential, Log-logistic, Lognormal, Generalized gamma, can be explored. Further improvements could be achieved with better covariates. More systematic approaches of discover-ing the triggering item could be explored. It would be helpful to carry out experiments with a real push-based system to evaluate the effectiveness of the opportunity model in a real user study. Due to the limited number of research data avail-able and our own computational limits, we only learn the category-level conditional opportunity model, which clearly work well at the category level prediction. Another follow-up work is to evaluate this approach on a large-scale system to learn the product-level models, which might lead to better prediction at the product level.
 We would like to thank shop.com for sharing the data. This work was funded by National Science Foundation IIS-0713111 and IIS-0953908. Any opinions, findings, conclusions or rec-ommendations expressed in this paper are the authors, and do not necessarily reflect those of the sponsors. [1] M. Beal. Variational algorithms for approximate [2] S. Chen, D. Beeferman, and R. Rosenfeld. Evaluation [3] P. Cremonesi, Y. Koren, and R. Turrin. Performance [4] C. Elkan. The foundations of cost-sensitive learning. [5] N. Golbandi, Y. Koren, and R. Lempel. Adaptive [6] Z. Huang, W. Chung, and H. Chen. A graph model for [7] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative [8] Y. S. Kim, B.-J. Yum, J. Song, and S. M. Kim. [9] Y. Koren. Factorization meets the neighborhood: a [10] Y. Koren. Collaborative filtering with temporal [11] S. li Huang. Designing utility-based recommender [12] R. J. Mooney and L. Roy. Content-based book [13] D. Parra-Santander and P. Brusilovsky. Improving [14] C. D. R. Regression models and life tables. Journal of [15] S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. [16] G. Shani, D. Heckerman, and R. I. Brafman. An [17] E. Shmueli, A. Kagian, Y. Koren, and R. Lempel. [18] J. Wang, B. Sarwar, and N. Sundaresan. Utilizing [19] J. Wang and Y. Zhang. Utilizing marginal net utility [20] J. Wang, Y. Zhang, and T. Chen. Unified [21] J. Wang, Y. Zhang, C. Posse, and A. Bhasin. Is it [22] L. J. Wei. The accelerated failure time model: A [23] L. Xiang, Q. Yuan, S. Zhao, L. Chen, X. Zhang, [24] G. Zhao, M. L. Lee, W. Hsu, and W. Chen. Increasing
