 Traditional web search engines find it challenging to achieve good search quality for recency-sensitive queries, as they are prone to delays in discovering, indexing and ranking new web pages. In this paper we introduce PreGen, an adaptive preview generation sys-tem, which is run as part of a web search engine to improve search result quality for recency-sensitive queries. PreGen uses a machine learning algorithm to classify and select live web feeds, and gener-ates X  X reviews X  of new web pages based on the link descriptions available in these feeds. The search engine can then index and present relevant page previews as part of its search results before the pages are fetched from the web, thereby reducing end-to-end delays. Our experiments show that PreGen improves the search relevance of a state-of-the-art search engine for recency-sensitive queries by 3% and reduces the average latencies of affected docu-ments by 50%.
 H.1 [ Models and Principles ]: General; D.2.8 [ Software Engi-neering ]: Metrics X  performance measures Algorithms, Design, Measurement The recent success of social networking sites such as Twitter and Facebook has spawned a new interest in real-time search (RTS). Social networking sites provide a steady stream of user updates in real time. RTS primarily involves presenting these updates for time-sensitive user queries such as  X  X aiti earthquake X  and  X  X P web sites and can never be fetched. With the help of abstracts and meta-data from RSS feeds, links from these feeds are indexed be-fore they are actually fetched by creating synthetic bodies from the abstracts and meta-data, which we call  X  X reviews X . This way the latency is reduced and the comprehensiveness of recency-sensitive information in the search engine index database is increased.
Finally, the presence of structured meta-data in the index also en-ables rich presentation of web search results. For example, authors and publish time of blog entries is shown to the end users in a clear and structured way for better user experience.

In this paper we present PreGen, a system that generates pre-views from RSS feeds. PreGen is run as a part of the search engine, which takes the content of a high-quality feed from crawler as input and creates previews for each and every link from the feed. These previews are then used to improve the search engine X  X  coverage, freshness, relevance and presentation. Figure 1 illustrates how the generated previews are consumed and displayed in search engine for a recency sensitive query.

Using RSS feeds to improve the performance and quality of a search engine is not trivial. We have estimated the number of feeds present in the web to be in the order of billions and not all of them can be fetched and refreshed frequently due to crawler capacity constraints. Apart from magnitude, the quality of the feeds used for preview extraction is also a concern. For example, it has been shown that RSS feeds are often used for spamming and in some cases for search engine optimization [19], to artificially increase the rank of a page. Hence, we need a good selection algorithm that will only choose high-quality feeds. This algorithm should be able to predict the quality of an unknown RSS feed, filter out low-quality feeds, and promote feeds t hat are updated frequently and that contain relevant and descriptive content.

One simple way to select a feed with high quality is based on the goodness of its host or of its URL. However, this does not guaran-tee the feed to be a source of good previews. For example, page edit feeds from Wikip edia have a good host quality and are large in number, but they are practically useless for previews. Hence, rank-ing by host quality does not yield the desired preview source or-dering. Page authority algorithms such as PageRank [3] also do not yield the correct ordering of preview sources. For instance, feeds of blogs and news pages are generally ranked low by these authority algorithms as they are not referred (linked) as much as their corre-sponding pages. Hence, we need a better algorithm to determine the quality of feeds. Under the guarantee of this algorithm, pre-views extracted from high-quality feeds will be trustworthy and a search engine can consume and display these previews in search results as a substitute for pages waiting to be crawled.
PreGen uses a machine learning (ML) based feed selection method to select feeds based on their quality . The notion of feed quality is defined later in detail, but in general the definition is based on feed use case, i.e. to extract previews. We built a Gradient Boosted Decision Tree (GBDT) [7] model for predicting the quality of the feed. This model is then used to select high-quality feeds. To the best of our knowledge, we do not know any existing work for feed selection method. Hence, we compared our ML-based feed selec-tion with PageRank-based selection and editor picked feeds. The ML-based selection method performed on par with editorial selec-tion, and outperformed the PageRank-based selection by 10% with respect to our evaluation metric, the click probability of the gen-erated articles. The ML-based selection also generated more arti-cles in the same period than editor picked feeds or PageRank-based feeds.

PreGen adds several advantages over a state-of-the-art search en-gine : and search history [18]. There has also been work to enrich the search results using non-regular web pages. Blogs have been com-monly used in web search to increase the relevance. For example, Mishne [12] uses blog properties such as timestamps, number of comments and query-specific terms to improve ranking.

There has been some research involving the use of feed selection algorithms for various purposes. NectaRSS [17] and Cobra [15] se-lect web feeds based on the user X  X  past choices and preferences in the context of news readers. Elsas et al. [5] present probabilistic re-trieval and feedback models for search and recommendation of blog feeds. RSSMicro uses a feed ranki ng algorithm for its feed search engine. It provides a free FeedRank calculation tool [16] that dis-plays the rank of a web feed based on its quality measure and can successfully distinguish spam f eeds from high-quality ones. How-ever, there has been very little published wor k on using RSS feeds directly to improve the traditional web search results quality.
Our work comes close to that of Macdonald and Ounis [11], which ranks blogs based on individual rankings of their posts (sim-ilar to the ranking of feeds in this work) and experiments with in-dexing the XML feeds instead of the actual blog posts. However, the reason the authors do this is to reduce crawler and indexer load and not to improve recency or relevance of the search results.
In this section, we define feed quality and model the feed selec-tion problem as a machine learning problem. The developed ML models are used to classify and select feeds. These feeds are used to extract previews. The quality of previews depends on the quality of feeds, hence we need a good ML algorithm to predict the quality of feeds, which can be used for feed selection.

Feeds can be selected by using a heuristic method such as PageR-ank to order the feeds and select the top ones. Alternatively, feeds can be selected by an ML-based approach. Richardson et al. [14] have shown that a query-independent ML ranking algorithm can order web pages better than PageRank. Their work orders pages based on their usefulness in answering search queries. As feeds are not directly used for answering search queries, we do not use the same objective function. However, we follow a similar ML-based approach with a different objective function. We could model the feed selection problem as a ranking problem, but generating a preference order of feeds based on quality is difficult, as quality is query-independent and is subjective to the application. Hence, we chose to model the feed selection problem as a classification prob-lem, where an ML algorithm is trained to predict the quality class of a feed. The feeds are then selected from the highest quality class. If the number of feeds from that class are more than what is required, then a subset of the feeds with the highest class probabilities are selected.

The quality of a feed is characterized by the application that uses it. For example, if the application is an RSS reader, then a high-quality feed can be characterized by how comprehensively it cov-ers trustworthy and personally relevant information to the user. Past work [17] has addressed the feed ranking problem for RSS readers using this definition of quality. However, in our case, feeds are used as a preview source for search engine and the feed quality needs to be redefined to suit this application. We propose that the properties listed in Table 1 are desirable in a high-quality feed. These proper-ties are generic in nature and can be used for other applications as well.

The listed properties determine the labels for modeling our ML algorithm. In order to measure whether a feed exhibits one or more of these properties, we define two quantifiers, linked page quality (  X  ) and item quality (  X  ) which we use to formally define the quality classification problem is to find an underlying function R ( X ) such that Y = R ( X ) . In general, the function R ( X ) is learnt by mini-mizing a loss function L ( Y , R ( X )) such as squared loss or hinge loss. There are several methods in literature, such as Logistic Re-gression, Naive Bayes, SVM, Random Forest and decision trees, to find the fitting function.

An important point to note from Table 2 is that we cannot com-pare classes. For example, we cannot claim class B is better than class C or vice versa and this explains the reason why we cannot model the problem of identifying feed quality as a regression prob-lem or a ranking problem.

We use Gradient Boosted Decision Trees (GBDTs) [7] to train the model. A boosted tree is an aggregate of regression trees. Each regression tree partitions the space of explanatory variable values into disjoint regions D j , j = 1 , 2 ,... J associated with the terminal nodes of the tree. Each region is assigned with a value  X  j which is the output of the regression tree for any input x in that region. The complete tree is then where  X  is the set of all regions D j and their values  X  j and I is the indicator function.

A boosted tree is an aggregate of M regression tees, which is an additive model of the form: At each stage m , a new tree is added to the model iteratively. The parameters  X  m of this new tree are estimated by fitting the residuals of the loss from stage m  X  1.

Most of the classification algorithms, including GBDT, usually solve only binary classification, but we have four classes as shown in Table 2. Hence we use a  X  X ne-versus-all X  scheme to predict the class probabilities. For each feed, the highest probability decides the class of the feed. Depending on the application within PreGen (offline and online feed selection as described later in section 4), the selection function can choose the top feeds ordered by class probability or choose feeds based on a cla ss probability threshold. We used four quality classes for classification, instead of two (i.e. end that forwards search queries from the user to the searcher, con-verts the search results into the required format and shows them to the end-users.

As one of its inputs, PreGen receives a stream of RSS feeds that were just crawled from the crawler. It uses the ML model described in Section 3 to classify these feeds. Then, it generates previews of the items present in the qualifying feeds and sends these previews to the indexer. This way PreGen receives feeds from the crawler and applies the ML model to determi ne the quality of the input feeds dynamically. The quality of a feed as a score (class probability) is used for the online feed selection process. The online selection has access to only one feed at a time. Hence, the decision to select the feed is independent of other selections. Therefore, we fix a threshold based on capacity and select any feed that has a quality score greater than the threshold at any instant. If a selected feed falls below the quality threshold, it is no longer used for preview generation.

The feature sets used in the online ML models are limited in number and time-sensitive in nature, based on past crawl events of each page, such as page content features and linked page features, which change with every crawl event. Hence, we also complement the online feeds with offline-selected feeds . The offline feeds are generated by sending a large pool of known RSS feeds through a specialized ML model trained using offline features. The ML algo-rithm in this case can use sophisticated features such as PageRank, host quality and features from query logs, which may not be avail-able online. This offline selection effectively creates a set of feeds that are pre-selected as appropriate for time-sensitive queries. In Section 5 we explain the effect of using different feature sets in terms of misclassification rate. By applying a capacity limit, a set of top-ranked feeds from the pool can be chosen as offline feeds. PreGen takes this set of feeds as input, preemptively fetches them and creates previews from them.

The previews generated from PreGen are sent to the indexer and stored in the database along with the other regular documents. When a relevant preview is returned from the searcher to the search front-end, the latter can use the preview and its associated meta-data to enrich the search result presentation as shown in Figure 1.
Figure 4 shows the internal workings of the PreGen implemen-tation that we used in our experiments discussed later in Section 5. As the crawler fetches documents from the web, it sends only RSS documents through an additional pipeline of PreGen modules. The crawled feeds are streamed into a Feature Generator that creates or extracts a set of features from each feed. While some features such as word count and number of items can be obtained directly from the feed, others such as view count and click count have to be derived from the search engine X  X  query and click logs.

The generated feature sets are then sent to the Prediction Engine , which executes our ML-based model, and calculates a quality score (class A probability) for each feed. The Prediction Engine is a C++ implementation of GBDT model applier. It reads a model file which contains a series of regression decision trees that uses feed features as its input variable. The models are built during the training process using Treenet software. The modeling procedure is explained in Section 5.

The feeds and their scores computed by the Prediction Engine are then streamed into the Preview Extractor which produces pre-views of items only for qualifying feeds. The Preview Extractor may also receive feeds from a Doc Fetcher that regularly fetches RSS documents that were preselected offline. The role of the Pre-view Extractor is to parse an RSS feed and extract the links and 3. A bookmarking site (delicious). 4. A pool of feeds selected by human editors. 5. A random sample set of feeds from web.
 As some of the sources such as book marking sites tend to have high number of low quality feeds, a random sampling for train-ing would skew the distribution of training set towards low quality feeds. Hence, for these sources that have statistics which can be used as surrogates for quality, we used those statistics and gener-ated stratified feed samples for modeling. For example, the per-sonalization site has a statistic called user subscription count ,the number of users subscribing to a feed. This measure gives a simple way to order feeds from this source approximating their quality. As shown in Figure 5, the user subscriptions are distributed by a power law. In order to select feeds for modeling, we performed stratified sampling based on the user subscription distribution. A similar procedure was adopted for the bookmarking site using the number of bookmarked tags as the quality measure. For the feeds from the web, we performed stratified sampling based on the num-ber of feeds in a host. The feeds from sources which did not have such a statistic were included directly in the final sample set for modeling. This included the feeds recommended by the news con-sortium and editorially picked feeds. The final feed set contained a total of 12,000 feeds.

In order to get the label for each feed, we obtained the qual-ity class of a feed with the help of the quality indicators, namely linked article quality (  X  ), and link description quality (  X  )asdis-cussed in Section 3. These indicators were obtained by the fol-lowing experiment. The generated 12000 feed samples were fed into the PreGen-enabled search engine which was crawled every 15 minutes and the previews created from these feeds were indexed continuously. Every 24 hours for 1 week, human editors picked queries from a recency-sensitive query dictionary and issued them to the PreGen-enabled search engine. The relevant previews and articles returned by the search engine were graded by editors, and these relevance grades were used to quantify the two feed quality indicators  X  and  X  as described in equations 1 and 2. We deter-mined the labels of all the feeds by mapping their respective quality indicators to the quality class as shown in table 2. The queries used in this experiment were editorially short-listed from a dictionary of recency-sensitive queries, which was updated every hour by run-ning a recency-sensitive query classifier [4] on the query logs of the search engine.
We compute our features using the content of the feed, the con-tent of the linked page, the link structure, host characteristics, and refresh and update characteristics. Since the feeds change frequently,
Figure 7: Class A ROC curves for online and offline model. the test set. The GBDT model had the lowest misclassification rate of 19.4% on the test set. The SVM model trained with the radial basis function exp (  X   X   X  X  u  X  v | 2 ) as kernel (  X  = 50, cost c = 1) had comparable performance with GBDT. Even though the difference is not statistically significant, we chose GBDT for its better average performance and its faster classification due to its feature reduction capabilities.

As discussed in the Section 4, ML models are used for both on-line and offline feed selection. These selection functions use differ-ent feature sets, but their goal is similar, to select high quality feeds for recency-sensitive queries. The offline models can comprehen-sively include all the host-level, page-level plus the time-sensitive features, whereas the online models can only use the time-sensitive features. The model performance in both cases did not differ much in overall misclassification rate. The time-sensitive online model had around 19.7% misclassification rate, whereas the offline model had 19.6%. The ROC curves as shown in Figure 7 for the class A classification for online and offline models are very similar and they both have similar area under the curve. This shows that time-sensitive features alone are strong enough indicators to match the performance of the offline selection feature set.
Our selection function uses the GBDT classifier to classify feeds and selects the top K feeds of class A feeds, where K is the capacity of the PreGen system. The order of feeds within a class is decided by the class ownership probabilities output by the classifiers. In order to evaluate the selection function, we used a test feed pool Figure 10: Percentage of queries for which relevance is im-proved using PreGen versus the baseline web index. Exper-iments were conducted at two different times and with two ranking functions to verify that the improvement was due to the preview index.
 Figure 11: Percentage of DCG improvement. PreGen provides a minor to moderate improvement to DCG metrics for recency-sensitive queries.
 Figure 9 shows the distribution of the feeds by class ownership. GBDT-based feeds have high quality (class A) feeds in the same proportion as editorially picked feeds. PageRank feeds do not per-form as well as others. This is due to the fact that the GBDT model was trained to predict these classes. The fact that the majority of the GBDT selected feeds fall in class A is desirable as this is the class of feeds with the highest item and linked page quality. These metrics show the advantage of our GBDT-based selection function. In the next section, we study the effect on search result quality due to the previews created from the feeds selected via this function.
As illustrated in section 4, PreGen generates previews for an-swering relevant recency sensitive queries. In this section, we will study the effect of PreGen on a state-of-the-art search engine. We assigned a maximum capacity of K = 100 , 000 feeds for PreGen. PreGen updates the feed set periodically based on the ML selection function. As the feeds selected online change frequently, we had to use only offline feeds in our experiment for the sake of consistency. The offline feeds were updated once every month to study the effect of feed set change on evaluation metrics before and after an update. system that indexes all web pages and the PreGen system that in-dexes only previews. We used the Discounted Cumulative Gain ( DCG ) and the normalized Discounted Cumulative Gain ( nDCG ) metrics to measure the advantage of PreGen. Given a query q and a ranked list of L documents, the DCG for query q can be expressed as: where g ( i ) is the relevance grade (assigned by human editors) in scale 0 to 4 of the i th document in the ranked result set. The nDCG DCG computed by applying the DCG function on the optimal rel-evance order of L documents. In this case the optimal relevance order is obtained by sorting the relevance grade g ( i ) of a docu-ment. For each query, we compared the search results from the pre-view index and the baseline web index using the metrics DCG ( 5 ) , DCG ( 1 ) and nDCG ( 5 ) . Figure 10 shows the percentage of recency sensitive queries for which the relevance metrics were higher for results from the preview index than those from the baseline web index. It can be observed that variations caused by using different ranking functions are small. However, the time of study affects the relevance due to the use of previews. 8-11% of all recency-sensitive queries affected DCG ( 5 ) positively due to previews on June 26th 2009, and 2-3% of queries on June 2nd 2009. The variation in time needs to be studied carefully in our future work as it could be due to varying feed set, changing preview documents, or changing na-ture of recency sensitive queries. For the case of queries where the DCG is lower than the baseline, the relevance will not be promi-nently affected when PreGen is integrated with the baseline. This is because, for those queries, although PreGen generates irrelevant previews, a good ranking function will not consider these previews for inclusion in the final search results. Hence, subject to the choice of a good ranking function, PreGen can only have a neutral or pos-itive effect on the baseline search engine.

Now, we study the effect of integrating PreGen with the baseline search system. The overall relevance of the PreGen enhanced base-line improved as shown in Figure 11. For instance, the DCG ( 5 ) improvement is between 0.2% and 3.2% over the baseline DCG ( 5 ) for Rank 2 . Another important result to observe is the presence of previews in the first position. DCG ( 1 ) increases by 3% in the worst case and 9.5% in the best case. These results indicate the usefulness of previews in improving the search relevance. Previews also cover a broad spectrum of recency-sensitive queries. Figure 12 shows that 90% of the queries are covered by the previews over different periods in time.

All these results support the fact that feeds selected using the ML algorithm satisfy our notion of quality as described by the three properties listed in Table 1. For example, Figure 8 indicates that the selected feeds generated high quality articles which had as high click probability as articles from editorial picked feeds. Further-more, Figures 10 and 11 show that the previews generated from feeds contained enough description and were relevant to the search engine. Thus, these results validate the first two properties. As shown in Figure 12, the selected feeds generated articles that cov-ered a broad spectrum (90%) of recency-sensitive queries, there-fore the articles must be about the recent events, which validates the third property.
The preview documents reduce the end-to-end latency of the search engine. Previews temporarily stay in the index as synthetic documents and answer relevant queries before actual contents of [7] Jerome H. Friedman. Greedy function approximation: A [8] Paul Heymann, Georgia Koutrika, and Hector [9] K. J X rvelin and J. Kek X l X inen. IR evaluation methods for [10] Thorsten Joachims. Optimizing search engines using [11] Craig Macdonald and Iad h Ounis. Key blog distillation: [12] G. Mishne. Using blog properties to improve retrieval. [13] Rudy Prabowo and Mike Thelwall. A comparison of feature
