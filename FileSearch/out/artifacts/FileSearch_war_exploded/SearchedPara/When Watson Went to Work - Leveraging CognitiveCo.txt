 In February 2011, the world was introduced to Watson, IBM X  X  cognitive computing system [1] that defeated Ken Jennings and Brad Rutter at Jeopardy! It was the first widely seen demonstration of cognitive computing, and it marked the end of the so-called X  X I winter. X  X atson X  X  ability to answer subtle, complex, pun-laden questions made clear that a new era of computing was at hand. An era where computers can start making sense of the vast amount of un-structured data in the world and apply this understanding not only to answer trivia questions, but also to tackle some of the world X  X  pressing problems and change how people in-teract with computers.

Indeed, since Jeopardy!, Watson has tackled increasingly complex data sets, and developed understanding, reasoning, and learning. Specifically, we have identified five core ca-pabilities of Cognitive Computing: 1. They create deeper human engagement; 2. They scale and elevate expertise; 3. They infuse products and services with cognition; 4. They enable cognitive processes and operations; 5. They enhance exploration and discovery. The true potential of the Cog-nitive Era will be realized by combining the data analytics, and statistical reasoning of machines with uniquely human qualities, such as self-directed goals, common sense, and eth-ical values. This is what Watson was built to do, and is in fact already doing. Banks are analyzing customer requests and financial data to surface insights to help them make investment recommendations. Companies in heavily regu-lated industries are querying the system to keep up with ever-changing legislation and standards of compliance. And oncologists are testing ways in which cognitive systems can help interpret cancer patients X  clinical information and iden-tify individualized, evidence-based treatment options that leverage specialists X  experience and research. Customer and technical support are in particular being re-invented, relying more on cognitive systems for self-help and for agent assist.
In this talk, we highlight some of the applications of Wat-son that are being pursued by IBM. These include applica-tions in customer and technical support, in Finance, in Legal and more. We also elaborate on some of the underlying tech-nologies that are available via APIs on the Watson Developer ing this technology in real-world use cases. We specifically discuss two challenges that we face in leveraging Watson for tech support and customer support in some more detail. The first is in the area of technical support, where Watson is being used to find solutions for relatively complex techni-cal support issues. In this case, we developed extensions to Watson X  X  state of the art techniques that can take into ac-count the format and the richness of the problem definition.
The second is in the area of customer support, where Wat-son is being used to answer customer queries about products and services. In this case, the sentiment of the person di-aloging with the system as well as the system X  X  responses are found to be important in being able to satisfy the customer X  X  information need.
As a concrete example, in one of the technical support use cases, Watson handles problem management records (PMRs) submitted by various clients and aims to discover techni-cal notes (technote) that contain potential solutions to their technical problems. Each such record may describe several aspects of the client X  X  problem expressed in natural lan-guage. For example, a PMR may include multiple prob-lem related issues describing the problem, the impact on the client X  X  business, the client X  X  system characteristics, etc. Fig-ure 1 depicts an example of a real PMR query and its match-ing technote (both represented in JSON format). PMR descriptions are highly ambiguous, verbose in most cases, multi-lingual and their quality spans from detailed problem descriptions to computer generated error log traces. On the other hand, technotes (documents) in the corpus describe technical details of various problem solutions, and may in-clude multiple searchable fields that may be relevant for solv-ing a PMR.

PMRs processing is a challenging task, and Watson X  X  orig-inal question-answering paradigm which is geared more to-wards factoid queries is insufficient here. In order for find a relevant solution, the system needs to search over multiple combinations of PMR problem aspects and technical doc-ument and find the best match(es). Alternative solutions to this challenging problem were explored using a  X  X REC-developercloud/ Figure 1: Example of a PMR query and its relevant technote like X  X ompetition, where several different research and devel-opment teams within IBM have explored various retrieval approaches including those that employ both state-of-the-art and novel QA, NLP, deep-learning and learning-to-rank techniques.

To handle such complex retrieval task, based on one of the leading retrieval strategies that were developed, Watson employs several state-of-the-art IR and question-answering methods, spanning from verbose query processing and pseudo-relevance feedback to techniques that utilize query perfor-mance prediction for selecting ranking strategies and their fusion. Furthermore, a new  X  X ulti-field X  retrieval approach developed as part of this approach further allows Watson to consider all possible PMR X  X echnote (cross product) query-ing options, while intelligently focus only on those combi-nations that are predicted to be the most important for answering the complex information need expressed in the PMR. Overall, Watson X  X  retrieval quality for this domain has been boosted by more than 30%.
One domain in which the concept of Watson has evolved since Jeopardy! is the domain of dialog . Originally, IBM Watson was conceived as a question answering system in which interactions with users were limited to question-answer pairs. When Watson technology was deployed in different domains, it became evident that more advanced dialog capa-bilities are necessary in order to handle more complex tasks e.g. in order to obtain clarifications from users about their questions. In this case, Watson becomes a dialog engine with which users can converse and relies on its question answering capabilities when necessary as a conversation evolves.
One of the most common implementations of Watson X  X  conversation engine is in the area of customer support. In this case, in addition to being able to converse with the user, it becomes important to understand the sentiment of the user as well as tailor the engine X  X  response based on this sentiment. In other words, as users start to converse with computers in very natural ways, they expect computers not only to address their information needs but also their emotional needs. Figure 2: Example of an affective dialog. The actual UI followed by the rest of the conversation
In such a case, computers should identify user emotions and then take those emotions into account when replying. Effectively, a computer involved in dialog should be able to thank, apologize, and be empathetic similar to a human agent. Such a dialog between a human and a Watson-based support agent is provided as an example in Figure 2 (showing which emotions have been detected).

This example is focused on textual interactions between the user and Watson but clearly other input modalities like speech and video offer even more opportunities to detect and act upon user emotions.
 In addition to emotions which are naturally transient, Watson provides capabilities to analyze more static aspects of a user X  X  personality based on the language being used. By combining personality and emotional aspects, the goal in the longer term is to automatically craft a digital person-ality personalized to interact with a particular user.
In a recent study, we examined emotions being expressed in Twitter service conversations between humans [2]. We show that customer X  X  and agent X  X  personality traits com-bined with the emotion being expressed in the first turn of a conversation are good predictors of user satisfaction at the end of the conversation: specifically, our model shows an improvement of 30% in the F1-score for predicting dissatis-faction. This result enables automatically matching the best agents to a particular user in a given context. [1] David Ferrucci, Eric Brown, Jennifer Chu-Carroll, [2] Jonathan Herzig, Guy Feigenblat, Michal
