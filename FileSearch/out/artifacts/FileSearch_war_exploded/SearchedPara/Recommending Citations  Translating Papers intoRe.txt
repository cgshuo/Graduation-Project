
When we write or prepare to write a research paper, we always have appropriate references in mind. However, there are most likely references we have missed and should have been read and cited. As such a good citation recommenda-tion system would not only improve our paper but, overall, the efficiency and quality of literature search.

Usually, a citation X  X  context contains explicit words ex-plaining the citation. Using this, we propose a method that  X  X ranslates X  research papers into references. By considering the citations and their contexts from existing papers as par-allel data written in two different  X  X anguages X , we adopt the translation model to create a relationship between these two  X  X ocabularies X .

Experiments on both CiteSeer and CiteULike dataset show that our approach outperforms other baseline methods and increase the precision, recall and f-measure by at least 5% to 10%, respectively. In addition, our approach runs much faster in the both training and recommending stage, which proves the effectiveness and the scalability of our work.
H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval Algorithms, Experimentation
Citation recommendation, machine translation
Citations are important in academic dissemination in at least two ways. First, correct citations demonstrate intellec-tual honesty by giving credit to the work of others; second, proper citations help readers trace the source and evaluate whether the referenced works support authors X  claims. So as to attribute completely the work of previous researchers, authors must be very careful when creating the literature review to avoid missing significant references. Most current literature search engines focus on short queries. In our work, we mainly deal with the cases where users pro-vide a longer query ranging from a sentence to an entire manuscript, and our recommendation system automatically suggests a list of references based on the query input.
As shown in Fig. 1, the descriptive language usually con-tains words that describe or summarize the main points of the cited papers. Therefore, citation recommendation can be described as a translation process, where we  X  X ranslate X  context sentences into papers to be cited.

A research paper is written using two different X  X anguages X : (1) the descriptive language , consisting of citation words used in the paper before the reference section; and (2) the reference language , consisting of references, where each referenced paper is considered as a  X  X ord X . In order to dis-tinguish different papers, the reference language vocabulary is a set of unique IDs representing cited papers.
The citation translation model for reference recommen-dation involves two steps: (1) Build up a dictionary that contains the translation probability of a reference given a word or phrase for all terms in the descriptive language vo-cabulary. (2) Compute the probability of a reference given the query using the translation probabilities. Recommend references in ranked order.

The major contributions of this paper are:  X 
We propose to represent the cited papers by unique IDs, regarding them as  X  X ords X  in a novel language, and then use translation model to estimate the translation proba-bility of a ID given citing words. We also use the model to capture the co-citation relationship in a novel way.  X 
We demonstrate that our approach improves the perfor-mance by increasing the precision, recall and f-measure by at least 5% to 10%, respectively, compared with the state-of-the-art approaches.  X 
By comparing the model complexity with baseline meth-ods, we show that on a large dataset our approach runs at least 100 times faster in the training stage and 5 to 600 times faster in the recommending stage, which proves the effectiveness and the scalability of our approach.
Most early works for citation recommendation require user profile information or a partial list of references. McNee, et al. [13] explore the use of collaborative filtering for recom-mending research papers. Their method uses the citation network, paper-citation information, and co-citation infor-mation to create a ratings matrix. This method based on the citing history of the user, however, did not take the con-tent into consideration.

Strohman, et al. [20] introduced a citation recommenda-tion system that uses the combination of content features and citation web information to evaluate the relevance and similarity between two documents. They construct a candi-date set by first using the text similarity to select an initial set, and then adding to it all the citations of each paper in the initial set. Then, they rank all the candidate papers using features such as bibliography similarity and Katz cen-trality measurement.

In recent years, various citation recommendation methods have been proposed using latent topic models [2]. Nallapati, et al. [16] models the text and citation together to propose a model named link-PLSA-LDA. Link-PLSA-LDA models the cited set of paper using PLSA [8] and the citing set using the link-LDA model [6]. Kataria, et al. [9] extended the method by associating terms in the citation contexts to the cited documents. The model, cite-PLSA-LDA, assumes that the words and citations occurring in the citing paper are generated from topic-word and topic-citation multinomial distributions, respectively.

Citation context analysis has been used in information retrieval for quite some time. Previous work shows that in-dexing cited articles with the terms appearing in citation context can improve effectiveness of retrieval compared to indexing the whole content of cited article [19, 18]. He, et al [7] use a context-aware approach for recommending cita-tions. This approach assumes that user has provided place-holders for citation in a query manuscript. They propose a probabilistic model to measure the relevance between docu-ments and between the citation contexts and the document.
In Statistical machine translation (SMT), a document is translated according to the probability distribution Pr( e that a string e in the target language is the translation of a string f in the source language.

The application of the translation model has gone far be-yond simple translation. Many tasks in information retrieval and natural language processing also adopt the translation model to estimate the relationship between two different ob-jects [1], such as sentence retrieval [15], question answer-ing [14], and tag suggestions [11].

Lu, et al. [12] used the translation model to recommend citations. They assumed that the languages used in the citation contexts and in the cited papers X  content are differ-ent, and tried to bridge these two languages by translating words in the document to words in the citation contexts. After training the model, they recommend papers according to the probability of translating a cited papers X  content to a citation context. Their ranking score for recommending ci-tations actually reveals the probability of how likely a cited paper can be summarized into a citation context.

In contrast, we propose to represent the cited papers in a concise fashion (unique IDs), regarding them as new X  X ords X  in a novel language, and we propose to directly estimate the probability of citing a paper given a citation context. Moreover, we introduce a novel way of parallelizing data that better capture the co-citation relationship such that the translation model can bridge the co-cited papers via terms appearing in the paper X  X  citation contexts.
In this section, we will first discuss how to construct par-allel training data from a given corpus, and then how to learn the translation model on the training data to build up a dictionary that captures the relationship between citations and terms in the two  X  X anguages X .
Given a corpus of research papers D corpus , we divide each paper into two parts: descriptive language d as the source language and the corresponding reference language r as target language as defined in SMT, then pair these two parts as one entry within the parallel dataset.

We use the terms in the citation context to form the source language. Our preliminary experiments indicate that a fixed size window surrounding the citation mention models the cited paper better than the whole content of the citing arti-cle which is too verbose and noisy for modeling the source language. A citation context c is defined as n sentences that appear before a citation and n sentences after. Intuitively, the sentence that contains a citation is the first place where descriptive terms will appear. For example, in Fig. 1, the term  X  X ageRank X  appears right before the citation. Some of the descriptive terms can be found in nearby sentences if the writer tries to expand more details for the citation. Therefore we vary the radius of a citation context n from 1 to 3. Note that it will lose the meaning of citation context if we set the radius too large.

Suppose there are k citation contexts within a descriptive language d =[ c 1 ,  X  X  X  ,c k ]and m references within the ref-erence language r =[ r 1 ,  X  X  X  ,r m ]. We construct the parallel data by obtaining all citation contexts within a paper as source language and pairing it with all citations in the pa-per. Thus, one paper forms one entry for the parallel data: where t c i ,j is the j th term appearing in the i th citation con-text of d and r i is the i th cited paper in r . We will refer to this method as All-to-All type of parallel data.

The context for neighboring citations may overlap when we set the radius to 2 or 3. We do not duplicate words in the overlap for All-to-All parallel data.
After constructing the parallel data, we applied the trans-lation model to build up a dictionary over the two vocab-ularies. We treat both descriptive and reference language as bag of words ignoring the ordering information of both languages, so we adopt the IBM translation Model-1 [3] to learn the translation model which is most suitable for our settings.

The IBM Model-1 models the translation process based on word-level alignment. The alignment from source lan-guage d =[ t 1 ,  X  X  X  ,t l ] to target language r =[ r 1 , described by a hidden variable A =[ a 1 ,  X  X  X  ,a m ]. In SMT, such an alignment is interpreted as the process of translation in which two words in different languages that are aligned together share the same meaning. In the citation transla-tion model, a word aligned to a paper indicates that the word may need that particular citation. According to an alignment A ,where a i = j means r i is aligned to t j ,the objective function for translation can be formulated as: where Pr( r i | t a i ) is the probability of citing r i given a term t , or as in SMT, the probability of translation t a i to r The objective function solved using EM algorithm [5]. Both the translation table Pr( r  X  | t  X  ) and probabilities of all possible alignments A can be initialized with uniform dis-tributions, the EM algorithm will iteratively calculate them until convergence. The result of the algorithm will give the model for word level recommendation probability Pr( r i | which maximizes the translation probability of document level recommendation probability Pr( r | d ). Null Token In the translation model, the alignment allows a = 0, indicating that an element of a target language is mapped from a null token . This alignment is essential for machine translation, because not all words in a target lan-guage have a specific mapping from a source language. How-ever, in scientific papers, every citation is usually cited in the text. The citation contexts will contain terms that summa-rize the citation. Therefore, the alignment to a null token is meaningless in our task, so we remove such kind of mapping. Co-citation Analysis As outlined in Section 3.1, we pro-posed the All-to-All parallel data which is a novel way to capture co-citation relationship. In All-to-All data, we pair words in all citation contexts with all references of a paper. At first glance, this pairing may seem inaccurate. However, note that citation contexts make very specific comments about the relationship of a cited paper from the perspec-tive of the citing paper. If two papers have been co-cited within a paper, they have some connections. So the trans-lation model built on the All-to-All data enables a cited paper to be modeled using terms related to co-cited papers. The more two citations co-occur, the higher the probability that the words used to describe one paper is related to the other, and, the higher the probability that they will be cited together in the future.

Take this paper for example. We cite papers from ma-chine translation and citation recommendation. The co-occurrence of these references indicates the relationship be-tween them. Thus, in the future when people mention the application of machine translation, they might want to cite citation recommendation papers too. Trained with All-to-All data, the translation model can bridge the co-cited pa-pers via terms appearing in this paper X  X  citation contexts.
After we obtain a dictionary that contains the translation table between two vocabularies in the form of triplet entries t ,r j ,Pr ( r j | t i ) . We can now  X  X ranslate X  a query into a reference list.

Given a query Q =[ t 1 ,  X  X  X  ,t l ], the task is to recommend a list of references R =[ r 1 ,  X  X  X  ,r m ]. We will go through all words in Q and assign the score for each reference r i as: where Pr( r i | t j ) is the probability of translating the term t to the reference r i and Pr( t j | Q ) is the probability that the term t j needs citations within the query.

Here we use the term-frequency-inverse-context-frequency (TF-ICF) to measure Pr( t j | Q ), the probability of a citation need. Given a query Q ,TF t is defined as the number of times a given term t appears in Q , which reveals the impor-tance of the term t within the particular query Q .ICFgives a measure of whether the term is common or rare across all citation contexts. ICF t =log | C | set of citation contexts, and t  X  C 1 indicate the number of citation contexts that contain the term t .
In this section, we evaluate the performance of citation translation model on two real datasets. We use the papers X  reference lists as ground truth for evaluation and compare our approach with different state-of-the-art approaches.
The first dataset CiteSeer hasbeenwidelyusedforci-tation recommendation by Kataria, et al. [9], Tang and Zhang [21] and Nallapati, et al. [16]. The second dataset we use was acquired from CiteULike 1 from November 2005 to January 2008. The dataset was also used by Kataria, et al. [10] for citation recommendation. The characteristics of both datasets are shown in Table 1.

For each dataset, we first remove the stopword and then randomly partition them into 5 subsamples and then per-form a 5-fold cross validation on the exact same partition for our approach and other baseline methods. set, we use the original set of references as the ground truth R . Assume that the set of recommended citations are R r ,the correct recommedations are R g  X  R r . Precision, recall and F-measure are defined as: In our experiments, the number of recommended citation ranges from 1 to 20.

Precision, Recall, and F-measure evaluation do not reveal the order of recommended references. To address this prob-lem, we select the following two additional metrics. pose an approach recommends a list of references S ,inwhich the correctly recommended citations is the list R .Let r be a correct recommendation and i be an incorrect recommen-dation. Bpref [4] is defined as: be the rank of the first correct recommendation within the list. MRR [22] is defined as: where Q is the testing set. MRR reveals the averaged rank-ing of the first correct recommendation.
We choose to compare our approach with both context-based and not context-based approaches as follows:  X 
Link-PLSA-LDA ( link-LDA ) [16]: We turned the pa-rameter setting as suggested in [9]. The number of topics is set to 200 for CiteSeer and 500 for CiteULike .This approach is not context based.  X 
Cite-PLSA-LDA ( cite-LDA )[9]: Wesetthecitation context radius n to 3 and the number of topic to 200 for
CiteSeer , 500 for CiteULike which give the best results as the author suggested [9]. The approach is context-aware.  X 
Context-aware Relevance Model ( CRM )[7]: We tuned the parameter settings as suggested in that paper. The citation context radius n is set to 3 sentences as the in
Cite-PLSA-LDA model. This approach is context-aware.  X 
Translation Model ( TM ) [12]: We use GIZA++ [17] 2 to learn translation between words in citation context and words in cited paper. We tuned the parameter settings as suggested in [12]. This approach is context-aware.  X 
Citation Translation Model ( CTM ): In our method, we modify the GIZA++ toolkit [17] to learn translation probabilities using IBM Model-1. The parameters that give the best performance is the citation context radius n = 1, and the number of training iterations around 10.
Denote the number of training iterations for link-LDA, cite-LDA, TM and CTM as I ( I actually varies among dif-ferent methods), the number of topics for link-LDA and cite-LDA as K , the average number of words each citation con-text has as  X  N cc , the average number of words each paper has as  X  N w , and the average citations each paper cites as
For the training stage, the CRM does not need a training phase. The complexity of link-LDA is O ( IKD  X  (  X  N w + cite-LDA is O ( IKD  X  N w ), TM is O ( ID  X  N w  X  N cc is 10 to 20 times less than K (ranging from 200 to 500 or even more) and  X  N cc  X  N c &lt;  X  N w .
For the recommending stage, assume we have a query q with N q terms. The complexity of link-LDA is O ( IKN q ), cite-LDA is O ( IKN q ), CRM is O ( D  X  N c 2 ), TM is O ( DN and CTM is O ( N q  X  R q ), where  X  R q is the average number of dictionary entries for each word in q .  X  R q usually drops tremendously (to around 20 to 50) after several iterations if we wipe out those with too low translation probabilities. From Table 2 3 and the above analysis we can see that CTM is comparatively much simpler and much more efficient for both the training and recommending tasks.
For all compared methods we use the parameter settings as mentioned in Section 5.3, which give the best perfor-mance. In Figure 2, Figure 3 and Table 3, we show the results on both CiteSeer and CiteULike dataset.
 From the results, we get the following observations:
First, the citation translation approach outperforms all the other baselines on both datasets across the different eval-uation metrics, which showed that our approach improved the recommendation significantly and robustly. The Bpref and MRR metrics show us that the proposed method gen-erates recommendation lists which are better ranked. The MRR results indicate that our method will recommend first correct citations with an average ranking at 2, while other baseline methods ranked first correct citations with an av-erage ranking at 4 or even worse.

Second, as shown in Section 5.3, we have to tune the settings for cite-LDA and link-LDA according to different datasets to get a best result for each approach. For exam-ple the number of topics is set to 200 for CiteSeer and 500 for CiteULike , which was obtained empirically from exper-iment. Although it is intuitive that we should assign more topics for larger datasets, however, you have to train many models with different number of topics to get the best re-sults. For the citation translation model, the only parameter needs to be tuned is the number of training iterations.
We propose a translation-based citation recommendation model. Our approach use the existing citations and their contexts and adapted the translation model to capture map-pings between terms in citation contexts and citations.
We show that using the citation contexts of all citations in a document together as the source language and the set of references in the document as the target language cap-tures co-citation and improves the quality of recommenda-tion. Experiments on two real datasets demonstrated that the proposed translation approach outperforms the existing state-of-the-art methods.

We plan to investigate the following problems:  X 
CTM can only recommend citations that have been cited before. For newly published papers, it is hard to recom-mend them if they have not been cited. We plan to incor-porate summarization and keyword extraction techniques to help put non-cited papers into translation tables.  X 
Different authors may cite different papers according to personal preferences or different emphases. Our approach is author-oblivious. We might obtain improved perfor-mance when the authors are taken into consideration.
