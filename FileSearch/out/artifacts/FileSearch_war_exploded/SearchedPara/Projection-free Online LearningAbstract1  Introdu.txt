 Elad Hazan ehazan@ie.technion.ac.il Technion -Israel Inst. of Tech.
 Satyen Kale sckale@us.ibm.com IBM T.J. Watson Research Center In recent years the online convex optimization model has become a prominent paradigm for online learning. Within this paradigm, the Online Gradient Descent algorithm of Zinkevich (2003), and its close cousin Stochastic Gradient Descent, have been successfully applied to many problems in theory and practice. While these algorithms are usually very efficient, a computational bottleneck that limits their applicabil-ity in several applications is the projection step in the algorithm. Specifically, whenever we take a step that causes the current iterate to leave the convex do-main of interest, thus leading to an infeasible point, we project the point back into the domain in order to restore feasibility. This projection step implies finding the nearest point in the domain in ` 2 distance, and in the general amounts to solving a convex quadratic program over the domain.
 In many settings of practical interest, while solving convex quadratic programs is out of the question, lin-ear optimization can be carried out efficiently. In this paper we give efficient online learning algorithms that replace the projection step with a linear optimization step for a variety of settings, as given in the following theorem: Theorem 1.1. There is an algorithm scheme for on-line convex optimization that performs one linear op-timization over the convex domain per iteration, and with appropriate modifications for each setting, obtains the following regret bounds: Furthermore, in each iteration t , the algorithm main-tains an explicit, efficiently sampleable distribution over at most t boundary points with expectation equal to the current iterate.
 The above theorem entails several appealing advan-tages over the existing methods for online learning, as we detail below: Computational efficiency. In several learning do-mains of interest projection steps are computationally very expensive. One prominent example is online col-laborative filtering, where the domain of interest is the set of all positive semidefinite matrices of bounded trace. Projecting into this set amounts to computing the singular value decomposition (SVD) of the matrix to be projected, whereas linear optimization is finding the top singular vectors, a much more efficient opera-tion.
 Parameter free. Since the basic primitive of our algorithm is linear optimization rather than gradient steps and projections, our algorithms in the stochas-tic case are naturally parameter-free. In particular there is no parameter corresponding to the learning-rate. This makes it particularly easy to implement, since no parameter tuning is necessary.
 Efficient representation and Sparsity. Another computational issue with standard projected gradient descent methods is more subtle: frequently the do-main of interest is the convex hull of  X  X nteger X  deci-sion points in Euclidean space (for example, in the online shortest paths problem (Awerbuch &amp; Klein-berg, 2008)). In such problems, points in the con-vex hull represent distributions over integer decision points, and to output a valid decision point we must be able to sample from such distributions. Typically, this requires being able to decompose points in the interior of the convex hull as explicit convex combi-nations of boundary points, and then sampling from the induced distribution. Such a decomposition may also require a lot of computational effort (for example, in the online shortest paths problem, this decomposi-tion amounts to computing a flow decomposition in a network).
 In contrast, our algorithm explicitly maintains a dis-tribution over the vertices (or more generally bound-ary points) of the decision set, thereby eliminating the need for any further decomposition. In fact, in round t the distribution is supported on at most t boundary points, thus giving a form of sparsity. 1.1. Some Appropriate Convex Domains In several interesting online learning scenarios the un-derlying decision sets do not admit  X  X ractically effi-cient X  projections. We list several interesting examples of such decision sets below.
 Bounded Trace Norm Matrices. The set of ma-trices with bounded trace norm is a common decision set for applications such as matrix completion and col-laborative filtering. For example, consider the set K of m  X  n matrices of trace norm bounded by some parameter  X  . Computing the projection of a matrix X requires computing the SVD of X , which requires O ( nm 2 ) time in general assuming m  X  n . Linear opti-mization over K amounts to computing the top singu-lar vectors of the matrix defining the objective, which can be done much faster: typically, linear time in the number of non-zero entries in the matrix.
 Flow polytope. Given a directed acyclic graph G with n nodes and m edges with a specified source node s and a sink node t , consider the set of all paths from s to t . Any such path can be represented as a vector in R m by its indicator vector over edges. Let K be the convex hull of all such path vectors. This can be equivalently described as the set K of all unit flows from s to t , which can be represented as a polytope in R m with O ( m + n ) linear inequalities. This set K arises in the online shortest paths problem (Awerbuch &amp; Kleinberg, 2008). Computing the projection of a vector on K amounts to solving a quadratic program on this polytope, for which the most efficient algorithm known takes O ( n 3 . 5 ) time. Linear optimization on K is much easier: it amounts to finding the shortest path from s to t given weights on the edges, and can be done in linear time using dynamic programming. Matroid polytope. Given a matroid M = ( E,I ), where | E | = n , any independent set A  X  I can be represented as a vector in R n by its indicator vector. The matroid polytope K is defined to be the convex hull of all such indicator vectors of independent sets. This polytope can be defined using O (2 n ) linear in-equalities. Computing a projection on K is therefore a difficult operation (although polynomial time, see (Nagano, 2007)). Linear optimization over K is very easy however: there is a simple greedy algorithm (see, e.g. Schrijver (2003)), amounting to sorting the co-ordinates of the objective vector, which solves it in O ( n log( n )) time.
 Rotations. Consider the set of all n  X  n rotation ma-trices. These are orthogonal matrices of determinant 1. Let K be the convex hull of all rotation matrices. This set K arises in the online learning of rotations problem (Hazan et al., 2010). Computing the projec-tion of a matrix on K is very difficult since there is no succinct description 1 of K . However, linear optimiza-tion on K is a classic problem known as Wahba X  X  prob-lem (Wahba, 1965), and can be solved using one singu-lar value decomposition. The only method of comput-ing projections on K that we know of uses the ellipsoid method with linear optimization. 1.2. Discussion of Main Result Our main result is that assuming it is possible to do linear optimization over the convex domain efficiently, we can obtain good algorithms (in the sense of obtain-ing sublinear regret) for online convex optimization over the domain using an online version of the classic Frank-Wolfe algorithm (Frank &amp; Wolfe, 1956). The above statement needs clarification: Zinkevich (2003) shows (via his Online Gradient Descent algo-rithm) that it is possible to do online convex opti-mization solving one quadratic program over the do-main per step. Since quadratic optimization can be reduced to a polynomial number of linear optimiza-tions via the ellipsoid algorithm, we can therefore do online convex optimization solving a polynomial num-ber of linear programs over the domain per step. In contrast, we show (via our Online Frank-Wolfe algo-rithm) that it is possible to do online convex optimiza-tion solving one linear program over the domain per step. This yields immediate computational benefits. Another computational benefit comes from the fact that the algorithm automatically computes a distribu-tion over boundary points for the iterates. In fact, if we simply want to sample from the distribution, then there is a very natural procedure for doing that: with a certain explicitly specified probability (viz. t  X  a , see Algorithm 1), we replace the current boundary point with a new one that is computed in the current iter-ation in the linear optimization. This also automati-cally gives a lazy versions of the algorithm, in which the chosen decision point is updated very infrequently. Our regret bounds are always sublinear, but not al-ways optimal (with the exception of the stochastic, smooth case, where we obtain optimal regret bounds via our methods). Thus, theoretically we have slower convergence, in terms of number of iterations, to the optimal decision point, but the computational savings per iteration lead to a faster algorithm overall. This is validated by our experiments in Section 5. 1.3. Related Work Vempala (2005). They give an algorithm (previously considered by Hannan (1957)) for online linear opti-mization which performs one linear optimization over the decision set in each iteration. The striking feature of their work is they are able to show optimal O ( regret bounds even for adversarial costs, although the limitation of their work is that the algorithm specifi-cally works only for linear cost functions. They also give lazy versions of their algorithm via a careful cor-relation of randomness from one iteration to the next. In comparison, our algorithm has a very natural lazy implementation (simply replace the previous decision point with a new one with an explicitly specified prob-ability) which, in our opinion, is significantly simpler. Our results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain. We show how to extend their techniques to handle online, changing cost functions in stochastic and adversarial settings, and also show how to handle non-smooth functions. Online convex optimization. The problem of in-terest is online convex optimization (see the survey of Hazan (2011) for more details). Iteratively in each round t = 1 , 2 ,...,T a learner is required to produce a point x t from a convex, compact set K X  R n . In re-sponse, an adversary produces a convex cost function f t : K  X  R , and the learner suffers the cost f t ( x The goal of the learner is to produce points x t so that the regret, is sublinear in T . If the cost functions are stochastic, regret is measured using the expected cost function f = E [ f t ] instead of the actual costs.
 We assume that the set K diameter bounded by D and it is possible to efficiently minimize a linear function, viz. computing arg min x  X  X  v  X  x for some given vector v  X  R n is easy. The cost functions f t are assumed to be L -Lipchitz, i.e. for any two points x , y  X  K , we have | f t ( x )  X  f t ( y ) | X  L k x  X  y k .
 Definition 2.1. Let f : R n 7 X  R be an arbitrary con-vex function which is also L -lipchitz. f is called  X  -smooth if for all x , y  X  X  we have f is called  X  -strongly convex if for all x , y  X  K we have Note that if f is twice differentiable, then  X  is upper bounded by the largest eigenvalue of the Hessian of f . The above definition together with first order op-timality conditions imply that for a  X  -strongly convex function f , if x  X  = arg min x  X  X  f ( x ), then Smoothed functions. Let B and S denote the unit ball and unit sphere in R n respectively. Given  X  &gt; 0, let the  X  -smoothing of a function f (c.f. (Flaxman et al., 2005)) be: where u is chosen uniformly at random from B . We are implicitly assuming that f is defined on all points within distance  X  of K . The following lemma (proof in the full version of this paper) shows that  X  f  X  is a good smooth approximation of f : Lemma 2.1. If f is convex and L -Lipschitz, then the function  X  f  X  has the following properties: 1.  X  f  X  is convex and L -Lipschitz. 3. For any x  X  X  , k X   X  f  X  ( x ) k X  dL . 4.  X  f  X  is dL  X  -smooth. 5. For any x  X  X  , | f ( x )  X   X  f  X  ( x ) | X   X L . K -Sparsity. A feature of our algorithms is that they predict with sparse solutions, where sparsity is defined in the following manner.
 Definition 2.2. Let K X  R n be a convex, compact set and let x  X  K . We say that x is t -sparse w.r.t K if it can be written as a convex combination of t boundary points of K .
 All our algorithms produce t -sparse prediction at iter-ation t w.r.t. the underlying decision set K . 3.1. Algorithm.
 Algorithm 1 Online Frank-Wolfe (OFW) 1: Input parameter: constant a  X  0. 2: Initialize x 1 arbitrarily. 3: for t = 1 , 2 ,...,T do 4: Play x t and observe f t . 6: Compute v t  X  arg min x  X  X  { X  F t ( x t )  X  x } . 8: end for 3.2. Analysis.
 Define  X  t = F t ( x t )  X  F t ( x  X  t ), where F t = 1 as defined in step 1 of the algorithm, and x  X  t = arg min x  X  X  F t ( x ). The regret bounds all follow from the following general theorem: Theorem 3.1. Assume that for t = 1 , 2 ,...,T , the function f t is L -Lipschitz, Bt  X  b -smooth for some con-stants b  X  [  X  1 , 1 / 2] and B  X  0 , and St  X  s -strongly convex for some constants s  X  [0 , 1) and S  X  0 . Then in Algorithm 1, for all t &gt; 1 , we have for both the following values of C and d : and ( C,d ) = max { 9 D 2 B, 36 L 2 /S, 3 LD } , 2+2 b  X  s In either case, this bound is obtained by setting a = d  X  b in Algorithm 1.
 Proof. First, we note that d  X  1 and a  X  0 in either case since b  X  [  X  1 , 1 / 2] and s  X  [0 , 1), so that t  X  a lemma by induction on t for either values of C and d . The statement is true for t = 1 since f 1 is L -Lipschitz, so C  X  LD  X  L k x 1  X  x  X  1 k X  f 1 ( x 1 )  X  f 1 ( x  X  1 ) =  X  assume that for some t  X  1, we have  X  t  X  Ct  X  d . Now by convexity of F t we have Since x  X  t  X  X  , we have that  X  F t ( x t )  X  x  X  t  X  X  X  F t From both observations: Since f t is Bt  X  b -smooth, the smoothness of F t is bounded by 1 t P t  X  =1 B X   X  b  X  3 Bt  X  b for b  X  1 / 2. We now have F using (2). Using the inequality F t ( x  X  t )  X  F t ( x  X  the bound above we get: F since C  X  9 D 2 B . In Lemma 3.1, we show the following bound using the strong convexity of the f t functions and the parameter choices: Multiplying (3) by t , adding the above bound, and dividing by t + 1, we get
F since d  X  1, thus completing the induction.
 Lemma 3.1. In the setup of Theorem 3.1, assuming  X  t  X  Ct  X  d , we have Proof. Since f t is  X  t -strongly convex, the strong con-vexity of F t is at least since  X   X  s  X  t  X  s for all  X   X  t . Thus, since x  X  t arg min x  X  X  F t ( x ), we have by (1): which implies that k x t  X  x  X  t k  X  p C/St s/ 2  X  d/ 2 . By a similar argument, since by a simple calculation (details in the full version of this paper) we have F t +1 ( x  X  t F k x t  X  x since C  X  3 LD , s &lt; 1 and d  X  1. Thus, using the triangle inequality and the trivial bound k x t  X  x  X  t +1 D , we get k x since C  X  36 L 2 /S if d = 2+2 b  X  s 3 , and C  X  3 LD if d = 1+ b 2 . Furthermore, we have since C  X  3 LD and d  X  1. So by triangle inequality, we have Since f t +1 is L -Lipschitz, we get the required bound. 4.1. Stochastic Costs Assume now that the cost functions f t are sampled i.i.d. from some unknown distribution, and let f  X  = E [ f t ], and let x  X  = arg min x  X  X  f  X  ( x ). 4.1.1. Smooth Stochastic Costs Theorem 4.1. For  X  -smooth stochastic convex loss functions f t , there is an algorithm such that with prob-ability at least 1  X   X  , its regret is bounded as follows : Proof. For  X  -smooth stochastic convex loss functions f , the algorithm is OFW applied to the functions f t with parameter settings that we specify now. First, f t is  X  -smooth, so we can set B =  X  and b = 0. Since we make no assumptions about the strong convexity of f t , so we can set S = 0, and s = 0. For these settings, the optimal values of the parameters are d = 1+ b 2 = 1 / 2, a = d  X  b = 1 / 2, and C = max { 9 D 2  X , 3 LD } . Thus, for all t , we have: This implies that for the optimal point x  X  we have In (Shalev-Shwartz et al., 2009), Theorem 5, the fol-lowing is proved: Theorem 4.2. With probability at least 1  X   X  , for any x  X  X  and for all t = 1 , 2 ,...,T we have Using this theorem and (4), we conclude that with proability at least 1  X   X  , we have f ( x t )  X  f  X  ( x  X  )  X  C/ Summing up from t = 1 to T , we get that the regret is O ( C p nT log( nT/ X  ) log( T )) with probability at least 1  X   X  . 4.1.2. Non-smooth Stochastic Costs Theorem 4.3. For non-smooth stochastic convex loss functions f t , there is an algorithm such with probability at least 1  X   X  , its regret is bounded as follows: Proof. For non-smooth stochastic convex loss func-tions f t , the algorithm is OFW applied to the  X  t smoothing of f t , i.e. the functions  X  f t, X  t for  X  t  X  smooth, so B = no assumptions about the strong convexity of  X  f t, X  t , so we can set S = 0, and s = 0. For these settings, the optimal values of the parameters are d = 1+ b 2 = 1 / 3, a = d  X  b = 2 / 3 and C = max { 9 9  X  point x  X  , we have Since |  X  f t ( x )  X  f t ( x ) | X   X  t L = |  X 
F t ( x )  X  F t ( x ) |  X  Using the above two bounds we get that From this point, arguing as in the proof of Theo-rem 4.1, we conclude that the regret is O ( LD p nT log( nT/ X  ) log( T )) with probability at least 1  X   X  . 4.2. Adversarial Cost Functions Theorem 4.4. For adversarial cost functions f t (smooth or non-smooth), there is an algorithm that has the following regret bound. For any x  X   X  K we have: Proof. We apply the OFW algorithm to the functions  X  f t defined as follows. Suppose the algorithm plays point x t in round t , and the adversary provides the cost function f t . Define of f t at x t such that k X  f t ( x t ) k X  L .
 We now estimate the Lipschitz, smoothness, and strong convexity parameters for  X  f t . First,  X   X  f k X  f t ( x t ) k  X  L , and k x  X  x 1 k  X  D , impying that Next, note that  X  f t ( x + y )  X  Thus  X  f t is ( L/D ) t  X  1 / 4 -smooth, so we set B = L/D and set S = L/D and s = 1 / 4. For these settings, the op-timal values of the parameters are d = 2+2 b  X  s 3 = 3 / 4, a = d  X  b = 1 / 4 and C = max { 9 D 2 B, 36 L 2 /S, 3 LD } = 36 LD . Thus by Theorem 3.1, for all t , we have: where  X  F t ( x ) = 1 t P t  X  =1  X  f  X  ( x ), x  X  t = arg min Kalai &amp; Vempala (2005) prove that the  X  X e-The-Leader X  algorithm has no regret. In particular, since x  X   X  X  , By strong convexity and since x  X  t = arg min x  X  X   X  F t ( x ), we have This implies that using (5). Next, since  X  f t is 3 L -Lipschitz we get Summing up from t = 1 to T , using the bound P which implies that D 2 . By convexity of f t , we have Plugging this into (7), we get the stated bound. To evaluate the performance benefits of OFW over OGD, we experimented with a simple test applica-tion, viz. online collaborative filtering. This problem is the following. In each round, the learner is required to produce an m  X  n matrix X with trace norm (i.e. sum of singular values) bounded by  X  , a parameter. This matrix is to be interpreted as supplying by users i  X  [ m ] rating for each item j  X  [ n ]. The adversary then chooses an entry ( i,j ) and reveals the true rat-ing for it, viz. y  X  R . The learner suffers the squared loss ( X ( i,j )  X  y ) 2 . The goal is to compete with the set of all m  X  n matrices of trace norm bounded by  X  . The offline version of this problem has been exten-sively studied in recent times, see e.g. Candes &amp; Recht (2009), Jaggi &amp; Sulovsk  X y (2010), Srebro et al. (2010), Lee et al. (2010), Salakhutdinov &amp; Srebro (2010) and Shamir &amp; Shalev-Shwartz (2011).
 As mentioned previously, OGD requires computing the SVD of the matrix in each iteration, an O ( nm 2 ) time operation (assuming m  X  n ), whereas OFW requires computing the top singular vector pair, an operation that in practice runs in near-linear time in the number of non-zero entries of the matrix.
 Datasets. We used two publicly available datasets: 1. MovieLens100K (GroupLens): 100000 ratings 2. Jester1 (Goldberg et al., 2001): first 100000 rat-For simplicity, the sequence of entries ( i,j ) chosen by the adversary is the same as the original sequence in these datasets. We also experimented with a 1000  X  1000 randomly generated matrix.
 Implementation. We implemented the smooth, stochastic version of the OFW algorithm, even though the cost functions are not necessarily stochastic, mainly because of its faster convergence rate (in case of stochastic costs) and ease of implementation be-ing parameter-free. We implemented the OGD and OFW algorithms in the most straightforward fashion in MATLAB, using the sparse matrices whenever pos-sible, and the svd function for OGD and the svds func-tion for OFW with a tolerance of 10  X  5 . The running times were obtained on an 2.33GHz Intel R  X  Xeon R  X  CPU. All experiments were run in MATLAB in single-threaded mode using the -singleCompThread option. To ensure that the OFW and OGD runs completed in a reasonable amount of time (a few hours), we ran 100000 OFW iterations for both datasets, and only the first 10000 and 20000 OGD iterations for Movie-Lens100K and Jester1 respectively. The trace norm bounds used were 5000 and 200 respectively with no tuning.
 Results. Figure 1 shows the results of our exper-iments. It can be clearly seen from the left plots that OFW is significantly faster than OGD, complet-ing all its 100000 iterations much before the far fewer OGD iterations. Not only is it faster per iteration, surprisingly given that the costs are not stochastic, OFW also reduces the average squared loss faster than OGD, as can be seen from the middle plots. The right plots show that OFW is consistently around 35 times faster than OGD for the MovieLens100K dataset and around 6 times faster for the Jester1 dataset, and in fact this ratio keeps increasing as the number of iterations increases and the matrix parameter be-comes more and more dense. This is reasonable since computing the SVD of a dense matrix requires much more effort than for a sparser matrix. The reason OGD is only about 6 times faster than OFW for Jester1 is because the matrix involved is tall-and-skinny, hav-ing only 100 columns, thus making the svd function almost as fast as the svds function. In our experi-ments with 1000  X  1000 randomly generated matrices we found that OFW was as much as 150 times faster than OGD. In this paper, we gave an efficient algorithmic scheme for online convex optimization that performs one linear optimization per iteration rather than one quadratic optimization. The advantages over tradi-tional gradient-descent techniques are speed of im-plementation, parameter-independence, explicit sam-pling scheme for iterates, sparsity, and natural lazy implementation. The disadvantage is that the prov-able regret bounds are not always optimal. The major open problem left is to improve the regret bounds, or show lower bounds on the number of linear optimiza-tions necessary to obtain optimal regret with only one linear-optimization operation per iteration.
 Awerbuch, B. and Kleinberg, R. D. Online linear op-timization and adaptive routing. J. Comput. Syst. Sci. , 74(1):97 X 114, 2008.
 Candes, E. and Recht, B. Exact matrix completion via convex optimization. Foundations of Computational Mathematics , 9:717 X 772, 2009.
 Clarkson, K. L. Coresets, sparse greedy approxima-tion, and the Frank-Wolfe algorithm. ACM Trans.
Algorithms , 6:63:1 X 63:30, September 2010. ISSN 1549-6325.
 Flaxman, A., Kalai, A. T., and McMahan, H. B. On-line convex optimization in the bandit setting: gra-dient descent without a gradient. In SODA , pp. 385 X  394, 2005.
 Frank, M. and Wolfe, P. An algorithm for quadratic programming. Naval Research Logistics Quarterly , 3:149 X 154, 1956.
 Goldberg, K. Y., Roeder, T., Gupta, D., and Perkins,
C. Eigentaste: A constant time collaborative filter-ing algorithm. Inf. Retr. , 4(2):133 X 151, 2001. GroupLens. http://www.grouplens.org/node/73.
 Hannan, J. Approximation to bayes risk in repeated play. Contributions to the Theory of Games , III: 97 X 139, 1957.
 Hazan, E. Sparse approximate solutions to semidefi-nite programs. In LATIN , pp. 306 X 316, 2008.
 Hazan, E. The convex optimization approach to regret minimization. Optimization for machine learning , 1, 2011.
 Hazan, E., Kale, S., and Warmuth, M. K. Learning rotations with little regret. In COLT , pp. 144 X 154, 2010.
 Jaggi, M. Convex optimization without projection steps. CoRR , abs/1108.1170, 2011.
 Jaggi, M. and Sulovsk  X y, M. A simple algorithm for nuclear norm regularized problems. In ICML , pp. 471 X 478, 2010.
 Kalai, A. and Vempala, S. Efficient algorithms for online decision problems. Journal of Computer and System Sciences , 71(3):291 X 307, 2005.
 Lee, J., Recht, B., Salakhutdinov, R., Srebro, N., and
Tropp, J. A. Practical large-scale optimization for max-norm regularization. In NIPS , pp. 1297 X 1305, 2010.
 Nagano, K. Faster parametric submodular function minimization algorithm and applications. Math-ematical Engineering Technical Reports , METR 2007-43, July 2007.
 Salakhutdinov, R. and Srebro, N. Collaborative fil-tering in a non-uniform world: Learning with the weighted trace norm. In NIPS , pp. 2056 X 2064, 2010. Sanyal, R., Sottile, F., and Sturmfels, B. Orbitopes. Mathematika , pp. 275 X 314, July 2011.
 Schrijver, A. Combinatorial Optimization . Springer, 2003.
 Shalev-Shwartz, S., Shamir, O., Srebro, N., and Srid-haran, K. Stochastic convex optimization. In COLT , 2009.
 Shamir, O. and Shalev-Shwartz, S. Collaborative fil-tering with the trace norm: Learning, bounding, and transducing. JMLR -Proceedings Track , 19: 661 X 678, 2011.
 Srebro, N., Sridharan, K., and Tewari, A. Smoothness, low noise and fast rates. In NIPS , pp. 2199 X 2207, 2010.
 Wahba, G. Problem 65-1, a least squares estimate of satellite attitude. SIAM Review , 7(3), July 1965. Zinkevich, M. Online convex programming and gen-eralized infinitesimal gradient ascent. In ICML , pp.
