 { jack.g.conrad, khalid.al-kofahi } @thomsonreuters.com Clustering is a useful tool for helping users navigate, sum-marize, and organize large quantities of textual documents available on the Internet, in news sources, and in digital libraries. A variety of clustering methods have also been applied to the legal domain, with various degrees of success. Some unique characteristics of legal content as well as the na-ture of the legal domain present a number of challenges. For example, legal documents are often multi-topical, contain carefully crafted, professional, domain-specific language, and possess a broad and unevenly distributed coverage of legal issues. Moreover, unlike widely accessible documents on the Internet, where search and categorization services are gener-ally free, the legal profession is still largely a fee-for-service field that makes the quality (e.g., in terms of both recall and precision) a key differentiator of provided services.
This paper introduces a classification-based recursive soft clustering algorithm with built-in topic segmentation. The algorithm leverages existing legal document metadata such as topical classifications, document citations, and click stream data from user behavior databases, into a comprehensive clustering framework. Techniques associated with the algo-rithm have been applied successfully to very large databases of legal documents, which include judicial opinions, statutes, regulations, administrative materials and analytical docu-ments. Extensive evaluations were conducted to determine the efficiency and effectiveness of the proposed algorithm. Subsequent evaluations conducted by legal domain experts have demonstrated that the quality of the resulting clusters based upon this algorithm is similar to those created by do-main experts.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval X  Clustering ; H.3.5 [ Information Storage and Retrieval ]: Online Information Services X  Commercial Services
Search is but one tool of a comprehensive information re-trieval system. Other tools include recommendation, nav-igation, clustering, query suggestion, and personalization, among others. Such tools are often featured more promi-nently in a vertical domain than they are in the open Web. This is primarily because the underlying use cases are more clearly defined; more information about the users is also available; and in the case of fee-based models, information providers often deploy editorial resources in addition to al-gorithmic means to organize and index content to further support specific information needs.

Topical taxonomies and encyclopedias are two examples of editorial tools that are designed to help legal researchers dis-cover critical information via navigation. West X  X  Key Num-ber System is one noteworthy example of such a taxonomy. It segments the American system of law into common re-search and practice areas (e.g., Civil Rights, Negligence, and Pretrial Procedure). Other legal information providers, such as Lexis provide similar tools, but the Key Number System, which contains about 100,000 nodes and existed since the 1870s, is considered by many to be the gold standard. The Key Number System still has its limitations as stated in [ 9 ]. We have found that document clustering can be very ben-eficial to supplement the traditional, often manual analysis and interpretation of the legal text corpora.

Most clustering algorithms view documents as single atomic units in that they do not segment them further into topics. This is also true of some soft clustering algorithms, where soft clustering refers to the fact that a document may be assigned to multiple clusters. While this may work well for short single-topic news stories, we claim it to be ineffective for complex legal documents. For example, a judicial opin-ion may deal with a driver X  X  complaint about the liability of an automobile insurer, where the driver caused personal injury, was denied insurance coverage, and where compen-sation was subsequently awarded by summary judgment.
Given the complexity and multi-topical nature of the ma-jority of legal documents, we developed a recursive soft clus-tering framework with a built-in topic segmentation algo-rithm. We have successfully applied it to millions of legal documents and generated high quality legal topical clusters. Evaluations of these machine-generated clusters by trained legal professionals were overwhelmingly positive, as the qual-ity was determined to be close to that of human-generated clusters.

Given a document, e.g., in a search result, a user is pre-sented with more documents, in a manner similar to the  X  X ore-like-this X  feature found on the open Web. However, we group the recommended documents by issues (or clus-ters), thus it can be viewed as issue-based more-like-this.
Logically, our work can be described as follows: (1) iden-tify the universe of legal issues, (2) for every legal issue, identify the set of most important documents for that issue, and (3) associate every document in our collections with one or more of these issues. The distinction between documents that are most important to a legal issue (i.e., members of a cluster), and those that are merely related to one (i.e., are associated with a cluster) is important because it allows us to distinguish between documents that are an authority on a subject and those that are merely relevant to it. Note that under such an organization, a document can be a member of some clusters and associated with others at the same time.
Collectively, these two clustering relationships produce a powerful, coherent, utility-based approach to supplementing search results with additional relevant documents, ones that sharethesamecommonissueifnotthesamecommonquery terms. Such a conceptual tool permits users to explore a topic at greater depth rather than simply surveying the topic through trial and error querying.

Figure 1 illustrates the overall workflow of the clustering processes and applications of the underlying algorithm. At the highest level, the primary tasks (described above) gener-ate the two key types of document-to-cluster relationships, (1) membership, and (2) associations (shown in the two blue boxes delineated by dotted lines). As the sub-components indicate, both the clustering membership and associations processes rely on the topic segmentation results that pre-cede them. Other significant components of the workflow include (a) merging, since the algorithm can be invoked re-cursively, and (b) labeling, which is an important piece of any outward facing rendering of the clusters. Each of these components will be discussed in the remainder of the paper to the extent necessary to explicate them.

The paper is organized as follows. Section 2 briefly dis-cusses related work. Section 3 gives a short description of the metadata available in the legal domain. Section 4 intro-duces definitions and notation used throughout this paper. Section 5 presents the overall clustering framework, which includes the topic segmentation algorithm, and the recursive clustering algorithm. Some potential applications using the generated clusters are discussed in Section 6. We describe our evaluation of cluster quality and system performance in Section 7. Finally, Section 8 concludes the work while discussing future research directions.
The ability to identify and partition a document into seg-ments is important for many Natural Language Processing (NLP) tasks, including information retrieval, summariza-tion, and text understanding. One of the most important applications of topic segmentation is the Topic Detection andTracking(TDT)task,asdescribedin[ 2 ]. Much re-search has been done on topic segmentation. Many unsu-pervised, domain independent approaches [ 7 , 13 , 27 ] exploit lexical cohesion information. The fact that related or sim-ilar words and phrases tend to be repeated in topically co-herent segments and segment boundaries often correspond to a change in the vocabulary [ 24 ]. Other approaches rely on complementary semantic knowledge extracted from dic-tionaries and thesauruses, or from collocations collected in large corpora, which use additional domain knowledge such as the use of hyponyms or synonyms [ 3 , 8 , 17 , 18 ].
Clustering is an active area of research and a variety of algorithms have been developed in recent years. Clustering algorithms can be categorized into agglomerative schemes or partitioning schemes (depending on how the final clus-ters are generated), or hard/soft clustering (depending on the nature of the membership function, i.e., whether single vs. multiple assignments are permitted). A comprehensive survey on clustering algorithms is presented in [ 4 ]. The legal community has also benefited from this technology [ 22 , 28 ].
Soft clustering is often used when algorithm designers want to capture the multi-topical nature of documents. The fuzzy C-means algorithm is one of the most widely used of these algorithms; it allows one document to be assigned to more than one cluster by using a fuzzy membership function. It has been applied to text document collections with some success [ 15 ]. However, the well-known limitation of fuzzy C-means and algorithms of this type X  X ts dependency on its initialization X  X imits their application to very large document collections. Other soft clustering solutions also exist, such as probabilistic clustering frameworks built upon Expectation-Maximization (EM) algorithms [ 6 , 23 ], Fuzzy Adaptive Res-onance Theory (Fuzzy-ART) neural network [ 16 ]andthe Suffix Tree Clustering (STC) algorithm [ 29 ], to cite a few examples.

Tagarelli and Karypis [ 26 ] incorporate document topic segmentation into their clustering framework by first break-ing documents into paragraph-based segments and then group-ing these segments into clusters using the spherical K-means algorithm. These segment-clusters, based on all the docu-ments in the collections, are then further grouped into high level clusters (segment-sets) using a  X  X uzzy X  version of the spherical K-means algorithm. In their framework, an induc-tion process is introduced to map the segment-sets clustering solution to document-level clusters in order to provide the user with a more useful organization of the input texts. In the case addressed by the authors, the text/topic segmenta-tion algorithm assumes that documents are multi-topical. It further assumes that document paragraphs represent coher-ent topics and topics shift on or around paragraph bound-aries. 2 Issues of scale are the prime differences between this work and our own. The segments with which we start are four magnitudes greater than those used in this study.
Documents in the legal domain have some unique char-acteristics. These characteristics include being intrinsically multi-topical, relying on well-crafted, domain-specific lan-guage, and possessing a broad and unevenly distributed cov-erage of legal issues.
Legal documents in the U.S. are complex in nature be-cause they are the product of a highly analytical and adver-sarial process that involves determining relevant law, inter-preting such law and applying it to the dispute to which it pertains. In doing so, courts must be careful not to diverge from established precedents or risk being overturned on ap-peal or criticized by future courts. This is because each case law document not only attempts to resolve a particular le-gal dispute, but also serves to help resolve similar disputes in the future. Legal publishers not only collect and publish the judicial opinions from the courts, but also summarize and classify them into topical taxonomies  X  such as the Key Number System (described in 3.1.3).

We mention some features of Thomson Reuters X  products below to illustrate a point about the kinds of resources le-gal publishers harness in order to offer researchers multiple entry points and search indexes into the content. Other le-gal publishers have their own analogous means of accessing their content.
A judicial opinion (or a case law document) contains a court X  X  analysis of the issues relevant to a legal dispute, ci-tations to relevant law and historical cases to support such analysis and the court X  X  decision. In other words, a judicial opinion expounds the law as applied to the case, and details the reasons upon which the judgment is based. By contrast, caselaw or legal cases refer to the collection of reported cases that forms a body of jurisprudence (i.e., the law on a par-ticular subject formed by the decided cases), and is distinct from statutes and other sources of law. Generally considered among the most important legal documents, judicial opin-ions represent the bedrock of our clustering environment. A judicial opinion typically consists of several conventional components. These include the parties involved in the case, the jurisdiction, the court and judge(s) hearing the case, the background and facts of the case, the case history (if this is an appellate court document), the holdings made by the court, and the mandate or binding legal decision. In addition, Thomson Reuters X  Westlaw System adds several annotations to these documents to summarize the points of law within and make them more accurate using a consistent language for the purposes of legal research. These include a synopsis of the case, a series of summaries of the points of law addressed in the case (3.1.2), classification of these points to a legal taxonomy (3.1.3), and an historical analysis of the case to determine whether its holdings and mandate remain intact or whether they have been overruled in part or in whole (3.1.4). Westlaw currently has just over 7 million an-notated caselaw documents in the system and an additional 5 million unannotated caselaw documents available to legal researchers. 3
Thomson Reuters X  Westlaw System creates  X  X eadnotes X  for case law documents, which are short summaries of the points of law made in the cases. A typical case law document produces approximately 7 headnotes, but cases with over one hundred headnotes are not rare. On average, about 500,000 new headnotes are created each year, and the total reposi-tory now contains over 22 million headnotes corresponding to over 7 million annotated cases. West has been writing headnotes for over 120 years and the 7 headnotes per case average is more reflective of the last 10-15 years.
Headnotes are further classified to a legal taxonomy known as the West Key Number System, an hierarchical classifica-tion of the headnotes across more than 100,000 distinct legal categories. Each category is given a unique alpha-numeric code, known as a Key Number, as its identifier along with a descriptive name. 4 An example of a headnote with its assigned key number is shown in Figure 2.
Equivalent to the links among Web pages, legal documents contain rich citation information just as documents from other domains do, such as scientific publications and patents. A case law document tends to cite previous related cases to argue for or against its legal claims; therefore, it is not unusual to have landmark cases decided by the U.S. Supreme Court with hundreds of thousands of cites to them. KeyCite, a citation system created and maintained by West, is an example of such a citation network that keeps track of these rich relations between legal documents. Two types of citations are maintained in the system, citing (out-links to other legal documents) and cited (in-links to the in-stant document). KeyCite X  X  key functionality includes: indi-cating whether a document represents good (valid) law (i.e., has a decision been overruled or weakened in a subsequent opinion?), the depth of treatment a citation may receive in the citing document, and whether the citing document di-rectly quotes the cited document. 5
These rich metadata provide useful information not only to legal researchers but also to data mining algorithms for better understanding of complicated legal issues.
Let D = { d 1 ,...,d N } denote the set of documents. Each document d i  X  D is seen as being comprised of a set of topics which contains text and other metadata information. Asetoftopics, T , is called a topic-set. We denote with T j a topic-set from a document d i , and further with T ij being the j th topic in the document d i .Alsoweuse TS =  X  set of topic-sets from all the documents in the collection.
For clustering purposes, we use C = { c 1 ,...,c M } to de-note the distinct cluster set that exists in the document col-lection D ,ofwhich c k is one cluster consisting of similar topics from different documents.

In general, the vector-space model is used to represent the documents to be clustered. A vector not only contains items from textual space, such as terms, but also contains items from other metadata, such as legal classification as-signments, citator information based on inter-document cit-ing and cited relationships, and click stream data from user behavior databases. For textual data, unless otherwise spec-ified, text term relevance is weighted by using the stan-dard tf.idf , which computes the weight of any term w as tf.idf ( w )= tf ( w )  X  log ( N/N ( w )), where tf ( w )isthenum-berofoccurrencesof w in a document (term frequency), N is the total number of documents in the collection D , and N ( w ) is the portion of text documents in N that con-tains term w . Weights for the metadata representations are defined in the next section. The length of each vector is normalized so that it is of a unit length.

The cosine similarity is applied to compute the similarity between two vectors x 1 and x 2 in the vector-space model, whichisdefinedtobe cos ( x 1 ,x 2 )=( x 1  X  x 2 ) / ( || x and || x || to be the length of a vector.
At a high level, our clustering approach consists of two steps. First, each document in the document set D is pro-cessed to identify its topic-set and the collection of topic-sets from all documents in D is aggregated to generate the topic-sets, TS . In the second step, similar topics in the topic-sets TS are grouped together to form final clusters us-ing a soft clustering algorithm. See Figure 3, where the topic sets, TS = { ts 1 ,ts 2 ,ts 3 ,...ts N } , populate clusters C = { c 1 ,...,c M } . The rest of this section describes how these two steps are performed.
The topic segmentation algorithm leverages available meta-data such as headnotes, key numbers, and citations. We found this approach to provide better results (in terms of coverage and quality of topics) over traditional topic seg-mentation algorithms that rely upon lexical cohesion and utilize only document text. For the purposes of emphasiz-ing the segmentation task, we will subsequently focus only on legal documents possessing headnotes, i.e., case law doc-........ uments. As stated in 3.1.2, headnotes are short sum-........ maries of points of law in case law documents, there-
Figure 3: Topic sets populating final soft clusters. fore have a near-complete coverage of the main legal issues in them. By grouping headnotes based on their  X  X imilari-ties X  within a case law document, it is possible to identify the main legal topics within a document.

We use the vector-space model to represent headnotes in a case law document. A headnote is represented in terms of four types of features: text, key numbers, KeyCite citations, and noun phrases. 6 Thus, a headnote feature vector, h , is composed of four separate feature components, one per feature type. The similarity between a pair of headnotes, sim ( h i ,h j ), is defined as the weighted sum of the similarities between the corresponding component vectors. The weights are determined using heuristics. 7
The similarity functions for the component vectors are defined as follows. For text-related features (i.e., headnote text and noun phrases) we use cosine similarity with a tf.idf weighting scheme. An analogous similarity function is also used for the key number features, where each key number is treated as if it was a word. For the KeyCite component vector we define similarity in terms of co-citations: in which cite ( h i  X  h j ) represents the number of documents that cite both headnotes h i and h j ,and cite ( h i  X  h j number of documents that cite either headnote h i or h j .
An agglomerative clustering algorithm groups similar head-notes to generate the topic-set for a document. The algo-rithm merges two headnotes together while maximizing the following equations, where  X  is the intra-cluster similarity and is the inter-cluster similarity, k denotes the total number of topics in a document, T denotes the topic-set for a document, T r de-notes an individual topic, and n r is the number of headnotes in the topic T r .Also, T r and T represents the center of a single topic and all topics, respectively.

Notice that the algorithm does not require the number of topics as an input parameter; rather, it depends on an intra-topic similarity threshold to control the granularity of the topics in a document. The threshold is determined empiri-cally by analyzing the histogram of intra-cluster similarities. We use a set of documents with known topic-segmentations to guide our threshold selection process.
The above document segmentation process resulted in a large number of topics, over 10 million in total. Clearly, many of these topics are duplicative and thus called for fur-ther merging or clustering. This section describes the clus-tering process.

First, we needed to reduce computational complexity of the underlying problem. We do this in two ways: we reduced the dimensionality of the topics themselves, and we reduced the computational complexity of the clustering algorithm.
We performed aggressive feature selection to reduce the dimensionality of the topics from hundreds of words, noun phrases, and key numbers to a much smaller set. We use a ranker support vector machine (SVM) [ 25 ] to rank noun phrases in a cluster, and select the top n most descriptive and discriminative ones ( n was set empirically to 5).
We then used a technique similar to that described in [ 21 ] to reduce the computational complexity of the algorithm. In [ 21 ], McCallum, et al. describe a  X  X anopy X  based clustering technique for large and high-dimensional data sets. The main idea is to use a cheap, approximate distance measure to efficiently divide the data into overlapping subsets, or  X  X anopies X  and then apply (traditional) clustering algorithms by measuring exact distances only between points that occur in a common canopy. This reduces the overall computational complexity of clustering dramatically.

Our methods are similar in that we first index the set of 10 million+ topics and for each topic we retrieve the top n most similar topics using several simple features. To merge topics, we use measurements in more extensive feature sets, but only against the set of most similar topics, thus pro-ducing dramatic improvements in processing speed without negatively affecting quality.

A topic can be a member of as many clusters as appropri-ate, a general property of soft clustering algorithms. A seed topic is a topic that can start its own cluster. However, a topic that is already a member of another cluster cannot be used as a seed for a new cluster. This means that the result-ing clusters are order dependent. To increase the likelihood that popular topics are represented in their own clusters we order topics according to their popularity (in terms of num-ber of citations to the headnotes in a cluster), and start with most popular topics first.

We used a document classification engine, CaRE [ 1 ], to retrieve similar topics (clusters). CaRE allows the utiliza-tion of an ensemble of classifiers and comes equipped with a number of meta-classifiers to be used to combine the re-sults of individual classifiers. For each topic (e.g., cluster), we have three classifiers  X  one per feature type  X  headnote texts, key numbers, and citation patterns. Other indexing engines (e.g., Lucene 8 ) could have been used.

Given a seed topic, we use CaRE to retrieve a pool of candidate topics. We then use a ranker SVM to determine which of the topics in the candidate pool can be merged with the seed topic. To do this, we represent each seed-candidate pair in terms of a feature vector. The features include CaRE scores, as well as the four similarity functions described in section 5.1. In addition, the feature vector includes a co-click similarity feature. The basic idea is that documents that are frequently viewed (clicked on) in the same session, by different users, tend to share common topics. This feature is computed as follows: coclick sim ( d i ,d j )= coclick ( d i in which coclick ( d i  X  d j ) represents the number of times that both documents d i and d j have been clicked in the same session, and coclick ( d i  X  d j ) is the number of times that either document d i or d j has been clicked in all sessions.
The above similarity features are then used to train a ranker SVM to rank clusters in the retrieved pool and top ranked clusters are then merged into the seed cluster.
The algorithm is designed as a recursive process such that multiple rounds can be performed if needed. The initial input of the algorithm is the set of 10 million+ topics, and the output of each round is the input to subsequent rounds. The process stops when the inter-cluster similarities between any two clusters are lower than a predefined threshold if a subsequent merge took place. In all, we performed 3 rounds. After the first round, we ended up with 1.4 million clusters, and these were further reduced to approximately 360,000 clusters after the third and final round.
WereliedupontwoLinuxservers,eachwith32GBRAM, and two quad core 2.66 MHz CPUs. One of them was used for the central clustering and merging tasks and the other for CaRE similarity services. These servers reduced processing time from days to tens of hours. Table 1 contains a sample of clusters as well as their metadata. Notice that the ma-jority of the 360,000 clusters are jurisdiction neutral. The clusters represent the universe of legal issues, some of which are state specific, others are federal and others are a mix of both. However, not all legal issues are represented in all jurisdictions. In fact, the resulting clusters only contain de-scriptions of legal issues. The process of  X  X opulating X  these clusters with legal documents is evaluated in section 7.
No clustering algorithm is complete without a discussion about labeling. As one can see in Table 1, cluster labels are hierarchical (separated by  X / X ) and coherent. The algorithm for generating these labels is quite complex and will be the subject of another paper.
By design, clusters are meant to contain the most impor-tant case law documents on a legal topic. Hence, not every case law document is a member of a cluster. Yet although clusters are case-centric, they are also populated with other types of legal documents such as statutes, regulations, ad-ministrative decisions. The utility of clusters as a means to organize legal content around issues or topics is as much a function of the quality of the clusters themselves as it is a function of their coverage. Without this universal coverage, one could not envision an issue-based  X  X ore like this, X  where legal researchers can discover topics related to a document they are examining or dig deeper into a topic of interest. In other words, it is critical that most if not all legal documents (regardless of their type) be linked to these clusters. To ad-dress this challenge, we designed a process by which docu-ments are associated with (or linked to) existing clusters. In other words, clustering defines the space of legal topics as well as the most important case law documents which are cluster members under that topic, while association indexes all types of legal content relative to the discovered topics.
As such, association is not part of the algorithm for cluster membership , but we mention it here because it significantly improves the utility of the resulting clusters. Very briefly, the document association algorithm consists of two steps: (1) segment documents into topics and (2) associate topics with clusters. The document segmentation step is tailored to the various content types but is analogous to the process described in Section 4. The association step is based on the similarity between topics and clusters. In summary, we have established a two-tier relationship between documents and clusters. The strongest relationship, for the most authorita-tive documents under a given topic, is one of membership . By contrast, the second relationship for documents that re-main relevant to a given topic, is that of association .
To assess the performance of our clustering approach, we clustered the set of headnoted case law documents on West-law. This consists of about 7 million U.S. case law docu-ments, and collectively contains more than 22 million head-notes classified to about 100,000 key numbers.
We designed three different experiments as follows:
Coherence was defined as the extent to which the docu-ments in a given cluster address the same specific legal issue. Utility was defined as the usefulness of the documents in the given cluster to a legal researcher. The rationale behind why utility was assessed in addition to coherence was because it would be possible to have a cluster with a high coherence score, but not be very useful to a legal researcher, for exam-ple, if the documents contained within were clustered based upon a common dimension such as  X  X ll litigation involving a company. X  So a cluster is considered to be useful to a legal  X  X ubject matter testimony X  researcher not simply because it groups documents contain-ing a similar  X  X opic X  together, but it also presents a useful legal concept with respect to the topic. In Evaluation I the top ranked 25 case law documents were evaluated for 128 clusters. These documents were ranked by relevance to the cluster definition. For both metrics, the reviewers used a five-point Likert scale ranging from 1 (low coherence with the current cluster X  X  central topic or low utility to a legal researcher) to 5 (high coherence with the current cluster X  X  central topic or high utility to a legal researcher).
In Evaluation II, the quality was evaluated indirectly through a document association process briefly described in Section 6. The quality of the associated clusters to documents of different types was graded by expert researchers using a five-point scale from A (high quality of associated clusters) to F (low quality of associated clusters).
In Evaluation III, a group of legal professionals were in-volved in creating 10 research reports from a cross-section of U.S. jurisdictions and covering different topical areas. Each of the reports included 7 or fewer of the most authoritative documents , including both primary sources, such as case law and statutes, and secondary sources such as analytical ma-terials. Legal topics were identified manually for each of the documents by these experts. Further, they found that each of the 10 reports in this study has a common  X  X hread X  (i.e., a common legal issue) running through it. However, the com-mon thread did not always appear in each document in each of the reports.

Our algorithm was applied to the same set of reports to detect clusters in the documents. The objective of the as-sessment in this evaluation was two-fold: (1) is the clustering algorithm able to discover all the legal clusters in these doc-uments, and (2) is the clustering algorithm able to find the commonlegalissueineachofthereports.

We used precision P and recall R to measure the perfor-manceforthefirstobjective,inwhich: For the second objective, we used precision P for evalua-tion, which is defined by the number of common legal issues identified among documents in all reports divided by the number of common legal issues manually identified among documentsinallreportsbyexperts.
Table 2 shows the quality assessment by legal experts of 128 randomly selected clusters. Each cluster was given three scores, for coherence, utility, and an overall score (an addi-tional score to assess the overall cluster quality, using a sim-pler 3-point scale, A-C-F, representing high-medium-low).
The result clearly demonstrates the effectiveness of the clustering framework even when applied to such a large scale data set. The results are significantly higher than the ones reported in the authors X  earlier work in [ 9 ].
The slight discrepancy between the coherence score and utility score suggests a unique advantage of this human as-sessment. A cluster can contain highly coherent topics from different documents, but that in itself does not guarantee they will be equally useful, thus a slightly lower score for util-ity is possible. For example, a  X  X ummary judgment X  cluster is a less interesting and less useful topic to a legal researcher due to its commonality in the legal litigation process; there-fore one would expect it to receive a lower utility grade, even though it may contain highly related documents. This type of quality characteristic can only be revealed though human expert assessments. Traditional machine-generated cluster quality measurements, such as entropy and purity, as used in [ 9 ], are not suitable for this purpose.
 Average 4.11 3.93 3.97
Table 2: Quality of Randomly Selected Clusters
In Evaluation II, more than a thousand documents from different content types were run through our association al-gorithm to associate clusters to each of the documents. Be-sides cases, documents from nine other types were tested by the system. These include U.S. statutes, U.S. government regulations, U.S. secondary law materials (a.k.a. analytical materials), and others indicated in Figure 4. Figure 4 shows the quality of the associated clusters of tested documents from all ten types.

When legal experts were evaluating the quality of the as-sociated clusters, they reached a consensus on the clusters with grade A being  X  X xcellent X , B being  X  X ood X , C being  X  X cceptable X , D being  X  X arginal X , and F being  X  X oor X . In addition, the experts defined the  X  X recision rate X  as the ra-tio of A+B graded clusters, and the  X  X uccess rate X  as the ratio of A+B+C grade clusters, to the total associated clus-ters, respectively. The algorithm shows a consistently high success rate and good precision rate in documents across different content types.

One reason why two of the content types have poorer per-formance when compared to others, e.g. Analytical Ma-terials and Expert Witness Reports, is that the language used in these types is quite different. For example, a typical expert witness report is recorded in a  X  X uestion and An-swer X  format with less specific legal terminologies such as those corresponding to common layman X  X  terms. By con-trast, Analytical Materials may address more conventional legal topics. However, Analytical content is difficult as it does not follow standards in terms of style, breadth or depth of material; so without tuning the segmentation algorithm to such stylistic variations, performance is bound to suffer. As an illustration, American Law Reports (ALR) is very different from American Jurisprudence (AmJur) in terms of document and section lengths, while both are dramatically different from the format of law reviews.
Regarding the first objective, the precision and recall of the system on 10 reports across different document types is shown in the Figure 5. Overall, we achieved reasonably high precision, but the recall was quite low especially for case law documents. The main reason for this is the aggressive filtering, by adopting much higher thresholds, in the post processing of the system to achieve high precision.
For the second objective, Table 3 shows the performance of the system in each individual report, as well as overall.
In this analysis, each of the 10 reports has a common legal issue running through it. However, the common  X  X hread X  did notappearineachdocumentineachofthereports.

In summary, the experts manually created clusters by identifying a common thread through all documents in 7 of the 10 reports; our system identified a common thread through all documents in 6 of the 10 reports. In one of the reports, our system missed a common thread in one of the documents in that report, and is thus considered as a failure. Across the entire set, experts manually created clus-ters and identified the common thread in 52 of the 58 doc-uments (89.7%). Our system created clusters and identified the  X  X ommon thread X  in 51 of the 58 documents (87.9%).
As demonstrated in three different evaluations, the assess-ment of our proposed clustering system for legal documents consistently achieved significantly reliable results overall.
This paper describes a large scale soft clustering algorithm that relies on topic-segmentation. The performance of the algorithms is encouraging, especially given its validation by human legal experts through different test assessments.
Clustering large document collections remains a challeng-ing problem, especially in the legal domain where documents with multiple topics are very common. Traditional clus-tering algorithms have shown limited success in this area. In the research we have conducted, we have shown that our topic segmentation-based soft clustering framework not only successfully incorporates metadata information into the topic segmentation process for a given document, but also develops a practical soft clustering system which is highly scalable.

In this paper, we have attempted to demonstrate the util-ity of highly refined issue-based clusters created through two important kinds of document-cluster relationships. The first, membership , identifies and populates these document clusters by defining a comprehensive set of legal issues. The second, association associates these clusters with the doc-uments retrieved by users who seek  X  X ore-like-this X  func-tionality, whether or not these documents have any terms in common with the original query. As such, this paper makes three contributions to the field. First, it implements a highly practical means for defining and populating clus-ters along issue-based dimensions. Second, it demonstrates how one can expand the set of original relevant legal docu-ments using  X  X ore like this X  functionality, one that does not require the intersection between original user query terms and those in the candidate documents. And third, by fo-cusing on high precision clusters, we show how users can expand both the breadth and depth of their legal research, rather than conducting research that only surveys the doc-uments returned by a given query. This approach has been scaled initially to address O(10M) clusters, which is another strength of the underlying techniques. Users, especially le-gal researchers, often prefer to have ability to drill down and focus on key concepts within a document set as opposed to getting a high-level overview of a document collection. Attention to fine-grained legal issues, robustness and result-ing heterogeneous document clusters, and scalability are the characteristics that transform this cluster-based application into a highly resourceful research tool.

Topic segmentation for documents with little metadata information will be one focus of our future research work. Topic modeling algorithms, such as latent semantic indexing (LSI) [ 11 ] or probabilistic LSI [ 14 ], and Latent Dirichlet Al-location (LDA) [ 5 ], have been shown to be capable of model-ing topics beyond lexical coherence from text documents into some conceptual aspects of basic linguistic notations, such as synonymy and polysemy. They have yet to be applied to complex documents X  X s far as we know, such as those in the legal domain X  X nd produce promising outcomes.

The MapReduce framework introduced by Google [ 10 ]to support distributed computing on very large data sets of clusters across commodity or dedicated computers has ig-nited much excitement given its ability to tackle very large scale document processing problems [ 19 ]. The development of the Apache Lucene Mahout [ 20 ] machine learning algo-rithm libraries implemented on top of the Apache Hadoop MapReduce paradigm [ 12 ] also holds promise to resolve crit-ical problems, including those of very large scale document clustering and classification. We are looking into these sub-jects as another future research direction. We thank John Duprey, Helen Hsu, Debanjan Ghosh and Dave Seaman for their help in developing software for this work, and we are also grateful for the assistance of Julie Gleason and her team of legal experts for their detailed qual-ity assessments and invaluable feedback.
