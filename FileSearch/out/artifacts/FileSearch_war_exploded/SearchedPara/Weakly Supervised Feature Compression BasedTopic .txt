 With the rapid development of Web 2.0, various types of social media such as product reviews, microblogs and forums have provided a wealth of information that can be very helpful to access the general public X  X  sentiment and opinions. Exploring these sentiment and opinions towards to different topics are useful in many applications [12]. Besides, the sentiment mining about user generated con-tent has played an important role in user interest mining, election poll and crisis management [15, 5]. Therefore, sentiment classification has been a hot research topic in many fields.
 considering sentiment classification as text classification [24]. Mainly these meth-ods are applying supervised machine learning techniques to train a sentiment classifier from a set of labeled data and predict the unlabeled data sentiment [3, 13]. It is a key issue how to extract more complex and valuable feature [25]. A variety of feature extraction methods have been proposed, including single words [16], and other novel models [22]. Nevertheless, all these methods don X  X  take the semantic relationships between words and the document topic feature into consideration. Many studies take advantage of external knowledge to build a classification model on both labeled training data and hidden topics discovered from external knowledge [14, 7, 20, 27]. Here we extract the topic of document as feature to reduce feature dimension.
 these work mainly focus on discovering the topic of document, without any con-sideration about sentiment. Inspired by the idea of using external knowledge mentioned above, we present a general framework for building a classifier with compressed topic feature instead of word feature discovered from document in-tegrated with external knowledge. In this paper, we focus on document-level sentiment classification in conjunction with topic analysis model LDA [1], and powerful machine learning method SVM.
 several representative works related to our method. Section 3 mainly introduces the Latent Dirichlet Allocation (LDA). Section 4 mainly presents our weakly supervised feature compression approach based on topic model in detail and the experiment results based on Chinese reviews and English reviews are illustrated and discussed in Section 5. Finally, Section 6 is the conclusion. A great deal of work has been focused on the problem of sentiment classifica-tion at various levels, from document level, to sentence and word level. At the early stage, Turney [17] used an unsupervised learning algorithm with mutual information to predict the semantic orientation at the word level. Pang et al. proposed a semi-supervised machine learning algorithm by employing a subjec-tivity detector at the sentence level [11]. At the document level, Wu [21] trained sentiment classifiers for multiple domains in a collaborative way based on multi-task learning. Zhang et al. mainly proposed a method for sentiment classification based on word2vec and SV M perf [26].
 classifier using labeled corpus. Pang et al. used SVM as the classifier to classify sentiment for the first time by using the n-grams model [13]. Wang et al. used document frequency (DF), information gain (IG), chi-squared statistic (CHI) and mutual information (MI) to choose features and then used boolean weight-ing method to set feature weight and constructed a vector space model [18, 19]. Besides, a pre-training method applied to deep neural networks based on restrict-ed Boltzmann machine was proposed to gain stable classification performance over short text [10].
 ering about the topic feature of the document which can reduce the document feature dimension. Some other work has been done regarding to this direction. Earlier topic models such as LDA and PLSA [6] have mainly focused on extract-ing topics. Those models have been extended to explore text sentiment as shown in Sentiment-LDA and Dependency-Sentiment-LDA [8]. Yang et al. regard the visual feature as a mixture of Gaussian and treat the corpus of comments as a mixture of topic model [23]. Multilingual Supervised Latent Dirichlet Allocation (MLSLDA) is proposed for sentiment analysis on a multilingual corpus [2]. to extract document topic feature and reduce the feature dimension. Here we use topic model to extract document topic feature and supervised method to classify the document instead of sentiment lexicon to represent the polarity of word. At the same time we can add the polarity feature weight by integrating with the external knowledge. More details will be discussed subsequently. Topic model [1] represents each document as mixtures of (latent) topics, where each topic is a probability distribution over words. Consider a collection of M documents containing words from the vocabulary of terms { 1 ,...,V } , and let { 1 ,...,K } be a set of topics. LDA was developed based on an assumption of document generation process depicted in both Algorithm 1.
 document m ,  X  k is the word distribution for topic k and N m is the length of document m . z m,n is the topic index of n th word in document m and w m,n is a particular word for word placeholder [m,n]. We can write the joint distribution of all known and hidden variables given the Dirichlet parameters as follows. The likelihood of a document w m is obtained by integrating over  X  m ,  X  and summing over z m as follows. Finally, the likelihood of the whole data collection W = { w m } M m =1 is as follows: which is a popular Markov chain Monte Carlo algorithm to sample from complex high dimensional distributions. In each step, the algorithm randomly samples a topic assignment for a word w i conditioned on the topic assignments of all other words. More formally, in each Gibbs sampling step, the algorithm replaces z i by a topic drawn from the distribution p ( z i | z  X  i ,w ) which is given by: excluding the current assignment and n ( k ) m,  X  i is the number of words in document m assigned to topic k except the current assignment. Samples obtained from the Markov chain are then used to estimate the distributions  X  and  X  as follows. The standard LDA topic model is completely unsupervised, and determines top-ics for words entirely based on the co-occurrence patterns of words across doc-uments. Here we mainly take advantage of weakly supervised topic model to extract document topic feature.
 for the traditional LDA model, aiming at improving document polarity feature weight on English dataset and Chinese dataset. The English and Chinese external knowledge A which all contain 5000 positive reviews and 5000 negative reviews are obtained from the NLPCC 2014 sentiment analysis task 1 . Here the external knowledge should be high-quality for the classified document, so the data type should be same. We mainly use the external knowledge to bias the weight of document polarity, so the topic feature which can represent polarity is most important. Phan et al. integrates external knowledge topic distribution with the original document and builds a classifier on both labeled training data and hidden topics discovered from the external knowledge [14]. By contrast, the purpose of our approach is to bias the topic-word distribution  X  k,t in favor of the words that are frequently annotated with topic k in A, while the document-topic distribution  X  m,k is in favor of topics that frequently occur in document m in A. tribution  X  k,t over words associated with each topic k, the distribution  X  m,k over topics for each document m.
 is the number of times of term t which is assigned topic k in A. Similarly, we can show that  X  m,k has a Dirichlet posterior with hyper-parameters  X  k +  X  k m where  X  m is the number of annotated terms in document m that are assigned topic k in A. Finally, we get the conditional probability that z i = k (for word w i = t in document m ) given the observed external knowledge A as: p ( z i = k | z  X  i ,w, X , X  ) = excluding the current assignment and n ( k ) m,  X  i is the number of words in document m assigned to topic k except the current assignment.
 pling equation above by adding the prior counts  X  t k and  X  k m observed in A to assignment for a word (in each Gibbs sampling step) in favor of topics that fre-quently appear in A for either the word or the document containing it. Further-more, this topic bias spreads to other occurrences of the word in the document corpus as well as to co-occurring words, and recursively through them to more words. Samples obtained from the Markov chain are then used to estimate the distributions  X  and  X  as follows. 1 ( z a denotes the topic assignment for words in A). Regarding the combination of the external knowledge A and documents D as A  X  D , we only sample topic for words in D while keeping the topics for words in A fixed at z a and save the result using Algorithm 2 where M represents the document number of A  X  D . to improve the corresponding document polarity feature weight. Here we describe how we present the document feature to build a classifier. Document m contains N m words as { w 1 ,w 2 ,...,w N m } . At last, we use ELDA to get the document-topic distribution  X  m,k to represent feature of document m as { p m 1 ,p m 2 ,...,p mk } which can reduce document dimension to get the compressed feature at the same time. p mk represents the probability that topic k is associated with document m. In this section, we mainly present the experiment results. Firstly we introduce t-wo real-word sentiment datasets in the experiment. We evaluate the performance of our approach by comparing it with other methods and explore the influence of parameter setting on the performance of our approach. 5.1 Data Preparation Two publicly available datasets are used in our experiment which contain the famous Amazon product review dataset [21] first used and the hotel review dataset in Chinese 2 . The Amazon dataset contains four different categories of product reviews crawled from Amazon.com including Book, DVD, Electronics and Kitchen. The detailed statistics are summarized in Table 1.
 are converted to lower cases. We mainly use JieBa Tokenization 3 to process hotel review dataset and all stopwords are removed. We take advantage of 5-fold cross-validation to select the most appropriate parameters of the classifier. We randomly allocate 80 percent of the data as training dataset, and the rest is used as testing dataset. We conduct each experiment ten times independently and select the average result as the final result. 5.2 Performance Evaluation tiveness of our approach. Here we compare the proposed method with other baselines in terms of accuracy, precision, recall and F1-score. The detailed base-lines are shown as follows.  X  NB-SVM: We use the Naive Bayes with Support Vector Machine (NB- X  Word2Vec-RNN: It is used for extracting the feature of document word.  X  LDA-SVM: It mainly extracts the hidden topics from user reviews [9]. It  X  sLDA-SVM: It is a supervised latent dirichlet allocation, a statistical model  X  ELDA-SVM: It employs the proposed ELDA method which leverages ex-performs the baselines in both datasets. NB-SVM only considers word-of-bag fea-ture and Word2Vec-RNN just translates the document word to the n-dimensional vector. LDA-SVM incorporates topic models to represent the feature of review in-formation. However it doesn X  X  present the sentiment feature specially. Although sLDA-SVM introduces supervised dirichlet allocation, it is more focusing on document label without considering the document word sentiment weight. By contrast, the proposed method compresses the document feature and increases the weight of sentiment feature with the introduction of the external knowledge. 5.3 Results with Different Topics We also conduct experiment to see how classification accuracy changes if we change the number of hidden topics. We estimate LDA model, sLDA model and ELDA model for the Amazon review dataset and the hotel review dataset with different topic number T  X  { 20 , 40 , 60 , 80 , 100 , 120 , 140 , 160 } . After doing topic inference, SVM classifiers are built on the training dataset according to different topic number. Then we use the remaining dataset to test and measure classifi-cation accuracy. Here we choose to show the change of classification accuracy in the Book, Electronic, all Amazon dataset and hotel dataset. As can be seen from Fig.1 (a, b, c), LDA-SVM, sLDA-SVM and ELDA-SVM have a significant im-provement over the baselines in all of dataset. Especially in Book, there is around 12 percent improvement at T = 140 over the NB-SVM baseline and around 14 percent improvement at T = 140 over the Word2Vec-RNN baseline. From Fig.1 (d) we also can find that ELDA-SVM can perform significantly better than all the state-of-the-art baseline methods when T = 100 and T = 120 in terms of accuracy on Chinese dataset.
 same tendency and they all perform much better (actually the best results in the experiment) when T = 120 on electronic dataset. We also can find that ELDA-SVM can perform better than sLDA-SVM along with the rising topic number. The ELDA-SVM appears to be a more appropriate model design for document sentiment classification. hotel dataset is shown in Fig.2 (a, b). It also clearly shows that ELDA-SVM can achieve higher performance in document sentiment classification. 5.4 Results with Different Gibbs Sampling Iterations fication accuracy. We have estimated different LDA models on the datasets with parameters of each model, we ran 1000 Gibbs Sampling iteration, and saved the sampling result at every 200 iterations. At last, we use these results to validate the accuracy of sentiment classification. In Fig.3 (a, b) we present the accuracy of LDA-SVM, sLDA-SVM and ELDA-SVM with different numbers of Gibbs sam-pling iterations when the topic is set 100. It is not hard to find that ELDA-SVM can perform better than other baselines after 600 iterations. Besides, we present the accuracy of ELDA-SVM according to the topics and the Gibbs sampling iteration on total Amazon dataset in Fig.4 (a) and on hotel dataset in Fig.4 (b). We can find the accuracy tends gradually in stability after about 600 iterations, although it is difficult to control the convergence of Gibbs Sampling. In this paper, we introduce ELDA, a LDA-based new method for extracting document feature , to reach the goal of feature compression. Here we regard the hidden topic as the feature of the document and leverage external knowledge to bias the document-topic distribution. Then we use SVM as the classifier and the experimental results clearly show that our method can outperform the baselines significantly on both datasets in terms of classification accuracy. Fig. 4: (a)-(b) Accuracy changes with topic and Gibbs sampling iterations
