
Contrasting collections of data is an important objecti ve in data mining and sequences are a particularly important form of data. In this paper , we introduce a new type of pat-tern that is useful for contrasting collections of sequences, called a Minimal Distinguishing Subsequence (MDS) . A distinguishing subsequence is a subsequence that appears frequently in one class of sequences, yet infrequently in an-other . A distinguishing subsequence is minimal if none of its subsequences is distinguishing. A key property of an MDS is that its items do not have to appear consecuti vely  X  there may be gaps between them. As mentioned in [4], in the analysis of purchase beha viours, web-logs and biochem-ical data (e.g. motifs research), sequence patterns with gaps are often much more useful than ones with no gaps.
There are man y situations where MDSs can be applied, such as the comparison of proteins, design of microarrays, characterisation of text and the building of classication models. We give two specic examples to highlight the idea.
 Example 1.1 When comparing the two protein families zf-C2H2 and zf-CCHC, we disco ver ed a protein section CLHH appearing as a subsequence 141 times among a total of 196 protein sequences in zf-C2H2, but never appearing among the 208 sequences in zf-CCHC. This subsequence repr e-sents a very strong contr ast featur e, that is potentially in-ter esting to biolo gists. From a classication per spective , an unknown protein sequence containing CLHH as a sub-sequence seems unlik ely to be a member of the zf-CCHC family .
 Indeed the potential usefulness of contrasts for protein datasets is highlighted by [12 ], where it is observ ed that bi-ologists are very interested in identifying signicant subse-quences that discriminate between outer membrane proteins and non-outer membrane proteins. Furthermore, the higher dimensional structure of proteins mak es allo wing gaps in a subsequence particularly important. Elements which have a gap between them in the sequence, may in fact be spatially very close in the 3-dimensional protein.
 Example 1.2 Comparing the rst and last books from the Bible , we found that the subsequences  X having horns X ,  X faces wor ship X ,  X stones price X  and  X ornaments price X  appear multiple times in sentences in the Book of Re vela-tion, but never in the Book of Genesis. (The gap between the two wor ds of eac h pair is 6 non trivial wor ds.) Suc h pair s might be seen as a ng erprint associated with the Book of Re velation and may be of inter est to Biblical scholar s. Items in an MDS do not necessarily have to appear immedi-ately next to each other in the original sequences. Ho we ver, subsequences in which items are far away from each other are lik ely to be less meaningful than those whose items are close in the original sequence. A key focus, therefore, is to set a maximum gap constraint when mining the MDS set. This restricts the distance between neighbouring elements of the subsequence. The benets are that the mining output is smaller and more intuiti ve and the mining process can be faster .
 Challenges : Several challenges arise in the mining of MDSs. The rst is that the Apriori property does not hold for distinguishing subsequences (unlik e it does for frequent subsequences), meaning that the subsequences of a distin-guishing sequence are not necessarily distinguishing them-selv es. Hence, any bottom up mining strate gy needs to em-plo y extra techniques for pruning the search space. This is especially important, since the search space is exponential and the number of MDS patterns present in the data may also be very lar ge.

The second challenge is that the MDS' s frequenc y threshold cannot be set as high as it is in frequent subse-quence mining. There, for some of the dense databases, the thresholds may need to be set to at least 80% [13 ]. Using the same thresholds for MDS mining is lik ely to result in empty output. In MDS mining, thresholds usually belo w 30% are needed for dense databases.

The third challenge arises with respect to the gap con-straint. Gap constraints have been considered in other con-texts, such as episode pattern mining [9, 3]. Techniques there rely upon storing all possible occurrences in a list. For each candidate, a scan through the list is performed to test if it fullls the gap constraint. This may be workable in pure frequent pattern mining under high frequenc y thresholds. Ho we ver, since the gap constraint is not class preserv ed (see Section 3 for a brief explanation) [16 ] and the search space is potentially lar ger in MDS mining, the position list may be very lar ge and thus such scans become very costly . Our contrib utions : Besides introducing the concept of minimal distinguishing subsequences, we describe a new algorithm called ConSGapMiner (Con trast S equences with Gap Miner ), to efciently mine the complete MDS set for a (maximum) gap constraint. We emplo y a novel technique using efcient bitset and boolean operations, to determine whether a candidate subsequence can satisfy the gap con-straint. We also emplo y several other pruning strate gies.
Experimental analysis sho ws that ConSGapMiner is able to efciently mine MDSs from some very dense real-w orld databases, using a relati vely low frequenc y threshold. In-deed, using the gap constraints, it is able to mine patterns for some very long proteins, in circumstances that would challenge the current generation of frequent subsequence miners.
 Related Work : Emer ging patterns, introduced by [5], can be used to build high accurac y classication models in rela-tional databases ([8 ]). It is dif cult to translate the mining techniques for emer ging patterns to sequential databases, since the order in which items occur in sequential data is signicant and items may also occur multiple times. Con-trasts for relational data have been considered in other work as well, see [2] and [14 ] for details.

In [4], the related concept of emer ging substrings is in-troduced. These are strings of items used to dif ferentiate between two classes of sequences. A suf x tree is used to store all the substrings. Because substrings are a special case of subsequences using maximum gap as 0, our frame-work can also be used to mine minimal distinguishing sub-strings. Ho we ver, since the items in subsequences may not necessarily appear consecuti vely , the use of a suf x tree is unsuitable for mining them. Also, the search space is lar ger and consequently the mining problem is more dif cult.
An algorithm is given in [6] to mine a single best subse-quence pattern maximising some function, which describes pattern goodness (and could describe a contrast). It does not enumerate a collection patterns.

Work in [7] examines the useful feature space for se-quence databases. The algorithm used is SP ADE [17 ], re-lying on the Apriori property . Thus, any contrast patterns it nds must have all their subsequences being contrast as well. This assumption isn' t true for MDS patterns.
References [16 ] and [9] consider sequential pattern min-ing with gap constraints. Ho we ver, their algorithm stores all occurrences for a given candidate in a list, which needs to be scanned when checking the gap constraint. This idea becomes less effecti ve in situations where the alphabet size and support thresholds are small and man y long sequences need to be check ed (such as in protein datasets).
There exists a lar ge body of work on nding motif pat-terns for protein sequences (see e.g. [10 ]). Such patterns are related to MDSs, but are far more general and thus much more dif cult to mine. The y also tak e into account various biological constraints and usually have 100% support. Or ganisation : Section 2 introduces the basic concepts used and Section 3 describes the ConSGapMiner algorithm. Ex-perimental results are given in Section 4, follo wed by dis-cussion in Section 5 and conclusion in Section 6.
Let I be a set of distinct items. We call I the alphabet and j I j the size of the alphabet. A sequence S over I is an ordered list of items, denoted as e 1 e 2 e 3 ::: e n , where e 1 i n . For example, DN A sequences are sequences over the alphabet of f A , C , G , T g , and the Declaration of Inde-pendence document is a sequence over the alphabet consist-ing of English words. We write S [ i ] to denote the i -th item of S , namely e i . Note that the sequences we consider are uni variate sequences, i.e. each element of the sequence is a single item. Although more general sequence denitions exist, the uni variate representation is able to capture some of the most important and popular sequences, such as DN A, proteins, documents and Web-logs.

A sequence S 0 is a subsequence of a sequence S = e e 2 e 3 ::: e n (and S is a supersequence of S 0 ), written as S 0 S , if S 0 = e i S 0 is a substring of S if i j + 1 = i j + 1 for all 1 j &lt; example, AB is a subsequence of ACBC but BA isn' t, and CBC is a substring of ACBC .
 Denition 2.1 (Max-Prex) A sequence e 1 e 2 e 3 ::: e n 's max-prex is e 1 e 2 e 3 ::: e n 1 . The max-pr ex is formed by remo v-ing the last item in S.
 Example 2.1 ABC is the max-pr ex of ABCD while AB isn' t. Accor ding to our denition, a sequence has exactly one max-pr ex.
 Denition 2.2 (Subsequence Occurrence) Given a se-quence S = e 1 e 2 e 3 ::: e n and a subsequence S 0 = e 0 rence of S 0 in S if 1 i k n and e 0 k = e i and i k &lt; i k + 1 for eac h 1 k &lt; m.
 Example 2.2 For the sequence S=A CA CBCB and subse-quence S 0 =AB, ther e are 4 occurr ences of S 0 in S: f 1,5 f 1,7 g , f 3,5 g and f 3,7 g .
 We now dene the gap constraints, which restrict the allo wed distance between items of subsequences in se-quences.
 Denition 2.3 (Gap constraint and satisfaction) A (max-imum) gap constr aint is specied by a positive inte ger g. Given a sequence S = e 1 e 2 ::: e n and an occurr ence o i i 2 ::: i m of a subsequence S 0 , if i k + 1 i k g + 1 8 f 1 ::: m 1 g , then we say the occurr ence o s fullls the g-gap constr aint. Otherwise we say o s fails the g-gap con-str aint. If ther e is at least one occurr ence of a subsequence S 0 fullling the g-gap constr aint, we say S 0 fullls the g-gap constr aint. Otherwise S 0 fails the g-gap constr aint. Example 2.3 In Example 2.2, only the occurr ence f 3,5 g fullls the 1 -gap constr aint. Thus, the subsequence S 0 ful-lls the 1 -gap constr aint since at least one of its occurr ences does. No occurr ence of S 0 fullls the 0 -gap constr aint and so S 0 fails the 0 -gap constr aint.

Given a set of sequences D , a sequential pattern p and a gap constraint g , the count of p in D with g -gap constraint, denoted as coun t D ( p ; g ) , is the number of sequences in D in which p appears as a subsequence fullling the g -gap constraint. The (relati ve) support of p in D with g -gap con-straint is dened as supp D ( p ; g ) = coun t D ( p ; g ) tive threshold d , if supp D ( p ; g ) d , we say p is frequent in D with g -gap constraint. Otherwise p is infrequent. Denition 2.4 ( g -MDS and the g -MDS mining problem) Given two classes of sequences pos (the positive) and neg (the negative), two support thr esholds d and a , and a max-imum gap 1 g, a pattern p is called a Minimal Distinguish-ing Subsequence with g-gap constr aint (g-MDS for short), if and only if the following conditions are true: 1. Frequency condition: supp pos ( p ; g ) d ; 2. Infrequency condition: supp neg ( p ; g ) a ; 3. Minimality condition: Ther e is no subsequence of p Given pos, neg, d , a and g, the g-MDS mining problem is to nd all the g-MDSs.
 The minimality condition is very important, because it both reduces output size and impro ves performance, as well as making patterns more succinct.

Similar to JEPs ([8 ]) we will place special emphasis on those g -MDSs satisfying a = 0 (ne ver appearing in the neg-ative class). In the experimental section, we focus on the g -MDS mining problem with a = 0. Our techniques are of course applicable for any value of a .
 Example 2.4 Given the two sets of sequences shown in Ta-ble 1, suppose d = 1 = 3 (and a = 0 ) and g = 1 . The 1 -MDSs are f BB, CC, BAA, CB A g . Notice that BB is a sub-sequence of all the negative sequences, if no gap constr aint is used. Howe ver all the occurr ences of BB in the nega-tive fail the 1 -gap constr aint, so BB becomes a distinguish-ing subsequence when g = 1 . Observe that every super se-quence of an 1 -MDS fullling the 1 -gap constr aint and sup-port thr eshold is also distinguishing . Howe ver , these are excluded from the MDS set, since the y are non-minimal and contain redundant information. We now introduce our algorithm kno wn as ConSGap-Miner , for solving the g -MDS mining problem. It operates in three stages. In the rst stage, a candidate c is generated. In the next stage, its frequenc y support and gap satisf action is computed for both the pos and neg . If supp pos ( c ; and supp neg ( c ; g ) a , then c is retained. Finally , in the third stage, post processing is used to remo ve all the non-minimal answers and yield the nal g -MDS set. We now discuss each of these stages in turn.
ConSGapMiner performs a depth-rst search in a lex-icographic sequence tree, similar to frequent subsequence mining techniques such as [1, 15, 11]. In the lexico-graphic sequence tree, each node contains a sequence s (we will interchangeably refer to nodes and the sequences the y represent), a value for coun t pos ( s ; g ) and a value for coun t neg ( s ; g ) . Each node is the max-prex of each of its children. During the depth-rst search, we extend the cur -rent node by a single item from the alphabet, according to a certain lexicographic order . For (the sequence of) each newly-generated node n , we calculate its supports from pos and from neg .
 Example 3.1 Part of the lexico graphic tree for mining the database from Table 1 is given in Figur e 1. Observe that the branc hes of the lexico graphic tree terminate at nodes whose coun t pos = 0 .
 Two basic pruning strate gies can be applied to reduce the size of the search space of the tree. These will be applied in the candidate generation process.

Non-Minimal Distinguishing Pruning : This strate gy is based on the fact that any supersequence of a distinguishing sequence cannot be a minimal one. Suppose we encounter a node representing sequence s , where c is the last item in s and supp pos ( s ; g ) d and supp neg ( s ; g ) a . Then i) we need never extend s and ii) need never extend any of the sibling nodes of s by the item c . Such an extension would lead to a supersequence of s and wouldn' t be an MDS. Example 3.2 In Figur e 1, because supp neg ( AA CC ) = 0 , AA CC must be distinguishing and we know in the subtr ee of its sibling AA CB, supp neg ( AA CBC ) must be 0 , too. So AA CBC can' t be an MDS.
 Max-Prex Infrequency Pruning : Whene ver a candidate isn' t frequent in pos , then none of its descendants in the tree can be frequent. Thus, whene ver we come across a node s , where supp pos ( s ; g ) &lt; d , we don' t need to extend this node any further . For example, in Figure 1, it is not necessary to extend AAB (which has support zero in pos ), since no frequent sequence can be found in its subtree.

It is worth noting that this technique does not generalise to full a-priori lik e pruning - X if a subsequence is infrequent Pr ocedur e 1 Candidate Gen( c , g , I , d , a ): Generate new can-didates from sequence c in pos , then no supersequence of it can be frequent X . Such a statement is not true, because the gap constraint is not class preserv ed [16 ]. This means that an infrequent sequence' s supersequence is not always necessarily infrequent and con-sequently increases the dif culty of our problem. Indeed, extending an infrequent subsequence by appending will not lead to a frequent sequence, but extensions by inserting items in the middle of the subsequence may lead to a fre-quent subsequence. An example situation is given next. Example 3.3 For Figur e 1, suppose d = 1 = 3 and g = 1 . Then AAB is not a frequent pattern because coun t pos ( AAB ; 1 ) = 0 . But looking at AAB' s sibling , the subtr ee rooted at AA C, we see that coun t pos ( AA CB ; So her e, a super sequence (AA CB) is frequent, but its subse-quence (AAB) is infr equent.

The algorithm for candidate generation is given in Pro-cedure 1. Assume MDS is set to empty initially . It is called at the top level by Candidate Gen ( fg ; g ; I ; d ; a ) .
For each newly-generated candidate c , coun t pos ( c ; g and coun t neg ( c ; g ) must be computed. The main challenge comes in checking satisf action of the gap constraint. A can-didate can occur man y times within a single positi ve se-quence. A straightforw ard idea for gap checking would be to record the occurrences of each candidate in a separate list. When extending the candidate, a scan of the list determines whether or not the extension is legal, by checking whether the gap between the end position and the item being ap-pended is smaller than the (maximum) gap constraint value for each occurrence. This idea becomes inef fecti ve in sit-uations with small alphabet size and support threshold and man y long sequences needing to be check ed, since the oc-currence list becomes unmanageably lar ge. Instead, we use a new method for gap checking, based on a bitset represen-tation of subsequences and the use of boolean operations. This technique is described next.
 Denition 3.1 (Bitset) A bitset is a sequence of bits whic h eac h tak es the value 0 or 1 . An n-bitset X contains n bits, and X [ i ] refer s to the i-th bit of X .

We use a bitset to describe how a sequence can occur within another sequence. Suppose we have a sequence S = e 1 e 2 e 3 ::: e n , and another sequence S 0 , which is no longer than S . The occurrence(s) of S 0 in S can be represented by an n -bitset. This n -bitset BS is dened as follo ws: If both i) there exists a supersequence of S 0 of the form e 1 e 2 ( i n ) and ii) e i is the nal item of S 0 , then BS [ i ] otherwise it is set to 0. For example, if S=B ACA CBCCB , the 9-bitset representing S 0 = AB is 000001001. This indicates how the subsequence AB can occur in BACA CBCCB , with a '1' being turned on in each nal position where the subse-quence AB could be embedded. If S 0 isn' t a subsequence of S , then the bitset representing the occurrences of S 0 consists of all zeros.

For the special case where S 0 is a single item, i.e. S 0 then BS [ i ] is set to 1 if e i = e . In the last example, the 9-bitset representing the single item C is 001010110.

It will be necessary to compare a given subsequence against multiple other sequences. In this case, the subse-quence will have associated with it an array of bitsets, where the k -th bitset describes the occurrences of S 0 in the k -th se-quence.

Initial Bitset Construction: Before mining begins, it is necessary to construct the bitsets that describe how each item of the alphabet occurs in each sequence from the pos and neg datasets. So, each item i has associated with it an array of j pos j + j neg j bitsets. For a given item, the number of bitsets in its array which contain one or more 1's, is equal to coun t ( i ; g ) .
 Example 3.4 Consider the database in Table 1.
 A's arr ay of bitsets contains 5 elements and is [ 0010 ; 11000 ; 00110 ; 0010 ; 101 00 ] . Also, coun t pos and coun t neg ( A ; g ) = 2 .
 Bitset Checking: Each candidate node c in the lexico-graphic tree has a bitset array associated with it, which de-scribes how the sequence for that node can occur in each of the j pos j + j neg j sequences. This bitset array can be directly used to compute coun t pos ( c ; g ) and coun t neg (i.e. coun t pos ( c ; g ) is just the number of bitsets in the array not equal to zero, that describe positi ve sequences). During mining, we extend a node c to get a new candidate c 0 , by ap-pending some item i . Before we can compute coun t pos ( c 0 and coun t neg ( c 0 ; g ) , we rst need to compute the bitset array for c 0 . The bitset array for c 0 is calculated using the bitset array for c and the bitset array for item i and is done in two stages.

Sta ge 1: Using the bitset array for c , we generate another array of corresponding mask bitsets. Each mask bitset cap-tures all the valid extensions of c , with respect to the gap constraint, for a particular sequence in pos [ neg . Suppose the maximum gap is g , for a given bitset b in the bitset array of c . We perform g + 1 times of right shift of it by distance 1, with 0s lling the leftmost bits. This results in g + 1 intermediate bitsets, one for each stage of the shift. By OR-ing together all the intermediate bitsets, we obtain the nal mask bitset m deri ved from b . The mask bitset array for c consists of all such mask bitsets.
 Example 3.5 Taking the last bitset 10100 in the previous example and setting g = 1 , the process is: 01111 is the mask bitset derived from bitset 10100 .
Intuiti vely , a mask bitset m generated from a bitset b , closes all 1s in b (by setting them to 0) and opens the fol-lowing g + 1 bits (by setting them to 1). In this way, m can accept only 1s within a g + 1 distance from the 1s in b .
Sta ge 2: We use the mask bitset array for c and the bitset array for item i , to calculate the bitset array for c 0 which is the result of appending i to c . Consider a sequence s in pos [ neg and suppose the mask bitset describing it is m and the bitset for item i is t . The bitset describing the occurrence of c 0 in s , is equal to m AND t . If the bitset of the new candidate c 0 doesn' t contain any 1, we can conclude that this candidate is not a subsequence of s with g -gap constraint. Example 3.6 ANDing 01111 (the mask bitset for sequence A) from the last example with C's bitset 00010 , gives us AC's bitset 00010 .

Taking the last sequence in Table 1, AB ACB, B's 5 -bitset is 01001 and its mask 5 -bitset is: So BB' s bitset is: 00110 AND 01001 = 00000 . This means BB is not a subsequence of AB ACB with 1 -gap constr aint. Example 3.7 Figur e 2 shows the process of getting the bitset arr ay BB from B. From the gur e we can see coun t pos ( BB ; 1 ) = 2 and coun t neg ( BB ; 1 ) = 0 .
The task of computing bitset arrays can be done very efciently . Modern computer architectures have very fast implementations of shift operations and logical operations. Since the maximum gaps are usually small (e.g. less Pr ocedur e 2 Support Count( c 0 , g , D ): calculate supp than 20), the total number of right shifts and logical op-erations needed is not too lar ge. Consequently , calculat-ing supp pos ( c ; g ) and supp neg ( c ; g ) can be done extremely quickly . The algorithm for support counting is given in Pro-cedure 2.
The patterns returned by Procedure 1 are not necessarily all minimal. For example, in Figure 1, we will get ACC , which is a supersequence of the distinguishing sequence CC . Thus, in order to get the g -MDS set, post-processing minimization is needed.

A nai ve idea for remo ving non-minimal sequences from a set, is to check each one against all the others, remo ving it if it is a supersequence of at least one other . For n se-quences, this leads to an O ( n 2 ) algorithm, which is expen-sive if n is lar ge. We impro ve on this basic idea by making use of two properties of non-minimal sequences.
 Theor em 3.1 Let S and S 0 be two distinguishing sequences returned by Procedur e 1. If S 0 is a subsequence of S, then Pr operty 1 j S 0 jj S j and Pr operty 2 S and S 0 must shar e the same nal item.
The proof is omitted here for space considerations and will be pro vided in a companion full paper .

Property 1 means that it is not necessary to check if a sequence is a superset of any longer sequence. This prop-erty is in fact true for any pair of subsequences, not just the distinguishing ones returned by Procedure 1. Property 2 means that each sequence need only be compared with those which share a common nal item. This property is only true for the sequences returned by Procedure 1. It isn' t true for arbitrary sequences. The actual minimization is performed as follo ws. We use the well-kno wn prex tree structure. For each item i in the alphabet, a prex tree pt is built. Sequences having nal item i are inserted into pt in order of length. At each insertion, the sequence being inserted is check ed to see whether it is a supersequence of any sequence in the prex tree and discarded if this is the case. In this section, we study the performance of ConSGap-Miner , as well as analysing some of the properties of the g -MDSs that we mine. No comparison is made against other systems, since we are not aware of any other work that is suitable for mining g -MDSs. A number of experiments on both protein families and Bible books have been carried out. These two sequence types represent some interesting real-w orld applications. On the one hand, protein families use a relati vely small alphabet (20 amino acids), each con-taining relati vely few sequences with long average length. On the other hand, books of the Bible are built on a lar ge alphabet (se veral thousand words), and have thousands of sentences of small average length. The protein families were selected from PF am: Protein Family Database ( http://www.sanger.ac. uk/Software/Pfam/ ) and the Bible books were downloaded from http://www.o-bible.c om/dlb.html . In all experi-ments, a (the maximum frequenc y in threshold for neg ) was set to zero and the experiments were run on a 3 : 0GHz Intel Xeon PC, with 4 gigabytes of main memory , running UNIX.
 Pr otein Families : The protein families that we used are listed in Table 2. These represent some challenging situa-
Family 1 (a): runtime vs d , for
Family 2 (a): runtime vs d , for
Family 3 (a): runtime vs d , for
Bible: runtime vs d for g = 6. Bible: runtime vs g for d tions and their sizes are representati ve for protein families. In Figure 3, we give the running time for varying frequenc y thresholds(refer to a) and (maximum) gap size (refer to b). We can see that as the maximum gap becomes lar ger , or as the frequenc y threshold d becomes lower , more time is required for mining. An important reason for this is that the MDS output size increases dramatically in both situa-tions. e.g. Take the nal pair of protein families in Table 2. When g = 5 and d = 24 : 3%, there are 20936 5-MDSs out-put. Changing d to 5.4%, the output size jumps to 3600822. For the same dataset with d = 27% and g = 3, the output size is 536, whereas for d = 27% and g = 7, it is 314791. The smaller the maximum gap is, the earlier a candidate is lik ely to become distinguishing (being less lik ely to appear in the neg ) and so earlier pruning of the search space is pos-sible. Similarly , earlier pruning is possible for high values of the frequenc y constraint d , since it is more dif cult to sat-isfy for longer (and thus lower) sequence nodes in the tree. Furthermore, the longer sequences in the pos and neg are, the more time ConSGapMiner needs, since it has to search to deeper levels in the lexicographic tree.
 We also examined the distrib ution of the 5-MDS for the TatC vs. TatD DNase. The y are approximately normally distrib uted around a mean length (i.e. the number of items in a pattern) of 7 8. There were some patterns with lengths 11, despite the gap size being 5. This reects the ability of g -MDS to capture long patterns. Indeed for these length 11 patterns, it would be permitted for there to be an occurrence where the rst item' s position and last item' s position are separated by distance of as much as ( 11 1 ) 5 = 50. Books of the Bible : We conducted experiments using sen-tences from the books of the Bible as sequences. This kind of sequential data dif fers from protein data, due to its lar ge alphabet size, much smaller sequence length and lar ger number of sequences. We used all sentences in the rst four books of the Ne w Testament (Matthe w, Mark, Luk e and John) as the positi ve class and all sentences in the the rst four books of the Old Testament (Genesis, Exodus, Le viticus and Numbers) as the negati ve class. In order to obtain meaningful patterns, we remo ved all the punctuation and frequently appearing words such as  X and X ,  X the X ,  X of X . Each sentence corresponds to a separate sequence. There are 3768 sequences in pos , 4893 sequences in neg , and a total (alphabet size) of 3344 unique words. Average sen-tence length is 7 words and the maximum is 25. The Exper -imental results are sho wn in Figure 3. Looking at these g-ures, we can see that ConSGapMiner operates much faster on this kind of data. The lar ger alphabet means that non-minimal distinguishing pruning happens very early in the lexicographic tree, while the small average length means the tree cannot become too deep. Table 3 lists some of the patterns returned when mining the 6-MDS. Both contigu-ous patterns (substrings) and non-contiguous patterns (sub-sequences) are sho wn, with the number of times the y oc-cur . Ob viously , for human understanding of the patterns, the meaning of the substrings is more straightforw ard than subsequences. Ho we ver, subsequence contrasts can some-times capture combinations of interesting words that are not found by substrings.

Effect of Pruning : We have seen the effect of vary-ing the parameters g and d . We also conducted a number of other experiments (not sho wn due to lack of space) to evaluate the power of the dif ferent pruning techniques. As expected, the Max-Prex infrequenc y pruning gives sub-stantial savings, similar to using the frequenc y constraint for frequent subsequence mining. By emplo ying the non-minimal distinguishing pruning strate gy, ConSGapMiner usually gains a speedup of factor two and the pattern size before minimization shrinks by a factor of four . The time tak en for the minimization post-processing is insignicant.
The results in the pre vious section are only a snapshot of the experiments we performed. We also tested ConSGap-Miner on a number of other protein datasets, with overall performance being similar .

The performance of ConSGapMiner is very pleasing overall. Ho we ver, as mentioned, the number of MDS pat-terns present for high dimensional datasets can be very lar ge. Gap size is certainly an important way of reducing this output size, but it would be useful to emplo y other con-straints as well. Using a length constraint (restricting the maximum number of items in an MDS) is straightforw ard within our frame work. Using a windo w size constraint (lim-iting the maximum gap between the rst and last item in an MDS) is more dif cult. Emplo ying bitset operations to maintain this constraint requires much more information to be maintained for each node in the lexicographic tree.
This paper has focused on presenting an efcient algo-rithm for mining g -MDS patterns. There is also the related question of how such patterns may be used. We belie ve these patterns are interesting, due to their intuiti ve, human understandable form and ability to capture strong contrasts. Similar to emer ging patterns ([8 ]), we belie ve g -MDSs will be useful for building classiers. Studying classication may also allo w examination of the tradeof fs between choos-ing an appropriate pos frequenc y threshold d and gap size, versus the quality of the g -MDS patterns that are mined.
We have introduced the problem of minimal distinguish-ing subsequences . These patterns can capture essential con-trast information between dif ferent classes of sequences.
We studied the efcient mining of minimal distin-guishing subsequences and made the follo wing major contrib utions: (a) A prex gro wth frame work for mining g -MDSs, utilising a number of pruning techniques. (b) A bitset operation based technique for checking gap con-straints. Analysis and experiments sho w that our approach works well for a number of datasets, particularly high dimensional proteins.

