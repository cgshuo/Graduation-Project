 Large-scale networks of sensing devices have become increasingly pervasive, with applications ranging from sensor networks and mobile robot teams to emergency response systems. Often, nodes in these networks need to perform probabilistic dynamic inference to combine a sequence of local, noisy observations into a global, joint estimate of the system state. For example, robots in a team may combine local laser range scans, collected over time, to obtain a global map of the environment; nodes in a camera network may combine a set of image sequences to recognize moving objects in a heavily cluttered scene. A simple approach to probabilistic dynamic inference is to collect the data to a central location, where the processing is performed. Yet, collecting all the observations is often impractical in large networks, especially if the nodes have a limited supply of energy and commu-nicate over a wireless network. Instead, the nodes need to collaborate, to solve the inference task in a distributed manner. Such distributed inference techniques are also necessary in online control applications, where nodes of the network need estimates of the state in order to make decisions. formed centrally. For example, in linear systems with Gaussian noise, the inference tasks can be solved in a closed form with a Kalman Filter [3]; for large systems, assumed density filtering can often be used to approximate the filtered estimate with a tractable distribution ( c.f. , [2]). Unfortu-nately, distributed dynamic inference is substantially more challenging. Since the observations are distributed across the network, nodes must coordinate to incorporate each others X  observations and propagate their estimates from one time step to the next. Online operation requires the algorithm to degrade gracefully when nodes run out of processing time before the observations propagate throughout the network. Furthermore, the algorithm needs to robustly address node failures and interference that may partition the communication network into several disconnected components. of processes modeled by dynamic Bayesian networks. In our algorithm, each node maintains a (possibly approximate) marginal distribution over a subset of state variables, conditioned on the measurements made by the nodes in the network. At each time step, the nodes condition on the observations, using a modification of the robust (static) distributed inference algorithm [7], and then advance their estimates to the next time step locally. The algorithm guarantees that, with sufficient communication at each time step, the nodes obtain the same solution as the corresponding centralized algorithm [2]. Before convergence, the algorithm introduces principled approximations in the form of independence assertions in the node estimates and in the transition model. tion their estimates on all the observations in the network, e.g., when interference causes a network partition, or when high latency prevents messages from reaching every node. Once the estimates are advanced to the next time step, it is difficult to condition on the observations made in the past [10]. Hence, the beliefs at the nodes may be conditioned on different evidence and no longer form a con-sistent global probability distribution over the state space. We show that such inconsistencies can lead to poor results when nodes attempt to combine their estimates. Nevertheless, it is often possible to use the inconsistent estimates to form an informative globally consistent distribution; we refer to this task as alignment . We propose an online algorithm, optimized conditional alignment ( OCA ), that obtains the global distribution as a product of conditionals from local estimates and optimizes over different orderings to select a global distribution of minimal entropy. We also propose an al-ternative, more global optimization approach that minimizes a KL divergence-based criterion and provides accurate solutions even when the communication network is highly fragmented.
 distributed camera localization [5]. These results demonstrate the convergence properties of the algorithm, its robustness to message loss and network partitions, and the effectiveness of our method at recovering from inconsistencies.
 ticle filtering (PF) techniques have been applied to these settings: Zhao et al. [11] use (mostly) independent PFs to track moving objects, and Rosencrantz et al. [10] run PFs in parallel, sharing measurements as appropriate. Pfeffer and Tai [9] use loopy belief propagation to approximate the estimation step in a continuous-time Bayesian network. When compared to these techniques, our approach addresses several additional challenges: we do not assume point-to-point communication between nodes, we provide robustness guarantees to node failures and network partitions, and we identify and address the belief inconsistency problem that arises in distributed systems. Following [7], we assume a network model where each node can perform local computations and communicate with other nodes over some channel. The nodes of the network may change over time: existing nodes can fail, and new nodes may be introduced. We assume a message-level error model: messages are either received without error, or they are not received at all. The likelihood of successful transmissions (link qualities) are unknown and can change over time, and link qualities of several node pairs may be correlated.
 processes , X = { X 1 ,...,X L } and a set of observed measurement processes Z = { Z 1 ,...,Z K } ; each measurement process Z k corresponds to one of the sensors on one of the nodes. State processes are not associated with unique nodes. A DBN defines a joint probability model over steps 1 ...T as The initial prior is given by a factorized probability model p ( X (1) )  X  Q h  X  ( A (1) h ) , where each A h  X  X is a subset of the state processes. The transition model factors as Q where Pa [ X ( t ) i ] are the parents of X ( t ) i in the previous time step. The measurement model factors Q n  X  X ; these are the processes about which node n wishes to reason. The nodes need to collab-orate so that each node can obtain (an approximation to) the posterior distribution over Q ( t ) n given node clocks are synchronized, so that transitions to the next time step are simultaneous. The goal of (centralized) filtering is to compute the posterior distribution p ( X ( t ) | z (1: t ) ) for t = 1 , 2 ,... as the observations z (1) , z (2) ,... arrive. The basic approach is to recursively com-all conditional independence structure. An effective approach, proposed by Boyen and Koller [2], independence assertions encoded in a junction tree [3]. Given a junction tree T , with cliques { C i } and separators S i,j , the projection operation amounts to computing the clique marginals, hence the filtered distribution is approximated as where N T and E T are the nodes and edges of T , respectively. With this representation, the es-timation step is implemented by multiplying each observation likelihood p ( z ( t ) k | Pa [ Z ( t ) k ]) to a clique marginal; the clique and separator potentials are then recomputed with message passing, so that the posterior distribution is once again written as a ratio of clique and separator marginals: compute the marginals over the clique at the next time step p ( C ( t +1) i | z (1: t ) ) . In principle, the centralized filtering approach described in the previous section could be applied to a distributed system, e.g., by communicating the observations made in the network to a central location that performs all computations, and distributing the answer to every node in the network. While conceptually simple, this approach has substantial drawbacks, including the high communication bandwidth, the introduction of a single point of failure to the system, and the fact that nodes do not have valid estimates when the network is partitioned. In this section, we present a distributed filtering algorithm where each node obtains an approximation to the posterior distribution over subset of the state variables. Our estimation step builds on the robust distributed inference algorithm of Paskin et al. [7, 8], while the prediction, roll-up, and projection steps are performed locally at each node. 4.1 Estimation as a robust distributed probabilistic inference In the distributed inference approach of Paskin et al. [8], the nodes collaborate so that each node n can obtain the posterior distribution over some set of variables Q n given all measurements made throughout the network. In our setting, Q n contains the variables in a subset L n of the cliques used in our assumed density representation. In their architecture, nodes form a distributed data structure along a routing tree in the network, where each node in this tree is associated with a cluster of variables D n that includes Q n , as well as any other variables, needed to preserve the flow of information between the nodes, a property equivalent to the running intersection property in junction trees [3]. We refer to this tree as the network junction tree , and, for clarity, we refer to the junction tree used for the assumed density as the external junction tree .
 ence algorithm, RDPI [7], for static inference settings, where nodes compute the posterior distribu-tion p ( Q n | z ) over Q n given all measurements throughout the network z . RDPI provides two crucial properties: convergence , if there are no network partitions, these distributed estimates converge to the true posteriors; and, smooth degradation even before convergence, the estimates provide a prin-cipled approximation to the true posterior (which introduces additional independence assertions). only the marginals of the prior distribution { p ( C i ) : i  X  L n } for a subset of cliques L n in the external junction tree, and its local observation model p ( z n | Pa [ Z n ]) for each of its sensors. We assume that Pa [ Z n ]  X  C i for some i  X  L n ; thus,  X  n is represented as a collection of priors over cliques of variables, and of observation likelihood functions over these variables. Messages are then sent between neighboring nodes, in an analogous fashion to the sum-product algorithm for junction trees [3]. However, messages in RDPI are always represented as a collection of priors {  X  i ( C i ) } over cliques of variables C i , and of measurement likelihood functions {  X  i ( C i ) } over these cliques. This decomposition into prior and likelihood factors is the key to the robustness properties of the algorithm [7]. With sufficient communication,  X  n converges to p ( Q n | z ) .
 observation about these variables, or to 1 otherwise. Through message passing  X  n converges to Property 1. Let  X  n be the result computed by the RDPI algorithm at convergence at node n . Then the cliques in  X  n form a subtree of an external junction tree that covers Q n . 4.2 Prediction, roll-up and projection The previous section shows that the estimation step can be implemented in a distributed manner, L n . In order to advance to the next time step, each node must perform prediction and roll-up, be computed by multiplying this subtree with the transition model p ( X ( t +1) | Pa [ X ( t +1) ]) for each X projection: after completing the estimation step, each node selects a subtree of the (global) exter-nal junction tree that covers Pa [ C ( t +1) i ] and collects the marginals of this tree from other nodes in the network. Unfortunately, it is unclear how to allocate the running time between estimation and collection of marginals in time-critical applications, when the estimation step may not run to com-pletion. Instead, we propose a simple approach that performs both steps at once: run the distributed inference algorithm, described in the previous section, to obtain the posterior distribution over the parents of each clique maintained at the node. This task can be accomplished by ensuring that these parent variables are included in the query variables of node n : Pa [ C ( t +1) i ]  X  Q n ,  X  i  X  L n . Scope [  X  n ] covered by the distribution  X  n that node n obtains may not cover the entire parent set Pa [ C ( t +1) i ] . In this case, multiplying in the standard transition model is equivalent to assum-ing an uniform prior for the missing variables, which can lead to very poor solutions in prac-tice. When the transition model is learned from data, p ( X ( t +1) | Pa [ X ( t +1) ]) is usually com-an improved solution for the prediction and roll-up steps, when we do not have a distribution over the entire parent set Pa [ C ( t +1) i ] . Specifically, we obtain a valid approximate transition model to introducing an additional independence assertion to the model: at time step t + 1 , X ( t +1) is 4.3 Summary of the algorithm Our distributed approximate filtering algorithm can be summarized as follows: nication, our distributed algorithm obtains the same solution as the centralized B &amp; K 98 algorithm: Theorem 1. For a set of nodes running our distributed filtering algorithm, if at each time step there is sufficient communication for the RDPI algorithm to converge, and the network is not partitioned, is equal to the distribution obtained by the B &amp; K 98 algorithm with assumed density given by T . In the previous section, we introduced an algorithm for distributed filtering with dynamic Bayesian networks that, with sufficient communication, converges to the centralized B &amp; K 98 algorithm. In some settings, for example when interference causes a network partition, messages may not be prop-agated long enough to guarantee convergence before nodes must roll-up to the next time step. Con-sider the example, illustrated in Figure 1, in which a network of cameras localizes itself by observing a moving object. Each camera i carries a clique marginal over the location of the object M ( t ) , its own camera pose variable C i , and the pose of one of its neighboring cameras:  X  1 ( C 1 , 2 ,M ( t ) ) ,  X  ( C 2 , 3 ,M ( t ) ) , and  X  3 ( C 3 , 4 ,M ( t ) ) . Suppose communication were interrupted due to a network partition: observations would not propagate, and the marginals carried by the nodes would no longer form a consistent distribution, in the sense that  X  1 ,  X  2 ,  X  3 might not agree on their marginals, measured, for example, by the root-mean-square error of the estimates). For simplicity of notation, we omit time indices t and conditioning on the past evidence z (1: t  X  1) throughout this section. 5.1 Optimized conditional alignment One way to define a consistent distribution  X  p is to start from a root node r , e.g., 1, and allow each clique marginal to decide the conditional density of C i given its parent, e.g., This density  X  p 1 forms a coherent distribution over C 1:4 ,M , and we say that  X  p 1 is rooted at node 1. Thus,  X  1 fully defines the marginal density over C 1 , 2 ,M ,  X  2 defines the conditional density of C 3 given C 2 ,M , and so on. If node 3 were the root, then node 1 would only contribute  X  1 ( C 1 | C 2 ,M ) , and we would obtain a different approximate distribution.
 root node r  X  N T , the distribution obtained by conditional alignment from r can be written as where up ( i ) denotes the upstream neighbor of i on the (unique) path between r and i . imates the true prior. Suppose that, in the example in Figure 1, the nodes on the left side of the par-tition do not observe the person while the communication is interrupted, and the prior marginals  X  1 ,  X  2 are uncertain about M . If we were to align the distribution from  X  2 , multiplying  X  3 ( C 4 | C 3 ,M ) into the marginal  X  2 ( C 2 , 3 ,M ) would result in a distribution that is uncertain in both M and C 4 (Figure 1(b)), while a better choice of root could provide a much better estimate (Figure 1(c)). resulting distribution  X  p r . For example, the entropy of  X  p 2 in the previous example can be written as where we use the fact that, for Gaussians, the conditional entropy of C 4 given C 3 , M only depends the best root would exploit this decomposition to compute the entropy of each  X  p 2 , and pick the root that leads to a lowest total entropy; the running time of this algorithm is O ( | N T | 2 ) . We propose a dynamic programming approach that significantly reduces the running time. Comparing Equation 3 with the entropy of the distribution rooted at a neighboring node 3, we see that they share a common term H  X  1 ( C 1 | C 2 ,M ) , and H  X  p 4 2 , 3 is positive, node 2 is a better root than 3 , 4 2 , 3 is negative, we have the reverse situation. Thus, when comparing neighboring nodes as root candidates, the difference in entropy of the resulting distribution is simply the difference in entropy their local distributions assign to their separator. This property generalizes to the following dynamic programming algorithm that determines the root r with minimal H  X  p Intuitively, the message m i  X  j represents the loss (entropy) with root node j , compared to the best root on i  X  X  side of the tree. Ties between nodes, if any, can be resolved using node IDs. 5.2 Distributed optimized conditional alignment In the absence of an additional procedure, RDPI can be viewed as performing conditional alignment. However, the alignment is applied to the local belief at each node, rather than the global distribution, and the nodes may not agree on the choice of the root r . Thus, the network is not guaranteed to reach a globally consistent, aligned distribution. In this section, we show that RDPI can be extended to incorporate the optimized conditional alignment ( OCA ) algorithm from the previous section. for the assumed density. Conceptually, if we were to apply OCA to this subtree, the node would have an aligned distribution, but nodes may not be consistent with each other. Intuitively, this happens because the optimization messages m i  X  j were not propagated between different nodes.
 In the standard sum-product inference algorithm, an inference message  X  m  X  n from node m to node n is computed by marginalizing out some variables from the factor  X  + m  X  n ,  X  m  X  Q k 6 = n  X  k  X  m that combines the messages received from node m  X  X  other neighbors with node m  X  X  local belief. The inference message in RDPI involves a similar marginalization, which corresponds to pruning some cliques from  X  + m  X  n [7]. When such pruning occurs, any likelihood information  X  i ( C i ) associated with the pruned clique i is transferred to its neighbor j .
 m i  X  j , which is stored in clique j . (To compute this message, cliques must also carry their original, unaligned priors.) At convergence, the nodes will not only have a subtree of an external tree, but also the incoming optimization messages that result from pruning of all other cliques of the external tree. In order to determine the globally optimal root, each node (locally) selects a root for its subtree. If of the conditional alignment. The alignment is propagated throughout the network. If the optimal root is determined to be a clique that came from a message received from a neighbor, then the neigh-bor (or another node upstream) is the root, and node n aligns itself with respect to the neighbor X  X  message. With an additional tie-breaking rule that ensures that all the nodes make consistent choices about their subtrees [4], this procedure is equivalent to running the OCA algorithm centrally: Theorem 2. Given sufficient communication and in the absence of network partitions, nodes run-ning distributed OCA reach a globally consistent belief based on conditional alignment, selecting the root clique that leads to the joint distribution of minimal entropy. In the presence of partitions, each partition will reach a consistent belief that minimizes the entropy within this partition. 5.3 Jointly optimized alignment While conceptually simple, there are situations where such a rooted alignment will not provide a good aligned distribution. For example, if in the example in Figure 1, cameras 2 and 3 carry marginals  X  2 ( C 2 , 3 ,M ) and  X  2 0 ( C 2 , 3 ,M ) , respectively, and both observe the person, node 2 will have a better estimate of C 2 , while node 3 X  X  estimate of C 3 will be more accurate. If either node is chosen as the root, the aligned distribution will have a worse estimate of the pose of one of the cameras, because performing rooted alignment from either direction effectively overwrites the marginal of the other node. In this example, rather than fixing a root, we want an aligned distribution that attempts to simultaneously optimize the distance to both  X  2 ( C 2 , 3 ,M ) and  X  2 0 ( C 2 , 3 ,M ) . Figure 2: (a) Testbed of 25 cameras used for the SLAT experiments. (b) Convergence results for individual gence from the aligned distribution to the clique marginals  X  i ( C i ) : where q | = T denotes the constraint that  X  p factorizes according to the junction tree T . This method will often provide very good aligned distributions (e.g., Figure (d)). For Gaussian distributions, this optimization problem corresponds to where  X  C and covariances of the marginals  X  i . The problem in Equation 4 consists of two independent convex optimization problems over the means and covariances of q , respectively. The former problem can be solved in a distributed manner using distributed linear regression [6], while the latter can be solved using a distributed version of an iterative methods, such as conjugate gradient descent [1]. We evaluated our approach on two applications: a camera localization problem [5] (SLAT), in which a set of cameras simultaneously localizes itself by tracking a moving object, and tempera-ture monitoring application, analogous to the one presented in [7]. Figure 2(a) shows some of the 25 ceiling-mounted cameras used to collect the data in our camera experiments. We implemented our distributed algorithm in a network simulator that incorporates message loss and used data from these real sensors as our observations. Figure 2(b) shows the estimates obtained by three cameras in one of our experiments. Note that each camera converges to the estimate obtained by the centralized &amp; K 98 algorithm. In Figure 2(c), we evaluate the sensitivity of the algorithm to incomplete com-munication. We see that, with a modest number of rounds of communication performed in each time step, the algorithm obtains a high quality of the solution and converges to the centralized solution. Figure 3(a), the network is split into four components; in each component, the nodes communicate fully, and we evaluate the solution if the communication were to be restored after a given number of time steps. The vertical axis shows the RMS error of estimated camera locations at the end of the ex-periment. For the unaligned solution, the nodes may not agree on the estimated pose of a camera, so it is not clear which node X  X  estimate should be used in the RMS computation; the plot shows an  X  X m-niscient envelope X  of the RMS error, where, given the (unknown) true camera locations, we select the best and worst estimates available in the network for each camera X  X  pose. The results show that, in the absence of optimized alignment, inconsistencies can degrade the solution: observations col-lected after the communication is restored may not make up for the errors introduced by the partition. disconnected scenarios. Here, the sensor network is hierarchically partitioned into smaller discon-nected components by selecting a random cut through the largest component. The communication is restored shortly before the end of the experiment. Figures 3(b) shows the importance of aligning from the correct node: the difference between the optimized root and an arbitrarily chosen root is significant, particularly when the network becomes more and more fractured. In our experiments, large errors often resulted from the nodes having uncertain beliefs, hence justifying the objective function. We see that the jointly optimized alignment described in Section 5.3, min. KL , tends to provide the best aligned distribution, though often close to the optimized root, which is simpler Figure 3: Comparison of the alignment methods. (a) RMS error vs. duration of the partition. For the unaligned to compute. Finally, 3(c) shows the alignment results on the temperature monitoring application. Compared to SLAT, the effects of network partitions on the results for the temperature data are less severe. One contributing factor is that every node in a partition is making local temperature obser-vations, and the approximate transition model for temperatures in each partition is quite accurate, hence all the nodes continue to adjust their estimates meaningfully while the partition is in progress. This paper presents a new distributed approach to approximate dynamic filtering based on a dis-tributed representation of the assumed density in the network. Distributed filtering is performed by first conditioning on evidence using a robust distributed inference algorithm [7], and then advancing to the next time step locally. With sufficient communication in each time step, our distributed algo-rithm converges to the centralized B &amp; K 98 solution. In addition, we identify a significant challenge for probabilistic inference in dynamical systems: nodes can have inconsistent beliefs about the cur-rent state of the system, and an ineffective handling of this situation can lead to very poor estimates of the global state. We address this problem by developing a distributed algorithm that obtains an informative consistent distribution, optimizing over various choices of the root node, and an alterna-tive joint optimization approach that minimizes a KL divergence-based criterion. We demonstrate the effectiveness of our approach on a suite of experimental results on real-world sensor data. Acknowledgments This research was supported by grants NSF-NeTS CNS-0625518 and CNS-0428738 NSF ITR. S.
 Funiak was supported by the Intel Research Scholar Program; C. Guestrin was partially supported by an Alfred P. Sloan Fellowship.

