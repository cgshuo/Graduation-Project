 It has long been held in linguistics that since the same concept can be expressed with words whose forms do not resemble each other (e.g., English dog vs. Italian cane vs. German Hund ), there is no in-trinsic link between how words sound and what they mean. This feature X  arbitrariness  X  X s often con-sidered a hallmark of human language (Saussure, 1916; Hockett, 1959). At the same time, how-ever, over the last decades, mounting evidence from psycholinguistic studies (Markel and Hamp, 1960; Ohala, 1984; Fordyce, 1989) has shown that speak-ers do in fact associate words that contain a particu-lar form with certain meaning X  X hat is, there is a de-gree of iconicity in language in addition to arbitrari-ness, which has been claimed to benefit language learning (Monaghan and Christiansen, 2006; Mon-aghan et al., 2014).

Non-arbitrary form-meaning associations come in two basic varieties: primary iconicity (also called  X  X rue X ) and secondary (or  X  X onventional X ) iconicity. In the former, the sound is thought to directly re-ter, the relationship is a statistical regularity accord-ing to which words that share similar sounds tend to be also similar in meaning, such as a large propor-tion of English words that end with the sound /- X S / (e.g., crash , slash , mash , trash , dash ) being related to destructive action or collision (Hutchins, 1998). The phonetic units that exhibit conventional mean-ing regularities of this latter kind are called phon-esthemes and are the focus of the present paper. In particular, we investigate two main questions: (1) how can the existence of phonesthemes be tested at a large scale by means of a data-driven method? and (2) how can the meaning arguably conveyed by a phonestheme be derived automatically?
Phonesthemes are traditionally distinguished from morphemes in being non-compositional. That is, unthinkable can be thought of as being com-posed of morphemes un-(meaning not ), think , and -able (meaning capable of ), all contributing to the overall meaning of  X  X ncapable of being thought X  and susceptible of being combined with other units with predictable semantic effects (e.g., un-drink-able, think-er ). On the other hand, crash is not con-sidered to be formed compositionally from cr-and -ash , since these components do not possesses an easily identifiable independent meaning that can be combined productively with other morphemes.

Because phonesthemes challenge defining fea-tures of language such as arbitrariness and compo-sitionality, they remain a rather controversial and poorly understood phenomenon. To a large extent, this is due to methodological issues. Early evi-dence for the existence of phonesthemes consisted primarily in linguists pointing out instances of in-tuitive correlations between a phonetic unit and the meaning of words containing that unit (Marchand, 1959; Reid, 1967), while early psycholinguistic ex-periments attempted to elicit meaning definitions for predefined lists of (real or nonsense) words shar-ing a phonetic unit traditionally considered to be a phonestheme (Fordyce, 1989; Abelin, 1999; Mag-nus, 2000). More systematic studies have subse-quently been carried out by Hutchins (1998) and Bergen (2004), but overall the phenomenon of con-ventional linguistic iconicity as reflected in phon-esthemes remains largely understudied, certainly within the computational linguistics community.
In this paper, we investigate phonesthemes by an-alyzing their orthographic correlates in a large cor-pus of written English, leveraging word embeddings constructed with word2vec and made available by Baroni et al. (2014). In particular, we make the fol-lowing contributions:  X  We develop a stricter test than previously done in the literature for deciding whether a unit exhibits conventional iconicity.  X  We propose a new unsupervised method to induce the meaning conveyed by a phonesthemic unit.  X  We evaluate our meaning induction method with new automatic evaluation techniques and com-pare its performance to a WordNet-based method proposed by Abramova et al. (2013), obtaining a very substantial improvement.  X  We additionally evaluate our automatically de-rived meanings with human judgments collected via a crowdsourcing experiment.
 We believe phonesthemes deserve thorough inves-tigation for both theoretical and practical reasons. Theoretically, adding more data-driven methods can substantially enhance work in linguistics and psy-cholinguistics. Within computational linguistics it-self, cross-fertilization with computational morphol-ogy (Wang et al., 2012; Marelli and Baroni, 2015), is an exciting avenue to be pursued. With respect to potential applications of automatic phonestheme meaning induction, creative brand naming (Klink, 2000;  X  Ozbal and Strapparava, 2012), sentiment anal-ysis (Sokolova and Bobicev, 2009) and construc-tion of more appropriate language teaching materi-als (Imai et al., 2008) are viable possibilities. Psycholinguistic studies on the nature of phones-themes have shown that people tend to associate cer-tain sounds with a particular meaning. Such stud-ies were conducted on different languages, employ-ing different methods and exhibiting various degrees of scale and systematicity (Fordyce, 1989; Abelin, 1999; Magnus, 2000; Hutchins, 1998). Recently, it has also been shown that phonesthemes affect online implicit language processing (Bergen, 2004) and language learning (Parault and Schwanenflugel, 2006).

What also emerged from these studies is that phonesthemes are not a homogeneous phenomenon. They can vary in terms of the number of words that contain a given phonestheme, their frequencies, the strength of their association with the core meaning of a phonestheme (for example measured as an av-erage of human ratings for all the words that com-prise the given phonesthemic cluster) and the regu-larity of that association (what proportion of words in the whole cluster are highly related to the pre-dicted meaning). However, psycholinguistic data is to some extent ambiguous on how these features of phonesthemes affect their productivity, learnabil-ity and their effect on language processing, which could partly be due the methods being employed. For example, in order to determine the regularity of sound-meaning association, Bergen (2004) consults word definitions in Websters 7th collegiate dictio-nary and counts how many of those words bear the required meaning for a given phonestheme. The pro-cedure requires an intuitive judgment from the ex-perimenter in determining the meaning of a phones-theme and estimating whether a given word has that meaning, and as a result is prone to experimenter bias and does not allow for large-scale testing. Find-ing a more automatic method for assessing phones-theme features and determining their meaning could thus alleviate this type of research liabilities.
Otis and Sagi (2008) and Abramova et al. (2013) are two studies that attempted to test for the exis-tence of phonesthemes in a corpus-based automatic manner. For both the guiding question was: are words that contain a given phonetic unit, thought to be a phonestheme, more semantically similar than would be expected by chance? Using distributional models they compared the average cosine similar-ity of the vectors that correspond to phonestheme-bearing words to similarly sized groups of random words. Both studies found support for a sizable proportion of phonetic units tested. However, it could still be questioned whether the comparison was sufficiently strict, given that sets of random words which do not overlap in form have a priori lower chance of being semantically related than sets of words that share a phonestheme. Therefore, in the first part of our study (Section 4) we present a stricter validation method for candidate phonesthemes that also includes considerations related to morphologi-cal diversity, which were ignored in previous work.
Abramova et al. (2013) presented the first at-tempt to automatically assign meaning to sets of phonestheme-bearing words. The authors viewed the task as an instance of unsupervised ontology ac-quisition in the style of Widdows (2003) and used WordNet to assign over-arching labels to phones-themic groups of words. While the approach was moderately successful in inducing WordNet labels that were in the direction predicted by the literature for a few phonesthemes (e.g., gl -containing words were assigned light-related labels), most phones-themes did not receive meaningful labels according to the meanings typically associated with phones-themes in the sound iconicity literature. The authors surmise that the failure could be due to the nature of WordNet, e.g., that it reflects only one type of semantic relation (hypernymy) which might not ex-haust the links between words that share a phones-theme. In Section 5, we present a different approach to phonestheme meaning induction that exploits the properties of word embeddings in a fully unsuper-vised manner and yields substantially better results. Candidate phonesthemes. Following the studies of Hutchins (1998), we compile a list of possible phonesthemes of interest and their respective seman-tic glosses (more on the latter in Section 5). We will refer to these units as  X  X andidate phonesthemes X  be-cause they all have been considered phonesthemes by previous qualitative studies and our aim is to investigate whether their alleged phenesthemic sta-tus is warranted quantitatively. Specifically, we fo-cus on two-consonant units in word-initial position, 16 prefix candidate phonesthemes listed in Table 1. Since we work with orthographic correlates of pho-netic units, we restrict ourselves to prefixes that have clear orthographic X  X honetic mappings, discarding prefixes that allow for variation, such as sc-/sk-. 3 Word embeddings. For our experiments, we use existing, high-quality word embeddings created and the best performing model amongst those tested by Baroni and colleagues, which has been constructed with word2vec 5 using the CBOW approach pro-posed by Mikolov et al. (2013). The model contains 400-dimension vectors generated by considering the 300K most frequent word tokens (without lemma-tization) in a large corpus comprising the English Wikipedia, the web-based corpus ukWaC (Baroni et al., 2009), and the BNC (Burnard, 2007).

Unfamiliar or very technical words are unlikely to contribute to the formation of sound-meaning associations (Hutchins, 1998). Accordingly, from the 300K target words present in the distributional model, we discard those that are not recognized by a comprehensive off-the-shelf English spell-checking dictionary. This results in a substantial reduction of the target vocabulary: 61,122 tokens remain after the corresponding embeddings in all our experiments. The aim of the first experiment is to investigate which of the candidate prefixes in Table 1 have phonesthemic character and thus evince conven-tional iconicity. 4.1 Methods For a prefix to exhibit conventional iconicity, the words sharing that prefix must be semantically simi-lar, while being morphologically diverse X  X .e., their semantic relatedness must stem from their shared sound (as captured by the prefix X  X  orthographic form), and not from their sharing of a common mor-pheme.
 Semantic similarity factors. We start by assess-ing the degree of semantic similarity exhibited by all the words in the vocabulary that share a can-didate phonestheme, which we refer to as candi-date phonesthemic clusters . Our aim is to conduct a stricter test than previously done in the litera-ture. Therefore, rather than comparing candidate phonesthemic clusters to sets of random words, as done by Otis and Sagi (2008) and Abramova et al. (2013), we compare them to words that share a ran-dom two-consonant prefix that is non-phonesthemic, i.e., not present in our list of candidate phones-themes. Our vocabulary contains a total of 307 non-phonesthemic two-consonant prefixes. We refer to the sets of words sharing these prefixes as baseline clusters . For our subsequent analyses we use only 191 baseline clusters which contain between 10 and 2000 words. Naturally, such baseline clusters will contain words that are morphologically and hence semantically related, which offers a more challeng-ing baseline.
In our first similarity test, we compute cosine sim-ilarities for all possible pairs of words within ev-ery phonesthemic and baseline cluster. We then run 191 independent-samples one-tailed Welch X  X  t -tests for each candidate phonestheme, comparing its pair-wise similarity to the pair-wise similarity of each of the baseline clusters. For each candidate phon-esthemic cluster, we record how many t -tests indi-cated significantly higher similarity than the base-line (using a Bonferroni-corrected threshold of  X  = . 05 / 191 ) as well as the effect size (Cohen X  X  d ) of the successful t -tests. Based on the binomial distribu-tion (with  X  = . 05 ), we obtain a significance thresh-old of 108 X  X e hence judge a candidate prefix to ex-hibit significantly higher similarity than the baseline if more than 108 out of 191 t -tests are successful.
Our second similarity test is a check on the over-all semantic cohesiveness of the candidate phones-themic clusters. We calculate the average of all the pairwise similarities within our 191 baseline clus-ters. We then compare the average pairwise simi-larity of each candidate phonesthemic cluster to the distribution of the average similarity of the baseline clusters. We expect a positive correlation between the number of successful t -test per candidate phon-estheme and their average similarity.
 Morphological diversity factors. Since high se-mantic similarity could be due to the presence of a large proportion of morphologically related words rather than to a sound-meaning association, we want to balance similarity-based factors with considera-tions about the morphological diversity of the word clusters we investigate. In general, the larger the size of a cluster, the higher the chance for morphological diversity and the lower the chance for finding high semantic cohesiveness. Hence, we would expect a negative correlation between cluster size and seman-tic similarity.
 In previous studies (Hutchins, 1998; Otis and Sagi, 2008) the impact of morphology is counter-acted by manually removing morphologically re-lated words before testing for semantic cohesive-ness. Since one of our aims is to minimize manual intervention, we instead take into account morpho-logical relatedness at the validation phase. To that end, we implement a crude lemmatization procedure and use the ratio between the number of words and the number of lemmas in a cluster to estimate mor-
The higher this ratio, the lower the morphological diversity X  X ith the maximum value being equal to the size of the cluster when all words are reducible to a single lemma. We calculate this proxy of morpho-logical diversity for candidate phonesthemic clusters and baseline clusters.
 Validation constraints. Given the factors de-scribed above, we judge a candidate prefix to be a phonestheme if all the following conditions hold:  X  pairwise semantic similarity is significantly  X  average effect size (Cohen X  X  d ) of pairwise simi- X  average semantic similarity is higher than 2 stan- X  ratio words/lemmas is lower than 3 standard er-We have chosen each of the thresholds to be reason-ably strong but not too restrictive since we rely on a combination of constraints. We deemed an aver-age effect size of 0 . 2 sufficient given the strictness of our comparison method. The average semantic similarity of the phonesthemic cluster was required to be at least 2 standard errors above average similar-ity of the baseline clusters to approximate the con-ventional one-tailed alpha level of 0.025. Finally, a stricter threshold of 3 standard errors was chosen for the lemma ratio just to exclude cases of prefixes that have abnormally low morphological diversity. A stricter condition (requiring high diversity) does not seem justified since there is no reason to expect phonestheme-bearing words to be more morpholog-ically diverse than average. The candidate phones-theme was judged to be significant when all con-straints were simultaneously satisfied. 4.2 Results We apply the validation methods to our data. As a sanity check, we test whether the information en-coded in the word embeddings is consistent with the data used in previous experiments: Indeed, the av-erage similarity of the 16 candidate prefixes tested is positively correlated with the human ratings for semantic cohesiveness collected by Hutchins (1998) ( r = . 46 ), and with the similarity values reported by Otis and Sagi (2008) ( r = . 68 ) and Abramova et al. (2013) ( r = . 58 ). 8
As predicted, the correlation between the average number of successful t -tests and average similarity is high ( r = . 93 ), suggesting that both methods are equally valid for evaluating semantic cohesiveness of phonesthemic clusters. Cluster size (both raw and as the number of lemmas) is negatively correlated with all semantic similarity measures, i.e. average pairwise similarity, average number of successful t -tests, and average effect size ( r  X  X  X  . 7 ). This is con-sistent with the experimental finding by Hutchins (1998), who obtained lower human ratings for larger clusters of words.

Regarding evidence for conventional iconicity, the following six prefixes meet all our validation constraints: bl-, gl-, sm-, sn-, sw-, and tw-. Of the remaining 10 prefixes tested, 3 fail all constraints ( cl-, cr-, tr-), 3 fail only the morphological diversity constraint ( gr-, sp-, st-), and the rest fail some com-a proper subset of the candidate phonesthemes val-idated according to the less strict methods used in earlier approaches: Otis and Sagi (2008) found sup-port for dr-and wr-in addition to our 6 supported phonesthemes and Abramova et al. (2013) discarded only cr-, sp-, and tr-amongst our 16 candidates. This shows that our proposed validation procedure provides a compatible as well as stricter test for evi-dence of phonesthemic conventional iconicity. The quantitative results presented so far show that, according to our validation constraints, some can-didate phonesthemes do have phonesthemic charac-ter: they are present in words that are semantically similar while not being highly morphologically re-lated. But what is the  X  X eaning X  that these phonetic units convey? In this section, we aim at investigating whether the kind of meanings that have been infor-mally proposed for these units in the sound iconic-ity literature can be derived using fully unsupervised methods.

In addition, we present ways for automatically evaluating the derived meanings, and finally conduct a human evaluation experiment via crowdsourcing. 5.1 Methods Gold standard. We construct a set of gold stan-dard meaning labels for each validated phonestheme by taking as a starting point the informal glosses provided by Hutchins (1998), who, in turn, com-piled them by inspecting previous literature by Firth (1930), Marchand (1959), Wescott (1971) and oth-ers. The glosses for our validated phonesthemes are content words (ignoring words that bear the given phonestheme to avoid circular results) and manually discard words that play only an instrumental role in the definition. For example, in the following gloss for the phonestheme sn-, we keep the words in italics and discard the rest:  X  X elated to the nose , or breath-ing ; or by metaphorical extension to snobbishness, inquisitiveness  X . Since the resulting lists of words are to some extent arbitrary (derived from intuitions of a single scholar), we extend them by manually adding synonyms of each of the initial seed words until each phonestheme is associated with 25 gold Meaning induction. We generate an abstract meaning representation for a phonestheme by com-puting the centroid of the phonestheme-bearing word cluster. Our method for inducing the core meaning conveyed by a phonestheme is then very simple: We extract the nearest neighbors of the phonestheme centroid, with the constraint that these neighboring words cannot be members of the clus-ter themselves (i.e., must not exhibit the prefix in question). This method outputs an ordered set of words or meaning labels , which we can then evalu-ate against the gold standard labels.

As described in Section 2, the only previous attempt at automatically deriving the meaning of phonesthemes is due to Abramova et al. (2013). Their approach is inspired by the work of Widdows (2003) on ontology acquisition and it consists in assigning to a phonesthemic cluster the WordNet synsets that subsume as many as possible of the clus-ter words as closely as possible (i.e., within as few as possible intervening levels in the WordNet hier-archy). As discussed in that paper, this method does not only have the disadvantage of relying on a hand-crafted ontology. Other shortcomings include Word-Net X  X  limited coverage in terms of vocabulary and type of semantic relations considered (mostly, hy-ponymy and synonymy).
 For comparison purposes, we apply the Word-Net meaning induction method of Abramova et al. (2013) and compare its performance to the unsuper-vised centroid method we propose. Automatic evaluation measures. Abramova et al. (2013) only offer an informal qualitative evaluation of their WordNet-based meaning labels. Here we propose two complementary ways of quantitatively evaluating induced phonesthemic meanings.

For our first meaning label evaluation test, we use a Monte Carlo analysis to determine whether generated labels are closer in vector space to gold labels than random sets of words. More specifi-cally, for each phonesthemic cluster, we compute the generated X  X old similarities , i.e., pairwise cosine similarities between all the generated labels and the gold set. We then create 100 sets of words, each composed of 25 words randomly drawn from the vo-cabulary and compute the random X  X old similarities , i.e., pairwise cosine similarities between these sets of random words and the gold set. Next, we run 100 independent-samples one-tailed Welch X  X  t -tests recording how many t -tests indicated significantly higher generated-gold similarity than random-gold (using a Bonferroni-corrected threshold of  X  = . 05 / 100 ). We also record the effect sizes (Cohen X  X  d ) of the successful t -tests. We repeat the proce-dure 3 times and take the average of these measures. Based on the binomial distribution (with  X  = . 05 and p = . 5 ), we judge obtaining at least 59 success-ful t -tests to indicate that the generated labels are better than random baseline at capturing the phones-themic meaning.

Our second evaluation test exploits the fact that both our centroid method and the WordNet method output ordered sets of labels (from more to less suit-able). We are interested in testing whether the gen-erated meaning labels are more similar to the gold labels the closer they are to the top of the list. To that end, we again compute the pairwise average similar-ity of each generated label with the gold label set and look at the correlation of that measure with the po-sition k of the generated label. We expect similarity to decrease as k increases: Hence a strongly neg-ative correlation indicates that the method retrieves the best labels first. 5.2 Results Automatic analysis. We compare the meaning la-bels induced with our unsupervised centroid method to those generated with the WordNet method. An overview of the results can be seen in Figure 1. Re-garding the first label evaluation test ( generated X  gold similarities vs. random X  X old similarities ; left plot in the figure), centroid overwhelmingly outper-forms WordNet: Our method obtains significant re-sults with high effect size for all phonestheme pre-fixes considered, while with the WordNet method only the labels derived for gl-are significantly more
Regarding the order-sensitive evaluation measure (ranking of induced labels, right plot in Figure 1), with the centroid method we obtain negative corre-lations for all phonesthemes, although rather weak for sw-tw-, and sm-. This shows that the top in-duced labels tend to be closer to the gold meaning. Although the WordNet method again obtains results that are poorer overall, there are strong negative cor-relations for two phonesthemes: gl-and tw-. Taken together, the results indicate that the Word-Net method might be able to generate a few of good labels at the top of the list, especially when these labels are associated with the phonestheme-bearing words by hypernymy (e.g., the top gl-labels are brightness, flash, radiance, lightness, look ). How-ever, the remaining labels are mostly generic con-cepts such as entity and object , which do not pro-duce significant results when compared as a group to the gold labels. The centroid method produces better labels overall as well as better labels at the top of the list. For example, the top gl-labels are shimmered, twinkled, satiny but it is also able to cap-ture the meaning of other phonesthemes: the pejora-tive sm-receives stunk and leered as the top two and twisting and oscillating tw- X  X  top label is waggled . Human evaluation. In addition to the automatic label evaluation procedures we have developed, we test our induced meaning labels against human judg-ments. What we aim at testing here is whether the semantic closeness to the gold standard meaning that we have been able to detect in vector space can ac-tually be perceived by speakers.

We conducted a data collection study using the the stimuli, for each of the six validated phones-themes we selected the 10 most frequent gold la-method, and 10 words randomly drawn from the vo-cabulary, with a BNC frequency of at least 100 to try to minimize the presence of words possibly un-known to the participants. The 100 cut-off is justi-fied given that the average frequency of the gold la-bels is not significantly higher than the average fre-quency of all words above this threshold ( t = 1 . 876 , p &lt; 0 . 05 ).
An annotation item consisted of the set of gold words and 10 pairs of induced-vs-random labels (randomized in order). The participants were asked to judge which of the words in each pair was more 10 annotation items per phonestheme (including the same top 10 induced labels but paired with different random words) and for each annotation item we col-lected judgments from three different subjects (thus N = 30 items per phonestheme).

To analyze the results, we counted how many times an automatically induced label was selected as more similar to the gold label set than a random word. We performed a t -test with an alternative hy-pothesis that the mean number of selected induced labels per item is greater than 5 (i.e., greater than chance since there were 10 pairs to be judged per item). Automatically induced labels for 4 out of 6 phonesthemes ( gl-, sm-, sn-and tw-) were judged to be related to the gold meaning to a higher degree than random words. Detailed results are in Table 3.
The fact that we obtain significant results indi-cates that our generated labels are meaningful not only according to automatic evaluation measures but also in terms of what speakers can perceive. However, the pattern of which phonesthemic labels receive better human judgments is somewhat less clear. For example, the appropriateness of the gl-labels is highly significant according to human judg-ment as well as both automatic tests (effect size and average similarity correlation with k). At the same time, while the sw-labels achieve a high effect size (see left plot in Figure 1), they are not judged signif-icant in our human study. The pattern is reversed for tw-. Whether this exposes a real difference in sen-sitivity to phonesthemic meanings in human judg-ments compared to vector-based methods, remains an open question. The analysis we have presented in this paper con-firms that the connection between sound and mean-ing is not always entirely arbitrary and shows that this can be detected using the properties of word em-beddings. We find, in line with previous computa-tional and psycholinguistic studies, that words that share certain phonetic prefixes without being mor-phologically related are more semantically similar that would be expected by chance. In particular, our phonestheme validation procedure is stricter com-pared to previous work since we use sets of words that share a random two-consonant prefix as base-line and, importantly, take into account morpholog-ical relatedness. According to our more principled and stricter constraints, the following six consonant prefixes exhibit symptoms of conventional sound iconicity: bl-, gl-, sm-, sn-, sw-, and tw-. The val-idation method we employ could serve as a start-ing point for discovering new phonesthemes. For example, we could inquire whether any of the two-consonant clusters that we consider a baseline is in fact a previously unrecognized phonestheme.

The second aspect we have addressed concerns the automatic induction of the meaning conveyed by a phonestheme. Up to now, the arguable meanings of phonesthemes have been approximated infor-mally by scholars (Hutchins, 1998; Bergen, 2004). To make progress on this front, we have proposed a fully unsupervised meaning induction method that relies on extracting semantic nearest neighbors of a phonesthemic cluster centroid in vector space. We have shown that this method achieves substantially better results than the WordNet-based method of our previous work (Abramova et al., 2013), generating meaning labels that are closer to the meanings pro-posed in the theoretical literature. For a subset of phonesthemes (4 out of 6: gl-, sm-, sn-and tw-), the higher suitability of the centroid-based meaning labels (as compared to random words) was also de-tected by human evaluators. Although there is ob-viously room for improvement, we think that these results are very promising given that this is the first data-driven study addressing this problem in an un-supervised manner.

