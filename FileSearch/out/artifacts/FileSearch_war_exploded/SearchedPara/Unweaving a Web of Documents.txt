 We develop an algorithmic framework to decompose a col-lection of time-stamped text documents into semantically coherent threads. Our formulation leads to a graph decom-position problem on directed acyclic graphs, for which we obtain three algorithms  X  an exact algorithm that is based on minimum cost flow and two more efficient algorithms based on maximum matching and dynamic programming that solve specific versions of the graph decomposition prob-lem. Applications of our algorithms include superior sum-marization of news search results, improved browsing par-adigms for large collections of text-intensive corpora, and integration of time-stamped documents from a variety of sources. Experimental results based on over 250,000 news articles from a major newspaper over a period of four years demonstrate that our algorithms efficiently identify robust threads of varying lengths and time-spans.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Miscellaneous Algorithms, Experimentation, Measurements News threads, Graph algorithms, Graph decomposition
Work done at the IBM Almaden Research Center. Work done while visiting the IBM Almaden Research Center.
The science of organizing and searching document collec-tions for the purpose of perusal by human users is emerging into a mature discipline. This field has evolved to a point where many basic paradigms  X  elements of information retrieval, link analysis, ranking functions, clustering tech-niques, etc.  X  may be considered well understood. On the other hand, the ubiquity of search as an important entry point into users X  interaction with large repositories of infor-mation has brought to the fore a new class of questions for scientific inquiry. Some of the prominent issues include de-veloping methodologies for searching and organizing specific collections of information  X  for example, enterprise data, e-commerce data, medical/legal libraries, news sources, desk-top data, etc. Each of these focused problems has its unique set of characteristics in terms of scale, relevant data mod-els, robustness requirements, and tolerance to spam, among other features.

In this work, we provide an algorithmic framework for the analysis of large collections of time-stamped text documents. The primary goal of our framework is to decompose a col-lection of documents into semantically significant threads . Motivation. Broadly speaking, we consider collections of documents of text in a single but arbitrary language; the only significant requirement we make is that each document have a unique time-stamp . We do not assume that the docu-ments are drawn from a single source, nor do we assume that all documents in the collection pertain to a single theme. A few motivating examples follow.

Consider an archive of news articles from one or more fairly generic sources (e.g., news feed from AP or Reuters). A convenient means to organize, summarize, browse, and search such data would benefit greatly from the decomposi-tion of the collection into threads of relevant articles. Sur-prisingly, the search facility at common sources of news ar-ticles (CNN, The New York Times, etc.) do not offer a threaded interface to their archives  X   X  X ort by date X  and  X  X ort by relevance X  appear to be the most commonly avail-able ranking options.

As an example, the query  X  X olin Powell X  produces a few thousand responses, and neither of these sorting criteria is quite adequate, especially considering the fact that arti-cles about Mr. Powell can be naturally organized into news threads corresponding to various time periods of his career (e.g., the Gulf war of 1990, his appointment as Secretary of State in 2001, his recent resignation, etc.). Furthermore, this organization is not unique, and depends on the  X  X ranu-larity X  of the decomposition  X  a long thread often consists of several shorter threads that are loosely bound together. Our framework. We propose a novel algorithmic frame-work that captures the essence of the thread decomposition problem. One of the highlights of our approach is a crisp combinatorial modeling of the problem as a graph decompo-sition problem for directed acyclic graphs. Loosely speaking, the problem is to decompose a directed acyclic graph into as few node-disjoint paths as possible while ensuring that as many nodes as possible participate in at least one path.
The graph decomposition problem we develop in this pa-per exhibits, as many graph problems do, an amazing spec-trum in terms of its computational complexity, from NP-hard incarnations to ones that admit efficient algorithms. We show that the class of instances we are interested in  X  directed and acyclic graphs  X  admits polynomial-time algo-rithms for the graph decomposition problem; this algorithm is based on minimum cost flow. We also propose a more ef-ficient two-pronged algorithmic attack for two special cases of the problem, one based on maximum matching in bipar-tite graphs, and the other based on dynamic programming. Each approach has its own advantages, depending on the scale of the problem instances. The matching-based algo-rithm needs sufficient memory to hold the graph and so is applicable only if the underlying graph is small. On the pos-itive side, matching is a well-understood graph algorithmic primitive, which allows us relatively easy use of (publicly) available and fairly well-optimized code. The dynamic pro-gramming approach we develop is tailored to be efficient in the stream X  X ort model [1], therefore admits implementa-tions that require substantially less memory than would be required to hold the graph.

A remark on relationship of our work to clustering. Threads in temporally ordered corpora offer a clean notion of clus-ters, and it is natural to ask if one may simply cluster the documents according to standard clustering algorithms, and order the documents within each cluster according to their timestamps. While this is possible in principle, in practice, one needs to examine all pairs of documents to determine their similarity or dissimilarity; our algorithms take special advantage of the temporal structure of documents and in-dices, and work with relations with O ( n ) entries, where n is the number of documents. A second advantage of our approach compared to traditional clustering is that news threads often have a natural drift of topic over time and our algorithms gracefully allow for this; in traditional clustering, a primary objective is to keep each cluster tightly focused. Experimental results. We illustrate the performance of our algorithms by presenting experimental results from a fairly large corpus of news articles (roughly 250,000 news articles that span a time period of over four years). Our experiments were conducted on the corpus of all articles, as well as on subcollections that contain specific query terms. These experiments indicate the feasibility of our algorithms at fairly large scale, and also demonstrate the efficacy of our framework in allowing the identification of several natural threads of news stories, some that span several months, and some that have rather large  X  X ormant gaps X  in the middle, which makes the task algorithmically quite challenging.
The related work falls into the following categories: topic detection and tracking, analysis of news and news events, automatic construction of hypertext and hyperlinks, and clustering/automatic identification of communities.
Topic detection and tracking (TDT) refers to automatic techniques for discovering, threading, and retrieving topi-cally related material in streams of data. The literature on TDT is extensive and we review only a few. 1 Clustering and text retrieval techniques were used by Yang et al. [25, 4] to automatically detect novel events from a temporally-ordered sequence of news stories. Statistical methods were used by Swan and Allan [22] to automatically generate an interac-tive timeline displaying major events in a corpus. Most of the work in TDT is focused on detecting new and significant events in a timeline; the usual tools are clustering and ma-chine learning. We, on the other hand, are interested in de-tecting not just the novel/major events, but all temporally and semantically connected set of events. Automatically identifying threads in document collections is also related to burst analysis and event analysis. Kleinberg [16] models the generation of bursts by a two-state automaton and proceeds to automatically detecting bursts in sequence of events; he looks for the burst of a single keyword. We, however, are interested in enumerating all threads and using all terms.
News articles and news groups have been analyzed in the context of search and data mining. Agrawal et al. [2] study the use of link-based and graph-theoretic methods to parti-tion authors into opposite camps within a given topic in the context of newsgroups. Finding news articles on the web that are relevant to news currently being broadcast was ex-plored by Henzinger et al. [14]. Uramoto and Takeda [24] describe methods for relating multiple newspaper articles based on a graph constructed from the similarity matrix. Allan et al. [5] propose several methods for constructing one-sentence temporal summaries of news stories. Smith [21] examines collocations of dates/place names to detect events in a digital library of historical documents.
There has been lot of work on automatically generating hypertext, beginning with the thesis of Allan [3]. The work most closely related to ours is that of Dalamagas and Dun-lop [8] and Dalamagas [7]. They consider the problem of automatic creation of hyperlinks for news hypertext that is tailored to the domain of newspaper archives. Their method is based on traditional clustering tools. Dalamagas [7] also explores the use of elementary graph-theoretic tools such as connected components to identify threads in news articles and builds a prototype system. Smeaton and Morrissey [20] use standard information retrieval techniques to compute a graph that is based both on node-node similarity and overall layout of the hypertext; they then use this graph to auto-matically create hyperlinks. Blustein [6] explore the problem of automatically creating hyperlinks between journal arti-cles. Green [13] develops a notion of semantic relatedness to generate hypertext. Most of these work, however, focus on examining the text of a news article and adding hyper-links to other news articles based on terms, dates, events, people, etc; they do not fully use the temporal nature of the underlying data.
E.g., http://www.lt-world.org/elf/elf/collatequery? h search=technology&amp;c technology name=Topic+ Detection&amp;exakt=ja
Our problem is also related to, yet different from, the problem of identifying communities in large graphs. Com-munity identification has been studied extensively in the context of web pages, web sites, and search results [18, 10, 17]. Like clustering, none of these algorithms uses a tempo-ral ordering of the documents.
A directed graph G = ( V, E ) consists of a set V of nodes and a set E  X  V  X  V of edges. A graph is weighted if there is a weighting function w : E  X  R + . A directed path p from u to v is a sequence of nodes u = w 1 , . . . , w k = v such that ( w i , w i +1 )  X  E for every i = 1 , . . . , k  X  1; it will be clear from the context whether we refer to the nodes or edges in a path. A directed cycle is a non-trivial directed path from u to itself. A directed acyclic graph is a directed graph with no directed cycles.
We are given a collection of documents D = { D 1 , . . . , } and the goal is to build a  X  X elevance X  graph that will help us identify the threads in the collection. Let t ( D ) give the timestamp of a document. For simplicity, we will assume that the documents can be linearly-ordered according to their timestamps with D 1 being the earliest document, i.e., i &lt; j  X  t ( D i ) &lt; t ( D j ). The goal of the graph is to express the relationship/relevance between two documents.
A natural way to construct a graph would be take every pair of documents D, D 0  X  X  and add the edge ( D, D 0 ) if and only if D and D 0 are deemed related. (We adopt the convention that whenever we add an edge between two documents D and D 0 , it is always directed from D to D 0 t ( D ) &lt; t ( D 0 ) and from D 0 to D if otherwise.) Unfortunately, this approach is not scalable. Even if |D| is only of the order of thousands, it is not possible to construct or represent this graph without compromising on efficiency and scalability.
Therefore, we take an entirely different approach to con-struct a relevance graph out of the documents. Let T = { T 1 , . . . } be the  X  X erms X  in the document collection. The set of terms is chosen by some appropriate text parsing or entity extraction mechanism and depends on the particu-lar application domain; in this section, we will not address the issue of how the terms are chosen. Suppose we build the term X  X ocument matrix M that corresponds to the terms and documents. Here, M ( D, T ) is the amount of  X  X resence X  of the term T in the document D ; once again, we will not address the issue of how M is constructed in this section (see Section 4). Our purpose is just to use this matrix M to build the relevance graph.

We illustrate the construction of the relevance graph in the case when M is binary, i.e., M ( D, T ) = 1 if and only if the term T occurs in the document D . For each term T  X  X  , we consider D T = { D 0 1 , . . . } , the set of document postings corre-sponding to the term, in order of their timestamps. Let w be a window parameter. We add the edge ( D 0 i , D 0 j ) if and only if | i  X  j | X  w , i.e., we add an edge between two documents if they are at most w apart in their ordering in D T ; note that it could very well be the case that | t ( D 0 i )  X  t ( D the end of this step, we end up with a multigraph on docu-ments. We use a simple threshold parameter  X  to  X  X ound X  the multigraph to obtain the relevance graph.

There are several merits to our way of constructing the relevance graph. Firstly, we avoid the quadratic blow up in time and space by restricting our attention to a small num-ber of document pairs. At the same time, we do not compro-mise on documents that are related to each other but do not occur close to each other in time. The window parameter w lets us control this behavior. Secondly, using the thresh-old  X  lets us have additional control in terms of rounding. By picking a suitably large threshold, documents that are brought together by small number of spurious co-occurring terms can be separated. Thirdly, it is an easy modification of our algorithm to deal with a non-binary term X  X ocument matrix, with additional information such as td X  X df; see Sec-tion 4. Fourthly, the construction can also be modified to work with a documents that not totally ordered, but just bucket-ordered. Finally, the construction of this graph for the entire document collection is a one-time step and hence does not contribute to the run-time cost.

Since we are interested in identifying threads, it suffices to work with the connected components of the relevance graph, treated the edges as undirected. To find connected components in this graph, we resort to the classical union-find algorithm. This algorithm maintains a family of sets via a standard union-find data structure. Initially, the fam-ily contains only singleton sets, each consisting of exactly one node of the graph. For every edge ( u, v ), the sets in the family containing u and v are merged. It is easy to see that after all the edges are processed, each set in the family contains the nodes of a connected component. For a sim-ple algorithm for connected components in the stream X  X ort model, see [1]. For the remainder of this section, we will find the threads in a single connected component. Threads represent directed paths in the relevance graph. Given such a graph, the problem of finding the best threads can be naturally cast in a combinatorial optimization frame-work. While there are several ways to carry out this, we adopt the following formulation. Given a directed graph, find a small number of disjoint directed paths to cover as many nodes as possible in the graph. Formally, the decision version of the ( A, B )-threads problem is stated as:
Problem 1 ( ( A, B ) -threads problem). Given a di-rected graph G = ( V, E ) and parameters A, B &gt; 0 , are there at most A node-disjoint directed paths such that the number of nodes included in the union of the paths is at least B ?
In this most general bicriteria formulation, the ( A, B )-threads problem is as hard as the Hamiltonian path problem in directed graphs [11]. If A = 1, then maximizing B is the longest path problem.

Fact 2. (1 , n ) -threads problem for directed graphs is NP-hard.
We now solve the ( A, B )-threads problem exactly for di-rected acyclic graphs. The solution is based on solving a minimum cost flow problem, for a which a polynomial time algorithm is known. To recap, in a minimum cost flow prob-lem, we are given a graph with both capacities and non-negative costs on edges and the goal is to push as much flow as possible from source to sink, while minimizing the total cost of the flow. Here, the cost is defined to be the sum over all edges, the product the edge cost and the flow through the edge. This problem can be solved in polynomial time (see, for instance, [9, 23, 12]); typically, the running time is  X  O ( nm ), where m is the number of edges. If all the costs and capacities are integral, there is an optimal integral flow as well. Furthermore, the problem can be solved in polynomial time even if some of the costs are negative, as long as the graph is acyclic.

From G , we first construct a graph G 0 = ( V 0 , E 0 ) as fol-lows. V 0 = { v 0 , v 00 | v  X  V } X  X  s, t } and E 0 = { ( v V } X  X  ( u 00 , v 0 ) | ( u, v )  X  E } X  X  ( s, v 0 ) | v  X  V } X  X  ( v v  X  V } . All the edges of the form ( v 0 , v 00 ) , v  X  V are as-signed cost  X  1 and the remaining edges are assigned cost 0. All the edges in G 0 have unit capacity.

Now, we run the minimum cost flow algorithm on G 0 to see if A units of flow can be pushed from source s to sink t . Since G 0 has unit edge capacities, an integral flow exists. G is acyclic and our construction ensures that G 0 is acyclic as well. Therefore, the algorithm can still solve the problem on G 0 even though some of its edges have negative costs.
From the construction, note that being able to route A units of flow from s to t means that there are A edge-disjoint paths in G 0 . Since the cost of each edge is  X  1, the minimum cost flow algorithm chooses to route the flow through as many edges of the form ( v 0 , v 00 ) as possible. Now, since each node v in G is split into v 0 and v 00 , edge-disjoint paths in G correspond to node-disjoint paths in G . Thus, each of the A unit flow path from s to t in G 0 corresponds to a node-disjoint path in G and if  X  B is the value of the minimum cost flow, then the total number of nodes participating in these paths is B .

Theorem 3. The above algorithm solves the ( A, B ) -threads problem for directed acyclic graphs in polynomial time.
The minimum cost formulation is quite powerful and has several advantages. Firstly, it is easy to persuade the al-gorithm to look only for threads with a minimum length ` . This can be accomplished by setting the cost of the edges ( v 00 , t ) to be + ` . Secondly, the formulation permits the dual version of the problem to be solved: given the number of documents B , minimize the number of threads A to cover all the B documents. The solution follows from the monotonic-ity of the ( A, B )-threads problem, i.e., if ( A, B )-threads is feasible, then ( A 0 , B )-threads is also feasible for all A
Finding the minimum cost flow, even though can be done in polynomial time, is prohibitively slow if the graph is mod-erately large. In the next two sections, we provide very sim-ple algorithms that permit more efficient implementations but solve weaker versions of the ( A, B )-threads problem. The first algorithm is based on bipartite matching and the second algorithm is based on dynamic programming.
We note a simple lower bound which is the inspiration behind the matching-based algorithm.

Lemma 4. B is at least the size of the maximum matching in G , when treated as an undirected graph.
 Using this, the first realization is that if we appropriately relax the bicriterion formulation of the ( A, B )-threads prob-lem, then the problem becomes simpler. The relaxation is to ignore A and just try to maximize B . Then, the problem can be solved optimally via the maximum matching algo-rithm. The only non-trivial aspect is that the matching has to be performed on a modified described below.

Given a directed acyclic graph G = ( V, E ), we construct an undirected bipartite G 0 = ( V 0 , V 00 , E 0 ). The node set V 0 = { a 0 | a  X  V } V 0 = { a 00 | a  X  V } , i.e., consists of a for every a  X  V . The edge set is given by E 0 = { ( u 0 , v ( u, v )  X  E } . Intuitively, selecting an edge ( u 0 , v sents selecting the directed edge ( u, v )  X  E and the matching constraint ensures that each node in G is matched at most once. After finding the maximum matching, the edges in the matching are referred back to the edges in G to construct the directed paths in G . We use the standard union-find data structure to recover the threads from the matched edges.
It is easy to see that a collection of threads in G of size B naturally implies a matching of size B in G 0 . Conversely, any matching of size B in G 0 can be decoded into a collection of node-disjoint paths in G ; the matching criterion translates to the node-disjointness requirement. Thus,
Lemma 5. The above algorithm solves the (  X  , B ) -threads problem in polynomial time.

While the matching-based formulation has the elegant ap-peal of solving a special case of the ( A, B )-threads problem exactly, it suffers from the following two serious shortcom-ings. Firstly, the best implementations of maximum match-ing in bipartite graphs take O ( n 5 / 2 ) time [15]. This algo-rithm loads the entire graph into memory and hence be-comes impractical for especially large graphs. Furthermore, finding maximum matching in the stream X  X ort model is a well-known open problem. Secondly, since matching maxi-mizes B , it might produce threads that are fragmented.
In the next section we present a simple dynamic programming-based algorithm for a different relaxation of the the threads problem. The main feature of this algorithm is its realiz-ability in the stream X  X ort model of computation.
We will now present an algorithm for extracting threads from a collection of documents represented as a graph ob-tained in Section 3.1 based on the dynamic programming paradigm. This dynamic program solves the ( A, B )-threads problem where B is fixed to be n and the goal is to mini-mize A . While this dynamic program computes the maximal chain cover of the directed acyclic graph, the crucial point is that it can be implementable in the stream X  X ort model.
Given the directed acyclic graph G = ( V, E ) of documents, and an integer parameter T denoting the maximum number of allowed threads, the goal is to find out if the nodes of V can be covered with at most T node-disjoint directed paths. Let  X  denote an arbitrarily fixed topological order on the nodes of G ; without loss of generality, we may assume that the set {  X  ( i ) | i  X  V } is exactly the set { 1 , . . . , n } , where n = | V | , so that we may identify the nodes with their rank in  X  . Define the table cover ( k, t, i ) = 1 if all nodes  X  k can be covered with at most t node-disjoint paths such that node i is a leaf in one of these paths. For j  X  V , suppose we have cover ( j  X  1 , t, i ) available for all i such that ( i, j )  X  E ; we will show how to determine the entries cover ( j, t, i ) for all i  X  j . Namely, cover ( j, t, j ) = 1 if and only if for cover ( j  X  1 , t, i ) = 1 for some i such that ( i, j )  X  E . Furthermore, cover ( j, t, i ) = 1 for i &lt; j if and only if cover ( j  X  1 , t, i ) and there is some node i 0 i 6 = i and cover ( j  X  1 , t, i 0 ) = 1 and ( i 0 , j )  X  E . Finally,
These recurrences lead to an algorithm in the stream X  X ort model where we maintain a T  X  n table corresponding to the second and third co-ordinates of the table cover  X  note that if the edges are presented in topological order of the des-tination node, then we do not need a 3-dimensional array as suggested by the recurrence. A crucial implementation de-tail is that we do not have to compute cover ( j, t, i ) for every value of i (which would take n 2 steps from the definition); since we obtain all edges pointing into j at the same time, we only need to consider N ( j ) 2 pairs ( i, i 0 ) that are relevant. To trace the actual paths, rather than resort to a 3-dimensional array of size n  X  T  X  n , we could compute cover ( j, t,  X  ) and cover ( j, t + 1 ,  X  ) and write an output stream that contains information necessary to trace the paths. For example, if we determine that cover ( j, t, j ) = 1 because for some i , cover ( j, t, i ) = 1 and ( i, j )  X  E (which we would at the time the edges with destination j are processed), we will write into the output stream the tuple ( j, t, j, i ). These tu-ples can be post-processed (again, using the sorting primi-tive) to construct the actual paths.

Lemma 6. The above algorithm solves the ( A, n ) -threads problem for directed acyclic graphs in polynomial time. Data source. Our data source is The Hindu , a daily news-paper from India. This popular newspaper is published in the English language, and is very broad in its coverage of news items, ranging from local to international articles of importance. We obtained all the articles in the online ver-sion of the newspaper ( www.hinduonnet.com ) from Jan 1, 2000 to Mar 31, 2004.
 Preprocessing. We obtained all the articles and parsed them to collect a subset of terms in each document. This step was based on an algorithm in [17] to extract the most important terms in a given document. Each news article comes with an obvious time stamp and we randomly break ties to obtain a linear ordering of the articles. A binary un-weighted term X  X ocument relation is then constructed from the articles and the terms. Our index consists of approxi-mately 29.5 million term X  X ocument pairs from a corpus of roughly 250,000 articles and 375,000 terms. Thus, on aver-age, a term occurs in roughly 78 documents and a document contains around 118 terms.

Let D denote the collection of documents, let T denote the collection of terms, and let R denote the term X  X ocument relation synthesized. The primary interface with the index is a query engine that takes a term T and produces the par-tial index R 0  X  X  defined by R 0 = { ( T 0 , D 0 ) | ( T, D that is, R 0 consists of the projection of R to the set of arti-cles that contain T . Producing R 0 = R 0 ( T ) from the term t takes advantage of the index sorted according each of the keys, terms and documents, and the output of this step is sorted by term. This enables the application of the rele-vance graph construction step described in Section 3.1. We then apply the connected components algorithm to decom-pose the relevance graph, and apply our thread-detection algorithms to each of the large connected components. 04/07/2000 Elian X  father arrives in U.S. 04/09/2000 Political pawn 04/11/2000 U.S. weighing options on Elian 04/16/2000 Court asked to order Elian handover 04/23/2000 U.S. enforces Elian-father reunion 04/24/2000 Widespread ire over re-union 04/27/2000 Senate panel may open hearings on Elian 05/01/2000 Elian case leaves impact on Florida politics 05/04/2000 Republicans not to press for hearings . . .
We present our results in the form of interesting threads uncovered by our algorithms. For definiteness, we set the window parameter w = 10 and the threshold parameter  X  = 5 in all these examples, and employed the mincost-flow based algorithm. The graphs in these case were quite sparse, and, on average, consisted of about 2,500 edges. The entire process, from issuing the query to web page creation, takes a few seconds (unoptimized). Based on preliminary stud-ies, the algorithm based on maximum matching is some-what more efficient on larger graphs, and the one based on dynamic programming offered a complete partition of all documents that respond to a query. Qualitatively, the mincost-flow based algorithm appears quite robust and pro-duces threads of varying lengths, while the matching based heuristic and the dynamic programming formulation tend to produce more short threads (since they maximize the num-ber of documents covered).

First, we consider the query  X  X linton X . This query pro-duced about 30 threads of length 5 or more, and corre-sponded to several news stories involving the former U.S. President as well as the present U.S. Senator. This included threads that corresponded to various visits to India by Clin-ton, a visit by the Indian National Security Adviser to the U.S., 2000 U.S. elections, Clinton X  X  involvement in the con-flicts in Ireland, Israel. In addition, the algorithm produced a thread on a local sports personality in India. Tables 1 and 2 present two sample threads, one that follows the thread of IRA attacks, and one that follows the drama surrounding the child Elian Gonzalez; note that the former thread spans several months, while the latter spans only a few weeks.
Next, we present two interesting threads from the query  X  X epal X , which produced several interesting threads involv-ing Indo X  X epalese relations, the politics and policy issues in the South Asian region. The first, presented in Table 3, 01/13/2000  X  X o IA flight to Kathmandu without . . . 03/07/2000 Team to review airport security in Nepal 04/04/2000 Talks on resuming flights inconclusive 04/25/2000 India for early decision on flights to Nepal 05/09/2000 Flights to Nepal may resume soon 05/11/2000 Resuming flights to Nepal 05/16/2000 IA to resume flights to Nepal from June 1 06/01/2000 IA flights to Kathmandu 06/02/2000 IA resumes service to Nepal 03/03/2002 Chinese silk flooding local market 06/14/2002 Centre urged to end illegal import . . . 06/16/2002 Prevent dumping of Chinese silk, CM . . . 12/22/2002 Centre X  X  decision a boost to sericulture sector 01/07/2003  X  X mported silk ruining ryots X  01/08/2003 Centre urged to increase assistance for . . .
Table 4: Thread: Silk smuggled through Nepal. spans six months, and is about the cancellation of Indian Airlines X  flights to Katmandu, Nepal X  X  capital, owing to se-curity concerns, and the subsequent restoration of flights. The second, presented in Table 4, is a short thread that nevertheless spans nearly a year, and discusses silk smug-gled through Nepal from China to India.
It will be interesting to see if there is a purely combinator-ial algorithm for the ( A, B )-threads problem and if the prob-lem can be solved (perhaps approximately) in the stream X  sort model. Further work includes more general formulation of the problem, for instance, allowing small width trees (in-stead of just directed paths) so as to identify subthreads in a thread, or requiring that there are many edges between the initial and later portion of the thread so as to prevent topic drift. These problems fall under the purview of par-tition problems in directed graphs; for instance, see [19]. It will also be interesting to see the results of applying our algorithm to patent, medical, and legal articles. [1] G. Aggarwal, M. Datar, S. Rajagopalan, and M. Ruhl. [2] R. Agrawal, S. Rajagopalan, R. Srikant, and Y. Xu. [3] J. Allan. Automatic Hypertext Construction . PhD [4] J. Allan, J. Carbonell, G. Doddington, J. Yamron, [5] J. Allan, R. Gupta, and V. Khandelwal. Temporal [6] W. Blustein. Hypertext Versions of Journal Articles: [7] T. Dalamagas. NHS: A tool for the automatic [8] T. Dalamagas and M. D. Dunlop. Automatic [9] J. Edmonds and R. M. Karp. Theoretical [10] G. W. Flake, S. Lawrence, and C. L. Giles. Efficient [11] M. Garey and D. Johnson. Computers and [12] A. Goldberg and R. Tarjan. Solving minimum-cost [13] S. J. Green. Automatically generating hypertext in [14] M. Henzinger, B.-W. Chang, B. Milch, and S. Brin. [15] J. E. Hopcroft and R. M. Karp. An n 5 / 2 algorithm for [16] J. Kleinberg. Bursty and hierarchical structure in [17] R. Kumar, U. Mahadevan, and D. Sivakumar. A [18] R. Kumar, P. Raghavan, S. Rajagopalan, and [19] J.-J. Pan. Path Partition and Its Variation in Graphs . [20] A. F. Smeaton and P. J. Morrissey. Experiments on [21] D. A. Smith. Detecting events with date and place [22] R. Swan and J. Allan. Automatic generation of [23] E. Tardos. A strongly polynomial minimum cost [24] N. Uramoto and K. Takeda. A method for relating [25] Y. Yang, T. Pierce, and J. Carbonell. A study on
