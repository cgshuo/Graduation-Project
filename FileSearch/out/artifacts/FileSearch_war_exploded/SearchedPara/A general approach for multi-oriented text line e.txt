 ORIGINAL PAPER Nazih Ouwayed  X  Abdel Bela X d Abstract Themulti-orientationoccursfrequentlyinancient handwrittendocuments,wherethewriterstrytoupdateadoc-ument by adding some annotations in the margins. Due to the margin narrowness, this gives rise to lines in different direc-tions and orientations. Document recognition needs to find the lines everywhere they are written whatever their orienta-tion. This is why we propose in this paper a new approach allowing us to extract the multi-oriented lines in scanned doc-uments. Because of the multi-orientation of lines and their dispersion in the page, we use an image meshing allowing us to progressively and locally determine the lines. Once the meshing is established, the orientation is determined using the Wigner X  X ille distribution on the projection histogram profile. This local orientation is then enlarged to limit the orientation in the neighborhood. Afterward, the text lines are extracted locally in each zone basing on the follow-up of the orientation lines and the proximity of connected components. Finally, the connected components that overlap and touch in adjacent lines are separated. The morphology analysis of the terminal letters of Arabic words is here considered. The pro-posed approach has been experimented on 100 documents reaching an accuracy of about 98.6%.
 Keywords Multi-oriented handwritten Arabic documents  X  Text line segmentation  X  Projection profile  X  Skew angle estimation  X  Cohen X  X  class distributions  X  Overlapping and touching lines 1 Introduction The ancient handwriting is inherently complex because of its irregularity due to the manual aspect of the script. Rarely, the writers used line support (or layer) to write, resulting in sinuous lines of writing. Moreover, because of the calli-graphic style of the writing, ligatures are easily introduced between the parts of words and attachment occurred between the words of the successive rows. Add to this that as the docu-ment existed only on paper, updating was done directly on the text itself, which led either to extend the lines in the margins, or adding entire blocks of lines in these margins.
All these artifacts complicate the problem of line seg-mentation, which is essentially contextual in old documents, although most segmentation techniques of modern document are rather  X  X atural X , seeking essentially parallel alignments of connected components. The problem with this  X  X ontex-tual X  segmentation is new and complex, which is the chal-lenge in research over the last decade.

A further difficulty arises when dealing with Arabic, cor-responding mostly to the calligraphic aspect more accentu-ated in the case of Arabic. Figure 1 shows different document classes with different kinds of orientation.

The literature suggests haphazardly a lot of techniques for extracting lines. Some are more suited than others to the former. We will expose, in the first part of this paper, a clas-sification of these techniques. The second section will be devoted to our approach for text lines extraction of ancient Arabic documents. Some experimental results are presented in Sect. 4 , and some conclusions and future trends of this work will be given in Sect. 5 . 2 Previous work Concerning the methods, they can be divided into three main classes: top-down, bottom-up, and hybrid. 2.1 Top-down methods Top-down methods start from the whole image and itera-tively subdivide it into smaller blocks to isolate the desired part. They use either an a priori knowledge on the documents suchasinterlineorinter-columnspaces,oradocumentmodel to separate the documents into blocks and blocks into lines. Projection-based methods: Localization of white separa-tions is generally done by analyzing the projection histogram profile. When the projection angle fits well the document ori-entation, we can consider an important difference between twosuccessivevaluesinthehistogramasaboundarybetween two blocks of text. The problem is the estimation of signifi-cant differences in the histogram. In general, one uses a pri-ori knowledge about the document being scanned (number of columns, margins, etc.) to locate more easily separations.
Bennasri et al. [ 4 ] have proposed a method involving the study of the histogram in vertical stripes. The starting points of all lines are detected by using the minimum of the partial projection profile of each column. Then, a contour tracking part of each line is done: first in the sense of writing, then in the opposite direction.

Nicolaou and Gatos [ 31 ] make the assumption that for each text line, there exists a path from one side of the image to the other that traverses only one text line. For that, they propose a segmentation technique by shredding the line sur-face with local minima tracers.

In [ 2 ], each minimum in the projection histogram profile is considered as separator between lines of text. A vector distance between potential points is then constructed to find the distance the most common, considered as the threshold for segmentation. When two potential neighbor points have a very close distance from the threshold, the connected com-ponents between these two points form the line of text.
The global projection cannot handle skewed documents, or documents with curved and sinuous lines. To cope with these artifacts, one uses Hough transform that considers the whole image composed of straight lines. It creates a space observation in which local maxima are assumed representing text lines. Nevertheless, Hough transform is enable to detect curved text lines. In Shapiro et al., [ 43 ] the orientation angle of the document is first estimated by Hough transform, then used to make projections. The number of maxima of the pro-jection profile gives the line number. The local maxima are rejected by comparing their values with those of the highest peaks.
 Document model-based methods: In several areas, the a priori knowledge is highly structured and many segmenta-tion problems (mostly related to the density of information) have not yet been solved by conventional methods presented in the literature.

Couassnon et al. [ 11 ] proposed a method called DMOS (Description and Modification of Segmentation), consisting of a grammatical formalism position to model knowledge and an associated parser authorizing a dynamic change in the structure analysis. This change allows them to introduce the context (symbolic level) in the segmentation phase (dig-ital level), to improve recognition.

In [ 48 ], Zheng et al. present a model-based approach to detect broken lines in noisy textual documents. They use directional single-connected chain, a vectorization-based algorithm, to extract the line segments. Then, they instantiate the line model with three parameters: the skew angle, the ver-tical line gap, and the vertical translation. From the model, they can incorporate the high-level contextual information to enhance detection results.

Nicolas, Paquet, and Heutte [ 32 ] propose a method based on AI problem-solving framework using production systems. The hypotheses management procedure of the production system allows them to analyze all the segmentation possibil-ities and to retain the most valuable one. 2.2 Bottom-up methods To deal with noise problems and writing variation, most methods of line extraction in handwritten documents are bot-tom-up. Bottom-up approaches are based on low-level ele-ments of the image as pixels or related components. The connected component-based methods are the mainstay of the bottom-up approaches. They are clustered into bigger elements such as words, lines, and blocks. In each research, simple rules are used in a different way. These rules are based on the geometric relationship between neighboring blocks, such as distance, overlap, and size compatibility. The differ-ence between the different works lies in their capabilities to cope with space variation and influence of the script and the writer peculiarities.

Several approaches for clustering connected components have been proposed in the literature, such as:  X  X _NN  X  Hough transform  X  Smoothing  X  Repulsive X  X ttractive Network  X  Minimal Spanning Tree K_NN: Clustering methods related to the notion of mutual neighborhood have been considered in the clustering litera-ture.

Zahour et al. [ 47 ] proposes such a method for line extrac-tion in ancient Arabic documents. The document is first divided in vertical columns having the same size. Then, in each column, three kinds of columns are considered: small corresponding to the diacritics, average related to the word bodies, and large representing the word overlapped between successive lines. The Euclidean distance is finally operated to re-assemble the close blocks, and hence form lines. An improved version of this approach is published in [ 5 ]. Here, the method deals with the problems of overlapping and multi-touching text-lines extraction.

Likforman X  X ulem et al. proposed in [ 25 ] an approach based on perceptual grouping of connected components. The grouping is based on the  X  X estalt theory X  which principles, such as proximity, similarity, and continuity, allow the human eye to perceive elements. To cope with conflicts, the method integrates a refinement procedure combining a global and a local analysis.

Feldbach and T X nnies proposed in [ 14 ] a grouping method based on the text line alignments. First, the minima of the skeletons are performed leading the baseline extraction. Then, the text line centers are estimated using the orientation of the baselines and the endpoints in the skeletons. These alignments are then grouped according to the size, the dis-tance between lines, and the line orientation. A correction step of conflicts between the alignments is applied to improve the rate of segmentation.

Kumar et al. proposed in [ 21 ] a graph-based method for text lines extraction from Arabic documents. The method starts by computing the local orientation of each primary component to build a similarity graph. Then, a shortest path algorithm is used to compute the similarities between non-neighboring components. From this graph, the text lines are obtained using two estimates based on the affinity propaga-tion and breadth-first search.
 Hough transform: Hough transform is also used in bottom-up approaches. The main questions are related to the voting points, the most representative of the text lines.
In [ 26 ], the voting points correspond to the center of grav-ity of connected components. They are first used for line orientation detection. Then, from these proposed lines, a val-idation is operated to eliminate the erroneous alignments using contextual information on connected components such as proximity and direction continuity.

InPuandShi[ 39 ],thevotingpointscorrespondtothemin-ima of the connected components, located in a vertical strip on the left side of the image. The alignments are searched by grouping cells in the Hough space in six directions. These alignments correspond to the sequences of related compo-nents that begin each line. Then, a sliding window is associ-ated with each alignment algorithm that allows to follow the remaining connected component, using the proximity of con-nected components and initial orientation found by Hough.
Louloudis et al. proposed in [ 27 ] a block-based Hough transform for the detection of potential text lines accom-panied by a post-processing phase to correct possible false alarms. The block sizes are estimated from the average of the character sizes in the document.
 Saha et al. proposed in [ 41 ] a technique based on the Hough transform for text line and word extraction from multi-script documents. The data set is composed of printed and handwritten text lines with variety in script and line spac-ing in single document image.
 Smoothing: The smoothing technique (Run Length Smooth-ing or RLS) is to darken the small spaces between the con-secutive black pixels in horizontal direction, which leads to connect them. The boxes, which include the successive con-nected components in the image, form the lines.

In [ 44 ], a fuzzy run length algorithm is used. The alignments, hence, created are analyzed according to sev-eral heuristics to form lines of text. Alignments of a size not exceeding a pre-determined value are deleted.

In [ 22 ], lines are extracted by applying RLSA, adapted to a gray-scale image. Instead of connecting a series of white and black pixels, the gradient of the image is expanded in the horizontal direction with a tilt angle that varies between  X  30  X  . The process can be applied in several directions if necessary.
 Repulsive X  X ttractive network: The repulsive X  X ttractive network is a dynamic system to minimize energy, which interacts with the textual image by attractive and repulsive forces defined on the components of the network and the document image. Experimental results indicate that the net-work can successfully extract the baselines under significant noise in the presence of overlaps between the ascending and descending parts of characters in two lines.

Oztop et al. proposed in [ 34 ], an equivalent approach based on the same principle. Initially, the baselines are built by scanning the image from top to bottom ordered by group-ing neighboring pixels. These lines are the repulsive forces, and the pixels are the attractive forces for the network. To extract lines, the relationship between pixels and the base-lines are studied from the forces in this network. The pixels that form the true line of text are kept, while the other pixels are deleted.
 Minimal spanning tree (MST): Considering the connected components in a document as the vertices of a graph, we can obtain a complete undirected graph. A spanning tree of a connected graph is a tree that contains all the vertices of this graph. A minimal spanning tree of a graph is that spanning tree for which the sum of the edges is minimal among all the spanning trees of this graph. A minimal spanning tree of a graph can be generated with Kruskal algorithm. In this algorithm, the tree is built by inserting the remaining unused edge with the smallest cost until all the vertices are connected.

In Yin and Liu [ 46 ], from a distance defined to better char-acterize the nearby connected components (two consecutive CCs on the same line will be considered closer than two CCs on different lines), Kruskal X  X  algorithm combines two to two pairs of the closest CCs. Then, this distance is applied to pairs of nodes to encompass all nodes, and so on. 2.3 Hybrid methods The hybrid schemes combine top-down and bottom-up algo-rithms to yield better results. In this class, we find the meth-ods based on the deformable contour model. The deformable model is an analytical approach that can act interactively on the modeling. It allows to change (in time and space) the representation of the model toward the solution of the min-imization problem introduced in the modeling. Concretely, this leads to introduce a term of time evolution in the mini-mization criterion, which allows, each time, to influence the prior model when necessary and to readjust to a better solu-tion. Early work in this area are those of Kass, Witkin, and Terzopoulos [ 18 ]. In the case of a 2D image, the deform-able contour model is used to find an existing object. The process is iterative. From an initial contour, a mechanism of deformable contour is applied to change this form, so that it is the target area. The evolution mechanism is an energy function. The target area will be found by minimizing this energy. Several deformable contour models exist in the lit-erature. Here are a few examples: the parametric active con-tour model (snake [ 18 ]), the geometric snake [ 8 ], the level set method [ 42 , 37 , 33 ], the B-spline or B-snake [ 23 ] and the Mumford X  X hah model [ 40 ].

The use of each model depends on the specific application and the type of processed images. In the field of line extrac-tion of handwritten documents, one used three models: the snake set, the method of level set, and Mumford X  X hah model. The parametric snake : In the formulation of Kass et al. [ 18 ], the best snake position was defined as the solution of a var-iational problem requiring the minimization of the sum of internal and external energies integrated along the length of the snake.

Bukhari et al. proposed in [ 6 , 7 ] a parametric snake-based method for the extraction of handwritten document lines. The initial snake is the central line of text lines. This line is esti-mated based on the intensity values in a gray-scale document image. Then, the mechanism of snake energy minimization is applied to find text lines.
 The level set : Unlike deformable model, level set approach is geometrical. The basic idea of the level set method is to evolve the boundary by its partial derivatives and an external vector field (i.e., the gradient). Li et al. proposed in [ 24 ] such a technique for extracting complex lines of handwritten doc-uments. The method starts by applying a Gaussian filter with an anisotropic kernel to estimate the pixel density. Then, a probability map is constructed giving the probability that a pixel belongs to a line of text. Finally, the model of Level Set is applied to deform the contour in order to find lines. The Mumford X  X hah : The Mumford X  X hah model [ 30 ] deforms the contours by minimizing the following energy function: E ( u , C ) = | u  X  u 0 | 2 d x d y +  X  where u 0 is the initial image, u the smoothed image after the use of a gaussian filter, C the set of the initial curves (or snakes), | C | the set of curve lengths, the image domain, \ C theimagedomainwithout thecurves,  X  u theimagegra-dient u , and  X  and v the parameters that balance the effect of other terms in this equation.

InDuetal.[ 12 ]theauthorsusepiecewiseconstantapprox-imation of the MS model to segment handwritten text images. The segmentation result does not depend on the number of evolution steps. In addition, they use the morphing to remove overlaps between neighboring text lines and connect broken text lines. 2.4 Method discussion Table 1 summarizes all the methods mentioned and divided according to 15 criteria: lines types (straight, oriented, and cursive), types of materials (printed, manuscript, multi-oriented, interval orientation (IO), Latin, Chinese, Indian, Arabic, Persian, Urdu), nature of content (C: Color, G: Gray, and B: Binary), and meshing. All these approaches are either too general, proceeding by projection or by alignment search, or too local, operating by connected component following. They find here their limits facing to the poor quality and multi-orientation of documents. Most of these techniques have been applied to documents with a single orientation. The adaptation of these approaches is impossible if we want to extract all directions. 3 Overview of the proposed system Given the failure of traditional methods, we propose a novel method for line extraction in multi-oriented documents. The technique has been studied for Arabic documents, but can be generalized to any other script that writing is linear. The method is based on an image meshing that allows it to detect locally and safely the orientations. These orientations are then extended to larger areas. The only assumption is that initially, the central part of the paper is horizontal. The ori-entation calculation uses the energy distribution of Cohen X  X  class, more accurate than the projection method. Then, the method exploits the projection peaks to follow the connected components forming text lines. The approach ends with a final separation of connected lines, based on the exploitation of the morphology of terminal letters. 3.1 Image meshing In this step, the document image is partitioned into small meshes of (w  X  h ) size. This size is generated, based on the idea that a mesh must approximately contain 3 lines, so as to produce a projection histogram profile that is representative of the writing orientation. The projection profile is represen-tative of the orientation when it contains three peaks and two valleys then three lines.

This follows several steps. First, an initial mesh of arbi-trarily size ( 15  X  15 pixels ) is placed in the middle of the image (see Fig. 2 a). The location choice is based on the assumption that the initial document is horizontally filled at the page center. To find the lines, we apply the active con-tour model (or snake) technique that will be presented in Sect. 3.1.1 . The mesh size is enlarged until the snake pro-vides at least 3 lines. Once the lines found, the average line height  X  h is performed as well as the average gap  X  g between them. The gap distance is calculated using the convex hull-based metric described in [ 28 ] (see Fig. 2 b). The final mesh size is equal to (w  X  h ) where w = h = 3  X   X  h + 2  X   X  g . 3.1.1 Active contour model (snake) The snake [ 17 ] is parametrically defined as v( s ) = { x y ( s ) } , where s  X  X  0 , 1 ] is the coordinate indice or order, x ( s ) and y ( s ) are x and y co-ordinates along the contour. The functional energy to be minimized is: E  X  The internal energy, E int , is the force that serves to  X  The external energy, E image , is the external force that  X  The constraint energy, E con , expresses some additional
In our application, the major axis (equal to the first har-monic of the Fourier descriptor [ 29 ]) of the connected com-ponents is used as the initial snake. We use GVF as external energy and a null internal energy. To detect the alignments, some morphological operations such as dilation and erosion are first applied to the initial image (see Fig. 3 b) to expand the edges. Then, the major axis of each connected compo-nent is determined using the Fourier descriptors (see Fig. 3 c). Finally, the energy minimization mechanism is operated on the snake to deform and push it to the text edge, more or less similar to the connected component skeleton (see Fig. 3 d). To ensure that the lines will be detected, we increment the size of the major axis by a threshold equal to the quarter of the aver-age width of the connected components. This threshold is obtained by experiments. Finally, the connected components that belong to the same line are grouped to form the lines (see Fig. 3 e). Figure 18 b shows the results of the automatic meshing of the document presented in the Fig. 2 a.
In order to reduce the running speedup, we discard the meshes containing few pixels, because their inclination is insignificant. If a mesh contains some text (i.e., few con-nected components) and thus no noise, it is automatically merged with the neighbor meshes. 3.2 Orientation area extraction 3.2.1 Orientation estimation As the lines are wavy, the orientation is first searched in small meshes,whereitismorelikelytohavepiecesofstraightlines. Then the meshes are enlarged to neighbors having similar orientation until the delimitation of real sizable orientation zones will be effective. Traditionally, the projection histo-gram profile is employed along different orientation angles to determine the local orientation. Each projection histogram profile contains several peaks. More the peaks are sharp and the valleys carved, more the histogram reflects a good ori-entation. Figure 4 a shows only one horizontal line for which there is only one sharp peak on the projection histogram com-puted for an angle equal to 0  X  . This is not the case for the projection along + 30  X  or  X  30  X  (see Fig. 4 b).

Usually, to determine the skew angle from the projection profile, the average difference between peaks and valleys is performed [ 1 , 35 , 36 , 38 ], and the profile having the maxi-mum difference reflects the maximum skew angle. However, this method does not always succeed, because of line dis-tortions and variabilities creating false maxima and minima (see Fig. 5 ). In the case of Arabic script, this phenomenon is very common. In fact, Arabic presents a very changing morphology depending on the writing style. Some ligatures between characters are vertical, whereas others are oblique that can affect the calculation of the word or the line orien-tation. Furthermore, the individual PAWs (Parts of Arabic Words) composing the words can also have oblique or verti-cal orientations, which are often opposite to the global word orientation (see Fig. 6 ).

To face this problem, we have examined other features to better analyze the histogram profile function. We then used the energetic time X  X requency distributions on the histogram profile considered as a signal. 3.2.2 Time X  X requency distributions Traditional approaches of signal processing such as Fou-rier transform cannot study the signal variation over time and frequency. The energetic time X  X requency distributions go beyond what these approaches allow by analyzing the non-stationarity of a signal and distribute the energy of a signal in time and frequency.

According to [ 16 ], the energy E x of a signal x ( t ) is defined as: E where x ( f ) is the Fourier transform of the signal x ( t value E x is quadratic. For this reason, the time X  X requency distributions must keep this property.
 Cohen X  X  Class: in 1966, Cohen [ 3 , 10 , 13 ] proved that a sig-nificant number of time X  X requency distributions can be seen as particular cases of the following general expression: C ( t , f ) = where A x ( X ,  X  ) is the ambiguity function defined by: A
The Cohen X  X  class contains all the time X  X requency distri-butions that are covariant under time and frequency shifts. The members of this class are identified by a particular ker-nel  X  dD ( X ,  X  ) , (expressed here in the delay-Doppler plane dD ), which determines their theoretical properties [ 9 , 15 , 16 ] and their practical readability.

We want to use these distributions on the signal represent-ing the histogram projection profile in each mesh, in order to estimate its orientation. The Cohen X  X  class distributions are used to estimate the orientation, because when computing the projection histogram of a document along one direction of projection, we obtain, if this direction is the real orienta-tion of the document, a histogram in which each line leads to a clearly localized local maximum. Each block of the doc-ument leads in the projection histogram to a succession of periodic peaks and valleys, whose period is relatively con-stant. This periodic succession is delimited by the block size ( X  X ime X  support) and oscillates at a frequency determined by the space width between the lines. As all the pixels are accumulated in the same positions, the local maxima have higher energy levels than with other projection directions. This explains why we can estimate the orientation of a docu-ment by seeking the projection angle for which the time X  frequency distribution localizes a large energy level on a small area of the time X  X requency plane. For example, Fig. 7 shows the increase in the maximum of the Wigner X  X ille dis-tribution when the number of peaks and valleys increases and when the valleys become wider.
 3.2.3 Implementation details To estimate the orientation angle, we use the analytic signal x ( t ) of the centered squared root of the projection histogram x ( t ) of the document. The calculation of the squared root of time X  X requency representation of projection histograms and not of the projection histograms, as is done in [ 19 , 20 ], rein-forcesthesignificanceofrepresentationvaluesanditsproper-ties. The analytic signal is the signal x ( t ) without its negative frequencies. The histogram x ( t ) is determined by projecting each document with a chosen orientation. To calculate all possible projection histograms, we turn the image around its center of gravity (which gives us a point deduced from the image content and not from its size and framing) and we choose the horizontal axis as an arbitrary reference for the zero-degree angle (see Fig. 8 ). Then, we compute a time X  frequency representation for the squared root of each projec-tion histogram, whose average has been removed. The angle corresponding to the projection histogram with the highest maximum value of its time X  X requency representation is cho-sen as the estimated angle of the document. Figure 9 shows 4 plots of the highest value of the Wigner X  X ille distribu-tion, spectrogram distribution and Fast Fourier Transform obtained from the squared root of projection histograms of the document shown on Fig. 10 , and the maximum average difference between the maxima and the minima of projec-tion histograms of the same document, as a function of the projection angle. Table 2 shows the estimated skew angle of the document shown on Fig. 10 , obtained with the methods mentioned below. We can note that the correct value, + 14 mentioned in Fig. 10 is the one found by the Wigner X  X ille distribution. 3.2.4 Orientation area expanding To extend the areas of orientation, we examine the orien-tations in neighboring meshes and proceed to an extension or a correction. Considering the writing direction in Arabic, we examine pairs of neighbors along three right X  X eft direc-tions: straight, sloping upward, and sloping down. The two neighbor meshes are merged if the orientation of the global mesh is equal to one of them, otherwise the orientations are maintained in both meshs. The operation is repeated for all the document meshes. After this step, the zones will be constructed. 3.3 Erroneous inclination When a mesh contains several orientations, the mesh ori-entation will be erroneous (see Fig. 11 ). To detect this phenomenon, we observe the orientation of the horizontal (resp. vertical) surrounding meshes that have angles dif-ferent of  X  , more precisely, when  X  1 is different from  X , X  different from  X  and  X  1 is different from  X  2 . In the Fig. 11 a,  X  =+ 60  X  , X  or oblique). Since this case arises inside the main horizontal writing, the vertical projection profile is used to resolve this case. If this case arises inside the main vertical writing, the horizontal projection profile is used to resolve this case. The first minimum value in the projection profile is looked for from the right representing the end of the first inclination ( I minimum index). Then, the mesh is divided at I m into two meshes w left and w right (see Fig. 11 b). Finally, the w assigned to the mesh w( X  1 ) and w left to w( X  2 ) . 3.4 Meshing correction Being applied automatically, the initial paving edges can cross the connected components creating problems (false maxima) in text line detection (see Fig. 12 ). The incorrect paving exists only in the horizontal and the vertical zones. We need to correct the position of these edges by proceeding a horizontal or vertical shift in order that the local paving cov-ers the local connected components. In the horizontal (resp. vertical) area, the edge that divides two consecutive rows (resp. columns) is moved to the nearest position in these rows (resp. columns), when the horizontal (resp. vertical) projec-tion vector for each of their two consecutive meshes has a minimum value. 3.5 Text line extraction The text line follow-up starts in the first window on the right side of the page. The algorithm starts by looking for the new maxima (see Fig. 13 a). Each peak represents the start-ing point P s of the orientation line bl j . The ending point P of the orientation line is calculated using the P s , the orienta-tion, the width and the height of each window (see Fig. 13 b). The orientation line bl j is calculated basing on the two points (
P components that belong to a baseline are looked for construct the text line (see Fig. 13 c).

A step of text line correction follows the text line detec-tiontoassignthenon-detectedcomponentsandthediacritical symbols to the appropriate text line (see Fig. 13 c and d). A distance method is used to address this problem. First, the distance between the centroid of non-detected component or diacritical symbol C i and the text line is calculated. C assigned to the text line l j if d ci , lj &lt; d ci , lj 3.6 Connected line separation The connections occur between two successive lines when their characters touch. Often, these connections are made between ascenders in the lower line and descenders in the higher line. Table 3 lists the four categories of connection in Arabic: (a) a descender with right loop, connects a vertical ascender, (b) a left descender with a loop, touches a verti-cal ascender, (c) a right descender touches the higher part of the loop of a character, and (d) a left descender connects the higher part of the lower curve of a letter.

In all connection cases, we note the presence of a descen-der connecting a lower end letter. The descenders are grouped into two categories: (a, c) where the descender of the line starts from the right and (b, d) where the descender of the line starts from the left. To streamline the work, the analysis focuses on the connection areas. (see Fig. 14 ).

The method starts by extracting in the two lines, the con-nected component created by the connection between the two successive lines (see Fig. 15 a). Then, the intersection points of each connected component is detected. An intersection point is a pixel that has at least three neighboring pixels. As in the case chosen, the connection occurs at a single point of intersection S p close to the minimum axis (valley between two lines). Thus, the point S p is the nearest point of the min-imum axis (see Fig. 15 b). We then look for the starting point of the ligature, B p , which is generally the highest point, near the baseline of the top line. Then, from this point, the method is to follow the descending character (i.e., its skeleton, see Fig. 15 c). The following continues beyond the intersection point respecting an minimum angular variation correspond-ing to the curvature of the descending character.

Due to the symmetry of the curve branches, the value of the orientation angle must always be positive. For exam-ple, in Fig. 16 , the angular variances are Var ( C 1 + 2 703 , 19 , Var ( C 1 + 3 ) = 299 and Var ( C 1 + 4 ) = 572 this example, the minimum angular variance Var ( C 1 + 3 ) given by the correct direction to follow. Figure 17 illustrates the effectiveness of the algorithm on a representative sam-ple of 12 arbitrarily chosen connected components from 640 occurrences found in 100 documents. 4 Experimental results and discussion To study the effectiveness of our approach, we have experi-mented on 100 Arabic ancient documents containing 2,500 lines. These documents belong to a database stemmed from websites of the Tunisian National Library, National Library of Medicine in the USA, and National Library and Archives of Egypt. The tests were prepared after a manual areas and lines labeling step of each document. The rotation angle examined during these experiments ranged from  X  75  X  to + 90  X  . The execution time is measured from the meshing phase until the line separation phase. It depends on the document and the mesh sizes. The tests were performed on a PC with a Intel Core 2 Duo processor 2.4GHz and a cache of 4GB in Windows XP. The application was developed with Matlab completed by the time X  X requency toolbox tftb [ 3 ].
The approach is composed of two main steps: multi-oriented area detection and text line extraction. Our results are measured according to theses algorithms.

The multi-oriented algorithm is composed of three main steps: image meshing, orientation estimation, and orientation extension, and paving correction. A global accuracy rate of 97% is reached. The 3% error is shared by the three stages of treatment: 1% is due to the image paving, 1.3% is due to the orientation estimation, and 0.7% is due to the orientation extension and paving correction.

In image meshing, it is just needed at least three text lines to obtain a projection profile representing the orientation in each mesh. So, if this criterion is not obtained by the paving algorithm, some errors may happen for area detection. The error rate of 1% is divided in two cases: 0.7% is due to the adjacent line connection and 0.3% is due to the small ori-ented areas. In the first case, the connection between lines is very frequent in ancient Arabic documents. When the active contour model (snake) is applied in a mesh to alignments extract, it is possible that it connect two adjacent lines. This will increase the alignment height and consequently the mesh height. A large mesh may include different oriented areas. In the second case, the oriented areas are composed of few small lines. These areas can be gathered by the paving in other meshes and naturally will not be extracted. The Fig. 18 shows the image meshing results of 4 different documents. We can note in these documents the presence at least of three lines in each mesh.

The meshes in our documents have, in some cases, more than one orientation or curved lines. In the two cases, the orientation estimation is wrong and will be wrong for the ori-entation extension and consequently for the area detection. The error rate of 1.3% is divided in two cases: 0.9% is due to the meshes with multi-orientations (several orientations in the same mesh) and 0.4% error is due to the curved lines in Arabic ancient documents (a mesh with curved lines has a insignificant projection profile that false the orientation esti-mation). The Fig. 19 shows the results of the first orientation estimation of four documents selected in our database. Each color represents an orientation (see Fig. 20 for the color leg-end). We remark in these documents the presence of meshes with erroneous orientation (multi-orientations or curved lines (Gray color)).

Four extension rules are applied for mesh extension hav-ing the same orientation. In the extension phase, any error is happened because all possible orientations in the documents are considered. The error rate of 0.7% is due to the pav-ing correction. As this paving is rectangular, the correction can be applied just along the horizontal and vertical direc-tions. In some cases (oblique areas), the paving correction cannot be applied that will yield some segmentation errors. This may happen when the vertical or horizontal bars cross some connected components. The Fig. 21 shows the results of the multi-oriented areas extraction of the four selected docu-ments. Each area is visualized by a color. In these documents, all the multi-oriented areas are extracted correctly.
Table 4 summarizes the results of the 4 representative doc-uments chosen arbitrary from the 100 documents selected. These results show the effectiveness and the performance of the multi-oriented area detection algorithm.
 For line segmentation, the extraction rate reaches 98.6%. This accuracy is defined by (number of text lines detected / number of text lines of the document)  X  100. The 0.9% of non-detectedlines is duetothedetectionareaalgorithm when small areas of few text lines are not extracted. The error rate of 0.5% is due to the presence of diacritical symbols and noise in the beginning of lines that create false maxima. The diacritical symbols are the points of Arabic letters and the noise come from the old age of these documents. Figure 22 illustrates the effectiveness of our algorithm on a sample of 3 documents chosen randomly among the 100 documents pro-cessed. To identify the lines, each pair of consecutive lines is presented in two different colors. 5 Conclusion A multi-oriented text line extraction approach is proposed in this paper is based on the local orientation estimation. To extract the lines, the approach proceeds first by an image meshing of the document. Then, the orientation in each mesh is estimated, extended, and corrected. Finally, the text lines are extracted and separated.

The mesh size is estimated using the active contour model (snake) approach. This size is fixed, once three lines in the mesh are extracted. The skew detection approach uses the Cohen X  X  class distributions applied on the projection his-togram profile in each mesh and considered as a signal. The Wigner X  X ille distribution (WVD) from this class is retained for our application, thanks to its interesting prop-erties adapted to the properties of ours signals. The mesh area is extended to similar oriented meshes to obtain largest orientation areas using 4 rules. These rules depend on the orientations presented in these documents. The text lines are extracted in each mesh using a follow-up connected compo-nents algorithm. The lines are separated based on the analysis of the terminal Arabic letters.

Experimental results on various types of handwritten Ara-bic documents show that the proposed method has achieved a promising performance for the text line extraction. This approachwillbegeneralizedtootherdocumentstypes(Latin, Urdu, Farsi, etc.) and to heterogeneous documents with text and images.
 References
