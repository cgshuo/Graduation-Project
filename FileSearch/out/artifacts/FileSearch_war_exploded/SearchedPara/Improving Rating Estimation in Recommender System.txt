 Previous work on using external aggregate rating informa-tion showed that this information can be incorporated in several different types of recommender systems and improves their performance. In this paper, we propose a more general class of methods that combine external aggregate informa-tion with individual ratings in a novel way. Unlike the previ-ously proposed methods, one of the defining features of this approach is that it takes into the consideration not only the aggregate average ratings but also the variance of the aggre-gate distribution of ratings. The methods proposed in this paper estimate unknown ratings by finding an optimal lin-ear combination of individual-level and aggregate-level rat-ing estimators in a form of a hierarchical regression (HR) model that is grounded in the theory of statistics and ma-chine learning. The proposed HR model is general enough so that the standard individual-level recommender systems and naive aggregate methods constitute special cases of this model. We show that for the general HR model, the pres-ence of the aggregate variance, surprisingly, does not signif-icantly improve estimation of unknown ratings vis-a-vis the case when only aggregate average ratings are considered. In the paper, we experimentally show that the optimal linear combination approach significantly dominates all other spe-cial cases, including the classical non-aggregated case and our previously studied aggregate methods, and therefore is the method of choice.
 Categories and Subject Descriptors: H.1.2 [Models and Principles]: User/Machine Systems -Human information processing.
 General Terms: Algorithms, Design, Theory Keywords: predictive models, aggregate ratings, aggregate variance, hierarchical models
Consider a Netflix recommender system [7] and assume that it is augmented with the aggregate ratings from the IMDB database [10], such as the one specifying that females in the age category of 18 to 29 gave an average rating of 6.9 (out of 10) to the movie  X  X adagascar. X  Can such additional aggregate rating information, provided from the external sources, improve the quality of individual ratings? More generally, a traditional recommender system providing indi-vidual ratings to individual users can be supplemented with an externally provided OLAP-based [2] system of aggregate ratings, such as the aggregate ratings for  X  X adagascar X  pro-vided by females vs. provided by females in the age category of 18 to 29 years.

In our prior work [16] and [17], we studied this question by assuming certain probabilistic models for recommender systems and incorporating the aggregate information as con-straints into these models. Although useful, one of the ma-jor limitations of these papers is the assumption about the specific model form.

In this paper, we present an alternative approach that is independent of the specific model assumptions and estimates the unknown individual-level ratings with the optimal linear combination of two estimators: individual-and aggregate-level estimators. We present two theorems about optimal linear combination of two rating estimators and, based on these theorems, we incorporate into the model not only the aggregate average rating but also the variance of the aggre-gate rating distribution. The resulting model constitutes a certain type of a hierarchical linear regression model [14] that we call the HR model. We show that our new approach has certain nice theoretical grounds and prove experimen-tally that it outperforms rating estimations produced by both the individual rating and the aggregate rating models under a wide range of assumptions about these models. We also consider several special cases of this HR model, includ-ing the non-hierarchical simple regression model (SR) from which the aggregate variance information is removed, em-pirically compare them with each other and also with our previously proposed method from [18] on several datasets and under a wide range of experimental conditions. As a result of this comparison, we experimentally demonstrate that 1. the optimal combination of two estimators outperforms 2. for the optimal linear combination of the estimators, 3. the optimal linear combination performs at least as
From all this, we conclude that for the optimal linear com-bination of the rating estimators, the aggregate variance does not improve performance of the model, as compared to a simpler regression-based model without variance (SR). Furthermore, this simple SR model performs as well as the hierarchical regression model (HR) and dominates all other models, including our previously studied model from [18]. Therefore, it is clearly the best choice for incorporating ag-gregate ratings into the individual rating models.
The usage of aggregate ratings has been previously stud-ied in the recommender systems literature. An idea of using an OLAP-based multidimensional approach to recommender systems was proposed by [3]. This approach was subse-quently extended by [2] by incorporating additional contex-tual information on ratings, such as when, how and with whom a movie was watched. Also, [13] presents a method for providing recommendations to a group of users. [11] dis-cusses new issues that arise when one considers web-based personalization involving groups for a certain subclass of group recommender systems. Both these methods deal with the bottom-up approach to recommendations that use ag-gregate ratings as a basis for recommendations to groups of users. In contrast to this, [9] presents a top-down method for using aggregate information about traversal of hypertext pages by a group of users in order to provide better rec-ommendations of hypertext pages to individual members of the group. [6] presents a two-level rating estimation method where at the lower level ratings are estimated using collabo-rative filtering deploying local scale neighborhood informa-tion. At the upper level, [6] uses SVD-style factorization based on global scale information to improve predictions. However, this work does not use any information on prespec-ified taxonomy of users or items, nor does it use externally specified aggregate ratings. [4] uses pre-existing taxonomy of webpages and advertisements in order to better estimate the click-through rate and combat the sparsity of the data. However, this work is only tangentially related to recom-mender systems, and also does not use any externally speci-fied aggregate information and does not deal with aggregate ratings.

The idea of incorporating aggregate rating information into a model of a recommender system was described in [16], where it is done for the statistical model of the rec-ommender system described in [5]. [16] theoretically demon-strates that these incorporated aggregate ratings indeed pro-vide for better estimation of unknown ratings than the stan-dalone model of [5]. However, [16] shows this only for the recommender system from [5]. Further, [17] studies how to incorporate aggregate rating information into collaborative filtering models. The paper presents experimental results showing that the aggregate information indeed improves es-timations of unknown ratings, and suggests the ways to make the proposed method more scalable. Additionally, [18] unites [16] and [17] into a single framework of utilizing the aggregate information by imposing constraints on the un-derlying model, provides more scalable method for statisti-cal estimation of model parameters and demonstrates the experimental results on larger datasets.

In this paper, we improve the initial approaches to in-corporating aggregate ratings information in recommender systems presented in [16] and [17] by proposing and study-ing more advanced and better performing models that con-sider not only the aggregate average ratings, but also the aggregate variances. Although, [1] proposed to use variance of neighbors in neighborhood-based collaborative filtering techniques and demonstrated the increased precision and di-versity of individual predictions based on precision-in-top-N and diversity-in-top-N metric, our results are based on ex-ternally provided variance of aggregate rating distribution rather than internally computed variance of distribution of ratings participating in the computation, therefore, our re-sults take place in a different domain of applying variance than [1].

In the following sections, we provide a detailed description of our approach.
Assume that we have a set of N users and M items and let r ij be a rating of user i for item j (either observed or unobserved). Also assume that a recommender system RS estimates unknown individual ratings r ij using some estima-tor  X  r ij , such as classical collaborative-filtering. We call it an Individual Rating Estimator (IRE) in this paper.

Also, let r a j be the aggregate average rating for the item j that is determined from the externally provided data sources such as the ones described in Section 1. Note that this ex-ternally specified aggregate rating r a j also constitutes an es-timator of an unknown rating r ij of user i for item j , which we call Aggregate Rating Estimator (ARE) . Note that this is a rather  X  X imple X  estimator, as compared to various possible individual-level estimators  X  r ij ; however it is an estimator.
These two estimators can be combined into one new esti-mator using various methods, including the linear combina-tion, such as
We, next, demonstrate that, as long as two estimators are not perfectly correlated, this linear combination (1) pro-duces a  X  X etter X  estimator in the following sense.
Theorem 1. Assume that  X  x 1 and  X  x 2 are two unbiased uncorrelated estimators of unknown quantity x with the fol-lowing properties:
Assume that we create a new estimator  X  x as a linear com-bination of  X  x 1 and  X  x 2 in the form
Then, the best unbiased estimator  X  x that achieves the low-est variance is where  X  = v 2 v
Furthermore, Var ( X  x )  X  min( Var ( X  x 1 ) , Var ( X  x 2 ))
The fact that the aggregate ratings r a j are given at the item-level and depend only on index j does not limit our analysis and is used only for the purpose of compatible notation with the aggregate dataset that we used. Figure 1: Break down of aggregate rating distribu-tion for a particular movie in IMDB database
The next theorem states a similar result but for the biased and correlated estimators.

Theorem 2. Assume  X  x 1 and  X  x 2 are two linearly biased correlated estimators of unknown quantity x with the fol-lowing properties: where a 1 , a 2 , b 1 , b 2 , v 1 , v 2 , c 12 are known values.
Assume that we create a new estimator  X  x as a linear com-bination of  X  x 1 and  X  x 2 , that is
Then, the estimator  X  x is unbiased and achieves the lowest variance if Furthermore, Var ( X  x )  X  min( Var ( X  x 1 ) , Var ( X  x 2 ))
Proof. The detailed proof of both theorems is available in [18], because of the space limitations. Note that both theorems make no assumptions about the shape of the dis-tributions for estimators  X  x 1 and  X  x 1 , except for the semipara-metric assumptions (2) about the expected values of these estimators and their variances.

When applied to our settings, Theorems 1 and 2 show that is an estimator with a smaller variance than that of  X  r ij r if we choose correct weights  X  ,  X  and  X  . Therefore, these theorems provide a theoretical way to combine the two esti-mators in order to create a more precise estimator, if we know the properties of these two estimators, such as their bias, variance and correlation between the two estimators.
For the aggregate-level estimator r a j , the external sources can provide not only aggregate average rating r a j itself, but also the complete aggregate distribution of the ratings. For example, Figure 1 displays the aggregate distribution infor-mation for movie  X  X ntz X  from the IMDB database by pro-viding the amount of users who gave a particular rating for every possible rating level. More specifically, let C jl be the number of users who gave a particular rating l to the item j , l  X  L , where L is the discrete and finite set of ratings. Let S be the set of all the users who gave a rating to item j . Then, the variance of the aggregate-level estimator can be computed as an aggregate variance of the distribution as follows Therefore, the variance of aggregate-level estimator r a j be directly computed from the aggregate distribution of rat-ings.

In contrast, for the individual-level estimator  X  r ij , the clas-sical techniques, such as the traditional collaborative filter-ing [15], typically, do not determine the  X  X ncertainty X  lev-els associated with the predicted rating value. Most of the recommender systems cannot determine how far the true rating value r ij is likely to be from the predicted value  X  r This  X  X ncertainty X  can be measured by the variance of the individual-level estimator Var( X  r ij ). Unfortunately, the es-tablished classical recommender systems methods typically do not provide ways to compute such variances.

Without having a good model for determining the uncer-tainty (in the form of variance Var( X  r ij )) of individual-level rating estimator  X  r ij , we cannot apply any of the theorems in practice directly, since the optimal coefficients depend on this unknown parameter.

Because of the difficulty and ambiguity with defining and estimating the variances and covariances of individual-level estimators, we propose a different and more practical ap-proach based on the ideas suggested by Theorems 1 and 2. Intuitively, what Theorems 1 and 2 state is that when the aggregate variance gets larger with other things being equal, the aggregate-level estimator r a j becomes less helpful, and therefore the theorems put less weight on the aggregate-level estimator in (1). The converse is also possible: when the aggregate variance is very small (that is, almost all the users tend to agree on the rating for that item), Theorems 1 and 2 put larger weight on the aggregate rating.
More specifically, consider what these theorems imply for weights  X  ,  X  ,  X  . Assume that the aggregate-level rating estimator variance v 2 = Var( r a j ) is a known number; then, after some algebraic manipulations, the optimal weighting  X  ,  X  ,  X  can be represented as a function of v 2 as follows: where A , B , C , D , E , F , G are independent of v 2 .
That is, according to Theorems 1 and 2, the optimal weighting  X  ,  X  ,  X  that achieves the best MSE prediction, depends on v 2 in a monotonous fashion. Therefore, given that individual-level estimator variance v 1 is not observed by us, but aggregate-level estimator variance v 2 is directly available, the effect of interest for us is how the predictive power of a recommender system is affected by the redistri-bution of weights caused by aggregate variance v 2 .
One way to capture this effect is to allow the data  X  X peak for itself X  by finding the best weights that fit the data and verifying whether the dependence of weights on aggregate variance changes the predictive power. In order to accom-plish that, we employed the following hierarchical regression model (HR) where
The variables  X  r ij , r a j , Var( r a j ) constitute known parame-ters of the model, while  X  0 ,  X  1 ,  X  0 ,  X  1 ,  X  0 ,  X  1 The variable r  X  ij constitutes a dependent variable that we are trying to estimate; so it is known for the training sample, but unknown for the testing purposes.

This model not only incorporates the fact that the change in the aggregate variance affects the weighting scheme as in Theorems 1 and 2, but also that the aggregate variance affects the weight in monotonous fashion.

Furthermore, the classical recommender system algorithms constitute special cases of model (3). In this paper, we con-sider the following cases: 1. Individual Rating Estimator (IRE):  X  0 = 1 and all 2. Aggregate Rating Estimator (ARE):  X  0 = 1, all other 3. Blending Rating Estimator (BRE):  X  0 = 1  X   X  0 and 4. Simple regression (SR):  X  1 =  X  1 =  X  1 = 0. This
Note that the coefficients  X  0 ,  X  1 ,  X  0 ,  X  1 ,  X  0 and  X  not known in advance and need to be estimated from the training sample. There are several different ways to do it using the training sample [8] and the specifics of this process are described in Section 4.4.

In this section, we presented two theorems that provide a theoretical way to find an optimal linear combination of the two rating estimators assuming the variances of both estimators are known. Since for the individual-level rating estimator the variance is unknown, we proposed an alterna-tive way to utilize the intuition of the theorems: a hierarchi-cal regression model HR that captures the effect of weight redistribution in the linear combination of rating estimators.
In the following sections, we apply this model and its spe-cial cases (1) -(4) to real life datasets in order to see the effect of weight redistribution caused by aggregate variance on the predictive performance of recommender systems.
In this Section, we describe the data used in our exper-iments, partitioning of the data into the training and the testing sets, and the performance measures used in our ex-periments.
We used the following  X  X eal-life X  datasets for learning in-dividual ratings and empirically validating our methods.
We used the full MovieLens dataset [12] consisting of more than 1 million ratings of 3900 movies provided by 6040 users.
We also used a random subsample 2 of the Netflix Prize dataset [7] consisting of 10,000 users, 10,000 movies, and 1,000,000 ratings. This subsample was produced using the following procedure: 1. Select 10,000 random users from the set of all the Net-2. Select 10,000 random movies out of the movies that 3. Select 1,000,000 random ratings out of the ratings that
This dataset contains the release year for the movies and no attributes for the users since the Netflix Prize dataset [7] contains no data at all about their customers beyond the customer ID number. For movies, the Netflix Prize dataset [7] provides the movie title and the release year. For users X  ratings, the dataset contains the timestamp when the rating appeared on the website.
This is another random subsample of the Netflix Prize dataset [7] consisting of 1,000 users and 1,000 movies with 5,000 ratings. The subsample was produced using the same procedure as described in Section 4.1.2.
This is also a subset of the Netflix Prize dataset [7] con-sisting of 1,000 users and 1,000 movies with 5,000 ratings, that is produced using the same procedure as described in Section 4.1.2. The reason for including both Subsample #2 and Subsample #3 is that we used different kinds of train-ing/test split for these datasets as described in Section 4.4.
In order to introduce aggregate rating information from the external sources into the Individual Rating datasets de-scribed above, we extracted the average ratings of the movies
We decided to use subsamples instead of complete datasets for the sake of the speed of computations used in those datasets from the IMDB database [10], i.e. for each movie in the Individual Rating datasets, we attempted to find a corresponding average movie rating from IMDB. The results of this matching process are presented in the following table:
We also extracted the information from IMDB on the full distribution of given ratings similar to the one shown in Fig-ure 1 which we used to compute the aggregate variance for each movie.
For the individual-level estimators, we employed the fol-lowing two models: classical item-based collaborative filter-ing [15] and hierarchical linear model (HLM) from [5].
More specifically, as a first method, we employed classi-cal item-based collaborative filtering method from [15] with Pearson correlation measure of similarity and with the size of neighborhood equal to the complete number of items in the system.

As a second method, we employed HLM approach from [5] that estimates the unknown ratings r ij in terms of user characteristics, item characteristics and the interaction ef-fects between them. Interaction effects arise from the hier-archical structure of the model and are intended to capture effects such as, for example, how the age of a user changes his or her preferences for certain genres of movies.
In order to empirically validate our approach, we split each dataset into 10 subsets for the 10-fold cross validation. The Netflix #1, #3 Subsets and MovieLens database were split randomly into 10 subsets with 40% of the data going into training set and 60% of the data going into the test set. The reason for this kind of split is that we would also like to validate generalizability of our techniques. Recom-mender systems are characterized by the fact that typically only a small percentage of all possible ratings is known, for example, in the Netflix Prize Dataset [7] only  X  1 . 2% of all possible ratings is given. However, ideally, in order to recom-mend to each user the best set of items out of all available, the ratings for all the rest  X  98 . 8% have to be estimated. Therefore, recommender systems are characterized by hav-ing very small training set as compared to the potential test set.

We used more traditional split for another subsample dataset to show that our results are not dependent on the type of the split. The Netflix #2 dataset was split randomly into 10 subsets with 90% of the data going into training set and 10% of the data going into the test set.

Note that as mentioned in Section 3, the coefficients  X  0  X  ,  X  0 ,  X  1 and  X  0 ,  X  1 in equation (3) are not known in ad-vance and need to be estimated from the training sample.
There are several different ways to do it using the training sample [8]. In this paper, we consider the following two methods: 1. Splitting the training set into two: 2. Choosing a designated test set from the usual split:
These two splitting methods present a trade-off between using more data and computational performance. The method #1 sacrifices some of the training data in order to have the complete range of test sets. The method #2 sacrifices some of the test sets in order to determine the model parameters on them, while verifying the results on the smaller number of test sets. We employed both of these methods, but these methods produced so similar results that there is no point to present both. Clearly, this is not a surprising result since the sizes of the datasets that we employed are more than enough to determine precisely only 6 free parameters of the model (3). Therefore, we plotted only the graphs for the method #2, that is clearly much faster.
In order to present performance of our models in intuitive way, we show the evolution of mean squared error (MSE) performance of the model as more and more aggregate in-formation is introduced into the model.
 first k aggregate observations and incorporate them into the model as described in Section 5. Then, for each k , we cal-culate the mean squared error (MSE) of predictions of the models that use exactly k aggregate ratings across all the aforementioned test sets. Finally, we plot the graph of these MSEs for each value of k = 0 , 1 , 2 , 3 , . . . , as is shown, for example, in Figure 2 for the case of the MovieLens dataset. Note that k = 0 means that no aggregate rating information is used at all, and we are dealing with the basic individual rating prediction model in this case.
The graphs in Figures 2 -6 represent the mean squared error (MSE) performance of the item-based CF and HLM model as a function of the number of additional aggregate ratings introduced for 3 subsets of the Netflix Prize [7] and MovieLens datasets.

More specifically, these figures plot on the x -axis the cu-mulative number of additional aggregate ratings introduced into the model. The 0-th tick corresponds to the plain basic recommendation model without any aggregate ratings. The 1st tick corresponds to adding just one aggregate rating of type (3) for the first item, all other ratings for all other items are predicted using individual-level estimator. The 2nd tick adds one more aggregate rating of type for the second item, and so on. On the y -axis we plot the MSE performance of the model based on 10-fold cross-validation described in Section 4.

Note that Figures 2 -4 present the MSE performance im-provements of the item-based CF, while Figures 5 -6 present the MSE performance for the HLM model from [5] (pre-sented in Section 4.3). Figure 2: Item-based CF performance on MovieLens dataset
By examining Figures 2 -6, we can make the following observations: 1. The MSE errors tend to go down on average with the 2. The ARE method is better than the classical item-
Some of these graphs exhibit occasional upward jumps when new aggregate ratings are introduced, which cannot be truly observed in these figures because of large numbers of aggregate ratings on the x-axis of the graphs. Figure 3: Item-based CF performance on Netflix #1 subset Figure 4: Item-based CF performance on Netflix #2 subset 3. Combining individual and aggregate rating models, as 4. The HR and SR methods outperformed BRE. This is
Figure 5: HLM performance on Netflix #2 subset
Figure 6: HLM performance on Netflix #3 subset 5. The performance of the HR and the SR models is com-
Unfortunately, we cannot describe them in this paper be-cause of space limitation.
From all these results reported above, we can draw the following conclusions:
In [16], we presented an alternative way to introduce the aggregate average rating information into the HLM model. We utilized the specific model properties of the HLM model and showed that this additional aggregate information is equivalent to imposing linear constraints on model param-eters. We also demonstrated that in practice these addi-tional model constraints improve predictive performance of the method presented in [18].

Since, SR method performed surprisingly well, we decided to compare it with our previous work [18]. Figure 7 demon-strates the performance comparison of the SR method pre-sented in this paper and the  X  X ative X  HLM model parameter constraint method presented in [18].

According to Figure 7, HR and SR model achieved ap-proximately 2 . 5% MSE performance improvement, while the  X  X ative X  X LM method achieved only 1 . 4% MSE performance improvement on the same Netflix #2 dataset. Note, how-ever, that we cannot make any claims on superiority of ei-ther method, since X  X ative X  X LM method was not trained to the best MSE performance in the original paper [18], that method did not utilize its full potential in terms of MSE performance, since only the simplest weighting scheme for the newly aggregate information was used.
In this paper, we presented a new method for incorporat-ing aggregate rating information into the traditional indi-Figure 7: Comparison of simple regression approach with model-based approach vidual rating estimation methods, such as the classical col-laborative filtering or the hierarchical linear model (HLM) from [5]. Our approach is based on the optimal linear combi-nation of the individual and the aggregate rating estimators that also incorporate aggregate variance information into the model, called HR , in a hierarchical manner. We also con-sider a simplified non-hierarchical version of the HR model, called SR, that drops the variance information and, there-fore, constitutes an instance of a simple linear regression. We show that, surprisingly, the simple regression model SR performs as well as the more complicated hierarchical linear model HR. This means that the additional aggregate variance information does not really help, even though it is suggested by statistical theorems. We also show that the SR model outperforms various other models considered in the paper, including some of our previously studied models [18], and therefore, provides the best approach of incorpo-rating aggregate rating information into the individual-level models. One of the reasons that would create such a phe-nomenon is the fact that both the individual-level and the aggregate-level estimator variances increase in unison.
One of the reasons why the SR model outperforms some of the models from [18] is because these other models have certain types of restrictive assumptions imposed on them (in the form of the model form and fixed weights for the aggregate information). Therefore, as a part of the future work, we plan to extend the models in [18] so that the models use optimal weight assignments rather than a fixed constant. This would allow for additional more extensive comparisons between HR model, SR model and the models from [18].
Another direction for the future work is incorporating multiple levels of hierarchical aggregate information. In some cases several different aggregate ratings are available for a single individual rating on the different levels of aggre-gation hierarchy, such as, a known aggregate average rat-ing for all comedies by all females in addition to known aggregate average rating for all comedies by all females in New York. The question of the optimal linear combination of those ratings with individual rating and the statistical theory behind it constitutes one of the important directions for the future work in this area. [1] G. Adomavicius and Y. Kwon. Overcoming [2] G. Adomavicius, R. Sankaranarayanan, S. Sen, and [3] G. Adomavicius and A. Tuzhilin. Multidimensional [4] D. Agarwal, A. Broder, D. Chakrabarti, D. Diklic, [5] A. Ansari, S. Essegaier, and R. Kohli. Internet [6] R. Bell, Y. Koren, and C. Volinsky. Modeling [7] J. Bennett and S. Lanning. The Netflix Prize. [8] C. Bishop and N. Nasrabadi. Pattern Recognition and [9] J. Bollen. Group user models for personalized [10] IMDB. http://www.imdb.com. 2006. [11] A. Jameson and B. Smyth. Recommendation to [12] MovieLens. available at [13] M. O X  X onnor, D. Cosley, J. A. Konstan, and J. Riedl. [14] S. W. Raudenbush and A. S. Bryk. Hierarchical [15] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl. [16] A. Umyarov and A. Tuzhilin. Leveraging aggregate [17] A. Umyarov and A. Tuzhilin. Improving Collaborative [18] A. Umyarov and A. Tuzhilin. Leveraging aggregate
