 Making inferences based on natural-language state-ments is a crucial part of true natural-language un-derstanding, and thus has many important applica-tions. As the field of NLP has matured, there has been a resurgence of interest in creating systems ca-pable of making such inferences, as evidenced by the activity surrounding the ongoing sequence of  X  X ecognizing Textual Entailment X  (RTE) competi-tions (Dagan, Glickman, and Magnini, 2006; Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, and Szpektor, 2006; Giampiccolo, Magnini, Dagan, and Dolan, 2007) and the AQUAINT knowledge-based evaluation project (Crouch, Saur  X   X , and Fowler, 2005).

The following two examples help illustrate the particular type of inference that is the focus of this paper. 1.  X  We know the epidemic spread quickly  X  2.  X  We doubt the epidemic spread quickly  X  A relaxation of  X  spread quickly  X  is  X  spread  X ; a re-striction of it is  X  spread quickly via fleas  X . From statement 1, we can infer the relaxed version,  X  We know the epidemic spread  X , whereas the restricted version,  X  We know the epidemic spread quickly via fleas  X , does not follow. But the reverse holds for statement 2: it entails the restricted version  X  We doubt the epidemic spread quickly via fleas  X , but not the relaxed version. The reason is that  X  doubt  X  is a downward-entailing operator ; 1 in other words, it al-lows one to, in a sense,  X  X eason from sets to subsets X  (van der Wouden, 1997, pg. 90).

Downward-entailing operators are not restricted to assertions about belief or to verbs. For example, the preposition  X  without  X  is also downward entail-ing: from  X  The applicants came without payment or waivers  X  we can infer that all the applicants came without payment. (Contrast this with  X  with  X , which, like  X  know  X , is upward entailing .) In fact, there are many downward-entailing operators, encompassing many syntactic types; these include explicit nega-tions like  X  no  X  and  X  never  X , but also many other terms, such as  X  refuse (to)  X ,  X  preventing  X ,  X  nothing  X ,  X  rarely  X , and  X  too [adjective] to  X .
As the prevalence of these operators indicates and as van der Wouden (1997, pg. 92) states, downward entailment  X  X lays an extremely important role in natural language X  (van Benthem, 1986; Hoeksema, 1986; S  X  anchez Valencia, 1991; Dowty, 1994; Mac-Cartney and Manning, 2007). Yet to date, only a few systems attempt to handle the phenomenon in a gen-eral way, i.e., to consider more than simple direct negation (Nairn, Condoravdi, and Karttunen, 2006; MacCartney and Manning, 2008; Christodoulopou-los, 2008; Bar-Haim, Berant, Dagan, Greental, Mirkin, Shnarch, and Szpektor, 2008). These sys-tems rely on lists of items annotated with respect to their behavior in  X  X olar X  (positive or negative) envi-ronments. The lists contain a relatively small num-ber of downward-entailing operators, at least in part because they were constructed mainly by manual inspection of verb lists (although a few non-verbs are sometimes also included). We therefore propose to automatically learn downward-entailing opera-tors 2  X  henceforth DE operators for short  X  from data; deriving more comprehensive lists of DE op-erators in this manner promises to substantially en-hance the ability of textual-inference systems to han-dle monotonicity-related phenomena.
 Summary of our approach There are a num-ber of significant challenges to applying a learning-based approach. First, to our knowledge there do not exist DE-operator-annotated corpora, and more-over, relevant types of semantic information are  X  X ot available in or deducible from any public lexical database X  (Nairn et al., 2006). Also, it seems there is no simple test one can apply to all possible candi-dates; van der Wouden (1997, pg. 110) remarks,  X  X s a rule of thumb, assume that everything that feels negative, and everything that [satisfies a condition described below], is monotone decreasing. This rule of thumb will be shown to be wrong as it stands; but it sort of works, like any rule of thumb. X 
Our first insight into how to overcome these chal-lenges is to leverage a finding from the linguistics lit-erature, Ladusaw X  X  (1980) hypothesis , which can be treated as a cue regarding the distribution of DE op-erators: it asserts that a certain class of lexical con-structions known as negative polarity items (NPIs) can only appear in the scope of DE operators. Note that this hypothesis suggests that one can develop an unsupervised algorithm based simply on check-ing for co-occurrence with known NPIs.

But there are significant problems with apply-ing this idea in practice, including: (a) there is no agreed-upon list of NPIs; (b) terms can be ambigu-ous with respect to NPI-hood; and (c) many non-DE operators tend to co-occur with NPIs as well. To cope with these issues, we develop a novel unsuper-vised distillation algorithm that helps filter out the noise introduced by these problems. This algorithm is very effective: it is accurate and derives many DE operators that do not appear on pre-existing lists. Contributions Our project draws a connection be-tween the creation of textual entailment systems and linguistic inquiry regarding DE operators and NPIs, and thus relates to both language-engineering and linguistic concerns.

To our knowledge, this work represents the first attempt to aid in the process of discovering DE oper-ators, a task whose importance we have highlighted above. At the very least, our method can be used to provide high-quality raw materials to help human annotators create more extensive DE operator lists. In fact, while previous manual-classification efforts have mainly focused on verbs, we retrieve DE oper-ators across multiple parts of speech. Also, although we discover many items (including verbs) that are not on pre-existing manually-constructed lists, the items we find occur frequently  X  they are not some-how peculiar or rare.

Our algorithm is surprisingly accurate given that it is quite resource-and knowledge-lean. Specifically, it relies only on Ladusaw X  X  hypothesis as initial in-spiration, a relatively short and arguably noisy list of NPIs, and a large unannotated corpus. It does not use other linguistic information  X  for exam-ple, we do not use parse information, even though c-command relations have been asserted to play a key role in the licensing of NPIs (van der Wouden, 1997). We mentioned in the introduction some significant challenges to developing a machine-learning ap-proach to discovering DE operators. The key insight we apply to surmount these challenges is that in the linguistics literature, it has been hypothesized that there is a strong connection between DE operators and negative polarity items (NPIs) , which are terms that tend to occur in  X  X egative environments X . An example NPI is  X  anymore  X : one can say  X  We don X  X  have those anymore  X  but not  X  We have those any-more  X .

Specifically, we propose to take advantage of the seminal hypothesis of Ladusaw (1980, influenced by Fauconnier (1975), inter alia): This hypothesis has been actively discussed, up-dated, and contested by multiple parties (Linebarger, 1987; von Fintel, 1999; Giannakidou, 2002, inter alia). It is not our intent to comment (directly) on its overall validity. Rather, we simply view it as a very useful starting point for developing computational tools to find DE operators X  indeed, even detractors of the theory have called it  X  X mpressively algorith-mic X  (Linebarger, 1987, pg. 361).

First, a word about scope. For Ladusaw X  X  hypoth-esis, scope should arguably be defined in terms of c-command, immediate scope, and so on (von Fintel, 1999, pg. 100). But for simplicity and to make our approach as resource-lean as possible, we simply as-sume that potential DE operators occur to the left of NPIs, 3 except that we ignore text to the left of any preceding commas or semi-colons as a way to en-force a degree of locality. For example, in both  X  By the way, we don X  X  have plants anymore they died  X  and  X  we don X  X  have plants anymore we look for DE operators within the sequence of words  X  we don X  X  have plants  X . We refer to such se-quences in which we seek DE operators as NPI con-texts .
Now, Ladusaw X  X  hypothesis suggests that we can find DE operators by looking for words that tend to occur more often in NPI contexts than they occur overall. We formulate this as follows: Here, F byNPI p d q is the number of occurrences of d in NPI contexts 4 divided by the number of words in NPI contexts, and F p x q refers to the number of occurrences of x relative to the number of words in the corpus.

An additional consideration is that we would like to focus on the discovery of novel or non-obvious DE operators. Therefore, for a given candidate DE operator c , we compute p F byNPI p c q : the value of F texts containing a DE operator on a list of 10 well-known instances , namely,  X  not  X ,  X  n X  X   X ,  X  no  X ,  X  none  X , (This list is based on the list of DE operators used by the RTE system presented in MacCartney and Man-ning (2008).) This yields the following scoring func-tion: Distillation There are certain terms that are not DE operators, but nonetheless co-occur with NPIs as a side-effect of co-occurring with true DE operators themselves. For instance, the proper noun  X  Milken  X  (referring to Michael Milken, the so-called  X  X unk-bond king X ) occurs relatively frequently with the DE operator  X  denies  X , and  X  vigorously  X  occurs frequently with DE operators like  X  deny  X  and  X  oppose  X . We re-fer to terms like  X  milken  X  and  X  vigorously  X  as  X  X ig-gybackers X , and address the piggybackers problem by leveraging the following intuition: in general, we do not expect to have two DE operators in the same NPI context. 5 One way to implement this would be to re-score the candidates in a winner-takes-all fash-ion: for each NPI context, reward only the candidate with the highest score S . However, such a method is too aggressive because it would force us to pick a single candidate even when there are several with relatively close scores  X  and we know our score S is imperfect. Instead, we propose the following  X  X oft X  mechanism. Each sentence distributes a  X  X udget X  of total score 1 among the candidates it contains ac-cording to the relative scores of those candidates; this works out to yield the following new distilled scoring function where n p p q izing factor and N p c q is the number of NPI con-texts containing the candidate c . This way, plausi-ble candidates that have high S scores relative to the other candidates in the sentence receive enhanced S d scores. To put it another way: apparently plausible candidates that often appear in sentences with mul-tiple good candidates (i.e., piggybackers) receive a low distilled score, despite a high initial score.
Our general claim is that the higher the distilled score of a candidate, the better its chances of being a DE operator.
 Choice of NPIs Our proposed method requires ac-cess to a set of NPIs. However, there does not ap-pear to be universal agreement on such a set. Lichte and Soehn (2007) mention some doubts regarding approximately 200 (!) of the items on a roughly 350-item list of German NPIs (K  X  urschner, 1983). For English, the  X  X oderately complete X  6 Lawler (2005) list contains two to three dozen items; however, there is also a list of English NPIs that is several times longer (von Bergen and von Bergen, 1993, written in German), and Hoeksema (1997) asserts that English should have hundreds of NPIs, similarly to French and Dutch.

We choose to focus on the items on these lists that seem most likely to be effective cues for our task. Specifically, we select a subset of the Lawler NPIs, focusing mostly on those that do not have a relatively frequent non-NPI sense. An example discard is  X  much  X , whose NPI-hood depends on what it modifies and perhaps on whether there are degree adverbs pre-modifying it (Hoeksema, 1997). There are some ambiguous NPIs that we do retain due to their frequency. For example,  X  any  X  occurs both in a non-NPI  X  X ree choice X  variant, as in  X  any idiot can do that  X , and in an NPI version. Although it is ambiguous with re-spect to NPI-hood,  X  any  X  is also a very valuable cue due to its frequency. 7 Here is our NPI list: Our main set of evaluations focuses on the precision of our method at discovering new DE operators. We then briefly discuss evaluation of other dimensions. 3.1 Setup We applied our method to the entirety of the BLLIP (Brown Laboratory for Linguistic Information Pro-cessing) 1987 X 89 WSJ Corpus Release 1, available from the LDC (LDC2000T43). The 1,796,379 sen-tences in the corpus comprise 53,064 NPI contexts; after discarding the ones containing the 10 well-known DE operators, 30,889 NPI contexts were left. To avoid sparse data problems, we did not consider candidates with very low frequency in the corpus (  X  150 occurrences) or in the NPI contexts (  X  10 oc-currences).
 Methodology for eliciting judgments The obvi-ous way to evaluate the precision of our algorithm is to have human annotators judge each output item as to whether it is a DE operator or not. However, there are some methodological issues that arise.

First, if the judges know that every term they are rating comes from our system and that we are hoping that the algorithm extracts DE operators, they may be biased towards calling every item  X  X E X  regard-less of whether it actually is. We deal with this prob-lem by introducing distractors  X  items that are not produced by our algorithm, but are similar enough to not be easily identifiable as  X  X akes X . Specifically, for each possible part of speech of each of our sys-tem X  X  outputs c that exists in WordNet, we choose a distractor that is either in a  X  X ibling X  synset (a hy-ponym of c  X  X  hypernym) or an antonym. Thus, the distractors are highly related to the candidates. Note that they may in fact also be DE operators.
The judges were made aware of the presence of a substantial number of distractors (about 70 for the set of top 150 outputs). This design choice did seem to help ensure that the judges carefully evaluated each item.

The second issue is that, as mentioned in the in-troduction, there does not seem to be a uniform test that judges can apply to all items to ascertain their DE-ness; but we do not want the judges to impro-vise excessively, since that can introduce undesir-able randomness into their decisions. We therefore encouraged the judges to try to construct sentences wherein the arguments for candidate DE operators were drawn from a set of phrases and restricted replacements we specified (example:  X  singing  X  vs  X  singing loudly  X ). However, improvisation was still required in a number of cases; for example, the can-didate  X  act  X , as either a noun or a verb, cannot take  X  singing  X  as an argument.

The labels that the judges could apply were  X  X E(ND) X  (downward entailing (narrowly-defined)),  X  X uperlative X ,  X  X omparative X ,  X  X ondi-tional X ,  X  X ard to tell X , and  X  X ot-DE X  (= none of the above). We chose this fine-grained sub-division because the second through fourth categories are all known to co-occur with NPIs. There is some debate in the linguistics literature as to whether they can be considered to be downward entailing, narrowly construed, or not (von Fintel, 1999, inter alia), but nonetheless, such operators call for special reasoning quite distinct from that required when dealing with upward entailing operators  X  hence, we consider it a success when our algorithm identifies them.

Since monotonicity phenomena can be rather sub-tle, the judges engaged in a collaborative process. Judge A (the second author) annotated all items, but worked in batches of around 10 items. At the end of each batch, Judge B (the first author) reviewed Judge A X  X  decisions, and the two consulted to resolve dis-agreements as far as possible.

One final remark regarding the annotation: some decisions still seem uncertain, since various factors such as context, Gricean maxims, what should be presupposed 8 and so on come into play. However, we take comfort in a comment by Eugene Charniak (personal communication) to the effect that if a word causes a native speaker to pause, that word is inter-esting enough to be included. And indeed, it seems reasonable that if a native speaker thinks there might be a sense in which a word can be considered down-ward entailing, then our system should flag it as a word that an RTE system should at least perhaps pass to a different subsystem for further analysis. 3.2 Precision Results We now examine the 150 items that were most highly ranked by our system, which were sub-sequently annotated as just described. (For full system output that includes the unannotated items, see http://www.cs.cornell.edu/ cristian . We would welcome external anno-tation help.) As shown in Figure 1a, which depicts precision at k for various values of k , our system performs very well. In fact, 100% of the first 60 out-puts are DE, broadly construed. It is also interesting to note the increasing presence of instances that the judges found hard to categorize as we move further down the ranking.

Of our 73 distractors, 46% were judged to be members of one of our goal categories. The fact that this percentage is substantially lower than our algo-rithm X  X  precision at both 73 and 150 (the largest k we considered) confirms that our judges were not mak-ing random decisions. (We expect the percentage of DE operators among the distractors to be much higher than 0 because they were chosen to be simi-lar to our system X  X  outputs, and so can be expected to also be DE operators some fraction of the time.)
Table 1 shows the lemmas of just the DE(ND) op-erators that our algorithm placed in its top 150 out-puts. 9 Most of these lemmas are new discoveries, in the sense of not appearing in Ladusaw X  X  (1980) (im-plicit) enumeration of DE operators. Moreover, the lists of DE(ND) operators that are used by textual-entailment systems are significantly smaller than that depicted in Table 1; for example, MacCartney and Manning (2008) use only about a dozen (per-sonal communication).

Table 3 shows examples of the words in our sys-tem X  X  top 150 outputs that are either clear mistakes or hard to evaluate. Some of these are due to id-iosyncrasies of newswire text. For instance, we of-ten see phrases like  X  biggest one-day drop in ...  X , where  X  one-day  X  piggybacks on superlatives, and  X  vowed  X  piggybacks on the DE operator  X  veto  X , as in the phrase  X  vowed to veto  X .
 Effect of distillation In order to evaluate the im-portance of the distillation process, we study how the results change when distillation is omitted (thus using as score function S from Equation 1 rather than S d ). When comparing the results (summarized in Figure 1b) with those of the complete system (Figure 1a) we observe that the distillation indeed has the desired effect: the number of highly ranked words that are annotated as not-DE decreases after distillation. This results in an increase of the preci-sion at k ranging from 5% to 10% (depending on k ), as can be observed by comparing the height of the composite bars in the two figures. 10
Importantly, this improvement does indeed seem to stem at least in part from the distillation process handling the piggybacking problem. To give just a few examples:  X  vigorously  X  is pushed down from rank 48 (undistilled scoring) to rank 126 (distilled scoring),  X  one-day  X  from 25 th to 65 th ,  X  vowed  X  from 45 th to 75 th , and  X  Milken  X  from 121 st to 350 th . 3.3 Other Results It is natural to ask whether the (expected) decrease in precision at k is due to the algorithm assigning relatively low scores to DE operators, so that they do not appear in the top 150, or due to there be-ing no more more true DE operators to rank. We cannot directly evaluate our method X  X  recall because no comprehensive list of DE operators exists. How-ever, to get a rough impression, we can check how our system ranks the items in the largest list we are aware of, namely, the Ladusaw (implicit) list men-tioned above. Of the 31 DE operator lemmas on this list (not including the 10 well-known DE operators), only 7 of those frequent enough to be considered by our algorithm are not in its top 150 outputs, and only 5 are not in the top 300. Remember that we only an-notated the top 150 outputs; so, there may be many other DE operators between positions 150 and 300.
Another way of evaluating our method would be to assess the effect of our newly discovered DE op-erators on downstream RTE system performance. There are two factors to take into account. First, the DE operators we discovered are quite prevalent in naturally occurring text 11 : the 90 DE(ND) operators appearing in our algorithm X  X  top 150 outputs occur in 111,456 sentences in the BLLIP corpus (i.e., in 6% of its sentences). Second, as previously men-tioned, systems do already account for monotonic-ity to some extent  X  but they are limited by the fact that their DE operator lexicons are restricted mostly to well-known instances; to take a concrete example with a publicly available RTE system: Nutcracker (Bos and Markert, 2006) correctly infers that  X  We did not know the disease spread  X  entails  X  We did not know the disease spread quickly  X  but it fails to in-fer that  X  We doubt the disease spread  X  entails  X  We doubt the disease spread quickly  X . So, systems can use monotonicity information but currently do not have enough of it; our method can provide them with this information, enabling them to handle a greater fraction of the large number of naturally occurring instances of this phenomenon than ever before. Magnini (2008), in describing modular approaches to textual entailment, hints that NPIs may be used within a negation-detection sub-component.

There is a substantial body of work in the linguis-tics literature regarding the definition and nature of polarity items (Polarity Items Bibliography). How-ever, very little of this work is computational. There has been passing speculation that one might want to learn polarity-inverting verbs (Christodoulopou-los, 2008, pg. 47). There have also been a few projects on the discovery of NPIs, which is the con-verse of the problem we consider. Hoeksema (1997) discusses some of the difficulties with corpus-based determination of NPIs, including  X  X ampant X  poly-semy and the problem of  X  X ow to determine inde-pendently which predicates should count as nega-tive X   X  a problem which our work addresses. Lichte and Soehn (Lichte, 2005; Lichte and Soehn, 2007) consider finding German NPIs using a method con-ceptually similar in some respects to our own, al-though again, their objective is the reverse of ours. Their discovery statistic for single-word NPIs is the ratio of within-licenser-clause occurrences to total occurrences, where, to enhance precision, the list of licensers was filtered down to a set of fairly unam-biguous, easily-identified items. They do not con-sider distillation, which we found to be an impor-tant component of our DE-operator-detection algo-rithm. Their evaluation scheme, unlike ours, did not employ a bias-compensation mechanism. They did employ a collocation-detection technique to extend their list to multi-word NPIs, but our independent experiments with a similar technique (not reported here) did not yield good results. To our knowledge, this work represents the first at-tempt to discover downward entailing operators. We introduced a unsupervised algorithm that is moti-vated by research in linguistics but employs simple distributional statistics in a novel fashion. Our algo-rithm is highly accurate and discovers many reason-able DE operators that are missing from pre-existing manually-built lists.

Since the algorithm is resource-lean  X  requiring no parser or tagger but only a list of NPIs  X  it can be immediately applied to languages where such lists exist, such as German and Romanian (Trawi  X  nski and Soehn, 2008). On the other hand, although the re-sults are already quite good for English, it would be interesting to see what improvements could be gained by using more sophisticated syntactic infor-mation.

For languages where NPI lists are not extensive, one could envision applying an iterative co-learning approach: use the newly-derived DE operators to in-fer new NPIs, and then discover even more new DE operators given the new NPI list. (For English, our initial attempts at bootstrapping from our initial NPI list on the BLLIP corpus did not lead to substantially improved results.)
In practice, subcategorization is an important fea-ture to capture. In Table 1, we indicate which sub-categorizations are DE. An interesting extension of our work would be to try to automatically distin-guish particular DE subcategorizations that are lex-ically apparent, e.g.,  X  innocent  X  (not DE) vs.  X  inno-cent of  X  (as in  X  innocent of burglary  X , DE).
Our project provides a connection (among many) between the creation of textual entailment systems (the domain of language engineers) and the char-acterization of DE operators (the subject of study and debate among linguists). The prospect that our method might potentially eventually be refined in such a way so as to shed at least a little light on lin-guistic questions is a very appealing one, although we cannot be certain that any progress will be made on that front.

