 Current search engines offer limited assistance for exploration and information discovery in complex search tasks. Instead, users are distracted by the need to focus their cognitive efforts on finding navigation cues, rather than selecting relevant information. In-teractive intent modeling enhances the human information explo-ration capacity through computational modeling, visualized for in-teraction. Interactive intent modeling has been shown to increase task-level information seeking performance by up to 100%. In this demonstration, we showcase SciNet , a system implementing inter-active intent modeling on top of a scientific article database of over 60 million documents.
 Intent modeling; Interactive information retrieval; Personalization; Visual information seeking H.3.3 [ Information Search and Retrieval ]
Recent behavioral studies show that a large portion of users X  information-seeking activities are exploratory and characterized by the complex and evolving nature of users X  information needs [4]. As a result, the users face the problem of entering correct terms that describe their evolving search intents, so that the desired in-formation can be retrieved on subsequent iterations [2]. We pro-pose Interactive intent modeling promoting resourceful interaction between humans and information retrieval systems to enable infor-mation discovery that goes beyond search [6]. It tackles the vocab-ulary mismatch problem [2] by providing the user with knowledge about potential intents to discover, visualizes the intents as direc-tions in the information space around the user X  X  present position, and transfers the exploratory search to a recognition task in which users can direct their search via an interactive visualization to in-teract with the system X  X  intent model [7].
 Interactive intent modeling is based on two principles [6]: 1) Visu-alizing the current search intents and directions in the information space, and 2) Interactive adaptation of the intent model balancing exploring the information space and exploiting the user feedback.
The SciNet system, shown in Figure 1, implements interactive in-tent modeling on top of over 60 million scientific documents. The search starts with the user typing in a query, which results in a set of keywords being displayed and laid out on a radial display called the Intent Radar [8], and a ranked list of articles. The estimated in-tents, for which the results on the right side list have been retrieved, are visualized for the user (inner circle). The angular distance cor-responds to similarity of intents and the radial distance from the centre corresponds to relevance. Predicted future intents, which are estimated for users to find directions on the radar away from their present intent estimate, are visualized in the outer circle of the Intent Radar. The user can provide positive feedback by dragging keywords closer to the center of the radar, and negative feedback by dragging them further away. Multiple keywords can be dragged at each iteration.
 Figure 1 shows two iterations of a search session: the Intent Radar visualization of the first iteration (left) and the second iteration with both the visualization and the final result list. The user first issues a query  X  X nformation visualization X  and the system visualizes the intent model (inner circle) and suggested potentially interesting in-tents (outer circle) as keywords, and a ranked document list. The user increases the relevance of  X  X isual information retrieval X  (red arrow) by dragging it to the center of the radar. The system then computes and visualizes new intent model represented as a set of keywords (inner circle), including  X  X mage representation and in-dexing, X   X  X erception, X  and  X  X isual data exploration. X  The system also computes projections in the intent space via pseudo-feedback and suggests relevant search directions for the user (outer circle), including  X  X ww, X   X  X nformation fidelity, X   X  X nformation visualiza-tion techniques, X   X  X nteraction. X  The user can continue the search by selecting to exploit to more specific topics or to explore to more general but yet relevant topics.
Learning the intent model. Given the evolutionary nature of search, as also demonstrated in our example search scenario, it is important to not only exploit the feedback elicited from the user Both the Intent Radar visualization and the final result list are shown. but also balance it with exploration. To put it simply, users need to be able to focus on a specific location of the information space (ex-ploit) and also be able to broaden their search through more gen-eral areas (explore). To learrn such models on-line, we use the exploration X  X xploitation paradigm of reinforcement learning [1, 3]. In this paradigm, the model (the search engine) and its envi-ronment (the user) form an online loop, and learning involves find-ing an optimal balance between exploration (selecting items from uncharted parts of the information space) and exploitation (select-ing items most likely to be relevant given the current intent model) to acquire feedback on subsequent iterations. The learning mech-anism predicts the model consisting of keyword relevances based on user interactions during the search session. The model is then used in combination with a statistical language model to rank the documents.
 Interactive visualization. We optimize a data-driven layout for the search intents by probabilistic modeling-based nonlinear dimen-sionality reduction [9]. The task of the layout algorithm is to place keywords so that neighboring keywords on the display have neigh-boring characterizations. To highlight the structure in the outer cir-cle layout, we apply a simple agglomerative clustering to angles of keywords in the outer circle and show for each cluster the label of the predicted most relevant keyword [7].
The SciNet system was studied in task-based experiments in which users were given 30 minutes to solve research tasks using information retrieval systems operating on a database of over 60 million scholarly articles. The system setup with interactive intent modeling was compared against conventional information retrieval system with a list-based visualization and interaction with typed queries. Interactive intent modeling was found to significantly im-prove users X  task performance on complex tasks, helping users to move away from their initial query context, thus allowing them to increase recall by over 50% while preserving precision. Moreover, session-level recall for novel information that was assessed sepa-rately was found to improve by over 100% [7, 5]. The improve-ments can be attributed to interactive intent modeling. The inter-action with intent visualization does not fully replace the query-typing interaction, but users still rely on typed keywords when ini-tializing new search directions. However, interactive intent model-ing offers an additional complementary way to express search in-tents to direct search towards novel, but still relevant information. Certain data included herein are derived from the Web of Science prepared by THOMSON REUTERS, Inc., Philadelphia, Pennsylvania, USA; the Digital Libraries of ACM, IEEE, and Springer. The search engine is commercialized by Etsimo Ltd. (www.etsimo.com).
