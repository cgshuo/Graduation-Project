 Recent research efforts have made notable progress in improving the performance of (exhaustive) maximal clique enumeration (MCE). However, existing algorithms still suffer from exploring the huge search space of MCE. Furthermore, their results are often undesir-able as many of the returned maximal cliques have large overlap-ping parts. This redundancy leads to problems in both computa-tional efficiency and usefulness of MCE.

In this paper, we aim at providing a concise and complete sum-mary of the set of maximal cliques, which is useful to many ap-plications. We propose the notion of  X  -visible MCE to achieve this goal and design algorithms to realize the notion. Based on the refined output space, we further consider applications includ-ing an efficient computation of the top-k results with diversity and an interactive clique exploration process. Our experimental results demonstrate that our approach is capable of producing output of high usability and our algorithms achieve superior efficiency over classic MCE algorithms.
 H.2.8 [ DATABASE MANAGEMENT ]: Database Applications X  Data mining ; G.2.2 [ DISCRETE MATHEMATICS ]: Graph The-ory X  Graph algorithms Algorithms, Performance Maximal clique enumeration, clique summarization, clique concise representation
Let G =( V,E ) be a simple undirected graph. A subset of ver-tices, C  X  V , is called a clique if the subgraph of G induced by C is a complete subgraph, and C is called a maximal clique if there exists no clique C in G such that C  X  C . The process of Maximal clique enumeration ( MCE ) is to enumerate the set of all maximal cliques in G .

MCE is a fundamental problem in graph theory and has been extensively studied [5, 6, 21]. Existing works have been focusing on improving the efficiency of MCE in real world graphs and in recent years, a number of new algorithms [8, 9, 10, 13] have been proposed for MCE in large graphs. However, an important issue of MCE has been largely ignored so far, that is, the output size of MCE, i.e., the number of maximal cliques (especially in a large graph), is often exceedingly large so that it has severely thwarted the applications of MCE in practice.

We give a number of problems arisen from the large output size of MCE as follows. First, it is often very expensive to output and store the result set since the set of maximal cliques is too large to be kept in memory and sometimes even on disk. Second, even though the output of MCE may be pipelined to another application program, it is still difficult to process and analyze the large number of maximal cliques. Third, there exists a high level of redundancy in the set of maximal cliques since vertices are often duplicated in multiple maximal cliques.
 To address the problem caused by the sheer output size of classic MCE, we propose to compute a summary of the set of maximal cliques. In particular, we require a summary to be small in size, able to represent the whole set of maximal cliques with a minimal level of redundancy, and quick to compute (therefore post-processing is not acceptable).

A concise yet complete summary of all maximal cliques in a graph can be useful in a wide range of applications. For example,
We make the following main contributions in this paper. Paper organization. The rest of the paper is organized as follows. Section 2 surveys related work. Section 3 further motivates the problem with an analysis of classic backtracking MCE algorithms and then defines the problem of  X  -visible MCE. Section 4 presents the algorithms for  X  -visible MCE. Section 5 discusses applications of  X  -visible summary. Section 6 reports the experimental results. Section 7 concludes the paper.
The classical maximal clique enumeration algorithm that is widely in use was proposed in [5] by Bron and Kerbosch. It is a depth-first search algorithm with the property that consecutively gener-ated maximal cliques are likely to be similar. Tomita et al. intro-duced a variant of the Bron-Kerbosch algorithm which is optimal in the maximum possible number of maximal cliques in [21]. This number was shown to be exponential in [18]. Eppstein et al. [13] introduced a method for listing all maximal cliques in sparse graphs in near-optimal time. For massive graphs, IO-efficient algorithms were studied by Cheng et al. in [10] and [8, 9]. The smallest mean-ingful clique in a graph is a triangle and the problem of listing all triangles was studied by Chu et al. in [11, 12] for massive graphs.
There are related works on returning meaningful subgraphs that are close to cliques. A quasi-clique Q is almost a clique in the sense that each vertex in Q is connected to at least a portion of  X  ( 0 &lt; X   X  1 ) of the other vertices in Q . Matsuda et al. [17] proposed an approximation algorithm to find a minimum number of quasi-cliques to cover all vertices in the given graph. For mining all quasi-cliques with given size and  X  thresholds, the fastest algorithm is due to Liu et al. [16]. Pei et al. [20] studied the problem of cross-graph quasi-cliques. Abello et al. considered  X  -cliques in a graph G ,wherea  X  -clique S is a set of vertices such that the induced subgraph in G is connected and contains at least  X   X  | S | a randomized adaptive search algorithm was proposed to find a  X  -clique with the maximum size [1]. Note that the objective of the above methods is to generate maximal cliques as well as subgraphs that are not cliques but close to cliques. Our objective is to alleviate the problem of returning too many maximal cliques to the user in the case where the cliques are highly overlapping and most of the results do not add values for the user. Our returned result is a subset of the set of all maximal cliques.

The problem of result diversification has been well studied for information retrieval. Without system support, a user may need to submit multiple queries to retrieve results of different natures. Vee et al. [22] formally defined diversity and introduced techniques that guarantee diversity. In [3], the problem of DIVERSIFY( K ) is to return the top K results that can best cover different possible categorizations of the query. A greedy algorithm is proposed with an approximation guarantee of (1  X  1 /e ) . Another way to select meaningful results is based on typical instances which represent a category of interest [14].

A similar problem of finding diverse results arises in data min-ing for discovering frequent patterns. In many applications the re-turned set of frequent patterns from data mining is very large and contains much redundancy. Similar to the problem in information retrieval, the mining result becomes unmanageable for the user. In [2], the aim is to find a small number of item sets which can best approximate a collection of sets. Yan et al. [25] considered how to summarize a large set of patterns using K representatives. Xin et al. [24] considered the mining of redundancy-aware top-k patterns.
Our  X  -visible summary may be applied to visualize a large graph [15] using local substructures, visualizing a large graph can also use global structures such as k -trusses [23] and k -cores [7].
We first briefly review the classic recursive backtracking proce-dure that exhaustively enumerates all maximal cliques in an undi-rected graph G . We identify the drawbacks of the traditional MCE computation and then propose a new type of redundancy-aware maximal cliques .
We denote by N ( v ) the set of neighbors of a vertex v in G ,and by M ( G ) the set of all maximal cliques in G . A classic MCE algorithm relies on recursive calls to Procedure ProcMCE ,which is outlined in Procedure 1. The algorithm takes a graph G as input and initially invokes ProcMCE (  X  ,V,  X  ) . The recursive procedure finally returns M ( G ) .

In Procedure 1, the basic idea is to recursively backtrack to add a vertex from the set of candidate vertices in T to grow the current
Procedure 1: ProcMCE( C , T , D ) clique C .Avertex v is a candidate to C if and only if v is a neigh-bor of all vertices in C . Each time when C is augmented by a vertex v ,werefine T by keeping only the vertices that are also neighbors of v .When T becomes empty, C cannot be further grown. At this point, we need to check whether C is indeed maximal. To do this, we maintain a set D which keeps the set of vertices that are neigh-bors of all vertices in C and have been outputted as part of some maximal clique earlier, i.e., the recursive procedure has outputted some maximal clique C  X  ( C  X  X  v } ) earlier, where v  X  D . Thus, if D is not empty, C is not a maximal clique; otherwise, we output C as a maximal clique.

The pivot vertex v p is used for pruning such that we do not need to start growing a maximal clique from any neighbor v of v cause a maximal clique containing v can be enumerated from either v or some neighbor u of v where u is not a neighbor of v p . Drawbacks. The above algorithm achieves the optimal worst-case time complexity [21], which is O (3 | V | / 3 ) .For d -degenerate graphs, the complexity is reduced to O ( | V | 3 d/ 3 ) [13]. In either case, however, the number of maximal cliques is exponential in either | V | or d , which is not practical for large graphs. For most real world graphs, the number of maximal cliques can be significantly larger than the size of the input graph.

The time taken to compute and output the set of all maximal cliques is generally large in practice. In fact, even if we can toler-ate the prolonged running time, the storage space required is often large and the sheer number of maximal cliques also makes it im-practical to use them in real applications.

Another problem with the set of maximal cliques is that there are a significant level of redundancy as many maximal cliques share a large portion of common vertices. Thus, it is not very useful to re-port all these cliques since they deliver a large amount of duplicate information. Such redundancy also slows down the computation significantly without delivering much more new information dur-ing the MCE process. Therefore, it is questionable that we always follow the classic exhaustive search approach for maximal clique reporting.
To address the drawbacks of the classic MCE approach, we pro-pose to compute redundancy-aware maximal cliques and we show that the computation process is efficient and the result set is able to convey information possessed by the set of all maximal cliques effectively.

We first introduce the notion of visibility that measures how well each maximal clique is revealed by a subset S of the set M
D EFINITION 1(V ISIBILITY ). Let S X  X  ( G ) be any subset of maximal cliques of G . We define the visibility of a maximal
Figure 1: Illustration of visibility and  X  -visible summary clique C  X  X  ( G ) with respect to S , denoted by V S ( C ) ,tobethe maximum ratio of coverage of C by any C  X  X  , i.e., V S ( C )= When the context is clear regarding S , we write V ( C ) instead of V ( C ) for short. On the basis of visibility, we define the problem of  X  -visible MCE as follows.
 D EFINITION 2(  X  -V ISIBLE MCE). The problem of  X  -visible MCE is to compute a  X  -visible summary , S X  X  ( G ) , such that the visibility of each C  X  X  ( G ) with respect to S is at least  X  , i.e., V ( C )  X   X  .

The notion of  X  -visible MCE provides us with the flexibility of trading the completeness of M ( G ) for a  X  -visible summary of M ( G ) that is more usable and more efficient to compute, in a con-trollable manner by adjusting the value of  X  .

E XAMPLE 1. In Figure 1(a), we show a graph with 3 maxi-mal cliques, namely C 1 = {a,b,c,d,f}, C 2 = {a,b,d,e,f}, and C 3 = {b,d,f,g}. It can be seen that the three cliques overlap in most of the vertices. If we set S = { C 2 } as shown in bold in Figure 1(b), then the visibility of C 1 , V S ( C 1 ) , is 0.8, and that of C Hence { C 2 } is a 0.75-visible summary. Similarly, { C 2 0.8-visible summary.

In the rest of the paper, we will discuss (1) efficient computation of  X  -visible MCE, for which we show that our algorithms drasti-cally outperform that for classic MCE, and (2) retrieval of the k best (top-k ) maximal cliques based on  X  -visible MCE. To reduce the redundancy in the result set returned by classic MCE, we first propose a randomized algorithm to obtain a sample summary of M ( G ) with an expected visibility of at least  X  .We then devise a method with similar powerful pruning technique to derandomize the randomized algorithm. The new algorithm com-putes an exact  X  -visible summary.
A common approach to reducing the output size is to use a sam-ple of smaller size to summarize the whole output space. However, in the case of maximal cliques, a simple uniform sampling can miss important details while the redundancy may not be effectively re-duced. To obtain a quality sample, we investigate the output pattern of classic MCE algorithms.

Our randomized algorithm is based on the important observa-tion that although the maximal cliques can be huge in number, an MCE algorithm (based on backtracking) typically outputs in an or-der such that two cliques tend to be similar if they are near in the output sequence. This is because the searching process follows a depth-first order. This property allows us to (1) avoid reporting a Algorithm 2: Summarization by Sampling clique largely overlapping with the previously reported clique and (2) effectively prune the search space. Both (1) and (2) can be per-formed with only the local knowledge of the search tree without examining all the previous outputs.

As outlined in Algorithm 2, the processes of sampling and prun-ing are embedded in a backtracking-based MCE algorithm. Specifi-cally, pruning is performed when the MCE process is starting a new search subtree T (Lines 5-8), while sampling is executed when a maximal clique is found by the MCE algorithm (on a non-pruned branch of the search tree) (Line 9).

First, we discuss sampling (Line 9). Let us consider whether a found maximal clique C should be reported. Let C be the maximal clique previously added to S . We retain C with a probability that is adaptive to its similarity to C . Formally, we add C to S ability | C | s ( r ) ,where r = | C  X  C | / | C | ,and s :[0 , 1) is the sampling probability function. We require s to be monoton-ically decreasing. We will show later in Theorem 1 that the prob-ability of each C chosen in S is at least s ( r ) . In other words, the larger portion of C is covered by its predecessor C , the lower prob-ability we add C to S . We remark that without the local similarity between maximal cliques in the output sequence of classic MCE, we will need a costly computation of | C  X  C | for all C  X  X 
Next, we discuss how we employ pruning to speedup the search whenever the MCE process is going to start a new search subtree T (Lines 5-8). Let d be the depth of T ,and d be an upper bound of d (we will discuss how we compute d shortly). Then, the size of each clique P to be generated from T is at most l = | C | On the other hand, we want to have | C  X  P | lower-bounded. Let Y = T \ C ,and t = | P \ C | (i.e., t vertices are used to grow C to P ). Part of the t vertices are taken from Y and the rest are from T  X  C . Assume that y t out of t vertices are taken from Y ,and let y t be an upper bound of y t ( y t will be estimated similarly as d ). First, C is known and we know | C  X  P | X | C  X  C | . Second, we know that y t (out of t ) vertices in P (or precisely in P in C  X  P since these y t vertices are taken from Y = T \ C . Thus, we have | C  X  P | X | C  X  C | +max { t  X  y t , 0 } .

Finally, by enumerating t , we can lower bound the ratio of P covered by C by Figure 2: Illustration of summarization by sampling with max-imal clique C contained in T l ,where l = | C | ,and r i (resp. l r (resp. l ) in Algorithm 2 associated with T i .

The search space represented by the search subtree T is only ex-panded with probability l s (  X  r ) . This probability is devised based on the idea as illustrated in Figure 2, which can be viewed as multi-layer sampling over levels of the search tree, where the samples from an upper level are cascaded downwards to the next lower level. Figure 3: Local similarity in running ProcMCE on a graph: (a) input graph G , (b) search tree for G
E XAMPLE 2. Consider the execution of ProcMCE (  X , V,  X  ) on the graph in Figure 3(a), where V = { 1 , 2 , 3 , 4 , 5 , 6 , 7 5of ProcMCE , we choose a pivot v p to maximize V  X  N ( v where N ( v p ) is the set of neighbors of v p excluding v choose v p =3 . T = { 3 } .AtLine9,wecall ProcMCE ( { 3 } { 3 } , X  ) . We can visualize this as the top level in Figure 3(b). In the next recursion, let us choose v p =6 . Then we have T = { The for loop at Line 7 is shown as the second level in the search tree in Figure 3(b). We first call ProcMCE ( { 3 , 6 } , { 4 will be chosen as our next pivot, so the next recursive call is ProcMCE ( { 3 , 6 , 4 } , { 1 , 5 } , X  ) , and further recursively we call ProcMCE ( { 3 , 6 , 4 , 1 } , X , X  ) , at which point a maximal clique is generated. The next clique generated is { 3 , 6 , 4 , 5 } dancy with the previously generated clique is 0.75.

Before a detailed discussion of how d (and similarly y t ) is esti-mated, we first present the nice properties of our algorithm in the following theorem.
 T HEOREM 1. Let 0  X   X   X  1 be a constant specified by users. By choosing s to be Algorithm 2 samples a maximal c lique with probability at least s ( r ) , and returns a sample summary S such that the expected visi-bility E [ V ( C )] of each C  X  X  ( G ) is at least  X  .
 P ROOF . Consider the event whether or not a maximal clique C is sampled. Since C is sampled only when the search sub-tree growing to the leaf that represents C is pruned. Let the se-quence of nodes from the root to the leaf in the search tree be v ,v 2 ,...,v k ,where k = | C | , and particularly v k is the leaf node that represents C . Referring to Algorithm 2, let the corre-sponding sequences of l and  X  r defined for the subtrees rooted at v ,v 2 ,...,v k be l 1 , l 2 ,..., l k and  X  r 1 ,  X  r 2 ,...,  X  r r =max {  X  r 1 ,...,  X  r l } . As the sampling probability function s is monotonically decreasing, s ( r  X  )  X  s (  X  r i ) for 1  X  s ( r  X  )  X  s ( r ) .Since l is an upper bound of the depth of some search subtree T i rooted at v i ,wehave 0 &lt;k  X  l i . It follows that If C is discarded, then there exists C  X  X  such that | C  X  C | / | C | X  r  X  .Then In case that r  X   X   X  , Otherwise, 0  X  r  X  &lt; X  , and
As shown by Theorem 1, the sampling algorithm is capable of not only reducing the output size, but also providing a summary with guaranteed quality by selecting a proper sampling probability function s . Note that in Theorem 1, r&lt; 1 because by definition a maximal clique C cannot be contained in any other clique. The function s chosen in Theorem 1 is monotonically decreasing and has the property that as illustrated in Figure 4. It implies that a maximal clique is almost always discarded when it is nearly identical to a maximal clique previously added to the summary S .

Now we provide the details of computing d and y t . Recall d is the depth of the search subtree T to be grown by a complete recursive evaluation of the current ProcMCE ( C, T, D ) procedure. In other words, d is the size of the maximum set of vertices X that can be added to C to obtain a maximal clique. Let G T ( V
G T ,E G T ) be the subgraph of G induced by T . Thus, X is a maximum clique in G T and hence to compute X exactly is NP-hard (with G T as input). Therefore, we devise heuristics to upper bound | X | . We discuss three heuristics as follows.
 Let d vnum be the maximum degree of any vertex in the subgraph G
T , d h be the maximum value of h so that there are h vertices with degree at least h in G T ,and d core be the maximum core number of G T (i.e., the maximum value of c such that every vertex in a subgraph F of G T has degree at least c within F and F is the largest such subgraph of G T ). It is easy to see that d vnum and d core are all upper bounds of | X | since X forms a complete subgraph in G T . By their definition, we can order the upper bounds as follows.
The smaller the value of the upper bound, the greater is the prun-ing power. On the other hand, it requires time to compute the bounds, respectively. Thus, there is a tradeoff between pruning power and efficiency. The effect of the choice of the upper bound is evaluated later in our experiments.

E XAMPLE 3. Here we consider how the lower bound  X  r is de-termined in Algorithm 2 and Algorithm 3 for graph G in Figure 3(a). When ProcMCE ( { 3 , 2 } , { 1 , 7 } , X  ) is processed, the cur-rent subtree T contains 2 candidate vertices: T = { 1 , 7 estimate d =2 . At this point, C = { 3 , 2 } . Hence the size of any clique to be generated from T is at most | C | +2 =4. If we do not consider future intersection with existing cliques, then the current overlap with existing clique is only C  X  C where C = { 3 , 6 , 4 , 1 and  X  r is given by 1 / 4=0 . 25 . To tighten the lower bound, we consider possible future intersection of P with existing cliques. If we let | P | =4 ,then t =2 . Consider the previous maximal clique C = { 3 , 6 , 4 , 1 } in S . Y = T \ C = { 1 , 7 } X  X  3 , 6 , 4 , 1 Hence y t =1 . To determine a lower bound  X  r , we choose 7 to be the next vertex in the potential P before we choose 1. Hence the ratio ( | C  X  C | +max { t  X  y t , 0 } ) / ( | C | + t )= let | P | =3 ,then t =1 , for the worst case, we choose 7 to be the final vertex in P , and ( | C  X  C | +max { t  X  y t , 0 } ) / ( 3 =0 . 33 .  X  r =min 1  X  t  X  d
To estimate y t , we may also use | Y | similarly, or the number of vertices in Y with degree at least t , or the number of vertices in Y . Algorithm 3: Deterministic Summarization A perspective of Algorithm 2. To get an intuition of our algo-rithm, recall the notion of importance sampling as used in the ap-proximation of integral of a (unknown) continuous function, for example, y = f ( x ) . The idea is to draw more samples in regions where y changes rapidly and less where the curve is relatively flat. Analogously, we can imagine a y -value being a maximal clique C and the corresponding x -value being the time-stamp when C is out-putted. By our observation, the output sequence of maximal cliques appears  X  X ontinuous X  where sharp changes are infrequent. Out-putting maximal cliques with probabilities adaptive to the changes (large coverage ratio indicating a small change) then approximates the entire space of maximal cliques.
 Derandomization. We now describe a method to derandom-ize Algorithm 2 in order to compute an exact  X  -visible summary. The algorithm also leverages the local similarity between maximal cliques in the output sequence of classic MCE to achieve effective pruning, as outlined in Algorithm 3.

Each time when the recursive procedure ProcMCE ( C, T, D ) is starting a new search subtree T , we first examine if the search in is capable of leading us to any maximal clique that is sufficiently different from the maximal clique previously included in the sum-mary S so far. We use the techniques similar to those used for the randomized algorithm to compute  X  r . Then, T is always discarded when  X  r&gt; X  and always retained when  X  r  X   X  .

The deterministic algorithm always summarizes M ( G ) with a guarantee in terms of visibility, since a maximal clique C is not included in S only when a fraction of at least  X  of C is covered by C  X  X  . In this case, the visibility of C is ensured by the presence of C . The result is summarized in Theorem 2 as follows.
T HEOREM 2. Algorithm 3 computes a  X  -visible summary.
Although the redundancy removal using local similarity can al-ready significantly reduce the output size of classic MCE, we can further remove redundancy with a global view of all maximal cliques in the summary.

In Algorithm 4, when a maximal clique C is found by proce-dure ProcMCE , C is first tested for redundancy with the existing maximal cliques in the current S . It is costly to compare C with every C  X  X  . We devise the following method to allow efficient redundancy testing for every newly found maximal clique with the maximal cliques in S .

Let f X and b X be the smallest and greatest id of any vertex in a clique X . Then, the vertex ids of X lie in the range [ f Instead of comparing C with every C  X  X  ,weretrieve C only Algorithm 4: Summarization with Global Filtering Input :Graph G , maximum redundancy  X 
Output :A  X  -visible summary S of M ( G ) when [ f C ,b C ]  X  [ f C ,b C ] is nonempty. To find such C quickly, we maintain a binary-search tree L with b C as the key and C as the value. Then, each relevant C can be retrieved in O (log time.
 In addition, we devise a method so that we do not keep every C  X  X  in L as follows. Assume in the first level recursion of ProcMCE , we pick a vertex in ascending order of the vertex id. Thus, a new clique C is generated in ascending order of f way, it is safe to remove a maximal clique C from L if b C since C cannot overlap with any maximal cliques found later.
To show the correctness of the algorithm we use the following lemma [21].

L EMMA 1 ([21]). ProcMCE ( C, T, D ) return all and only maximal cliques containing all vertices in C , some vertices in T , and no vertex in D , without duplication.
 T HEOREM 3. Algorithm 4 returns a  X  -visible summary S .
P ROOF .Let C be a maximal clique and v c be the vertex with the smallest id in C .When ProcMCE ( { v c } ,T c ,D c ) is called in Algorithm 4, by Lemma 1 all and only the maximal cliques con-taining v c andnovertexin { v 1 , ..., v c  X  1 } will be generated. Since ProcMCE ( C, T, D ) is called by the algorithm for C = { v each v i  X  V , each maximal clique of G will be generated exactly once or pruned by Algorithm 2 or 3 for being found redundant. Thus, S is a  X  -visible summary since Lines 15-18 make sure that C is not included into S only when | C  X  C | / | C | &gt; X  for an exist-ing C in the current S .
 A heuristic can be applied to shorten the interval [ f C ,b C can be discarded earlier. Initially, G is clustered and the vertices are assigned id X  X  in a way that vertices in the same cluster have close id X  X . Since vertices in a clique is highly interconnected, their id X  X  also tend to cluster and fall in a relatively small interval.
The results of  X  -visible summary can be used for different appli-cations. Here we consider two possible refinement processes: top-k enumeration based on diversity and interactive clique exploration. Both processes can help end users to further sharpen their result sets and will be valuable in the investigation of different types of graph data.
Top-k computation is a useful and important operation in database systems and related applications, especially when the size of results is massive making it difficult to use the results. We consider com-puting the top-k results, A ,of M ( G ) . To ensure the quality of we should not rely only on the qua lity of any individual result in but also be aware of the relationship between them. In particular, we desire results in the top-k answers to be diverse .
While quality measures of A X  X  ( G ) with diversity considera-tion depend on applications, most of these measures are NP-hard to compute. However, an interesting family of evaluation functions, called submodular functions, allow efficient approximation of the top-k results.

A set function f :2 N  X  R is submodular if and only if for all sets S, T  X  N such that S  X  T ,and d  X  N \ T , f ( S + d ) f ( S )  X  f ( T + d )  X  f ( T ) [19]. For example, in the NP-hard problem of maximum k -set coverage problem (M k C), the function that evaluates the coverage of a collection of sets can be shown to be submodular.

We discuss efficient top-k clique computation with any submod-ular measure, using the objective function in M k Casanexam-ple. That is, we compute a collection A of k maximal cliques that covers the maximum number of vertices in G . With some M  X  X  ( G ) as the input, the algorithm each time greedily se-lects a maximal clique C  X  X  that adds maximum marginal cov-erage to the current A and include C in A . From the result by Nemhauser, Wolsey, and Fisher [19], the resulting collection has a coverage that is not smaller than (1  X  1 /e ) times the optimal solution. Thus, our algorithm is (1  X  1 /e ) -approximate and has complexity O ( k X  |M | ) ,where  X  is the average clique size in
However, even if we can compute A efficiently by taking advan-tage of a submodular measure, the computation can still be imprac-tically expensive with the input M ( G ) from a classic MCE algo-rithm, due to the explosion in the number of maximal cliques. With  X  -visible MCE, however, the problem can be readily solved with a significantly smaller  X  -visible summary S as the input, while the quality of A given S is still comparable to that by M ( G ) as veri-fied by our experiments.
We propose Interactive Clique Exploration (I CE ) that is natural and efficient for a user to incrementally approach the target clique. On the contrary, a classic MCE algorithm can overwhelm the users with too many results, thus severely hindering the applications of maximal cliques. The workflow of I CE is depicted in Figure 5.
Initially we select a set of seed vertices  X  from V , which means that we are to grow cliques containing at least a vertex from  X  .Let G
 X  be the extended subgraph of  X  , i.e., G induced by the set of vertices containing  X  and all neighbors of  X  . We then apply  X  -visible MCE to G +  X  to compute a  X  -visible sum-mary S of M ( G +  X  ). The list of top-k answers A ( S ) in computed by the greedy algorithm described in Section 5.1, which is efficient with a submodular quality measure and S as input. Next, A is presented to the user. When the user finds some C  X   X  X  to be the target, I CE terminates with C  X  as the answer. Otherwise, if the user finds some C  X  X  interesting and it worths a further exploration on C ,weset  X = C and increase  X  to zoom in the vicinity of C , and start from Step 2 for a new iteration now with G + C . In case A ( S ) is unsatisfactory, A ( S ) is removed from and we re-compute the top-k answers in the new summary S the new A is again presented to the user as shown in Figure 5.
In this section, we evaluate the efficiency and effectiveness of our method, compared with the classic MCE algorithm. For short, we denote by MCE the classic backtracking MCE algorithm [21] that has been proved to achieve optimal worst-case complexity, by  X  -RMCE the randomized algorithm that computes an expected  X  -visible summary, and by  X  -DMCE the deterministic algorithm that computes an exact  X  -visible MCE. The experiments were run on a machine with Intel Core i5 3.30GHz CPU and 4GB main memory. Datasets. We use four real world graphs to evaluate the algorithms. Some statistics about the datasets are given in Table 1. Blog is from the blogs network and has vertices as blogs and an edge indicates that two blogs appear in the same search result of the top-15 pop-ular queries published by Technorati. Skitter describes an internet topology constructed from sever al sources to a bout a millio n des-tinations. Wiki represents Wikipedia users as vertices and an edge indicates that a user once edited a talk page of another user. Patent is a graph with U.S. patents as vertices and citations between them as edges.

The default setting in our experiments is  X  =0 . 8 and using d as the estimation heuristic for d (see details in Section 4.1). We demonstrate the advantage of  X  -visible MCE algorithms,  X  -RMCE and  X  -DMCE, over the classic MCE algorithm, MCE, by comparing their running time and output size. We vary  X  from 0.5 to 1 (note that we choose  X &gt; =0 . 5 for practical visibility insurance).

The running time of  X  -RMCE and  X  -DMCE is reported in Figure 6, where the running time for MCE is equivalent to the time at by MCE (at  X  =1 ) Table 1: Statistics of datasets (K =10 3 ,M =10 6 ): the number of vertices and edges ( | V | and | E | ), the size of maximum clique and average size of maximal cliques ( c max and c avg ), and total number of maximal cliques with size at least 3 ( |M| )ingraph G  X  =1 . The result shows that, for all the datasets, the running time drops sharply when  X  changes from  X  =1 to  X  =0 . 9 ,which indicates a significant reduction in time with only a small loss of completeness. The result also shows a clear trend of decreasing running time as  X  ranges from 0 . 9 to 0 . 5 .

Figure 7 reports the size of the  X  -visible summary computed by  X  -RMCE and  X  -DMCE, respectively, where we also report the total number of maximal cliques returned by MCE (i.e., at  X  =1 )asa reference. The result verifies our claim in the significant level of redundancy in the set of maximal cliques. The number of maximal cliques decreases exponentially when  X  changes from  X  =1 to  X  =0 . 9 , and the number continues to decrease significantly when  X  changes from 0 . 9 to 0 . 5 . In other words, the redundancy already begins to drop dramatically as we start to introduce the  X  -visible summary with a small change in the visibility threshold  X  .
The estimation of d can affect the performance of  X  -RMCE and  X  -DMCE considerably, as shown by the result using  X  -RMCE in Table 2 (the result for  X  -DMCE is similar as the same principle is applied). While the core number can provide the tightest bound d core , it results in much longer running time. On the contrary, the heuristics d vnum and d h result in significantly better efficiency. These two heuristics are no more costly than the set intersection operations in the ProcMCE procedure, thus giving the same time complexity and incurring only little time overhead. Thus, the tighter bound d h , though having slightly higher overhead than computing the simple heuristic d vnum , turns out to improve the efficiency of  X  -RMCE more than the low-overhead d vnum .
 Table 2: Running time (in seconds) of  X  -RMCE with d esti-Table 3: Running time (in seconds), t local / t global ,of  X  -RMCE and the number of maximal cliques in the  X  -visible summary, |S local | / |S global | , with/without global filtering
The global filter described in Section 4.2 further refines the  X  -visible summary S computed by  X  -RMCE and  X  -DMCE. Its effect in producing a smaller summary an d the additional time overhead are evaluated by the results using  X  -RMCE in Table 3 (the results using  X  -DMCE are similar).
 As reported in Table 3, the running time for the datasets Blog, Skitter and Patent is only marginally increased with the addition of global filter, but it takes 3 times more time to finish on Wiki.
As for the size of the  X  -visible summary S , we observe that the reduction in the number of maximal cliques by a global filter is not as obvious as compared with those filtered locally (as shown in Figure 7). This agrees with our observation of local similarity be-tween maximal cliques in the output sequence of classic recursive backtracking MCE algorithms.
Finally, we use top-k maximal clique retrieval as an example to demonstrate how  X  -visible MCE can be useful in practice. The objective function in M k C (maximum k -set coverage) as discussed in Section 5.1 is used as the quality measure. In our experiment, we set k =20 , as a typical setting in information retrieval applications. We report in Table 4 the comparison of the quality of top-k results and the time taken to compute them from a  X  -visible summary and from the set of all maximal cliques in the graph.
 Table 4: Quality of and running time (in seconds) to compute top-20 results from the  X  -visible summary by  X  -RMCE ( Q T rand )and  X  -DMCE( Q det , T det ), and from the set of all maxi-mal cliques ( Q all , T all )
As shown in Table 4, the quality (i.e., the number of vertices in the graph being covered by the top-20 results) of the top-20 results computed from a  X  -visible summary is very close to that computed from the set of all maximal cliques. However, computing top-20 re-sults from a  X  -visible summary is approximately an order of mag-nitude faster than from the set of all maximal cliques.
The results thus support the use of a  X  -visible summary for top-k computation for its much smaller size (resulting in higher effi-ciency) without sacrificing the quality.
In this paper, we highlighted the problem of excessive size and redundancy in classic maximal clique enumeration (MCE). We in-troduced the notion of  X  -visible MCE to reduce the redundancy while capturing the major information in the result. We proposed efficient algorithms for the computation of a  X  -visible summary, and introduced top-k clique computation on top of the summary to further enhance the result usability. Our empirical studies showed significant improvements in both the result size and computation time over classic MCE, and demonstrated the usefulness of a  X  -visible summary. [1] J. Abello, M. G. C. Resende, and S. Sudarsky. Massive [2] F. Afrati, A. Gionis, and H. Mannila. Approximating a [3] R. Agrawal, S. Gollapudi, A. Halverson, and S. Leong. [4] N. M. Berry, T. H. Ko, T. Moy, J. Smrcka, J. Turnley, and [5] C. Bron and J. Kerbosch. Algorithm 457: finding all cliques [6] F. Cazals and C. Karande. A note on the problem of [7] J. Cheng, Y. Ke, S. Chu, and M. T.  X zsu. Efficient core [8] J. Cheng, Y. Ke, A. W.-C. Fu, J. X. Yu, and L. Zhu. Finding [9] J. Cheng, Y. Ke, A. W.-C. Fu, J. X. Yu, and L. Zhu. Finding [10] J. Cheng, L. Zhu, Y. Ke, and S. Chu. Fast algorithms for [11] S. Chu and J. Cheng. Triangle listing in massive networks [12] S. Chu and J. Cheng. Triangle listing in massive networks. [13] D. Eppstein, M. L X ffler, and D. Strash. Listing all maximal [14] M. Hua, J. Pei, A. Fu, and X. Lin. Top-k typicality queries [15] F. Kose, W. Weckwerth, T. Linke, and O. Fiehn. Visualizing [16] G. Liu and L. Wong. Effective pruning techniques for mining [17] H. Matsuda, T. Ishihara, and A. Hashimoto. Classifying [18] J. Moon and L. Moser. On cliques in graphs. Israel J. Math , [19] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis of the [20] J. Pei, D. Jiang, and A. Zhang. On mining cross-graph [21] E. Tomita, A. Tanaka, and H. Takahashi. The worst-case time [22] E. Vee, U. Srivastava, J. Shanmugasundaram, P. Bhat, and [23] J. Wang and J. Cheng. Truss decomposition in massive [24] D. Xin, H. Cheng, X. Yan, and J. Han. Extracting [25] X. Yan, H. Cheng, J. Han, and D. Xin. Summarizing itemset
