 In English and other western languages, space delimiters are used to mark word boundaries. However, no such spaces are used between adjacent words in Chinese (and some other Asian languages such as Japanese and Korean). Word segmentation (WS) is thus required to find the corresponding word sequence for a given Chinese character sequence. As words are the basic units for text analysis, WS plays an im-portant role, and is the first step, in most Chinese natural language processing (NLP) applications such as machine translation, information retrieval, and question answer-ing. Since WS is the first phase, its errors will be passed along to subsequent phases. Thus the accuracy of WS is crucial for Chinese NLP.

Although WS is the initial task for Chinese NLP, it would sometimes benefit from subsequent phases that have not been carried out yet. Moreover, some ambiguities can be resolved only by additional contextual information from beyond the sentence. For example,  X   X  X  X  X  X  X  X  X   X  can be segmented into two different meaningful sequences:  X   X  X  X  X  (discussion forum)  X  (very)  X  X  X  (hot) X   X  X r  X  X  X  (discussion)  X  (will)  X  (very)  X  X  X  (hot) X . Even humans cannot disambiguate this segment without the additional context. Such problems are difficult to address and are beyond the scope of this article.
We can, however, address another major problem. In real applications, words are often encountered which have never been encountered before. Among these out-of-vocabulary (OOV) words, named entities, numerical expressions, new words, and ab-breviations are four typical types. No dictionary and no corpus could possibly contain all of them; so handling them is an unavoidable problem for all WS systems.
In the literature, rule-based approaches [Palmer 1997; Yeh and Lee 1991] and statistics-based approaches [Asahara et al. 2005; Gao et al. 2003, 2005; Xue 2003; Zhang and Clark 2007; Zhang et al. 2006] have been proposed as two major categories of WS algorithms. Due to its robustness in handling OOV words and its capability to automatically acquire knowledge, the statistical approach has been widely adopted and has become the mainstream approach since 1990. We will thus focus here on statistical approaches for further study. According to the basic unit adopted for extract ing features, statistical approaches can be classified as either word-based [Gao et al. 2003; Zhang and Clark 2007; Zhang et al. 2003] or character-based [Asahara et al. 2005; Jiang et al. 2008; Ng and Low 2004; Peng et al. 2004; Tseng et al. 2005; Xiong et al. 2009; Xue 2003]. The word-based ap-proach of course treats the word as the basic unit, so the desired segmentation result is the best word sequence directly obtained from the search process. By contrast, the character-based approach treats the word segmentation task as a character tagging problem by labeling each character as the beginning, the middle, or the end of a word. The final segmentation result is thus indirectly generated from the tag sequence as-signed to the sentence.

Besides classification by basic unit as above, statistical approaches can also be clas-sified as either adopting a generative model 1 or a discriminative model . The generative model learns the joint probability of the given input and its associated label sequence, while the discriminative model learns the posterior probability directly. Comparison of these two basic models is a perennial and interesting topic [Liang and Jordan 2008; Ng and Jordan 2002; Raina et al. 2004; Toutanova 2006; Xue and Titterington 2008]. In general, for the sequence labeling problem, the generative model closely couples each input and its associated label as a joint event, and thus cannot use the succeeding input to decide the current label in the sequence labeling problem. By contrast, the discriminative model does not associate each input with its label as a joint event and thus it is capable of using the succeeding input to decide the current label. In recent years, the discriminative model has become the dominant solution for NLP problems due to its flexibility in incorporating features with dependencies between them and di-rectly optimizing classification accuracy [Toutanova 2006]. However, the performance advantage for the discriminative model can be very slight [Johnson 2001]; and the generative model can achieve very similar or even better performance than the cor-responding discriminative model if a suitable structure can be adopted that avoids certain unrealistic independence assumptions [Toutanova 2006].

The above two dimensions of classification are orthogonal to each other, and thus can be freely combined. However, in the literature that we have checked, all the character-based tagging approaches adopt the discriminative model, and almost all the word-based approaches adopt the generative model. The exception is Zhang and Clark [2007] 2 , a word-based approach which adopts the averaged perceptron [Collins 2002] for training. For clarity, the time-honored word-based n -gram model will be called the word-based generative approach hereafter, and the model of Zhang and Clark [2007] will be called the word-based discriminati ve approach. The well-known character-based tagging model will be called the character-based discriminative approach. In addition, the word  X  X odel X  will be freely exchanged with the word  X  X pproach X  if there is no confusion.

Since the word-based generative model and the character-based discriminative model are the best-known ones in the generative and discriminative families respec-tively, and many different approaches have been built by extending them, they will be regarded as our baseline systems for performance comparison and will be briefly introduced now. The word-based n -gram generative model can be formulated below.
 where WSeq  X  w m 1 =[ w 1 ,w 2 ,...w m ] indicates a specific word sequence with m words, and c n 1 denotes a given sentence with n characters. The classical word-trigram model P ( w Since P ( c n 1 w m 1 )=1and P ( c n 1 ) is the same for various WSeq candidates, only P ( w m 1 ) should be considered. It can be further simplified with the second order Markov Chain assumption shown below.

In Equation (3), the dependency between two adjacent characters within a word is implicitly handled by regarding the characters as a joint event (i.e., characters within a word are treated together as a unit). This model works well when there is no OOV word (i.e., only in-vocabulary (IV) words appear in the testing-set). However, this con-dition cannot be met in real applications. For example, named entities and numeri-cal expressions are two kinds of OOV words which are often encountered. Since the associated candidates of multi-character OOV words cannot be generated during the searching process without OOV pre-detection, it is impossible to identify them in this word-based approach. Most OOV words will thus be segmented into their correspond-ing sequences of uni-character-words. High recall of IV words (abbreviated as R IV )and low recall of OOV words (abbreviated as R OOV ) are thus obtained (see Table VI). In other words, OOV words are problematic for word-based models. Meanwhile, the over-all precision rate may also be low, as OOV words are segmented into more relatively short IV words.

Since the word-based approach has problems handling OOV words, an additional procedure incorporating other knowledge (not covered by the given corpus) is usually required [Gao et al. 2003; Zhang et al. 2003]. Although the performance of word-based models can be greatly enhanced with additional OOV detection and named entity recognition modules, the resulting system is rather complicated in comparison with the character-based discriminative approach described below. Thus the character-based discriminative model has become the dominant approach since it was proposed by Xue and Shen [2003]. The character-based discriminative model [Xue and Shen 2003] treats segmentation as a tagging problem, which assigns a corresponding tag to each Chinese character. The model is formulated as follows.
 where t k is a member of { B egin, M iddle, E nd, S ingle } (which are separately abbre-viated as B , M , E ,and S , and defined in Table I) to indicate the corresponding posi-tion of the character c k in its associated word. For example, the word  X   X  X  X  (Beijing City) X  will be assigned with the corresponding tags as:  X   X  /B(North)  X  /M(Capital)  X  /E(City) X .

In this work, the feature templates used in the character-based discriminative model are those of Ng and Low [2004], which have been widely adopted and reported in many papers. However, we exclude the features forbidden by the closed test regula-tions of the second SIGHAN Bakeoff. For example, the feature template Pu ( C 0 ), which indicates whether the current character is a punctuation or not, is not allowed. The adopted feature templates are listed below: For example, when we consider the third character  X   X   X   X  in the character sequence  X   X   X  X  X  X  X   X , template (a) results in these features: C  X  2 =  X  , C  X  1 =  X  , C 0 =  X  , C 1 =  X  , C =  X  . Template (b) generates these features: C  X  2 C  X  1 =  X  X  , C  X  1 C 0 =  X  X  , C C 1 =  X  X  X  , C 1 C 2 =  X  X  . Finally, template (c) generates the feature C  X  1 C 1 =  X  X  .
In fact, in the literature, various tag-sets have been proposed which include 2, 3, 4, and even 6 tags. It was reported that the 6-tag set is much better than both the 2-tag set and the 3-tag set, but its superiority over the 4-tag set is not obvious [Zhao et al. 2006; Zhao et al. 2010]. According to our experiments on the second SIGHAN Bakeoff, the overall performances of the 4-tag set and the 6-tag set with the same features are 0.9467 (see Table VI) and 0.9472, respectively. Since this performance difference is statistically insignificant, the 4-tag set has been adopted by most previous studies. In order to fairly compare our approach with those in the literature, the 4-tag set will be adopted in this work as well.
 Compared with the word-based generative model, this approach can better tolerate OOV words. Since the vocabulary size of the possible character-tag-pairs is limited, there are almost no OOV character-tag-pairs under this approach, and each multi-character OOV word can be converted into its corresponding sequence of character-tag-pairs. It is thus possible to correctly identify those OOV words. Therefore, this approach is robust with respect t o OOV words and can yield a high R OOV . On the other hand, though the dependencies between adjacent tags (labels) can be addressed in the character-based discriminative model, the dependency between adjacent characters within words cannot be directly modeled under this framework.

The dependency between adjacent characters within a word, which is implicitly handled in Equation (3), makes the word-based approach yield significantly higher R
IV . To study how this improvement comes about, we calculated log P ( c i ious character-bigrams collected from all the training corpora provided by the second SIGHAN Bakeoff [Emerson 2005]. Figure 1 gives the distributions of log P ( c i | c i  X  1 )for the class of character-bigrams within words (shown by black bars) and the class of character-bigrams between words (shown by white bars), where the X-axis represents different intervals of log P ( c i | c i  X  1 ) and the Y-axis denotes the relative frequencies of events associated with various intervals. As indicated in this figure, log P ( c i | c i  X  1 )for the class of character-bigrams within-words 3 tends to have higher value, which ex-plains why those IV words are more lik ely to be selected, so that high R IV is obtained in the word-based approach. Hence, even the word-based unigram model gives a much higher R IV than the character-based discriminative model (see Table VI). As mentioned above, the traditional word-based generative model gives excellent performance for IV words. However, it is incapable of handling the OOV words in the testing set. Thus, in this paper, we first propose a character-based generative model to replace the word-based n -gram with the character-tag-pair-based n -gram. As the vocabulary of characters is a closed set (as opposed to the open set of words), robustness with respect to OOV words is enhanced in this generative model. Com-pared with the character-based discriminative approaches in the second SIGHAN Bakeoff, this new generative model achieves competitive results. As a second proposal, since the generative model and the discriminative model complement each other in handling IV words and OOV words, we further suggest a joint model with log-linear interpolation to integrate them. This joint approach achieves a good balance between IV word identification and OOV word recognition. The experiments on closed tests in the second SIGHAN Bakeoff show that this joint model significantly outperforms the baseline models of both generative and discriminative approaches. Furthermore, statistical significance tests show that the joint model is significantly better than all state-of-the-art systems reported in the literature.

Afterward, a complete and detailed error a nalysis is conducted. According to the analysis, a significant portion of the criti cal errors is related to numerical or for-eign strings. Information concerning chara cter type, which distinguishes numerical or foreign or punctuation characters from Chinese characters, is thus proposed to fur-ther improve performance. Last, the proposed integrated approach is tested on cross-domain corpora, and a semi-supervised learning algorithm is proposed to carry out domain adaptation. Experiments on the CIPS-SIGHAN 2010 set show that this adap-tation is effective in improving cross-doma in performance, especially when there is a considerable difference between the two domains in the test.

The remainder of this article is organized as follows: Section 2 describes the pro-posed models in detail. The experiments conducted are reported in Section 3. Statisti-cal significance tests for comparing various approaches are shown in Section 4. Section 5 provides error analysis and related discu ssion. Section 6 shows the effect of domain adaptation, and related work is described in Section 7. Finally, concluding remarks are made in Section 8.

The character-based generative model and the character-based joint model were originally introduced in Wang et al. [2009, 2010]. In this article, we provide more de-tails concerning model analysis and experiment setting. In addition, complete error analysis is provided here, and new models exploiting character-type information are added and tested. Last, an effective semi-supervised algorithm for domain adaptation is proposed to improve cross-domain performance. To enhance the robustness of the generative approach in handling OOV words, a character-based model is required. We propose such a model in the following section. Afterwards, in Section 2.2, a character-based joint model is proposed to take full ad-vantage of both the generative and the discriminative models. As explained in Section 1.2, the word-based approach is vulnerable to OOV words. To address the problem of OOV word recognition, we must adopt the character-based ap-proach. However, we also need the generative model X  X  ability to handle the dependency of character-bigrams within-words. Accordingly, we here propose a character-based generative model to take advantage of both of the above-mentioned approaches by re-placing w i with its corresponding [ character , tag ] sequence (abbreviated as [ c , t ]), where tag is the same as in the character-based discriminative model above. With this new representation, P ( w m 1 | c n 1 ) can be re-derived based on the character-tag pair as follows: Following the derivation of Equation (2), only P ([ c , t ] n 1 ) must be handled. It can be further simplified to:
In this work, the SRI Language Modeling Toolkit 4 (SRILM) [Stolcke 2002] is used to train various character-tag pair n -gram models using the modified Kneser-Ney smooth-ing method [Chen and Goodman 1998]. A beam search decoder with dynamic program-ming is applied to find the best result.

As shown in the last section, P ( c i | c i  X  1 ) within words tends to have a higher value than between words. Therefore, for bi-character-words (and for other [ t  X  1 = BorM ; t i = EorM ] is frequently higher than for [ t i  X  1 = EorS ; t i = BorS ], where the latter expression corresponds to the character-bigram between two adjacent words. In other words, IV words are more likely to be selected in the former case, and high R IV is thus expected. However, the dependency between [ c , t ] i and [ c , t ] i  X  1 (represented by P ([ c , t ] i [ c , t ] i  X  1 ) in the generative model) cannot be modeled in the discriminative approach, as c i and t i must be jointly considered as an event.
Unlike the existing word-based generative model specified above, this new approach treats the character as a unit. It can thus correctly identify multi-character OOV words, as their corresponding candidates can now be generated during the searching process. In addition, the ability to handle the dependency between adjacent characters within words, which has been shown to be important for obtaining high R IV in the word-based approach, remains in the new model with its adopted generative form. Furthermore, as the basic unit in the new proposed model is the character, the model X  X  vocabulary size is much smaller than that of the word-based approach. Thus the data sparseness problem will be greatly alleviated.

In summary, compared with the character-based discriminative approach, the pro-posed character-based generative model retains the capability to handle OOV words because it, too, regards the character as a unit. Also, since the generative form is adopted, the dependency between adjacent characters is now directly modeled; the proposed approach thus will prefer the IV word when it is encountered. By contrast, such dependency is not modeled in the character-based discriminative approach. Fi-nally, compared with the word-based model, the character-based generative model can be more easily and naturally integrated with the character-based discriminative model within the searching process (shown in Equation (7)), since both models yield scores based on characters.

Nonetheless, besides those advantages mentioned above, a problem still remains for the new character-based generative model (and for all other generative models as well): The future context cannot be utilized in assigning the tag of the current character, as a character and its tag are jointly observed in the model. However, the future context can help to select the correct tag when the associated trigram has not been observed in the training set, as is the case for OOV words. By contrast, the character-based discriminative model can take advantage of the future context in this case, as the character and its tag are not jointly observed in the model. An example will clarify this situation.

In the sentence  X   X  (that)  X  (place)  X  (of)  X  X  X  X  (street sleeper)  X  (only)  X  (have/exist)  X  (some)  X  (person) (In that place, there are only some street sleep-ers) X  in the CITYU corpus,  X   X  /B  X  /M  X  /E(street sleeper) X  is an OOV word, while  X   X  /B  X  /E(sleep on the street) X  is an IV word, where the associated tag of each char-acter is given after the slash symbol. The character-based generative model wrongly splits  X   X  X  X  X   X  ( X  X leep street person X , i.e., street sleeper) into two words  X   X  /B  X  /E X  (sleep street) and  X   X  /S (person) X , as the associated trigram for  X   X  X  X  X   X  is not seen in the training set. However, the character-based discriminative model gives the correct result for  X   X  /M X  (sleep) and this character X  X  dominant features come from its future context  X   X   X (person)and X   X   X  (only), as shown in Table II. Similarly, the future context  X   X   X  (only) helps to assign the correct tag  X  X  X  to the character  X   X   X (person).
Table II gives the corresponding feature weights (i.e., lambda values under the Max-imum Entropy (ME) framework [Berger et al. 1996]) for  X   X  X  X  X   X  in the character-based discriminative model. The table shows that in the Feature row of  X  C 1  X  below  X   X   X , the lambda value associated with the correct tag  X  X  X  is  X 2.9422 X , which is the highest value in that row and far greater than that of the wrong tag  X  X  X  (i.e.,  X -1.2696 X ) assigned by the character-based generati ve model. This indicates that feature  X  C 1  X  ( X   X   X ) is the most important feature for correctly tagging  X   X   X . This observation fits a linguistic interpretation perfectly. We can explain this point as follows. Since  X   X   X  acts as a Chinese suffix with probability 0.878 (3,202 out of 3,647) in the CITYU cor-pus examined in this article, once we foresee it as the next character, we can strongly suspect that the current character will be bound to it (i.e., the current character is very unlikely to be tagged with  X  X  X ). Similarly, in the Feature row of  X  C 1  X  below  X   X   X , the lambda value associated with the correct tag  X  X  X  is  X 2.8300 X , which is also much larger than those of the wrong tags  X  X  X  (-0.7207) and  X  X  X  (0.0000). Also, since the next character  X   X   X  acts as either a prefix or a single-character-word with probability 0.976 (2,336 out of 2,394) in CITYU corpus, once we foresee it as the next character, we can strongly suspect that the current character will not be bound with it (i.e., the current character is very unlikely to be tagged with  X  X  X  or  X  X  X ). From the above discussion, it is clear that the proposed character-based generative model and the character-based discriminative model complement each other. Since the performance of IV word identification and t he performance of OOV word recognition are both important for real applications, we need the strength of both models.
In general, combining two different models will yield better performance if the fol-lowing conditions can be met: (1) The two models complement each other with respect to remaining errors. Of course, if both mode lsmakethesamewrongdecisionformost errors, then they cannot help each other, and combining them is useless. (2) In cases of error, the model that makes the correct de cision gives a strongly preferred or confi-dent answer over its competitor, while the model that makes the wrong decision gives a much weaker preference, so that the strong model can override the weak one.
Table III shows the results for the first test condition comparing the generative model and the discriminative model. It displays the statistics of the remaining errors resulting from these two models (please refer to Section 3.2 for detailed settings). In the table,  X  X  X  denotes the discriminative model, and  X  X  X  denotes the generative model. Also,  X  X + X  indicates that the generative model gives the correct decision for words in that column, and  X  X - X  indicates that it gives the wrong decision. Similar interpretation also applies for  X  X + X  and  X  X - X  in relation to the discriminative model. Apparently, the errors under  X  X -D- X  cannot be recovered by combining these two models, as both models prefer the incorrect answer. The last row of Table III (labeled  X  X verall X ) shows that  X  X -D- X  cases make up only 31.2% of the overall errors (11,456 out of 36,729). After this portion is extracted, the row shows that  X  X +D- X  occupies 71.8% under the IV category (12,027 out of 16,750); however, it occupies only 28.0% under the OOV category (2,384 out of 8,523). By contrast,  X  X -D+ X  occupies only 28.2% under the IV category (4,723 out of 16,750), but occupies 72.0% under the OOV category (6,139 out of 8,523). Therefore, we can conclude that these two models do complement each other to a considerable extent.

The situation for the second condition comparing the generative and discriminative models is shown in Table IV. It gives the strength of preference of the character-based generative model and the character-based discriminative model. This table simply follows Table III, replacing its entries wit h the corresponding average-gap, which is the average score difference between the desired answer and its top competitor. In each cell, the first number denotes the average-gap given by the generative model, and the second number denotes that given by the discriminative model. The last row of this table (labeled  X  X verall X ) shows that, for IV Errors, the average-gap of  X  X  X  under  X  X +D- X  is 0.84, which is larger than that of  X  X  X  (-0.39), and is also larger than that of  X  X  X  under  X  X -D+ X  (-0.25). In comparison, the average-gap of  X  X  X  under  X  X -D+ X  is 0.79, which is larger than that of  X  X  X  (-0.25), and is also larger than that of  X  X  X  under  X  X +D- X  (-0.39). In other words, for the errors in  X  X +D - X  column, the generative model gives rel-atively strong positive preference, and the discriminative model gives relatively weak negative preference. By comparison, for t he errors in  X  X -D+ X  column, the generative model gives relatively weak negative preference, and the discriminative model gives relatively strong positive preference.

Similar phenomena can also be observed for the average-gap of  X  X  X  of the OOV er-rors under  X  X -D+ X  (marked in the last row of Table IV). However, no such phenomenon are observed for the average-gap of  X  X  X  of the OOV errors under  X  X +D- X  (which is only 0.30 versus -0.46 of  X  X  X  under  X  X +D- X , and versus -0.62 of  X  X  X  under  X  X -D+ X ). The above statistics shows that the generative model is relatively weak in handling OOV words. Therefore, combining these two models is unlikely to improve the situation in this portion of the data. Fortunately, it is only a small portion (19.1% of OOV errors, as shown in Table III). Therefore, to a cons iderable degree, these two models meet the second condition as well as the first. Since both conditions are met in our data set, we do expect that combining the two models would give better performance than employing either model individually.

In the literature, various ways have been proposed to combine the generative and discriminative models. Generative related terms are directly integrated into the dis-criminative model in Raina et al. [2004] and Fujino et al. [2005], but unfortunately this method cannot be applied to our case. By contrast, Jiampojamarn et al. [2010] integrates the generative joint n -gram model into the discriminative model as a set of binary features. However, among the various combining methods, the log-linear in-terpolation remains a simple but effective one [Bishop 2006]. Thus the following joint model is proposed. For the k  X  th character c k , the score of the tag t k can be calculated via log-linear interpolation as below: In this joint model, c k and t k are as previously specified, and  X  (0.0  X   X   X  1.0) is the weight for the generative model, obtained from a cross-validation set. Score ( t k ) will be directly used when searching for the best sequence. In this proposed joint model, the generative model and the discriminative model are integrated in a natural way 5 ,since both are character-based. As different NLP tasks may require differe nt segmentation criteria [Zhang and Clark 2007], there is no unified criterion for Chinese WS. Various corpora are thus frequently created with different criteria, and the WS pe rformance for each corpus must be eval-uated accordingly. For example, time expre ssions and organizations are treated as words in the MSR corpus, but are segmented as several smaller units in all other cor-pora provided in the second SIGHAN Bakeoff [Emerson 2005]. A system trained in one corpus thus might behave worse in another corpus if it is evaluated with different criteria; and almost no system can outperfo rm all others across all different corpora. Therefore, to enable fairer comparison among various approaches, a set of corpora is usually required. For instance, the widely cited second SIGHAN Bakeoff WS contest provides four different standard corpora w ith their own criteria. These will be de-scribed in Section 3.1. Then various experiments that have been conducted on those corpora will be described in Section 3.2. Since the corpora provided by the second SIGHAN Bakeoff [Emerson 2005] were widely adopted in various articles for comparing the performance of different ap-proaches, they will be used to conduct various experiments in this article as well. These include the Academia Sinica Corpus (AS), the Hong Kong City University Cor-pus (CITYU), the Microsoft Research Corpus (MSR), and the Peking University Corpus (PKU). These corpora provide both Unicode coding and Big5/GB coding, and the latter format is adopted in our work. The statistics of these corpora are shown in Table V.
The PKU corpus is a bit different from the others. Arabic digits and English char-acters are encoded differently across its training set and testing set. In the training set, Arabic digits and English characters are in full-width format, occupying two bytes. However, in the testing set, these characters are half-width characters occupying only one byte. Most researchers in the SIGHAN Bakeoff competition performed a conver-sion before segmentation [Xiong et al. 2009]. Since the coding inconsistency issue is unrelated to the WS problem that concerns us, this annoying disturbance ought to be eliminated to reflect the true performance. However, as the performance of both cases has been reported in previous studies, we will follow suit by conducting tests on both the unconverted case (denoted as ucvt.), which keeps the original half-width format in the testing set, and the converted case (denoted as cvt.), which pre-converts half-width format into full-width format in the testing set before evaluation. After the Arabic digits and English characters are converte d, the OOV rate of the converted corpus is significantly lower than that of the unconverted corpus (as shown by the  X  X KU(cvt) X  row in Table V). To show the power of our proposed models, the word-based n -gram generative model and the character-based discriminative model are first tested as two baseline systems in Section 3.2.1, as they are the best known in the generative and discrimina-tive families. Afterwards, the proposed character-based generative model and the character-based joint model are tested in Sections 3.2.2 and 3.2.3 respectively. Last, in Section 3.2.4, our experiments show that weighting various features initially in the ME approach makes significant improvements.

For performance evaluation, to fairly compare the proposed approaches with pre-vious work, the  X  X losed test X  regulation, as stipulated in the second SIGHAN Bakeoff WS contest, will be respected in our experiments. This means that only the informa-tion found in the training data can be used: all other data or information is excluded, including knowledge of characters sets, punctuation characters, etc. In all tests to be conducted below, Precision ( P ), Recall ( R ), F-score ( F ), Recall of OOV ( R OOV )and Re-call of IV ( R IV ) are used to evaluate the segmentation results. The balanced F -score is calculated as: F =2 PR /( P + R ). 3.2.1. Word-Based Generative Model and Character-Based Discriminative Model. To evaluate the word-based generative approach, we fi rst extract a word list from the training set as our vocabulary. The word-based generative model is also trained using the SRILM toolkit, with the same settings used in the character-based generative model (mentioned in Section 2.1).

The segmentation results of the word-based generative model are shown in Table VI (where the best F -score in each corpus is marked for visibility). As expected, it shows that all word-based n -gram models have high R IV (even its unigram model outperforms the character-based discrimina tive approach with respect to R IV )andverylowR OOV . Having further analyzed the testing-set errors generated by the trigram model, we find that, among the 16,781 error-patterns resulting from all the testing-sets, 11,546 (69%) errors are caused by segmenting an OOV into a sequence of IV words. This result clearly illustrates the model X  X  disadvantage in handling OOV words and accounts for its low R OOV .
 For the character-based discriminative model, the ME Package 6 provided by Zhang Le has been used to conduct experiments. (Training was carried out with Gaussian prior 1.0 and 300, 150 iterations for AS and other corpora respectively.) Table VI shows that the character-based discriminative model outperforms the word-trigram model on F -score and R OOV metrics, but the latter obtains higher R IV .ThelowR IV for the character-based discriminative model clearly shows the disadvantage of not using dependencies between adjacent characters within multi-character words. Among the 15,336 error-patterns from all of the testing-sets, we see that 9,291 of them (61%) occurred because an IV word-sequence was incorrectly segmented. This illustrates this model X  X  weakness in handling IV words, which accounts for its low R IV .
Since the word-based n -gram model tends to segment OOV words into uni-character-word sequences, we might think of further r aising the performance by replacing the uni-character-word sequence generated via the word-based generative model by the corresponding result from the character-bas ed discriminative mo del. Unfortunately, this simple merging method yields only results comparable with those of the character-based discriminative model, as not all uni-character-word sequences should be re-placed and it is difficult to judge which ones. For instance,  X   X  X  X  X  X  (between the two points) X  is correctly segmente d by the word-trigram model as  X  [  X  ] (two) [  X  ] (point) [  X  X  ] (between) X , but the character-based discriminative approach gives the wrong result:  X  [  X  X  ] (an OOV word which would mean two o X  X lock or two points) [  X  X  ] (between) X . The above strategy will thus co nvert the original co rrect result into an incorrect one,  X  [  X  X  ] [  X  X  ]  X . 3.2.2. Character-Based Generative Model. The experimental setting introduced in Sec-tion 2.1 is adopted here. Table VII gives the results of the proposed character-based generative model for various character n -gram-sizes ranging from n =2to n =5,and the best F -score for each corpus is highlighted for visibility. Table VII shows that the character-trigram model significantly outperforms the character-bigram model over all four corpora, but also shows that almost no improvement was observed as we increased the n -gram length. (Only the 4-gram result is a bit better than that of the MSR corpus, since it has the largest average-word-length.) This outcome strongly suggests that the training data is too sparse to support models with 4-grams and 5-grams.

From these results, it can be seen that the proposed character-trigram generative model significantly outperforms the word-trigram generative model and slightly out-performs the character-based discriminative model. Compared with the word-trigram approach, the proposed character-trigram model has dramatically raised the overall R
OOV from 0.053 to 0.511 at the cost of slightly degrading the overall R IV from 0.987 to 0.973. This result clearly shows that the handicap of the word-based generative model in handling OOV words has been alleviated. In addition, compared with the character-based discriminative approach, the proposed character-trigram model is able to increase the overall R IV from 0.956 to 0.973, at the cost of degrading the overall R
OOV from 0.680 to 0.511. Also, the overall precision rate of the proposed character-trigram model (0.946) is lower than that of the discriminative model (0.950), while the overall F -score of the proposed model (0.950) is higher than that of the discriminative one (0.947). This implies that the proposed model tends to segment OOV words into more words than the discriminative model does, while the higher recall also indicates that the proposed model results in more correct words.

Aside from performance, in regard to execution speed, the generative model is not significantly faster than the discriminative model in our experiments. However, the learning process of the generative approach is found to be much faster than that of the discriminative model, as the discriminative model needs hundreds of iterations for the adopted corpora. Taking the CITYU corpus as an example, the training time of the generative and discriminative models are 8.5s vs. 1333.4s (150 iterations) with the same environment. That is, the first model is approximately 157 times faster. Thus the proposed approach has a large additional advantage when massive training data must be processed.

When the remaining errors are examined, we find that the proposed model fails to handle some OOV words such as  X   X  X  X   X   X  due to its inability to utilize future con-text when required, as illustrated in Section 2.1. However, the future context for the character-based generative model scanning from left to right is just its past context when scanning from right to left. We thus expected that such errors would be fixed if we let the model scan in both directions and then combined their results. However, we actually observed that these two scanning modes share more than 90% of their errors (and thus do not satisfy the first condition stipulated in Section 2.2). For example, in the CITYU corpus, the left-to-right sca n generates 1,958 incorrect words and the right-to-left scan results in 1,947, while 1,795 errors are the same. Similar behavior is also observed for other corpora. So, unfortunately, the two scanning modes seem not to complement each other after all.

To analyze the problems, ten errors similar to  X   X  X  X  X   X  were selected for exam-ination. Only one of them was fixed via the abovementioned right-to-left scanning approach, and  X   X   X  X  X   X   X  still was not segmented correctly. Having analyzed the scores from both scanning directions, we found that the original scores (in the left-to-right scan) when processing  X   X   X  X nd X   X   X  do improve if the model scans from right-to-left. However, the score when processing  X   X   X   X  deteriorates because the useful feature  X   X   X  (person) (a non-adjacent character for  X   X   X , seen first when scanning from right to left) still cannot be utilized when the prior context  X   X  X  X   X  as a whole is unseen, when the related probabilities are estimated via the Kneser-Ney smoothing technique. In other smoothing technique. Although either the multiple-backoff [Bilmes and Kirchhoff 2003] or the ME estimator could overcome this drawback, the packages 7 that we have adopted yield no obvious improvement or even worse overall performance for all our tri-gram models, as they are not designed to estimate n -gram probabilities for our problems. It would be interesting to see whether a multiple-backoff (or an ME) estima-tor could fix this problem, if either procedure were well designed for estimating n -gram probabilities. However, such experimentation is beyond the scope of this article. 3.2.3. Character-Based Joint Model. When the remaining errors were inspected, we found that the character-based generative mo del and the character -based discrimina-tive model complement each other much more than the two scanning modes do. These two approaches share at most 38.7% of their errors in all corpora tested (31.2% overall, as shown in Table III). For example, in the CIT YU corpus, the generative approach re-sults in 1,958 incorrect words and the discriminative approach generates 2,338, while only 832 of them (38.7%) are the same. Similar statistics can also be observed in other corpora, per our original expectation.

For the character-based joint model, a development set is required to obtain the weight  X  for its associated generative model. Therefore, a small portion from each original training corpus is extracted as the development set and the remaining data is treated as the new training-set, which is then used to train two new parameter-sets for both of the associated generative and discriminative models. The number of sentences in each development set is proportional to the size of the corresponding training sets, with a ratio of about 0.5%. For the PKU training corpus, the last 300 sentences are extracted as the correspondi ng development set. Similarly, the last 400 sentences from the CITYU corpus, the last 600 sentences from the MSR corpus, and the last 2,000 sentences from the AS corpus are extracted as their development sets to obtain the various corresponding  X  values. The statistics for various new data sets are shown in Table VIII. In the rows of the testing sets, the number before  X / X  is the OOV number (or OOV rate) with respect to the original training sets, and the number after the slash is the OOV number (or OOV rate) with respect to the new training sets (after excluding the development sets). The variation of the OOV rate is barely noticeable.
The F -scores of the character-based joint model versus various  X  values are evalu-ated for four different development sets, as shown in Figure 2. The curves are flat near the top, which indicates that the character-based joint model is not sensitive to the  X  value selected. Judging by these curves, the most appropriate  X  values for the AS, CITYU, MSR, and PKU corpora are 0.30, 0.60, 0.60, and 0.60, respectively. The  X  val-ues selected from the development sets are then adopted for conducting experiments on the testing sets.

Note that the AS corpus obtains the lowest  X  value (0.3, even less than 0.5; however, this curve is quite flat from 0.3 to 0.6). Thi sisbecausetheAScorpusistheonlycorpus for which it X  X  the generative model slightly lags behind the discriminative model in the development set 8 (with F -scores of 0.956 vs. 0.958).

Per Table IX, the character-based joint model significantly outperforms both the character-based generative model and the character-based discriminative model in F -score for all test corpora. Compared with the character-based generative approach, the joint model increases the overall R OOV from 0.510 to 0.633, at the cost of slightly degrading the overall R IV from 0.973 to 0.971. These scores show that the joint model retains the advantage of the character-based generative model on IV words. Compared with the character-based dis criminative model, the propo sed joint model improves the overall R IV from 0.956 to 0.971, at the cost of degrading the overall R OOV from 0.680 to 0.633.

In addition, a Recall-Upper-Bound 9 column is added to Table III to show how much room is left to the proposed approach for further improvement. This score indicates a reasonable upper bound for the recall rate when these two models are integrated. Since combining the scores of the two models cannot recover from  X  X -D- X  errors, and since  X  X +D-, OOV X  errors are almost hopeless (because  X  X - X  yields relatively strong preference for the wrong choice, while  X  X + X  gives only weak preference for the correct one, as shown in Table IV), a reasonable upper-bound of recall rate 10 can be obtained by excluding all the  X  X -D- X  errors and the  X  X +D-, OOV X  errors in Table III. Per the Overall row, the proposed model fails to rescue 29.3% 11 of the errors in the classes  X  X -D+ X  and  X  X +D-, IV X  (please see various error patterns at Section 5.1).

Although the proposed joint model has achieved the best performance, it gives the same weight to the character-based generative model for both IV words and OOV words. However, one might suspect that we should weight the character-based genera-tive model more when IV words are encountered, and less when OOV words are seen. And yet, for character-based approaches, it is difficult to judge if the corresponding word is an IV word or an OOV word before we reach the last character of that word. Therefore, we tried weighting the character-based generative model d ifferently accord-ing to whether the given character-bigram has been observed or not. Unfortunately, the results are disappointing and the improvements are slight. The reason for this phenomenon is that an observed character-bigram (even with the tag of c k  X  1 ) cannot guarantee that its corresponding word is an IV word. For example,  X   X   X  X  X  (street sleeper) X  is an OOV word, but  X   X  X  X  (sleep on the street) X  is an observed character-bigram in the training set. As another example,  X  [  X  ] (big) [  X  X  X  ] (crane) X  are two IV words but  X   X  X   X  is an unseen character-bigram. It is thus difficult to distinguish IV words from OOV words until we reach the last character of a word. Therefore, adopt-ing more weight parameters seems unnecessary (at least for the corpora that we have adopted).

Furthermore, as mentioned in Section 2.2, there are various ways to combine the generative and discriminative models. Besides the log-linear interpolation method, we have also tested different approaches that incorporate generative features into the dis-criminative training framework [Andrew 2006; Jiampojamarn et al. 2010]. However, (where t  X  1 and t  X  2 are the tags of character C  X  1 and C  X  2 ), or real-value generative n -gram scores, only negligible improvements are achieved for the original discriminative models, and the results are significantly worse than for the proposed joint model. This result is not surprising, as the feature C  X  1 t  X  1 C 0 cannot really reflect the dependency that we want to incorporate between [ c , t ] i and [ c , t ] i  X  1 . The result thus shows that log-linear interpolation is an effective way to integrate two models, simple though it is. 3.2.4. Weight Various Features Differently. Under the ME framework, each feature should be trained only once for a given observation and its associated weight will be learned from the training corpus automatically. However, when we repeat the work of Jiang et al. [2008], which reports achieving state-of-the-art performance in the data-sets that we have adopted, we find that some features (e.g., C 0 ) are inadvertently trained several times in their original implementation, which is implicitly generated from various feature templates adopted in the paper. Further, we observe that this study X  X  improvements are mainly due to this implicit feature repetition, overlooked by the authors. For example, consider the feature C 0 . (The meanings of the features are illustrated in Section 3.2.1.) This feature actually appears twice during training, which is implicitly generated from two different templates C n (with n = 0, generates C )and[ C 0 C n ](with n = 0, generates [ C 0 C 0 ]). The repetitive features also include [ C  X  1 C 0 ]and[ C 0 C 1 ], which implicitly appear three times.

All the features adopted in Jiang et al. [2008] possess binary values. Thus, if a binary feature is repeated n times, it should behave like a real-valued feature with value  X  n  X , at least in principle. With the above discovery in mind, we converted all binary-value features into their corresponding real-valued features and set the value of C 0 to 2.0; the value of C  X  1 C 0 and C 0 C 1 to 3.0; and the values of all other features to 1.0. Then the original character-based dis criminative model was re-trained under the ME framework. Logically, this new implementation is equivalent to simply starting from a different initial point when conducting ME training (i.e., with initial lambda values not necessarily equaling one). The training process was also done using Zhang Le X  X  software with Gaussian prior 1.0 and 300, 150 iterations for AS and other corpora respectively. The new result is shown in Table X (in the Discriminative-Plus row). The original data is also shown in parentheses next to the new data for comparison. Table X shows that this new Discriminative-Plus implementation significantly outper-forms the original one (the overall F -score is raised from 0.947 to 0.953) when both implementations adopt real-valued features for training. Therefore, it seems that, starting from different initial values, training will converge on different points in the parameter space for this case.

To test whether this phenomenon is general for various ME training algorithms, we conduct similar experiments with two additional ME packages: (1) MaxEnt Classifier 12 from Tsujii laboratory, University of Tokyo (denoted as (2) Dekang Lin X  X  ME package 13 (denoted as Lin). Training was performed with Gaus-
Similar improvements have been observed again with these two packages (as shown in Table XI). Perhaps giving more initial weight to closely related features would gen-erate better results. ( C 0 should be the most relevant feature for assigning tag t 0 .) However, further analysis and detailed explanation of this problem would be beyond the scope of this article 14 .

This new implementation is then further integrated with the character-based gener-ative model. The resulting model will be called the character-based Joint-Plus model . Table X shows that this Joint-Plus implementation achieves better results than the Discriminative-Plus implementation, demonstrating that our Joint-Plus approach is an effective and robust method of Chinese word segmentation. However, compared with the original Joint model, the new Joint-Plus approach does not show much im-provement, as shown in Table X, regardless of the significant improvement made by the Discriminative-Plus model. This is because the additional benefit generated by the Discriminative-Plus model has already been mostly covered by the generative model. (Among the 6,965 error words corrected by the Discriminative-Plus model, 6,292 of them (90%) are covered by the generative trigram model.) Although Tables IX and X showed that the proposed character-based joint model out-performs all other approaches mentioned above, we would like to know if the difference is statistically significant. Since the second SIGHAN Bakeoff provides only one test-ing set for each training corpus and creating a set of additional testing suites is very expensive, the well-known bootstrapping technique [Koehn 2004; Zhang et al. 2004] is adopted to conduct the significance tests. Following this approach, given an original testing-set T 0 , M -1 additional testing-sets T 1 ,... T M  X  1 will be generated (each with the same size of T 0 ) by repeatedly resampling data from T 0 . Thus we will obtain a total of M testing-sets for each training corpus (with M = 2,000 in our experiments). We then follow Zhang et al. [2004] in measuring the confidence interval for the discrep-ancy between two models. For each performance measure (e.g., F -score) obtained from a specific testing-set T i ( i =0 , 1  X  X  X  , M  X  1), assuming that its values are assigned by system A and system B as a i and b i respectively, then the discrepancy between system AandBfor T i would be  X  i = a i  X  b i .After M discrepancy values are found, the 95% confidence interval for the discrepancy between system A and B is obtained by finding the minimum interval that could cover the middle 95% of the discrepancy values. If this confidence interval does not include the point of origin (value-zero), system A is considered to be significantly different from system B.

Table XII gives the results of significance tests among various models mentioned above. In this table,  X  &gt;  X  means that system A is significantly better than system B;  X  &lt;  X  means that system A is significantly worse than B; and  X   X   X  X susedtomeanthat the two are not significantly different. As s hown in Table XII, the proposed character-based generative trigram model achieves competitive results with the character-based discriminative model. The proposed Joint model is significantly better than the two baseline models on all corpora. Similarly, the proposed Joint-Plus model also sig-nificantly outperforms the character-based generative model and the character-based Discriminative-Plus model on all corpora except for the PKU(ucvt.) corpus. The com-parison shows that the proposed Joint model and the Joint-Plus model outperform each of their component models. Further, the generative approach is inferior to the discrim-inative approach in the AS corpus, as the AS has a relatively high OOV rate. (The Discriminative model perfo rms better for OOV words.) Finally, the Discriminative-Plus model is inferior to the generative one in the MSR corpus, as the MSR has the lowest OOV rate. (The generative model performs better for IV words.) The above comparison shows the superiority of the proposed model among the ap-proaches that we implemented and tested. However, it would be interesting to know if the proposed Joint and Joint-Plus models also outperform state-of-the-art systems that have not been reimplemented in our lab. Since our tests have been performed on the corpora provided by the second SIGHAN Bakeoff 15 [Emerson 2005], the systems that performed best for F -score for at least one corpus in that contest have been first selected for comparison. This category includes Asahara et al. [2005] (denoted as Asa-hara05) and Tseng et al. [2005] 16 (Tseng05). The reported performance of these two systems is listed in Table XIII, and they are briefly summarized as follows. Asahara et al. [2005] achieves the best result on the AS corpus, using the character-based ap-proach to first identify the OOV candidates and then integrate them into the system. Tseng et al. [2005] adds numerous linguistic features such as information on  X  X ord-prefixes X  and  X  X ord-suffixes X  (automatically extracted from the training-set) as well as morphological and character reduplication features. This system thus overcomes the drawbacks of character-based approaches and performs best on the remaining three corpora.

In addition, the systems reported to outperform the preceding two systems in the last few years have also been selected for comparison. This category includes Zhang et al. [2006] (denoted as Zhang06), Zhang and Clark [2007] (Z&amp;C07), Jiang et al. [2008] (Jiang08), Sun [2010] (Sun10), and Zhang and Clark [2011] (Z&amp;C11). Their perfor-mances are also reported in Table XIII, and t heir approaches are briefly summarized as follows. Zhang et al. [2006] use a sub-word tagging approach to utilize sub-word information and achieve the best performance on CITYU, MSR, and PKU. Zhang and Clark [2007] use perceptrons to generate word candidates with both word and char-acter features and is the only word-based approach that adopts the discriminative form. Jiang et al. [2008] 17 also adopt a perceptron based model for word segmentation based on Ng and Low [2004], with additional lexical-target features associated with the current character. (The feature templates (a)  X  (c) in Section 3.2.1 are called non-lexical-target features in Jiang et al. [2008]. Lexical-target features are generated by adding C0 to each feature templates (a)  X  (c)). Sun [2010] combines the outputs of the word-based discriminative model and the cha racter-based discriminative model with a bagging approach. Last, Zhang and Clark [2011] uses a single discriminative model to adopt both word-based and character-based features.

Since the above-mentioned systems have not been re-implemented, the desired pair-wise samples cannot be obtained from the testing-set as in the last section. To overcome this problem, we associate each system that has been implemented with a 95% confidence interval by finding the minimum interval that could cover the mid-dle 95% of its total MF -scores. Afterwards, the un-implemented systems are checked against each of the implemented systems. If (and only if) the F -score of system B (un-implemented) does not fall within the 95% confidence interval of system A (imple-mented), the two systems are considered significantly different statistically. In most cases, this sequential (or non-pair-wise) sampling test will have a wider confidence in-terval and is thus a stricter test [Zhang et al. 2004]. Table XIV gives a 95% confidence interval for our Joint model and Joint-Plus model for various corpora.

Table XV gives the results of significance tests for the un-implemented systems mentioned in this section. It shows that both our Joint model and Joint-Plus model outperform (or are comparable to) almost all state-of-the-art systems across all cor-pora, except Zhang and Clark [2007] and Zhang and Clark [2011] on the PKU(ucvt.) corpus. In that special case, Z&amp;C07 outp erforms the Joint-Plus model by 0.3% on F -score (0.4% for the Joint model). However, the Joint-Plus model exceeds Z&amp;C07 on the AS and CITYU corpora by 1.0% and 0.5%, respectively (1.0% and 0.3% for the Joint model). Similarly, Z&amp;C11 outperforms the Joint model by 0.3% on F -score; while the Joint model exceeds Z&amp;C11 by 0.5% on the CITYU corpus. Thus it is fair to say that both our Joint model and Joint-Plus model are superior to all state-of-the-art systems reported in the literature. We collect and analyze the errors on the C ITYU and MSR corpora generated by the character-based joint model, because the OOV rates of these corpora are the highest and lowest among the five corpora. The statistics for remaining errors on CITYU and MSR are shown in Tables XVI and XVII respectively. The tag in parentheses following each character sequence (e.g.,  X   X  (IV) X  in the first row under the Example column) indicates whether the sequence is an IV word or an OOV word (or not a word at all, as denoted by NW).

The errors are first classified as IV or OOV . Clearly, most of the remaining errors are related to OOV words. In the CITYU corpus, among 1,120 error-sequences, 802 (71.6%) are related to OOV. In MSR, this ratio is much less but still over 50%. (The gap arises because the OOV ratio of MSR is much less than that of CITYU.) Each category is then further classified into three main sub-categories: Critical, Inconsistency, and Not-Critical (to be defined later). In the headings of the following paragraphs, the first percentage in parentheses indicates the co rresponding ratio (combining both IV and OOV) in the CITYU corpus, and the second percentage denotes the ratio in the MSR corpus. (I) Critical (68.5% = 71.6% * 73.8% + 28.4% * 55.3%; 65.9% = 53.0% * 58.6% + 47.0% * 74.2%): Such errors yield information loss or meaning distortion. For ex-ample, the two uni-character words [ X  (j) (IV) X  (slip)] and [ X   X  (IV) X  (fall down)] in Ta-ble XVI are wrongly combined into an OOV word [ X   X )j( (OOV) (slip) X  X , which would lose information (since no lexicon information can be found for an OOV word) and thus create additional problems for subsequent tasks such as pos-tagging and parsing. Sim-ilarly, the sequence [ X   X  X  X  X  (IV) X  (automation) and  X   X   X  (IV) X  (factory)] is grouped into one word [ X   X  X  X  X  X  X  (OOV) X  (automated factory)] with coarser granularity. For com-parison, [ X   X  X  X  (IV) X  (ChiaYi)], a city name, and [ X   X  X  X (11) (OOV) X  (Shinong Creek)] are two location names, and are segmented into [ X   X  X  X  X  (NW) X  (a nonsense string)] and [ X   X (11) (NW) X  (Nong Creek)], in which the meaning is distorted (and displays bracket-pair crossing). Similarly, [ X   X  X  (IV) X  (in no way; never)] and [ X   X  X  X  X  X  (OOV) X  (reach for what is beyond one X  X  grasp)] are segmented into a sequence [ X   X  (IV) X  (definitely)  X   X  X  (IV) X  (not good)  X   X  X  (NW) X  (a nonsense string)  X   X  (IV) X  (far)] (with bracket-pair crossing), in which the meaning is distorted as well. (II) Not Critical (20.5% = 71.6% * 26.2% + 28.4% * 6.0%; 27.9% = 53.0% * 41.4% + 47.0% * 12.6%): For such errors, there is no bracket-pair crossing: instead, different granularity levels have been adopted. Thus the result gives finer granularity without distorting the original meaning. For example, [ X   X  X  X  X  (IV) X  (little daughter)] in Table XVI is segmented into [ X   X  (IV) X  (little)] and [ X   X  X  (IV) X  (daughter)]; also, [ X   X  X  X  X  X  X  X   X  X  X  (IV) X  in Table XVII (large scale integrated circuit)] is segmented into [ X   X  X  X  X  (IV) X  (large scale)] and [ X   X  X  X  X  X  X  (IV) X  (integrated circuit)]; [ X   X  X  X  X  (OOV) X  (white rose)] is segmented into [ X   X  (IV) X  (white)] and [ X   X  X  (IV) X  (rose)]; similarly, [ X   X  X  (IV) X  (steel needle)] is segmented into [ X   X  (IV) X  (steel)] and [ X   X  (IV) X  (needle)]. None of these examples distort the original meaning. (III) Inconsistency (11.0% = 28.4% * 38.7%; 6.2% = 13.1% * 47.0%): This kind of error only applies to IV words. It indicates that the benchmark and the Top-1 candidate are different, and that both of them have been observed in the training set. It may also indicate that the same words (in similar contexts) are segmented differently across the training set and the testing set. For example, both [ X   X   X  X  X  (IV) X  (just like)] and the sequence [ X   X  (IV) X  (just),  X   X  (IV) X  (be)] are found in the training set in similar contexts in the CITYU corpus; by comparison, [ X   X   X  X  X  X  (IV) X  (interview team)] is a single word in the MSR training set but is segmented into two words [ X   X   X  (IV) X  (interview)] and [ X   X  (IV) X  (team)] in the benchmark.
 As the  X  X nconsistency X  category is unrelated to the proposed models, and the  X  X ot Critical X  category is usually not critical for the following processing phases, only the  X  X V-Critical X  and the  X  X OV-Critical X  sub-categories will be further analyzed here. For the  X  X V-Critical X  cases, although the ambiguity problem has been reported in the lit-erature as the main issue in segmenting the sequence of IV words [Zong 2008], it is not the major problem among  X  X V-Critical X  errors in our experiments. Most of the re-maining  X  X V-Critical X  errors instead res ult from data sparseness. For example, [ X  (j) (IV) (slip) X ,  X   X   X  (IV) (fall down) X  X  are two successive uni-character IV words in the CITYU testing benchmark, and are incorrectly grouped into an OOV word [ X   X )j(  X  (slip)]; how-ever,  X   X )j(  X  has not been observed as a continuous character sequence in the training set. Although  X  (j)  X  X nd X   X   X  turn up as two uni-character words here, their associated probabilities are very low: the probability of  X  (j)  X  with tag  X  X  X  is only 0.0370 (5 out of 135), while the probability with tag  X  X  X  is 0.4074 (55 out of 135); on the other hand, the probability of  X   X   X  with tag  X  X  X  is merely 0.1675 (67 out of 400), while the probabil-ity with tag  X  X  X  is 0.2075 (83 out of 400). Therefore, these two characters tend to be grouped together, if they do not appear consecutively in the training set. Many similar cases can be found in the  X  X V-Critical X  cate gory. This problem is more serious in the MSR corpus than in CITYU, as there are more long words in MSR. This issue would be less significant if a larger corpus were adopted.
 Table XVIII and Table XIX give the distributions of  X  X OV-Critical X  errors on the CITYU and MSR corpora, respectively. The errors in this category are further clas-sified into five sub-categories (as shown above) according to the causes; and the sub-categories are indexed according to their associated ratios in the CITYU corpus. The errors in each sub-category w ill be classified again into various sub-classes if necessary, also according to the causes.
 The distributions of various sub-categories for these two corpora are quite different. For example, the error type  X (A) Not Adopting Named Entity Preprocessing  X  X akesup the biggest portion in CITYU (30.5%); however, it is instead  X (B) Not Using Character-Type Information  X  which occupies the largest portion in MSR (36.1%). Furthermore, even the distributions of various sub-types under those sub-categories differ consider-ably between these two corpora. For example,  X  X oreign name X  is the largest sub-class (40%) under sub-category (A) in CITYU; however, it occupies only 6% in MSR. This difference arises because the CITYU corpus is collected from various regions (Beijing, Hong Kong, Shanghai, Taiwan, Singapore and Macao), so there are many more for-eign names than in the MSR corpus, which mainly covers the China news. As another example,  X  X unctuation X  makes up the largest portion (71%) under sub-category (B) in CITYU; however, it occupies only 2% in MSR. This large difference is mainly due to the corpus X  X  coding inconsistency problem. In this corpus, punctuation symbols are en-coded inconsistently in the training set and testing set; thus many punctuation errors occur. However, in the MSR corpus, such inc onsistency appears only for the decimal point and not for other punctuation symbols.
 The detailed description of each error type in the above tables is given as follows. Following the convention adopted above, the first percentage in parentheses in the headings of the following paragraphs indi cates its corresponding ratio in the CITYU corpus, and the second percentage denotes that in the MSR corpus. (A) Not Adopting Named Entity Pre-processing (30.5%; 25.4%): Named entities (NE) frequently cannot be handled with character n -gram information only. Errors of this type can be further classified into four sub-classes as follows. Again, the first per-centage in parentheses following the sub-class name indicates the corresponding ratio within this sub-category for the CITYU corpus, and the second number denotes that for the MSR. (1) Foreign Name (40%; 6%). Most foreign names are rendered via syllable-by-syllable (2) LOC  X  location (28%; 11%). For example, in Table XVIII (and also in Table XVI), the (3) ORG  X  organization (23%; 55%). As in the case of LOC, more features, rather than (4) Chinese Name (9%; 28%). Unlike in English, Chinese family names (mostly com-
A named-entity recognizer, which usually incorporates many features beyond char-acter n -gram information [Gao et al. 2005; Wu et al. 2005], should be helpful in cor-recting errors in this category. Such modul es should thus be used to provide candidate information for word segmentation models; however, this work is beyond the scope of the present paper. (B) Not Using Character-Type Information (24.2%; 36.1%): Some OOV errors can be corrected if character-type information (indicating if the character is a digit, a punc-tuation symbol, a foreign-character, or a Chinese-character) is utilized. As an exam-ple for numbers, the numerical string [ X   X   X  X  X  X  X  X  X  ( (OOV) X  (23661416)] shown in Table XVIII, which is  X 23661416 X  written in Chinese, is wrongly segmented into [ X   X  X  X  X  (OOV) X  (2366)] and [ X   X   X  X  X  (OOV) X  (1416)] as two OOV words. Also,  X 12.4(OOV) X  (shown in Table XIX) is incorrectly segmented into  X 12.(OOV) X  and  X 4(IV) X . Both errors can be corrected if we realize that all the associated charac-ters are characters related to numerical expressions. As an example for punctua-tion symbols, the word [ X   X  X  (IV) X  (single man)] and its following word [ X   X  (OOV) X  X , a colon symbol, are currently grouped together as one OOV non-word [ X   X   X  X  (NW) X  X  (shown in Table XVIII). Of course, this e rror can also be corrected if we know that  X   X  (OOV) X  is a punctuation symbol. Similarly, two words [ X   X  X  (IV) X  (the first)] and [ X   X  (OOV) X  X  are incorrectly grouped into [  X  X  X  (NW)] in Table XIX; and this error can also be corrected using character-type infor mation. Lastly, as an example for foreign-characters, the Chinese word [ X   X  X  X  (IV) X  (English)] and its following English word [ X  X alley(OOV) X  X , an English string, are currently grouped together as one OOV non-word [ X   X   X  X  X  valley(NW) X  X  (shown in Table XVIII). T his error, too, can be corrected if we are aware that [ X  X alley(OOV) X  X  is an English string. Similarly, [ X   X  X  (IV) X  (invent)] and [ X  X  c e d (OOV) X  X  in Table XIX will be correctly separated if the English string [ X  X  c e d (OOV) X  X  can be recognized as a string of foreign characters. (C) Not Adopting Prefix/Suffix Information (15.7%; 10.3%): Some OOV errors with prefixes or suffixes are likely to be corrected if the information concerning prefixes and suffixes can be utilized. As two examples in Table XVIII and Table XIX, the prefixed word  X   X   X   X  X  X   X  (unseeded) and the suffixed word  X   X  X  X  X   X   X  (desertization) are wrongly segmented into sequences of two words [ X   X  (IV) X  (un-),  X   X  X  X  (IV) X  (seed)] and [ X   X  X  (IV) X , (desert)  X   X  (IV) X  (-ization)] respectively. However, if we know that  X   X   X  (un-) is a prefix-character, then the chance that  X   X   X  is tagged as  X  X  X  will increase. Similarly, if  X   X   X   X  (-ization) is known to be a suffix-character, then the likelihood of  X   X   X  being tagged as  X  X  X  will increase as well. Clearly, it would be beneficial to integrate relevant features into the current models. (D) Idioms (14.4%; 11.7%): Chinese idioms are special words which often contain four characters, and they form a nearly clo sed-set, which grows very slowly. Accord-ing to the most stringent definition, there are about 5,000 such idioms in the Chinese language, though some dictionaries list over 20,000 19 . As an example in Table XVIII, the Chinese idiom  X   X   X  X  X  X  (OOV) X  (wonderful workmanship excelling nature) is in-correctly segmented into a sequence of three words [ X   X  (IV) X ,  X   X  (IV) X ,  X   X   X  (NW) X  X . A similar example  X   X  X  X  X  X  (OOV) X  (reach for what is beyond one X  X  grasp) can be also found in Table XIX. If we recognized this string as an idiom via a pre-constructed table, then the sequence [ X   X  X  (IV) X ,  X   X  X  X  X  X  (OOV) X  X  would not be segmented into [ X   X  (IV) X ,  X   X  X  (IV) X ,  X   X  X  (NW) X ,  X   X  (IV) X  X . (E) Others (15.2%; 16.4%): All remaining errors belong to this category. There are various sub-classes according to the causes, but the portion of each sub-class is small. Thus only some typical sub-classes, compri sed of errors with clear linguistic causes, are discussed here. The first percentage in parentheses following the sub-class names indicates the corresponding ratio within a given sub-category for the CITYU corpus, and the second number denotes that for the MSR corpus. (1) Split Compound (7%, 4%): Since the distance between elements of a split compound is usually beyond tri-gram scope in either the generative or discriminative model (i.e., usually indicates a long-distance dependency), neither model can handle this problem. For an example in the MSR corpus, [ X   X  (IV) X  (when),  X   X  X  X  (OOV) X  (solar total eclipses; total solar eclipses),  X   X  (IV) X (time)] is segmented into [ X   X  X  (IV) X  (this day),  X   X  X  (OOV) X  (com-plete eclipses),  X   X  (IV) X (time)], because  X   X  X   X  is an IV word. However, humans will know not to treat  X   X  X   X  as a group if the end of the sentence is  X   X   X (when),because  X   X  X  X  X   X  (at the time/when) is an indicator of adverbial of time. A list of split com-pounds (or a syntactic parser with an appr opriate grammar) wo uld be required to resolve such errors. (2) Abbreviations (6%, 13%): Chinese abbreviations are mainly formed in three major ways: reduction, elimination, and generalization [Lee 2005]. The abbreviation [ X   X  X  (OOV) X  (double insurance)] (shown in Table XIX) is formed via generalization: its full name in the MSR corpus is  X   X  X  X  X  X  X  ,  X  X  X  X  X   X   X (Ensure the summer harvest; Ensure the spring seedling emergence). Compared with other sub-categories, abbreviations are much more difficult to correct. Different strategies would need to be adopted for various formation patterns. Related information can be found in Chang and Lai [2004] and Sun and Wang [2006]; (3) Reduplication (2%; 2%), which includes  X  X ABB X  and  X  X BAB X  two forms (where A and B are different Chinese characters); related features have been adopted in Tseng et al. [2005] and Andrew [2006]. Table XVIII gives an example of  X  X ABB X : [ X   X  X  X  X  (OOV) X  (go out and come in; literally go out, go out, come in, come in)] is incorrectly split into [ X   X  (IV) X  (go out)] and [ X   X  X   X  (NW) X  X . It seems a collection of these patterns will be required to solve these errors. The remaining sub-classes are sparse, and thus will be skipped here.
Among the various categories mentioned above, sub-category (B) is selected for fur-ther improvement in this article, as it occupies the biggest portion in MSR (36.1%) and ranks the second in CITYU (24.2%). Furthermore, it can be implemented without additional resources such as prefix/suffix lists, idiom tables, etc. Lastly, the CIPS-SIGNAN Bakeoff 2010 [Zhao and Liu 2010] allowed the use of character-type informa-tion. There are two ways to utilize character-type information in our proposed Joint model: (1) Write rules for handling numerical expressions, punctuations, and English strings during construction of the word la ttice (by constraining the possible candi-dates); (2) Regard character-type information as a feature, and then integrate that information into the character-based generative/discriminative model. Since various rule-sets would be required fo r different corpora (accordin g to their different segmenta-tion criteria), method (2) is preferred, as no rule modification will be needed if criteria are updated: only the parameters need be retrained. The following section shows how much improvement can be achieved if character-type information is integrated into the Joint model as just suggested. As mentioned, the knowledge of character-type can be integrated into the model as an additional feature, which classifies a given character into five different types: (1) a Chinese character; (2) a punctuation-symbol; (3) an Arabic digit; (4) a Chinese nu-meral; and (5) a foreign character. Since the discriminative approach (under the ME framework) is capable of easily incorporating additional features, this character-type feature can be directly integrated into the character-based discriminative model. The new feature template (d) is thus added to the original list as follows: Where templates (a)  X  (c) are the same as those used in the closed-test mentioned before, and T ( C i ) represents the corresponding character-type mentioned above for C i . For example, when considering the punctuation-symbol  X , X  in the character sequence  X  each individual digit indicates the corresponding character-type defined above.
By contrast, incorporating additional features is more complicated for the gener-ative approach. The original character-tag pair [ c , t ]isfirstexpandedinto[ c , y , t ], where letter  X  y  X  denotes the corresponding character-type (i.e., the class of the given character) and is the same as T ( C i ) mentioned above. Afterwards, this new [ c , y , t ] trigram model is the log-linear integration of two simpler models (named Method 1, and shown below), since we would like to retain the advantages of the original model for handling IV words. The above formulation integrates the primary character-based generative model with a new character-type-based generative model. Since many character-bigrams of numerical or foreign strings cannot be covered in the training-set, this new model should play an essential role when such strings are encountered in a testing-set. The parameter  X  (0.0  X   X   X  1.0) is the weight for the [ c , t ] trigram factor, obtained from the cross-validation set (described in Section 3.2.3).

An alternative method for incorporating character-type information into the gen-erative model, to be designated Method 2, is to pre-convert various foreign alpha-bets, Arabic digits, and Chinese numerical characters into meta-foreign characters, meta-Arabic-numeral characters, and meta-Chinese-numeral characters, respectively. Note that the punctuations are not pre-converted into meta-punctuation characters, because most punctuations have been seen in training-sets (except the CITYU cor-pus), and different punctuation symbols behave differently (especially in the computer domain, which includes various path-names); therefore, various punctuation symbols will not be pooled together into a meta-class. Otherwise, we proceed as we have previ-ously done for the generative model for  X  X losed X  tests.

The segmentation results of the above open-test approaches (adopting the additional character-type feature) are shown in Table XX. In this table, the symbol  X / X  separates the results of closed-test and open-test. The  X  X enerative-1 X  rows show the segmen-tation results of the original generative trigram model in  X  X losed X  tests and of the Generative-1 model (with Method 1) in  X  X pen X  tests. Likewise, the  X  X enerative-2 X  rows give the results of the original generative trigram model in  X  X losed X  tests and the Generative-2 model (with Method 2) in  X  X pen X  tests. The results show that the character-type feature is useful in improving the performance of generative models for both Methods 1 and 2; and that Method 2 is superior to Method 1 (with 0.952 vs. 0.948 in Overall F -score). Also, Method 2 is much better than Method 1 in the PKU(ucvt.) corpus (0.951 vs. 0.938 in F-score), due to the problem of character-encoding-inconsistency mentioned above: Arabic digits and English characters are en-coded differently across its training and testing sets. This inconsistency problem exists for Method 1, but not for Method 2. This difference arises because Method 1 still uses the character-tag-pair trigram as a factor, while in Method 2 English characters and Arabic numerical characters are pre-converted into the meta-foreign character and the meta-Arabic-numeral character, respectively.

In addition, we test Method 2 with pre-conversion of various punctuation symbols into the same meta-punctuation character. Compared with the original Method 2, which did not pool the various punctuation-symbols, this new modification signifi-cantly improves the F -score from 0.946 to 0.950 in the CITYU corpus (not shown in Table XX), because punctuation symbols are encoded inconsistently in this corpus. However, this trick gives no improvement in other corpora, and even causes some mi-nor deterioration. The degradation occurs because punctuation symbols are not always tagged with  X  X  X : some, like  X / X ,  X - X ,  X   X , etc., may be tagged with  X  X  X . Thus, to further improve the performance of the generative model, we will need to categorize punctua-tion symbols according to their different behavior patterns.

Table XX also gives the segmentation results of the modified Discriminative model and the modified Discriminative-Plus model. Again, we see that character-type information is useful in improving the perfo rmance on all corpora and is most effective in the CITYU and PKU(ucvt.) corpora. Next, the modified generative and the modified Discriminative models are further integrated as in the previous  X  X losed X  tests: the Generative-1 model and the modified Discriminative model are integrated into the character-based Joint-1 model (abbreviated as Joint-1); the Generative-1 model and the modified Discriminative-Plus model are integrated into the character-based Joint-Plus-1 model (abbreviated as Joint-Plus-1); the Generative-2 model and the modified Discriminative model are integrated into the character-based Joint-2 model (abbreviated as Joint-2); and the Generative-2 model and the modified Discriminative-Plus model are integrated into the character-based Joint-Plus-2 model (abbreviated as Joint-Plus-2).

The segmentation results for the modified Joint models and the modified Joint-Plus models are also given in Table XX. We see that the Joint-Plus-2 model achieves the best F -score on each corpus. It is marked for visibility. Also, improvement is espe-cially noticeable in the CITYU and PKU(ucvt.) corpora, because the punctuations are inconsistent in the CITYU corpus, as are th e Arabic numbers and English characters in the PKU(ucvt.) corpus. In addition, the Joint-2 model holds an apparent edge over the modified Discriminative model on both the closed-tests and the open-tests. For the overall F -score, the Joint-2 model outperform s the Discriminative model by 0.9 per-cent on the closed-test and 1.1 percent on the open-test. The advantage of using the Joint-Plus-2 model over the Discriminative-Plus model is smaller but still significant (in comparison to that of the Joint model over the Discriminative model). For the over-all F -score, the Joint-Plus model exceeds the Di scriminative-Plus model by 0.4 percent on the closed-test, while the advantage rises up to only 0.5 percent on the open-test.
Although the overall improvement does not seem very impressive, most errors re-lated to numerical expressions, punctuations, and foreign character sequences are in-deed fixed. With the character-based Joint-2 model, 129 out of the original 143 related errors in the CITYU corpus and 185 out of 203 in the MSR corpus have been tagged cor-rectly with character-type information. Th e remaining errors (totaling 32 from both the CITYU corpus and the MSR corpus) can be classified into two sub-classes: (1) Missing Space Character (53%), and (2) Grouping with Quantifier (47%). The first sub-class indicates cases in which the usual space characters are missing. For example, in e r X  (Internet service provider)], the space s normally used to separate different words are absent; however, the benchmark segments them into [ X 2(IV) X  (Item 2),  X .(IV) X  (a periodsymbol), X 1992  X  (IV) X  (In year 1992)] and [ X  X  n t e r n e t (OOV) X ,  X  X  e r v i c e (OOV) X ,  X  X  r o v i d e r (OOV) X  X , respectively. For these two examples, the former is wrongly recognized as a false numerical expression [ X 2 . 1 9 9 2  X  (OOV) X  X , while the latter is identified as only one English OOV word because there is no space character. The errors in this sub-class are due to incorre ct text format conversion, and are beyond the capability of the character-type feature.

The second sub-class ( Grouping with Quantifier , 47%) denotes cases in which not all the Chinese characters following a number should be separated from the number. For example, in the MSR corpus, some Chinese measurement-units such as  X   X   X  (a Chinese quantifier for counting items) and  X   X   X  (Yuan, the currency unit for RMB), are often grouped with numbers, such as [ X 3 4  X   X  (34),  X   X   X  (county)] and [ X 5 80  X   X   X  (5,800,000 RMB)]. However, as the character-type adopted above cannot distinguish  X  X easurement-Unit X  characters from others, our model incorrectly groups two consecutive uni-character words [ X 5 (IV) X  (five)] and [ X   X  (IV) X  (province)] into one OOV word [ X 5  X  (OOV) X  (five provinces)]. Similarly, the two-word sequence [ X 9 9 3  X  (OOV) X  (9,930,000),  X   X  (IV) X  (working-day)] is grouped into one OOV word as [ X 9 9 3  X  X  (OOV) X  (9,930,000 working-day)], because  X   X   X  X nd X   X   X  are often tagged with  X  X  X  in the training-set. Apparently Chinese  X  X easurement-unit X  characters should be grouped together and treated as an additional character-type. Since the new character-type does not target the errors mentioned above, we can conclude that it is actually quite effective. As shown in the above section, the proposed Joint-2 model and Joint-Plus-2 model achieve better performance than previously reported models on all corpora tested. However, both the training-sets and the testing-sets are from the same domain. To test the cross-domain performance of the proposed models, we will adopt the Sim-plified Chinese Text corpora of different domains provided by CIPS-SIGNAN Bakeoff 2010 [Zhao and Liu 2010]. Four testing sets are provided by this Bakeoff, each of them from a different domain: literature, computers, medicine, and finance. However, only two of them (literature and computers) are provided with unlabeled training sets. In addition, it turns out that the labeled training data of Simplified Chinese Text in this Bakeoff is the same as the PKU training data of SIGHAN Bakeoff 2005, which comes from the News domain. The statistics of the SIGHAN 2010 corpora are shown in Table XXI.

Since the character-based Joint-Plus-2 model (with the character-type feature) achieves the best performance so far, we will conduct the domain adaptation test on this model only, for simplicity. Furthermore, the cross-domain performance and the ef-fect of domain adaptation will not be compared with the systems reported in SIGNAN Bakeoff-2010: because strict regulation was not provided, these systems adopted vari-ous rule-sets and additional information (e.g., the pinyin spelling of each character), so that it would be difficult to conduct fair comparisons between them. Finally, again for simplicity, we fix the weight of the generative score in our Joint-Plus-2 model during the training procedure (to  X  =0 . 60, acquired from the PKU development set in the last section).

To incorporate unlabeled training data, Mcclosky et al. [2006] adopted a semi-supervised learning method called self-training . The issue of convergence during such learning has been studied in Haffari and Sarkar [2007] and Culp and Michailidis [2008]. In the present study, we adopt a similar semi-supervised learning method, which proceeds as follows: The initial segmenter is first trained with a pre-labeled corpus; then this trained segmenter is used to segment the unlabeled training data; and finally, the resulting data is regarded as labeled data (denoted by U i for the i -th iteration) and added to the original pre-labeled data to form a new training set. The above procedure is repeated until the convergence criterion is met. Currently, the iter-ations stop when the similarity between the results of two consecutive iterations ( U i  X  1 and U i ) reaches a high level ( F -score &gt; 0.9999, evaluated by treating U i  X  1 as the bench-mark and U i as the testing set). In our observation, the above procedure converges quickly, with only three or four iterations for both Literature and Computer corpora. The flow of the adopted semi-supervised learning procedure is shown in Figure 3.
Table XXII gives the segmentation results of various cross-domain testing-sets un-der different conditions. The performance of in-domain testing-set is shown in the first row in Table XX, labeled PKU(cvt.). For cross-domain testing-sets, the performance without conducting domain adaptation is given in the rows labeled  X  X oint-Plus-2 X ; in contrast, the performance with domain adaptation is given in the rows labeled  X  X oint-Plus-2+S X . Marked entries denote that the performance with domain adaptation is significantly better than without.

In comparison with the in-domain performance (SIGHAN 2005), the cross-domain performance (except for the Finance domain) degrades significantly, because many technical terms in different domains cannot be covered by the training-set of the News domain. (This analysis is supported by the dramatic increment of OOV Rate in Table XXII.) Among the various domains, the Finance domain obtains the best result, which is even a bit better than the in-domain performance. The reason is that most OOV words in the Finance domain are numerical expressions, which can be easily handled by exploiting character-type information. The worst domain is Medicine, because there are many OOV medical terms. Table XXII also shows that conducting domain adaptation significantly improves the performance of the Computer domain (raising F -score from 0.935 to 0.940, which is statistically significant); however, performance improves only slightly in the Literature domain (from 0.937 to 0.939, also statistically significant). This is because the difference between News and Computer is much greater than that between News and Literature. The unlabeled training data from the Computer domain is thus more effective in providing information con-cerning computer-related technical terms , which are not found in the original News domain.

Table XXII also gives the OOV rates for cross-domain testing-sets with and without domain adaptation. In the case with domain adaptation, the OOV words in the testing set are checked against the union of the pre-labeled and the unlabeled training cor-pora. For the unlabeled training corpus, the OOV words are checked against its final segmentation results after convergence. We see that the OOV rates of the Computer domain decreases sharply after domain adaptation (decreasing from 0.152 to 0.079). This decrease is much more obvious than that seen in the Literature domain (from 0.069 to 0.056). However, the improvement (of F -score)withdomainadaptationin the Computer domain is only 0.5%. Upon analyzing, we find that most of the OOV words in the Computer domain, which are covered by the unlabeled training data, are numbers and English strings; and most of these words have already been correctly handled by the Joint-Plus-2 model before the semi-supervised learning. Thus, even though the OOV rates decrease sharply, the improvement with domain adaptation in the Computer domain is still minor.

On the other hand, the Computer domain performs better than the Literature do-main after domain adaptation (0.940 versus 0.939 in F -score). Even its OOV rate is higher (0.079 versus 0.056, after adaptation). This observation can be explained as fol-lows: after numbers and English strings are excluded, the number of remaining OOV words covered by the unlabeled training data in the Literature domain is only 177, while the number in the Computer is 1,011. Further, the unlabeled corpora provided by the SIGHAN Bakeoff-2010 are very small compared with the pre-labeled corpora. The gain from the unlabeled data should thus be greater if a larger unlabeled training corpus is provided. The word-based generative model is a well-known approach used in many successful applications [Gao et al. 2003; Zhang et al. 2003]. However, Zhang et al. [2006] has shown that, while this approach performs excellently for IV words, it is quite weak for OOV words. To handle OOV words appropriately, Zhang et al. [2003] adopted a proce-dure for incorporating other knowledge of various sorts. In contrast to the word-based generative model, the word-based discriminative model is adopted only in [Zhang and Clark 2007]. This study utilizes a discriminative perceptron algorithm [Collins 2002] to generate word candidates with features related to both words and characters. This model reportedly achieves state-of-the-art performance on some of the corpora tested.

We can now consider the character-based tagging model [Xue 2003]. This method has become dominant because it can tolerate OOV words. As a consequence, in the SIGHAN Bakeoff 2005 [Emerson 2005], all systems ranked in the first tier [Asahara et al. 2005; Tseng et al. 2005] are based upon it. However, the performance of this approach is still quite unsatisfactory [Huang et al. 2007], and many studies have tried to improve it. For example, Peng et al. [2004] integrates domain knowledge, such as additional word lists, character lists , and  X  X art-of-speech character lexicons X  (including title prefixes, title suffixes, Chinese surnames, etc.) into the framework of the conditional random field (CRF) [Lafferty et al. 2001]. In a similar spirit, Tseng et al. [2005] adopts a large number of linguistic features, such as features representing morphological and character reduplication. Zhao et al. [2006] reports that the six-tag set using a three-character window outperforms the standard four-tag set with a five-character window. Finally, Li and Sun [2009] uses punctuation as implicit annotation to improve OOV word recognition.

In general, the character-based tagging model yields high recall of OOV words (R
OOV ) but unsatisfactory recall of IV words (R IV ). To overcome this weakness, Zhang et al. [2006] propose a sub-word tagging approach, and Fu et al. [2008] adopts a morpheme-based chunking approach. Sun et al. [2009] incorporates hybrid infor-mation, based on both word and character sequences, with a latent variable model. Sun [2010] compares the performance of the word-based discriminative model and the character-based discriminative model, and then uses a bagging approach to combine the outputs of these two models. Recently, Zhang and Clark [2011] use a single dis-criminative model to adopt both word-based and character-based features. Notably, while the character-based model can be associated with the generative form as argued here, there are no related papers in the literature. (The only exceptions are our own conference articles [Wang et al. 2009, 2010], which are greatly reduced versions of the current article.)
With regard to integration of generative and discriminative models, a hybrid gener-ative/discriminative approach was proposed by Jaakkola and Haussler [1999]. In that study, the kernel function for the discriminative model was extracted from a genera-tive model. Also, Raina et al. [2004] divide the feature vector into sub-vectors based on na  X   X ve Bayesian assumptions, and then combines these sub-generative models with discriminative learning. More recently, Jiampojamarn et al. [2010] integrated a gen-erative joint n-gram model as binary features into the discriminative training. Specifi-cally for WS, Andrew [2006] improves performance by adding generative features into a semi-Markov CRF framework. However, the gain from adopting these additional generative components has been insignificant. As compared with these various ap-proaches, our experiments have shown that our proposed log-linear interpolation is still the most effective way to combine the ge nerative and the discriminative models for the WS problem, simple though it is.

Since some ambiguities of word segmentation require even the information of sub-sequent phases (e.g., POS tagging, parsing, etc.) to solve, some researchers do word segmentation jointly with subsequent tasks. For example, Shi and Wang [2007] in-corporate the Part-of-Speech (POS) information in the WS procedure, and the best outputs are searched with the overall joint WS and POS probabilistic score. Simi-lar works also include Jiang et al. [2008], Zhang and Clark [2008], Kruengkrai et al. [2009], Sun [2011], and Zhang and Clark [2011]. Furthermore, Li [2011] proposes a new paradigm for Chinese word segmentation, which do word segmentation, word inter-structure, and phrase parsing at the same time in a unified way. However, all of them require additional linguistic resources (e.g., a corpus annotated with POS or a Chinese Treebank).

This article differs from previous approaches in several ways. First, we propose a new model form including the character-tag-pair (as opposed to simply adding a few new features under the same discriminative framework). Second, we propose and test a simple but effective way to integrate the generative and discriminative models. Third, all state-of-the-art systems reported in the literature are checked and compared with our systems. Fourth, a complete and detailed error analysis is conducted, which clearly points out directions for future research. Fifth, we show the effect of adding character-type information on the SIGHAN Bakeoff 2005. Last, a semi-supervised learning method is proposed to conduct domain adaptation for word segmentation. Since word segmentation is the first step for most Chinese NLP applications, WS er-rors will be carried forward into subsequ ent phases. Thus WS accuracy is crucial for Chinese NLP and should be raised as much as possible. The traditional word-trigram generative model can identify IV words quite well, but cannot handle OOV words. To address this issue, this article first proposes a new character-based gen-erative model, which replaces word-based n -grams with character-tag-pair n -grams. As the vocabulary of characters is a closed-set, as opposed to the open-set of words, there will be no more unseen candidates if the training set is large enough. Thus the character-based approach can handle OOV words much better than the word n -gram approach (R OOV is significantly raised from 0.053 to 0.511). Experiments conducted on the second SIGHAN Bakeoff 2005 corpora have shown that the proposed character-based generative model not only achieves a good balance between IV words and OOV words, but also obtains competitive results with the widely adopted character-based discriminative model.
 On the other hand, although the character-based discriminative approach handles OOV words better, given its ability to incorporate the future context as features (as generative models cannot), it fails to model the adhesion and dependency between ad-jacent characters within words (as the generative model does, and as humans are be-lieved to do when segmenting words). It thus gives unsatisfactory performance for IV words. That is, the generative and discriminative approaches complement each other in handling IV words and OOV words. To take advantage of these complementary ca-pacities, a joint model is thus further propo sed to combine the character-based discrim-inative approach and the proposed character-based generative approach. A closed-test on the SIGHAN Bakeoff 2005 corpora shows that this joint model significantly outper-forms all the state-of-the-art systems reported in the literature. Although the proposed approaches have been tested on Chinese corpora only, we believe that they should also be applicable to other languages with similar characteristics (e.g., Japanese and Korean), since no Chinese-specific features (e.g., prefixes, suffixes, or Chinese family names) are adopted in the models.

After the remaining errors of the Joint model were analyzed, we observed that many of them (24.2% of the OOV Critical section for the CITYU corpus, and 36.1% for MSR) were caused by failure to take the character -type into account  X  that is, failure to dis-tinguish punctuation-symbols, Arabic numbers, and English characters from common Chinese characters. And indeed, after we incorporated such character-type informa-tion, most errors related to numerical expressions, English character sequences, and punctuations were corrected. We thus suspect that more character-related features (showing for example whether the character is a prefix or suffix, a surname-character, etc) should be added in the future if further improvement is required.

Finally, cross-domain performance has been evaluated on the SIGHAN 2010 cor-pora, and a semi-supervised method has been proposed for conducting domain adap-tation. The results show that this approach is effective, especially when the mismatch between two domains is large.

