 1. Introduction
Air pollution (e.g. CO 2 ,NO x ,PM 10 and O 3 ) has been a major concern, especially for densely populated metropolitan areas, since the level of pollution is strictly associated with the health of the inhabitants. Especially important is the particulate matter (PM) of the diameters up to 10 m m (PM 10 ). The main source of PM is the vehicular traffic and dust of the streets generated by the circulation. These particles not only reduce the visibility of the air but have also direct impact on human health via inhalation ( Martuzzi et al., 2005 ; Wilks, 1995 ). Actually, PM is of importance for an European policy (the new European Air Quality Directive
EC/2008/50) defining the restrictions for the yearly and 24 h averages PM 10 concentrations.

To respect the short term limit values defined by these restrictions and diminish dangerous concentration levels, emis-sion abatement actions have to be planned at least one day in advance. Moreover, according to EU directives, public information on the air quality status and on the predictable trend for the next days should be also provided.

In the last decade, several forecasting systems have been designed by applying different mathematical tools and models.
Various methods of prediction have been already developed. ( Agirre-Basurk et al., 2006 ; Al-Alawi et al., 2008 ; Grivas and
Chaloulakou, 2006 ; Kukkonen et al., 2003 ; Paschalidou et al., 2010 ; Osowski et al., 2009 ). Some of them use complex mathe-matical models simulating the dynamics of the environmental processes ( Agirre-Basurk et al., 2006 ; Nicolaides et al., 2004 ; Peace et al., 2005 ), often used representatives of the latter approach are the autoregressive linear or nonlinear models ( Kukkonen et al., 2003 ; Perez and Reyes, 2002 , 2006 ), multilayer perceptron (MLP) or radial basis function (RBF) neural networks ( Grivas and
Chaloulakou, 2006 ; Hooyberghs et al., 2005 ; Kukkonen et al., 2003 ; Niska et al., 2004 ; Perez and Reyes, 2002 ), support vector machine ( Osowski and Garanty, 2007 ) or even the ensemble of many neural predictors ( Siwek et al., 2009 ).

For instance, Perez and Reyes (2002 , 2006) applied MLP to predict the PM 10 concentrations in Santiago, Chile while
Chaloulakou et al. (2003) evaluated neural network models and multiple regression models for the prediction of daily average
PM 10 concentrations in Athens, Greece. Kukkonen et al. (2003) used and evaluated five neural network models in comparison to a linear statistical model and a deterministic modeling system for the prediction of urban NO 2 and PM 10 concentrations in central
Helsinki, Finland. Hooyberghs et al. (2005) used the resources of environmental data of the European Center for Medium-Range
Weather Forecasts (ECMWF) to develop a neural network model to forecast the daily one-day-ahead average PM 10 concentrations in Belgium. Grivas and Chaloulakou (2006) compared the performance of various developed neural models to get the predictions of PM 10 hourly concentrations. They used also a genetic algorithm optimization procedure for the selection of the input variables. Paschalidou et al. (2010) presented the methods of forecasting the hourly PM 10 concentration in Cyprus using artificial neural networks (MLP and RBF) and multiple regression models.

There is still no solved problem whether linear or nonlinear models of PM 10 prediction are better. The papers of Perez and Reyes (2002 , 2006) and Corani (2005) have not found significant differences between the results of applying linear and nonlinear approaches. We will also investigate this problem by applying the statistical Hinich test on the data measured in Warsaw.
Nowadays, most papers develop the methods of forecasting the daily average values of PM 10 using different solutions relying on application of the neural networks and other statistical signal processing methods. They have developed particular (different) models of forecasting, relying on the prediction of the chosen one, regarded by them as the best. There were no attempts to integrate simultaneously different models into one final forecast.
In our paper, we present different strategies. First, we decom-pose the time series into few sub-series using wavelet transforma-tion ( Osowski and Garanty, 2007 ; Misiti et al., 2009 ). These sub-series are next subject to prediction and combined together to form the final forecast. As a result, instead of one high variability time series we predict few of them but of lower variability. Recently, there are some other papers ( Deng et al., 2010 ; Zaharim et al., 2009 ; Sharuddin et al., 2008 ; Li and Shue, 2004 ) showing usefulness of such approach to pollution prediction.
Secondly, we investigate the simultaneous application of few different models of neural prediction methods. In contrary to the commonly used approaches, we take into account all of them simultaneously, integrating their outcomes into one final forecast to get better accuracy. The important condition of good perfor-mance of this solution is the independence of predictors working in the ensemble ( Haykin, 1999 ; Kuncheva, 2004 ) and the compar-able (although not necessarily equal) accuracy of each predictor. To satisfy this condition, we apply different neural networks: multilayer perceptron (MLP), support vector machine for regres-sion (SVR), Elman network (EN) and radial basis function network (RBF), working in prediction mode, including also the linear model. The integration of them into one system is solved by an additional neural network, for which the input signals are formed by the predicted values generated by the individual neural predictors.

The theoretical considerations have been followed by the numerical experiments made for the data gathered within few years in Warsaw, Poland. The results of experiments have shown that application of wavelet transformation is the most important factor in improving the accuracy of forecasting. Application of ensemble leads also to some limited improvement, although in a not significant way. The results of these experiments are given and discussed in the paper.

The paper is organized as follows. The Section 2 is devoted to the analysis of the prediction problem. We investigate the rela-tion between the concentration of pollution and the parameters of other atmospheric variables, as well as the linearity of the process. Section 3 introduces briefly three structures of the neural networks and support vector machine working in regression mode, all applied in the prediction mode. In Section 4, the wavelet decomposition of the analyzed time series of PM 10 concentration is presented as well as the idea of the distributed prediction of the wavelet coefficients on different levels. Section 5 introduces the application of many predictors integrated into one ensemble network responsible for the final forecast of PM 10 . The results of numerical experiments are given in Section 6 . They present and compare the results of the individual predictors and the ensem-ble. The last section represents the conclusions of the study. 2. Problem analysis 2.1. Analysis of PM 10 distribution
In the prediction of the next day pollution of PM 10 , the great impact is paid on its previous day values. The difficulty of the prediction problem is measured by the changes of the PM 10 concentration from day to day. The higher this variability the more difficult is the prediction problem.

Fig. 1 presents the daily averaged values of PM 10 pollution measured by the meteorological station situated in suburb Ursy-now of Warsaw in three succeeding years: 2006, 2007 and 2008.
We can see quite significant changes of the distribution of these values from year to year. The higher is the variability of the time series the more difficult its prediction task. Therefore, good measure of the difficulty of prediction is the ratio of standard deviation and mean value of the series. The higher is this ratio, the more harder is the prediction problem. Table 1 presents the mean values and standard deviations of pollution presented in Fig. 1 corresponding to different years. The ratio std./mean assumes relatively high values, however, they are changing from year to year.

In signal processing society, the difficulty of treating the time series is measured by the signal to noise ratio, defined in decibels as SNR  X  20 log(mean/std.). The fifth column of Table 1 presents these ratios for the investigated three years. Especially, difficult case is presented by the data of the year 2008, for which this value is the smallest one. Additionally, we can see high differ-ences for different years between the number of exceedances of the mean over the allowed level of pollution. Summarizing, the statistical data presented in Table 1 is the evidence of the difficulty in building the universal model if we want it to be valid for any year of consideration.

Fig. 2 presents the plots of correlation coefficients of the PM data for three investigated years, presenting them as the function of delays (days). Although the general shape of the curves is some degree similar as we can observe the differences in detailed values corresponding to different days. The irregularities in shape are the evidence of the non-stationarity of data. There are also visible repeatabilities of some patterns regarding the chosen types of the days.

The difficulty of the prediction problem may be additionally illustrated by presenting the pollution of the actual day as a function of its value of the previous day. The prediction is easiest when the distribution of data is close to the diagonal relationship in this coordinate system. Fig. 3 presents the distribution of the
PM 10 data corresponding to three years. As we see the data are distributed in large regions of the plane and are far from diagonal.
Quite interesting is also the correlation of the pollution among different years. Table 2 represents the values of the cross correlation coefficients among the years under consideration regarding the PM 10 pollution. They stay on a reasonably high level, although we can observe some differences among them. The lowest correlation is observed between 2007 and 2008. However, note that relatively high values of correlation coefficients not necessarily mean facilitation of the prediction task, since correla-tion takes into account only the trends of the time series and not the equality of the absolute values.

The last problem that should be analyzed before starting to build predictive model of the time series is the assessment of the linearity or nonlinearity of the process under modeling. Linearity may simplify the representation of the model, since the linear process can be described by the linear relations, much easier in modeling.

Hinich test for checking the linearity of the process has been applied ( Nikias and Petropulu, 1993 ; Swami et al., 1993 ). The basic idea behind the test is that if the third order cumulant of the process is zero, then the bispectrum and its bicoherence are also zero. If the bispectrum is not zero then the process is non-
Gaussian (potentially nonlinear). In the case of a non-Gaussian and linear process, the bicoherence is a nonzero constant.
In practice, the so-called  X  X  X robability of false alarm X  X  (PFA), that is the probability that we will be wrong in assuming that the data have a nonzero bispectrum which has been implemented to test the Gaussianity. If this probability is small, reject the assumption of zero bispectrum and also reject the assumption of the Gaussianity of the process.

In the case of non-Gaussian process, the linearity test, checking whether the squared bicoherence is constant for all frequencies f and f 2 reveals the eventual linearity of the process. In practice, the bicoherence is not always flat. In testing for linearity or non-linearity of the non-Gaussian processes, we may rely on the comparison of the so called empirical and theoretical sample interquartile ranges ( Swami et al.,1993 ). If their values are comparable the process is linear. In the case of high differences, the process is regarded as nonlinear ( Nikias and Petropulu, 1993 ).
In checking the nonlinearity, we have applied the function glstat.m of Matlab ( Swami et al.,1993 ). After doing it on the PM pollution data, we have got PFA  X  0, which means that the assumption of Gaussianity should be rejected. In checking linear-ity and nonlinearity of the process, we compared in this test the estimated ( R e ) and theoretical ( R t ) values of the interquartile ranges. We have got estimated value of R e  X  99.1574 and theore-tical value R t  X  22.4438. The ratio R e / R t  X  4.41. Such value corre-sponds to weak nonlinearity of the process ( Swami et al., 1993 ). It means that the nonlinear methods of prediction should be better than the linear. Therefore, in further experiments we will be concerned mainly with the nonlinear (neural) methods, but linear one will be also compared to them. 2.2. Analysis of meteorological variables
To build the adequate prediction model, we have to generate the proper input prognostic features, on the basis of which the predictor will generate its forecast. So it is quite important to discover the relationship between PM 10 concentration and the other meteorological parameters influencing the pollution.
According to the actual research, the most important recognized parameters having the greatest impact on the mechanism of pollution creation are: the temperature, pressure (not available in our measurements), direction and speed of the wind and humid-ity. To provide the appropriate representation of the wind, we have applied its speed 9 w 9 and the angle j combined together in the form x and y components as following: w  X  9 w 9 cos j w  X  9 w 9 sin j  X  1  X  (2 signals in vector representation). Such representation pro-vides the continuity of both components at the change of an angle. To understand these relations we have investigated the distribution of PM 10 concentration as a function of these para-meters. Fig. 4 presents the relationships between the daily PM concentration and two chosen pollution factors: the speed of the wind ( x -coordinate) and the average daily humidity, all given for 3 years under consideration.

As it is seen the distribution of the measured points is far from any unique dependence and represents rather complex chaotic process. There is no explicit functional relations between PM concentration and these meteorological variables. However, even in this case we can observe quite evident principle: the higher is the speed of the wind (the absolute value) the smaller the averaged values of pollution. Complex relations are also observed for the other meteorological variables associated with the mechanism of pollution creation. For example, the temperature inversion may cause the trap of air pollution into the atmo-sphere X  X  lowest layer, from which it can be removed only by strong horizontal winds. The impact of humidity on PM 10 is also evident, since PM 10 contains hygroscopic components which attract water. Due to this, the water uptake particles of PM may become so large that they fall down on the ground.
The important are also the relations between PM 10 and the environmental variables themselves. PM 10 concentration should be well correlated with environmental variables, while we should avoid environmental variables strongly correlated with each other. Table 3 presents the values of correlation coefficients. They have been calculated for a data corresponding to all three years under consideration.

It is evident that all atmospheric parameters are weakly correlated with each other (except humidity and temperature), hence there is no reason to remove any of them. This fact is also well illustrated on Fig. 5 presenting the distribution of points corresponding to the wind speed ( x-coordinate) and the tempera-ture ( Fig. 5 a) and the wind speed and humidity ( Fig. 5 b). The points are distributed randomly on a plane and well illustrate the lack of correlation.

To check the multi-collinearity among the exogenous variables (the meteorological parameters), we have performed different tests. The tested vector was composed as follows: x  X  [ temperature , wind x , wind y , humidity ]. The F -test testing the joint hypothesis that all coefficients are all equal zero (more precisely for model
PM  X  a 0  X  a 1 U temperature  X  a 2 U wind x  X  a 3 U wind y ( e is iid N (0,1)), we have tested the null hypothesis: H  X  a 2  X  a 3  X  a 4  X  0 against the alternative hypothesis: H 0 3 a 2 a 0 3 a 3 a 0 3 a 4 a 0). The results Fstat  X  47.25, p _value o 0.001 vote against the null hypothesis ( Swami et al., 1993 ). In the t -test we tested if each variable is significant (more precisely for null hypothesis H 0 : a i  X  0 or for the alternative hypothesis:
H 1 : a i a 0 (four tests, for i  X  1.2.3.4). The results are given in Table 4 .

These results suggest that there is no collinearity between the exogenous variables, since all p -values are below the threshold level 0.05. The second applied test, variance inflation factor (VIF) performed in Matlab ( Swami et al., 1993 ) has generated the results depicted in Table 5 .

The tolerance of none of the variables was below the value of 0.1 and none of variables was characterized by VIF value above 5.
This is once again the evidence of the lack of muli-collinearity among them ( Swami et al., 1993 ).

The important conclusion from the analysis presented above is that the PM 10 prediction represents difficult, weakly nonlinear problem, and to obtain the highest accuracy of prediction we should rather apply the nonlinear model of the process, taking into account the complex relations between the concentration of
PM 10 and the basic atmospheric parameters influencing the mechanisms of creation and spreading the pollution. In the presented solution, we propose the simultaneous application of few neural networks working in various arrangements. We have also included the linear ARX model to compare its effectiveness with the nonlinear neural predictors. All of them will develop their predicted values by relying decision on different principles of signal processing. We combine them together in an ensemble integrated in order to increase the final accuracy of forecast. 3. The neural type networks for prediction
The important point in our approach to the prediction problem is applying many independent predictors combined in the ensem-ble. It was proved in Kuncheva (2004 ) that combining many, even lower quality solutions in an ensemble should increase the accuracy of performance under the condition of their independent operation. The output signals of the individual predictors, elabo-rated on the basis of the same input data but of different principles of operation give good hope to generate independent outcomes, which combined together provide the room for further improvement of prognosis accuracy.

At independent operation of predictors, each of them commits the prediction errors of different values for the particular days.
Some of these errors are positive and some negative. Taking into account all these results for any particular day we are able to compensate (to some degree) the errors and in this way to increase the accuracy of prognosis. To get the best results we should chose predictors of similar quality, however of indepen-dent operation. In our solution, we have chosen 4 neural type predictors: the multilayer perceptron, radial basis function network, Elman recurrent network and support vector machine working in regression mode.

We have chosen these types of solution since they represent different (independent) approaches to the approximation pro-blem. The MLP is one of the best known universal, global approximator ( Hornik et al., 1989 ) applying the sigmoidal activa-tion function. RBF network uses local (Gaussian) function and special learning algorithm significantly different from MLP. SVR is a universal solution applying kernel principle and very sophisti-cated, robust statistical learning algorithm. All of them (MLP, RBF and SVR) use the feedforward structure of signal processing. The fourth predictor (Elman network) belongs to feedback structures and was proved to behave well at modeling the complex pro-cesses of pollution creation ( Brunelli et al., 2007 ). Additionally, to provide the highest possible independence we have learned each of them on partially different data, selected randomly from the whole learning set. All of the chosen networks are known from excellent operation in nonlinear signal processing ( Haykin, 1999 ;
Sch  X  olkopf and Smola, 2002 ). The tests made in Meyer et al. (2003 ) are good evidence of this statement. Application of predictors relied in their operation principle on different fundamentals as well as training them on different data should provide the independent results of their operation ( Kuncheva, 2004 ).
We have limited the number of neural predictors to only four most representatives, differing significantly in their principle of operation and providing in this way their independence. Increas-ing this number to more predictors presents no difficulty, and the same procedure of signal processing may be applied in such case.
To represent the generally unknown, next day PM 10 pollution level, we map its past values into the present forecasted one. The number of past days has been adjusted in an experimental way by trying different numbers of them and checking the generalization ability of the predictors. These experiments have shown that one previous day is an optimum choice. To confirm it we have also calculated the correlation between the actual and many previous days pollution. These experiments have shown that there is a little correlation between the actual and higher than one past days pollution levels (the relative correlation coefficient below 0.1 for delays higher than one). The general supervised model of the pollution forecast for d th day has been assumed in the following mathematical form ( Osowski and Garanty, 2007 ): ^ P  X  d  X  X  f  X  w , w x , w y , t , h , r , s , P  X  d 1  X  X  X  2  X 
In this expression, w represents the vector of adjusted para-meters of the network, w x , w y  X  the wind speed in x and y directions, t  X  temperature, h  X  humidity, r  X  type of the day and s  X  the season of the year. The symbol ^ P  X  d  X  represents the predicted PM and the P  X  d 1  X  written without that  X  the known exact value of the pollution of the previous day. To pro vide the appropriate represen-tation of the wind, we have applied its two components w x , as defined by Eq. (1). In our model, we did not use the information of the pressure since this variable was not measured in the meteor-ological station. Additionally, we take into account the type of the day under prediction (binary representation of weekend or work day: 1 for work day and 0 for weekend) and the season of the year (binary representation of four seasons: 11  X  winter, 10  X  spring, 01  X  summer and 00  X  autumn). Fig. 6 presents the general model of forecasting the pollution corresponding to the next d th day. The exogenous variables (wind, temp erature, humidity) refer to the d th day. Since their values are usually not exactly known in advance, we use in practice their predicted values given by the meteorological authority instead of real variables.

To be sure that all these variables are significant for the prediction process, we have checked their significance by per-forming the selection procedure developed in the paper ( Guyon et al., 2002 ), based on the application of linear SVM. All input variables had the relative significance level (compared to the best one) higher than 0.4, which means that all of them are important for prediction process.

To provide similar impact of all input variables the data samples should be normalized. The normalization may take different forms, from which the simplest one is to divide the real value by the mean of the data base, corresponding to the years taking part in experiments.

The particular forms of the applied predictors depend on their structure and way of learning. The expression (1) may be asso-ciated with all types of neural type predictors considered in our work: MLP, RBF, SVR and EN. Good description of these networks may be found in the books, ( Haykin, 1999 ; Vapnik, 1998 ; Sch  X  olkopf and Smola, 2002 ), therefore, it will be omitted here.
In the case of MLP the optimal number of hidden neurons was found by using trial and error approach. It means learning many different structures of MLP networks ( Osowski et al., 1996 ) and accepting this one which provides the least value of the error on the validation data extracted from the learning data set (10% of learning data). On the basis of these experiments, we have found the optimal MLP structure consisting of one hidden layers of 8 sigmoidal neurons (the structure 8-8-1).

The process of RBF network parameter adaptation (number of hidden Gaussian neurons, their centers and weights) was solved by applying the orthogonal least square (OLS) procedure ( Haykin, 1999 ). The input data for RBF network are exactly the same as for
MLP predictor. The best results have been obtained at 40 Gaussian hidden neurons (the network structure 8-40-1).

In the case of Elman network, we have used the structure 8-5-1 applying 8 input external nodes (the same as in MLP), only 5 hidden neurons and 1 output neuron, responsible for the predicted value.
The learning strategy of Elman network exploited the minimization of error function and was performed using the Levenberg X  Marquardt algorithm implemented on Matlab platform.

The learning strategy of SVR network is relied on another philosophy than in the MLP, RBF or Elman networks. Instead of minimizing the error function defined for the learning data it minimizes the weights of the network, while keeping the output signals as close as possible to the their destination values with the predefined tolerance limit e ( Vapnik, 1998 ; Sch  X  olkopf and Smola, 2002 ). The regularization constant C is applied for weighting between the values of weights and the prediction error on the learning data.

To get the reliable results of learning, we have to make the proper choice of hyperparameters: e (the assumed tolerance), the parameter g of the Gaussian kernel and C (the user specified regularization parameter). Constant e determines the margin within which the error is neglected. The smaller its value the higher is the accuracy of the required matching of the response y ( x i ) of SVR to the proper target values t i in the learning data set.
However, too accurate matching of the learning data may result in loss of the generalization ability of network, leading to the increase of the testing error. For the normalized input signals applied to the network the value of e is usually adjusted in the range (10 3  X 10 2 ) while C is much higher than the value of 1 (the typical value 100 X 1000). The optimal values of hyperparameters ( C , e and g ) were determined for each pair of classes independently after additional series of learning experiments through the use of the validation test sets. The process of optimizing them was done together. Many different values of C , e and g combined together in the learning process have been used in the learning process and their optimal values are those for which the classification error on the validation data set was the smallest one. 4. Wavelet representation of the time series
Our main task is the prediction of the mean value of PM 10 the next day, knowing the history of previous days and the predicted values of the meteorological parameters for the day under prediction. The important problem is the choice of the variable subject to prediction. The natural way is to predict the whole pollution value for the next day. However, because of high variability its accurate prediction is difficult. Another solution is to decompose the predicted time series into terms of lower variability, apply the prediction strategy to each of them and then sum up the individual terms. We will use here the wavelet decomposition of the original time series of PM 10 concentration ( Daubechies, 1988 ; Mallat, 1989 ). The application of wavelet in time series analysis and prediction (including PM 10 ) has been already applied in some papers ( Deng et al., 2010 ; Li and Shue, 2004 ; Osowski and Garanty, 2007 ; Shaharuddin et al., 2008 ;
Zaharim et al., 2009 ). These papers have shown the advantages of decomposition of original time series into sub-series resulting from wavelet decomposition.

Let us denote the analyzed time series by x ( n ). The goal of the discrete wavelet transformation is to decompose this time series into a finite summation of shifted wavelets at different scales (levels) according to the expansion ( Daubechies, 1988 ; Mallat, 1989 ) x  X  n  X  X  where c jk is a new set of coefficients and c  X  2 j nT k  X  is the wavelet of j th level (scale) shifted by k samples.

In practice, the wavelet transformation decomposes the origi-nal time series into the detailed coefficients D j ( k ) of the proper time shifts k at different levels ( j  X  1, 2, y , J ) and the residual approximated signal A J ( k ) using the so called Mallat pyramid algorithm through the series of high and low pass filtering processes ( Mallat, 1989 ). As a result of the discrete wavelet transformation, the number of points of the succeeding levels is halved. However, we return to their original number by applying the reconstruction procedure developed by Mallat at application of the filters related to the original analyzing filters by the mirror and quadrature relations ( Mallat, 1989 ).

In this way, we can reconstruct the original time series x ( n )in a simple way by summing them up together ( Misiti et al., 2009 ) x  X  n  X  X  D 1  X  n  X  X  D 2  X  n  X  X  X  D J  X  n  X  X  A J  X  n  X  X  4  X 
Fig. 7 presents the results of the exemplary 5-level wavelet decomposition of the real data of PM 10 concentrations of one year (the upper curve) obtained by applying Daubechies Db4 wavelets implemented on Matlab platform ( Daubechies, 1988 ; Misiti et al., 2009 ). We have chosen Db4 after series of introductory experi-ments using different wavelet functions and selecting this one providing the smallest variability of signals at the particular levels.
All signals, from the first ( D 1 ) to the fifth ( D 5 ) levels and the coarse approximation A 5 on the fifth level are illustrated in the original resolution (the same as signal x ( n )). Observe that the detailed coefficients take either positive or negative values, so their physical interpretation, if we take into account always positive pollution level, has no sense. However, their sum with the coarse approximation A 5 represents the real pollution value.
Analyzing the signals at different levels, we can see the significant difference of variability. The higher is the wavelet level, the lower is variation of its coefficients, and easier is the prediction of them.
Our main idea is to substitute the prediction task of the original time series of high variability by predicting its lower variability wavelet coefficients on different levels. The final forecast of the pollution at any time point n is then obtained by applying the Eq. (4). Since most of the wavelet coefficients are of lower variability, we expect the increase of the total prediction accuracy of the time series.

The additional problem is to take decision what the optimal value of J is. At higher J the variability of larger number of predicted signals is lower, so their prediction is easier and the expected accuracy higher. However, if the number of predicted terms is too large the total error associated with the increased number of terms begins to dominate and as a result the total accuracy of prediction deteriorates. In our solution, we have determined the value of J on the basis of standard deviation of the approximated signal A J . The decomposition is stopped on the level for which the standard deviation of the approximated signal is substantially smaller than that of the original signal. This condition was expressed in the empirical form ( Osowski and
Garanty, 2007 ) std  X  A
 X  std  X  x  X 
For the data distribution presented in Fig. 7 the value of J  X  5 relation (6).

The prediction of the detailed coefficients D i and the residual signal A J needs to train as many predictors as is the number of predicted detailed signals plus one of the residual signal (at five level decomposition there is a need to train six predictors). Any kind of predictors may be used at this step. In our approach, we used 5 predictors (4 of neural type and one linear ARX). The input signal structure for the predictor is identical to that of general scheme of Fig. 6 with the exception that the past history refers now to the predicted variable and not to the whole signal x ( n ). The training of each predictor is done with similar accuracy. This prevents us against deterioration of final forecasting results following from the improper performance predictor responsible for any sub-band estimation.

In converting the original time series to the wavelet repre-sentation we have applied the strategy of using the data of the whole year. Thanks to this we are able to pick up the most important tendencies of pollution corresponding to all seasons of the year. When treating separately, one particular day, we attach its data to the previous 364 days, forming in this way the whole year data vector. Thanks to this we avoid the edge effect.
We are aware that application of the additional step of wavelet transformation makes the prediction procedure more complex and time consuming. However, application of Mallat algorithm is very efficient (comparable to FFT in Fourier transformation) and in the case of time series containing 365 items is done in practically one second on PC. On the other side training few predictors (instead of one in classical approach) needs some additional time only in the learning phase. The everyday use of the already trained predicting system needs only analysis of the actual input data at fixed parameters of the system and is done in practically no time. 5. The ensemble of predictors
Application of many predictors generates many prediction results concerning the pollution level of the next day. Our idea is to combine them together into one final forecasting system by integrating them in an optimal way. Observe that each predictor generates the time series which is independent from each other. All of them are burdened by some errors, which are also independent from each other. Combining all individual results together allows to compensate some errors and in this way to reduce its average level.

The simplest, although not optimal approach to the integration is averaging the outcomes of all applied predictors. Good results of integration might be also obtained by applying blind source separation approach, arranged in the way presented in ( Osowski et al., 2009 ). In this paper, we propose the nonlinear mixing of the results of individual predictions by the neural type networks of the most effective types: the SVR and MLP. These networks are known as very robust universal approximators, able to represent the complex input X  X utput relations. Proper training of them provides good accuracy of any approximation problem.

The results of the individual predictors are used as the input signals to the final integrating unit (MLP or SVR network). The number of input signals for the integrating unit is equal to the number of applied predictors. Training of the final stage predictor uses real pollutions corresponding to the days used as the destination values in learning.

Fig. 8 presents the most general final structure of the forecast-ing system applied in our solution, in which ^ P  X  d  X  represents the predicted value of PM 10 for the next d th day. It contains 8 indivi-dual predictors based on MLP, SVR, RBF and Elman networks generating directly the whole pollution value for the day, and also in composition with the wavelet transformation, where the pre-diction task is focused on the wavelet coefficients. Additionally, we have applied well known linear ARX predictor ( Swami et al., 1993 ). The upper five predictors in the figure forecast the whole pollution for the next day and the next five are combined with the wavelet decomposition (inside of them there is the set of 6 pre-dictors used for predicting the wavelet coefficients D i ( i  X  1,2,3,4,5) and the approximation A 5 on fifth level). The wavelet transforma-tion is made for the data of the whole year.

In general, the final neural type integrator is excited by 10 streams of data representing 10 individual solutions. It undergoes the regular learning procedure. The training of it is done after adapting the individual predictors and fixing their parameters. Its learning data are generated by all individual predictors (the input vector composed of their predicted results) and by known values of pollution corresponding to them (the destination).

After learning its parameters are fixed and the system is ready for the use in an on-line operation, when only the input vector x is known. 6. The results of numerical experiments
The numerical experiments have been performed in two phases. In the first phase of experiments, we have used the meteorological data of the three years (2006, 2007 and 2008), measured in the suburb Ursynow of Warsaw (1098 data samples together) and in the second phase we have made on-line predic-tion for the actual data obtained sequently from day to day (the results of these predictions have been used every day by the
Institute of Nuclear Study, responsible for controlling the pollu-tion in the region).

In the first part of experiments, th eavailabledatahavebeenpre-processed and normalized according to the presented procedure prior totheneuraltypemodeldevelopmentphase.Thenwehavesplit them randomly into two sets: 871 points have been used in learning and remaining 227 points left for testing of the trained system. To enhance the independence of predictors we have learned them on partially different data samples. For each predictor in the learning phase we have drawn randomly 500 samples out of 871. To get the most objective results, we have repeated the experiments of learning and testing 10 times at randomly chosen composition of learning and testing data (the crossvalidation). The mean values and standard deviation of the results have been calculated and compared to the real PM 10 concentration of the appropriate days. In all experiments of learning the number of hidden neurons in MLP, RBF and EN networks as well as the hyperparameters of SVR remained the same. They have been adjusted using some validation data extracted from the learning set (10% of learning data). Many different networks have been used in the introductory learning process and their optimal settings of parameters are those for which the classification error on the validation data set was the smallest one.

In the case of direct approach only one predictor of each type is needed. In the case of mixed approach (predictor  X  wavelet preprocessing), we have applied the Daubechies wavelets Db4.
This type of wavelet was selected after some introductory experiments. The wavelet decomposition has been carried out up to the fifth level. It means that 6 predictors should be trained: five for detailed coefficients D i ( n )( i  X  1, 2, y , 5) and one for the residual signal A 5 ( n ). Their results in the form of sum (Eq. (4)) create the forecast for the whole pollution of the day.
In this way, the general scheme of solution uses 8 different neural type predictors cooperating in the ensemble. Additionally, we have added the linear ARX predictor cooperating with the other predicting networks in ensemble. Their outcomes have been inte-grated together using the final neural type predictor in the form of either SVR or MLP. This integrator is responsible for the final forecast of PM 10 pollution for the next day (see Fig. 8 ). To assess the obtained results in a most objective way, we have applied different measures of prediction quality. Five measures have been used The mean absolute error (MAE) MAE  X  1 p The mean absolute percentage error (MAPE) MAPE  X  1 p The root mean squared error (RMSE)
RMSE  X 
The correlation coefficient ( R ) of the observed and predicted data R  X  R yt std  X  y  X  std  X  t  X   X  9  X  The index of agreement (IA) IA  X  1 where p is the number of data points, y i  X  ^ P i is the predicted value, t i  X  the really observed value, t is the average of really observed data, R yt is the covariance value between the really observed and predicted data points of PM 10 concentration and std. denotes standard deviation of the appropriate variable.
To get the most objective assessment of the proposed predic-tion system, we have applied 10-fold cross validation. This means repeating 10 times the sessions of learning and testing the system using the learning and testing data organized in different ways. In each session, we have generated randomly the set of learning (500 out of available 871 samples) and testing (227 samples) data. The final results of learning and testing are the mean of all trials.
In presentation of the results, we limit ourselves only to the testing data, not taking part in learning, since these data represent the future operation of the system in the most objective way.
Before performing the essential experiments with the non-linear models represented by the neural type networks we have tried first the linear model of prognosis using ARX, implemented in Matlab ( Swami et al., 1993 ). Irrespective of the fact that the process was found to be weakly nonlinear, we have got the results comparable (although worse) to the direct application of non-linear predictors (see Table 6 ). The ARX adaptation procedure has shown that the best results have been obtained at the rank of denominator N a  X  4 and numerator N b  X  1 of the ARX model.
In experiments concerning the nonlinear models of prediction, we have used the same structures for predicting the whole pollution and the wavelet coefficients. The developed nonlinear network structures were as follows: 8-8-1 of MLP, 8-40-1 of RBF and 8-5-1 of EN. They have been found after a series of additional introductory trials. The number of Gaussian kernels of SVR net-work was automatically adjusted by the learning procedures ( Sch  X  olkopf and Smola, 2002 ), and in each experiments was different, changing from 18 to 47.

Table 6 presents the statistics of prediction results of 10 individual predictors (8 nonlinear predictors and two linear ARX models) on the testing data. They represent the mean values obtained in 10 repetitions of experiments at random choice of learning and testing sets. The entries of the table represent the mean values and standard deviations (after the sign 7 ) for all measures of quality of the testing data. The columns of RBF, SVR, EN, MLP and ARX represent the direct approach to the prediction.
The other five columns represent the results of application of the wavelet transformation ( W ) in combination with the appropriate type of predictor.

It is seen that application of wavelet preprocessing is an extremely important in obtaining good results of prediction (more than 50% improvement rate in comparison to the standard application of predictors). The presented numerical values show that the best results have been obtained at application of SVR in combination with wavelet decomposition (SVR  X  W ). Very high relative differences between different type predictors by applying (or not) the wavelet preprocessing means that the combination of all individual predictors in the ensemble may not necessarily lead to the optimal solution, since the worst predictors may substan-tially deteriorate the performance of the whole ensemble. Hence, we have tried both approaches., combining together firstly all 10 and then only 4 best predictors applying the wavelet preprocessing of data (we have excluded ARX  X  W model since it was least efficient).

From the point of view of analysis quite interesting is also the correlation of the individual solutions presented by individual predictors. We have investigated these dependencies by calculat-ing the correlation coefficients between them. Table 7 presents the values of the correlation coefficients between the prediction errors corresponding to different solutions.

The results suggest, that in general there is relatively weak correlation between the individual predictors, especially for wavelet based preprocessing and neural type predictors. The least correlation is seen between the linear (ARX) and nonlinear predictions, especially these applying the wavelet preprocessing. Therefore, combining all results together in the ensemble we may expect the improvement of the prediction results.

Because of significant differences among the direct and wave-let approaches to the prediction, in further investigations we have performed two forms of integration. In the first one, we combined the results of all 10 predictors and in the second  X  only the best 4 neural type predictors that have applied wavelet preprocessing of the data. As the integration tool we have applied both SVR and MLP networks just for comparison. It means that crude forecasted values generated by the individual predictors were directly input to SVR or MLP, working in integration mode of the system.
Table 8 presents the results of integration of all 10 predictors combined in the ensemble. The results are represented by the mean values and standard deviation of 10 cross validation experiments. They are depicted at application of SVR and MLP as the final integrating unit. Worse measures of quality corre-spond to the application of MLP, for which the results are inferior to the best individual predictor (SVR  X  W ). At the same time, we see that SVR integration generates results which are better than the best individual predictor (SVR  X  W ).

In the next experiments, we have excluded all direct approaches as less efficient and integrated only the best 4 wavelet based neural type predictors. The statistical measures character-izing the prediction accuracy in this case are presented in Table 9 . The results depicted here are only slightly better than in the case of all 10 predictors and better than the best individual predictor. However, we observe also the significant simplification of the forecasting system (four individual predictors instead of eight).
However, we may note, that ensemble of predictors has only slightly improved the results with respect to the best individual wavelet-based predictor (SVR  X  W ). This is the result of relatively high correlations of these predictors (see Table 7 ). Since the differences between the errors of prediction of the best individual predictor (SVR  X  W ) and the ensemble of 4 predictors are low we have performed additional statistical t -test, verifying the null hypothesis that errors corresponding to these two techniques come from distributions of equal means (the null hypothesis). The t-test of Matlab has rejected the null hypotheses of equal mean values of the errors. Comparing the ensemble approach with the best individual predictor, the t -test has rejected the null hypoth-esis at the significance level p  X  0.0564. This value (only slightly above the normally assumed threshold of 0.05) confirms close similarity of both approaches, although not equality.

To find the distribution of prediction errors, we have prepared the histogram of errors for the testing data in one run of experiments. This histogram is presented on Fig. 9 . The horizontal axis represents the error values and vertical one  X  the number of their appearances. These results correspond to the application of
SVR as the final predictor in the ensemble. Observe that most of errors are concentrated between the values of 10 and 12 m g/m
There are only few errors of significantly higher values. Five of them exceed the value of 7 15 m g/m 3 . They correspond probably to the not typical (unexpected) events that were not similar to any data points from the past.

Fig. 10 illustrates the results of forecasting the testing data in a graphical way. The upper figure corresponds to all 227 testing days used in one run of the experiment, and the bottom one to the error of prediction. Note that these testing points have been chosen randomly from the data set. As we can see the predicted values quite well follow the changes of pollution within the considered days.

In this phase of experiments, we have created also the confusion matrix showing over-and under-prediction against the regulatory threshold, equal 50 m g/m 3 . Fig. 11 presents the results for the days, for which such mistakes have been made. The horizontal axis represents the particular days (from 1 to 227) for which the over-or under-prediction has been made. The bar of positive value represents under-prediction and negative  X  the over-prediction. In the analyzed period, there were 39 excee-dances over the allowed level of pollution. The prediction system has made 8 under-predictions and 5 over-predictions.

The additional experiments have been done at different arrangement of the data. Two years (2006 and 2007) have been used for learning and the third one (2008) for testing only. The statistical results of testing the whole system by applying SVR as an integrator are presented in Table 10 . They depict the quality measures for only third year not taking part in learning.
In the analyzed period of the year 2008, there were 58 exceedances over the allowed level of pollution. The prediction system has made 17 under-predictions. Besides this there were 28 overpredictions.

In the second phase of research, we have learned our pre-dictive system using all data of 3 years, fixed all parameters, and used it in the on-line operation for the prediction of PM pollution from day to day. We used the actually available data in an on-line mode. Each time we decomposed the whole year data (365 day) by taking 364 previous days and adding the actual day at the end of series. In this way, we have made the wavelet transformation using the same amount of data corresponding to 365 days. These wavelet preprocessed data have been used to generate the input variables for the individual predicting net-works in the developed ensemble models used for prediction of the wavelet coefficients ( D 1  X  D 5 ) and approximation ( A
The quality of results was comparable (although slightly worse) to those presented in the first phase of experiments. The differences may follow from the fact, that this time we have used the forecasted values of the exogenous variables (temperature, wind and humidity) instead of true values available in the first phase of experiments.

We have compared the results of ensemble with the best classical predictor (SVR) and the best single SVR  X  W predictor in the same on-line mode of operation. Once again they were similar to the results of experiments made off-line. Table 11 shows the comparison of the statistical measures of quality in the on-line experiments corresponding to the last two years.

The results presented in Table 11 confirm the significant advantage of application of the wavelet transformation in the preprocessing of data. The results also show that the ensemble of predictors is able to improve the accuracy of forecast, although this improvement is not very significant.

Note that at this stage of processing the model of prediction (all classifiers involved in the ensemble system) is already fixed. Although we use the historic data which had taken part in learning, they are used only to prepare the input data for the already adapted model. When we advance in the year the influence of the historic (partly learning) data is less and less and after 365 days they disappears. However, to check the influence of the historic data on the prediction results we have made additional experiments, using the data of two years (2006 and 2007) for learning, skipping one year (2008) and using the data of the year 2009 and 2010 for testing only. In this way, we avoid the historic data (used partially in learning) in preparation of the input data in the testing stage. The statistical results concerning the testing data of this experiments are presented in Table 12 .
 As we see the results are comparable to that presented in Table 11 . They confirm our statement that the model based on wavelet transformation acts well also in the case when the data used in testing do not overlap the learning set. 7. Conclusion The paper has proposed the novel forecasting system of the PM 10 concentration in the air. It is based on the application of the wavelet transformation and few predictors combined in the ensemble. Instead of discarding the less fortunate predictors, we include them into the system, mining their most significant information and use it in the final forecasting procedure.
The significant point of this approach is the decomposition of the data into the wavelet coefficients and using the individual prediction of the time series corresponding to wavelets at different levels. Application of this technique has decomposed the prediction problem into few easier and simpler tasks allowing in this way to increase the accuracy of the final forecast.
The another novelty of the proposed approach is the 2-stage prediction with application of the additional neural type network for integration of the ensemble. It was found that application of this two stage prediction approach leads to the improvement of the accuracy of pollution forecast.

The important advantage of the proposed approach is that it does not require very exhaustive information about air pollutant, reaction mechanisms, meteorological pollutant sources and that they have the ability of allowing the nonlinear relationships between very different predictor variables. These facts and good quality of the results make them attractive in predictive applica-tion of PM 10 concentration.
 Acknowledgment This research activity was financed by the Polish Ministry of
Science and Higher Education as a research project within the years 2010 X 2012.
 References
