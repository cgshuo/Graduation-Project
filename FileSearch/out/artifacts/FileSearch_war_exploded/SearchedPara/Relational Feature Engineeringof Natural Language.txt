 We present a new framework for feature engineering of nat-ural language processing that is based on a relational data model of text. It includes fast and flexible methods for im-plementing and extracting new features and thereby reduces the effort of creating an NLP system for a particular task.
In an instantiation and evaluation of the framework for the problem of coreference resolution in multiple languages, we were able to obtain competitive results in a short imple-mentation period. This demonstrates the potential power of our framework for feature engineering.
 I.2.7 [ ARTIFICIAL INTELLIGENCE ]: Natural Lan-guage Processing; H.2.8 [ Information Systems ]: DATA-BASE MANAGEMENT X  Database applications Design, Languages, Theory Natural Language Processing, Feature Engineering, Coref-erence Resolution, Relational Data Model
We present a new framework for feature engineering of natural language processing (NLP) that is based on repre-senting unstructured text in a relational data model. It in-cludes powerful and flexible methods for implementing and extracting new features and thereby reduces the time and effort needed for creating a natural language processing sys-tem.
 powerful. It supports a rapid development cycle in which a feature can be defined, tested and modified in a few minutes. This greatly reduces the effort of creating an NLP system for a particular task. (iii) Our framework also makes it easy for the developer to reduce the number of features in cases where this is de-sirable. Removing redundant features often improves clas-sification accuracy. Smaller feature sets also can be more robust and cut down classification times. If the latter is the main motivation for removing features, the developer can rapidly remove those features that have the smallest effect on classification accuracy. (iv) The framework X  X  modular architecture provides a clean separation between data storage, feature engineering and machine learning algorithms. As a result, it is easy to integrate any additional machine learning algorithm into the system. (v) Many algorithms from the knowledge discovery and data mining community are intended and implemented for relational databases. Since we are using a relational model for all our data, it is possible to use these methods for NLP with little design and implementation effort.

To demonstrate the utility of our framework in NLP fea-ture engineering, we have presented an instantiation and evaluation of the framework for the problem of CR in multi-ple languages [8]. A system (SUCRE) built with the frame-work achieved competitive results in a short implementa-tion period doing a full CR of named entities, pronouns, and full noun phrases on the data sets of the six languages from SemEval-2010 Task 1 Coreference Resolution in Mul-tiple Languages .

This paper is organized as follows. The data model is con-ceptualized in Section 2. Section 3 describes our approach to feature engineering. The Framework Architecture is in-troduced in Section 4. Sections 5 and 6 present related work and conclusions.
Relational data modeling is a well-known method for structured data and is supported by a wide range of soft-ware and many tools. The main purpose of the relational model in our framework is the use of a language like SQL [3] for feature definition. Using SQL, which is originally based on relational algebra (an offshoot of first-order logic), as the feature definition language is an easy to understand and flexible method for extracting different features from the relational data model of the text corpus.

The relational data model is the basis for defining the underlying structures of the text. To the extent that features in NLP are based on values of attributes of textual entities and on relations between entities, the relational database model is a natural formalism for supporting the definition and extraction of features. Converting a text corpus to its equivalent relational data model in a preprocessing step is simple and efficient as we will show below.

The main relation (table) 1 of the data model is built of tokens. This relation has one tuple (row) per token indexed from the beginning of the corpus. This tuple contains the to-ken itself and its attributes (e.g. part-of-speech and lemma). According to this main relation (which is enough to rebuild
We use the formal terms relation , tuple and attribute for table , row and column . UPDATE TrainSamplesFeatureVector SET Feature-Vector[1] = SELECT * from Token INNER JOIN Markable
ON Markable-ID = X AND (Token-ID == Head-Token-ID AND WHERE TrainSamplesFeatureVector.Sample-ID = Y
In the above SQL example, the token attribute 1 ( Token.Attribute-Vector[1] ) is part of speech and "NP" means proper noun.
SQL includes operators on relations that we use to define features, including arithmetic, concatenation, comparison, logical, set and user-defined operators. Each feature defini-tion is an attribute (column) of a relation (the feature vector table). In our setup, the feature extraction process consists of the calculation of features and their storage in the feature vector table.

The key capabilities of the relational model that we ex-ploit are (i) all all data is available in a uniform relational model and (ii) SQL operators provide a uniform and power-ful way of manipulating the data, in particular, for defining features. As a result, the developer can easily and quickly define features and thereby explore the feature space.
In addition to SQL operators, we can define our own func-tions such as the edit distance calculator or the feature bina-rizer. And in addition to features that are directly defined and computed on the relations, it is also possible to im-port externally generated features. For this purpose, it is enough to relate an externally generated feature value to its corresponding textual entity. This approach to feature en-gineering is suitable when a complex preprocessing pipeline provides complex features for the NLP task.

For example, a semantic similarity measure that is cal-culated by use of a search engine can be imported as an external feature and be combined with any other available feature in the system.

After its initial definition, the features are engineered with the goal of creating a feature set that will result in good per-formance. We view feature engineering as a process that consists of two parts: (1) Feature definition: which can be done by a feature definition language (SQL or pseudo-language) (2) Feature selection: we can consider two models of feature selection [9]: the filter model and the wrapper model . In the filter model, there is a set of features, and the final feature set is the subset that gives the best learning re-sult. In the wrapper approach, a method for semiautomatic exploration of the feature space is used for finding better features. Our method of feature engineering can be catego-rized as a wrapper model, where we are able to search the feature space by defining new features or combining them to find the best possible feature set according to the result of training and evaluation data sets.

Feature definition and selection in our setup is an iterative process that consists of the following steps. 1. Definition of new features (new definition from scratch 2. Evaluation of the features using the figure of merit (e.g. Table 1: Relational Data Model of Text Corpus for CR It means: feature 2 is set to 1 if the head words of the two markables exactly match and are nouns (a1 is part of speech in SUCRE); else 0.
Early work on the application of relational models to facil-itate text processing includes Crawford X  X  approach [4], where it was shown that SEQUEL (the first version of SQL) can be used for keyword search. Searching in relational textual databases and user-defined operators to manage text were discussed by Lynch [11]. Grossman introduced a database design for document retrieval within the relational model [5]. He also uses relational databases for keyword-based informa-tion retrieval [6]. We are not aware of other work that uses the relational model for fast, interactive feature engineering in NLP.
 The well-known WEKA [7] data mining software has a SQL viewer user interface that allows users to extract data from a database. But WEKA does not support the rapid iterative feature engineering that is the main purpose of our framework; for example, it does not offer an interac-tive mechanism to define features that can seamlessly access relational data. However, our framework could be easily in-tegrated into WEKA for feature definition and extraction for NLP tasks. An example of such an adaptation for geo-graphic data processing is proposed in [2] where an interop-erable module is presented that uses a Geographic Database Management System to model distance and topological spa-tial relationships.
We have presented a new framework for feature engineer-ing of NLP that is based on representing unstructured text in a relational database model. It includes powerful and flexible methods for implementing and extracting new fea-tures. It allows systematic and fast search of the space of features and thereby reduces the time and effort needed for
