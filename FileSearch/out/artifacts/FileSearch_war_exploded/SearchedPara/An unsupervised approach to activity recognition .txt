 1. Introduction
In recent years, human activity recognition, which aims to recognize the actions and goals of one or more agents from a many useful healthcare and context-aware applications. A typical healthcare application is monitoring activities of daily cation can be activity-based adaptation such as lowering TV volume when a user answers a phone call or providing instruc-tions when a user operates unfamiliar appliances.

Recognizing activities based on sensor readings is challenging because sensor data are inherently noisy and human activ-ities are usually performed in a non-deterministic fashion. In addition, we argue that we need to address more challenges since different individuals may perform the same activity in different ways. A key issue is to develop appropriate activity models that map low-level sensor features to high-level concepts. To obtain activity models, a straightforward method is to learn from a set of training data. Most existing approaches [2 X 11,22 X 29,31 X 33] leverage on supervised learning tech-niques to construct their activity models; however, learning from training data typically requires human labeling. Applica-in real-life deployment where scalability, applicability and adaptability are highly concerned.
 activity class from the web, and then mining contrast patterns among object terms based on emerging patterns [35] to con-trast any two activity classes. We then propose a fingerprint-based algorithm to recognize activities. We also propose two heuristic algorithms to segment an activity trace and detect the boundary of any two adjacent activities. We evaluate the effectiveness of our proposed techniques using a real-world dataset collected by seven subjects performing 17 activities involving 132 objects in a smart home environment. The experimental and comparison results show both efficiency and robustness of our proposed system.

Section 3. We then propose our activity recognition and segmentation algorithms in Section 4, and evaluate them in Section 5. Finally, we conclude the work in Section 6. 2. Related work on video cameras, and explore various tracking methods and spatio-temporal analysis to track moving objects and recognize people X  X  actions from video sequences.
 human, the environment and human X  X bject interaction. Most existing work focuses on applying supervised machine learning techniques to this task where manual labeling of training data is typically required. There are two major models for recognizing human activities from artificial intelligence: logic-based approach and probabilistic approach. Early ap-scription, and represented by a set of first-order statements called event hierarchy. However, logic-based approaches have limitations in distinguishing among consistent plans and have problems to handle uncertainty and noise in sensor data.
Probabilistic models gain more popularity as sensor readings are usually noisy and human activities are typically per-formed in a non-deterministic fashion. Probabilistic models can be generally categorized into static classification or tem-observations (i.e., sensor readings). We name a few examples here: hidden Markov models (HMMs) used in [9,10,13,14,30,31] , dynamic Bayesian networks (DBNs) used in [4] and conditional random fields (CRFs) used in [31 X  33]. Specifically, Bao et al. [2] proposed to use multiple accelerometers placed in multiple locations of the human body
Ward et al. [10] proposed to use microphones and 3-axis accelerometers to recognize continuous activities to assemble tasks in a  X  X  X ood workshop X . They applied linear discriminant analysis (LDA) on the sound segments and HMM on the acceleration data. Tapia et al. [3] proposed an activity recognition system based on a set of small and simple sensors.
The Na X ve Bayesian classifier was chosen to predict the activity labels. Philipose et al. [4] proposed to use RFID tags at-converted into DBNs to compute the probabilities of the activities. Lester et al. [29] used the multi-modal sensor board and applied both static classifier and HMM classifier to recognize activities. A variant of CRF (i.e., skip chain CRF [33]) and a variant of HMM (i.e., interleaved mixture of HMMs [37]) can be used to recognize interleaving activities, and an-models typically require labeled training data for an appropriate training process.

Recent work shows an interesting direction towards an unsupervised approach to activity recognition. Perkowitz et al. initions of activities from the web. They represented the activities as HMM-based on the object sequence used with proba-bilistic distributions. However, activity traces were manually segmented and input to their HMM models, and hand segmentation still requires involvement of human effort. In addition, it may cause the data belonging to the same activity activity models by mining the web in a wider scope. They presented a bootstrap method that can produce labeled segmen-tations automatically. Their model abstraction uses a large number of labeled web pages as the training set in which human efforts are involved. The segmentation in this work was based on the duration of an activity that may vary greatly from one user to another. Therefore, the accuracy may drop obviously when their activity models were applied to real-world scenar-segmentation process is sequential in nature such that any error in one segment may affect the segmentations of the sub-sequent traces. Pentney et al. [14] demonstrated the use of a large number of hand-entered common sense database to inter-pret activity traces. Wang et al. [30] combined a generative common sense model of activity with a discriminative model of formed. The approach is based on combining relational databases of large common sense created by the user with techniques discovering and matching the Motif which is defined as the subsequences with similar behavior appeared frequently in time-and presented a computational framework for unsupervised activity discovery and classification [24].

As we discussed, existing unsupervised approaches [12,13] mine both object and object sequence using web mining to ob-perform the same activity in several different ways. Under a real-world situation, it is difficult to obtain complete HMM-based models. Most likely, this has to be complemented by hand specification. Our work in this paper is motivated by the recent advancement of unsupervised approaches. We build a simply activity model based on object-use fingerprints. Compared to [12,13] , we only mine object terms from the web. Mining sequential data has been well studied in the data mining literature [38 X 41] . In this paper, we apply contrast pattern mining to sensor-based human activity recognition and mine contrast patterns (i.e., fingerprints) from object terms for each activity to maximize the discriminating power of fingerprints. Furthermore, our trace segmentation algorithms operate independently such that the segmentation process for one segment does not affect that for subsequent segments. This approach is in contrast to sequential segmentation com-monly employed in previous research where an error in a segmentation process affects the subsequent ones. 3. Mining object-use contrast patterns for fingerprints
This section describes our fingerprint-based activity models. The problem of activity recognition based on object-use can the web. We then mine a set of contrast patterns for each class which will be used as fingerprints for the subsequent rec-ognition process. 3.1. Mining object terms and relevance weights from the web each activity a 2 A , together with their associated weights W from the web. First, we obtain a set of object terms instructions for an activity on two websites: www.wikihow.com and www.ehow.com. Both websites provide comprehensive instructions for many day-to-day activities such as make tea , brush teeth and take pills .
 html documents is transformed into plain text and stemmed using Porter X  X  stemming algorithm [15]. In stemming, morpho-reduced to their stemmed or root forms. Secondly, the number of relevant object terms is further reduced by removing object from a server that stored the entire object IDs.

Next, we identify the relevance weight for each object term. Apparently, there are many object terms appearing in an the object in real usage, we determine the weight W of each object term t 2 a by computing its term frequency  X  inverse document frequency ( tf X  X df ) [20,21] , shown as follows: of documents in a ; j d a : t a i 2 d a j is the number of documents where the i th object term appears  X j t a i j  X  0  X  . score. The simple factor, log j D j j d : t words that occur in a limited number of documents (specific terms).
 a common basis of comparison among relative object term weights in different activities, we define our normalization tech-nique as follows: object terms in a .
 terms based on their weights do not have high variability due to the smoothing effect of the log transformation. Moreover, this transformation lessens the strong bias in weights of the topmost object terms.
 3.2. Mining contrast patterns from object terms object terms as fingerprints for each activity. However, in real-life, activities may share common objects. To maximize the The mining results will be used as fingerprints for activity recognition.
 The definition of our contrast pattern is motivated by the concept of emerging pattern which was first introduced in [35]. An emerging pattern is a set of items whose frequency changes significantly from one dataset to another; it describes sig-nificant changes (differences or trends) between two classes of data. Unlike an emerging pattern where each item has the While other forms of contrast pattern exist, e.g., minimal distinguishing subsequence patterns [42], we leverage the basis associated with a weight W C x . We denote the set of all items in D as T .
 Definition 1. The support of an itemset X , where X  X f x 1 ; x 2 ; ... ; x m g and X # T , is defined as Q :  X  a target class C 2 if GrowthRate  X  X  X  P q .

Definitions 2 and 3 are similar to the definitions in emerging patterns. Contrast patterns are those itemsets with large can be seen as a strong signal indicating the class of a test instance containing it.
 patterns to contrast its instances, D a i , against all other activity instances D 0 a
We develop an algorithm to discover contrast patterns based on an emerging patterns mining algorithm described in [20], which mines closed patterns and generators simultaneously under one depth-first search scheme. After computation, we get tea activity. Column 1 shows the CPs. For example, the CP {tea, teapot} has a support of 95% and a growth rate of 1 . 4. Activity recognition and segmentation algorithms
We can now apply fingerprints we obtained to recognize activities. 4.1. Recognizing activities using fingerprints sliding window (i.e., L a i  X  to obtain a test instance (i.e., S t t  X  L a averagelengthofalltheinstancesofactivity a i .Theactivityyieldingthehigherscorewinsoutanditsclasslabelwillbeassigned boundary.Thisalgorithmservesasafeedbackloopintherecognitionprocessaimingtolabelsequencesegmentsaccuratelyand overcome the drawback of a sliding window based our segmentation method. The score function is defined as follows.
Definition 4. Given a test instance S t t  X  L a where supp a ences between activity classes. In real-life, some activities may share similar objects, however, the weight of each object appeared in each activity will unlikely be the same. Hence, by mining contrast patterns, we are able to obtain different CP subsets with different supports and growth rates for each of these activities, and aggregate each CP subsets for classification.
 Algorithm 1. Fingerprint-based activity recognition algorithm 4.2. Activity trace segmentation length of each activity is an approximation of the actual length, the segmentation may not be accurate. Moreover, any error in one segment may affect the recognition of the subsequent trace. This error may accumulate and affect the recognition accuracy seriously. This problem is referred to as the activity boundary detection problem or trace segmen-tation problem.
 ferent activities.
 compute the difference of each consecutive RW pairs ( gap ), and the maximum gap is the boundary for these two activities. The output of the algorithm is the timestamp of an object where we should segment the two activities. The complexity of MaxGap is linear.
 Algorithm 2. The MaxGap algorithm
In cases where the two adjacent activities share common objects, boundary detection will be complicated if the common objects are located nearby the boundary. This is because their RW s will be close to zero. The MaxGap algorithm may fail to that of the MaxGap algorithm.
 Algorithm 3. The MaxGain algorithm 1: foreach  X  x ; y  X 2 a x ; a y do 2: for ctr = x to y do 3: RW ctr  X  W x  X  o ctr  X  W y  X  o ctr  X  ; 4: for ctr = x to y do 5: upperSum = 0; lowerSum = 0; 6: for upper = x to ctr do 7: upperSum  X  X  RW upper ; 8: for lower = ctr +1to y do 9: lowerSum  X  X  RW lower ; 10: GAIN ctr  X  upperSum lowerSum; 11: endfor 12: return the boundary such that GAIN ctr is maximum;
We walk-through the MaxGain algorithm using an example shown in Fig. 2 . The first column is a segment of objects ex-all RW s from x i  X  1 to tea . We then compute the Gain for each candidate boundary, where Gain is defined as: The result is shown in the last column. The timestamp of the object with the maximum Gain value is the boundary. In the example shown in Table 3 , the creamer object yields the maximum Gain of 5.28 which also indicates the location of the boundary in the ground truth.

Compared to MaxGap, MaxGain considers the interplay of the group of objects between two adjacent activities, while the former algorithm only makes use of the relationship between two adjacent objects. Intuitively, MaxGain tends to be more Sum )is O ( n ). 5. Experimental studies
We now move to evaluate our proposed algorithms. We develop a wearable RFID system as shown in Fig. 3 . The RFID wristband reader ( Fig. 3 b) incorporates a SkyeTek M1-mini RFID reader, a Crossbow Mica2Dot wireless sensor module, book in a smart home. We have three types of tags (Fig. 3a) and all operate on 13.56 MHz. In the case of metal objects, on a pre-defined table. The server runs on a Linux-based laptop PC with a programming interface board and a Mica2Dot wireless module connected through its serial port. The sever samples tag IDs at a frequency of 1 Hz and records them in a text file.
 unteers (one female and six males) and each volunteer wore an RFID wristband reader on each of her/his hands. We tagged used in other work [2 X 5,7 X 14] . Each day, each of them performed these activities in any order they like. Each subject was of tag IDs) was logged each day in a server. There was only one subject performing activities at any given time to reduce annotation efforts. One of the volunteers annotated the traces to establish the ground truth. All the traces collected were annotated by hand. 5.1. Comparison results not actually occur; and FN is ( false negative ) denotes the number of times that an activity that actually occurred is not detected.

We compare our fingerprint-based recognition algorithm with a supervised learning model  X  HMM, which is commonly iable at each time step. To test the HMM model, we use leave-one-out cross validation. We build a HMM model where activ-then we use the Viberbi algorithm to recover the hidden state sequence for testing.

The overall comparison result of the two models is shown in Table 5 and the detailed result is given in Fig. 3 . While the learned HMM model gets the highest precision, our algorithm achieves a comparable result in terms of precision and recall. recognition occurred when the subject touched another objects unintentionally while an activity is being performed or be-cause of the close proximity to nearby objects. The consequence in this case will cause the objects collected around the neighborhood of these objects to carry relatively high weights in another activity. Section 5.2 evaluates this case further and discusses our potential solution.

We now compare the performances of the MaxGap and MaxGain algorithms. The performance comparison is based on the two metrics, namely: (1) M ean A bsolute E rror from the true B oundary (MAEB) and (2) M ean P ercentage of the true B oun-daries detected (MPB). MAEB is a continuous value that measures how many objects away is the algorithm X  X  boundary from the true boundary. A good algorithm must have MAEB value near zero. MPB, on the other hand, is the ratio between the num-ber of true boundaries detected by the algorithm and the total number of boundaries. A good algorithm has MPB value near 100%. MAEB and MPB are summarized in as follows: where trB is the true boundary; algB is the algorithm X  X  boundary; N is the total number of boundaries; T is the number of
In the evaluation, we did not include detecting boundary in cases where two consecutive activities are of the same type since it is trivial to detect such boundaries.

Table 6 shows the comparison result. As expected, MaxGain outperforms MaxGap since MaxGain takes the consideration the above result, we observe two limitations. First, by analyzing the ground truth, many cases of false segmentation are caused by missed detection and false recognition in the activity recognition process as explained previously. However, the detection of each boundary is done in an independent way that the false segmentation for one boundary does not affect missed detection and false recognition during the segmentation process. 5.2. Robustness and scalability
This section evaluates and discusses our concerns in the previous sections. The trace collection in this paper was per-formed by a number of subjects in a smart home environment. These traces provided a variety of test cases in a close-to-real-life, noisy environment to validate and evaluate the effectiveness of the proposed algorithms. However, it was done robustness of both the activity recognition and segmentation algorithms, we conducted a number of simulation studies by manually adding additional noise to our traces. Noise was randomly selected from the entire tagged IDs. This simulation al-formed or because of the close proximity of nearby objects. We generated a set of traces by adding different percentages of noise randomly to each trace, and compared our fingerprint-based recognition algorithm with a HMM model. The compar-ison result is shown in Fig. 4 . As expected, both two models experience performance drop; however, both decrease linearly.
The precisions/recalls of our fingerprint-based algorithm and the HMM model decrease by 19.4%/18.8% and 48.5%/54.5%, respectively, when 40% of additional noise was added. The result also demonstrates the fingerprint-based recognition algo-rithm is more robust to sensor noise as compared to HMM since Fig. 4 shows that both the precision and recall of a HMM model decrease rapidly.
 of MaxGap and MaxGain decrease by 35.5% and 12.1%, respectively, when 40% of additional noise was added. MaxGain out-performs MaxGap since MaxGain decreases in a much lower gradient as compared to MaxGap. This is probably because Group RW resists random noise much better than RW .
 huge efforts on manual labeling. On the contrary, our fingerprint-based recognition algorithm is unsupervised, and we can mine a comprehensive, large number of activity models on the web without manual labeling. Hence, our solution can achieve better scalability than a HMM model. 6. Conclusion data mining techniques. We mine a set of object terms form the web for each activity, and mine a set of contrast patterns print-based algorithm to recognize activities. We also address the trace segmentation problem by proposing the two algo-rithms, MaxGap and MaxGain, based on the comparison of the relative weights of all objects sandwiched in the two adjacent activities. We conduct real-world trace collection in a smart home environment. The experimental results demonstrate both effectiveness and robustness of our algorithms.

Though RFID has been used in both research and commercially approved contexts, the long-term effects on humans re-quire thorough investigation and further research towards human-centric RFID [43]. For our future work, we will further develop our sensor platform to include more sensor features and seek a more nature data collection which should be con-and concurrent activities.
 References
