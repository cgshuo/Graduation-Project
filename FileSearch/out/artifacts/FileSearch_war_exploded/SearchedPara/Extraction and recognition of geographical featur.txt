 ORIGINAL PAPER Deeptendu Bikash Dhar  X  Bhabatosh Chanda Abstract With the emergence of Geographical Information Systems (GIS), map acquisition and recognition have be-come hotly pursued topics, both by the industry and the academia. The paper presents a novel methodology for the extraction and recognition of symbol features from to-pographic maps. The method proceeds by separating the map into its constituent layers and then attempting to rec-ognize the features in different layers on the basis of symbol-specific geometrical and morphological attributes. Text strings have also been separated. The output is obtained in the form of an  X  X -map X  that is vectorized and hence is suit-able for GIS. To demonstrate the usefulness of the proposed system a simple database along with a query processing facility is constructed integrating the information obtained from the e-map and  X  X ome X  user inputs. The methodology has been observed to perform quite satisfactorily.
 Keywords Cartography  X  GIS  X  Feature  X  Layer separation  X  Map recognition  X  E-map 1 Introduction Geographical maps have been in use since long for a variety of purposes. With computers invading every field in academics and industry, map processing is now no longer limited to paper-based maps. Efforts to automate the extraction of information from geographical maps using computers have led to the advent of Geographical Information System (GIS), which is a computer-assisted in-formation management system of geographically referenced data. The two central problems in GIS are map acquisition and map interpretation . Though quite a lot of research has been going on in the map automation process, most researchers have focussed on raster to vector conversion, and the success in map recognition has been limited. As such, the importance of a work in this direction cannot be overemphasized. By the term e-map , we mean an electronic version of a geographical map where entities are represented in such a fashion that the map can be reconstructed, updated and accessed much more easily using computer. Secondly, spatial and geographical information can be obtained as a result of query processing over this e-map.
 cartographic pattern recognition system using homogeneous parallel algorithms [ 4 ], an automatic map recognition sys-tem [ 5 ] and query-driven map recognition based on tem-plate matching [6]. Yamada et al. [ 7 ] focussed on extract-ing specific features such as points and lines based on a computationally intensive multi-angled parallelism method, whereas Samet and Soffer [8 X 10] reported a legend-driven map recognition system based on weighted bounded several nearest-neighbour classifier that is noise sensitive and re-quires separate map layers as inputs. Research has also been done on separating the layers of scanned maps by colours, as in [11, 12]. Efforts to separate text from graphics in an at-tempt to isolate and recognize lettering include the works in [13, 14], which are oriented more towards character separa-tion from engineering drawing than maps. Methods for char-acter string extraction specifically adapted to a cartographic context [15] use complex techniques of dynamic program-ming, graph theory and combinatorial exploration. In con-trast, the method outlined here is much simple and gives good results for the maps dealt with.
 symbol features (henceforth is termed as only  X  X eature X ) in topographical maps. The term feature differs from that used in pattern recognition, but refers to the unit of data by which a geographical entity is represented. The rest of the paper is organized as follows. Section 2 gives a brief overview of the work. Sections 3 and 4 describe the layer separation and feature extraction and recognition phases in detail. Database construction and query processing is discussed in Sect. 5 . Section 6 presents the results and discussion. Concluding re-marks are given in Sect. 7 .
 2 Brief overview For convenience, the entire work done is divided into four phases as follows. (1) Acquisition : Topographic Sheets prepared by Survey of (2) Layer separation : The map is separated into its con-(3) Recognition : This is the most important and time-(4) E-map generation : To make the results of recognition (5) Database construction and query processing :Integrat-Sects. 3 and 4 , respectively. Database construction and query processing is discussed in Sect. 5 . 3 Layer separation phase The most intuitive and natural approach to this problem is to use the R, G, B pixel values for classification. However, a direct clustering approach (e.g. K -means algorithm) is not suitable due to wide variations in colour intensity. For exam-ple, the green component of red pixel may be more than the green component of green pixel in the same map. Secondly, as the a priori probabilities of pixels in different layers are not comparable, the cluster corresponding to the dominant layer tends to encroach the other layers. Another problem is that the intensity values of black or white pixels have rarely the ideal values of (0, 0, 0) or (255, 255, 255) and such pixels tend to be wrongly classified. Because of the above difficul-ties, the strategy devised for layer separation first determines the initial cluster centres on the basis of an enhanced image, followed by the actual separation. The steps involved are de-scribed below.
 Step (a). Image enhancement The training image is en-hanced such that the R, G, B values of the pixels are either 0 or 255. The heuristic followed is as follows. Pixels with a small difference in their R, G, B values are set to either fully black (0, 0, 0) or fully white (255, 255, 255) depending upon the average intensity value. Otherwise the maximum of the three values is set to 255, and others to 0. So we have the following classes to represent layers: C 0 ={ 0 , 0 , C C respectively. If two values are equal and the maximum, both of them are set to 255. So we have three additional classes to represent layers: C 5 ={ 255 , 255 , 0 } , C 6 ={ 0 , 255 C tively. However, since in our present experiment, selected maps do not have any such colour layers, any pixel satisfy-ing one of these is mapped to one of C i ( i = 0 , 1 ,..., depending on the frequency of occurrences over its neigh-bourhood. This allows us to deal with only five classes lead-ing to four layers.
 in Fig. 1 a and the image after enhancement is shown in Fig. 1 b.
 Step (b). Clustering The K -means algorithm [ 1 ]isusedto generate K = 5 clusters, where each pixel of the original image is allocated to one of the five clusters such that the intra-class distance is minimum. The feature vector is se-lected to be the normalized original R, G, B values, along with the normalized intensity I ( X  I  X  was added as a compo-nent of the feature vector in order to differentiate between the black and white clusters, as their normalized { r i , values tended to be similar) as follows: r = R i b = B i The initial cluster centres are supplied as the average of the normalized components ( r j , g j , b j , I j )ofthepixelscorre-sponding to each of the C j  X  X  of the enhanced image, where r b where n j is the total number of points in class or group C of the enhanced image.
 Step (c). Final separation Once the final cluster centres are determined, the map image is separated into the desired lay-ers by a procedure similar to the nearest prototype classifi-cation algorithm. At the end of the algorithm, K = 5binary images are generated, such that the pixel value of the i th pixel in the j th image is 1 if the feature vector of the corre-sponding pixel { f i } has been assigned to cluster C j . training image are shown in Fig. 2 . 4 Feature extraction and recognition Even after separation of the map into its constituent layers, feature extraction and recognition remains sufficiently diffi-cult to attract a simple solution. The procedure of template matching does not work as different instances of the same symbol vary in scale and orientation. The high level of ob-struction of geographical symbols due to the map-making process causes the pixels in the intersections of two features to be put into one layer, thus making the symbols in the other layers discontinuous. For example, a bridge may cause a discontinuity in the river. Consequently, statistical pattern recognition with features invariant to scale and rotation as used in [8 X 10] does not work. To alleviate this problem, re-searchers have used images of separate map layers as inputs to their systems. However, such separate map layers are not available to us. The quality of the print and noise in the im-ages also add to the difficulty. Hence, the current approach focuses on  X  X iscovering X  simple spatial and geometrical at-tributes of the features by extensive experimentation and ob-servation. 4.1 Feature extraction in the green layer The features extracted and identified in the green layer in-clude trees, grasses and green fields or forests. The steps in-volved are as follows.
 Step (a). Noise removal In a binary image, if noise con-verts a black pixel to white pixel, it is considered as nega-tive noise. Such noise usually creates holes in a region and discontinuities in strokes. Negative noise is removed by mor-phological closing [ 1 ]. This also causes arms of grasses and shrubs to be fused, and vacant areas within green fields to be filled, such that they would be counted as single compo-nents. Positive noise (which converts a white pixel to black pixel) is removed by component counting [ 3 ] and then delet-ing components of small size. At the end of this step, the im-age becomes clean (Fig. 3 ) and suitable for applying recog-nition criteria.
 Step (b). Thinning or skeletonization A closer examination of Fig. 3 reveals that most of the trees have just one Y-shaped junction, whereas grasses and green fields have more of them. Thus, the number of such junctions could serve as a criterion for recognition of trees. Locating points, which have Rutovitz connectivity number equal to 3, can iden-tify such junctions. However, to correctly identify junction points by Connectivity number, the components must be thinned. The result is shown in Fig. 4 .
 Step (c). Feature extraction The genus or Euler number of each remaining component G ( C ) is computed [ 1 ]. Ideally, the Euler number of each tree should be zero as it has exactly one hole. However, because of the obstruction of geograph-ical symbols, many of the trees do not satisfy this criterion. So, some additional criterion is required to recognize trees. As said in the previous step Rutovitz connectivity number helps identifying trees. This is computed as the number of transitions from the object pixel to the background pixel if we travel along the 8-neighbourhood of a candidate pixel of a thinned component. Then for each component, the number of pixels n ( C ) for which this number is 3 is counted. Maxi-mum (MAX) of the number of object-to-background transi-tions along any row of a component is also determined. Step (d). Recognition Finally, identity of the components of the green layer is determined based on the following rules:  X  If G ( C ) = 1andMAX = 2, it is a tree.  X  If MAX = 2and n ( C )  X  2, it is a tree.  X  If 3  X  MAX  X  6, it is a grass.  X  If MAX &gt; 6, it is a green field or forest.
 nized map for the green layer of the training image is shown in Fig. 6 .  X  X  X  represents tree,  X  X  X  grass and  X  X  X  green field. 4.2 Feature extraction in the blue layer The features extracted and identified in the blue layer in-clude rivers (R) and tanks (K). Identifying rivers is difficult, since they are intersected by bridges and dams, and thus have large parts missing from the blue layer. The different com-ponents of a river are spatially so far apart that they cannot be joined algorithmically using any neighbourhood operator of reasonable size. Thus, human intervention seems the only way out. The steps involved are as follows.
 Step (a). Noise removal The user is expected to join the components in the input image, if needed. This is followed by a component labelling step that removes positive noise. Negative noise may be removed by median filtering [ 2 ]. Step (b). Recognition It is done based on the following de-cision criteria: suppose F i ( i = 0 , 1 , 2 , 3 ) denote the set of pixels of one of the extreme rows or columns of the image. Then B  X  F i =  X  indicates that an object B intersects a side of the image. Thus,  X  If B  X  F  X  If B  X  F  X  If B  X  F performed, is shown in Fig. 7 .
 4.3 Feature extraction in the red layer The features to be recognized in the red layer are huts (H, small rectangular blobs), metal roads (M, solid double par-allel lines), cart roads (C, solid single line), non-metal roads (U, dashed double parallel lines) and village/town/human habitation (V). These feature types are processed one at a time in the order mentioned above. The detailed steps are as follows.
 Step (a). Preprocessing The entire image is thinned, and the end points of the lines are identified and joined with their nearest end-point neighbour, provided that they are within a specified orientation and distance from each other [16, 17]. This joins many broken lines in which the breaks are a few pixels long. For lines with long breaks, an approach based on directional mathematical morphology [ 18 ]isused. The directions of all possible lines are first determined using Hough transform [ 1 ]. After the line joining, noise-cleaning operation is done through connected component analysis. Step (b). Isolation of hut Huts are separated using the shape features such as (i) aspect ratio , the ratio of the smaller to the larger dimension of the minimum bounding box, and (ii) vacant ratio , the ratio of the area of the component to that of the bounding box. The components with aspect ratio and vacant ratio greater than a particular threshold (0.5 in the present case) are recognized as huts.
 Step (c). Isolation of metal and cart roads The unique ge-ometric characteristic of roads is their high length-to-width ratio or low aspect ratio. However, for roads not aligned with the x or y directions, this statement may not be true. For such cases, the vacant ratio will be quite small. Thus the compo-nents with a low aspect ratio or a low vacant ratio (less than a threshold, chosen to be 0.15 here) are recognized as metal or cart roads.
 Step (d). Distinguishing metal roads from cart roads Once identified, metal and cart roads are drawn on a separate im-age and Hough Transform is applied to them. If in the Hough transform domain we find two maxima at the same angle and few cells away from each other, then it represents two lines having the same inclination but only a few pixels apart. Then these are parallel lines representing a metal road. Otherwise, the roads are cart roads. Correspondingly, the lines are la-belled as  X  X  X  or  X  X  X .
 Step (e). Detecting non-metal roads From the residual im-age, the components with area less than a specified thresh-old (chosen to be 50 here) are extracted to search for the possible presence of non-metal roads (dashed lines). Hough transform is again used on these components to determine the presence of a dashed parallel line, which represents non-metal roads. Hough transform may detect an isolated line from sporadic points, and such lines should be neglected. Step (f). Recognizing human habitations The image left after deleting the above features consists mainly of villages or towns, barring a few small-sized components. (These components may remain because of noise.) After these small-sized components are filtered out using connected component analysis, the minimum-bounding octagon is determined for the remaining components that represent the human habitation.
 above, whereas the final output of the recognition and e-map generation phase on the red layer of the training image is shown in Fig. 9 . 4.4 Feature extraction in the black layer In the black layer, text strings are to be extracted so that the names can be recognized by an OCR system and are entered into GIS. For this, the size criterion similar to that in [ 12 ]is used here to judge the components as characters. The spe-cific steps are detailed below.
 Step (a). Preprocessing Positive noise is removed by com-ponent labelling and removing small-sized components, whereas negative noise is removed by morphological clos-ing.
 Step (b). Text extraction using size criteria The size (dimen-sions of both sides of the bounding box) of the components is determined. A typical size histogram is expected to con-tain three peaks [ 18 ] when the map contains letters of single font size only (Fig. 10 a). The first peak is caused by numer-ous specks and isolated lines, while the other two represent the width and height, respectively.
 ferent sizes, the histogram is not exactly tri-modal, but of the shape as shown in Fig. 10 b. Characters are extracted by selecting components that lie within the range [ d , e ]. The peaks within the range correspond to the height or width of different font sizes. layer include wells and tube wells. Wells are represented as circles and tube wells as triangles. The steps involved in their recognition are as follows.
 Step (c). Recognition of wells The problem with recogni-tion of wells is the presence of several different features of similar shape. Such features include telegraph lines and district boundaries. However, these features generally oc-cur in a serial line and not in isolation. This fact is used in the recognition of wells. The operations performed are (i) applying morphological hit-and-miss transform with cir-cular structuring element of appropriate size and its eroded complement (this detects circles of the desired size), (ii) fol-lowed by thinning of the image (all components of circu-lar shape would be one or two pixels in area), (iii) Hough transform of one-or two-pixel thin components to deter-mine which of them fall in straight lines (these are not wells) and (iv) identifying one-or two-pixel area components that do not contribute to line formation in Hough transform as wells.
 Step (d). Recognition of tube wells Triangular features are easily distinguished in image by the monotonically increas-ing width of the projection in the direction orthogonal to the principal axis. The recognized e-map of the black layer is shown in Fig. 11 . 5 Database construction and query processing In order to make the information obtained from map recog-nition more useful, query-processing capability, similar to that in GIS, is added to the system. The following steps are involved.
 5.1 Database construction The scale of the map and the starting and ending latitudes and longitudes of the map are taken as user input. The objective is to locate any point on the map precisely giving its latitude and longitude instead of the pixel coordinates. This has the advantages that (i) it is global to all maps (pixel coordinates are local to individual maps and are dependent on image resolution), (ii) it supports query processing based on information from more than one map or parts of maps, and (iii) it enables the calculation of the actual distance between two points instead of the distance in pixels, thus being more meaningful while answering a query.
 layer are correlated with features detected in the other layers. This is done by matching the centre of gravities of minimal bounding box of a name in the black layer and the features in other layers. At the end of this step, the information is entered into a database in the following format: location, feature name, proper name ,where location isgivenbythe latitude and longitude of the centre of gravity of a feature, feature name is the feature recognized by the current sys-tem and proper name is the name that is found to be the OCR-retrieved name associated with the feature. Note that one field of the above triplet may remain empty.
 tures such as rivers and roads. For roads, the locations of the end points are stored instead of a single point. This is suffi-cient since roads are approximated by straight lines and re-constructed by Hough transform and hence their end points are known. The storage of river information is trickier since the above statement is not true for rivers. Hence, the follow-ing steps are performed: (i) Determination of the medial axis of the river by thinning (ii) The curve so obtained is approximated piecewise by river, Ganges ; ( x 3 , y 3 ), railway station, Dharampur ; ( x 5 , y 5 ), Behrampur .
 5.2 Query processing At present the following query functions are supported:  X  dist(source location/proper name, destination loca- X  list(source location/proper name, destination feature in the case of extended features for query processing too. For roads, since the end points are known, finding the distance from a point location involves calculating the perpendicular distance from the point to the straight line. For rivers that are approximated by multiple straight lines, determining the distance from a compact feature involves determining which line segment is closest (i.e. which consecutive end points are closest) to the point location, and then calculating the per-pendicular distance from that line segment to the point. For the list query, the location output by the system corresponds to this  X  X losest point X  on the extended feature to the compact feature.
 6 Results and discussion 6.1 Results from the training image The training image was taken from the Survey Map 53H/6 showing parts of Delhi, Ghaziabad (UP) and Faridabad (Haryana) prepared by the Survey of India. The map was scanned at 300 dpi, giving a 2 , 024  X  2 , 035 pixel image. From this map, the training image of size 400  X  380 pixels was chosen. The final e-map for this image (after combin-ing the outputs of the different layers) is shown in Fig. 12 . The facility used for this purpose was a Silicon Graphics machine with IRIX 5.6 as the operating system.
 the said map is manually ground-truthed. A comparison of the number of features in the actual map and that in the e-map is given in Table 1. The result of this count shows a high recognition rate of 90%. However, it should be noted that the system is tested only on a handful of images obtained by scanning SOI maps of the Indian Northern Plain region. So no general conclusion can be drawn immediately. In spite of this fact, it should be mentioned that results obtained by such low-cost features and simple rules are encouraging and suggest further exploration in this direction. Most of the fail-ures are resulted from the fact that recognition of all symbols was not attempted, and hence such features were interpreted wrongly. 6.2 Count of errors Three types of errors [ 13 ] are common in pattern recogni-tion, optical character recognition (OCR) and document im-age analysis, and serve as an objective measure for the eval-uation of the adopted methodology adopted. These are as follows. (i) Substitution errors  X  X  valid label is assigned incorrectly (ii) Deletion errors  X  X  valid symbol is classified as un-(iii) Insertion errors  X  X n invalid symbol is classified as one sults are obtained on the training image: 1 substitution er-rors (one tree was wrongly identified as grass), 1 deletion errors (one tree could not be recognized) and 2 insertion errors (two components which are actually parts of a dam were recognized as huts). This count does not include the er-rors of counting four trees and three grasses for components that are actually part of the green field but recognized sepa-rately because they remained as separate components in the image. 6.3 Results for other test images The map recognition procedure is performed on many other test images, all drawn from the same map as is the training image. The results of three of them are shown in Figs. 13  X  15 . The count of errors for these images too is small, and is displayed in Table 2. In all the three cases, recognition rates in excess of 90% have been recorded. Secondly, the results do not differ up to addition of 10% Gaussian noise. The low count of errors and the robustness to noise show the methodology followed in particularly good light. 6.4 Query processing results The results of query processing are sufficiently accurate for queries involving  X  X ompact X  features such as trees and tanks, and mixed for features such as rivers, roads and railway lines. This is understandable since the  X  X entre of gravity X  of these features often does not make a true representation of location of the feature.
 are as follows: chained hash table. Each bucket of the hash table is indexed by a separate feature. Chains for each feature contain the ac-tual entries sorted on the location (latitude first). While this is a sufficiently simple data structure providing quick inser-tion and also quick search for queries containing a feature name, it is not always the best data structure for all types of queries in terms of search time. However, it is adequate for the purpose of demonstration of our query-processing abil-ity and a better performing data structure and/or algorithm may be added at any point of time. 7Conclusion In this paper we have presented initial steps of development of a prototype system for automatic recognition of map symbols from the standard paper maps for generating e-map. The system puts together mostly well-known methods and makes them work in particular order to achieve the said goal almost without any user intervention. So the novelty of the work lies in selection and engineering of the appropriate tools. The proposed heuristics are seen to be robust and per-form well in the presence of noise. Obviously, the success of the system relies on the success of each tool at various steps. For example, success of layer separation depends on the ability of the clustering algorithm. There are a good number of clustering algorithms available in the literature, and we have used one of the simples ones, namely K -means. With its known limitations (e.g. it detects isotropic clusters around its centre), it can do its job satisfactorily given pre-computed seed points. This is because colours used in maps are supposed to be uniform (i.e. without any shading) except noise due to paper and print quality and also due to digitization. Secondly, in road extraction stage, selection of structuring element for directional morphological operation, ample care should be given. Though some default values are incorporated in the system for this as well as some other parameters, sometimes user intervention is needed to produce more fruitful results. An AI-based technique for the selection of such values seems to be helpful and we are searching for a suitable one.
 have been very encouraging, and efforts are on to serve more complicated and useful queries. For example, the distance between a linear feature, e.g., a road or a railway track, and a compact feature may be more useful than the Euclidean distance between two locations in many cases. Again, more work needs to be done in tackling problems while building a composite database from more than one map, since the same object, for example a river or a road, might be present in more than a map.
 References
