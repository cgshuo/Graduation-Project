 Recent years have observed a significant progress in infor-mation retrieval and natural language processing with deep learning technologies being successfully applied into almost all of their major tasks. The key to the success of deep learn-ing is its capability of accurately learning distributed rep-resentations (vector representations or structured arrange-ment of them) of natural language expressions such as sen-tences, and effectively utilizing the representations in the tasks. This tutorial aims at summarizing and introducing the results of recent research on deep learning for informa-tion retrieval, in order to stimulate and foster more signif-icant research and development work on the topic in the future.

The tutorial mainly consists of three parts. In the first part, we introduce the fundamental techniques of deep learn-ing for natural language processing and information retrieval, such as word embedding, recurrent neural networks, and convolutional neural networks. In the second part, we ex-plain how deep learning, particularly representation learn-ing techniques, can be utilized in fundamental NLP and IR problems, including matching, translation, classification, and structured prediction. In the third part, we describe how deep learning can be used in specific application tasks in details. The tasks are search, question answering (from either documents, database, or knowledge base), and image retrieval.
 Deep Learning, Information Retrieval, Search, Question An-swering, Image Retrieval  X  X nformation retrieval (IR) is the activity of obtaining in-formation resources relevant to an information need from a collection of information resources X  -Wikipedia. Figure 1 gives an overview of the major tasks in IR, including search, question answering (from either documents, database, or Figure 2: Hard problems in information retrieval and natural language processing. cult or even impossible to perform direct matching between the intent and content in the tasks. Although some methods had been proposed for question answering, image retrieval, etc, they tended to be ad-hoc, and their performances were not satisfactory. Recently, significant progresses have been made in solving the hard problems in IR, with deep learning as the major machinery.

Deep learning is powerful, because it can help automati-cally learn representations of different data in different tasks [18]. The learned representations are all in the same form, namely real valued vectors, also referred to as distributed represen-tations. In this way, the matching in IR can be conducted through the vector representations, and therefore the perfor-mance of some IR tasks can be significantly enhanced and the other tasks which were previously considered impossible can be successfully carried out.

For example, it is found possible to directly learn repre-sentations from images and their associated texts, exploit the representations in matching between questions and im-ages, and achieve high accuracy in image retrieval (e.g., [15, 14, 17, 24, 36, 23]). Deep learning can also be employed to carry out question answering from database or knowledge base. Recent work shows that given only question answer pairs, a relational database or knowledge base, as well as the  X  X rounding X  relations between the answers and the database or knowledge base, one can learn a deep neural network to automatically conduct question answering from the database or knowledge base. No human effort is needed in construc-tion of a semantic parser for analyzing the questions and the performance can be even higher (e.g., [4, 28, 38, 41, 1, 43, 42]). It is also found that deep learning can improve tra-ditional question answering from documents, which can be formalized as a problem of matching between two sentences (question and answer) each having a complicated syntactic and semantic structure. The advantage of the approach is that usually one does not need to use linguistic knowledge to build the system (e.g., [32, 22, 10, 37]). Another new and interesting finding is that with deep learning and a large amount of question answer pair data one can build a system which automatically generates an answer given a question in question answering, or in general in single turn dialogue (e.g.,[30, 35]). This was considered as a very hard problem.
The tutorial consists of four parts. We introduce the con-tent of each part.
We start with introducing the basic tools in deep learning for information retrieval and natural language processing, including word embedding [25, 27, 19, 20], recurrent neu-ral network (RNN) [26, 9, 6], convolutional neural network (CNN) [7, 10, 13, 31], as well as training of deep neural network models.
We formalize many tasks in IR and NLP into a number of fundamental problems including matching, translation, classification, and structured prediction, described below.
We first point out when we apply deep learning to the problems, we in fact learn representations of natural lan-guage in the problems. The learned representations can be used in realizing the tasks, with often enhanced perfor-mance. We explain methods that can be used for learning the representations in matching [22, 10, 37], translation [33, 6, 2, 8], classification [13, 16, 44], and structured prediction [7, 34, 5].
We introduce the recent work on applications of deep learning to IR tasks. First, we describe deep learning models which have been successfully applied to search to enhance relevance [11, 31, 29], as extensions of conventional linear models [3, 40, 39].

We also talk about deep learning for question answering including the retrieval-based setting in which answers are retrieved and returned from a large repository of question answer pairs [32, 22, 10, 12, 37], as well as the generation-based setting in which answers are automatically generated from a system which is trained with a large number of ques-tion answer pairs [30, 35].

We explain the work about question answering from database or knowledge base using deep learning in which only ques-tion answer pairs and the database or knowledge base are used in construction of the system [4, 28, 38, 41, 1, 43, 42]
We introduce the recent progress in image retrieval using deep learning in which only images and their associated texts (questions) are used as training data [15, 14, 17, 36, 24, 23]. [16] Y. Kim. Convolutional neural networks for sentence [17] R. Kiros, R. Salakhutdinov, and R. S. Zemel. Unifying [18] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. [19] O. Levy and Y. Goldberg. Neural word embedding as [20] O. Levy, Y. Goldberg, and I. Dagan. Improving [21] H. Li and J. Xu. Semantic matching in search. [22] Z. Lu and H. Li. A deep architecture for matching [23] L. Ma, Z. Lu, L. Shang, and H. Li. Multimodal [24] J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille. [25] T. Mikolov, K. Chen, G. Corrado, and J. Dean. [26] T. Mikolov, M. Karafi  X at, L. Burget, J. Cernock`y, and [27] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and [28] A. Neelakantan, Q. V. Le, and I. Sutskever. Neural [29] A. Severyn and A. Moschitti. Learning to rank short [30] L. Shang, Z. Lu, and H. Li. Neural responding
