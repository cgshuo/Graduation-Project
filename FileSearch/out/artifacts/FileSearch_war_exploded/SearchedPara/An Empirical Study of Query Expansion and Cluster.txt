 Recently, language modeling approach has become a popular IR model based on its [12], [14], [15], [16], [17], [19], [20], [21]. In contrast to the probabilistic model [18], the language modeling does not explicitly infer the relevance information, estimating individual document models that use unique probability distribution of words. The main difference between the language modeling and the probabilistic model is what relevance measure of documents is. In the language modeling, relevance of document is calculated by query likelihood generated from document language models. On the query, estimates na X ve Bayesian relevance probabilistic model, and ranks documents by posterior probability of the model, called the probability ranking principle. 
From the perspective of information retrieval, the language modeling approach provides a very flexible framework which enables deal with complex relationship among terms. For example, adjacent two terms in a query has a dependency in bi-term language model [19], whereas a term in a query can have a syntactic dependency with any terms within query in dependency language model [2]. Language modeling ap-proach also can be incorporated with some advanced techniques to resolve word mismatch problem, such as query expansion and cluster-based retrieval. Lafferty and Zhai [9] introduced the concept of query model within language modeling approach, and regarded retrieval as ranking by KL divergence between query model and docu-ment language model. Cluster-based retrieval within language modeling approach was explored by two methods, interpolation [8] and cluster-based smoothing [12]. 
Until now, there was no empirical or theoretical comparison between query expan-sion and cluster-based retrieval in resolving word mismatch problem. It is meaningful induce optimal parameters in one method from those of another method. This paper various issues, and thus provides reasonabl e direction to develop theoretical argument following summarizes several issues of this paper. 1) What is the effect of using parsimony in query expansion? Parsimonious language models reduce the number of terms with non-zero probabili-ties by eliminating common terms in document [5]. It enables to decrease storage size in indexing database. Previous studies showed that parsimonious language models are term co-occurrence statistics requires large time complexity. However, retrieval per-proved that it drastically reduces time-and space-complexity. In this regard, this pa-per performs several kinds of experiments to investigate an effectiveness of parsi-mony in terms of retrieval performance. based retrieval? Query expansion and cluster-based retrieval have some differences when applying it in retrieval model. Consider another technique, document expansion which deter-document expansion do in document level. Cluster-based retrieval can be viewed as approximation of document expansion that similarities among documents is indirectly considered through clusters. Are these two approaches almost same? Or, is one ap-proach approximation of another one? To answer these theoretical questions is not parison of retrieval performances of two approaches in several collections. This result future. 3) What is the effect of clustering algorithm in cluster-based retrieval? Intuitively, cluster-based retrieval X  X  performance depends on clustering algorithms. ing algorithm? To draw potential answers for these questions, we compare two tradi-tional clustering approaches: Agglomerative clustering and partitional clustering . Agglomerative clustering fully utilizes structure of documents by explicitly using document-to-document similarities, while partitioning clustering has a limit to utilize the structure because document-to-document similarities are indirectly calculated via cluster. Comparison results provide conclusion for whether fully utilizing document structures is essential or not. 4) Is there a novel method to combine query expansion and cluster-based retrieval? In this paper, two methods are proposed to combine query expansion and cluster-based retrieval: a) Cluster-based Retrieval after Query Expansion (Q&amp;C) and b) Clus-cording to their cluster membership. Evaluation of combining methods will help clar-ify discussion for second question. For example, if combined method is effective, two approaches may play a different role fo r resolving word mismatch problem. modeling approach and methods for query expansion and cluster-based retrieval. In nally, a conclusion will be given in Section 4. 2.1 Kullback-Leiber Divergence Framework Basically, original language modeling approach ranks documents in collection with the query-likelihood that a given query q would be observed during repeated random sampling from each document model. To allow relevance feedback and query expan-sion, Lafferty and Zhai [9] proposed the Kullback-Leiber(KL) divergence framework by introducing a query language model, the probabilistic model for user X  X  information need. In the framework, the query likelihood of original language modeling approach is generalized to negative KL divergence between the query model and document language models as follows. p ( w|  X  D ) is a document language model for D . 2.2 Methods for Query Expansion In this section, we introduce two methods of query expansion, Markov Chain Transla-tion Model and Parsimonious Translation Model. Markov Chain Translation Model (MCTM). Estimation of the query model is performed by term co-occurrence statistics, based on MCTM between words and documents [9]. For given term q, translation model (word transition probabilities) induced from the Markov chain is calculated in random walk as follows [9]. 
Translation model t ( w | q ) means the probability to generate w from document which topically related to q . 
Formula (2) is rewritten as follows by applying the Bayesian theorem on p (  X  D | q ). occurrence information. It implies that the translation model is used as another meas-urement of co-occurrence statistics. 
Given query Q, we can estimate an expanded query model from the translation model as follows, similar to [9]. query model of MLE for given Q . The final query model  X  Q X  is obtained by mixing the expanded query model and the MLE of the query model using parameter  X  . Parsimonious Translation Model (PTM). The parsimonious translation model first estimates parsimonious language models for available documents and calculate word translation probabilities by pairs of topical terms selected from documents [15]. There select_ratio ( P ), where terms are selected as long as summation of probabilities of the method for this experimentation due to its generality. 
To derive parsimonious document langua ge model, document specific topic model to maximize the document likelihood is first constructed. It is assumed that document global collection model  X  C . maximize the document likelihood D .  X  D* is calculated by applying the EM algorithm [4]. 
Let us define the parsimonious document language model s D  X  consisting of topical terms selected by select_ratio ( P ). Let D s be a set of topical terms of the document D fies the constraint w Ds p ( w|  X  D* ) &lt; P. where  X  D is a normalization factor with value 1/ w Ds p ( w|  X  D* ). 
The parsimonious translation model is derived by substituting the document lan-guage model in formula (3) into the parsimonious document language model of for-mula (7) as follows. 2.3 Methods for Cluster-Based Retrieval Interpolation Method. The main intuition of cluster-based retrieval is to rank method, scoring schemes of document for given query reflect the score of cluster that the document belongs to, with interpolation format. 
To derive the interpolation method, let us first introduce the aspect-x method. For a probabilistic derivation of the aspect model as follows [8]. ing words from the cluster is independent to a document. Then formula (9) is rewrit-ten by 
Cluster-based retrieval induced from this formula (10) is called the aspect-x method. Formula (11) shows the interpolation method which is derived by substitut-on individual-document information [8]. than the linear mixture in our experiments, the following ranking formula is derived p ( C|D ) = 0 for C  X  c D . where c D indicates a cluster to which document D belongs. 2.4 Combining Methods for Cluster-Based Retrieval and Query Expansion mismatch problem in IR, each method differs each other in terms of effectiveness. It is valuable to explore how to the combine methods of cluster-based retrieval and query expansion to identify difference. 
As mentioned in the Section 1, this paper examines two combining methods-, clus-ter-based retrieval from query expansion and cluster-dependent query expansion. Cluster-Based Retrieval after Query Expansion (Q&amp;C). This performs cluster-baseline method in our experiments in combining cluster-based retrieval and query combining methods will improve performance over that of each method alone. Cluster-Dependent Query Expansion (C&amp;Q). In the language modeling approach, translation model. 
The cluster-dependent translation model t ( w | q,C ) means the probability to generate belongs to cluster C . The model is given by adding cluster conditional term. 
By applying the Bayesian rule for p (  X  D |q,C ) in formula (5), we can further derive it as follows. 
Now, for a given query Q , the query-context dependent translation model is de-rived by using the cluster-dependent translation model as follows. P ( C|Q ) of cluster C for given query Q is rewritten by. This Section shows experimental results for four issues in noted in Section 1 in order. 3.1 Experimental Setup Our experimental database consists of two collections in Korean, and five TREC4 average number of unique terms of documents,  X # Q X  is the number of topics and  X # R X  is the number of relevant documents in each test set. 
In Korean documents, it is well known that bi-character (n-Gram) indexing units are highly reliable [13]. Thus the bi-character indexing unit is used in this experimen-where stop words are removed and then Poster stemming is applied. 3.2 Effects of Parsimony on Query Expansion baseline language model using the MLE of the query sample, the query model esti-mated from the original translation model (formula (3)), and the query model esti-mated from the parsimonious translation model (formula (8)). Interpolation parameter  X  is fixed at 0.1, which was performed well in all test collections. 
As shown in Figure 1, for almost all parsimony levels, parsimonious translation model (PTM) significantly improves baseline in the seven data collections. Remarka-model (OTM) at low parsimony level. In OTM, some noise occurs because common words of query can be expanded by common terms of document. Therefore, com-pared with baseline, high accuracy of PTM implies that PTM can effectively elimi-retrieval performance. 
Concerning optimal parsimony level, while for Korean collection optimal parsi-and 0.4. However, performance in TREC4-FR test collection is relatively exceptional. As shown in Figure 1, PTM does not good in parsimony levels not in 0.2~0.4 but in 0.6 ~0.8. It seems that in TREC4-FR good expansion terms have relatively small probabilities value. Table 2 summarizes the best performance of the parsimonious models (PTM*) and OTM in the seven test collections. The last column with symbol  X %chg X  indicates improvement ratio of PTM* over OTM. P* is the parsimony level at the best. From this table, we know that PTM highly outperforms baseline from 5% to 25%, and es-pecially 25.55% improvement is achieved at TREC4-ZIFF collection. 
From these experiments, we can conclude that the parsimonious translation model not only drastically reduces time-and space-complexity but also highly improves re-trieval performance at the optimal parsimony levels. Although it is necessary to tune for different collections for an optimal parsimony level, it seems that an optimal par-simony level is almost same for the same language. 3.3 Query Expansion vs. Cluster-Based Retrieval For document clustering, the K-means clustering algorithm is used because of its low time complexity. Similarity measure for K-means clustering between a document and a cluster is regarded as negative KL divergence between a parsimonious document language model (set P be 1.0 with select_ratio ( P )) and cluster language model. 
For the cluster language model, JM(Jerlinek Mercer) smoothing with smoothing parameter 0.25 is used. We randomly select K documents and use them as initial clus-ter centroids. To perform Cluster-based Retr ieval (CR), formula (13) is utilized where  X  is set to be 0.8 which is known to be relatively good in preliminary experimentation. smoothed with collection language models by using an parameter  X  . In the experimen-tation, interpolating parameter  X  is set to 0.8. for each different parameter (i.e. 100, 200, and 500 and 1000) and select the best one. The results are described in Table 3 with the original translation model (OTM) in the six data collections. The result in KTSET 1.0 will be discussed in next Section. Bold faces express best performance in each collection. In five test sets except for TREC4-ZIFF, the best performances are achieved at K = 500. Overall, the effect of CR differs in each test set. In NTCIR3-KK and TREC4-AP CR is highly effective, improving the baseline with a difference between 2% and 3%, obtaining better performances over OTM. However, in other test sets, performance improvements are not significant over the baseline. The possible reason is that initial centroids randomly selected are not good for those test sets. Due to local convergence characteristics of K-Means, final clustering result is very sensitive to initial condition, so with a bad initial condition it is likely that the resulting clusters obtained from the local maximum result are not adequate for CR. We believe that the result can be im-good criterion are used. 
Let X  X  compare the performance by PTM in Table 2 and CR in Table 3. In five test collections except for TREC-AP, the best performance by CR is generally lower than performance by PTM. In these five test sets, the best performances are achieved at K = 500, and at K = 200 in TREC4-ZIFF. They are not as good as the best performances of the parsimonious translation models. There is one exceptional case, in TREC4-AP, where cluster-based retrieval is better than the optimal parsimonious translation model at K = 500. 3.4 Effects of Clustering Algorithms in Cluster-Based retrieval consider two clustering algorithms: the Agglomerative and Partitional. The agglom-erative clustering methods group the documents into a hierarchical tree structure using cluster trees in hierarchical clusters are extracted. We use group average criterion for merging clusters [7]. 
The partitioning methods decompose the document set into a given number of dis-Means clustering belongs to partitional clustering approach. Because the size of KTSET 1.0 is small, we could successfully perform agglomerative clustering at com-putationally feasible time. 
Figure 2 shows the results of CR in KTSET 1.0 varying the number of clusters from 10 to 100 increasing by 10.  X  is the same as the value in Section 3.3. K-Means cluster-ing is unstable according to the number of clusters and sometimes is worse than base-ters showing a maximum difference of about 6%. In addition, it is always better than K-Means regardless of the number of clusters and more stable than K-Means. 3.5 Combining Methods of Query Expansion and Cluster-Based Retrieval Again, let us look at Figure 1. Figure 1 compares performance of baseline, PTM*, and two kinds of combination methods of query expansion (QE) and CR (Q&amp;C and same to those in individual method. 
Concerning Q&amp;C and C&amp;Q, in Korean collection, two methods are successful, showing that they outperform the baseline and individual methods of QE and CR. Especially, Q&amp;C is better than C&amp;Q. However, two combining methods are not suc-not improve individual methods or sometimes are worse in other four collections. One KTSET 1.0, NTCIR3-K, and TREC4-AP, the best performance of CR is higher than baseline (about 3%) and QTM (about 1.5%). On the other hand, in the other four rather is worse than them. To sum up, combination of QE and CR is meaningful, only if performance of each method is higher than baseline. In addition, in such a case, the Q&amp;C is slightly better than the C&amp;Q. 
Let X  X  consider relationship between performance by Q&amp;C and C&amp;Q and perform-about this experiment due to limits of this paper) we found a tendency that perform-can be more improved if clustering algorithm is more refined. However, performance of C&amp;Q is relatively less dependent on performance of CR and is highly depends on the number of clusters. It is understandable because C&amp;Q has almost the same effect each document, resulting in total N clusters given N documents. 
Table 4 presents performance of PTM* (best performance by PTM in each collec-Compared with performance by PTM*, performance by Q&amp;C is higher about 2% in only three collections (KTSET 1.0, NTCIR3-KK, and TREC4-AP). This paper performs an empirical study of query expansion and cluster-based retrieval in order to resolve the word mismatch problem in a language modeling framework. From this work, several conclusions are derived as follows. 
The parsimonious translation model not only remarkably reduces time-and space-complexity but also highly improves retrieval performance at the optimal parsi-mony levels. 
Cluster-based retrievals depend on clustering algorithm and the number of clus-ters. Cluster-based retrieval outperforms the baseline language modeling in almost all cases, but, generally it is worse than the parsimonious translation model. 
Combination of cluster-based retrieval and query expansion is effective in the case that each query expansion and cluster-based retrieval outperforms baseline lan-guage modeling. In such case, cluster-based retrieval after query expansion is slightly better than cluster-dependent query expansion. And, the following potential conclusions are also derived. 
For cluster-based retrieval, agglomerative clustering directly using document-to-document similarities are more effective than partitioning clustering such as K-Means based on centroid-to-document similarities 
Cluster-based retrieval in our work considers only two traditional approaches, but, many clustering algorithms such as spectral clustering, information bottleneck method investigate a theoretical relationship between cluster-based retrieval and query expan-sion based on our experimental results. Finally, more elegant method to combine cluster-based retrieval and query expansion is remained as a challenging research issue This work was supported by the KOSEF through the Advanced Information Technol-ogy Research Center(AITrc) and by the BK21 Project. 
