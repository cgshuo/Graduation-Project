 1. Introduction
The main objective of image segmentation is to divide an image into regions that can be considered homogeneous with respect to a given criterion such as color or texture. Image segmentation is one of the most widely studied problems in image analysis and computer vision and, it is a significant step towards image under-standing. In the past three decades, a variety of image segmentation methods have been developed in the image processing and com-puter vision communities. Although seemingly very different, they all share the same property: to divide the image into regions with similar attributes ( Unnikrishnan et al., 2007 ; Rigau et al., 2009 ; Francisco and Allan 2009 ). The existing image segmentation work can be roughly divided into Thresholding ( Aroraa et al., 2008 ; Horng 2011 ; Hammouche et al., 2008 ), Template matching ( Zeng et al., Christoudias et al., 2002 ), Clustering ( Chatzis and Varvarigou, 2008 ; Comaniciu and Meer, 2002 ; Wang and Bu, 2010 ), Region growing ( Yu and Clausi, 2008 ; Kang et al., 2012 ; Panagiotakis et al., 2011 ), and Graph-based methods ( Wenbing et al., 2007 ; Boykov et al., 2001 ; Salah et al., 2011 ).

Thresholding ( Rigau et al., 2009 ; Aroraa et al., 2008 ; Horng 2011 ; Hammouche et al., 2008 ) is a basic technique of image segmentation with a significant degree of popularity, especially in applications where speed is an important factor. The thresholding algorithm provides a number of threshold levels, which determine the region in which each pixel belongs depending on its intensity value. In order to find these thresholds, almost all methods analyze the histogram of the image. In most cases, the optimal thresholds are found by either minimizing or maximizing an objective func-tion, which depends on the positions of the thresholds. Threshold-ing is best suited for bimodal distribution, such as solid objects resting upon a contrasted background. However, traditional histogram-based thresholding algorithms cannot separate those areas which have the same gray level but do not belong to the same part. In addition, they cannot process images whose histo-grams are nearly unimodal, especially when the target region is much smaller than the background area. Template matching method becomes time consuming when the image becomes more complexorlargerinsize( Zeng et al., 2004 ; Guan-Yu Chen et al., 2008 ). Edge-based segmentation methods perform segmentation, on the basis of the information conveyed by the edges that exist in an image ( Li et al., 2007 ; Horng 2011 ; Christoudias et al., 2002 ).
Supplementary processing steps must follow to combine edges into edge chains (borders) in order to form coherent objects in the image. The edge-based methods are insensitive to image nonsta-tionarity and are efficient in describing local behaviors, but are ineffective in producing results globally meaningful. Cluster analy-sis is a methodology developed for capturing local substructures in multivariate data by applying an affinity criterion to group data points. Many authors have proposed image segmentation schemes based on fuzzy set theory ( Chatzis and Varvarigou. 2008 ). During the last decades, fuzzy clustering methodologies, especially the fuzzy c-means algorithm (FCM), have been widely applied as the effective means to conduct image segmentation ( Comaniciu and Meer 2002 ; Wang and Bu, 2010 ). Their success chiefly is attributed to their fuzzy nature, which appears to allow the clustering procedure to retain more information from the original image than the crisp or hard clustering methodologies. Although the FCM algorithm usually performs well with noise-free images, it obtains a rather poor result when having to deal with images corrupted by noise, outliers, and other imaging artifacts, as is often the case with real-world images. Region-based segmentation methods perform segmentation by dividing an image into zones of maximum homo-geneity ( Li et al., 2007 ; Yu and Clausi 2008 ; Kang et al., 2012 ;
Panagiotakis et al., 2011 ). The criteria for homogeneity can be based on gray-level, color, texture, and shape information. Several criteria can then be employed to force region growing in order to form consistent objects in the image. It is very important to note that region-based methods may produce different segmentation results, and therefore a combination of the segmentation results is often used as the objective is to form the most accurate segmentation map. The region splitting and merging category provides the possibility of incorporating a variety of regional features but often has difficulty in determining suitable merging and stopping criteria for a result that is neither oversegmented nor undersegmented.
Graph-based approaches can be regarded as image perceptual grouping and organization methods based on the fusion of the feature and spatial information. In such approaches, visual group is based on several key factors such as similarity, proximity, and continuation. The common theme underlying these approaches is the formation of a weighted graph, where each vertex corresponds to n image pixel or a region, and the weight of each edge connecting two pixels or two regions represents the likelihood that they belong to the same segment. The weights are usually related to the color and texture features, as well as the spatial characteristic of the corresponding pixels or regions. A graph is partitioned into multiple components that minimize some cost function of the vertices in the components and/or the boundaries between those components. So far, several graph cut-based methods have been developed for image segmentations ( Wenbing et al., 2007 ; Boykov et al., 2001 ;
Salah et al., 2011 ). But generally, graph-based segmentation approaches suffer from high computational complexity.
 and support vector machine (SVM) ( Sowmya and Sheela Rani 2011 ), have already been utilized successfully in image segmenta-tion. Sowmya and Sheela Rani (2011) explained the task of segmenting any given color image using fuzzy clustering algorithms and competitive neural network. Lian and Wu (2011) presented a new approach based on adaptive probabilistic neural network (APNN) and level set method for brain segmentation with magnetic resonance imaging (MRI). The APNN is employed to classify the input MR image, and to extract the initial contours. Based on the extracted contours as the initial zero level set contours, the modified level set evolution is performed to accomplish the segmentation. Quan and Wen (2008) proposed an effective multi-scale method for the segmentation of the synthetic aperture radar (SAR) images via probabilistic neural network. By combining the probabilistic neural network (PNN) with the multiscale autoregres-sive (MAR) model, a classifier, which inherits the excellent strong-point from both of them, is designed. Yu and Chang (2004) presented an effective and efficient method for solving scenery image segmentation by applying the SVMs methodology. Cyganek (2008) proposed an efficient color segmentation method which is based on the SVM classifier operating in a one-class mode, and the method has been developed especially for the road signs recogni-tion system. Wang et al. (2011) presented a color image segmenta-tion algorithm by integrating the support vector machine (SVM) and fuzzy c-means. Both local spatial similarity measure model based color features and Steerable filter based texture features are extracted from the image. Before feeding to SVM algorithm for image segmentation, fuzzy c-means based algorithm is employed for clustering color and texture features. Yu et al. (2011) proposed a modified SVM based on the properties of support vectors and a pruning strategy to preserve support vectors, while eliminating redundant training vectors at the same time. Bertelli et al. (2011) proposed a supervised segmentation approach that tightly inte-grates object-level top down information with low-level image cues. The information from the two levels is fused under a kernelized structural SVM learning framework.

In this paper, we propose a color texture segmentation based on image pixel classification. We first extract the pixel-level color feature and texture feature of the image via the local spatial similarity measure model and localized Fourier transform, which is used as input of FSVM model (classifier). We then train the
FSVM model (classifier) by using FCM with the extracted pixel-level features. Color image segmentation can be then performed through the trained FSVM model (classifier). Compared with three other segmentation algorithms, the results show that the pro-posed algorithm is more effective in color image segmentation.
The rest of this paper is organized as follows. Section 2 presents the basic theory about FSVM and FCM. In Section 3 , the pixel-level color feature and texture feature extraction are described. Section 4 contains the description of our color image segmentation. Simula-tion results in Section 5 will show the performance of our scheme.
Finally, Section 6 concludes this presentation. 2. The fuzzy C-means clustering and fuzzy support vector machine classification 2.1. The fuzzy C-means (FCM)
Clustering analysis is a branch of unsupervised pattern recog-nition. The fuzzy cluster analysis attracts more and more atten-tion recently with introducing the fuzzy set theory. Clustering algorithms are used to find groups in unlabeled data, based on a similarity measure between the data patterns (elements). This means that similar patterns are placed together in the same cluster. The main difference between fuzzy clustering and other clustering techniques is that it generates fuzzy partitions of the data instead of hard partitions. Therefore, data patterns may belong to several clusters, having in each cluster different mem-bership values.

The FCM algorithm assigns pixels to each category by using fuzzy memberships ( Chen and Zhang 2004 ). Let I  X  fi , j  X  X  , 0 r i r M , 0 r j o N denote an image with M N pixels to be parti-tioned into c clusters, where fi , j  X  X  represents multispectral (fea-tures) data. The algorithm is an iterative optimization that minimizes the cost function defined as follows: JU , V  X  X  X  where U  X  [ m k ( i , j )] is the fuzzy clustering matrix,
V  X  v 0 , v 1 , v 2 , , v c 1 is the set of clustering centers, u sents the membership of pixel f ( i , j ) in the k th cluster, m is the weighting exponent and a constant, which controls the fuzziness of the resulting portions, and m  X  2 is used in this study. d the distance between pixel f ( i , j ) and the k th cluster which is defined as  X  d k i , j  X  X  X  2  X  J fi , j  X  X  v k J 2  X  X  fi , j  X  X  v k  X  T fi , j  X  X  v where fi , j  X  X  A I , T denotes matrix transposition, J J metric, denotes Euclidean distance.

The cost function is minimized when pixels close to the centroid of their clusters are assigned high membership values, and low membership values are assigned to pixels with data far from the centroid. The membership function represents the probability that a pixel belongs to a specific cluster. In the FCM algorithm, the probability is dependent solely on the distance between the pixel and each individual cluster center in the feature domain. FCM algorithm is as follow: b) Step 5: Repeat until the algorithm has converged (that is, 2.2. Fuzzy support vector machine (FSVM)
Support vector machines (SVM) based on statistical learning theory, are introduced by Vapnik (1995) . Vapnik constructed the standard SVM to separate training data into two classes. The goal of the SVM is to find the hyperplane that maximizes the mini-mum distance between any data point. SVM has been successfully applied in classification and function estimation problems, but some limitations exist in the SVM theory. Traditionally, we know each sample { x i , y i } in the training dataset belongs to either one class or the other, i.e., the value of y i is only assigned to 1 or 1. All samples in training dataset are treated uniformly in the same class during the learning process of SVM.

In practical classification problems, the effects of the samples in training dataset may be different ( Vapnik, 1995 ; Lin and Wang, 2002 ). Usually, some of samples in training dataset are corrupted by noise, which is introduced during sampling. These samples are called outliers, and usually less important than others. In fact, that we care about the meaningful samples can be classified correctly. In short, a sample in the training dataset may not completely belong to one class. For example, 90% of the sample belongs to one of the two classes and 10% is meaningless, or we say that the sample belongs to one of two classes with 90% confidence. In other words, each training sample x i , y i is associated with a fuzzy membership 0 r s i r 1  X  X  . This fuzzy membership s i indicates the certainty that the sample belongs to one of two classes is s i , and the value 1 X  s be regarded as meaningless in the classification problem. In 2002, Lin and Wang (2002) introduced Fuzzy Support Vector Machine (FSVM) by incorporating fuzzy membership into standard SVM. In the FSVM, each sample x i , y i in the training data is weighted by using fuzzy membership function. It becomes as x i , y is the fuzzy membership, i.e., the confidence of this sample belong to one of two classes. Then the optimal hyperplane problem in SVM is reformulated as ( Shi et al., 2006 ) Minimize L a  X  X  X  1 2 subject to y a i  X  0 , 0 r a i r s i C , i  X  1 , 2 , , n
The significant difference of FSVM from SVM is that the sample with smaller fuzzy member S i is less important than all other samples in SVM during training. It indicates that the importance of the training sample can be measured by the fuzzy membership S
Choosing appropriate fuzzy memberships for a given problem is very important for FSVM. In Lin and Wang (2002) , the fuzzy membership function for reducing the effect of outliers is a function of the distance between each data point and its corre-sponding class center, and the function is represented with parameters of the input space. 3. The pixel-level color and texture feature
In this paper, each pixel of an image is identified as belonging to a homogenous region corresponding to an object or part of an object. The problem of image segmentation is regarded as a classification task, and the goal of segmentation is to assign a label to individual pixel or a region. So, it is very important to extract the effective pixel-level image feature. Here, we extract the pixel-level color and texture feature via the local spatial similarity measure model and localized Fourier transform. 3.1. Pixel color feature
Color is one of the most dominant and distinguishable low-level visual features in describing image, and many researchers have employed color to segment images ( Rigau et al., 2009 ). In this section, we introduce a new pixel-level color feature accord-ing to local spatial similarity measure model ( Cai et al., 2007 ). Green, and Blue) of the i th pixel, and the pixel-level color feature
CF k  X  R , G , B  X  X  of component X k i  X  k  X  R , G , B  X  can be computed as follows (Each color component can be treated as a gray scale image). 3.1.1. Construct the local image window
As shown in Fig. 1 , the i th pixel is the center of the local image window (for example, 5 5), and the j th pixel are the set of the neighbors O i falling into a window around the i th pixel. 3.1.2. Compute the local color feature of component X k i
The local color feature cf k ij of component X k i depends mainly on both the local spatial relationship and the local gray-level relationship. Its definition is presented as below where the i th pixel is the center of the local window and the j th pixel are the set of the neighbors O i falling into a window around the i th pixel, as shown in (3) . sf k ij denotes local spatial relation-ship, gf k ij is expressed as the local gray-level relationship, cf local color feature. change flexible according to their distance from the central pixel and thus more local information can be used. Here the definition of sf k ij is given as follows: sf k ij  X  exp where ( x i , y i ) and ( x i , y j ) are the spatial coordinate of the i pixel. l S denotes the scale factor of the spread of sf k easily determined. When l S are set to 1, 3 and 10, respectively, the changing trend of sf k ij against the size of the window is shown in Fig. 2 .
 window center the location is, the larger the sf k ij value is, thus sf reflects different damping extent for pixels according to different spatial locations within a given window. Here, axis spatial denotes the effect degree of pixels in local image widow. same window can reflect the local neighborhood inhomogeneity of the window. To suppress the influence of the outlier, we define the local gray-level similarity measure gf k ij as follows: gf ij  X  exp where gx i , y i k is the color component value of the central pixel within a special window, g  X  x j , y j  X  k is color component value of the
J th pixels in the same window, ( x i , y i ) and ( x i , y coordinate of the J th pixel and J th pixel. l G denotes the global scale factor of the spread of gf k ij . The parameter s G the local density surrounding the central pixel and its value reflects gray value homogeneity degree of the local window.
The smaller its value is, the more homogenous the local window is, and vice versa. s G  X  where O i is the set of the neighbors falling into the window around the central pixel i , N O i denotes the pixel number in O
Obviously, when the gray value of the neighbors of the pixel i is close to the gray value of the pixel j , gf k ij should be large. 3.1.3. Compute the pixel-level color feature CF k i of component
X  X  k  X  R , G , B  X 
CF where O i is the set of the neighbors falling into the local window around the central pixel i , and N O i denotes the pixel number in O
So, we can obtain the pixel-level color feature CF i of the i th image pixel X i
CF i  X  X  CF R i , CF G i , CF B i  X  :
Fig. 3 shows the color image and its three pixel-level color feature matrix. 3.2. Pixel texture feature
Texture is one common feature used in image segmentation. It is often used in conjunction with color information to achieve better segmentation results than possible with just color alone.
In this paper, we introduce a new pixel-level texture feature that is called the localized angular phase (LAP) ( Saipullah and
Kim, 2012 ). LAP is based on the localized Fourier transform that provides information in both the time and frequency domains.
In contrast with the 2D short term Fourier transform, the LAP pixels that have been converted into the polar space with a fixed radius. The phase sign is analyzed to form 8-bit codewords where the distribution of their decimal values is used to describe pixel texture.

For pixel texture feature extraction purposes, we use the HSI representation of the color image because this color space can control color and intensity information independently. In this paper, the pixel-level texture feature is extracted from the I component, this is because that the I component closely matches human perception of lightness.

As shown in Fig. 4 , let the window be the subimage s ( x , y )in the Cartesian coordinate where s (0,0) pixel is at the center of the subimage. This 3 3 subimage is then converted into the fixed-radius polar space p ( r , y ) using the following formula:
Some s ( x , y ) points do not fall on the rectangular grid. These values need to be interpolated using bilinear interpolation given by sx 0 , y 0  X  X  X  ax 0  X  by 0  X  cx 0 y 0  X  d  X  10  X  where a , b , c and d are the four nearest neighbors of point s ( x , y ). nine samples. We denote this discrete signal by p ( n ), n  X  0,1, The Fourier transform and inverse transform of p ( n ) are given by Pk  X  X  X  where N is the number of samples in p ( n ), and for 3 3subimage, N coefficients p ( k ).

After the Fourier transform, the values of nine complex coefficients p (0), p (1), y , p ( 8 ) are obtained. The next step is to select some complex coefficients to extract the phase information.
The p (0) is the DC value of the Fourier transform and contains no phase information, thus it is excluded from the selected coeffi-cients. Because the image contains only real values, its Fourier transform becomes centrally symmetric where half of the coeffi-cients are redundant.

In previous research, eight circular neighbors were used as input for the Fourier transform. If the number of samples is even, e.g., eight samples, then the resulting complex coefficients will have another DC value. This extra DC value will reduce the number of useful non-redundant complex coefficients. So, to avoid information loss, the LAP method uses nine samples, instead. This will result in only one DC value. Then, four non-redundant complex coefficients are selected, whereby half of the complex coefficients are either p (1), extracted from these four complex coefficients by observing the signs of each real and imaginary part of the four complex coeffi-cients. Let the C matrix contain the information of these four complex coefficients given by C  X  X  Re f X  X  4  X g Im f X  X  4  X g Re f X  X  3  X g Im f X  X  3  X g where matrix C is then quantized into 8-bit binary code by using the following formula: b  X  k  X  X  where p ( k ) is the sign of each coefficient. By arranging p (1), p (2), , p (8), the 8 bit binary code can be formulated, and a binomial factor is assigned as 2 for each p ( k ),henceitispossibletotransform (12) into a unique LAP number, given by LAP  X  resulting from the 8-bit binary code. Fig. 5 shows the color images and their pixel-level texture feature matrix. 4. The pixel-based color image segmentation using FSVM and FCM classification problems, which can be solved using anyone of well-known classification techniques. FSVM is one of the classi-fication techniques and good results of the FSVM technique in pattern recognition have been obtained, so we can choose the
FSVM for solving color image segmentation problems. In this paper, we propose a pixel-based color image segmentation using
FSVM and FCM, and it can be summarized as follows (see Fig. 6 ). 4.1. Pixel-level color and texture features extraction
The pixel-level color and texture features are extracted via the local spatial similarity measure model and localized Fourier transform (see Section 3 ). 4.2. FCM based FSVM training sample selection
Training sample selection is one of the major factors determin-ing to what degree the SVM classification rules can be generalized to unseen sample. A previous study showed that this factor could be more important for obtaining accurate classifications than the selection of classification algorithms. For SVM based image segmentation, training pixels can be selected in many ways. A commonly used sampling method is to identify and label small patches of homogeneous pixels in an image. However, adjacent pixels tend to be spatially correlated or have similar values.
Training samples collected this way underestimate the spectral variability of each class and are likely to give degraded classifica-tion. A simple method to minimize the effect of spatial correlation is random sampling. There are two random sampling strategies, one is called equal sample rate (ESR) in which a fixed percentage of pixels are randomly sampled from each class as training data., and the other is called equal sample size (ESS) in which a fixed number of samples are randomly sampled from each class as training data. In this paper, we will select the training samples for FSVM classifiers by using FCM clustering algorithm.

Step 1: Set the initial parameters, such as the number of clusters c , convergence error e etc.

Step 2: The FCM algorithm is used to cluster the image pixels according to their color and texture features, and the member-obtained. Where n is the number of image pixels.
Step 3: Classify the image pixels by membership value m k  X  x i , y i  X  . Suppose m J x i , y i  X  max m 1 x i , y i , m 2 x i , y i , ... , m pixel at x i , y i belongs to the J th cluster.

Step 4: For the image pixels in the J th cluster, n j /10 image pixels are selected as the training samples of the J th cluster according to bigger membership value m J x m , y m . Where n the number of image pixels in the J th cluster. Combine the 4.3. FSVM model training the previous step. In this paper, we used 50 image samples for training. In addition, we performe d cross-validation exercise, and selected the hyper-parameters by experiment. For the limited com-putational power, we use the results by six-fold cross validation to select the appropriate parameters and evaluate the performance. Five images were used for training and the remaining one was used for testing for each iteration. All six images and their corresponding manually classified images came from BSD (Berkeley segmentation database). 4.4. FSVM pixel classification samples) using the trained FSVM model (classifier). Combine the training set (class labels given by FCM clustering) and the test set (class labels given by FSVM) to obtain the complete label vector and return it as the clustering solution (image segmentation results). 5. Performance evaluation 5.1. Evaluation setup and dataset
Comprehensive experiments were conducted in natural scene images to evaluate the performance of our image segmentation method. The proposed method has been used to segment an image into distinct color-textured regions on three publicly available datasets: Berkeley image Segmentation Database (BSD) ( Fowlkes and Malik 2004 ), Microsoft Research Cambridge data-base (MSRC) ( Shotton et al., 2006 ), and Segmentation Evaluation
Database (SED) ( Alpert et al., 2007 ). The BSD comprises of various images from the Corel dataset and contains ground truth of 300 images for benchmarking image segmentation and boundary detection algorithms. The content of the images are landscapes, animals, portraits and various objects. The MSRC contains 591 color images of 21 object classes such as building, grass, tree, cow, sheep, etc. Several papers report results on this dataset with similar training/test conditions including ( Unnikrishnan et al., 2007 ). The SED consists of 100 color and gray images, with a single prominent foreground object in each. The goal is to generate a coverage of the whole object with a single segment as accurately as possible.

The metrics used for the quantitative evaluation of the proposed algorithm were the following ( Unnikrishnan et al., 2007 ; Francisco and Allan 2009 ).
 the measure, the BCE ignores the frequency with which pixel labeling refinements in the test image are reflected in the manual segmentations. To ease comparison of BCE with measures that quantify similarity, the equivalent index BCI  X  1 BCE is defined taking values in [0, 1] with a value of 1 indicating a perfect match.
The  X  X  X  X  X  in the abbreviations stands for  X  X  X ndex, X  X  complying with the popular usage of the term in statistics when quantifying similarity. 5.2. Experimental results
In this section, we demonstrate the segmentation results of the proposed method on natural images obtained from Berkeley image Segmentation Database (BSD) ( Fowlkes and Malik 2004 ),
Microsoft Research Cambridge database (MSRC) ( Shotton et al., 2006 ), and Segmentation Evaluation Database (SED) ( Alpert et al., 2007 ). The contrastive experiment results using Edison system by Christoudias et al. (2002) , using Mean-shift by Comaniciu and
Meer (2002) , and using Graph cuts by Boykov et al. (2001) are also presented for comparison.

During the experimentation, we selected the radius-based function (RBF) as the SVM kernel function, and implemented a grid search using a 6-fold cross-validation on UCI dataset for obtaining the optimal upper bound C and kernel parameter g .
Table 1 summarized the results of the grid search using the 6-fold cross-validated accuracy as an evaluation criterion. After con-ducting the grid search on the training data, the optimal (C, g )is (2 ,10) with a cross-validated accuracy of 79.49%.

Fig. 6 shows the relation between the segmentation Error Rate (ER) and local window size (for four different color images from BSD). From Fig. 6 , we can see that the less ER can be obtained when the local window size is selected as 5 5. For other parameter, we set c  X  2, l S  X  3, l G  X  5,p  X  1, q  X  1. All the experi-ments are carried out on a Pentium 4PC with 2 GHz CPU and 1 GB memory, within MATLAB 7.0 in Windows XP.

Figs. 7 and 8 show visual comparison of the proposed color image segmentation algorithm with Edison system ( Christoudias et al., 2002 ), Mean-shift ( Comaniciu and Meer 2002 ), and Graph cuts ( Boykov et al., 2001 ) on the Berkeley image Segmentation Database (BSD) ( Fowlkes and Malik 2004 ). Figs. 9 and 10 show visual comparison of the proposed color image segmentation algorithm with Edison system ( Christoudias et al., 2002 ), Mean-shift ( Comaniciu and Meer 2002 ), and Graph cuts ( Boykov et al., 2001 ) on the Microsoft Research Cambridge database (MSRC) ( Shotton et al., 2006 ). Figs. 11 and 12 show visual comparison of the proposed color image segmentation algorithm with Edison system ( Christoudias et al., 2002 ), Mean-shift ( Comaniciu and Meer 2002 ), and Graph cuts ( Boykov et al., 2001 ) on the Segmentation Evaluation Database ( Alpert et al., 2007 ). Table 2 presents the quantitative evaluation (ER, LCI, BCI) for the four different image segmentation algorithms. Looking at the experi-mental results, it can be seen that the proposed segmentation algorithm performs superior to Edison system ( Christoudias et al., 2002 ), Mean-shift ( Comaniciu and Meer 2002 ), and Graph cuts ( Boykov et al., 2001 ) for test images from three different publicly available datasets.

Overall, the proposed color image segmentation scheme reached competitive results as i t gives relatively good results in terms of some segmentation indices for natural images, and the best subjective segmentation quality for most natural images compared to some state of the art segmentation algo-rithms. The main contribution of the proposed scheme are using novel pixel-level color and texture features, introducing the
FCM clustering for initialization and training sample selection, and replacing SVM with FSVM for better classification efficiency.
However, for some complex scen es, the proposed segmentation method sometimes cannot achieve the optimal segmentation performance, this is because that the used pixel-level color and texture features are not suitable for describing effectively complex images.
 6. Conclusions on FSVM and FCM is introduced in this paper. We first extract the pixel-level color feature and texture feature of the image via the local spatial similarity measure model and localized Fourier transform, which is used as input of FSVM model (classifier).
We then train the FSVM model (classifier) by using FCM with the extracted pixel-level features. Color image segmentation can be then performed through the trained FSVM model (classifier). Results obtained on the Berkeley image Segmentation Database, Microsoft Research Cambridge database, and Segmentation Evalua-tion Database indicates that the proposed algorithm achieves better quantitative results than three known color image segmentation algorithms. However, in this paper, the over-segmentation problem is not described. In addition, another limitation of this algorithm is that users have to have before hand information about the classes of some the pixels. Future work will focus on eliminating these drawbacks.
 Acknowledgements This work was supported by the National Natural Science Foundation of China under Grant No. 61272416, 60773031 &amp; 60873222, the Open Foundation of State Key Laboratory of Information Security of China under Grant No. 04-06-1, the Open Foundation of Network and Data Security Key Laboratory of Sichuan Province, the Open Foundation of Key Laboratory of Modern Acoustics Nanjing University under Grant No. 08-02, and Liaoning Research Project for Institutions of Higher Education of China under Grant No. 2008351 &amp; L2010230.
 References
