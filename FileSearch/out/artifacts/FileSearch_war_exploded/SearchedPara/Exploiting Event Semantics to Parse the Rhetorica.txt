 Discourse is a structurally organized set of coher-ent text segments. The minimal unit of discourse is called an elementary discourse unit (EDU). An EDU or a span of EDUs constitute a segment. When we read text, we automatically assign rhetorical (coher-ence) relations to segments of text that we deem to be related. Consider the segmented text below:
It is plausible to state that the rhetorical relation between (1 a ) and (1 b ) is preparation:act . We can also posit that the relation act:goal holds between (4 a ) and (4 b ) . Figure 1 shows the complete annota-tion of the full text. Now, if we were to reorder these the text would not make much sense. Therefore, it is imperative that the contiguous spans of discourse be coherent for comprehension. Rhetorical relations help make the text coherent.

Rhetorical relations based on the subject matter of the segments are called informational relations. A common understanding in discourse study is that informational relations are based on the underlying content of the text segments. However, previous work (Marcu, 2000; Polanyi et al., 2004; Soricut and Marcu, 2005; Sporleder and Lascarides, 2005) in discourse parsing has relied on syntactic and lex-ical information, and shallow semantics only.
The goal of this thesis is to build a computa-tional model for parsing the informational structure of instructional text that exploits  X  X eeper seman-tics X , namely event semantics. Such discourse struc-tures can be useful for applications such as informa-tion extraction, question answering and intelligent tutoring systems. Our approach makes use of a neu-ral network discourse segmenter, a rhetorical rela-tion classifier based on ILP and a discourse pars-ing model that builds sentence level DPTs bottom-up and document level DPTs using a shift-reduce parser.

In section 2, we describe how we collected our data. In section 3, we present our automatic dis-course segmenter. Section 4 details our discourse parsing model based on event semantics followed by the conclusion in section 5. Our work calls for the use of a supervised machine learning approach. Therefore, we have manually an-notated a corpus of instructional text with rhetorical relations and event semantic information. We used an existing corpus on home repair manuals (5Mb). 1 2.1 Manual Discourse Annotation In order to carry out the manual discourse anno-tation, a coding scheme was developed based on Marcu (1999) and RDA (Moser et al., 1996). The annotated data consists of 5744 EDUs and 5131 re-lations with a kappa value of 0.66 on about 26% of the corpus. We analyzed a total of 1217 examples to determine whether a cue phrase was present or not. Only 523 examples (43%) were judged to be signalled. Furthermore, discourse cues can be am-biguous with regard to which relation they signal. In order to account for cases where discourse cues are not present and to resolve such ambiguities, we intend to exploit event semantics. 2.2 Semi-Automatic Event Semantic Informational relations describe how the content of two text segments are related. Therefore, it makes intuitive sense that verb semantics can be useful in determining these relations. 2 In Subba et al. (2006), we integrated LCFLEX (Rose and Lavie, 2000) with VerbNet (Kipper et al., 2000) and CoreLex (Buite-laar, 1998) to compositionally build verb based event semantic representations of our EDUs.
VerbNet groups together verbs that undergo the same syntactic alternations and share similar seman-tics. It accounts for about 4962 distinct verbs clas-sified into 237 main classes. The semantic infor-mation is described in terms of an event that is de-composed into four stages, namely start , during , end and result . Semantic predicates like motion and to-gether describe the participants of an event at var-ious stages. CoreLex provides meaning represen-tations for about 40,000 nouns that are compatible with VerbNet.

The parser was used to semi-automatically anno-tate both our training and test data. Since the output of the parser can be ambiguous with respect to the verb sense, we manually pick the correct sense. 3 The task of the discourse segmenter is to segment sentences into EDUs. In the past, the problem of sentence level discourse segmentation has been tackled using both symbolic methods (Polanyi et al., 2004; Huong et al., 2004) as well as statistical mod-els (Soricut and Marcu, 2003; Marcu, 2000) that have exploited syntactic and lexical features.
We have implemented a Neural Network model for sentence level discourse segmentation that uses syntactic features and discourse cues. Our model was trained and tested on RST-DT (2002) and achieves a performance of up to 86.12% F-Score, which is comparable to Soricut and Marcu (2003). We plan to use this model on our corpus as well. Once the EDUs have been identified by the dis-course segmenter, the entire discourse structure of text needs to be constructed. This concerns deter-mining which text segments are related and what re-lation to assign to those segments. Our discourse parsing model consists of a rhetorical relation clas-sifier, a sentence level discourse parser and a docu-ment level discourse parser. 4.1 Rhetorical Relation Classifier In a preliminary investigation (Subba et al., 2006), we modeled the problem of identifying rhetorical re-lations as a classification problem using rich verb se-mantics only.

Most of the work in NLP that involves learn-ing has used more traditional machine learning paradigms like decision-tree algorithms and SVMs. However, we did not find them suitable for our data which is represented in first order logic (FOL). We found Progol (Muggleton, 1995), an ILP system, ap-propriate for our needs. The general problem spec-ification for Progol (ILP) is given by the following posterior sufficiency property:
Given the background knowledge B and the ex-amples E , Progol finds the simplest consistent hy-pothesis H , such that B and H entails E . The rich verb semantic representation of pairs of EDUs form the background knowledge and the manually anno-tated rhetorical relations between the pairs of EDUs serve as the positive examples. 4 An A*-like search is used to search for the most probable hypothesis. Given our model, we are able to learn rules such as the ones given in Figure 2. Due to the lack of space we only explain RULE1 here. RULE1 states that
Figure 2: Examples of Rules learned by Progol there is a theme (C) in motion during the event in EDU1 (the first EDU) and that C is located in loca-tion D at the start of the event in EDU2 (the second EDU).

We trained our classifier on 423 examples and tested it on 85 examples. 5 A majority function base-line performs at a 51.7 F-Score. Our model outper-forms this baseline with an F-Score of 60.24.
This study has shown that it is possible to learn rules from FOL semantic representations using In-ductive Logic Programming to classify rhetorical re-lations. However, it is not yet clear how useful event semantics is for discourse parsing. In the future, we intend to extend our model to incorporate syntactic and lexical information as well. Such an extension will allow us to assess the contribution of event se-mantics. 4.2 Building Discourse Parse Trees In addition to extending the rhetorical relation clas-sifier, our future work will involve building the dis-course parse tree at the sentence level and at the doc-ument level. At the document level, the input will be the sentence level discourse parse trees and the output will be the discourse structure of the entire document.

When combining two text segments, promotion sets that approximate the most important EDUs of the text segments will be used. As a starting point, we propose to build sentence level DPTs bottom-up. EDUs that are subsumed by the same syntactic con-stituent (usually an S, S-Bar, VP) will be combined together into a larger text segment recursively until the the DPT at the root level has been constructed. At the document level, the DPT will be built us-ing a shift-reduce parser as in Marcu (2000). How-ever, unlike Marcu (2000), there will only be one shift and one reduce operation. The reduce oper-ation will be determined by the rhetorical relation classifier and an additional module that will deter-mine all the possible attachment points for an in-coming sentence level DPT. An incoming sentence level DPT may be attached to any node on the right frontier of the left DPT. Lexical cohesion will be used to rank the possible attachment points. For both sentence level discourse parsing and document level discourse parsing, the rhetorical relation classifier will be used to determine the informational relation between the text segments. In conclusion, this thesis will provide a computa-tional model for parsing the discourse structure of text based on informational relations. Our approach exploits event semantic information of the EDUs. Hence, it will provide a measurement of how helpful event semantics can be in uncovering the discourse structure of text. As a consequence, it will also shed some light on the coverage of the lexical resources we are using. Other contributions of our work in-clude a parser that builds event semantic represen-tations of sentences based on rich verb semantics and noun semantics and a data driven automatic dis-course segmenter that determines the minimal units of discourse.

