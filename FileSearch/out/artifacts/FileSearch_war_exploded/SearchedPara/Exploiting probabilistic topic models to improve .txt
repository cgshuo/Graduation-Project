 1. Introduction
Text categorization/classification ( Sebastiani, 2002 ) is a common technique for automatically organizing documents into predefined categories. While existing text categorization techniques have shown promising results in many application sce-imbalanced class distributions remain a challenging research issue.
 fact Yang and Liu (1999) compared the robustness and classification performances of several text categorization methods such as Support Vector Machine (SVM), Naive Bayes classifier, and K-Nearest Neighbor (KNN) classifier on data sets with var-rare classes. A promising direction to handle the class imbalance problem is applying re-sampling techniques. Specifically, over-sampling techniques ( Japkowicz, 2000 ) can be used to increase the number of data instances in rare classes and under-ultimate goal is to adjust the sizes of classes to a relatively balanced level.
 Although both over sampling and under sampling can alleviate the class imbalance problem, there are some side effects. be missing due to under sampling. This, in turn, will hinder the classification performance. Therefore, many modified re-sampling methods were developed to overcome the disadvantages described above. For example, the overfitting problem in random over-sampling methods can be avoided to a certain extent by bringing in random Gaussian noise to samples performance than random under-sampling methods can be achieved by only eliminating samples that are further away from class boundaries ( Batista, Prati, &amp; Monard, 2004 ).

As a matter of fact, most re-sampling techniques were developed for general types of data rather than for text. Our ap-proach intends to exploit the semantic characteristics uniquely existing in text documents to improve text categorization under class imbalance. New samples of rare classes are generated by using global semantic information of classes repre-smoothed and the impact on the classification performance by noisy samples will also be alleviated.

In this paper, we propose two re-sampling methods based on probabilistic topic models: DECOM (data re-sampling with probabilistic topic models) and DECODER (data re-sampling with probabilistic topic models after smoothing). DECOM deals with class imbalance by generating new samples of rare classes using probabilistic topic models. In addition, for data sets with a high proportion of noisy samples, DECODER first smoothes data by regenerating all samples in data sets and then gen-that both DECOM and DECODER can achieve better classification performances on rare classes. Also, DECODER is more robust in handling very noisy data.

Overview : The remainder of this paper is organized as follows. Section 2 introduces probabilistic topic models as well as two re-sampling methods based on probabilistic topic models. In Section 3 , we present experimental results on a number of real-world document data sets. Section 4 describes some related work. Finally, we draw conclusions in Section 5 . 2. Re-sampling with probabilistic topic models
Then we propose two re-sampling methods: DECOM and DECODER. 2.1. Probabilistic topic models
Probabilistic topic models are generative models that specify a probabilistic process for generating documents. Table 1 for each word token in this document, a topic is selected randomly by sampling from the distribution over topics and next a word is selected randomly by sampling from the word distribution of this topic.

Fig. 1 illustrates the generation of documents by probabilistic topic models. There are only two topics containing a certain number of words in this simple example. The distribution of topics is different in different documents. For example, topic 2 word  X  X  X oney X  is selected. For the second word, topic 1 is selected again randomly and the word we get this time is  X  X  X ank X . words in DOC2 can be decided.

We adopt the probabilistic topic model proposed in Steyvers and Griffiths (2007) as the generative model for training samples. We use P ( w ) to denote the probability of generating the current word w where T is the number of topics.
 the i th topic from the topic distribution of the current document.

Given a collection of D documents containing T topics expressed over W unique words, we represent the word index with w and document index with d i for each word token i . Here  X  X  X ord token X  refers to an instance of a word at a certain position topic is sampled from this conditional distribution and then stored as the new topic assignment for the word token. We rep-resent this conditional distribution as P ( z i = j | z i other word and document indices w i and d i , and hyperparameters a , and b . Griffiths and Steyvers (2004) shows that this probability P ( z i = j | z i , w i , d i , ) can be computed by the following equation: where C WT and C DT are matrices with dimensions W T and D T respectively. C sampled from topic j , not including the current token i , and C distribution for document d i . The Gibbs sampling algorithm begins with the assignment of each word token to a random to-for the chain to approach the target distribution, the current values of the z mated by: 2.2. Re-sampling with probabilistic topic models
In this study on text categorization, we assume that documents belonging to the same class have the same topic distri-Hence if we generate a new document using the topic model of a class, the new document should still belong to this class.
Based on this assumption, we propose two re-sampling methods DECOM and DECODER based on topic models for different situations. Assuming that the training samples belong to n classes C ={ c m , ... , m n } for each class can be extracted from the documents belonging to each class by the Gibbs sampling algorithm, respectively.
 Algorithm 1 : GenerateSample( M , N )
Algorithm 2 : Roulette(Pro) 2.2.1. DECOM
The number of samples in the largest class is denoted as MAX . For any other class c new samples are generated by the corresponding topic model. Then the new samples of each class are used together with the 2002 ), the generation of new samples by the topic model is based on the whole sample space, not just several local samples. The process of generating new samples by topic models is presented in Algorithm 1 and Algorithm 2. Specifically, for each word token in a new sample containing N words, a topic T i of topic T i . By this way, all words are selected and they compose the new sample document. For each class, the size of the new sample N (in terms of words) is randomly picked from the distribution of the sizes of documents in this class. 2.2.2. Data smoothing
All samples in the training data are assumed to be labeled without any errors. However, in reality it is labor-intensive to samples. For this reason, topic models can be used to smooth the available training samples and to reduce the impact of noisy samples on the performance of classification. Before training the classifier, | c affected by the noisy samples. As shown in  X  X  X esult 1 X  some samples in the blue class are mislabeled as the red class when 2.2.3. DECODER
For data sets with a high proportion of noisy samples, the DECODER method, a modified version of DECOM, is proposed. In this case, the original data is replaced by the same amount of new samples generated by topic models. After this phase, the as that of class 2. 3. Experimental evaluations In this section, we evaluate the effectiveness of the proposed DECOM and DECODER re-sampling methods in two stages.
COM and DECODER in improving the classification performances on rare classes. In the second stage, we evaluate the per-formance of DECODER on very noisy data. 3.1. The experimental setup SVM is adopted as the base classifier in our experiments because of its good performance in most cases ( Cristianini &amp; Shawe-Taylor, 2000 ). The implementation of SVM used in this study is LIBSVM ( Chang &amp; Lin, 2001 ) and the parameters of
SVM are set as follows: linear kernel, the parameter gamma in kernel function and the parameter C of C-SVC is obtained automatically by grid-search using cross-validation for each data set as shown in Table 2 , and other parameters are set as default. The IG (Information Gain) feature selection algorithm is used to select the top 1000 words as features. The param-methods ( Maimon &amp; Rokach, 2005; Tan, Steinbach, &amp; Kumar, 2005 ): random over sampling (ROS), random under sampling (RUS) and SMOTE ( Chawla et al., 2002 ). Note that we run all methods 10 times and return the average results in our exper-ments are from three sources as shown in Table 2 . CV indicates the dispersion of the class distribution for each data set. In general the larger the CV value is, the more unbalanced the data is.

The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned nearly evenly across 20 different topics. For the purpose of studying class imbalance, we reduce the size of some classes artificially in
The documents in the Reuters-21578 collection appeared on the Reuters newswire in 1987. The data was originally collected and labeled by Carnegie Group, Inc., and Reuters, Ltd. in the course of developing the CONSTRUE text classification system. in the subject hierarchy of Yahoo!. The RCV1-v2 data set is a large corpus of newswire stories provided by Reuters Ltd. and later corrected by Lewis, Yang, Rose, and Li (2004) . We use a sample of 20402 documents belonging to five categories and refer to it as RCV1-v2_t5. 3.2. Experimental results
In this subsection, the experimental results show how the classification performance can be improved by DECOM. Since data set without other sources of interference. For comparing the balancing methods more accurately, we conduct experi-class data sets. The results on multi-class data sets are consistent with those on two-class data sets. 3.2.1. Results on two-class data sets
Table 3 presents the performance comparison based on the F-measure with other balancing methods on two-class data sets. DECOM shows a good performance on two-class data sets on various data sets. When the CV value is low, random under sampling has a better performance than random over sampling. For example, on the reuters3 data set with CV value of 0.530, under sampling has a competitive performance close to the best result achieved by DECOM. However, when the CV becomes high, over sampling beats under sampling significantly. The SMOTE method has limited improvement because new samples are related to a few local samples as we discussed above. Note that on reuters2 data set, DECODER has better performance than DECOM. An alternative explanation is that there exits some noisy samples in this data set. Compared to pure SVM, the large classes are improved by DECOM. Large improvement of the recall value or precision value can be achieved with a little cost of decreasing the other one. For example, the recall value of class 1 in 20news_b1 data set is improved from 0.6000 to 0.9920 while the precision value is decreased just from 0.9677 to 0.9094. 3.2.2. Results on multi-class data sets
An overview of macro F-measure comparison of these methods is shown in Table 5 . In this case, random under sampling does not perform well on multi-class data sets. DECOM still performs better than other balancing methods although the improvement by DECOM is not as large as on two-class data sets in some cases. Besides DECOM, random over-sampling method also has stable performance on all data sets while random under sampling and SMOTE are not so stable. The results in the table show that DECOM is more robust on multi-class data sets than others.

Another observation is that the increase of the F-measure value of the rare classes is not at high cost of the decrease of others. As shown in Fig. 5 , different from other traditional balancing methods such as random over sampling, DECOM can improve the classification accuracy for most classes. For example, the performance of about 83% classes is improved by DE-
COM on reuters6 data set while it is only 60% for random over sampling. Fig. 6 shows how DECOM improves performance for only 59 samples is greatly increased by DECOM while only the performance in class 6 is decreased slightly. On k1b data set, all performance of DECODER is a little weaker than DECOM because some information useful for classification may be lost in the data smoothing phase.
 The number of topics in topic models ( T ) is an important parameter that may affect the performance of classification. likelihood is affected by T greatly. It is difficult to find the best value of T in DECOM since the value with optimal likelihood P ( w | T ) may not always result in the best classification performance. In fact, the best value of T for DECOM is distinct on different data sets. Fortunately, the impact that T has on the classification performance is limited. Fig. 7 shows the macro F-measure with different values of T on 20news_m2 and reuters3 data sets. Obviously, the impact of
T is small and acceptable. 3.3. Tolerance to noisy samples
As we discussed in Section 3.2 , the data sets may have noisy samples. Even if all training samples are labeled correctly, some samples are important for classification while some samples are unimportant. Table 7 shows an interesting result that DECODER can improve the performance on balanced data set 20news_b2. In this case, DECODER does the same thing as pure with DECODER.
Although there may be some noisy samples in the data sets used in this paper, the number of noisy samples could be reason, we have preprocessed the data sets so that they can be suitable for noise tolerance experiments. In order to inves-tigate the tolerance of each method to noisy samples, we get three two-class data sets from 20 Newsgroups data sets and
Reuters-21578 data sets intentionally, as shown in Table 8 . Some samples are removed from one class and are used to ran-achieved by the balancing methods are shown in Fig. 8 . On 20news_b21 data set, DECODER has slower performance decrease with increasing ratio of noisy samples than pure SVM. Even when the noise ratio is 50%, a macro F-measure of about 87% can be achieved. On reuters8 data set, when the noise ratio is under 5%, DECOM can achieve a better performance than DECODER since replacing the original samples may lose the information which can be helpful for classification. However, with the noise ratio increasing, the performance of DECOM becomes worse and only DECODER still has a stable performance. On
RCV1-v2_t5 when the noise ratio increases from 0% to 50%, the performance decrease of DECODER is only 3% as measured by F-measure, in comparison to more than 40% for all the other approaches. In order to make more natural multi-class data with noisy samples and the macro F-measure reflects the amount of noise in the training set. Now this noisy training set is on 20news_m1 data set is shown in Table 9 . Due to data smoothing, the performance decrease of DECODER is much slower than others when the macro F-measure of unlabeled data set is decreasing. 4. Related works
The class imbalance problem is a major research issue, and researchers have addressed this problem from various perspectives.

First, there are research works focusing on understanding the class imbalanced problem. For example, it has been shown cepts in the data sets with imbalanced classes. The higher the degree of class imbalance, the higher the complexity of the performance.

Second, researchers have addressed the class imbalance problem from an algorithmic perspective by examining how different algorithms or algorithm design decisions can make an impact on this problem. For example Brank and Grobelnik (2003) studied the training of SVMs with few positive samples, while Tan (2005) presents the NKNN method which im-proves the performance of k-NN on imbalanced data sets. Also, Zheng, Wu, and Srihari (2004) addressed the class imbal-ance problem by feature selection and suggested that negative features are quite valuable on imbalanced data. Moreover, the COG method ( Wu et al., 2007 ) has an elegant way to decompose the complex concepts in large classes, which hinder the performances of linear classifiers. In the COG method, each large class is divided into several small sub-classes with relatively balanced sizes. This, in turn, can greatly alleviate the class imbalance problem and helps to improve the performance.

The third direction is to manipulate the training data using sampling techniques, such as random over sampling, focused over sampling, random under sampling, and focused under sampling. For example, researchers have developed methods ( To-mek, 1976; Hart, 1968; Kubat &amp; Matwin, 1997; Laurikkala, 2001; Wilson, 1972 ) of under and over sampling to balance the class distribution of training data. According to experimental evaluation of these methods and their combination, Batista et al. (2004) found that, in general, over-sampling methods provide more accurate results than under-sampling methods con-ses in simple over sampling, Chawla et al. (2002) proposed SMOTE method (Synthetic Minority Over-sampling TEchnique). neighbors of A is selected randomly as B. The value of new sample is the value of A plus a Gaussian random value of the difference between A and B. The SMOTE method overcomes the overfitting of over sampling to a certain extent. However, the generation of new sample is just dependent on a few samples so that noisy samples may have more impact on the clas-sification performance.

However, the above-mentioned approaches do not make use of semantic information, which is essential to text docu-ments. Instead, in this paper, our focus is on exploiting global semantic information of classes, which are represented by probabilistic topic models. The scope of our methods is limited to text categorization.
 5. Conclusion
In this paper, we have proposed a semantic re-sampling method to handle the class imbalance problem in text catego-rization. Specifically, two re-sampling techniques DECOM and DECODER were developed based on probabilistic topic mod-els. DECOM was proposed to deal with class imbalance by generating new samples of rare classes. For data sets with noisy samples and rare classes, DECODER was developed to smooth the data by regenerating all samples in each class using prob-abilistic topic models and then expanding the sizes of rare classes.

A key idea of our re-sampling techniques is the exploitation of global semantic information captured by probabilistic to-pic models. Experimental results on various real-world data sets show that DECOM and DECODER can achieve better clas-sification performances on rare classes. In addition, DECODER is more tolerant to noisy samples.
 Acknowledgements
The authors wish to thank the reviewers for their invaluable comments. The work described in this paper was supported by grants from Natural Science Foundation of China (Grant No. 60775037), the Key Program of National Natural Science
Foundation of China (Grant No. 60933013), the National High Technology Research and Development Program of China (No. 2009AA01Z123) and Research Fund for the Doctoral Program of Higher Education of China (20093402110017). References
