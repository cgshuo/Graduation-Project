 We study the problem of online classification of user gen-erated content, with the goal of efficiently learning to cat-egorize content generated by individual user. This prob-lem is challenging due to several reasons. First, the huge amount of user generated content demands a highly efficient and scalable classification solution. Second, the categories are typically highly imbalanced, i.e., the number of samples from a particular useful class could be far and few between compared to some others (majority class). In some appli-cations like spam detection, identification of the minority class often has significantly greater value than that of the majority class. Last but not least, when learning a classi-fication model from a group of users, there is a dilemma: A single classification model trained on the entire corpus may fail to capture personalized characteristics such as lan-guage and writing styles unique to each user. On the other hand, a personalized model dedicated to each user may be inaccurate due to the scarcity of training data, especially at the very beginning; when users have written just a few articles. To overcome these challenges, we propose learning a global model over all users X  data, which is then leveraged to continuously refine the individual models through a col-laborative online learning approach. The class imbalance problem is addressed via a cost-sensitive learning approach. Experimental results show that our method is effective and scalable for timely classification of user generated content. H.3.3 [ Information Search and Retrieval ]: Information Filtering; I.2 [ Artificial Intelligence ]: Machine Learning Experimentation online learning, classification, imbalanced class distribution our algorithm against batch learning methods that are up-dated periodically, to show that ours are not only orders of magnitude faster, but also equally effective for the UGC classification task.

The rest of this paper is organized as follows. Section 2 introduces related work. Section 3 presents the proposed algorithm. Section 4 gives experimental results and discus-sions. Section 5 concludes this paper.
Unlike typical machine learning methods, which assume all training examples are available before the learning task begins, online learning is more appropriate for some real-world problems where training data arrives sequentially. It has been extensively studied in the machine learning com-munity [14, 12, 13, 9, 8]. Moreover, the vast majority of existing work in online learning only studies the predic-tion mistake rates or accuracies, without regard to class distributions or actual classification accuracies. Notably, methods that perform seemingly well on balanced datasets may not perform well on real-world imbalanced datasets [1, 7]. As a result, such performance evaluations are not al-ways appropriate for real world applications, where datasets are often imbalanced. To address class-imbalance problem, a multi-class cost-sensitive extension to the original online passive aggressive algorithm has been proposed by Cram-mer et al. [8], along with theoretical loss bounds. Our work extends Crammer X  X  approach by adding the collaborative learning element.

Our work is also related to learning multiple related tasks in parallel. Multi-task learning solves multiple related learn-ing problems simultaneously instead of independently. Em-pirical evidence shows that multi-task learning can improve classifier X  X  performance [3, 4, 5]. Ando et al. [2] consid-ered learning predictive structures on hypothesis spaces from multiple learning tasks. Evgeniou et al. [10] extended the single-task kernel learning methods to multi-task learning by defining a family of multi-task kernel functions. Instead of defining specific kernel functions, we use a generic model shared by many parallel learners to leverage the information embedded in individual tasks. Our approach not only enjoys an improvement on classification performance, but also re-tains the hallmark low computational cost of online learning algorithms.
Figure 1 illustrates the idea of collaborative online learn-ing. Our method operates in a sequential manner. At each learning round, it collects the current global set of data; one from each of the engaged users, which are employed to update the global classification model. At the same time, a collaborative personalized model is maintained for each user. The individual collaborative classification model is subsequently updated using the latest individual data and the global model X  X  parameters.

For simplicity, we assume that the training data from all users can be represented in a global feature space and the sequence of training data is ordered chronologically. Denote by ( x t ,y t ) a training instance at round t ,where x t  X  R d is a d -dimensional vector representing the example and y t  X  { 1 ,...,m } ,m  X  3 refers to its class label. Further, denote by D i = { ( x t ,y t ): t =1 ,...,T i } a collection of training
A critical step of our algorithm is to apply the existing global model to collaboratively learn the individual model foreachofthe K users. Using the same PA formulation, the goal is to learn a classification model for the i -th user as where w ( i ) t  X  R dm is the weight vector of the i -th user X  X  model learned at round t . To ease the discussion, we shall use w t to denote w ( i ) t henceforth.

We formulate learning the collaborative model as a con-vex optimization problem that minimizes the deviation of the new weight from the prior collaborative weight and the global weight, as follows where  X  1 and  X  2 are regularization parameters that balance the tradeoff between the global model u t and the collabora-tive model w t , and parameter C  X  0 controls the influence of the slack variable  X  on the objective function.
The above formulation aims to achieve a balance between the global and individual models, i.e., in spite of its unique-ness, each individual also shares some commonness with other members in the group. It coherently combines the collaborative model with the global one. In particular, if we set  X  2 = 0, the optimization reduces to the approach of learning an individual classification model without engaging the global model; if we set  X  1 = 0, it reduces to the global model. Accordingly, we can fine tune the contribution of each model by setting appropriate parameters.

Applying the Lagrangian multiplier technique, the update rule for optimization problem (5) can be derived as where  X  is given by
To alleviate the class imbalance problem, we define a new loss function that assigns a penalty for rare class higher than that for majority class, as follows where  X  i  X  1 ,i =1 ...m are biased penalties setting in inverse ratio to the amount of the i -th class.

By replacing the loss function in (5) with this, we obtain the cost-sensitive collaborative online learning optimization problem. The update rule has the same form as equation (6), and  X  is given by  X  =min C,  X  i (  X  1 +  X  2 )
Finally, Algorithm 1 summarizes our approach. It is clear that the algorithm has linear time complexity with respect to the number of instances and dimensions, which is not dif-ferent from typical online learners. In terms of space com-plexity, for a group of K users, in addition to a set of K collaborative models, it only needs to keep an extra global
We adopt the cumulative error rate , i.e., the ratio of the number of mistakes made by the online learning algorithm over total number of examples received up-to-date as a met-ric for comparing different algorithms. Despite its extensive usage in online learning studies, the cumulative error rate is not suitable for evaluating performances on class-imbalanced datasets. Because for a highly imbalanced dataset, it is pos-sible to deploy a trivial classifier (i.e., blanket prediction of the majority class) that has low error rates but actually is of little use. We thus report the F1-measure in addition to cumulative error rate. It is typically harder for a classifier to achieve a good F1-measure compared to error rate on an imbalanced dataset. For simplicity, we fix the parameter C to 1 for all PA variations and our algorithm. We also fix  X  2 to 1 and only choose  X  1 from a small range of values.
We apply online collaborative learning to construct effec-tive personalized spam email filters. The task is to classify each new incoming email message into two categories: le-gitimate or spam . We use a dataset hosted by the Inter-net Content Filtering Group 2 . The dataset contains emails collected from the mailboxes of four users (denoted by pu1 , pu2 , pu3 ,and pua ). Strictly speaking, the set of all emails re-ceived by a user is not generated per se by that specific user. However, the characteristic of each user X  X  email can be said to match his or her interest, whatever that may be. Each email entry is converted to a word document vector using the TF-IDF (term frequency-inverse document frequency) representation. Table 2 summarizes the characteristics of this dataset.

Since the email dataset has no time stamp, each user X  X  email was shuffled into a random sequence. The cumulative http://labs-repos.iit.demokritos.gr/skel/i-config/
Lastly, Table 3 shows that COL is slightly slower than the original PA algorithm. This is expected since COL has to update one global model. However, for a group of users, only one group model is needed. The extra computational cost is trivial compared to the combined cost to update every user model. Therefore, the proposed COL algorithm is efficient and applicable for solving large-scale problems.
 Table 3: Run-time (in seconds) for each algorithm
With the growing popularity of micro-blogs like Twitter 3 comes the demand to understand their users. We present an interesting problem, namely the micro-blog sentiment analysis, which aims to automatically classify each micro-blog post into three categories: positive emotion , negative emotion ,and non-emotional . This problem is challenging because a micro-blog post is often very short and each per-son may have his/her unique way of expressing sentiments. Moreover, the proportion of emotional posts is typically very small, and varies across individuals. Ideally, a personalized classifier should be created for each micro-blogger. However, there is a dearth of training data for each user, making the personalized sentiment model vastly inaccurate unless the model has been trained over hundreds of micro-blogs.
Aposton Twitter is called a tweet. We crawled 7131 tweets written by six influential users according to wefol-low.com 4 . The latest tweet in our dataset was published in May, 2010, and the oldest one was in February, 2008. Each tweet was converted to a word vector using the TF-IDF representation. A human annotator was employed to label tweets as one of three categories: positive emotion (class 1), negative emotion (class 2), and non-emotional (class 3). Ta-ble 4 summarizes the labeling result. We can see that on average, 20-30% of a user tweets are sentimental (belonging to positive or negative emotion). This result matches our conjecture that emotional tweets are generally a minority for Twitter users.

The experimental results are reported in Table 5. For fairness, cost-sensitive learning is also applied to SVM and LIBLINEAR via setting a larger penalty parameter C for the minority classes. To make a clear comparison between collaborative online learning and PA algorithm, we show the variation of their cumulative error rates along the en-tire online learning process in Figure 3. The biased penalty parameters for CS-COL are set to  X  1 = 25,  X  2 = 50, and  X  = 1 for class 1, 2, and 3, respectively. http://twitter.com http://wefollow.com competitors for most cases, again verifying the effectiveness of the proposed technique for online micro-blog sentiment classification.
In this paper, we proposed a collaborative online learning algorithm that is able to take advantage of individual and global models to achieve an overall improvement in classifi-cation performance for processing UGC of a group of users. We showed that it is possible to outperform both the global and personal models by coherently integrating them in a unified collaborative learning framework. The experimental results show that our algorithm is both effective and effi-cient for online spam email filtering. For the micro-blog sentiment classification task, the cost-sensitive mechanism of CS-COL produced improvements to the classification of both positive and negative emotional tweets, however, at the slight expense of the majority class (F1-measure reduced from 79.08% to 63.43%). From a theoretical standpoint, this is a serious trade-off. In practice, users will be happy if the system can accurately predict positive and negative emotions, even if it performed poorly on the non-emotional tweets. Moreover, despite the significant improvements, the overall F1-measure of both the positive and negative class tweets still have a long way to go, as both are extremely low at around 25%. In conclusion, our collaborative online learning is a significant first step towards a more effective online user-based classification method.
This research was supported in part by Singapore Min-istry of Education X  X  Academic Research Fund Tier 1 grant RG30/09. [1] R. Akbani, S. Kwek, and N. Japkowicz. Applying [2] R. K. Ando and T. Zhang. A framework for learning
