 1. Introduction
The internet has become an integr al part of the human life. People spend much of their time connec ted to the internet and they are exposed to danger from hackers and intruders. Reliable and secure countermeasures are required to protect their data. Intrusion detec-tion systems (IDS) are powerful security solutions that operate inside a fi rewall or another security system to report intrusions.
The human immune system (HIS) i s like an intrusion prevention system that protects the human body from bacteria and foreign entities. An arti fi cial immune system (AIS) is inspired by the human immune system and uses algorithms derived from human immune system organs. Clonal selection algorithms and immune network are two of these algorithms that increase the detection rate by com-muning between detectors to improve the population.

Distributed systems can solve complex problems using colla-borative agents. Each agent can sense a problem by observation and help other agents to solve huge and complex problems. Virtualization is useful for distributed systems because it allows one computer to appear to be multiple computers ( Fenn et al., 2008 ). Virtualization can be performed in operating system using hypervisor system software ( Kivity et al., 2007 ). A hypervisor is a virtualization manager that creates and runs virtual machines so a guest OS can boot up in each virtual machine. Virtualization can arrange or control a desired target using Orchestra. Orchestration is a  X  paradigm that supports cloud providers when arranging, coordinating, and managing computing resources as a system of components and automated work fl ows that can be delivered as cloud services to cloud consumers  X  ( ODCA Master Usage Model, 2012 ).

MAIS-IDS is proposed as a hybrid anomaly IDS that analyses both system-setting and network traf fi c. The network analysis is done at the virtual machine level. The hypervisor is KVM and three virtual machines run on it. Each virtual machine has agents to perform clonal selection algorithm to improve their populations. These agents use the immune network algorithm to communicate with each other and distinguish better individuals . The agents of each virtual machine collaborate with other agents using Orchestra. Experimental results show that MAIS-IDS has higher recognition accuracy by collaboration between virtual machines than individual works. 2. Literature review
One de fi nition of intrusion detection is the process of monitoring events on a computer system or network and analyzing them for signs of intrusion, which are attempts to compromise con fi integrity, and availability, or bypass the security mechanisms ( Brown et al., 2002 ). Nazer and Selvakumar (2011) have described the architecture of a simple IDS using different criteria ( Farid et al., 2009; Afzali Seresht et al., 2012; Balasubramaniyan et al., 1998;
Lazarevic et al., 2005; Axelsson, 2000 ). This system architecture changes from centralized systems to distributed ones. ( Lazarevic et al., 2005 ). Agents are used in distributed IDSs and possess speci fi c characteristics ( Lam, 1999 ). They are applied in industrial, joinery, network, medical, and didactic usages. Each has a structure formed according to its task. The main and common structure components are mentioned in ( Morikawa et al., 2001 ).
Morikawa found that these agents require learning techniques to improve ( Morikawa et al., 2001 ). AIS is a powerful learning paradigm with four main algorithms: negative selection, clonal selection, immune network, and danger theory ( Ramakrishnan and Srinivasan, 2009; Azmi and Pishgoo, 2013 ).
 classi fi ed based on these algorithms. The fi rst group of studies uses a negative selection algorithm. There are many members of this group because of the similarity of anomaly detection with the human immune system. In anomaly detection, normal behaviors are modeled; in the immune system, the self-cells are recognized and analyzed in the self-region. The negative selection algorithm can easily remove the detectors from this self-area.
 nicate and contribute with each other in 3 system layers to detect, identify, and remove malicious code from the system. The con-versations of their system are based on agentMOm framework developed by the AFIT Agent Research Group ( DeLoach, 1999 ). In similar work, Zhang et al. (2005 ) proposed an immune agent system consisting of C, B and M agents. The C-agent is the core of the model. The B-agent (random detector) matures by negative selection using admin and M-agent feedback. In this model, mobile agents travel from one host to another in a network and monitor foreign invaders.
 each computer generates diverse agents that are shared with other computers on the LAN. This sharing contributes to the diversity of the agents. User-speci fi c agents are generated for every user on each computer; each agent has a unique pro fi le that is presented by a parameter of the detection method. Another example of the combination of negative selection and the MAS approach is the research reported by Zhongmin et al. (2007 ). They detected and analyzed the data of a network packet captured by the monitored host in the LAN environment. Their state-full agents were mobile and migrated to other hosts and mature detector agents are reactivated by visiting non-self data.
 form the duties of a single security detector and communicate with neighboring agents to share information and inferences. The main task of these detectors is to monitor the routed and over-heard packets and build a model of the normal/abnormal behavior of the system. The neighborhood approach was also used by Le
Boudec and Sara fi janovi  X  (2004 ). They considered the nodes in mobile ad-hoc networks as agents that are fi xed and can monitor their neighbors; they collect one protocol trace per monitored neighbor. A misbehaving node was detected after the learning phase using a heuristic threshold.
 as an evolutionary algorithm that makes powerful agents. The clonal selection algorithm is used to create ef fi cient agents population by cloning and mutating pro fi cient agents and remov-ing others. Machado et al. (2005) used mobile agents and dependent agents to combine desirable characteristics. In their work, agents monitor, distribute, store, persist and react to event fi les originating from the log check in some agency. Their clonal selection algorithm avoids mutation and only employing cloning as a copy process.

Yang et al. (2009 ) proposed a hierarchical structure of the intelligent agents to decrease the latency of redundant commu-nication, avoid network transmission of intermediate data, and complete the overall task more quickly than a traditional client/ server solution. The high level structure is composed of manager, analyzer, sensor, alert, and message agents. Mobile agents move from one host to another, learn from experience, continuously self-learn, and cooperate.

Jiang and Chang (2010 ) proposed a security system and de immune cells as agents. These agents can detect and reject intrusion by cooperating. They are generated dynamical in a network environment and individually gather information from a network or process level in a computer. These agents observe the non-self process at network level and cooperate with other immunity agents at process level to remove processes identi as non-self that constitute a route of intrusion and all fi executed by the intrusion.

Rosaci and Sarn  X  (2011, 2013) allowed users to increase their own satisfactions. Agents were cloned and selected by user request and a user can evaluate the clones of agents to compare their performances with those of his/her current agents and adopt them. The strategy behind these agents is based on a reputation model where the cloned agent inherits the reputation of its parent agent and will autonomously evolve in its own environment. The cloned agent will use its learning capability and reputation to increase and improve its skills.

Some researchers such as Luther et al. (2007 ) have adopted both negative and clonal selection approaches. Luther has pro-posed AIS agents as a set of detectors obtained by negative selection during a training phase and exchanged status informa-tion and detectors on a periodical and event-driven basis, respec-tively. The cloning and mutation were done based on detector agent counter amount. These AIS agents collaborate to achieve better detection performance by sharing detection results and their own statuses in the P2P infrastructure.

The third group uses the danger theory algorithm. Although this algorithm was proposed about 10 years ago, it has many contributors. Researches simulate danger signals and dendrite cells to increase agent differentiation and agent learning and decrease false alarms. Ou ( 2011 ) used agents called Ag, DC and
TC in his model to implement dendritic cell functionality. These agents coordinate to exchange virus detection information. This model is similar in nature to the DC agent that is based on observed functionalities of natural DCs that monitor host tissue for evidence of cell damage. DC agents in this model evaluate antigens and their corresponding signals using the TC agent to determine whether the antigens are malicious. The TC agent categorizes antigens according to the (updated) threat pro
Ou (2012 ) proposed an agent-based IDS based on the previous model in ( Ou, 2011 ). Dendrite cell agents were also used by
Greensmith et al. (2008 ) as a DCA population that each DCA representing an individual dendrite cell that can fuse signal input to produce its own signal output.

Mohamed and Abdullah (2010 ) proposed a secure approach using a mobile agent that was well-prepared with a required database. The agent consists of fi ve processes that assess different scenarios in the wireless ad-hoc domain, and the monitoring, detection, classi fi cation, blocking/isolation, and recovery parts.
This agent is con fi gured to take a snapshot of a data recovery when successfully attached to a new node that intends to join the wireless domain. This intelligent agent contains the gene pro non-self pro fi le, and detector pro fi le. They are distributed to all nodes inside the domain upon connection.
 The last group of research uses an immune network algorithm.
This algorithm improves agent communication, but has had few contributors. Chang and Zhu ( 2011 ) used this algorithm in a limited fashion as a starting point. Their system is composed of fi ve agents in each host that coordinate, distribute and cooperate to detect intrusions. For self-security, the agents send keep-alive messages to their neighborhoods. The immune algorithms are used in the sandbox, study unknown intrusions and generate rules used to detect intrusion.

Table 1 is a review of the related works; agent characteristics are listed in Table 2 . The bene fi ts of clonal selection and immune network algorithms were used to create ef fi cient agents with good communication. The immune network algorithm and hybrid approach are rarely used in this fi eld, making the proposed system a novel one. 3. Proposed system 3.1. System architecture
Virtualization is a hot topic in operating systems and a hypervisor is responsible for the management of multiple virtual machines ( Bressoud and Schneider, 1996 ). This process requires controls that are provided by Orchestra. Orchestration is the automated management and arrangement between organizations and individuals.

KVM is a type of hypervisor that runs on bare-metal hardware as a normal program inside a normal operating system ( Fenn et al., 2008 ). KVM can create and run multiple virtual machines. With a KVM hypervisor, live migration can be performed between physi-cal hosts with no interruption to service. Fig. 1 shows the proposed architecture with some server in Orchestra and an ejabberd client in other hosts.
 Linux is the operating system used with KVM as hypervisor. This operating system is free and open source and can be customized by creating kernel modules. These modules are neces-sary to implement agent models in the virtual environments.
In addition to the bene fi ts of KVM, it is compatible and stable in Linux; this stability allows implementation of an agent model more easily. Furthermore, KVM as a virtualization platform sup-port Python languages and can facilitate implementation.
Agents must communicate with each other. Ejabberd is a messaging protocol that enables agents to communicate. It is a distributed platform designed to be a rock-solid and feature-rich
XMPP server. Its bene fi ts include low CPU consumption (important in MAS), stability (clients may crash or bugs accrue, but the server keeps running), its support of both old SSL and new STARTTLS and full compliance with XMPP standard) powered protocol of instant messaging and real-time communication). It is also open, public, secure and free. The XMPP protocol offers a great architecture in which agents can communicate in a structured way, solves issues such as authenticating users (agents) and provides a directory or creates communication channels. 3.2. System components
Three virtual machines were used to implement the proposed algorithm with communication between them. These virtual machines ran on a KVM hypervisor and each was installed on a separate machine connected by a LAN network. KVM is con fi on Linux. Orchestra management is considered to be an agent that manages virtual machine communications. The proposed system has the following agents and subsystems:
Detector agents : These mobile agents identify and recognize non-self-antigens from self-antigens.

Antigen agents : These mobile agents migrate to other virtual machines and transform into detector agents.

Orchestra agent : This is the central agent for managing and controlling communication ( Section 3.2.2.3 ).

The main characteristics of the proposed agents are mobility, adaption, autonomy, cooperation, learning, and coordination.
Mobility moves agents temporarily or permanently (migration) to other VMs. Adaption improves agent behavior and increases the detection rate. Autonomy allows behavior without the help of admin. Cooperation decreases false alarms throughout the LAN.
Learning improves agent behavior. Coordination enables agents to work together. 3.2.1. Subsystems
The host-based subsystems include population control, selec-tion and evaluation subsystems. Since the detector agent popula-tion increases by cloning, a population control subsystem is required to remove weak agents in an equal number to the number of cloned detectors. The memory cells in this subsystem contain ID and fi tness values of detector agents. Using this information, the subsystem kills detector agents having a low level of fi tness to stabilize the population of detector agents.
This subsystem is also employed to control the antigen agent population. In the Orchestra population, a control subsystem is required to control the number of antigen agents and remove those con fi rmed by a few judgment agents. The selection sub-system is used in the detector agents selection phase. This subsystem has a random generator and a comparison operator to select a group of judgment detector agents. This subsystem is also selects the best detector agent.

The evaluation subsystem calculates the fi tness of each detec-tor agent. Each detector agent has a memory that stores the IDs of detected antigen agents. The evaluation subsystem knows the true labels of the detected antigen agents and can determine the of each detector agent based on the number of true labels. 3.2.2. Agent structure characteristics are explained as follows. Mobility helps the MAS system to perform strongly with low numbers of agents. In other words, instead of using many agents across the area, a few mobile agents are used. This movement requires coordination and resource binding, but to decrease resource usage of the proposed
MAS architecture, resource binding overhead is neglected. Agent mobility between VMs results from host migration. Zhang et al. (2005 ), Zhongmin et al. (2007 ), Yang et al. (2009 ), Mohamed and
Abdullah (2010 ) and Rosaci and Sarn  X  (2013 ) have used migration to improve system abilities. In the proposed approach, it is used between virtual machines.
 negotiate transfer information through communication. Commu-nication helps agents to cooperate and collaborate in different ways. Byrski and Carvalho (2008 ) used communications with neighbors and shared information with them. In Luther et al. (2007 ), Ou (2011, 2012 ), and Chang and Zhu (2011 ) collaboration were used to exchange the agent information. Communication plays an important role in the proposed system and this role is explained in Section 4 .

An interesting feature of the proposed agents is autonomy, for which a goal is ascribed and a satisfaction function that rewards when a goal is achieved. There is no central authority, thus, no single point of failure in the autonomous systems ( Harmer et al., 2002 ). Autonomous agents can learn on their own without the help of an administrator or manager. Administrative assistance is useful and can immediately divert agents from faults as done in
Rosaci and Sarn  X  (2013, 2011) in their EVA system. In the real world, solutions are automatically satis fi ed without direct control. Autonomy is a powerful agent character used in Byrski and
Carvalho (2008 ), Yang et al. (2009 ) and Mohamed and Abdullah (2010 ).

The proposed agents are equipped with the following features and can learn based on their fi tness and adaptability: 3.2.2.1. Detector agent. A detector agent is a mobile agent that identi fi es and recognizes non-self-antigens from self-antigens. Each detector agent has a detection radius, counter, and memory cells. The detection radius determines the scan area in which to recognize foreign (non-self) antigens. The counter value is the number of foreign agents identi fi ed in the detection area and memory cells memorize the identity of these foreign agents. Detector agents perform some actions themselves and are subject to modi fi in their life cycles by other agents or subsystems.

Detection radius, counter and memory cells for each detector agent were initialized in the fi rst phase of its lifecycle. Eq. (1) calculates the detection radius using the minimum Euclidean distance and X and Y , respectively, as the coordinates of the detector and self-antigen. M is the number of dimensions and matches the number of data set features. N is the number of self-antigen agents. The minimum distance was calculated to choose the nearest self-antigen agent and used the negative selection algorithm. detectin radius  X  min  X 
In the detection phase, detector agents scan their detection area to discover foreign antigen agents. Each antigen agent is identi a foreign agent and the counter value of a detector agent increases as these foreign antigens are stored in the memory cells.
The evaluation subsystem calculates the fi tness of each detec-tor agent in the calculation phase. This subsystem knows the real label of the identi fi ed antigen agents and the fi tness of the detector agent depends on the real number of identi fi ed foreign antigen. A detector agent that detects a large number of foreign antigens correctly possesses a higher fi tness score than a detector agent which identi fi es them incorrectly. Fitness is proportional to the number of antigens identi fi ed by each detector agent.
In the selection phase, two groups of detector agents are selected. The fi rst group contains only one member, which is the best detector agent with the highest fi tness. If there is more than one agent with the best fi tness, the agent with the highest counter is selected. This detector agent informs other detector agents. The second group contains a number of detector agents that are considered to be informed by the best detector agent. This group is selected randomly by the selection subsystem based on the probability of their counter number. This means that the detector agent with the higher counter has a greater chance of being selected than an agent with a low counter.

In the next phase, the second group clone themselves. These cloned detector agents move near the best detector agent to aid scanning. This movement is like a mutation that randomly changes their locations. In this phase, the population control subsystem is run to fi x the detector agents' number. Detector agents with a low level of fi tness and weak recognition performance are killed in direct proportion to the number of detector agents cloned.
The last phase in the detector agent life cycle is  X  judgment and sort  X  . In this phase, the cloned detector agent judges the antigen agents stored in the best detector agent memory cells. Each judg-ment agents reads the memory of the best detector agent cell by cell, determines the label of the antigen agent and inserts its opinion into the best detector memory cells. This is performed by all judgment agents. Ultimately, the memory cells of the best detector agent are sorted discordantly based on the number of con fi rmations by the judgment agent. The detector agent cycle is illustrated in Figs. 2 3.2.2.2. Antigen agent. Antigen agents are both self and non-self.
Antigens are mobile agents that migrate to other virtual machines if identi fi ed by the best detector agent. The antigen agents have a sensor to detect the alarm of the Orchestra agent. These agents are informed by the Orchestra agent, migrate from one virtual machine to the Orchestra, clone themselves to migrate to other virtual machines and transform into detector agents at the destination virtual machine. This last action describes the polymorphism property of these agents. 3.2.2.3. Orchestra management agent. Orchestra has the role of the static agent comminuting management in the proposed system.
It is informed by detector agents to receive memory cells and then calls the antigen agents that are saved in the memory cells by their IDs. It gathers all antigen agents that have migrated from one virtual machine and sends them to another virtual machine. Afterward, the population control subsystem manages the population of antigen agents. It removes extra agents based on the judgments con fi rmation value. Finally, Orchestra orders the remaining antigens to migrate to a virtual machine. These processes are shown in Fig. 6 . 3.3. Proposed algorithm The proposed algorithm is summarized in pseudo-code form.
As said before, the human immune system is used as a pattern for the proposed algorithm to improve anomaly detection by the agents. A negative selection algorithm is used to determine the detection radius (detection domain) of detector agent, a clonal selection algorithm is used to improve the detector agent popula-tion, and an immune network algorithm is employed for colla-boration between agents.
 virtual machine and in Orchestra. Fig. 7 shows that the algorithm in each VM began immediately after the antigen agents and VM set have been initialized; Before the detector agents begin to work ( Section 3.2.2.1 ). The pseudo-code of the initialization phase is shown in Fig. 8 . In this phase, antigen agents transform into detector agents (if they already received by Orchestra). There is no transformed agent in the fi rst iteration. Other detector agents are created randomly. This initialization phase is shown in Fig. 2 .
The pseudo-code of the detection phase is shown in Fig. 9 . Each agent began its life cycle detection phase as shown in Fig. 2 . The distance between each detector and antigen agent is calculated and compared with its detector radius. If the distance is larger than the detector radius, it means that the antigen is outside the detection area is a self-antigen agent. If it is inside the detector radius, it is recognized as a non-self-antigen and its ID is added to the detector agent memory and the detector agent counter is updated.

The pseudo-codes of the calculation and selection phases are shown in Figs. 10 and 11 , respectively. In the calculation phase, the fi tness of each detector agent is computed by the evaluation subsystem. In the selection phase, two groups include best detector agent and judgment agents are selected. The processes of selection and calculation are illustrated in Figs. 2 and 3 .
Members of the judgment group should be located suitably for judgment. The cloning and mutation processes are employed to locate them in a doubtful area near the best detector agent. Since the number of detector agents is fi xed, weak agents are removed as the same numbers of new cloned agents using the negative selection algorithm. Fig. 4 shows these processes in detail and Fig. 12 shows them in pseudo-code form.

The pseudo code of the immune network algorithm employed in the judgment phase is illustrated in Fig. 13 . In this phase, comments by each judgment agent about non-self-antigen agents are stored in the memory of the best detector agent. After all judgment agents have completed their tasks, the best memory should be organized based on their comments ( Fig. 5 ). The main processes and communication in Orchestra were illustrated in Fig. 14 . 4. Experimental results
The aim of this study was to present the proposed algorithm and system, so only one dataset was used to evaluate MAIS-IDS. The NSL_KDD99 dataset is a version of the KDD Cup99 dataset. Each pattern in this dataset has 38 numeric features and 3 non-numeric features. Only 19 of the most important features were used in this study, as recommended by Farid et al. (2009) . Because of the large size of the dataset, only a portion was used to test the proposed algorithm. The fi nal dataset contained 199 normal and 198 abnormal records.

In an anomaly detection system, a normal and an abnormal set and their labels (normal or abnormal) are required. The normal and abnormal data were fi rst separated, the false data was removed during pre-processing and they were normalized. After this step, each normal and abnormal fi le was split into training and testing sets.

The proposed system was compared with a similar system where there was no communication between the virtual machine agents. The proposed system with communication was hereafter referred to as the distributed system and the proposed system without communication was referred to as the centralized system. The comparison demonstrated the powerful character of agent communication in the distributed system to direct agent behavior in a pro fi table manner.

Agents must learn in both systems. This learning was done using the dataset labels by showing real labels to the agents and removing low fi tness agents. There were 2 steps for an effective learning: agents fi rst learned by the training dataset in and then the testing dataset was used. The test data was split into 2 blocks. The fi rst block was used to improve learning after initial assessment of the trained agents and the second block was employed for fi nal agents evaluation. The last evaluation results were expected to be better than the fi rst stage. Fig. 15 shows the process in diagram form.

At the beginning, learning agents from training phase assigned the label to the fi rst test data block. Then the labels of this data block were shown to these learning agents. This is the learning process in the test phase. After that, these appropriate agents assigned the labels to the second test data block. So an interactive test phase was employed to use the bene fi ts of interaction as one of the natural features of agents.
 (Acc), false alarm (FA) and detection rate (DR). FA is also known as false positive rate and DR is known as true positive rate. Eqs. (2) (4) de fi ne these criteria.
 Acc  X  X  TP  X  TN  X  =  X  TP  X  TN  X  FP  X  FN  X  X  2  X  FA  X  FP =  X  FP  X  TN  X  X  3  X  DR  X  TP =  X  TP  X  FN  X  X  4  X 
TP is the number of abnormal patterns that are recognized as abnormal and TN is the number of normal patterns that are recognized as normal. FP is the number of abnormal patterns that are recognized as normal and FN is the number of normal patterns that are recognized as abnormal. It is clear that the IDS is ideal if
DR  X  1, FA  X  0 and, consequently, Acc  X  1.

The proposed system was tested with different numbers of detector agents using k-fold cross-validation (5-fold). The mean of the proposed algorithm criteria were calculated in 20 independent runs in both the distributed and centralized systems. Figs. 16 and 17 indicate that accuracy in the distributed system was higher than in the centralized system. Since some detectors were gener-ated randomly, the highest accuracy is not necessarily produced by the highest number of detectors, but occurs for a reasonable number of detectors that have not been affected by randomness. Figs. 16 and 17 show that high accuracy can be achieved by using only 12  X  15 detector agents. The accuracy was greater in the second scenario as a bene fi t of training in the test phase.
In the fi rst scenario, agents learned in the training phase; in the second scenario, agents learned in both the training and testing phases. It was expected that agents in the second scenario produce better evaluation results. Figs. 17  X  19 show the ACC and FA for the fi rst and second scenarios. In all fi gures, the horizontal axis is the number of detectors and the vertical axis is the criteria value. Fig. 17 shows that the second test block showed higher accuracy than fi rst test block as a result of training in the test phase. This should occur using a reasonable number of detectors (about 12) because randomness affects higher numbers of detector agents; however, with few detectors, training should be inadequate. Figs. 16 and 17 , by contrast, show that the distributed system produced a nearly straight line with no signi fi cant deviation between small and large numbers of detector agents.

In IDSs, decreasing FA is very important. Assume a system has an IDS with a high FA. This means that for each action, such as opening Microsoft Word or loading a site, the system will be blocked by an alarm. Because this is so disruptive, a user may decide to turn off the IDS. Fig. 18 shows the FAs in the fi and Fig. 19 shows the FAs in the second scenario. As shown, the distributed system had fewer FAs than the centralized system. Overall, the distributed system using about 12 detector agents had the lowest number of FAs. In other words, the ability to commu-nicate in the distributed system increased accuracy and decreased false alarms. t -Tests ( Sheskin, 2007 ) were applied to the ACC, FA, and DR at a 95% con fi dence level. This statistic test was applied to indicate how likely the experimental results were gotten by chance or in other words, how much the experimental results are con fi
The con fi dence level was set to default value (0.95%) so if there was less than 5% chance of getting the observed differences by chance, the null hypothesis would be rejected. Table 3 shows the maximum, minimum, mean and standard deviation of the ACC, FA and DR (out of 20 independent runs) by the proposed algorithm in the distributed and centralized system with about 12 number of detector agents. The t -test was applied to 3 criteria values of proposed algorithm in the distributed and centralized systems. In all of them, the p -value results were less than 0.05.
The performance of the proposed system was appraised using micro benchmarks on a HP DL380 G server with 2 core CPUs and 384 GB memory. The MAIS-IDS consumes about 0.6% CPU and 200  X  300 MB of memory. The network resource usages are related to different detector agent life cycle phases. So, these traf summarized in Table 4 for each phase and based on Orchestra as the server and for each VM. Table 4 shows the results of evaluation with 12 detector agents in each iteration. 5. Conclusion Agents are intelligent entities that operate well in various areas.
The use of agents in an IDS can improve its performance. In an agent-based approach is a mechanism in distributed IDSs where agents handle complex tasks by learning. The human immune system is a successful system that identi fi es foreign aggressors such as viruses or bacteria. The human immune system is similar to anomaly IDSs, thus, a powerful multi-agent IDS will result from modeling the human immune system as an agent learning method. The proposed system, MAIS-IDS, is a multi-agent IDS that uses AIS paradigms to implement powerful agents. An AIS has negative selection, clonal selection, danger theory and immune network algorithms.

Immature agents were generated randomly in the fi rst itera-tion. These autonomous agents learned and improved their populations based on fi tness. The AIS algorithm was used to learn and improve their behaviors. Negative selection was used to remove and kill weak agents. The most powerful agent was the best agent was located in a good area that can detect many foreign antigens. Ultimately, it calls for other agents to help. Cloning can help to create more copy of best agent. These cloned agents used the immune network algorithm and judged antigens stored in the best agent's memory. Due to random nature of clonal selection using judgment and con fi rmation help system to control and overcome many of bad selected antigens using judgment and con fi rmation to control mistakes. useful since there are a lot of common information between VMs.
Intrusions evidence can be also one part of this common informa-tion. Therefore, the informed VM can prevent the damage of intrusion in the other VMs. In the proposed approach, antigens discovered by the best agent, are likely to be common to all VMs. These antigens can used as detector agents in the other VM.
Experimental results show that this cooperation can decrease FA and increase accuracy.
 and network traf fi c. The network of this system was implemented on 3 virtual machines in a KVM hypervisor. Decreasing FA is essential to IDSs. Experimental results showed that MAIS-IDS decreased FAs signi fi cantly using effective multi-agent commu-nication and collaboration between VMs.
 with high loading and complexity that approximates the real environment. Agent features will be increased and optimized and the system will be implemented using a real IDS.
 Acknowledgments (ITRC) for their support of this work.
 References
