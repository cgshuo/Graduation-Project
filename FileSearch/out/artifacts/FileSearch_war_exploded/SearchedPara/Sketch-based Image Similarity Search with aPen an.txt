 We present a novel and innovative user interface for query-by-sketching based image retrieval that exploits emergent interactive paper and digital pen technology. Users can draw sketches with a digital pen on interactive paper in a user-friendly way. The pen is able to capture the stroke vectors and to interactively stream them to the underlying content-based image retrieval (CBIR) system via the pen X  X  Bluetooth interface. We present the integration of inter-active paper/digital pen technology with QbS, our CBIR system tailored to Query-by-Sketching, and we demonstrate the use of the paper and pen interface together with QbS for three different collections: MIRFLICKR-25K, a cartoon collection, and a collection of medieval paper watermarks. H.5.2 [ Information Interfaces and Presentation ]: User Interfaces; H.3.3 [ Information Storage And Retrieval ]: Information Search and Retrieval digital pen, interactive paper, query-by-sketch, CBIR
Content-based image retrieval (CBIR) allows to search in image databases even when no descriptive metadata is at-tached to the individual objects. To overcome the problem of finding appropriate query objects in CBIR, Query-by-Sketching allows users to contribute sketches (mainly edge drawings) as query objects. However, Query-by-Sketching has suffered in the past from the limitations of existing user interfaces. Drawing sketches with a mouse is a highly in-exact method, and even using graphic tablets involves con-stantly looking away from the hand. Methods that combine the functionalities of graphic tablets with those of a moni-tor (e.g., the iPad) are best suited for rather simple gestures and thus do not meet the precision necessary for providing exact sketches. Therefore, the intuitively most promising approach to drawing sketches is to just use a (conventional) pen and paper interface [2].

Figure 1: Execution of Pen-based CBIR Query
Digital pens are designed for drawing on normal paper on which a proprietary Anoto dot pattern is printed. The pens which are equipped with an infrared LED camera can localize the position on paper by reading a 6  X  6 dot area on paper (approx. 1.8  X  1.8 mm in size). Each dot is subject to one of four displacements from a regular grid position, leading to 4 36 different combinations of the 6  X  6 dot area, which is read to identify the pen tip coordinates. The pens store the pattern information in the form of pen stroke data, which are continuous curves made up of coordinates and which are interactively transmitted to the back-end CBIR application (our QbS system, see Figure 1) via Bluetooth.
The QbS system exploits angular radial partitioning for the extraction of features in the user-provided sketch, and also supports the image distortion model and edge histogram descriptors. This combination provides several highly rele-vant invariances that allow the query sketch to slightly de-viate from the searched image in terms of rotation, trans-lation, relative size, and/or unknown objects in the back-ground. The pen and paper interface for the QbS system has been subject to evaluations and user studies [1] with three different collections: i.) the MIRFLICKR-25K photo collection, ii.) a collection of cartoon images, and iii.) a collection of medieval paper watermarks which are used in the humanities to date ancient documents. This work has been partly supported by the Swiss National Science Foundation, projects PAD-IR and MM-DocTable.
