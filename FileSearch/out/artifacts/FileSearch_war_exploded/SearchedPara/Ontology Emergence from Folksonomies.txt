 The folksonomies built from the large-scale social annota-tions made by collaborating users are perfect data sources for bootstrapping Semantic Web applications. In this pa-per, we develop an ontology induction approach to harvest the emergent semantics from the folksonomies. We propose a latent subsumption hierarchy model to uncover the im-plicit structure of tag space and develop our ontology in-duction approach on basis of this model. We identify tag subsumptions with a set-theoretical approach and model the tag space as a tag subsumption graph. While turning this graph into a concept hierarchy, we address the problem of in-consistent subsumptions and propose a random walk based tag generality ranking procedure to settle it. We propose an agglomerative hierarchical clustering algorithm utilizing the result of tag generality ranking to generate the concept hi-erarchy. We conduct experiments on the Delicious dataset. The results of both qualitative and quantitative evaluation demonstrate the effectiveness of the proposed approach. folksonomy, ontology induction, subsumption I.2.4 [ Knowledge Representation Formalisms and Meth-ods ]: Semantic networks; H.5.4 [ Hypertext/Hypermedia ]: Navigation; H.3.3 [ Information Storage and Retrieval ]: Clustering Algorithms, Experimentation  X 
This work was partially supported by the National Natu-ral Science Foundation of China under Grant No. 60703014 and No. 60933005, the 973 Program of China under Grant No. G2007CB311100 and No. 2011CB302605,and the Na-tional High-Tech Research and Development Plan of China under Grant No. 2009AA01Z437 and No. 2007AA01Z442.

Social tagging systems, such as Delicious 1 for sharing book-marks, Flickr 2 for sharing photos and CiteULike 3 for sharing academic publications, stimulate collaborating users to sub-mit shared resources and to provide light-weight semantic annotations in the form of freely chosen tags, thereby form-ing the so-called folksonomies . The success of these systems is mainly relying on the flexible underlying infrastructure and the easy-to-use user interface, which can provide users with immediate benefits without too much overhead.

The collaborative and dynamic aspects of the folksonomies make them perfect data sources for bootstrapping Seman-tic Web applications. As shown in previous studies [9, 12], sufficient active annotations in social tagging systems will develop a stabilized distribution with a limited number of stable tags and a much larger  X  X ong-tail X  of more idiosyn-cratic tags X  X  X he individual interactions of a large number of rational agents would lead to global effects that could be observed as semantics X  [21]. Thus, extracting the emergent semantics [29] from folksonomies becomes an attractive re-search topic. Specifically, many efforts have been conducted into learning lightweight ontologies from the annotations made by a large number of collaborating users [13, 21, 28, 27, 24]. Unlike the ontologies manually created by domain experts, those automatically induced from the collaborative knowledge of the folks have the advantages of inexpensive to generate, dynamically evolving in time, and easy to be deployed in real-world systems.

In this paper, we develop an ontology induction approach to harvest the emergent semantics from folksonomies. Specif-ically, we make the contributions including: i) we propose a latent subsumption hierarchy model to uncover the hier-archical structures of tag space; ii) we address the problem of noisy subsumptions while turning a subsumption graph into a concept hierarchy and propose a random walk based generality ranking mechanism to settle it; iii) we propose a simple yet effective agglomerative hierarchical clustering algorithm to generate the concept hierarchy; iv) we conduct experiments on a dataset collected from a real-world system to evaluate the proposed approach and the experimental re-sults demonstrate the effectiveness the proposed approach.
The rest of this paper is structured as follows. We review the previous studies on ontology induction in folksonomies in Sec. 2. We introduce the latent subsumption hierarchy model in Sec. 3. Based on this model, we develop the ontol-http://delicious.com/ http://www.flickr.com/ http://www.citeulike.org/ ogy induction approach in Sec. 4. The experimental results are shown in Sec. 5. In Sec. 6, we discuss the issues with our approach and conclude this paper.
There has been a plenty of studies conducted into auto-matically inducing ontology from folksonomies. Basically, they can be grouped into two classes: the similarity-based approaches and the set-theoretical approaches.

The similarity-based approaches are characterized by the use of a similarity measure to compute the pairwise simi-larity between concepts in order to decide if they can be clustered together or not [6]. The notion of similarity plays an important role in such approaches. Markines et al. [19] analyzed the semantic similarity relations obtained from so-cially annotated data through experimental evaluation, and informed the choice of an appropriate measure in different given contexts. Agglomerative clustering algorithms were usually employed by similarity-based approaches to build the hierarchy. Brooks and Montanez [5] noticed the overlap in tag usage and adopted cosine similarity among tag clus-ters as similarity measure for hierarchically clustering tags into a hierarchy. Tag clustering methods were also used for enhancing the user experience [2] and discovering social in-terests [16] in social tagging systems. Heymann and Garcia-Molina [13] employed a simple but effective algorithm to discover the hierarchical taxonomies in the tag space. They denote each tag by a vector, in which each element corre-sponding to a resource represented the number of times the tag was used to annotate the resource. They defined the similarity between two tags as the cosine similarity between the corresponding vectors. They then defined a tag similar-ity graph with tags as nodes. Two nodes were connected with an edge if the similarity between them was above a predefined threshold. To create a concept hierarchy, they started with an empty concept hierarchy with only one root node and added each tag in descending order of closeness-centrality in the similarity graph. A tag was added as a child of either the tag it was most similar to if the similarity was above a threshold, or the root node.

The set-theoretical approaches partially order the con-cepts with the pairwise subsumption relations. The sub-sumption relation of two concepts is usually derived by a set-theoretical method according to the inclusion relation between their specific attribute sets [6], such as the occur-rences in documents for terms. Sanderson and Croft [26] described a simple statistical model for subsumption. They defined x to subsume y if P ( x | y ) = 1 ,P ( y | x ) &lt; 1 , where uments containing x . They also noticed that many term pairs were not detected because a few occurrences of the subsumed term, y , did not co-occur with x . Thus, they relaxed the first condition and redefined the subsumption as P ( x | y )  X  0 . 8 ,P ( y | x ) &lt; 1. P. Schmitz [28] extended Sanderson and Croft X  X  approach to Flickr tag data. He ad-justed the statistical thresholds to reflect the ad hoc usage by adding filters to control for the highly idiosyncratic tags. He defined x to subsume y if P ( x | y )  X  t,P ( y | x ) &lt; t and D was the co-occurrence threshold, D x was the number of re-sources that were tagged by x , which must be greater than a minimum value D min , and U x was the number of users that used tag x for at least once, which must be greater than a Figure 1: The proposed latent subsumption hierar-chy model suggests that the concept hierarchy can be induced from the tag subsumption graph by ad-dressing the problem of irrelevant and inconsistent subsumptions. minimum value U min . The problem of discovering subsump-tion relations in tag space was also formulated by C. Schmitz et al. as an association rule mining problem on a formal context [27] (also see Sec. 4.1). They explored several ways of projecting the folksonomy onto a 2-dimensional space to produce the formal context on which the association rules could be extracted. They considered an association rule as being of interest if its support and confidence were greater than the predefined thresholds. The traditional bipartite model of ontology was extended with the social dimension by Mika [21]. He also suggested to use the graph modeling the co-occurrence of tags to resources for ontology induction by applying an graph clustering method. Besides the proba-bilistic subsumption approaches, Plangprasopchok and Ler-man also leveraged the user-specified relations between tags to induce ontologies [24].
Our goal is to induce ontologies from folksonomies. A folksonomy is built from the social annotations made by collaborating users while annotating shared resources with descriptive tags.

Definition 1. ( Folksonomy ) A folksonomy is a struc-ture F := ( U,T,R,Y ) consisting of i) a set U of users , ii) a set T of tags , iii) a set R of resources and iv) the ternary relation among them, i.e. Y  X  U  X  T  X  R , called annotations . An ontology is a formal representation of a set of concepts within a domain and the relationships between those con-cepts [11]. We adopt the following definition of ontology that contains only the lexical layer and the concept hierarchy.
Definition 2. ( Ontology ) An ontology is a structure O := ( C, root , C ) consisting of i) a set C of concept identifiers , ii) a designated root element , i.e. root , representing the top element of the iii) upper semi-lattice ( C  X  X  root } , C ) called concept hierarchy or taxonomy .

In [13], Heymann and Garcia-Molina suggested a latent hi-erarchy model underlying the tag similarity graph to demon-strate the rationale of their approach. They proposed three hypotheses: i) the sub-and super-concept relation in the in-duced ontology is also present in the tag similarity graph; ii) not all the connections in the tag similarity graph are use-ful; iii) these noisy connections are higher up in the concept hierarchy. Based on empirical analysis (also see Sec. 5), how-ever, we believe that a latent subsumption hierarchy model the concept hierarchy is generated using the output of previous steps. would be more suitable for uncovering the implicit structure of the tag space.

Consider we model the tag space as a graph, with tags as nodes and subsumption relations as edges (as illustrated in the left part of Figure 1). We want to turn this graph into a concept hierarchy (as illustrated in the right part of Figure 1). We now state three hypotheses in this model: Connection preexistence The edge representing the sub-Noise presence There are irrelevant and inconsistent sub-Noise locality The irrelevant subsumptions are higher up
In the next section, we will develop our ontology induction approach on basis of this model. We leverage the first hy-pothesis to identify the tag subsumptions and build the tag subsumption graph (see Sec. 4.1). The second hypothesis reminds us that we can not turn the tag subsumption graph into the concept hierarchy directly without eliminating the noisy subsumptions. We settle the problem of inconsistent subsumptions with a tag generality ranking procedure that introduces a total order of generality into the tag space (see Sec. 4.2). Finally, we leverage the third hypothesis to recon-struct the concept hierarchy with a top-down agglomerative clustering method (see Sec. 4.3).
In this section, we demonstrate the details of our ontol-ogy induction approach. As illustrated in Figure 2, our ap-proach consists of three steps. In the first step, we identify subsumption tags with a set-theoretical method. Since the subsumption relations discovered in this step may be incon-sistent, we resort to ranking the tags by generality to settle this problem. Therefore, in the second step, we construct a tag subsumption graph to compute the generality scores of tags with a random walk based procedure. In the final step, we use an agglomerative clustering approach, which lever-ages the result of the tag generality ranking procedure, to generate the concept hierarchy.
We make a simple assumption that users use tags to rep-resent concepts, i.e. C = T . Of course, this assumption oversimplifies the complex tag usage in folksonomies. We will discuss this issue in Sec. 6.

We exploit the vocabulary from Formal Concept Analysis (FCA) [8] to describe the subsumption model used in this paper, as it may fit with the folksonomy model introduced in Definition 1 very well.

Definition 3. ( Formal Context ) A formal context is a structure K = ( G,M,I ) consisting of i) a set G of objects , ii) a set M of attributes and iii) the incidence relation of the context I  X  G  X  M .
 For A  X  M , we define and the support of A as We further define the support and confidence of the relation between A 1 ,A 2  X  M as Given the minimum support and minimum confidence thresh-olds  X  s  X  [0 , 1] and  X  c  X  [0 , 1], we say that A 1 is subsumed by A 2 , denoting by A 1 A 2 , if
By projecting a folksonomy onto a formal context, we can derive subsumptions using the above model. Notice that we map each tag directly to a concept, thus only singleton subsets of the attribute set within the formal context are considered while identifying subsumptions. Different pro-jections can be used, such as
For the experiment, we use K U,R as it preserves most the information of the social annotations and thus can achieve a good performance.
By identifying subsumption tags, we can build a tag sub-sumption graph with tags as nodes and subsumption rela-tions as edges. However, turning this graph into a concept hierarchy is not a trivial task X  X e must deal with those irrel-evant and inconsistent subsumptions (see Sec. 3). As illus-trated in Figure 3, for a given minimum confidence thresh-old, the cyclic subsumptions among C , A and E make it hard for us to determine which one should be assigned to a higher level in the ontology.

In order to settle the problem of inconsistent subsump-tions, we propose a tag generality ranking mechanism to bring a total order to the tag space X  X he tag with a higher generality score will be assigned to a higher level in the on-tology. Notice that the term  X  X enerality X  here just refers to a quantitative measure which is used to order tags. A tag hav-ing a higher generality score does not necessarily imply that it is a more general concept in human mind. For example, though tags such as object and general are very general concepts, they will get low generality scores since they are rarely used by users and subsume few other tags for the experimental dataset. In fact, such general tags cannot be automatically identified without any external knowledge.
The basic idea of the tag generality ranking mechanism is that a tag that subsumes another tag having a high gen-erality should have a high generality, too. In other words, we are essentially leveraging the generality mutual reinforce-ment relations between tags. Each subsumption is consid-ered as a reinforcement relation, which is further weighted by the confidence of this subsumption. All the paths be-tween the nodes can be exploited to propagate the general-ity. In this setting, random walk methods, which have been widely applied in machine learning and information retrieval fields[23, 15, 17], are good candidates for this task.
A random walk procedure is hereby performed over the tag subsumption graph in order to rank tags by generality. This process will promote tags that have many subsumed neighbors with high confidence, and demote those isolated ones. We formally model the tag space as a tag subsumption graph G = ( T,E, W ). The nodes of the graph are tags Figure 3: Illustration of inconsistent tag subsump-tions. With the confidence threshold of 0.2, all of the subsumptions C A , A E and E C are of in-terest, which form the cyclic subsumption relations. and the edges are the subsumptions weighted by confidence, i.e. for t i ,t j  X  T , the element of W is defined as Given the tag subsumption graph G defined above, we use the row-stochastic version of the adjacency matrix, denoted by P , as the transition matrix for the random walk proce-dure. Its elements p i,j , which represent the transition prob-ability from node t i to t j , are computed as We define the random walk procedure over the tag subsump-tion graph as follows, 1. with probability  X  , jump from the current node to a 2. with probability 1  X   X  , jump from the current node We use the stationary probabilities derived from this ran-dom walk procedure as the generality scores of tags. Using an iterative computation procedure, the generality score of node t i at iteration n , denoted by g ( n ) i , can be computed with generality scores at iteration n , the equation above can be rewritten in matrix form as This iterative computation can be terminated if either the number of iterations reaches a predefined value n g , or the difference between g ( n ) and g ( n  X  1) is less than a predefined value  X  g . For the experiment, we use n g = 100,  X  g = 0 . 001 and the difference between g ( n ) and g ( n  X  1) is calculated as k g the computation formulated in Equation (9) can be found in [30]. The distribution s is used to customize the ranking result. If any external knowledge on tag generality, such as that derived from a lexicon or that manually created by experts, is available, then s can be initialized to produce a customized ranking result. For the experiment, we impose a uniform distribution on s , i.e. s i = 1 / | T | .
After the generality scores of tags are computed, we finally generate the concept hierarchy with an agglomerative hier-archical clustering approach by adding tags to the concept hierarchy in descending order of their generality scores. The complete algorithm for generating the concept hierarchy is shown in Algorithm 1. Two auxiliary functions are used: GeneralitySort ( T ) for sorting all the tags in T by generality score in descending order and Ancestors ( t, C ) for getting all ancestors of tag t except root in C . We start by sort-ing the tags by generality (line 3). Then, for each tag, its subsuming tag with the highest confidence that is already in the concept hierarchy is found to be a parent candidate (lines 5 X 23). While finding this candidate, not only the can-didate itself, but also all its ancestors will be checked against the minimum support threshold  X  s and minimum confidence threshold  X  c (lines 10 X 21). If we do not check the whole path, chains such as macintosh apple fruit plant in which each pair makes sense but the entire chain is im-proper, may be generated. Obviously, tags with multiple senses (e.g. apple ) may result in such improper chains. We will discuss this issue in Sec. 6. Here, we essentially keep only one sense for each tag with the above checking pro-cedure. Finally, if we can find a proper parent, the tag is added as its child; otherwise it will be added as the root X  X  child (lines 24 X 25).
 Algorithm 1 : Concept Hierarchy Generation Procedure Input : F = ( U,T,R,Y ) -the folksonomy data Input :  X  s -the minimum support threshold Input :  X  c -the minimum confidence threshold Output : O = ( C, root , C ) -the induced ontology
C  X  X  X  end return O = ( C, root , C )
Leveraging the generality ranking results, this algorithm incorporates well with the latent subsumption hierarchy model proposed in Sec. 3. The irrelevant connections are elimi-nated by selecting the subsuming tag with highest confidence as parent in the hierarchy. The inconsistent connections are eliminated by adding tags in descending order of generality. Since irrelevant connections are commonly higher up in the concept hierarchy, a top-down agglomerative clustering ap-proach ensures that there are less candidates, thus less error-prone to choose a proper parent while generating the higher part of the hierarchy. And when we generate the lower part of the hierarchy, where the inconsistent connections tend to increase, there are more parent candidates. This will reduce the probability of introducing inconsistent connections into the concept hierarchy.

The parameters,  X  s and  X  c , play an important role in this algorithm. Smaller or larger values of these parameters may result in a hierarchy with more nodes or higher quality. To make a reasonable compromise between coverage and qual-ity, we will adopt an empirical method to select the optimal parameter setting in Sec. 5.
Let m be the average number of annotations made by each user. For each pair of tags, compute the confidence and support of the subsumption relation between them need O ( m ) steps. Thus, the time complexity for the subsumption tags identification step is is O ( m | T | 2 ). For the tag gener-ality ranking step, compute the generality score for each tag needs O ( | T | ) steps, thus the overall time complexity is O ( n | T | 2 ), where n is the number of times the iterative com-putation needs be performed until the result converges. For the concept hierarchy generation step, the maximum num-ber of candidate parents need to be checked while adding a new tag is | T | , thus the overall time complexity is O ( | T | While asymptotically expensive, in practice our approach is quite scalable. For the first step, m is relatively small (less than 100 for our experimental dataset). For the second step, the time cost is determined by the number of times the it-erative computation is performed, which is relatively small in practice (about 20 to 50). For the last step, the actual number of candidate parents need to be checked can be re-duced dramatically if for each tag, we eliminate those tags that do not subsume it in the first step.
In this section, we will first describe the dataset used in the experiments, then introduce the evaluation framework in general and finally present the experimental results in detail.
We conduct experiments on a dataset collected from a real-world system, namely Delicious, for online sharing book-marks. The dataset is a partial dump of Delicious rep-resenting annotating activities during a certain period of time. Starting at Dec 2007, we crawled thousands of web pages from Delicious and extracted post information such as user, resource, post date and corresponding tags. The raw dataset consists of 825,401 users, 59,623,937 resources, 6,420,685 tags and 459,686,018 annotations.

The preprocess of dataset was done according to the fol-lowing two steps. In the first step, we normalized all the tags with Porter stemmer [25] to clean noise due to individ-ual variations in vocabulary. Note that the Porter stemmer works only for English language, while there are many non-English tags in our dataset. We will discuss this issue in Sec. 6. In the second step, we compute the p -core [1, 14] at level 20 of the tripartite hypergraph representation of the dataset. The p -core at level t has the property that each user, resource and tag has/occurs in at least t annotations. The algorithm for p -core computation can be found in [1]. By p -core computation, inactive users, unpopular resources and idiosyncratic tags are eliminated from the dataset. We ignore the annotations made by/to inactive users and un-popular resources since i) it is hard to aggregate the collabo-rative knowledge from them, and ii) they potentially contain more noise than those made by/to active users and popular resources. The idiosyncratic tags mainly consist of i) ty-pos, e.g., infomation , comunications , ii) uncommon nonce words, e.g. todownloadlinks , linux08howtos , iii) person-alized tags, e.g. my_home_theatre , todo2009 and iv) other tags that are hard to understand, e.g., or_not!!! . It is rea-sonable to eliminate such idiosyncratic tags since we are only interested in the tags that are used by users for specifying concepts, which are very likely to be used by many users. There are 282,016 users, 90,790 resources, 32,615 tags and 30,902,845 annotations in the preprocessed dataset
We can see an ontology learning approach as an automatic procedure that takes a domain centered corpus as input and generates an ontology which conceptualizes the information implicitly available in the corpus. Thus, we can evaluate an ontology learning approach by assessing the quality of the learned ontology. In our study, we evaluate the proposed approach with a comparative methodology by comparing the outcome of our approach with those generated by other state-of-the-art approaches.
We performed a comparative evaluation with two other state-of-the-art approaches: one was Heymann X  X  approach proposed in [13] and the other was Schmitz X  X  approach pro-posed in [27] (also see Sec. 2 for a brief review). These two approaches were chosen for three reasons. Firstly, they were well documented in the original works, which made the reimplementation feasible. Secondly, they respectively belonged to the two categories of ontology induction ap-proaches as mentioned in Sec. 2. Specifically, Heymann X  X  ap-proach was similarity-based, while Schmitz X  X  approach was set-theoretical. Thirdly, good results for them were reported in the original works and observed in the preliminary ex-periments. Other methods mentioned in Sec. 2 were ei-ther very similar to them, such as Mika X  X  approach [21], which was analogous to Schmitz X  X  approach; or not applica-ble in our dataset, such as Plangprasopchok and Lerman X  X  approach [24], which leveraged the user-specified relations that were not available in our dataset.

The original Heymann X  X  approach computed the similar-ity between tags using the cosine similarity between the cor-responding tag vectors. For each tag vector, the element corresponding to a resource was the number of times that the tag annotates the resource. To enable a fair comparison, we used another form of tag vectors, for which the element corresponding to a user and a resource is 1 if the user had an-notated the resource with the corresponding tag, otherwise 0. According to the preliminary experimental results, this adaption slightly improved the performance of Heymann X  X  approach.

The study of Schmitz et al. did not describe how a con-cept hierarchy could be generated from the mined associa-tion rules. To evaluate the result of Schmitz X  X  approach, we first mined a set of association rules with their approach, and then defined a graph with tags as nodes, and the confi-dence of associations as weight of edges. By eliminating all the incoming edges but the one with the greatest weight for each node, and breaking circles at the edge with the least weight, a forest of trees was generated. Finally, all the roots of the trees were connected to an external root node to form the final result.

For Heymann X  X  approach, we used the same similarity threshold of 0.099 as in [13]. For Schmitz X  X  approach, we used an empirical minimum support threshold of 0.00001. For the proposed approach, we used  X  = 0 . 95 in Equa-tion (9). We used an empirical minimum support thresh-old of  X  s = 0 . 00001, and systematically varied the minimum confidence threshold of  X  c = (0 . 05 , 0 . 10 ,..., 0 . 95) to find the best setting, namely  X  c = 0 . 15, which achieved the best lex-ical F-measure (see Sec. 5.4).
Ontology evaluation is known as a difficult task. While many studies have been conducted into this subject [3, 7, 4], performing a comprehensive evaluation still needs much effort. In this paper, we perform an integrative evaluation in the following ways: Qualitative evaluation To gain a qualitative insight into Quantitative evaluation For quantitative evaluation, we
We start the evaluation by gaining some qualitative in-sights into different approaches. We plot the number of con-cepts at each level of the induced ontology to compare the structural characteristics. We illustrate the induced ontolo-gies and give a brief error analysis.
The structure of an ontology is characterized by the max-imum depth of the concept hierarchy and number of con-cepts at each level. A too deep concept hierarchy indicates a failure of distinguishing different concepts, while a too flat one indicates a lack of abstract ability. Figure 4 shows the number of concepts at each level of the induced ontologies. From this figure we can see that the proposed approach gen-erates the most tags at the first level and 35.7% of them are singleton subtrees. The average depth is 2.70. While adding a new tag into the concept hierarchy, except for the direct parent candidate, we also check whether the ances-tors subsume this tag. This checking makes more tags be-Figure 4: The number of concepts at each level of the induced ontologies. come the root X  X  children, hence more tags at the first level. This also implies a higher precision but a lower recall for the proposed approach (see Sec. 5.4). Comparing with Hey-mann X  X  approach, the proposed approach produces a flat-ter tag hierarchy, while Heymann X  X  approach produces a too deep one with an average depth of 8.57 and a maxi-mum depth of 20. The main reason for this difference is that Heymann X  X  approach is similarity-based, by which tag clusters are prone to be overly expanded. Comparing with Schmitz X  X  approach, the proposed approach also generates a flatter structure. Since there is no generality ranking step in Schmitz X  X  approach, about 17.5% more general tags are placed lower down the hierarchy, causing a deeper structure with an average depth of 3.51.
Figure 5 shows ontologies induced by the proposed, Hey-mann X  X  and Schmitz X  X  approach, respectively. We extract the subtrees associated with a single root concept for con-venient browsing. Though very simple, these ontologies can provide us with useful insights into these approaches. First of all, all the children of sport are some kind of sports, or organizations and web sites related to sports. Comparing the structure of these ontologies, we can see that the obser-vations made in Sec. 5.3.1 are confirmed.

We can also find some errors in these ontologies. In Fig-ure 5(b), Heymann X  X  approach identifies a long chain of nhl hockey leagu nfl footbal sport , which is not reasonable. It seems that the two chains of nhl hockey leagu and leagu nfl footbal sport are concate-nated by the tag leagu . In Figure 5(c), Schmitz X  X  approach identifies a disordered chain of olymp cricket sport . This problem may be caused by the noisy subsumptions in the tag subsumption graph.
While the qualitative comparison can provide us with use-ful insights, we have to resort to a formal quantitative method-ology to evaluate the performance of the proposed approach. Here, we adopt the methodology of comparing with a gold-standard ontology, which is usually a hand-crafted one, to quantitatively measure the quality of the induced ontology. Figure 5: Illustration of the ontologies associated with the root concept of sport (with root concept in green) induced by the (a) proposed, (b) Heymann X  X  and (c) Schmitz X  X  approach. Only certain represen-tative portions of the ontologies are shown due to the lack of space. cal precision, recall and F-measure are used for lexical layer comparison.
While choosing a golden-standard ontology, one need to consider two issues, i) scope: how many common concepts it shares with the induced ontologies, and ii) structure: how similar it is organized with the induced ontologies. We propose using the concept hierarchy from Open Directory Project (ODP) 4 . ODP is a free, user-maintained hierarchi-cal web directory. Each node in the ODP hierarchy has a topic label (e.g. Sports or Arts ) and a set of associated URLs. ODP is generated by collaborating users who tend to use more colloquial terms, which makes it share more com-mon concepts with our induced ontologies than those based on controlled vocabulary.

Both the lexical layer and concept hierarchy of the induced ontology will be evaluated with metrics extending the idea of precision, recall and F-measure to the gold-standard based ontology evaluation. For the lexical layer, the lexical pre-cision, recall and F-measure metrics will be used. For the concept hierarchy, another group of metrics, namely taxo-nomic precision, recall and F-measure will be used.
Lexical precision, recall and F-measure ( LP , LR and LF ) measure how good an induced ontology covers concepts ex-isting in the gold-standard, regardless of its structure [7]. Given an induced ontology O I = { C I , root , C I } and a gold-standard O G = { C G , root , C G } , they are defined as Taxonomic precision, recall and F-measure ( TP , TR and TF ) measure the structural similarity of two concept hierar-chies [7]. There exist several versions of TP for different eval-http://dmoz.org uation purposes. We adopt the one using the common se-mantic cotopy since it enables the separate evaluation of the functional dimension of the taxonomic and lexical layer[7]. Specifically, given two ontologies O 1 and O 2 , the common semantic cotopy of a concept c is the set of all the common super-and sub-concepts of c , i.e., csc ( c,O 1 ,O 2 ) = { c 0 | c 0  X  C 1  X  C 2  X  ( c 0  X  C 1 Given an induced ontology O I and a gold-standard O G , the local taxonomic precision ( tp ) of the concept c is defined as Then, TP , TR and TF can be computed with the local taxonomic precision values of the common concepts between the induced ontology and the gold-standard, i.e.,
Note that ODP handles polysemy by allowing the same concept in different places in the hierarchy. While calculat-ing the metrics above, we preserve all the occurrences of a concept in the gold-standard.
The automatically induced ontologies contain many un-popular concepts and many of them are at the first level (also see Figure 4). If we directly compare the induced ontologies with the gold-standard, very poor results for all the performance metrics, which are useless for a meaningful comparison, will be obtained. Thus, we manually selected a set of root concepts, which were all popular topics and the subtrees under them shared a significant portion with the corresponding subtrees in the gold-standard. If a root con-cept had multiple occurrences in the ODP hierarchy, the one with the most descendants was chosen as the gold-standard. We also compared the  X  X omplete X  ontology, which contained all these subtrees and a root node, with the corresponding gold-standard that contained only the corresponding sub-trees and a root node. The results are shown in the rows entitled with  X  X ll X .

Table 1 shows the lexical layer evaluation results. We can see that the proposed approach has gained the best lexical precision in most cases (11 out of 15), while the other ap-proaches perform better in lexical recall. By generality rank-ing and top-down hierarchical clustering, our approach tends to conceptualize less but more informative concepts. Thus, our approach achieves a higher lexical precision while a lower lexical recall. When balancing the lexical precision and re-call with the lexical F-measure, our approach achieves the best performance in 8 out of 15 cases. Overall, the proposed approach outperforms Heymann X  X  and Schmitz X  X  approach in F-measure and this result is statistically significant at a level of p = 0 . 05. This indicates that our approach can make a good compromise between concept precision and coverage. Table 2 shows the concept hierarchy evaluation results. We can see that our approach has gained a very high average taxonomic precision yet a relatively low average taxonomic recall. As we have analyzed in Sec. 3, most of the hierar-chical errors are caused by the noisy subsumptions. In our approach, by ranking tags with generality, more general tags are promoted and inconsistent subsumptions are thus effec-tively suppressed. When choosing parent node for each tag, we select the one with the greatest subsuming confidence to eliminate other related irrelevant subsumptions. All these steps may make more tags become the root X  X  children. Thus, our approach does not perform well in taxonomic recall. Heymann X  X  approach generates a deeper hierarchy and per-forms best in taxonomic recall. While combining these met-rics with taxonomic F-measure, our approach performs the best in 7 out of 15 cases. Overall, the proposed approach outperforms the other approaches in F-measure and this re-sult is statistically significant at a level of p = 0 . 05.
There are some issues with the proposed approach need to be further considered. We assume a one-to-one mapping from tag space to concept space, which obviously oversim-plifies the synonymous and polysemous usage of tags. One possible solution is to cluster tags with proper similarity measure, and map such tag clusters to concepts. Polyse-mous tags are potentially more difficult to tackle. To the best of the authors X  knowledge, there are few studies focus-ing on this problem in the ontology induction setting, though the problem of word sense disambiguation is well-studied in the literature[31, 20, 22].

We do not deal with the problem of multilingual tags ex-plicitly in this paper. For example, we use Porter stemmer (see Sec. 5.1), which works only for the English language, to stem the tags. In Figure 5(a), the tag fussbal is in-deed the German word  X  X ussball X  crippled by the stemmer. Though multilingual stemmers [10, 18] can be used to settle this problem, words in different languages sharing the same stem still need further investigation. In such cases, word sense disambiguation techniques can be employed since tags in different languages should have different contexts.
This paper has demonstrated our approach to induce on-tology in folksonomies. The proposed approach is based on a latent subsumption hierarchy model, which depicts the implicit structure of the tag space. We also address the problem of inconsistent subsumptions and propose a random walk based procedure settle it. We employ an agglomerative hierarchical clustering algorithm, which fits well with the la-tent subsumption hierarchy model, to generate the concept hierarchy. The effective combination of the subsumption models, the tag generality ranking procedure and the con-cept hierarchy generation algorithm superbly fits into the latent subsumption hierarchy model, making the proposed approach a competitive candidate for the task of ontology induction in folksonomies. [1] V. Batagelj and M. Zaversnik. Generalized cores. [2] G. Begelman, P. Keller, and F. Smadja. Automated [3] J. Brank, M. Grobelnik, and D. Mladenic. A survey of [4] C. Brewster, H. Alani, S. Dasmahapatra, and [5] C. H. Brooks and N. Montanez. Improved annotation [6] P. Cimiano. Ontology Learning and Population from [7] K. Dellschaft and S. Staab. Strategies for the [8] B. Ganter and R. Wille. Formal Concept Analysis: [9] S. A. Golder and B. A. Huberman. Usage patterns of [10] J. A. Goldsmith, D. Higgins, and S. Soglasnova. [11] T. R. Gruber. Toward principles for the design of [12] H. Halpin, V. Robu, and H. Shepherd. The complex [13] P. Heymann and H. Garcia-Molina. Collaborative [14] R. J  X  aschke, L. Marinho, A. Hotho, [15] Y. Jing and S. Baluja. Visualrank: Applying pagerank [16] X. Li, L. Guo, and Y. Zhao. Tag-based social interest [17] J. Liu, W. Lai, X. S. Hua, Y. Huang, and S. Li. Video [18] P. Majumder, M. Mitra, S. K. Parui, G. Kole, [19] B. Markines, C. Cattuto, F. Menczer, D. Benz, [20] R. Mihalcea. Using wikipedia for automatic word sense [21] P. Mika. Ontologies are us: A unified model of social [22] R. Navigli. Word sense disambiguation: A survey. [23] L. Page, S. Brin, R. Motwani, and T. Winograd. The [24] A. Plangprasopchok and K. Lerman. Constructing [25] M. F. Porter. An algorithm for suffix stripping. [26] M. Sanderson and B. Croft. Deriving concept [27] C. Schmitz, A. Hotho, R. J  X  aschke, and G. Stumme. [28] P. Schmitz. Inducing ontology from flickr tags. In [29] S. Staab, S. Santini, F. Nack, L. Steels, and [30] W. Xi, B. Zhang, Z. Chen, Y. Lu, S. Yan, W.-Y. Ma, [31] D. Yarowsky. Unsupervised word sense disambiguation
