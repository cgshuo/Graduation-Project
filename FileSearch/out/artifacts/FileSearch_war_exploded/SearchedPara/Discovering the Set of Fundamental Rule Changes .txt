 The world around us changes constantly. Knowing what has changed is an important part of our lives. For businesses, recognizing changes is also crucial. It allows businesses to adapt themselves to the changing market needs. In this paper, we study changes of association rules from one time period to another. One approach is to compare the supports and/or confidences of each rule in the two time periods and report the differences. This technique, however, is too simplistic as it tends to report a huge number of rule changes, and many of them are, in fact, simply the snowball effect of a small subset of fundamental changes. Here, we present a technique to highlight the small subset of fundamental changes. A change is fundamental if it cannot be explained by some other changes. The proposed technique has been applied to a number of real-life datasets. Experiments results show that the number of rules whose changes are unexplainable is quite small (about 20% of the total number of changes discovered), and many of these unexplainable changes reflect some fundamental shifts in the application domain. Keywords: Change mining, data mining. Detecting and adapting to changes are important activities for businesses and organizations. Companies and organizations want to know what are the changes in order to tailor their products and services to suit the changing needs of their customers. In many business environments, mining for changes can be more important than producing accurate models or classifiers for prediction, which has been the focus of existing data mining research. A model, no matter how accurate, in itself is passive because it can only predict based on patterns mined in the old data. It should not lead to actions that may change the environment because otherwise the model will cease to be accurate. Building models for prediction is more suitable in domains where the environment is relatively stable and there is little human intervention. However, in most business situations, constant human intervention is a fact of life. Companies simply cannot allow personal or classroom use is granted without fee provided that copies are not made or distributed/'or profit or commercial advantage and that requires prior specific permission and/or a fee. KDD 01 San Francisco CA USA Copyright ACM 2001 1-58113-391-x/01/08...$5.00 nature to take its course. They constantly need to perform actions in order to provide better products and services, to win more customers, and to resolve outstanding problems faced by the companies. For example, in a supermarket, there are always discounts and promotions to raise sale volume, to clear old stocks and to generate more sale traffic. Change mining is important in such situations as it allows the supermarket to compare results before and after promotions to see whether the promotions are effective, and to find interesting changes in customer behaviors. association rules, i.e., to find rule changes that occur in the new time period as compared to the old time period. Association rule mining is defined as follows [2]: Let I = {il ..... i~} be a set of items, and D be a set of transactions. Each transaction consists of a subset of items in I. An association rule is an implication of the form X---~ Y, where X c I, YcL andXn Y= f~. The rule X---) Y holds in D with confidence c if c% of transactions in D that support X also support Y. The rule has support s in D if s% of transactions in D contains X u Y. The problem of mining association rules is to generate all association rules that have support and confidence greater than the user-specified minimum support (minsup) and minimum confidence (minconf). relational table, which consists of a set of tuples described by a number of attributes. An item in this context is an attribute value pair, i.e., (attribute = value) (numeric attributes are discretized). Mining in such data is typically targeted at a specific attribute, as the user normally wants to know how the other attributes are related to this target attribute (which has a number of discrete values) [3, 16]. With a target attribute, an association rule can be expressed as: X ~ y, where y is an item (or a value) of the target attribute, and X is a set of items from the rest of the attributes. from data in two time periods is easy. We simply compare the supports and confidences of each rule from the two time periods, and then report the differences. This approach was taken by a number of researchers [e.g., 1, 5, 8]. However, it has two major problems. First, it often reports far too many changes and most of them are simply the snowball effect of some fundamental changes. Second, analyzing the difference in supports/confidences may miss some interesting changes. For example, rule A,B---~y has similar supports in time period tl and t2. However, the support of A---)y and the support of B---~y have both increased dramatically. This is an interesting phenomenon and should be reported. fundamental changes (changes that cannot be explained by the presence of other changes) and report only the fundamental changes to the user. This makes sense because the fundamental changes are typically those that require user attention. This paper proposes a technique to identify the set of fundamental changes in two given datasets collected from two time periods. To the best of our knowledge, this is the first time that such a technique is proposed. We now use an example to illustrate the idea. Example 1: Assume that the following three rules are mined from the data of time period 1. rl: Job = yes ~ Lean = approved [sup=3.2%, conf= 60%] r2: Own_house = yes ---) Loan = approved 
In time period 2, the three rules become: rl': Job = yes ~ Loan = approved [sup=5.0%, conf= 65%] r2': Own_house = yes --) Loan = approved r3': Job = yes, Own_house = yes ---&gt; Loan = approved 
Focusing on the changes in support, we observe the following facts. First, the proportion of people who have jobs and have their loans approved increased significantly in time period 2. 
Second, the proportion of people who own houses and have their loans approved has also increased. Third, the proportion of people who have jobs, own houses and have their loan approved increased significantly as well. The question that we would like to ask is: "is the increase in r3 (we use r3' and r3 in time period 2 interchangeably) the consequence of the increases in rl and r2?" That is, can the increase in support of r3 be explained in terms of the changes in support of rl and r2? If it can be explained, then we say the change observed in r3 is not a fundamental change. Intuitively, we can see that in this example the support increase in r3 could be somehow explained by the support increases in rl and r2. If, however, we have the following rule in time period 2 instead of r3', 
The decrease in support of r3 (r3") is hard to explain because we would expect the support of r3 to increase given that the supports of rl and r2 have both increased. In this case, we say that the change observed in r3 is unexplainable, and represents a fundamental change. This paper proposes a technique to identify all such fundamental changes -changes that cannot be explained by other changes. Such rules are very interesting because they often represent some major shifts in the domain. The proposed technique has been evaluated using 10 real-life datasets. Experiment results show that only a small subset of the rules exhibit fundamental changes in support and/or confidence. They can be manually analyzed without much difficulty. The user can then focus his/her attention on those important/interesting aspects of changes, and selectively view those less important or explainable changes. Mining or learning in a changing environment has been studied in both data mining and machine learning. In data mining, [1, 5, 8] address the problem of monitoring the support and confidence of association rules. Given an association rule, their techniques track the support and confidence variations of the rule over time. These techniques basically belong to the simple approach mentioned in Section 1. None of them aims to find fundamental changes. in [1]. The paper proposes to monitor rules in different time periods. The discovered rules from different time periods are collected into a rule base. Ups and downs in support or confidence over time (called history) are represented and defined using shape operators. The user can then query the rule base by specifying some history specifications. Clearly, this is different from our work, as it does not mine fundamental rule changes. differences in two models (e.g., two sets of association rules from two datasets).The framework does not mine fundamental changes. The techniques aim to incrementally update the rules when data tuples are deleted or inserted. They do not mine explicit changes. trend is defined as a regular change of one or more non-spatial attributes when moving away from a given start object. This is different from our work, as it is not concerned with rule changes. datasets. It first partitions the data into sections. Each section is summarized with a profile, a set of statistics. The profiles from the old data set and the new dataset are then compared using statistic tests for proportions and for change of means. This work is also different from ours, as it is not concerned with rule changes. summarization in [16] and finding the minimal set of unexpected rules in [ 18]. Both techniques, however, do not deal with changes. data mining. [19, 14, 18] propose a number of approaches for finding unexpected rules with respect to the user's expectations. These techniques also do not deal with rule changes. produce good classifiers (or concepts) in on-line learning of a drifting environment [e.g., 20, 13]. Their framework is different from ours, as they do not mine explicit drifts. Let the dataset from time period tl be DI and the dataset from time period t2 be D2. The technique consists of the following two steps: 1. Rule generation: We first perform association rule mining on 2. Identification of fundamental rule changes: This step finds The rest of the paper will focus on step 2. Step 1 will not be discussed any further as it is fairly straightforward. This section presents the proposed technique for finding fundamental rule changes. We distinguish two types of changes, namely, those identified through quantitative analysis, and those identified through qualitative analysis. Below, we first present these two types of fundamental changes and the techniques for identifying them, and then discuss two sub-sets of changes that are of particular interest. In quantitative analysis, we use a statistical test for homogeneity to identify those unexplainable rule changes (or fundamental rule changes). Basically, the change in support (or confidence) of a rule is unexplainable or fundamental if the change is unexpected. Definition 1 (expected supports or confidences): The expected support (or confidence) of a rule r in t2 is defined as follows: (1) If r is a 1-condition rule, the expected support (or (2) If r is a k-condition rule r (k &gt; 1) of the form, possible partition. However. these alternatives require mere computation. Conceptually. they are also more difficult to understand. The computation of the expected supports and confidences are based on the Constant Proportion Assumption. Constant Proportion Assumption 2: The proportional relationships between rone and rrest to rule r should remain the same from time period tl to time period t2, where t2 &gt; ta. This assumption is reasonable as it follows our intuition and allows us to find those unexpected or unexplainable changes that are important in practice. Definition 2 (fundamental rule change in support or confidence via quantitative analysis): A change in support (or confidence) of rule r from tt to t2 is said to be fundamental if: (1) r is a 1-condition rule and its support (or confidence) is (2) r is a k-condition rule r (k &gt; 1), and for Note that (2) of Definition 2 basically says that if the change in r can be explained by any one combination, it is not a fundamental rule change. This is reasonable because as long as there is one possible explanation for r's change, we cannot say that r is a fundamental change. Notice also that in this definition, we need a significance test. Here, we use the popular Chi-square test statistics for the purpose (see Section 5). Example 2: We have the following rules in time period 1: 
In time period 2, the three rules become: Since rl and r2 are 1-condition rules, we can use Chi-square test to check whether the support (or confidence) of each of them in t2 is significantly different from that in tl. If so, it is a fundamental rule change. We now focus on r3 (r3') in t2. Here, we only evaluate the change in support (change in confidence can be evaluated in the same way). The expected supports of r3 in t2 with respect to rl and r2 are 0,018 and 0.015 respectively. Chi-square test for homogeneity to check whether Ert(suPt2(r3)), E,,z(suPt2(r3)), and the actual support of r3 in t2 (i.e., significantly different. Suppose it turns out that they are statistically different. Then, the support of r3 in t2 is unexplainable, and it is a fundamental rule change in support. changes. The algorithm only shows the rule support evaluation. Confidence evaluation can be done in exactly the same way. 
We experimented with a number of other assumptions (ways to compute to understand. Algorithm findFdmChanges(R) /* R is the set of input rules */ 1 FdmChanges = 0; 2 for each r in R from the shortest rule to the longest rule do 3 for each pair, ro~e (Xi --&gt; y) and r~st (X,e~:--&gt; y) of r, said to be a fundamental support (or confidence) change if for all ron, and rrest combinations, the directions of support (or confidence) changes of ro~, r~t and r in time period 2 do not belong to any of the 7 cases in Figure 2. The algorithm for finding fundamental rule changes in this case 4 compute Erone(Supt2(r)), and E~rest(suptz(r)); 5 flag = homoTest(Eron,(suptz(r)), Errest(suPt2(r)), suPt2(r)); 6 if flag = true then 8 endif 9 endfor 10 if flag =false then/* r's support has changed fundamentally */ 11 FdmChanges = FdmChanges u { r} 12 endif 13 endfor Figure 1. Finding fundamental rule changes -quantitative analysis Line 1 initializes the variable FdmChanges for storing the set of fundamental rule changes. Line 2 sets the loop to start evaluation of each rule from the shortest rule to the longest rule. Line 3 produces every rone and rrest pair from r. Lines 4 &amp; 5 compute Eron,(supt2(r)) and E~,,t(suptz(r)), and perform the homogeneity test (see Section 5) to determine whether the support of r in t2 can be explained by rone and rrest. In lines 6-12, if r can be explained by any of the ro~e and rrest pairs, it is not a fundamental change (lines 6 &amp; 7). Those fundamental rule changes (line 11) are stored in FdmChanges. In lines 6-12, if r can be explained by any of the Fundamental rule changes (line 11) are stored in FdmChanges. Complexity: The time complexity of the algorithm is linear in the number of discovered rules. See [15] for details. We now identify fundamental changes via qualitative analysis. Here, the magnitude of change is ignored. Instead we only focus on the direction of change, i.e., increase, drop or noChange from two sub-sets of interesting rules, as we will see later. Definition 3 (fundamental rule change in support/confidence via qualitative analysis): The support (or confidence) change can be obtained easily by modifying the algorithm in Figure 1. Note that Definition 2 and Definition 3 may result in different sets of fundamental rule changes. They are both useful in practice. We now discuss some interesting situations. We produce all the cases of Definition 3. To simplify our discussion, we omit noChange, as it is unlikely to occur in practice (but it can be easily included). Without noChange, the total number of possible cases is reduced to 8 (see Figure 3). Note that Case 7 and Case 8 are symmetric to Case 5 and 6 respectively with respect to rone and rrest. We use support change in our following discussion. in Case 1 and Case 2 are intuitively sound. If two things increase or drop, we would expect their combination to increase or drop too. However, Cases 3, 4, 5, 6, 7 and 8 are hard to explain. with qualitative analysis. For instance, if a particular rule belongs to Case 1 in Figure 3, it is thus explainable qualitatively. However, if we take into consideration the magnitude of changes, it becomes non-trivial. If the supports of rone and rre,t increase a little and the support of r also increases a little, then quantitative analysis may also show the rule is explainable. However, if the actual support of r increases drastically, it may suggest that r is a fundamental change, as the drastic increase cannot be explained by the small increases in ron~ and rrest. of fundamental rule changes. Let the set of fundamental rule changes obtained from quantitative analysis be Fqt, and the set of fundamental rule changes obtained from qualitative analysis be Fqt, i.e., Cases 3-8. Two interesting subsets of fundamental rule changes can be defined (these two subsets partition Fqt): 1. Fqt -Fqt: These rules are either 1-condition fundamental change rules, or fall in Case 1 or Case 2 (i.e., their directions of change are the same, but their magnitudes of change cannot be explained). For example, for a particular rule r, its supt2(ron~) increases to 5% from supq(ron,) = 4.8% and suptz(rr,,t) increases to 6% from suPtt(rrest) = 5.6%. However, supt2(r) increases to 4% from suptl(r) = 1.5%. This situation falls into Case 1 above. 
However, supq(r) = 4% is hard to explain as its increase is too drastic. These rules are interesting because they represent some relationship of disproportional increases. In applications, if we want to achieve a big increase in r, we only need to perform some actions to generate a small increase in ron e and rrest. 2. Fqt n Fqt: These are rules (with 2 or more conditions) that have changed dramatically, both qualitatively and quantitatively. 
They belong to Cases 3-8 and their magnitudes of change are also significant. These rules are most unexplainable, and they warrant further analysis. For the proposed technique, we need a statistical test for homogeneity of a set of proportions (support and confidence are both proportions). Chi-square (X ~) test [17] is a popular choice. Test of homogeneity: A test of homogeneity involves testing the null hypothesis (H0) that the proportions, Pb P2 ..... pk, in two or more populations are the same against the alternative hypothesis (Hx) that these proportions are not the same. That is, We assume that the data consists of independent random samples 2xk contingency table (Figure 4). The numbers xl ..... xk, nl-xl, .... nk-Xk listed inside the 2k cells are called observed frequencies of the respective cells. Successes xl x2 ... x~ Failures nl-x~ n~-x2 ... nl-xk Let O be an observed frequency, and E be an expected frequency for a cell in the above table. The statistic defined as has a Z 2 distribution with: df= (Row -1)(Column -1), degrees of freedom, where Row and Column are the number of rows and the number of columns, respectively, in the given contingency table. expect the frequency E (expected frequency) for a cell to be as follows [17]: (Row total) X (Column total)/Sample size. It works as follows: if all values were really homogeneous, the value would be 0. If it is higher than a threshold value (5.99, at the 95% significant level with two degrees of freedom) we reject Ho, and state that the population proportions are significantly different. Let us see an example. Example 3: We use the three rules in Example 2. Assume the dataset in time period 2 has 1000 tuples. Here, only support is used as an example. The expected supports of r3 (r3') in time period 2 with respect to rl and r2 are: 
Er2($uPt2(r3)), and suPt2(r 3) are the same statistically using the significance level of 95% (a commonly used level [17]). contingency table (Figure 5) containing 6 cells. The expected frequencies are included in parentheses next to the observed frequencies within the corresponding cells. computed 4. The observed X 2 value is 18 (as computed). If we use 2 degree of freedom (dr = (2-1)(3-1) = 2). The observed 3(2 value is much larger than the critical value. Thus, we reject the null hypothesis, and conclude that the supports are significantly different. We say that r3 shows an fundamental change in support. We experimented the proposed technique on 3 real-life datasets from three different domains. These datasets were collected by our user organizations over a number of years. The first dataset is from the education domain. We have 4 years of data. The second set of data is from the insurance domain. We also have 4 years of data. The last set is from the medical domain. We have 5 years of patients' screening data. We group all the datasets into pair groups (each pair group consists of data from two successive years from their respective domains). This gives us 10 pair groups of data. We mine the fundamental changes from each pair group. quantitative analysis. Each column is explained below (the average value for each column is shown in the last row): of data). Column 2 gives the total number of rules in R from the two years (see Section 3 for the definition of R) that satisfy the minimum support and minimum confidence requirements. Column 3 gives the number of rules after pruning for each data group. Pruning removes those non-significant rules. We apply the pruning technique in [16]. Column 4 gives the number of explainable confidence rules for each group, and column 5 gives the number of significant rules that exhibit fundamental changes in confidence through the quantitative analysis in Section 4.1. We observe that the number of fundamental rule changes is quite small. It is possible to manually analyze them. Column 6 shows the ratio of column 5 vs. column 3. On average, the number of rules that exhibit fundamental changes in confidence is only 23% of the total number of rules. It is also interesting to note that the education domain is very stable as the number of fundamental rule changes is consistently small over the years. The insurance domain is the most volatile. Columns 7-9 show the same set of results as columns 4-6, but for rule support changes. We can see that only 34% of the rules exhibit fundamental changes. Column 10 gives the number of fundamental rule changes in both support and confidence. Column 11 shows the rule generation time for each data group. Column 12 gives the time used for finding fundamental rule changes, i.e., the proposed technique in this paper. It includes the time for both confidence and support change evaluations through quantitative analysis and for finding (Fqt-Fq~) and (Fqt  X '~ Fql). We can see that these operations can be done extremely efficiently. Columns 13 and 14 give the number of to deal with them when the assumptions are not satisfied. 1 EDU1 27626 534 478 56 10.49% 2 EDU2 29572 565 515 50 8.85% 3 EDU3 29525 625 565 60 9.60% 4 INSURI 2595 5713 410 160 28.07% 5 INSUR2 2022 569 282 287 50.44% 6 INSUR3 1694 566 370 196 34.63% 7 MED1 5489 264 173 91 34.47% 8 MED2 6258, 274 179 95 34.67% 9 MED3 5569 298 256 42 14.09% 10 MED4 6523 291 271 20 6.87% conf &amp; sup tuples in time period 2 and 1 respectively. All our experiments were conducted on a PII-350 PC with 128MB RAM. fundamental rule changes, i.e., Fqt---Fqt and Fqt (3 Fqt. The table has two parts. The first part (columns 2-4) gives the results for fundamental confidence changes. The second part (columns 5-7) gives the results for fundamental support changes. 
Dataset fund. Fqr--Fql Fqt  X '~ Fql 1 EDU1 56 29 27 2 EDU2 50 31 19 3 EDU3 60 29 31 4 INSUR1 160 65 95 5 INSUR2 287 216 71 6 INSUR3 196 95 101 7 MED1 91 63 28 8 MED2 95 50 45 9 MED3 " 42 12 30 10 MED4 20 6 14 Detecting fundamental shifts in the environment is of crucial importance to businesses. Companies constantly need to know what are changing in the market place. This allows them to produce the right products and/or services to suit the changing market needs. Fundamental changes often require immediate attention and action. In this paper, we studied this issue in the context of association rules, and proposed an efficient technique to identify fundamental rule changes in support and in confidence. Empirical evaluation showed that only a small percentage of rules exhibit fundamental changes. This enables the users to analyze them to obtain those actionable changes without much difficulty. [1], Agrawal, R. and Psaila, G. "Active data mining." KDD-95. [2], Agrawal, R. and Srikant, R. "Fast algorithms for mining [3]. Bayardo, R., Agrawal, R, and Gunopulos, D. "Constraint-[4]. Cheung, D. Han, J, V. Ng, and Wong, C.Y. "Maintenance [5]. Dong, G. and J. Li. "Efficient mining of emerging patterns: [6]. Ester, M., Frommelt, A., Kriegel, H-P., and Sander, J. [7]. Fayyad, U. M. and Irani, K. B. "Multi-interval discretization [8]. Ganti, V., Gehrke, J., and Ramakrishnan, R. "A framework [9]. Ganti, V., Gehrke, J., and Ramakrishnan, R. "DEMON: [10]. Han, J. and Fu, Y. "Discovery of multiple-level association [11]. Johnson T. and Dasu, T. "Comparing massive high-[12]. Kohavi, R., John, G., Long, R., Manley, D., and Pfleger, K. [13]. Lane, T. and Brodley, C. "Approaches to online learning [14]. Liu, B., Hsu, W., and Chen, S. "Using general impressions [15]. Liu, B., Hsu, W. and Ma, Y. Discovering the set of [16]. Liu, B., Hsu, W. and Ma, Y. "Pruning and summarizing the [17]. Mann, P. Introductory statistics. John Wiley &amp; Sons, 1998. [18]. Padmanabhan, B., and Tuzhilin, A. "Small is beautiful: [19]. Silberschatz, A., and Tuzhilin, A. "What makes patterns [20]. Widmer, G. "Learning in the presence of concept drift and 
