 1. Introduction Given a simple undirected graph G  X  X  V ; E  X  with vertex set
V  X f v 1 ; ... ; v n g and edge set E V V . An independent set S is a subset of V such that no two vertices are adjacent, i.e., 8 v ; v j A S ; f v i ; v j g = 2 E . An independent set is said maximum if it has the largest cardinality among all the independent sets of G .
The maximum independent set problem (MIS) is to determine a maximum independent set of an arbitrary graph. As one of Karp's 21 NP-complete problems ( Karp, 1972 ), MIS is among the most popular problems in combinatorial optimization ( Garey and Johnson, 1979; Johnson and Trick, 1996 ).

In graph theory, there are two tightly related problems: the maximum clique problem (MC) and minimum vertex cover pro-blem (MVC). A clique C of G is a subset of V such that all vertices in
C are pairwise adjacent, i.e., 8 v i ; v j A C ; f v i ; v clique C of maximum cardinality. A vertex cover VC of G is a subset of V such that each edge of E is incident to at least one vertex of VC , cover of minimum cardinality.

Let G  X  X  V ; E  X  be the complementary graph of G  X  X  V ; E  X  such that E V V and 8 v i ; v j A V ; f v i ; v j g A E if and only if f v
Then given a subset S of V , the following three statements are equivalent ( Wu and Hao, 2014 ): S is an independent set in G , V n S is a vertex cover in G and S is a clique in G . As a consequence, MIS,
MC and MVC are three equivalent problems such that any algo-rithm designed for one of these problems can be directly applied to solve the other two problems. These problems are relevant to a wide variety of applications such as code theory, information retrieval, signal transmission, classi fi cation theory, experimental design and many more others ( Bomze et al., 1999; Johnson and
Trick, 1996; Wu and Hao, 2014 ). In this work, we focus on studying the MIS problem.

During the past decades, a large number of solution procedures for solving MIS, MC and MVC have been reported in the literature.
Among them are several exact algorithms based on the general branch-and-bound framework ( Carraghan and Pardalos, 1990; Li and Quan, 2010;  X sterg X rd, 2002; San Segundo et al., 2011; Tomita and Kameda, 2007 ). These exact methods are applicable to problem instances of limited sizes. For larger cases, various heuristics have been proposed to obtain near-optimal solutions. The most representative heuristics include tabu search ( Battiti and
Protasi, 2001; Friden et al., 1989; Wu et al., 2012; Wu and Hao, 2013 ), stochastic local search ( Andrade et al., 2012; Grosso et al., 2008; Katayama et al., 2005; Pullan, 2006, 2008 ), parallel hyper-heuristics mixing several low-level heuristics ( Pullan et al., 2011 ), simulated annealing ( Geng et al., 2007 ), variable neighborhood search ( Hansen et al., 2004 ), breakout local search ( Benlic and Hao, 2013 ), local search with edge weighting ( Cai et al., 2013; Richter et al., 2007 ) and evolutionary algorithms ( Brunato and Battiti, 2011;
Zhang et al., 2005 ).). According to the reported results on bench-mark instances, in particular those of the well-known Second DIMACS Implementation Challenge on Cliques, Coloring, and
Satis fi ability ( Johnson and Trick, 1996 ), it seems that ILS and GLP ( Andrade et al., 2012 ), BLS ( Benlic and Hao, 2013 ), NuMVC ( Cai et ( Richter et al., 2007 ), MN/TS ( Wu et al., 2012 ) and AMTS ( Wu and
Hao, 2013 ) are among the top performing heuristics in the literature. Nevertheless, due to the large variety of structures of these instances (they are random graphs or transformed from different real problems), no single approach can attain the best-known results for all the DIMACS instances.
 (SBTS) heuristic for the maximum independent set problem. SBTS inspects the search space by a dynamic alternation between intensi fi cation and diversi fi cation steps ( Glover and Laguna, 1997; Louren X o et al., 2003; Schrimpf et al., 2000 ). The search process is driven by a general and uni fi ed ( k ,1)-swap ( k operator combined with speci fi c rules to explore four constrained neighborhoods. Given an independent set S ,( k ,1)-swap exchanges one vertex (which is strategically selected) in V n S against its k adjacent vertices in S . For the purpose of intensi fi cation, SBTS uses (0,1)-swap to improve the solution and (1,1)-swap to make side-walks with the help of speci fi c selection rules. To overcome local optima, SBTS adopts an adaptive perturbation strategy which applies either a (2,1)-swap for a weak perturbation or a (k,1)-swap ( k 4 2) for a strong perturbation. A tabu mechanism is also employed to prevent the search from short-term cycles. Compared with existing local search algorithms, SBTS distinguishes itself by dedicated rules for neighborhood exploration.
 for all 120 instances of the well-known DIMACS and BHOSLIB benchmarks with very different structures and topologies. This is the fi rst time a single heuristic reaches such a performance. The best-known results are also attained on an additional set of 11 real instances from code theory.
 the SBTS approach. Section 3 shows computational results and comparisons with the state-of-the-art algorithms in the literature.
Before concluding, Section 4 investigates and analyzes some impor-tant issue of the proposed algorithm. 2. A swap-based tabu search for MIS the iterated local search framework ( Louren X o et al., 2003 ) and shares similarities with other methods like variable neighborhood search ( Hansen et al., 2004 ) and the ruin-and-recreate search ( Schrimpf et al., 2000 ). However, as we explain in this section,
SBTS possesses some particular features like four constrained neighborhoods and the speci fi c rules for an effective exploration of these neighborhoods. 2.1. General procedure
SBTS uses a fast randomized construction procedure (Section 2.3 ) are adjacent, S is also called a feasible solution or simply a solution in the paper). From this initial solution, SBTS tries to fi solutions (i.e., larger independent sets) by a series of intensi tion and diversi fi cation steps (Sections 2.7 and 2.8 ). Both intensi-fi cation and diversi fi cation steps are based on the general  X  k swap operator (Section 2.5 ).
 ( k  X  0 ; 1) to increase the cardinality of the independent set or search new solutions while keeping the cardinality unchanged. Inversely, a diversi fi cation step applies a  X  k ; 1  X  swap move ( k to decrease temporarily the quality of the current solution (the current solution loses k 1 vertices). Whenever there exist inten-si fi cation moves, they are always preferred over diversi fi cation moves. Diversi fi cation moves are only applied to escape from a local optimum (i.e., when no eligible  X  k ; 1  X  swap move ( k  X  0 available). As we explain in Sections 2.7 and 2.8 , both intensi tion and diversi fi cation are subject to dedicated rules which govern the way  X  k ; 1  X  swap moves are executed.

SBTS uses a global variable S n to record the best solution ever discovered during the search and a tabu list to prevent short-term cycles (see Section 2.6 ). The algorithm stops when a fi xed number of iterations are realized.
 Algorithm 1. General procedure of the SBTS algorithm for MIS. 1: Input : A graph G , Iters max (maximum allowed iterations 2: Output : The largest independent set S n found. 3: S  X  Initialization  X  X  / n Generate a feasible independent set 4: S n  X  S / n S n records the largest independent set found so 5: f n  X  f  X  S  X  / n f n records the cardinality of S n n 6: Initialize tabu_list / n Initialize the tabu list, Section 2.6 7: for iters  X  1 to Iters max do 8: if there exists an eligible intensi fi cation move then 9: S  X  IntensificationStep  X  S  X  / n Apply  X  k ; 1  X  swap 10: if f  X  S  X  4 f n then 11: S n  X  S , f n  X  f  X  S  X  12: end if 13: else 14: S  X  DiversificationStep  X  S  X  / n Apply  X  k ; 1  X  swap 15: end if 16: Update tabu_list / n Section 2.6 n / 17: end for 18: return S n 2.2. Search space and evaluation function
Before presenting the components of the SBTS algorithm, we de fi ne fi rst the search space  X  explored by the algorithm as well as its evaluation function f to measure the quality of a candidate solution.

For a given graph G  X  X  V ; E  X  , the search space  X  explored by SBTS is the set of all the independent sets of G , i.e.,  X   X f S D S ; sets S and S 0 , S is better than S 0 if and only if f  X  S  X  2.3. Initial solution
The initial solution used by the SBTS algorithm is generated by the following sequential randomized heuristic ( V is the vertex set of graph G ). 1. Set S to empty. 2. Select randomly a vertex u A V and add u into S. 3. Remove from V vertex u and all its adjacent vertices v  X f u ; v g A E  X  . 4. Repeat steps (2)  X  (3) until V becomes empty and return S.
It is easy to observe that the resulting solution S is a feasible (and maximal) independent set. Due to the random choices at step (2), each run of this construction procedure may lead to a different solution. Given the stochastic nature of SBTS, this feature is useful for multiple runs of SBTS. 2.4. Preliminary de fi nitions
To explain the intensi fi cation and diversi fi cation mechanisms of SBTS, we introduce some key concepts (measures) which are particularly useful to de fi ne the different neighborhoods and the application rules of the general  X  k ; 1  X  swap operator.
De fi nition 1 ( Mapping Degree K M ). Given a graph G  X  X  V ; E  X  and an independent set S , the Mapping Degree of a vertex v i is the number of its adjacent vertices v j in S , i.e., 8 v K  X  v i  X  X jf v j A S : f v i ; v j g A E gj . A similar de fi Degree can be found in Andrade et al. (2012) .
 Fig. 1 shows a graph G with 10 vertices and an independent set tion, vertex 2 in V n S has one adjacent vertex (1) in S , hence the
Mapping Degree K M  X  2  X  X  1. Similarly, the Mapping Degrees of the other vertices in V n S are shown in Table 1 . The Mapping Degree is used to partition the vertices of V n S into four subsets which de fi ne the neighborhoods used by SBTS (see Section 2.5 ).

De fi nition 2. (Expanding Degree K E ) The Expanding Degree of a vertex v i in S is the number of its adjacent vertices V n S whose Mapping Degree K M equals to 1, i.e., 8 v i A jf v A V n S : f v i ; v j g A E ; K M  X  v j  X  X  1 gj .

In Fig. 1 , among the 4 vertices of S , only vertices 1 and 4 have adjacent neighbors in V n S with a Mapping Degree of 1, thus their
Expanding Degree is K E  X  1  X  X  1 and K E  X  4  X  X  2 while vertices 6 and 8 have zero Expanding Degree (see Table 1 ). The Expanding
Degree is used to de fi ne the rule to exploit the neighborhood induced by (1,1)-swap (see Section 2.7 ).

De fi nition 3 ( Diversifying Degree K D ). Given a graph G  X  X  V an independent set S , the Diversifying Degree of a vertex is the number of adjacent vertices v j in V n S , i.e. 8 v K  X  v  X  X jf v j A V n S : f v i ; v j g A E gj .

The Diversifying Degree is used to differentiate vertices with the same Expanding Degrees when the neighborhood induced by (1,1)-swap is exploited (see Section 2.7 ). It is also employed to de fi ne the rule to select degrading, i.e.,  X  k ; 1  X  swap  X  k to escape from local optima (see Section 2.8 ).

For the details of our example shown in Fig. 1 , see Table 1 .As shown in the Appendix, these measures will be dynamically updated after each iteration of the algorithm and this can be achieved ef fi ciently in an incremental way. 2.5.  X  k ; 1  X  swap , neighborhoods and exploration of neighborhoods
The search process of the SBTS algorithm is basically driven by we provide a detailed presentation of this operator, the diffe-rent neighborhoods induced by the operator and the way these neighborhoods are explored.
 Let  X  S  X  k ; 1  X  swap  X  denote the application of  X  k ; 1  X  swap ( k to S . Then the resulting solution S 0 is given by S 0  X  S  X  k cardinality of the current solution S . The resulting solution has a k
Z 2), the resulting solution is deteriorated by k 1 units. More-over, whatever the value k takes, applying a  X  k ; 1  X  swap move to an independent set always leads to a feasible solution. we introduce four different neighborhoods. Precisely, given an independent set S (the current solution), we partition its comple-mentary set V n S into four subsets according to the Mapping
Degree of each vertex (see Section 2.4 ). 1. NS k : the set of vertices v i in V n S whose Mapping Degree K 2. NS 4 2 : the set of vertices v i in V n S whose Mapping Degree K f 2 ; 3 ; 5 ; 7 ; 9 ; 10 g ,wehave NS 0  X f 9 g ; NS 1  X f 2 ; 3 NS 4 2  X f 7 g .
 different (and constrained) neighborhood when it is employed by neighborhood is composed of all the solutions obtained by swap-ping a vertex of NS k with its k adjacent vertices in S . For this reason, we will also use NS k ( k  X  0 ; 1 ; 2 ; 4 2  X  to denote the associated neighborhoods interchangeably.
 iteration a particular vertex from one NS k ( k  X  0 ; 1 ; follows. SBTS fi rst examines NS 0 to see whether an improving (0,1)-swap move is applicable. If NS 0 is not empty, a (0,1)-swap move is applied with a vertex randomly chosen from NS 0 . Other-wise, if NS 1 offers eligible vertices, a side-walk (1,1)-swap move is applied to a vertex of NS 1 which is selected according to the speci fi c rule presented in Section 2.7 .If NS 1 is empty or all the vertices of NS1 are forbidden by the tabu list, SBTS makes a degrading  X  k ; 1  X  swap move with a vertex from NS 2 or NS following the rule de fi ned in Section 2.8 . Hence, at each iteration, neighboring solutions to explore the search space. According to the value of k , each iteration corresponds to either an intensi tion step ( k  X  0,1) or a diversi fi cation step ( k Z 2). After each iteration, K M ; K E ; K D , along with the neighborhoods NS sizes are updated accordingly (see Appendix).

NS 0 will be exhausted very rapidly. Among the remaining NS and should not be used frequently. The only set that could lead to a hopeful improvement of the solution is NS 1 .In Sections 2.7 and 2.8 , we introduce dedicated rules for the exploration of the neighborhoods NS k with k Z 1. 2.6. Tabu list and aspiration rule ( Glover and Laguna, 1997 ). Precisely, each time a  X  k ; is executed, the k vertices which are swapped out from the independent set S are classi fi ed tabu in order to prevent these vertices from moving back to S for the next tt iterations ( tt is called tabu tenure). On the other hand, the vertex which joins S is not subject to tabu prohibition. Thus the tabu list is updated only after a  X  k ; 1  X  swap with k Z 1.

Suppose  X  k ; 1  X  swap exchanges vertex v i A NS k ( k Z 1) and its k adjacent vertices ( v j 1 ; v j 2  X  v j k )in S . For each vertex v tabu tenure tt is adaptively set as follows. Random ( A ) returns a random value from the domain f 0  X 
Otherwise, tt  X j NS 1 j . k 4 1: tt is set to 7.

These tabu tenure rules are purely empirical. However, for the case of k  X  1, the fi rst part corresponds to situations which occur usually and the adopted tabu tenure ( tt  X  10  X  Random  X j NS 1 j X  )is inspired from the literature ( Dorne and Hao, 1998; Galinier and Hao, 1999; Wu and Hao, 2013 ). The second part (which occurs occasionally) is based on the consideration that when there are many side-walk moves (i.e., j NS 1 j is very high relative to j NS before having tried a number of side-walk moves as high as j NS For the case of k 4 1, since there are several vertices (at least two) leaving the independent set and these k vertices are not chosen according to speci fi c objectives, there is no reason to prevent them from joining the solutions for a long period of time. For this reason, the tabu tenure for them can be set to a relatively small value. In fact, we observe that as long as the tabu tenure remains in the range of 4 to 10, it does not really impact the performance of the algorithm. So we set the tabu tenure to the middle value 7 which proves to be robust in our experiments. In Section 4.2 ,we provide more information about the tabu tenure.

Notice that vertices in NS 0 are never forbidden by the tabu list given that any vertex in NS 0 can increase the current solution by one unit. This can be considered as an aspiration condition ( Glover and Laguna, 1997 ) that revokes the tabu status of any vertex if it belongs to NS 0 .

Finally, given an independent set S and the associated sets NS ( k  X  1 ; 2 ; 4 2), a vertex from any NS k is said eligible if it is not forbidden by the tabu list. 2.7. Intensi fi cation
Intensi fi cation of the SBTS algorithm aims to fi nd better solutions or to reach new solutions without deteriorating the current solution. For this purpose, whenever NS 0 is not empty, SBTS applies  X  0 ; 1  X  swap to improve the solution. For instance, in Fig. 1 , given the current solution S  X f 1 ; 4 ; 6 ; 8 g , NS NS 1  X f 2 ; 3 ; 5 g , SBTS will select vertex 9 to apply  X  0 generate a better solution S  X f 1 ; 4 ; 6 ; 8 ; 9 g . When NS empty, SBTS checks then the NS 1 neighborhood for a possible (1,1)-swap (side-walk) move.

If NS 1 offers multiple choices for a (1,1)-swap, one must decide which vertex of NS 1 is selected for the (1,1)-swap. One trivial strategy is to make this decision at random. However, as we illustrate below, the order of examining the vertices in NS (1,1)-swap may impact the solution quality. To make this decision as fruitful as possible, we devise a selection rule which takes into account problem speci fi c information relative to the Expanding Degree and Diversifying Degree (see Section 2.4 ). The proposed selection rule favors the (1,1)-swap moves that tend to create new promising (e.g., improving) moves for future iterations.
Selection Rule for the NS 1 neighborhood examination : 1. Collect in set NS 1 any vertex v i A NS 1 such that its adjacent neighbor v j in S has the largest Expanding Degree. 2. If NS 1 is composed of a single vertex, select this vertex; otherwise, select the vertex v i A NS 1 with the largest Diversify-ing Degree (ties are broken at random).

The fi rst part of this Selection Rule is based on the following consideration. When swapping v i A NS 1 with v j A S such that the largest Expanding Degree, we encourage the emergence of improving (0,1)-swap moves. For instance, in Fig. 1 , given
NS  X f 2 ; 3 ; 5 g and suppose that all the vertices in NS 1 are eligible for a (1,1)-swap move (the notion of eligibility under the tabu rule is explained in Section 2.6 ). Since vertices 3 and 5 of NS adjacent vertex 4 in S with an Expanding Degree of 2 while vertex 2of NS 1 has the adjacent vertex 1 in S with an Expanding Degree of 1, we have NS 1  X f 3 ; 5 g (i.e., vertices 3 and 5 are preferred than vertex 2). At this point, one notices a (1,1)-swap using any vertex 3or5of NS 1 (say 3) will change the Mapping Degree of the other vertex (vertex 5) to 0. This makes the other vertex to become a member of the updated NS 0 and could be added to the indepen-dent set at the next iteration. In comparison, since vertex 2 has an Expanding Degree of 1, swapping 2 into S cannot create any improving moves.

The second part of this Selection Rule is based on the con-sideration that the vertices of NS 1 with a larger Diversifying
Degree could make the search more diversi fi ed after a (1,1)-swap move. Indeed, after swapping v i A NS 1 and v j A S , we need to update the Mapping Degree, the Expanding Degree and Diversify-ing Degree concerned by v i and v j (see Appendix), leading to modi fi cations of the neighborhoods NS k  X  k  X  0 ; 1 ; 2 nition, a vertex v i A NS 1 with a larger Diversifying Degree has more adjacent vertices in V n S . Selecting such a vertex for a (1,1)-swap move leads to more changes in V n S , thus more changes in the diversify the choices of the next iteration of the search procedure. For our example in Fig. 1 , vertices 3 and 5 have respectively a
Diversifying Degree of 2 and 3. According to the Selection Rule , vertex 5 (instead of vertex 3) is selected to take part in the swap move with vertex 4 in S . After this move, three vertices (2, 9 and 10 which are adjacent to 5 in V n S ) take part in neighborhood updating. In comparison, vertex 3 in NS 1 (with a small Diversifying Degree) will induce fewer changes in the neighborhoods.
One notices that this heuristic selection rule has no theoretical guarantee of being able to always lead to the best choice. However, the rule is designed to favor a good choice when such a choice is available. The computational results shown in the paper con its usefulness in practice.
 Further reducing NS 1 neighborhood examination :
As explained above, among the vertices of NS 1 , those v i adjacent neighbor v j in S has an Expanding Degree of 1 are less promising than the other vertices since using these v i in (1,1)-swap can only lead to new side-walk (or degrading) moves and can never create new improving moves for the next iteration. In order to prevent the search from making uselessly too many side-walk moves, we de fi ne an additional rule to reduce NS 1 as follows. If there are more (1,1)-swap moves than  X  k ; 1  X  swap  X  k 4 (i.e., j NS 1 j 4 j NS 2 j X j NS 4 2 j ), we exclude from NS its adjacent neighbor v j has an Expanding Degree of 1. For instance, in Fig. 1 , NS 1  X  {2, 3, 5}. If we apply this reduction rule, vertex 2 will be excluded from NS 1 since the Expanding Degree of its neighbor in S (vertex 1) equals to 1. Experiments show that this reduction rule could improve the search ef fi ciency for a number of situations where a large number of side-walk moves frequently appear during the search process.

Algorithm 2. The Intensi fi cation Step for MIS. 1: Input : A feasible independent set S 2: Output : The independent set S 0 . 3: / n Explore neighborhood NS 0 with an improving (0,1)-swap 4: if NS 0 is not empty then 5: Choose randomly a vertex v i from NS 0 ; 6: S 0  X  S  X  0 ; 1  X  swap; 7: else 8: / n Explore neighborhood NS 1 with a side-walk (1,1)-9: if j NS 1 j 4 j NS 2 j X j NS 4 2 j then 10: Exclude vertices v i from NS 1 whose neighbor v j in S 11: end if 12: Determine a vertex v i from NS 1 according to Selection 13: if v i is obtained then 14: S 0  X  S  X  1 ; 1  X  swap; 15: else 16: S 0  X  S ; 17: end if 18: end if 19: Perform the updating procedure; / n see Appendix n / 20: Return S 0 ; The pseudo-code of one intensi fi cation iteration is given in
Algorithm 2 where S is the current independent set and NS  X  k  X  0 ; 1 ; 2 ; 4 2  X  are the associated neighborhoods.

Notice that after each  X  1 ; 1  X  swap, the neighborhoods NS are updated accordingly (see Appendix). Additionally, the vertex that is swapped out from S is added to the tabu list to prevent it from being moved back to S for a number of next iterations (see Section 2.6 ).

If NS 0 is empty and NS 1 does not offer any eligible (1,1)-swap move (i.e., NS 1 is empty or all the vertices of NS 1 are forbidden by the tabu list), the search continues with a diversi fi which is explained in the next section. 2.8. Diversi fi cation
When the current solution cannot be further improved by a (0,1)-swap or changed by a (1,1)-swap, the search procedure is trapped in a local optimum. To escape from this local optimum, the SBTS algorithm resorts to  X  k ; 1  X  swap  X  k Z 2  X  moves to perturb the current solution in order to displace the search to a new search zone. These swap moves are carried out according to some dedicated rules which once again depend on problem speci fi information.

One observes fi rst that a  X  k ; 1  X  swap  X  k Z 2  X  move applied to a solution S deteriorates the cardinality of S by exactly k 1 units.
Consequently, a smaller k (e.g., k  X  2) perturbs more weakly a solution while a larger k (e.g., k 4 2) changes more strongly the solution. To control the perturbation strength, SBTS adopts an adaptive strategy according to a relation between the number of possible  X  1 ; 1  X  swap moves (i.e., j NS 1 j ) and the number of  X  k ; 1  X  swap ( k 4 1) moves (i.e., j NS 2 j X j NS 4 2 j ). Precisely, the adaptive perturbation strategy is de fi ned as follows. perturbation by a  X  k ; 1  X  swap  X  k 4 2  X  move as follows: Select an eligible vertex v i of NS 4 2 with the largest Diversifying Degree (ties are broken at random) and swap the chosen vertex v i its k neighbors in S . 2. Otherwise, SBTS applies with equal probability either NS
NS 4 2 to perform either a weak or strong perturbation. optimum is reached, all the vertices of NS 1 are prohibited by the tabu list (i.e., they have been removed recently from the indepen-dent set S , see Section 2.6 ). A large NS 1 indicates thus that in the recent past, the search has gone through a high number of side-walk moves. This situation corresponds to a kind of deep local optimum which is dif fi cult to escape. To displace the search into a new search zone, we need to apply a strong perturbation which is achieved by employing a  X  k ; 1  X  swap move with k 4 2. has made a relative small number of side-walk moves. In this case, we alternate probabilistically the perturbation strength to try to fi nd better solutions in a zone around the current local optimum (with a weak perturbation) or far from current local optimum (with a strong perturbation).
 neighborhood sets NS k ( k  X  0 ; 1 ; 2 ; 4 2) are updated accordingly (see Appendix). The k vertices that are swapped out from S are added to the tabu list (Section 2.6 ). 3. Experimental results 3.1. Benchmark instances carry out experiments on three different data sets: DIMACS, BHOSLIB and CODE.
 their complement graphs to test our SBTS algorithm. For BHOSLIB and CODE benchmarks, the original graphs are used. 3.2. Experimental protocol
Our SBTS algorithm is coded in C  X  X  1 and compiled using g  X  X  with the  X  -O2  X  option on a Cluster running Linux with 2.83 GHz and 8 GB. When we run the DIMACS machine benchmark program 2 on our machine, we obtain the following results: 0.20 CPU seconds for graph r300.5, 1.23 CPU seconds for r400.5 and 4.68 CPU seconds for r500.5.

Given its stochastic nature, we run SBTS independently 100 times to solve each instance with initial solutions generated by the procedure of Section 2.3 . The stop condition of each run is a maximum of 10 8 iterations which are divided into 10 4 restarts, each restart being limited to 10 4 iterations (i.e., Iters Algorithm 1 ). This experimental protocol is typically used in the literature (see next section). SBTS runs with the self-tuned tabu tenure tt given in Section 2.6 . Though fi ne-tuning tabu tenure would lead to improved results for some graphs, for our experi-ments, we used the above tabu tenure except as otherwise stated. No other parameter is required by SBTS. 3.3. Computational results of SBTS on DIMACS, BHOSLIB and CODE instances
Tables 2  X  4 show respectively the computational statistics of the SBTS algorithm on the three sets of benchmark instances with respect to f bk which designates the optimal value or the best lower bound (i.e., the largest independent set ever reported in the literature). Notice that for the popular DIMACS and BHOSLIB benchmarks, recent heuristics can attain the f bk value for many cases, as it is shown in Table 5 of Section 3.4 .

Table 2 shows the computational statistics of the SBTS algo-rithm on the set of 80 DIMACS instances. Columns 1  X  4 give the characteristics of each graph: the name, the number of vertices and edges, and the optimal or best-known result f bk (optimal values are marked with  X  n  X  ). The columns under heading Success for reaching f n over the 100 independent runs, the average iterations AvgIters and the average CPU time t ( s ) (seconds) over the successful runs.

Table 2 demonstrates that SBTS obtains quite competitive results on the set of DIMACS instances. Speci fi cally, SBTS can consistently reach the previous best-known solutions for 75 out of the 80 instances with a perfect success rate. Furthermore, SBTS can reach the best-known results for all the instances with various topologies and densities, including the most dif fi cult graphs (brock best of our knowledge, the top-performing heuristics in the literature miss at least one best-known result of these dif graphs. On the other hand, one observes that SBTS has a low success rate (less than 50%) for 3 graphs. Notice that for the 4 open instances (C500.9, C1000.9, C2000.9, johnson32_2_4), SBTS hits the best lower bounds for each run except for C2000.9. One can speculate that these lower bounds (except for C2000.9) would be close to or would be optimal solutions and thus are dif fi improve, even though this observation does not constitute a proof. As for the computing time, SBTS requires on average less than 1000 seconds except for C2000.9 and C4000.5.

Table 3 reports the computational results of SBTS on the set of 40 BHOSLIB instances. The columns 1  X  4 give the characteristic of the graphs and columns 5  X  9 present the detailed results of the proposed SBTS algorithm. From this table, one fi nds that SBTS also performs well for this benchmark set. Speci fi cally, SBTS reaches the optimal results with a perfect success rate for the instances with up to 1000 vertices. The BHOSLIB set is known to be more dif fi cult compared to most of the DIMACS benchmark. Yet, SBTS can still attain the optimal results for all the 40 instances. On the other hand, SBTS has a low or very low success rate (less than 50%) for 11 graphs and requires a large computing time for the largest instances.
 on the set of 11 CODE instances where the best-known results f bk are from ( Andrade et al., 2012; Sloane, 2000 ). The results of SBTS are obtained with the default tabu tenure tt except those of 1et.2048, 1tc2048 and 1zc.4096 for which tt  X  40  X  Randdom  X j NS 1 j X  .Fromthetable,one fi nds that SBTS attains the best-known results for all the CODE instances in a short time. SBTS reaches the best-known results with a perfect success rate for 9 out of 11 instances. However, for one ca se (1zc.4096), its success rate is very low (1%).

From the results on DIMACS, BHOSLIB and CODE benchmarks, one observes that there is no clear correlation between the problem size and the necessary time to solve it since the dif of an instance also depends on its structure.
 3.4. Comparisons with seven state-of-the-art algorithms relative to the state-of-the-art methods, we compare in this section SBTS with some best-performing algorithms for MIS, MC and MVC in the literature. We present two comparisons which concern the DIMACS and BHOSLIB sets on the one hand and the
CODE set on the other hand. 3.4.1. Comparisons with fi ve references algorithms on DIMACS and BHOSLIB benchmarks from DIMACS and BHOSLIB sets and ignore the other instances since they can be easily solved with a 100% success rate by all the compared algorithms. First we summarize below the experimental conditions used by 5 reference algorithms which are implemented on sequential architectures and report state-of-the-art computa-tional results on both DIMACS and BHOSLIB benchmarks.
 All the results are based on 100 independent runs for each graph.
The reported results of the reference algorithms are extracted from the corresponding papers while the results of SBTS are from Tables 2 and 3 .
 followed by the average result f avg given in parenthesis over 100 runs if the success rate is lower than 100%, and the average time in seconds t ( s ) over the successful runs. For COVER, as stated in of a typical run of the algorithm. instances for which an algorithm cannot reach the best-known results in the literature and  X  Avg.  X  indicates the average value of f avg for the 45 instances for each algorithm. Note that,  X  means that the result is unavailable.
 algorithm fails to fi nd the best-known results for at least two instances (entries in italic). Indeed, given that these instances have very different characteristics and structures, it is known that it is very dif fi cult for a single heuristic to perform well on all the instances ( Pullan et al., 2011 ). Besides, SBTS has a slightly better average result of 74.21 against 74.18 of PLS which is the best among the reference algorithms (except NuMVC whose average is an optimistic upper bound since its results are missing for six instances). When we examine the results of Table 5 in detail, we can make the following observations.

For the DIMACS instances, MN/TS, BLS and PLS (which are maximum clique or maximum independent set algorithms) reach the best reported results for the groups  X  brock  X  ,  X  C  X  high success rate except for C2000.9 which is among the most dif fi cult instance. For this instance, MN/TS and BLS achieve the best-known result (80) with an average of 78.37 and 78.60 respectively while PLS fails to fi nd solutions larger than 78. For the group  X 
MANN  X  , MN/TS, BLS and PLS cannot to reach the best-known results of MANN_a45 (345) and MANN_a81 (1100). The largest solutions they fi nd have a size of 340, 342, 344 for MANN_a45, and a size of 1090, 1094, 1098 for MANN_a81 respectively. Generally, it seems that the typical MC or MIS algorithms (e.g., MN/TS, BLS, PLS) have serious dif fi culties to solve these two  X  MANN  X  instances.
By contrast, the typical MVC algorithms COVER and NuMVC perform well on the group  X  MANN  X  with a high success rate while they clearly encounter dif fi culties for the group  X  brock COVER fails to reach the best-known result for 6 out of the 12 brock instances. For the 6 brock instances tested by NuMVC, two results do not match the best-known values. Besides, for C2000.9, NuMVC can achieve the best-known result of 80 while COVER can only achieve a solution of size of 78.
 Our SBTS algorithm achieves the best-known results for all 25 DIMACS instances including the two  X  problematic  X  groups and  X  MANN  X  . In particular, SBTS can attain the best results for MANN_a45 and MANN_a81 with a perfect success rate, which is better than the typical MC or MIS algorithms.
 The average results given in parenthesis show that MN/TS, BLS, PLS, COVER and NuMVC can attain the reported best results in every single run for 20, 19, 21, 14 and 20 cases out of 25 DIMACS instances respectively, while SBTS has a perfect success rate for 20 cases, which is more than BLS and COVER, equal to MN/TS and NuMVC and one less than PLS. However, for C2000.9, the average result of SBTS is slightly worse than the reference algorithms.
For the BHOSLIB instances, the reference algorithms can attain the best-known results except PLS which fails to reach the optimal solutions for frb59-26-1 and frb59-26-2. One observes from the average results that MN/TS, BLS, PLS, COVER and NuMVC can attain the optimal solutions in every single run for 3, 4, 1, 1 and 13 cases respectively. Our SBTS algorithm is able to reach the best-known results with a perfect success rate for 2 cases, which is more than PLS and COVER but less than MN/TS, BLS and NuMVC.

Finally, it is more delicate to make a fully fair comparison of the computing time given that the compared algorithms are coded in different languages with different data structures, run on different platforms and more importantly lead to results of different quality for a number of graphs. As an indicative, we observe that to reach a result of equal quality, SBTS is more time consuming than MN/TS, COVER and NuMVC, but remains competitive with BLS and PLS. 3.4.2. Comparisons with two reference algorithms on CODE benchmark The CODE benchmark is less popular than the DIMACS and BHOSLIB sets and few papers report results on the 11 CODE instances including ( Andrade et al., 2012; Butenko et al., 2009; Etzion and Ostergard, 1998 ). However, we think the CODE instances are of interest since they come from real problems (code theory) and known to be relatively dif fi cult. For this study, we adopt as our reference two most recent algorithms that use the CODE benchmark: ILS and GLP ( Andrade et al., 2012 ). 3 Both ILS and
GLP are run on a computer equipped with a 3.16 GHz Intel Core 2 Duo CPU and 4 GB of RAM. Unlike the reference studies of the last section which make 100 independent runs, the results of ILS and GLP reported in Andrade et al. (2012) are based on 15 runs.
The stop condition for each run is the average arc (edge) scans limited to 2 17 ( Andrade et al., 2012 ).

In addition to the 11 CODE instances, the authors of Andrade et al. (2012) also report results on a subset of 33 DIMACS and 9 BHOSLIB instances (8 instances as they are introduced in Section 3.1 plus one additional challenging instance frb100-40). To make a fair comparison, we re-run SBTS 15 times (like ILS and GLP) on these 11 CODE instances and the 42 DIMACS/BHOSLIB instances.
Since there is no evident way to relate the number of average arc (edge) scans used by ILS and GLP to the number of iterations used by SBTS, SBTS is run under the stop condition given in Section 3.4 .
To report the results, we only retain the 12 (out of 33) most dif fi cult graphs for the DIMACS set while keeping the 11 CODE instances and the 9 BHOSLIB instances since for the remaining instances, all three compared algorithms reach the same results.
Table 6 shows the comparison of ILS (columns 3 and 4), GLP (columns 5 and 6) and SBTS (columns 7 and 8): the best result f followed by the average results f avg given in parenthesis over 15 runs, and the average time in seconds t ( s ) over the successful runs.
From Table 6 , one observes that ILS and GLP cannot reach the best-known results for 9 (entries in italic) out of 21 dif
DIMACS and BHOSLIB instances while SBTS fails to reach the best-known result for 4 instances with its 15 runs (corresponding to the cases where its success rate is lower than 15%, see
Tables 2 and 3 ). Furthermore, the average results of SBTS on the instances which cannot be solved with a 100% success rate are all better than ILS and GLP except for C2000.9 where the average of
SBTS (77.1) is worse than GLP (77.5) but better than ILS (76.9). We do not emphasize the computing time since the compared algo-rithms give several results of different quality ( f n ).
For the CODE set, the three compared algorithms can achieve the best-known result for the 11 instances. Furthermore, ILS and
GLP reach the best results with a 100% success rate for 5 and 6 cases respectively against 10 cases for our SBTS algorithm (i.e., except 1zc.4096).
 To conclude, the comparative results indicate that the proposed
SBTS algorithm is quite competitive with the reference algorithms not only for the best obtained solutions but also for the average solutions. SBTS seems to be the most comprehensive approach to solve the DIMACS, BHOSLIB and CODE instances with multiple topologies and densities. 4. Analysis of SBTS
Now we turn our attention to an analysis of the important feature of the proposed SBTS algorithm: the selection rule for intensi fi cation (Section 2.7 ) and the analysis of tabu tenure (Section 2.6 ).
 4.1. In fl uence of the selection rule for intensi fi cation
NS 1 neighborhood for (1,1)-swap moves. In this section, we carry out an experiment to verify the importance of this dedicated
Selection Rule compared to a random selection rule. For this purpose, we create a variant of SBTS (denoted by SBTS random replacing its Selection Rule with a random selection rule. With
SBTS random , when NS 1 offers multiple eligible vertices, one of them is picked at random and used by the (1,1)-swap move.
 each of the 32 instances (DIMACS, BHOSLIB, CODE) of Section 3.4.2 under the same condition as before. The results are given in Table 7 which shows for each algorithm the best result f n , the average result f avg (in parenthesis) and the average time in second t ( s )toreachthe best result f n .From Table 7 , one notices that SBTS performs better than SBTS random both in terms of the best result f n and the average instances except frb100-40 while SBTS random attains the best-known result for only 25 cases out of 32 instances. Besides, SBTS has a perfect success rate for 20 cases against 13 cases for SBTS experiment demonstrates the use fulness of using the proposed
Selection Rule to explore the NS 1 neighborhood. 4.2. Analysis of the tabu tenure technique or k 4 1 (see Section 2.6 ). In this section, we carry out an experiment to show the usefulness of this tuning technique. For this purpose, we adopt for the case k 4 1 the same tabu tenure as for the case k  X  1 and denote the resulting variant by SBTS We use SBTS unique to solve 100 times each of the 32 instances under the same condition as before.

Table 8 shows the comparative results of SBTS unique (columns 3 and 4) and SBTS (columns 5 and 6). For each algorithm, we show the best result f n followed by the average result f avg (in parenth-esis) and the average time in second t ( s ). We observe that contrary to SBTS which fi nds all the best-known results except frb100-40 instance, SBTS unique fails to do so for 3 instances. SBTS has a perfect success rate of reaching the best-known result for 20 cases against 17 cases for SBTS unique . This study shows the interest of the adopted tabu tenue technique and con fi rms the importance of tuning the tabu tenure carefully. 5. Conclusion
In this paper, we have presented SBTS, a general and uni fi swap-based tabu search algorithm for solving the maximum independent set problem. The proposed algorithm explores the search space by a dynamic alternation between intensi fi cation and diversi fi cation steps. The search process is driven by the  X  k ; 1  X  swap operator combined with speci fi c rules to examine four different neighborhoods. For the purpose of intensi fi SBTS uses (0,1)-swap to improve the solution and (1,1)-swap to make side-walks with speci fi c selection rules. To overcome local optima, SBTS adopts an adaptive perturbation strategy which applies either a (2,1)-swap for a weak perturbation or a ( k ,1)-swap ( k 4 2) for a strong perturbation. A tabu mechanism is also employed to prevent the search from short-term cycles.
We have tested the proposed algorithm on two sets of 120 well-known instances (DIMACS and BHOSLIB) with multiple topologies and densities. Computational results show that SBTS competes favorably with 5 state-of-the-art algorithms in the literature. In particular, SBTS can achieve the best-known results for all the 120 instances. An additional test of SBTS on a set of 11 instances from code theory has con fi rmed its competitiveness relative to two other reference methods.

Even though the proposed approach achieves competitive results on the three benchmarks, one observes that some best results can only be reached occasionally. More studies are needed to improve the stability and search capacity of the approach. One possibility would be to introduce multiple search strategies and apply them dynamically and adaptively according to learned guiding information. Another possibility would be to combine
SBTS with the memetic search framework where a meaningful solution recombination mechanism must be sought.
 Acknowledgment
We are grateful to the anonymous referees for valuable sugges-tions and comments which helped us to improve the paper and to
Dr. R.F. Werneck for kindly sending us the CODE benchmarks. The work is partially supported by the following projects: RaDaPop and LigeRO (2009  X  2013, Pays de la Loire Region) and PGMO project (2014  X  2015, Jacques Hadamard Mathematical Foundation).
Support for Yan Jin from the China Scholarship Council is also acknowledged.
 Appendix A. Information updating procedure After each ( k ,1)-swap, SBTS updates the Mapping degree,
Expanding degrees and Diversifying degree of some vertices as well as the associated neighborhoods NS k ( k  X  0 ; 1 ; 2 explain below the updating procedure.

Suppose that v i A NS k ( k  X  0 ; 1 ; 2 ; 4 2) is swapped with its k adjacent vertices v j A S . Let v ia A V n S be any adjacent vertex of e., v ia A V n S , f v ia ; v i g A E ). For each v j , let v ja dure realizes the following operations. 1. First, for v i and each v j : Since v i moves from NS k Expanding Degree is initially set to 0. Since v j is removed from
S , its Mapping Degree and Diversifying Degree is initially set to 0. 2. Then, for each vertex v ia : its Diversifying Degree decreases by 1 and its Mapping Degree increases by 1. Meanwhile, the Mapping Degree of v j increases by 1.
 The Expanding Degree of v i increases by 1 if the Mapping Degree of v ia increases from 0 to 1 (including v j ) while the
Expanding Degree of v i decreases by 1 if the Mapping Degree of v ia increases from 1 to 2.

When the Mapping Degree of v ia changes from k to k  X  1 ( k  X  0 ; 1 ; 2), v ia moves from NS k to NS k  X  1 for k  X  0
NS 4 2 for k  X  2. If k 4 2, v ia stays in NS 4 2 . Notice that now to NS 1 . 3. Finally, for each v j and its adjacent vertices v ja in V n S : The Diversifying Degree of v ja increases by 1 while the Mapping Degree of v ja decreases by 1. Meanwhile, the Diversifying Degree of v j increases by 1 for each v ja .

For any v 0 j A S adjacent to v ja ( f v 0 j ; v ja g A E
Degree increases by 1 if the Mapping Degree of v ja decreases from 2 to 1.

According to the decrease of the Mapping Degree of v ja from k  X  1to k ( k  X  0 ; 1 ; 2), v ja displaces from NS k  X  1 ( NS NS k .If k 4 2, v ja stays in NS 4 2 .

Notice that no v j is swapped out from S if a (0,1)-swap is applied. In this case, only v i and its adjacent vertices in V n S need to be updated.

This procedure can be ef fi ciently performed in O  X  k  X jf v k jf v gj X  . For Fig. 1 , if vertex 9 is added into the solution S  X  {1, 4, 6, 8} after a (0,1)-swap, the Mapping Degree of its neighbors {5, 7, 10} becomes K M  X  5  X  X  2 ; K M  X  7  X  X  4 and K M  X  10  X  X  3. The Expanding
Degree of vertex 4 becomes K E  X  4  X  X  1. The new neighborhoods become: NS 0  X   X  , NS 1  X f 2 ; 3 g , NS 2  X f 5 g and NS 4 2 References
