
Our goal is to automatically identify which species of bird is present in an audio recording using supervised learning. Devising effective algorithms for bird species classification is a preliminary step toward extracting useful ecological data from recordings collected in the field. We propose a probabilistic model for audio features within a short interval of time, then derive its Bayes risk-minimizing classifier, and show that it is closely approximated by a nearest-neighbor classifier using Kullback-Leibler diver-gence to compare histograms of features. We note that fea-ture histograms can be viewed as points on a statistical manifold, and KL divergence approximates geodesic dis-tances defined by the Fisher information metric on such manifolds. Motivated by this fact, we propose the use of another approximation to the Fisher information met-ric, namely the Hellinger metric. The proposed classifiers achieve over 90% accuracy on a data set containing six species of bird, and outperform support vector machines.
Our goal is to develop algorithms that can predict which species of bird is present in an audio recording, by learn-ing from a collection of labeled examples. Such algorithms will serve as part of a system to automatically collect bird species presence/absence data, which will provide valu-able ecological information for species distribution model-ing and conservation planning. Existing bird species distri-bution data are collected by manual surveys, which are labor intensive, and require observers trained in bird recognition [2]. Automated bird population surveys could provide vast amounts of useful data for species distribution modeling, while requiring less effort and expense than human surveys. Other applications of classifying bird sounds include reduc-ing plane crashes caused by collisions with birds [5], and audio classification in general.

Sounds that birds make have a grammatical structure; two important levels of organization in this structure are songs and syllables. Syllables are single distinct utterances by a bird and serve as the basic building blocks of bird song
Figure 1. The spectrogram for a one-second portion of a recording of a Swainson X  X 
Thrush. Darker areas indicate higher energy at the corresponding frequency. [3]. A song consists of a series of syllables arranged in a particular pattern. In this study, our goal is to classify bird species from an interval of sound (containing one or more syllables), which roughly corresponds to the song level of organization.

Audio classification systems typically begin by extract-ing acoustic features from audio signals. Such features of-ten pertain to individual frames (i.e., very short segments of signal). For example, one commonly used feature is the spectrum of a signal frame, which describes the intensity of (a short segment of) the signal as a function of frequency. To apply many standard algorithms for classification, it is nec-essary to represent a sound, which contains multiple frames, using a fixed-length vector. To construct such a fixed-length feature vector to describe a sound as a whole, a common approach is to first identify interesting frames by segmenta-tion, compute features for those frames, then take the aver-age of the features over all frames [13, 23, 29]. For exam-ple, in the context of bird species recognition, a recent work by Fagerlund [13] (current state-of-the-art) averages frame-level features and applies support vector machines (SVMs).
Rather than averaging frame-level features, we represent their distributions using histograms (bag-of-codewords) de-fined by a  X  X odebook X  of clustered frame-level features. Codebook based representations have been successfully ap-plied in computer vision [7, 31, 19], and have also recently achieved success in music genre classification [26].
Our main contribution in this paper is to establish a the-oretical framework that connects nearest-neighbors classi-fiers using histograms of features, Bayesian risk minimiza-tion, and geodesics on statistical manifolds. In particular,  X  We propose a probability model for audio, then fol- X  We explain that not only do Kullback-Leibler and  X  We experimentally compare the accuracy of nearest-
We review data representation for audio classification, and related work on species identification from bird sounds.
Our goal is to classify a recording of bird sound as one of several species. A critical initial step toward this goal is to extract meaningful features to describe an interval of sound. This section presents our approach to constructing feature vectors to describe such intervals. 2.1.1 Basics: Signals and Spectrograms Audio signals consists of a time-series of samples , which we denote as s ( t ) . It is often easier to recognize patterns in an audio signal when samples are converted to a fre-quency domain spectrogram using the Fast Fourier Trans-form (FFT) [3], (see Fig. 1 for an example spectrogram).
To compute a spectrogram, samples in a sound are di-vided into overlapping frames (Fig. 2), each of which con-tains a fixed number of consecutive samples. The FFT is applied to each frame to obtain the complex Fourier coeffi-cients. The magnitudes of these coefficients are called the
Figure 2. An audio signal is made up of samples, which are divided into overlapping frames. frame X  X  magnitude spectrum and represent the intensity of the sound during that frame at different frequencies. A spec-trogram is a plot of the spectrum for each frame in a signal. 2.1.2 Frame-Level Features Many features for audio classification describe individual frames of a signal. In this section, we describe three features that we used in our experiments.
 Spectrum Density. The magnitude spectrum of a frame can be normalized to form a probability distribution. If the magnitude spectrum is ( | c 1 | ,..., | c l | ) , where l is the num-ber of elements in a spectrum, then the spectrum density is as the feature vector describing a frame.
 Mean Frequency and Bandwidth. Consider the spectro-gram shown in Fig. 1; each vertical slice represents the spectrum of one frame of sound. Bird sounds are usually concentrated at a few frequencies; we can see this phe-nomenon as horizontal strips in the spectrogram. This sug-gests that it is possible to condense the information con-tained in the spectrum density into just two values: the mean frequency and the bandwidth of the spectrum. The mean frequency of a frame indicates the vertical position of the strip, while bandwidth describes the width of the strip. Specifically, the mean frequency is f c = R xf ( x ) dx , and bandwidth is BW = q R ( x  X  f c ) 2 f ( x ) dx .
 Mel-Frequency Cepstral Coefficients. Mel-frequency cepstral coefficients [9] (MFCCs) are one of the most widely used features for audio classification. The idea is to first compute Mel-frequency coefficients (MFCs), which are like the magnitude spectrum, but in units of mels rather than Hz (mels correspond more closely with human percep-tion of pitch [30]). MFCs are computed by applying a col-lection of triangular filters to the magnitude spectrum; the MFCs are the response of each filter. The filters are evenly spaced in the mel scale. MFCCs are the result of applying the discrete cosine transform (DCT) to the log of the MFCs. 2.1.3 Aggregating Frame-Level Features An interval contains a large number of frames, which can be aggregated to produce a single fixed-length feature vector.
Figure 3. 2D histograms of frame mean fre-quency and bandwidth from two different in-tervals of audio recordings of the Downy Woodpecker.
 A common approach that has been used in syllable clas-sification is to average frame-level features [13, 23, 29]. However, by averaging, significant information about the distribution of features is lost, which can be problematic when the distribution of features in an interval is multi-modal. For example, Fig. 3(b) shows the distribution of the features (mean-frequency and bandwidth) of the frames from a 30-second recording of a downy woodpecker (ap-proximated by a 5000-bin histogram). In this case, the dis-tribution is clearly multimodal and its mean will actually be in an area of relatively low probability, making it a poor representation for the overall distribution. We observed that such multimodality is common for bird sound. This obser-vation suggests that aggregation schemes that can capture multimodality in feature distributions may be more success-ful than averages (our experimental results support this idea; Sec. 5.6). Inspired by the use of codebooks for image clas-sification [7, 31, 19], and recent work in music genre classi-fication [26], we consider aggregating frame-level features by representing their distributions with histograms. Low-Dimensional Feature Histograms. Given an inter-val (i.e., a set of frames), each of which is described by a d -dimensional feature vector, a natural way to represent the interval is to use the probability distribution of features in this interval. This distribution can be approximated by a d -dimensional histogram, where dimension i is discretized into k i bins, leading to a total of Q d i =1 k i bins. Note that since the total number of bins grows exponentially with d , this method can only be applied for small values of d . The vector of frequencies for each histogram bin can be used as a feature vector for classification.
 Codebook Feature Histograms. The simple binning ap-proach does not work for higher dimensional frame-level features such as spectra or MFCCs  X  we would need an infeasible number of bins to cover these high-dimensional spaces. Instead, we take a  X  X odebook X  approach [26] to con-structing histograms for high-dimensional features, which amounts to using non-uniform bins. A codebook is a collec-tion of k codewords, each of which is a feature vector that is considered as representative in the feature space. There is one bin associated with each codeword. Given an inter-val (i.e., a set of frames each described by a feature vector) and a codebook, to compute a feature for the interval, assign each frame to its closest codeword, then count the number of frames assigned to each codeword. The vector of counts, normalized by dividing by their sum, gives the final feature vector, which is a histogram.
Bird species can be classified using features extracted from audio recordings. A common approach to bird species classification is to identify distinct syllables, then construct feature vectors for those syllables and apply a standard clas-sifier such as nearest neighbor or support vector machines to predict the species for each syllable [29, 13, 16, 12, 23, 22, 27]. Song-level species prediction has also been inves-tigated using Hidden Markov Models [21, 29], Gaussian Mixture Models [29], based on comparisons of syllable-pair histograms [28], or nearest-neighbor classifiers using a fea-ture constructed by aggregating syllable features [23].
To classify syllables or songs, most prior work relies on segmentation of the input audio into syllables [29]. As such, the classifier accuracy can be strongly dependent upon ac-curate segmentation [12]. A standard approach to segmen-tation is to compute the energy of each frame, then adap-tively compute a threshold that separates syllables from background noise [29, 13, 25, 25]. It is difficult to obtain reliable segmentation using this method in recordings with low signal-to-noise ratio. In this paper, we use a simple ap-proach to detect a set of interesting frames within the signal that correspond to bird sound, and do not require that they precisely match syllable time-boundaries (Sec. 5).

Audio classification in general has been widely stud-ied, with applications to human speech and music being the most common. Our work is closely related to recent work by Seyerlehner et al. [26] on music genre identifi-cation. They follow a codebook approach to constructing audio feature histograms (Sec. 2.1.3), and use a nearest-neighbor classifier with L1 distance to classify these fea-tures. However, it is not obvious why a nearest-neighbor classifier is ideal for classifying histograms of features, or which distance measures are the best for comparing his-tograms. In this paper, we show that the Bayes optimal classifier for a probability model for audio is closely related Figure 4. The plate diagram for the Interval-IID model.

Variable Description m class label (bird species) n number of interesting frames in an interval  X  frame feature histogram parametrization x i i th test frame feature vector x ik i th training frame feature vector
X frame feature vector collection for an
X k frame feature vector collection for the y k class label associated with the K number of training intervals
K m number of training intervals from class m
P ( m ) class prior probability p (  X  | m ) class-conditional histogram probability p x |  X  ( x |  X  ) interval-conditional frame-p
X |  X  ( X |  X  ) interval-conditional features probability p
X | m ( X | m ) class-conditional features probability to nearest-neighbor classifiers using histograms of features with appropriate distance measures.
In the following section, we present a theoretical jus-tification for the frame-level feature histogram represen-tation through a probability model, namely the Interval-IID model, and show that the corresponding Bayes risk-minimizing classifier can be approximated by a nearest-neighbor classifier with KL divergence.
The Interval-IID model follows the graphical represen-tation in Fig. 4. The model suggests that to generate an interval, we first determine its class label m based on the class prior p ( m ) . Given m , we then generate an interval-specific parameterization  X  based on p (  X  | m ) , which param-eterizes the the frame feature distribution p x |  X  ( x |  X  ) of that interval. Given  X  , we then generate n independent and iden-tically distritbuted (i.i.d.) frame feature vectors x i based on p x |  X  ( x |  X  ) (thus the name Interval-IID, i.e., frames are i.i.d. within an interval).

Given an observed interval represented by its collection of frame features X = [ x 1 ,x 2 ,...,x n ] , using Bayes rule, we write its class-conditional probability as where  X  is a parametrization determining the interval-conditional feature distribution p x |  X  ( x |  X  ) and m denotes the class label. Here we marginalized over the interval-conditional features probability model p X |  X  ( X |  X  ) accord-ing to the class conditional histogram parametrization dis-tribution p (  X  | m ) . As the Interval-IID model name suggests, conditioned on  X  , the frame-level features are assumed i.i.d., and hence p X |  X  ( X |  X  ) can be written as a product of the marginal distributions of each frame-level feature: where x i denotes the feature vector of the i th frame. Sub-stituting (2) into (1), the class conditional model for the Interval-IID model is given by The integral w.r.t.  X  here applies to the product of marginal probabilities. By writing p as e log p and replacing the inte-gral with the expectation notation, (3) becomes To express p X | m ( X | m ) in (4) in terms of the Kullback-Leibler (KL) divergence, start by introducing the following terms: Note that  X   X  is the maximum-likelihood estimator of  X  . Us-ing (5-7) and the observation that P n i =1 log p x |  X  ( x  X  n (  X  H (  X   X  ) + D (  X   X  , X  )) , we rewrite (4) as By the definition of  X   X  in (5), we have that D (  X   X  , X  )  X  0 for all  X  and is zero for  X  =  X   X  . We proceed with the specific case in which the features are discretized into L non-intersecting bins defined by the sets A l . Hence, we represent the class-conditional distribution of frame-level features using histograms. Each frame-level feature x i can fall into one of the histogram bins { A 1 ,...,A with probability {  X  1 ,..., X  L } , respectively. The vector  X  = [  X  1 ,..., X  L ] T is a probability mass function (or a his-togram), i.e., P  X  l = 1 and  X  l  X  0 . The interval-conditional probability model for a frame-level feature is given by where I (  X  ) is the indicator function which takes the value one if its argument is true and zero otherwise. We would p (  X  | m ) is the Dirichlet distribution, then (3) becomes the Dirichlet-Multinomial model, which is also referred to as Polya distribution [24] or the Dirichlet compound multino-mial (DCM) model [11]. This model is often used as a topic model in text document classification. One criticism con-cerning the choice of Dirichlet prior is the limited capabil-ity of representing multimodal priors [34]. Our experience with bird sounds suggests that the probability model p (  X  | m ) is indeed multimodal; as Fig. 3 shows, frame-level feature histograms for the same species differ between intervals.
For p x |  X  ( x |  X  ) given by (9), we have where  X  p l = 1 n P n i =1 I ( x i  X  A l ) is the l th empiri-cal histogram bin probability estimate based on the ob-served feature collection X = [ x 1 ,x 2 ,...,x n ] , H ( p ) =  X  P L l =1 p l log p l is the entropy associated with a multino-mial parameterized by p (the vector of bin probabilities of a histogram), and is the Kullback-Leibler (KL) divergence between a multi-nomial parameterized by  X   X  and another parameterized by  X  . Substituting (10)-(12) into (8), we have This form for p X | m ( X | m ) acts as the likelihood component in the Bayes risk minimizing classifier in the following sec-tion. Moreover, it highlights the role of the KL divergence in optimal Bayesian classification for the problem at hand.
We start with a brief review of the Bayes risk minimiza-tion approach to classification [14]. The probability of error for a given classification rule  X  m ( X ) is The classification rule that minimizes the error in (14) is This rule is also referred to as maximum a-posteriori (MAP), as it assigns a decision based on the highest class probability given the set of observations. Using Bayes rule p m | X ( m | X ) = p X | m ( X | m ) P ( m ) /p X ( X ) and the fact that p X ( X ) is constant w.r.t. to the class variable m , yields an equivalent form to the MAP classifier:
After replacing the likelihood P X | m ( X | m ) with (13), the MAP classification rule (16) for the Interval-IID model in (3) is Note that since H (  X  p ) in (13) is independent of m , it is not incorporated into (17). It is equivalent to replace the maxi-mization with minimization and divide by n  X  m = arg min With no exact knowledge about P ( m ) and the PDF p (  X  | m ) used to compute the expectation E  X  [  X | m ] , we propose esti-mating these quantities from the training data.
To describe the training process, we start by explain-ing the format of the training data. Each interval k in the training data contains n training features X t [ x We assume that K training intervals are available, i.e., ables using the superscript t notation.

To train the classification rule in (18), we replace P ( m ) and E [  X | m ] through their sample estimates  X  m = arg min where k is the interval number, K is the total number of training intervals, y t k is the class label for the k th training in-terval, and  X   X  ( k ) is a histogram estimated from the k th train-ing interval given by where x t ik is the i th feature vector from the k th interval. With a slight abuse of notations, we rewrite (19) as where the  X   X  ( k,m )  X  X  are the sorted version of the  X   X  class m such that D kl (  X  p k  X   X  (1 ,m ) )  X  D kl (  X  p k ...D kl (  X  p k  X   X  ( K m ,m ) ) , and K m is the number of training in-tervals for the m th class. Using the ordered training class histograms, we reorganize (21) as  X  m = arg min We refer to (22) as the Interval-IID MAP classifier. While equivalent to (21), (22) provides insight into the relation between Bayes risk-minimization, nearest-neighbor classi-fiers, and manifold geodesics. Identifying the training inter-vals with their feature histograms, and the test interval with its feature histogram, the first term on the RHS of (22) is a KL divergence based nearest neighbor rule in histogram space. Note that if the KL distance to points other than than the distance to the first nearest neighbor D kl (  X  p k then the second term on the RHS of (22) becomes negligi-ble, and (22) is simply a nearest neighbor classifier using KL divergence.
The connection between optimal Bayes classification and the histogram KL nearest neighbor rule leads us to ex-tend the approach to nearest neighbor classification on his-tograms. Note that a collection of probability models (i.e, histograms) can be regarded as a manifold. Denote a model by p ( X |  X  ) or in short by p (  X |  X  ) . The collection of models given by is a d -dimensional statistical manifold if there exist a one-to-one smooth mapping between  X  to p (  X |  X  ) . In the geo-metric approach to statistical models [20], one can measure the geodesic distance between two histograms by using the Fisher information metric (FIM) as the Riemannian metric D
F ( p (  X |  X  ) ,p (  X |  X  0 )) = min  X  (  X  ) , where I (  X  ) is the Fisher information matrix given by The FIM is considered a natural metric for statistical man-ifolds as it reflect the capability to discriminate between probability models from their samples.

To generalize the nearest neighbor approach discussed in the previous section in the context of statistical mani-folds, we consider a geodesic nearest neighbor rule using D of the manifold is unavailable, an exact computation of the geodesic distance D F ( p,p 0 ) is impossible. Since the nearest neighbor approach prompts us to calculate short geodesic distances, local approximations of D F ( p,p 0 ) can be used instead. For two close probability models p  X  p 0 is known [20] that p 2 D kl ( p k p 0 )  X  D F ( p,p 0 ) . The KL di-vergence provides a computable approximation to the FIM manifold geodesic distance.

Note that other approximations for the FIM are avail-able (e.g., certain Ali-Silvey divergences, and specifically, Hellinger divergence). In this paper, we use the Hellinger divergence given by which is a metric as opposed to the KL divergence. The approximation of the FIM using Hellinger distance for close models is 2 D H ( p,p 0 )  X  D F ( p,p 0 ) [20].

For the purpose of comparison, we experimentally eval-uate nearest neighbor classifiers using L1 and L2 distances as well as KL and Hellinger. L2 is the standard Eu-clidean distance, which is widely used, but not theoreti-cally justified for the comparison of probability distribu-tions. L1 is fairly common for comparing probability dis-tributions. It is a member of the Ali-Silvey family, but due to non-differentiability, it is not an approximation to the FIM. However, it is related to Hellinger by the inequal-ity, 1 2 D H ( p,q ) 2  X  D L 1 ( p,q )  X  D H ( p,q ) [8]. This rela-tion between L1 and Hellinger hints at why classifiers using these distances achieve similar results (Sec. 5.6).
In this section, we describe the experimental setup used to measure the accuracy of the proposed methods for bird species classification, and to compare with SVMs [13]. We consider various frame-level features (mean frequency and bandwidth, MFCCs, and spectral density), interval-level features (averages vs. histograms), and metrics for nearest-neighbor classification (L1, L2, KL, and Hellinger). We also empirically verify that a nearest-neighbor classifier us-ing Kullback-Leibler closely approximates the Interval-IID MAP classifier (22) as suggested in Sec. 3. We have 1.13 GB of recordings from the Cornell Macaulay library, of 6 species: Black Throated Blue War-bler, Hermit Warbler, Downy Woodpecker, Swainson X  X  Thrush, Western Tanager, and Winter Wren. All of these recordings are at least 30 seconds long, and most are less than 10 minutes. We divide each recording into intervals of 30 seconds, resulting in 413 intervals. Our goal is to classify these intervals according to species.

The recordings were collected over several decades, mainly in the western United States. Most are made using a directional microphone in the field. The amount of noise in the recordings varies widely. In addition to static and wind, some recordings contain cars sounds, human speech, and other non-bird sounds. We manually removed most por-tions of sound with human voices. Although each recording is labeled with just one species, some recordings contain multiple birds, sometimes of different species; usually the loudest bird present corresponds to the label for the record-ing. The sampling frequency for all recordings is 44.1 kHz. The audio data is stored as mono-channel WAV files.
Section 2.1 covers the process of converting a sequence of samples from an audio interval into interval-level fea-tures. We proceed by further elaborating on the specific details of our experimental setup.

When dividing a signal into frames, we use 256 samples per frame, and successive frames overlap by 50%. To re-duce noise and decrease processing time in later stages, we discard the lowest 8 and highest 64 elements of each frame X  X  spectrum, leaving 56 elements from the original 128 (equiv-alent to removing all sound below 1.378 kHz and above 10.852 kHz).

Instead of syllables, we detect a subset of interesting frames (which are more likely to contain bird sound) in an interval. To find these interesting frames, we compute the total magnitude of each frame, P | c i | , and retain only the 10% of frames with highest total magnitude in all subse-quent calculations. Note that the total magnitude is similar to, but not the same as the energy of a frame. 1
Our implementation of MFCCs (Sec. 2.1.2), is based on the description provided by Ganchev et al. [15] of the MFCCs computed in the Cambridge Hidden Markov Mod-els Toolkit (for MATLAB), known as HTK [33]. We use 24 filters, 2 resulting in 24 MFCs, then take only the first 12 el-ements of the output of the DCT as the frame-level feature.
For constructing 2D histograms, we divide the range of values for mean frequency and bandwidth into square bins 100 Hz wide, with 100 bins on the mean frequency axis, and 50 bins for the bandwidth axis (for a total of 50  X  100 = 5000 bins, covering a range of 0 Hz to 10,000 Hz for f c and 0 Hz to 5000 Hz for BW ). There is one element in the feature vector for each histogram bin, so this representation results in a 5000-dimensional feature vector. 3
For constructing codebooks, we apply the k -means++ clustering algorithm [1] to the frame-level features from a training data set. Note that there are several hundred-thousand frames to cluster in our data set. To speed-up codebook construction, we follow a two-staged clustering proceedure suggested by Seyerlehner et al. [26]. In particu-lar, we first cluster features within each 30-second interval, then cluster the resulting cluster centers to obtain the final codewords. In the first stage of clustering, the feature vec-tors are either the spectrum density, or MFCCs for the in-teresting frames. In the second stage, the examples are the cluster centers from the first stage. We use k = 10 clusters for the first stage and k = 100 for the second. Thus, the fi-nal interval-level features constructed using this method are 100-dimensional. In our preliminary experiments, this ap-proach to clustering yielded an order-of-magnitude speedup over clustering all frame-level features at once, because the first stage of clustering does not need to be repeated in each fold of cross-validation.
There are many combinations of frame-level features and methods of aggregating them. The combinations we con-sider in this study are: averages of f c and BW , spectrum density, and MFCCs, 2D histograms of f c and BW , and codebook histograms of spectrum density and MFCCs.

Using the above features extracted from the data de-scribed in Sec. 5.1, we compare several classification al-gorithms: nearest neighbor with L1, L2, KL and Hellinger distances, and the Interval-IID MAP classifier proposed in Sec. 3.2 (22), as well as support vector machines. Of these classifiers, Interval-IID Map, KL and Hellinger are our pro-posed methods, and the others are included for comparison. 5.4.1 Support Vector Machines Support vector machines [6] (SVMs) are a family of algo-rithms for supervised classification that find a linear de-cision boundary by maximizing the margin between two classes. In cases where linear classification is insufficient, the kernel trick is applied to non-linearly project features into a higher dimensional space where linear separability is possible. The implementation of SVMs that we used is WLSVM [10], which integrates LIBSVM [4] into the Weka [32] machine learning system. Following Fagerlund [13], and the recommendations of Hsu, Chang and Lin [17], we use a radial basis function kernel, and optimize the SVM parameter C and the kernel parameter  X  , by grid search. We evaluate the SVM at all combinations of C and  X  in { 10  X  1 , 10 0 , 10 1 , 10 2 } , and report the best accuracy achieved with any set of parameters. To handle multiple classes (in our case, species), LIBSVM use the one-against-one voting scheme [18].
To measure the accuracy of the proposed classifiers, we use them to predict the species in each of 413 thirty-second intervals of sound. Each classifier is trained using all of the intervals that do not come from the same recording as the interval being classified (the data set consists of longer recordings that are split into intervals). We use this setup so the classifier must identify species without already hav-ing example recordings of the individual bird being classi-fied. Fagerlund [13] used a similar  X  X ndividual independent X  setup for cross-validation.

Classifiers that use a codebook to construct feature his-tograms depend on a randomized clustering algorithm. To account for the randomness, we ran five trials with differ-ent random seeds, and report average accuracy,  X  average deviation.
Table 2 lists the accuracy of each classifier on the species recognition problem. We make the following key observa-tions.  X  Regardless of which frame-level features we use, his- X  Using the 2D histogram of f c and BW, the Interval- X  Comparing different distance functions when using  X  Despite their relative simplicity, classifiers using 2D  X  Finally, we note that the proposed methods achieved
In this paper, we addressed the problem of bird species classification from audio recordings. Following a Bayesian approach to classification, we introduced the interval-IID model to describe the distribution of feature vectors within an interval consisting of frames, and derived the corre-sponding MAP classifier. The MAP classifier suggests ag-gregating features into histograms and using KL nearest neighbor to classify. This connection to nearest neighbor classification on statistical manifolds led us to extended the classifier by proposing different metrics (e.g., Hellinger). To use the MAP classifier with high-dimensional frame-level features, we employ codebook histograms.

Our study suggests that 1) using histograms of frame-level features in an audio classifier can produce better re-sults than using averaged frame-level features 2) nearest-neighbor classifiers using Kullback-Leibler and Hellinger distance to compare feature histograms results are com-petive with state-of-the-art method such as SVM and 3) metrics appropriate for histograms such as Hellinger, KL, and L1 perform better than the Euclidean L2 metric.
The classifiers in this study make predictions from inter-vals based on the collection of frames within the interval. A common alternative is to instead focus on individual sylla-bles. We are working on an experimental survey of methods for classifying bird species from syllables, as well as prob-ability models that are specialized for this purpose.
The experiments and algorithms presented here are a pre-liminary step toward analyzing a large (terabyte scale) data set of bird sounds that our collaborators collected in field conditions, using an array of omnidirectional microphones. We intend to apply algorithms for bird species classification to these recordings to extract information about patterns of bird activity at an unprecedented spatial and temporal reso-lution.
This work is partially funded by the IGERT pro-gram through National Science Foundation grant No. DGE 0333257, as well as the College of Engineering, Oregon State University. We would also like to thank Dr. Matthew Betts at Oregon State University for his help in acquiring the bird sound data.

