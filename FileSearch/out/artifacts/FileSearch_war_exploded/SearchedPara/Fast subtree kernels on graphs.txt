 Graph kernels have recently evolved into a branch of kernel machines that reaches deep into graph mining. Several different graph kernels have been defined in machine learning which can be catego-rized into three classes: graph kernels based on walks [5, 7] and paths [2], graph kernels based on limited-size subgraphs [6, 11], and graph kernels based on subtree patterns [9, 10]. and on limited-size subgraphs [11], it is unclear how to compute subtree kernels efficiently. As a consequence, they have been applied to relatively small graphs representing chemical compounds [9] or handwritten digits [1], with approximately twenty nodes on average. But could one speed up subtree kernels to make them usable on graphs with hundreds of nodes, as they arise in protein structure models or in program flow graphs? It is a general limitation of graph kernels that they scale poorly to large, labeled graphs with more than 100 nodes. While the efficient kernel computation strategies from [11, 12] are able to compare unlabeled graphs efficiently, the efficient comparison of large, labeled graphs remains an unsolved challenge. Could one speed up subtree kernels to make them the kernel of choice for comparing large, labeled graphs? subtree kernel that scales up to large, labeled graphs .
 its efficient computation based on the Weisfeiler-Lehman test of isomorphism. In Section 4, we compare these two subtree kernels to each other, as well as to a set of four other state-of-the-art graph kernels and report results on kernel computation runtime and classification accuracy on graph benchmark datasets. Terminology We define a graph G as a triplet ( V,E, L ) , where V is the set of vertices, E the set of undirected edges, and L : V  X   X  a function that assigns labels from an alphabet  X  to nodes in the graph 1 . The neighbourhood N ( v ) of a node v is the set of nodes to which v is connected by an edges, a maximum degree of d , and that there are N graphs in our given set of graphs. A walk is a sequence of nodes in a graph, in which consecutive nodes are connected by an edge. A has no cycles, but a designated root node. A subtree of G can thus be seen as a connected subset of distinct nodes of G with an underlying tree structure. The height of a subtree is the maximum distance between the root and any other node in the graph plus one. The notion of walk is extending to the set of all subtree patterns in graph G .
 Definition The first subtree kernel on graphs was defined by [10]. It compares all pairs of nodes where and Intuitively, k Ramon iteratively compares all matchings M ( v,v 0 ) between neighbours of two nodes v from G and v 0 from G 0 .
 Complexity The runtime complexity of the subtree kernel for a pair of graphs is O ( n 2 h 4 d ) , in-exponent, as one can implement the subtree kernel recursively, starting with k 1 and recursively com-in O ( N 2 n 2 h 4 d ) .
 Related work The subtree kernels in [9] and [1] refine the above definition for applications in chemoinformatics and hand-written digit recognition. Mah  X  e and Vert [9] define extensions of the classic subtree kernel that avoid tottering [8] and consider unbalanced subtrees. Both [9] and [1] ings to matchings of up to  X  nodes, but the runtime complexity is still exponential in this parameter  X  , which both papers describe as feasible on small graphs (with approximately 20 nodes) with many and thousands of nodes next. 3.1 The Weisfeiler-Lehman test of isomorphism Our algorithm for computing a fast subtree kernel builds upon the Weisfeiler-Lehman test of isomor-phism [14], more specifically its 1-dimensional variant, also known as  X  X aive vertex refinement X , which we describe in the following.
 Assume we are given two graphs G and G 0 and we would like to test whether they are isomorphic. The 1-dimensional Weisfeiler-Lehman test proceeds in iterations, which we index by h and which comprise the following steps: Algorithm 1 One iteration of the 1-dimensional Weisfeiler-Lehman test of graph isomorphism 1: Multiset-label determination 2: Sorting each multiset 3: Sorting the set of multisets 4: Label compression 5: Relabeling The sorting step 3 allows for a straightforward definition and implementation of f for the compres-compressed before. f assigns the current value of this counter to a string if an identical string has been compressed before, but when one encounters a new string, one increments the counter by one strings are mapped to the same number, because they occur in a consecutive block.
 { l out giving an answer.
 Complexity The runtime complexity of Weisfeiler-Lehman algorithm with h iterations is O ( hm ) . Defining the multisets in step 1 for all nodes is an O ( m ) operation. Sorting each multiset is an O ( m ) operation for all nodes. This efficiency can be achieved by using Counting Sort, which is an instance of Bucket Sort, due to the limited range that the elements of the multiset are from. The set is upper-bounded by n , which means that we can sort all multisets in O ( m ) by the following procedure: We assign the elements of all multisets to their corresponding buckets, recording which multiset they came from. By reading through all buckets in ascending order, we can then extract O ( m ) . Hence all these steps result in a total runtime of O ( hm ) for h iterations. 3.2 The Weisfeiler-Lehman kernel on pairs of graphs Based on the Weisfeiler-Lehman algorithm, we define the following kernel function. Definition 1 The Weisfeiler-Lehman kernel on two graphs G and G 0 is defined as: for all i 6 = j .
 That is, the Weisfeiler-Lehman kernel counts common multiset strings in two graphs. Theorem 2 The Weisfeiler-Lehman kernel is positive definite.
 two graphs. More formally, let us define a mapping  X  that counts the occurrences of a particular number of occurrences of s in G , and analogously  X  ( h ) s ( G 0 ) for G 0 . Then and if we sum over all s from  X   X  , we obtain where the last equality follows from the fact that f is injective.
 kernel with corresponding feature map  X  ( h ) W L , such that Theorem 3 The Weisfeiler-Lehman kernel on a pair of graphs G and G 0 can be computed in O ( hm ) .
 Proof This follows directly from the definition of the Weisfeiler-Lehman kernel and the runtime 3.3 The Weisfeiler-Lehman kernel on N graphs For computing the Weisfeiler-Lehman kernel on N graphs we propose the following algorithm which improves over the naive, N 2 -fold application of the kernel from (4). We now process all N graphs simultaneously and conduct the steps given in the Algorithm 2 in each of h iterations on each graph G .
 The hash function g can be implemented efficiently: it again keeps a counter variable x which counts that is different from all previous ones, then the string is mapped to x + 1 , and x increments. As before, g is required to keep sets of compressed labels from different iterations disjoint. Theorem 4 For N graphs, the Weisfeiler-Lehman kernel on all pairs of these graphs can be com-puted in O ( Nhm + N 2 hn ) .
 Proof Naive application of the kernel from definition (4) for computing an N  X  N kernel matrix would require a runtime of O ( N 2 hm ) . One can improve upon this runtime complexity by comput-Weisfeiler-Lehman algorithm by a hash function g that is applied to all N graphs simultaneously. Algorithm 2 One iteration of the Weisfeiler-Lehman kernel on N graphs 1: Multiset-label determination 2: Sorting each multiset 3: Label compression 4: Relabeling This has the following effects on the runtime of Weisfeiler-Lehman: Step 1, the multiset-label de-via a joint Bucket Sort (Counting Sort) of all strings, requiring O ( Nn + Nm ) time. The use of the strings will be mapped to the same (compressed) label anyway. Step 4 and Step 5 remain unchanged. runtime of O ( N 2 hn ) , as each graph G has at most hn non-zero entries in  X  ( h ) W L ( G ) . 3.4 Link to the Ramon-G  X  artner kernel The Weisfeiler-Lehman kernel can be defined in a recursive fashion which elucidates its relation to the Ramon-G  X  artner kernel.
 where k i ( v,v 0 ) = and is equivalent to the Weisfeiler-Lehman kernel k ( h ) W L .
 Proof We prove this theorem by induction over h . Induction initialisation: h = 1 : The equality follows from the definition of M ( v,v 0 ) .
 Figure 1: Runtime in seconds for kernel matrix computation on synthetic graphs using the pairwise (red, dashed) and the global (green) Weisfeiler-Lehman kernel (Default values: dataset size N = 10 , graph size n = 100 , subtree height h = 5 , graph density c = 0 . 4 ). neigborhoods of v and v 0 are identical, that is if f ( s h +1 ( v )) = f ( s h +1 ( v 0 )) . Theorem 5 highlights the following differences between the Weisfeiler-Lehman and the Ramon-G  X  artner kernel: In (8), Weisfeiler-Lehman considers all subtrees up to height h and the Ramon-whether the neighbourhoods of v and v 0 match exactly, whereas the Ramon-G  X  artner kernel considers all pairs of matching subsets of the neighbourhoods of v and v 0 in (3). In our experiments, we next examine the empirical differences between these two kernels in terms of runtime and prediction accuracy on classification benchmark datasets. 4.1 Runtime behaviour of Weisfeiler-Lehman kernel Methods We empirically compared the runtime behaviour of our two variants of the Weisfeiler-Lehman (WL) kernel. The first variant computes kernel values pairwise in O ( N 2 hm ) . The second variant computes the kernel values in O ( Nhm + N 2 hn ) on the dataset simultaneously. We will refer to the former variant as the  X  X airwise X  WL, and the latter as  X  X lobal X  WL.
 Experimental setup We assessed the behaviour on randomly generated graphs with respect to four parameters: dataset size N , graph size n , subtree height h and graph density c . The density of an undirected graph of n nodes without self-loops is defined as the number of its edges divided values and varied the fourth parameter. The default values we used were 10 for N , 100 for n , 5 for { 2 , 4 , 8 } and c in { 0 . 1 , 0 . 2 ,..., 0 . 9 } .
 For each individual experiment, we generated N graphs with n nodes, and inserted edges randomly until the number of edges reached b cn ( n  X  1) / 2 c . We then computed the pairwise and the global WL kernel on these synthetic graphs. We report CPU runtimes in seconds in Figure 1, as measured in Matlab R2008a on an Apple MacPro with 3.0GHz Intel 8-Core with 16GB RAM.
 Results Empirically, we observe that the pairwise kernel scales quadratically with dataset size N . Interestingly, the global kernel scales linearly with N . The N 2 sparse vector multiplications that have to be performed for kernel computation with global WL do not dominate runtime here. This large datasets.
 When varying the number of nodes n per graph, we observe that the runtime of global WL scales linearly with n , and is much faster than the pairwise WL for large graphs.
 We observe the same picture for the height h of the subtree patterns. The runtime of both kernels grows linearly with h , but the global WL is more efficient in terms of runtime in seconds. Varying the graph density c , both methods show again a linearly increasing runtime, although the runtime of the global WL kernel is close to constant. The density c seems to be a graph property that affects the runtime of the pairwise kernel more severely than that of global WL. Across all different graph properties, the global WL kernel from Section 3.3 requires less runtime than the pairwise WL kernel from Section 3.2. Hence the global WL kernel is the variant of our Weisfeiler-Lehman kernel that we use in the following graph classification tasks. 4.2 Graph classification Datasets We employed the following datasets in our experiments: MUTAG, NCI1, NCI109, and D&amp;D. MUTAG [3] is a dataset of 188 mutagenic aromatic and heteroaromatic nitro compounds labeled according to whether or not they have a mutagenic effect on the Gram-negative bacterium Salmonella typhimurium . We also conducted experiments on two balanced subsets of NCI1 and NCI109, which classify compounds based on whether or not they are active in an anti-cancer screen ([13] and http://pubchem.ncbi.nlm.nih.gov ). D&amp;D is a dataset of 1178 protein struc-tures [4]. Each protein is represented by a graph, in which the nodes are amino acids and two nodes are connected by an edge if they are less than 6 Angstroms apart. The prediction task is to classify the protein structures into enzymes and non-enzymes.
 Experimental setup On these datasets, we compared our Weisfeiler-Lehman kernel to the Ramon-the fast geometric random walk kernel from [12] that counts common labeled walks (with  X  chosen from [11] that counts common induced labeled connected subgraphs of size 3, and the shortest path kernel from [2] that counts pairs of labeled nodes with identical shortest path distance. We performed 10-fold cross-validation of C-Support Vector Machine Classification, using 9 folds for training and 1 for testing. All parameters of the SVM were optimised on the training dataset only. To exclude random effects of fold assignments, we repeated the whole experiment 10 times. We report average prediction accuracies and standard errors in Tables 1 and 2.
 We choose h for our Weisfeiler-Lehman kernel by cross-validation on the training dataset for h  X  { 1 ,..., 10 } , which means that we computed 10 different WL kernel matrices in each experiment. We report the total runtime of this computation ( not the average per kernel matrix). Results In terms of runtime the Weisfeiler-Lehman kernel can easily scale up even to graphs with thousands of nodes. On D&amp;D, subtree-patterns of height up to 10 were computed in 11 minutes, while no other comparison method could handle this dataset in less than half an hour. The shortest path kernel is competitive to the WL kernel on smaller graphs (MUTAG, NCI1, NCI109), but on on MUTAG in approximately 40 minutes, but for the large NCI datasets it only finished computation on a subsample of 100 graphs within two days. On D&amp;D, it did not even finish on a subsample of 100 graphs within two days. The random walk kernel is competitive on MUTAG, but as the Ramon-The graphlet kernel is faster than our WL kernel on MUTAG and the NCI datasets, and about a Maximum # nodes 28 111 111 5748 Weisfeiler-Lehman 6 X  5 X  7 X 20 X  5 X  7 X 21 X  58 X  11 X  graphlets turns out to lead to poor accuracy levels on three datasets. Using larger graphlets with 4 or 5 nodes that might have been more expressive led to infeasible runtime requirements in initial experiments (not shown here).
 On NCI1, NCI109 and D&amp;D, the Weisfeiler-Lehman kernel reached the highest accuracy. On D&amp;D the shortest path and graphlet kernels yielded similarly good results, while on NCI1 and NCI109 the Weisfeiler-Lehman kernel improves by more than 8% the best accuracy attained by other methods. On MUTAG, it reaches the third best accuracy among all methods considered. We could not assess the performance of the Ramon &amp; G  X  artner kernel and the random walk kernel on larger datasets, as their computation did not finish in 48 hours. The labeled size-3 graphlet kernel achieves low accuracy levels, except on D&amp;D.
 To summarize, the WL kernel turns out to be competitive in terms of runtime on all smaller datasets, We have defined a fast subtree kernel on graphs that combines scalability with the ability to deal and outperforms them significantly in terms of runtime on large graphs, even the efficient computa-tion schemes for random walk kernels [12] and graphlet kernels [11] that were recently defined. level, or on gene networks for phenotype prediction. An exciting algorithmic question for further studies will be to consider kernels on graphs with continuous or high-dimensional node labels and their efficient computation.
 The authors would like to thank Kurt Mehlhorn, Pascal Schweitzer, and Erik Jan van Leeuwen for fruitful discussions. [1] F. R. Bach. Graph kernels between point clouds. In ICML , pages 25 X 32, 2008. [2] K. M. Borgwardt and H.-P. Kriegel. Shortest-path kernels on graphs. In Proc. Intl. Conf. Data [3] A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch. [4] P. D. Dobson and A. J. Doig. Distinguishing enzyme structures from non-enzymes without [7] H. Kashima, K. Tsuda, and A. Inokuchi. Marginalized kernels between labeled graphs. In [8] P. Mah  X  e, N. Ueda, T. Akutsu, J.-L. Perret, and J.-P. Vert. Extensions of marginalized graph [9] P. Mah  X  e and J.-P. Vert. Graph kernels based on tree patterns for molecules. q-bio/0609024 , [11] N. Shervashidze, S.V.N. Vishwanathan, T. Petri, K. Mehlhorn, and K. M. Borgwardt. Efficient [13] N. Wale and G. Karypis. Comparison of descriptor spaces for chemical compound retrieval [14] B. Weisfeiler and A. A. Lehman. A reduction of a graph to a canonical form and an algebra
