 1. Introduction
Reverse logistics can be defined as the reverse process of logistics. The Council of Logistics Management (CLM) defines reverse logistics as  X  X  X he process of planning, implementing, and controlling the efficient, cost effective flow of raw materials, in-process inventory, finished goods and related information from the point of consumption to the point of origin for the purpose of recapturing value or proper disposal X  X  ( Stock, 1992 ). In the process of logistics or reverse logistics, they refer to many program problems, and the traveling salesman problem (TSP) and the vehicle routing problem (VRP) are the famous problems. they are considered the most successful areas in Operations Research in the past decades. In the framework of integrating logistics and reverse logistics, classical routing problems such as TSP and VRP must be take into account simultaneously both good distribution and returning materials. The vehicle routing problem with simulta-neous pickups and deliveries (VRP-SPD) is a variant of the classical vehicle routing problem (VRP) where customers require simulta-neous delivery and pick-up service. Deliveries are supplied from a single depot at the beginning of the vehicle X  X  service, while pick-up loads are taken to the same depot at the conclusion of the service. that finding a feasible solution to the traveling salesman problem with time windows (TSPTW) is NP-complete. Therefore, finding a feasible solution to the VRP-SPDTW with a fixed number of vehicles is also NP-complete, since this problem is even more complex than the TSPTW.

VRP-SPDTW often appears in practice, and it has broad prospects in theory and practice. For example in the soft drink industry, empty bottles must be returned, in the delivery to grocery stores, reusable pallets/containers are used for the transportation of merchandise, and each customer is serviced by exactly one vehicle within its time windows. Reverse logistics is an important area in which the planning of vehicle routes takes the form of VRP-SPDTW, as companies become interested in gaining control over the whole lifecycle of their products. For example, in some countries legislation forces companies to take responsibility for their products during lifetime, especially when environmental issue are involved (as in the disposal of laser printers X  cartridges). Returned goods are another example where the definition of vehicle routes may take the form of a
VRP-SPDTW. Owing to difficulty of the problem itself and deficiency of attention, even now very little work can be found in this area.
 Angelelli and Mansini (2003) presented an exact algorithm for the
VRPSPDTW. The authors have proposed a branch-and-price proce-dure based on a set covering formulation for the master problem.
Results with the use of different pricing and branching strategies on instances with 20 customers and up to five vehicles are presented. To the best of our knowledge, there are no correlative reports on adopting metehuristics to solve VRP-SPDTW. In this paper, we attempt to use improved differential evolution to solve this problem.
The VRP-SPDTW has received sparse attention in the literature compared to the VRP. There exist, however, abundant references related to vehicle routing problem with pickups and deliveries. In pickups and deliveries problem (PDP) situation transportation requests have to be carried out, where the origin as well as the destination of each of these requests can be and typically are locations other than the depot. There is a review of papers on a wider class of pickups and deliveries problems and some give a different classification compared to the classifications of Savels-bergh and Sol (1995) . More recently, Gerardo Berbeglia et al. (2007) presented a general framework to model static pickup and delivery problems and introduced a three-field classification scheme and survey. They introduced the relative research devel-opment on VRP-SPD in their reviews. Mosheiov (1998) considered
PDP with divisible demands, in which each customer can be served by more than one vehicle, and presented greedy constructive algorithms based on tour partitioning. Nagy and Salhi (2005) presented a number of heuristics for PDP with single and multiple depots.

Moreover, there exist a few references related to vehicle routing problem with pickups and deliveries with time windows (VRPPDTW), but simultaneously pickup and delivery was not considered. Ropke et al. (2007) proposed models and also a branch-and-cut algorithm for VRPPDTW. Ropke and Pisinger (2006) adopted an adaptive large neighborhood search heuristic for VRPPDTW.
 There are theoretical relationships between these problems and
VRP-SPDTW and it is possible to transform VRP-SPDTW into other routing problems. The PDP is an extensive generalization of the
VRP-SPD. The VRP-SPD is the very special case of the PDP, where either the origin or the destination of each transport request is the depot and, in addition, transport requests only occur pair wise, to and from the same customer. The VRP-SPDTW itself is a general-ization of the VRPPDTW. The VRPPDTW can be considered as a special case of the VRP-SPDTW where either the delivery demand or the pickup demand of each customer equals zero.
 has to be serviced with a given fleet of vehicles of limited capacities ( Q ) which are usually assumed to be identical; each vehicle leaves the depot carrying an amount of goods equal to the total amount it must deliver and returns to the depot carrying an amount of returning materials equal to the total amount it pick-up.
Each customer must be serviced within a specified time interval (or time window) [ a i , b i ]. The lower ( a i ) and upper bounds ( b the time window define the earliest and latest time for the beginning of service at the customer. A vehicle is not allowed to begin service at a customer location after b i . Moreover, a waiting time arises if a vehicle reaches a customer before a i . Each customer also has a specified service time ( t i ) which is the time spent by the vehicle to load and unload the goods. Hence, the total route time of a vehicle is the sum of travel time (which is proportional to the distance traveled), waiting time and service time. The total route distance should not exceed the maximum route distance of the vehicle. In each point along its tour no vehicle can carry load greater than its capacity. The goal is to minimize the overall length of the tours. The following notation will help in the description of the methods used for solving the VRP-SPDTW.
 Notation Sets V set of customers
V 0 set of customers plus depot (customer 0): V 0  X  V [f 0 g
Parameters k maximum number of vehicles Q vehicle capacity N total number of customers: n = 9 V 9
C ij distance between customer i and j
S ik time of beginning of service at customer i by, it is t i service time at customer i , where i  X  1 ; 2 ; ... ; n t ij travel time (proportional to the Euclidean distance) d i delivery demand of customer i , where i  X  1 ; 2 ; ... ; n p i pick-up demand of customer i , where i  X  1 ; 2 ; ... ; n
Decision variables x y ij the demand picked up from customers up to node i and z ij the demand to be delivered to customers routed after
The corresponding mixed integer programming mathematical formulation of VRP-SPDTW is given by Minimize s : t : x population-based and direct stochastic search algorithm (mini-mizer or maximizer). These simple, yet powerful and straightfor-ward, features make it very attractive in numerical optimization.
DE uses a rather greedy and less stochastic approach to problem solving compared to evolution algorithms. Recently, differential evolution algorithm have drawn great attention from researchers due to their robustness and flexibility and have been used to tackle many combinatorial problems, and its field of use is fast expanding (Home http://www.icsi.berkeley.edu/ storn/code.html) . But no work about VRP that using differential evolution can be found .To the best of our knowledge the differential evolution we develop in this paper is the first attempt to solve VRP-SPDTW using metaheuristics. In this section, we proposed an improved self-adapting differential evolution algorithm for VRP-SPDTW and this algorithm also can solve other routing problems just as the special cases of this problem.

DE combines simple arithmetic operators with the classical operators of crossover, mutation and selection to evolve from a randomly generated starting population to a final solution. The crucial idea behind DE is a new scheme for generating trial parameter vectors. DE generates new parameter vectors by adding the weighted difference vector between two population members to a third member. If the resulting vector yields an objective function value lower than a predetermined population member, the newly generated vector replaces the vector with which it was compared. In addition, the best parameter vector is evaluated for every generation in order to keep track of the progress that is made during the minimization process. DE uses a rather greedy and less stochastic approach to problem solving compared to evolution algorithms. These simple, yet powerful and straightforward, features make it very attractive in numerical optimization.
Obviously, the original DE cannot solve the combinational optimization problem when some variables must be integer values, because the original parameter vectors by difference mutation operator will be including non-integer values. When applying DE to VRP-SPDTW, we face many difficulties.
How to deal with the relative constraints and to extend the canonical DE to optimize integer variables problems are the key problems. The customer permutation-based encoding scheme ((Dantzing and Ramser, 1959 ; Fisher, 1995 ; Gen and Cheng, 2000 ) has been widely used for VRP. However, due to DE X  X  continuous nature, the standard encoding scheme of DE cannot be directly adopted for VRP-SPDTW. So, the important issue to apply
DE to VRP-SPDTW is to find a suitable mapping between customer sequence and individuals (continuous vectors) in DE. Formally, according to the canonical DE strategy DE/rand/1/bin, the improved differential evolution algorithm is briefly described in order to solve VRP-SDPTW effectively as follows. And more detailed working strategies about DE can be founded in Storn and Price ( Storn and Price, 1995 ; Storn, 1996 ; Home http:// www.icsi.berkeley.edu/ storn/code.html ).

Formally, the improved differential evolution algorithm is briefly described in the following: 3.1. Coding and initiation population
As with all evolutionary optimization algorithms, DE is a novel parallel direct search method that works with a population of solutions, not with a single solution for the optimization problem.
Like conventional GA for the VRP ( Gen and Cheng, 2000 ), a chromosome Chrom ( i,: ) is a sequence (permutation) of n custo-mers. We adopt this ordinal number encoding method, the initial population is chosen randomly and population size is NP , NP doesn X  X  change during the minimization process, and each individual is an n -dimensional solution vectors that is a permuta-following equation: trial  X  i ; j  X  G  X  1  X  where rand j is a random value within interval [0,1], randn ( i )isa randomly chosen index from the set of customers. We obtain the ordinal valued vector after mutation operation including auxiliary operator. Therefore all vectors of formulations (13) are integer-valued vectors. Obviously, the index randn ( i ) refers to a randomly chosen vector parameter and it is used to ensure that at least one vector parameter of each individual trial vector trial ( i ,:) from its counterpart in the previous generation Chrom ( i ,:) other words, a certain sequence of the vector elements of trial ( i ,:) G +1 is identical to the elements of v ( i ,:) number less than CR results, otherwise the other elements of trial ( i ,:) G +1 acquire the original values of Chrom ( i ,:) In formulations (16), G is the number of current iteration, CR
A [0,1] is the crossover probability factor. In order to improve the population X  X  diversity and the ability of breaking away from the local optimum, we present a new self-adapting crossover prob-ability factor, namely the crossover probability ( CR ) is time varying. It changes from small to large with iteration number G . I.e. CR  X  CR min  X  G CR max CR min MAXGEN ;  X  14  X  Where CR min is the proposed minimum crossover probability, and
CR max is the maximum crossover probability, MAXGEN is the number of maximum iteration. In the early stage of evolution, the crossover probability is smaller, which can improve the global searching capability; in the later stage of evolution, the crossover probability is less, which can improve the local searching capability. 3.4. Estimation and Selection operation
According to formulation (1) we obtained the total planned length of all routes ( R ). We defined the fitness value as the replaced by its offspring if the fitness of the offspring is better than that of its parent. However, the parent is retained in the next generation if the fitness of the offspring is worst than that of its parent, according to the following equation:
Chrom  X  i ; :  X  G  X  1  X 
Usually, main parameters of DE are fewer than other that of other evolutionary algorithms. The performance of a DE algorithm depends on three parameters: the population size NP , the scaling factor F and the crossover probability CR . And practical advice on how to select control parameters NP , F and CR can be found in Storn and Price (1995) and Storn (1996). using a random number r i that is uniformly distribution over the into consideration, too. Instances with different vehicle capacities are generated by choosing the minimal number of vehicles required (denoted by u ). The corresponding capacity Q  X  P 40 i  X  1 chessi and Righini 2007). The lower bounds a i of time windows are uniformly distributed over the interval [0,10], and the upper bounds b arecomputedbyusingarandomnumber l I that is uniformly distributed over the interval [0,1] such that  X  2  X  l i  X  a is 1815.2, and average computational time is 61.6516 s. The average route distance obtained by adopting genetic algorithm is 1661.8, and average computational time is 74.0342 s. IDE executes more difference operator when the customer numbers is increasing, and it takes time to generate many random numbers. So the runtime increase with the problem size, but it save too much time than branch-and-price algorithm and genetic algorithm introduced in Gerardo Berbeglia et al. (2007) . The convergence results on the shortest distance (1594.7)
Lastly, for assessing the performance of the proposed differ-ential evolution algorithm, we did some experiments by generat-ing VRP-SPDTW randomly and by setting different parameters of the differential evolution algorithm. We adopted the following in the experiments: (1) VRP-SPDTW is a mixed integer programming problem, we adopted a natural number coding method and an auxiliary operator based on integer order criterion to improve the mutation operation. If we adopted other rounded number methods to obtain integer, we could not solve vehicle routing problem. (2) The self-adapting crossover operator avoids effec-tively the common defects of early convergence and the diversity of population in traditional differential evolution algorithm. (3)
The improved differential evolution also can solve other classical routing problems, because the mixed integer programming mathematical formulation of VRP-SPDTW in Section 2 turns into other classical vehicle routing problems by setting different parameters. 4. Conclusions
This paper contributed to a vehicle routing problem with simultaneous pickups and deliveries and time windows in the following respects: (a) An integer programming mathematical model of VRP-SPDTW was proposed for finding the optimal solutions, which described the relationship between VRP-SPDTW and other vehicle routing problems. (b) An improved differential evolution algorithm to solve the vehicle routing problem with simultaneous pickups and deliveries and time windows was presented, focusing on minimization of total distance traveled, in the operation process. The natural number permutation encoding was used to represent solution, and penalty function was designed to eliminate illegal solutions. More importantly, the mutation operator, crossover operator and selection operator were used as improved differential evolution operators to prevent premature convergence and accelerate searching procedure. (c) The perfor-mance of the improved differential evolution algorithm was studied by some numerical examples.

It will also be useful to investigate the application of DE to other combinatorial optimization problems with discrete variables such as quadratic assignment problem (QAP), other vehicle routing problem, etc. To date these problems have not been so tackled.
Moreover, it will be significant to improve and compare the performance of IDE with other metaheuristics such as tabu search, and simulated annealing, as well as simple heuristics. Acknowledgements
We would like to appreciate two anonymous reviews for the pertinent and helpful comments. This research was supported by the National Science Foundation for Distinguished Young Scholars of China under Grant 70925006, and the Major Special Program for
Science and Technology of Hunan Province, China under Grant 2008FJ1006.

 1. Introduction
Task assignment problem (TAP) was first introduced by Stone (1977) , and it involves assigning a number of tasks to a number of processors in a distributed system. The objective of TAP is to minimize the total execution and communication costs incurred by the task assignment, which is limited by the resource require-ments. Specially, the number of tasks that a given processor is able to handle is restricted by its memory capability and proces-sing ability.

Over the past decades a number of optimization algorithms have been used extensively in different kinds of task assignment problems. Lo (1988) proposed a family of heuristic algorithms for
Stone X  X  classic model. In addition, they augmented this model to include interference costs which reflect the degree of incompat-ibility between two tasks. The inclusion of interference costs in the model yielded assignments with greater concurrency, thus overcoming the tendency of Stone X  X  model to assign all tasks to one or a few processors. Park (1997) described a genetic mean field annealing (GMFA) algorithm for the task assignment pro-blem, and it was based on two types of stochastic search techniques  X  genetic algorithm ( Holland, 1992 ) and mean field annealing ( Van den Bout and Miller, 1990 ). The problem was to find an optimal mapping of multiple communicating tasks onto the processing nodes of a distributed computing system. The objective of mapping was to minimize the total execution time without sacrificing solution quality. Kopidakis et al. (1997) transformed the minimization problem to a maximization one, where they tried to determine and avoid large communication costs and inefficient allocations. After an appropriate graph transformation, they proposed two fast algorithms, the Matching based and Max Edge heuristics, in order to consider trade-offs between task clustering and task processor assignment. Lee and Shin (1997) focused on the assignment problem on a homoge-neous network, which was composed of N functionally identical processors, each with its own memory. The assignment problem in such a homogeneous network was known to be NP-hard even for N  X  3, thus making it intractable for a network with a medium to a large number of processors. They, therefore, focused on task assignment in general array networks, such as linear arrays, meshes, hypercubes, and trees. They first developed a modeling technique that transforms the assignment problem in an array or tree into a minimum-cut maximum-flow problem. The assign-ment problem was then solved for a general array or tree network in polynomial time. Salman et al. (2002) presented a new task assignment algorithm that is based on the principles of particle swarm optimization (PSO). PSO follows a collaborative popula-tion-based search, which models over the social behavior of bird flocking and fish schooling. PSO system combines local search methods (through self experience) with global search methods (through neighboring experience), attempting to balance explora-tion and exploitation. They also discussed the adaptation and implementation of the PSO search strategy to the task assignment problem. Tom and Murthy (1999) considered the problem of finding an optimal allocation of tasks onto processors of a distributed computing system. The processors need not have any particular inter-connection structure. They considered two models, one in which no precedence relations exist between tasks, and another in which there are precedence relations between tasks. Each task causes two types of costs to be incurred by the processor to which it is allocated  X  the execution cost of the task (which varies from processor to processor in a hetero-geneous system), and communication cost when the task has to communicate with other tasks which are not allocated to the same processor. Their work concentrated on determining an optimal task allocation that leads to minimum turnaround time possible. Ucar et al. (2006) considered the version in which communicating tasks are to be assigned to heterogeneous pro-cessors with identical communication links to minimize the sum of the total execution and communication costs. They used three methods to obtain a family of task assignment algorithms including multilevel ones that applied clustering and refinement heuristics repeatedly. Salcedo-Sanz et al. (2006) introduced a novel formulation of TAP, in which each processor was limited in the number of task it can handle, due to the so-called resource constraint. They proposed two hybrid meta-heuristic approaches for solving this problem. Both hybrid approaches used a Hopfield neural network to solve the problem X  X  constraints, mixed with a genetic algorithm (GA) and a simulated annealing for improving the quality of the solutions found. Kaya et al. (2007) considered the problem of scheduling an application on a computing system consisting of heterogeneous processors and data repositories. The application consists of a large number of file-sharing otherwise independent tasks. The files initially reside on the repositories.
The processors and the repositories are connected through a heterogeneous inter-connection network. Their aim was to assign the tasks to the processors, to schedule the file transfers from the repositories, and to schedule the executions of tasks on each processor in such a way that the turnaround time is minimized. Kaya et al. (2007) proposed a heuristic composed of three phases: initial task assignment, task assignment refinement, and execution ordering. Ho et al. (2008) proposed an orthogonal particle swarm optimization (OPSO) algorithm to solve task assignment problem. The OPSO performed well in solving the large discrete task assignment problem which was NP-complete in a limited amount of computation time. This was achieved by the novel move behavior in the swarm: an intelligent move mechanism (IMM) using a divide-and-conquer strategy. Discrete particle swarm algorithm (DPS) ( Schoofs and Naudts, 2002 ) was a newly developed method to solve constraint satisfaction problem (CSP) which has advantage on search capacity and can find more solutions. Yang et al. (2009) proposed an improved DPS to solve
TAP. The algorithm had a special operator namely coefficient multiplying speed, which was designed for CSP. Accordingly, they redefined a coefficient multiplying speed operator with probabil-ity selection. They analyzed the speed and position updating formula, and derived a refined position updating formula.
Differential evolution (DE) algorithm was first proposed by Storn and Price (1995) , it is a simple but practical optimization algorithm. Due to its good performance, the DE has been applied to various optimization problems, such as permutation flowshop scheduling problem ( Pan et al., 2008 ), manufacturing cell forma-tion problem ( Noktehdan et al., 2010 ), optimization of chemical process ( Wu et al., 2008 ), etc.; however, it has never been used to solve task assignment problem. In this paper, we modified the two important control parameters of the DE algorithm so as to improve its performance. The improved version of the DE is called improved differential evolution (IDE) algorithm, and we used the
IDE to obtain the optimal/near optimal solutions for a number of task assignment problems.
 formulation of task assignment problem is presented. In Section 3, the procedure of the DE is briefly presented, and two improved versions of DE are also summarized. In Section 4, an improved differential evolution (IDE) algorithm is proposed, and the proce-dure of the IDE is adequately described. In Section 5, some preparation work is considered for using the IDE to solve task assignment problems. In Section 6, a large number of experiments are carried out to test the optimization performance of the IDE for task assignment problems. We end this paper with some conclu-sions for further research in Section 7. 2. Problem formulation formulation we consider in this paper is from Yin et al. (2006) .
The general formulation of TAP can be described as follows: min Q  X  X  X  X  s : t : x ik A f 0 , 1 g , 8 i , k
The notations used in the above problem formulation are listed in Table 1 .
 programming problem, and its objective function is the total sum of execution costs and communication costs. This problem is limited by three kinds of constraints: the first is an equality constraint, and it means that any task should be assigned to only one processor; the second is an inequality constraint, and it means that the sum of memory requirements of the tasks assigned to processor k should not exceed the memory capacity of processor k ; the third is an inequality constraint, and it means that the sum of processing requirements of the tasks assigned to processor k should not exceed the processing capacity of processor k .

Since Eq. (1) is an integer program with a quadratic objective function and is computationally prohibitive due to enormous computation efforts, Ernst et al. (2001) and Billionnet et al. (1992) transformed the formulation Q ( X ) to the following 0 X 1 integer linear program. min L  X  X  X  X  s : t : y ijkl  X  x jl , 8 i , j  X  1 , 2 , ... , r ; l  X  1 , 2 , ... , n y ijkl  X  x jk , 8 i , j  X  1 , 2 , ... , r ; k  X  1 , 2 , ... , n m i x ik r M k , 8 k  X  1 , 2 , ... , n p x ik r P k , 8 k  X  1 , 2 , ... , n x , y ijkl A f 0 , 1 g , 8 i , j , k , l
Here, y ijkl is a binary variable and y ijkl  X  1 if and only if task i is assigned to processor k and task j is assigned to processor l .
Unfortunately, the above formulation is still time-consuming for deriving optimal solutions to large-scaled problems. Thus, Yin et al. (2006) used a hybrid particle swarm optimization (HPSO) to solve TAP efficiently. In HPSO, each particle corresponds to a candidate solution of the underlying problem. Thus, Yin et al. (2006) let each particle represent a decision for task assignment using a vector of r elements, and each element is an integer value between 1 and n . Yin et al. (2006) used an illustrative example for the i th particle which corresponds to a task assignment that assigns five tasks to three processors, and particle i , 5 that task 5 is assigned to processor 2. The HPSO randomly generates an initial swarm of K particles, where K is the swarm size. These particle vectors will be iteratively modified based on collective experiences in order to improve their solution quality. 3. Three differential evolution algorithms
DE is a competitive and potential algorithm compared to the other evolutionary algorithms, and an excellent performance of the DE has drawn much attention from Researchers. Due to the enormous application potential of DE algorithm, its many improved versions have been developed, such as ODE ( Rahnamayan et al., 2008 )andJADE( Zhang and Sanderson, 2009 ). 3.1. The original differential evolution algorithm (DE)
The DE algorithm includes three important operators: muta-tion, crossover and selection. Mutation and crossover are used to generate new vectors (trial vectors), and selection then are used to determine whether or not the new generated vectors can survive the next iteration. In short, the procedure of the DE works as follows: Step 1: Initial algorithm parameters.
 They are: scale factor F , crossover rate CR , the population size M and the maximum number of iterations K .
 Step 2: Randomly generate M candidate solutions.

The initial candidate solutions are generated from a uniform number of variables.
 Step 3: Mutation a trial vector, v k  X  1 i is created by mutating a target vector. Randomly select the target vector x k i individuals x k i then calculated as v Here, F is a scale factor used to control the amplification of the differential variation, and F A  X  0 , 2 .
 Step 4: Crossover
DE follows a discrete recombination approach where elements from the parent vector x i k , are combined with elements from the trial vector v i k , to produce the offspring u i k . u where, r 1 D is a random integer in [1, D ]. CR represents crossover rate, and CR A  X  0 , 1 .
 Step 5: Selection
The generated offspring u i k +1 replaces the parent x i k fitness of the offspring is better than that of the parent. The selection can be stated as follows: x Step 6: Check the stopping criterion
If the stopping criterion (maximum number of iterations K )is satisfied, computation is terminated. Otherwise, Steps 3 X 5 are repeated.

Generally speaking, the most important steps of the DE are mutation, crossover and selection, respectively, and they have profound effects on the performance of the DE algorithm. The three steps increase the diversity of individuals, accelerate the convergence of the DE algorithm, and guarantee the high quality of individuals. 3.2. Opposition-based differential evolution (ODE)
Opposition-based differential evolution (ODE) was proposed by Rahnamayan et al. (2008) , and it employed opposition-based learning (OBL) ( Tizhoosh, 2005 ) for population initialization and also for generation jumping. In this work, opposite numbers had been utilized to improve the convergence rate of DE. Further studies were still required by Rahnamayan et al. (2008) to investigate its benefits, weaknesses, and limitations. The possible directions of their future work included the adaptive setting of the jumping rate, proposing other possibilities to implement ODE (e.g., opposition-based mutation strategies), and applying the same or similar scheme to accelerate other population-based methods (e.g., GA and PSO). 3.3. Adaptive differential evolution with optional external archive (JADE)
Zhang and Sanderson (2009) proposed an adaptive differential evolution with optional external archive (JADE) to improve opti-mization performance of DE. They implemented a new mutation strategy  X  X  X E/current-to-pbes X  X  with optional external archive and updated control parameters in an adaptive manner. The  X  X  X E/current-to-pbest X  X  was a generalization of the classic  X  X  X E/ current-to-best, X  X  while the optional archive operation utilized historical data to provide information of progress direction. Both operations diversified the population and improve the convergence performance. The parameter adaptation automatically updated the control parameters to appropriate values and avoided a user X  X  prior knowledge of the relationship between the parameter settings and the characteristics of optimization problems. It was thus helpful to improve the robustness of the algorithm. 4. An improved differential evolution algorithm (IDE)
The key difference between IDE and traditional DE is in the way of adjusting scale factor F and crossover rate CR . To improve the performance of the DE algorithm, we devise an improved differential evolution (IDE) algorithm. Our method modifies scale factor F according to the objective function values of all candidate solutions in mutation step, and adjusts crossover rate CR in terms of iteration number in crossover step. Both modified operators can not only diversify candidate solutions, but also increase the convergence of the algorithm. In short, the IDE and the DE are different in two aspects as follows: (1) For scale factor F of DE algorithm, it is set to a fixed value for all candidate solutions over all iterations. That is to say, all candidate solutions have the same magnification factor of differ-ence vector x k i adaptive scale factor F i for the i th candidate solution, and it is stated as follows:
F  X 
Here, rand i belongs to a uniform distribution in the ranges [0,1]. f i represents the objective function value of the i th solution, f min represents the minimal objective function value of all candi-date solutions, and f aver represents the average objective function value of all solutions. A closer look at adaptive scale factor F reveals that each candidate solution has its own unique scale factor F i due to the utilization of random number rand i to Eq. (6), F i belongs to the ranges [0,2], which coincides better with F of DE (as Eq. (3)). If the objective function value of the i th solution is close to f min , F i tends to be a small value, which is beneficial to the local search of the IDE, otherwise, F i large value, which is beneficial to the global search of the IDE. In short, the adaptive scale factor F i can adjust itself according to the ratio of ( f i f min ) and ( f aver f min ), and it can balance the local search and global search well. (2) For crossover rate CR of DE algorithm, it is set to a fixed value for any dimension of any candidate solution over all iterations. In other words, any dimension of any candidate solution has the same crossover rate, which does not change with the evolution process (as Eq. (4)). In this paper, we devise a dynamic crossover CR k for all candidate solutions at iteration k , and it is stated as follows:
CR k  X  a exp  X  b k 2  X  b  X  1 K 2 1 ln CR max CR
Here, k and K are current iteration number and maximal iteration number, respectively. CR min and CR max represent mini-mal crossover rate and maximal crossover rate, respectively.
Suppose K  X  1000, CR min  X  0 : 1, CR max  X  0 : 9, and the optimization curve of crossover CR k is shown in Fig. 1 .
 early iterations. In this case, any offspring component u
Eq. (4)) keeps its previous state x i , j k with a large probability, so each candidate solution is more like a conservative one in the early iterations. CR k keeps to be large values in the late iterations.
In this case, any offspring component u k  X  1 i , j prefers to adopt the trial component v i , j k +1 , which provides a promising and alternative search direction for each candidate solution. In short, a small CR is beneficial to the convergence of IDE, and a large CR k improve an exploring capability of solution space of IDE. Based on the above-detailed illustration of two modified parameters, the full procedure of the IDE works as Table 2 . 5. Some preparation work 5.1. A modified mathematical model
Before illustrating the new model, it is necessary to explain the candidate solution related to this new model. We represent candidate solution with a vector of r elements, and each element is an integer value between 1 and n . Fig. 2 shows an illustrative example for the i th candidate solution x i , which describes a task allocation that assigns five tasks to three processors. For example, x  X  2 means that the third task is assigned to the second processor. Formally, x i , j  X  l implies that the j th task is assigned to the l th processor, which can guarantee that the first kind of equality constraint (as Eq. (1)) is always satisfied. 5.2. Constrained optimization
We employ a usual penalty function method to trade-off the constraints and the objective function value. The new fitness function can be formulated as min F  X  x i  X  X  f  X  x i  X  X  l x i represents the i th candidate solution. g j ( x i ) is the j th inequality constraint, and N g is the number of inequality con-straints. l is penalty function coefficient, and it is set as 10 this paper. 5.3. Process for discrete variables
Many real-world applications require the variables to be optimized to be integers, such as reliability optimization ( Zou et al., 2010 ), production scheduling ( Sawik, 2005 ), resource allocation ( Qiu and Zhang, 2008 ) and so on. In addition, TAP also involves integer variables. Any variable of TAP adjusted by our method is a real number, and we transform it into a nearest integer. 6. Experimental results and analysis
In this section, we randomly generate three groups of exam-ples to test the performance of the IDE, and compare our algorithm with the ODE and JADE on solving task assignment problems. The results show that the IDE outperforms the other two DE algorithms for most task assignment problems. The results also demonstrate that the IDE is competent for both small-scale and large-scale task assignment problems.

The inter-task communication of TAP is interpreted by a task interaction graph (TIG). G ( V , E ) is used to illustrate the TIG, V is a set of r nodes indicating the r tasks to be executed and each edge  X  i , j  X  A E is associated with a communication cost c ij only when tasks i and j are assigned to different processors. Yin et al. (2006) defined the task interaction density d of G ( V , E )as where j E j calculates the number of existing communication demands in the TIG, and r ( r 1)/2 indicates the maximal number of communication demands among r tasks. The task interaction density d quantifies the ratio of the inter-task communication demands for a TIG and it is one of the key factors that affect the problem complexity. The other key factors are the number of tasks ( r ) and the number of processors ( n ). Yin et al. (2006) set the order to testify the algorithm with different problem scales. For each pair of ( r , n ), they generated three different TIGs at random with density d equivalent to 0.3, 0.5, and 0.8. The values of the other parameters are generated randomly: the execution cost is between 1 and 200, the communication cost is between 1 and 50, the memory and processing capacity of each processor varies from 50 to 250, and the memory and processing requirement of each task ranges from 1 to 50.

We adopt the three different task interaction densities ( d  X  0.3, 0.5, 0.8) as in Yin et al. (2006) ; moreover, we add two other pairs of ( r , n ), and they are (30,18) and (50,30), respectively. We select these two pairs of ( r , n ) to demonstrate that our algorithm is not only competent for TAP with small scales, but also competent for TAP with large scales. For any combination of r , n and d , we use the same randomly generated parameters to test the performance of three algorithms for 20 times, and compare the IDE with the ODE and JADE. For the three algorithms, the parameters settings are as follows:
For the ODE, jumping rate J r  X  0 : 3, scale factor F  X  0 : 5, cross-over rate CR  X  0 : 9; for the JADE, mean m CR  X  0 : 5, location para-meter m F  X  0 : 5, positive constant c  X  0 : 1, parameter p %  X  5 % ; for the IDE, the minimal crossover rate CR min  X  0 : 1, the maximal crossover rate CR max  X  0 : 9. 20 independent runs were made for these three algorithms, and the results for above task assignment problems are reported in Tables 3 X 5 .

Here, n and r are the number of processors and the number of tasks, respectively. M and K are population size and maximal iteration number, respectively.  X  X  X ver.t X  X  represents the average optimization time among 20 runs of each algorithm. Table 3 sum-marizes the results obtained by three algorithms when task inter-action density d  X  0 : 3. Each value in the column  X  X  X ta.dev X  X  is the standard deviation of 20 fitness values obtained by each algorithm. Moreover, each number in the column  X  X  X F X  X  is the number of feasible solutions found by each algorithm among 20 runs.
It can be seen from Table 3 that the IDE always use less average time than the other two DE algorithms in each case. For optimal value which is equal to 2.6135e+002. Specially, all the three algorithms can continuously find the optimal value, and their success rates are all 100%. For (10,6, 0.3), all the three algorithms can find the same optimal value which is equal to 7.1513e+002, and the success rate of the IDE is 100% which i s the highest. For (15,9,0.3), both the ODE and the IDE can find the same optimal value which is equal to 1.0530, in contrast, the JADE fails to find this value, and the JADE value is equal to 1.1921e+003 which is worse than the former. For the other three examples, the IDE performs better than the other two algorithms according to multiple criteria (Aver.t, Best, Worst, Mean, Median). The optimal values of the three examples obtained by the IDE are better than those obtained by the other two DE algorithms, and they are 1.1382e+003, 3.6444e+003 and 8.2842e+003, respectively. Specially, the worst values of the three other two DE algorithms. So, ODE and JADE cannot show better results than IDE even on one example for the last three TAPs. A closer look at the term  X  X  X F X  X  reveals that all the three DE algorithms can successfully find feasible solutions over all 20 runs for any example with d  X  0 : 3. In short, the IDE has demonstrated higher efficiency than the other two DE algorithms on finding better optimal fitness values especially for TAPs with large scales.
Table 4 summarizes the results obtained by three algorithms when task interaction density d  X  0 : 5. Again, it is clear that the IDE always use less average time than the other two DE algorithms in the same optimal value which is equal to 5.1079e+002. Specially, the IDE can continuously find the optimal value, and the success rate of the IDE is 100%. For (10,6,0.5), both the ODE and the IDE can find the same optimal value which is equal to 5.8451e+002, in contrast, the JADE fails to find this value, and the JADE value is equal to 5.9347e+002 which is worse than the former. For the other four TAP examples, the IDE performs better than the other two algorithms in terms of multiple criteria (Aver.t, Best, Worst,
Mean, Median). The optimal values of the four examples obtained by the IDE are better than those obtained by the other two DE algorithms, and they are 1.3472e+003, 1.9750e+003, 5.8367e+003 and 1.5174e+004, respectively. Specially, the worst values of the four examples using the IDE are even better than those obtained by the other two DE algorithms. Similarly, all the three DE algorithms can successfully find feasible solutions over all 20 runs for any example with d  X  0 : 5. In short, The results clearly confirm that the IDE outperforms the ODE and JADE on solving all the utilized six TAP examples.
 the three algorithms can find the same optimal value which is equal to 2.9036e+002, and the success rate of the IDE is 100 %
IDE can find the same optimal value which is equal to 1.2373e+ 003, in contrast, the ODE result is equal to 1.2468e+003 which is worse than the former. For the other four TAP examples, the IDE performs better than the other two algorithms in terms of multi-ple criteria (Aver.t, Best, Worst, Mean, Median). The optimal values of the four examples obtained by the IDE are better than those obtained by the other two DE algorithms, and they are 1.6818e+003, 3.5862e+003, 7.7847e+003 and 2.3524e+004, respectively. It is worth noting that all the average values using the IDE are better than those obtained by the other two DE algorithms over all 20 runs for all of the six TAP examples with d  X  0 : 8. According to the above observations, we conclude that the performance of the proposed approach is superior to the other methods when used to solve all the utilized six TAP examples. paper, thus, we draw optimization curves of all pairs ( r , n ,0.8) to demonstrate our approach. Figs. 3 X 8 depict the optimization results of six TAP examples with d  X  0 : 8.
 better performance than the other two DE algorithms on finding optimums; for the other pairs ( r , n ,0.8), the IDE can yield better fitness values than those obtained by the ODE and the JADE. It can be observed that the evolution curves of the ODE and JADE descend slowly, which indicates the poor convergence of both algorithms on solving TAPs. On the other hand, the evolution curves of the IDE descend much faster and reach lower level than that of the other two DE algorithms. Thus, it can be concluded that overall the IDE algorithm outperforms the other two meth-ods on solving TAPs.
 we select all TAP examples with d  X  0 : 8. For comparison, the other two DE algorithms are also considered. Most parameters of the three algorithms are the same as the former settings, however, both M and K are halved. The optimization results using three algorithms are recorded in Table 6 .
 time than the other two DE algorithms in each case. For can successfully find the optimal value which is equal to 1.2373e+003, but the ODE and the JADE failed. For the other four examples, the IDE outperforms the other two algorithms according to multiple criteria (Aver.t, Best, Worst, Mean, Median). The optimal values of the four examples obtained by the IDE are better than those obtained by the other two DE algorithms, and they are 1.7478e+003, 3.7663e+003, 8.1919e+003 and 2.3535e+004, respectively, for the IDE can obtain better average optimal objective function values than those obtained by the other two algorithms for all examples in Table 6 are even better than the ODE results and the JADE results in Table 5 . Specially, the best objective function values (as Table 6 ) obtainedbytheIDEarebetterthanthose(as Table 5 ) obtained by the optimal objective function values (as Table 6 ) obtained by the IDE are better than those (as Table 5 ) obtained by the other two other words, the IDE uses smaller M and K ,butitcanstillobtain better average objective function values than those obtained by the other two DE algorithms for most TAPs. Based on the above observation, the IDE has demonstrated stronger convergence than the other two DE algorithm on solving TAPs. 7. Conclusions
We proposed an improved differential evolution algorithm (IDE) to solve task assignment problem in this paper. The IDE introduced an adaptive scale factor and a dynamical crossover rate so as to improve the performance of the DE algorithm. A large number of examples had been used to extensively investigate the performance of the proposed algorithm. Experimental results show that the IDE algorithm performs well on finding the optimal/near optimal task assignment, and it is a viable approach for the task assignment problem.

The task assignment problem is known to be NP-complete. To find an optimal solution (or near optimal solution) in polynomial time, we should turn to fast heuristic techniques. For the task assignment problem, we use an improved differential evolution algorithm to assign the tasks of an application to a set of distributed processors, which is beneficial to minimizing the incurred cost and maximizing the system efficiency.
 Acknowledgment This work was supported by National Science Foundation of PR China under Grant 81000639.
 Appendix A. Supplementary material
Supplementary data associated with this article can be found in the online version of 10.1016/j.engappai.2010.12.002 . References
