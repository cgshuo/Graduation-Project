 different levels of artificial noise are injected in the data. On this noisy data, noise reduction process is applied and the output is compared to the original human generated data, which is assumed to be correct for the sake of the eval-uation. Since the effectiveness is tested on a wide range of injected noise, it also checks the robustness of the proposed process to initial noise present in the data. Learning to Rank. Geng et al. proposed a way of computing training data qual-ity for Learning to Rank with a concept of  X  X airwise Preference Consistency X  (PPC). They have shown a way to select the most optimal subset of the initial training data which maximizes the PPC score [ 3 ]. However, because of selection of a subset there is a possibility of loosing some important examples which are discarded in this process. Hence, in this attempt an error correction, rather than error elimination approach is targeted. Xu et al. proposed a method of error correction, by leveraging the information from click-through data [ 11 ]. However, it is not natural to assume the availability of such data in all cases. To the best of our knowledge, there hasn X  X  been any work yet, that deals with improving the quality of training data for learning to rank by error correction rather than error elimination solely on the based on training data itself.
 quality of training data for classification [ 2 ]. Ensemble learners are often used for this purpose in classification data. For example, many classifiers are learnt from different samples of training data and used to classify the data. If there is a good amount of agreement among the classifiers then only that instance is kept, otherwise discarded. A similar approach is used here to correct the highly probable error-some instances and there by reducing noise in data. However, instead of elimination, correction of the highly suspicious preference pairings is performed. Hence unlike noise elimination, there is no risk of loosing important training instances in process of noise correction.
 approach, Sect. 3 elaborates on the experimental setup, Sect. 4 discusses the results and Sect. 5 concludes and discusses future scope of this project. Learning to Rank training data contains queries, the associated documents, set of features extracted from each query-document pair and the relevance label of documents for the corresponding query. Formally, given query q, there is a set of documents D = { d 1 ,d 2 ..d n } and for each query-document pair ( q,d i ) there exists of this representation to pairwise preference sets is performed as following: any combination of x and a . It is worth noting that taking such intersection highly improves the precision of fault identification. Once, these suspected faulty preference pairs are extracted, they are removed from the full pairwise preference set. A separate set is made from them, basically decomposing the initial data in 2 parts: purer and noisier sub-sample.
 do not claim that this is the best choice, but it is at least a good choice for per-forming this task. Also, Multilayer Perceptron classifier with default parameters was found to be giving far better results for this task than any other classifier available in weka software.
 Phase 2. The purer sub-sample of full preference set is used to train the classifier b . The trained model is then used for detecting the faulty preferences in noisier sub-sample. Here b  X  X  Multilayered Perceptron, Random Forest } . Finally a union of these faults (errors) predicted by each classifier b is taken and they are considered as the final pairwise preference faults which need to be flipped. 2.4 Noise Measurement Once the appropriate flips are made, measurement of the noise of updated paired representation is done. It is computed as the number of incorrect document preference pairs to the total number of preference pairs. The idea of computing Document Pair noise is taken from [ 7 ] in which it is referred to as pNoise. From the study, they have concluded that document pair noise captures the true noise of ranking algorithms, and can well explain the performance degradation of ranking algorithms. Hence, it has been used to evaluate the effectiveness of the noise-correction process by the reduction in document pair noise achieved by the method 2 . Experiments are performed on 3 standard Learning to Rank LETOR 3.0 datasets [ 8 ]: OHSUMED, TREC-TD-2003, TREC-TD-2004. Noise levels of { 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5 } are injected in each of these datasets and checked to what extent noise can be corrected depending on the initial noise present. The process is performed thrice and the average results are reported. ated with each query. TREC-TD-2003 contains 50 queries with approximately 1000 documents associated with each query and TREC-TD2004 contains 75 queries with approximately 1000 documents for each query. OHSUMED repre-sents query-documents pair by a set of 45 features, while TREC-TD 2003, 2004 use 44 features each. OHSUMED has 3 relevance levels { 2 , 1 , 0 } while TD2003 and TD2004 have { 1 , 0 } . 0.4. After this, curve takes a very steep turn and almost fails to reduce noise at statistically significant levels around noise level of 0.5. However, the process has been proved robust enough to correct errors even at high noise level of 0.45 in each of the 3 datasets.
 datasets is due to an inherent characteristic of the datasets. OHSUMED has 3 relevance labels { 2 , 1 , 0 } and so it X  X  preference set contains 3 kinds of docu-ment pairs: ( d 2 ,d 1 ) , ( d 1 ,d 0 )&amp;( d 2 ,d 0 ) from which anomalies are to be found. Whereas, TREC-TD datasets contain only 2 relevance labels { 1 , 0 } and so have only 1 kind of document pair ( d 1 ,d 0 ). So the noise reduction is efficient in case of TREC-TD compared to OHSUMED in which there are mixed document pairs because of which error detection is difficult. This paper proposes a simple yet very efficient approach to correct the errors in pairwise preferences for learning to rank. The proposed approach was able to reduce up to 90 % of induced noise at statistically significant levels depending on the initial noise injected in it. The robustness of this process has also been checked by inducing different noise levels. On response to this, the process was able to correct errors at statistically significantly even at high noise level of 0.45. The proposed model has been checked on three different Learning to Rank data-sets and shown to work efficiently on each of them.
 mistakes are not equally probable. So, a more realistic method for noise injection which considers this can help to better evaluate this approach. Apart of that, reduction in noise of pairwise document preferences should have direct positive impact on efficiency of pairwise learning to rank algorithms. Different Learning to Rank algorithms have different levels of robustness against noise [ 7 ]. Hence, as a future work, it would also be interesting to analyse the effect of noise correction of training data on efficiency of various pairwise learning to rank algorithms.
