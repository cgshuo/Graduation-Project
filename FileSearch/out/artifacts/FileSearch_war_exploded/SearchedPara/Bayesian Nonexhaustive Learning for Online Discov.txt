 Murat Dundar dundar@cs.iupui.edu Ferit Akova ferakova@cs.iupui.edu Yuan Qi alanqi@cs.purdue.edu Bartek Rajwa brajwa@purdue.edu A training set is considered exhaustive if it contains samples from all classes of informational value. When some classes are missing and hence not represented, the resulting training set is considered nonexhaustive . It is impractical, often impossible, to define a training set with a complete set of classes and then collect sam-ples for each class, mainly because some of the classes may not be in existence at the time of training, they may exist but are not known, or their existence may be known but samples are simply not obtainable. A traditional supervised classifier trained using a nonex-haustive training set misclassifies a sample of a missing class with a probability one, making the associated learning problem ill-defined. 1.1. Motivation The current research is driven mainly by a biosensing problem involving prediction of the presence of specific as well as unmatched/emerging pathogenic microor-ganisms in various biological samples. A global surge in the number of outbreaks together with elevated con-cerns about biosecurity has led to an enormous interest among scientific communities and government agencies in developing reagantless techniques for rapid identifi-cation of pathogens. Traditional recognition methods based on antibodies or genetic matching remain labor intensive and time consuming, and involve multiple steps. Recent studies based on quantitative phenotypic evaluation has shown great promise for distinguishing bacterial cultures at the genus, species, and strain level. The core advantage of label-free methods is their ability to quantify phenotypes for which there are no avail-able antibodies or genetic markers. This information can be used within a traditional supervised-learning framework in which knowledge discovered from inde-pendently tested and prelabeled samples is used for training. However, the quality of training libraries is po-tentially limited because the sheer number of bacterial classes would not allow for practical and manageable training in a traditional supervised setting; for instance Salmonella alone has over 2400 known serovars. Ad-ditionally, microorganisms are characterized by a high mutation rate, which indicates new classes of bacteria can emerge anytime. Nonexhaustive learning when implemented in this domain in an online fashion aims at rapid identification of new, emerging classes of mi-croorganisms, which are not represented in the initial training library. Ability to detect the sudden presence of a new class (or classes) would be an important ele-ment of an automated outbreak-identification strategy. 1.2. Proposed approach in a nutshell Using a nonexhaustive training dataset, a Dirichlet pro-cess prior (DPP) is coupled with a Normal data model to deal with known as well as unknown classes. The parameters of the base distribution, which is chosen as a bivariate Normal  X  Inverted Wishart distribu-tion, are estimated using samples initially available for known classes. A sequential importance resampling (SIR) technique is proposed to perform online infer-ence to efficiently evaluate the probability of a new sample belonging to an emerging class or one of the existing ones without the need for explicit knowledge of the class labels of previously observed samples. In this framework new classes characterized by a rapid increase in sample size is of significance for early identification of potentially interesting class formations. 1.3. Related Work Early work most similar to nonexhaustive learning includes the two studies reported in (Akova et al., 2010; Miller &amp; Browning, 2003). In (Akova et al., 2010) a Bayesian approach based on the maximum likelihood detection of novelties using a dynamically updated class set was proposed. In (Miller &amp; Browning, 2003) known and unknown classes were modeled by a mixture of experts model with learning performed by expectation-maximization. The former depends on the class conditional likelihoods for creating new classes and the latter uses minimum description length coupled with some heuristics to determine the optimal number of mixture components. Neither of the approaches consider a prior model for class distributions which results in the decision to create a new class to be mainly data driven and ad-hoc in both approaches. Also the lack of efficient online/incremental learning capabilities makes both approaches impractical for processing large sequential data.
 Other work related to nonexhaustive learning can be reviewed within the scope of offline anomaly/novelty detection, online/incremental learning, and online clus-tering with novelty detection. Most of the early work on offline anomaly/novelty detection is developed around one-class classification problems and uses either sup-port estimation, one-class classifiers, or density-based models to identify novelties. These techniques provide an offline framework for detecting novelties but do not differentiate among them; thus, lack the capability to discover and model individual classes online.
 Online/incremental learning develops efficient algo-rithms for sequential classification problems such that the classifier model can be updated using only the current sample without retraining with past samples. Many of these studies assume that the initial training set is exhaustive. The one (Kivinen et al., 2001) that does consider nonexhaustiveness studies novelty detec-tion along with online learning, but its scope is limited to one class problems only.
 Another line of work related to nonexhaustive learning has been developed in the area of online clustering with and without novelty detection. We will use DPP in this study for online class modeling the same way these techniques use it for online cluster modeling. How-ever, unlike online cluster modeling, which depends on a vague prior, a more informative prior can be obtained in a nonexhaustive setting using samples of represented classes. To avoid the vague prior issue the work in (Zhang et al., 2005) proposes using a histor-ical dataset to estimate the parameters of the DPP. Although the work is framed as a clustering problem with a multinomial data model, it is similar to the proposed study in using labeled data for estimating the prior model. However, the solution offered in this approach for the sequential update of the cluster mod-els is suboptimal in that the posterior probability for each incoming sample was evaluated once and same values were used for all subsequent samples. As new samples emerge these previously evaluated probability values can increase/decrease resulting in suboptimal class assignments for samples observed earlier. We be-lieve that the proposed sequential inference technique involving particle filters is an important step toward addressing this problem in a nonexhaustive setting. In this section we present a general framework for learn-ing with a nonexhaustively-defined training dataset, which allows for online discovery as well as modeling of new classes. To differentiate classes discovered online from those initially available in the training library we introduce the notion of labeled vs. unlabeled classes, where the terms labeled and unlabeled refer to verified and unverified classes, respectively. When referring to classes discovered online the terms unlabeled class and cluster are used interchangeably throughout this text. In the proposed framework online class modeling is tackled by a DPP model (Ferguson, 1973). 2.1. Dirichlet process prior Let x i , i = { 1 ,...,n } be the feature vector characteriz-ing a sample in the d-dimensional vector space &lt; and y be its corresponding class indicator variable. If x i is distributed according to an unknown distribution p ( . |  X  i ), then defining a DPP over class distributions is equivalent to modeling the prior distribution of  X  by a Dirichlet process. More formally, where G is a random probability measure, which is distributed according to a Dirichlet process (DP) de-fined by a base distribution, G 0 , and the precision parameter,  X  . Given that G is distributed according to a DP, the stick-breaking construction due to (Ish-waran &amp; James, 2001) suggests G = P  X  i =1  X  i  X   X  i where  X  i =  X  The points  X  i are called the atoms of G . Note that un-like continous distributions the probability of sampling the same  X  i twice is not zero and proportional to  X  i . Thus, G is considered a discrete distribution. 2.2. DPP in a nonexhaustive framework The suitability of the DPP model for nonexhaustive learning can be better conceived with the help of the conditional prior of  X  . Let X  X  assume that at a certain time point the training set contains a sequence of n sam-ples. The conditional prior of  X  n +1 conditioned on all past  X  i , i = { 1 ,...,n } can be obtained by integrating out G in (1) which becomes, This conditional prior can be interpreted as a mix-ture of two distributions. Any sample that originates from this prior comes from the base distribution G 0 (  X  ) with a probability of  X   X  + n or uniformly generated from {  X  1 ,..., X  n } with a probability of n  X  + n . With a positive probability a sequence of n samples generated this way will not be all distinct. If we assume that there are k  X  n distinct values of  X  in a sequence of size n , then (2) can be rewritten,  X  where  X   X  j , j = { 1 ,...,k } are the distinct values of  X  and n j are the number of occurrences of each  X   X  j in the sequence. Each  X   X  j defines a unique class with an indicator variable y  X  j , whose samples are distributed according to the probability distribution p (  X |  X   X  j ). Based on (3), after a sequence of n samples are generated, y n +1 = y  X  j with probability equal to y k +1 , with probability equal to the new class whose parameter is defined by  X   X  k +1 and sampled from G 0 (  X  ).
 This prior model can also be illustrated as a Chinese Restaurant process (CRP) (Aldous, 1985). The CRP uses a metaphor of a Chinese restaurant with infinitely many tables where the ( n + 1) th customer sits at a previously occupied table j with a probability of n j  X  + n and at a new table k + 1 with a probability of  X   X  + n . Here n j is the number of customers sitting at table j and n is the total number of customers.
 Our discussion so far has been limited to the prior model. Next, we will incorporate the data model and use the conditional posterior to determine whether a new sample x n +1 should be assigned to one of the existing classes or to a new class sampled from G More specifically, we are interested in the distribution p (  X  n +1 | x n +1 , X  1 ,..., X  n ), which is proportional to which indicates x n +1 either comes from a new class, y k +1 , which inherits  X  with a probability proportional to  X   X  + n p ( x n +1 belongs to y  X  j with a probability proportional to Since  X   X  j are not known and has to be estimated using samples in the represented classes, p ( x n +1 |  X   X  j ) can be replaced with the class conditional predictive distri-bution p ( x n +1 | D j ) where D j = { x i } i  X  C j denotes the subset of samples belonging to class y  X  j defined by the index set C j . Thus, provided that class membership information for all samples processed before x n +1 are known, the decision function to assign x n +1 to a new class or one of the existing ones can be expressed as, in the nonexhaustive learning framework class mem-bership information is only available for samples ini-tially present in the training dataset. For all samples processed online before x th n +1 sample the true class membership information is unknown. Before we move on to discussing how inference can be performed in this framework, we introduce new notation to distinguish between the two types of sam-ples available during online execution: samples ini-tially available in the training dataset with known class membership information and samples observed online with no verified class membership information. Let X = { x 1 ,...,x ` } be the set of all training sam-ples initially available, Y = { y 1 ,...,y ` } be the corre-sponding set of known class indicator variables with y  X  X  1 ,...,k } , k being the number of known classes,  X  X n = {  X  x 1 ,...,  X  x n } be the set of n samples sequentially sponding set of unknown class indicator variables with  X  y sented classes associated with these n samples. 3.1. Inference by Gibbs Sampling We are interested in predicting  X  Y n +1 , i.e., the class labels for all  X  X n +1 at the time  X  x n +1 is observed, which can be done by finding the mean of the posterior dis-cannot be easily evaluated, the closed form solution for the conditional distributions of the latent vari-ables  X  y i can easily be obtained. Thus, Gibbs sam-pling with the sampler state consisting of variables  X  y , i = { 1 ,...,n + 1 } , can be used to approximate p (  X 
Y n +1 |  X  X n +1 ,X,Y ). One sweep of the Gibbs sampler will involve sampling from the following conditional distribution  X  i . 3.2. Inference by Sequential Importance With the Gibbs sampler approach every time a new sample is observed the sampler has to run from start to predict whether the current sample belongs to one of the existing classes (labeled/unlabeled) or to a new class. This sampling scheme eventually becomes in-tractable as the number of unlabeled samples gradually increases. We believe that this problem can be ad-dressed to a greater extent by developing a sequential sampling approach based on Sequential Importance Re-sampling (SIR) (Doucet et al., 2000). In this approach, at any given time, the sampler only depends on a set of particles and their corresponding weights, which are efficiently updated in a sequential manner each time a new sample is observed without the need for the past samples.
 More specifically, we are interested in evaluating the vant integral can be approximated as follows.
 = R  X  Y n +1 p (  X  Y n +1 |  X  Y n ,  X  X n +1 ,Y,X )  X  where M is the number of particles and w n +1 m (  X  Y n +1 m th particle at the time ( n + 1) th sample is observed. Particles are sampled from the importance function q (  X  ated sequentially up to an unknown constant as out-lined next.
 Using the chain rule and after some manipulations a sequential update formula for the particle weights w Although, it is not optimal in terms of minimizing the variance, the common choice for q (  X  y n +1 |  X  Y n ,  X  Y,X ) = p (  X  y n +1 |  X  Y n ,Y ) further simplifies the update formula by canceling out both terms in (8). After con-with respect to  X  Y n +1 , the sequential update formula for the particle weights become  X  x n +1 for any given particle, the weights at stage n + 1 can be obtained up to an unknown constant C . Using normalized weights eliminates C and thus the discrete probability distribution in (7) can be fully evaluated and efficiently updated.
 Every time a new sample is observed, first, a designated number of, i.e., R , new particles are resampled for each of the M particle using the importance function, then, weights are updated for the M  X  R particles, finally, downsampling, stratified on the particle weights, is performed to select M particles out of M  X  R ones. Resampling is critical to avoid the weight degeneracy problem mainly associated with Dirichlet process mix-ture models. To address the weight degeneracy problem a resampling strategy that ensures a well-distributed particle set was introduced in (Fearnhead &amp; Clifford, 2003; Wood &amp; Black, 2008). Using this strategy, in-stead of resampling R new particles for each existing particle from the importance function, k +  X  k + 1 par-ticles are generated by considering all possible class labels an incoming sample can take for a given particle. Note that although k , i.e., number of labeled classes is constant across all particles,  X  k , i.e., number of unla-beled classes, varies from one particle to other. Since all possible classes are considered in this approach, it is now essential to revise the weight update formula to include prior probability for each class. 3.3. Estimating the precision parameter  X  In the proposed framework  X  is the parameter that controls the prior probability of assigning a new sam-ple to a new cluster and thus, plays a critical role in the number of clusters generated. When the training samples are collected to reflect the true proportion of each class as well as the actual number of classes as in a training set with the same number of samples collected in real-time, the marginal distribution of the number of clusters p (  X  k ) can be maximized to obtain the maximum likelihood estimate of  X  . However, in many machine learning applications only the most prevalent classes are available in the training set and the training samples are almost never collected in real-time. Thus, p (  X  k ) may not model a training set collected offline very well.
 One viable approach to predicting  X  when training samples are not collected in real-time is to sample it from the distribution p (  X  |  X  k,n ) (Escobar &amp; West, 1994). This approach although widely used in mixture density estimation involving batch data as part of a Gibbs sam-pler, it is not suitable for the proposed SIR algorithm, mainly because with SIR particles themselves are a function of  X  . Therefore,  X  has to be fixed in order for the weight update formula to hold and thus, the SIR algorithm to work. In this study we encode our prior belief about the odds of encountering a new class by a prior probability value p that indicates the prior prob-ability of a new sample coming from one of the labeled classes in the training set. Once a vague value for p is obtained for a given domain,  X  can be estimated by empirical Bayes by sampling a large number of samples from a CRP for varying values of  X  and then picking up the one that minimizes the difference between the empirical and true values of p . Both the Gibbs sampler and SIR requires the evaluation of the predictive p (  X  x i | D j ) and the marginal p (  X  x tributions. The predictive distribution for both labeled and unlabeled classes can be obtained by integrating out  X  . The marginal distribution can be obtained from p (  X  x i | D j ) by setting D j an empty set. In general the exact solution for the predictive and marginal distri-butions does not exist and approximations are needed. However, a closed-form solution does exist for a Nor-mally distributed data model and a properly chosen base distribution as presented next. We give  X  j a Gaussian distribution with mean  X  j and covariance  X  j ; that is,  X  j  X  X  (  X  j ,  X  j ). For the mean and covariance matrix, we use a joint conjugate prior G 0 : where  X  0 is the prior mean and  X  is a scaling constant that controls the deviation of the class conditional mean vectors from the prior mean. The smaller the  X  is, the larger the between class scattering will be. The parameter  X  0 is a positive definite matrix that encodes our prior belief about the expected  X . The parameter m is a scalar that is negatively correlated with the degrees of freedom. In other words the larger the m is the less  X  will deviate from  X  0 and vice versa. To evaluate the update formula in (9) for SIR we need out  X  = {  X ,  X  } . Since the sample mean  X  x and the sample covariance matrix S are sufficient statistics for the multivariate Normally distributed data, we can posterior and its derivation is widely available in books on multivariate statistics (Anderson, 2003). Once we  X  and then with respect to  X  we obtain the predictive distribution in the form of a multivariate Student-t distribution.
 In addition to p ( x n +1 | D j ) we also need p ( x n +1 evaluating the decision function in (5), which is also a multivariate Student-t distribution with D j an empty set.
 4.1. Estimating the parameters of the prior The parameters ( X  0 ,m, X  0 , X  ) of the prior model can be estimated offline using samples from the well-defined classes. The maximum-likelihood estimates for  X  0 and m do not exist. The study in (Greene &amp; Rayens, 1989) suggests estimating  X  0 by the unbiased and consistent estimate S p , i.e., the pooled covariance, and maximizing the marginal likelihood of ( n j  X  1) S j for m &gt; d + 1 numerically to estimate m . Here, S p is the pooled covariance matrix defined by where n is the total number of samples in the train-ing set, i.e., n = P k j =1 n j . The marginal distri-bution of ( n j  X  1) S j can be obtained by integrat-ing out the joint distribution p (( n j  X  1) S j ,  X  j data model p (( n j  X  1) S j |  X  j ) is a Wishart distribution with a scale matrix  X  j and degrees of freedom n j  X  1, i.e., ( n j  X  1) S j |  X  j  X  W ( X  j ,n j  X  1) and p ( X  j ) is an inverted Wishart distribution as defined in (10). The parameters  X  and  X  0 can be estimated by maximizing the joint likelihood of  X  x and S , p (  X  x,S ), with respect to  X  and  X  0 , respectively. 5.1. An illustrative example We present an illustrative example demonstrating the proposed algorithm discovering and modeling classes with a 2-D simulated dataset. We generate twenty three classes where the class covariance matrix of each class is obtained from an inverted Wishart distribu-tion with parameters  X  = 10 I and m = 20 and mean vectors are equidistantly placed alongside the periph-eries of two circles with radius 4 and 8 creating a flower-shaped dataset. Here, I denotes the 2-D identity matrix. Three of the twenty three classes are randomly chosen as unrepresented. The nonexhaustive training data contains twenty classes with each class represented by 100 samples (a total of 2000 samples) whereas the exhaustive testing data contains twenty three classes with 100 samples from each (a total of 2300 samples). The objective here is to discover and model the three unrepresented classes while making sure samples of rep-resented classes are classified as accurately as possible. Figure 1a shows true class distributions for all twenty three classes. The represented classes are shown by solid lines and unrepresented ones by dashed lines. The ellipses correspond to the distributions of the classes that are at most three standard deviations away from the mean. The testing samples are classified sequen-tially using the SIR algorithm discussed in Section 3.2. The precision parameter  X  and the number of particles M are chosen as 1 and 500, respectively. Figures 1b, 1c, and 1d demonstrate the online discovery and modeling of new classes when 100, 300, and all 2300 test samples are classified, respectively. The discovered classes are marked by solid blue lines. All three classes are discov-ered and their underlying distributions are successfully recovered by generating one cluster for each class. 5.2. Bacteria detection A total of 2054 samples from 28 classes each represent-ing a different bacteria serovar were considered in this study. These are the type of serovars most commonly found in food samples. Each serovar is represented by between 40 to 100 samples where samples are the forward-scatter patterns characterizing the phenotype of a bacterial colony obtained by illuminating the colony surface by a laser light. Each scatter pattern is a gray level image characterized by a set of 50 features. More information about this dataset is available in (Akova et al., 2010). Samples are randomly splitted into two as train and test, with 70% of the samples going into the training set and the remaining 30% in the test. Stratified sampling is used to make sure each class is proportionately represented in both the training and the test sets. Four of the classes are considered un-known and all of their samples are moved from the training set to the test set. The nonexhaustive training set contains 24 classes whereas the exhaustive testing set contains 28 classes. Since the training samples are collected offline the number of samples initially avail-able for labeled classes may not necessarily reflect true class proportions. To avoid introducing bias in favor of classes with larger numbers of samples we assumed that each labeled class is a priori likely by setting n j = 1. The performance of the proposed SIR algorithm (NEL-SIR) discussed in Section 3.2 is evaluated on three fronts: classification accuracy for represented classes, classification accuracy for unrepresented classes, and the number of clusters discovered for each of the un-represented classes. To compute the latter two values each unlabeled cluster is assigned to the unrepresented class having the majority of the samples in that class. Classification accuracy for each unrepresented class is computed by the ratio of the total number of samples recovered by the corresponding clusters to the total number of samples in that class. To see the effect of the execution order of the test samples on the overall results the experiment is repeated multiple times each time with a different ordering of test samples. Using the approach discussed in Section 3.3 the precision parameter  X  is predicted as 10 for a p of 0.95, i.e., an incoming sample a priori belongs to one of the 24 labeled classes by a probability of 0.95. The number of particles M is chosen to be 2000.
 The proposed NEL-SIR is compared against the Bayes-NoDe algorithm proposed in (Akova et al., 2010). Both the proposed NEL-SIR and Bayes-NoDe use the same data model, i.e.,  X  j  X  N (  X  j ,  X  j ) , (  X ,  X )  X  N  X  |  X  0 ,  X  tioned in Section 1.3, there are significant differences between the two approaches in terms of prior mod-eling of class distributions and performing inference in a nonexhaustive setting. In addition to these two algorithms we also considered the exhaustive case, i.e., the setting under which all 28 classes are represented in the training set to serve as a benchmark for comparing our results. The results including the classification accuracies for represented as well as unrepresented classes and the number of clusters discovered for each unrepresented class are shown in Table 1.
 Classification accuracy achieved by the proposed NEL-SIR algorithm for represented classes is on par with that achieved by Bayes-NoDe. Although all four un-represented classes are successfully discovered by both NEL-SIR and Bayes-Node, NEL-SIR tend to generate far less number of clusters in general and achieves sig-nificantly higher accuracy than BayesNoDe for each unrepresented class. The average number of clusters discovered for each unrepresented class is especially important for practical purposes because in a real-time biodetection system once new clusters are discovered as unknowns, their samples has to be analyzed offline to assess the pathogenic nature of these clusters. The less the number of clusters discovered for each unrepre-sented class the less time and resources offline analysis will require.
 The perfect accuracies achieved for two of the unrepre-sented classes in the exhaustive setting indicate these classes are well separated from other classes. For the two well-separated classes NEL-SIR performs equally well with the exhaustive case. These results indicate that if the unrepresented classes are well separated the proposed approach not only discover these classes and recover them by a reasonable number of clusters but also classify their samples at an accuracy compa-rable to an exhaustive classifier. If the unrepresented classes are not perfectly separated these classes can still be discovered but some loss in classifier accuracy as compared to an exhaustive classifier is inevitable. Online class discovery is an important problem that finds its place in many real-life applications involving evolving datasets. In this study, in an effort to discover emerging classes, a sequential inference algorithm based on particle filters was proposed for a Dirichlet process mixture model. In this approach the posterior distribu-tion of the class indicator variables is approximated by a discrete distribution expressed by a set of particles and the corresponding weights. The particles and their weights are efficiently updated each time a new sam-ple is observed. This way the posterior distribution is updated in a sequential manner without the need to have access to past samples enabling efficient online inference in a nonexhaustive setting. Our algorithm is validated using a 28-class bacteria with four of the classes considered unknown and promising results are obtained with respect to classification accuracy and class discovery.
 The data model used in this study was limited with the Normal model. The proposed approach can be extended to problems involving more flexible class dis-tributions by choosing a mixture model for each class data and a hierarchical DPP model over class distribu-tions. Additionally, the model used in our studies does not explicitly model variation in class size as a function of time. Modeling time can be essential for modeling burstiness. We believe a time-dependent Dirichlet pro-cess can be useful toward achieving this end. Owing to the long tail behavior of DPP, with the current approach the probability of discovering a new class will converge to zero as n goes to infinity. Although we cannot verify whether Zipf X  X  law holds for bacteria population we believe a Pitman-Yor process can offer more control over tail behavior of the prior model. The project was supported by Grant Number 5R21AI085531-02 from the National Institute of Al-lergy and Infectious Diseases (NIAID). The content is solely the responsibility of the authors and does not necessarily represent the official views of NIAID or the National Institutes of Health.
 Akova, Ferit, Dundar, Murat, Davisson, V. Jo, Hirle-man, E. Daniel, Bhunia, Arun K., Robinson, J. Paul, and Rajwa, Bartek. A machine-learning approach to detecting unknown bacterial serovars. Statistical Analysis and Data Mining , 3(5):289 X 301, 2010. Aldous, David J. Exchangeability and related topics. In  X  Ecole d X   X  Et  X e St Flour 1983 , pp. 1 X 198. Springer-Verlag, 1985. Lecture Notes in Math. 1117.
 Anderson, Theodore W. An Introduction to Multi-variate Statistical Analysis, 3rd Edition . Wiley-Interscience, 3rd edition, 2003.
 Doucet, Arnaud, Godsill, Simon, and Andrieu,
Christophe. On sequential Monte Carlo sampling methods for Bayesian filtering. Statistics and Com-puting , 10(3):197 X 208, 2000.
 Escobar, Michael D. and West, Mike. Bayesian density estimation and inference using mixtures. Journal of the American Statistical Association , 90:577 X 588, 1994.
 Fearnhead, Paul and Clifford, Peter. On-line infer-ence for Hidden Markov Models via particle filters. Journal of the Royal Statistical Society -Series B: Statistical Methodology , 65(4):887 X 899, 2003. Ferguson, Thomas S. A Bayesian analysis of some nonparametric problems. Annals of Statistics , 1(2): 209 X 230, 1973. ISSN 00905364. doi: 10.1214/aos/ 1176342360.
 Greene, Tom and Rayens, William. Partially pooled covariance matrix estimation in discriminant analysis.
Commun. Statist. Theory Meth. , 18(10):3679 X 3702, 1989.
 Ishwaran, Hemant and James, Lancelot F. Gibbs sampling methods for stick-breaking priors. Jour-nal of the American Statistical Association , 96(453): pp. 161 X 173, 2001. ISSN 01621459. URL http: //www.jstor.org/stable/2670356 .
 Kivinen, Jyrki, Smola, Alex J., and Williamson,
Robert C. Online learning with kernels. In Diet-terich, Thomas G., Becker, Suzanna, and Ghahra-mani, Zoubin (eds.), Advances in Neural Informa-tion Processing Systems 14 , pp. 785 X 792. MIT Press, 2001.
 Miller, D. J. and Browning, J. A mixture model and em-based algorithm for class discovery, robust classifica-tion, and outlier rejection in mixed labeled/unlabeled data sets. IEEE Transactions on Pattern Analysis and Machine Intelligence , 25(11):1468 X 1483, 2003. Wood, F. and Black, M. J. A non-parametric Bayesian alternative to spike sorting. Journal of Neuroscience Methods , 173:1 X 12, 2008.
 Zhang, Jian, Ghahramani, Zoubin, and Yang, Yiming.
A probabilistic model for online document cluster-ing with application to novelty detection. In Saul, Lawrence K., Weiss, Yair, and Bottou, Lean (eds.),
Advances in Neural Information Processing Systems
