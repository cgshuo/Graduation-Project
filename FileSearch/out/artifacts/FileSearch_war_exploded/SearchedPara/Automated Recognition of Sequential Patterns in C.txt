 Motion capture (mocap) data is a kind of multi-attribute time series, with the sample at each time instance representing a posture. Motion capture has been frequently used formation of the postures across time. The mocap data is often captured continuously such that a captured motion may contain multiple patterns (i.e. basic moves) con-nected in a sequential manner without obvious breakpoints between them. It is thus non-trivial to learn the patterns in the captured motions since their boundaries segmenting and recognizing the sequential patterns in mocap data given some prede-fined references. 
It is quite challenging to automatically segment and recognize the sequential pat-terns in mocap data due to three major reasons: (1) It is not known in advance which (2) The intra-class variations can be quite large as different subjects may perform the same motion with different speeds and styles. (3) Some motions from different classes may have a certain degree of similarity making it difficult to differentiate these misrecognized or the boundaries of the patterns to be wrongly detected. 
For data stream segmentation, unlike the work reported in [4] and [9], where the time series is segmented according to the accumulative reconstruction error or low level kinematics features, we process the sequential patterns by comparing with pre-defined references. The segmentation of the patterns is determined by the matching scores between the input motion and the predefined reference motions. 
Among the existing approaches on sequential patterns recognition, hidden markov model (HMM) [5][6] and dynamic time warping (DTW) [7][8] with their variants are the two main streams. With HMM, each class of patterns is trained as a separate HMM and the segmentation and recognition of the patterns is determined by the probabilities under the HMMs. Based on the complicated mathematical model, HMM based methods can handle the temporal variations of the motions and obtain good performance. The major drawback is the complexity in training each HMM and it will be problematic when there is insufficient training data. 
DTW and similar methods based on dynamic programming gain significant atten-different durations and easy training. Continuous dynamic programming (CDP) and open-end dynamic time warping (OE-DTW) are the two most commonly used vari-mally matched subsequence in the reference. On the other hand, OE-DTW [1] relaxes the constraint on the alignment of the end points, and hence it facilitates recognizing a pattern before it is completely input. In this paper, we propose a new method based on OE-DTW to segment and recognize the sequential patterns in mocap data. 
The contributions of our proposed method include the followings: 1. A new global constraint, named K-Repetition , is introduced to apply on OE-DTW 2. We improve the end point detection scheme of the original OE-DTW by intro-The rest of the paper is organized as follows. In Section 2, we give a brief review on some important background of this work. Our proposed method is presented in concludes the paper and discusses the future work. 2.1 DTW and OE-DTW DTW is a well-known distance measure in matching two signals. Given two patterns, to find the optimal aligned path between them and calculate the minimal distance using dynamic programming as follows. where D( 1 , 1 ) = d( 1 , 1 ); D(i, 1 ) = D(i -1 , 1 ) + d(i, 1 ); D( 1 ,j) = D( 1 ,j -1 ) + d( 1 ,j); In the above equations, D(i,j) denotes the minimum accumulative distance between between frames q i and r j . Finally the expression D DTW (Q,R) = D(n,m) / N(n,m), where N(n,m) is the normalization factor in the cell ( n , m ), is returned as the DTW distance between Q and R . The optimal warped path can be obtained by backtracking the recursion. An example of the DTW alignment is shown in Fig. 1. 
As shown in Eq. (2), DTW has boundary constraint in which the start and end points of the two patterns must be aligned correspondingly. This will lead to undesir-able result if we apply DTW to recognize an incomplete pattern. To handle this prob-lem, OE-DTW [1] frees the constraint on en d point alignment. It was demonstrated to be effective and efficient on incomplete pattern recognition. OE-DTW chooses the cell with minimal normalized distance in the last column of the distance table as the result. The process is illustrated by the following two equations: where J is returned as the matched end point in the reference, meaning that the input Q matches best with the prefix R (J) ( R (J) = r 1 ,r 2 ,...,r J ). 
In essence, OE-DTW computes DTW distances between Q and all the possible sub-minimal distance as the final result. The solid line in Fig. 5 shows such an example. 2.2 Normalization and Global Constraint on DTW During both DTW and OE-DTW calculation, it requires normalizing the distances in determined as the length of the optimal warped path from the cell (1,1) to ( i , j ) in the original DTW. If we take N(i,j) as the sum of weights on the corresponding path, then this normalization scheme can be illustrated by Fig. 2(a). Fig. 2(b) shows another scheme of normalization, which puts more weights on the diagonal direction. In our application, we apply the latter normalization scheme because with this scheme, we optimal path to get its length as performed by the former scheme. 
On the other hand, DTW may not find the desired warped path because it just tries to obtain the minimal distance without considering the shape of the path (see Fig. 3(a) for a negative example). This will deteriorate the efficiency of DTW on the classifica-been proposed, such as Sakoe-Chiba band [2], Itakura Parallelogram [11], and Ratanamahatana-Keogh band [12], to constrain the warped path within the shadow region as illustrated in Fig. 3(b)(c)(d). We apply a new global constraint named K-Repetition on OE-DTW, and introduce a flexible scheme to improve the end point detection with OE-DTW. Based on this extended OE-DTW, an algorithm is proposed to recognize the sequential patterns in mocap data. 3.1 K-Repetition Global Constraint As shown in Fig. 3, all the mentioned global constraints work by relying on the main diagonal of the distance table, hence the en d points of the two patterns to be compared should be known in advance. As a result, these constraints cannot be applied to OE-DTW in which the end point of the warped path needs to be determined. Subsequently the main diagonal cannot be relied on. 
On the other hand, after our analysis on negative DTW alignments, we find that the unwanted result often comes up when there exist many repetitions of some samples in one pattern matching with the other pattern. Subsequently there are many long verti-tackle this problem by introducing a new global constraint of K-Repetition . 
The basic idea of K-Repetition is to limit the number of times that each sample in that each sample in one pattern cannot be matched more than k times by the samples of the other pattern. Fig. 4 shows an example of DTW alignment with K-Repetition , where k =3. With K-Repetition , the number of times that each sample is matched is considered. other pattern, then it is not allowed to be matched any more. There is no need to con-sider the case with the main diagonal. In other words, DTW with K-Repetition samples. Due to this feature, K-Repetition can be applied to OE-DTW as well. 3.2 Flexible End Point Detection As shown in Eq. (4), OE-DTW determines the forepart of the reference that matches result. 
Here we propose a flexible end point detection scheme. The rational behind the new scheme is to make the input pattern Q to be matched with the reference R with a implement our scheme by adding the following conditions: While J X &lt;m &amp;&amp; D OE (Q,R)*(1+  X  )&lt;D(n,J X +1) 3.3 Recognition Algorithm of the Sequential Patterns In this section, we propose an algorithm based on the extended OE-DTW, namely, OE-DTW with K-Repetition and the flexible end point detection scheme, to recognize the sequential patterns in mocap data. For example, in Fig. 6, the input motion is first considered as a sequence of unknown patterns. The beginning part of the input motion is compared with each of the references using our proposed extended OE-DTW algorithm in order to find the best match. Since the reference R A is the best match, the first pattern of the input motion is recognized. bound (say 300 samples), when processing a pattern, it does not need to take the whole motion as an input to OE-DTW. For example, in Fig. 6, when we process the first pattern, matching R A with the beginning part of the input motion with OE-DTW can generate the same result as matching R A with the whole motion with OE-DTW. The former condition requires much less calculation. To save the calculation, we thus define len as the upper bound of the length of any pattern. Each time when a pattern is compare them with the references. 
Based on the above discussions, the proposed algorithm is presented as the follow-Initially, start is set to be 1. 1. Input len consecutive samples beginning at start from I into the sliding window, 2. For each reference R i ( i=1,2,...,C, where C is the number of references), calculate 4. If there are more samples left in I , return to Step 1. Otherwise end the algorithm. 
For each pattern in the input stream, we can segment and recognize it with a com-putation complexity of O(C  X  L  X  len) , where L is the average length of the references. In this section, we will apply the proposed method to human motion recognition. We first introduce the acquired motion data and then present the experiments and results. 4.1 Data Acquisition The dataset is captured by using a marker-based 3D optical motion capture system as shown in Fig. 7(a). An actor wears a special suit with 35 optical markers adhered to different body parts including head, torso, waist, limbs etc. From the 3D coordinates of the markers, we extract the 3D angles of the 20 joints (see Fig. 7(b), not including the end factors marked by  X * X ) to represent each posture. 
In our experiments, we capture the motion data with the sampling rate of 60 frames per second. There are 19 classes of patterns (basic moves) for A-go-go dance as shown in Table 1. It can be observed that some patterns have similar postures but with different temporal patterns and different durations. For example, Move 8 and Move was performed 2 or 3 times by each of the 5 actors who have different levels of dance tion. These streams were performed by the same 5 actors with various numbers of patterns in the streams (see Table 2 for the detail). 4.2 Experiments and Results The experiments include three parts: (1) evaluating the performance of DTW with K-Repetition on isolated moves; (2) OE-DTW with K-Repetition on incomplete moves; and (3) the extended OE-DTW on continuous motion streams. 
In the first experiment, we applied DTW with K-Repetition for isolated move rec-ognition. Among the 265 captured isolated motions, 19 motions (1 motion per class) are chosen as the references. The remaining 246 motions are used for testing. Each of the 246 motions is chosen as the input, and then DTW with K-Repetition is applied to recognize the class of the input motion. Th e total number of recognition errors among Fig. 8(a). We can see that when k=5 , the number of recognition errors is the least (4 eventually becomes the same as that by DTW without K-Repetition . This means that global path. 
In the second experiment, similar to the first experiment, 19 motions are used as the references and the others are used for testing. For each test motion, we just take its first half as the incomplete pattern input to be recognized by OE-DTW. The result is K-Repetition . Comparing the results between the first and the second experiments, the input for the second experiment. 
In the third experiment, we apply our extended OE-DTW method for sequential pat-tern recognition, and compare the result with that of CDP. Since our task is to segment and recognize the patterns in the motion streams, we define the recognition accuracy of each stream as shown in Eq. (5). Moreover, there are two criteria in determining whether a pattern in a stream is correctly recognized: (1) the pattern is classified with ground truth boundary, say within a range of 30 frames in this experiment. sets of captured streams. A comparison of the performance by the two methods is shown in Fig. 9. From the result we can see that our method has higher recognition accuracy than CDP on all the 4 sets of test sequences. On the other hand, for both methods, as the number of patterns in a stream increases, the average accuracy decreases with more obvious trend with our method. This is because as there are more patterns in a stream, subsequently the errors will affect the recognition of the next patterns in the stream. In this paper, we propose a novel method based on an extension of OE-DTW to seg-ment and recognize the sequential patterns in mocap data. A new global constraint named K-Repetition is proposed to be applied with OE-DTW. A flexible end point detection scheme is also proposed to detect the end points of patterns in a more robust manner. Experimental results demonstrated the effectiveness of our methods, and showed that our method outperformed CDP on sequential pattern recognition. 
In future work, the proposed method will be applied to some real applications, such as dance education and interactive dancing games. Also, we will further study the temporal alignment between motion patterns and expect to work out a real time method to segment and recognize the sequential patterns in mocap data. Grants Councils of the Hong Kong Special Administration Region, China (Project No. CityU 1165/09E). 
