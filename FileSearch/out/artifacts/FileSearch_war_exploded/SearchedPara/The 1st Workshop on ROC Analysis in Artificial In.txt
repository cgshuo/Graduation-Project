 Univ. Polit X c. de Val X ncia Cami de Vera, S/N 46022 This short report includes a summary of the presentations and discussions held during the ROCAI-2004 workshop, as well as the workshop conclusions and the future agenda. ROCAI-2004 was held in Valencia, on August the 22nd, as part of the 16th European Conference on Artificial Intelligence, ECAI-2004, in Valencia, Spain. Artificial Intelligence, ROC Analysis, Machine Learning Receiver Operating Characteristic (ROC) analysis has been regularly used in medicine (radiology, diagnosis, ... ) and psychology for many decades, as a powerful tool for cost/benefit analysis in decision making. It has been introduced relatively recently in several areas of artificial intelligence: machine learning, data mining, intelligent decision support and expert systems. In this context, ROC analysis provides techniques to select possibly optimal models and to discard suboptimal ones independently from (and prior to specifying) the cost context or the class distribution. Furthermore, the Area Under the ROC Curve (AUC) has been shown to be a better evaluation measure than accuracy in contexts with variable misclassification costs and/or imbalanced datasets. AUC is also the standard measure when using classifiers to rank examples, and, hence, is used in applications where ranking is crucial, such as campaign design, model combination, collaboration strategies, and co-learning. Nevertheless, there are several open questions and limitations that hamper a broader use and applicability of ROC analysis. Its connections with other evaluation measures is not yet completely clarified, its incorporation in decision support and expert systems technology just envisaged, its use for improving the decisions of (communities of) intelligent agents unexplored, and its use in data mining hasn X  X  yet reached its full potential. Among the limitations of ROC analysis, an important one, despite some recent progress, is its possible but difficult and computationally expensive extension to more than two classes. The first motivation for a first workshop on ROC analysis was to have a first meeting to exchange ideas and advances in the fundamentals and applications of ROC analysis from the point of view of computer science. The second motivation was to broaden its scope and applicability to other areas of computer science, as well as getting attention from those fields in AI that could benefit as well from ROC analysis. And here we mean a broad view of ROC analysis in the sense of exploiting the ROC analysis Spain, The Netherlands, UK and USA. We had submissions from 7 different countries: Canada, France, Germany, Slovenia, Spain, UK and USA. Each paper was reviewed by at least two program committee members. Reviewers X  scores aggregated and the 11 papers with highest scores were selected for presentation at the workshop. These papers were published in a workshop notes volume, edited by the workshop organisers and the ECAI organisation. The technical program of ROCAI-2004 consisted of one invited talk, eleven paper presentations, one invited workshop presentation and a round table, organised in several sessions during this one-day workshop. The topics of these sessions covered a wide spectrum on ROC Analysis theory and applications, including new ideas and results, recent developments, and new research directions The workshop started with a short welcome and had an average audience of 20 attendees. Then, the technical program started with an invited talk by Peter Flach on "Recent advances in Machine Learning applications of ROC analysis", shortly revisiting some ROC analysis basics and then moving to recent advances in the interpretation of several evaluation measures (ISO-accuracy lines, decision tree splitting criteria...) and new advances in calibration and the notion of deriving better models from existing models using ROC analysis. The paper presentation started with a paper from Chris Drummond and Robert C. Holte on "What ROC Curves Can't Do (and Cost Curves Can)", which discussed an alternative way of analysing and comparing classifiers, based on Cost Curves, where each line represents a classifier (instead of points in classical ROC analysis). Robert showed several examples where Cost curves could be advantageous over classical ROC Curves representation. The paper raised significant interest and comments from the attendees. Session 1 Robert Holte presented the first paper of the session:  X  X hat ROC Curves Can't Do (and Cost Curves Can) X  by Chris Drummond and Robert C. Holte. In this work the authors show some of the limitations of classical ROC curves, and how these problems are solved with their alternative cost curves. The next presentation was "Confidence Bands for ROC Curves: Methods and an Empirical Study" by Sofus A. Macskassy and Foster Provost. Sofus A. Macskassy explained some techniques for generating and evaluating confidence bands on ROC curves. The authors showed the convenience of the techniques with some experiments. Alexandru Niculescu-Mizil presented "An Empirical Analysis of the Relationship Between AUC and 8 Standard Supervised Learning Performance Criteria" by Rich Caruana and Alexandru Niculescu-Mizil. In this work the authors studied by a thorough experimental evaluation the behaviour of 9 different performance metrics, including AUC. Session 2 The first speaker of this session was Jerome Aze, with the paper "Interestingness measures based on supervised learning. Application to terminology extraction" by Mathieu Roche, Jerome Aze, Yves Kodratoff and Michele Sebag. This work shows how paper presents two new ways of example weighting for subgroup discovery. The authors implemented them in APRIORI-SD and studied their behaviour both theoretically by means of ROC analysis and practically by application to a real-life data set. The last paper was "An Empirical Evaluation of Supervised Learning for ROC Area" by Rich Caruana and Alexandru Niculescu-Mizil. The paper was presented by Alexandru Niculescu-Mizil. The work contains an empirical comparison of the AUC performance of seven supervised learning methods. The paper also presents an ensemble selection method that yields even better AUC than the rest of methods. Ensembles are built with forward stepwise selection, the model that maximizes ensemble AUC performance being added at each step. The workshop concluded with the general impression that it succeeded as a first specific workshop on ROC analysis in a computer science scenario. First, it was a success mainly because of the number and quality of submissions. Secondly, we got attention to a workshop on ROC analysis, which is, per se, very particular, but in this case even more specific, since it was focussed to computer science. Thirdly, participants were really active during the workshop, with many questions and discussions. The open discussion centred around these three issues: 1) Most relevant topics, open questions, 2) Broadening the scope, and 3) Continuation. About the most relevant topics treated during the workshop or that needed to be tackled next, some of them were suggested: first, the idea of a "ROC analysis" software repository was suggested, warmly welcome by the rest of attendees. Some people volunteered to start working on that. Another very important issue raised by some participants was the multiclass extension of ROC analysis. We had different views on this, maybe because many application areas only deal with 2-class problems or just because multiclass ROC analysis is very difficult or a combination of both. Finally, another important point suggested was the statistical validation and confidence bands, a topic that was covered by some ROCAI-2004 papers. One of the motivations of the workshop was broadening the scope and application areas of ROC analysis. It was suggested that for most of the AI topics where ROC analysis could be applied (agent selection/ranking, expert systems and knowledge bases, consensus and collaboration in multi-agent systems, constraint satisfaction, planning and robotics, control, reinforcement learning, etc.) we didn't quite succeed to get submissions about this. Everybody agreed that this doesn't mean we shouldn't go on trying to 
