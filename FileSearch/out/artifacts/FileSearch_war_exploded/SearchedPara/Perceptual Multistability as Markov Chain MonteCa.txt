 People appear to make rational statistical inferences from noisy, uncertain input in a wide variety of perceptual and cognitive domains [1, 9]. However, the computations for such inference, even for relatively small problems, are often intractable. For larger problems like those people face in the real world, the space of hypotheses that must be entertained is infinite. So how can people achieve solutions that seem close to the Bayesian ideal? Recent work has suggested that people may use approximate inference algorithms similar to those used for solving large-scale problems in Bayesian AI and machine learning [23, 4, 14].  X  X ational models X  of human cognition at the level of compu-tational theories are often inspired by models for analogous inferences in machine learning. In the same spirit of reverse engineering cognition, we can also look to the general-purpose approximation methods used in these engineering fields as the inspiration for  X  X ational process models X  X  X rincipled algorithmic models for how Bayesian computations are implemented approximately in the human mind.
 Several authors have recently proposed that humans approximate complex probabilistic inferences by sampling [19, 14, 21, 6, 4, 24, 23], constructing Monte Carlo estimates similar to those used in Bayesian statistics and AI [16]. A variety of psychological phenomena have natural interpretations in terms of Monte Carlo methods, such as resource limitations [4], stochastic responding [6, 23] and order effects [21, 14]. The Monte Carlo methods that have received most attention to date as rational process models are importance sampling and particle filtering, which are traditionally seen as best suited to certain classes of inference problems: static low dimensional models and models with explicit sequential structure, respectively. Many problems in perception and cognition, however, require inference in high dimensional models with sparse and noisy observations, where the correct global interpretation can only be achieved by propagating constraints from the ambiguous local information across the model. For these problems, Markov Chain Monte Carlo (MCMC) methods are often the method of choice in AI and machine vision [16]. Our goal in this paper is to explore the prospects for rational process models of perceptual inference based on MCMC.
 MCMC refers to a family of algorithms that sample from the joint posterior distribution in a high-dimensional model by gradually drifting through the hypothesis space of complete interpretations, following a Markov chain that asymptotically spends time at each point in the hypothesis space proportional to its posterior probability. MCMC algorithms are quite flexible, suitable for a wide range of approximate inference problems that arise in cognition, but with a particularly long history of application in visual inference problems ([8] and many subsequent papers).
 The chains of hypotheses generated by MCMC shows characteristic dynamics distinct from other sampling algorithms: the hypotheses will be temporally correlated and as the chain drifts through hy-pothesis space, it will tend to move from regions of low posterior probability to regions of high prob-ability; hence hypotheses will tend to cluster around the modes. Here we show that the characteristic dynamics of MCMC inference in high-dimensional, sparsely coupled spatial models correspond to several well-known phenomena in visual perception, specifically the dynamics of multistable per-cepts.
 Perceptual multistability [13] has long been of interest both phenomenologically and theoretically for models of perception as Bayesian inference [7, 20, 22, 10]. The classic example of perceptual multistability is the Necker cube, a 2D line drawing of a cube perceived to alternate between two different depth configurations (Figure 1A). Another classic phenomenon, extensively studied in psy-chophysics but less well known outside the field, is binocular rivalry [2]: when incompatible images are presented to the two eyes, subjects report a percept that alternates between the images presented to the left eye and that presented to the right (e.g., Figure 1B).
 Bayesian modelers [7, 20, 22, 10] have interpreted these multistability phenomena as reflections of the shape of the posterior distribution arising from ambiguous observations, images that could have plausibly been generated by two or more distinct scenes. For the Necker cube, two plausible depth configurations have indistinguishable 2D projections; with binocular rivalry, two mutually exclusive visual inputs have equal perceptual fidelity. Under these conditions, the posterior over scene interpretations is bimodal, and rivalry is thought to reflect periodic switching between the modes. Exactly how this  X  X ode-switching X  relates to the mechanisms by which the brain imple-ments Bayesian perceptual inference is less clear, however. Here we explore the hypothesis that the dynamics of multistability can be understood in terms of the output of an MCMC algorithm, drawing posterior samples in spatially structured probabilistic models for image interpretation. Traditionally, bistability has been explained in non-rational mechanistic terms, for example, in terms of physiological mechanisms for adaptation or reciprocal inhibition between populations of neurons. Dayan [7] studied network models for Bayesian perceptual inference that estimate the maximum a posteriori scene interpretation, and proposed that multistability might occur in the presence of a multimodal posterior due to an additional neural oscillatory process whose function is specifically to induce mode-switching. He speculated that this mechanism might implement a form of MCMC inference but he did not pursue the connection formally. Our proposal is most closely related to the work of Sundareswara and Schrater [20, 22], who suggested that mode-switching in Necker cube-type images reflects a rational sampling-based algorithm for approximate Bayesian inference and decision making. They presented an elegant sampling scheme that could account for Necker cube bistability, with several key assumptions: (1) that the visual system draws a sequence of samples from the posterior over scene interpretations; (2) that the posterior probability of each sample is known; (3) that samples are weighted based on the product of their posterior probabilities and a memory decay process favoring more recently drawn samples; and (4) that perceptual decisions are made deterministically based on the sample with highest weight.
 Our goal here is a simpler analysis that comes closer to the standard MCMC approaches used for approximate inference in Bayesian AI and machine vision, and establishing a clearer link between the mechanisms of perception in the brain and rational approximate inference algorithms on the engineering side. As in most applications of Bayesian inference in machine vision [8, 16], we do not assume that the visual system has access to the full posterior distribution over scene interpretations, which is expected to be extremely high-dimensional and complex. The visual system might be able to evaluate only relative probabilities of two similar hypotheses (as in Metropolis-Hastings), or to compute local conditional posteriors of one scene variable conditioned on its neighbors (as in Gibbs sampling). We also do not make extra assumptions about weighting samples based on memory decay, or require that conscious perceptual decisions be based on a memory for samples; consciousness has access to only the current state of the Markov chain, reflecting the observer X  X  current brain state.
 Here we show that several characteristic phenomena of multistability derive naturally from applying standard MCMC inference to Markov random fields (MRFs)  X  high dimensional, loosely coupled graphical models with spatial structure characteristic of many low-level and mid-level vision prob-lems. Specifically, we capture the classic findings of Gamma-distributed mode-switching times in bistable perception; the biasing effects of contextual stimuli; the situations in which fused (rather than bistable) percepts occur, and the propagation of perceptual switches in traveling waves across the visual field. Although it is unlikely that this MCMC scheme corresponds exactly to any process in the visual system, and it is almost surely too simplified or limited as a general account of percep-tual multistability, our results suggest that MCMC could provide a promising foundation on which to build rational process-level accounts of human perception and perhaps cognition more generally. Our starting point is a simple and schematic model of vision problems embodying the idea that images are generated by a set of hidden variables with local dependencies. Specifically, we assume that each observed image element x i is connected to a hidden variable z i by a directed edge, and each hidden variable is connected to its neighbors (in set c i ) by an undirected edge (thus implying that each hidden variable is conditionally independent of all others given its neighbors). This Markov property is often exploited in computer vision [8] because elements of an image tend to depend on their adjacent neighbors, but are less influenced by more distant elements. Formally, this assumption corresponds to a Markov random field (MRF). Different topologies of the MRF (e.g., lattice or ring) can be used to capture the structure of different visual objects (Figure 1C,D). The joint distribution over configurations of hidden and observed variables is given by: where Z is a normalizing constant, and R and V are potential functions . In a Gaussian MRF, the conditional potential function over hidden node i is given by where  X  is a precision (inverse variance) parameter specifying the coupling between neighboring hidden nodes; when  X  is large, a node will be strongly influenced by its neighbors. The  X  i term represents the prior mean of z i , which can be used to encode contextual biases, as we discuss below. We construct the likelihood potential R ( x i | z i ) to express the ambiguity of the image by making it multimodal: several different hidden causes are equally likely to have generated the image. Since for our purposes only the likelihood of x i matters, we can arbitrarily set x i = 0 and formalize the multimodal likelihood as a mixture of Gaussians evaluated at points a and b : The computational problem for vision (as we are framing it) is to infer the hidden causes of an observed image. Given an observed image x , the posterior distribution over hidden causes z is There are a number of reasons why Equation 4 may be computationally intractable. One is that the integration in the denominator may be high dimensional and lacking an analytical solution. Another is that there may not exist a simple functional form for the posterior. Assuming it is intractable to perform exact inference, we now turn to approximate solutions based on sampling. The basic idea behind Monte Carlo methods is to approximate a distribution with a set of samples drawn from that distribution. In order to use Monte Carlo approximations, one must be able to draw samples from the posterior, but it is often impossible to do so directly. MCMC methods address this problem by drawing samples from a Markov chain that converges to the posterior distribution [16]. There are many variations of MCMC methods but here we will focus on the simplest: the Metropolis algorithm [18]. Each step of the algorithm consists of two stages: a proposal stage and an acceptance stage. An accepted proposal is a sample from a Markov chain that provably converges to the posterior. We will refer to z ( l ) as the  X  X tate X  at step l . In the proposal stage, a new state z 0 is proposed by generating a random sample from a proposal density Q z 0 ; z ( l ) that depends on the current state. In the acceptance stage, this proposal is accepted with probability where we have assumed for simplicity that the proposal is symmetric: Q ( z 0 ; z ) = Q ( z ; z 0 ) . If the proposal is rejected, the current state is repeated in the chain. We now show how the Metropolis algorithm applied to the MRF image model gives rise to a number of phenomena in binocular rivalry experiments. Unless mentioned otherwise, we use the following parameters in our simulations:  X  = 0 , X  = 0 . 25 , X  = 0 . 1 ,a = 1 ,b =  X  1 . For the ring topology, we used  X  = 0 . 2 to compensate for the fewer neighbors around each node as compared to the lattice topology. The sampler was run for 200 , 000 iterations. For some simulations, we systematically ma-nipulated certain parameters to demonstrate their role in the model. We have found that the precise values of these parameters have relatively little effect on the model X  X  behavior. For all simulations we used a Gaussian proposal (with standard deviation 1.5) that alters the state of one hidden node (selected at random) on each iteration. 4.1 Distribution of dominance durations One of the most robust findings in the literature on perceptual multistability is that switching times in binocular rivalry between different stable percepts tend to follow a Gamma-like distribution. In other words, the  X  X ominance X  durations of stability in one mode tend to be neither overwhelmingly short nor long. This effect is so characteristic of binocular rivalry that there have been countless psychophysical experiments measuring the differences in Gamma switching time parameters across manipulations, and testing whether Gamma, or log-normal distributions are best [2]. To account for this characteristic behavior, many papers have described neural circuits that could produce switching oscillations with the right stochastic dynamics (e.g., [25]). Existing rational process models of multistability [7, 20, 22] likewise appeal to specific implementational-level constraints to produce this effect. In contrast, here we show how Gamma-distributed dominance durations fall naturally out of MCMC operating on an MRF.
 We constructed a 4  X  4 grid to model a typical binocular rivalry grating. In the typical experiment reporting a Gamma distribution of dominance durations, subjects are asked to say which of two images corresponds to their  X  X lobal X  percept. To make the same query of the current state of our simulated MCMC chain, we defined a perceptual switch to occur when at least 2 / 3 of the hidden nodes turn positive or negative. Figure 2A shows a sample of the timecourse 1 and the distribution of dominance durations and maximum-likelihood estimates for the Gamma parameters  X  (shape) and  X  (scale), demonstrating that the durations produced by MCMC are well-described by a Gamma distribution (Figure 2B).
 It is interesting to note that the MRF structure of the problem (representing the multivariate structure of low-level vision) is an important pre-condition to obtaining a Gamma-like distribution of domi-nance durations: When considering MCMC on only a single node, the measured dominance dura-tions tend to be exponentially-distributed. The Gamma distribution may arise in MCMC on an MRF because each hidden node takes an exponentially-distributed amount of time to switch (and these switches follow roughly one after another). In these settings, the total amount of time until enough nodes switch to one mode will be Gamma-distributed (i.e., the sum of exponentially-distributed ran-dom variables is Gamma-distributed). [20, 22] also used this idea to explain mode-switching. In their model, each sample is paired with a weight initialized to the sample X  X  posterior probability, and the sample with the largest weight designated as the dominant percept. Since multiple samples may correspond to the same percept, a particular percept will lose dominance only when the weights on all such samples decrease below the weights on samples of the non-dominant percept. By assuming an exponential decay on the weights, the time it takes for a single sample to lose dominance will be approximately exponentially distributed, leading to a Gamma distribution on the time it takes for multiple samples of the same percept to lose dominance. Here we have attempted to capture this effect within a rational inference procedure by attributing the exponential dynamics to the opera-tion of MCMC on individual nodes in the MRF, rather than a memory decay process on individual samples. 4.2 Contextual biases Much discussion in research on multistability revolves around the extent to which it is influenced by top-down processes like prior knowledge and attention [2]. In support of the existence of top-down influences, several studies have shown that contextual cues can bias the relative dominance of rival stimuli. For example, [5] superimposed rivalrous tilted grating patches on a background of either rightward or leftward tilting gratings (Figure 3A) and showed that the direction of background tilt shifted dominance towards the monocular stimulus with context-compatible tilt. Following [20, 22], we modeled this result by assuming that the effect of context is to shift the prior mean towards the contextually-biased interpretation. We simulated this contextual bias by setting the prior mean  X  = 1 . Figure 3B shows the timecourse of transient preference (probability of a particular interpretation at each timepoint) for the  X  X ontext X  and  X  X o-context X  simulations, illustrating this persistent bias. Another property of this timeseries is the initial bias exhibited by both the context and no-context conditions, a phenomenon observed experimentally [17, 22] (Figure 3C). In fact, this is a distinctive property of Markov chains (as pointed out by [22]): MCMC algorithms generally take multiple iterations before they converge to the stationary distribution [16]. This initial period is known as the  X  X urn-in. X  Thus, human perceptual inference may similarly require an initial burn-in period to reach the stationary distribution. 4.3 Deviations from stable rivalry: fusion Most models have focused on the  X  X table X  portions of the bistable dynamics of rivalry; however, in addition to the mode-hopping behavior that characterizes this phenomenon, bistable percepts often produce other states. In some conditions the two percepts are known to fuse, rather than rival: the percept then becomes a composite or superposition of the two stimuli (and hence no alternation is perceived). This fused perceptual state can be induced most reliably by decreasing the distance in feature space between the two stimuli [11] (Figure 4B) or decreasing the contrast of both stimuli [15]. These relations are shown schematically in Figure 4A. Neither neural, nor algorithmic, nor computational models of rivalry have thus far attempted to explain these findings.
 In experiments on  X  X usion X , subjects are given three options to report their percept: one of two global precepts or something in between. We define such a fused percept as a perceptual state lying between the two  X  X istable X  modes  X  that is, an interpretation between the two rivalrous, high-probability interpretations. We can interpret manipulation of feature space distance in terms of the distance between the modes, and reductions of contrast as increases in the variance around the modes. When such manipulations are introduced to the MRF model, the posterior distribution changes as in Figure 4A (inset). By making the modes closer together or increasing the variance around the modes, greater probability mass is assigned to an intermediate zone between the modes X  X  fused percept. Thus, manipulating stimulus separation (feature distance) or stimulus fidelity (contrast) changes the parameterizations of the likelihood function, and these manipulations produce systematically increasing odds of fused percepts, matching the phenomenology of these stimuli (Figure 4B). 4.4 Traveling waves Fused percepts are not the only deviations from bistability. In other circumstances, particularly in binocular rivalry, stability is often incomplete across the visual field, producing  X  X iecemeal X  portion looks like the image in the other eye. One tantalizing feature of these piecemeal percepts is the phenomenon known as traveling waves: subjects tend to perceive a perceptual switch as a  X  X ave X  propagating over the visual field [26, 12]: the suppressed stimulus becomes dominant in an isolated location of the visual field and then gradually spreads. These traveling waves reveal an interesting local dynamics during an individual switch itself, rather than just the Gamma-distributed dynamics of the time between complete switches of dominance. Like fused percepts, these intra-switch dynamics have been generally ignored by models of multistability.
 Demonstrating the dynamics of traveling waves within patches of the percept requires a different method of probing perception. Wilson et al. [26] used annular stimuli (Figure 5A), and probed a particular patch along the annulus; they showed that the time at which the suppressed stimulus in the test patch becomes dominant is a function of the distance (around the circumference of the annulus) between the test patch and the patch where a dominance switch was induced by transiently increasing the contrast of the suppressed stimulus. This dependence of switch-time on distance (Figure 5B) suggested to Wilson et al. that stimulus dominance was propagating around the annulus. Using fMRI, Lee et al. [12] showed that the propagation of this  X  X raveling wave X  can be measured in primary visual cortex (V1; Figure 5): they used the retinotopic structure of V1 to identify brain regions corresponding to different portions of the the visual field, then measured the timing of the response in these regions to the induced dominance switch as a function of the cortical distance from the location of the initial switch. They found that the temporal delay in the response increased as a function of cortical distance from the V1 representation of the top of the annulus (Figure 5C). To simulate such traveling waves within the percept of a stimulus, we constructed an MRF with ring topology and measured the propagation time (the time at which a mode-switch occurs) at different hidden nodes along the ring. To simulate the transient increase in contrast at one location to induce a switch, we initialized one node X  X  state to be +1 and the rest to be  X  1 . Consistent with the idea of wave propagation, Figure 5D shows the average time for a simulated node to switch modes as a function of distance around the ring. Intuitively, nodes will tend to switch in a kind of  X  X omino effect X  around the ring; the local dependencies in the MRF ensure that nodes will be more likely to switch modes once their neighbors have switched. Thus, once a switch at one node has been accepted by the Metropolis algorithm, a switch at its neighbor is likely to follow. We have proposed a  X  X ational process X  model of perceptual multistability based on the idea that humans approximate the posterior distribution over the hidden causes of their visual input with a set of samples. In particular, the dynamics of the sample-generating process gives rise to much of the rich dynamics in multistable perception observed experimentally. These dynamics may be an approximation to the MCMC algorithms standardly used to solve difficult inference problems in machine learning and statistics [16].
 The idea that perceptual multistability can be construed in terms of sampling in a Bayesian model was first proposed by [20, 22], and our work follows theirs closely in several respects. However, we depart from that work in the theoretical underpinnings of our model: It is not transparent how well the sampling scheme in [22, 24] approximates Bayesian inferences, or how it corresponds to stan-dard algorithms where the full posterior is not assumed to be available when drawing samples. Our goal here is to show how some of the basic phenomena of multistable perception can be understood straightforwardly as the output of familiar, simple and effective methods for approximate inference in Bayesian machine vision.
 A related point of divergence between our model and that of [20, 22], as well as other Bayesian mod-els of multistable perception [7, 10], is that we are able to explain multistable perception in terms of a well-defined inference procedure that doesn X  X  require ad-hoc appeals to neurophysiological pro-cesses like noise, adaptation, inhibition, etc. Thus, our contribution is to show how an inference algorithm widely used in statistics and computer science can give rise naturally to perceptual mul-tistability phenomena. Of course, we do not wish to argue that neurophysiological processes are irrelevant. Our goal here was to abstract away from implementational details and make claims about the algorithmic level. Clearly an important avenue for future work is relating algorithms like MCMC to neural processes (indeed this connection was suggested previously by [7]).
 Another important direction in which to extend this work is from rivalry with low-level stimuli to more complex vision problems that involve global coherence over the image (such as in natural scenes). Although similar perceptual dynamics have been observed with a wide range of ambiguous stimuli, the absence of obvious transition periods with the Necker cube suggests that these dynamics may differ in important ways from perception of rivalry stimuli.
 Acknowledgments: This work was supported by ONR MURI: Complex Learning and Skill Trans-fer with Video Games N00014-07-1-0937 (PI: Daphne Bavelier); NDSEG fellowship to EV and NSF DRMS Dissertation grant to EV.
