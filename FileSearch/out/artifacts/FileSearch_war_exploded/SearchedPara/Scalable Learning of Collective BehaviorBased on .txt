 The study of collective behavior is to understand how in-dividuals behave in a social network environment. Oceans of data generated by social media like Facebook, Twitter, Flickr and YouTube present opportunities and challenges to studying collective behavior in a large scale. In this work, we aim to learn to predict collective behavior in social me-dia. In particular, given information about some individu-als, how can we infer the behavior of unobserved individ-uals in the same network? A social-dimension based ap-proach is adopted to address the heterogeneity of connec-tions presented in social media. However, the networks in social media are normally of colossal size, involving hun-dreds of thousands or even millions of actors. The scale of networks entails scalable learning of models for collective behavior prediction. To address the scalability issue, we propose an edge-centric clustering scheme to extract sparse social dimensions. With sparse social dimensions, the social-dimension based approach can efficiently handle networks of millions of actors while demonstrating comparable predic-tion performance as other non-scalable methods.
 H.2.8 [ Database Management ]: Database applications X  Data Mining ; J.4 [ Social and Behavioral Sciences ]: So-ciology Algorithm, Experimentation Social Dimensions, Behavior Prediction, Social Media, Re-lational Learning, Edge-Centric Clustering Social media such as Facebook, MySpace, Twitter, Blog-Catalog, Digg, YouTube and Flickr, facilitate people of all walks of life to express their thoughts, voice their opinions, and connect to each other anytime and anywhere. For in-stance, popular content-sharing sites like Del.icio.us, Flickr, and YouTube allow users to upload, tag and comment dif-ferent types of contents (bookmarks, photos, videos). Users registered at these sites can also become friends, a fan or follower of others. The prolific and expanded use of social media has turn online interactions into a vital part of human experience. The election of Barack Obama as the President of United States was partially attributed to his smart Inter-net strategy and access to millions of younger voters through the new social media, such as Facebook. As reported in the New York Times, in response to recent Israeli air strikes in Gaza, young Egyptians mobilized not only in the streets of Cairo, but also through the pages of Facebook.

Owning to social media, rich human interaction informa-tion is available. It enables the study of collective behavior in a much larger scale, involving hundreds of thousands or millions of actors. It is gaining increasing attentions across various disciplines including sociology, behavioral science, anthropology, epidemics, economics and marketing business, to name a few. In this work, we study how networks in social media can help predict some sorts of human behavior and individual preference. In particular, given the observation of some individuals X  behavior or preference in a network, how to infer the behavior or preference of other individuals in the same social network? This can help understand the behav-ior patterns presented in social media, as well as other tasks like social networking advertising and recommendation.
Typically in social media, the connections of the same network are not homogeneous. Different relations are inter-twined with different connections. For example, one user can connect to his friends, family, college classmates or col-leagues. However, this relation type information is not read-ily available in reality. This heterogeneity of connections limits the effectiveness of a commonly used technique  X  collective inference for network classification. Recently, a framework based on social dimensions [18] is proposed to ad-dress this heterogeneity. This framework suggests extracting social dimensions based on network connectivity to capture the potential affiliations of actors. Based on the extracted dimensions, traditional data mining can be accomplished. In the initial study, modularity maximization [15] is exploited to extract social dimensions. The superiority of this frame-work over other representative relational learning methods is empirically verified on some social media data [18].
However, the instantiation of the framework with mod-ularity maximization for social dimension extraction is not scalable enough to handle networks of colossal size, as it in-volves a large-scale eigenvector problem to solve and the cor-responding extracted social dimensions are dense. In social media, millions of actors in a network are the norm. With this huge number of actors, the dimensions cannot even be held in memory, causing serious problem about the scala-bility. To alleviate the problem, social dimensions of sparse representation are preferred. In this work, we propose an ef-fective edge-centric approach to extract sparse social dimen-sions. We prove that the sparsity of the social dimensions following our proposed approach is guaranteed. Extensive experiments are conducted using social media data. The framework based on sparse social dimensions, without sac-rificing the prediction performance, is capable of handling real-world networks of millions of actors in an efficient way.
The recent boom of social media enables the study of col-lective behavior in a large scale. Here, behavior can include a broad range of actions: join a group, connect to a person, click on some ad, become interested in certain topics, date with people of certain type, etc. When people are exposed in a social network environment, their behaviors are not inde-pendent [6, 22]. That is, their behaviors can be influenced by the behaviors of their friends. This naturally leads to behavior correlation between connected users.

This behavior correlation can also be explained by ho-mophily . Homophily [12] is a term coined in 1950s to ex-plain our tendency to link up with one another in ways that confirm rather than test our core beliefs. Essentially, we are more likely to connect to others sharing certain similarity with us. This phenomenon has been observed not only in the real world, but also in online systems [4]. Homophily leads to behavior correlation between connected friends. In other words, friends in a social network tend to behave sim-ilarly. Take marketing as an example, if our friends buy something, there X  X  better-than-average chance we X  X l buy it too.

In this work, we attempt to utilize the behavior correla-tion presented in a social network to predict the collective behavior in social media. Given a network with behavior information of some actors, how can we infer the behavior outcome of the remaining ones within the same network? Here, we assume the studied behavior of one actor can be described with K class labels { c 1 ,  X  X  X  , c K } . For each label, c can be 0 or 1. For instance, one user might join multi-ple groups of interests, so 1 denotes the user subscribes to one group and 0 otherwise. Likewise, a user can be inter-ested in several topics simultaneously or click on multiple types of ads. One special case is K = 1. That is, the stud-ied behavior can be described by a single label with 1 and 0 denoting corresponding meanings in its specific context, like whether or not one user voted for Barack Obama in the presidential election.

The problem we study can be described formally as fol-lows:
Actors Affiliation-1 Affiliation-2  X  X  X  Affiliation-k
Note that this problem shares the same spirit as within-network classification [11]. It can also be considered as a special case of semi-supervised learning [23] or relational learning [5] when objects are connected within a network. Some of the methods there, if applied directly to social me-dia, yield limited success [18], because connections in social media are pretty noise and heterogeneous.

In the next section, we will discuss the connection hetero-geneity in social media, briefly review the concept of social dimension, and anatomize the scalability limitations of the earlier model proposed in [18], which motivates us to develop this work.
Connections in social media are not homogeneous. People can connect to their family, colleagues, college classmates, or some buddies met online. Some of these relations are helpful to determine the targeted behavior (labels) but not necessarily always so true. For instance, Figure 1 shows the contacts of the first author on Facebook. The densely-knit group on the right side are mostly his college classmates, while the upper left corner shows his connections at his grad-uate school. Meanwhile, at the bottom left are some of his high-school friends. While it seems reasonable to infer that his college classmates and friends in graduate school are very likely to be interested in IT gadgets based on the fact that the user is a fan of IT gadget (as most of them are majoring in computer science), it does not make sense to propagate this preference to his high-school friends. In a nutshell, peo-ple are involved in different affiliations and connections are emergent results of those affiliations. These affiliations have to be differentiated for behavior prediction.

However, the affiliation information is not readily avail-able in social media. Direct application of collective infer-ence[11] or label propagation [24] treats the connections in a social network homogeneously. This is especially prob-lematic when the connections in the network are noisy. To address the heterogeneity presented in connections, we have proposed a framework ( SocDim ) [18] for collective behavior learning.

The framework SocDim is composed of two steps: 1) so-cial dimension extraction, and 2) discriminative learning. In the first step, latent social dimensions are extracted based on network topology to capture the potential affiliations of ac-tors. These extracted social dimensions represent how each actor is involved in diverse affiliations. One example of the social dimension representation is shown in Table 1. The entries show the degree of one user involving in an affili-ation. These social dimensions can be treated as features of actors for the subsequent discriminative learning. Since the network is converted into features, typical classifier such as support vector machine and logistic regression can be employed. The discriminative learning procedure will de-termine which latent social dimension correlates with the targeted behavior and assign proper weights.
 Now let X  X  re-examine the contacts network in Figure 1. One key observation is that when actors are belonging to the same affiliations, they tend to connect to each other as well. It is reasonable to expect people of the same department to interact with each other more frequently. Hence, to infer the latent affiliations, we need to find out a group of people who interact with each other more frequently than random. This boils down to a classical community detection problem. Since each actor can involve in more than one affiliations, a soft clustering scheme is preferred.

In the instantiation of the framework SocDim , modularity maximization [15] is adopted to extract social dimensions. The social dimensions correspond to the top eigenvectors of a modularity matrix. It has been empirically shown that this framework outperforms other representative relational learning methods in social media. However, there are several concerns about the scalability of SocDim with modularity maximization: are numerous affiliations involved.
Consequently, it is imperative to develop scalable meth-ods that can handle large-scale networks efficiently without extensive memory requirement. In the next section, we elu-cidate an edge-centric clustering scheme to extract sparse social dimensions. With the scheme, we can update the social dimensions efficiently when new nodes or new edges arrive in a network.
In this section, we first show one toy example to illustrate the intuition of our proposed edge-centric clustering scheme EdgeCluster , and then present one feasible solution to handle large-scale networks.
As mentioned earlier, the social dimensions extracted based on modularity maximization are the top eigenvectors of a modularity matrix. Though the network is sparse, the so-cial dimensions become dense, begging for abundant mem-ory space. Let X  X  look at the toy network in Figure 2. The column of modularity maximization in Table 2 shows the top eigenvector of the modularity matrix. Clearly, none of the entries is zero. This becomes a serious problem when the network expands into millions of actors and a reasonable large number of social dimensions need to be extracted. The eigenvector computation is impractical in this case. Hence, it is essential to develop some approach such that the ex-tracted social dimensions are sparse.

The social dimensions according to modularity maximiza-tion or other soft clustering scheme tend to assign a non-zero score for each actor with respect to each affiliation. How-ever, it seems reasonable that the number of affiliations one user can participate in is upperbounded by the number of connections. Consider one extreme case that an actor has only one connection. It is expected that he is probably active in only one affiliation. It is not necessary to assign a non-zero score for each affiliation. Assuming each connection represents one dominant affiliation, we expect the number of affiliations of one actor is no more than his connections.
Instead of directly clustering the nodes of a network into some communities, we can take an edge-centric view, i.e., partitioning the edges into disjoint sets such that each set represents one latent affiliation. For instance, we can treat each edge in the toy network in Figure 2 as one instance, and the nodes that define edges as features. This results in a typical feature-based data format as in Figure 3. Based on the features (connected nodes) of each edge, we can cluster the edges into two sets as in Figure 4, where the dashed edges represent one affiliation, and the remaining edges denote another affiliation. One actor is considered associated with one affiliation as long as any of his connections is assigned to that affiliation. Hence, the disjoint edge clusters in Figure 4 can be converted into the social dimensions as the last two columns for edge-centric clustering in Table 2. Actor 1 is involved in both affiliations under this EdgeCluster scheme.
In summary, to extract social dimensions, we cluster edges rather than nodes in a network into disjoint sets. To achieve this, k-means clustering algorithm can be applied. The edges of those actors involving in multiple affiliations (e.g., actor 1 in the toy network) are likely to be separated into different
Features clusters. Even though the partition of edge-centric view is disjoint, the affiliations in the node-centric view can overlap. Each actor can be involved in multiple affiliations.
In addition, the social dimensions based on edge-centric clustering are guaranteed to be sparse . This is because the affiliations of one actor are no more than the connections he has. Suppose we have a network with m edges, n nodes and k social dimensions are extracted. Then each node v i has no more than min( d i , k ) non-zero entries in its social dimensions, where d i is the degree of node v i . We have the following theorem.

Theorem 1. Suppose k social dimensions are extracted from a network with m edges and n nodes. The density (proportion of nonzero entries) of the social dimensions ex-tracted based on edge-centric clustering is bounded by the following formula: Moreover, for networks in social media where the node degree follows a power law distribution, the upper bound in Eq. (1) can be approximated as follows: where  X  &gt; 2 is the exponent of the power law distribution. Please refer to the appendix for the detailed proof. To give more than 1 million actors and verify the upperbound of the density. The YouTube network has 1 , 128 , 499 nodes and 2 , 990 , 443 edges. Suppose we want to extract 1 , 000 dimen-sions from the network. Since 232 nodes have degree larger than 1000, the density is upperbounded by (5 , 472 , 909 + 232  X  1 , 000) / (1 , 128 , 499  X  1 , 000) = 0 . 51% following Eq.(1). The node distribution in the network follows a power law with the exponent  X  = 2 . 14 based on maximum likelihood estimation [14]. Thus, the approximate upperbound in Eq.(2) for this specific case is 0 . 54%.

Note that the upperbound in Eq. (1) is network specific whereas Eq.(2) gives an approximate upperbound for a fam-ily of networks. It is observed that most power law distri-butions occurring in nature have 2  X   X   X  3 [14]. Hence, the bound in Eq. (2) is valid most of the time. Figure 5 shows the function in terms of  X  and k . Note that when k is huge (close to 10,000), the social dimensions becomes extremely sparse ( &lt; 10  X  3 ). In reality, the extracted social dimensions is typically even more sparse than this upperbound as shown in later experiments. Therefore, with edge-centric cluster-ing, the extracted social dimensions are sparse, alleviating the memory demand and facilitating efficient discriminative learning in the second stage.
As mentioned above, edge-centric clustering essentially treats each edge as one data instance with its ending nodes being features. Then a typical k-means clustering algorithm can be applied to find out disjoint partitions.

One concern with this scheme is that the total number of edges might be too huge. Owning to the power law distribu-tion of node degrees presented in social networks, the total number of edges is normally linear, rather than square, with respect to the number of nodes in the network. That is, m = O ( n ). This can be verified via the properties of power law distribution. Suppose a network with n nodes follows a power law distribution as where  X  is the exponent and C is a normalization constant.
Input: data instances { x i | 1  X  i  X  m }
Output: { idx i } 10. M axSim i = sim ( i, C j ) 11. idx i = j ; 12. for i=1:m 13. update centroid C idx i 14. until no change in idx or change of objective &lt;  X  Then the expected number of degree for each node is [14]: where x min is the minimum nodal degree in a network. In reality, we normally deal with nodes with at least one con-nection, so x min  X  1. The  X  of a real-world network fol-lowing power law is normally between 2 and 3 as mentioned in [14]. Consider a network in which all the nodes have non-zero degrees, the expected number of edges is Unless  X  is very close to 2, in which case the expectation diverges, the expected number of edges in a network is linear to the total number of nodes in the network.

Still, millions of edges are the norm in a large-scale social network. Direct application of some existing k-means im-plementation cannot handle the problem. E.g., the k-means code provided in Matlab package requires the computation of the similarity matrix between all pairs of data instances, which would exhaust the memory of normal PCs in sec-onds. Therefore, implementation with an online fashion is preferred.

On the other hand, the edge data is quite sparse and struc-tured. As each edge connects two nodes in the network, the corresponding data instance has exactly only two non-zero features as shown in Figure 3. This sparsity can help acceler-ate the clustering process if exploited wisely. We conjecture that the centroids of k-means should also be feature-sparse. Often, only a small portion of the data instances share fea-tures with the centroid. Thus, we only need to compute the similarity of the centroids with their relevant instances. In order to efficiently identify the instances relevant to one centroid, we build a mapping from the features (nodes) to instances (edges) beforehand. Once we have the mapping, we can easily identify the relevant instances by checking the non-zero features of the centroid.

By taking care of the two concerns above, we thus have a k-means variant as in Figure 6 to handle clustering of many edges. We only keep a vector of M axSim to represent the maximum similarity between one data instance with a cen-troid. In each iteration, we first identify the set of relevant Input: network data, labels of some nodes
Output: labels of unlabeled nodes 1. convert network into edge-centric view as in Figure 3 2. perform clustering on edges via algorithm in Figure 6 3. construct social dimensions based on edge clustering 4. build classifier based on labeled nodes X  social dimensions 5. use the classifier to predict the labels of unlabeled ones instances to a centroid, and then compute the similarities of these instances with the centroid. This avoids the itera-tion over each instance and each centroid, which would cost O ( mk ) otherwise. Note that the centroid contains one fea-ture (node) if and only if any edge of that node is assigned to the cluster. In effect, most data instances (edge) are as-sociated with few (much less than k ) centroids. By taking advantage of the feature-instance mapping, the cluster as-signment for all instances (lines 5-11 in Figure 6) can be fulfilled in O ( m ) time. To compute the new centroid (lines 12-13), it costs O ( m ) time as well. Hence, each iteration costs O ( m ) time only. Moreover, the algorithm only requires the feature-instance mapping and network data to reside in main memory, which costs O ( m + n ) space. Thus, as long as the network data can be held in memory, this clustering algorithm is able to partition the edges into disjoint sets. Later as we show, even for a network with millions of ac-tors, this clustering can be finished in tens of minutes while modularity maximization becomes impractical.

As a simple k-means is adopted to extract social dimen-sions, it is easy to update the social dimensions if the net-work changes. If a new member joins a network and a new connection emerges, we can simply assign the new edge to the corresponding clusters. The update of centroids with new arrival of connections is also straightforward. This k-means scheme is especially applicable for dynamic large-scale networks.

In summary, to learn a model for collective behavior, we take the edge-centric view of the network data and partition the edges into disjoint sets. Based on the edge clustering, social dimensions can be constructed. Then, discriminative learning and prediction can be accomplished by considering these social dimensions as features. The detailed algorithm is summarized in Figure 7.
In this section, we present the data collected from social media for evaluation, and the baseline methods for compar-ison.
Two benchmark data sets in [18] are used to examine our proposed model for collective behavior learning. The first cerning the behavior, following [18], we study whether a user joins a group of interest. Since the BlogCatalog data does not have this group information, we use the blogger X  X  topic http://www.blogcatalog.com/ http://www.flickr.com/ interests as the behavior labels. Both data sets are publicly
To examine the scalability, we also include a mega-scale without connections and select the groups with at least 500 members. Some of the detailed statistics of the data set can be found in Table 3.
The edge-centric clustering (or EdgeCluster ) is used to extract social dimensions on all the data sets. We adopt cosine similarity while performing the clustering. Based on cross validation, the dimensionality is set to 5000, 10000, and 1000 for BlogCatalog, Flickr, and YouTube, respectively. A linear SVM classifier is exploited for discriminative learning.
In particular, we compare our proposed sparse social di-mensions with the social dimensions extracted according to modularity maximization (denoted as M odM ax ) [18]. We study how the sparsity in social dimensions affects the pre-diction performance as well as the scalability. For complete-ness, we also include the performance of some representa-tive methods: wvRN , N odeCluster and MAJORITY . We briefly discuss these methods next.

Weighted-Vote Relational Neighbor Classifier (wvRN) [10] has been shown to work reasonably well for classification with network data and is recommended as a baseline method for comparison [11]. It works like a lazy learner. No model is constructed for training. In prediction, the relational classi-fier estimates the class membership as the weighted mean of its neighbors. This classifier is closely related to the Gaus-sian field [24] in semi-supervised learning [11].
Note that social dimensions allow one actor to be involved in multiple affiliations. As a proof of concept, we also ex-amine the case when each actor is associated with only one affiliation. A similar idea has been adopted in latent group model [13] for efficient inference. To be fair, we adopt k-means clustering to partition the network into disjoint sets, and convert the node clustering result as social dimensions. Then, SVM is utilized for discriminative learning. For con-venience, we denote this method as N odeCluster . It is es-sentially the same as the LGC variant presented in [18].
MAJORITY uses the label information only. It does not leverage any network information for learning or inference. It simply predicts the class membership as the proportion of positive instances in the labeled data. All nodes are assigned with the same class membership. This classifier is inclined to predict categorizes of larger size.
 Note that our prediction problem is essentially multi-label. It is empirically shown that thresholding can affect the fi-http://www.public.asu.edu/~ltang9/ http://socialnetworks.mpi-sws.org/data-imc2007. html http://www.youtube.com/ nal prediction performance drastically [3, 20]. For evalu-ation purpose, we assume the number of labels of unob-served nodes is already known and check the match of the top-ranking labels with the truth. Such a scheme has been adopted for other multi-label evaluation works [9]. We ran-domly sample a portion of nodes as labeled and report the average performance of 10 runs in terms of Micro-F1 and Macro-F1. We use the same setting as in [18] for the baseline methods for Flickr and BlogCatalog, thus the performance on the two data sets are reported here directly.
In this section, we first examine how the performance varies with social dimensions extracted based on edge-centric clustering. Then we verify the sparsity of social dimensions and its implication for scalability. We also study how the performance varies with social dimensionality.
The prediction performance on all the data sets are shown in Tables 4-6. The entries in bold face denote the best one in each column. M odM ax on YouTube is not applicable due to the scalability constraint. Evidently, the models fol-lowing the social-dimension framework ( EdgeCluster and M odM ax ) outperform other methods. The baseline method MAJORITY achieves only 2% for Macro-F1 while other methods reach 20% on BlogCatalog. The social network do provide valuable behavior information for inference. The collective inference scheme wvRN does not differentiate the connections, thus shows poor performance when the network is noisy. This is most noticeable for Macro-F1 on Flickr data. The N odeCluster scheme forces each actor to be involved in only one affiliation, yielding inferior performance compared with EdgeCluster .

Moreover, edge-centric clustering shows comparable per-formance as modularity maximization on BlogCatalog net-work. A close examination reveals that these two approaches are very close in terms of prediction performance. On Flickr data, our EdgeCluster outperforms M odM ax consistently. Among all the compared methods, EdgeCluster is always the winner This indicates that the extracted sparse social dimensions do help in collective behavior prediction.
It is noticed the prediction performance on all the studied social media data is around 20-30% for F1 measure. This is partly due to the large number of labels in the data. Another reason is that we only employ the network information here. Since the SocDim framework converts network into features, other behavior features (if available) can be combined with the social dimensions for behavior learning.
As we have introduced in Theorem 1, the social dimen-sions constructed according to edge-centric clustering are guaranteed to be sparse as the density is upperbounded by a small value. Here, we examine how sparse the social di-mensions are in practice. We also study how the computa-tional time (with a Core2Duo E8400 CPU and 4GB mem-ory) varies with the number of edge clusters. The computa-tional time, the memory footprint of social dimensions, their density and other related statistics on all the three data sets are reported in Tables 7-9.

Concerning the time complexity, it is interesting that com-puting the top eigenvectors of a modularity matrix actually is quite efficient as long as there is no memory concern. This is observable on the Flickr data. However, when the network scales to millions of nodes (YouTube Data), modularity max-imization becomes impossible due to its excessive memory requirement, while our proposed EdgeCluster method can still be computed efficiently as shown in Table 9. The com-putation time of EdgeCluster on YouTube network is much smaller than Flickr, because the density of YouTube network is extremely sparse and the total number of edges and the average degree in YouTube are actually smaller than those of Flickr as shown in Table 3.
 Another observation is that the computation time of Edge-Cluster does not change much with varying numbers of clus-ters. No matter what the cluster number is, the computation time of EdgeCluster is of the same order. This is due to the efficacy of the proposed k-means variant in Figure 6. In the algorithm, we do not iterate over each cluster and each cen-troid to do the cluster assignment, but exploit the sparsity of edge-centric data to compute only the similarity of a cen-troid and those relevant instances. This, in effect, makes the computational time independent of the number of edge clusters.

As for the memory footprint reduction, sparse social di-mension did an excellent job. On Flickr, with only 500 di-mensions, the social dimensions of M odM ax require 322.1M, whereas EdgeCluster requires only less than 100M. This ef-fect is stronger on the mega-scale YouTube network where ModMax becomes impractical to compute directly. It is ex-pected that the social dimensions of M odM ax would occupy 4.6G memory. On the contrary, the sparse social dimensions based on EdgeCluster only requires 30-50M.

The steep reduction of memory footprint can be explained by the density of the extracted dimensions. For instance, in Table 9, when we have 50000 dimensions, the density is only 5 . 2  X  10  X  5 . Consequently, even if the network has more than 1 million nodes, the extracted social dimensions still occupy tiny memory space. The upperbound of the density is not tight when the number of clusters k is small. As k increases, the bound is getting close to the truth. In general, the true density is roughly half of the estimated bound. 2 . 2  X  10  X  1 8599 1221.3 187 23.5 1 . 1  X  10  X  1 5662 618.8 344 30.0 6 . 0  X  10  X  2 3990 328.6 408 31.8 3 . 1  X  10  X  2 3979 166.9 598 32.4 1 . 3  X  10  X  2 3934 67.7 682 32.4 7  X  10  X  3 3852 34.4 882 33.3 3 . 9  X  10  X  1 42453 9683.4 156 24.1 2 . 2  X  10  X  1 31462 5604.0 352 34.8 1 . 3  X  10  X  1 26504 3583.2 619 44.5 7 . 2  X  10  X  2 25835 1289.5 986 54.4 2 . 9  X  10  X  2 28281 1058.2 1405 65.7 1 . 5  X  10  X  2 12160 570.8 1673 70.9 2 . 3  X  10  X  2 266491 11315 121 1.9877 9 . 7  X  10  X  3 211323 4992 255 2.1927 5 . 0  X  10  X  3 147182 2664 325 2.3225 2 . 6  X  10  X  3 81692 1381 375 2.4268 1 . 0  X  10  X  3 35604 570 253 2.5028 5 . 1  X  10  X  4 35445 289 356 2.5431 2 . 6  X  10  X  4 29601 147 305 2.5757 1 . 1  X  10  X  4 28534 59 297 2.6239
In Tables 7 -9, we also include the statistics of the affilia-tions represented by the sparse social dimensions. The size of affiliations is decreasing with increasing number of social dimensions. And actors can be associated with more than one affiliations. It is observed the number of affiliations each actor can be involved in also follows a power law pattern as node degrees. Figure 8 shows the distribution of node de-grees in Flickr and Figure 9 shows the node affiliations when k = 10000.
Our proposed EdgeCluster model requires users to spec-ify the number of social dimensions (edge clusters) k . One question remains to be answered is how sensitive the per-formance is with respect to the parameter k . We examine all the three data sets, but find no strong pattern to de-termine the optimal dimensionality. Due to space limit, we only include one case here. Figure 10 shows the Macro-F1 performance change on YouTube data. The performance, unfortunately, is sensitive to the number of edge clusters. It thus remains a challenge to determine the parameter auto-matically.

A general trend across all the three data sets is that, the optimal dimensionality increases as the proportion of labeled nodes expands. For instance, when there is 1% of labeled nodes in the network, 500 dimensions seem optimal. But when the labeled nodes increases to 10%, 2000-5000 dimen-sions become a better choice. In other words, when label information is scarce, coarse extraction of latent affiliations is better for behavior prediction; But when the label infor-mation multiplies, the affiliations should be zoomed into a more granular level.
Within-network classification [11] refers to the classifica-tion when data instances are presented in a network format. The data instances in the network are not independently identically distributed (i.i.d.) as in conventional data min-ing. To capture the correlation between labels of neighboring data objects, typically a Markov dependency assumption is assumed. That is, the labels of one node depend on the la-bels (or attributes) of its neighbors. Normally, a relational classifier is constructed based on the relational features of labeled data, and then an iterative process is required to
Figure 8: Node Degree Distribution determine the class labels for the unlabeled data. The class label or the class membership is updated for each node while the labels of its neighbors are fixed. This process is repeated until the label inconsistency between neighboring nodes is minimized. It is shown that [11] a simple weighted vote re-lational neighborhood classifier [10] works reasonably well on some benchmark relational data and is recommended as a baseline for comparison. It turns out that this method is closely related to Gaussian field for semi-supervised learning on graphs [24].

Most relational classifiers, following the Markov assump-tion, capture the local dependency only. To handle the long-distance correlation, the latent group model [13], and the nonparametric infinite hidden relational model [21] assume Bayesian generative models such that the link (and actor attributes) are generated based on the actors X  latent cluster membership. These models essentially share the same fun-damental idea as social dimensions [18] to capture the la-tent affiliations of actors. But the model intricacy and high computational cost for inference with the aforementioned models hinder their application to large-scale networks. So Neville and Jensen [13] propose to use clustering algorithm to find the hard cluster membership of each actor first, and then fix the latent group variables for later inference. This scheme has been adopted as N odeCluster method in our experiment. As each actor is assigned to only one latent affiliation, it does not capture the multi-facet property of human nature.

In this work, k-means clustering algorithm is used to par-tition the edges of a network into disjoint sets. We also propose a k-means variant to take advantage of its special sparsity structure, which can handle the clustering of mil-lions of edges efficiently. More complicated data structures such as kd-tree [1, 8] can be exploited to accelerate the pro-cess. In certain cases, the network might be too huge to reside in memory. Then other k-means variants to handle extremely large data sets like On-line k-means [17], Scal-able k-means [2], Incremental k-means [16] and distributed k-means [7] can be considered.
In this work, we examine whether or not we can predict the online behavior of users in social media, given the be-havior information of some actors in the network. Since the connections in a social network represent various kinds of re-lations, a framework based on social dimensions is employed. In the framework, social dimensions are extracted to repre-sent the potential affiliations of actors before discriminative learning. But existing approach to extract social dimen-sions suffers from the scalability. To address the scalability issue, we propose an edge-centric clustering scheme to ex-tract social dimensions and a scalable k-means variant to handle edge clustering. Essentially, each edge is treated as one data instance, and the connected nodes are the corre-sponding features. Then, the proposed k-means clustering algorithm can be applied to partition the edges into dis-joint sets, with each set representing one possible affiliation. With this edge-centric view, the extracted social dimensions are warranted to be sparse. Our model based on the sparse social dimensions shows comparable prediction performance as earlier proposed approaches to extract social dimensions. An incomparable advantage of our model is that, it can eas-ily scale to networks with millions of actors while the ear-lier model fails. This scalable approach offers a viable so-lution to effective learning of online collective behavior in a large scale.

In reality, each edge can be associated with multiple affil-iations while our current model assumes only one dominant affiliation. Is it possible to extend our edge-centric parti-tion to handle this multi-label effect of connections? How does this affect the behavior prediction performance? In so-cial media, multiple modes of actors can be involved in the same network resulting in a multi-mode network [19]. For in-stance, in YouTube, users, videos, tags, comments are inter-twined with each other. Extending our edge-centric cluster-ing scheme to address this object heterogeneity as well can be a promising direction to explore. For another, the pro-posed EdgeCluster model is sensitive to the number of social dimensions as shown in the experiment. Further research is required to determine the dimensionality automatically. It is also worth pursuing to mine other informative behavior features from social media for more accurate prediction.
This research is, in part, sponsored by the Air Force Office of Scientific Research Grant FA95500810132. [1] J. Bentley. Multidimensional binary search trees used [2] P. Bradley, U. Fayyad, and C. Reina. Scaling [3] R.-E. Fan and C.-J. Lin. A study on threshold [4] A. T. Fiore and J. S. Donath. Homophily in online [5] L. Getoor and B. Taskar, editors. Introduction to [6] M. Hechter. Principles of Group Solidarity . University [7] R. Jin, A. Goswami, and G. Agrawal. Fast and exact [8] T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. [9] Y. Liu, R. Jin, and L. Yang. Semi-supervised [10] S. A. Macskassy and F. Provost. A simple relational [11] S. A. Macskassy and F. Provost. Classification in [12] M. McPherson, L. Smith-Lovin, and J. M. Cook. [13] J. Neville and D. Jensen. Leveraging relational [14] M. Newman. Power laws, Pareto distributions and [15] M. Newman. Finding community structure in [16] C. Ordonez. Clustering binary data streams with [17] M. Sato and S. Ishii. On-line em algorithm for the [18] L. Tang and H. Liu. Relational learning via latent [19] L. Tang, H. Liu, J. Zhang, and Z. Nazeri. Community [20] L. Tang, S. Rajan, and V. K. Narayanan. Large scale [21] Z. Xu, V. Tresp, S. Yu, and K. Yu. Nonparametric [22] G. L. Zacharias, J. MacMillan, and S. B. V. Hemel, [23] X. Zhu. Semi-supervised learning literature survey. [24] X. Zhu, Z. Ghahramani, and J. Lafferty.

It is observed that the node degree in a social network follows power law [14]. For simplicity, we use a continu-ous power-law distribution to approximate the node degrees. Suppose where x is a variable denoting the node degree and C is a normalization constant. It is not difficult to verify that Hence, It follows that the probability that a node with degree larger than k is Meanwhile, we have
Therefore, The proof is completed.
