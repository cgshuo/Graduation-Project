 Thomas G. Dietterich tgd@cs.orst.edu Adam Ashenfelter ashenfad@engr.orst.edu Yaroslav Bulatov bulatov@cs.orst.edu Many applications of machine learning involve assign-ing labels to sequences of objects. For example, in part-of-speech tagging, the task is to assign a part of speech ( X  X oun X ,  X  X erb X , etc.) to each word in a sentence (Ratnaparkhi, 1996). In protein secondary structure prediction, the task is to assign a secondary structure class to each amin o acid residue in the pro-tein sequence (Qian &amp; Sejnowski, 1988).
 We call this class of problems sequential supervised learning (SSL), and it can be formalized as follows: Given: A set of training examples of the form Find: A classifier H that, given a new sequence X Perhaps the most famous SSL problem is the NETtalk task of pronouncing English words by assigning a phoneme and stress to each letter of the word (Se-jnowski &amp; Rosenberg, 1987).
 Early attempts to apply machine learning to SSL prob-lems were based on sliding windows .Topredictla-bel y t , a sliding window method uses features drawn from some  X  X indow X  of the X sequence. For exam-ple, a 5-element window w t ( X ) would use the features x SSL problem into a standard supervised learning prob-lem to which any ordinary machine learning algorithm can be applied. However, in most SSL problems, there are correlations among successive class labels y t .For example, in part-of-speech tagging, adjectives tend to be followed by nouns. In protein sequences, alpha he-lixes and beta structures always involve multiple adja-cent residues. These correlations can be exploited to increase classification accuracy.
 Recently, many new learning methods have been de-veloped with the goal of capturing these y  X  y corre-lations. See Dietterich (2002) for a review. One of the most interesting new methods is the conditional ran-dom field (CRF) proposed by Lafferty et al. (2001). The CRF is a probabilistic model of the conditional probability that input sequence X will produce out-put label sequence Y : P ( Y | X ). The CRF has the form of a Markov random field (Geman, 1998): P ( Y | X )= functions that capture (respectively) the degree to which y t is compatible with X and the degree to which y is compatible with a transition from y t  X  1 and with X . These potential functions can be arbitrary real-valued functions. The exponential function ensures that P ( Y | X ) is positive, and the normalizing constant ensures that P ( Y | X ) sums to 1. This representation is completely general, subject to the assumption that P ( Y | X ) &gt; 0 for all X and Y (Besag, 1974; Hammers-ley &amp; Clifford, 1971). Normally, it is assumed that the potential functions do not depend on t , and we will adopt that assumption in this paper.
 To apply a CRF to an SSL problem, we must choose a representation for the  X  functions. Lafferty et al. studied  X  functions that are weighted combinations of binary features: where the  X  a  X  X  and  X  b  X  X  are trainable weights, and the features g a and f b are boolean functions. For example, in part-of-speech tagging g 234 ( y t ,X )mightbe1when x t is the word  X  X ank X  and y t is the class  X  X oun X  (and 0 otherwise). As with sliding window methods, it is nat-ural to define features that depend only on a sliding window w t ( X )of X values. This linear parameteriza-tion can be seen as an extension of logistic regression to the sequential case.
 Once a parameterization i s chosen, the CRF can be trained to maximize the log likelihood of the training data, possibly with a regularization penalty to prevent overfitting. Let  X  = {  X  1 ,..., X  1 ,... } denote all of the tunable parameters in the model. Then the objective function is to maximize J ( X ) = log = = = Lafferty et al. introduced an iterative scaling algorithm for maximizing J ( X ), but they reported that it was exceedingly slow. Several groups have implemented gradient ascent methods, but naive implementations are also very slow, because the various  X  and  X  pa-rameters interact with each other: increasing one pa-rameter may require compensating changes in others. McCallum X  X  Mallet system (McCallum, 2003) employs the BFGS algorithm, which is an approximate second-order method that deals with these parameter interac-tions.
 A drawback of this linear parameterization is that it assumes that each feature makes an independent con-tribution to the potential functions. Of course it is pos-sible to define more features to capture combinations of the basic features, but this leads to a combinatorial explosion in the number of features, and hence, in the dimensionality of the optimization problem. For ex-ample, in protein secondary structure prediction, Qian and Sejnowski found that a 13-residue sliding window gave best results for neural network methods. There are 3 2  X  13  X  20 = 2340 basic f b features that can be defined over this window. If we consider fourth-order conjunctions of such features, we obtain more than 10 12 features. This is obviously infeasible.
 McCallum X  X  Mallet system starts with a single con-stant feature and introduces new feature conjunctions by taking conjunctions of the basic features with fea-tures already in the model. Candidate conjunctions are evaluated according to t heir incremental impact on the objective function. He demonstrates signifi-cant improvements in speed and classification accu-racy compared to a CRF that only includes the basic features.
 In this paper, we introduce a different approach to training the potential functions based on Freidman X  X  (2001) gradient tree boosting algorithm. In this ap-proach, the potential functions are represented by sums of regression trees, which are grown stage-wise in the manner of Adaboost (Freund &amp; Schapire, 1996). Each regression tree can be viewed as defining several new feature combinations X  X ne corresponding to each path in the tree from the root to a leaf. The result-ing potential functions still have the form of a linear combination of features, but the features can be quite complex. The advantage of the gradient boosting ap-proach is that the algorithm is fast and straightfor-ward to implement. In addition, there may be some tendency to avoid overfitting because of the  X  X nsemble effect X  of combining multiple regression trees. Suppose we wish to solve a standard supervised learn-ing problem, where the training examples have the form ( x i ,y i ) ,i =1 ,...,N and y i  X  X  1 ,...,K } .We wish to fit a model of the form Gradient tree boosting is based on the idea of func-tional gradient ascent. In ordinary gradient ascent, we would parameterize  X  in some way, for example, as a linear function, Let  X  = {  X  1 ,... } represent all of the tunable param-eters in this function. In gradient ascent, the fitted parameter vector after iteration m , X  m ,isasumof an initial parameter vector  X  0 and a series of gradient ascent steps  X  m : where each  X  m is computed as a step in the direction of the gradient of the log likelihood function: and  X  m is a parameter that controls the step size. Functional gradient ascent is a more general approach. Instead of assuming a linear parameterization for  X , it just assumes that  X  will be represented by a weighted sum of functions: Each  X  m is computed as a functional gradient : The functional gradient indicates how we would like the function  X  m  X  1 to change in order to increase the true log likelihood (i.e., on all possible points ( x ,y )). Unfortunately, we do not know the joint distribution P ( x ,y ), so we cannot evaluate the expectation E x ,y . We do have a set of training examples sampled from this joint distribution, so we can compute the value of the functional gradient at each of our training data points: We can then use these point-wise functional gradients to define a set of functional gradient training exam-h m ( y, x ) so that it approximates  X  m ( y i , x i ). Specifi-cally, we can fit a regression tree h m to minimize We can then take a step in the direction of this fitted function: Although the fitted function h m is not exactly the same as the desired  X  m , it will point in the same general direction (assuming there are enough training examples). So ascent in the direction of h m will ap-proximate true functional gradient ascent.
 A key thing to note about this approach is that it replaces the difficult problem of maximizing the log likelihood of the data by the much simpler problem of minimizing squared error on a set of training exam-ples. Friedman suggests growing h m viaabest-first version of the CART algorithm (Breiman et al., 1984) and stopping when the regression tree reaches a pre-set number of leaves L . Overfitting is controlled by tuning L (e.g., by internal cross-validation). In principle, it is straightforward to apply functional gradient ascent to SSL. All we need to do is to repre-sent and train  X ( y t ,X )and X ( y t  X  1 ,y t ,X )asweighted sums of regression trees. For historical reasons, we took a slightly different approach. Let be a function that computes the  X  X esirability X  of label y t given values for label y t  X  1 and the input features X .Thereare K such functions F k ,oneforeachclass label k . Then the CRF has the form We now compute the functional gradient of log P ( Y | X ) with respect to F y t ( y t  X  1 ,X ). To simplify the computation, we replace X by w t ( X ), which is a window into the sequence X centered at x . We will further assume, without loss of generality, that each window is unique, so there is only one occurrence of w t ( X ) in each sequence X . Proposition 1 The functional gradient of log P ( Y | X ) with respect to F v ( u, w d ( X )) is  X  log P ( Y | X )  X  X  v ( u, w d ( X )) where I ( y d  X  1 = u, y d = v ) is 1 if the transition u is observed from position d  X  1 to position d in the sequence Y and 0 otherwise, and where P ( y d  X  1 = u, y d = v | w d ( X )) is the predicted probability of this transition according to the current potential functions. To demonstrate this proposition, we must first intro-duce the forward-backward algorithm for computing Z ( X ). We will assume that y t takes the value  X  for t&lt; 1. Define the forward recursion by  X  ( k, 1) = exp F k (  X  ,w 1 ( X ))  X  ( k, t )= Define the backward recursion as  X  ( k, T )=1  X  ( k, t )= The variables k and k iterate over the possible class labels. The normalizer Z ( X ) can be computed at any position t as If we unroll the  X  recursion one step, we can also write this as Z ( X )= Table 1 shows the derivation of the functional gradient. In line 3, exactly one of the F y t ( y t  X  1 ,w t ( X )) terms will match F v ( u, w d ( X )), because w d ( X ) is unique. This term will have a derivative of 1, so we represent this by the indicator function I ( y d  X  1 = u, y d = v ). In line 5, we expand Z ( X ) at position d using the forward-backward algorithm. Again because w d ( X )is unique, only the product where k = u and k = v will give a non-zero derivative, so this gives us line 6. The right-hand expression in 6 is precisely the joint prob-ability that y d  X  1 = u and y d = v given X . Q.E.D. If w d ( X ) occurs more than once in X , each match contributes separately to the functional gradient. This functional gradient has a very satisfying inter-pretation: It is our error on a probability scale. If the transition u  X  v is observed in the training example, then the predicted probability P ( u, v | X ) should be 1 in order to maximize the likelihood. If the transition is not observed, then the predicted probability should be 0. Functional gradient ascent simply involves fitting regression trees to these residuals.
 Table 2 shows pseudo code for our tree-boosting al-gorithm. The potential function for each class k is initialized to zero. Then M iterations of boosting are executed. In each iteration, for each class k ,aset S ( k ) of functional gradient training examples is gen-erated. Each example consists of a window w t ( X i )on the input sequence, a possible class label k at time t  X  1, and the target  X  value. A regression tree hav-ing at most L leaves is fit to these training examples to produce the function h m ( k ). This function is then added to the previous potential function to produce the next function. In other words, we are setting the step size  X  m = 1. We experimented with performing a line search at this point to optimize  X  m , but this is very expensive. So we rely on the  X  X elf-correcting X  property of tree boosting to correct any overshoot or undershoot on the next iteration.
 One way to improve upon this algorithm is to initialize the potential functions more intelligently. The pseudo-probability of the correct label at position t given the correct labels for y t  X  1 and y t +1 . The pseudo-likelihood can be computed without p erforming any forward-backward iterations: The pseudo-likelihood X  X ecause it assumes that the correct labels are known for y t  X  1 and y t +1  X  X orks well if our eventual error rate will be small. We found that it significantly sped up our training trials. It is known to be a consistent estimator of the likelihood (Besag, 1977). We perform three iterations of gradient tree boosting using the pseudo-likelihood to compute the boosting examples S ( k ). Then we switch to using the full functional gradient.
 The sets of generated examples S ( k ) can become very large. For example, if we have 3 classes and 100 train-ing sequences of length 200, then the number of train-ing examples for each class k is 3  X  100  X  200 = 60 , 000. Although regression tree algorithms are very fast, they still must consider all of the training examples! Fried-man (2001) suggests two tricks for speeding up the computation: sampling and influence trimming. In sampling, a random sample of the training data is used for training. In influence trimming, data points with  X  values close to zero are ignored. We did not apply either of these techniques in our experiments. Once a CRF model has been trained, there are (at least) two possible ways to define a classifier Y = H ( X ) for making predictions. First, we can predict the entire sequence Y that has the highest probability: This makes sense in applications, such as part-of-speech tagging, where the goal is to make a coher-ent sequential prediction. This can be computed by the Viterbi algorithm (Rabiner, 1989), which has the advantage that it does not need to compute the nor-malizer Z ( X ).
 The second way to make predictions is to individually predict each y t according to and then concatenate these individual predictions to obtain H ( X ). This makes sense in applications where the goal is to maximize the number of individual y t  X  X  correctly predicted, even if the resulting predicted Y sequence is incoherent. For example, a predicted se-quence of parts of speech m ight not be grammatically legal, and yet it might maximize the number of indi-vidual words correctly classified. P ( y t | X )canbecom-puted by executing the forward-backward algorithm as We implemented gradient tree boosting for CRFs and compared it to McCallum X  X  Mallet system on four benchmark data sets. We will call our algo-rithm TreeCRF . We will use TreeCRF-V for the TreeCRF with Viterbi predictions and TreeCRF-FB for the TreeCRF with forward-backward predic-tions. Mallet implements McCallum X  X  feature induc-tion algorithm. Mallet makes its predictions using the Viterbi algorithm, so we will denote it by Mallet-V . 5.1. Data Sets We tested these algorithms on four data sets: pro-tein secondary structure prediction and three Usenet FAQs: ai-general, ai-neural, and aix.
 The protein secondary structure benchmark was pub-lished by Qian &amp; Sejnowski (1988). A protein consists of a sequence of amino acid residues. Each residue is represented by a single feature with 20 possible val-ues (corresponding to the 20 standard amino acids). There are three classes: alpha helix, beta sheet, and coil (everything else). There is a training set of 111 sequences and a test set of 17 sequences.
 Each of the FAQ data sets consists of Frequently Asked Questions files for a Usenet newsgroup (McCallum et al., 2000). The FAQs for each newsgroup are di-vided in separate files: ai-general has 7 files, ai-neural has 7 files, and aix has 5 files. Every line of an FAQ is labeled as either part of the header, a question, an answer, or part of the tail. Hence, each x t consists of a line in the FAQ file, and the corresponding y t  X  { header, question, answer, tail } . The measure of ac-curacy is the number of indivi dual lines correctly clas-sified. McCallum provided us with the definitions of 20 features. We made a slight correction to one of the features, so our results are not directly comparable to his. For each newsgroup, performance was measured by leave-1-out cross-validation: the CRF was trained on all-but-one of the files and tested on the remaining file. This was repeated with each file, and the results averaged.
 Both TreeCRF and Mallet have parameters that must be set by the user. For both algorithms, the user must set (a) the window size, (b) the order of the Markov model, and (c) the number of iterations to train. For TreeCRF , the only additional parameter is L , the depth limit for the regression trees. For Mal-let the parameters are (a) the regularization penalty for squared weights (called the variance), (b) the num-ber of iterations between feature inductions (kept con-stant at 8), (c) the number of features to add per fea-ture induction (kept constant at 500), (d) the true la-bel probability threshold (kept constant at 0.95), (e) the training proportions (kept constant at 0.2, 0.5, and 0.8), (f) the number of iterations to train. Except for the variance, we kept all of Mallet  X  X  parameters fixed at the values recommended by Andrew McCal-lum (personal communication). To set the remaining parameters, we manually tried a handful of settings and chose the setting that gave the best test set (or cross-validation) performance. Ideally, these would be set via internal cross-validation. However, because we did not perform a very careful search of the parameter settings, we believe that the parameters are not highly tuned. 5.2. Results Figure 1 shows the results on the protein task. In all cases (except Qian-Sejnowski), a first-order CRF was employed. The input features consisted of an 11-residue sliding window. The TreeCRF-FB attains its peak performance of 64.7% correct after 28 iterations. The next best method is the neural network sliding window of Qian and Sejnowski (1988), which attains 64.5%. Mallet-V reaches 62.9% after 145 iterations. A McNemar X  X  test comparing the peak performance of TreeCRF-FB and Mallet-V shows that the differ-ence is statistically significant ( p&lt; 0 . 05). One worrying aspect of Mallet is that the perfor-mance curve exhibits a high degree of fluctuation. This is presumably due to the effect of introducing new fea-tures. Butitalsosuggeststhatitwillbedifficultto find the optimal stopping point for avoiding overfit-ting. The peak performance of 62.9% is achieved in only one iteration. The second-highest performance is 62.6%, and a more realistic estimate of its achievable performance (i.e., by using cross-validation to deter-mine the stopping point) would be around 61.5%. It is difficult to compare the CPU time of the methods, because TreeCRF is written in C++ while Mallet is written in Java. Despite these differences the run-ning times of the two programs are quite similar. The time required for TreeCRF to reach its peak perfor-mance is 1979.98 s; the time required for Mallet to reach its peak performance is 3634.37 s.
 With an 11-residue window, it is not feasible to run LinearCRF on this problem. Table 3 compares the CPU time per iteration for smaller window sizes. We see that LinearCRF is faster for small window sizes, but that it slows down exponentially as the window size grows.
 Figure 2 plots the percent age of lines correctly clas-sified by the two algorithms on the ai-general FAQ. Again we see that Mallet  X  X  performance fluctuates wildly. A McNemar X  X  test of the performance on the final iterations of the two methods concludes that TreeCRF is better ( p&lt; 0 . 001).
 Figure 3 plots the results for the ai-neural FAQ. This time, despite fluctuations, Mallet converges to a bet-ter classifier than TreeCRF according to McNemar X  X  test ( p&lt; 0 . 001). Finally, Figure 4 plots the results for the aix FAQ. Although it is difficult to see from the graph, Mal-let again converges to a slightly better classifier ( p&lt; 0 . 025). Note that on this data set, TreeCRF required about twice as much time to reach peak performance. This paper has introduced a novel method for train-ing conditional random fields based on gradient tree boosting. We can evaluate it along several dimensions. Ease of implementation: TreeCRF is simpler to implement than Mallet .
 Ease of tuning: TreeCRF introduces only one tun-able parameter, L , the maximum number of leaves permitted in each regression tree. Mallet has many more parameters to consider. Mallet  X  X  performance fluctuates wildly, while TreeCRF improves smoothly. Scaling to large numbers of features: tree boost-ing scales much better than the original linearly-parameterized CRF method. It appears to match Mallet , which also gives dramatic speedups when there are many potential features.
 Run time: In our experiments TreeCRF required run time within a factor of two of Mallet .Bothare reasonable.
 Accuracy: In our experiments, TreeCRF was more accurate on two data sets and less accurate on two data sets.
 Scaling to large numbers of classes: In experi-ments not shown, we attempted to apply TreeCRF to the NETtalk text-to-speech problem, which has 140 classes. This is infeasible because the cost of perform-ing the forward-backward algorithm (required by both TreeCRF and Mallet to compute gradients) scales as T 140 n +1 ,where T is the length of the sequences and n is the order of the Markov model. For NETtalk, T is around 7, but previous research has suggested that n should be at least 3. This means that the forward-backward computation for each training sequence re-quires 2 . 7  X  10 9 operations, which means that it is very slow. An important challenge for SSL research is to develop methods that can handle large numbers of classes.
 Gradient tree boosting may provide another advantage over methods based on standard parametric gradient ascent: the ability to handle missing values in the in-puts. There are very good methods for handling miss-ing values when growing regression trees including the surrogate split method of CART (Breiman et al., 1984) and the instance weighting method of C4.5 (Quinlan, 1993). In future work, we will evaluate whether these methods work well for training and evaluating CRFs. Acknowledgements The authors gratefully acknowledge the support of NSF grants IIS-0083292 and IIS-0307592.
 Besag, J. (1974). Spatial interaction and the statisti-cal analysis of lattice systems. Journal of the Royal Statistical Society B , 36 , 192 X 236.
 Besag, J. (1977). Efficiency of pseudolikelihood esti-mation for simple Gaussian fields. Biometrika , 64 , 616 X 618.
 Breiman, L., Friedman, J. H., Olshen, R. A., &amp; Stone, C. J. (1984). Classification and regression trees . Wadsworth International Group.
 Dietterich, T. G. (2002). Machine learning for sequen-tial data: A review. Structural, Syntactic, and Sta-tistical Pattern Recognition (pp. 15 X 30). New York: Springer Verlag.
 Freund, Y., &amp; Schapire, R . E. (1996). Experiments with a new boosting algorithm. ICML-96 (pp. 148 X  156). Morgan Kaufmann.
 Friedman, J. H. (2001). Greedy function approxima-tion: A gradient boosting machine. Annals of Statis-tics , 29 .
 Geman, D. (1998). Random fields and inverse prob-lems in imaging. In A. Ancona, D. Geman and flour xviii , Lecture Notes in Mathematics 1427, 117 X  196. Berlin: Springer-Verlag.
 Hammersley, J. M., &amp; Clifford, P. (1971). Markov fields on finite graphs and lattices (Technical Re-port). Unpublished.
 Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data. ICML-2001 (pp. 282 X 289). San Francisco, CA: Morgan Kauf-mann.
 McCallum, A. (2003) . Efficiently inducing features of conditional random fields. UAI-2003 (pp. 403 X 410). San Francisco, CA: Morgan Kaufmann.
 McCallum, A., Freitag, D., &amp; Pereira, F. (2000). Max-imum entropy Markov models for information ex-traction and segmentation. ICML-2000 (pp. 591 X  598). Morgan Kaufmann, San Francisco, CA.
 Qian, N., &amp; Sejnowski, T. J. (1988). Predicting the secondary structure of globular proteins using neural network models. J. Mol. Bio. , 202 , 865 X 884. Quinlan, J. R. (1993). C4.5: Programs for empirical learning. San Francisco, CA: Morgan Kaufmann. Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recogni-tion. Proc. IEEE , 77 , 257 X 286.
 Ratnaparkhi, A. (1996). A maximum entropy model for part-of-speech tagging. Proceedings of the confer-ence on empirical methods in natural language pro-cessing (pp. 133 X 142). Somerset, NJ: ACL.
 Sejnowski, T. J., &amp; Rosenberg, C. R. (1987). Parallel networks that learn to pronouce English text. Com-
