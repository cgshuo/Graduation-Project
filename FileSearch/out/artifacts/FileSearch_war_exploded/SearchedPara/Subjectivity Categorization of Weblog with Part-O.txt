 comments on weblogs for different reasons such as politics or commerce. All these needs necessitate automatically distinguishing subjective weblog contents from objective ones, namely subjectivity categorization. Since weblogs contain various topics from different domains, limited training data can hardly cover all the topics and  X  X nseen words X  becomes a serious problem for categorization tasks. In this paper, Part-Of-Speech (POS) based smoothing is proposed to alleviate the  X  X nseen words X  problem. In conjunction with a na X ve Bayes model constructed from limited training data, the probability of an unseen word in a new domain can be well smoothed by the probability of its POS result. Empirical studies on five datasets show that our approach consistently outperforms the basic na X ve Bayes with Laplace smoothing. In a cross-domain experiment, our approach achieves 22.0% improvement in Macro F1 and 24.4% in Micro F1 over basic na X ve Bayes. These verify that POS based smoothing can indeed benefit subjectivity categorization, especially in the cases with a large number of unseen words. information for marketing professionals, politicians, social psychologists, and others interested in extracting and mining opinions, views, moods, and attitudes. Some applications are currently being explored: z Public feedbacks towards certain products or brands. z Public effects of policies and political events. z Global and personal mood phenomena. Mishne and subjective content extraction from blog space. Subjectivity in natural languages refers to the aspects of languages used to express opinions and evaluations [11]. Typically, if a sentence represents a user X  X  opinions, feelings, or attitudes, we regard it as subjective. For example,  X  X he script is a tired one, with few moments of joy rising above the stale material X . If a sentence only contains some facts stated by a user, we regard it as objective. Such as:  X  X avid is a painter with painter's block who takes a job as a waiter to get some inspiration X . subjectivity categorization, has been explored in some previous work such as [1][2][6][9]. However, none of them has thoroughly studied the  X  X nseen words X  problem, which is quite common due to the far less focused and organized topics discussed on weblogs. Here  X  X nseen word X  means a new word that never appears in the training data. Moreover, categorization approaches using n-gram [15][20] even exacerbate this problem. Na X ve Bayes algorithm [8] and statistic language modeling [19] exploit smoothing methods to attack this issue and most of them are based on a reference model over word distribution. Given the specialty of subjectivity categorization, we try to use a more general linguistic feature, Part-Of-Speech , to address the  X  X nseen words X  problem. utilized in text genre classification [12] or text style categorization [16][17]. The example in Table 1 illustrates the idea behind POS-based genre categorization: There are 4 sentences, 2 subjective ones and 2 objective ones, selected from a movie review and a digital camera dataset results in Table 1. As Table 1 shows, both the subjective sentence group and the objective sentence group contain some common POS n-grams. That means even a word (or n-gram) does not occur in the training data, its POS tag can still help predict the subjectivity category. Subjective 
Sentence 1 with POS Tags Subjective 
Sentence 2 with POS Tags Common 
POS N-gram Objective 
Sentence 1 with POS Tags Objective 
Sentence 2 with POS Tags Common 
POS N-gram the  X  X nseen word X  problem in subjectivity categorization through smoothing . We first introduce several variants of na X ve Bayes based on POS and n-gram and then we discuss POS-based smoothing model. Finally, we use linear regression to determine the smoothing coefficients automatically. Our approach is referred as Subjectivity Categorization using POS-based Smoothing (SCPS) . The empirical results on five datasets show that SCPS consistently outperforms the baseline algorithm. Especially in the cross-domain experiments, SCPS can achieve even more accuracy improvement. z Proposing a smoothing method based on POS to z Designing cross-domain experiments to verify the z Using regression model to learn coefficients for Section 2, we review some related work. Section 3 describes POS-based smoothing for subjectivity categorization. In Section 4, we present the results of empirical studies. Finally, we conclude the paper in Section 5. a corpus of 1,001 sentences from the Wall Street Journal Treebank Corpus was manually annotated. In the consequent work, Wiebe [7] identified strong clues of subjectivity through clustering words according to distributional similarity [10]. Besides adjectives, other linguistic features, such as verbs and n-gram, were studied in [3][4][6]. Turney [3] used a part-of-speech tagger to identify phrases that contain adjectives or adverbs. Hatzivassiloglou and Mckeown [4] constructed a log-linear regression model to predict the orientations of conjoined adjectives. Wiebe and Wilson [6] proposed three types of potential subjective elements: unique word, adjective/verb and fixed-n-gram of word/POS. Riloff and Wiebe [9] explored the bootstrapping methods to train subjectivity classifiers together with un-annotated text. focus on  X  X nseen words X  problem. Finn [12] showed a pilot study in domain transfer: how well the learned classifiers generalize from the training corpus to a new coupus. POS statistics are utilized and the results are promising. Wolters and Kirsten [18] argued that the additional non-content information, like POS, may help only in some cases. Besides, n-gram based text categorization [15][20] even aggravates the  X  X nseen words X  problem. In language modeling, researchers used models based on n-grams of word classes to generalize unseen word sequences, and hence offer improved robustness to novel or rare word combinations [28][29]. Niesler et al. [29] showed that classes created by automatic clustering resulted in more performance improvements than classes based on POS. Our approach differs from the above category-based approaches in two aspects: First, because it is difficult to cluster a large amount of unseen words from different domains in advance, we adopt POS-based word classes for subjectivity categorization. Second, we try to exploit POS-based smoothing for subjectivity categorization, not to predict word sequences as the language modeling does. words, naive Bayes categorization [8] and statistic language modeling [19] need smoothing techniques to adjust the maximum likelihood estimates Standard naive Bayes uses Laplace smoothing method [8]. Peng [20] applied Good-Turing [21], Witten-Bell [22], Linear [22] and Absolute [23][24] smoothing methods to naive Bayes using n-gram model respectively, called Chain Augmented Naive Bayes classifier (CAN). While most of the smoothing techniques are based on a reference model over word distribution, we show that smoothing based on POS information is more effective in the task of subjectivity categorization. SCPS algorithm. Then some variants of naive Bayes using POS tags and n-gram are introduced. After that, the smoothing technique is discussed in details. Finally, we describe how to choose coefficients for smoothing by linear regression model automatically. { w 1 , w 2 , ..., w n } be the words and POS = { pos 1 , pos pos m } be the POS tags for all words respectively. The overview of SCPS is shown in Figure 1. 
Figure 1. POS based smoothing for subjectivity 3.2.1 Basic na X ve Bayes overview. Na X ve Bayes is widely used for text categorization and is based on a simple application of Bayes X  X  rule. The goal of na X ve Bayes is to predict the categories of a document d by P ( c|d ). By Bayes X  X  rule, we have: where c denotes a category and d denotes a document. P ( c ) is the prior probability of category c . The Bayes classifier can be constructed by seeking the optimal category which maximizes the posterior P ( c|d ): Basic naive Bayes (refered as BNB) introduces an additional assumption that all the attributes are independent given the category label. Since P ( d ) is a constant for every category c , we have: where document d is represented by a vector of N attributes which are treated as words appearing in the document, d =( w 1 , w 2 ,...... w n ). One key issue is how to calculate P ( w i | c ) . Here we consider several variants of basic na X ve Bayes using n-gram and POS models. 3.2.2 Na X ve Bayes using n-gram and POS. N-gram phrases characterize the  X  X hallow X  features of text. There exist two frequent usages of n-gram: what we call n-gram phrase and Markov n-gram. N-gram phrase takes an alphabetically ordered sequence of n consecutive words as a single unit [15]. Markov n-gram considers the local Markov chain dependence in the observed words [20]. 1. PNB: na X ve Bayes using POS tag. We exploit the 2. NG: na X ve Bayes using n-gram phrase. In [15], 3. PNG: na X ve Bayes using POS n-gram phrase. POS-4. MNG: na X ve Bayes using Markov n-gram. The 5. MPNG: na X ve Bayes using Markov POS n-gram. 
Algorithm Overview: SCPS z Tag POS for each word z Construct n-gram for both words and POS tags z Calculate probabilities using different naive z Learn coefficients for each model in the seen z Categorize documents using POS based the experiments. Based on the above discussions, we can get 10 variants of basic naive Bayes, as summarized in Table 2. Word POS 3.3.1 Smoothing methods overview. The smoothing techniques are used to overcome the problem of under-estimated probability of any word unseen in a document. In general, all smoothing methods are trying to discount the probabilities of the words seen in the text, and then assign the extra probability mass to the unseen words. Standard NB uses Laplace smoothing method [8]. Peng [20] applied Good-Turing [21], Witten-Bell [22], Linear [22] and Absolute [23][24] smoothing methods to na X ve Bayes using n-gram model respectively. In this paper, we select Laplace as the baseline for comparison with our smoothing approach based on POS tags. The Laplace smoothing equation is as following: where N j c is the frequency of word j appearing in category training corpus. 3.3.2 Smoothing using POS tags. As we mentioned, unseen words smoothing is a key issue for supervised learning. Here we exploit POS for smoothing in subjectivity categorization. Our basic idea of Smoothing using POS (denoted by SP) is similar to that of Jelinek-Mercer method [26] in language modeling, which involves a linear interpolation of two models. Here the two models are the word maximum likelihood model and the POS maximum likelihood model. The equations for three kinds of smoothing are listed here. 1. Smoothing by PNB (na X ve Bayes using POS tag) Pwc P wc P wc 2. Smoothing by PNG (na X ve Bayes using POS n-gram Pwc Pwc Pwc 3. Smoothing by MPNG (na X ve Bayes using Markov PwcPwcPwc The linear interpolation coefficients  X  and  X  controls the contribution of each model. One key issue is to determine their values. As discussed in next section, we try to learn these coefficients by linear regression model. propose an overall combination of na X ve Bayes models. We call this approach Subjectivity Category using POS-based smoothing (SCPS) : (|) (|) (|) (|) Pw c P w c P w c P w c In this approach, we take into account n-gram phrases, Markov n-grams and POS tags. The benefits include: z Since POS representation is included, this equation z N-gram phrases and Markov n-grams will benefit one important problem is how to assign coefficients to each one. Here we utilize linear regression model to learn the coefficients automatically. Regression is used to determine the relationships between two random variables to the data. The linear regression model postulates that: where the "residual" e is a random variable with mean zero. The coefficients b j (0  X  j  X  p ) are determined by the condition that the sum of the square residuals is as small as possible. Therefore the linear combination with b  X  X  should be better than those with any other coefficients. In our case, the independent variable x can be the probabilities that a single word belongs to a category under the 10 models, x = ( P BNB , P BG , P TG , P P variable y can be the probability between 0 and 1, which indicates whether the word belongs to a category or not. According to our assumption, POS-based models are more important for unseen words than for seen words. To verify this by experiments, we use the training data to generate regression samples for seen words and unseen words separately. which category. In our experiment, the belongingness is determined by supervised feature selection. For text processing, supervised feature selection [27] assumes the words are independent to each other, and try to find relevant words through correlations between category labels and words. Here we use Information Gain (IG) [27] to select words for linear regression. examine the effectiveness of our approach for subjectivity categorization. Particularly, we address the following issues: z Does POS-based smoothing benefit subjectivity z Which model is more important for prediction z How does n-gram, including both n-gram phrases the cross-domain scenarios in weblog data: Movie Review (MR), Wiebe MPQA (WM), Hyppia (HY), Yahoo Shopping (YS) and Digital Camera (DC). z Hyppia dataset contains the documents from three z Yahoo shopping dataset includes digital product z Digital camera dataset is composed of 300 reviews news, politics, finance and online shopping. The statistics of the datasets are summarized in Table 3. We did not conduct stopword removal and word stemming because we found that the categorization accuracy will drop when the two approaches are adopted. This means that sometimes the stopword and morphology information may be valuable clues for subjectivity categorization. In Table 3,  X  X ercentage in All Unigram/Bigram/Trigram Vocabulary X  means the ratio of a dataset X  X  n-gram vocabulary to that of the whole five datasets. According to the statistics, we can find that the word-based vocabulary obviously contains many more miscellaneous words than the POS-based one, which consequently makes  X  X nseen words X  a more serious problem for subjectivity categorization. Movie Review Word-based Statistics POS-based Statistics For POS tagging, we used a tool implemented in our group which can identify 34 kinds of POS tags with accuracy higher than 95%. domain test and the cross-domain test. The goal of the design is to verify our assumption that SCPS is more effective in the cross-domain case. z Single-domain test : for each dataset, we use ten-z Cross-domain tests : different from the single F1 measures are used in our experiments [25]. Let TP, TN, FP and FN denote true positive, true negative, false positive, and false negative. In the micro-averaging computation, the correct categorizations are first summed: In macro-averaging, precision and recall are averaged over categories: 4.3.1 Overall results. First we present the overall experiment results. The average results of different models in the single-domain test are shown in Figure 2, and the average results in cross-domain test are shown in Figure 3. From the single-domain test, we can find: z Words play an important role for subjectivity z N-gram of word (BG, TG), especially trigram (TG) z N-gram of POS tag (PBG, PTG), especially bigram z Only POS is not enough for subjectivity For cross-domain test, we conclude that: z Word based models, including BNB, BG and TG, 
Figure 2. Single-domain average results, with 
Figure 3. Cross-domain average results, with z When the training and testing data are from different z With unseen words appearing more frequently, POS-cross-domain tests, no one single model can achieve the best result in all cases while SCPS consistently improve the overall categorization results. 4.3.2 Performance of different model variants. In this subsection, some details of 10 model variants are investigated. Taking Micro F1 as a sample, we list the categorization results of each model variant in Table 4 (single-domain test) and Table 5 (cross-domain test). For each dataset, we highlight the model which achieves the highest F1 score, and call it  X  X o be the best X  model. In order to demonstrate the effectiveness of POS tags, we also divide the models into two groups: word-based models and POS-based models, which are shown as the items named as  X  X rouped TB (Times to be the Best) X  in the tables. As seen from Table 4, word-based models outperform POS-based models in all of the five single-domain datasets. BNB has one time to be the best, while both BG and MBG have two times to be the best. The reason is mentioned above: the vocabulary within single domain is limited, and the unseen words problem is not serious. In contrast, as Table 5 shows, POS-based models perform better in cross-domain tests. Among the 10 tests, POS-based models become the best in 8 times. Especially, PNB, PTG and MPBG have two times to be the best. The difference between single-domain and cross-domain settings means that when unseen words become very frequent, POS-based smoothing is more effective than the Laplace smoothing. models have strong relations to unseen words occurrences, which is consistent with our assumption that unseen words are in a higher need of POS-based smoothing compared with seen words. That is also why we learn the coefficients in Equation (13) for the two kinds of words separately. For each dataset, we count the top three models with the highest coefficients for seen and unseen words respectively. Table 6 and 7 summarized the results in single-domain test and cross-domain test. The number behind a model name is the times that the model to be  X  X he top three X . We highlight the POS-based models. As can be seen from the tables, no matter in the single-domain or the cross-domain settings, POS-based models are more important for unseen words than for seen words. Besides, compared with single-domain, cross-domain makes POS more important for both seen and unseen words.
 Seen Word BNB(5), MBG(4), MTG(2), PBG(2) , BG(1), TG(1) Unseen Word BNB(3), MBG(3), PBG(5) , MTG(2), BG(1), PTG(1) Seen Word Unseen Word 4.3.3 N-gram effectiveness. We try to estimate the effectiveness of n-gram, including both n-gram phrase and Markov n-gram. The main drawback of the Bag-Of-Words representation is that the semantic relations between words are lost. Using n-gram to represent document is reasonable in the aspect that n-grams have less ambiguity than their constituent words. However, even though  X  X ood X  n-grams are indeed able to improve the classification results, their contribution is weak in comparison to what hundreds of thousands of unigrams can contribute [15]. One major reason is that n-gram has very low probability of occurrence, which is called  X  X he sparseness of n-grams X . single-domain test. Word-based models include BNB, BG, TG, MBG and MTG. POS-based models include PNB, PBG, PTG, MPBG and MPTG. For word-based models, both n-gram phrase and Markov n-gram gradually degrade the categorization results while the gram size increases. For POS-based models, n-gram phrase slightly improves the results and Markov n-gram does not result in obvious accuracy degradation. By and large, word-based n-gram models behave better than POS-based ones. This verifies again that the word itself is still important for subjectivity categorization in single-domain dataset. cross-domain test. We notice that, different from Figure 4, word-based n-gram slightly improves the result when bigram is adopted. By studying the experimental data, we found that when the domain changes, a large number of unseen unigrams appeared. The unseen bigrams and trigrams are not overwhelming anymore compared with the unseen unigrams. As to POS-based n-gram models, trigram slight improve the results. The reason why bigram models are slightly inferior to unigram and trigram models will be further studied in future work. Overall, POS-based n-gram models behave better than word-based ones. This makes it reasonable to apply POS-based smoothing on unseen words. 
Figure 4. N-gram performance in single-domain 
Figure 5. N-gram performance in cross-domain solve the  X  X nseen words X  problem in weblog subjectivity categorization task. The experiments on 5 datasets show that our approach consistently outperforms the basic naive Bayes algorithm. Even in the cross-domain case, SCPS achieves Macro F1 and Micro F1 higher than 80%, which indicates our POS-based smoothing approaches are effective for subjectivity categorization tasks. with the conventional smoothing methods other than Laplace smoothing. Besides, we could use sets of synonyms as another smoothing method. This will help alleviate the unseen words problem and won't lose as much information as POS does. [1] J. Weibe, R. Bruce, and T. O X  X ara,  X  X evelopment [2] R. Bruce, and J. Wiebe,  X  X ecognizing Subjectivity: A [3] P. Turney,  X  X humbs Up or Thumbs Down? Semantic [4] V. Hatzivassiloglou, and K. McKeown,  X  X redicting [5] M. Hu, and B. Liu,  X  X ining and Summarizing [6] J. Wiebe, and T. Wilson,  X  X earning to Disambiguate [7] J. Wiebe,  X  X earning Subjective Adjectives from [8] A. McCallum, and K. Nigam,  X  X  Comparison of [9] E. Riloff, and J. Wiebe,  X  X earning Extraction [10] D. Lin,  X  X utomatic Retrieval and Clustering of [11] J. Wiebe,  X  X racking Point of View in Narrative X , in [12] A. Finn, N. Kushmerick, and B. Smyth,  X  X enre [13] L.A. Adamic, and N. Glance,  X  X he Political [14] G. Mishne, and M. Rijke,  X  X apturing Global Mood [15] C.M. Tan, Y.F. Wang, and C.D. Lee,  X  X he Use of [16] S. Argamon, M. Koppel, and G. Avneri,  X  X outing [17] M. Gamon,  X  X inguistic Correlates of Style: [18] M. Wolters, and M. Kirsten,  X  X xploring the Use of [19] J. Ponte, and W. Croft,  X  X  Language Modeling [20] F. Peng, D. Schuurmans, and S. Wang,  X  X ugmenting [21] S. Katz,  X  X stimation of Probabilities From Sparse [22] I. Witten, T. Bell,  X  X he Zero-frequency Problem: [23] H. Ney, U. Essen, and R. Kneser,  X  X n Structuring [24] C. Zhai, and J. Lafferty,  X  X  Study of Smoothing [25] Y. Yang,  X  X n Evaluation of Statistical Approaches to [26] F. Jelinek, and R. Mercer,  X  X nterpolated Estimation of [27] Y. Yang, and J.O. Pedersen,  X  X  Comparative Study [28] P.F. Brown, V.J. DellaPietra, P.V. deSouza, J.C. Lai, [29] T.R. Niesler, E.W.D. Whittaker, and P. C. Woodland, 
