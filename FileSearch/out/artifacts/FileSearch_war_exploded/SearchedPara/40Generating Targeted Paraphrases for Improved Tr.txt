 Statistical Machine Translation (SMT) is distinguished by the heavy use of machine learning methods and has proven extremely successful over the last decade. Almost all SMT techniques apply a learning algorithm to a large body of previously translated text, known as a parallel corpus or a bitext . It is assumed that the learner can generalize from these already translated examples and learn how to translate unseen sentences. Almost all modern SMT methods have been influenced, in one way or another, by the translation approach first proposed by Brown et al. [1990, 1993] at IBM. The IBM models represent the earliest statistical translation models and operate at word level. The next iteration of SMT methods were phrase based in that they used models that were designed to translate contiguous sequences of words together as a unit [Marcu and Wong 2002; Koehn et al. 2003]. Subsequent innovation took SMT methods one step further, building directly upon the strengths of the phrase-based approach: since phrases are good for learning reorderings of words, they can be used to learn reorderings of phrases as well. This was achieved by the use of hierarchical phrases ,thatis,a phrase that contains placeholders that can be filled by other phrases. Hierarchical-phrase-based models represent the current state-of-the-art. For a more comprehensive survey of contemporary SMT, the reader is referred to Lopez [2008] and Koehn [2010].
As the translation models have become more complex, the reliance on large bitexts has increased. In addition to data used to extract lexical, phrasal, and hierarchical cor-respondence units, today X  X  SMT systems also require additional high-quality human translations for parameter tuning. Such tuning is usually carried out by means of ma-chine learning algorithms that intelligently traverse the very large multidimensional parameter space [Ostendorf et al. 1991; Oard 2003]. Translations are produced for each explored point X  X sing a piece of software called a decoder  X  X n the parameter space and a quantitative estimate of the quality of said translations is computed by comparing them against human reference translations in terms of the BLEU metric [Papineni et al. 2002]. The components of this BLEU score are then used to guide the search to a more useful point in the parameter space.

Since BLEU is based on n -gram overlap between hypotheses and reference transla-tions, it is most accurate when computed with as many distinct reference translations (usually four) as possible. Intuitively this makes sense: there are usually a multitude of ways to phrase the meaning of the source sentence in the target language and the translation quality criterion should take as many of these variations into account as possible. With only a single reference, we risk the possibility that BLEU might judge good translations to be poor when they fail to match the exact wording within that reference translation and, therefore, provide misguided feedback to the search process. However, this reliance on multiple reference translations creates a problem, because reference translations are labor intensive and expensive to obtain. Therefore, with a few exceptions X  X otably NIST X  X  annual MT evaluations X  X ost new MT research datasets are provided with only a single reference translation, particularly in rapid development, low-density source language scenarios (e.g., Oard [2003]). This leads to the problem of reference sparsity , one that has a serious effect on the SMT parameter tuning process.

Although several solutions have been proposed to tackle this problem, we adopt an approach that uses automatic paraphrase generation, that is, given the single reference translation, we build a paraphrase generation system that produces several semanti-cally equivalent variants that can then be used as additional reference translations. One of the most novel things about this solution is that the paraphrase generation system itself is built only using resources that are available for the SMT system and no others. 1 In our previously published work, we showed that this solution to reference sparsity could yield significant improvements in translation quality but suffered seri-ous issues stemming from noisy paraphrases [Madnani et al. 2007, 2008]. This article addresses these shortcomings in a novel manner and demonstrates further significant improvements in translation quality over the previous method, as measured by auto-mated metrics as well as human judges.

The rest of the article is organized as follows: in Section 2, we describe the funda-mental idea underlying both our paraphrase-driven solutions: constructing a sentential paraphrase generator built using the SMT system itself. In Section 3, we describe our previously published solution and summarize its results. In Section 4, we describe the new solution presented in this article and compare its results to those in our previous papers. 2 Section 5 situates our work in the landscape of existing research and Section 6 concludes with a summary of our contributions. This section describes the design and implementation of a sentential paraphraser using SMT machinery. We first introduce the machine translation formalism that we adopt and then describe how we use this formalism for the purpose of paraphrase generation. The statistical machine translation formalism that we use employs a hierarchical SMT framework [Chiang et al. 2005; Chiang 2007]. Such a framework is formally based on a weighted Synchronous Context-Free Grammar (SCFG), containing synchronous rules of the form where X is a symbol from the nonterminal alphabet, and  X  e and  X  f can contain both words (terminals) and variables (nonterminals) that serve as placeholders for other phrases. Each  X  denotes a feature function defined over the rule. Examples of such rules can be the following. 3
Note that the nonterminals representing the same subphrases on either side of each rule are co-indexed. In the context of SMT, where phrase-based models are frequently used, these synchronous rules can be interpreted as pairs of hierarchical phrases . The underlying strength of a hierarchical phrase is that it allows for effective learning of not only the lexical reorderings, but phrasal reorderings as well. 4
Several different kinds of feature functions can be used but some of the most com-mon features are conditional and joint cooccurrence probabilities over the hierarchical paraphrase pair. Another common feature is one computed via an n -gram language model that estimates the fluency of the translation as it is being constructed during the translation process. Given a synchronous context-free grammar consisting of these translation rules and features, the actual translation process is simply equivalent to parsing with this grammar. Any given source sentence is parsed using the source side of the synchronous grammar. A target language derivation is generated simultaneously via the target side of the same rules, and the yield of this hypothesized derivation represents the hypothesized translation string in the target language.
Mathematically, the actual translation model defined over the set of synchronous derivations is a log-linear model of the form where each  X  i represents the weight for the respective feature  X  i . From this equation, we can see that the translation returned by the system is the one that can be read off the highest scoring synchronous derivation (as defined by a linear weighted combination of the feature values).

The hierarchical translation framework allows learning grammars and feature val-ues from parallel corpora during the model training process, without requiring any syntactic annotation of the data. For more details on the training process, the reader is referred to Chiang [2007]. Our paraphraser approaches sentence-level paraphrasing as a problem of English-to-English translation and constructing this monolingual translation model using a bilingual English-F translation model, for a second language F , and performing pivot-ing as described next.

First, we employ the same phrase-level strategy as Bannard and Callison-Burch [2005] and induce a monolingual translation grammar. The SMT model is trained in standard fashion on a bilingual English-F training corpus. Then, for each exist-ing production in the resulting bilingual grammar, multiple new English-to-English productions are created by pivoting on the foreign hierarchical phrase in the rule. For example, assume that we have the previously shown rules (2) X (5) present in an English-Chinese bilingual grammar. If the Chinese hierarchical phrase X 1  X  X 2 is used as a pivot, then the following two distinct English-to-English rules can be extracted from the bilingual rule (2). In a similar fashion, pivoting on the same phrase for other bilingual rules will produce the following rules (the corresponding rules in the other direction are not shown).
 To limit noise during pivoting, only the top 25 most frequent source language pivots for any English hierarchical phrase are used.

Each synchronous rule production in the original bilingual grammar is weighted by several feature values. The most commonly used features are usually probabilistic in nature and are computed from the counts assigned to that rule during the training process. Examples of such probabilistic features include the maximum likelihood esti-and target sides of the rule, respectively. In order to perform accurate pivoting, these feature functions must be recomputed for the newly created English-to-English gram-mar. The probabilistic features for the monolingual rules are computed directly from the corresponding feature values for the bilingual rules. First, we have the conditionals p (  X  e 1 |  X  e 2 ) where the two constituent bilingual probabilities are the bilingual rule features. The similarly.
 just counts the number of terminal symbols in  X  e 2 . This feature allows the monolingual translation model to learn whether it should produce shorter or longer paraphrases. In addition to the preceding features that are estimated from the training data, a trigram language model is also used. Since the production of English sentences is done via regular decoding, the same language model that is employed in a standard SMT setting can be and is used here.

Since the sentential paraphraser is based on an English-to-English log-linear trans-lation model, it also requires its own tuning of feature weights just as the bilingual SMT system does. However, the tuning setup for the paraphraser is straightforward: regardless of how the paraphrasing model will be used, it is possible to use any ex-isting set of English paraphrases as the tuning set for English-to-English translation. Given such a set of paraphrases, one sentence can be randomly chosen as the source sentence, and the remainder as the  X  X eference paraphrases X  for the purpose of finding the optimal feature weights. The optimization is then carried out exactly as it would be for tuning the weights for features in a bilingual translation system.

Once the English-to-English translation model, represented by the induced para-phrase grammar, has been induced, it can be used within the SMT decoder X  X ust as a bilingual translation model would be used X  X o paraphrase (translate) new sentences. We show in the subsequent sections that paraphrases so generated are quite useful for addressing the reference sparsity problem. In this section, we describe how we used the sentential paraphraser, described in Section 2, to address the reference sparsity problem when performing SMT parameter tuning. We assume, in line with current expectations, that only a single good, human-authored reference translation is available for each item in the development set used for SMT parameter tuning. We present results that show that reference sparsity can be offset by augmenting that single reference with its paraphrases as produced by the sentential paraphraser. The first set of results we present are for Chinese-to-English translation and the second for three European source languages: French, Spanish, and German. For both sets of experiments, the dataset used to tune the paraphraser X  X  parameters is the NIST MT02 set (using one of the 4 human translations as the  X  X ource X  and the others as the  X  X eference paraphrases X ). For both experiments, we present results in terms of both widely used automated MT metrics as well as in terms of human judgments of translation quality. Although we have previously published the Chinese-English automated results, the automated results for French, Spanish, and German are completely novel. The results in terms of human judgments for all four source languages (Chinese, French, Spanish, and German) are novel.
 The details of the first set of experiments for Chinese-English translation are as follows. (1) Training Data . The Chinese-English parallel data used for this set of experiments (2) Decoders . Both the SMT and paraphrase decoders use a state-of-the-art hierarchical (3) Tuning Set . The NIST MT03 Chinese set containing 919 sentences is used, as the (4) Validation Set . The validation set is the NIST MT04 + 05 set which contains both
As the baseline, the simulated single-reference set (1H = 1 Human) is used to tune the parameters of the SMT system which is then evaluated on the MT04 + 05 validation set. The simulated set is then paraphrased, the 1-best paraphrase extracted as an additional reference, and the MT system tuned on this new 2-reference tuning set (1H + 1P = 1 Human, 1 Paraphrase). The results, shown in Figure 1, confirm that using a paraphrased reference when only a single human reference is available is extremely useful and leads to huge gains in both the BLEU and TER scores on the validation set. 7
Since the paraphraser is an English-to-English SMT system, it can generate k -best hypothesis paraphrases for each input reference. An obvious extension to the aforesaid experiment then is to see whether using k -best paraphrase hypotheses as additional reference translations, instead of just the 1-best, can alleviate the reference sparsity to a larger extent during the optimization process. For this experiment, the top 1, 2 and 3 paraphrases for the MT03 simulated single-reference set are used as additional references; we have three tuning sets 1H + 1P, 1H + 2P, and 1H + 3P, respectively. As points of comparison, the tuning sets 2H, 3H, and 4H are also constructed from MT03 in the same simulated fashion 8 as the single-referenced tuning set 1H. The results for this experiment are shown in Figure 2.

The graph shows that starting from the simulated single-reference set, adding one more human reference translation leads to a significant gain in BLEU score, and adding more human references provides smaller but consistent gains at each step. With paraphrased references, gains continue up to 3 references, and then drop off; presumably beyond the top two paraphrases or so, n -best paraphrasing adds more noise than genuine diversity (one can observe this drop-off in provided diversity 9 in the example shown in Figure 3). Crucially, however, it is important to note that only the performance difference with four references X  X etween the human and the paraphrase condition X  is statistically significant.

In addition to results with automatic metrics, it would also be worthwhile to get actual human judgments indicating whether the translations produced by the system augmented with paraphrases are significantly better than those produced by the base-line system that is tuned with the single human-authored reference. To obtain such judgments, we conducted two sets of experiments on Amazon Mechanical Turk.  X  1H vs 1H + 1P . 100 sentences were randomly chosen from the NIST MT04 + 05 Chinese validation set. 10 HITs were then created, each containing 10 of the 100 source sentences along with: (a) the corresponding reference translations; (b) transla-tion outputs from a system tuned with the single human-authored reference; and (c) translation outputs from a system tuned with the single human-authored refer-ence and its 1-best paraphrase.  X  1H vs 1H + 3P . 100 sentences were randomly chosen from the NIST MT04 + 05 Chinese validation set. 10 HITs were then created, each containing 10 of the 100 source sentences along with: (a) the corresponding reference translations; (b) transla-tion outputs from a system tuned with the single human-authored reference; and (c) translation outputs from a system tuned with the single human-authored refer-ence and its 3-best paraphrases instead of just the 1-best.
 The instructions in each task for both sets of experiments described told the partici-pating Turkers to pick the translation output that they thought was more correct. A third option indicating that there was no difference between the two was also provided. Answers from Turkers were validated by embedding a control question in each HIT for which the correct answer was known beforehand. If the answer given by a Turker for this control question did not match the known answer, her answers for that HIT were discarded. Each sentence was annotated three times and the final answer for each sentence was picked by a simple majority vote. If the final answer for a sentence was the no-difference option, then that sentence was excluded from consideration.
The results for both of these sets of experiments are shown in Figure 4. It is clearly evident from the preference judgments obtained from the Turkers that using the para-phrases as artificial references yields significantly improved translation output when compared to the baseline system that was only tuned with a single reference. Assum-ing that choosing the system augmented with paraphrases is deemed as  X  X uccess X , the null hypothesis is that success and failure are equally likely with a probability of 0 . 5. Using a two-sided exact binomial test with these judgments shows that they are not in agreement with the null hypothesis and that success is more likely than failure with p-values as shown in the figure. 10 Here 95% confidence intervals are also shown. As with the automatic metrics, using the 3-best paraphrases tends to lead to lower performance for the MT system due to the decreased n -gram diversity and increased noise. In addition to showing the applicability of the sentential paraphraser for tuning in Chinese-English, it would also be very useful to show the same for a language pair for which there is only a single reference available and no simulation is required. Of course, for such a scenario, it would be impossible to compare the performance of the artificial, paraphrased references to actual human references. In this section, machine translation experiments from three different European languages X  X rench, German, and Spanish X  X nto English are presented. The details of these experiments are as follows. (1) Training Data . For these sets of experiments, mainly bitexts extracted from (2) Decoders . These are the same as Chinese-English. (3) Tuning Set . As the tuning set, the test set from the 2008 workshop on machine (4) Validation Set . The validation set is the newstest2009 set which contains 2 , 525
Figure 5 shows the BLEU and TER results for the validation sets for each of the three language pairs. These results confirm that the benefits from the paraphrased references are able to generalize across multiple source languages. However, as more paraphrases are added, the noise inherent in the paraphrases starts to overwhelm the benefits. One important thing to note about this set of results is that the improvements in the BLEU scores are much smaller than in the case of Chinese. The most likely reason for this is that the BLEU scores are being measured only against a single reference whereas in the case of Chinese-English translation, they were being measured against 4 reference translations that were available for the validation set.

To confirm whether human judgments of translation outputs would agree with the automatic metrics, experiments identical to the Chinese-English case were conducted on Amazon Mechanical Turk. Figure 6 shows the results of these experiments for the three European languages. So far we have shown that our sentential paraphraser can be used to create multiple, artificial reference translations by paraphrasing an existing good-quality human refer-ence translation. We also showed that using the 1-best artificial reference so produced, combined with the already existing human reference, for tuning the parameters of a statistical machine translation system yields significant gains. However, we also found that using more than just the 1-best output from the sentential paraphraser as addi-tional references for tuning does not yield any further improvements. In fact, doing so causes the performance to degrade as shown.

The degradation with paraphrases beyond the 1-best is a direct result of the in-creased noise in the paraphrase output as one goes down the n -best list. The bilingual phrasal correspondences extracted via commonly used word alignment methods are already noisy. The process of pivoting, a process relying on an equivalence relationship between these noisy correspondences that is approximate at best, only serves to intro-duce additional noise into the generated monolingual paraphrastic correspondences. This section describes a new SMT-specific instantiation of the sentential paraphraser that overcomes this behavior. 11
There is also a more serious problem with the sentential paraphraser: there are ab-solutely no constraints imposed on the paraphrasing process. The paraphraser is free to paraphrase any and every n -gram in the input sentence with any n -gram that the pivoting process has declared to be equivalent to it. The result of such unconstrained paraphrasing is that there is no guarantee that the paraphrased reference will match the translation output for that particular source sentence. It is basically a crap shoot; by allowing the paraphraser free rein, the hope is that at least some of the new n -grams brought into the mix via the paraphrased references will prove useful to the tuning algorithm. However, due to the noisy alignment and pivoting process, it is observed that the likelihood of this event decreases as more paraphrased references are added. Therefore, a more useful approach might be one that ensures that the paraphrasing is performed in a constrained manner, wherein the constraints are designed to in-crease the likelihood of the paraphrased reference matching the translation output. One way of constraining the paraphrasing is by  X  X argeting X  it, in some fashion, to-wards the translation output. The rest of this section describes how such targeting can be incorporated into the sentential paraphraser and what such incorporation entails. For convenience, the unconstrained sentential paraphraser, as described previously, is heretofore termed as the  X  X ntargeted X  paraphraser. Rather than inventing an entirely new method for targeting the paraphrasing to the translation output, it is more prudent to base the heuristic on an already existing and successful example of such targeting in the SMT literature. The example used here is one that has been used in the world of machine translation evaluation where a recent trend has been to move from automatic metrics such as BLEU and TER to human-in-the-loop measures.

Translation Edit Rate (TER) is one of the most popular metrics used to measure the quality of the translation output produced by a machine translation system. It is computed as the minimum number of edits needed to change a hypothesis so that it exactly matches one of the references, normalized by the average length of the references. Possible edits include the insertion, deletion, and substitution of single words as well as shifts of word sequences.

However, the TER score is not sufficient to indicate the acceptability of a translation hypothesis since it ignores notions of semantic equivalence. Therefore, a translation hypothesis containing the phrase rise in unemployment could be unfairly penalized even if the corresponding phrase in the reference is the semantically equivalent phrase increase in joblessness . This is where HTER (Human-targeted Translation Edit Rate), a modified version of TER that employs human annotation, enters the picture. HTER is the official evaluation measure used for the GALE research program [Olive 2005] and has been shown to yield higher correlations with human judgments than BLEU [Snover et al. 2006].

To compute HTER, human annotators X  X ho are fluent speakers in the target language X  X tart from the original, untargeted reference and edit it to make it closer to the given translation hypothesis, without losing its original meaning. TER is then computed against this targeted reference and is referred to as the HTER score of the translation output.
 Given this description of the HTER computation process, the analogy between an HTER annotator and the sentential paraphraser is obvious. The annotator is essen-tially a  X  X anual X  sentential paraphraser; one that paraphrases the original reference by targeting to the translation output. The result is a new, semantically equivalent reference that has a higher likelihood of matching that output. By using this reference in place of the original reference, the translation output will not be unfairly penalized for using words that mean the same thing as the original reference but are different on the surface. Therefore, it would be a reasonable strategy to fashion the sentential paraphraser to target the translation output in a similar manner. We describe the implementation of this targeting strategy in the next section. In the untargeted scenario, the paraphraser was not part of the tuning loop but instead only used as an offline component: the original human reference was paraphrased externally and the (untargeted) paraphrased references were added to relevant files of the tuning set. However, for a paraphraser that needs to target the translation output, the paraphrasing needs to happen online, that is, during the parameter tuning. Here are several important changes that need to be made to the paraphraser and its role in the tuning process. (1) Given that the paraphraser is targeting to the translation output, the output itself (2) In almost all SMT systems, the output of the decoder when translating a given (3) Usually, the algorithm that is used to tune the parameters of an SMT system is
A convenient way to implement targeting for the sentential paraphraser is to leverage the log-linear nature of the paraphrasing model. We previously defined the paraphraser as essentially an English-English translation model and since the translation model is log-linear, targeting can simply be implemented as a feature in that model. This targeting feature is defined as where  X  e h is a complete paraphrase hypothesis, e r is the original reference that is being paraphrased, and T is the translation output for the source sentence f . The value of the targeting feature for a complete paraphrase hypothesis, as defined, is simply the number of words that are in the paraphrase hypothesis but that are not in the translation output (for that particular source sentence). Of course, this feature cannot be precomputed for any translation rules (or phrase pairs) and is computed by the decoder as the paraphrase hypothesis is being constructed. Note also that, given this definition of the feature, its weight must be negative in order to elicit targeting behavior.

Now that the formulation of the targeting feature has been described, the next question that must be answered is how the weight for this feature will be computed. An obvious answer may be that the weight for this feature should be computed in the same way as the weights for the other paraphraser features were determined, that is, by taking a dataset that has four reference translations available, treating one of them as the  X  X ource X  and the others as the  X  X eference paraphrases X  and then using the usual SMT tuning paraphernalia. However this strategy will not carry over to the targeted paraphraser even if targeting is realized as simply another feature in the model.
Recall that the objective of the tuning algorithm is to find the set of feature weights that maximize the BLEU score of the tuning set against the provided reference transla-tions (paraphrases). In nonquantitative terms, the objective is to produce translations (paraphrases) as close to the reference translations (paraphrases) as possible. There-fore, the tuning algorithm has no reason to learn a nonzero weight for the targeting feature that is, in fact, designed to create paraphrases that are closer to an altogether different utterance: the translation output. One could, perhaps, modify the tuning cri-terion to be a weighted linear interpolation of two quantities: a measure of closeness to the reference paraphrases and a measure of closeness to the translation output. However, this solution is less than ideal and, instead, we have designed and imple-mented a different method for choosing the weight. However, first we need to describe an additional modification that must be included in the paraphraser. In the untargeted scenario, there is an explicit meaning-preserving link between the original reference and the untargeted paraphrase, that is, the paraphraser attempts to preserve the meaning of the original reference, often doing so in only a partial manner given the noisy paraphrase induction process. Note also that although there is an indirect link between the original reference and the translation output X  X oth being renderings of the same source language utterance X  X here is no link between the paraphrase of the original reference and the translation output: the paraphrase generation process and the translation process are completely independent. Therefore, the additional artificial references, while extremely noisy, do not bias the tuning process in any way.

In the targeted paraphrasing scenario there is an additional, explicit link between the generated paraphrase and the translation output resulting from the targeting, that is, the targeted paraphrase is now semantically related to both the original ref-erence and the translation output, albeit via different mechanisms. The existence of this explicit link between the paraphrase and the translation output provides an op-portunity for the introduction of a systematic bias into the tuning process; the targeted paraphrases use words from the translation output but are also used as additional ref-erences against which the translation output is matched. Furthermore, given the noisy nature of the paraphrasing process, it will not be adequate to counter this systematic bias. We confirm this hypothesis empirically shortly. More specifically, we use the tar-geted paraphraser X  X ith the usual pivot-based semantic link between the paraphrase and the original reference X  X or tuning the weights of an SMT system and show that the obtained results point to a biased tuning process.

Before the targeted paraphraser is used for tuning, a weight for the targeting feature must be chosen. Since a principled method by which choice must be made has not yet been introduced, the weight is chosen manually for this experiment. As this is simply an experiment designed to show that using a  X  X ufficiently well-targeted X  paraphraser for parameter tuning will lead to biased results, choosing the weight manually is a reasonable option. Based on feature selections experiments not described in this article in order to conserve space, 12 we use two weights for the targeting feature:  X  10 and  X  20. Figure 7 shows the results of the experiment using the targeted paraphraser with these weights for tuning the parameters of a Chinese-English SMT system. The paraphraser was used with the modifications listed in the previous section and the 1-best targeted paraphrase was used as an additional reference, in combination with the original. The graph shows two sets of curves, one each for the two different targeting weights. Each set contains two curves: one showing the BLEU score obtained for the tuning set after each iteration of tuning and the other showing the BLEU score for the val-idation set. The tuning set used for these experiments was, as before, NIST MT03 (919 sentences) and the validation set was NIST MT04 + 05 (2870 sentences). For both feature weights, the curves verify the previous hypothesis. The BLEU score on the tuning set obviously increases given that one of the references is designed to look like the translation output. However, since this increase is motivated more by a biased ref-erence than by an improved set of feature weights for the translator, the BLEU score on the validation set degrades after each iteration of the tuning process. Note that the degradation is self-sustaining: as poorer sets of weights are chosen based on a biased match, the translation output produced is worse in quality and, therefore, the targeted references retain even less of the meaning of the original reference. Had the set of references been completely independent of the translation output X  X s is generally the case X  X he tuning process would have automatically detected the worsening quality of the translation output and tried to move away from that part of the parameter space. However, given the strong link between the targeted references and the translation output, the tuning algorithm is unable to break the feedback loop.

Therefore, the usual semantic link obtained by the paraphrasing process is not suffi-cient to counter the bias that may be introduced into the tuning process if the targeted paraphrases are used as additional references. An external mechanism is necessary to counter this bias and the mechanism we propose is a self-paraphrase bias . The crux of the mechanism is simply to redistribute the probability mass such that a prestipulated portion of said mass is devoted to  X  X elf-paraphrasing X . In other words, a probabilistic bias is introduced into the paraphrasing process such that in the space of all possible paraphrases for a given human-authored reference, a fixed amount of probability mass is reserved for that paraphrase which is identical to the input, hence retaining all of its meaning. This bias is introduced into the conditional and joint probability features that we mentioned earlier in the article. The mathematical details of this bias are omitted here but can be found in the online appendix. At this point, we have two novel additions to the untargeted paraphraser: the targeting feature and the self-paraphrase bias. Note that these two primary mechanisms involved in targeted paraphrases are actually at odds with each other. The goal of the targeting feature is to change the original reference by using words from the translation output. On the other hand, the goal of the self-paraphrase bias is to retain as many of the words in the original reference as possible. At first this tension might seem like a problem. However, we actually leverage this tension to determine the targeting feature weight we seek, as well as the value of the self-paraphrase bias.

Before this technique is described, picture the original reference and the translation outputs as points in the vast space of possible  X  X eference X  translations that can be pro-duced for a given source sentence. If the SMT system were perfect, then the translation output would be a perfectly valid reference translation. However, as it stands, it is a less useful reference translation since it is not fully correct. Obviously, the original reference is a good reference in that it is correct. However, it has no a priori likelihood of matching the translation output even if the output may be correct. Therefore, in this sense, the original reference is also not a very useful reference translation. The point of paraphrasing the original reference is to try and come up with more useful references that lie in this space of reference translations. If untargeted and targeted paraphrases of the original references are compared in the context of this picture, can be inferred the following.  X  X ntargeted paraphrasing results in reference points that are  X  X andom, X  that is, they are created by changing words and phrases in the original with no regard to the translation output. The only reason a new reference point is useful is due to the sheer number of changes: a large percentage of the words in the original reference are changed and some of them just happen to match the words in the translation output.  X  X argeted paraphrasing, on the other hand, is designed to produce reference points that are closer to the translation output, but at the same time do not sacrifice the meaning of the original reference. This form of paraphrasing comes closer to achiev-ing the true goal of using paraphrasing to create additional reference translations. With this picture in mind, the concept of  X  X istance X  in this space of reference transla-tions can be introduced. All the new reference points that are created via paraphrasing (untargeted or targeted) can be assumed to be at some distance from both the original reference and the translation output, that are themselves points in this space. Note that this space is more conceptual than Euclidean. Therefore, this proposed distance is only required to satisfy a simple mathematical requirement: a lower distance between two points should indicate that they are semantically closer and a larger value should indicate the opposite. We use TER as the distance measure between the points in this space.

Two such distances in this space of reference translations are most important: (1) the distance (in terms of TER) from the original reference ( d ref ), and (2) the distance (in terms of TER) from the MT output ( d mt ).

These two distances can be used to find the balance that is sought between the targeting and the self-paraphrasing. The nature of this balance must be such that many changes to the original reference are disallowed, any changes that are allowed should create new points in the reference space that are closer to the MT output. In terms of these two distances, this requirement can be stated as follows: the magnitude of the movement of the new reference point away from the original reference (i.e., the positive change in d ref ) should be approximately equal to the magnitude of the movement of the reference point towards the MT output (i.e., the negative change in d
The obvious search technique that can be applied to this problem is a grid search. For this search, the targeting feature weight is varied along one dimension and the self-paraphrasing bias along the other. For each pair of values, an n -best paraphrase list is generated and the difference D =| d mt  X  d ref | is computed. In this expression, d ref represents how much further away the new point in the reference space (as represented by the output of the paraphraser instantiated with that specific feature weight and that specific self-paraphrase bias) is from the original reference. Similarly, d mt represents how much the new point has moved closer to the translation output. As mentioned before, the ideal scenario would be that all movement away from the reference is converted to movement towards the MT output. Therefore, the optimal point on the grid would be one where the difference D is closest to zero, with the additional constraint that d ref and d mt are sufficiently large for effective paraphrasing.

Figure 8 shows the grid search process for Chinese. For each point [ p ,w ] on the grid X  X  specific targeted paraphraser configuration with -w as the targeting feature weight and p as the self-paraphrasing bias X  D is computed over the paraphrase n -best list for 100 randomly chosen sentences from the NIST MT03 dataset. Technically speak-ing, the point on the grid with the lowest D is ( 50, 10 ) . However, that point is not ideal since the targeted paraphrases produced with that configuration will hardly be any different from the original references themselves (as indicated by d ref ) and will also not be targeted enough to the translation output (as indicated by d mt ). The ideal point on the grid that matches our grid search criterion and is truly likely to create lexically different targeted paraphrases is, instead, ( 25, 14 ) . At this point, all the pieces are available for incorporating the notion of targeting into the sentential paraphraser: a reasonably good implementation of the targeting feature, the self-paraphrase biasing mechanism required to offset any systematic bias that may result from using targeted references, and a technique that finds the right balance between these two opposing mechanisms. All that is required now is to put all of these pieces together to achieve improved parameter tuning.

Before the actual tuning process is discussed, it is important to mention the stages of the pipeline that need to be completed before the paraphraser can be used in tuning. First, five sets of paraphrase rules are generated from the parallel corpora by using the pivoting process; one each for the 5 self-paraphrase bias values of 5%, 10%, 15%, 25%, 40%, and 50%. A random selection of 100 sentences is made from the set that is to be used for SMT parameter tuning (heretofore T ). The grid search process is then carried out, as described in the previous section, to determine the optimal combination of the targeting feature weight and the self-paraphrasing bias. The configuration for the paraphraser is now fully determined. The resulting targeted paraphraser can now be used for SMT parameter tuning.

The actual setup is shown in Figure 9. During the first iteration of tuning, the source sentences from T are translated with an SMT decoder (whose weights have been tuned with just the original human reference) to produce an n -best list of translation hy-potheses. Each hypothesis is then used as the target to produce an n -best list of tar-geted paraphrases for the corresponding original reference. At this point, rather then choosing the 1-best targeted paraphrases from this list, a reranking process is applied that reranks the various hypotheses in the n -best list, using some additional features. One of these features is the probability score assigned to each targeted paraphrase hypothesis by a higher order X  X nd thus, more informative X  n -gram language model (5-gram). Usually such higher-order language models are used for reranking an n -best list rather than during the actual decoder search due to more demanding memory requirements. The other feature used by the reranker is the Word Error Rate (WER) between the target (the specific translation hypothesis) and the paraphrase hypoth-esis. 13 The reranking process can help by moving the targeted paraphrases that are both more fluent (and, possibly, more meaningful) and better targeted to the top of the n -best list. Once reranking is done, the 1-best targeted paraphrase is extracted from the reranked n -best list. This targeted paraphrase is then combined with the original reference and this pair now represents the new set of references for that spe-cific translation hypothesis. The SMT parameter tuning algorithm will now use this new set of references in its search process. Although Figure 9 only focuses on a single source sentence and a single translation hypothesis, new sets of references are actually generated for each translation hypothesis of each source sentence. Furthermore, this entire process is repeated for each iteration of the tuning process with the learned parameters in iteration k feeding forward into iteration ( k + 1). Generally, about 6 X 7 iterations of tuning are used. At the end of the last iteration, the learned parameters are taken and used to decode a validation set which is then scored against its own set of human-authored references.

Generally, the complete process would take an inordinately long time X 3 weeks X  X o finish since the paraphraser needs to run for every single translation hypothesis. How-ever, it was factored to run efficiently on a computer cluster containing several hundred nodes and only takes about 36 hours to complete 7 iterations of tuning, decoding, and scoring the validation set at the end. In this section, we present results from experiments that use the targeted paraphraser to create additional references for parameter tuning. These results are then compared to results from previous experiments that used either just the original human reference or additional references created by the untargeted paraphraser. Just as in Section 3, we use both automated metrics and human judgments as part of our results.

Figure 10 shows the BLEU and TER results for the validation sets for each of the four language pairs. The targeted paraphraser has a much better behavior than the untargeted paraphraser; it provides substantially larger performance gains as more paraphrases are added. Figure 11 shows the results for the human judgment experiments for these languages as conducted on Amazon Mechanical Turk. These results confirm that the targeted paraphrases are more useful for SMT parameter tuning than the untargeted paraphrases.

We also show example translations in Figures 12 and 13 in the following for ran-domly chosen French and German sentences as output by the SMT system using tar-geted paraphrases (TRG). We compare these translations to those produced by: (a) the baseline SMT system using just the single human-authored reference for parameter tuning (BSN) and, (b) the SMT system using the human reference and its 1-best un-targeted paraphrase (UNT). We also indicate the translation that was preferred by the Turkers. This figure illustrates the improved translation quality obtained by us-ing targeted paraphrases for SMT parameter tuning. Note that we chose a different set of sentences for the TRG-BSN comparison and a different set of sentences for the TRG-UNT comparison. In this section, we attempt to provide a more intuitive explanation of why targeted paraphrases work better than untargeted paraphrases for the purpose of parameter tuning. Note that the untargeted paraphraser is free to make as many changes to the original reference as it wants. The primary reason that the 1-best untargeted paraphrase helps tuning is the sheer lexical diversity: it contains a large number of changes and some of these changes just happen to match the translation output. However, as one goes down the paraphrase n -best list and more and more untargeted paraphrases are used as references, such fortuitous matches become less and less likely and noise starts to take over. However, the main problem with the untargeted paraphraser is not just that it makes too many changes. The problem is that it makes too many potentially useless changes, that is, it replaces n-grams in the original reference with other n-grams that have a small a priori likelihood of matching the translation output. 14
One possible correction to this behavior is to just use a self-paraphrase bias and simply reduce the probability of making making any changes to the original reference. However, this is clearly not useful because it does not alter the proportion of useful to useless changes. Instead, the right solution must be to increase the number of useful changes made to the original reference where and that is precisely what the targeted paraphraser is designed to do. The best way to understand the interaction between the self-paraphrase bias and the targeting feature is to imagine the analogy with the HTER computation, a process the targeted paraphraser is designed to emulate. The goal for HTER is to make the smallest number of (semantically equivalent) changes such that the reference is closer to the translation output. Note that if a human were creating the targeted reference (as is done for HTER computation), any explicit self-paraphrase bias would be unnecessary. In this section, we relate our research to two other research efforts. First, the idea of using the translation output to influence the reference has also been explored by Kauchak and Barzilay [2006]. However, their work differs significantly from the ideas presented here. One difference is that they create one paraphrase for the sole purpose of obtaining a more informative automatic evaluation score for the final translation out-put of an already tuned SMT system. We create multiple paraphrases, for the purpose of addressing reference sparsity in the SMT parameter tuning process. Another differ-ence is that, although used for evaluating SMT output, their paraphrasing technique relies on machinery entirely unrelated to the translation. They paraphrase words in the reference by replacing them with synonyms from WordNet that might occur in the translation output. In contrast, we create a fully data-driven sentential paraphraser entirely from SMT machinery. Finally, the work of Kauchak and Barzilay [2006] shows that, by using this alternative reference in place of the original human reference for computing BLEU, better correlation with human judgments is obtained. The human judgments they used are manually assigned ratings on a 1-to-5 scale reflecting only the adequacy of the translation output but disregarding its fluency. We show that by using the targeted sentential paraphraser in addition to the human reference, parameter tuning can be improved significantly as measured by both automatic metrics as well as human preference judgments. Past experience with annotations of human judgments of SMT output has shown that human raters have difficulty in consistently assigning absolute scores X  X uch as those for adequacy X  X o MT system output, due to the large number of possibly correct translations. Callison-Burch et al. [2008a] showed that preference judgments are considerably easier to make and, therefore, more reliable.
More recently, researchers have demonstrated the feasibility of human-in-the-loop tuning of SMT parameters [Zaidan and Callison-Burch 2009]. This idea is related to our work since it is concerned with the same stage of the SMT pipeline: parameter tuning. Nonetheless, the motivation for their work is derived from a different, extrinsic problem associated with the SMT parameter tuning process rather than the intrinsic problem of reference sparsity. Parameters of most SMT systems are tuned using BLEU. However, when evaluating the translations produced by these systems, a recent trend is to use a metric with a human component like HTER. Therefore, the authors propose a new metric, Ratio of Yes nodes in the Parse Tree (RYPT), which takes human judgments into account thereby lengthening the tuning process and requiring significantly more human effort. A mitigating factor is that the metric only requires human input to build a database that can be reused over and over again, hence eliminating the need for human input at tuning time. The authors show this metric to be a better predictor of human judgment of translation quality as compared to BLEU. Amazon Mechanical Turk is used to create the aforesaid database in a cost-effective manner.

Another alternate view that deserves mention is that of using a different MT metric for tuning; one that has an inherent notion of semantic equivalence such as METEOR [Lavie and Agarwal 2007] or TERp [Snover et al. 2009]. Using one of these metrics could alleviate the effects of reference sparsity and, as such, they are being increas-ingly employed for MT evaluation. On the other hand, BLEU still remains the most commonly accepted evaluation metric and, therefore, the best translation performance is achieved by using BLEU for parameter tuning as well. In addition, tuning with METEOR or TERp is accompanied by issues that need to be worked out before they can be used as replacements for BLEU. In our previously published research, we showed that: (a) it is possible to build a general sentential paraphraser architecture that is built entirely using bilingual SMT machinery and (b) the same paraphraser can be used to address the reference sparsity problem that afflicts SMT parameter tuning.

In this article, we presented results of our previous solution for three additional source languages including results in terms of human judgments. The new results confirmed our previously published findings. However, the primary contribution of this article is a novel modification to our paraphraser architecture that addresses all the shortcomings of our previous reference sparsity solution and yields much larger, and statistically significant, improvements in translation quality as measured by both automated MT evaluation metrics as well as human preference judgments.
 The electronic appendix can be accessed in the ACM digital library.

