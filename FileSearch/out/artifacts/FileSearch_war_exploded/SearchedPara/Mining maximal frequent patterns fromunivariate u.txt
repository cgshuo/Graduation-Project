 Department of Information Management, National Dong Hwa University, No. 1, Sec. 2, Da Hsueh Road, Hualien, Taiwan Tel.: +886 3 863 3116; Fax: +886 3 863 3100; E-mail: daxliu@mail.ndhu.edu.tw 1. Introduction
Frequent pattern mining plays an important role in the data mining area. Recent research interest in frequent pattern mining has shifted from mining precise data to mining uncertain data. With precise data, items are either present in, or absent from, a transaction ( Boolean data mining ), or each attribute of a transaction is associated with a quantitative value ( quantitative data mining ). In contrast, items or values of attributes are not definitely recorded in uncertain data.

Three types of uncertain data have been studied for mining frequent patterns in the literature: 1) uni-variate uncertain data [22,23]; 2) itemset uncertain data [8,9,17,18]; and 3) tuple uncertain data [25]. Univariate uncertain data refers to cases where each attribute in a transaction is associated with a quan-titative interval and a probability density function, the latter of which assigns a probability to each value in the interval. Itemset uncertain data, on the other hand, have an existential probability for each item in a transaction, which indicates the probability that the item exists. For tuple uncertain data, each transac-tion (tuple) is associated with a probability indicating the possibility of its existence. In this article, we propose three algorithms for mining maximal frequent patterns from univariate uncertain data.
More and more data sources are recording univariate uncertain data. For example, a low sensitivity sensor used to record atmospheric pollution may record a quantitative interval, instead of a precise value, to indicate the amounts of suspended particulates at 06:00 every day. Then, a probability density function is explicitly or implicitly assigned to the interval to indicate the possibility that each value exists in the quantitative interval. Another example is a network monitoring system that records a quantitative interval for network traffic flow every hour, with a probability density function indicating the possibility that each value exists in the interval. Figure 1(a) shows an example of a database containing three transactions. A quantitative interval is recorded for each of the two attributes in a transaction, namely, suspended particulates and sulfur dioxide, denoted as A 1 and A 2 respectively. The probability density function for each quantitative inte rval can be assigned according to the obser ved status, or simply as a uniform or a normal distribution. A pattern of univariate uncertain data such as [ A 1 :[13, 15], A 2 :[52, 54]] is called a U2 pattern , where the lower bound and upper bound of A 1  X  X  interval are 13 and 15 respectively. Mining frequent patterns from univariate uncertain data has been addressed in [22], where the retrieved patterns are called frequent U2 patterns . However, when a database is very dense and/or the minimum support is low, the number of all frequent U2 patterns is usually very large. A frequent U2 pattern with n attributes name a subset as an across-attribute reduction ; please refer to Definition 6 in Section 3). Returning only the maximal frequent U2 patterns is usually more acceptable to users, as this reduces both the number of patterns returned and the amount of memory required for storing them. A maximal frequent U2 pattern is a frequent U2 pattern without any frequent superset. The full set of frequent U2 patterns can be generated from the set of maximal frequent U2 patterns. Therefore, we propose mining maximal frequent U2 patterns. For example, in Fig. 1(a), three frequent U2 patterns exist if the minimum support pattern, but the first two are not. The first two can be inferred from the third because of the downward closure property, i.e., the subsets of a frequent pattern are also frequent.

The key contributions of this research are as follows. First, to the best of our knowledge, this is the first study on retrieving maximal frequent U2 patterns from univariate uncertain data. Second, we propose three algorithms, each of which has different properties from the others and excels at handling different kinds of datasets. Third, we propose integrating the base intervals, which are atomic sub-intervals in each attribute, into the three mining algorithms. This facilitates the retrieval of maximal frequent U2 patterns. Fourth, comprehensive experiments are conducted to compare the performance of the proposed algo-rithms against each other and against two other compared algorithms. Fifth, we report some interesting maximal frequent U2 patterns discovered in two real datasets.

The remainder of this paper is structured as follows. Section 2 contains a review of the literature on mining uncertain data and mining maximal frequent patterns. In Section 3, we define some key terms used throughout the paper. We discuss the proposed algorithms in detail in Section 4. In Section 5, we present the experiment results. Section 6 contains some concluding remarks and future work. 2. Literature review
We review the methods for mining maximal frequent patterns and for mining frequent patterns from uncertain data in Sections 2.1 and 2.2 respectively. A summary is given in Section 2.3. 2.1. Maximal frequent pattern mining
Zaki et al. [28] proposed the MaxEclat and the MaxClique algorithms. Both obtain supersets of max-imal frequent patterns. The former derives less accurate results and requires less computation time than the latter. Lin and Kedem [21] proposed the Pincer-Search algorithm, which constructs candidate pat-terns in a bottom-up manner, while also performing a top-down search to maintain a candidate set of maximal frequent patterns. Bayardo [5] used the breadth-first search strategy for traversing a pattern tree . A pattern tree contains all possible patterns in a dataset. The designed method, MaxMiner, prunes candidate patterns by using subset infrequency pruning and superset frequency pruning. Agarwal et al. [3] used the depth-first search strategy and the breadth-first search strategy at the same time to tra-verse the pattern tree. The transactions are transformed into the bitstring horizontal data format. Their proposed method is called DepthProject algorithm. The MAFIA algorithm [7] proposed by Burdick et al. utilizes the bitmap vertical data format. It uses the depth-first search strategy and three pruning strategies, namely, PEP, HFUT, and HUTMFI. The GenMax algorithm [11] is similar to the MaxMiner algorithm. It uses the tid-list instead of the bitmap used by MAFIA to store the transactions. It also constructs a local set of found maximal frequent patterns to accelerate the mining process. Zou et al. [29] proposed the SmartMiner algorithm, which utilizes the tail information of a node in the pattern tree to choose the next node to explore in the depth-first mining process. Liu et al. [24] proposed the AFOPT algorithm, which uses the AFOPT-tree combined with superset frequency pruning and the lookahead technique to derive maximal frequent patterns. Later, Grahne and Zhu [12,13] proposed the FPmax and the FPmax* algorithms. Both algorithms use the FP-tree [16]. The FPmax* improved on the FPmax by incorporating the FP-Array technique and the conditional MFI-tree technique. The former technique reduces the time required for traversing the FP-tree, and the latter technique accelerates the process of comparing the candidate patterns with the maximal frequent patterns found up to a given point in time. Li et al. [20] proposed the DSM-MFI algorithm for mining maximal frequent patterns from data streams. 2.2. Frequent pattern mining on uncertain data Mining frequent patterns from three types of uncertain data has been addressed in the literature. Liu [22] proposed the U2P-Miner algorithm, which adopts the pattern-growth methodology, to mine frequent U2 patterns from univariate uncertain data. Sun et al. [25] proposed two algorithms, p-Apriori and TODIS, to mine frequent patterns from tuple uncertain data by utilizing the bottom-up framework and the top-down framework respectively. Both algorithms can also be modified to mine maximal fre-quent patterns. There exist several methods for mining frequent patterns from itemset uncertain data. Generally, they can be classified as the Apriori-based [1,8,9], the FP-growth-based [17,18] and the H-mine-based methods [4]. Mining uncertain data is different from mining precise data in terms of comput-ing the pattern support. Owing to the uncertain nature of the former, computing the support of a pattern is not as simple as counting the number of transactions containing the pattern. Most methods compute the expected support of a pattern, which is the expected number of transactions containing the pattern. We elaborate on the expected support in Section 3. 2.3. Summary
With the exception of tuple uncertain data, mining maximal frequent patterns has not been addressed for the other two types of uncertain data. In this article, we propose three algorithms to retrieve maximal frequent U2 patterns from univariate uncertain data. Due to the difference properties between univariate uncertain data and tuple uncertain data, the methods for mining the latter cannot be applied to the former directly. Table 1 summarizes the characteristics of the proposed algorithms and the related methods. Each method is characterized by three properties: 1) the data source the method deals with; 2) the traversal strategy the method uses to traverse a pattern tree; and 3) the data format the method adopts to represent the data. The MU2P -Miner , U2GenMax ,and U2MAFIA are our proposed algorithms. The proposed algorithms fill an important gap in the research field by retrieving maximal frequent U2 patterns from univariate uncertain data. The properties of the proposed algorithms cover nearly all properties used in the existing methods except for the breadth-first search strategy and the horizontal data format, both of which have been shown to be not very effective compared to the depth-first search strategy and vertical data format in the literature [7,11]. 3. Preliminaries
Liu [22] proposed the base interval scheme to mine frequent U2 patterns. The base intervals are atomic sub-intervals formed by each pair of two consecutive bound values in each attribute. For instance, for A 1 in Fig. 1(a), the bound values are 13, 15, 30, and 31. This forms three base intervals: [13, 15], [15, 30], and [30, 31]. Figure 1(b) shows the base intervals of both attributes, where each base interval is given a serial number BI i , 1 i 5 . In this study, we also adopt the base interval scheme. Next, we explain several key terms used throughout the paper.
 Definition 1. An attribute A  X  X  interval I with a lower bound LB and an upper bound UB is denoted as A :[ LB , UB ]. A U2 pattern comprises one or more non-repeated attributes, each of which is associated UB ] can also be represented by using base intervals which the interval I covers.
 patterns, where each of the first two consists of one attribute and the last consists of two attributes. In Definition 2. Suppose an attribute A in a transaction T is associated with a quantitative interval I A and a probability density function P A .The existential probability of an interval I AS  X  I A is the possibility that the values in I AS appear in T . This is defined as the integral of the density over I AS , denoted by ExProb ( I AS ,T ).
 Example 2. The existential probability of an interval A 2 : [54, 78], i.e., BI 5 ,in T 3 in Fig. 1(a) is 0.923 ( = (78  X  54)/(78  X  52)).
 Definition 3. For a given U2 pattern Pat ,the expected support , i.e., the expected number of transac-tions that contain Pat in the database, is denoted as ExSupport ( Pat ). Let T Pat be the set of transactions containing Pat, and let an interval x of a transaction TRA i  X  T Pat correspond to one of the intervals in Pat . Thus, where | T Pat | denotes the number of transactions in T Pat .
 Example 3. Pattern [ BI 5 ] exists in all three transactions in Fig. 1(a). Therefore, the pattern X  X  expected support is 2.923 ( = 1.0 + 1.0 + 0.923).
 Definition 4. AU2patternis frequent if its expected support exceeds the minimum support specified by the user. Thus, a frequent U2 pattern represents the intervals where the actual values locate with high probability.
 Example 4. [ BI 5 ] is regarded as frequent when the minimum support is 1.0.
 Definition 5. A base interval and its existential probability form a base element .
 Example 5. The interval of A 1 in T 1 , A 1 : [15, 30], forms a base element { BI 2 ,1.0}.
 Definition 6. An across-attribute extension PatE of a U2 pattern Pat is a U2 pattern extending Pat by inserting into Pat one or more intervals belonging to attributes that do not appear in Pat . In contrast, Pat is an across-attribute reduction of PatE .
 not.
 Definition 7. A maximal frequent U2 pattern is a frequent U2 pattern without any frequent across-attribute extension.
 mum support is 2.
 Definition 8. Every possible combination of base intervals in each attribute is an artificial item , here-after referred to as Atem .AnAtem i formed by a set of base intervals, { BI j , BI j +1 ,..., BI j + n }, is In addition, AT i belongs to the attribute that this set of base intervals belongs to.
 Example 8. Figure 1(c) shows the Atems formed by using base intervals in Fig. 1(b). For instance, sented as [ AT 4 , AT 9 ].

We only combine successive base intervals to form Atems. That is, we do not combine disjunctive base intervals to form an Atem because this results in an Atem of disjunctive intervals. Therefore, we do not consider a U2 pattern that covers disjunctive intervals such as [ BI 1 , BI 3 ]. The rationale for not con-sidering these kinds of U2 patterns is that an attribute of real-world data usually occupies a continuous interval. 4. The proposed algorithms In this section, we introduce the three proposed algorithms, namely, MU2P-Miner (M aximal U2P-Miner ), U2GenMax (U nivariate U ncertain GenMax ), and U2MAFIA (U nivariate U ncertain MAFIA ) in Sections 4.1 X 4.3, respectively. In Section 4.4, we discuss the pruning techniques used for mining maximal frequent patterns. In the rest of this article, a frequent U2 pattern is abbreviated as FU2P and a maximal frequent U2 pattern is abbreviated as MFU2P . 4.1. The MU2P-Miner algorithm
The MU2P-Miner algorithm is modified from the U2P-Miner algorithm [22]. The U2P-Miner com-presses the transactions into a U2P-tree by decomposing each transaction into the base intervals con-tained in the transaction. For example, T 1 in Fig. 1(a) is transformed into { BI 2 , BI 5 }. Figure 2(a) shows the U2P-tree constructed by using the transactions in Fig. 1(a). Please refer to [22] for the details of constructing a U2P-tree. Figure 2(a) shows the two-level index structure of the U2P-tree in the left side of the tree. The first level of the index lists all the attributes, each of which has pointers pointing to its base intervals in the second level of the index. The second level of the index lists the pointers of all the base intervals that appear in the transactions. The pointers indicate the corresponding tree nodes. The base intervals of an attribute can be merged to form potential FU2Ps in the mining process, and the two-level index structure is used to trace the process. The U2P-tree and the list of base intervals can be constructed by scanning the transactions once. The tree node { BI 2 : 1.0}: (2, 2.0) means that the base element { BI 2 : 1.0} occurs twice and the partial expected support of this node is equal to 2.0. The partial expected support is equal to the value of the existential probability of the base element multiplied by its occurrence frequency.

The MU2P-Miner also constructs a U2P-tree. The MFU2Ps are retrieved by mining the U2P-tree. Take the U2P-tree in Fig. 2(a) for example. Mining the U2P-tree begins from the last base interval of the last ( = 1.0 + 0.923 + 1.0). The expected support of BI 5 represents the expected number of transactions containing BI 5 . Suppose the minimum support is 2.0, thus the U2 pattern [ BI 5 ] is frequent. Nevertheless, we cannot conclude [ BI 5 ] is a MFU2P at this point. This is because [ BI 5 ] may have frequent across-attribute extensions since there exists another attribute, i.e., A 1 , at a higher level than the attribute of or not. To do so, the conditional U2P-tree of [ BI 5 ] is constructed as shown in Fig. 2(b), where [ BI 5 ] is called the projected base of the conditional U2P-tree. To construct [ BI 5 ] X  X  conditional U2P-tree, the tree paths containing [ BI 5 ] in the original U2P-tree are retrieved, each of which serves as a conditional transaction. However, only the base intervals of A 1 are considered because the interval of A 2 is BI 5 . Note that the partial expected support of each tree node in the conditional U2P-tree is updated. For example, it is 1.923 for the tree node { BI 2 : 1.0}: (2, 1.923) in the conditional U2P-tree because the node originates from two tree paths in the original U2P-tree; while a path contributes (1.0  X  1.0), i.e., the partial expected support of BI 5 multiplied by the existential probability of BI 2 in this path and another path contributes (0.923  X  1.0). Mining the conditional U2P-tree also starts from the last base interval of A attribute reduction of any MFU2P or not, before computing its expected support because computing expected support usually requires more time than check of across-attribute reduction. The MU2P-Miner stores the found MFU2Ps in a tree structure, MFU2P-tree . To see whether [ BI 3 , BI 5 ] is an across-attribute reduction of any found MFU2P or not, it is compared with the MFU2Ps in the MFU2P-tree. At this point, there exist no MFU2Ps in the MFU2P-tree. Therefore, [ BI 3 , BI 5 ] is still a candidate for a MFU2P. Then we check whether [ BI 3 , BI 5 ] is frequent or not. However, it is not frequent because subsets of the base intervals of A 1 in the conditional U2P-tree. Only [ BI 2 , BI 5 ]isaMFU2P.Wedo MFU2P and is inserted into the MFU2P-tree. We elaborate on the MFU2P-tree later. After mining the patterns and evaluate them. None of them is a MFU2P. Although most of them are not across-attribute across-attribute reduction of [ BI 2 , BI 5 ]. Therefore, its expected support is never computed because it is excluded before computing. The mining process terminates and [ BI 2 , BI 5 ] is returned.

A MFU2P-tree is similar to a FP-tree [16] in structure except that the MFU2P-tree does not record the number of occurrences for a tree node. To insert a MFU2P into a MFU2P-tree, the representation of MFU2P is converted by using Atems. The benefits of this conversion are in reducing the size of a MFU2P-tree and facilitating the search for a MFU2P. Inserting a MFU2P into a MFU2P-tree is identical to inserting a frequent pattern into a FP-tree. The order of Atems in a MFU2P follows a predefined or-der, e.g., the order of the Atems X  serial numbers. Each node of a MFU2P-tree contains an Atem. During the mining process, the MU2P-Miner maintains an array, MIndex , each element of which points to a MFU2P-tree X  X  node whose Atem is contained in the U2 pattern currently under examination. The MIn-dex is used to accelerate the search for a MFU2P in a MFU2P-tree. We use an example to demonstrate how to utilize a MIndex. Let a synthetic database (not the database in Fig. 1(a)) contain twelve Atems, i.e., AT i for 1 i 12. Let the three MFU2Ps that have been discovered in succession during the mining show the MFU2P-trees after inserting the first, the second, and the third MFU2P, respectively. Note that insertion of the second MFU2P does not generate the second child node of the root because the first and the second MFU2P have the same prefix, AT 1 . In these figures, we do not show the header table and the links between the Atems for ease of presentation. The MFU2P-tree also compresses the MFU2Ps. This accelerates the search for a MFU2P. Now, suppose we consider a U2 pattern [ AT 8 ] in the mining process. Before mining [ AT 8 ] X  X  conditional U2P-tree, we have the MIndex X  X  two elements point to the two occur-rences of AT 8 in the MFU2P-tree, which is shown in Fig. 3(d). Through the pointer in the MFU2P-tree X  X  header table, we can easily find AT 8  X  X  occurrences. Next, assume mining [ AT 8 ] X  X  conditional U2P-tree [ AT 5 , AT 8 ] X  X  conditional U2P-tree and mine it. Before mining, we update the MIndex by having another of MIndex X  X  elements point to the AT 5  X  X  occurrence in the tree paths pointed to by the first two MIndex X  X  elements, i.e., the elements pointing to AT 8 . Figure 3(e) shows the result. By doing so, we keep track of the occurrences of the U2 pattern currently being considered, i.e., [ AT 5 , AT 8 ], in the MFU2P-tree. Next, if we have to check whether [ AT 1 , AT 5 , AT 8 ] is an across-attribute reduction of any MFU2P during mining the [ AT 5 , AT 8 ] X  X  conditional U2P-tree, we only need to consider the tree path that contains [ AT 5 , to mine [ AT 6 , AT 8 ] X  X  conditional U2P-tree. Before that, the MIndex is updated by first invalidating the third element X  X  pointer, and then having it point to AT 6  X  X  occurrence in the MFU2P-tree. Figure 3(f) represents the result. This shows that the elements in the MIndex are reusable. The number of elements contained in the MIndex can be set as an arbitrary number before mining. If more elements are needed during the mining process, the MIndex can be extended dynamically. We present the MU2P-Miner al-gorithm in Fig. 4. Figure 5 shows the MU2PRunner procedure.

Line 4 in Fig. 4 shows the algorithm returns the set of MFU2Ps stored in the MFU2P-tree, where each tree path represents a MFU2P. In Fig. 5, a projected base is a candidate for a MFU2P if none of its across-attribute extensions is frequent; lines 17 X 21 in Fig. 5 deal with this situation. Each time we insert a MFU2P into the MFU2P-tree, the MIndex should be updated (lines 7 and 19 in Fig. 5). 4.2. The U2GenMax algorithm
The U2GenMax algorithm is modified from the GenMax algorithm. First, for each Atem, we construct a tid -list , which is a list recording the identifiers of the transactions that contain the Atem. Figures 6(a) 0.923, respectively. The expected support of an Atem i s the sum of the existential probabilities in the elements of the Atem X  X  tid-list. Therefore, the expected supports of AT 1 and AT 9 are 0.111 and 2.923 and (b). The partial expected support of transaction T j that appears in IS is the multiplication of the two the tid-list of a U2 pattern comprised of a U2 pattern P and an Atem AT is derived by repeating the above operation on the tid-lists of P and AT . For instance, let AT 10 belong to an attribute other than tid-lists of [ AT 1 , AT 9 ]and[ AT 10 ]. The number of elements contained in a tid-list is hereafter called the To mine MFU2Ps, the U2GenMax employs a depth-first search strategy to traverse the pattern tree. Figure 7 shows a complete pattern tree for univariate uncertain data. Suppose there exist two attributes, A results in an Atem and two base intervals result in three Atems. We use two Atems here for simplicity. Each node in the pattern tree contains a representative U2 pattern, which is called the head of the node. In addition, the tail of a node is a set of Atems, each of which can be combined with the head of the node to form a U2 pattern. In Fig. 7, a head is enclosed in square brackets and a tail is enclosed in braces. For A U2 pattern [ AT 1 , AT 3 ] with no other possible extensions. In this pattern tree, four Atems can be used to form U2 patterns in the root node; each path of the root selects an Atem to form a U2 pattern.
The mining process begins by retrieving all frequent Atems, i.e., the Atems whose expected supports exceed the minimum support, to serve as the initial tail (the tail in the root node). Then each Atem i in Atems whose attributes X  orders are higher than those of the Atems in the head; and 2) the Atems that are frequent when combined with the Atems in the head. Next, each Atem j in t i combines with h i to serve This process recursively proceeds. Constructing a tail by using the above two rules avoids traversing every node of the complete pattern tree, which accelerates the mining process. If a tail is empty, its head is a candidate for a MFU2P. Checking a candidate is done by comparing it with the currently found MFU2Ps. In order to accelerate the checking process, the U2GenMax generates a local set of MFU2Ps, LMFU2Ps , for the currently mined node. Each MFU2P in the LMFU2P contains the node X  X  head. In detail, mining the node with head [ AT i ], i 1, first constructs a local set of MFU2Ps, denoted as LM i , by gathering the MFU2Ps that contain [ AT i ] from all currently found MFU2Ps. Next, mining the node with head [ AT i , AT j ], j&gt;i , constructs another local set of MFU2Ps, LM j , by gathering the MFU2Ps that contain [ AT j ] from the MFU2Ps in the LM i . If we consider whether [ AT i , AT j , AT m ], m&gt;j ,is U2GenMax algorithm and U2GenMaxRunner procedure respectively.

When the NewHset is constructed in line 2 of Fig. 9, the tid-list of the NewHset is also constructed for computing expected supports in line 3. In line 3 of Fig. 9, Y . attr &gt;I . attr means the attribute order of Y is larger than the attribute order of I . In line 11 of Fig. 9, any new found MFU2P from a recursive call is incorporated in the current LMFU2Ps . 4.3. The U2MAFIA algorithm
The U2MAFIA algorithm is modified from the MAFIA algorithm. The U2MAFIA also uses Atems for mining. For each Atem, the U2MAFIA construct a bitmap . A bitmap is an array whose length equals the number of transactions. If an Atem appears in i th transaction, the i th element of its bitmap records the Atem X  X  existential probability in the i th transaction; otherwise, the i th element records zero. Fig-ures 10(a) and (b) show the bitmaps of Atems, AT 1 and AT 9 in Fig. 1, respectively. We can construct a bitmap for a pattern consisting of two Atems by setting the i th element to the multiplication of the two Atems X  i th element (1 i the number of transactions in the database) in their respective bitmaps. Figure 10(c) shows the bitmap of [ AT 1 , AT 9 ]. Let a U2 pattern Pat be comprised of a U2 pattern P and an Atem AT , we can repeat the above operation on the bitmaps of P and AT to derive the bitmap of Pat . The expected support of an Atem or a pattern is simply the sum of the elements in its bitmap. The mining process of the U2MAFIA algorithm is similar to the U2GenMax algorithm; however, the U2MAFIA algorithm does not construct local sets of MFU2Ps. The U2MAFIA algorithm is presented in Fig. 11. We construct a bitmap for each frequent Atem and then call U2MAFIARunner procedure. Figure 12 shows the U2MAFIARunner procedure. In steps 1 and 2 of the U2MAFIARunner procedure, each Atem in the tail is subsequently combined with the head to serve as a new head, if this combination is frequent. The bitmap of the new head is also constructed. A new tail is constructed by using the same two rules used in the U2GenMax algorithm. The new head NewHset becomes a candidate for a MFU2P if the new tail is empty; otherwise, the U2MAFIARunner procedure is called again.

Despite their similarities, the U2MAFIA and the U2GenMax algorithms excel in different circum-stances. Using bitmaps is preferable to using tid-lists when most of the patterns found in a dataset exist in many transactions. Let there be m transactions in a database, and a U2 pattern Pat is formed by com-bining a U2 pattern P and an Atem AT during the mining process. In theory, the time complexities for constructing the Pat  X  X  bitmap and tid-list should be the same, i.e., O( m ). In reality, when Pat appears in a large number of transactions, significantly longer time is required for constructing the tid-list than is re-quired for constructing the bitmap. This is because constructing Pat  X  X  tid-list requires searching P  X  X  and AT  X  X  tid-lists for elements with identical transaction identifiers, whereas constructing the bitmap does not incur this overhead. In addition, we often use the linked list data structure to implement a tid-list. During the construction, an element is dynamically produced and inserted into Pat  X  X  tid-list when we find two elements with identical transaction identifiers from P  X  X  and AT  X  X  tid-lists. This operation en-tails frequently requesting memory allocation for elements, which greatly hampers the efficiency of the algorithm. In contrast, only a single memory allocation is required for constructing Pat  X  X  bitmap, which allocates an array of m elements. Moreover, Pat  X  X  tid-list will consume more memory than Pat  X  X  bitmap when Pat appears in more than half of the transactions because an element in a tid-list has to record a transaction identifier in addition to an expected support. On the other hand, the local set of MFU2Ps is beneficial when the number of MFU2Ps is large. In Section 5, we present experiment results that show the circumstances under which the U2MAFIA and the U2GenMax excel, respectively. 4.4. Discussion on pruning techniques
The literature reports two pruning techniques to accelerate the mining process by pruning the pattern tree of precise data. A pattern tree of precise data is shown in Fig. 13, where a head is enclosed in square brackets and a tail is enclosed in braces. The first technique, subset infrequency pruning ,usesthe downward closure property to prune the pattern tree. That is, any pattern with an infrequent subset is pruned from the pattern tree; it is just ignored during the mining process. For instance, if pattern [ B ]is not frequent, its branch, [ B , C ] is pruned.

The second technique is superset frequency pruning . There are three types of superset frequency pruning discussed in the literature, namely, Parent Equivalence Pruning ( PEP ), Frequent Head Union Tail ( FHUT ), and HUTMFI . (1) PEP. Suppose there is a node in the pattern tree with head x . There is an item y in the node X  X  tail (2) FHUT. Suppose a node x exists in the pattern tree. If x  X  X  HUT (the union of x  X  X  head and x  X  X  tail) (3) HUTMFI. Suppose a node x exists in the pattern tree. If x  X  X  HUT (head union tail) is a subset of
HUTMFI is generally preferable to FHUT. This is because HUTMFI does not traverse the leftmost path of x , while FHUT does. Therefore, some computations can be skipped in the former.

Despite the foregoing, superset frequency pruning is not applicable to mining MFU2Ps. In univariate uncertain data, if an Atem y appears in each transaction containing a FU2P x , it is not necessarily true that ( x  X  y ) is also frequent. For instance, [ BI 2 ] is frequent in Fig. 1(a) if the minimum support is Actually, [ BI 2 , BI 5 ] X  X  expected support is only 2.76. Hence, PEP does not work. FHUT and HUTMFI require that every pattern in the subtree rooted at a node x is a subset of x  X  X  HUT. The pattern tree of univariate uncertain data does not possess this property. This is because the Atems belong to different attributes; the HUT of a node x is not a valid U2 pattern. In addition, the U2 pattern at the deepest node in x  X  X  leftmost path is not an across-attribute extension of all U2 patterns enumerated from x  X  X  subtree. Therefore, FHUT and HUTMFI cannot be used to prune the pattern tree of univariate uncertain data. In contrast, subset infrequency pruning is still useful for mining MFU2Ps.
 5. The experiments
We used two synthetic datasets and two real datasets to evaluate the performance of the proposed algorithms. The experiments were divided into three sets. The first set used the synthetic datasets of different average transaction length , i.e., average number of attributes included in a transaction, to eval-uate the proposed algorithms. The second experiment set evaluated the proposed algorithms on the real datasets. The third experiment set evaluated the scalability , i.e., the ability to handle large datasets, of the proposed algorithms, and used the synthetic datasets used in the first experiment setup. We used two compared algorithms in the first and second experiment setups: the na X ve Apriori algorithm and the na X ve U2P-Miner algorithm. All the experiments were performed on an IBM compatible PC with an In-tel Core i7 CPU (2.67 GHz) and 3 GB main memory, running Windows XP Professional. The algorithms were implemented using Microsoft Visual C ++ 2008. Sections 5.1 and 5.2 introduce the datasets and the compared algorithms respectively. Sections 5.3 X 5.5 present the three experiment sets, respectively. Section 5.6 summarizes the experiment results. We present some MFU2Ps which discovered from the two real datasets in Section 5.7. These MFU2Ps reveal the air quality and weather conditions in Taiwan. 5.1. The synthetic and real dataset
The procedure for generating the synthetic datasets is as follows. A transaction contains at most 15 attributes, i.e., the length of a transaction is at most 15. An interval of quantitative values between 0 and 511 is generated for each attribute. In addition, the probability density function over each interval is set as a uniform distribution. The number of transactions, i.e., the size of a dataset, is set at 100,000 for each synthetic dataset. We generated one hundred transactions to serve as the seeds of the MFU2Ps for each synthetic dataset. The length of each seed of the MFU2Ps in the SYN1 dataset is determined by using a normal distribution of mean equal to 3; while in the SYN2, we used a normal distribution of mean equal to 9. The number of instances of each seed of the MFU2Ps in the dataset is determined by randomly selecting a number between 100 and 1,000. Then, for each synthetic dataset, a set of additional transactions is generated to let the number of transactions in the dataset be 100,000 and the average transaction length is 6 in SYN1 and 12 in S YN2. The SYN1 dataset is sparse, while the SYN2 dataset is dense, which means the SYN1 dataset does not generate many FU2Ps, while the SYN2 dataset generates many, even at higher minimum supports.

The first real dataset, AirQuality, contains indices of the daily air quality in Taiwan in 2008, such as suspended particulates, sulfur dioxide, and nitrogen dioxide. The data was collected by the Taiwan Environmental Protection Administration and can be downloaded from the EPA website [31]. We se-lected five indices from the AirQuality dataset, namely, suspended particulates, sulfur dioxide, nitrogen dioxide, carbon monoxide, and ozone. According to [31], these are the key indices used to measure the level of air quality. For every observation station, the o riginal AirQuality dataset lists hourly readings for each index. However, to mine FU2Ps, we modify the dataset to obtain five intervals formed by the daily minimum and maximum values of the five indices at each observation station. The probability density function for each interval is set as a uniform distribution. There are 26,527 transactions in total.
The second real dataset, DY2009, contains a variety of data on daily weather conditions in Taiwan in 2009, including atmospheric pressure, temperature, and relative humidity readings. The data was col-lected by the Department of Atmospheric Science, National Taiwan University, and can be downloaded from the DBAR website [30]. For each transaction, we selected the following five attributes from the DY2009 dataset: atmospheric pressure at the observation stations, atmospheric pressure at sea level, tem-perature, vapor pressure, and relative humidity. We chose these attributes because the daily minimum and maximum of each attribute at every observation station are recorded in the original data. There-fore, the original dataset is reduced to a set of transactions, each of which contains five intervals that indicate the daily minimum and maximum values of the five attributes with respect to an observation station. There are 8,187 transactions in the DY2009 dataset. In addition, the probability density function associated with each interval is set as a uniform distribution.

Table 2 presents the characteristics of the four datasets.  X  X verage number of elements X  lists the av-erage number of elements in Atems X  tid-lists in the four datasets, respectively. This shows the Atems of the AirQuality dataset have much longer tid-lists than the Atems in other three datasets.  X  X parse-ness X  indicates the ranks showing the relative sparseness of the four datasets:  X  X  X  means the sparsest and  X  X V X  means the densest. Therefore, the SYN1 dataset is the sparsest dataset and the SYN2 dataset is the densest dataset.  X  X ompressibility X  indicates the ranks showing the relative compressibility of the U2P-trees constructed by using four datasets:  X  X  X  means the most compact U2P-tree and  X  X V X  means the loosest U2P-tree. A U2P-tree has high compressibility when transactions in the underlying dataset have common prefixes. The U2P-tree constructed by using the SYN1 dataset compresses the dataset most, while the U2P-tree derived by using the DY2009 dataset does not compress the dataset well. The two real datasets do not have values in terms of average length of the seeds of the MFU2Ps because they are not synthetic datasets. In addition, there exist no missing values and noise in each dataset. 5.2. The compared algorithms
The na X ve Apriori algorithm first discovers all FU2Ps by treating Atems as items. Calculating the existential probability of an item in a transaction involves computing the integral over the range cov-ered by the base intervals of the item. In iteration k , candidate k -itemsets are formed by using large ( k  X  1 )-itemsets, i.e., frequent patterns. The expected support of a k -itemset is derived by scanning the database once. An itemset does not contain more than two items of an attribute. After discovering the complete set of FUPs, a post-processing procedure is applied to the complete set of FU2Ps to derive the MFUPs. The na X ve U2P-Miner algorithm also discovers the complete set of FU2Ps first by using the U2P-Miner algorithm, and then the post-processing procedure is used to derive the MFU2Ps. Figure 14 shows the post-processing procedure used in both compared algorithms. In Fig. 14, MaxLen is the max-imum lengths of the discovered FU2Ps. The length of a FU2P is the number of attributes contained in the FU2P. 5.3. The first experiment set In this experiment set, we evaluated the proposed and compared algorithms on the synthetic datasets. Figures 15(a) and (b) show the runtimes (in seconds) on the SYN1 dataset at high and low minimum supports, respectively. It should be noted that the runtimes of the na X ve Apriori algorithm at the minimum support of 1% in Fig. 15(a) and at all minimum supports in Fig. 15(b) are not shown because they are much longer than the runtimes of the other algorithms. Showing those runtimes in the figures would cause the lines of the other algorithms to overlap with each other. For the minimum supports larger than 1%, the three proposed algorithms perform sim ilarly, owing to the very small numbers of FU2Ps and MFU2Ps. When the minimum support is lower than or equal to 1%, the U2GenMax outperforms the other algorithms. The MU2P-Miner is slower than the U2GenMax because the time required for constructing U2P-trees dominates the total mining time when the dataset is sparse. The U2MAFIA becomes slower when minimum support gets lower, because it requires a lot of runtime for constructing bitmaps. The na X ve U2P-Miner is slower than the MU2P-Miner because of the post-processing procedure of the former. The na X ve Apriori requires much longer runtime than the other algorithms because of its breadth-first traversal strategy and the need to compute patterns X  expected supports (by scanning the original dataset).

Figures 16(a) and (b) present the experimental results on the SYN2 dataset at high and low minimum support, respectively. In order to show the effect of the local sets of MFU2Ps under dense datasets, we also used a variant of U2GenMax that compares a candidate for a MFU2P with the full set of found MFU2Ps. In the figures, U2GenMaxW represents the U2GenMax that uses the local set of MFU2Ps during the mining process; U2GenMaxWO represents the U2GenMax that does not use the local set of MFU2Ps. Once again, the na X ve Apriori algorithm X  X  runtimes are only partially shown because they are so much longer than those of the other algorithms. The MU2P-Miner gains an advantage because of the density of the SYN2 dataset and the U2P-tree, which compresses the transactions in a compact tree structure, and the MU2P-tree. Therefore, the MU2P-Miner outperforms the other algorithms, as shown in both figures. The na X ve U2P-Miner also benefits from the U2P-tree such that it performs better than the U2GenMaxW, U2GenMaxWO, and U2MAFIA at low minimum supports. In Fig. 16(a), the U2GenMaxW and U2GenMaxWO perform nearly the same. This shows that the use of local sets of MFU2Ps only helps slightly at high minimum supports. In contrast, the runtime differences between the U2GenMaxW and U2GenMaxWO are obvious at low minimum supports, as shown in Fig. 16(b), where the local sets of MFU2Ps greatly reduce the number of MFU2Ps required to be compared. The MAFIA is comparable to the U2GenMax when minimum support is higher than 2.5%, but the runtime becomes much longer in Fig. 16(b) because the MAFIA lacks the local sets of MFU2Ps.

We do not present the runtimes derived by applying the U2GenMaxWO to the SYN1 dataset in Figs 15(a) and (b). This is because the runtime differences between the U2GenMaxW and U2GenMaxWO are not very significant at most minimum supports, except for very low ones. We omit these statistics in Figs 15(a) and (b) for ease of presentation.
 at different minimum supports on the SYN1 and the SYN2 datasets respectively. When the minimum support is high, there are not many long FU2Ps in a sparse dataset. Therefore, in Fig. 17(a), the R MF is near to 1 when the minimum support is at 3%. As the minimum support gets lower, the R MF drops. Only approximately half of the number of FU2Ps are returned when the minimum support equals 0.7%. 5.4. The second experiment set In this section, we present the experiment results on the AirQuality and the DY2009 datasets. The AirQuality dataset is denser than the SYN1 dataset, but sparser than the DY2009 dataset, while the DY2009 dataset is sparser than the SYN2 dataset. Figures 18(a) and (b) show the runtimes on the AirQuality dataset at high and low minimum supports, respectively. The U2MAFIA performs better than the U2GenMaxW and U2GenMaxWO at almost all minimum supports, and better than the MU2P-Miner at high minimum supports. The U2MAFIA X  X  good performance benefits from a characteristic of the AirQuality dataset: most of the Atems in this dataset appear in many transactions, which results in many lengthy tid-lists. This benefits the U2MAFIA, but results in comparatively poorer performance by the U2GenMaxW and U2GenMaxWO. The MU2P-Miner runs slower than the other two proposed algorithms at high minimum supports because it spends a lot of time constructing the U2P-tree, which dominates the total mining time when the number of FU2Ps and MFU2Ps are relatively small. However, the MU2P-Miner greatly outperforms the other algorithms when minimum support becomes low, due to its compression of the dataset and the MU2P-tree. The performance of the na X ve U2P-Miner deteri-orates when minimum support is low because of the increased FU2Ps and MFU2Ps. The na X ve Apriori algorithm is still not competitive, whatsoever.

To justify the negative influence of frequent-memory-allocation in constructing a tid-list, we also modified the U2GenMax algorithm by using an array to implement a tid-list, instead of using a linked list. This means construction of a tid-list first involves allocating an array of m elements ( m is the number of transactions in the dataset). To insert an element to the tid-list is simply to copy the transaction identifier and the expected support of this element to the next empty element in the tid-list. The runtimes of this modified algorithm are also presented in Figs 18(a) and (b), and marked  X  X 2GenMaxArray X . In both figures, the U2GenMaxArray runs faster than the U2MAFIA, especially at minimum support lower than 2%. This is because the advantage of constructing a bitmap is neutralized, and the U2GenMaxArray still uses local sets of MFU2Ps. Although the U2GenMaxArray represents a great improvement in terms of runtime, it requires more memory consumption. We do not provide the runtimes of the U2GenMaxArray in the other experiments, because using an array to implement a tid-list does not result in significant improvement in runtimes in the other experiments.

Figures 19(a) and (b) show the experiment results on the DY2009 dataset. The U2GenMaxW and the U2MAFIA outperform the MU2P-Miner at most minimum supports. When the minimum support becomes low, the U2GenMaxW runs faster than the U2MAFIA and the U2GenMaxWO because the U2GenMaxW maintains the local sets of MFU2Ps. The MU2P-Miner and the na X ve U2P-Miner do not perform well in the DY2009 dataset until the minimum support is below 0.3%. This is because most of the transactions in the DY2009 dataset do not share common prefixes. Therefore, the U2P-tree does not compress the DY2009 dataset as well as it compresses other datasets. This increases the runtime for constructing and traversing U2P-trees in the mining process. The na X ve Apriori performs badly on the DY2009 dataset. 5.5. The third experiment set
In this section, we present the scalabilities of the proposed algorithms. We generated two groups of different-sized synthetic datasets. The different-sized datasets in the first group were generated by using the same parameters as those used to generate the SYN1 dataset, while those in the second group were generated by using the same parameters as those used to generate the SYN2 dataset. Figures 20(a) and (b) show the runtimes of the three proposed algorithms in the two groups, respectively. The minimum support is set at 5%. The runtimes required by each algorithm in both groups increase linearly as the size of the dataset becomes larger. The MU2P-Miner requires less time than other two algorithms, in all cases. The U2GenMax is slightly faster than the U2MAFIA. However, their lines nearly overlap in Fig. 20(a) because the runtime differences are very small. In Fig. 20(b), the runtime differences are larger. This experiment result shows that the MU2P-Miner is the most efficient and the most scalable among the three proposed algorithms. 5.6. Summary
We summarize the findings from the experiments as follows: (1) The MU2P-Miner algorithm excels in the dense dataset that can be compressed well by the U2P-(2) The U2GenMax algorithm performs well in sparse datasets and in datasets that cannot be com-(3) The U2MAFIA algorithm can compete with other algorithms at high minimum supports. It per-(4) The performance of the na X ve U2P-Miner algorithm is poor because a large number of FU2Ps are (5) Using a local set of MFU2Ps or a MFU2P-tree accelerates the mining process in a dense dataset 5.7. The discovered maximal frequent U2 patterns
The following MFU2Ps derived from the AirQuality dataset show that the air quality in Taiwan is usu-ally good: [suspended particulates 17 to 24, sulfur dioxide 5.2 to 9.7, nitrogen dioxide 13.44 to 17.09]; [suspended particulates 3 to 10, sulfur dioxide 1.6 to 5.2, ozone 2.7 to 7.0]; and [suspended particulates 24 to 38, sulfur dioxide 1.6 to 5.2, nitrogen dioxide 21.33 to 25.18, ozone 17.3 to 27.4]. However, other MFU2Ps, such as [suspended particulates 95 to 121, sulfur dioxide 10.3 to 33.8], [suspended particu-lates 82 to 120, sulfur dioxide 17.3 to 34.5], [suspended particulates 86 to 141, sulfur dioxide 7.0 to 35.4], [suspended particulates 114 to 176, sulfur dioxide 8.3 to 30.5], and [suspended particulates 123 to 254, sulfur dioxide 11.0 to 47.4], show that the air quality sometimes gets worse; there are both a high concentration of suspended particulates and a high level of sulfur dioxide, at the same time. This reflects the influence of sand storms that originate in northwest China and affect Taiwan. These storms carry large amounts of sulfur dioxide; one of the most serious industrial pollutants in China.
In the DY2009 dataset, most MFU2Ps reveal that the weather in Taiwan is usually hot and wet at the same time. For example, the following MFU2Ps exist: [temperature 28.1 to 29.0, relative humidity 82 to 83]; [temperature 26.8 to 28.3, water vapor pressure 28.9 to 30.1, relative humidity 77 to 82]; and [atmospheric pressure at the observation stations 1006.8 to 1008.6, temperature 28.1 to 32.1, relative humidity 80 to 84]. In addition, MFU2Ps such as [temperature 15.2 to 21.3, relative humidity 75 to 78] show that Taiwan X  X  winter weather is also wet. 6. Conclusions and future work
In this article, we propose three algorithms for mining MFU2Ps from univariate uncertain data. Re-trieving MFU2Ps provides a concise and informative mining result to users. In addition, a set of MFU2Ps provides a unique representation of the full set of FU2Ps. The full set of FU2Ps can be easily generated by using the set of MFU2Ps. The three proposed algorithms, the MU2P-Miner, the U2GenMax, and the U2MAFIA all adopt subset infrequency pruning to prune the pattern tree. In the MU2P-Miner, mining is performed by traversing a U2P-tree, which compresses the transactions. A MU2P-tree is constructed for storing MFU2Ps found during the mining process. A MIndex array is maintained to facilitate searching for a MFU2P in the MFU2P-tree. In the U2GenMax, a tid-list is constructed for each Atem. Mining is performed by using the depth-first search strategy. A local set of MFU2Ps is maintained to facilitate searching for a MFU2P. In the U2MAFIA, each Atem has a bitmap. Mining also adopts the depth-first search strategy. However, U2MAFIA does not maintain a local set of MFU2Ps. Different algorithms excel at different datasets and settings.

In future work, we will focus on two research avenues. First, we would like to extend this research to mining MFU2Ps from univariate uncertain data streams . Mining precise data streams has been ad-dressed in the literature [6,10,19,27]; however, mining univariate uncertain data streams has not been considered yet. In the real world, data usually appears to form continuous data streams, e.g., data streams of air quality readings. Thus, the ability to mine univariate uncertain data streams is in high demand. Sec-ond, we want to study how to cluster the derived FU2Ps. Except for mining maximal frequent patterns, researchers also proposed clustering frequent patterns to derive a concise representation set of frequent patterns [2,15,26]. We observed that the number of MFU2Ps may not have a large difference from the number of FU2Ps in some datasets. For instance, the R MF ratio of the DY2009 dataset is 0.81 when the minimum support is 0.2%. In contrast, at the same minimum support, the R MF ratios of the SYN1, SYN2, and AirQuality dataset are all lower than 0.5. By clustering the FU2Ps found in the DY2009 dataset, we expect to derive a more concise mining result that is comprised of cluster centers. Acknowledgement This research was supported in part by the National Science Council of Republic of China under Grant No. 101-2221-E-259-035-.
 References
