 S tatistical bilingual word alignment (Brown et al. 1993) is the base of most SMT systems . As co m-pared to si ngle -word alignment , m ulti -word align ment is more difficult to be identified . A l-though many methods were proposed to improve the quality of word alig n ment s ( Wu , 1997 ; Och and Ney , 2000 ; Marcu and Wong, 2002; Cherry and Lin , 2003 ; Liu et al., 2005; H u ang , 2 009 ) , the correlation of the words in multi -word alignment s is not fully co n sidered.

In phrase -based SMT ( Koehn et al. , 200 3 ) , the phrase boundary is usually de termined based on the bi -directional word alignment s . But as far as we know , few previous studie s exploit the coll o-cation relations of the words in a phrase. Some researches used soft syntactic constraints to pr e-dict whether source phrase can be translated t o-gether ( Marton and Resnik , 2008 ; Xiong et al., 200 9 ). H owever, the co n straints were learned f rom the parsed corpus , which is not available for many languages . 
In this paper, w e propose to use monolingual collocations to improve SMT . We first identify potentially collocated words and estimate coll o-cation probabilit ies from monolingual corpora usin g a Mon o lingual Word Alignment (MWA) method (Liu et al., 2009), which does not need any additional resource or linguistic preproces s-ing , and which outperforms previous methods on the same experimental data . The n the collocation information is employed to i mprove B i lingual W ord A lignment ( B WA) for various kinds of SMT systems and to i m prove phrase table for phrase -based SMT .

T o improve BWA , we re -estimate the alig n-ment probabilities by us ing the collocation pro b-abilit ies of words in the same cept. A cept is the set of source words that are connected to the same target word (Brown et al., 1993) . A n alignment b e tween a source multi -word cept and a target word is a ma n y -to -one multi -word alignment .

To improve phrase table, w e calculate phrase collocation probabi lities based on word colloc a-tion probabilities. Then the phrase collocation probabilities are used as additional fe a ture s in phrase -based SMT systems .

T he evaluation results show that the proposed method in this paper significantly improves mu l-ti -word alig nment, achieving a n absolute error rate reduction of 29 %. T he alignment improv e-ment r e sults in an improvement of 2.16 BLEU score on phrase -based SMT system and an i m-provement of 1.76 BLEU score on parsing -based SMT system. If we use phrase collocation prob a-bilities as add i tional feature s , the phrase -based SMT performance is further i m proved by 0. 24 BLEU score.

The paper is organized as follows: In s ection 2 , we introduce the collocation model based on the MWA method . In s ection 3 and 4 , we show how to impro ve the BWA method and the phrase t a-ble using collocation models respectively . We describe the experimental results in s ection 5, 6 and 7 . Las t ly, we conclude in s ection 8 . Collocation is generally defined as a group of words that occur to gether more often than by chance (McKeown and Radev, 2000) . A colloc a-tion is composed of two words occurring as e i-ther a consecutive word sequence or an inte r-rupted word sequence in sentences, such as "by acc i dent" or "take ... advice". In this paper, we u se the MWA method (Liu et al., 2009) for co l-location extraction. This method adapts the b i-lingual word alignment algorithm to monoli n gual scenario to extract collocations only from mon o-lingual cor p ora . A nd the experimental results in (Liu et al., 2009) sho wed that this method achieved higher precision and recall than pr e-vious methods on the same experimental data . 2.1 M onolingual word alignment The monolingual corpus is first replicated to generate a parallel corpus, where each sentence pair co n sists of t wo identical sentences in the same language. Then the monolingual word alignment algorithm is e m ployed to align the potentially collocated words in the monolingual sentences.
 According to Liu et al. (2009), we employ the MWA Model 3 (corresponding to IBM M odel 3) to calculate the probability of the monolingual word alignment s e quence , as shown in Eq. ( 1 ) . denotes the number of words that are align ed with the alignment set is d e noted as abilities are involved in this model: w ord coll o-cation probability ) | ( ty ) | (
I n the MWA method, t he similar algorithm to bilingual word alignment is used to estimate the parameters of the models , except that a word cannot be aligned to i tself . 
Figure 1 shows an example of the potentially co llocated word pairs aligned by the MWA m e-thod.
 2.2 Collocation probability Given the monolingual word aligned corpus, we calculate the frequency of two words aligned in the aligned words occurring only once. Then the probability for each aligned word pair is est i-mated as follo w s :
I n this paper, the words of collocation are symmetric and we do not determine which word is the head and which word is the modifier . T hus, the collocation probability of two words is d e-fined as the a v erage of both probabilities , as in Eq. (4).
If we have multiple monolingual corpora to e s timate the collocation probabilities, we interp o-lat e t he probabilities as shown in Eq. (5). the probabilities estimated on the k th corpus. W e use the collocation information to improve both one -directional and bi -directional bilingual word alignment s . T he alignment probabil ities are re -estimated by us ing the collocation probabil i-t ies of words in the same cept .
 3.1 Improv ing one -directional bilingual A ccording to the BWA method, g iven a bilingual alignment sequence A b e tween E and F can be obtained as in Eq. ( 6 ).
The method is implemented in a series of five models ( IBM Model s ). IBM Model 1 only e m-ploys the word translati on model to calc u late the probabilities of alignments. In IBM Model 2, both the word translation model and position di s-tribution model are used. IBM Model 3, 4 and 5 co nsider the fertility model in addition to t he word translation model and position distri bution model . And these three models are similar , e x-cept for the word di s tortion models.

O ne -to -one and many -to -one alignments could be produced by using IBM models . Although t he fertility model is used to restrict the number of source words in a ce p t and the position distortion model is used to describe the co r relation of the positions of the source words , the quality of many -to -one alignment s is lower than that of one -to -one alig n ments .

I ntuitively , the probability of the source words aligned to a target word is not only related to the fe r tility ability and their relative positions, but also related to lexical tokens of words , such as co m mon phrase or idiom . In this paper , w e use the coll oc ation probability of the source words in a cept to measure their co rrelation strength . G i v-collocation probability is ca l culated as in Eq. ( 7 ).
Here, the co l location probability of shown in Eq. (4 ). 
T hus, the collocation probab ility of the alig n-ment sequence of a sentence pair can be calc u-lated according to Eq. ( 8 ).
Based on maximum entropy framework, w e combine the collocation model and the B WA model to calculate the word alignment probabil i-ty of a sentence pair, as shown in Eq. ( 9 ).
Here, ) , , ( A E F h feature weights, respectively. We use two fe a-tures in this paper, namely alignment probabil i-ties and c ollocation probabilities .

T hus, we obtain the decision rule:
B ased on the GIZA++ package 1 , we impl e-mented a tool for the improved BWA method . W e first train IBM Model 4 and collocation model on bilingual corpus and mon olingual co r-pus respectively. Then we employ the hill -climbing algorithm ( Al -Onaizan et al., 1999) to search for the optimal alig n ment sequence of a given sentence pair, where the score of an alig n-ment sequence is calc u lated as in Eq. (1 0 ).
W e note that Eq . (8) only deals with many -to -one alignments , but the alignment sequence of a sentence pair also includes one -to -one alig n-ments. To calculat e the collocation probability of the alig n ment sequence, we should also consider the collocation pro b abilities of su ch one -to -one alignments. To solve this problem, we use the collocation probability of the whole source se n-tence, ) ( F r , as the collocation probability of one -word cept . 3.2 Improving bi -directional bilingual word In word alignment models implemented in G I-ZA++ , only one -to -one and many -to -one word alig n ment links can be found. Thus, some multi -word units cannot be correctly aligned. The symmetriz a tion method is used to effectively overcome this deficiency (Och and Ney, 2003). B i -dir ectional alignments are generally obtained from source -to -target alignments to -source alig n ments rules ( Koehn et al. , 200 5 ). T his method ignores the correlation of the words i n the same alig n-ment unit , so an alignment may include many unrelated words 2 , which influences the perfo r-mances of SMT systems.
I n order to solve the above problem, we inco r-porate the collocation probabilit ies into the bi -directional word alignment process .

Given alignment sets obtain the union cept can be a consecutive word sequence or an interrupted word s e quence .

F inally, the optimal alignments A between fo l lowing decision rule.
H ere, ) ( probabilit ies of the word s in the source language and target language respectively, which are ca l-culated by using Eq. ( 7 ). ) , ( word transl a tion probability that is calculated according to Eq. (1 2 ). these pro b abilities . and target -to -source translation probabilities trained from the word aligned bilingual co r pus. Phrase -based SMT system automatically extracts bilingual phrase pairs from the word aligned b i-lingual corpus. In such a system, a n idiomatic e x pression may be split into several fragments , a nd the phrases may include irrelevant words. I n this paper, we use the coll o cation probability to measure the possibility of words co m posing a phrase .

For each b ilingual phrase pair automatically extracted from word aligned corpus, we calculate the collocation probabilities of source phrase and targe t phrase respectively, according to Eq. (1 3 ). Additional monoli n gual word pair calcu lated according to Eq. (4 ). F or the phrase only including one word, we set a fixed co l location probability that is the average of the co llocation probabilit ies of the sentences on a develo p ment set. These collocation probabilities are incorporated in to the p hrase -based SMT sy s-tem as fe a tures. 5.1 E xperimental settings W e use a bilingual corpus, FBIS ( LDC2003E14 ) , to train the IBM model s. To train the coll o cation models , besides the monolingual parts of FBIS, we also employ some other large r Chinese and En g lish monolingual corpora , namely, Chinese Gigaword ( LDC2007T38 ), English Gigaword ( LDC2007T07 ) , UN corpus ( LDC 2004E12 ) , S i-norama corpus ( LDC2005T10 ) , as shown in T a-ble 1 .

Using these corpora, we got three kinds of co l-location models:
CM -1 : the training data is the additional m o-
CM -2 : the training data is either side of the b i-CM -3 : the interpolation of CM -1 and CM -2.
T o investigate the quality of the generated word alignment s, we randomly selected a subset from the bilingual corpus as test set , including 500 sentence pairs. T hen word alig n ments in the subset were manually labeled, r eferring to the guid e line of the Chinese -to -English alignment ( LDC2006E93 ), but we made some modific a-tion s for the guideline . For example, i f a prepos i-tion appears after a verb as a phrase aligned to one single word in the corresponding sentence, then they are glued t o gether.

T here are several different evaluation me tric s for word alignment (Ahrenberg et al., 2000). W e use precision (P), recall (R) and alignment error ratio (AE R ), which are sim i lar to those in Och and Ney (2000), except that we consider eac h alig n ment as a sure link.
W here, generated alignment s and the reference alig n-ments.

I n order t o tune the interpolation coefficients in Eq. (5) and the weights of the probabilities in Eq. (11) , we also manually labeled a develo p-ment set including 100 sentence pairs, in the same ma n ner as the test set. B y m inimizing the AER on the development set , the interpolation coefficients of the coll o cation probabilities on CM -1 and CM -2 were set to 0.1 and 0.9. An d t he weights of probabilities were set as 6 . 0 5.2 Evaluation results One -directional alignment results
To train a C hinese -to -E nglish SMT system, we need to perform both Chinese -to -Englis h and En g lish -to -Chinese word alignment. We only evaluate the English -to -Chinese word alignment here. G I ZA++ with the default settings is used as the baseline method . The evaluation results in Table 2 ind i cate that the performances of our methods on single word alig n ment s are close to that of the baseline method. For multi -word alignments, our methods significantly outpe r-form the baseline method in term s of both prec i-sion and recall, achieving up to 18% absolute error rate r e duction.

Although t he size of th e bilingual corpus is much smaller than that of additional monolingual corpora , our methods using CM -1 and CM -2 achieve comparable performances. It is because CM -2 and the BWA model are derived from the same r e source. By interpolat ing CM1 and CM2, i.e. CM -3, the error rate of multi -word alignment r e sults is further re d uced.

F igure 2 shows an example of word alignment results generated by the baseline method and the i m proved method using CM -3. In this example, our method successful ly identifies many -to -one a lig n ments such as " the people of the world  X  X  X  " . In our colloc a tion model, the collocation probability of "the people of the world" is much higher than that of "people world". A nd our m e-thod is also effective to prevent the unrelated words from being aligned. For example, in the baseline alig n ment "has made ... have  X  X  X  ", "have" and "has" are unrelated to the target word , while our method only gene r ated "made  X   X  ", this is because that the collocation probabil i-ties of "has/have" and "made" are much lower than that of the whole source se n tenc e.
 Bi -directional alignment results
We build a bi -directional alignment baseline in two steps: (1) GIZA++ i s u s ed to obtain the source -to -target and target -to -source alignments; (2) the bi -directional alignments are generated by using "grow -diag -final". We use the method s proposed in section 3 to replace the correspon d-ing steps in the baseline method. We evaluate three met h ods : 
W A -1 : one -directional alignment method pr o-
W A -2 : GIZA++ and the bi -directional bili n-W A -3 : both methods proposed in section 3.
Here, CM -3 is used in our methods. The r e-sults are shown in T a ble 3.

We can see that WA -1 achieves lower alig n-ment error rat e as compared to the base line m e-thod, sinc e the performance of the improved one -directional alignment method is better than that of GIZA++. This result indicate s that i m prov ing one -directional word alignment results in bi -directional word align ment improv e ment .
The results also show that t he AER o f W A -2 is lower than that of the baseline . T his is b e cause t he proposed bi -directional alignment m e thod can effectively recognize the correct alig n ments from the alignment union, by leveraging colloc a-tion probabilit ies of the words in the same cept.
O ur me thod using both methods proposed in section 3 produce s the best alignment perfo r-mance , achieving 11% absolute error rate redu c-tion.
 ferent bi -directional word alignments (Signif i-6.1 E xperimental settings We use FBIS corpus to train the Chinese -to -English SMT systems . Moses (Koehn et al., 2007) is used as the baseline phrase -based SMT system. We use SRI language modeling too l kit (Stolcke, 2002) to train a 5 -gram language model on the English sentences of FBIS cor pus . We use d the NIST MT -200 2 set as the development set and the NIST MT -200 4 test set as the test set. And Koehn's implementation of min i mum error rate training (Och, 2003) is used to tune the fe a ture weights on the development set.

We use BLEU (Papineni et al., 2002) as eva l-uation metrics . W e also calculate the statist i cal signif i cance differences between our method s and the baseline method by using paired boo t-strap re -sample method (Koehn, 2004). 6.2 Effect of improved word alignment on W e i nvestigate the effectiveness of the i m proved word alignments on the phrase -based SMT sy s-tem . The bi -directional alignments are obtain e d + Phrase c ollocation probability 3 0 . 47 + Phrase c ollocation probability our proposed methods (S ignificantly better than using the same methods as those shown in T a ble 3. Here, we investigate three different coll o cation models for translation quality improv e ment. T he results are shown in T a ble 4.

F rom the results of Table 4, i t can be seen that the systems using the improved bi -directional alignments achieve higher quality of transl a tion than the baseline system. If the same alignment method is used, the systems using CM -3 got th e highest BLEU scores. A nd if the same colloc a-tio n model is used, the systems using WA -3 achieved the higher scores. T hese results are consistent with the evaluations of word alig n-ments as shown in Tables 2 and 3. 6.3 Effect of phrase collocation probabil i-To investigate the effectiveness of the method p roposed in section 4, we only use the colloc a-tion mo d el CM -3 as described in section 5 .1 . T he results are shown in Table 5 . W hen the phrase co l location probabilities are incorporated into the SMT system, the translation quality is i m proved , achiev ing an ab solute improvement of 0.85 BLEU score . This result indicates that the coll o-cation probabilities of phrases are useful in d e-termining the boundary of phrase and predic t ing whether phrases should be translated together, which helps to improve the phrase -base d SMT perfo r mance.

F igure 3 shows an example : T1 is generated by the system where the phrase collocation pro b-abilities are used and T2 is generated by the baseline system. In this example, since the coll o-cation probability of "  X   X  X  " is much higher than that of "  X  X   X  ", our m e thod tends to split "  X   X  X   X  " into " (  X   X  X  ) (  X  ) " , rather than " (  X  ) (  X  X   X  ) " . For the phrase "  X  X  X   X  X  X  " in the source sentence, the collocation probability of the tran s lation "in order to avoid" is higher than that of the transl a tion "can we avoid". T hus, our method selects the former as the translation. A l t hough the phrase "  X  X  X   X  X  X   X  X  X   X  X  X   X   X  " in the source sentence has the same transl a-tion " We must adopt effective measures ", our method splits this phrase into two parts "  X  X  X   X   X  " and "  X  X  X   X  X  X   X  X  ", because two par t s have higher co l location probabilities than the whole phrase.

W e also investigate the performance of the system employing both the word alignment i m-prov e ment and phrase table improveme nt m e-thods. F rom the results in Table 5, i t can be seen that the quality of translation is future improved . A s compared with the baseline system , an abs o-lute improvement of 2.4 0 BLEU score is achieved. And this result is also better than the results s hown in Table 4 . W e also investigate the effectiveness of the i m-proved word alignments on the parsing -based SMT sys tem , Joshua (Li et al., 2009) . I n this sy s-tem, t he Hiero -style SCFG model is used ( Chiang , 2007 ) , wit hout syntactic information . The rules are extracted only based on the FBIS co r pus , where words are aligned by "MW -3 &amp; CM -3". And the la n guage model is the same as that in Moses. The feature weights are tuned on the d e velopment set using the minimum error ferent word alignments (Significantly better than rate training method. We use the same evaluation measure as describ ed in se c tion 6.1.
 The translation results on Joshua are shown in Table 6 . T he system using the improved word alignments achieves an absolute improvement of 1.76 BLEU score , which indicates that the i m-provements of word alignment s are also effe c tive to imp rove the performance of the parsing -based SMT sy s tems . We presented a novel method to use monoli n gual collocations to improve SMT. We first used the MWA method to identify potentially collocated words and estimate collocation probabilit ies only from monolingual corpora, no additional r e-source or linguistic preprocessing is needed. The n the collocation information was employed to improve BWA for various kinds of SMT sy s-tems and to i m prove phrase table for phrase -based SMT.

To improve BWA , we re -es timate the alig n-ment probabilities by us ing the collocation pro b-abilit ies of words in the same cept. To i m prove phrase table, w e calculate phrase collocation probabilities based on word collocation probabi l-ities. Then the phrase collocation probabil i ties a re used as additional feature s in phrase -based SMT systems .

T he evaluation results show ed that the pr o-posed method significantly improve d word alignment, achieving a n absolute error rate r e-duction of 29 % on multi -word alignment . The improved word alignment results in an improv e-ment of 2.16 BLEU score on a phrase -based SMT sy s tem and an improvement of 1.76 BLEU score on a par s ing -based SMT system. When we also use d phrase collocation probabilities as a d-d i tional feature s , the phrase -based SMT perfo r-mance is f i nally improved by 2 . 4 0 BLEU score as co m pared with the baseline system .

