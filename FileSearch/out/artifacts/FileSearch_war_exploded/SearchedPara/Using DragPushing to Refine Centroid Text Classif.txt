 We present a novel algorithm, DragPushing, for automatic text classification. Using a training data set, the algorithm first calculates the prototype vectors, or centroids, for each of the available document classes. Using misclassified examples, it then iteratively refines these centroids; by dragging the centroid of a correct class towards a misclassified example and in the same time pushing the centroid of an incorrect class away from the misclassified example. The algorithm is simple to implement and is computationally very efficient. Evaluation experiments conducted on two benchmark collections show that its classification accuracy is comparable to that of more complex methods, such as support vector machines (SVM). H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval-search process; I.2 [ Artificial Intelligence ]: Learning; I.5 [ Pattern Recognition ]: Applications Algorithms, Performance, Experimentation Text Classification, Information Retrieval, Machine Learning 
Centroid classifiers [1] provide a simple and efficient method for automatic document classification. In such classifiers, documents are first represented using the vector space model (VSM), where each document is considered to be a vector in term space. Based on a pre-labeled document collection, a prototype vector (centroid) is calculated for each class as the average vector of all documents belonging to that class. The class of an unlabelled document is then determined simply by assigning it to the class with the most similar centroid. 
The computational complexity of the learning phase of such centroid-based classifiers is linear in the number of documents and the number of terms in the training set. However their overall classification accuracy often suffers from what is known as an inductive bias or model misfit [2] that occurs when the vector representing a document is more similar to the centroid of a class other than the correct one. This typically occurs due to the large number of terms used in the VSM, and due to the fact that such terms are all weighted equally. In the remainder of this 
Initialization : for each category C i we calculate the summed denotes current iteration-step, i.e., the 0 th iteration-step. 
DragPushing : in each iteration, the centroids are used to classify all documents. If a document d labeled with a true class  X  A  X  is misclassified into class  X  B  X , DragPushing modifies the summed and normalized centroids of classes  X  A  X  and  X  B  X  using the following  X  X rag X  formulae (1-2) and  X  X ush X  formulae (3-4): where o denotes the o th iteration-step and l stands for feature index of document vectors and centroid vectors. Note that we employ |.| + to substitute the negative with zero since we found that nonnegative centroid performs better than real centroid in our experience. Obviously after the execution of  X  X rag X  and  X  X ush X  formulae, the similarity between document d and the centroid of class  X  A  X  will be enlarged while the similarity between document d and the centroid of class  X  B  X  will be reduced. In our evaluation experiments, we used two standard corpora: Reuter-21578 [3] and WebKB [4]. For Reuter-21578, we used a subset consisting of 10,346 documents and 92 categories. For WebKB, we used a subset containing 4,199 documents and four categories. The algorithms were coded in C++ and executed on a Pentium-4 machine with 2.0GHz CPUs. We set the Max_Iteration_Step in DragPushing to 5, and fixed both the drag_weight and push_weight at 1.0. For experiments involving SVM we employed SVMTorch [5]. 
We based our evaluations using best MicroF1 and MacroF1 measures [6]. DragPushing significantly outperforms Centroid and Winnow classifiers [7] on both corpora. On Reuter-21578, the performance of SVM is only about one percent higher than that of DragPushing. Our results indicate that DragPushing yields excellent performance approaching SVM, and offers faster execution times. 
