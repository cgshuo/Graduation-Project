 1. Introduction To be competitive, businesses need to help clients find quickly and accurately interesting products. Designing software for this task becomes important as on-line shopping often does away with salespersons and offers a limited view of the products to the prospective which makes automated recommendation systems possible. In a wider context, one of the of dynamic data and any process that can support these searches is valuable to the users.
Collaborative filtering systems are recommender systems where the recommendations are based on a database of user ratings as opposed to content-based recommender systems which are based on the characteristics of the objects to recommend. The basic principle behind rating some of the products or features they know, so that, in turn, they can get accurate recommendations. Content-based recommender systems tend to work well with objects where the content can be processed with some convenience such as text (Amrani et al. 2001, Salton and Buckley 1998). With other types of objects such as movies or books, it is not always easy to access the content on-line, and even if possible, automated content the user may simply not have enough information about the product or service required. Someone surfing on a e-commerce web site might not always have a specific request and the burden is on the web site to provide an interesting recommendation. In such cases and 130 LEMIRE if we can get some ratings from the users either explicitly or implicitly, we may prefer collaborative filtering may serve to help sort results.

However, one of the challenges we face is that most users rate only few objects and thus, we have to deal with sparse data (Ghahramani and Jordan 1994). In many information that must be matched. On the other hand, collaborative filtering has to deal with a severe lack of information and the information available is both imprecise and inaccurate. Thus, collaborative filtering is a prediction rather than a search problem.
 rithms in three classes depending on their query and update costs: learning-free, memory-based and model-based. Obviously, there might be many types of operations that could be described as an update or a query, but we focus our attention on adding a user and (query). We say that an operation whose complexity is independent of the number of users offers constant-time performance (with respect to the number of users). Essentially, the cheapest schemes are described as learning-free and have both constant-time updates and queries while schemes involving a comparison with users in the database are classified as memory-based and offer constant-time updates but linear-time queries, and finally the schemes requiring more than linear time learning or more sophisticated updates are said to classes of algorithms and others that would fit in more than one class.
 time irrespective of the current user and the prediction is written as corresponding to an item. For example, the simplest learning-free scheme is obtained when N received by item number k , and Prediction ( u ) = v (0) .

Memory-based collaborative filtering systems usually compute weighted averages over ing probabilistic ones (Pennock and Horvitz 1999). Generally, we can write a memory-based SCALE AND TRANSLATION INVARIANT 131 prediction as as we need to match the current user against the entire database each time. Memory-based systems can outperform a wide range of model-based systems (Breese et al. 1998, Pennock systems for benchmarking purposes. The main drawback of memory-based scheme is their users from the database (Yu et al. 2002, 2003) making memory-based systems more balanced in terms of update and query performance while preserving and even increasing slightly the accuracy. However, unlike learning-free and model-based schemes, memory-based systems a memory-based system cannot run conveniently on devices with very limited storage.
If all possible preference sets were equally likely, no prediction would be possible and are many hidden constraints and few remaining degrees of freedom which suggests making predictions based on a model. Model-based collaborative filtering systems extract from the database some key parameters and do not use the database directly to answer queries. Examples include Principal Components Analysis (PCA) (Goldberg et al. 2001), Factor Analysis (Canny 2002), Singular Value Decomposition (Drineas et al. 2002, Sarwar et al. 2000), Bayesian Networks (Breese et al. 1998), Item-Based models (Vucetic and Obradovic 2000, Sarwar et al. 2001) and Neural Networks (Billsus and Pazzani 1998). Model-based updating the database can be expensive as it may require up to a completely new learning phase. Another possible drawback is that most model-based systems assume a large database
One can test the accuracy of an algorithm by applying it on data where some of the ratings have been hidden. While results vary depending on the data set and the experimental pro-Fo re xample, with the EachMovie data set, the accuracy improvement in going from a naive proach is of no more than 17% (Canny 2002). Similarly, extensive work has been done to improve the Pearson correlation approach (Breese et al. 1998, Herlocker et al. 1999) and yet, accuracy improvements do not exceed 20%. The differences between inexpensive schemes and more sophisticated ones are even smaller when one upgrades simple averaging scheme to the Bias From Mean algorithm introduced by Herlocker et al. (1999). In the re-percentages are significant. 132 LEMIRE without measuring the practical usefulness of each axiom. They present four collaborative filtering properties: universal domain and minimal functionality, unanimity, independence of irrelevant alternatives, and scale invariance. Whereas scale invariance is a simple and compelling axiom, few scale invariant algorithms have been proposed. This paper investi-algorithms and propose novel variants that are scale invariant. Then, we show that the new algorithms perform better or as well as the old ones. 1.1. Structure and main results The paper is organized as follows. We first introduce the collaborative filtering problem, then present some of the most competitive schemes, introduce three types of scale and translation invariant collaborative filtering systems, and finally, we conclude with some e xperimental results on two significantly different data sets.

The main results of the paper are evidence that scale and translation invariance is an important property that can be used to improve existing schemes and a set of novel highly scalable algorithms with good performance. We show that by normalizing users with respect constant time performance for updates and queries. 1.2. Notation and terminology The variables m and n have special meaning consistent with other authors (Breese et al. 1998) and refer respectively to the number of users under consideration and to the number of items to be rated.

A norm  X  is typically defined as a non-negative real-valued function satisfying  X v = |  X  | v whenever  X  is a real number, x + y  X  x + y , and x = 0  X  x = 0. In some sense, the norm of an object measures its size .W e will abuse the terminology by dropping the condition that x + y  X  x + y whenever x + y is not defined.

Tw o norms  X  Norm 1 and  X  Norm 2 are equivalent if there exists positive numbers A , B  X  R such as R k , all norms are equivalent.
 SCALE AND TRANSLATION INVARIANT 133
Fo r the purpose of this paper, we define Lebesgue norms for p = 1 , 2 ,... as where the sum is over all indexes of x .W e define the norm so that (1 ,..., 1) l drawback that x l simpler. As examples, (1 , 2 , 0) l 1 . contribute to the norm value whereas for larger p  X  X  only the larger components contribute up to the point where only the very largest component matters. We have 2. Definitions Let  X  be an ordered set of n items labeled from 1 to n which we write  X  ={ 1 ,..., n } for as an e valuation and there is a one-to-one map between users and evaluations. Given an by this user. For the purpose of this paper, we assume that ratings are real numbers even typically much smaller than card (  X  ). Alternatively, u can be thought of as a incomplete On the other hand, the set of all possible evaluations is noted  X   X  . Note there may be some constraints on : for example that some items are rated by all users or that all users have rated at least a given number of items.
 an ew ev aluation w with, again, arbitrary numerous ratings over up to n items, we seek to find a complete evaluation w such that w and w are close and such that w agrees as much as possible with  X  .W e say that w is a prediction and we write w = P ( w ) where P is a function (called a predictor) from the space of all evaluations to the space of complete that this definition is not general since it excludes top-N algorithms (Karypis 2000). Definition 2.1 .A function P :  X  R n is called a predictor .
 to this process as a collaborative filtering system. 134 LEMIRE  X  to predictors.
 Given two numbers  X ,  X   X  R and an evaluation u ,w e define a new evaluation w =  X  u +  X  we define the constant evaluation w =  X  |  X  by w i =  X  for all i in  X  and S ( w ) =  X  .We of u ove r items in sigma  X  S ( u ). We define the inner product of u  X  and x  X  R n by u , x = note x 2 l
Ratings are inaccurate if only because there are malicious users. We say that a CFS is if we take averages over the entire database for example. However, it is necessary to make some assumptions about the evaluation set  X  for stability to be possible. For example, we must assume that, for every item, there is a large set of evaluations with corresponding inaccurate ratings, then the predictions regarding this item may be inaccurate. Among the CFS schemes that are not stable are the N closest neighbor schemes unless N is large because these systems assume that the N closest neighbors have given accurate ratings. All schemes considered in this paper are stable under r easonable assumptions .
Because the mapping from user ratings to R is arbitrary, a CFS must be independent are equally sensible. For  X &gt; 0 , X   X  R , let m  X , X  ( u ) =  X  u +  X  ,wesay that a CFS is for all  X &gt; 0 , X   X  R and all u  X  . All CFS considered in this paper are normalization invariant.

Scale and Translation Invariance (STI) states that each user may have its own scale when rating items and is a stronger condition than normalization invariance. If for all  X   X  0 , X   X  R that is P commutes with m  X , X  , then the predictor is said to be STI. be compensated for: some users might tend to be naturally generous, others might be more critical, whereas others might rate most items as roughly similar while others tend to use more often extreme ratings. Note that we do not allow  X  to be negative: a user who likes SCALE AND TRANSLATION INVARIANT 135 transformation m  X , X  of the evaluation set  X  so that P  X , X  = P and P commutes with m  X , X  because it is STI.

All schemes considered in this paper are translation invariant except for Per Item Aver-age and Eigentaste 2.0. In the case of memory-based CFS, it is documented (Breese et al. (Pearson-based). On the other hand, there is no comparable studies regarding scale invari-will count more than a user with more modest ratings. For example on range from 1 to 10, if use rAgivesmovie1a10andmovie2a1 whereas user B gives movi e1a4andmovie2 a6 ,w eh av et wo users in disagreement and without scale invariance, user B X  X  opinion is going to be overwritten by user A. 2.1. Measuring the accuracy Many authors use the Mean Absolute Error (Breese et al. 1998, Herlocker et al. 1999) of rest is hidden and one important MAE error measure is obtained by subtracting a single element i from S ( u ) and setting  X  = S ( u )  X  X  i } , that is S ( u )  X   X  ={ i } , Canny (2002) pointed out that such an AllBut1 error measure is the most realistic error measure given a large enough database. Another argument for using the AllBut1 measure (AllBut1). In the remainder of this paper, we will use the AllBut1 Mean Absolute Error test evaluation set  X   X  W ith some schemes such as Eigentaste 2.0 or STI Eigentaste the sum over S(u) above must some fixed items have been rated. Note that some authors prefer the NMAE which is defined as the MAE divided by the range of observed rating values (Goldberg et al. 2001). 136 LEMIRE 3. Competitive collaborative filtering systems We begin by describing the most commonly used learning-free schemes. The simplest CFS MAE as measure, it proves of little use in practice and is only used as for benchmarking. P rating for that item. Most applications where users are invited to rate items use Per Item results show that it is possible to leverage the knowledge we have of the current user to improve predictions.

Finally, there is one more commonly used learning-free scheme (Herlocker et al. 1999) called Bias From Mean which tends to outper-form the previous two in our experiment, It combines both the average and the Per Item Average approaches in a single scheme. It does better than the Per Item Average because it uses some information about the current user (mean rating).
 updated in constant time with respect to the number of users whenever a value is changed or a user is added. Queries are in constant time.

The Bias From Mean scheme is normalization invariant as a corollary of the following proposition by setting  X   X  1.
 Proposition 3.1. W eighted sum CFS of the form for all i  X   X , are normalization invariant if and only if  X  is normalization invariant :
In the proposition above, whenever  X  ( u ,w ) which might measure the similarity between u and w , depends on u , CFS is memory-based. A commonly used normalization invariant SCALE AND TRANSLATION INVARIANT 137 choice is  X  =  X  P earson where fication where with  X   X  1. Intuitively, case amplification tends to favor close neighbor as small values raised to a power become negligible, and it improves accuracy for some values of  X  such as  X   X  2 . 5 (Breese et al. 1998).

Per Item Average, Bias From Mean and all the memory-based schemes we discussed are not STI. We will propose STI variants and show that they tend to perform better. 4. Scale and translation invariant CFS In other words, u and v contain the same information as they are identical up to a change
We can show that the condition  X  u i +  X  = v i can be replaced by the simpler condition that v i  X   X  v =  X  ( u i  X   X  u ).
 138 LEMIRE  X  v =  X   X  u +  X  and v i  X  S ( u )  X  S ( v ), then u  X  v by choosing  X  = X   X   X  u +  X  v .
 and divide by their norm. This normalization is justified because STI schemes should not depend on either the average or the norm of ratings: by normalizing evaluations we ensure of a set of ratings can be defined in many ways especially because the number of ratings may differ from a user to another. Given a norm  X  ,w e can define a map m  X  ( u ) from all incomplete vectors ( )to R n by where by convention, 0 / 0 = 0 and  X  is any norm. Empirically, we found that l p norms were a good choice and we write m p = m  X  which intuitively means that we don X  X  penalize users who rate a large number of items. We also consider  X  p = m  X  l ratings. The maps  X  p will penalize users who rated a large number of items and scale down their ratings accordingly. Many other norms are possible, but we only choose these two as representatives.
 and u (2) = (10 ,  X  10 , unrated ), a STI scheme would first normalize them so that in general, we must cope with many perfectly valid normalizations and choose based on empirical results.
 equivalence classes. The next lemma makes this precise whereas Table 3 gives an example. Lemma 4.2. u  X  v if and only if m  X  ( u ) = m  X  ( v ) .
 done in the mapped space and, in this sense, our approach to CFS design is gemetrical. SCALE AND TRANSLATION INVARIANT 139 m m p ( w ) , m p ( v ) and the norm of u is m p ( u ) l using m 2 and  X  2 . 5. Learning-free scale and translation invariant CFS v set the coefficients  X  i ( u ) such as to minimize to u . This choice also makes P STI. The simplest such scheme is defined by k = 0 and it amounts to P ( u ) =  X  u .
 The next step is to introduce a STI variant of both the Per Item Average and Bias From Mean schemes. Thus, we define the first-order STI non personalized scheme ( STIN 1( m  X  )) with the space m  X  (  X  ). Minimizing the residual energy u  X  P STIN 1 140 LEMIRE v See Appendix for a practical example of how to compute efficiently STIN 1( m 2 ). defining where u = Proj v  X  previously defined and minimize the residual energy u  X  P STIN 2( m  X  only when there are new ratings, P STIN 2 is easy to implement.

Higher order STINx schemes exists, but are likely to be of little practical use because the difference in practice between STIN 1 and STIN 2i s already small (see Table 4). STINx schemes can be updated in constant time with respect to the number of users and they are always STI.
 SCALE AND TRANSLATION INVARIANT 141 6. Memory-based scale and translation invariant CFS by using the form and  X  ( u , X  )i s the weighted average over the space m 2 (  X  ) where by convention 0 / 0 = 0. In this last equation, we choose 142 LEMIRE 7. EigenTaste 2.0 and STI eigentaste rate a common set of jokes and then providing these users with recommendations. The Eigentaste 2.0 scheme is a collaborative filtering system which was designed specifically the existence of a normal set can be used to outperform schemes that don X  X  make use of such a normal set. The Eigentaste 2.0 scheme applies a Principal Component Analysis, also sometimes called a Karhunen-Lo` eve transform, on this vector space.

The authors Eigentaste 2.0 normalize the ratings by subtracting the per item mean and dividing this bias from mean by the standard deviation of these ratings. We implement and find that this per item normalization actually degrade the accuracy in our experiment simpler version of Eigentaste 2.0 without normalization.
 We first compute the 10  X  10 matrix coordinates  X   X  N is a positive integer (see figure 1). To do so, first find M SCALE AND TRANSLATION INVARIANT 143 i defined as satisfying  X   X   X  I ( u ) , J ( u )  X  X  X   X  and I ( u ) , J ( u ) = 0 with and where sign ( x ) = 1 when x  X  0 and sign ( x ) = X  1 otherwise.

These functions I , J allow us to determine in which cluster of the eigenplane any given  X 
Once we have determined in which cluster of evaluations u belongs, it is then reasonable to simply predict that u will rate according to the per item average using its neighbors A , j  X  R n just like we did with the Per Item Average scheme, The Eigentaste predictor is then defined by P ( u ) = A I ( u ) , J ( u ) .
Because the averages A and the eigenvalues  X  ( i ) need only the be updated when new less evaluations and thus, averages might be less reliable. We choose  X  = 4asitisthe v alue reported in Goldberg et al. (2001) and it is found empirically to be a good choice. cluster of evaluations, this scheme amounts to the Per Item Average CFS.

To produce a STI variant of the Eigentaste algorithm, we use exactly the same algorithm 144 LEMIRE by STI Eigentaste is STI.

While much more lightweight than memory-based schemes, Eigentaste schemes are not number of users if we assume that the eigenvectors are constant, however once we take into account that the eigenvectors will change albeit slowly as we add more users, the update a constant time operation and it only need to be done when more users are added and not when users add ratings. We argue that having slow updates is not as much a problem as having slow queries since updates can be implemented off-line as a background task. 8. Experimental results 8.1. Data sets The EachMovie data set is the result of a movie rating web site. The DEC Systems Research 1.0 in increments of 0.2.

The Jester data set is the outcome of a joke rating web site (Goldberg et al. 2001). Users rate a fixed number of jokes and they are then presented with recommendations. According we found that very few ratings (less than 1%) were beyond this range.

As a basis for comparison, we used Amazon SOAP open API to retrieve the information about Music CDs. On June 20th 2003, metadata about all Music CDs from the web site Amazon.com were downloaded and only the 5,958 CDs with ratings were kept. The API provides the average rating for each item. We present the plots giving the frequency of e xplained by saying that users tend to rate what they like.
 SCALE AND TRANSLATION INVARIANT 145 146 LEMIRE 8.2. Methods Fo r each algorithm, we computed the AllBut1 MAE (see Eq. (1)) using enough evaluations memory-based schemes because of the computational burdens. Because all ratings in the 10 items in the standard set. The typical relative standard deviation ( N = 6) for AllBut1 MAE values in both data sets is 5%.

As an additional step, we attempt to improve predictions by replacing predicted ratings above or below the allowed range of values ([0.0, 1, 0] for EachMovie and [  X  10.5, 10.5] be implemented for practical reasons. 8.3. Results In EachMovie, we find 36,656 users with at least 20 ratings each for a total of 2,579,985 MAE for EachMovie is 0.2. Because EachMovie has a rating range of 1, normalized MAE (NMAE) are the same as the MAE values (AllBut1 NMAE = AllBut1 MAE).
 labeled from 1 to 100. The density of ratings is therefore 52.2%. For Eigentaste and STI all users. In our implementation of the Eigentaste algorithms, we compute the eigenvectors from the training set each time and do not use the eigenvectors provided with the docu-computed over an arbitrarily large number of users without running time penalty. However, we also penalize STI Eigentaste, Bias From Mean, Per Item Average, and STINx schemes both Eigentaste and STI Eigentaste, we chose  X  = 4. If we divide the typical AllBut1 MAE of 3.75 by the range of values (20.0), we get a NMAE of 0.19 which implies an accuracy similar to that of EachMovie data set. It was already reported (Goldberg et al. 2001) that these two data sets appear to lead to the same NMAE even though they are very different. SCALE AND TRANSLATION INVARIANT 147 From Mean by at least 3%, it outperforms Per Item Average by at least 15%, and is within 4% of the memory-based Pearson scheme while being significantly faster. STIN 2(  X  2 ) also forms Pearson in this study by at least 6%. Because both schemes based on  X  2 and m 2 perform well, we have evidence that STI is a desirable property. As additional evidence, Eigentaste 2.0. 148 LEMIRE
While STIN 1(  X  2 ) performs as well as Bias From Mean for the EachMovie data set, it lags such as STI Eigentaste are competitive.

There is only one instance in our experiment where a STI scheme did not systematically outperform or at least match the performance of the corresponding non-STI scheme: STI and Pearson have comparable accuracy.

The storage requirements for the STINx schemes is O ( xn + 1) where n is the number of items. For example, the EachMovie data set has at most 1949 items and because we use 32 bits floating point numbers for ratings even though they only have 6 possible values, Jester data set which has 100 items is under 1 KB. Therefore STINx schemes can easily run on very small devices. Comparatively, memory-based schemes such as Pearson and STI Pearson require around 256 KB to store a training set with at least 50,000 ratings, additional memory might be needed to buffer computations, and since a full database of occupies around 22 Megs. As far as the computational cost of the STINx predictors, we can cost is close to (1 + x ) n operations which is O ( nx ). As with the memory-based scheme it is possible to reduce the computational burden by requesting predictions over only a subset of  X  . Comparatively, memory-based schemes have a computational cost O ( mn ) and so they are at least two orders of magnitude slower in practice ( m = card (  X  ) 1 + x ). Eigentaste schemes have roughly the same storage and computational characteristics as STINx .
 A ppendix: Numerical example We present and example based on Table 2 for the STIN 1( m 2 ) scheme which is one of the it was done in Table 3. This can be done offline irrespective of the current user. (0 , 1 , 0 ,  X  1). For m and the l 2 norm is SCALE AND TRANSLATION INVARIANT 149 (0 , 1 / 2 , 0 ,  X  1 / 2) and  X  because it contains more ratings.
 v (0) = 1 and we must compute v (1) using the formula: { u { u Hence, by using Table 3, we have
How do we use this in practice? Let the evaluation of the current user be u = (2 , 1, A convenient formula is  X  (2 , 1 , 1 , 2 . 2).
 and 2.2 to items 3 and 4 respectively. Comparatively, the Per Item Average scheme would predict 9 2 and 7 3 respectively.
 Acknowledgment The author would like to thank Compaq Research and professor Ken Goldberg for conve-Sean McGrath for providing the script which retrieved ratings from the web site Amazon. The author is supported by a Canadian NSERC/CRNSG grant. 150 LEMIRE
Source code and scripts necessary to reproduce the experimental results are freely avail-able from the author.
 References
