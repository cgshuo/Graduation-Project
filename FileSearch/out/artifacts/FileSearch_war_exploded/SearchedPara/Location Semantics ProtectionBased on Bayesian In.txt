 Zhengang Wu 1 , 2( Location Based Services (LBSs), as the representative of context-aware services, can recommend accurate and timely information according to user locations. The wide application of LBSs (such as Check-ins, Navigation, Maps and Mobile Social Networks) is benefit from the widespread availability of wireless networks and smart devices with built-in positioning modules. However, LBS gets involved in the problematic concern about location privacy because of its operating mech-anism. Generally, in popular LBS-based applications and systems, real-time user locations from the LBS clients (e.g. some specific APPs installed in smartphones) as the vital contextual information need to be reported to the corresponding LBS providers in the on-demand manner. As a result, massive user locations are read-ily collected by potential adversaries via some untrusted servers and connection channels in mobile Internet.
 location privacy preservation have aimed at constructing the cloaking region under general privacy metrics such as k -anonymity and l -diversity to generalize exact user locations into custom extended spatial regions. Although effectively achieving a limited guarantee for location privacy, these techniques are vulner-able to Location Semantics Attack [ 1 ]. Intuitively, for a target user of LBS, the entire or major part of a k -anonymity cloaking region may be annotated with a similar sensitive semantic label such as Cancer Treatment Hospitals, and there-fore adversaries can breach his privacy by learning his poor health status with a high probability.
 Contributions. This solution involves three-fold contributions. First, the pro-posed approach LSRG models the process which extracts sensitive semantics form user requests and measures the degree of the semantics leakage. Second, this paper introduces a spatial cloaking method for preserving sensitive seman-tics on user locations. Third, its performance is demonstrated experimentally under different configurations by our adjusting crucial parameters.
 Outline. The rest of the article is organized as follow. The 2nd section describes background. Section 3 and Section 4 shows two major parts of this work, extract-ing sensitive location semantics and constructing the cloaking region respectively. And Section 5 evaluates the performance of this solution through experiments. Section 6 reviews related works and the last section makes a summary. System Description. Following the popular three-tire architecture [ 2 ] for loca-tion privacy protection, our solution runs on this middle server in Figure 1 .An LBS provider holds massive Point-of-Interest (POI) records which are meaning-ful location points over real maps. This middle server as a Trusted-Third-Party (TTP) is deployed between mobile clients and LBS servers to protect location privacy. First, for a user, this middle server extends exact locations into cloak-ing regions where all POI results are ready for forwarding. Second, this middle server refines and dispatchs POIs to corresponding users.
 Problem Setting and Motivation. Intuitively, the adversary analyzes pub-lished locations by mining semantic information for a target user. For example, a user Alice reports her current location coordinate loc to an untrusted LBS provider Malice in real activities. Next, Malice learns that a cancer hospital is located in the location point loc after querying public POI databases and map services such as Baidu Maps, Tencent Maps and Google Maps. Finally, Malice learns that Alice X  X  health is poor with a high probability since some LBS requests are linked with meaningful labels.
 background knowledge on POI databases as same as users. In Figure 2 ,the cloaking region CR 1 discloses that the active user is probably a cancer patient since all requests in CR 1 are from cancer hospitals and the poor health status is one of his sensitive attributes. By contrast, these requests of CR 2 are dispersed into various semantic regions such as hospitals, malls, restaurants and hotels and thus it is safer if the distribution of the adversary X  X  guessing is uniform over these regions without additional information.
 sensitive semantics on various locations. The majority of existing cloaking meth-ods fail to capture the semantic risk. A cloaking region can still leak some risky semantics information in spite of satisfying the k -anonymity rule, since the major or entire part of the cloaking region which holds k users in a snapshot of LBS requests may be mapped into a risky semantic label such as infectious hospitals. Generally, in client-side of LBS, when visiting LBS, a user submits a location request ( U, L, T ) where the users identifer U , the raw location L and the times-tamp T . e.g. A request is (Alice,(116.42284,39.908063), X 12:00 X ). In server-side of LBS, a POI entry is defined as a tuple ( L, S, D ). The raw location L is a pair ( lng, lat ) refers to the longitude lng and the latitude lat . The semantic label S refers to a meaningful brief name on this raw location L . The detail content D is a readable text to describe this raw location. e.g. a POI is ((116.42284,39.908063),  X  X ank X ,  X  X he Bank of China X ). Thus, a location request discloses that this user may execute a personal activity about this semantic information  X  X ank X . We model the causal relationship among raw locations (i.e. location coordi-nates), semantic labels (i.e. the meaning name of the raw location in real maps) and privacy risks (i.e. possible privacy disclosure events on special semantic labels) and naturally measure the belief of privacy risks using the probability of the privacy disclosure events on any raw locations and regions (the section/set of raw locations). 3.1 Modeling Location Semantics As shown in Figure 3 , this graphical model Location Semantics Risk Graph (in short LSRG) describes the privacy risk belief of a location request when the adversary eavesdrops this request after knowing semantic information of raw locations.
 Definition 1. Location Semantics Risk Graph is a three-tier directed acyclic graph G =( V, E ) . The node collection V falls into three mutually exclusive subsets, the set of raw locations V l , the set of semantic labels V risk belief A . A directed edge e = &lt;a,b&gt;  X  E refers to the dependency belief between its start point a and its end point b that is a conditional probability P ( b | a ) &gt; 0 .
 To simplify this model properly, we adopt an assumption that events of loca-tions are independent of one another and so those of semantic labels are. i.e. There are no edges which connect two peer nodes of locations or semantic labels. Clearly, connections between locations and semantic labels have a many-to-many relationship, referring to edges from the location node set V node set V s . This is consistent with real-world experiences. A building on a loca-tion may be comprehensive with offices and shopping centers. Similarly, hospitals may be dispersed into different regions in a real city.
 3.2 Inferring Privacy Risks The binary class variable A that is the root node of LSRG denotes the prob-ability event that A = A t if the adversary learns privacy information of users via location semantics inference and otherwise A = A f . In brief, the event A means a risky request and A f refers to a safe request form the perspective of user privacy.
 which the middle server submits into an untrusted LBS server for forwarding the user request. O loc actually is a cloaking region in the generalization-based location privacy protection schemes. O loc is a subset of location nodes V O loc  X  V l . Without cloaking, O loc holds only one location that is the user X  X  current location. But after cloaking locations, O loc becomes a continuous spatial region which includes the current location.
 ability for the privacy disclosure event A t of a request on the published location information O loc . Naturally, P ( A t | O loc ) can be used to measure the privacy risk degree. The privacy risk P ( A t | O loc ) can be calculated by the Bayesian rule as follow.
 3.3 Estimating Parameters Computing the posterior belief needs to obtain three prior beliefs P ( O P ( O loc | A f )and P ( A t ) which are estimated by given samples and the Max-imum Likelihood Estimation (MLE). For all cloaked location-based requests, each published location information O loc  X  V l can be decomposed into a series of basic locations, relying on specific methods of clustering or partitioning spatial data for original location coordinates. Basic locations in Figure 3 are the m -order collection of leaf nodes, V l = { L 1 ,  X  X  X  ,L m } . Therefore, for A basic location l  X  V l . Naturally, repetitive computation steps can be reduced using precalculated beliefs P ( l | A ) of all basic locations.
 The Prior Belief P ( O loc | A t ). Without loss of generality, the adversary observes a spatial region O loc which refers to a set of locations as the evidence. Specifically, throughout a middleware for location privacy protection, the cloak-ing region R ca is actually the observed region. i.e. O loc be calculated as follow.
 first factor is the location semantics knowledge. The adversary can access public POI databases and thus obtains corresponding semantics information on loca-tions. Next, the semantics risk knowledge is the other factor. The adversary X  X  intention relies on semantics labels for learning sensitive attributes of a target user and thus different location semantics implies different risk levels for loca-tion privacy. Based on the intuitive understanding, we can estimate this belief P ( O loc | A t )= l  X  O loc P ( l | A t ) under the LSRG model, after knowing these two factors which express as two condition probabilities P ( s tively where s  X  pa ( l )  X  V s and l  X  V l . For simplicity, pa ( l ) denotes the set of parent nodes of the node l in LSRG.
 The location semantics knowledge can be computed using P ( l where the function F ( x ) is the metric of the event x . We assume that for a semantics label s the adversary X  X  attack is the spatial uniform distribution over the region of this semantics s and so the metric function F ( x ) should be the area of the region meeting the event ( l, s )or( s ). i.e. P ( l computation of exact areas of massive irregular regions over a real map will generally consume intensive resources since popular online map services fail to provide related data directly. As a practical alternate, we can employ the number of POI entries in the region meeting specific semantics conditions. i.e. P ( l ( s ) . Given the POI database which the untrusted LBS holds, the function count ( s ) counts up the number of POI entries whose semantics label is s and the function count ( l, s ) refers to the number of POI entries whose semantics label is s and meanwhile whose location coordinates fall in the spatial cell annotated by l . For convenience, we use the pyramid structure [ 2 ] based on Quad-Tree to index POI entries in the 4 n grid and in fact the location semantics knowledge reflects the inherent feature of POI databases over real maps.
 The semantics risk knowledge can be estimated using the frequency of risky events which are annotated by the semantics label s  X  V s statistic analysis on the frequency of risky events grouped by semantic categories such as  X  X ospitals X ,  X  X ffices X  and so on. count ( s, A t ) adds up the number of risky events with the semantics label s and count ( A t ) is the total number of all risky events. e.g. 50 risky events on  X  X ospitals X  exist in 100 risky events and thus we can learn the belief P ( s = hospitals | A t )=0 . 5 on the semantics information  X  X ospatials X  based on this sample. Note that, all events of a sample are classified into defined catalogs (semantics labels). i.e. Each event relates to only one label, and for all semantics labels s  X  V The Prior Belief P ( O loc | A f ). The probability of safe requests on the observed region O loc denotes this prior belief P ( O loc via a safe LBS, this MLE is obtained by Equation 3 . Since O basic locations on this partitioned maps, the probability of each basic loca-count ( l, A f ) is the number of safe requests on this basic location l and count ( A is the total number of all requests on the safe sample dataset.
 The Prior Belief P ( A t ). Intuitively, the prior belief P ( A status of the entire LBS system including related network connections. Given an event sample of accessing an LBS, the MLE of P ( A t ) can express as the frequency of past request events in Equation 4 where the class variable A risky requests. By the sample, count ( A t ) is the number of violated request events where user sensitive information is disclosed and count ( A ) denotes the number of all events on both risky and safe requests simply. Note that, P ( A This section describes a cloaking region construction method to protect loca-tion semantics. Based on the aforementioned privacy risk evaluation method, we design Algorithm 1 which can recursively construct a ( k, l, t )-Secure Cloak-ing Region (for short, ( k, l, t )-SCR) to meet three privacy requirements. First, k -anonymity[ 2 , 3 ] means that the cloaking region holds k different users at least. Second, l -diversity[ 2 , 4 ] means that the cloaking region covers l different loca-tions (or spatial cells) at least. Third, t -safety ensures that the semantics safety of the cloaking region is larger than a threshold t . This can be defined as follow. Definition 2. A cloaking region O loc meets t -safety if and only if its semantics safety P ( A f | O loc )=1  X  P ( A t | O loc )  X  t .
 Definition 3. ( k, l, t ) -Secure Cloaking Region is a cloaking region which satisfies k -anonymity, l -diversity and t -safety.
 linked with a node of the Quad-Tree. Each non-root node has only one parent node. Importantly, each non-leaf node has four child nodes like a cross and thus the non-root node has the only vertical or horizontal neighbor node in the four quadrants of the cross. For convenience, two notations VNode and HNode refer to the vertical neighbor and the horizontal one of Node respectively. leaf to root along the Quad-Tree by gradually merging neighbors and check whether these candidate regions satisfy the pre-defined privacy profile. First, for k -anonymity, the region X  X  request amount defines the anonymity degree. Here, N ode.N is the request amount in the region referred by Node . Second, for l -diversity, the region X  X  area denoted by Area ( Node ) measures the diversity degree. We employ the number of cells in the region Node to count Area ( Node ) since all cells occupy the same area as the basic unit of the Quad-Tree partitioned
Algorithm 1. SCR( k, l, t, Node ) maps. Finally, for t -safety about location semantics, the function Safety ( Node ) refers to 1  X  Pr ( A t | O loc = Node ).
 In addition, the computation of P ( A t | O loc ) can be divided into two phases for reducing its time cost since a region O loc are divided into a set of distinct spatial cells and for A  X  X  A t ,A f } , P ( O loc | A )= l  X  O line phase can calculate these prior beliefs P ( l | A ) for each basic cell l Second, Algorithm 1 can obtain P ( A t | O loc ) with linear complexity O ( m ) where m is the number of cells in the region O loc , using the prepared prior beliefs from the off-line phase. This way can help to achieve the high processing performance on spatial cloaking and POI forwarding in the real-time LBS environment. We implement the proposed solution using JAVA and run it in the experiment platform which is a laptop with a quad-core 2.4Ghz Intel i7 CPU and 16G RAM. The experimental dataset from MNTG[ 5 ] holds trajectory data of about 1000 users who move along the real road networks of Beijing on 20 continuous timestamps (from 0 to 19) . All raw locations lie in a rectangle region about 67 km 2 and are indexed by the n -height full Quad-Tree structure [ 2 ] where 4 leafs divide the region into 4 n cells which refer to atomic regions and the default height is 4.
 dataset from a popular electronic map web site  X  X ap.baidu.com X , including about 8700 POI entries in this experimental region. Next, we explore 12 chosen semantics labels which are s 1 =hospitals, s 2 =nurseries, s s =bank, s 6 =malls, s 7 =offices, s 8 =houses, s 9 =school, s the default value of the total risk belief Pr ( A t ) is set to 0 . 05. 5.1 Evaluating Privacy Risks on Location Semantics mobile users leak their current locations to untrusted LBS servers on partitioned maps annotated by semantic information. Each location point refers to a POI record labeled by a meaningful string according to public real maps and POI databases, and therefore the leakage of location coordinates via a request leads to the leakage of the corresponding meaningful labels.
 cells in the 4-height full Quad-Tree structure. Intuitively, each location-based request involves a piece of risky semantic information. Generally, the majority of these cells have low risks for the perspective of user privacy. e.g. Mobile users visit in locations of public places like offices and malls. And there are some high-sensitive cells which refers to restricted regions such as hospitals and military areas. This distribution relies on two factors: First, the inherent semantic feature of a POI database or a real map expresses as the belief Pr ( O the adversary X  X  intention refers to Pr ( s  X  V s | A t ).
 P ( A t ). Under the distinct values of P ( A t )  X  [0 , 1], we count up the mathemati-cal expectation (Average Risk) of Pr ( A t | O loc = x ) for all cells. Three curves are under different Quad-Tree partitioning [ 2 ] configurations whose heights are 4, 5 and 6 respectively. More accurate location information (i.e. more finer gran-ularity and higher Quad-Tree) leads to more privacy leakages and a higher Pr ( A t | O loc = x ) and the prior belief P ( A t ) which refers to the estimated total risk. Specially, when P ( A t ) approximates 1, the privacy disclose event on any location is inevitable with the probability that is close to 1.
 Figure 4(c) demonstrates the distribution of these 12 semantics labels over the POI dataset. The majority of POI entries have low risks for user privacy and by contrast POI entries with two high risk semantics labels, s s =kids, take over 0.32% and 0.18% respectively. Clearly, high risky POI entries are sparse in a real-world maps. As a result, ( k, l, t )-SCR can be constructed with an accepted success ratio to satisfy its custom privacy conditions. 5.2 Cloaking Published Locations By comparing existing location cloaking methods, experiments in Figure 5 demonstrates that the proposed location cloaking method is feasible and prac-tical. First, the label  X  X lain X  means the straigh tway method that the loc ation cloaking server is only a simple proxy to forward requests from mobile clients to LBS servers by replacing an exact location with a spatial cell. Next, the label  X  X -LA X  is the popular location k -anonymity method (NewCasper[ 2 ]) which gen-eralizes an extended rectangular region under the k -anonymity metric. Finally, the label  X  X CR X  represents our solution that can guard against the Location Semantics Attack.
 Figure 5(a) compares complexity on time and communication. The straight-way method  X  X lain X  has the lowest cost on both execution time and downloaded data amount. And SCR possesses slightly more costs for controlling privacy risks under location semantics than location k -anonymity. Thus additional costs of SCR are still affordable.
 AsshowninFigure 5(b) , the proposed method can control privacy risks on location semantics by checking Pr ( A t | O loc ) of all cloaking regions. The straight-way method labeled by  X  X lain X  has high risks on location semantics disclosure. Next, location k -anonymity and SCR hold similar performance of privacy preser-vation but SCR builds safer cloaking regions than other two methods. On two SCR curves of t=0.9 and t=0.95, for a higher safety threshold t , this method reduces privacy risks by generalizing exact locations into larger regions. building SCRs. For specific values of the total risk belief P ( A R=0.05,R=0.1,R=0.2, and R=0.5, the ratios drop significantly after horizontal lines which refer to 100% cloaking success, when the required safety thresholds t increasing gradually. As a result, visiting high-risk LBSs especially, we have to trade off the required safety and the cloaking success ratio. When publishing a dataset where each object holds generally one identifier and multiple attributes, the adversary can re-identify objects because of the pos-sible uniqueness of attribute values in spite of removing identifiers. For this, k -anonymity[ 3 ][ 6 ] ensures that at least k objects are indistinguishable in an anonymity set. l -Diversity[ 4 ] requires that the number of different attributes which each object in an anonymity set associates with is more than at l . t -Closeness [ 7 ] guarantees that an anonymity set is statistically similar under the probability metric such as Earth-Mover-Distance.
 cryptography and anonymization. Wernke et al.[ 8 ] survey research works on attacking and protecting location privacy. Cryptography-based methods[ 9 ][ 10 ] can give strong privacy assurance but need extremely intensive resources. By comparison, location anonymization (e.g. spatial cloaking) can achieve enough privacy assurance under appropriate resources.
 into a region which holds at least k requests, extended from k -anonymity. Plenty of solutions such as CliqueCloak[ 12 ], HilbertCloak[ 13 ] and NewCasper[ 2 ]have adopted location k -anonymity in the last decade. Following t -closeness[ 7 ], Lee et al. introduce a location anonymization method which constructs  X  -Secure Cloaking Area[ 1 ] after extracting semantics information from staying duration. Shokri et al. introduced a Markov Chain based approach[ 14 ] to measure location privacy.
 Parent et al.[ 15 ] review various methods which model and mine semantics infor-mation on trajectory data. This paper investigated privacy protection against Location Semantics Attacks. To solve this problematic issue, we introduce the Location Semantics Risk Graph model to evaluate privacy risks about the dependence of location coordinates and sensitive semantics information, using Bayesian inference. And next we proposed a spatial cloaking algorithm under this model. Finally, experiments demonstrate that this solution can achieve a better privacy guarantee than existing schemes.
