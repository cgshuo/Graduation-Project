 Compression in database systems can improve performance significantly. A column-oriented database system (or "column-store") is well-suited for more compression schemes, such as RLE (Run-length Encoding) and LZ, and achieves higher perform-ance than traditional row-oriented database system (or "row-store")[1]. 
The idea of decreasing CPU costs by operating directly on compressed data was introduced by Graefe and Shapiro[2]. Each type of compression schemes will gain dif-pression algorithms are divided into two categories by encoding and decoding overhead of CPU: light-weight schemes (such as Null suppression, Dictionary Encoding, RLE, Bit-Vector Encoding) and heavy-weight schemes (LZ encoding). Some light-weight schemes can gain this benefit easily, but heavy-weight schemes need revising the execu-tion of query to get the improvement and have never been studied yet. 
In this paper, we introduce a join algorithm, LZ join, which is operating directly on heavy-weight LZ compressed data as light-weight schemes do. We differ from other work on operating directly on light-weight compressed data without join in column-oriented DBMSs (Daniel et. al [1] on c-store), in which we focus on column-oriented heavy-weight compression algorithms and join directly on compressed data (whereas [2] focuses on improving join performance of standard row-based light-weight techniques). 
In summary, we demonstrate several fundamental results related to join on compression in column-oriented database:  X 
First, operating directly on heavy-weight compressed data is feasible. And LZ join will speed up table join compare to hash join in some case.  X  encoding scheme. Data with low run-length and high cardinality is popular, for such data, LZ join could gain more speedup than light-weight scheme for its higher compression ratio. Although sorting data to get higher run-length does good to light-weight scheme for join operation, but sorted data needs to store position of all the tuples in memory and resort join results by ID for tuple reconstruction[3] to ac-quire the final answer which is time-consuming. Column-oriented database systems, such as the C-store [4] and monetDB [5] are read-optimized databases which are designed to implement sophisticated queries by storing  X  X ow-store X  approach. Data in column-store are easy to compress and are avoided to be read when they are useless for query. 
Data compression in DBMS reduces the size of the data and improves I/O per-often compensated for by the I/O improvements. Many lossless encoding algorithm using in compressed file are exploited for database system, such as entropy encoding (Hu ff man encoding[6]), dictionary encoding (Simple Dictionary, RLE, LZ). Some other encoding algorithms, like frame Prefix Suppression, Frame of Reference, Bit-Vector encoding, are implemented in column-oriented database. 
When data are compressed, we will gain a big improvement by operating on them directly [1][2]. But it is difficult to implement direct operation on heavy-weight com-pressed data. Heavy-weight LZ encoding was first proposed by Ziv and Lempel in 1977[7], which has some variants, such as LZ78, LZW, LZ77. 
The input columns stored on disk must be converted to rows at some point in the query plan, called materialization. Two materialization Strategies are proposed in [3]: adds all output columns before join. However, late materialization dose not form tuples until some part of the plan has been processed, that is more efficient. So, in LZ join, we use late materialization, especially for sorted column data. s  X  S and the two records satisfy some given condition. In the remainder of this paper, table. 1. Encoding data encoding process, each attribute (the basic data element in the relation column) was coding position backwards, i.e. the last W processed characters. When length attrib-from offset in dictionary window, output ( offset , length , attribute ). When no match for the attribute, output ( 0,0,attribute ). Decoding is on the reverse way. 
The compression ratio that LZ method achieves is very good for many types of data, especially for data with low run-length and high cardinality. Although encoding of LZ is quite time-consuming which has a lot of comparisons to be performed be-tween the lookahead buffer (from Coding position to the end of input stream) and the dictionary window, but decoding is very simple and fast. 2. Join operation Time-consuming encoding has been done offline yet, joins need only simple decod-ing. LZ join keeps two phases: decoding and probing phase. 
In decoding phase, decoder read triples from compressed data. LZ Compressed window offset (and it is a flag of whether attribute match the attribute in windows,  X 0 X  matching the dictionary window from the offset, attribute means next attribute. From windows. If offset is no match( X 0 X ), we call the attribute probing attribute , which need meeting probing attribute, decoder copies the attribute of triple to dictionary window. from window and replicate it (them) to the successive place. 
In probing phase, we choose hash join or nested-loop join at will but no sort-merge join. Hash join is recommended for its high performance. keep join results and make a point in dictio nary window for each attribute to link join result to the attribute. cached attribute (1,2, vali ) arrived, LZ join read  X 2 X  cached results from offset ( X 1 X ) of attribute or cached attribute. 
Algorithm LZ join can be easily implemented from the description above, we omit it for length restriction of the article. dictionary window, block window, because encoder with sliding window need de-compress all the data no matter how many data is selected that is time-consuming and storage-wasting. Block dictionary window can overcome this problem by choose the own block window. On the condition of laze materialization [3] of tuple recon-struction in column-oriented database, whether data need decompress or not is indi-accessing the right block directly with indicatio n of block size and decode only part of blocks. 
As shown in Fig.1, each entry of dictionary window has two elements: value , point and replicates successive length number of cached results. Build table S . Before S is built in memory, execution plan instructs how to load data from disk and which column is needed. Build phrase of table S is just like row-store vertical partitioned tuples after each column was decompressed (if compressed). Cached results buffer. Cached results buffer is storing join results of current diction-ary window. When LZ join finished, all the join results will be found in a number of result may write to disk.
 dictionary window must do after finish of decoding, which is no good for LZ join to operation directly on compressed data. So, sort-merge join can not apply to LZ join. The other two join methods, hash join and nested-loop join, are suited for LZ join to probe build table S. Whichever LZ join takes, it does not affect LZ join. Commonly, hash join is a good choice for its execution faster than nested-loop join. We compressed the data in each of the following four ways: Lempel-Ziv (LZ), RLE, bit-vector (BV), and no compression (NC) and use SSBM[8] which is popular in data all the tuples in fact table LO_ are order by orderkey and linenumber. The fact table each dimension table is custkey 20k, partkey 200k, suppkey 10k, orderdate 2406. LZ compression has the smallest space than RLE and S-RLE, as shown in Fig. 2(a). run-length and high cardinality. 
In Fig 2.(b) join phrase, decoding the compressed data take most part of join over-head, so that LZ join can not surpass RLE join in all case. Resorting results of S-RLE join waste most of its join time, so it is not good for full column join. 
Although LZ join is not the best in join algorithm, but we propose a novel ideal to do join operation, and this approach can not be outstanding in all the cases. Many light-weight schemes, such as RLE and bit-vector encoding, can operate di-rectly on compressed data. However, heavy-weight compression is considered to be mind by combining join operation into decoding. Actually, LZ decoding is much and experiments verifies this point. 
In summary, vertical partition of table in column-oriented database system raises the ability of compression schemes which could not have in row-oriented database overhead make a novel approach to promote system performance. 
