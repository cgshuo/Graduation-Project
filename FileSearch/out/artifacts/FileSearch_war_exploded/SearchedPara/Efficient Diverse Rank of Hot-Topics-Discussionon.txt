 Recently, online social media services attract many users and become a popular way to share personal opinions. Microblogging, such as Twitter 1 and Sina Weibo 2 is one of the most popular social media services. These platforms group tweets into different topics using hastag 3 and provide the Hot-Topic-Discussion service which allows users to express personal opinions and read about other people X  X  views about a specific hot topic. Ranking is necessary when displaying tweets to users because of the large quantity of tweets under one topic. Conventionally, tweets are ranked according to time sta mps. This approach is widely used by social networking applications such as Twitter and Sina Weibo. Another popular ranking strategy is based on the frequency of forwarding and commenting rate of the tweet. However, both ranking methods might result in redundancy on the content of tweets. Hence, we need a mor e effective strategy to rank the tweets under the same hot topic.
Furthermore, Hot-Topic-Discussion dr aws a lot of attention and receives many queries at the beginning of its lifetime. That is to say, the number of tweets on a topic grows quickly and massive queries about the tweets are simultaneously emerging during the discussion X  X  lifetime. Additionally, users constantly post new messages, repost and comment the existing ones. Thus ranking efficiency and the update cost of the ranking are very important.

In this work, we present an efficient div erse ranking algorithm for the tweets under a hot topic which is eligible for offline ranking and online updating. To summarize, we make the following contributions in this paper:  X  Proposing a novel measure to the increase diversity of the top tweets effec- X  Designing an efficient ranking and updating algorithm based on locality sen- X  Implementing the ranking algorithm on MapReduce framework to enhance  X  Conducting a series of experiments on real-life dataset to verify the efficiency The rest of the paper is organized as fo llows: Related work is given in section 2. We give a formal statement about the diverse ranking problem in section 3, and introduce the LSH-based algorithms for ranking and updating operations in section 4. Besides, we discuss the implementation on the MapReduce framework. In section 5, experiments on real datasets are conducted to verify the efficiency and effectiveness of our approach. And we conclude this work in section 6. Information Retrieval(IR) is concerned with finding relevant documents that satisfy user information needs [2] . IR systems rank documents mainly according to the relevance to the query. It has an assumption that the usefulness of a result to the user is independent of the usefulness of the others [3]. For cases where there is a large volume of potentially relevant documents, highly redundant with each other or containing partially or fully duplicative information in extreme, pure relevance ranking is not enough. Hence, beyond pure relevance for document ranking, diversity is ought to be combined to reduce redundancy.

Recently, diversity has gained great attention as it is a way to improve the quality of query results [4 X 6]. Corbonell and Goldstein [4] introduced the con-cept of diversity in text retrieval and summarization as well as the maximal marginal relevance, an aggregation of relevance and diversity. Quantum Prob-ability Ranking Principle [6] and the Modern Portfolio Theory[5] introduced similar criterions. They designed different diversity measures and utilized differ-ent approaches to aggregate documents X  relevance and diversity. However, all of them have a quadratic time complexity and update operation is unfeasible under these measures. Result diversification has been considered in different applications[7, 8]. In [7], Sofiane Abbar considered the problem of recommending a set of diversified re-lated articles where relevance and diversity are considered independently. First, the most similar documents are retriev ed. Second, a diverse subset which max-imize the minimum pair-wise distance is constructed by using a 2-approximate greedy algorithm. In [8], location visualization with geo-tagged photos is dis-cussed. The author both took the content similarity and geographic distance to model the redundancy between each objects, and used a clustering-based ap-proach to generate a representative subset . Besides, they designed a hybrid index to achieve query efficiency.

In this work, we consider the problem of diverse ranking for the tweets set on a hot topic. And our focus is the efficiency of ranking and feasibility of update operation for the tweets collection. This section is to define the diverse ranking problem studied in this work. A tweet is represented as a quadri-tuple &lt;tid,text,rf,cf &gt; where tid is an unique identifier, text is the content, rf is retweeting frequency and cf is comment frequency. T = { t 1 ,t 2 ,...,t n } is a set of tweets on a topic O .
To highlight the importance of different tweets under the same topic, we first adopt popularity in [10] to measure how popular a tweet is. Intuitively, the tweets retweeted and commented frequently are the popular ones. Hence, we explore retweeting frequency and comment frequency to evaluate the popularity of a tweet formally in Definition 1.
 Definition 1 (Popularity). The popularity of a tweet t i is a sum of its retweet-ing frequency and comment frequency.
 Here Z =max t j  X  T ( rf j + cf j ) is a normalization factor.

In addition, we propose diversity to highlight the content novelty that a tweet would contribute to the whole ranking sequence, as some tweets might share similar content. We observe that a tweet is of less diversity if it is similar to a more popular one. Thus, the higher the similarity of a tweet, the lower the diversity of the tweet is. We define diversity formally in Definition 2. Definition 2 (Diversity). The diversity of a tweet t i is negative correlated with the maximum similarity with another more popular one in T .
 content of tweets.
 In particular, the similarity metric used here is the Jaccard similarity [11] over K -shinglings [12] set.

Based on the popularity and diversity defined, the diverse ranking is to put the popular and diverse one in the front of the tweet sequence, which is formally defined as follows: Definition 3 (Diverse Ranking Problem). The diverse ranking problem is O , according to Here,  X  is a parameter for controlling the tradeoff between popularity and diver-sity. It is desirable that tweets are ranked in the order of popularity when  X  =1, whereas diversity is mostly wanted when  X  =0.

To answer user queries with short resp onse time, it is indispensable to solve the above problem efficiently. Clearly, the diversity ranking can be done at the beginning of the topic discussion, with each tweet X  X  popularity and diversity measured. After that, the ranking order is periodically updated along with the evolvement of a topic discussion. Thus, we can always answer user queries by selecting the top tweets efficiently.

Based on the above discussion, the problems we tackled are listed as follows:  X  How to efficiently, in offline manner, rank each tweet when the topic discus- X  How to efficiently, in online manner, update the ranking order periodically? In this section, we introduce how to rank tweets efficiently and update the rank-ing periodically.

Firstly, we demonstrate a naive method to analyze the bottleneck of the rank-ing method.

Given a collection of tweets on a partic ular topic, we can rank all tweets as follows: step 1 Measuring the popularity of each tweet, and sorting them in descending step 2 For each tweet, computing content similarity with all other more pop-step 3 Sorting all tweets in order of the aggregation of popularity and diversity. Assuming the size of tweet collection is n , such approach is associated with n popularity computation, n  X  ( n  X  1) 2 similarity computation and two sort oper-ations. Thus, the most time-consuming part would be the pair-wise similarity computations. If the collection size is very large, such approach is inefficient. 4.1 Lrank: LSH-Based Rank Algorithm Here we utilize LSH to reduce similarity computation into a small set of tweets pairs. We start the description of the LSH-based rank algorithm with an overview of the LSH algorithm[1].

LSH adopts Minhash functions which can preserve Jaccard similarity so that similar objects have a high probability of colliding in the same bucket. A min-hash function mh  X  ( S ) outputs an element of set S , which firstly appeares in an element permutation  X  . Minhash has the property that the probability of two tweets sharing the same minhash value equals with the their Jaccard similarity.
Essentially, given a tweet, the LSH attempts to find all candidate tweets which are similar to it. It is done as follows: firstly, LSH creates b hash functions g ,...,g b , and their corresponding hash tables A 1 ,...,A b . Here, each function g is a combination of d minhash functions mh j (i.e. g i = mh 1 ,...,mh d ). Then  X  X  X  X  A the time complexity of the nearest neighbor query is O ( n e )where e&lt; 1[13].
Let us recall the computation of D ( t ). Formally, given a tweet t and let C = { t | P ( t ) &gt;P ( t )  X  t  X  U } , the key here is to find the nearest neighbor for t in set C . Thus, we can use LSH to accel erate the computation of D ( t ) by finding an approximate nearest neighbor.

At the beginning of diverse ranking, we compute tweets X  popularity(line 2) and partition them into LSH buckets(line 4) as the following pseudo-code. Algorithm 1. Preprocessing
Based on the LSH tables, algorithm 2 only computes the similarity between the tweets pairs in the same bucket. At the beginning, the diversity scores of all tweets are initialize to 0(line 1). Next we check all similar tweets pair ( t 1 ,t 2 )in is at most -Sim ( t 1 ,t 2 )(line 4-9).

The time complexity of algorithm 2 is O ( Mn (1+ e ) + n log( n )) where e&lt; 1 and M is the complexity of similarity computation.

Proof Let us assume there are l buckets with a 1 ,a 2 ,...,a l ( l i =1 a i = b  X  n ) in algorithm 2.
 Algorithm 2. LSH-based Rank ( lRank )
On the other hand, querying the nearest neighbor for t on the LSH table is as-sociated with b i =1 | g i ( t ) | similarity computations. Therefore, the total times of similarity computations for querying all tweets X  nearest neighbor is:
The time complexity of nearest neigbor query on LSH table is O ( Mn e ) ( e&lt; 1 ) according to [1]. Therefore, the total complexity of similarity computation in algorithm 2 is O ( Mn (1+ e ) ) ( e&lt; 1 ). The sort operation has a complexity of n log( n ) . Totally, algorithm 2 has a complexity of O ( Mn (1+ e ) + n log( n )) . Example 1. Considering 4 tweets ( t 1 ,t 2 ,t 3 ,t 4 ) whose shinglings are given in P ( t 3 ) ,then D ( t 3 )=min { 0 ,  X  1 2 } =  X  1 2 . After processing the second bucket, we get D ( t 4 )=  X  1 2 . From the third bucket, we get D ( t 2 )=  X  1 3 . For the rest, there is only one tweet and no similarity computation is needed. At last, we get D ( t 1 )=0 ,D ( t 2 )=  X  1 3 ,D ( t 3 )=  X  1 2 ,D ( t 4 )=  X  1 2 . 4.2 Implementation on MapReduce When the tweets set is very large, th e ranking phase would contain a large number of similarity computations even after being pruned by LSH. A single-machine-implementation is not applicable for extra large datasets and does not have scalability. Thus, we implement the ranking algorithm under the MapRe-duce framework, which consists of two stages, as in figure 1. The first stage scans the whole tweets set, uses LSH to partitio n tweets into different buckets and pro-duces a list of similar-tid pairs. The second stage makes similarity comparisons for all tids pairs and evaluates diversity for each tweet. Stage 1: Tid-Pair Generation The first stage scans the whole tweets set and computes LSH signatures for ea ch tweet in the mapper. For a tweet t ,the is hash functions used in LSH.

Each reducer collects tweets sharing the same hash values and then uses a Tids-pair ( tid 1 ,tid 2 ) means one similarity comparison is needed in order to com-pute the diversity of tid 1 .
 Stage 2: Diverse Ranking In the second stage, we compute the diversity score of each tweet and rank them by the aggregation of popularity and diversity. Here we distribute the original tweets records to all nodes and store them in the main memory using distributed cache. Since the length of tweet is restricted in 140 characters, the whole tweet file is small and can be stored in the main memory.
In the mapper, we simply output the tid-pairs with the tid of the less popular tweet as key and the more popular one X  X  tid as value.

Each reducer collects all other tweets ids that the one denoted by key is necessarily compared with. We make sim ilarity computations between the tweet with tid key and all others tweets whose tid is in the value list. And, the diversity of tweet with tid key is easily evaluated by calculating the maximal similarity. ranking score for tweets.
 4.3 Update Algorithm During the lifetime of a Hot-Topic-Discussion, tweets are frequently updated(i.e. retweet, comment). Single update has micro impact on the diverse ranking order. A bundle of updates will make the ranking change a lot. Therefore we need to re-estimate the popularity and diversity periodically in order to maintain a proper diversed ranking.
 If a unpopular tweet receives much attent ion, its popularit y would increase. Thus, this would change its diverse ranking score. In such case, we should re-evaluate the diversity of other tweets. Besides, we also need to re-evaluate the diversity of other tweets according to the following constraints: (1), they were more popular but now are less than the updated one; (2), they take the updated one as a new nearest neighbor which is more popular. The second constraint lim-its update-needed tweets into the LSH buc kets that the updated one is associated with.

Here we introduce algorithm 3 to re-evaluate a tweet X  X  popularity and diver-sity. First, we update its popularity and reset its diversity. In line 3-11, we check the relationship between t and other tweets similar with it. If t is less popular, we should update t X  X  diversity(line 7); otherwise, update the other one X  X (line 9). Algorithm 3. Update ( update )
The complexity of our update algorithm is O ( n e )( e&lt; 1). Both update and nearest neighbor query of an input tweet need to scan the related hash buckets. Therefore, algorithm 3 has the same time complexity with nearest neighbor query[13].
 Example 2. Reconsider the example 1. If t 2 received lots of attention and be-came more popular, the popularity of t 2 is updated. After then, we have P ( t 2 ) &gt; P ( t 1 ) . The diversity is re-computed as follows: firstly, we set D ( t 2 )=0 and pick Secondly scan these buckets and compute similarities between t 2 and { t 1 ,t 4 } . D ( t 4 ) . We get D ( t 1 )=  X  1 3 ,D ( t 2 )=0 ,D ( t 3 )=  X  1 2 ,D ( t 4 )=  X  1 2 . In addition, we consider the problem of adding a new tweet into the collection. The minor difference between adding and updating is whether we need to insert the new tweet into the LSH tables.
 In this section, we discuss the algorithm to solve the diverse ranking problem. We utilize LSH to prune the similarity comparison between the dissimilar tweet pairs. Furthermore, we discuss the MapReduce implementation of our algorithm to enhance the capability of processing large dataset. In this section, a series of experiments on real dataset are conducted to verify the effectiveness and efficiency of the proposed algorithms. 5.1 Datasets and Setup The dataset is crawled from Sina Weibo , which contains three hot topics: Mo Yan 4 , Food Safety 5 , Medicine 6 . Some statistics are shown in Table 2.
Besides, we use the DBLP 7 dataset to verify the efficiency of our algorithm for the case of processing large datasets under the MapReduce framework. We extract paper records containing title, authors list and journal name. Experiments are conducted on a desktop machine equipped with Intel(R) Core(TM) i5-3470 CPU @ 3.20GHz, 8.00GB memory, 64-bit Windows 7. We run MapReduce experiments on a 9-node clu ster. Each node has four cores, 8GB of RAM. Empirically, LSH X  X  band number is fixed at 16 with 2 min-hash functions used in each one. Totally, 32 hash functions are used in LSH to partition tweets into different buckets.

We compare three ranking methods including sRank, mRank, lRank and in-vestigate these algorithms in two as pects: effectiveness and efficiency.  X  sRank: the simple ranking method used in real application only based pop- X  mRank: the diversity ranking approach based on maximal marginal relevance  X  lRank: the ranking algorithm proposed in our paper.
For effectiveness, we compare the dive rsity of top results in each ranking list. Here a collection of tweets is considered to be more diverse if it contains more entities. Users may feel tweet set m ore diverse if each tweet includes more different entities. Hence, the number of entities is an indicator of its diversity. The Standford NER 8 tool is used to extract entities. We use the following metric to measure the diversity of different tweets list L .
For efficiency, we mainly compare the time cost of each algorithm. 5.2 Efficiency In the first experiment, we study the effic iency of lRank. Here we generate col-lections of size 500, 1000,..., 4500 for the Food Safety dataset; 1000, 2000, ..., 10000 for the Mo Yan and the Medicine dataset.  X  is set to 0.7. It is necessary to mention that  X  does not affect the efficiency of rank algorithm (except for  X  = 1, which does not consider the diversity).

The following figures show the perfo rmance of each algorithms. We can see that lRank is at least one magnitude faster than mRank. With the increase of the collection size, the gap betw een lRank and mRank becomes larger.
Next, we demonstrate the efficiency of update operation. To initialize update operation, tweet collections and the corre sponding LSH tables are loaded in the main memory. To simulate the update scenarios, we choose a tweet and increase its popularity randomly. Figure 3(a) reveals that our algorithm has the capacity of processing updates efficiently.

To evaluate the efficiency of our algorithm on MapReduce, we vary the dataset size from 0.1 million to 1.5 million. In figure 3(b), we show the running time on different dataset size. The bar consists of Stage 1 and Stage 2 represents the running time of lRank under the MapReduce framework, while the other bar represents lRank running time on a single machine. As we can see, when the dataset size is 0.1 million, both implementations have similar performance. As the size increases to 0.5 million, running on MapReduce is much more efficient than running on a single machine. The time cost of single-machine version on processing 1(1.5) million-sized data set is 13890s(21445s), while the MapReduce version of lRank is 6-7 times faster than the single-machine lRank. 5.3 Effectiveness In the second experiment, we evaluate the effectiveness of our approach. Table 3 shows how many entities are there in the top-k tweets. For mRank and lRank, we evaluate the results under different  X  (0.1, 0.2, ..., 0.9) and select the best one as their performance. We have the following observations: 1) The top-k tweets contain more entities when diversity is taken into consideration. We can see that the mRank and lRank always outperform the sRank. 2) lRank and mRank have similar performance. When k is small, mRank is slightly better. But lRank is better when k is large. 3) sRank has a good performance if there is little redundancy in the dataset. In Mo Yan dataset, the most popular tweets are quite different from each other. Hence, all of the three ranking methods show the same performance among the top-20 tweets.

Figure 4 shows the cumulative distribution of entities over the whole ranking list. As we can see, there are more entiti es contained in lRank and mRank than sRank in all the three datasets since sRank does not consider diversity. At the tail of the curves, neither mRank nor lRank increases since the last left tweets are duplicated with the ones selected before.
 With social network services, people can ea sily discuss hot topics with each other, which results in a large volume of tweets. In this paper, we discuss the diverse ranking for tweet set under the same hot topic. The improved ranking list is proved to be more informative. Besides, we propose a LSH-based approximate ranking algorithm, which is at least one magnitude faster than MMR. Further-more, we implement our ranking algorithm on MapReduce framework to handle extra large datasets and enhance scalability. Experiments on real-world dataset verify the efficiency and effectiveness of our approach.
 Acknowledgments. This work was supported by the 973 project(No. 2010CB32-8106), NSFC grant (No. 61170085 and 61033007), Shanghai Knowledge Service Platform Project (No. ZF1213) and the general project of Guangxi Provincial De-partment of Education (No. 2013YB095) .

