 and segmentation in scenes with perceptually distinct foreground and background layers. We do this in a probabilistic framework using a Gaussian process prior to model the geometry of typical employed incrementally which is useful for circumstances in which the time allowed for processing is constrained or variable; secondly it is probabilistic enabling fusion with other sources of scene information.
 Segmentation and depth estimation are well-studied areas (e.g., [1] and [2, 3, 4]). However the in-spiration for the work in this paper is [5] in which both segmentation and depth are estimated in a unified framework based around graph cuts. In [5] the target application was video conferenc-ing, however such an algorithm is also applicable to areas such as robotics and augmented reality. Gaussian process regression has previously been used in connection with stereo images in [6] to learn the non-linear mapping between matched left-right image points and scene points as an alter-native to photogrammetric camera calibration [7]. In this paper we use a Gaussian process to help discover the initially unknown left-right matches in a complex scene: a camera calibration procedure might then be used to determine actual 3D scene geometry.
 The paper is organized as follows: Sec. 2 describes our Gaussian process framework for inferring depth (disparity) and segmentation from stereo measurements. Sec. 3 proposes and demonstrates two observation schedules: the first operates along image scanlines independently, the second treats the whole image jointly, and makes a sparse set of stereo observations at locations selected by an active learning criterion [8]; we also show how colour information may be fused with predictions by the switched GP, the results of which are comparable to those of [5]. Sec. 4 concludes the paper. Figure 1: Anatomy of a disparity map. This schematic shows some of the important features in short baseline binocular stereo for an horizontal strip of pixels. Transitions between foreground and background at the right edge of a foreground object will induce a discontinuity from high to low disparity. Background X  X oreground transitions at the left edge of the foreground induce an occlusion region in which scene points visible in the left image are not visible in the right. We use the data from [5] which are available on their web site: http://research.microsoft.com/vision/cambridge/i2i This framework is intended for use with short baseline stereo, in which the two images are taken assume that both L and R have been rectified [7] such that all corresponding points have the same map for points x in the left image.
 are two important exceptions to this and, because they occur at the boundaries between an object and the background, it is essential that they be modelled correctly (see also Fig. 1): Discontinuity Discontinuities occur where one pixel belongs to the foreground and its neighbour Occlusion At background X  X oreground transitions (travelling horizontally from left to right), there The next subsection describes a prior for disparity that attempts to capture these characteristics by modelling the bi-layer segmentation. 2.1 A Gaussian process prior for disparity We model the prior distribution of a disparity map to be a Gaussian process (GP) [9]. GPs are defined of disparities at a set of points { x where f In order to specify a mean and covariance function that give typical disparity maps an high proba-makes it possible to model the fact that disparities in the background/foreground are smooth (spa-tially correlated) within their layers and are independent across layers. For a given segmentation, the covariance function is where D is the maximum disparity in the scene and  X  is the Dirac delta function. The covariance of label. Disparity is undefined within occlusion regions so these points are treated as independent with high variance to capture the noisy observations that occur here, pixels with other labels have disparities whose covariance falls off with distance engendering smoothness in the disparity map; the parameter  X  controls the smoothness and is set to  X  = 0 . 01 for all of the experiments shown in the background has been discussed previously by [10] in which switching was demonstrated for a 1D regression problem. 2.2 Stereo measurement process A proposed disparity d ( x ) is compared to the data via the normalized sum of squared differences (NSSD) matching cost over a region  X  (here a 5  X  5 pixel patch centred at the origin) using the normalized intensity is  X  L ( x ) = L ( x )  X  1 This cost has been shown in practice to be effective for disparity estimation [11].
 To incorporate this information with the GP prior it must be expressed probabilistically. We follow the approach of [12] for this in which a parabola is fitted around the disparity with minimum score with  X  ( x ) =  X  b Given a segmentation and a set of noisy measurements at locations X = { x Normal (  X   X  ( x ) ,  X  v ( x )) with [9] where  X  C ( s ) = c ( X , X ; s ) + diag v ( x 2.3 Segmentation likelihood The previous discussion has assumed that the segmentation is known, yet this will rarely be the case observations, the probability that they are a sample from the GP prior is given by This is the evidence for the parameters of the prior model and constitutes a data likelihood for the segmentation. The next section describes an algorithm that uses this quantity to infer a segmentation whilst incorporating observations. We propose an incremental and greedy algorithm for finding a segmentation. Measurements are incorporated one at a time and the evidence of adding the i th observation to each of the three seg-mentation layers is computed based on the preceding i  X  1 observations and their labels. The i th point is labelled according to which gave the greatest evidence. The first i  X  1 observation points X sets X  X  matrix for these.
 As shown in [13], the GP framework easily facilitates incremental incorporation of observations by repeatedly updating the matrix inverse required in the prediction equations (6). For example, to add where Similarly, there is an incremental form for computing the evidence of a particular segmentation as E ( X i | s ( x i ) = j ) = E ( X i  X  1 ) +  X  E j ( x i ) where By computing  X  E that which gives the greatest increase in evidence.
 of useful size. We propose two mechanisms to overcome this: 3.1 Independent scanline observation schedule By handling the image pixels one row at a time, the problem becomes one-dimensional. Points are processed in order from right to left: for each point the disparity is measured as described in Algorithm 1 Add and label measurement at x input  X  F  X  1 ,  X  B  X  1 , X
Compute matrix building blocks r
Compute change in evidence for adding to each layer  X  E
Label point s ( x
Add point to set X if s ( x end if i = i + 1 return  X  F  X  1 ,  X  B  X  1 , X Figure 2: Scanline predictions. Disparity and segmentation maps inferred by treating each scanline Inferred segmentation s ( x ) with F = white, B = grey (orange) and O = black.
 Sec. 2.2 and incorporated/labelled according to Algorithm 1. In this setting there are constraints on which labels may be neighbours along a scanline. Fig. 1 shows the segmentation for a typical image segmentation are B  X  F , F  X  O and O  X  B . Algorithm 1 is therefore modified to consider legal segmentations only.
 Fig. 2 shows some results of this approach. Both the disparities and segmentation are, subjectively, sharing of information. There are also a number of artifacts where an incorrect segmentation label has been assigned; in many cases this is where a point in the foreground or background has been labelled as occluded because there is no texture in that part of an image and measurements made for such points have an high variance. The occlusion class could therefore be more accurately described as a general outlier category. 3.2 Active selection of sparse measurement locations As shown above, our GP model scales badly with the number of observations. The previous sub-shortcoming of this approach is that no information is propagated vertically, introducing streaky artifacts and reducing the model X  X  ability to reason about occlusions and discontinuities. Rather than introduce artificial independencies, the observation schedule in this section copes with the O ( n 3 ) scaling by making measurements at only a sparse set of locations. Obvious ways of implementing this include choosing n locations either at random or in a grid pattern, however these fail to exploit information that can be readily obtained from both the image data and the current predictions made by the model. Hence, we propose an active approach, similar to that in [14]: given the first i  X  1 observations, observe the point which maximally reduces the entropy of the GP [8] after making an observation at x . To compute the entire posterior for each observation would be prohibitively expense; instead we approximate it by the product of the marginal distributions at each Figure 3: Predictions after sparse active observation schedule. This figure shows the predictions made by the GP model with observations at 1000 image locations for the images used in Fig. 2. (a) point (i.e., ignore off-diagonal elements in  X  ) which gives  X  H ( x )  X  1 is monotonic, an equivalent utility function is used: Here the numerator drives the system to make observations at points with greatest predictive uncer-tainty. However, this is balanced by the denominator to avoid making observations at points where using Algorithm 1.
 Predicting disparity in the scanline factorization was straightforward because a segmentation label had been assigned to every pixel. With sparse measurements, only the observation points have been i.e.: Fig. 3 shows the results of using this active observation schedule with n = 1000 for the images of Fig. 2. As expected, by restoring 2D spatial coherence the results are smoother and have none of the streaky artifacts induced by the scanline factorization. Despite observing only 1.3% of the points used by the scanline factorization, the active algorithm has still managed to capture the important features in the scenes. Fig. 4a shows the locations of the n observation points; the observations are clustered around the boundary of the foreground object in an attempt to minimize the uncertainty the image which are most interesting, important and informative. Fig. 4b demonstrates further the benefits of selecting the points in an active framework compared to taking points at random. Figure 4: Advantage of active point selection. (a) The inferred segmentation from Fig. 3 with spots (blue) corresponding to observation locations selected by the active criterion. (b) This plot compares the accuracy of the segmentation against the number of sparse observations when the observation locations are chosen at random and using our active schedule. Accuracy is measured as the percentage of mislabelled pixels compared to a hand-labelled ground truth segmentation. The active strategy achieves better accuracy with fewer observations. Figure 5: Improved segmentation by fusion with colour. (a) Pixel-wise energy term V ( x ) combin-ing segmentation predictions from both the switched GP posterior and a colour model; (b) Segmen-tation returned by the Viterbi algorithm. This contains 0.5% labelling errors by area. (c) Inferred foreground image pixels. 3.3 Adding colour information The best segmentation accuracies using stereo information alone are around 1% labelling errors (with n  X  1000 ). In [5], superior segmentation results are achieved by incorporating colour infor-mation. We do the same here by computing a foreground  X  X nergy X  V ( x ) at each location based on the variances predicted by the foreground/background layers and a known colour distribution P F | L c ( x ) where L c ( x ) is the RGB colour of the left image at x : We represent the colour distribution using a 10  X  10  X  10 bin histogram in red-green-blue colour a binary HMM and use the Viterbi algorithm to find a segmentation. A result of this is shown in Fig. 5c which contains 0.58% erroneous labels. This is comparable to the errors in [5] which are around 0.25% for this image. We suspect that our result can be improved with a more sophisticated colour model. We have proposed a Gaussian process model for disparity, switched by a latent segmentation vari-able. We call this a switched Gaussian process and have proposed an incremental greedy algorithm for fitting this model to data and inferring a segmentation. We have demonstrated that by using a sparse model with points selected according to an active learning criterion, an accuracy can be achieved that is comparable to the state of the art [5].
 We believe there are four key strengths to this probabilistic framework: Flexibility The incremental nature of the algorithm makes it possible to set the number of observa-Extensibility This method is probabilistic so fusion with other sources of information is possible Efficiency For small n , this approach is very fast ( 30 ms per pair of images for n = 200 on a 3GHz Accuracy We have shown that (for large n ) this technique achieves an accuracy comparable to the problem [15]. The framework described in this paper can operate at real time for low n , however any technique that combats the scaling will allow higher accuracy for the same execution time. Also, improving the approximation to the likelihood in (5), e.g., by expectation propagation [16], may increase accuracy.
 [1] D. Comaniciu and P. Meer. Robust analysis of feature spaces: color image sgementation. In [2] Y. Ohta and T. Kanade. Stereo by intra-and inter-scanline search using dynamic programming. [3] D. Geiger, B. Ladendorf, and A. Yuille. Occlusions and binocular stereo. Int. J. Computer [4] V. Kolmogorov and R. Zabih. Computing visual correspondence with occlusions using graph [5] V. Kolmogorov, A. Criminisi, A. Blake, G. Cross, and C. Rother. Bi-layer segmentation of [6] F. Sinz, J. Qui  X  nonero-Candela, G.H. Bakir, C.E. Rasmussen, and M.O. Franz. Learning depth [7] R. Hartley and A. Zisserman. Multiple View Geometry . Cambridge University Press, 2000. [8] D.J.C. MacKay. Information-based objective functions for active data selection. Neural Com-[9] C.E. Rasmussen and C.K.I. Williams. Gaussian Processes for Machine Learning . MIT Press, [10] A. Storkey. Gaussian processes for switching regimes. In Proc. ICANN , 1998. [11] D. Scharstein and R. Szeliski. A taxonomy and evaluation of desnse two-frame stereo corre-[12] L. Matthies, R. Szeliski, and T. Kanade. Incremental estimation of dense depth maps from [15] J. Qui  X  nonero-Candela and C.E. Rasmussen. A unifying view of sparse approximate Gaussian [16] T.P. Minka. Expectation propagation for approximate Bayesian inference. In Proc. UAI , pages
