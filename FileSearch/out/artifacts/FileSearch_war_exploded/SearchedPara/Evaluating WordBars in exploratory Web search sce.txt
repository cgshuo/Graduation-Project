 1. Introduction
Studies of Web search user behaviour have shown that a large portion of Web search queries consist of only one to three terms ( Jansen &amp; Pooch, 2001; Spink, Wolfram, Jansen, &amp; Saracevic, 2001 ). These short queries provide an indication that users of Web search engines often have difficulties crafting queries that accurately reflect their information needs. Clearly, most Web search engines provide little support for users as they attempt to construct and refine their queries; it is up to the user to decide which terms to use (both initially and during query refinement), and manually add or remove these terms from the query. As a result of this lack of support, Web searchers seldom make subsequent modifications to their queries ( Silverstein, Henzinger,
Marais, &amp; Moricz, 1999; Spink et al., 2001 ).
Even if the users are able to effectively craft a query, few consider more than three pages worth of search of going in depth through what is retrieved X  X . This low tolerance may be attributed to the static representations of Web search results that are common in Web search engines. These require the users to consider each doc-ument individually, and to some degree, in the order provided. Most Web search engines provide little ability to manipulate or explore the search results.

WordBars has been designed to provide support to Web searchers through interactive query refinement and interactive search results exploration. The primary hypothesis in this work is that frequently used terms in the results of an initial search can provide valuable information to Web searchers, both for interactive query expansion as well as for interactive search results re-sorting and exploration. Information visualization tech-niques are employed to convey the term frequency information to the users in a compact manner that can eas-ily be interpreted, understood, and used.

The WordBars system retrieves the top 100 document surrogates from the Google API ( Google, 2005 ), and counts the frequencies of all the terms used within the titles and snippets. The term frequencies are sorted and depicted in a visual manner, allowing the users to easily identify the commonly used terms within the top search results. Single-clicking on any term re-sorts the search results based on the frequency of that term. Selecting multiple terms results in a re-sorting of the search results based on the combined term frequencies.
Double-clicking a term either adds a new term to the query, or removes the corresponding term from the query. New search results are retrieved by clicking the search button. A screen shot of the WordBars system is provided in Fig. 1 .

A fundamental design principle in the development of WordBars is the balance between computer automa-tion and human control ( Shneiderman, 1998 ). Crafting a query that accurately represents a user X  X  information need is an inherently human task, as is the evaluation and exploration of the search results. While some have suggested automatically expanding users X  queries ( Qiu &amp; Frei, 1993; Voorhees, 1994; Xu &amp; Croft, 2000 )we believe that the human decisions which are made in the query refinement process are vitally important. Sim-ilarly, most Web search engines provide automated rankings of the search results based on complex and pro-prietary algorithms, such as PageRank ( Brin &amp; Page, 1998 ). However, these algorithms result in a static ordered list of search results. Interactive exploration, drawing upon the user X  X  understanding of their informa-tion need, can allow highly relevant documents located deep in the search results to be brought to the attention of the user. This is especially valuable when the search results consist of a mixture of relevant and non-relevant documents, which is often the case.

The features of WordBars provide support to the users in exploratory Web search processes. Starting with an initial query, the users can readily identify terms of interest within the WordBars histogram. Selecting some of these terms will move the documents that make use of them to the top of the list, making it easy for the users to decide whether this is an aspect of the search results that they would like to explore further. These terms can easily be added to the query and a new set of search results generated. In this manner, users of
WordBars are able to both explore the current search results, as well as refine their queries as they seek to fulfill their information needs.

User evaluations were conducted to verify that the features of WordBars can assist the users in finding rel-evant documents as they explore the search results and attempt to construct better queries. Two participant groups were recruited: an expert group and an intermediate group. The search tasks followed an exploratory
Web search scenario consisting of an initial query, exploration of these search results, refining the query, and further exploration of the refined query search results. These studies showed that although there were differ-ences among the participant groups, both were able to make effective use of WordBars to find relevant doc-uments. Both groups reported positive subjective reactions to the features, although they reported having different preferences for which feature they liked the best. These positive results illustrate the benefits of Word-Bars for supporting exploratory Web search.

The remainder of this paper is organized as follows: a overview of the previous work on query refinement and search results re-sorting is provided in Section 2 . In Section 3 , an overview of the design and features of
WordBars is given. Two examples for using WordBars to interactively refine a query and interactively explore the search results are provided in Section 4 . The experimental design for the user evaluations and the results of these user evaluations are provided in Sections 5 and 6 . The paper concludes with a discussion on the merits of
WordBars and the results of the user evaluation in Section 7 , followed by conclusions and future work in Sec-tion 8 . 2. Background 2.1. Interactive query expansion
Query expansion is the process of adding additional terms to a user X  X  original query, with the purpose of improving retrieval performance ( Efthimiadis, 1996 ). Although query expansion can be conducted manually by the searcher, or automatically by the information retrieval system, the focus here is on interactive query expansion which provides computer support for users to make choices which result in the expansion of their queries.

A common method for interactive query expansion is a technique known as relevance feedback ( Rocchio, 1971 ), in which the users indicate the relevance and non-relevance of entire documents from the results of an initial search. This information is used to construct a new vector-based query with increased weights on the terms found in the relevant documents, and decreased weights on the terms found in the non-relevant documents.

Salton and Buckley (1990) conducted an extensive evaluation of the relevance feedback techniques using a number of test collections, and showed these techniques to be quite effective. Chang and Hsu (1999) clustered the initial search results, allowing the users to tag entire clusters of documents (as well as individual docu-ments), thereby improving the user efficiency in providing the relevance feedback information.

One of the problems with applying these relevance feedback techniques directly to Web searches is that the vector-based query model that is assumed in relevance feedback is not readily available for Web searching.
For a meta-search systems that uses the Google API ( Google, 2005 ) or the Yahoo API ( Yahoo, 2006 ), weighted, vector-based queries are not well supported.

Instead, we investigate methods for analysing and processing the initial search results, and allowing the users to choose specific terms to add (or remove) from their query. This use of the data present in the top search results is often called local analysis . When users are able to explicitly remove terms from their query in addition to adding new terms, the result is commonly referred to as query modification ( Harman, 1992 ). In our work, we prefer to call this process query refinement in order to highlight the positive nature of changing the query.

Zoom used automatic frequency analysis to provide an ordered list of terms and phrases appearing within the top 50 records from the previous search ( Ingwersen, 1984; Martin, 1982 ). Intended to assist inexperienced searchers, this information could be used to decide the success of their current query, as well as indicate poten-tially useful query expansion terms. Part of a larger information retrieval system, the Zoom feature supported heuristic searching, allowing the user to browse, scan, and recognize terms ( Ingwersen &amp; Wormell, 1986 ).
However, the terms were presented in a simple list, with no interactive support assisting the users in adding terms of interest to their query.

Harman (1988) developed an information retrieval system that provided three different lists to the user from which they could select additional terms to add to their query. The first list contained terms found in the first 10 documents returned from the initial query, sorted based on various statistical techniques. The second list consisted of linguistic variations on the query terms. The third list was based on the co-occurrence of terms within the entire collection. The results reported from this work were good when users made perfect choices from the lists of available terms. However, others have shown that when presented with a list of potential terms to add to a query, users may have difficulties choosing good terms from these lists ( Magennis &amp; Rijs-bergen, 1997; Ruthven, 2003 ).

Interactive query expansion in the Okapi system was developed to assist users in more effectively crafting queries ( Beaulieu, 1997 ). Two term selection techniques were used: presenting terms extracted from documents identified as relevant by the user; and suggesting terms based on matching the query to a thesaurus. Candidate terms were presented in a simple list, allowing the users to select terms to add to their query. Although improvements were shown through user evaluations, many chose not to use the interactive query expansion features. This may have been due to the novelty of the features as well as with the methods for presenting and interacting with the information.

Joho, Coverson, Sanderson, and Beaulieu (2002) generated a hierarchy of query expansion terms from the set of retrieved documents, and presented these to the user via cascading menus. Although there is value in deducing and representing the relationships among terms within the search results set, their process requires access to the contents of the entire documents within the search results, which is not feasible for interactive Web search systems.

Applying the fundamentals of these techniques to Web search is somewhat problematic, especially for meta-search systems. Collecting the common terms used in the top documents returned by the initial search requires retrieving these documents from their source. This introduces a delay that would not be well received by Web searchers that are used to near-instant response times from their search engines. The utility of vari-ations on the query terms is questionable. Generating a list of co-occurring terms within the collection is not feasible due to the size of the Web (on the order of billions of documents). Requiring users to manually iden-tify relevant and non-relevant documents upon which to base the query expansion introduces an extra step required before query refinement can proceed. Thesaurus-based techniques have not proven to be very effec-tive for query expansion ( Voorhees, 1994 ).
 In WordBars, frequently used terms are selected from the top search results in a manner similar to Zoom.
However, rather than retrieving and processing the textual contents of the source documents, the frequency statistics are based only on the title and snippet provided by the underlying search engine. To address the cri-tiques of Harman X  X  work, WordBars provides a visual representation of the frequency of the terms, as well as an indication of which terms are present in the current query. The ability to re-sort the search results allows users to see how potential query expansion terms are used in the top search results. This additional informa-tion allows the users to make informed decisions for query expansion that would not be possible when simply considering a list of terms. 2.2. Search results re-sorting
The re-sorting of search results based on Web search personalization is a rather active research field ( Pitkow et al., 2002; Radlinski &amp; Dumais, 2006; Sugiyama, Hatano, &amp; Yoshikawa, 2004; Teevan, Dumais, &amp; Horvitz, 2005 ). These systems generally provide an automated re-sorting and filtering of the search results based on the personalized profiles of the users. Although some support the editing of the personalized profiles (e.g., Pitkow et al., 2002 ), in general, these systems provide little ability to interactively re-sort or manipulate the search results. There appears to be little research on interactive tools to allow the users to control the re-sorting methods, in personalized systems or otherwise.

In our previous work on HotMap ( Hoeber &amp; Yang, 2006b ), we allowed the users to re-sort the search results based on the frequencies of the query terms within the search results. In Concept Highlighter ( Hoeber &amp; Yang, 2006c ), we re-sorted the search results based on fuzzy membership scores with relation to user-selected concepts. In both of these systems, the re-sorting features helped to bring highly relevant documents that are buried deep in the search results to the attention of the searcher. In a user study comparing these sys-tems to Google, we found that the interactive search results exploration features can increase user perfor-mance in finding relevant documents ( Hoeber &amp; Yang, 2006a ). 3. WordBars
The design of WordBars is best explained with respect to three primary features: (1) the meta-search and processing of the search results, (2) the visual representation of the term frequency information, and (3) the interaction features that are supported by the system. The details of these features are described in the remain-der of this section. 3.1. Meta-search and term frequencies
WordBars is a meta-search system that makes use of the services of the Google API ( Google, 2005 )to retrieve the Web search results. Upon submitting a query to the system, the top 100 search results are obtained. This occurs in blocks of 10 document surrogates at time, due to a restriction in the Google API.
The information of interest in the document surrogate are the title and snippet. The title is often descriptive of the information present within the document; the snippet provides information about how the query terms are being used within the document. Both of these pieces of information are calculated by the underlying search engine (Google in this case). The title is selected based on the specifications of various document types (i.e., using the title tag in HTML documents). When selecting the snippet, most search engines attempt to select portions of a sentence from the contents of the document that use most or all of the query terms.
As WordBars retrieves each block of document surrogates, the title and snippet from each document sur-rogate are combined in a bag-of-words approach resulting in a document descriptor text string. Stop words (i.e., commonly appearing terms that carry little meaning) are ignored, as are terms that are less than three characters long. All other terms are reduced to their root forms using Porter X  X  stemming algorithm ( Porter, 1980 ). The frequency of each stem in the document descriptor is counted, and this number is added to both a master vector that represents the term frequencies in the entire set of search results, and a local vector, which represents the term frequencies within the current document surrogate.

After processing each document surrogate, the master vector is sorted to ensure that the most frequent terms are always located at the top. This vector is used as the basis for visually representing the term frequen-cies, as explained in the following section. A mapping between this sorted master vector and the local vectors is maintained to support re-sorting the document surrogates. Because the amount of information processed and stored is relatively small, all these calculations occur in near real-time. As quickly as the blocks of document surrogates are retrieved, they are processed and the system awaits the next block. 3.2. Visual representation of term frequencies
While some previous systems have used simple textual lists to provide recommendations for additional terms to add to the query ( Harman, 1988 ), providing additional information about the terms in a visual manner can be extremely beneficial. For example, Joho et al. (2002) showed benefits to using a cascading menu representation of query expansion terms. In WordBars, we opted for a simpler representation that both allows the user to browse the available terms, as well as perceive and interpret the relative frequencies of these terms in the top search results.
 The visual representation of the term frequencies consists of a vertically oriented, colour-coded histogram.
Both the sizes of the bars in the histogram, as well as the intensities of the colours, are used to represent the frequencies of the commonly used terms in the top search results. Using multiple visual features to represent the same data attribute provides redundant coding, and can result in an increase in the ease, speed, and accu-racy in which the users are able to perceive and interpret the information ( Rosson &amp; Carroll, 2002 ). The colour scale was chosen to vary both on the red-green colour channel, as well as the luminance channel. Visually, this colour scale appears to be a heat scale, resulting in high frequency terms appearing hot, and low frequency terms appearing neutral or warm. The colour scales used in WordBars were generated using the ColorBrewer application ( Brewer, 2005 ).

The term labels are provided to the right of each frequency bar. Although the calculation of the term fre-quencies is based on stems, the format used in the term labels is that from the first occurrence of each unique stem. This has the outcome of hiding the stems from the users, instead providing complete words in the term frequency histogram. All the terms that are present in the query are coloured red; all others are black. This use of colour allows the users to easily identify their query terms within the histogram, as well as identify fre-quently used terms that are not present in the query. Further, these colour distinctions can be pre-attentively processed ( Ware, 2004 ), allowing the near-instant recognition of the distinction between the query terms and the other terms.

Due to space considerations, only the 20 most frequently used terms are displayed in the term frequency histogram. While there may be relevant terms beyond this cut-off mark, we assume that the most beneficial terms are those that are used frequently within the top search results. Although this may not be the case in many search situations, providing only the top 20 terms produces a list that can be easily browsed and is not overwhelming for the users to evaluate.

A grey box is used to indicate which terms the user has selected for re-sorting the search results. This pro-vides a simple yet effective method for indicating the current state for the re-sorting of the search results.
Fig. 1 a shows a screenshot of the WordBars system for a sample query; Fig. 1 b shows zoomed-in view of the visual representation of the term frequencies. 3.3. Interaction
As the search results are retrieved from the Google API, the document surrogates are automatically loaded into the document list window, and the term frequency histogram is updated as each document surrogate is processed. This has the effect of providing an animation of the growth and re-sorting of the terms used in the search results. A video showing this animation, as well as a complete usage scenario, is available on the author X  X  Web site. 1
Once data begins to be displayed in the term frequency histogram, the user can interact with this interface by either single-clicking or double-clicking a term. These simple interaction methods were chosen to reduce the learning curve associated with using WordBars.

Single-clicking is used to initiate a re-sort of the search results displayed in the document list window based on the frequency of all the currently selected terms. Clicking a term toggles its status between selected and not selected. Selected terms are easily identified by the grey box surrounding them. This simple process allows the user to interactively explore the search results based on the terms they feel are relevant to their information needs.

Double-clicking is used to add or remove terms from the current query. All terms that are in the current query are displayed in a red font in the term frequency histogram. Double-clicking on any of these will remove that term from the query; double-clicking on any term that is currently not in the query will add that term to the end of the query. This feature allows the users to easily refine their query based on the terms that are present in the current set of search results. Clicking the search button sends the refined query to the Google API, producing a new set of search results and a new histogram of the term frequencies.

Within the document list window, the search results are displayed in a list-based representation that is sim-ilar to that used by the major search engines. The document number from the original order of the search results provided by the Google API is included to highlight the effects of the re-sorting features, as well as to facilitate data collection during the user evaluations. Clicking on any document will open that document in a new window, and will change the link colour from blue to purple (as per the defacto standard for visited links in a Web page). This allows the users to easily identify documents that have already been visited, even after the search results are subsequently re-sorted by the user. 4. Examples
To illustrate the utility of WordBars in supporting the user X  X  tasks of query refinement and search results exploration, we provide two examples: one that begins with a vague initial query, and one that begins with a specific initial query. 4.1. Vague initial query
When a user has problems specifying their information need, the result is commonly a vague query ( Fuhr, 2001 ). Vague queries can also result from a desire to explore a general topic, or choosing a query term that is inherently vague. User evaluations of Web search systems have found that many participants use vague terms within their queries ( Nowicki, 2003 ).

The search results generated for vague queries are often vague themselves. Sometimes these search results will all be relevant to some general topic that is clearly not specific enough to satisfy the users X  information needs; other times, the search results may be relevant to two or more very different topics. A common outcome is for users to spend a lot of time considering document surrogates that are not relevant to their information needs. Web search engines provide little support to help the users improve their queries or to focus on more specific aspects of their search goal.

With WordBars, the users can benefit from being able to easily browse the commonly used terms in the search results. Vague search results can be identified by the high frequency of the query terms, and the rela-tively low frequency of all the other terms. This is due to the search results being a mixture of documents on multiple topics or sub-topics, all of which use different terms in their descriptions.

Users of WordBars benefit from the support the system provides as they explore and browse the search results. If relevant documents are found near the top of the list after re-sorting the search results, the selected terms can be added to the query, and other less valuable terms removed. As a result, the user can first consider documents that make use of a potential new query terms, and then easily add these terms to the query. All this interaction occurs within the same interface, allowing the user to readily flip back and forth between their task of search results exploration and their task of query refinement.

Suppose the user starts with the vague initial query:  X  X  X ocument clustering X  X . Clearly, the query terms are used frequently; but few other terms are used consistently in many of the search results, indicating the vague-ness of the initial query ( Fig. 2 a). The user can explore the search results by selecting terms that are better descriptors of their information need, such as  X  X  X ierarchical X  X  and  X  X  X ocuments X  X  ( Fig. 2 b). If the top documents are relevant, the user may choose to add these terms to the query by double-clicking on them ( Fig. 2 c). The user may decide that some of the query terms are not very descriptive, and may choose to remove these, such as  X  X  X lgorithms X  X  ( Fig. 2 d).

From this example, it is easy to see the value of being able to re-sort and explore the search results, as well as refine the query, using the simple interaction features supported by the term frequency histogram. The terms presented in the histogram can easily be considered for relevance, and can be used to focus on a subset of the search results that are relevant to a specific sub-topic (i.e., by re-sorting the search results), or focus and refine the query with respect to this sub-topic (i.e., by adding the terms to the query).

In this scenario, the user was able to start with a vague initial query, and explore the search results using the term frequency histogram to find additional terms that were also relevant to their goal. The user recognized terms in the histogram that were relevant to their information need, and was able to evaluate how these terms were being used in the search results. This exploration was further supported by allowing the user to craft a new query using terms from the histogram, which could then be further explored. 4.2. Specific initial query
In general, when a user is able to provide a specific initial query that accurately reflects their information needs, Web search engines do a very good job of providing highly relevant documents within the first few pages of the search results. Even in these situations, there is a benefit to using WordBars.

By providing a term frequency histogram to represent the commonly used terms in the top search results, the users can easily verify that their initial query is indeed returning documents that are relevant. In these sit-uations, many of the top terms in the histogram should be relevant to the user X  X  information need. By provid-ing a visual indication of the frequency of the terms, the users can easily interpret the relative frequency differences between terms. The user may use the term frequency histogram to re-sort the search results to fur-ther focus on and explore a particular aspect of the information need. The user may even add new terms to the query, resulting in a search that is even more specific than the initial query.

Suppose the user starts with a specific initial query  X  X  X ibrary automation storage X  X . By reviewing the top terms provided in the term frequency histogram, the user can easily verify that many of the documents are relevant to their information need ( Fig. 3 a). The user can easily focus on a specific aspect of the search results, such as  X  X  X etwork X  X  and  X  X  X oftware X  X  by clicking on these terms in the histogram ( Fig. 3 b). Alternately, the user may choose to select the term  X  X  X ackup X  X  to obtain a different sorting of the search results ( Fig. 3 c). The user may decide to add this term to their query by double-clicking on it, generating a more specific set of search results ( Fig. 3 d).

This scenario shows how the user is able to explore the search results using WordBars. This allows them to interactively manipulate the search results as they evaluate how various terms are being used within the doc-ument surrogates. In some cases, the users may find that exploring the search results from their initial query is sufficient to satisfy their information needs. In other cases, after exploring how some of the terms are being used in the search results, they may wish to refine their queries, resulting in a new set of search results that can be further explored using the new term frequency histogram.

In both of these examples, the users are provided with a visual indication of the term frequencies, and are able to take advantage of their human intelligence as they use this information to both interactively explore the search results, as well as interactively refine their queries. One of the key benefits of the term frequency histogram in WordBars is that it allows the users to recognize terms from the list, rather than having to recall relevant query terms for a given topic. Recognition rather than recall is a primary usability principle, suggesting that users should be able to see what they need, rather than having to remember it ( Nielsen, 1994 ). This allows the users to begin with an initial query, and use their recognition ability to explore and subsequently add addi-tional terms to the query, resulting in a refined query that did not require the user to remember the specific terms that are relevant to their information need. 5. Experimental design of user evaluations 5.1. Method
In order to evaluate and compare the effectiveness of the features of WordBars, we employed a 4  X  3  X  2 (feature  X  task  X  participant group) within-subjects design ( Rosson &amp; Carroll, 2002 ). The features tested in the evaluation are described in more detail in the following section. In order to reduce the biasing effects, par-ticipants were provided the tasks in a pseudo-random order. Two separate participant groups were used: expert Web searchers consisting of graduate students and intermediate Web searchers consisting of undergrad-uate students. To ensure that the system provided the same set of search results to each participant, the results of each initial search task were cached. 5.2. Procedure
After completing a pre-experiment questionnaire, each participant was provided with a training session in which all the features of the WordBars system were explained. Using a training task as an example, the par-ticipants were required to use the system to become familiar its operation, with guidance provided by the investigator. The procedure for the user study was described as the participant worked through the training task. The training task asked the participants to  X  X  X dentify systematic explorations and scientific investigations of Antarctica, current or planned X  X , using the initial query  X  X  X ntarctica exploration X  X . The entire training pro-cedure took approximately 10 min.

When provided with each of the search tasks, the investigator answered any questions the participants had about the task itself. Each participant was asked to rate how well they understood the task. For each task, the participants were asked to perform the following steps: (1) Provide relevance scores for the top 10 documents from the initial query in the order provided by the (2) Select one or more terms from the histogram in order to re-sort the search results (with the goal of mov-(3) Refine the query by adding or removing terms from the query (with the goal of constructing a better (4) Select one or more terms from the histogram in order to re-sort the search results (with the goal of mov-
These steps represent an example of an exploratory Web search scenario, in which a user would start with an initial query and attempt to find relevant documents in the top search results. The user would then attempt to explore certain aspects of the search results by selecting a few relevant terms from the histogram, and then evaluating the top documents in the list. Next, having learned something about the search results and the terms in the histogram, the user would attempt to refine their query and evaluate the top search results from this new query. Having previously had success with using the histogram to re-sort the search results, the user may attempt to do so again using this new set of search results. While in real-world use, this cycle of refining the query and exploring the search results may continue until the user is satisfied that they have fulfilled their information need, in this study we finish after only one cycle.

After each of these steps, an in-task questionnaire was administered regarding the participants feelings of confidence and satisfaction, and impressions of ambiguity among the search results considered. Once all three tasks were completed, a post-experiment questionnaire was administered. In addition, the participants were asked to provide a ranking of their preference among the features of WordBars to which they were exposed. The entire procedure took approximately 60 min for each participant.

Each search task included a written description of the information need, along with the initial query to be used. These were selected from the TREC 2005 HARD Track 2 difficult tasks, yet understandable by a wide range of participants. The search tasks are listed below:
Task A : Identify hydroelectric projects proposed or under construction by country and location. Detailed
Task B : Isolate instances of fraud or embezzlement in the international art trade.
Task C : Identify documents that discuss opposition to the introduction of the euro, the European currency.
As the participants evaluated the sets of search results, they were asked to speak the relevance scores using a four-point relevance scale (see Table 1 ). This information was logged by the investigator, along with the time required to evaluate the top 10 documents. In addition, the time taken to choose terms for re-sorting, and the time taken to refine the queries were also logged.

In this study, the primary interest was in the Web search results interface and the ability for the participants to explore the search results and refine the queries. As such, the participants were asked to only consider the document surrogates for relevance; they were asked to not view the actual documents. If the documents within the search results had been viewed, the users would have been able to learn more about the topic as the study progressed. Keeping them from viewing the documents and basing their decisions only on the document sur-rogates and the other information provided in the WordBars interface reduced the impact of these learning effects on the study. The fact that a non-relevant document may appear to be relevant based on the title and snippet provided by the underlying search engine is beyond the scope of this research.

When collecting the top 100 search results for the search tasks, a number of duplicate documents were found. The duplication of documents with Web search engine indexes is a well-known problem ( Henzinger,
Motwani, &amp; Silverstein, 2002 ). With the tasks used in this evaluation, the number of duplicate documents was relatively small. Often, the re-sorting features of WordBars resulted in duplicate documents appearing next to one another. In these cases, the participants were instructed to provide a score for the first, and skip the duplicate. 5.3. Analysis
Since the participants have different abilities to identify relevant documents, as well as different thresholds for viewing marginally relevant documents, performing a statistical analysis on the raw relevance data may not be meaningful. Instead, we compared each participant X  X  performance using the features of WordBars to a baseline provided by their performance using the original order of the search results. In addition, we ranked each participant X  X  performance in finding relevant documents, and used pair-wise Wilcoxon signed rank test to identify the statistical significance of these results. The tasks were analysed both independently and in aggregate form.
 The subjective evaluations, which were provided on a Likert scale, were analysed using non-parametric
Friedman tests. The preference ranks were analysed using pair-wise Wilcoxon signed ranks tests. For all of these statistical tests, the expert participants were evaluated separately from the intermediate participants in order to identify the differences in their performance and subjective reactions. Where relevant, the statistical significance of these tests are noted and highlighted by a bold font.

The methods used for evaluating WordBars are a novel approach to evaluating information retrieval sys-tems. Often, test collections are available that include test queries and expert relevance judgments for all doc-uments in the collection. However, for Web search evaluations, it is difficult to obtain expert relevance judgments, even just for the top search results. Instead, we evaluate the improvements individual participants are able to make throughout the exploratory search scenario. 6. User evaluation results 6.1. Participant demographics
Twenty-four computer science students were recruited to participate in this study, and were classified into two groups. The expert group consisted of 12 graduate students; the intermediate group consisted of 12 under-graduate students (registered in first and second year computer science courses). The results from the pre-experiment questionnaire administered to these two participant groups are presented in Table 2 .

All the participants in this study indicated that they use a computer more than 10 times per week. This should come as no surprise since all the participants were students in computer science courses or programs. As is to be expected, the expert group indicated a higher degree of computer experience, and conducted more searches per week than the intermediate group. All the participants showed a preference for the Google search engine.
In terms of pages of search results viewed, the expert group showed a tendency to view fewer pages in the search results than the intermediate users. Although it is difficult to determine the reasons for these differences, we suspect it has to do with the ability and confidence the participants have in crafting queries. The members of the expert group may have had a high degree of confidence in constructing an effective query, resulting in fewer pages of documents being viewed before they either satisfied their information needs or refined their query. Among the intermediate group, a number of participants reported viewing many more than the three pages of search results that are common ( Silverstein et al., 1999; Spink et al., 2001 ). This may be due to having a strong need to satisfy their information needs, but an inability to craft or refine a query; in these cases, the only alternative is to view many pages of search results.

While both groups showed similar tendencies for adding terms to their initial queries, the intermediate group expressed more likelihood of removing terms from their query than the expert group. This may be due to the expert group having more confidence in the terms selected for their initial queries than the intermediate group. It is interesting to note that both participant groups self-reported a similar degree of Web search experience.
Prior to starting each search task, the participants were asked to report their understanding of the assigned task. In asking this question, we were not concerned with their prior knowledge on the topic, but instead how well they understood the description of the information they were to be finding. These results are illustrated in
Fig. 4 . For both participant groups, most participants reported a moderate to high degree of understanding of the topics, although there was some variability in these results between the tasks and between the groups. 6.2. Comparison to baseline
Although it is common to use variants of the precision metric for evaluating information retrieval systems ( Kobayashi &amp; Takeda, 2000 ), these metrics generally assume the existence of expert relevance scores for the documents. In this study, obtaining such expert evaluations was difficult since for each of the three tasks, each participant was asked to craft a new query using the features of WordBars. In the worst case, with each of the 24 participants of this study generating a unique new query for each task, experts would have had to decide the evaluations in this study.

Instead, the effectiveness of the features of WordBars were analyzed under the assumption that the partic-ipants all made accurate relevance judgments. Although this assumption may not be valid for all participants, each participant believed they were making accurate relevance judgement choices to the best of their abilities.
Therefore, evaluating the effectiveness of WordBars under this assumption provides a meaningful analysis of the performance of each participant using the features of the system.

In order to make a comparison for each participant X  X  performance using the features of WordBars, their performance in evaluating the search results from the initial query in the original order provided by the Goo-gle API was used as the baseline. For all four sets of documents considered (original order, first re-sort, refined query, and second resort), the number of documents that were given scores of three or four (i.e., the docu-ments that were indicated as  X  X  X robably relevant X  X  and  X  X  X elevant X  X  by the participants) were counted.
The difference between the number of relevant documents found using the baseline, and the number found for the other three sets of search results generated using the features of WordBars were counted. This allowed for the labeling of each participant as having done  X  X  X etter X  X ,  X  X  X ame X  X  or  X  X  X orse X  X  using each feature of Word-Bars for each task assigned.

As is to be expected, the ability for the participants to use the features of WordBars to find more relevant documents depends greatly upon the specific search task. It is also expected that there will be differences in the abilities of the participants in the expert and intermediate groups. As such, the results of this comparison to the baseline performance data are reported separately for each task and each participant group in Fig. 5 .
These results show that a large portion of the participants from both groups were able to effectively use the features of WordBars in each task to find more relevant documents than in the original order of the search results from the initial query. A summary of the aggregate results are provided in Table 3 .

A visual comparison of the results between the expert and intermediate groups for each tasks reveals a sim-ilarity in the general trends of performing better, the same, or worse using the WordBars features. In partic-ular, it appears that one to three more participants from the intermediate group achieved worse results than the baseline when compared to the expert group. We suggest that this difference is due to the different levels of experience and skill in Web searching. Clearly the expert participants were able to make more effective use of the features of WordBars. 6.3. Rank comparison
To further analyse the performance data, a ranking of the relative performance of each participant in find-ing relevant documents from the original order of the search results (i.e., the baseline in the previous compar-ison), as well as from each of the three other sets of search results generated using the features of WordBars was produced. This provides a more detailed view of the performance of the features of WordBars, since it considers the relative performance between the various features, rather than comparing the results only to the baseline performance of the original order of the search results from the initial query. The results of this rank comparison are provided in Fig. 6 , grouped by participant group and task (including an aggregate of all the tasks). The results of pair-wise Wilcoxon signed rank tests are provided in Table 4 . 6.3.1. Task A
For Task A (see Fig. 6 a and Table 4 a), it is clear that the best results for the expert group were achieved by re-sorting the search results from the original query. Many of the expert participants had difficulties construct-ing a new query that accurately captured the assigned information need. However, when re-sorting the search results from the refined query, these participants were able to perform nearly as well as when they re-sorted the search results from the original order.

For the participants in the intermediate group, the best results for Task A were achieved by resorting the search results from the refined query. These participants appeared to have some difficulty in the first re-sort of the search results from the initial query, as well as in constructing an effective refined query. However, most were able to achieve good results from the second re-sorting (of the refined query).
For the expert group, the improvements over the original order of the search results proved to be statisti-cally significant after re-sorting the results of the original query, as well as re-sorting the results from the refined query. There was also a significant improvement over the refined query after re-sorting. For the inter-mediate group, none of the results form Task A were statistically significant. 6.3.2. Task B
For Task B (see Fig. 6 band Table 4 b), the expert group were able to use the re-sorting feature of WordBars to achieve a moderate improvement over the results from the original search. In refining their queries, the results were much better than the original order in most cases. Re-sorting the search results from the refined query resulted in the best performance.

The participants from the intermediate group achieved similar results as those from the expert group; they showed a moderate improvement by re-sorting the original search results, and then a large improvement when refining the query. However, when re-sorting the refined query results, their performance decreased.
The improvements over the original order of the search results for the expert group proved to be statisti-cally significant for all of the features of WordBars. Although the participants were able to improve upon the refined query by re-sorting these search results, this improvement was not significant. For the intermediate group, the improvement over the original order for the first re-sort was not statistically significant, although the results from the refined query and the second re-sort were. The decrease in the performance after re-sorting the refined query results did not prove to be statistically significant. 6.3.3. Task C
For the expert group on Task C (see Fig. 6 c and Table 4 c), re-sorting the search results resulted in mod-erately better performance than the original order. Refining the query for this task produced the best results.
Re-sorting the search results of this refined query resulted in a decrease in the performance compared to the refined query, but still a substantial increase over the original order.

The participants from the intermediate group showed a continued improvement over the original search results as they used the features of WordBars to re-sort the original search results, refine the query, and then re-sort the results of the refined query. The refined query and the re-sorted results from the refined query were substantially better than the original order and the re-sorted results from the original order.

For the expert group, the improvements over the original order for all the features of WordBars proved to be statistically significant. The decrease in performance after re-sorting the refined query results did not prove to be statistically significant. The moderate improvement by the intermediate group in using WordBars to re-sort the original search results did not prove to be statistically significant. However, the results provided by refining the query and performing the second re-sort were significant. The improvement of the second re-sort over the refined query was not significant. 6.3.4. Negative performance
In Task B for the intermediate group, and Task C for the expert group, there was a reduction in the per-formance of the participants using WordBars to re-sort the results of the refined query. This negative perfor-mance did not prove to be statistically significant in either case. It can be attributed to a number of participants finding all 10 documents to be relevant in the refined query search results, leaving no room for improvement from the re-sorting features. In other cases, poor choices of terms from the histogram resulted in a re-sorting of these search results that was not effective.
 6.3.5. All tasks (aggregate)
When considering the data from all tasks as an aggregate (see Fig. 6 d and Table 4 d), the improvement in finding relevant documents using the features of WordBars is clear. The participants showed an increase in their ability to find relevant documents after re-sorting the original search results, a further increase after refin-ing their query, and a continued increase after re-sorting the results from their refined query. These improve-ments over the original search results were shown to be statistically significant. The results from this analysis are very positive, and illustrate the potential effectiveness of interactively exploring the search results and inter-actively refining a query through the features of the WordBars term frequency histogram.
 However, when considering each task and participant group separately, it is not clear which feature of
WordBars is the most effective. In some cases, the participants performed best when re-sorting the results of the original query. In other cases, the participants were able to effectively refine their queries, resulting in a significant improvement. Some participants were able to further improve their performance through re-sorting the search results from their refined queries. Although the aggregate analysis shows that with each step an improvement can be made, one of the great benefits of the exploratory features of WordBars is that each user can choose the method that works best for them for their current search task. One user may take advantage of the search results exploration features of WordBars when conducting an exploratory search, whereas another may find the query refinement features most beneficial while conducting a fact-finding search. An avenue for further evaluation is to assess the abilities of the users to take advantage of the support Word-
Bars provides as they become more familiar with the features of the system and the support it provides for their various Web search tasks. 6.4. Time to make selections
While it would be beneficial to comment on the amount of time the participants took to evaluate the search results at each stage of using WordBars, there are extensive learning effects within this data. For example, the time the participants took in the second stage to evaluate the WordBars histogram for re-sorting the search results allowed them to make selections in the third stage for query refinement much more quickly than if the second stage had not occurred. Further, there is a high degree of variability in this data as a result of the different techniques participants used while considering the terms in the histograms. Some participants quickly evaluated each term, and selected all that they considered to be relevant. Others carefully considered each term, and experimented with the results of selecting and un-selecting terms. Therefore, it is difficult to make strong statements with respect to how much more time the participants spent when using the features of WordBars. 6.5. Subjective measures
After evaluating the 10 search results in each step of using WordBars, participants completed a short in-task questionnaire to measure their subjective reactions to using the specific feature to find relevant documents for the assigned task. Of interest were the participants X  feelings of confidence in finding relevant documents, satisfaction with the search results considered, and perceptions of ambiguity among the search results set.
While there may have been some learning effects within these results, they are strongly influenced by the rel-evance of the documents considered by the participants, and provide an indication of whether the participants felt they were performing better or worse in each step of the study. In general, these subjective measures were very positively in favour of the features of WordBars, and showed little differences between the expert and intermediate groups.

For the confidence measure, the participants rated how confident they were in their ability to find a good set of relevant documents ( Fig. 7 a). For the satisfaction measure, the participants rated how satisfied they were with the documents considered in the search results set ( Fig. 7 b). For the ambiguity measure, the participants rated how ambiguous they thought the search result set was ( Fig. 7 c). With all three of these measures, the search results from the original order followed a normal distribution. The re-sorting of the original search results, refining the query, and re-sorting the refined query search results were all positively skewed to varying degrees, both for the expert and intermediate groups.

Of note are the subtle differences between the expert and intermediate groups. The expert group reported the highest confidence and least amount of ambiguity after the final step of the evaluation, whereas the inter-mediate group were most confident and found the results to be less ambiguous after the refinement step. In the satisfaction measure, there were few differences between the two groups. Although this is somewhat contrary to the aggregate performance data (see Fig. 6 d), it is possible that intermediate participants found the final stage of the evaluation unnecessary. The results of Friedman tests on these responses showed them to be sta-tistically significant. These statistics are reported in Table 5 . 6.6. Preference rank
After all the tasks were completed by the participants, a post-experiment questionnaire was administered which included a question asking the participants to rank their preference for the search results considered.
That is, each participant was asked to indicate at which stage of using WordBars they thought they got the best search results, the second-best search results, the third-best search results, and the fourth-best search results. The options were (a) search results in the original order, (b) the search results after re-sorting, (c) the search results after refining the query, and (d) the search results after re-sorting the refined query. These rank responses are reported in Fig. 8 .

The original order of the search results was almost unanimously ranked last (fourth) by participants in both groups (although one participant from the intermediate group ranked it first). This result provides a clear indi-cation that almost all the participants found value in the interactive query refinement and interactive search results exploration features of WordBars.

Among the participants in the expert group, the rank depended greatly upon their ability to refine the query. Those who were able to effectively choose relevant terms to add to their query (as well as replace or remove ambiguous terms) tended to select (c) the refined query as their top preference, followed by (d) the second re-sorting of the refined query as their second choice, and (b) the first re-sort of the original search results as their third choice. The participants who had difficulty choosing terms with which to refine their query tended to indicate (b) the first re-sorting of the original search results to be most preferable. They also had a tendency to indicate that (d) the second re-sorting of the refined query was preferable to (c) the refined query itself.

It is interesting to note that for the expert group, their preference ranks did not follow their performance when considering all tasks in aggregate (see Table 6 d). This may be due to the difficulties some had with refin-ing their queries, as well as their generally high level of confidence in initial queries due to their expert Web search abilities. Further, many of these participants reported viewing few pages of search results, which indi-cates a low tolerance for spending time searching. For some, this low tolerance may have resulted in lower rankings for the tasks that would have taken more time (i.e., refining and further exploring the search results).
For the intermediate group, there was a clear preference for the ability to (c) refine their queries as well as (d) subsequently re-sort the results from the refined query. This followed closely their performance when con-sidering all tasks in aggregate (see Table 6 d). The low rank responses for re-sorting the results of the original query may be due to the lower experience and Web search skill levels of the participants in this group. This may have resulted low confidence in the initial search results, and therefore, in their ability to re-sort and explore these search results.

A pair-wise analysis of the rank responses using Wilcoxon signed ranks tests are reported in Table 6 . For the expert group, all the features of WordBars, including (b) the first re-sort, (c) the refined query, and (d) the second re-sort, were shown to be preferable to (a) the original order of the search results, with statistical sig-nificance. However, there was no clear preference between the features of WordBars themselves. For the inter-mediate group, (c) the refined query and (d) the re-sort of the refined query results were shown to be preferable to (a) the original order of the search results, with statistical significance. Further, (d) the second re-sort was shown to be significantly preferable to (b) the first re-sort. 7. Discussion 7.1. WordBars features
One of the primary limitations of WordBars is that there is little ability to support the users in their explor-atory Web search tasks when a very poor initial query is provided. If no relevant document surrogates are returned within the top 100 search results, then the ability to explore the search results is of little value to the users. The terms that are common among these top search results will likely not be relevant to the user X  X  information need, making it difficult for them to choose from the term frequency histogram. However, the lack of relevant terms in the term frequency histogram may indicate to the user that they need to start with a better initial query than the one provided.
 Supposing that at least some of the document surrogates returned from the initial search are relevant,
WordBars can be very beneficial in assisting the users in their information retrieval tasks. The term frequency histogram provides a visual indication to the users of the relative frequencies of the terms used in the top doc-ument surrogates from the search results. The users may explore the search results through re-sorting based on the terms they select as relevant to their information need. They can use these terms to further refine their query, commonly resulting in a more specific set of search results that can then be explored further.
The term frequencies in WordBars are generated from a subset of the actual document: the title and the snip-pet provided by the Google API. The title is commonly descriptive of the information within the document, and the snippet contains contextual information regarding the use of the query terms within the document. These both provide valuable information about the documents in the search results, providing the basis for the gen-eration of the term frequency histogram. However, for some documents, Web search engines have a difficult time generating a meaningful title and snippet. In these cases, little information of value is provided in the doc-ument surrogate, making it difficult for WordBars to provide assistance to the users based on these documents.
The generation of the WordBars histogram is based only on the information present in the document sur-rogates. While it would be possible to retrieve the entire textual contents of each document in the search results list, the outcome would be significant delays in presenting the search results to the users. As an interactive Web search interface, such a delay would not be acceptable. Since the title and snippet are commonly descriptive of the documents themselves, further investigation may find that they generate a better list of terms than if the entire textual documents were considered.

Since only a simple pre-processing of the title and snippet are performed, it is possible for terms that are not meaningful to appear in the term frequency histogram. For example, the word  X  X  X wo X  X  may appear somewhat frequently in the top search results for a given query, even though this word is not meaningful for search results exploration or query refinement. While it is possible to add such terms to the stop-words list, in some situations, these terms may be relevant and meaningful. As such, the stop-words list is limited to commonly used verbs, adverbs, pronouns, and prepositions, which are of little value in exploring the search results or refining the queries.

Even when presented with a list of potential terms to add to a query, research has shown that users may still have difficulties choosing good terms to use for query expansion ( Ruthven, 2003; Magennis &amp; Rijsbergen, 1997 ).
However, in the techniques considered by these authors, the query terms were presented to the users in a simple list format. WordBars provides a visual representation of the frequency of the terms, as well as an indication of which terms are present in the current query. Further, the ability to re-sort the search results can allow users to see how potential query expansion terms may be used. This additional information can allow the users to make informed decisions for query expansion that would not be possible when simply considering terms in a list. 7.2. User evaluations
As noted by White, Muresan, and Marchionini (2006) , evaluating systems that have many interactive options is difficult due to the large number of experimental variations that must be evaluated. Further, separating individual features may produce artificial results that are substantially different than when the fea-tures are all used together. As a result, it is challenging to design user evaluations that are somewhat realistic, yet allow for the measurement and evaluation of key performance metrics.

The user studies reported in this work attempted to control the interaction to mimic an exploratory Web search scenario. Since each participant performed the same tasks and followed the same general interaction procedures, the benefit of this design was that data collected could be compared between the stages in the interaction as well as between the two groups of participants. However, separating the dependent and inde-pendent variables proved to be rather difficult due to the complexity of the interaction supported by the sys-tem. It is difficult to comment on how much of the outcome was a result of the features of WordBars, and how much was due to the abilities of the participants. At any rate, the results indicate that the participants were effectively able to make use of the visual and interactive features to improve their Web search performance.
There are four features of the user evaluations that are worth discussing in further detail: the tasks, the par-ticipants, the relevance judgments, and the search procedures. The three search tasks used in this study were intentionally chosen to be easy to understand, yet somewhat ambiguous. By choosing easy to understand tasks, prior knowledge or experience in the task domain was not necessary. By choosing tasks that were also somewhat ambiguous, the top search results returned by the Google API included a mixture of relevant and non-relevant documents. With very specific tasks, Google and other Web search engines perform very well, providing many highly relevant documents in the top search results, leaving little room for improvement.
However, for ambiguous tasks, there is a great opportunity to improve the performance of the users through interactive query refinement and interactive search results exploration, as we have seen in this study.
By conducting the user evaluations with two distinct participant groups, we were able to not only determine the potential effectiveness of WordBars for these groups, but also to make comparisons between these groups in terms of the participants X  abilities to use this exploratory Web search system to find relevant documents.
While the aggregate performance over all three tasks was very similar for both groups, the expert group per-formed much better than the intermediate group when re-sorting the search results from the initial query. The subjective reactions were very similar for both groups. As is to be expected from the aggregate performance results, the intermediate participants ranked the refinement and subsequent re-sorting features as most pref-erable. By contrast, the expert participants also indicated the first re-sort as a preferable feature, even though their performance results for this feature were not as good as re-sorting the search results from the refined query.

Since expert evaluations of the documents were not available, the performance of the participants in terms of finding relevant documents was based solely on the relevance scores provided by the participants. Our assumption that the participants were able to give accurate relevance judgments ignored the situations where the title, snippet, and URL for a document were misleading, or where the participant incorrectly interpreted the information provided. We can ignore these errors since it was possible for the participants to make them during all stages of the study (including the baseline evaluation of the search results in the original order).
Therefore, from the perspective of the user, the assumption of accurate relevance judgments does not inval-idate the results reported in this study. Evaluating whether users are able to accurately make relevance judg-ments given the limited information provided by Web search engines is worth further study, not just with WordBars, but with Web search results in general.
 Even though the results of this study were very positive, and indicate that in most cases the features of
WordBars can help the users to find more relevant documents, we believe that real-world use may result in even better results. This study required the participants to use WordBars in a structured and measured man-ner, by first evaluating the top 10 documents, then re-sorting the search results and evaluating the top 10 doc-uments, followed by refining the query and evaluating the top 10 documents, and then re-sorting the search results again and evaluating the top 10 documents. The participants had only one chance to select terms for re-sorting, as well as for refining their query. In real-world use, users can easily experiment with  X  X  X hat-if X  X  scenarios, selecting terms for re-sorting, considering a few documents, making further selections or changes, considering the results of these changes, etc. Similarly, for refining the query, if the users feel that they have made a mistake in modifying the query, they could easily return to the previous query, or attempt to make a further refinement of the query. Therefore, in future research, we wish to study the benefits of interactive query refinement and interactive search results exploration under real-world Web search conditions.

Other methods for evaluating an interactive Web search system such as WordBars may be used in the future to determine the potential effectiveness of the various features. Borlund (2003) describes a controlled evaluation model that uses realistic search scenarios for participants to complete (called simulated work tasks) and performance measures based on subjective relevance assessments such as relative relevance (RR), ranked half-life (RHL) ( Borlund &amp; Ingwersen, 1998 ), cumulated gain (CG), and cumulated gain with discount (CGD)
Bars in more realistic search settings. White, Ruthven, Jose, and van Rijsbergen (2006) describes a method for simulating user interaction at the search interface as a means for choosing among different alternatives for a query modification system. A similar approach may be used to evaluate different methods for choosing sets of potentially relevant terms to display to the users in WordBars. 8. Conclusions and future work
In this paper, we have presented our work on the development of an exploratory Web search system that allows the users to interactively explore Web search results, as well as interactively refine their queries.
Although these tasks are fundamentally different, they comprise the key aspects of exploratory search. By pro-viding the ability for the users to both explore the search results and refine their queries in the same interface, the users are able to easily transfer back and forth between these two tasks. The visual representation of the term frequencies, and the interactive nature of the features of WordBars allows the users to take advantage of their intelligence and judgement abilities as they perform their information retrieval tasks.

Through the visual representation of the term frequency histogram, the users can easily identify the relative frequencies of their query terms in the top search results, as well as the relative frequencies of other terms pres-ent in the document surrogates. Identifying terms in this histogram can help the user to understand the general makeup of the search results, as well as the degree of specificity of their initial query. Terms can easily be selected, resulting in a re-sorting of the search results based on the frequencies of the selected terms, assisting the users in exploring the search results. Terms can also be added or removed from the query, automatically generating a new set of search results which the user can explore further.
 Although the techniques used in this work are rather simple, there is a benefit to the users for this simplicity.
The interface is uncluttered, easy to learn, and simple to use. There are no complex interactions required to re-sort the search results, nor to add or remove terms from the query. The frequency statistics are calculated interactively as the search results are retrieved from the Google API, resulting in a minimal delay. These sta-tistics are easy for the users to make sense of, and result in a meaningful ordering of the terms present in the search results. The visual display of this information allows the users to easily, quickly, and accurately perceive and interpret the term frequencies, and make use of this information to support their interactive query refine-ment and interactive search results exploration tasks.

In the user evaluations, the effectiveness of the interactive and visual features of WordBars were evaluated with respect to supporting users X  Web search and exploration tasks. The participants X  abilities to find relevant documents in the top search results returned from an initial query were compared to their abilities to find rel-evant documents when they re-sorted the search results, when they constructed a refined query, and when they re-sorted the search results from the refined query. The primary information tool that was used to support the re-sorting and query refinement processes was a term frequency histogram generated from the most frequent terms appearing in the top 100 search results.

The results of this study are very positive. In most cases, there was an improvement in the performance of the participants using the re-sorting and query refinement features of WordBars, in comparison to the top search results in the original order provided by the Google API. Further, it was shown that when considering the aggregate results from all three tasks, these improvements are statistically significant for both the expert and intermediate participant groups.

The subjective measures reported by the participants were very positive in favour of WordBars. Among the expert group all participants ranked some aspect of the use of WordBars above the original order of the search results. However, there wasn X  X  a clear indication of which feature was most beneficial. For the intermediate group, all but one participant ranked some aspect of WordBars above the original order of the search results.
These participants showed a clear preference for the query refinement and subsequent re-sorting of the search results.
 The results of this study provide strong evidence in support of the fundamental hypothesis in the design of
WordBars: that frequently used terms in the results of an initial search can provide valuable information to the user, both for crafting a better query as well as for re-sorting and exploring the search results. WordBars rep-resents an example of what we believe will be the next generation of Web search interfaces: tools that focus on supporting the fundamental Web search tasks through interactive query refinement and interactive search results exploration.

In future work, we wish to explore the effectiveness of WordBars in real-world use situations, over extended periods of time. As well, an investigation of the differences between using only the title and snippet versus the entire textual contents of the documents for constructing the term frequency histogram will be of value. We plan to add additional features to allow the users to have more control over the exploration of the search results, to assign different weights to terms of interest, and to construct complex queries. The ability to per-sonalize the search results based on previous term selection will also be investigated.
 References
