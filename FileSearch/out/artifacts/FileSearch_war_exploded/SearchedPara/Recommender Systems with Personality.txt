 We believe that in the future, the most common form of recom-mender systems will be present in a personal assistant. We claim that such an intelligent agent must be personal, i.e., know its user X  X  preferences and recommend relevant content, a dynamic learner, instructable, supportive and affable. We describe the current state of the art and the challenges which should be addressed in each of these agent properties and provide examples of how we expect future personal agents to convey these properties.
Modern smartphones come with an array of rich sensors, fast networking capabilities, significant CPU power, and mass storage. Most smartphones also come with a mobile agent: Android devices come with Google Now, iPhone devices with Siri, and Microsoft devices with Cortana. Despite this, the major use of these intelli-gent agents is for web search, or for very simple commands such as launching an app or setting an alarm. These agents are not that of-ten used as a recommender systems, and usually do not recommend content without explicitly being asked. Much of the functionality these agents offer does not push far beyond today X  X  direct manip-ulation user interfaces [8], in which an agent X  X  actions are an im-mediate response to a user command, or a preprogrammed feature, rather than people using the agent as an actual proxy.

While prototypes for personal assistants date back to over two decades ago [11], we believe that the time is now ripe for making a quantum leap in what an intelligent personal assistant can offer. While, currently, some personal assistants are used for recommen-dations (e.g. asking Siri for good restaurants near by), and some recommender systems try adding agent personality to them (e.g. Emmy at TasteKid), we believe that future recommender systems will have a much richer  X  X ersonality X  and that the most common form of recommender systems will be a personal assistant. We claim that a personal assistant agent should be: personal , being personalized to each user knowing its user X  X  preferences and rec-ommending relevant content, and doing so in a privacy-sensitive manner; a dynamic learner , continuously learning and acquiring knowledge about the world and about the user, actively learning the user X  X  preferences; supportive , providing long-term assistance, and initiating actions in order to pursue users goals and tasks; affa-ble , offering interaction methods which appear natural to the user and can build rapport with her over time; and instructable , allow-ing the user to tailor the agent and its recommendations to her per-sonal needs, by allowing the user to teach the agent what she wants and how to do it.

Such an agent is nearly possible due to major advances in hard-ware, systems, algorithms, and data. Smart devices (such as smart-phones, smart-watches, smart-glasses, and smart clothes) are start-ing to become ubiquitous, and each of these devices comes with a rich range of on-board sensors that can gather tremendous amounts of data about their users and the environments in which they op-erate. The widespread availability of cloud computing, fast wire-less networking, and cheap storage further enhances these capabili-ties. With respect to algorithms and data, the rise of big data, along with relevant machine learning algorithms, provides us with impor-tant capabilities which were previously out of reach, such as high-quality automatic speech recognition, image and gesture recogni-tion, machine translation, and natural language understanding and grounding. There has also been a leap in text-to-speech and non-verbal gesture generation for virtual agents. All these advances provide a never ending interaction opportunity for personal agents to learn user X  X  preferences and provide much better recommenda-tions which are much more personalized to each user and tailored to her needs and goals. In this paper, we drill down on each of the themes we believe an intelligent personal agent should be able to offer within a decade and show how these themes are relevant for recommending better content, actions and behavior.
The key idea behind recommender systems is that people are dif-ferent, and that recommendations should vary according to users X  personal preferences and interests. In the past, the content on the web was identical for all users (no personalization), in the present, the recommendation system is identical to everyone (but has per-sonalized output depending on the user X  X  history). We believe that in the future, each user will have her own agent which provides these recommendations. In order for a user to feel that recommen-dations are truly tailored to her they should come from an agent which is truly personalized to her. Using all the sensors and user history as input, the personal agent may collect enormous infor-mation on the user. High personalization level of such personal assistants entails that each user may actually have a unique agent. We therefore propose that each agent may have a unique name, voice and body appearance which travel across all possible plat-forms (phone, watch, glasses, laptop, etc.). Perhaps, these unique names may be non-word names (which can X  X  collide with other people the user knows). These names may be generated based on the user X  X  demographics. One name generation method could be based simply on the frequency of different n-grams in names in the user X  X  country, possibly filtered by age and gender 1 , or even take into account the user X  X  email, contacts and other personal informa-tion. Such agents express the differences between different agents, and make it clear to a user that her agent belongs to her which may help it become more trustworthy.

Since personalization requires collecting sensitive data on the user, it raises a serious threat of privacy invasion. Furthermore, since people are different and unique. Indeed, currently, any usage of an agent comes with a high privacy price tag. Anyone using an agent agrees that any information sent to the agent will serve the company which built it. This implies that people are likely to avoid sharing sensitive information with it. The agent does not actually belong to them, but to some corporation. We believe that this is one of the main roadblocks of this field, and that it will grow stronger as the field continues to advance. We therefore argue that the single overall goal for the agent must be assisting their user and provid-ing relevant content to them in order to help her accomplish her own goals (e.g. saving time, making tasks easier, being more pro-ductive, healthier, success in school or other user-defined goals). That is, the agent is there for its user, and data collected by the agent should not be shared with anyone (as if it does not leave the user X  X  phone), unless the user explicitly wants to share this infor-mation, or the agent believes that it is the user X  X  will. Using an agent should require a minimal privacy price tag. The current basic market model is that recommender systems are hosted on a website and collect as much information as they can on each user, in or-der to provide relevant recommendations. Personal agents collect as much information as they can which is shared with the com-pany building those agents, allowing that company to post relevant ads. We believe that if the agent would collect this information and share it will the relevant websites or services on behalf of the user, both sides could benefit. The user will have full control over what is shared with whom, and since the user would receive recom-mendations which take into account far more information than any singe website could collect, the user is more likely to make a pur-chase or consume relevant content. While, we may want to assume that all the user specific information does not actually leave the user X  X  phone, this may not be optimal in terms of speed and func-tionality especially if the agent operates across multiple platforms. Therefore, the user may either have her own hardware which keeps this information, or ,if this information does reside on a companies server, the user must be assured that it is not shared with anyone (not even the agent developers) unless instructed by the user. An-other privacy related challenge is selective sharing: since the agent will have access to a large amount of sensitive data, the user can-not always explicitly tell the agent which data to share with whom. Therefore, the agent must learn which information to share with other people, personal agents, or third part agents and apps. The agent is not limited to sharing raw data, but may decide to share (and even sell) some high level, averaged or noised data, share a model built using the data, or provide anonymized data and ensure that the released data may not be de-anonymized. In our vision, there is no single source who has all the data, but many agents each with a different goal, some personal agents and some may be third party agents and even research agents (e.g. a diabetics agent which collects data from diabetics user who decide to share their data).
This unique name generation method using letter-based trigram frequency, based on female names, with year of birth of 1980, in the USA, yield the following unique names: Jerlessey, Roberica, Vinaly, Jerin, Pathley, Amarissa, Laniquela, Jillistin and Trany. Each agent accesses different data, and knowledge is on a  X  X eed to know X  basis.
In order to recommend highly relevant content the agent must be a constant learner. The main dimension of learning should be about the individual. Modern smart devices offer a wealth of in-formation about individuals, including one X  X  calendar, Facebook, email, text messages, call logs, and a great number of sensors. This kind of information can be used to learn about a person X  X  com-munication habits, relationship with others, and general activities, which in-tern could be used to provide more relevant content or recommendations. However, one major research challenge is that it can be hard to create generalizable models of individuals. For example, it is easy for anyone in the world to verify many general inferences (e.g.  X  X ockey is a sport X ), but very few people can ver-ify a personal inference such as  X  X ohn is the user X  X  best friend X . Another major research challenge is that data is siloed across many different devices, apps, services, and formats. As one example, Wiese et al. [15] have found that a person X  X  contacts often spread across their smartphone, Facebook, LinkedIn, and email. Wiese et al. have pointed that it may be hard to integrate contacts across these services, in part due to unusual contact names such as  X  X at (Neighbor), X   X  X om at Home X , and  X  X o Not Answer X . We believe that learning both user preferences and a general knowledge should be an active and never ending process.

Learning should not be limited to the individual user X  X  prefer-ences, but the agent could also better perform if it learned general facts about the world. One example for a never ending learner is NELL [12], which has the goal of reading and learning from the mass amounts of text on the web. The same can be done with the large quantity of images [4], sounds, and videos on the web. This kind of knowledge can help disambiguate queries, understand rela-tionships between entities, common-sense, and help with execution of tasks. For example, if the agent is given a task to organize a sur-prise party for John, it should know that it should contact John X  X  friends and not John.

The widespread adoption of crowdsourcing also offers new op-portunities for learning. An agent that requires certain information (perhaps for completing a certain task) might post it on a ques-tion answering websites or on a crowdsourcing platform, and have other crowd workers rate the quality of the response. Over time, the agent might also learn from these crowd responses in an active manner. One example for a system that allows people to converse with the crowd is Chorus, [10]. Chorus uses the crowd to rank its own candidate responses in an attempt to provide the best response to a user X  X  query. These responses are later used to train the system.
A simple usage of this knowledge is annotation of content with respect to user goals and preferences. For example, assume that the agent knows that the user is interested in  X  X pace exploration X  the agent should know that an article about  X  X he curiosity rover X  is highly relevant, despite not mentioning the word  X  X pace X  or even  X  X lanet X  or  X  X ars X  in it. The agent may use its learned knowledge to encourage the user to perform certain tasks, for example, the agent may tell a user aiming at wight loss, that her friend has just posted that he is looking for a partner for running, or the agent may notice that it is currently raining outside and thus suggest indoor activity instead. When communicating with the user the agent can also refer to common ground, for example, the agent can use a landmark, when assisting the user in a navigation task (e.g.  X  X rive past your grocery store X ).

Perhaps, the most important knowledge which the agent must pursue to acquire is user preferences. Learning users X  preferences is not limited to user history purchase, or a thumbs up or down on a given content. An intelligent personal agent must proactively try to understand its user X  X  preferences. Therefore, the agent should use active learning and suggests content which may not be the con-tent which the agent predicts that the user will like best, but by suggesting this content the agent learns more about the user, and future content can be better personalized. User preferences can also be learned using preferences of social groups, using common methods such as collaborative filtering [2]. The agent can approach the exploration and exploitation problem in the larger context of all users and try to maximize the social welfare. User preference elicitation is not limited to content provision, but also has to do with learning users privacy preferences. The agent will learn the user X  X  privacy preferences (using similar techniques) and consider these preferences when deciding whether to share some informa-tion with a service provider or other agents. Since user models are complex they should not be treated only as a set of weights to be assigned to a set of features. The intelligent agent should try to adopt a set of rules which best explains user actions and the con-tent which the user is most interested in (possibly using first order logic) [14]. The user should be allowed to update this user model and rules according to her actual preferences and interests.
Another challenge for the agent is to learn user routines and us-age patterns by observing user behavior. These routines and pat-terns can be used to discover irregularities, which may impose that the user may require help, in which case, the agent could recom-mend some actions such as visiting a physician, recommend some different behavior, such a healthier diet, or a relevant product which may be of help. The agent might also recommend a pattern used by a different user, if it assumes that it is more efficient. User us-age patterns can also be useful when considering a perfect timing for the agent to interrupt the user for suggesting content, triggering reminders, or obtaining feedback.
We believe that a personal assistant should be a long-term assis-tant, i.e. take into account the user X  X  long-term goals while provid-ing recommendations or taking actions, just as human assistants may do. A human assistant seeks relevant content and accom-plishes tasks in order to complete the requester X  X  long-term goal. Current recommeder systems are very myopic, most of the time recommending a specific product without taking into account that the user may be returning to the website the next day. While some recommender system do try taking the future into account [13], still they are very  X  X arrow minded X , limited to recommending a set of products or content, and are totally unaware of the broader context, which includes what the user actually wants and her goals. Cur-rent personal assistants, on the other hand, only respond to user queries, actions or specific events. For example, the user may ask a question, and get a response, or send a message, set an alarm or any other action which is immediately executed. The agent should learn about many possible long-term goals in general, but may modify the common time-line structure of a specific goal to best suit its user. A long term assistant must be aware of some of the user X  X  goals and tasks, and initiate actions in order to pursue the accom-plishment of these goals over a period of time.

One example of such long-term assistant may include writing a paper for a conference. The agent is aware of the paper content, the co-authors, the deadlines and the venue and monitors the user X  X  progress. The agent can recommend related work and notify the user if new relevant papers are published. It can show a dashboard helping the user track the progress in writing the paper and alert the user when proposed milestones should be reached and make sure that the user notices relevant emails. If required, the agent may recommend that the user contacts co-authors who were asked to provide feedback or write certain parts, if it notices that this hasn X  X  been done. Eventually, the agent may help in registering for the venue and recommend a hotel and flight. The agent can also help with reimbursements before or after the trip. The agent can apply knowledge it has about trips in general for providing recommen-dations (such as interesting places to visit, restaurants, hotels etc.). Additional long-term examples may include, losing weight, health behaviors such as workout and taking medication, teaching a class. A long-term goal may even be buying an item, such as a good cam-era, in which the agent may recommend content which will allow the user to learn about the possible options and important prop-erties of the interested item (e.g. ISO, HDR, Shutter-speed, focal length, aperture etc.), and only then recommend content related to specific items or brands. With such goals which span over months or even years, it may be challenging for the agent to acknowledge whether it was helpful, and whether its provided content was use-ful. Depending on its belief, it may decide to selectively share some information with other users X  agents.
Human communication and rapport establishment involves many channels, including verbal speech, tone, and body language. The timing of speech also plays a role, with people cutting-off or com-pleting each other X  X  sentences. Humans also take into account each other X  X  context and will talk differently if they know, for example, that someone is currently driving. However, today X  X  agents only make use of very little of this rich input. Recent advances in gesture detection, acoustic modeling, and virtual agents make it possible to offer an embodied agent which can take in as input both audio and visual non-verbal cues [5]. The agent can also incorporate multiple approaches to establish rapport with the user, for example by vary-ing its language and gestures as a function of the rapport level it be-lieves that it is having with the user [6]. This same agent should be ubiquitous, and allowed to be accessed via wearable devices, lap-tops, tablets, etc. Cross-device presence raises a major challenge for a consistent and unified user experience. The agent must be fully aware of its actions and which interaction channels are cur-rently being used. For example, if the user is using a navigation application, and tells the agent "I can take it from here", the agent should reply gracefully and stop providing navigation instructions (unlike current agents which are not aware that they are currently providing navigation instructions, and thus perform a web search instead). The agent also needs to appear as unified to users, as if it were a single entity, despite having a wide range of front-ends that users interact with. The agent also needs to capture what interac-tions have happened on different devices, and also be aware that it may not be able to perform certain tasks on certain devices.
Current personal agents are rigid, limited to predefined com-mands, and not extendable by the end users. For example, if Google Now finds a flight reservation in a user X  X  email it will recommend the user to leave for the airport when it is time to do so. However, this capability is predefined (handcrafted) and the user cannot ex-tend this functionality by requesting the agent to notify her if she should leave for an important meeting located out of town. Cur-rent apps are developed only if there are enough users who will use them.

While this theme falls beyond recommender systems, our vision is to allow end users to instruct their agent in natural language, us-ing the agent X  X  sensors and effectors as well as its general and pri-vate knowledge. The user should be able to define any procedure or rule (if-then clause) in a natural way, just as the user would instruct and teach another human [1, 7]. Recent advances in grounded lan-guage acquisition [3], learning by demonstration [9] and natural language parsing and understanding, lead us to believe that over-coming this challenge is closer than ever.

If we take the above example, a user should be able to define her own command simply by saying:  X  X et me know when it X  X  time to leave for the airport X . The agent may know how to add this rule, but if not, the agent may ask follow-up questions leading the user to further explain. Users will be able to define numerous func-tionalities without a need for knowledge on programming. Once functionalities are defined, users will be able to share these func-tionalities with each other.

We argue that the agent should learn these commands on demand and in a natural way for the user, i.e., the user gives commands (or creates rules) and if the agent doesn X  X  understand, it may ask the user to explain what it should do (or how it should apply the rule). With such methodology, the user is not required to inform the agent that it is about to teach it something new, but simply uses the agent casually, and only if the agent fails, will the user be required to teach it. Since the user actually needs this functionality (and thus gave the agent the command), she may be willing to spend the time and teach the agent this new functionality. Once acquired, the user may share this new acquired command with others or the public. If, on the other hand, the user refuses to teach the agent or fails doing so, the agent may contact the crowd for help. Some users (or crowd workers) may also help by defining composite virtual sensors which can be used by others.
In this paper we present our vision for a personal assistant, argue that in the future, the most common form of recommender system would be a personal assistant, and list the most important proper-ties of such an agent. The question remains, as whether a personal assistant can be viewed as a form of a recommender system. We believe that any boundaries between the two, lie in the level of au-tonomy given to the agent.

In the present, the most commonly used recommender system, is one in which the recommender system responds either to an explicit or implicit request by a user, and provides either recommended items, content, movies, etc. The next level of autonomy, could include agents that initiate action recommendation such as recom-mending that the user leaves to the airport (as present in Google Now). The next level can include an agent that takes actions on behalf of the user but still requires confirmation on any such ac-tion (for example, any email it sends on behalf of the user). All actions of such an agent, could still be viewed as a recommenda-tions. The next level of autonomy, includes an agent which may autonomously take actions on behalf of the user if it is confident enough that the user would confirm the action. Future personal as-sistants may either have the user set a threshold for this confident level, or learn the optimal threshold for each user and each domain (based on user actions and data). We believe that this intermediate-level of autonomy is the perfect blend of recommender systems and fully autonomous agents. Indeed one of the original papers to de-scribe the use of personal assistants, took use of such a threshold and performed actions autonomously, if such a threshold was met [11]. A fully autonomous agent which acts on behalf of the user at all times (possibly leaving the user some high-level control), is no longer a recommender system. However, we believe that while such level of autonomy may be useful for some domains (e.g. space exploration), it is not very useful as a personal assistant, as we be-lieve that even in the far fetched future, users would always want some level of direct control over their personal assistants.
This work was supported by the Yahoo! InMind project for the development of an intelligent personal mobile agent. [1] Amos Azaria, Jayant Krishnamurthy, and Tom M Mitchell. [2] John S Breese, David Heckerman, and Carl Kadie. Empirical [3] David L Chen and Raymond J Mooney. Learning to interpret [4] Xinlei Chen, Ashish Shrivastava, and Arpan Gupta. Neil: [5] Fiorella De Rosis, Catherine Pelachaud, Isabella Poggi, [6] Lixing Huang, Louis-Philippe Morency, and Jonathan [7] Ting-Hao Kenneth Huang, Amos Azaria, and Jeffrey P [8] Edwin L Hutchins, James D Hollan, and Donald A Norman. [9] George Konidaris, Scott Kuindersma, Roderic Grupen, and [10] Walter S Lasecki, Rachel Wesley, Jeffrey Nichols, Anand [11] Pattie Maes et al. Agents that reduce work and information [12] Tom M Mitchell, William Cohen, Estevam Hruschka, Partha [13] Guy Shani, Ronen I Brafman, and David Heckerman. An [14] William Yang Wang, Kathryn Mazaitis, and William W [15] Jason Wiese, Jason I Hong, and John Zimmerman.

