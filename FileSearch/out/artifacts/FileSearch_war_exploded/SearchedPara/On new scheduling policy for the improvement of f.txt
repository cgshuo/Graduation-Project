 1. Introduction Real-time database systems (RTDBSs) must guarantee the transactions ACID (Atomicity, Consistency,
Isolation, Durability) properties on one hand, and they must schedule the transactions in order to meet their individual deadlines, on the other hand [1] . An RTDBS can be considered as a combination of a traditional database system and a real-time system (RTS).

Real-time systems (RTSs) are defined as systems in which the correctness of the system depends not only on and analysis methods have focused on transactions with hard deadlines, and they are based on the knowledge of the activation period and worst case execution time (WCET). Once this information is provided, some classical have been devoted to RTSs characteristics. We quote for instance the study of the WCET of tasks [8] and the estimation of WCET in hard RTSs [9] . The purpose of such methods is to produce estimates of the WCET of tasks (considered in isolation) on their target hardware. To be valid for use in hard real-time systems, WCET estimates must be safe, i.e. guaranteed not to underestimate the real WCET. To be useful, the WCET must also devoted to scheduling problems in periodic RTSs. Among theses studies, we cite the analysis presented in [11] which considers the problem of scheduling periodic tasks with variable resource requirements, and the gener-uling, i.e. to minimize the resources consumption while meeting deadlines of tasks and to analyze their schedulability under some assumptions.

In traditional database management systems (DBMSs), many concurrency control protocols have been proposed for managing the conflict accesses to data. These protocols allow as much transactions as possible to access data while still avoiding the database inconsistencies, by mainly using data locks. For instance, we quote the study done in [13] , where some problems of the acquisition of locks in commercial DBMSs have been addressed such as frequency of locking and unlocking, deadlock and blocking, duration of locks, types of locks, correlations between applications of lock types, two-phase versus non-two-phase locking, when locks are held and released, etc. This work proposed an evaluation of the workload behavior in the presence of the assumptions commonly made in the research literature, and discussed the circumstances where those assump-tions may or may not lead to erroneous conclusions. We note that in DBMSs, the scheduler does not deal with the transactions priorities: it has only to ensure that the eventual precedence relationships between transac-tions are respected, i.e. to ensure the serializability property.

In RTDBSs, concurrency control and scheduling mechanisms are designed to cooperate tightly in order to manage the data access conflicts of the transactions according to their priorities. The problem of scheduling transactions with the objective of minimizing the percentage of transactions missing their deadlines was first rithms in RTDBS environment, evaluating the relative performance of pessimistic concurrency control proto-cols (PCC) and optimistic concurrency control protocols (OCC) through simulations. They have shown that outperform PCC protocols. The papers [18,19] have dealt with an hybrid protocol that combines OCC and is delayed as far as possible to allow urgent transactions to commit. Many studies on RTDBSs have been pro-posed to manage real-time transactions according to their category: hard , firm ,or soft (see among others [15,20] ). For a general review on RTDBSs, see for instance [1] .

Most performance studies in RTDBSs use EDF scheduling policy which is based on a priority assignment with EDF, successful transactions are prioritized in favor of transactions which are close to their deadlines, i.e. successful transactions are not necessarily the most important transactions in the system. Moreover, it is well-known that EDF is not efficient to schedule transactions (or tasks) in overload conditions, leading to the degradation of the system performances. This comes from the fact that with EDF, high priorities are assigned to transactions which finally might miss their deadlines. These high-priority transactions also waste system resources and delay other transactions [21] . To overcome these disadvantages, the study dealt with in [22] introduced an extension of EDF called adapted earliest deadline (AED). AED is a priority assign-ment policy which stabilizes the overload performance of EDF through an adaptive admission control mech-anism in an RTDBS environment. In this method, the incoming transactions are assigned to either hit or miss group. Using a feedback mechanism, the capacity of the hit group is adjusted dynamically to improve the per-formances. Transactions in miss group only receive processing if the hit group is empty. In [23] , Pang et al. proposed an extension of AED, called adaptive earliest virtual deadline (AEVD), to address the fairness issue in an overloaded system. In AEVD, virtual deadlines are computed based on both arrival times and deadlines.
Since transactions with longer execution times will arrive earlier relative to their deadlines, AEVD can raise their priorities in a more rapid pace as their durations in the system increase. Consequently, longer transac-The results of a comparative performance study of AED and AEVD reported in [23] have established that
AEVD provides better performances than AED. To resolve some weaknesses of AEVD, Datta et al. [24] have introduced priority based scheduling policy, called adaptive access parameter (AAP) method where they use explicit admission control. An other study done in [25] deals with the problem of repeatedly transactions pro-cessing in an RTDBS. In this work, Dogdu gave a number of priority assignment techniques based on the execution histories of real-time transactions that overcome the biased scheduling in favor of the short trans-actions when using EDF policy.

In this paper, we introduce a new approach based on a weight technique: a weight is assigned to a trans-action according to its tasks importance. We also give a new priority assignment technique which uses both the deadline and the transaction importance. This assignment policy leads to a new scheduling policy, called Gen-eralized Earliest Deadline First (GEDF) developed to overcome the weakness of EDF scheduling policy.
GEDF is considered as a generalization of EDF due to its flexibility and its adaptability to the system work-load conditions. To show the effectiveness of GEDF scheduling policy on RTDBS performances, we analyze the system performances according to the transactions success ratio and quality of service (QoS). To this pur-pose, Monte Carlo simulations are conducted on the RTDBS simulator we have developed. This simulator is based on components generally encountered in RTDBSs [16,26,27,20,1] . The results are compared to EDF scheduling technique under various execution constraints and conditions, such as the transactions arrival pro-cess, system load, conflicts level, concurrency control policy and database size.

The remainder of this paper is organized as follows. In Section 2 , we describe the system model and the simulator components. Then, we present our weighted approach of transactions and the GEDF scheduling policy we propose. Section 3 is devoted to the Monte Carlo simulation experiments and the obtained results.
We then present the performance evaluation results of the GEDF scheduling policy. Finally, in Section 4 ,we conclude the paper and discuss some aspects of our future work. 2. Simulator and system model
We base our work on a system model dealt with in our previous work [28,29] , where some other real-time characteristics are added, e.g. temporal data, update transactions and the implementation of the freshness manager. We have also developed a new priority assignment policy where the importance criterion is added and on which is based the new scheduling approach, called GEDF. Note that we do not use an admission control mechanism (ACM [30,31] ) to reduce or to manage the submitted transactions according to the system workload. In our application, all transactions are accepted to be scheduled in the system. We think that it is more profitable to study the behavior of GEDF versus EDF without influencing the system workload by using an ACM.

Due to decreasing of main memory cost and its relatively high performance [32,33] , main memory dat-abases have been increasingly applied to real-time data management such as stock trading, e-commerce, and voice/data networking. In this work, we consider a main memory database model. The RTDBS is mate-we will focus on the components related to the data and transactions model and the GEDF scheduling tech-nique. Other components of the simulator are detailed in earlier papers [28,29] . 2.1. Data and transactions
The database is composed of independent data objects classified into two classes: temporal data (TD) and non-temporal data (NTD). The state of a temporal data object may become invalid with the passage of time.
Associated with its state, there is an absolute validity interval, denoted avi [34] . A temporal data d ered temporally inconsistent or stale if the current time is later than the timestamp of d followed by the length of the absolute validity interval of d not restrict the notion of temporal data to data provided by physical sensors. Instead, we consider a broad meaning of sensor data. Any item whose value reflects the time-varying real world status is a temporal data with the passage of time is a non-temporal data object [34] .
 We consider only firm real-time transactions and we classify them into update and user transactions.
Update transactions are periodic and only write temporal data which capture the continuously state changing environment. We assume that an update transaction is responsible for updating a single temporal data item in the system. Each temporal data item is updated following a more X  X ess approach where the period of an update transaction is assigned to be more than half of the validity interval of the temporal data [35] . We assume that user transactions can read or write non-temporal data and only read temporal data [36] .
The user transactions arrive in the system according to a Poisson process with an average rate k . The number (denoted User SInerval ). Data accessed by the operations of the transaction are randomly generated and built the transaction characteristics in Table 2 .

To distinguish the important transactions from the others, the transactions are weighted according to their importance, which is called transaction system priority (denoted by SPriority ). In the following, we will describe fully how this importance criterion is assigned to each transaction. 2.2. Transactions system priorities (SPriority)
The transaction system priority (SPriority) is a parameter related to each transaction. It expresses the degree of importance of the task(s) executed by a transaction and defines its rank among all the transactions in the system. This parameter is assigned to each transaction when it is generated. The proposed GEDF sched-
In order to maintain temporal data consistency, i.e. to ensure that data in the database reflect the state of update transactions class is more important than that of the user transactions because one of the main design goals of RTDBSs is to guarantee the temporal data freshness [1] and to maintain the database consistency. the first interval  X  0 ; N is devoted to the SPriority values of update transaction and the second, ity = 0, corresponds to the highest rank that a transaction can have in the system. To assign the SPriority value to each transaction, we use the following technique:
Transaction weight technique (WTec) To assign the SPriority value, we use two weight functions according to the transaction class: 1. Update transactions class : we consider that temporal data items which are updated frequently, i.e. which have short update period, are data items that contain important information (for example, position of an aircraft). We relate the importance of a temporal data item to its update frequency because its absolute validity interval is also short ( more X  X ess approach [35] ), which makes its update more critical.
Let MaxPeriod be the longest period among the periods of update transactions. The SPriority of an update transaction T is computed according to the following formula: operations and the transaction  X  X  X ead X  X  set operations. A user transaction T is assigned a SPriority value by the following formula:
Motivations: the choice of Formula (2) to assign the SPriority value to user transactions is motivated by the following arguments:  X  To favor the results derived from transactions that read temporal data, we consider that their results are generally more important than those derived from transactions which read non-temporal data. Thus, a transaction which will read many temporal data is assigned a higher rank than others (see Formula (3) ).  X  To favor database freshness, we consider that the write operations are more important than read opera-tions, because their role is to refresh the database regularly. Thus, a transaction which will write many data items on the database is assigned a higher rank than others (see Formula (3) ).  X  To reduce data access conflicts in the database, we consider that transactions that execute many read oper-ations on the database are transactions that can induce many data access conflicts when the database is in update state. Pessimistic conflict resolution approach (2PL-HP [15,37] ) induces many restarts and aborts, whereas optimistic conflict resolution approach (OCC-Wait-50 [17,38] ) creates long wait durations for con-flicts resolution. In both situations, the system is overloaded and its performances are degraded. In order to avoid those weaknesses, the rank of a transaction which reads many non-temporal data is decreased in the system (see Formula (3) ).  X  The database administrator can influence the transactions priorities by modifying their importance in the system. This interaction is modelized in Formula (2) by DBA priority to an urgent transaction or to transactions that need high services. 2.3. Transaction scheduler (TS)
In RTDBSs, transactions can be periodic with synchronous release times, periodic with asynchronous release times or aperiodic. EDF protocol is considered as the best policy among RTS scheduling policies that are adapted to RTDBSs to schedule transactions. The EDF effectiveness to schedule synchronous and asyn-chronous tasks was dealt with in [5,39] .

With EDF scheduling policy, transactions are scheduled according to their deadlines. However, the dead-been shown to improve the average success ratio of the transactions, it discriminates against longer transac-tions under overload conditions [22,23] .

In order to optimize the system quality of service and to schedule transactions according to both the impor-tance criterion (SPriority), and the deadlines, we propose an adapted scheduling policy, called Generalized
Earliest Deadline First (GEDF), which is described in the following section. 2.3.1. GEDF Scheduling policy
GEDF is a dynamic scheduling policy where transactions are processed in an order determined by their priorities, i.e. the next transaction to run is the transaction with the highest priority in the active queue. (see Section 2.2 ) which expresses the importance of the transaction. We consider that the zero value of the by the formula: transactions to resolve data conflicts.

Table 1 illustrates an example of priority assignment when N =20and a  X  1 actions are released at the same time, then they will be scheduled by GEDF in the following order:
T ; T 3 ; T 6 ; T 2 ; T 1 ; T 4 ; T 5 .

In the example given in Table 1 , we can see that with GEDF if a transaction belongs to prioritized class or ities are computed according to both deadline and SPriority. In Table 1 , T update transaction, and T 5 is scheduled after T 4 even if its SPriority rank is higher than that of T 2.3.2. GEDF contributions  X  Update transactions are assigned high priorities with GEDF, which guarantees both the temporal data freshness and the database consistency (see Section 3 ).  X  Important transactions are assigned high priorities which gives them more chances to be scheduled and exe-cuted before their deadlines.  X  Each transaction executes a group of operations (Read/Write); this operations group of a transaction can be seen as more or less important than operations groups of other transactions. EDF policy can not express this importance. With GEDF policy we can express both the criticality of time and the transactions impor-tance in the priority assignment policy.  X  GEDF can be adapted to the system load in order to optimize its performances by varying the parameter a .
This assertion will be explained deeply in Section 3.3 .  X  GEDF can be seen as an extension of EDF scheduling policy. In fact, it is sufficient to initialize the SPri-ority of transactions with the same value or to initialize the weight parameter in priority formula to zero value, i.e. a = 0, and GEDF becomes a classical EDF scheduling policy. This property is used to preserve the EDF qualities when it gives better results (see Section 3.3 ). 2.4. Conflicts level
Data conflicts result from the behavior of the transactions in the database. We assume that some data are more important than others and they are frequently requested by user transactions. In order to reproduce this behavior in the transaction action (read or write), we assign to each data item a drawing probability in the following manner.

Let r 1 &lt; r 2 &lt; &lt; r k &lt; &lt; r n , denote the ranking of the data items D
We use ranking function defined as follows: r i  X  i  X  1, where i is the index of data item D The probability of drawing the data item D i is given by the following formula: where R  X  with low probabilities.
 We select the data item D k according to the above probabilities, i.e. we generate a uniform random variable U in (0,1) and select D k if U 2 2.5. User transactions deadline assignment function
A deadline function is used to assign a deadline to each transaction according to the operations it has to execute. In order to favor transactions with short execution times and to reduce the long wait periods, it is transactions deadlines [17] . In our experiments, the deadline assignment policy uses a slack function which defines the value of the slack factor according to the best (minimum) estimated execution time. The deadline assignment function is given by: where DT denotes the deadline of the transaction T , AT the arrival time (or release time) of T , BET the best estimated execution time of T and SF  X  BET  X  X  a  X  1 exp  X  b BET  X  X  the slack function, scaled by the parameters a and b and takes its values in the interval  X  0 ; a .

The BET parameter of a transaction T i is estimated by the number of cycles needed for the transaction exe-cution and is given by: where ReadTime denotes the quantum consumption of a read operation, WriteTime denotes the quantum con-sumption of a write operation and Quantum denotes the execution capacity in one clock cycle (see Table 3 for more details).
 allows transactions with short execution times to be assigned higher priorities than that with long execution times (EDF and GEDF scheduling policies). 2.6. System performance metrics 2.6.1. Transaction success ratio (SRatio)
To measure the system performances, we consider transaction success ratio as the main metric. The success ratio is given by: where CommitT indicates the number of transactions committed by their deadlines, and SubmittedT indicates to the class of transactions:  X  Success ratio of update transactions:
This ratio indicates the number of update transactions committed by their deadline. It represents the con-sistency level of temporal data in the database.  X  Success ratio of user transactions: 2.6.2. System quality of service (QoS)
The QoS can be seen as a global metric which measures the service X  X  performance provided by the system to the users. In the following, we define two parameters of the system QoS:  X  the success ratio of committed user and update transactions;  X  and the satisfaction degree ( SatDegree ) of the system on the important transactions, i.e. maximization of the commit of important transactions among the committed transactions.
 We measure SatDegree by:  X  it takes values between 0 and 1;  X  it increases from 0 to 1 according to the number of the committed transactions with smaller SPriority .
We specialize this measure according to the class of transactions:  X  SatDegree of user transactions:  X  SatDegree of update transactions:
It follows that, in order to maximize the system QoS, we have to maximize the quadruplet 2.7. General mechanism of the simulator
User transactions are submitted to the system following a Poisson process (see Fig. 1 ) with an average rate k into the active queue. The deadline controller (DC) supervises the transactions deadlines and informs the transaction scheduler (TS) when a transaction misses its deadline (in order to abort it). Freshness manager accesses it and blocks all user transactions reading stale temporal data. Transactions data conflicts are resolved by the Concurrency controller (CC) according to transactions priorities. CC informs TS in the fol-lowing cases: (a) when a transaction is finished (committed) and its results are validated in the database, best execution time is higher than its deadline minus the current time ( BET a transaction is transferred from the blocked queue to the active queue, i.e. its data conflicts are resolved. 3. Simulations and results
To assess the performances of GEDF scheduling policy in comparison to EDF scheduling policy, we car-ried out Monte Carlo simulations. This allows us to study the transactions success ratio behavior and the sys-tem quality of service. Given the system parameters described in Tables 2 X 4 , we repeat the experiment 1000 times in each simulation in order to obtain a sample of 1000 values for the performances, i.e. SRatio and
QoS. Each point shown in Figs. 4 X 7 and 10 (success ratio) and Figs. 8 and 11 (quality of service) represents the computed average of performance results deduced from each simulation sample.

The workload of the system is varied according to both the database size and the arrival rate k of user trans-in the database and increases substantially when TD increases. In our simulations, the number of temporal data iation of the number of update transactions is due to the absolute validity interval avi of each data. have enough workload of temporal data (minimum 15 updates and maximum 335 updates in the experiment duration). Each update transaction is assigned a period and a deadline according to the avi of the temporal data it accesses (for more details see more X  X ess approach [35] ).

The parameters a and b of the slack function SF are assigned the values 4 and 0 : 9 in order to obtain an average behavior of transactions load in the system ( Fig. 3 ). The probability to execute a read operation is quantum units for execution and a read operation requires one quantum unit. The parameter c is assigned the value 4 5  X  0 : 8 in order to minimize the effect of the DBA the SPriority formula. In order to show the influence of the SPriority weight on the GEDF behavior and on the system performances, we varied the value of the parameter a in Formula (4) . The assigned values used the parameter a according to the system workload (see Section 3.3 ).
 In the following subsection, we introduce the discussions of simulation results while comparing EDF and
GEDF using the defined weight technique to assign SPriority of transactions. We also introduce a discussion on GEDF flexibility and how it is possible to exploit this flexibility in order to improve the system performances.
 3.1. Influence of the scheduling and concurrency control policy 3.1.1. Scheduling policy
In order to analyse the influence of the scheduling policy on the success ratio performances, we compare the results obtained under EDF and GEDF when using 2PL-HP protocol and when varying the system workload. Figs. 4 and 5 illustrate graphically this comparison.

The best performances for update transactions are obtained with GEDF scheduling policy, see Fig. 4 b, the values, we obtain the same performances on the update success ratio results for all system workload condi-tions. We can conclude that when increasing the user transactions number, there is no effect on the update transactions performances. This result may be explained by the higher priority given to update transactions which ensures their processing before user transactions. When we look at the performances with EDF sched-uling policy, see Fig. 4 a, we notice a progressive decreasing of the success ratio when the workload progres-sively becomes heavy.

With EDF, there is no difference between the two classes of transactions, since only the deadline is taken nent, which affects and decreases the success ratio of update transactions and degrades the temporal data con-system workload is heavy. In the following, we comment the user transactions performances on three inter-(high workload).
 is not overloaded, EDF gives better performances on user transactions SRatio than GEDF with all variations of the parameter a . Indeed, when using GEDF scheduling policy, the lower priority transactions must wait for the commit of the higher priority transactions to be executed even if their deadlines are imminent. This has a negative effect when the system workload is light, which reduces the chances of lower priority transactions to commit, i.e. the user transaction success ratio decreases.

GEDF provides better results than EDF according to the variations of the SPriority weight parameter. The reversible points corresponding to those situations can be seen in Fig. 5 a and b: k  X  1 : 2 with a  X  1 with a  X  1 7 , k  X  1 : 28 with a  X  1 6 , k  X  1 : 32 with a  X  1 this interval of k .
 When the system workload is heavy, i.e. k 2 X  1 : 5 ; 2 : 4 , the situation is reversed completely in favor of
GEDF that provides better performances than EDF (for example SRatio  X  GEDF  X  a  X  1 10 % when k  X  2 : 4) with all values assigned to the parameter a . We also deduce that when the workload increases, the improvement of the system performances is correlated with the increasing of the value assigned to the parameter a . The results obtained by GEDF can be explained by the fact that the temporal data con-sistency is more safeguarded with GEDF than with EDF policy (see the success ratio of update transactions in
Fig. 4 b). With GEDF, the waiting time of fresh data is reduced thanks to the success ratio of update trans-actions which is maximal, i.e. 100%. This gives to the user transactions reading temporal data the maximum chances to meet their deadlines, decreasing then the system load. Moreover, only the important transactions are scheduled in the system. When the system workload is heavy, GEDF scheduling policy reduces the useless by other transactions which finally miss their deadlines. 3.1.2. Concurrency control A comparison between the performances provided by 2PL-HP and OCC-Wait-50 CC protocols is shown in
Fig. 6 (when using EDF scheduling policy) and in Fig. 7 (when using some variants of GEDF scheduling pol-icy). When we look at the performances registered with EDF and the performance registered with GEDF, we can notice that (i) 2PL-HP and OCC-Wait-50 provide the same performances on the user transactions success ratio, and (ii) the GEDF scheduling policy has a similar behavior to EDF scheduling policy with the two pro-tocols. Thus, using either 2PL-HP or OCC-Wait-50 does not improve the system performances. 3.2. System quality of service (QoS) In the following, we discuss and compare the system quality of service (QoS) registered under EDF and
GEDF when using OCC-Wait-50 protocol. Fig. 8 a and b illustrate graphically this comparison. When we look at the QoS given on update transactions, see Fig. 8 a, we deduce that all variants of GEDF give the optimal performances 2 on SRatio and SatDegree , i.e  X  SRatio update
GEDF scheduling policy is better than EDF and gives high QoS on update transactions in all system work-load conditions. Thus, GEDF scheduling policy maintains the temporal data consistency in all workload conditions.

When we consider QoS on user transactions, see Fig. 8 b, the values of  X  SRatio lowing, we comment the QoS of user transactions in three intervals k 2 X  0 : 6 ; 1 : 1  X  (light workload), k 2 X  1 : 1 ; 1 : 5  X  (average workload) and k 2 X  1 : 5 ; 2 : 4 (high workload). When k is in the interval  X  0 : 6 ; 1 : 1  X  , EDF gives the best QoS on user transactions, i.e. QoS can be explained by the high SRatio registered with EDF when the system workload is light (as detailed in Section 3.1.1 ), which gives high SatDegree on the committed user transactions.
 ible points deduced in Section 3.1.1 . The situation is reversed in favor of GEDF with SatDegree according to the value assigned to the parameter a , the reversible points can be seen in Fig. 8 b: k  X  1 : 1 with a  X  1 with GEDF is higher than that with EDF. When we combine the results with the reversible points deduced in
Section 3.1.1 we can argue that GEDF gives a better QoS than EDF. For example, see in Fig. 8 b the intervals: k 2 X  1 : 25 ; 1 : 5  X  when a  X  1 8 , k 2 X  1 : 38 ; 1 : 5  X  when a  X  1 tions the best chances to commit before their deadlines.
 capacity of GEDF to schedule transactions when the workload is heavy (see SRatio value in Section 3.1.1 ).
We can also explain this result by the greater ability of GEDF to succeed in the commit of important trans-actions than EDF. 3.3. GEDF flexibility according to the system workload
In this section, we show the GEDF flexibility and the capacity it gives to the system manager to interact and to adapt to different system workload situations. To this purpose, we exploit the GEDF variants to enhance the system performances.

Our objective is to obtain the optimal output of the system on user transaction SRatio and QoS. To this pur-pose, we have deduced by simulations the adequate values of the parameter a according to the system workload intervals. Fig. 9 shows the weight values assigned to the SPriority which we use in GEDF priority assignment formula according to the system workload intervals. In Fig. 9 , we can see for example when k is between 0.6 and 1.2 the assigned value to a is 0 and when k is between 1.5 and 1.7, the assigned value to a is 1 of the parameter a values are deduced by simulation in order to have the best results with GEDF.
A comparison of success ratio obtained by GEDF scheduling policy when varying the parameter a according assigned zero value, i.e. GEDF becomes a classical EDF scheduling policy and allows to exploit the EDF char-adequate values for the parameter a . This allows GEDF to give the best performances on user transactions suc-the SRatio decreases up to k = 1.2 and when a &gt; 0 the SRatio becomes optimal, i.e. 100%, see Fig. 10 a.
The related QoS results obtained on the user transactions when exploiting the GEDF flexibility in compar-ison to the EDF scheduling policy are summarized in Fig. 11 . We can argue that GEDF provides better QoS on user transactions in all system conditions workload, and it optimizes not only the SRatio but also the sat-isfaction degree, i.e. SatDegree , on the user transactions in all workload conditions (note that
SatDegree  X  GEDF  X  X  SatDegree  X  EDF  X  X  15 % , when k = 2.4). 4. Conclusion
In this paper, we have proposed a weighted approach which expresses the transactions tasks importance and a new scheduling policy (GEDF) to improve the system performances in firm RTDBS. The GEDF sched-uling policy uses deadline and importance criterion to schedule transactions. The impact of the GEDF sched-uling policy on RTDBS performances, i.e. transactions success ratio and system QoS, is studied under different system workload situations and when using different concurrency control protocols. The study is done in comparison with EDF scheduling policy performances. We have also discussed the GEDF scheduling the transactions success ratio and system QoS in firm RTDBSs.

In our future work, we plan to deduce the function that expresses the value of the parameter a in Formula (4) according to the system workload in order to give GEDF scheduling policy a better flexibility. We also project to extend our study to other scheduling policies and concurrency control protocols to compare their performances with the results obtained in this paper.
 Acknowledgement This work is supported by the Research Ministry of France ( ACI-JC#1055 ).

References
