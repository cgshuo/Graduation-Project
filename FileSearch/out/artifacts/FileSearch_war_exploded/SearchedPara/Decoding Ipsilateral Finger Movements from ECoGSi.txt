 The evolving understanding of motor function in the brain ha s led to novel Brain Computer Inter-face (BCI) platforms that can potentially assist patients w ith severe motor disabilities. A BCI is a device that can decode human intent from brain activity alon e in order to create an alternate com-munication and control channel for people with severe motor impairments [39]. This brain-derived control is dependent on the emerging understanding of corti cal physiology as it pertains to motor function. Examples are seen in the seminal discoveries by Ge orgopoulus and Schwartz that neu-rons in motor cortex show directional tuning and, when taken as a population, can predict direction and speed of arm movements in monkey models [12, 19]. In the su bsequent two decades, these findings were translated to substantial levels of brain-der ived control in monkey models and prelim-inary human clinical trials [14, 34]. Another example is see n in Pfurtschellers work in analyzing electroencephalography (EEG). His group was one of the first to describe the changes in amplitudes in sensorimotor rhythms associated with motor movement [24 ]. As a result, both Pfurtscheller and Wolpaw have used these signals to achieve basic levels of con trol in humans with amyotrophic lat-eral sclerosis (ALS) and spinal cord injury [25, 40]. All the se methods are based on a functioning motor cortex capable of controlling the contralateral limb . This is the exact situation that does not exist in unilateral stroke. Hence, these systems to date off er little hope for patients suffering from hemispheric stroke. For a BCI to assist a hemiparetic patien t, the implant will likely need to utilize unaffected cortex ipsilateral to the affected limb (opposi te the side of the stroke). To do so, an ex-panded understanding of how and to what degree of complexity motor and motor associated cortex encodes ipsilateral hand movements is essential.
 Electrocorticography (ECoG), or signal recorded from the s urface of the brain, offers an excellent opportunity to further define what level of motor informatio n can be deciphered from human ipsi-lateral cortex related to movements (e.g. gross motor movem ents versus fine motor kinematics of individual finger movements). The ECoG signal is more robust compared to the EEG signal: its much greater (0.125 versus 3.0 cm for EEG), and its frequency bandwidth is significantly higher (0-550 Hz versus 0-40 Hz for EEG) [11, 30]. When analyzed on a f unctional level, many studies have revealed that different frequency bandwidths carry hi ghly specific and anatomically focal in-formation about cortical processing. Thus far, however, no studies have utilized these ECoG spectral features to definitively analyze and decode cortical proces sing of the specific kinematics of ipsilat-eral finger movements.
 simple device control have been published both with ECoG (in healthy subjects) and MEG (in stroke patients) [4, 38]. In this study we set out to further e xplore the decoding of individual finger movements of the ipsilateral hand that could potentially be utilized for more sophisticated BCIs in the future. We studied 3 subjects who required invasive moni toring for seizure localization. Each had electrode arrays placed over the frontal lobe and a portion o f sensorimotor cortex for approximately a week. Each subject performed individual finger tasks and the concurrent ECoG signal was recorded and analyzed. The principal results show that individual ip silateral finger movements can be decoded with high accuracy. Through machine learning techniques, o ur group was able to determine the intent to flex and extend individual finger movements of the ip silateral hand. These results indicate that an ECoG based BCI platform could potentially operate a h and orthotic based on ipsilateral motor signals. This could provide a neuroprosthetic altern ative to patients with hemispheric stroke who have otherwise failed non-invasive and medical rehabil itative techniques. epilepsy who underwent temporary placement of intracrania l electrode arrays to localize seizure foci prior to surgical resection. All had normal levels of cognit ive function and all were right-handed. Subject 1 had a right hemispheric 8  X  8 grid while subjects 2 and 3 had left hemispheric 8  X  8 grids. All gave informed consent. The study was approved by the Wash ington University Human Research Protection Office.
 Each subject sat in their hospital bed 75 cm from a 17-inch LCD video screen. In this study, the subject wore a data glove on the each hand to precisely monito r finger movements. Each hand rested on a table in front of the screen. The screen randomly cued the patient to flex and extend a given finger (e.g., left index finger, right ring finger, etc.). A cue came up on the monitor and as long as it was present, subjects would, at a self-paced speed, mov e the indicated finger from the flexed to the extended position until the cue disappeared. They wer e instructed on the method prior to participation. Each cued task period would last 2 seconds wi th a randomized rest period between 1.5 and 2.5 seconds(i.e., a trial). There were on average 30 t rials per finger for a given subject. For subject 1, the thumb data recording was found to be noisy a nd hence was eliminated from any further analysis. Visual cues were presented using the BCI2 000 program [27]. All motor hand kinematics were monitored by the patient wearing a USB linke d 5DT Data Glove 5 Ultras (Fifth Dimension, Irvine, CA) on each hand. These data gloves are de signed to measure finger flexure with one sensor per finger at up to 8-bit flexure resolution. Th e implanted platinum electrode arrays were 8  X  8 electrode arrays(Ad-Tech, Racine, WI and PMT, Chanhassen , MN). The grid and system setup details are described elsewhere [38]. ECoG signals we re acquired using BCI2000, stored, and converted to MATLAB files for further processing and anal ysis. All electrodes were referenced to an inactive intracranial electrode. The sampling freque ncy was 1200 Hz and data acquisition is band-pass filtered from 0.15 to 500 Hz. 2.1 Data Preprocessing Gabor Filter Analysis All ECoG data sets were visually inspected and re-reference d with respect to the common average to account for any unwanted environmenta l noise. For these analyses, the time-series ECoG data was converted into the frequency domain usi ng a Gabor filter bank [17]. Spectral amplitudes between 0 and 550 Hz were analyzed on a logarithmi c scale. The finger positions from the data glove were converted into velocities. These freque ncy responses and velocities were then used as an input to machine learning algorithms described be low. Inherent in this is the estimation further analysis. Average time lags were then used to align t he ECoG signal to the finger movement signal. Those features optimized for predicting individua l finger movement were then reviewed in light of anatomic location and spectral association in each subject.
 Dimensionality Reduction Due to the high dimensionality of the spectral data ( # channels ( N )  X  # f requencies ( F ) ), it is important to reduce the dimensions in order to build a more conducive machine learning algorithm. Principle component analysis , or PCA, is among the most popular dimensionality reduction algorithm. PCA projects the orig inal high-dimensional feature space into a much lower principle subspace , such that the variance of low-dimensional data is maximize d. In the real-time decoding task, we use PCA to reduce the input da ta. However, in the weight analysis, we preserve all the N  X  F features because we want to study the effect of using all the f eatures. Electrode Co-Registration Radiographs were used to identify the stereotactic coordin ates of each grid electrode [10], and cortical areas were defined the GetL OC package for ECoG electrode local-ization [18]. Stereotactically defined electrodes were map ped to the standardized brain model. The experimental results were then collated with these anatomi cal mapping data. In this section, we describe the machine learning algorithm s used for the finger movement decoding parameters based on a validation dataset split from the trai ning dataset.
 Binary Classification We treat the finger movement detection problem as a binary cla ssification setting. The data is presented as a time series with feature v ector x The goal is to predict if at time t , a finger is moving ( y (SVM) [7]. Both classifiers learn parameters ( w , b )  X  X  d  X R . The prediction at time t is computed as  X  y t = sign ( w  X  x t + b ) . The vector w is learned with the following optimization problem Here,  X   X  0 is the regularization constant that trades off weight spars ity with complexity. The norm of the regularization can be the  X  1 norm ( q = 1 ) or the  X  2 norm ( q = 2 ). The  X  1 norm has the tendency to result in sparse classifiers which assign non-ze ro weights to only a small subset of the available features. This allows us to infer which brain regi ons and frequencies are most important to optimize) but is not as interpretable as it typically assi gns small weights to many features. The loss functions L differ for the two above mentioned algorithms. We will denot e the loss function for logistic regression as L Multiclass Classification A second setting of interest is the differentiation of finger s. Here we do not want to predict if a finger is moving but which one . Consequently, at any time point t we could have one of K possible labels, such as  X  X ndex Finger X  ( y adopt the Crammer and Singer multi-class adaptation of supp ort vector machines (MCSVM) [8]. For each class k  X  X  1 , . . . , K } , we learn class-specific parameters w pairwise comparisons between the different classes and ens ures that w  X  if y t = k for any r 6 = k . For completeness, we re-state the optimization problem: Similar to the scenario of binary classification, the consta nt  X   X  0 regulates the trade-off between complexity and sparseness.
 Multitask Learning In the movement detection setting, each finger is learned as a n independent classification problem. In the finger discrimination settin g, we actively discriminate between the detection problems by learning them jointly [5]. In the sett ing of brain decoding, it seems reasonable to assume that there are certain features which are associat ed with the general cortical processing of finger movements. This is analogous to the notion of language processing and articulation in cortical areas. Functional magnetic resonance imaging (fMRI) studi es have shown that although speech is represented in general cortical areas, individual feature s specific to different kinds of words can be found [16, 23]. We adopt the MTL adaptation for SVMs of [9], and an analogous framework for logistic regression, which leverages the commonalitie s across learning tasks by modeling them explicitly with an additional shared weight vector w as  X  y t = ( w 0 + w k )  X  x t . The corresponding optimization problem becomes The parameter  X  reduce our setting to the original binary classification men tioned above. On the other hand, setting  X  0 = 0 single classifier with weight vector w In this section we evaluate our algorithms for ipsilateral d ecoding on three subjects. First, we ap-proximate the time-lag between ECoG signal and finger moveme nt, then we present decoding results on finger movement detection, discrimination and also joint decoding of all fingers in one hand. Time Lag We first study the effects of decoding time lag between cortical signal and movement using features. The decod-ing accuracy is computed by shifting the feature dataset x by a presumed number of sample points (i.e. we are evaluating the performance of decoder h: h ( x the value of  X  selected as the value of  X  to best decoding accuracy. Figure 1 shows the decoding accuracy as a function of time-lag for four individual finger movements in Subject 1. Offsets between 0 and 800 ms are tested for all fingers and an average offset time is computed. The average time lag for the ipsilateral finger movement for Subject 1 is observed to be around 158 ms. This is in accordance with previous studies by our group which show similar time lags between cortical activity relative to movement by the average time-lag reported here. Figure 2: ROC curve for the ipsilateral finger movement decod er. Horizontal axis shows the false positive rate, and the vertical axis shows the true positive rate. The dotted line is the accuracy of a random classifier. Classifiers that have higher area under the ROC curve , or AUC, indicate better classification performance.
 Detecting Finger Movement We characterize the movement detection task as a binary clas sifica-tion. We first set a threshold thresh , and label the targets y and -1 otherwise. Then, we use  X  1 -regularized logistic regression for the binary classifica tion. We use receiver operating characteristic (ROC) curve to evalu ate the performance of the binary clas-sification. ROC curve is widely used in signal estimation and detection theory, and is a graphical plot of true positive rate versus the false positive rate. RO C analysis allows user to pick the opti-mal discrimination threshold for the binary classifier. We p ick regularizer  X  from validation dataset. Figure 2 shows the result of ROC curve for three subjects. Thi s demonstrates that  X  1 -regularized logistic regression is a powerful tool in detecting finger mo vement.
 Finger Discrimination In this section, we study how to discriminate which finger has made the movement. We first extract the sample points of which the finge r is moving from the time-series. matrices in Figure 3, and the colorbar shows the accuracy. Ea ch row of the matrix represents the finger that actually moved and each column represents predic ted finger. The elements of the matrix shows the percentage of all movements of a particular finger t hat has been classified as particular predicted finger. Note that the accuracy by a random multicla ss classifier is 1/(number of fingers). It can be concluded that the ECoG signal contains useful info rmation to discriminate individual finger movement. Figure 3: Confusion matrix of finger movement multiclass cla ssification. The rows are the actual movement, and the columns are the predicted movement. 4.1 Learning Commonality from the Brain Activity In this section, we present how multitask learning improves the performance of the classifier. Al-though multitask learning has been employed in the context o f brain signal decoding [2], we are the first to decode ECoG signals in humans. We group all the indivi dual finger movement together, such that each task has similarity with others. First of all, we ev aluate the performance of single-task learning using SVM. Then, we study the SVM-based multitask l earning. As we show in Equation 4, we make trade-off between modeling joint component and and m odeling class-specific components by adjusting parameters  X  up the parameters that lead to highest average AUC for all tas ks. Table 1 shows the comparison of SVM-based single task learning and multitask learning. H ere we evaluate the multitask learning algorithm based on the improvement of (1-AUC); (1-AUC) stan ds for the area above the curve. The average improvement of the decoder for three patients is 25. 53%, 5.60%, and 18.57%, respectively. This confirms our assumption that there exists brain activit y that controls the finger movement, ir-respective of any particular finger. By carefully searching the best parameters that regulates the trade-off between learning commonality among all finger mov ement and specificity of exact finger movement, the classification algorithm can be significantly improved. We also compare the  X  1/  X  2-regularized logistic regression-based multitask learnin g with SVM-based multitask learning. There is an improvement on (1-AUC) for logistic regression-based multitask learning. Again, it illustrates However, we prefer SVM-based multitask learning because of the larger improvement.
 Table 1: Comparison of SVM-based single-task learning (STL ) and SVM-based multi-task learn-ing (MTL). The parameters are chosen from validation datase t. The best decoding performance is indicated in bold . An important part of decoding finger movements from cortical activity is to map the features back to cortical domain. Physiologically, it is important to und erstand the features which contribute most to the decoding algorithms i.e. the features with the highes t weights. As shown in Table 2 below, the decoding accuracy, indicated by AUC, does not change much as we increase the number of features form the core and are the most important. To visualize these c ore features, we mapped the top 30 features back to the brain. Figure 4 above shows the normaliz ed weights from the features used to classify finger movements from non-movements. It is appar ent from the figure that the features are wide spread and signify distributed (networked) cortic al processing. It can also be seen that many prominent features are located in the frontal cortical areas which supports previous findings that areas anterior to the motor cortex are involved in plann ing of motor movements (pre-motor and dorsolateral prefrontal cortex). Also, as previously repo rted, the frequency range with the highest weights falls in the lower frequencies in ipsilateral movem ents [38]. In our case, the frequencies fall in the delta-alpha range. As noted by Tallon-Baudry, at tention networks of the brain affect the oscillatory synchrony as low as theta-alpha range frequenc ies [31]. Table 2: The area under the curve (AUC) as a function of the num ber of features used for classifi-cation. Features were selected in decreasing order of their respective absolute weights from logistic regression with  X  1 regularization. processing occurs as a network involving dorsolateral pref rontal cortex, pre-motor and motor areas. The frequency range for these features is in the delta and alp ha range i.e. the low frequency range. The notion that motor cortex plays a role in ipsilateral body movements was first asserted by Nyberg-to represent more axial motor control. Further studies in si ngle-neuron recordings in monkey models extended this observation to include ipsilateral hand and fi nger function. Tanji et al. demonstrated that a small percentage of primary motor cortical neurons sh owed increased activity with ipsilateral hand movements [32]. This site was found to be anatomically d istinct from contralateral hand sites and, when stimulated, produced ipsilateral hand movements [1]. Additionally, a larger subset of premotor neurons was found to demonstrate more robust activ ations with cues to initiate movement during both ipsilateral and contralateral movements than w ith primary motor sites [3, 6]. These findings in animal models support the conclusion that a small percent of motor and a larger percent of premotor cortex participate in control of ipsilateral li mb and hand movements.
 In humans, there appears to be a dichotomy in how motor region s contribute depending on whether the primary or non-primary motor cortex is examined. Using f MRI Newton et al. demonstrated that there was a negative change from baseline in fMRI bold sequen ce in M1 associated with ipsilateral movements and postulated this to represent increased inhib ition [21]. Verstynen et al., however, recently published contrasting results. Their group showe d that anatomically distinct primary motor sites demonstrated increased activation that became more p ronounced during the execution of com-plex movements [36]. The role that premotor cortex plays app ears to be distinct from that of primary motor cortex. In normal subjects, fMRI shows that there is mo re robust bilateral activation of the dorsal premotor cortex with either contralateral or ipsila teral hand movements [15]. The findings by Huang, et al. (2004) demonstrated that ipsilateral premo tor areas have magnetoencephalogra-phy (MEG) dipole peak latencies that significantly precede c ontralateral M1 sensorimotor cortex in performing unilateral finger movements. Using electroen cephalography (EEG), ipsilateral hand movements have been shown to induce alteration in cortical p otentials prior to movement; this is re-ferred to as premotor positivity [33, 29]. Spectral analyse s of EEG signals have shown bihemispheric low-frequency responses with various finger and hand moveme nts. Utilizing electrocorticography (ECoG), Wisneski et al more definitively demonstrated that t he cortical physiology associated with ipsilateral hand movements was associated with lower frequ ency spectral changes, an earlier timing, and premotor predominant cortical localization, when comp ared to cortical physiology that was as-sociated with contralateral hand movements [38]. Taken tog ether, these findings support more of a motor planning role, rather than execution role, in ipsilat eral hand actions.
 Decoding the information present in the ECoG signal with reg ard to ipsilateral finger movements is important in defining the potential use of BCI methodologies for patients with hemispheric dysfunc-tion due to stroke or trauma. If high resolution motor kinema tics can be decoded from the ECoG signal (e.g. individual finger flexion and extension), a BCI p latform could potentially be created to restore function to a stroke induced paretic hand. Since u p to one-half of hemispheric stroke patients are chronically left with permanent loss of functi on in their affected hand, this could have substantial clinical impact [20]. Functional imaging has s hown these severely affected patients to have increased activity in the premotor regions of their una ffected hemispheres [28, 37]. The exact role this activity plays is still unclear. It may simply be an indicator of a more severe outcome [35] or an adapative mechanism to optimize an already poor situat ion [13]. Thus, incomplete recovery and its association with heightened ipsilateral activatio n may reflect the up-regulation of motor plan-ning with an inability to execute or actuate the selected mot or choice. In this situation, a BCI may provide a unique opportunity to aid in actuating the nascent premotor commands. By decoding the brain signals associated with a given motor intention, the B CI may then convert these signals into commands that could control a robotic assist device that wou ld allow for improved hand function the nerves and muscles of the hand). The BCI would allow the ip silateral premotor cortex to bypass the physiological bottleneck determined by injured and dys functional contralateral primary cortex (due to stroke) and the small and variable percentage of uncr ossed motor fibers from ipsilateral M1. This new methodology would allow for restoration of functio n in chronically and severely affected subjects for whom methods of rehabilitation have not accomp lished a sufficiently recovery. Although the results presented here show high decoding accu racies, it is important to discuss the inating as a result of trans-collosal inhibition from the si de contralateral to the moving limb has been discussed. Although a direct comparison between ipsil ateral and contralateral activity was not the main aim of this study, out findings from ipsilaterel cort ex mesh well with the previous studies which did a direct comparison between the two [38]. The optim al time lag in this study for decoding finger movements was 150 ms which is similar to findings by Wisn eski et al. and is different from the time difference for contralateral activations ( 90ms). This time difference supports the notion that ipsilateral motor physiology is more associated with m otor planning than its execution. Given contralateral physiology or a result of trans-collosal inh ibition. Future studies need to be conducted to further address this issue explicitly. To our knowledge, this work describes the first instance of su ccessful detection of individual finger movements from human ipsilateral ECoG signals. In this pape r, we present a general decoding framework using the following algorithms: (1)  X  1 -regularized logistic regression for detecting finger movement; (2) Multiclass support vector machines to discri minate between fingers; and (3) First demonstration of multitask learning into the ECoG signal to improve decoding accuracy. The results presented here suggest that there exists information on the cortex ipsilateral to the moving fingers which can be decoded with high accuracy using machine learni ng algorithms. These results present a great potential in the world of neuroprosthetics and BCI. F or patients suffering from stroke and hemiparesis, decoding finger movements from the unaffected hemisphere can be of tremendous help. Our future goals involve simultaneous decoding of finger and arm movements (using standard center out joystick task) from both ipsilateral and contralateral hemispheres. Another important goal is the real-time use of these decoding results and demonstrate the ir utility in the world of BCI.
