 Memory-based collaborative filtering algorithms have been widely adopted in many popular recommender systems, al-though these approaches all suffer from data sparsity and poor prediction quality problems. Usually, the user-item matrix is quite sparse, which directly leads to inaccurate rec-ommendations. This paper focuses the memory-based col-laborative filtering problems on two crucial factors: (1) sim-ilarity computation between users or items and (2) miss-ing data prediction algorithms. First, we use the enhanced Pearson Correlation Coefficient (PCC) algorithm by adding one parameter which overcomes the potential decrease of accuracy when computing the similarity of users or items. Second, we propose an effective missing data prediction al-gorithm, in which information of both users and items is taken into account. In this algorithm, we set the similarity threshold for users and items respectively, and the predic-tion algorithm will determine whether predicting the missing data or not. We also address how to predict the missing data by employing a combination of user and item information. Finally, empirical studies on dataset MovieLens have shown that our newly proposed method outperforms other state-of-the-art collaborative filtering algorithms and it is more robust against data sparsity.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Systems]: Information Search and Retrieval -Informa-tion Filtering General Terms: Algorithm, Performance, Experimenta-tion.
 Keywords: Collaborative Filtering, Recommender System, Data Prediction, Data Sparsity.
Collaborative filtering is the method which automatically predicts the interest of an active user by collecting rating information from other similar users or items, and related techniques have been widely employed in some large, fa-Copyright 2007 ACM 978-1-59593-597-7/07/0007 ... $ 5.00. mous commercial systems, such as Amazon 1 ,Ebay 2 .The underlying assumption of collaborative filtering is that the active user will prefer those items which the similar users prefer. The research of collaborative filtering started from memory-based approaches which utilize the entire user-item database to generate a prediction based on user or item sim-ilarity. Two types of memory-based methods have been studied: user-based [2, 7, 10, 22] and item-based [5, 12, 17]. User-based methods first look for some similar users who have similar rating styles with the active user and then employ the ratings from those similar users to predict the ratings for the active user. Item-based methods share the same idea with user-based methods. The only difference is user-based methods try to find the similar users for an active user but item-based methods try to find the simi-lar items for each item. Whether in user-based approaches or in item-based approaches, the computation of similarity between users or items is a very critical step. Notable sim-ilarity computation algorithms include Pearson Correlation Coefficient (PCC) [16] and Vector Space Similarity (VSS) algorithm [2].

Although memory-based approaches have been widely used in recommendation systems [12, 16], the problem of inaccu-rate recommendation results still exists in both user-based and item-based approaches. The fundamental problem of memory-based approaches is the data sparsity of the user-item matrix. Many recent algorithms have been proposed to alleviate the data sparsity problem. In [21], Wang et al. proposed a generative probabilistic framework to exploit more of the data available in the user-item matrix by fusing all ratings with a predictive value for a recommendation to be made. Xue et al. [22] proposed a framework for collab-orative filtering which combines the strengths of memory-based approaches and model-based approaches by introduc-ing a smoothing-based method, and solved the data sparsity problem by predicting all the missing data in a user-item ma-trix. Although the simulation showed that this approach can achieve better performance than other collaborative filtering algorithms, the cluster-based smoothing algorithm limited the diversity of users in each cluster and predicting all the missing data in the user-item matrix could bring negative influence for the recommendation of active users.
In this paper, we first use PCC-based significance weight-ing to compute similarity between users and items, which overcomes the potential decrease of similarity accuracy. Sec-ond, we propose an effective missing data prediction algo-http://www.amazon.com/. http://www.half.ebay.com/.
 rithm which exploits the information both from users and items. Moreover, this algorithm will predict the missing data of a user-item matrix if and only if we think it will bring positive influence for the recommendation of active users instead of predicting every missing data of the user-item matrix. The simulation shows our novel approach achieves better performance than other state-of-the-art collaborative filtering approaches.
 The remainder of this paper is organized as follows. In Section 2, we provide an overview of several major approaches for collaborative filtering. Section 3 shows the method of similarity computation. The framework of our missing data prediction and collaborative filtering is introduced in Sec-tion 4. The results of an empirical analysis are presented in Section 5, followed by a conclusion in Section 6.
In this section, we review several major approaches for collaborative filtering. Two types of collaborative filtering approaches are widely studied: memory-based and model-based .
The memory-based approaches are the most popular pre-diction methods and are widely adopted in commercial col-laborative filtering systems [12, 16]. The most analyzed ex-amples of memory-based collaborative filtering include user-based approaches [2, 7, 10, 22] and item-based approaches [5, 12, 17]. User-based approaches predict the ratings of active users based on the ratings of similar users found, and item-based approaches predict the ratings of active users based on the information of similar items computed. User-based and item-based approaches often use PCC algorithm [16] and VSS algorithm [2] as the similarity computation meth-ods. PCC-based collaborative filtering generally can achieve higher performance than the other popular algorithm VSS, since it considers the differences of user rating styles.
In the model-based approaches, training datasets are used to train a predefined model. Examples of model-based ap-proaches include clustering models [11, 20, 22], aspect mod-els [8, 9, 19] and latent factor model [3]. [11] presented an algorithm for collaborative filtering based on hierarchical clustering, which tried to balance robustness and accuracy of predictions, especially when little data were available. Au-thors in [8] proposed an algorithm based on a generaliza-tion of probabilistic latent semantic analysis to continuous-valued response variables. The model-based approaches are often time-consuming to build and update, and cannot cover as diverse a user range as the memory-based approaches do [22].
In order to take the advantages of memory-based and model-based approaches, hybrid collaborative filtering meth-ods have been studied recently [14, 22]. [1, 4] unified collab-orative filtering and content-based filtering, which achieved significant improvements over the standard approaches. At the same time, in order to solve the data sparsity problem, researchers proposed dimensionality reduction approaches in [15]. The dimensionality-reduction approach addressed the sparsity problem by deleting unrelated or insignificant users or items, which would discard some information of the user-item matrix.
This section briefly introduces the similarity computation methods in traditional user-based and item-based collabora-tive filtering [2, 5, 7, 17] as well as the method proposed in this paper. Given a recommendation system consists of M users and N items, the relationship between users and items is denoted by an M  X  N matrix, called the user-item matrix. Every entry in this matrix r m,n represents the score value, r ,thatuser m rates an item n ,where r  X  X  1 , 2 , ..., r max user m does not rate the item n ,then r m,n =0.
User-based collaborative filtering engaging PCC was used in a number of recommendation systems [18], since it can be easily implemented and can achieve high accuracy when comparing with other similarity computation methods. In user-based collaborative filtering, PCC is employed to define the similarity between two users a and u basedontheitems they rated in common: where Sim ( a, u ) denotes the similarity between user a and user u ,and i belongs to the subset of items which user a user u both rated. r a,i is the rate user a gave item i ,and represents the average rate of user a . From this definition, user similarity Sim ( a, u ) is ranging from [0 , 1], and a larger value means users a and u are more similar.

Item-based methods such as [5, 17] are similar to user-based approaches, and the difference is that item-based meth-ods employ the similarity between the items instead of users. The basic idea in similarity computation between two items i and j is to first isolate the users who have rated both of these items and then apply a similarity computation tech-nique to determine the similarity Sim ( i, j ) [17]. The PCC-based similarity computation between two items i and j can be described as: where Sim ( i, j ) is the similarity between item i and item and u belongs to the subset of users who both rated item i and item j . r u,i is the rate user u gave item i ,and r i represents the average rate of item i . Like user similarity, item similarity Sim ( i, j ) is also ranging from [0 , 1].
PCC-based collaborative filtering generally can achieve higher performance than other popular algorithms like VSS [2], since it considers the factor of the differences of user rating styles. However PCC will overestimate the similarities of users who happen to have rated a few items identically, but may not have similar overall preferences [13]. Herlocker et al. [6, 7] proposed to add a correlation significance weight-ing factor that would devalue similarity weights that were based on a small number of co-rated items. Herlocker X  X  lat-est research work [13] proposed to use the following modified similarity computation equation:
This equation overcomes the problem when only few items are rated in common but in case that when | I a  X  I u | is much higher than  X  , the similarity Sim ( a, u ) will be larger than 1, and even surpass 2 or 3 in worse cases. We use the following equation to solve this problem: where | I a  X  I u | is the number of items which user a and user u rated in common. This change bounds the similarity Sim ( a, u ) to the interval [0 , 1]. Then the similarity between items could be defined as: where | U i  X  U j | is the number of users who rated both item i and item j .
In pratice, the user-item matrix of commercial recommen-dation system is very sparse and the density of available ratings is often less than 1% [17]. Sparse matrix directly leads to the prediction inaccuracy in traditional user-based or item-based collaborative filtering. Some work applies data smoothing methods to fill the missing values of the user-item matrix. In [22], Xue et al. proposed a cluster-based smoothing method which clusters the users using K-means first, and then predicts all the missing data based on the ratings of Top-N most similar users in the similar clusters. The simulation shows this method could generate better results than other collaborative filtering algorithms. But cluster-based method limits the diversity of users in each cluster, and the clustering results of K-means relies on the pre-selected K users. Furthermore, if a user does not have enough similar users, then Top-N algorithm generates a lot of dissimilar users which definitely will decrease the prediction accuracy of the active users.

According to the analysis above, we propose a novel ef-fective missing data prediction algorithm which predicts the missing data when it fits the criteria we set. Otherwise, we will not predict the missing data and keep the value of the missing data to be zero. As illustrated in Fig. 1(a), before we predict the missing data, the user-item matrix is a very sparse matrix and every user only rates few items with r u,i at the same time, other unrated data are covered with shade. Using this sparse matrix to predict ratings for active users always results in giving bad recommendations to the ac-tive users. In our approach, we evaluate every shaded block (missing data) using the available information in Fig. 1(a). For every shaded block, if our algorithm achieves confidence in the prediction, then we give this shaded block a predicted rating value r u,i . Otherwise, we set the value of this missing data to zero, as seen in Fig. 1(b).

Accordingly, the collaborative filtering is simplified into two simple questions. The first is  X  X nder what circumstance does our algorithm have confidence to predict the shaded block? X  and the second is  X  X ow to predict? X . The following subsections will answer these two questions.
Similar neighbors selection is a very important step in predicting missing data. If selected neighbors are dissimilar with the current user, then the prediction of missing data of this user is inaccurate and will finally affect the predic-tion results of the active users. In order to overcome the flaws of Top-N neighbors selection algorithms, we introduce a threshold  X  . If the similarity between the neighbor and the current user is larger than  X  , then this neighbor is selected as the similar user.

For every missing data r u,i , a set of similar users S ( towards user u can be generated according to: where Sim ( u a ,u ) is computed using Eq. (4). At the same time, for every missing data r u,i , a set of similar items towards item i can be generated according to: where  X  is the item similarity threshold, and Sim ( i k ,i computed by Eq. (5). The selection of  X  and  X  is an im-portant step since a very big value will always cause the shortage of similar users or items, and a relative small value will bring too many similar users or items.

According to Eqs.(6) and (7), we define that our algorithm will lack enough confidence to predict the missing data r and only if S ( u )=  X  X  X  S ( i )=  X  , which means that user not have similar users and item i does not have similar items either. Then our algorithm sets the value of this missing data to zero. Otherwise, it will predict the missing data following the algorithm described in Subsection 4.2.
User-based collaborative filtering predicts the missing data using the ratings of similar users and item-based collabora-tive filtering predicts the missing data using the ratings of similar items. Actually, although users have their own rat-ing style, if an item is a very popular item and has obtained a very high average rating from other users, then the ac-tive user will have a high probability to give this item a good rating too. Hence, predicting missing data only using user-based approaches or only using item-based approaches will potentially ignore valuable information that will make the prediction more accurate. We propose to systematically combine user-based and item-based approaches, and take advantage of user correlations and item correlations in the user-item matrix.
 Given the missing data r u,i ,accordingtoEq.(6)and Eq. (7), if S ( u ) =  X  X  X  S ( i ) =  X  , the prediction of missing u u u u u u u after missing data prediction. data P ( r u,i ) is defined as: P ( where  X  is the parameter in the range of [0 , 1]. The use of parameter  X  allows us to determine how the prediction relies on user-based prediction and item-based prediction.  X  =1 states that P ( r u,i ) depends completely upon ratings from user-based prediction and  X  = 0 states that P ( r u,i ) depends completely upon ratings from item-based prediction.
In practice, some users do not have similar users and the similarities between these users and all other users are less than the threshold  X  . Top-N algorithms will ignore this problem and still choose the top n most similar users to predict the missing data. This will definitely decrease the prediction quality of the missing data. In order to predict the missing data as accurate as possible, in case some users do not have similar users, we use the information of similar items instead of users to predict the missing data, and vice versa, as seen in Eq. (9) and Eq. (10). This consideration in-spires us to fully utilize the information of user-item matrix as follows: If S ( u ) =  X  X  X  S ( i )=  X  , the prediction of missing data P ( r u,i ) is defined as: If S ( u )=  X  X  X  S ( i ) =  X  , the prediction of missing data P ( r u,i ) is defined as:
The last possibility is given the missing data r u,i ,user does not have similar users and at the same time, item i also does not have similar items. In this situation, we choose not to predict the missing data; otherwise, it will bring negative influence to the prediction of the missing data r u,i .Thatis: If S ( u )=  X  X  X  S ( i )=  X  , the prediction of missing data P ( r u,i ) is defined as:
This consideration is different from all other existing pre-diction or smoothing methods. They always try to predict all the missing data in the user-item matrix, which will pre-dict some missing data with bad quality.
After the missing data is predicted in the user-item ma-trix, the next step is to predict the ratings for the active users. The prediction process is almost the same as predict-ing the missing data, and the only difference is in the case for a given active user a ;namely,if S ( a )=  X  X  X  S ( i )= then predicts the missing data using the following equation: In other situations, if (1) S ( u ) =  X  X  X  S ( i ) =  X  ,(2)  X  X  X  S ( i )=  X  or (3) S ( u )=  X  X  X  S ( i ) =  X  , we use Eq. (8), Eq. (9) and Eq. (10) to predict r a,i , respectively.
The thresholds  X  and  X  introduced in Section 3 are em-ployed to avoid overestimating the users similarity and items similarity, when there are only few ratings in common. If we set  X  and  X  too high, most of the similarities between users or items need to be multiplied with the significance weight, and it is not the results we expect. However, if we set  X   X  too low, it is also not reasonable because the overestimate problem still exists. Tuning these parameters is important to achieving a good prediction results.

The thresholds  X  and  X  introduced in Section 4.1 also play an important role in our collaborative filtering algorithm. If  X  and  X  are set too high, less missing data need to be pre-dicted; if they are set too low, a lot of missing data need to be predicted. In the case when  X  = 1 and  X  =1,our approach will not predict any missing data, and this algo-rithm becomes the general collaborative filtering without data smoothing. In the case when  X  =0and  X  =0,ourap-proach will predict all the missing data, and this algorithm converges to the Top-N neighbors selection algorithms, ex-cept the number N here includes all the neighbors. In order to simplify our model, we set  X  =  X  in all the simulations.
Finally, parameter  X  introduced in Section 4.2 is the last parameter we need to tune, and it is also the most important one.  X  determines how closely the rating prediction relies on user information or item information. As discussed before,  X  = 1 states that P ( r u,i ) depends completely upon ratings from user-based prediction and  X  = 0 states that P ( r u,i depends completely upon ratings from item-based predic-tion. This physical interpretation also helps us to tune accordingly.

With the changes of parameters, several other famous col-laborative filtering methods become special cases in our ap-proach as illustrated in Table 1.
We conduct several experiments to measure the recom-mendation quality of our new approach for collaborative fil-tering with other methods, and address the experiments as the following questions: (1) How does our approach compare with traditional user-based and item-based collaborative fil-tering methods? (2) What is the performance comparison between our effective missing data prediction approach and other algorithms which predict every missing data? (3) How does significance weighting affect the accuracy of prediction? (4) How do the thresholds  X  and  X  affect the accuracy of pre-diction? How many missing data are predicted by our al-gorithm, and what is the comparison of our algorithm with the algorithms that predict all the missing data or no miss-ing data? (5) How does the parameter  X  affect the accuracy of prediction? and (6) How does our approach compare with the published state-of-the-art collaborative filtering al-gorithms?
In the following, Section 5.3 gives answers to questions 1 and 6, Section 5.4 addresses question 2, and Section 5.5 describes experiment for the questions 3 to 5.
Two datasets from movie rating are applied in our ex-periments: MovieLens 3 and EachMovie 4 .Weonlyreport the simulation results of MovieLens due to the space limi-tation. Similar results can be observed from the EachMovie application.

MovieLens is a famous Web-based research recommender system. It contains 100,000 ratings (1-5 scales) rated by 943 users on 1682 movies, and each user at least rated 20 movies. The density of the user-item matrix is: http://www.cs.umn.edu/Research/GroupLens/. http://www.research.digital.com/SRC/EachMovie/. It is retired by Hewlett-Packard (HP), but a postprocessed copy can be found on http://guir.berkeley.edu/projects/swami/. Table 3: MAE comparison with other approaches (A smaller MAE value means a better performance).
 Training Users Methods Given5 Given10 Given20 MovieLens 300 UPCC 0.838 0.814 0.802 MovieLens 200 UPCC 0.843 0.822 0.807 MovieLens 100 UPCC 0.876 0.847 0.811 The statistics of dataset MovieLens is summarized in Ta-ble 2.

We extract a subset of 500 users from the dataset, and divide it into two parts: select 300 users as the training users (100, 200, 300 users respectively), and the rest 200 users as the active (testing) users. As to the active users, we vary the number of rated items provided by the active users from 5, 10, to 20, and give the name Given5, Given10 and Given20, respectively.
We use the Mean Absolute Error (MAE) metrics to mea-sure the prediction quality of our proposed approach with other collaborative filtering methods. MAE is defined as: where r u,i denotes the rating that user u gave to item i r u,i denotes the rating that user u gave to item i which is predicted by our approach, and N denotes the number of tested ratings.
In order to show the performance increase of our effective missing data prediction (EMDP) algorithm, we compare our algorithm with some traditional algorithms: user-based al-gorithm using PCC (UPCC) and item-based algorithm using PCC (IPCC). The parameters or thresholds for the experi-ments are empirically set as follows:  X  =0 . 7,  X  =30,  X  =25,  X  =  X  =0 . 4.

In Table 3, we observe that our new approach significantly improves the recommendation quality of collaborative filter-ing, and outperforms UPCC and IPCC consistently.
 mance).
 Figure 2: MAE Comparison of EMDP and PEMD (A smaller MAE value means a better performance).
Next, in order to compare our approach with other state-of-the-arts algorithms, we follow the exact evaluation pro-cedures which were described in [21, 22] by extracting a subset of 500 users with more than 40 ratings. Table 4 summarizes our experimental results. We compare with the following algorithms: Similarity Fusion (SF) [21], Smooth-ing and Cluster-Based PCC (SCBPCC) [22], the Aspect Model (AM) [9], Personality Diagnosis (PD) [14] and the user-based PCC [2]. Our method outperforms all other com-petitive algorithms in various configurations.
Our algorithm incorporates the option not to predict the missing data if it does not meet the criteria set in Section 4.1 and Section 4.2. In addition, it alleviates the potential negative influences from bad prediction on the missing data. To demonstrate the effectiveness of our approach, we first conduct a set of simulations on our effective missing data prediction approach. The number of training users is 300, whereweset  X  = 30,  X  = 25,  X  =  X  =0 . 5, and vary  X  from zero to one with a step value of 0 . 05. We then plot the graph with the ratings of active users of Given5, Given10 and Given20, respectively. As to the method in predicting every missing data (PEMD), we use the same algorithm, and keep the configurations the same as EMDP except for Eq. (11). In PEMD, when S ( u )=  X  and S ( i )=  X  ,we predict the missing data r u,i using the nearest neighbors of the missing data instead of setting the value to zero. In this experiment, we set the number of nearest neighbors to 10. The intention of this experiment is to compare the performance of our EMDP algorithm with PEMD under the same configurations. In other words, we intend to determine the effectiveness of our missing data prediction algorithm, and whether our approach is better than the approach which will predict every missing data or not.

In Fig. 2, the star, up triangle, and diamond in solid line represent the EMDP algorithm in Given20, Given10 and Given5 ratings respectively, and the circle, down triangle, and square in dashed line represent the PEMD algorithm in Given20, Given10 and Given5 ratings respectively. All the solid lines are below the respectively comparative dashed lines, indicating our effective missing data prediction algo-rithm performs better than the algorithm which predict ev-ery missing data, and predicting missing data selectively is indeed a more effective method.
Significance weighting makes the similarity computation more reasonable in practice and devalues some similarities which look similar but are actually not, and the simulation results in Fig. 3 shows the significance weighting will pro-mote the collaborative filtering performance.

In this experiment, we first evaluate the influence of  X  , and select 300 training users, then set  X  =0 . 7,  X  =  X  =0  X  = 26. We vary the range of  X  from 0 to 50 with a step value of 2. Fig. 3(a),(b),(c) shows how  X  affects MAE when given ratings 20, 10, 5 respectively, and Fig. 3(d) shows that the value of  X  also impacts the density of the user-item matrix in the process of missing data prediction. The density of the user-item matrix will decrease according to the increase of the value of  X  . More experiments show that  X  has the same features and impacts on MAE and matrix density as  X  ; however, we do not include the simulation results due to the space limitation. Parameter  X  balances the information from users and items. It takes advantages from these two types of collaborative fil-tering methods. If  X  = 1, we only extract information from users, and if  X  = 0, we only mine valuable information from items. In other cases, we fuse information from users and items to predict the missing data and furthermore, to pre-dict for active users.

Fig. 4 shows the impacts of  X  on MAE. In this experiment, we test 300 training users, 200 training users and 100 train-ing users and report the experiment results in Fig. 4(a), Fig. 4(b) and Fig. 4(c) respectively. The initial values of other parameters or thresholds are:  X  =  X  =0 . 5,  X  =30,  X  =25.

Observed from Fig. 4, we draw the conclusion that the value of  X  impacts the recommendation results significantly, which demonstrates that combining the user-based method with the item-based method will greatly improve the rec-ommendation accuracy. Another interesting observation is when following the increase of the number of ratings given (from 5 to 10, and from 10 to 20), the value of arg min  X  of each curve in Fig. 4 shifts from 0.3 to 0.8 smoothly. This implies the information for users is more important than that for items if more ratings for active users are given. On the other hand, the information for items would be more im-portant if less ratings for active users are available; however, less ratings for active users will lead to more inaccuracy of the recommendation results.  X  and  X  also play a very important role in our collabora-tive filtering approach. As discussed in Section 4,  X  and directly determine how many missing data need to be pre-dicted. If  X  and  X  are set too high, most of the missing data cannot be predicted since many users will not have similar users, and many items will not have similar items either. On the other hand, if  X  and  X  are set too low, every user or item will obtain too many similar users or items, which causes the computation inaccuracy and increases the computing cost. Accordingly, selecting proper values for  X  and  X  is as criti-cal as determining the value for  X  . In order to simplify our model, we set  X  =  X  as employed in our experiments. In the next experiment, we select 500 users from Movie-Lens dataset and extract 300 users for training users and other 200 as the active users. The initial values for every parameter and threshold are:  X  =0 . 7,  X  = 30,  X  = 25. We vary the values of  X  and  X  from 0 to 1 with a step value of 0.05. For each training user set (100, 200, 300 users respec-tively), we compute the MAE and density of the user-item matrix. The results are showed in Fig. 5.

As showed in Fig. 5(a), given 300 training users and given 20 ratings for every active user, this algorithm will achieve the best performance around  X  =  X  =0 . 50, and the related density of user-item matrix in Fig. 5(d) is 92.64% which shows that 7.36% missing data of this user-item matrix are not predicted. In this experiment, the number of data that was not predicted is 0 . 0736  X  500  X  1000 = 36800. We observe that around  X  =  X  =0 . 70, this algorithm already achieves a very good MAE value which is almost the same as the best MAE values in Fig. 5(b). The related matrix density is 29.00%, which illustrates that more than 70% data of user-item matrix are not predicted. Nevertheless, the algorithm can already achieve satisfactory performance.
In this paper, we propose an effective missing data pre-diction algorithm for collaborative filtering. By judging whether a user (an item) has other similar users (items), our approach determines whether to predict the missing data and how to predict the missing data by using information of users, items or both. Traditional user-based collaborative fil-tering and item-based collaborative filtering approaches are two subsets of our new approach. Empirical analysis shows that our proposed EMDP algorithm for collaborative filter-ing outperforms other state-of-the-art collaborative filtering approaches.

For future work, we plan to conduct more research on the relationship between user information and item infor-mation since our simulations show the algorithm combining these two kinds of information generates better performance. Lastly, another research topic worthy of studying is the scal-ability analysis of our algorithm.
We thank Mr. Shikui Tu, Ms. Tu Zhou and Mr. Haix-uan Yang for many valuable discussions on this topic. This work is fully supported by two grants from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. CUHK4205/04E and Project No. CUHK4235/04E).
