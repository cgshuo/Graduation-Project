 ORIGINAL PAPER Weihan Sun  X  Koichi Kise Abstract Manga, a kind of Japanese comic book, is an important genre in the realm of image publications requiring copyright protection. To copy manga, illegal users gener-ally focus on certain interesting parts from which to make partial copies to apply in their own drawings. With respect to their sources, copying of manga can be divided into two types: (1) exact copies, which duplicate specific contents of manga, such as scanned manga publications (printed copies) and traced outlines of manga (hand-drawn copies), and (2) similar partial copies, which infringe the copyright of manga characters based on their features. In this paper, we propose applying content-based image retrieval methods to detect both exact and similar copies based on two kinds of regions of interest (ROIs): generic ROIs and face ROIs. The method is able not only to locate the partial copies from images with complex backgrounds, but also to report the corre-sponding copied parts of copyrighted manga pages for exact copy detection and copied manga characters for similar copy detection. The experimental results prove high performance of the proposed method for detecting printed partial copies. In addition, 85 % of hand-drawn and 77 % of similar partial copies were detected with relatively high precision using a database containing more than 10 , 000 manga pages. Keywords Manga  X  Printed copy  X  Hand-drawn copy  X  Similar copy  X  Partial copy  X  Content-based image retrieval 1 Introduction The term  X  X anga X , which is derived from the Japanese word, describes a kind of narrative artwork expressed by sequential comics and printed cartoons. Normally, a certain manga title or series consists of multiple volumes containing several hun-dred manga pages. As shown in Fig. 1 a, 1 objects in manga are mainly drawn with lines, but tones and word balloons elabo-rating the story lines are also employed. Although some full-color manga exist, manga publications are typically printed in black-and-white.

The modern style of manga developed in Japan in the late 19th century. In its short history, it has developed quickly to become one of the most popular types of image publication in the world. In Japan, especially, manga occupies a piv-otal position in the publishing industry. From a report by the AJPEA (All Japan Magazine and Book Publisher X  X  and Edi-tor X  X  Association) in 2006, manga account for 36.7 % of all publications [ 1 ]. Moreover, volumes of famous manga have been translated into other languages and exported to many countries. The North American manga market (2007) gener-ated $210 million in annual sales [ 30 ], and the manga markets of France and Germany (2006) also reached $212.6 million collectively [ 12 ]. In recent years, the Internet has also been used for the distribution of e-manga, which can be down-loaded to PCs, mobile phones and other digital terminals for viewing. The profitability of manga is not only confined to the sales of manga publications; revenues from other areas like advertisements and animation films using manga char-acters are also significant. Therefore, there is great interest in protecting the related copyrights.
To copy manga, illegal users not only duplicate whole manga pages directly, but also focus on certain interesting parts to make partial copies and apply them to their own drawings. Therefore, we must consider the detection of par-tial copies from unknown complex backgrounds. In addition, because of the simple compositions and abstract expressions applied in manga, there are some unusual types of copies, such as hand-drawn copies and similar copies described in the following, which may not occur in other kinds of images. We divide the illegal copies of manga into the following two categories based on their copy sources. (1) Exact copies are of content in specific manga pages, such as printed copies that are scanned from printed manga publications. Since manga are basically created in lines, hand-drawn copies can also be made easily by tracing. (2) Similar copies infringe copy-rights of manga characters. By imitating their features, new drawings of the same characters are created with different expressions. These kinds of copies make the copyright issues for manga more complex than other images.

In actuality, the determination of what constitutes an ille-gal copy is a controversial problem and always depends on the judgment of professionals. However, the huge volumes of manga publications require copyright protection, and it is impossible for human beings to check all manga pages manually. The purpose of our research is to apply computer techniques to detect candidate images for professionals X  fur-ther judgment.

To detect image copies, one of the methods is content-based image retrieval (CBIR). In that method, original images are collected to build a database, and suspicious images are treated as queries. Based on the features extracted from queries and images in the database, the queries similar to the original images are reported to the users. Since local features of images are robust for kinds of image transfor-mation, they are popularized in CBIR methods. Mikola-jczyk and Schmid [ 32 ] have compared various kinds of local features and proved that the SIFT (Scale-Invariant Feature Transform) [ 27 ]-based descriptors perform best for image retrieval. Ke et al. [ 23 ] proposed to detect near-duplicates and sub-images based on PCA-SIFT [ 22 ] features, which are Principal Component Analysis-based representations of SIFT features. Douze et al. [ 8 ] proposed applying SIFT features and a bag-of-features method to detect keyframes of video. Their performance on TRECVID2008 proved the robustness of this method to transformations like cropping, occlusions, etc. However, in the case of manga, hand-drawn copies change lines in detail, which challenges the robustness of these local features. Furthermore, since similar copies are created based on common features of manga characters per-ceived by human beings, these methods are no longer effec-tive.

In this paper, we propose a CBIR-based method to detect partial copies of manga. The method is based on two kinds of regions of interest (ROIs): generic ROIs for exact partial copies and face ROIs for similar partial copies. For generic ROIs, we propose a process of database construction and compare several approximate nearest neighbor search meth-ods by experiment. For face ROIs, we discuss the relation between the size of the database and performance for similar partial copy detection. All ROIs in the proposed method are automatically detected from manga pages and used to gen-erate the databases without any supervision. In the experi-ments, we employed over 10 thousand manga pages from 21 titles as copyrighted images. Three kinds of copies are applied as queries: printed exact copies, hand-drawn exact copies and similar copies. From the experimental results, we have confirmed the following:  X  Effectiveness of the proposed method in detecting exact  X  Benefits of database construction strategies. For generic The generic ROIs and face ROIs are based on our previ-ous work [ 40 , 41 ], respectively. The extensions of this paper include (1) discussion on the scales of ROIs and a more com-pact feature representation, (2) database construction meth-ods to increase the scalability, (3) stable matching methods for generic ROIs and face ROIs, separately. In the experi-ments, a database 10-times the size of the one in [ 40 ]was employed for exact copy detection, and a larger database compared to that of [ 41 ] was applied for similar copy detec-tion.

The rest of this paper is arranged as follows: Sect. 2 defines our task. Section 3 covers related work. Section 4 introduces the proposed method. Experiments and results are presented in Sect. 5 . Finally, Sect. 6 concludes the paper and discusses future work. 2 Task definition Let us first define the task of partial copy detection of manga. A sample manga page is shown in Fig. 1 a. To copy an image, rather than duplicating the whole page, a partial copy is usu-ally the method applied. As shown in Fig. 1 b focusing on a part of this manga page, several kinds of partial copies can be created. Printed partial copies are produced by scanning printed manga and always include some image noise. Hand-drawn partial copies are created by tracing the main lines of manga pages, which contain many changes in detail. These two kinds of copies are based on contents of a specific original and thus are called exact partial copies. For these, we should consider protecting the entire image, since any part can be copied. In contrast to exact copies, similar copies are created based on features of main characters, but with more global differences, such as poses, facial expressions and occlusions. Mostly, main characters are the targets for similar copies. Furthermore, the partial copies are always applied as parts of other drawings, as shown in Fig. 1 c. Therefore, for copyright protection, all kinds of partial copies should be detected from complex backgrounds.

To reduce the burden of manual checking by humans, the copy detection system should report which part of a suspi-cious image is a possible partial copy and also offer its corre-sponding original regions as evidence to assist the judgment. Since for human beings the partial copy is easy to recognize if related to its original, our task is defined as matching parts of partial copies with their originals. Therefore, the matchings shown in Fig. 2 a, b are defined as correct matchings since they can help users locate the partial copy, and the matching shown in Fig. 2 c is erroneous. For exact copy detection, the correct matching is one-to-one matching between a partial copy and its original contents. For similar copy detection, the correct matching is one-to-many matching in which mul-tiple similar patterns of the same character are reported for further checking. 3 Related work There are few methods proposed for the detection of illegal copies of manga. However, methods applied to other images offer us much related work. 3.1 Digital watermarking To protect the copyright of color images, digital watermark-ing is a commonly applied method. By changing the contents of images slightly, copyright owners can incorporate work-identifying information into images. Within huge amounts of color information, watermarks can be embedded invisibly to the human eye. Many watermarking schemes have been designed to resist geometric distortions using such methods as invariant transforms [ 25 ], image features [ 3 ] and template insertion of frequency domain [ 34 ].

However, since manga generally have minimal color infor-mation, it is difficult to embed enough information without being perceived. In addition, the hand-drawn copies simply trace the main outline of the originals; thus, any embedded information will not be included. 3.2 Content-based image retrieval Since illegal copies contain elements similar to the originals, content-based image retrieval (CBIR) is an effective method for detecting image copies [ 4 , 18 , 23 , 45 , 46 ] and video copies [ 8 , 20 , 21 ]. In this method, copyrighted images are collected to build a database, and illegal copies as queries are retrieved and matched with similar ones in the database. Rather than using metadata such as keywords or tags, CBIR methods retrieve images by analyzing their visual content, such as tial for CBIR systems to have appropriate feature represen-tations of images with corresponding similarity measures to rank the retrieved results.

At the point of feature regions, global attributes have lim-itations in resistance to cropping, shifting or compositing, for which features based on distinctive local region detec-tors show good performance. Local features are therefore often applied in CBIR methods. Berrani et al. [ 4 ] proposed an image near-duplicate detection system employing local differential descriptors and approximate similarity search. Zhang and Chang [ 45 ] used color and texture features around interest points detected by the SUSAN corner detector [ 39 ] for near-duplicate detection. Ke et al. [ 23 ] employed PCA-SIFT [ 22 ] features for detecting near-duplicates and sub-images. Joly et al. [ 20 ] proposed a video copy identification method based on Harris interest points [ 37 ] and a differential description of the local region around each interest point from key frames corresponding to extrema of the global inten-sity of motion [ 9 ]. Douze et al. [ 8 ] applied a bag-of-features method to detect key frames of videos, in which SIFT [ 27 ] and CS-LBP [ 16 ] features are applied to describe Hessian-Affine regions [ 31 ].

To improve the performance of retrieval under various kinds of transformations, reliable matchings are carefully designed in many methods. Ke et al. [ 23 ] employed a typical criterion of similarities and RANSAC (RANdom SAmple Consensus) [ 11 ] for affine geometric verification. Zhang and Chang [ 45 ] applied Stochastic Attributed Relational Graphs of interest points. Hsiao et al. [ 18 ] applied virtual prior attacks to copyrighted images to generate novel features. Zhao and Ngo [ 46 ] proposed Scale-Rotation Invariant Pattern Entropy to measure the spatial regularity of matching patterns formed by local keypoints.

Because of the tremendous amount of features in the data-base, fast similarity searching is another critical step for CBIR systems. To handle the scalability issue, approximate nearest neighbor search techniques such as [ 2 , 14 , 36 , 44 ], exploring trade-offs between accuracy and speed, have been actively studied. Muja and Lowe [ 33 ] proposed applying multiple, randomized k-d trees for matching SIFT features. Joly et al. [ 21 ] proposed an approximate search method with probabilistic selection of feature space regions based on the distribution of the feature distortion. In [ 23 ], Local Sensitive Hashing (LSH) [ 14 ] was employed for indexing features. Rather than using randomized projections in LSH, Weiss et al. [ 44 ] proposed code generation using the projections on the principal component directions, and Torralba et al. [ 42 ] applied Restricted Boltzmann Machines [ 17 ] and a Boosting method [ 38 ] to learn the codes. Both of them were applied to image global features for a database of millions of images.
Our method follows CBIR methods for detecting copies of manga. The most similar research is [ 23 ], which offered good performance on color images. However, in the case of manga, hand-drawn copies and similar copies pose a chal-lenge to popular methods. Our previous work [ 40 ] introduced a feature-matching method to detect partial copies of line drawings. It achieved detection of printed and hand-drawn partial copies of manga and has been proved to be robust to rotations and scale transformations in a certain range. In [ 41 ], we focused on important parts of manga and proposed a method to detect similar manga characters using their face patterns. The ROIs applied in the proposed method are based on these two works. In this paper, we discuss parameters of ROIs for performance and represent them in a more com-pact way. Furthermore, for exact copy detection, we pro-pose a process to build a more discriminative database with a smaller size and compare several approximate nearest neigh-bor searching methods. For similar partial copies, we discuss factors for higher recall and precision and show the effective-ness by experiment. 4 Proposed method 4.1 Overview The processing of the proposed method is shown in Fig. 3 . First, copyrighted manga pages are collected, from which two kinds of ROIs are extracted: generic ROIs, which are born from salient parts of pixels, and face ROIs, which are based on face regions of manga characters. Each ROI has a label of its original manga page ID as well as its position in that manga page, which will be used to locate the infringed originals. Each ROI is represented as a feature vector obtained by using a feature descriptor, and for each generic ROI and face ROI, we build a database of feature vectors. On the other hand, suspicious images are treated as queries, from which face ROIs and generic ROIs are detected and described as feature vectors. Then, feature vectors from queries are matched with the feature vectors in two databases separately. Depending on the matched ROIs, the regions of candidate partial copies and corresponding evidence are reported to assist users in finding the illegal copies. 4.2 Generic ROI detection For exact copy detection, to obtain robust ROIs from both printed and hand-drawn copies, we apply regions based on MSERs (Maximally Stable Extremal Regions) [ 29 ]. First, pixels of the detected image are sorted by intensity. Like a binarization, pixels under a threshold are marked. With grow-ing of the threshold, more pixels are marked and merged with neighbors as regions. Based on the function of rela-tive changes between the regions and thresholds, MSERs are detected as regions corresponding to thresholds, which gen-erate local minima of the function. The MSERs can also be understood as parts of the image where local binarization is stable over a certain change of intensity. For hand-drawn copies, lines contain many local variations in thickness, intensity and orientation. However, the regions surrounded by lines are relatively stable and the intensity inside gives contrast to the lines. Therefore, the properties of MSERs are helpful for obtaining stable regions.

As shown in Fig. 4 b, by diagonalizing the covariance matrix of MSERs, we can obtain some ellipse regions from the image. Since the handwriting may change the image in detail, we filter small regions out as unreliable ones. In addi-tion, as shown in Fig. 4 d, to increase the information amount in generic ROIs, we scale the ellipses of MSERs S g times, which is discussed in the experiments (Sect. 5.1.2 ). Finally, as shown in Fig. 4 e, by rotating the long axis of the ellipse parallel to the y axis of the image, we obtain one generic ROI. 4.3 Face ROI detection For similar copy detection, since the faces are one of the most characteristic parts of manga, regions around centers of faces are applied as face ROIs. To detect faces of manga characters, we use the Viola-Jones detection framework [ 43 ], which is an object-detection method and has been proved to be effective for detecting faces from images. We have proved that it is also available to detect the faces of manga characters [ 41 ]. In the framework, first, a classifier is trained to extract certain properties of the detected object. Then, based on the classifier, the entire image at every possible location and scale are scanned to locate objects. 4.3.1 Cascade classifier To train the classifier, positive samples (images containing the object) and negative samples (images without the object) are collected and represented by using image features. In our research, we applied Haar-like features in the same way as the Viola-Jones framework. For each feature, a decision tree is built as a weak classifier. predict whether the image contains the objects. Then, the AdaBoost algorithm [ 13 ]is utilized to select the weak classifiers and arrange them into a cascade structure (called the cascade classifier) using a set of optimization criteria.
 ( a ) (b) (c) 4.3.2 Detection of face ROIs The sliding window technique is applied to detect sub-windows in different scales with the cascade classifier. The detected sub-windows are grouped by the union-find algo-rithm. Normally, the detected regions (unit ROI) are from eyebrow to chin, as shown in Fig. 5 a. Because cartoon char-acters are drawn with simple lines, it is difficult to recognize them only based on unit ROIs. For more discriminative infor-mation, the detected regions are enlarged as face ROIs. As shown in Fig. 5 , face ROIs have the same centers as the unit ROIs, and their sides are set to 1 + S f / 8 times as large as the original unit ROIs. However, with increasing S f ,more noise from the backgrounds is input into the ROIs, which is adverse to detection. The effect of S f is discussed in the experiments (Sect. 5.2.3 ). 4.4 Feature representation Then, each ROI (both generic ROIs and face ROIs) are rep-resented by a feature vector. To cope with variations con-tained in copies of manga, we apply histograms of oriented gradients (HOG) [ 6 ] to describe the face ROIs and generic ROIs. Because HOG features are robust to changes of edges and illuminations, they are often employed for detection of objects [ 6 , 10 ] and also successfully applied to handwriting recognition [ 26 ].

The basic idea of HOG is that local object appearance and shape can often be characterized rather well by the distrib-ution of edge directions, even without precise knowledge of the edge positions. The calculation of HOG feature vectors is shown in Fig. 6 . The parameters are set based on the dis-cussion in [ 6 ]. First, we calculate the gradient magnitude and orientation at each pixel, then divide each ROI into 8  X  8 cells evenly. Next, the gradient orientations are quantized into 9 bins. For each cell, we calculate the gradient orientation his-togram based on the gradient magnitude. After that, cells are combined into overlapping blocks as 3  X  3 cells per block, thus 6  X  6 blocks per ROI. By normalizing the features in units of blocks, we obtain a 9  X  3  X  3  X  6  X  6 = 2 , 916 dimensional HOG feature vector for one ROI.

Moreover, PCA (Principal Component Analysis) [ 19 ] is applied to compress the HOG vectors. We build the eigenspace using 60 , 000 training feature vectors for generic ROIs and 20 , 000 training feature vectors for face ROIs. The top 100 principal components are retained. Finally, the fea-ture vectors of both face ROIs and generic ROIs are reduced to 100 dimensions, which are called PCA-HOG feature vectors. 4.5 Database constructions For each ROI, the feature vector with the image ID and the position of its source are stored into databases. Depending on the type of ROI, two databases are built with different strategies for performance. 4.5.1 Generic ROIs Since generic ROIs are based on local feature regions of the whole image, some widely applied patterns, such as tones, words and frames, are also detected from manga pages. They occupy a large part of the database but without contributions for copy detection. Furthermore, because of their similar shapes, they always cause erroneous matchings. Therefore, their removal not only reduces the size of the database but also leads more effective detection.

To remove these patterns, we propose a method from the viewpoint of image retrieval. If there are other similar pat-terns that may cause erroneous matchings, the patterns are treated as low discriminative ones and need to be removed. The process is based on the relationship of ROIs in the fea-ture vector space. Because low discriminative patterns follow similar or almost the same style or shape characteristics, their feature vectors are close to others as a cluster. As shown in Fig. 7 , we detect such clusters and remove them in the data-base. Since the results of exact copy detection are reported by matching features of queries with manga pages in the database (described in Sect. 4.7 ) and similar features of the same page can offer clues for locating copies, we cluster the features based on features of different manga pages. Specifically, for each feature vector, distances with its neigh-bors from different manga pages are calculated. If the dis-tance between two feature vectors is less than a threshold T they are similar to each other. By the union-find algorithm, we obtain the clusters of similar feature vectors.
In the proposed method, depending on the threshold T c , some patterns, which are helpful for detection, may also be removed. However, since there are still many discriminative ones left, the detection performance is not seriously affected. In the experiments (Sect. 5.1.5 ), we achieve better perfor-mance with a more compact database by the database con-struction method. 4.5.2 Face ROIs Compared to generic ROIs, the number of face ROIs is much lower, since only the patterns with face-shape features are detected. Within one manga title, the main characters appear frequently while changing as the story unfolds. Therefore, for one manga character, there are usually more than one face ROI, which are different as scenes change. All of these face ROIs are applied in the database. In addition, since there may be many variations in the similar copies of manga char-acters, more possible patterns in the database can offer better detection performance. An example is shown in Fig. 8 a. The circles and triangles represent the face ROIs of two different manga characters in the database, and the star represents a query. As a similar copy, the query is far different from its originals and difficult to classify based on the current data-base. This can be improved on the benefit of increasing face ROIs in the database, as shown in Fig. 8 b. Based on this idea, the database construction of face ROIs is to apply more patterns. The original volumes of manga pages provide us a huge resource of patterns in different scenes; therefore, the implementation is to simply increase manga pages for face ROIs. 4.6 ROI matching Both the generic ROIs and face ROIs are local feature regions, which are parts of the images. For image retrieval using local feature matching, the Euclidean distance is usually utilized as a dissimilarity measure, such as [ 23 , 27 ]. Here, we also rate the similarities of ROIs according to the Euclidean dis-tances of their feature vectors. For different ROIs, the reliable matchings are defined as follows.  X  For generic ROIs, each ROI from the query can only be  X  For face ROI, one ROI from the query can be matched Furthermore, we employ ANN (Approximate Nearest Neigh-bor Search) [ 2 ] to speed up the matching. ANN is a method to find approximate nearest neighbors by using the k-d tree. First, the feature vector space of the database is subdivided into a k-d tree structure. One leaf of the k-d tree includes only one feature vector and corresponds to the segmented area in the feature space. Figure 9 shows an example where rectan-gles represent leaves of the k-d tree. Given a query vector q , by using the k-d tree, the leaf that also contains q is located and the feature vector in this leaf area is regarded as a tentative nearest neighbor with the distance r . The true nearest neigh-bor is in the hypersphere with this radius. Thus, all leaf areas that overlap with the hypersphere are searched and the feature vector with the minimum distance is reported as the nearest neighbor. The approximation of search is done by shrinking the radius r by the factor 1 /( 1 +  X ) . Although the processing can speed up the matching drastically, shrinking the space always carries the risk of missing the true nearest neighbor. In the case of Fig. 9 , p 2 is found as the approximate near-est neighbor. As shown by the dotted circle, the true nearest neighbor p 3 is missed. In the experiments (Sect. 5.1.4 ), we compare the performance of ANN with two other hashing-based approximate nearest neighbor search methods.
To use ANN, we need to build a k-d tree using the feature vectors of all ROIs in the database. It is necessary only for one time at the beginning and is applied in all of the detection. For changes of the database, the k-d tree should be rebuilt. However, the features of the manga pages are only computed one time and applied in later database constructions. 4.7 Outputs Now, we obtain some ROIs from query images matched with their corresponding ROIs in the database. Based on their manga page IDs and position information, the proposed method can locate the partial copies in the query with copied original parts. 4.7.1 Exact partial copy We apply affine geometric verification using RANSAC [ 11 ] to matched generic ROIs between queries and corresponding database manga pages. If the number of the verified match-ings is over a threshold M g , the partial copy will be reported. 4.7.2 Similar partial copy As similar partial copies, matched face ROIs are reported directly. Since more than one face ROI in the database may be matched with one query face ROI, we limit the number of outputs and only report the top M f results depending on their similarities. 5 Experiments In this section, we present a number of experiments to dis-cuss the parameters for performance and test the effective-ness of the proposed system for detecting exact and similar partial copies. As data for experiments, we made a collec-tion of manga pages (grayscale images, about 800  X  1200 pixels) from 21 titles. 2 All experiments were done using a computer with CPU INTEL Core i7-870 2 . 93 GHz and RAM 8 GB. The detection results are reported by using recall R = A / B and precision P = A / C , where A is the number of correctly detected partial copies, B is the number of cor-rect partial copies, and C is the number of detected partial copies. The recall and precision will change with the thresh-old T g , T f for reliable matchings and M g , M f for outputs. The parameter setting of the proposed method is shown in Table 1 . We report the performance of detections by interpo-lated precision-recall graphs. Since high recall is important to illegal copy detection, for evaluations of performance and analyses of experimental results, we focus on high recall with an acceptable precision. 5.1 Experiments on exact copy detection 5.1.1 Experimental settings For exact partial copies, we selected 109 manga pages con-taining large entire scenes. From each of them, we cropped one part of fixed size (400  X  400 pixels) that includes some objects interesting to copy. Regarding cropped parts as copy targets, we printed them as printed partial copies and traced their main lines to make hand-drawn partial copies. Then, two kinds of partial copies are scanned into digital images (300  X  300 pixels). Some examples are shown in Fig. 10 .For backgrounds, we chose 9 manga pages (about 800  X  1 , 200 pixels) from our collection, which were not included in the databases. Each exact partial copy was embedded into these backgrounds at random positions, and thus, 109  X  9 = 981 partial copies with backgrounds were created for each type of exact copy.

There are five experiments for exact copy detection. The first three experiments are (1) discussion of the scales of generic ROIs, (2) evaluation of feature representations and (3) comparison of search methods. In these three experi-ments, we applied printed and hand-drawn partial copies without backgrounds as queries and a small database of 109 manga pages, from which partial copies were made. After that, we tested the effectiveness of the database construction method by using the partial copies with backgrounds and a database of 10 , 009 manga pages. Finally, different datasets were applied to test the robustness of the proposed method. 5.1.2 Scale of generic ROI First, we chose the scale S g of generic ROIs depending on precision of ROI matchings.

In this experiment, M g was set to 1; thus, the results were precise for single ROI. To check the performance of ROIs precisely, exact nearest neighbor searching was applied. T was varied to obtain the recall and precision of single ROI. We employed the precision at 95 % recall for the evaluation of different S g as shown in Fig. 11 .

For printed partial copies, except for S g = 1, other scales achieved precisions over 95 %. This is because detected MSERs (generic ROI of S g = 1) were so small that less discriminative information was contained. For hand-drawn partial copies, S g = 3 performed the best. With increase in the scale, there is more information inside the generic ROIs, including the variations resulting from drawing by hand. We used S g = 3 for the rest of the experiments. 5.1.3 Evaluation of effectiveness Next, we tested the effectiveness of the proposed method (named PCA-HOG) compared with the method using PCA-SIFT features [ 22 ] (named PCA-SIFT).

PCA-SIFT Many studies have applied PCA-SIFT fea-tures and retrieved images with various transformations [ 23 , 24 ]. PCA-SIFT features were based on SIFT feature points [ 27 ] but use a PCA-based representation. We retrained the eigenspace using 55 , 000 patches from manga pages. The process of the PCA-SIFT method was the same as the pro-posed method except for the employed local features. For the PCA-SIFT method, the parameters of distance restric-tion, the distance rate and number of verified matchings are T , M The parameter setting is shown in Table 2 .

We detected printed and hand-drawn partial copies by exact nearest neighbor search. Figure 12 shows the compari-son results of the two methods. We can see that both methods had good performance for printed partial copies. However, for hand-drawn copies, compared to the ineffectiveness of PCA-SIFT, PCA-HOG achieved much better detection. From this experiment, we can see that (1) PCA-SIFT features are not robust for the variations of hand drawings and (2) PCA-HOG features are available for the detection of both printed and hand-drawn copies.

To conduct a clear discussion on the effectiveness of the region detectors (the SIFT region detector and the proposed generic ROI detector, which is called GROI for short) and feature descriptors (the SIFT feature descriptor and HOG feature descriptor) for variations caused by hand drawing, we made comparisons of their combinations. With different region detectors and feature descriptors, three features were created as follows.  X  SIFT+SIFT is the SIFT features based on the SIFT  X  GROI+SIFT uses the proposed generic ROI detector and  X  GROI+HOG uses the proposed generic ROI detector
By using these three features, we conducted an experi-ment on hand-drawn partial copy detection again ( R = 0 . for all three methods). As shown in Fig. 13 , the method using GROI+SIFT features performed much better than using SIFT+SIFT features, and the performance was improved by using the HOG feature descriptor to describe the generic ROIs. From the results, we can draw a conclusion as follows.  X  The proposed generic ROIs are more robust than regions  X  HOG offers a more effective description than the SIFT 5.1.4 Approximate nearest neighbor searching Then, we compared several approximate nearest neighbor search methods for exact partial copy detection, including ANN [ 2 ], a method using Spectral Hashing (named SH) [ 44 ] and a modified method of SH (named PSH), which only searches in a reliable range using codes of SH.

SH The basic idea of spectral hashing is to map feature vectors to binary codes. Compared to LSH [ 14 ] using ran-domized projections, spectral hashing generates much more compact codes (length of the code l ) by thresholding some nonlinear functions on the projections along the principal component directions. It has been proved to outperform LSH for retrieving similar neighbors [ 44 ]. We speed up the search-ing by retrieving the nearest neighbor within a small Ham-ming distance d of the code for the query.

PSH Considering the changes of binary codes caused by variations from queries, we also applied a similar strategy as [ 24 ] to the SH method. To obtain the binary code, the projection value of each bit was thresholded in the method of spectral hashing. In general, some values are very close to the thresholds and likely to be unreliable. Therefore, we evaluated the reliability of each bit by the difference between the projection value and the threshold and sorted the bits of binary codes in descending order of reliability. The top b bits within a tolerance e are treated as unreliable ones, otherwise as reliable. The search was done with the codes whose reliable bits are the same as the code for the query, and other bits were flipped to generate all possible 2 patterns. Therefore, we can focus only on the unreliable parts of codes and speed up the searching more than searching within Hamming distance ranges.
 The parameters for three methods are set as shown in Table 3 . For ANN, there is only one parameter  X  . is to search the exact nearest neighbor. Larger  X  leads to a faster searching with more risk for missing the exact nearest neighbor. For the methods of SH and PSH, the performance is affected by several parameters, and we chose a range of them that may achieve acceptable results. Except for search meth-ods, other settings of the detection are the same as the last experiment. We used precision at 95 % recall as the criterion for the evaluation of detection accuracy. The detection times with corresponding accuracy are shown in Fig. 14 . We can see that PSH performed better than SH. Compared to ANN, PSH could achieve the same performance for printed par-tial copies. However, for handwritten partial copies, PSH did not perform better than ANN. This is because hand drawing causes many changes to the codes. As approximate nearest neighbor search, methods based on hashing can find sim-ilar data points quickly but may lose many exact nearest neighbors. As the results of [ 23 ], 71 % correct matchings are missed by using LSH. For the case of many correct match-ings contained in queries, the large fraction of missed correct matchings have few effects on the results. Since our hand-drawn partial copies contain little information with many variations, the correct matchings are important for the per-formance. Therefore, we applied ANN as an approximate search method and set  X  = 5 for the balance of accuracy and search speed in the next experiment. 5.1.5 Partial copy detection from complex backgrounds In this experiment, we tested the performance of the pro-posed method for detecting exact partial copies from back-grounds based on larger databases. The queries were 981 manga pages with one partial copy inside each at a random position (named printed copies and hand-drawn copies for short in the following). There were 269 PCA-HOG features per query image on average. The database contained 10 , 009 manga pages, from which we obtained 6 , 423 , 467 generic ROIs and built a database (DB1) using all of them. We empir-ically set Tc = 5 . 5 for database construction of the proposed method and obtained a database (DB2) of 4 , 338 , 910 generic ROIs.

The interpolated precision-recall graphs of the detec-tion based on these two databases are shown in Fig. 15 . The results show that the performance for both printed and hand-drawn copies improved by using the process of data-base construction. The proposed method achieved the detec-tions of 99 % precision at 95 % recall for printed copies, and 42 % precision at 85 % recall for hand-drawn copies. Some correctly detected examples are shown in Fig. 16 ,from which we can see that although there is only a small partial copy (about 10 % of the whole image) in queries, the pro-posed method can locate them and offer the copied parts precisely.

For the failures of hand-drawn copy detection, main rea-sons are listed in the following:  X  Little discriminative information. No results were  X  Similar parts. Although the manga pages of back-
The database size (DB2) was 4 . 1 GB (including the feature vectors, image IDs and position information). The detection time was about 1 . 2 s per query. 5.1.6 Copy detection based on different datasets Of course, the performance of the proposed method is related to parameter settings. However, they are insensitive to changes of datasets. To test this point, we divided both the printed and hand-drawn queries utilized in Sect. 5.1.2 into two groups (one group contained 412 images and the other contained 549 images) based on their original titles. Three databases were built including 109 copied manga pages and 3 , 000 other manga pages for each. Except for the copied originals, the other manga pages are from different titles of manga with various contents and resolutions. The parameters of the system were set as T c = 5 , T g = 7 . 5 , M g = 3 for high recall. With these fixed parameters, we detected the groups of queries based on different databases.

The detection results are shown in Fig. 18 . Compared to the detection of printed copies, the performance of hand-drawn copy detection was lower. Viewing printed and hand-drawn copies separately, the results were not so different for different datasets. The variations of recall and precision are within 5 % for the printed copy detection and 3 % for hand-drawn copy detection. It proved that the performance of the proposed method is not dependent on datasets. 5.2 Experiments of similar partial copy detection 5.2.1 Experimental settings For detection of similar partial copies, we used three volumes (vols. 1 , 2 , 4) of our manga collection (21 titles) to build the databases. As similar partial copies with backgrounds (named similar copies for short in the following), 100 full manga pages were chosen from vol. 3 of collected manga (5 pages for each title of published works, 10 pages for the other three titles of manga drawn for this research). Here, the specific volumes of queries and databases are not impor-tant. In one title of manga, the main characters should appear throughout all volumes, but with changes, such as different poses, facial expressions and viewpoints. Therefore, the case is the same as that of actual similar copies.
Experiments were done for three purposes: (1) to discuss the effect of training samples for face ROI detection, (2) to select the scale of face ROIs and (3) to test the performance of database construction ideas. 5.2.2 Face ROI detection To train the cascade classifier, we cropped 3 , 000 faces of manga characters as positive samples and 8 , 000 non-face patterns from manga as negative samples. The faces were cropped from just above the eyebrows to the chins of the characters and normalized to 24  X  24 pixels. In the simi-lar copies, there were 365 faces, which were treated as true answers in this experiment. We trained 4 kinds of classifiers by different sizes of sample sets and detected the face ROIs with them.

As shown in Table 4 , the results show us the trade-off between precision and recall. Take the classifier trained with 1 , 000 positive samples and 1 , 000 negative samples as a base-line, we can see that a larger number of negative samples can increase precision and decrease recall. In contrast, increasing positive samples can lead to a higher recall with lower preci-sion. By increasing both positive and negative samples, we can obtain relatively high recall and precision. Considering the balance between recall and precision, we chose the clas-sifier trained with 3 , 000 positive samples and 8 , 000 negative samples, by which we detected 333 regions (293 true posi-tives) from the similar copies. Examples of the detection by this classifier are shown in Fig. 19 . The detection time was 472 ms per image. 5.2.3 Scale of face ROI Next, we discuss the scale of face ROIs by an experi-ment on face ROI recognition. The 293 face ROIs (contain-ing true faces) were treated as queries. The database was built with face ROIs detected from vol. 1 of the manga in the collection. We changed the scale of face ROIs ( S f = 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8) and matched them with their near-est neighbors ( M f = 1) in the corresponding databases. For the exact performance of face ROIs of different scales, exact nearest neighbor searching was applied in this experi-ment. Right answers are the matching between the face ROIs belonging to the same character.

From the results shown in Fig. 20 , we can see the per-formance by using ROIs of different scales. Because of dif-ferent facial expressions for the same characters in different volumes, the recognition rates were not over 80 %, and the peak was achieved by S f = 3, which was used in the next experiment. 5.2.4 Similar copy detection Finally, we tested the idea of database construction for similar copy detection. We built three databases using different vol-umes of manga in our collection: DB1 (vol. 1), DB2 (vols. 1 , 2) and DB3 (vols. 1 , 2 , 4), based on which we detected similar copies. Because each volume contains the same main characters of the manga, there were more face ROIs for one character in DB3. The matchings of ROIs for the same char-acters were treated as correct results. M f wassetto5sothat at most 5 matchings were reported for one ROI.  X  was set to 5 for ANN.

By changing T f , we obtained the interpolated precision-recall graph as shown in Fig. 21 . Because of the false neg-atives from face ROI detection (recall = 80 . 0 %), the recall did not exceed 80 %. DB3 achieved relatively high recall with higher precision than DB1 and DB2. This is because DB3 offered more patterns for the variations of faces of manga characters.

Then, we checked detection results based on DB3 using a fixed parameter setting. M f was set to 1; thus, only the patterns with the maximum similarity to the queries were reported, and T f was set to 3. Some correct matchings are showninFig. 22 . We can see the effectiveness of the proposed method for the recognition of similar ROIs. In particular, as Fig. 22 d X  X  (they represent the same character) show, although facial expressions contain significant variations, the proposed method correctly detected them. Moreover, face ROIs of dif-ferent resolutions can be matched, since they are described evenly with normalization of blocks.

Main reasons for the failures are threefold. (1) False neg-atives and false positives of face ROI detection. As shown in Fig. 19 b, the bottom-right region was falsely detected, and one face close to it was missed. Since only the matching of the same character is treated as a correct answer, the erro-neous and mis-detected face ROIs must be errors for the final results. (2) No discriminative features in the face ROIs. Some characters have similar faces and the discriminative features are outside of the face ROIs applied in the proposed method. As shown in Fig. 23 a, for the face ROIs, they are similar, but the hair style and the ribbon, from which their difference becomes clear, are outside of the ROIs. (3) Similar expres-sion of different characters. As shown in Fig. 23 b, c, they are from different manga titles, and the exaggerated facial expressions made them different from their corresponding face ROIs in the database, but similar to each other.
There are 11,603 manga pages in DB3, from which 28,566 face ROIs were detected and employed in the database. The database size was 114 MB. Similar copy detection includes two parts: face ROI detection and similar face ROI recogni-tion. The average time for similar face copy detection was 538 ms (including 472 ms for face ROI detection) per manga page.

To look at the performance on different titles of manga, the 21 titles of manga (DB3 and 100 query pages) were divided into 7 groups. Except for the three titles drawn for this research (named as group 0), others were grouped ran-domly as three titles for each. Using the same parameters ( T corresponding groups of databases. The results are shown in Fig. 24 . Because there were much fewer manga pages in group 0 than other groups, the result of group 0 was worse than other groups. Except for group 0, the detection results of other groups were within 10 % variation of recall and preci-sion. The difference is mainly because of the low face detec-tion rate of cartoon characters in some titles of manga. For the results within such a variation, the parameter setting can also be applied for different titles of manga. 5.3 Discussion For an applicable method, we should consider three kinds of performance: database size, detection time and detection rate.  X  Database size The database size depends on the number  X  Detection time The ROI detection time and feature  X  Detection rate For illegal copy detection systems, recall
In addition, for both building the databases and detec-tion of illegal copies, manga pages are used directly without selection, cropping or any supervision in our system. This is a practical feature for actual use. 6 Conclusion and future work To protect the copyright of manga, we presented a CBIR-based method to detect exact and similar partial copies in order to reduce workload of humans. Based on feature match-ing, the proposed method is able not only to locate the posi-tion of partial copies in complex backgrounds but also to retrieve the original parts as evidence. We also proposed dif-ferent database construction methods for exact and similar copies to improve performance. Through experiments, we proved the high performance of the proposed method for detecting printed partial copies. In addition, the proposed method showed effectiveness for detecting hand-drawn and similar partial copies, which cannot be detected by traditional CBIR methods.

Our future work includes (1) improving the scalability of the proposed method, (2) increasing the detection rate of sim-ilar partial copies and (3) constructing automatic parameter setting schemes for the performance.
 References
