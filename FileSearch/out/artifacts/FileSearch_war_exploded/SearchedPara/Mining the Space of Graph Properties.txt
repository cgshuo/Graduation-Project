 Existing data mining algorithms on graphs look for nodes satisfying specific properties, such as specific notions of struc-tural similarity or specific measures of link-based impor-tance. While such analyses for predetermined properties can be effective in well-understood domains, sometimes identify-ing an appropriate property for analysis can be a challenge, and focusing on a single property may neglect other impor-tant aspects of the data. In this paper, we develop a foun-dation for mining the properties themselves. We present a theoretical framework defining the space of graph properties, a variety of mining queries enabled by the framework, tech-niques to handle the enormous size of the query space, and an experimental system called F-Miner that demonstrates the utility and feasibility of property mining.
 Categories &amp; Subject Descriptors: H.2.8 [Database Management]: Database Applications -Data Mining General Terms: Algorithms Keywords: data mining, graph mining
Graph analyses have been used for a variety of applica-tions to analyze interrelationships among entities. Some of these analyses concern standard graph-theoretic properties, such as the radius of the graph or embedded cliques. Other analyses yield high-level, subjective information about the data. For example, the web graph has been analyzed us-ing the PageRank [21] and HITS [17] algorithms to identify web pages likely to be deemed  X  X mportant X  by the user. The citation structure of scientific papers has been analyzed to find papers related to a given paper [13, 16, 22].
These techniques have in common that they analyze graph structures for predetermined properties. Although such anal-yses can be very effective, coming up with a good property for analysis is often a challenge, especially when little is knownaboutthedatatobeginwith. Moreover,byfixing specific properties for analysis, other important aspects of the data may be ignored. Therefore the space of properties itself should be explored.

As a concrete example, consider the simple case of looking for intuitively  X  X imilar X  nodes in the graph of Figure 1. One possibility is to conclude that Prof1 and Prof2 are similar because they are both pointed-to by Univ ,asinthecom-monly used co-citation metric [22]. Analogously, we may conclude that StudentB and StudentC are similar because they are both pointed-to by Prof2 . On the other hand, we may argue that StudentA , StudentB ,and StudentC are all similar because they are pointed-to by a node that is pointed-to by Univ , as in the recursive SimRank metric in-troduced in [13]. Each or all of these inferences may be valid, depending on the domain and application. However, current methods require the user to fix one measure of similarity (e.g., co-citation or SimRank) and query for nodes found to be similar under this measure. Ideally, we would like to query simply for  X  X imilar X  nodes and get as a result the sets { Prof1 , Prof2 } , { StudentB , StudentC } ,and { StudentA , StudentB , StudentC } along with explanations for why they are similar. This functionality is not supported by any cur-rent system we know of. It is supported by F-Miner ,an implementation of the framework to be presented.

In this paper, we develop a framework for mining  X  X n-teresting X  or  X  X mportant X  graph properties. Essentially, we treat the space of properties as a domain and perform data mining on this domain. Our goal is to develop an appro-priate analysis for mining the space of properties, just as analyses have been developed for mining the graph data it-self. An obvious challenge is in handling the enormous size of the space of properties, in which even the simplest data mining operations seem hopelessly infeasible. We develop techniques that allow computational resources to be focused on only the most important properties, allowing us to im-plement a practical mining system based on the framework.
The main contributions of this paper are:  X  A theoretical framework that defines the space of graph  X  Several specific data mining query types enabled by this  X  Techniques for dramatically reducing the computational  X  A simple and intuitive metric for calculating the  X  X mpor- X  The F-Miner experimental system, an implementation of This version of the paper is abbreviated, omitting a proof of the theorem presented in Section 3.4. The full paper is available on the web at http://dbpubs.stanford.edu/pub/ 2003-10 .
Before we can pose queries on the space of graph prop-erties, we first have to define precisely what this space is.  X  We begin with a labeled directed graph representing the  X  We encode properties as formulas in the syntax and se- X  We consider the set F of all formulas and their extents ,
A logical diagram of the framework, as seen by the user, is shown in Figure 2. The property mining framework itself is enclosed in the dashed box. The framework enables querying on properties of the input data (in our case a graph), from which a set of predicates representing basic relationships are derived. It is possible to derive predicates from sources other than graphs, such as the less-than relationship in a numeric data set, but for concreteness we limit ourselves in this paper to discussing predicates corresponding to graph edges. The predicates form the basis of formulas, and the user X  X  queries posed are on the set of all formulas and their extents F .Ofcourse, F is only an abstraction provided to the user; in most cases F would never be materialized by an implementation. We define F formally in the next section. Let G =( V,E ) be a labeled directed graph, where E  X  V  X  V  X  L , for an arbitrary set L of strings serving as edge labels. For simplicity, we do not consider edge weights, although they can be added to the framework with slight modification. The fundamental relationships encoded in the edges are building blocks for the properties we will consider. In many domains there is an obvious canonical representa-tion of the data as a graph, although in some domains the representation may require some consideration. As an ex-ample, consider the data shown in Figure 3, which is a small fragment of a survey of members of the Stanford Database Group. The obvious representation of the data as a labeled graph is also shown in the figure. Many data types can read-ily be modeled as a graph, including data in relational and XML format.

The next step is to represent properties of the domain as formulas . We use formulas in the language of Datalog [24], although arbitrary logic formulas, say of first order logic, are also possible. Clearly, the more powerful the logic, the greater the semantic and computational complexity of the system. Datalog has expressive power far beyond what we can hope to support in practice. As we shall see, even the very restricted subset of Datalog that we use allows func-tionality well beyond what existing systems can support. We will define the syntax and semantics of our formula lan-guage as we go along.
 The constants (or objects ) of the logic are the nodes in G (i.e., objects of the domain), while predicates correspond to edges (i.e., relationships of the domain). We consider Datalog formulas f of the form: for k  X  1, where p i  X  L , A is the head variable ,andeach  X  , X  i is either a variable or a constant (object). We use cap-ital letters to denote variables, lowercase letters to denote constants, and Greek letters to denote either. Each predicate p (  X ,  X  ) corresponds to the existence of an edge with label between its two arguments: predicate p ( u, v ), for u, v is true if and only if the edge u, v, p exists in G .Inthe example of Figure 3, the predicate Food ( Sriram , Indian )is true. A formula f is satisfied by the satisfying assignment a , a function that maps variables to constants, if all the predicates in f aretruewhenallvariables X in f have been replaced by a ( X ). In a formula, at least one of the argu-ments of each predicate must be a variable, for otherwise the predicate would have a constant truth value. Two formulas that are identical except for variables names and predicate ordering are considered identical.

The most important aspect of a formula f is its extent , denoted E ( f ). It is the set of all objects v for which there exists a satisfying assignment a such that a ( A )= v (recall that A is always the head variable). Intuitively, each formula specifies a  X  X roperty X  of the domain, and the extent of the formula is the set of objects which satisfy the property. For example, the formula encodes the property  X  X eing the advisor of someone who likes Chinese food X , and its extent is { Hector } .
We define the set F = { ( f, E ( f )) | f is a formula } of all formulas and their extents as the space in the context of which we pose our queries. A fragment of F is shown in Figure 2 as a relation. Of course, F is infinite, and is not meant to be computed. It serves only as the logical relation over which queries are posed.
There are many interesting data mining operations one can perform over F , and many common notions in data mining, such as the frequent itemsets computation [3], have analogues in the space of formulas. Here are some exam-ples:  X  Object similarity . Two or more objects can be consid- X  Frequent itemsets .Wecanruna frequent itemsets  X  Frequent substructures . Many graph structures cor- X  Association rules . We can look for association rules  X  Explanations . Given a set of objects U , we can  X  X x-
These are but some examples of the kinds of queries that can be posed on F . We use the examples as motivation for some of the techniques we develop, but it is important to remember that these queries are end-applications of the framework, which itself consists only of the logical relation F . Other queries are possible in the framework and some may be more application-specific. In contrast to traditional data mining, the queries here generally focus on the prop-erties themselves, rather than the objects which satisfy the properties.

As a reminder, it is not possible (nor necessary) to mate-rialize F in order to query it. Rather, once a specific appli-cation has been determined (e.g., finding similar objects), we can solve the end-to-end problem without explicitly con-structing F .
There are two major technical challenges to answering queries within our framework. The first is in dealing with the enormous size of the query space. We develop techniques to handle this problem in Section 3. The second challenge is in determining the  X  X mportance X  of formulas. This is a major component of property mining: just as we look for important (interesting) objects in traditional data mining, here we look for important properties. Moreover, identi-fying important formulas is intertwined with reducing the space considered, since we would like as much as possible to restrict ourselves to considering only the most important formulas. Computing importance of formulas is discussed in Section 4.
The query space F is infinite, and it is impossible to con-sider all formulas in F . Instead, we want to focus as much of our computational resources as possible on the most impor-tant formulas. This poses a dilemma, since one of the goals of our mining is to identify these important formulas!
At a high level, our solution is to construct formulas from basic building blocks called pseudopredicates .Weanalyze these building blocks for importance instead of analyzing the actual formulas. This allows us to determine the importance of the formulas that can be constructed from the building blocks, so that only the most important formulas are ever created. Hence much of the mining actually takes place in the space of pseudopredicates. Our approach can be broken into3steps: In this section we present steps (1) and (3). Step (2) is presented in Section 4.
We motivate our approach using an example. Consider the top half of the structure shown in Figure 4, a hypothet-ical fragment of the web graph. The web pages u 1 ,...,u k all point to FOXSports.com , so they satisfy the formula where e is taken to be the label of every edge in the (un-labeled) graph. FOXSports.com in turn points to baseball X  X  MLB.com ,so FOXSports.com satisfies the formula Finally, u 1 ,...,u k all satisfy It seems redundant to record this fact, however, since it fol-lows immediately from the facts that u i , for all 1  X  i  X  satisfies formula (1) and that FOXSports.com satisfies for-mula (2). More generally, for any formula g satisfied by FOXSports.com ,each u i points to a node that satisfies g . That is, u i satisfies the formula where g ( B )is g with head variable A replaced by a variable B not appearing already in g . 1
Now we consider the entire Figure 4, where v 1 ,...,v m all point to the sports site ESPN.com .Since ESPN.com points to MLB.com , u 1 ,...,u k and v 1 ,...,v m are all related by their common satisfaction of formula (3), a consequence of the fact that the u i  X  X  and v j  X  X  all point to either FOXSports.com or ESPN.com . We record this by saying that u i  X  X  and v j satisfy the pseudoformula
A pseudopredicate is a predicate that may have as an ar-gument a nonempty set of objects, as well as variables. It is a generalization of a regular predicate, which can be thought of as the special case when the only set-arguments of a pseu-dopredicate are singleton sets. We have already seen one example of a pseudopredicate in Section 3.1: which represents the property of pointing to either FOXSports.com or ESPN.com . We define a pseudoformula as a formula consisting of pseudopredicates, and define the extent of a pseudoformula f as the set of objects v for which there exists a satisfying assignment a for f such that a ( A )= v ,where a assigns each set-argument to one of its members. For example, the extent of the pseudoformula is { u 1 ,...,u k ,v 1 ,...,v m } .

Note that the set of formulas can be thought of as a sub-set of the set of pseudoformulas, since we can replace each constant argument v by { v } to get a pseudoformula having the same semantics. Conversely, some pseudoformulas can be converted to formulas: if all set-arguments of a pseudo-formula f are either singleton sets or the set of all objects V , then f has the same semantics as the formula f which is a copy of f except with singleton objects replaced by their sole members, and each set-argument V replaced by a dangling variable not appearing anywhere else in f .
We take the set of basic building blocks to be ( P , E ( P set of all head pseudopredicates P and their extents E ( P A head pseudopredicate is a pseudopredicate whose two ar-guments are the head variable A and a set-argument S  X  V . These pseudopredicates can be treated as 1-predicate pseudoformulas. In the coming sections, we will talk about extents of head pseudopredicates as though they were 1-predicate pseudoformulas, and omit the  X  X ead X  qualification when the meaning is clear.

From this base set of head pseudopredicates we can com-pose a large class of more complex pseudoformulas and thus
Technically, we do not allow formulas within formulas, so g  X  X  predicates must be substituted explicitly into h with ap-propriate variable renaming. formulas, which as noted before are a subset of pseudoformu-las. The two composition steps are conjoining and chaining .
Conjoining two formulas f and g creates a new formula h whose predicates are a conjunction of the predicates in f and g , with appropriate renaming of non-head variables to avoid conflict. For example:
Chaining is a formalization of the example in Section 3.1 of deriving formula h from f and g . Suppose we have a 1-predicate pseudoformula f ( A ): X  p ( A, S ). Then for any pseudoformula g whose extent is a superset of S ,anyobject satisfying f also satisfies the pseudoformula We say that h is the result of chaining f and g . In the gen-eral case, if S appears as a set-argument in f ,and S  X  E ( for some formulas g 1 ,...,g k , then we can derive a new for-mula h by chaining f with g 1 ,...,g k on S , as follows:  X  Let h be f with S replaced by a new variable X not  X  For i =1 ...k ,appendto h all predicates of g i ,withnon-Note that the resulting h has an extent E ( h )thatisasuper-set of E ( f ). Moreover, if S = E ( g i ) for all 1  X  i  X  E ( h )= E ( f ).

A key concept here is that an object-set S  X  V ,whenit occurs as a set-argument in a pseudoformula, represents the set of pseudoformulas satisfied by all members of S . Pseudo-formulas (and formulas) are thus partitioned into classes ac-cording to their extents. In computation, we deal with the set of object-sets (seen as both extents and set-arguments), with each object-set representing a class of formulas. There are 2 n such sets, which although large is at least finite.
Through chaining and conjoining, the base set of pseudo-predicates P can be used to construct more complex pseud-oformulas and formulas. For a formula f ,let G ( f )bethe undirected, unlabeled graph corresponding to f :  X  The nodes of G are the variables and constants appearing  X  For every predicate p (  X ,  X  )in f there is a correspond-Then we can state the following theorem about the formulas that can be constructed.

Theorem 1. If G ( f ) is a tree, then f can be constructed by chaining and conjoining pseudoformulas, starting from P The theorem says that we can construct all formulas corre-sponding to tree structures. In general, formulas that are not tree-structured cannot be constructed; however, it is important to note that this does not mean the input graph must be tree-structured. A stronger version of this theorem is stated in Section 3.4.
The set P has size O (2 n | L | ), which, although much smaller than that of the set of all formulas (which is infinite), is still enormous. In practice, we have to restrict ourselves to using only a subset of P , at the cost of restricting the set of formu-las that can be constructed. Ideally, we would use only the most important pseudopredicates as building blocks, from which the most important formulas can be constructed. But we cannot tell which pseudopredicates are important in ad-vance, so we start with an initial set of pseudopredicates as seed, then iteratively expand (or refine) the set of pseu-dopredicates included.

We maintain a series of head pseudopredicates and their extents ( P i , E ( P i )), for i  X  1. Each P i is the set of pseu-dopredicates created on iteration i ,and E ( P i )isthesetof their extents. We compute ( P i +1 , E ( P i +1 )) from ( P on each iteration i + 1. Their successive unions: are the working (trimmed) sets of basic building blocks.
We take P 1 to be the set of all head pseudopredicates whose set-argument is a singleton set or the set of all ob-jects. On each iteration, we consider the extents of the pseudopredicates already created, as well as the extents X  in-tersections, and create new pseudopredicates having these sets as set-arguments. More precisely, given that we have ( P i , E ( P i )), we perform the following steps on iteration i +1  X  Compute I i , the intersection-closure of E ( P i ) (i.e., the  X  Compute P i +1 as: Each successive iteration considers formulas corresponding to trees one level deeper. This idea is formalized by the following theorem (the proof is in the technical report [14]).
Theorem 2. Aformula f whose corresponding graph G ( f ) is a tree of depth at most k from A can be constructed by chaining and conjoining pseudoformulas starting from P k . Note that the sole formula with a G ( f )depthof0isthe trivial formula f ( A ): X  p ( A,A ), which we do not consider. It follows immediately from the theorem that in the limit where k =  X  , all formulas corresponding to tree structures can be constructed from P  X  (and hence P ,asupersetof P  X  ), from which follows the weaker version of the theorem, as stated in Section 3.3.

The larger the k , the more formulas can be constructed, at the cost of using more computational resources. In the F-Miner system, we found that k = 3 accounts for a wide range of interesting formulas while having very manageable resource requirements (Section 5).

Therearemanywaystheset P k can be further pruned or tailored for the class of formulas suitable for a specific application. First, instead of taking I to be the intersection-closure of E ( P i ) in the iterative step i +1, we can simply take I to be E ( P i ), or take I to be the (first-level) intersection of elements of E ( P i ). Thus conjunctions of pseudoformu-las are only formed when their extents are equal. Second, those pseudopredicates in P k and those sets in E ( P k ) deemed unimportant (Section 4) can be pruned away after each iter-ation. By keeping only a fixed number of the most important pseudopredicates and their extents, we can limit the growth of ( P k , E ( P k )), while still allowing important formulas corre-sponding to deep tree structures to be considered.
In Section 3 we established a set of head pseudopredicates and their extents ( P , E ( P )) as building blocks for formulas. Formulas can be constructed from P through conjoining and chaining. Because P is usually extremely large, we showed how to iteratively compute a manageable subset P k of P . The next step is to construct important formulas from P .Wefirstanalyze( P k , E ( P k )) as to the importance of the formulas that can be constructed. The problem of com-puting importance on formulas becomes that of computing importance on sets (representing classes of formulas satisfied by these sets) and pseudopredicates. Just as in traditional data mining we look for interesting objects satisfying some predefined property, we now mine the space of properties for interesting properties satisfying some predefined notion. Accordingly, the development of a good measure of impor-tance for properties is fairly ad-hoc, although we try as much as possible to develop upon known principles. The ranking techniques presented in this section are largely based on em-pirical experimentation. We present these techniques only as a concrete, viable example. In practice, the computation of importance should be specialized to the application.
We start with some fundamental notions of importance for head pseudopredicates (simply  X  X redicates X  in the rest of this section), and then let the analysis compute importance based on these notions. We borrow a technique from the field of web search. The PageRank [21] and HITS [17] algo-rithms have been used to analyze web pages for importance to aid in web search. The idea behind PageRank is that a web page is important if it is pointed-to by important web pages. Similarly, the HITS algorithm identifies good hub pages and good authority pages recursively: good hubs are those which point to good authorities, and good authorities are those pointed-to by good hubs. Good authorities are regarded as important pages. Common to these two algo-rithms is their recursive, mutually-reinforcing definition of importance, and the iterative computation method (corre-sponding to an eigenvector computation).

In the same spirit, we develop an iterative algorithm for ranking the importance of sets and pseudopredicates. And analogous to the definition of hubs and authorities in HITS, we say that:
Now, we might mine the space of notions-on-properties to identify the important notions, but obviously this just pushes the same problem up a level. Instead, we settle for mining the space of properties using some predefined no-tions. Note this does not mean that we are back to where we started, since we can now mine for (first-level) properties instead of just atomic objects. Extension to mining higher-level properties (i.e., properties of properties) is a possible direction for future work.  X  A pseudopredicate is important if its set-argument is im- X  A set is important if it satisfies important pseudopredi-Thus, the basic notions from which we derive importance are satisfaction of pseudopredicates (for sets), and importance of the set-argument (for pseudopredicates).

To compute importance scores, this intuition must be for-malized mathematically. We take importance scores to be in the interval [0 , 1], with importance scores for all pseu-dopredicates summing to 1, and importance scores for all extents of pseudopredicates summing to 1. For S  X  E ( P k we define P k ( S ) to be the set of predicates satisfied by S : As a basis, we start with the core equations for predicates, which says that the importance I ( p )ofa predicate p is the importance of its set-argument arg ( p ), and which says that the importance of a set S has two compo-nents: (1) a small inherent importance c | E ( P k ) | (in our experi-ments we used c =0 . 2), and (2) the sum of the importances of the predicates p satisfied by S. This  X  X ecursive X  equation is analogous to that used for PageRank [21].

These two core equations provide a good starting point in capturing the recursive intuition presented, but more spe-cific details of the analysis should be incorporated.
First, instead of summing over the set of all predicates p satisfied by S , we should sum only over those that are not subsumed by another predicate satisfied by S .Wesaythata pseudopredicate p ( A, S ) subsumes another pseudopredicate p ( A, S )if S  X  S ,inwhichcase E ( p ( A, S ))  X  E ( p ( A, S )). Intuitively, p ( A, S ) specifies a property more specific than that specified by p ( A, S ). For example, in Figure 4, if we al-ready know that v 1 satisfies e ( A, ESPN.com ), it is pointless to also record that v 1 satisfies e ( A, { FOXSports.com , ESPN.com
Another aspect that can be improved is when S  X  E ( p ), but S is only a small fraction of the objects in E ( p ). Then I ( p ) X  X  contribution to I ( S ) should be weighed lower than to I ( S ), where S = E ( p ). For example, in Figure 4, we have so e ( A, ESPN.com ) X  X  contribution to the importance of a set S = { v 1 ,v 2 } should be smaller than to that of S = { v 1 ,v 2 ,v 3 ,v 4 } . Thus we consider the term which assigns weights according to the relative sizes of S and E ( p ), as compared with other sets S satisfying p .For both data sets in our experiments we used w 1 ( x, y )=( x which we found to work well empirically.

We may also attribute more importance to those sets that satisfy many pseudopredicates independently of the impor-tance of the pseudopredicates. Let be the number of predicates satisfied by S ,weightedbya function w 2 ( x ). In our experiments, we found w 2 ( x )= x to work well empirically.

The equations we used in our experiments for scoring predicates and sets are: As with the HITS equations, equations (4) and (5) can be solved by iterating to a fixed-point. On each iteration, the scores are normalized so that p I ( p )=1and S I ( S )=1. For equation (5), the set P k ( S ) must be precomputed for each S , which in general is an expensive operation. One way to alleviate the problem is to set w 1 ( | S | , | E ( p ) it is below a certain threshold t , in which case we need not check whether S  X  E ( p ) at all. In our experiments, we used t =0 . 01, which sped up the computation with no noticeable effect on quality of results.

Note that an appropriate choice of equations is in general dependent on the data set and query type. However, we have found the above equations to work well on the two data sets and two query types we tried. Also note that inherent importances can be assigned nonuniformly to bias the results when there are sets we know apriori to be important. This is analogous to biasing web pages nonuniformly in PageRank to enable a personalized web search [9, 15].
The importance rankings for the base set of pseudopred-icates and their extents ( P k , E ( P k )) tell us the importance of the formulas that can be constructed. Using the chaining procedure as described in Section 3.3, it is straightforward to construct formulas from P k . However, many queries, such as those in Section 2.2, are computed based on the importance scores of the extents, while the actual formulas serve only as an explanation to the user. Thus an exhaustive construc-tion of all constructable formulas is usually not necessary (nor feasible). Instead, we want to construct only the most appropriate formulas, taking into account not only the com-puted importance of the formulas but such human aspects as the formulas X  brevity, comprehensibility, and variety. Here we present the chaining operation from Section 3.3 as a pro-cedure that allows us to take these factors into account.
We define the function chain ( f ), which takes a pseudofor-mula f as argument and returns the result f of chaining f with some pseudopredicates. The result is a pseudoformula whose graph G ( f ) is one level deeper than f :  X  Start off with f set equal to f .  X  For each pseudopredicate (not just head pseudopredi- X  Return f .
 The function P ( S ) can be adjusted, based on the computed importance of the pseudopredicates (and human factors, etc.), to suit the specific query types and end application. As a general rule, it should consist of the m most important pseudopredicates satisfied by S . Most of the variability is in choosing m properly so as to produce informative formulas while minimizing complexity for the sake of user intelligibil-ity. Specific rules for choosing m in the F-Miner system are discussed in Section 5.
 Each call to chain results in a more complex formula. In theory, we could chain some formulas indefinitely, since the same set may be chained over and over again in a cy-cle. In practice, users will want formulas to be simple, so a maximum-depth or cycle-detection stopping criterion will be used anyway.

As an example, consider the pseudoformula which represents the property of  X  X eing the home of Glen or Beverly  X . If Glen and Beverly both like either Chinese or Indian food, then the formula may be expanded (through one call to chain )to which represents the property of  X  X eing the home of someone who likes Chinese or Indian food X . Finally, this formula may be expanded to if Jennifer likes Chinese and Indian food.
Based on the framework and algorithms presented in the previous sections, we have implemented an experimental system, F-Miner , that supports some of the data mining queries discussed in Section 2.2. Specifically, F-Miner sup-ports the following two query types on arbitrary input graphs:  X  Similarity. Given a set of input objects, return a ranked  X  Explanation. Given a set of input objects, return for-
For efficiency, the user may assign types to each object to minimize redundant comparisons by the system. For exam-ple, a university would never be considered as an argument to an Advisor predicate between two people. Types help to speed up the implementation without having any effect on semantics.

The exact parameters used in F-Miner are given in Section 5.3.
We ran F-Miner on two data sets. The first is based on a survey of Stanford University X  X  Database Group, along with publication data from the Database Group X  X  publica-tion server [1]. The data is modeled as a graph where nodes represent all entities that participate in relationships, such as people, food types, and publications. The edges represent relationships, including those that denote food preferences, advisors, undergraduate institution, home country, research interests, and authorship for publications. The graph con-sists of 1725 nodes and 3552 edges.

When the system is first run, the set of basic building blocks ( P k , E ( P k )) is precomputed as described in Section 3.4. A prompt is then presented to the user where a list of objects can be entered as a query for both similarity and explanation. The precomputation takes less than a minute, and each query returns in milliseconds.
 We begin with a simple single-object query for  X  Steve  X . The results of the query are shown in Figure 5. Scores in the query results for this data set have been scaled by 10 for legibility. The top portion of the output shows the most important formulas (as determined by the system) satisfied by the input. We find that Steve is a Masters student, and that his advisor is Jennifer . We chose to list these as separate formulas, although they can be printed as a single conjunctive formula instead. Among the properties satisfied by Steve , including the foods he likes and where he went as an undergrad, these two are found to be the most im-portant by the algorithm. The importance scores are listed next to the formulas. The bottom portion of the output lists the 5 objects most similar to Steve , along with their similarity scores. The similarity score s ( x ) for an object x is the weighted sum of the importance scores of the extents satisfied by both x and Steve : where w 1 is the same weighting function used in Section 4.1. The self-similarity s ( Steve ) is given as a reference (listed as [input] ) for comparison. In effect, the program finds those people who have  X  X  lot X  in common with Steve ,taking into account the numerous properties they may share. The top match is Jing , whom we know to be the only other Masters student in the group. The following are two of Jennifer  X  X  other students. The next match, Beverly ,is neither a Masters student nor Jennifer  X  X  student. To find out why Beverly is listed, we can type in  X  Steve , Beverly  X  as a new query. The results are shown in Figure 6. We find that Beverly and Steve both went to Stanford as undergrads and are from California originally. Note that these attributes were not regarded by the program to be Steve  X  X  most important attributes, but they are the most important of those attributes he shares with Beverly .Ap-propriately, the top matches returned are other students who went to Stanford as undergrads, followed by other students from California.

The next example illustrates more complex formulas for the query  X  Glen , Qi  X . The results are in Figure 7. Com-paring the absolute magnitudes of the formula scores with those for the query  X  Steve , Beverly  X , we see that there is relatively little in common between Glen and Qi . The first formula says that the two people both went to schools that Jeff  X  X  students tend to go as undergrads. The second for-mula is analogous. The two students do not share advisors or other preferences, and these formulas are the best con-nection between them.
 Of course, we can also query on objects other than people. The query results for  X  UC Berkeley , Stanford  X  X reshown in Figure 8. The formula identifies these as schools that tend to be attended by people from California. This is indeed the most intuitive result that can be inferred from the data. To test F-Miner on a larger data set, we used data from Club Nexus [2], which contains various personal information about 2469 Stanford students. Attributes used include the student X  X  academic standing, major, and a list of Club Nexus members he knows. The data is modeled in F-Miner anal-ogously to the Database Group survey data. The resulting graph has 2852 nodes and 74197 edges. The precomputa-
Note that the Undergrad , Home ,and Advisor relationships tend to be favored over, say, Food because each person has a unique choice for these attributes, whereas he usually has multiple food preferences. This is an effect of the  X  func-tion (Section 4.1), which causes a preference for a particular food to be deemphasized when the person has other food preferences. Figure 9: Results for  X  user-8 , user-9 , user-10  X .
Figure 10: Results for  X  user-7 , user-98 , user-178  X . tion step, which needs to be done only once, takes about 3 hours, and each query at the prompt takes about 2 sec-onds. (Note that our system has not yet been optimized or tuned for scalability.) Sample results for the random queries  X  user-8 , user-9 , user-10  X  X nd X  user-7 , user-98 , user-178  X  are shown in Figure 9 and Figure 10, respectively. Scores in the query results for this data set have been scaled by 10 10 for legibility.

The results in Figure 9 say that the input students are re-lated because they are all males, they all know someone who knows and is known by user-178 , and they all know some-one who knows user-898 . The results in Figure 10 say that the students are related because they are all undergraduates and are known by a person who majors in international re-lations. These kinds of connections are found by the system for most random groups of people.
Our experiments were run on a 2.4GHz Pentium with 1GB of RAM using Java SDK 1.4.1. The code is written entirely in Java, unoptimized and without native methods. The core of the F-Miner system is implemented based on the techniques presented in the previous sections. The same parameter settings were used for both data sets. We used k = 3 when deriving the basic building blocks ( P k , E ( and ranked pseudopredicates using 10 steps of the fixed-point iteration process. In computing E ( P k +1 ), we used I = E ( P k ), omitting the intersection step for speed, and found this to have little effect on the results (conjunctions were already accounted for).

A proper setting of m for P ( S ), as discussed in Section 4.2, is largely a user-interface issue. We have developed a heuristic to determine m .Let p i ( i =1 , 2 ,... )bethe i -th ranked predicate in order of decreasing importance. We take m to be the minimum of 10, the smallest i such that 1  X  j&lt;i I ( p j )  X  10  X  p i (i.e., when extra pseudopredicates are trivial compared to those already included), and the smallest i such that 1  X  j  X  i I ( p j )  X  0 . 9  X  1  X  j I ( p when at least 90% of pseudopredicates have been accounted for). We have found this heuristic to work well in most cases, providing the results illustrated in the previous figures.
Our framework most resembles that of inductive databases [11], which are based on the inductive logic programming ( ILP ) framework [20]. In inductive databases, rules (e.g., association rules) about database objects are treated as first-class objects of the database, so that queries (e.g., in SQL) may be posed on rules as well as objects. For example, in the MolFea [10] system for molecular databases, one can query for  X  X ll structures (represented by formulas) occurring as substructures in more than 30 molecular structures X . While our framework also supports such queries (Section 2.2), it further develops the treatment of formulas as first-class ob-jects by considering the interrelationships between formulas and objects and among formulas themselves. This develop-ment is manifested in two key features of F-Miner: the rela-tionships between objects and formulas are used to support similarity queries, and the relationships among formulas are analyzed in the recursive computation of importance.
Along similar lines, the traditional association rules of market basket analysis are generalized in the WARMR sys-tem [6, 7] to association rules on Prolog formulas (similar to our Datalog formulas) evaluated on a relational database. The goal is to find association rules of the form f =  X  g where f and g are formulas. As discussed in Section 2.2, this extension of association rule mining can be formulated as a query type in our framework.

The traditional data mining problem of finding frequent itemsets in market basket data [3] has also been extended to graph structures [12, 18, 19, 25, 26]. The focus in graphs is on finding frequent substructures, the graph equivalent of frequent itemsets. Again, such queries are but one instance of the query types supported in our framework, as discussed in Section 2.2.

Other instances of property mining have been studied in specific contexts. One is the problem of identifying  X  X at-terns and relations X  in the unstructured text of web pages, e.g., [5, 23]. Patterns are essentially regular-expressions and correspond to the formulas of this paper; relations corre-spond to extents. The sets of patterns and relations are ex-panded iteratively starting from a small initial set of known relations. The process can be seen roughly as an extension of the frequent itemsets problem in our framework: frequent itemsets are used to discover additional frequent itemsets.
Other graph mining algorithms to compute similarity of nodes based on graph structure include co-citation [22] and its generalization SimRank [13]. Again, similarity is but one application for our framework, and advantages of the simi-larity computation enabled by our framework over specific measures of similarity were noted in Section 2.2.
A particular feature of F-Miner is the ability to relate nodes in a graph through relationships beyond just a single edge, as in the query of Figure 7. This feature was also exhibited in the proximity search of [8], which finds nodes in a graph that are nearby in terms of graph distance. However, there is no mechanism in [8] for explaining query results, one of the strengths of our approach. A system was presented in [4] that, given keywords matching tuples across different tables in a relational database, returns a tree denoting the schema relating the matching tuples, where the edges of the tree are foreign-key relationships. The tree serves to explain how the tuples are related. However, these tree structures lack the expressive power of our formulas, and there is no ranking of explanations.
As discussed in Section 4.1, the recursive notion of im-portance of pseudopredicates is analogous to the notion of importance computed by the PageRank [21] and HITS [17] algorithms for web pages.

The syntax and semantics of the formulas used in our framework are borrowed from the logic-programming lan-guage Datalog [24].
The main contributions of this paper are summarized as follows:  X  We presented a framework under which data mining queries  X  We developed techniques to deal with the enormous size  X  We defined a general measure of importance for prop- X  We implemented the F-Miner experimental system sup-
Our experiments to date have been with relatively small data sets. Much work is yet to be done in algorithms, ap-proximations, tuning, and optimizations if we wish to scale to the largest data sets, such as the web. Nonetheless, many modest-sized data sets with acceptable precomputation and query response times pose interesting applications for our framework already, such as the examples in our experiments. With the proliferation of XML and other easy means of ex-pressing and interlinking data, we expect in the near fu-ture to see numerous graph-structured datasets amenable to property mining.

The intent of this paper is mainly to provide a founda-tion for the mining of (graph) properties. The emphasis has been on demonstrating the utility and feasibility of this new kind of data mining. We have only scratched the surface in terms of theory, algorithms, implementation, and applica-tions; many aspects are open for further research.
