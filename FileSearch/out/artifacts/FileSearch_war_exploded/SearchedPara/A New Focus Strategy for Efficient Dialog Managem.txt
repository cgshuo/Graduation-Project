 some goal s . The dialog manager is the most important component for a dialog system. Typically, it should deal with the state tracking task and system action generating task during the conversation. In the state tracking task, the dialog manager interprets what the user has said and updates some representation s of the current dialog state, which encodes various dialog information including user X  X  goal, current user X  X  action and di-alog history. Then in the action generating task, the dialog manager generates proper response action back to the user based on the current dialog state representation, which is then updated as in the first task.

In a dialog manger, t he dialog state tracking is crucial because the system re lies on it to know where the dialog goes and how to generate proper response. Conventional updat e the state. However, it is not easy to maintain a precise and accurate representa-tion o f the dialog state because there are always ambiguities and uncertainties in what the user said. What X  X  more , natural language understanding techniques are not perfect, and thus it may cause the system misunderstand ing the true goal of the user and tak ing a lot of efforts in error recovering.

S tatistical approach es for dialog state tracking provide an opportunity for solving the above problems in a flexible way (Young, 2002). Early attempts model the dialog pro-cess as a Markov Decision Process (MDP) (Levin et al., 2000) , which uses reinforce-ment learning for policy optimizing and provides a well -formed statistical framework allowing forward planning. However, MDP assumes fully observable dialog state s and cannot deal with the uncertainty of those s tate s . Par tially Observable MDP (POMDP) explicitly models the uncertainty of many possible dialog states , which is more robust to recogn izing errors and ambiguit ies .

However, it is not straightforward to construct a POMDP -based dialog manager for a real -world task because maintaining a full state space distribution will be intractable. Two types of views are proposed to achieve tractable and scalable implementation of POMDP -based state tracking . The first one tries to reduce the state space complexi ty by factor ing the dialog state into independent components. For example, in a  X  X lot fill-ing X  task, the whole dialog state space can be factored in to subspaces of independent tion over each individual slot (Williams and Young, 2007a, b). The second view is to et al., 2006; Williams, 2010). The intuition behind the second approach i s that, during each other, because they are not involved in the current dialog yet . So t he dialog man-ager may safely neglect them and consider only the high probable one s to approximate the true state distribution. These two views do not conflict with each other. Actually, optimizing techniques from the second view takes advantages of careful independence assumptions related to the first view. in a typical  X  X lot filling X  task with N slots to fill and K different candidate values for each slot, there are K N possible value combinations . The state space size grows expo-nentially as N and K become large, so efficient state representation and manipulation states comes from two aspects: large factor size from state space decomposition (related to N ) an d large candidate value size of each factor (related to K ) .

The latter problem is partially resolved by clustering the undistinguishable states into partitions like Hidden Information State (HIS) model ( Young et al. , 2010 ). However, though many previous P OMDP -based systems model the dialog process as a slot -filling task and factor the goal of a dialog into many slots, no work has paid attention to the first problem. 
In this paper, we propose a method to solve the large factor size problem, namely dialog f ocus strategy. The intuition is that, not all factors of slots should be computed beliefs of complex factors every time and thus reduce the time complexity greatly. Our stra tegy is more efficient and easy to implement than previous approaches. To the best of our knowledge, this is the first work to address the large factor size problem to build a tractable and scalable dialog manager. Also, we implement partition -based strate gy ( Thomson and Young, 2010; Young et al. , 2010 ) into our framework to deal with the inner factor complexity. Finally, we conduct an ensemble method that combines both strategies to take advantage of their complement property. We fit our system into a real -strategy with comparable quality . out to be more robust and scalable than hand -crafted ones (Bohus et al., 2006; Young et al. , 2010; Thomson and Young , 2010) . These methods try to maintain a distribution over different dialog sta te hypothesis to help the dialog manager choose the proper di-alog strategy.

Bohus and Rudnicky (2006) train a conditional model in a discriminative fashion to estimate the distribution over a set of state hypotheses. They employ a large set of in-formative features to achieve high accuracy. However, they only keep track of a handful of state hypotheses thus the correct one may be discarded. Angeliki et al. ( 2013) ex-ploits the structure of the dialog state hypothesis , and draws a rich set of features and furt her keep s a number of hypotheses -invariant features to allow an unlimited number of hypotheses.

Williams et al. (2006) propose a POMDP model that effectively represents the un-certainty of dialog states. Later, POMDP -based models are widely used as generati ve approach es in different domains, such as restaurant recommendations (Jur X  X  X ek et al., 2012), sightseeing recommendations (Misu et al., 2010), appointment scheduling (Georgila et al., 2010), etc. Some experiments apply it to the more difficult problem of learning negotiation policies (Heeman, 2009; Georgila and Traum, 2011 a, b ), and tu-toring domains (Tetreault and Litman, 2008; Chi et al., 2011) .
 Many efforts have been made to solve the state space exploding problem in the POMDP framework. Thomson and You ng (2010 ) presents a method based on the loopy belief propagation algorithm to make the state distribution updating tractable. They fac-tor the state space into different components and use the marginal of these components as features for policy optimizatio n. A grouped form of loopy belief propagation is im-with many parallel components like in our task.

The HIS model (Young et al. , 2010 ) groups similar user goals into equivalence clas-ses called partitions , based on the assumption that all of the goals in the same partition are equally probable. The partitions are refined as the dialog progre sses , and they are State tracking then requires only maintain ing and updat ing relatively fewer partitions, when there are many slots such that the number of partitions will grow exponentially with the slot size as the dialog progresses. 3.1 Basic mathematics We first outline the mathematics of POMDP and explain our basic P OMDP -based dia-log model . A partially observable Markov decision process is formally defined as state .

The POMDP operates as follows. At each timest am p t , the world is in an unobserved s machine then receives an observation o t+1 , which is dependent on s t+1 and a t . 3.2 Dialog Model We now fit the POMDP into our dialog process. As in Thomson and Young (2010) , the dialog state at each t imestamp t is decomposed into three distinct types of information belief state b t is then a joint distribution over these three components.
The user X  X  goal encompass es the information that must be gleaned from the user in different aspects of the goal. For example, in a simple weather information system, the sentence  X  X  want to know the weather in Beijing today X  , the goal can be represented as denoted as g i and has N i possible values v i k ( k=0,1.. N i ) .
 types. In the experiment, we use a SVM classifier to predict the user  X  s act with a preci-sion 96%. 
The dialog history h t tracks some information relating to previous turns. We model previous acts made by the user and the system, such as the most recent server X  X  act and whi ch is represented by a four -state machine , as shown in Figure 1.

The dialog goes as follow s (shown in Figure 2). At each timestamp t , the user choose s response to the user X  X  act by some dialog policy , and updates the dialog states and goes into the next timestamp.
 The belief state for dialog history h is deterministically updated by heuristic rules. And the joint belief state b t (u t ,g) for the goal and act is calculated by Equation (1):
Our model is a little different from previous works mainly in the following three aspects: 1) Our system is designed for online dialog tasks where users type in the content by 2) T he observation o t is t he user X  X  natural language input instead of recognizing 3) In a re al application, it is always assume d that the user does not change his goal in 3.3 Policy optimization We select Natural Actor Critic (NAC) (Peters and Schaal, 2008) to learn the optimal 2012; Teruhisa Misu et al., 2012). 
At timestamp t , the system action s e t is sampled from a soft -max policy: NAC optimizes over policy parameter W by solving linear regression problems.
The above training procedure requires thousands of dialog tracks to gather gradient information. So a simulated user (SU) (Georgila et al., 2006) that will behave similarly thus facilitate learning. We will describe our user simulator in the succeeding section . It becomes intractable to directly implement t he proposed POMDP -based dialog pro-cess when there are many slots and many candidate values for each slot . Al though the state space is decomposed into subcomponents and the user X  X  goal is further decom-P(goal i =k) of slo t values . A straight forward na X ve method is to exponentially enumer-ate over many possible slot value combinations as shown in F igure 3 . 
Thomson and Young ( 2010) use the L oopy B elief (LP) propagation to improve effi-ciency by exploiting the dependencies bet ween graph components. But LP does not fit into our model because there can be many slot factors creating high costs in message passing .

In the next subsections , we will introduce our belief updat ing strategies that alleviate computation burden in maintain ing marginal probabilities of slot values and current the large slot size and the large candidate value size for each slot. Accordingly we im-plement two different metho ds to deal with the two problems, namely partition strategy and focus strategy. Further, an ensemble method combining both strategies is proposed to achieve better performance . //initialization For each user goal slot g i :
For each candidate value v ij o f g i : For each user  X  s act type u : //updating For each user goal slot value combination : g g v g v g v  X   X   X   X 
For each user  X  s act type u : //normalizing Normalize the beliefs b_goal t and b_a t 4.1 Partition Strategy T o deal with the large candidate value size problem, w e follow the methodology of HI S model (Young et al. , 2010) . A t any timestamp, the candidate value space for each slot of the user X  X  goal can be divided into a number of equivalence classes called partitions , where the members of each class are equally possible and undistinguishable wit h each other.

Young et al. ( 2010) use a tree -based structure to represent the belief state and encode policy sampling as in Equation (2), we need to maintain slot va lue marginal probabilit y explicitly. Stronger dependency assumptions are made in our work.
 timestamp if and only if 1) they are of the same marginal belief 2) for any two slo ts 
This means that the current collected information does not help distinguish between two values and so it is unnecessary to treat them separately . progresses, this root partition is repeatedly split into smaller partitions.

If we can maintain the partitions of each slot dynamically, the belief updating process can be simplified by packaging the values of a partition and just enumerating over com-calculated by : //split partitions S plit partitions based on the current user  X  s input . //initialization For each user goal slot g i :
For each partition j of g i : For each user  X  s act type u : //updating For each value partition combination p g partition g partition g partition  X   X   X   X  For each user  X  s act type u :
For each slot g i : //normalizing Normalize the beliefs b_goal t and b_a t C alculating marginal of single values value with some keywords according to the domain specification documents . If a key-word is observed in user X  X  input then the associated value s are spitted from its original purchasing domain, the word  X  online  X  triggers the system to separate those candidate usages from the original partition . 4.2 Fo cus Strategy In many dialog systems, the number of candidate values of most of slots is quite small, and so the partition -based method does not fit them well, since it has to maintain parti-calculate the marginal probability for all values of all slots, which affects the computa-tion efficiency taken by partitions, as illustrated in Figure 4.
 In order t o deal with the large slot size problem, we propose a f ocus -based strat egy . The intuition is that when two people talk in a task -oriented conversation, they focus their attention only on a small portion that they know or are interested in. They concen-So i n our dialog model, we assume that the user tends to mention only a small propor-or provide more information for some mentioned slots, but is not likely to refer all slots in a turn, because there is too much information when the slot size becomes large that he may not have enough knowledge to explicitly express them.

For example, a user wants to know the price of a service that has a lot of releva nt at once, because it is too complex for a non -expert to grasp all the knowledge. A good solution is to make a conversation between the server and the user. The se rver asks for these relevant parameters one by one through many dialog turns, and the user gives an explicit answer to each question. timestamp , if and only if fo r any two slot value combinations g 1 , g 2 : and for any user X  X  act u : user X  X  dialog act and the natural language output. 
If we can determine the focus slot set at each timestamp, th e marginal P (g i =v) can be simplified as: We can see that the marginal probabilities of those slots outside of the focus set re-main fixed , so there is no need to recalculate them in a turn . As a result, we only need c alculatin g the marginal probabilities of those slots in the focus set, which only re-quires enumerating over values within the focus set . 
T he computation complexity now reduces from O(|V| n ) to O(|V| m ) , where |V| denotes the maximum size of each slot X  s candidate val ues , n is the full slot size, and m is the focus set X  X  size which is generally observed to be less than 2 and is far smaller than n . Our focus strategy will work much faster than the above na X ve method . What  X  s more, //get focus set Generate the focus slo ts S ame as na X ve method except that only the focus slots are estimated //updating For each focus slots value combination
For each user  X  s act type u : ( , ) ( | , ) ( | , ) ( ) P u g P o u g P u g h P g  X   X   X   X 
For each slot g i in the focus set: _ [ ][ ] _ [ ][ ] ( , ) b goal i v b goal i v P u g  X  X  //normalizing Normalize the beliefs b_goal t and b_a t //split partitions S plit partitions based on current user  X  s input //get focus set Generate the focus slots //initialization For each user goal slot g i in focus set //updating For each partition value co mbination from focus slots p g partition g partition g partition  X   X   X   X  For each user  X  s act type u :
P ick representative g from p : _ [ ][ ] _ [ ][ ] ( , ) b goal i partition b goal i partition P u p  X  X  _ [ ] _ [ ] ( , ) //normalizing Normalize the beliefs b_goal t and b_a t C alculating marginal of single value it does not use dynamic structures to maintain all the values and thus expected to be rithm.

I n our experiments , w e use some heuristics to determine the focus set at each timestamp . W e build a domain keyword vocabulary from the domain documents , and each key word is asso ciated with one or more slots according to the domain description input sentence and mark s the hit words with the associated slots . T he slot referred by th e system X  X  query and focus on the slot that the system has mentioned . 4.3 Combined Strategy As noted before, the computation complexity comes from both the large slot size and large value size. In this section, we combine the two strategies to simultaneously r educe the complexity from both aspects. Figure 6 illustrates our combined strategy. The com-bined method takes advantage of the complement property of the two optimizing strat-independent value partitions for each slot and only update partitions for focus slots. This section reports the expe rimental results of our proposed model s and belief updat-ing strategies. We first introduce the specific domain that our syst em applied to. Then we describe our user simulator that interacts with the system to train the dialogue policy. 5.1 The domain leading supplier of images for business and cons umers in China. It operates a commer-images vary greatly according to different factors which often confuse the purchasers , thus there needs an intellective server agent to a utomatically ga ther those factors and natural language dialog rather than providing a large, confusing and tedious HTML form to them.

The user's goal is repres ented by a table of different factors , which should be filled in during the conversation and requires the clients to provide relevant infor mation in a number of can didate values , as listed in Table 2 .
 5.2 User simulator A user simulator simulates the user's behavior to train the dialog policy . At the start of a dialog, the system randomly generates a set of values for each slot which are treat ed as the real goal of the simulated user. The simulator then interacts with the system and provides relevant information based on the system's act. We constrain the dialog length the dialog should be forced to stop. The simulator then gives a score to the completed dialog according to certain metrics . The training process runs totally 80 iterations. In e ach iteration , it contains two steps: in simulating step 300 dia logs are simulated and then the optimization step updates policy parameters with the collected information of (dialog, score) pairs in the first step. 5.3 Computation Efficiency We use 4 belief updating strategies stated above to train the model policy. The n a X ve method is the baseline, and the partition strategy mainly follows the idea of HIS and so also is regarded as a baseline. For each strategy, we simulate dialog s between the server agent and the user simulator , as mentioned in the above subsection. 
We run our experiments on an Intel i5 Core machine with 4GB memory. The average s trategy takes 57.33 millisecond s (ms) per dialog . T he focus strategy takes only 5.02 than the na X ve algorithm. T he combined method is as fast as 2.38 ms per dialog , whic h is 24 time faster than t he partition strategy . We can see that the focus strategy greatly reduce s the computation time compared with t he partition strategy , that is because as the dialog progresses, the size of partitions grows larger which makes the pro cess slow down. As expected, combing the two strategies obtain the best efficiency.
 convergence speed of three strategies is satisfying .
 In this paper, we aim to address the state space exploding problem for efficient dialog management in a POMDP framework. We claim that the intractability of dialog states based metho d similar to HIS model, with some adaptation in our task. We then combine both strategies to get better performance. We apply our systems to a real task of image purchasing , and conduct evaluation both with a user simulator and real users. Our focus strate gy is far faster than partition -based method with comparable quality, and our com-bined method gets the best performance both in the computation time and the quality evaluated by human testers. Acknowledgement This work is supported by National Natural Sci ence Foundation of China (61371129), National High Technology Research and Development Program of China ( 2015AA015403 ), Humanity and Social Science foundation of Ministry of Education ( 13YJA740060 ), and the Opening Project of Beijing Key Laboratory of Inte rnet Cul-ture and Digital Dissemination Research ( ICDD2014 02 ). 
