 A fundamental issue for C2C transactions is how to rank the prod-ucts based on the reviews written by the previous customers. In this paper, we present an approach to improve products ranking by tack-ling the noisy ratings that exist in the practical systems. The first problem is the credibility of the customers. We design an iterative algorithm to measure the customer credibility. In the algorithm, we use a feedback strategy to increase or decrease the customer cred-ibility. We increase the credibility for a customer if the customer gives a high (low) score to a good (bad) product and decrease the value if the customer gives a low (high) score to a good (bad) prod-uct. The second problem is the inconsistency between the review comments and scores. To deal with it, we train a classifier on a training data that is constructed automatically. The trained clas-sifier is used to predict the scores of the comments. Finally, we calculate the scores of products by considering the customer credi-bility and the predicted scores. The experimental results show that our proposed approach provides better products ranking than the baseline systems.
 H.2.8 [ Database Applications ]: Data mining; H.3.3 [ Information Search and Retrieval ]: Clustering Algorithms, Management Credibility, Clustering, E-Commerce
In online C2C (customer-to-customer) sites such as Ebay (www.ebay. com), Taobao (www.taobao.com), Gmarket (gmarket.co.kr), etc., people can easily set up a shop to sell products to each other. These sites allow people to share shopping experience via writing re-views on the products (goods, services) that they have purchased. The product reviews include review comments and scores. These reviews play an increasing important role in decision-making for other persons who are trying to buy products online. However, there are an increasing large amount of reviews available, which makes it difficult to check all the reviews for online shopping. Be-fore reading all the reviews to the relevant items in detail, it is com-mon to rank the candidates and decide which one to click (check). The ranking is usually based on the overall scores by averaging the individual review scores given by the customers [10, 7].
However, in the real-world systems, there exist many noisy rat-ing leading to incredible average scores to items. The main reasons are: 1) some customers do not give out fair reviews; 2) there is the inconsistency between the score and comment of a review. For the first one, some customers are prone to give gentle evaluations [14], some customers may assign scores randomly to products, and some customers always give the maximal/minimal scores. For the second one, the inconsistency means that a review with a high score has a negative comment.
 the confidence to believe the customer X  X  reviews including both re-view comments and scores.

In this paper, we present an approach to tackle the above prob-lems and rank products and shops fairly. We calculate the new overall scores of products by two steps. The first step is to use a su-pervised learning method to correct the inconsistency between the review score and comment. Newly auto-predicted scores are used as the customer review scores for calculating the overall scores. The second step is to explore the shopping and reviewing behaviors to evaluate the customer credibility. We design a feedback strategy to increase and decrease the customer credibility according to dif-ferent situations. The basic idea behind is: good products deserve to receive high review scores while bad ones should be given low scores; good customers should give high scores to good products and low scores to bad ones. The main difference between the pre-vious approaches and ours is that we consider the product quality to analyze the customer credibility defined as in Defn.1.
In summary, we make the following contributions: 1) We resolve the inconsistency problem between the review comment and score by a supervised learning model. The key is-sues for training the model are to construct the training data and design feature templates. To the best of our knowledge, it is the first work to deal with this type of inconsistency problem. 2) We calculate the customer credibility by analyzing the peo-ple shopping and reviewing behaviors. We design a novel fixed-point iteration algorithms by considering that the customer credi-bility can be revealed by comparing its reviews to the reviews by others on the same product. 3) We design an evaluation method for ranking algorithms. We make the ground truth data from a real dataset instead of using the results from the baselines[7]. Then, we conduct experiments on a real dataset (Taobao, the biggest Chinese C2C site) and the experimental results demonstrate the efficiency and correctness of the proposed approach.
Studying reviews on products has attracted increasing attention recently. Most of previous work [3, 5, 8, 14, 12] emphasizes on analyzing the review content features for detecting helpful reviews. The main purpose of them is to evaluate and select some useful reviews for persons to read as described in [3, 8]. Review qual-ity is calculated by classification or regression model based on re-view comment and test on customer X  X  voting data, which act as the ground-truth. But the credibility of these ground-truth has never been studied. [14] verifies that the syntactic features from the re-view comments are most useful. [5] uses both content features and metadata features, such as ratings, and finds that ratings are most useful for their SVM regression model. [8] takes a non-linear regression model to calculate helpfulness of reviews by inputting reviewer X  X  expertise and the timeline features. [12] compares re-views of different products in one category to find the reputation of the target product by generating in advance syntactic and linguistic rules to determine the (positive/negative) opinions. [4] suggestes to mine and summarize customer X  X  reviews by different properties so as to ease the other X  X  browsing and checking activities. All of these work takes the review comments as their study objects. [9] is the first work to exploit users social context information from voting relationship to predict review quality. However it has not tackled with the quality of peers in the context of open review system. And it can not be adapted to all of the e-commence sites, where there are lack of voting relationship.

Our work is different with but complementary to previous work to solve the credibility of reviewers (customers) and we propose to amend the inconsistency problem between the review comment and score, which has been overlooked so far. Our work is closely related to the reputation system [11, 7]. But [7] is tailored for the signed network and their algorithm will ignore the negative bias of the nodes which affects the ranking seriously. [11] calculates user X  X  reputation by the simple collective comparison. However, they do not distinguish different quality of products/shops when calculating the credibility values. Ours can increase or reduce the credibility according to different situations.
We model the shopping procedures using a graph where the edge weight indicates the customer review score. If a customer does not give out a review on a product, then there is no edge. Formally, let G P CS = f P; C; S; E P C ; E SC g be a graph, where P , S and C denote products, shops, and customers respectively, E P C the links between P and C , and E SC denotes the links between P and C . Review r includes comment x and score w . Edge e c E
P C has weight w c ! p . We say that customer c gives the review r with score w c ! p to product p . Edge e c ! s 2 E SC has weight w ! s that is the average of the review scores from c to the products of shop s . Here, if customer c gives review r to product p which is sold in shop s , we say that c also gives this review to s .
C p and C s are the sets of the customers who give reviews to product p and shop s , respectively. P c and S c are the sets of the products and shops that receive reviews from c , respectively. the number of set . The credibility value of customer c is Cred ( c ) and the overall score of product p and shop s are Score ( p ) and Score ( s ) , respectively.

We normalize the review scores and keep them in the range of [ 1 ; 1] . In our algorithm, a customer can give scores with either both positive and negative, or only non-negative. From here on, the scores are under a normalized range of [ 1 ; 1] . And we also nor-malize the customer credibility values and keep them in the range of [0 ; 1] .

In graph G P CS , the customers directly affect the overall scores of the products and shops by the way of reviewing. So the graph is constructed based on the reviewing relationship between the cus-tomers and the products/shops.
Usually, the overall scores of products and shops are the average of the review scores from the customers [10]. For product p , its original overall score is:
Then, we consider the customer credibility when computing the overall scores. For product p , its overall score with the customer credibility is: Similarly, for shop s , the original overall score is: , while its overall score with the customer credibility is:
Our approach to calculate the scores of the products and shops includes three steps: 1) Review Comment Analysis: To check the inconsistency between the original review scores and the comments and predict the scores of the review comments by using a super-vised learning model; 2) Customer Credibility Analysis: To an-alyze the credibility of the customers by exploring shopping and reviewing behaviors; 3) Re-scoring: To re-score the products and shops by considering the predicted scores of the comments and the customer credibility.
We build a classifier based on Maximum Entropy (ME) model [1, 13] to predict the score of the review comment. Here we are interested in scoring the input examples by the binary classifica-tion. In this paper, we call these scores of review comments as ME-predicted scores w ME c ! p and the original review scores as customer-assigned scores w CA c ! p . We define the feature templates for ME model as shown in Table.1 and select the combination of feature templates for the final systems by tuning on the development dataset.
To train a Maximum Entropy model, we need a set of labeled examples as the training data. However, labeling the data is hard because of the high cost of human annotation. We design a method to construct the training data that include negative and positive ex-amples.

For negative examples, we choose the reviews with low review scores. We investigate the data we collect from some C2C sites and find that for the review with low scores, the customers always write negative words to express his opinion in the comments. There are few cases in which the customers write good comments with low scores.

But for positive examples, the above method does not work be-cause of the existence of inconsistency between scores and com-ments that we have discussed. One important observation is that for the same shop the repeat customers are always positive to the bought products. Here  X  X epeat" means periodically buying the same product or some products in the same shop, such as one week or one month. In most cases, the repeat customers write the positive comments with high scores. Thus, we use the reviews with high customer-assigned scores written by the repeat customers as the positive examples.
We use the feature templates of Table 1 to perform feature rep-resentation for the above data. We then use the MaxEnt 1 , a freely available implementation of Maximum Entropy, to train a classi-fier. Given an review comment, the classifier can predict a score in [0 ; 1] for each class (positive and negative). The predicted class y is: y = argmax y ( p ( y j x )) Thus, the final ME-predicted scores for review x given by customer c to product p is:
This module is to detect the customer credibility, which means to what extend we can believe the review given by the customer. In order to realize this target, we propose a graph-based analysis method. The following ideas are well supported in our design: 1) Customers write good (bad) reviews to good (bad) products are the credible customers and customers write good (bad) reviews to bad http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.html (good) products are incredible; 2) Good products should receive high review scores from the credible customers while bad products should receive low scores from the credible customers. Shops meet the similar situation.

Based on the PCS graph, we design the algorithms to calculate the credibility for all the customers. In our algorithms, if good(bad) products/shops are given low(high) scores by a customer, we give a negative feedback to reduce the credibility of the customer. If good(bad) products/shops are given high(low) scores by a customer, we give a positive feedback to improve the credibility of the cus-tomer.

We first use the relationship between the products and customers for calculating the customer credibility. Then, we use the relation-ship between the shops and customers. Finally, we combine them to seek the balance.
In this section, we describe an algorithm to calculate the credibil-ity for all the customers based on the relationship between the prod-ucts and the customers. The score of a product depends the scores given by its customers and the credibility of its customers while the credibility in turn depends on the feedback from products. Thus, to solve this, we use the method of fixed-point iteration. We denote the credibility of customer c and the score of product p at iteration n by Cred n P ( c ) and Score n ( p ) respectively. We compute the values for iteration n +1 using the values obtained at iteration n . One iter-ation has two phases: Product-Scoring and Credibility-calculating. We initialize the credibility values randomly and get credibility ini-tial vector . The iteration is finished when the change of the cred-ibility is small than predefined threshold .

Product-Scoring : For each product p , its score Score ( p ) is the overall score by considering its customer scores and the customer credibilities. So for p , its ( n + 1) th score is:
Then, we normalize the product scores and keep them in the range of [ 1 ; 1] .

Credibility-calculating We perform feedback only on the good and bad products which are the most highly scored and the most lowly scored respectively. First, we order the products decreasingly by the current scores to a list. Then we select the top t % and bottom t % products of the list as the representative products for good and bad ones into P G and P B , respectively, where t is a threshold that will be tuned on the development data. The rest of products are classified as normal and put into set P N . We use X p to evaluate the consistency to good and bad classifications. X p is in the range of [0,1] that defined as follows: where, M ax P G and M in P G are the maximum and minimum scores in P G respectively while M ax P B and M in P B are the max-imum and minimum scores in P B respectively. The feedback value from p to c is: w
N is the average score for the normal products. Thus, the feed-back value is measured by X p and the difference between the cus-tomer score and the normal score. From the above equation, we can see that when a product is normal, its feedback value becomes zero and there is no effect of the credibility. Otherwise, it gives a positive or negative feedback value to its customers. For a good product, its customer receives a positive (negative) feedback value if the customer gives a positive (negative) score. Similarly, for a bad product, its customer receives a positive (negative) feedback value if the customer gives a negative (positive) score.
Then the credibility of customer c at iteration n + 1 is calculated by considering the feedback values.
 We normalize the credibility values and keep them in the range of [0,1].
We also use the relationship between shops and customers to calculate the credibility of the customers in the similar manner. We denote the credibility of customer c and the score of shop p at itera-tion n by Cred n S ( c ) and Score n ( s ) respectively. We also have two phases in one iteration: Shop-scoring and Credibility-calculating. The calculations are similar with the ones introduced in Sec.5.1.
In the above sections, we calculate the credibility on single graphs (Graph G P C and G SC ). We also can combine them in each iter-ation (on the twin graph). At iteration n , the combined credibility is:
Finally, we obtain the credibility value Cred ( c ) for each cus-tomer c and have two types of review scores: 1) w ME c ! p score; 2) w CA c ! p : customer-assigned score. Then we calculate the new overall scores of the products by using these two types of scores.
We collect the data from the Taobao site that is the biggest Chi-nese C2C site. In Taobao, only the customers who have purchased a product can write a comment and assign a score (customer-assigned score) to the product. The collected data include 15 categories, such as  X  X lothes and shoes",  X  X ooks" and so on. There are 553 ; 000 cus-tomers, 300 ; 000 products, 10 ; 000 shops, and 924 ; 000 reviews after we preprocess the data. Each review contains the comment, the evaluation score, the customer who writes it, the product, and the shop.
As described in Section 4, we construct the labeled data auto-matically. The positive examples are based on the reviews given by the repeat customers with high customer-assigned scores and the negative examples are the ones with low scores. We define two repeat types:  X  X oftBuy" and  X  X ardBuy" that are defined by the re-shopping interval with repeat interval  X  1 day" and  X  5 days", respectively. Then we select 33113 and 17766 data for positive  X  X oftBuy" and  X  X ardBuy" respectively; we select 5950 negative ones. To train the Maximum Entropy model and tune the parame-ters, we randomly select 70% as training data, 10% as development data, and 20% as test data.

We also label some reviews manually to evaluate from a differ-ent view. We invite several students to label the reviews which are selected randomly from the  X  X loth and shoes" category. The stu-dents assign one of three types of labels:  X  X ood",  X  X ormal", and  X  X ad" to each review. Each review is labeled by three students. We keep the reviews with labels  X  X ood" and  X  X ad", and then check the agreement of labels. Finally, we obtain 1000 reviews that have the labels agreed by at least two students.

We call the manual data TestMan data and the automatic gener-ated test data TestAuto data. Both two data are used in the evalua-tion.
We evaluate the ME-based classifier by two ways: automatic and manual methods. The difference is which data we use for testing. For the automatic method, we use the TestAuto data as the test data. For the manual method, we use the TestMan data .
 We measure the classifier quality by the accuracy: accuracy = N =N , where N c is the number of comments with correct labels and N is the number of comment in the test set.
We train the Maximum Entropy model with different types of features (as defined in Table 1) on the trained data and select the best feature combination on the development data. After test on development dataset, we select the Base features and Emotion fea-tures for the classifier in our experiments.

We evaluate the classifier on the TestAuto data. The accuracy is 91.4% for the Softbuy data and 90.2% for the Hardbuy data. We also evaluate the classifier, which is trained on the HardBuy data, on the TestMan data. The accuracy is 85 : 2% that is a little lower than the score ( 90% ) of the automatic method for the same cate-gory.
How to get the ground truth is an important problem for eval-uating the ranking algorithms [7]. In practise, no ground truth products/shops ranking is available in advance. In previous stud-ies, they have to use a baseline system to generate a ranking list as the ground truth [7]. This method is hard to judge how good the new algorithms are. In this paper, we use real data to generate the ground truth. We rely on the following assumptions: The products having the repeat customers are good products with a higher prob-ability than other products; the shops having the repeat customers are good shops with a higher probability than others.
We extract the products and the shops which have the repeat cus-tomers, from the collected data. To select the parameters for the systems, we randomly select 30% of products/shops as develop-ment data and others as test data.
After obtaining the ground truth, we evaluate the systems as fol-lows. We first calculate the scores of the products (shops). Then, we sort the products (shops) in decreasing order by the scores and calculate the number of products (shops) N k having the repeat cus-tomers among the TOP K% in the sorted list. The evaluation met-ric is: B k @ T OP K = N k =N all , where N all is the total number of products (shops) having the repeat customers. According to our assumption, the expectation is that the products (shops) with higher scores should have more chances to have the repeat customers.
Baselines : (1) Arithmetric average algorithm (AA) which ranks (a) Using Customer -Assigned
Scores(Products) (c) Using ME-predicted
Scores(Products) the products/shops by the average customer-assigned scores as de-fined in Eqn.1 and 3. AA is a popular method for ranking in IR community and easy to be implemented [10, 7]. (2) HITS algo-rithms. We use the HITS algorithm proposed in [2] designed for bipartite graphs. (3) L1-AVG algorithm which also takes an itera-tive approach for bipartite rating networks proposed by [7].
We test the influence of parameters and t in the algorithms to system performance on the development data. The experiments are run on the twin graph with the ME-predicted scores. Then we use the settings: = 10 6 and t = 30% ,in the following experiments.
First, we use the customer-assigned scores. The results are shown in Fig.1(a) and Fig.1(b), where  X  X winGraph" refers to the method using the credibility combination ( G P CS -twin bipartite graph) and  X  X ingleGraph" refers to the method using the individual cred-ibility ( G P C / G SC -single bipartite graph). For the products, we find that twinGraph performs the best and SingleGraph outperforms the baseline systems. And for the shops, twinGraph performs a lit-tle better than SingleGraph.

Second, we use the ME-predicated scores. For the reviews writ-ten by the non-repeat customers, we use the model trained on the training data to score them. For the reviews written by the repeat customers, we also have to assign the ME-predicted scores to them by taking the 10-way jackknifing[6] method.
 Here, We test our systems with the credibility combination (twin-Graph). Fig.1(c) and Fig.1(d) show the results. We can see that us-ing reviews comment analysis (ME+twinGraph) can improve sys-tem performance for both products and shops ranking.
We have presented an approach to rank the products and shops for C2C transactions. First, we design a way to construct training data automatically for the Maximum Entropy model. Then we train the classifier to predict the opinion scores for the review comments. Second, we design an iteration algorithm to analyze the shopping behaviors to measure the customer credibility. An effective strategy is designed to increase or reduce the customer credibility accord-ing to different situations. Finally, we combine the ME-predicted scores and the customer credibility to rank the products and shops. We conduct the experiments on a large amount of real-world data that is collected from Taobao. The experimental results show that our proposed approach yields better products and shops ranking than the baseline systems.
This work is partially supported by National Basic Research Pro-gram of China(Grant No. 2012CB316200), National Natural Sci-ence Foundation of China (Grant No.61103039), the State Key Pro-gram of National Natural Science of China(Grant No. 61033007), Joint Research Program with MSRA(Microsoft Research Asia). [1] A. L. Berger, S. A. D. Pietra, and V. J. D. Pietra. A maximum [2] H. Deng, M. R. Lyu, and I. King. A generalized co-hits [3] A. Ghose and P. G. Ipeirotis. Estimating the helpfulness and [4] M. Hu and B. Liu. Mining and summarizing customer [5] S.-M. Kim, P. Pantel, T. Chklovski, and M. Pennacchiotti. [6] T. Koo, X. Carreras, and M. Collins. Simple semi-supervised [7] R. H. Li, J. X. yu, J. Yang, and H. Cheng. Robust [8] Y. Liu, X. Huang, A. An, and X. Yu. Modeling and [9] Y. Lu, P. Tsaparas, A. Ntoulas, and L. Polanyi. Exploiting [10] M. Medo and J. R. Wakeling. The effect of discrete vs. [11] A. Mishra and A. Bhattacharya. Finding the bias and prestige [12] S. Morinaga, K. Yamanishi, K. Tateishi, and T. Fukushima. [13] K. Nigam, J. Lafferty, and A. McCallum. Using maximum [14] O. Tsur and A. Rappoport. Revrank: a fully unsupervised
