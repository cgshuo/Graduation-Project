 We consider the experts recommendation problem for open collaborative projects in large-scale Open Source Software (OSS) communities. In large-scale online community, rec-ommending expert collaborators to a project coordinator or lead developer has two prominent challenges: (i) the  X  X old shoulder X  problem, which is the lack of interest from the ex-perts to collaborate and share their skills, and (ii) the  X  X old start X  problem, which is an issue with community members who has scarce data history. In this paper, we consider the Degree of Knowledge (DoK) which imposes the knowledge of the skills factor, and the Social Relative Importance (SRI) which imposes the social distance factor to tackle the afore-mentioned challenges. We propose four DoK models and integrate them with three SRI methods under our proposed Expert Ranking (ER) framework to rank the candidate ex-pert collaborators based on their likelihood of collaborating in response to a query formulated by the social network of a query initiator and certain required skills to a project/task. We evaluate our proposal using a dataset collected from Github.com, which is one of the most fast-growing, large-scale online OSS community. In addition, we test the models under different data scarcity levels. The experiment shows promising results of recommending expert collaborators who tend to make real collaborations to projects.
With continuous growth of online social communities, en-gaging experts of various specialties to collaborate online becomes more and more feasible nowadays. In Open Source Software (OSS) communities, skills and strong motivations from volunteers are both crucial elements leading to success of collaborative software projects [17, 4, 1, 8, 6]. With grow-ing complexity of software systems and size of online collab-orative projects, finding relevant expertise for specific tasks becomes very challenging. Thus, there is a need to develop expert recommendation systems for OSS communities.
Two main challenges arise in developing such expert rec-ommendation systems. The first is to find a suitable yet motivated expert and the second is related to data scarcity. For the first challenge, there exist several works to find ex-perts who are the most knowledgeable about the given task, e.g. [16, 12, 5]. However, these works may not be sufficient for recommending experts in large online community as they mostly focus on finding experts in offline corporate projects. Under the context of OSS development, a significant issue, known as the  X  X old shoulder X  problem [1], is that an expert may simply ignore requests/invitations from project coor-dinators. To mitigate this problem, most previous works, e.g. [8, 6, 3] suggest decreasing the social distance to the project coordinator who issues the request. The idea is to increase the chance of responses by finding socially close ex-perts based on their social distance to the requester. The challenge in this matter is how to define this social closeness notion in a massive network of collaborators with the ability of accommodating disconnected or new members.

We adopt the notion of Relative Importance in [19] where two nodes in a graph are related by the paths that con-nect them and the amount of importance is given according to the path(s) distance, i.e, the longer the path is the less importance conveyed by that path. To accommodate the nature of the open collaborative networks that may have disconnected subgraphs, we adapt the methods in [19] to propose Social Relative Importance (SRI) such that discon-nected nodes are still considered with penalty weights. We consider three SRI approaches, including two weighted-path methods, i.e., Shortest Path (SP) and k-Short Node Disjoint Paths (kSNDP), and a Marcov-Chain based approach, i.e., Random Walk with Restart (RWR).

Given the unique environment of open collaborative projects that requires motivations and skills, the SRI approaches may not be sufficient for predicting the likelihood of an expert willing to collaborate, since socially close developers do not necessarily have the required skills and knowledge to work on the requested task. To address this problem, we introduce the notion of the Degree of Knowledge (DoK) that antici-pates the expert X  X  ability and willingness to collaborate in a given task. The first DoK model is based on the amount of accumulated knowledge on programming skills over previ-ously participated in projects called Relative Accumulative Knowledge Score (RAKS). The second model uses a content-based filtering approach [2], where a developer X  X  profile of previously participated projects is compared with the query project, and the developer X  X  preference is given by the RAKS score. We call the model the Project Content-Based Filter-ing (PCBF) model.

In addition to the cold shoulder problem, the challenge of data scarcity is prominent in OSS communities since the developer-project participation follows a power-law distri-bution [13], i.e, the majority of developers contribute only to a few projects yet there are a few developers contribut-ing to many projects. The developers who participate in few projects does not mean that they are not experts since some of them do have a great amount of contribution in those projects. In recommender systems, the problem of a user or an item having limited history data is known as the  X  X old-start X  X roblem, which degrades the performance of rec-ommender systems. To mitigate this problem, we introduce two probabilistic generative models, namely, Skill Preference Model (SPM) and Skill and Contribution Preference Model (SCPM). These two models, following the concept of Aspect model, introduced by Hofmann et al. [9], repre-sents an individual X  X  preferences as a convex combination of preference factors. The first model uses a latent variable to capture the developers X  preference on selecting projects with certain skills and contribution, while the second model uses two latent variables to separately capture the developers X  skill preferences and the developers X  contribution level.
Accordingly, we propose the Expert Ranking (ER) frame-work which combines the factors of DoK and SRI, to rank the candidate expert collaborators based on their amount of knowledge and interest to collaborate with the query initia-tor on a given task. Finally, we evaluate the proposed models on a real dataset collected from GitHub.com ,afast-growing online OSS community. The experiment shows promising results for recommending expert collaborators to make real collaborations to projects.

In this paper, we have made a number of contributions:
The rest of the paper is organized as follows. Section 2 reviews some related works. Section 3 introduces some pre-liminaries and defines the expert collaborator recommenda-tion problem. Section 4 introduces the proposed models. Section 5 details the experiment methodology and evaluates the proposed models, and finally Section 6 concludes the paper.
In this section we present some works on experts recom-mendation proposed in the literature. Surian et al. [18] con-sider finding the most compatible developers to a query ini-tiator by considering whether a candidate and the initiator have collaborated before, worked in similar projects, and shared similar skills. This approach focus on the compati-bility between the developers but ignores the compatibility between the developer and the task in hand. As a result, it may not recommend new experts. The works by Mart  X   X n-Vicente et al. [14] and Massa et al. [15] consider building a trust network for recommendation either by inferred action, i.e., approving similar items, as in [14], or by explicit trust action as in [15]. In our work, the trust network is real-ized by the explicit social (acquaintances) and collaboration links. Fritz et al. [5] developed a model to find experts for specific software components by authorship and the amount of interaction with the component information. This model is suitable to find experts within the project X  X  team members and is not suitable for open collaborative community con-sisting of thousands of projects. On the other hand, Ma et al. [12] argue that searching for experts based on their soft-ware components X  usage expertise is comparable to imple-mentation expertise which makes the search possible outside the team members. Hu et al. [10] propose to combine de-velopers X  skills information with the collaboration network. In our work, we combine the collaboration network with the social network, i.e., the network represents social links and the link weights are derived from previous collaborations if exist. Finally, the works in [20, 7] target the field of finding experts on scientific papers via bibliographic network and propose a Bayesian model to estimate an expert X  X  knowl-edge on some topic. In our work, in addition to modeling the amount of expertise, we model the likelihood of an ex-pert to participate in a task with specific skills by adding the amount of contribution on each skill to the model. In contrast to previous works on experts recommendation, we focus on increasing the likelihood of experts responding to a query by considering their participation history, knowledge and social ties.
In this section, we introduce some preliminaries and de-scribe the problem formulation for expert collaborator rec-ommendation in the OSS communities.
 Let G ( X,E ) be an undirected social graph representing an OSS community, where X = { x 1 , ..., x n } is the set of active developers in the community and E represents the acquain-tances relationships among the developers. Here each edge e is associated with a weight w . Edge weights can be derived from any relation type. In this work, edge weight is derived from the frequency of collaborations. Note that, if two nodes are socially linked but never collaborated before then w =0, otherwise w&gt; 0. Also, let S = { s 1 , ..., s m } be the set of all skills and Y = { Y 1 , ..., Y l } be the set of all projects. Every project Y k  X  Y consists of a set of developers and requires a set of skills. Thus, we also use Y k to denote the set of skills in a project k , i.e., Y k  X  S .

Given a developer x i ,let y i = { y 1 , ..., y w } be a vector of projects that x i participates in and let x i = { s 1 , ..., s be a vector of skills possessed by developer x i . Together, y i and x i represent a Developer Profile (DP). Likewise, let s j = { x 1 , ..., x h } be a vector of developers who possess skill s j , which represents a Skill Profile (SP). Vectors x , s and y are derived from a 3-dimensional, developer-skill-project , matrix M of size n  X  m  X  l where a matrix entry m i,j,k &gt; 0 denotes the contribution of developer i to project k with skill j .
 Problem Formulation. Given an expert collaborator query Q  X  ( x Q ,Y Q )where x Q  X  G is the query issuer (a devel-oper who issues the query) and Y Q = { s 1 , ..., s  X  } is a set of required skills for the project/task. In responding to Q , an expert collaborator recommender finds and ranks top-n developers who are most likely to collaborate with x Q on project/task Y Q .
To answer the expert collaborator query, we consider two main aspects to find and rank experts who are most likely to collaborate with a query issuer in a given task. The first as-pect considers the Degree of Knowledge (DoK) and the sec-ond aspect considers the Social Relative Importance (SRI). We propose four models under the DoK aspect and enhance the models with three SRI approaches. The two aspects are used in the Expert Ranking (ER) framework to rank the ex-perts. In the following sections, we introduce in detail the proposed solutions.
The Degree of Knowledge (DoK)aspectconcernsabout the amount of knowledge a developer has towards a certain set of skills and the likelihood of contributing in projects with such skills needed. In this section, we introduce in de-tail four alternative models for the DoK aspect: (1) Relative Accumulative Knowledge Score (RAKS) based on the accu-mulated knowledge on programming skills over previously participated in projects; (2) Project Content-Based Filtering (PCBF) which compares previous projects with the query project where the similarity is weighted by a developer X  X  preference given by the RAKS score; (3) Skill Preference Model (SPM), based on a probabilistic generative model that captures the developers X  preferences on selecting cer-tain skills with certain amount of contribution; (4) Skill and Contribution Preference Model (SCPM), based on a proba-bilistic generative model. Here, SCPM captures developers X  preference on selecting skills and their contribution level sep-arately, allowing for more precise prediction.

Instead of considering all the developers in the OSS as candidates for a given query Q  X  ( x Q ,Y Q ), we first use Y Q as a filter to eliminate those who do not have the required skills. Thus, a set of developers X Q =  X  s j  X  Y Q s j where each developer in X Q possesses at least one skill in Y Q are extracted. 1 In the following sections, we detail the DoK models.
Note that we do not solve the skills coverage problem in this work since experts are ranked as individuals and not as ateam.

Figure 1: SPM model with one latent variable.
The Relative Accumulative Knowledge Score (RAKS) mea-sures the amount of knowledge a developer has on certain skills. Given a developer x i  X  X Q , RAKS is defined based on Eq. (1).
 Y Q , cont s j ,Y k is the frequency of contributions or commits of developer x i using skill s j in project Y k ,and  X  is a normal-izing factor such that RAKS ( x i ,Y Q )=[0 , 1]. The RAKS score considers the amount of contribution, measured by the number of commits 2 ,byadeveloper i using a skill j in dif-ferent projects as a way to measure developer i  X  X  expertise to skill j .Also,the  X  factor in Eq. (1) assists to distinguish between a developer who knows all the required skills in Y and another who knows a fraction of the required skills.
The Project Content-Based Filtering (PCBF) aims to im-prove over RAKS by considering both the amount of knowl-edge and the likelihood of a developer x i to participate in value for x i to collaborate in Y Q based on Eq. (2):
PCBF ( x i ,Y Q )=  X  where sim ( Y Q ,Y k ) is the similarity measure between Y Q and a previously participated in project Y k by developer x i , RAKS ( x i ,Y k ) measures the RAKS score for Y k sim-ilar to Eq. (1), and  X  is a normalizing factor such that PCBF ( x i ,Y Q )=[0 , 1].

In a user-item recommendation scenario, the content-based filtering model measures the expected rate of a user i on se-lecting a given item j based on the history of user i  X  X  ratings for previously selected items that are similar to item j .Like-wise, Eq. (2) measures the expected rate of developer i to collaborate in project Y Q based on the history of developer i  X  X  previous collaborations on similar projects to Y Q as well as i  X  X  knowledge on each of these previous projects. The similarity measure is essential to the success or failure of a content-based filtering approach. In PCBF, we use skills as a main attribute to measure similarities between projects.
A commit is the update procedure a developer performs to upload his/her edits to a project X  X  files.
Figure 2: SCPM model with two latent variables.
The Skill Preference Model (SPM) is designed to pre-dict the probability of an expert to participate in a query project Y Q . SPM is based on the notion of aspect model which models individual preferences as a convex combina-tion of preference factors. In OSS community, a history record &lt; x,y,s,c &gt; consists of a developer x participating in project y using skill s with amount of contribution (com-mits count) c has a great amount of information that can be used for advanced predictions. 3 A latent variable in the aspect model is associated with each observation (record) which allows classifying each skill and contribution selection by x in its appropriate class. This creates a great amount of flexibility on classifying individuals X  preferences and be-havior. In addition, probabilistic generative models tend to work well with scarce data since it can classify records based on the trained distributions of the model X  X  parameters. (i.e., P ( Y Q | x i )orsimply P ( y | x )). Note that P ( y computed as
Assuming one latent variable Z = { z i , ..., z k } ,wedesign the aspect model as in Figure 1. The model shows the im-portant fact that x , s , y and c are independently conditioned on Z . The probability model can be simply written as where S y is the set of skills associated with y and C x is the set of contribution levels associated with x . Also, the joint probability distribution over all factors is where P ( z | x ) is the probability of x falling in class z ,and distributions giving the probabilities of class z selecting s , y and c . Overall, the SPM model with one latent variable gives the probability of developer x selecting project y with skill s and amount of contribution c . Comparing to a user-item recommendation scenario, one can think of s as the content of an item and c as the rating given to the item. Hence, SPM models the developer X  X  preference on selecting projects with certain skills and how much contribution is exerted in such project with these skills.
The amount of contribution in this work is converted to a nominal value representing different levels of contributions (e.g., low, med and high). One can interpret it as ordinal value as well.

To train SPM model, we use the Expectation Maximiza-tion (EM) algorithm to learn the model parameters from the set of developer-project-skills-contributions history H , i.e., &lt;x,y,s,c&gt;  X  H . Note that a project may require multiple skills in which s may be a set of skills S . Our model param-eter learning algorithm is based on the idea of maximizing the log-likelihood of L (  X  ).
 where  X  denotes the model parameters, i.e., P ( z | x ), P ( s P ( c | z )and P ( y | z ). The EM algorithm iterates between the E-step and M-step. In the E-step, the algorithm calculates the posterior probability of every latent variable z  X  Z , based on the current estimates of the parameters. More specifically, we calculate
In the M-step, model parameters are computed to maxi-mize the expected log-likelihood in the E-step as below. c  X  C P ( c | z ) are all 1. Note in Eq. (8) the variable with a prime means counting every value of this variable. Iterating between the E-step and M-step, the EM algorithm improves the model parameters on each iteration until they converge to a local log-likelihood maximum.
A developer has different contribution efforts (levels) using certain skills in each project participation. Using one latent variable may not be able to precisely capture the contribu-tion level of a developer since the contribution information c is mixed with the skills information s . To distinguish be-tween a developer X  X  preference on selecting certain skills and his/her contribution level, we introduce a second version of SPM that uses two latent variables as depicted in Figure 2.
Having two latent variable Z s = { z s i , ..., z s k } representing ing developers X  contribution level. Then we notice that x , s and y are independently conditioned on Z s , while x , c and y are independently conditioned on Z c . The probability model canthusbewrittenas and the joint probability distribution over all factors is P ( x, y, z s ,z c ,s,c )= P ( z s | x ) P ( z c | x ) P ( s where P ( z s | x ) is the probability of x falling in skill prefer-ence class z s and P ( z c | x ) is the probability of x falling in of both z s and z c selecting project y . Eq. (10) calculates the joint probability of developer x falling in class z s to select project y with skill s ,and x falling in class z c to contribute at c level in project y . This refined model is expected to raise the accuracy of prediction.

The EM algorithm is used here as well. However, SCPM is more challenging since it has two latent variables. In this case the E-step contains two posterior probabilities, one for each latent variable as follows.

In the M-step, model parameters are computed to maxi-mize the expected log-likelihood in the E-step as below.
P ( z s | x )=
P ( z c | x )=
P ( s | z s )=
P ( c | z c )= tween the E-step and M-step, the EM algorithm improves the model parameters on each iteration until they converge to a local log-likelihood maximum.
In order to enhance the DoK models, we integrate the SRI factor to the DoK models. We propose that this integration can enhance the prediction accuracy of the DoK models to recommend experts who are willing to contribute their skills and knowledge.

Different from global importance models, e.g., centrality measures and PageRank , that measures the importance of a node in the entire network, in this work we consider the Social Relative Importance (SRI) between two nodes, i.e., a candidate developer relative to the query issuer. Given a network G ( X,E ), the relative importance between a source node i  X  G and a target node j  X  G can be defined by the path distance between i and j , in general. In this sense, relative importance recognizes the importance of a target node relative to a source node.

We adopt the approaches in [19] to estimate the relative importance and modify the approaches to consider the dis-connected nodes to accommodate new members or members that are disconnected from the query issuer. In the follow-ing, we introduce three adapted approaches to realize SRI, in which two are weighted-path methods, i.e., Shortest Path (SP) and k-Short Node Disjoint Paths (kSNDP), and the third is a Marcov-Chain based approach, i.e., Random Walk with Restart (RWR).
The SP is the simplest form of measuring SRI between two nodes. Given a social graph G as defined in Section 3, an edge weight w may equal zero if the two end nodes never collaborated before but are socially acquainted. Since we cannot use zero edge weights into weighted-path methods, we offset every edge weight by a very small value that is less than the minimum edge weight in G . Eq. (13) shows the SP model for nodes i and j .
 where P is the set of paths between i and j and  X  is a very large value as a penalty if no path exist. The mindist function outputs the minimum distance value of the shortest path in P . In addition to SP, we consider the kSNDP defined in [19]. Instead of considering a single shortest path, kSNDP ac-counts for multiple node-disjoint paths between i and j of length  X  k nodes. Node-disjoint means that no node is re-visited in another path. A target node connected to a source node through multiple unique paths is assumed to have high importance value. We refer the reader to [19] for further de-tails on calculating kSNDP. Similar to the SP approach, if a target node is disconnected from the source node, then a penalty value  X  is set instead.
Random Walk with Restart , a.k.a. personalized PageRank or PageRank with priors [19], is based on Markov chains. The original idea derived from the random walker model which gives, globally, the probability of a random walker in a graph to end on some node after a number of time-steps transiting from one node to another neighboring node with a probability  X  to randomly jump to any node in the graph. These probabilities represent the fraction of time that the random walker spends at any single node. RWR adds to the random walker model prior probabilities to start at certain node(s) R where those probabilities sum to one, and a probability  X  to restart the random walk from R at each time-step. After convergence, the probability of a node j relative to a source node i  X  R gives the likelihood of i to visit j , which is a stochastic notion of relative closeness in a graph. In this paper, the query issuer represents the re-starting node r where R = { r } . We use the resulting scores, biased towards r , as the relative importance value after convergence. Originally, RWR works in a connected graph only. Therefore, if a target node is disconnected from r , then a penalty value  X  is set instead.
Given the various realizations of SRI and DoK, we propose a multiplicative framework, called Expert Ranking (ER) to rank experts as in Figure 3. Given a query Q  X  ( x Q ,Y Q ), the ER framework obtains the OSS data records, &lt;x,y,s,c&gt; , and social graph G , then filters the records based on the skills required in Y Q and processes G according to each SRI method as discussed in Section 4.2. The ER framework, then, integrates the outputs from DoK and SRI based on the ER scoring function, ER Q,i , in Eq. (14) for a query Q and a candidate expert i .
 where DoK  X  X  RAKS,PCBF,SPM,SCPM } . Basically, one DoK model is used with one SRI approach on each ER evaluation, e.g., ER = RAKS  X  kSNDP .Inthecaseof SRI  X  X  kSNDP, RWR } , ER multiplies the values of the two models since a larger value of kSNDP (multiple short paths) and RWR (probability value) is better than a smaller value. On the other hand, in the case of SRI  X  X  SP } ,ER multiplies DoK by the reciprocal of SRI since a smaller value of SP (shorter path means closer distance) is better than a bigger value. The ER score is distinct for each SRI and DoK model combination. Therefore, we emphasize that our purpose of the ER is to rank the candidate experts and not to define a unique measuring score.

We opted to use the multiplication over addition in the ranking function for the following reasons: First, it is sim-pler and more effective to penalize the ranking score, in the case of disconnected experts from x Q , than addition which needs a trained balancing weight factor between SRI and DoK. Second, the absolute value differences between SRI and DoK are of less interest and importance than the per-centage changes between them which makes a multiplication a better choice. Finally, the multiplication performs better than addition in the initial experiments. However, we do not show those results since this is not the focus of this paper.
We evaluate the proposed models on a historical data set collected from Github.com which is one of the most fast-growing OSS online repository. Github.com, hosting over two million OSS projects and over one million contributors, is unique since it provides a variety of interaction tools be-tween the contributors. One of these tools allows contribu-tors to explicitly recognize each other through a follow link that creates a directed social network of contributors. Ta-ble 1 summarizes the data set collected from Github.com. Participations in row one is the total number of developer-project records. In the experiment, we consider only the col-laborators with account in Github.com since they are iden-tifiable by a unique ID, whereas anonymous contributors are hard to track and know their participation history.
To setup the experiment, we conduct a series of process-ing steps on the Github.com dataset. First, a social graph is constructed from direct follower/following links between the contributors. However, we consider these edges as undi-rected in the experiment. We emphasize that the graph edge is based on a social tie and the edge weight is based on col-laborations between two endpoints (i.e., developers). This means if two individuals are acquaintances but did not col-laborate, then their edge weight is set to zero, on the other hand, if two individuals collaborated in a project but are not acquaintances, then there is no edge between them. We do not use an affiliation graph since the OSS community is a large Web-based community in which some developers work in isolation and do not actually know each other. Therefore a social network would resemble true acquaintance among contributors which may increase a recommender system X  X  ac-curacy. Besides the social graph of collaborators, projects X  meta data, e.g., skills used, collaborators, and their amount of contribution (number of commits), is stored in a database.
Having the graph of collaborators and the projects X  database, we randomly select one project at a time, and from the set of collaborators in this project we choose one developer as a query issuer x Q and mark off (remove) his collaborators from the social graph and the projects X  database. The re-quired skills of the marked-off project become Y Q .Inthe social graph, the edge weights between x Q and his/her ac-quaintances in Y Q are decremented by one. Therefore, if the marked-off project is the only collaboration, then the edge weight is set to zero. Note that the social links are not nec-essarily existing within members of the same project. On the contrary, many links exist with developers outside the project team. In this case, the SRI approaches consider dis-tant collaborators in the solution.

The marked-off collaborators and their associated projects become the test set with their associated queries of x Q and each query, Q  X  ( x Q ,Y Q ), we match the top-20 develop-ers recommended by ER with the original team members marked off and consider each match as a hit, which means that the recommender system was able to predict a collabo-rator that indeed made a collaboration with the query initia-vancy and responsiveness of a matched contributor to Q by her/his percentage of contribution in the marked-off project project are more relevant and responsive to Q than develop-ers who contributed less. We discuss the evaluation metrics in detail in Section 5.2.

To train the probabilistic models, SPM and SCPM, we remove all the test (marked-off) projects X  teams from the history data. Furthermore, we make sure that the selected test projects X  teams do not have overlapping contributors to insure that each test is unique and not repeated. Also, we select teams of sizes between 40 to 50 members to have fair evaluation between the queries since small teams of 2-5 members may be difficult to find matches in top-20 while large teams of &gt; 100 members may be easy to find matches in top-20. Moreover, in SPM and SCPM, we want to com-pute P ( y | x ), where y is marked-off (i.e., not included in the training set). Therefor, in the experiment, we use a simi-lar project to y in terms of skills required to be the project task/project associated with x Q .

Finally, to evaluate the strength and weakness of each model on different data availability, we divide the test sets, the marked-off projects, based on the developers X  number of participation records in each team. We divide the test set into four sets: [2, 10), [10, 50), [50, 200) and  X  200. For example, projects in [2, 10) include teams of developers with participation records between 2 to 9 project participations. Set [2, 10) resembles the most scarce data set, and set  X  200 resembles the most abundant dataset. The next section presents the evaluation and discussion.
We want to evaluate the different combinations of DoK models and SRI methods based on (i) how many expert candidates can they find? (ii) how responsive are those can-didates to Q ? and (iii) how well are they ranked in the top-20? We use the precision metric for (i), the expert X  X  percentage of contribution, i.e., responsiveness (resp.), in Y
Q for (ii) and the normalized Discounted Cumulative Gain (nDCG) [11] metric for (iii). Recall that precision is the fraction of relevant records over the total number of records retrieved. As mentioned in the previous section, we con-sider a developer as relevant if she/he is a member of the original marked-off project Y Q . We emphasize that finding the members of the original team is not the purpose of the recommender system proposed, but only a method to eval-uate its effectiveness in recommending developers who tend to make actual collaborations in the future.

Recall that the nDCG evaluates relevant records retrieved based on its relevancy level and its position on the rank, i.e., a system ranking highly relevant records in high positions is considered better than a system ranking highly relevant records in low positions. Under the context of this work, relevancy is estimated by the amount of contribution a de-veloper exerts in a project, i.e., the number of commits. To measure nDCG, we develop a multi-level relevancy model based on the percentage of contribution for a developer in a project as follows:  X  %50 is highly relevant, [%20, %50) is moderate relevant, [%5, %20) is relevant, and  X  %5 is least relevant.

We emphasize that the nDCG is different from precision as the latter only counts the number of relevant records in the retrieved set, while, nDCG evaluates the relevancy and ranking position of these relevant records. Moreover, resp. evaluates the quality of the relevant records in terms of the amount of relevancy regardless of ranking. Finally, the pa-rameters of the models are as follows: for kSNDP, the maxi-mum path length is k = 6 and the decay coefficient is 2. For RWR, the restart probability  X  =0 . 3. For SPM, | Z | = 15, and for SCPM | Z s | =10and | Z c | = 6, where the number of classes initialized by a clustering technique. In the following sections we present the results and discuss and analyze the findings.
Based on the ER framework, one can use different combi-nations of DoK and SRI schemes to make expert recommen-dations. In order to evaluate the ER on each DoK model with different SRI methods, we evaluate all the combinations grouped by the SRI method. The first experiment evalu-ates the DoK models without the SRI factor, i.e., DoK-only. The second, third and fourth experiments evaluate the DoK models with SP, kSNDP and RWR, respectively. Figure 4 and Table 2 shows the results of each DoK model and SRI method combination. Table 2 shows the Hits@100 , resp.@20 and nDCG@20 , where the bold face result resembles the maximum result for its group, while, the highlighted result resembles the maximum value overall.
 DoK-only: Figure 4(a) shows the average precision of the top 20 expert collaborators retrieved. With no SRI fac-tor, we can see that the overall precision values are very low (below 0.1). Also, we notice that the memory-based models, RAKS and PCBF, have better precision, Hits@100 , resp.@20 and nDCG@20 than SPM and SCPM. The reason might be that, without a social factor, SPM and SCPM find experts that are not responsive or willing to participate with the query issuer. As a result, the memory-based models will perform better with no social factor since it depends mainly on history data.
 DoK-{ SP } : In Figure 4(b), we notice that the precision values are all above 0.1, which is a great improve when us-ing a social factor. Comparing the DoK models, we notice the superiority of SPM and SCPM over RAKS and PCBF in all metrics. SPM and SCPM seem to have similar pre-cision, however, SCPM has better Hits@100 , resp.@20 and nDCG@20 . This means SPM and SCPM find similar num-Figure 4: The average precision for various k ex-pert collaborators on combinations of DoK and SRI methods grouped by the SRI method. ber of hits on top-20 but SCPM finds more responsive de-velopers and rank them higher than SPM.
 DoK-{ kSNDP } : Figure 4(c) and Table 2 shows that SPM and SCPM perform better than RAKS and PCBF on all metrics except resp.@20 where RAKS and PCBF have higher values. This shows the advantage of RAKS and PCBF on retrieving highly responsive developers with the kSNDP method, while SPM and SCPM retrieve more hits and rank them higher.
 DoK-{ RWR } : In Figure 4(d), we notice that the RAKS and PCBF precision got slightly higher, while the SPM and SCPM precision got lower, and overall close precision per-formance to all. Also, RAKS has the highest resp.@20 and nDCG@20 while SCPM has the highest Hits@100 .Using RWR seems to boost the memory-based DoK models while a bit halting the probabilistic based DoK models. The rea-son might be that RWR finds socially close developers that also have high centrality in the social network which prevent them from being highly responsive. This explains the fact that probabilistic models find more hits but less responsive developers. Moreover, memory-based models, RAKS and PCBF, finds more responsive developers since they count more on history data.

Overall, SCPM-SP has the best Hits@100 and nDCG@20 , where RAKS-RWR has the best resp.@20 . There is no winner between the SRI methods but it is definite that SRI methods improve the DoK models in general. Also, the probabilistic models seem to perform the best with SP, while, the memory based models perform the best with RWR for the aforementioned reasons. Moreover, we notice that SPM has the lowest resp.@20 in all combinations because SPM models skill preference and contribution level com-bined. With the separation of preferences, skill and con-tribution level, we see that SCPM can find more responsive developers than SPM.
This evaluation investigates the ER performance on differ-ent history records (h.r.) levels. We control the social factor by using one SRI method and compare all DoK models on Table 2: ER Evaluation on Hits, resp. and nDCG.
 multiple h.r. levels. We choose the base line SRI = { SP } then ER = { RAKS,PCBF,SPM,SCPM } X { SP } .
 Precision: Figure 5 shows the average precision of the top 20 expert collaborators found corresponding to differ-ent sets of h.r. [2, 10), [10, 50), [50, 200) and  X  200. Fig-ure 5(a) shows clearly the superiority of the probabilistic models SPM and SCPM over the memory based models RAKS and PCBF which could not retrieve any developer on top 20. This particular result shows the power of SPM and SCPM in recommending experts with very limited data history.

In Figures 5(b) and 5(c), we still notice the superiority of SPM and SCPM over RAKS and PCBF. However, Fig-ure 5(b) shows that RAKS is performing better than PCBF which still suffers from data scarcity and it improves as data becomes abundant as shown in Figures 5(c) and 5(d). In particular, Figure 5(d) shows that memory based models, RAKS and PCBF, performs better than probabilistic mod-els, SPM and SCPM, when data is abundant. Comparing SPM and SCPM, we notice similar performance, with simi-lar number of hits on top 20.
 Figure 6 shows that SCPM retrieves more experts than SPM in all test sets except set [10, 50) where they appear to be identical. Moreover, SPM and SCPM have more hits than PCBF and RAKS in all test sets except the  X  200 set. Also, PCBF outperforms RAKS on sets [50, 200) and  X  200 of abundant data history.
 Responsiveness: Next, we evaluate the responsiveness of the relevant experts to Q .Figure7shows resp.@20 for each data history record set. In scarce data set [2, 10), SPM and SCPM outperform RAKS and PCBF with the superiority to SCPM. However, when data becomes more abundant, RAKS and PCBF performs better where PCBF has slight advantage over RAKS in sets [50, 200) and  X  200. The results suggest that SPM can find candidates as much as SCPM, as suggested by the precision evaluation, but SCPM finds more responsive candidates than SPM. (a) For h.r. between [2, 10) (c) For h.r. between [50, 200) Figure 5: The average precision for various k expert collaborators on multiple h.r. sets. Figure 6: The avg. Hits@100 for DoK models on multiple h.r. sets. Figure 7: The avg. resp.@20 for DoK models on multiple h.r. sets. Figure 8: The average nDCG@20 for DoK models on multiple h.r. sets.
 Ranking: Finally, we evaluate the quality of ranking by the nDCG metric. Figure 8 shows nDCG@20 for each data history record set. We see the difference between SPM and SCPM very clear, where SCPM has better quality on rank-ing more relevant developers in higher positions than SPM in all test sets. Also, RAKS has better quality than PCBF in all test sets except the  X  200 set, and RAKS and PCBF perform better than SPM and SCPM in the very abundant data set of  X  200.
 Discussion: Dividing the data set according to the his-tory records availability gave new insights on the strengths and weaknesses of well known recommender models such as memory-based and probabilistic models. The previous eval-uation shows that the probabilistic models, SPM and SCPM, have unmatched superior performance over the memory-based models, RAKS and PCBF, when data is scarce. The design of SPM and SCPM allows high prediction power, even when data is very scarce, because a developer X  X  preference is classified according to the learned parameters from the train-ing dataset. On the other hand, the memory-based models, RAKS and PCBF, perform better when data is very abun-dant because the models by design increase the prediction power as it sees more data which makes it more accurate than the probabilistic models in this case.

We also notice another unpredicted results where the test set  X  200 has the lowest performance in all evaluations. We argue that most of the developers who have too many par-ticipations (  X  200) tend to have low contribution in these projects. This is logical since a volunteering developer may not have enough time to contribute much in each project (assuming a simultaneous participation to multiple projects at one time). The less amount of contribution by a devel-oper in a project is interpreted by the DoK models as lack of experience or/and a lack of interest from that developer in the project, which reduces the prediction accuracy. Comparing SPM to SCPM, the evaluation shows that SCPM finds more responsive experts than SPM and has higher nDCG than SPM. This is due to the separation of the latent variable Z into Z c and Z s , which makes the distinc-tion between a developer X  X  contribution level and skills pref-erence, respectively. Given this advantage, SCPM can more accurately recommend higher contributing (responsive) de-velopers than SPM.
In this paper, we target two main problems in recom-mending experts in online open projects. The first problem is related to the responsiveness of experts in collaborating in open projects, and the second problem is related to data scarcity. We mitigate those problems in two aspects, i.e., DoK and SRI. The DoK involves the amount of knowledge or expertise of candidate experts to a given task. The SRI in-volves the social factor between the candidate experts and a query issuer. We consider three approaches, i.e., SP, kSNDP and RWR, to estimate the SRI and proposed four models, i.e., RAKS, PCBF, SPM and SCPM to estimate the DoK. Moreover, we introduced the ER framework to incorporate the DoK and SRI to rank the candidate experts. We con-duct extensive experiments on a real historical data set from Github.com of more than a million contributors and more than two millions open projects. We evaluate the precision, responsiveness and goodness of ranking of each DoK model and SRI approach combination. We also evaluate the DoK models on different data scarcity level. The results show the effectiveness of the ER in recommending experts that are highly responsive and motivated to contribute their skills. In the future, we aim to investigate the possibility of defin-ing a metric score to quantify the expert X  X  interest to partic-ipate instead of the ER score for ranking. We believe that the proposed models to recommend experts can increase the experts X  involvement in open projects and, as a consequence, increase its probability of success. [1] L. Backstrom, D. Huttenlocher, J. Kleinberg, and [2] M. Balabanovi  X  c and Y. Shoham. Content-based, [3] A. Barreto, M. De O Barros, and C. M. L. Werner. [4] L. V. Casal  X o, J. Cisneros, C. Flavi  X  an, and [5] T. Fritz, J. Ou, G. C. Murphy, and E. Murphy-Hill. A [6] J. Hahn, J. Y. Moon, and C. Zhang. Emergence of [7] S.H.Hashemi,M.Neshati,andH.Beigy.Expertise [8] P.J.Hinds,K.M.Carley,D.Krackhardt,and [9] T. Hofmann and J. Puzicha. Latent class models for [10] D. Hu and J. L. Zhao. Expert recommendation via [11] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [12] D. Ma, D. Schuler, T. Zimmermann, and J. Sillito. [13] G. Madey, V. Freeh, and R. Tynan. The open source [14] M. I. Mart  X   X n-Vicente, A. Gil-Solla, M. R. Cabrer, [15] P. Massa and P. Avesani. Trust-aware recommender [16] D. Schuler and T. Zimmermann. Mining usage [17] C. Subramaniam, R. Sen, and M. L. Nelson.
 [18] D. Surian, N. Liu, D. Lo, H. Tong, E.-P. Lim, and [19] S. White and P. Smyth. Algorithms for estimating [20] Z. Zhan, L. Yang, S. Bao, D. Han, Z. Su, and Y. Yu.
