 Our work is motivated by anomaly detection in datasets that have several at-tributes with tens of thousands of categorical values. We want to know the exis-tence of anomalous behavior by finding abnormal records, i.e. , records strangely repeated or strangely less than expected . For example, an intrusion detection system (IDS) monitors network traffic for suspicious activity, and each record in IDS logs has attributes such as srcIP , dstIP , port ,and type as shown in Table 1. A serious problem for analysts in charge of a company X  X  security system is that IDS logs contain too many records to inves tigate all of them precisely. Therefore, it is important not only to determine ordinary behaviors, i.e. , the day X  X  trend of attacks which changes rapidly day-to-day, but also to spot anomalous behaviors, i.e. , remarkable attacks which greatly differ from ordinary behaviors of the day, which are worth investigating. We ca n build a model of records caused by ordi-nary behavior under the assumption that the majority of records are caused by ordinary behavior, and distinguish anomalous behaviors from them. One possi-ble model is to assume the probability of an ordinary record which contains two attribute sets A and B as P ( A ) P ( B ), i.e. , statistically independent, and to de-clare a record anomalous if their joint appearance P ( A, B ) is much higher than P ( A ) P ( B ). This is an intuition based on suspicious coincidence [1]. However, there are large amount of abnormal records caused by noise, e.g. , false positives in IDS logs [2], and they can be repeated more abnormally than those caused by anomalous behaviors, and they are hard to be distinguished. We can assume that an anomalous behavior can affect a group of records with similar attribute values, and can be distinguished from noise by gathering abnormal records into such a group. For example, many abnormal records with similar srcIP , dstIP , port ,and type can be caused by a common remarkable attack, instead of false positives. However, a problem is that it becomes harder to detect abnormal records in such a group as the size of th e group grow, because they become more likely to be ordinary behaviors, e.g. , P ( A ) P ( B ) gets closer to P ( A, B ).
To tackle these difficulties, we propose a two-step anomaly detection. In the first step, we detect abnormal records as individual anomalies with a statistical anomaly detection that mod els the distribution of the numbers of records caused by ordinary behaviors as Poisson distribution. By making a stronger assumption of the distribution for ordinary behaviors, we try to detect abnormal records in larger groups more effectively. This step can be improved by using Poisson Tensor Factorization ( PTF ) [3]. In the second step, we gather the individual anomalies into groups of records with similar attribute values. This step can be implemented by using CANDECOMP/PARAFAC (CP) Decomposition [4].

Our main contributions are: (1) We proposea novel framework MultiAspectSpot-ting combining statistical anomaly detection with spotting groups of abnormal records. (2) By using datasets added with synthesized anomalies, we show our method can spot anomalous behaviors effectively. (3) We show our method can spot interesting patterns in real world datasets like IDS logs and web-access logs.
The remainder of this paper is organized as follows. We describe the related literature in Section 2 and introduce o ur method in Section 3. We describe the accuracy and scalability of our method in Section 4 and the experimental evaluation on real data in Section 5. In Section 6 we summarize our conclusions. 2.1 Anomaly Detection in Categorical Datasets Anomaly detection has attracted wide interest in many applications such as se-curity, risk assessment, and fraud analysis [5]. Das et al. [6] proposed an anomaly pattern detection in noisy categorical datasets based on a rule-based anomaly detection [7]. They searched through all possible one or two component rules and detected anomalies whose counts were si gnificantly differed from the expected counts determined by the training dataset. They used the conditional anomaly detection [8,6] as a definition of anomalies which is an alternative of suspicious coincidence proposed by Barlow [1]. However, they tried to find groups of ab-normal records which significantly differed from the training dataset, whereas our problem is to spot groups of abnormal records which are most remarkable among all records in the dataset. 2.2 Tensor Decomposition Tensor decomposition is a basic technique that has been widely studied and ap-plied to a wide range of disciplines and scenarios. CP Decomposition and Tucker Decomposition are two well-known approaches [4], and has been applied to study tensor streams [9]. Non-negative tensor factorizations have been proposed to re-tain the nonnegative characteristics of the original data [10], as natural expan-sions of non-negative matrix factorizations[11]. PTF is one such technique, that models sparse count data by describing the random variation via a Poisson dis-tribution [3]. Our work is also related to the Boolean Tensor Factorization [12], which uses Boolean arithmetic, i.e., defining that 1 + 1 = 1. The problems of Boolean Tensor Factorization were proved to be NP-hard, and heuristics for these problems were presented [12]. Som e implementations of tensor decompo-sition algorithms have been made publicly available, such as MATLAB Tensor Toolbox [13]. We combine some of these tensor decompositions effectively to spot anomalous behaviors. Moreover, some works detected outliers in a low-dimensional space obtained by tensor decompositions [14], but outliers caused by anomalous behaviors were not distinguished from those caused by noise. 3.1 Notation A tensor can be represented as a multi-dim ensional array of scalars, and we call each scalar an entry .Its order is the dimensionality of the array, while each dimension is known as one mode .Atensoris rank one if it can be written as the outer product of vectors. The rank of a tensor is defined as the smallest number of rank-one tensors that can generate the tensor as their sum, and we refer to each rank-one tensor as a component . Throughout, scalars are denoted by lowercase letters ( a ), vectors by boldface lowercase letters ( v ), matrices by boldface capital letters ( A ), and higher-order tensors by boldface Euler script letters ( X ). The j th column of a matrix A is denoted by a j ,and i th entry of a vector v is denoted by v i . We use multi-index notation so that a boldface i represents the index ( i 1 ...i M ) of a tensor of order M .Thesizeof n th mode is denoted as I n . The notation  X  refers to the square root of the sum of the squares of the entries, analogous to the matrix Frobenius norm. The outer product is denoted by  X  , and the inner product is denoted by  X  ,  X  . 3.2 Problem Setting Our problem can be defined as follows: Given a dataset in which each record i has M categorical attributes and repeated x i times, how can we detect abnormal records repeated strangely more th an or less than expected, caused by anomalous behaviors as distinguished from those caused by noise?
We make two assumptions. (1) The majority of records are caused by ordinary behavior, and we can build a model with minimal harm caused by anomalous behaviors and noise. (2) A group of abnormal records with similar attribute values is likely to be caused by a common anomalous behavior. 3.3 MultiAspectSpotting Framework In this paper, we focus on statistical anomaly detection based on the assumption  X  Normal data instances occur in high probability regions of a stochastic model, while anomalies occur in the low probability regions of the stochastic model  X  X 5]. However, a simple statistical anomaly det ection is insufficient to spot interesting anomalies effectively because we cannot distinguish abnormal records caused by anomalous behaviors from those caused by noise. To tackle this difficulty, we propose a novel framework MultiAspectSpotting that can spot anomalous behaviors by conducting two-step different tensor decompositions (Fig. 1): 1. Create a tensor X in which m th mode corresponds to m th attribute of a 2. Create a binary tensor B in which 1s indicate individual anomalies, and spot
Deciding threshold t to pick up individual anomalies in the first step is very important. Our strategy is to set the ratio of noise records Z , and to decide threshold t so that the ratio Z of distinct records is picked up as individual anomalies. We assume that a specific ra tio of records are caused by noise, and that the number of records caused by anomalous behavior is relatively small. If no groups are spotted in the second step, we conclude that the dataset is not affected by anomalous behaviors.

Now we do not have a clear strategy of the parameter settings of R , S ,and Z , and there is a big room for improvement of our framework. However, in Section 4 we show we can achieve better results by using R&gt; 1or S&gt; 0 than using R =1 (assuming a single Poisson distribution) or S = 0 (without the second step). Moreover, we show the selection of Z does not dramatically affect the results of spotting anomalous behaviors. 3.4 A Statistical Anomaly Detection Approach We describe details of the first step. The probability of the number of records of i to be x i in a fixed interval of time can be modeled as the Poisson distribution in which the cumulative probability function is where  X  i is the Poisson parameter equal to t he expected number of the records of i caused by ordinary behaviors. Anomaly score is calculated as We consider a distinct record of i to be an individual anomaly if the anomaly score is higher than a threshold t .Also, F ( x i , X  i ) can be easily computed with the incomplete gamma function. As  X  i is the expected number of records of i , we can estimate  X  i as where  X  is total number of records and p ( m ) i be i m , under the assumption of independence among the attributes. p ( m ) i estimated as p ( m ) i value is i m . Alternatively, we can assume the distribution as the mixture of R Poisson distributions. The Poisson parameters can be estimated as under the assumption of independence among the distributions, where  X  r is the expected total number of records emerged from r th distribution and p ( m ) ri probability of m th value to be i m in r th distribution. We can estimate  X  r and p minimize the generalized Kullback-Leibler divergence, i.e. , i  X  i  X  x i log X  i [3]. The details of PTF are outside the scope of this paper. Note that PTF of R =1 is equivalent to calculating the parameters of equation (3). 3.5 Spotting Anomalous Behaviors by Tensor Decomposition In the second step, we try to find S product sets D s = { ( i 1 ,...,i M ) | i m  X  d 1 ,...,S ), such that each product set contains as many individual anomalies as possible. We propose DenseSpot , a tensor decomposition approach (Algorithm 1). DenseSpot construct a binary tensor B of order M in which an entry b i is The aim of DenseSpot is to obtain a rank-S tensor which minimize B X  X  ,where c ( m ) s are binary vectors. However, the decision ver-sion of this problem is a NP-hard problem similar to Boolean Tensor Factoriza-which minimize B  X   X  C ,where  X  c ( m ) s are real-value vectors. This is a relaxation problem of the above problem, and we can obtain a solution by conducting CP Decomposition [4]. After that, DenseSpot checks entries in s th component of  X  C corresponding to individual anomalies ( i 1 ,...,i M ) and puts 1 on i m th element of c ( m ) s if the entries are greater than a threshold h . Finally, DenseSpot selects h , which minimizes B  X  C and returns those C calculated by the h .Wecan easily calculate B  X  X  2 as B 2  X  2 B , C + C 2 .Aset d ( m ) s can be created by selecting value 1 entries of c ( m ) s .
 Also, Boolean Tensor Factorization [12] might be a good solution for this. Even though this could improve the efficiency of our method, we explain how our simple heuristics can perform better than baseline methods in Section 4. In this section, we present experimental results on the accuracy and scalability of our methods. The running example in this section comes from network traffic logs that consist of packet traces in an enterprise network (LBNL/ICSI Enterprise Tracing Project 1 ). We abbreviate them as LBNL logs. Each trace in the logs is a Algorithm 1. DenseSpot triplet of { source IPs (srcIP) , destination IPs (dstIP) ,and port number (port) } , which can be represented as a 3-mode tensor. First, we evaluate the accuracy of spotting anomalous behaviors by using 10 largest LBNL logs added with synthesized anomalies. Then we evaluate the scalability by using many LBNL logs of various numbers of records.

MultiAspectSpotting is implemented in the MATLAB language, and we use implementations of PTF ( cp apr )and CP Decomposition ( cp als ), publicly avail-able in MATLAB Tensor Toolbox [13]. All the experiments are performed on a 64-bit Windows XP machine with four 2.8GHz cores and 8GB of memory. 4.1 Putting Synthesized Anomalies on Datasets We create some synthesized anomalies and add into 10 largest LBNL logs, and evaluate how effectively our method can spot these anomalies. These LBNL logs have about 900 , 000 to 9 , 000 , 000 records and 15 , 000 to 50 , 000 distinct ports. Each distinct record is repeated about 50 to 350 times in average, and the standard deviation is about 1 , 000 to 22 , 000.
 Given parameters of volume V , density D and maximum number P ,wecreate N groups of abnormal records as follows: (1) For e ach group, we randomly select three values s , d , p between 0 and 1, and decide the number of srcIPs and dstIPs and ports in accordance with the rat io of three selected values, so that sdp is ceiling function. (2) " VD # distinct records are rando mly selected for each group, and (3) the number of each record is decided randomly between 1 and P .We test for V = 50, D =0 . 1 , 0 . 3 , 0 . 5 , 0 . 7 , 0 . 9, P = 500, and N = 10. 4.2 Methods Compared We compare the accuracies in spotting synthesized anomalies among the follow-ing methods: MASP-Multi MultiAspectSpotting with R =10and S = 20.
 MASP-Single MultiAspectSpotting with R =1and S = 20, which is equiva-DS-Only Conducting just DenseSpot of S = 20 by picking up all distinct SC-DS Usingameasureof suspicious coincidence proposed by Barlow [1]. For
Note that we have tried several methods similar to SC-DS , such as those using the maximum value of r , or those considering records with lower r as anomalous, or those using the ratio r = P ( A, B, C ) / ( P ( A ) P ( B ) P ( C )) where P ( A ), P ( B ), P ( C )and P ( A, B, C ) correspond to attributes A , B and C , but these variations have obtained far worse results than SC-DS (not shown). 4.3 Accuracy of Spotting Synthesized Anomalies We apply the above methods to LBNL logs added with synthesized anomalies and compare a group of records spotted by each method with a group of syn-thesized anomalies. We conduct chi-square tests of independence, which assess whether these two groups are independent of each other. In short, given these where n is the total number of distinct records, a is the number of common dis-tinct records between two groups, e and g are the numbers of distinct records of two groups. If  X  2 is greater than a value of p-value at 0 . 05 of the chi-squared dis-tribution for 1 degree of freedom, we c onclude that the method has successfully spotted the synthesized anomalous group.
 Fig. 2 is the number of groups spotted by each method. MASP-Multi and MASP-Single can spot many more groups than DS-Only , which suggests the statistical anomaly detection in the first step works efficiently. However, SC-DS is worse than DS-Only , which suggests the measure of suspicious coincidence is not good at detecting the anomalies we consider in this paper. Moreover, MASP-Multi is better than MASP-Single , which indicates we can model ordinary behaviors better by using a mixture of Poisson distributions. Overall, the more density grows, the better MASP-Multi and MASP-Single can spot than DS-Only and SC-DS . Moreover, the results of MASP-Multi and MASP-Single do not dramatically differ between Z =0 . 01 (Fig. 2 left) and Z =0 . 1 (Fig. 2 right), especially for higher density such as P =0 . 7 , 0 . 9. 4.4 Details of Accuracy We detail the effectiveness of each step. For the first step, we show the area under the ROC curve (AUC) of each method in detecting distinct synthesized anomalies out of all distinct records at various settings of Z (Fig. 3 left). Overall, AUCs of MASP-Multi and MASP-Single are better than those of SC-DS ,and do not become much worse as density grow, whereas AUCs of SC-DS become much worse. These indicate that this statistical anomaly detection is a better strategy at least in detecting anomalie s described here. There are no signifi-cant differences between MASP-Multi and MASP-Single in view of AUCs. For the second step, we select as many record s with the highest anomaly scores as the total number of individual anomalies DenseSpot has detected, which we call TopRecords .Wecomparethe precision of detecting synthesized anomalies out of individual anomalies between DenseSpot and TopRecords .The precision of DenseSpot and TopRecords are calculated as p/k and q/k ,where p is the total number of distinct synthesized anomalies that DenseSpot has detected, q is the number of those TopRecords has selected, and k is the total number of indi-vidual anomalies that DenseSpot has detected. Fig. 3 (right) shows precisions on each method ( Z =0 . 01). The precisions of DenseSpot are much better than those of TopRecords on MASP-Multi and MASP-Single for higher density .This means the synthesized anomalies do not have very high anomaly scores among individual anomalies, whereas DenseSpot can pick up these synthesized anoma-lies, especially for higher density. Additionally, the precisions of DenseSpot on MASP-Multi are better than those on MASP-Single , which indicates that the difference in the number of Poisson distributions in the first step strongly affects the second step, even though differences in AUCs are very small. In addition, the precisions of DenseSpot are worse than those of TopRecords on SC-DS , possibly due to the poor accuracy of the suspicious coincidence in the first step. 4.5 Scalability We conduct experiments for scalability on 123 different LBNL logs with various numbers of records, from less than 100 to more than 9 , 000 , 000. As shown in Fig. 4, computation time of PTF (left) and DenseSpot (right) increases linearly along with the number of non-zero ent ries in the tensor (entries of 1 for Dens-eSpot ) multiplied by the number of iterations of cp apr and cp als . These results are consistent with these alternating optimization algorithms implemented for sparse tensor [4,3] and suggest that these two steps of our framework scale lin-early along with the number of distinct records in the dataset. We present our experimental results on two sets of real world data: intrusion detection system logs and web-access logs ( R = 20, S = 20, and Z =0 . 1). We cannot mention the names of the companies from whom we have obtained these datasets because of the business relationship. Table 2 summarizes these datasets. 5.1 Intrusion Detection System Logs We apply our method to IDS logs of a crowd system of an IT company. We analyze inbound logs on Dec 2011, that is, suspicious packets sent from outside the crowd system. Each record repres ents a report which has attributes of { source IP (srcIP) , destination IP (dstIP) , port number (port) ,and attack type (type) } .
Table 3(a) summarizes the five largest groups of anomalous records spotted by our method. The descriptions are characteristics of these groups guessed by a specialist knowledgeable about the IDS of this crowd system. These include several kinds of attacks: attacks from many srcIPs including suspicious FTP login trials(#2), attacks on many dstIPs (#1,#4), attacks on many port numbers (#3), and attacks from several srcIPs of various attack types (#5). For example, the group #3 indicates that an outside IP has attacked many port numbers of an inside IP with a specific attack type, and that these attacks are remarkable because they are very rare events. Moreover, it is hard for analysts to notice the existence of this group of attacks because the number of records of this group is almost 0.02% of the total number of records within this dataset. 5.2 Web Access Logs We also apply our method to web-access logs of a web-service company on Jan 10, 2013. Each record has attributes of { hour , IP , URL ,and UserID } which means an access on the URL by the UserID from the IP at the hour of a day. The engineers at this company want to find an y strange accesses within web-access logs and surprising or illegal usage of their web pages.

Table 3(b) summarizes the five largest groups of anomalous records spotted by our method, with descriptions of characteristics of these groups guessed by a specialist knowldgeable about the web site. For example, the group #2 is a point-gathering group, in which two users have strangely accessed a set of URLs many times from a IP continuously from 16 pm to 17 pm of this day. By accessing these URLs, users can obtain points that can be exchanged for some gifts, so the user who accesses just for gathering points illegally is suspicious. We proposed a novel framework MultiAspectSpotting that can effectively spot anomalous behaviors by leveraging a two-step approach of a different kind of tensor decomposition. Experimental results of synthesized anomalies show our method can spot groups of individual anomalies more effectively than some base-line methods and can be improved by using PTF . The effectiveness of our method is achieved thanks to the combination of the accuracy of statistical anomaly de-tection in the first step and the ability of gathering individual anomalies in the second step, even though it might become harder for our method to model ordinary behaviors as the number of the attributes grows, i.e. , the dataset be-comes sparser. Moreover, experimental results on real world data proved that our method could spot interesting patte rns within IDS logs and web-access logs.
