 Optical flow refers to the deformation of the domain of an image that results from ego-or scene motion. It is, in general, different from the motion field , that is the projection onto the image plane of the spatial velocity of the scene [28], unless three conditions are satisfied: (a) Lambertian re-flection, (b) constant illumination, and (c) constant visibility properties of the scene. Most surfaces with benign reflectance properties (diffuse/specular) can be approximated as Lambertian almost ev-erywhere under sparse illuminants (e.g., the sun). In any case, widespread violation of Lambertian reflection does not enable correspondence [23], so we will embrace (a) as customary. Similarly, (b) constant illumination is a reasonable assumption for ego-motion (the scene is not moving relative to the light source), and even for objects moving (slowly) relative to the light source. 1 Assumption (c) the optical flow literature, because in the limit where two images are sampled infinitesimally close in time, there are no occluded regions, and one can focus solely on motion discontinuities. Thus, most variational motion estimation approaches provide an estimate of a dense flow field at each location on the image domain, including occluded regions. Alas, in occluded regions, the problem is not that optical flow is discontinuous, or forward-backward inconsistent; it is simply not defined. Motion in occluded regions can be hallucinated ; However, whatever motion is assigned to an occluded region cannot be validated from the data. In defense of these methods, it can be argued that, even without taking the limit, for small parallax (slow-enough motion, or far-enough objects, or fast-enough tem-poral sampling) occluded areas are small. However, small does not mean unimportant, as occlusions are critical to perception [8] and a key for developing representations for recognition [22]. For this reason, we focus on issues of visibility in optical flow computation. We show that forgoing assumption (c) and explicitly representing occlusions is not only conceptually correct, but also al-gorithmically advantageous, for the resulting optimization problem can be shown to become convex once occlusions are explicitly modeled. Therefore, one can guarantee convergence to a globally optimal solution regardless of initial conditions (sect. 2). We adapt Nesterov X  X  efficient optimization scheme to our problem (sect. 3), and test the resulting algorithm on benchmark datasets (sect. 4), including evaluation of occlusion detection (sect. 1.2). 1.1 Related Work The most common approach to handling occlusions in the optical flow literature is to define them as regions where forward and backwards motion estimates are inconsistent [19, 1]. Most approaches return estimates of motion in the occluded regions, where they cannot be invalidated: As we have already pointed out, in an occluded region one cannot determine a motion field that maps one image onto another, because the scene is not visible in one of the two. Some approaches [11, 4], while also exploiting motion symmetry, discount occlusions by weighting the data fidelity with a monotonically decreasing function. The resulting problem is non-convex, and therefore the proposed alternating minimization techniques can be prone to local minima. An alternate approach [15, 14, 25] is to hard. Various approximate solutions using combinatorial optimization require fine quantization and, therefore, suffer from a large number of labels which results in loose approximation bounds. Another class of methods uses the motion estimation residual to classify a location as occluded or visible wither with a direct threshold on the residual [30] or with a more elaborate probabilistic model [24]. In each case, the resulting optimization is non-convex. 1.2 Evaluation Optical flow estimation is a mature area of computer vision, and benchmark datasets have been de-veloped, e.g., [2]. Unfortunately, no existing benchmark provides ground truth for occluded regions, nor a scoring mechanism to evaluate occlusion detection performance. Motion estimates are scored even in the occluded regions, where the data does not support them. Since our primary goal is to detect occlusions, we have produced a new benchmark by taking a subset of the training data in the Middlebury dataset, and hand-labeled occluded regions. We then use the same evaluation method of the Middlebury for the (ground truth) regions that are co-visible in at least two images. This provides a motion estimation score. Then, we provide a separate score for occlusion detection, in terms of precision-recall curves. In this section, we show how the assumptions (a)-(b) can be used to formulate occlusion detection and optical flow estimation as a joint optimization problem. Let I : D  X  R 2  X  R +  X  R + ; ( x,t ) 7 X  I ( x,t ) be a grayscale time-varying image defined on a domain D . Under the assumptions (a)-(b), the relation between two consecutive frames in a video { I ( x,t ) } T t =0 is given by where w : D  X  R +  X  R 2 ; x 7 X  w ( x,t ) . = x + v ( x,t ) is the domain deformation mapping I ( x,t ) onto I ( x,t + dt ) everywhere except at occluded regions . Usually optical flow denotes the incremental displacement v ( x,t ) . = w ( x,t )  X  x . The occluded region  X  can change over time depending on the temporal sampling interval dt and is not necessarily simply-connected; so even if we call  X  the occluded region (singular), it is understood that it can be made of several disconnected portions. Inside  X  , the image can take any value  X  :  X   X  R +  X  R + that is in general unrelated to I ( w ( x ) ,t + dt ) | of the scene and its motion (i), and because the additive term n ( x,t ) compounds the effects of a large number of independent phenomena 3 and therefore we can invoke the Law of Large Numbers (ii), in general we have that i.e., the additive uncertainty is normally distributed in space and time with an isotropic and small variance  X  &gt; 0 . We define the residual e : D  X  R on the entire image domain x  X  D , via which we can write as the sum of two terms, e 1 : D  X  R and e 2 : D  X  R , also defined on the entire domain D in such a way that there, including zero, which we will assume henceforth. We can then write, for any x  X  D , will use this as an inference criterion for w , seeking to optimize a data fidelity term that minimizes the number of nonzero elements of e 1 (a proxy of the area of  X  ), and the negative log-likelihood of n . not know anything about e 1 other than the fact that it is sparse, and that what we are looking for is  X  ( X )  X  e 1 , where  X  : D  X  R + is the characteristic function that is non-zero when x  X   X  , i.e., where the occlusion residual is non-zero. So, the data fidelity term depends on w but also on the characteristic function of the occlusion domain  X  . 5 For a sufficiently small dt , we can approximate, for any x  X  D \  X  , where the linearization error has been incorporated into the uncertainty term n ( x,t ) . Therefore, following the same previous steps, we have Since we typically do not know the variance  X  of the process n , we will treat it as a tuning param-eter, and because  X  data or  X  X  data yield the same minimizer, we have attributed the multiplier  X  to the second term. In addition to the data term, because the unknown v is infinite-dimensional and the problem is ill-posed, we need to impose regularization, for instance by requiring that the total variation (TV) be small where v 1 and v 2 are the first and second components of the optical flow v ,  X  is a multiplier factor to weight the strength of the regularizer and the weighted isotropic TV norm is defined by is desirable in the context of occlusion detection because it does not penalize motion discontinuities significantly. The overall problem can then be written as the minimization of the cost functional  X  =  X  data +  X  reg , which is In a digital image, the domain D is quantized into an M  X  N lattice  X  , so we can write (12) in matrix form as: where e 1  X  R MN is the vector obtained from stacking the values of e 1 ( x,t ) on the lattice  X  on top of one another (column-wise), and similarly with the vector field components { v 1 ( x,t ) } x  X   X  and { v 2 ( x,t ) } x  X   X  stacked into MN -dimensional vectors v 1 ,v 2  X  R MN . The spatial deriva-tive matrix A is given by A = [ diag (  X  x I ) diag (  X  y I )  X  I ] , where I is the MN  X  MN dimensional vectors u  X  R MN , k u k ` 2 = p  X  u,u  X  , k u k ` 0 = |{ u i | u i 6 = 0 }| and k u k TV = { g In practice, (13) is NP-hard. Therefore, as customary, we relax it by minimizing the weighted -` 1 norm of e 1 , instead of ` 0 , such that where W is a diagonal weight matrix and k u k ` 1 = P | u i | . When W is the identity, (14) becomes a standard convex relaxation of (13) and its globally optimal solution can be reached efficiently [27]. However, the ` 0 norm can also be approximated by reweighting ` 1 , as proposed by Candes et al. [5], The data term of the standard (unweighted) relaxation of (13) can be interpreted as a Huber norm [10]. We favor the more general (14) as the resulting estimate of e 1 is more stable and sparse. The model (9) is valid to the extent in which dt is sufficiently small relative to v (or v sufficiently is not the case, remedies must be enacted to restore proper sampling conditions [22] and therefore differentiate contributions to the residual coming from sampling artifacts (aliasing), rather than oc-clusions. This can be done by solving (14) in scale-space, as customary, with coarser scales used to scale.
 changes [21, 16, 26, 13]. Note that, even if the model (5) appears similar, the priors on e 1 are rather different: Sparsity in our case, smoothness in theirs. While sparsity is clearly motivated by (i), for illumination changes to be properly modeled, a reflectance function is necessary, which is absent in all models of the form (5) (see [23].) In this section, we describe an efficient algorithm to solve (14) based on Nesterov X  X  first order scheme [17] which provides O (1 /k 2 ) convergence in k iterations, whereas for standard gradient descent, it is O (1 /k ) , a considerable advantage for a large scale problem such as (14). To simplify the notation In order to implement this scheme, we need to address the nonsmooth nature of ` 1 in the computation of  X   X  [18], a common problem in sparse optimization [3]. We write  X  ( v 1 ,v 2 ,e 1 ) as max k u k  X   X  1  X  u,e 1  X  in terms of its conjugate. [18] proposes a smooth approximation and shows that (15) is differentiable and  X  e 1  X   X  2 ( e 1 ) = u  X  , where u  X  is the solution of (15): weighted horizontal and vertical differentiation operators , and u  X  has the form [ u 1 ,u 2 ] where  X  v 2  X  4 can be computed in the same way. Once we have computed each term,  X   X  ( v 1 ,v 2 ,e 1 ) is We also need the Lipschitz constant L to compute the auxiliary variables y k and z k to minimize  X  . Since k G T G k 2 is bounded above [7] by 8 , given the coefficients  X  and  X  , L is given by A crucial element of the scheme is the selection of  X  . It trades off accuracy and speed of conver-gence. A large  X  yields a smooth solution, which is undesirable when minimizing the ` 1 norm. A small  X  causes slow convergence. We have chosen  X  empirically, although the continuation algo-rithm proposed in [3] could be employed to adapt  X  during convergence. To evaluate occlusion detection (Sect. 1.2), we start from [2] and generate occlusion maps as fol-lows: for each training sequence, the residual computed from the given ground truth motion is used as a discriminant to determine ground truth occlusions, fixing obvious errors in the occlusion maps by hand. We therefore restrict the evaluation of motion to the co-visible regions, and evaluate oc-clusion detection as a standard binary classification task. We compare our algorithm to [29] and [14], the former is an example of robust motion estimation and the latter is a representative of the approaches described in Sect. 1.1.
 In our implementation 6 , we first solve (14) with standard relaxation ( W is the identity) and then with reweighted-` 1 . To handle large motion, we use a pyramid with scale factor 0 . 5 and up to 4 levels;  X  and  X  are fixed at 0 . 002 and 0 . 001 (Flower Garden) and 0 . 0006 and 0 . 0003 (Middlebury) respectively. To make comparison with [29] fair, we modify the code provided online 7 to include anisotropic regularization (Fig. 1). Note that no occlusion is present in the residual of the motion field computed by TV-L1, and subsequently the motion estimates are less precise around occluding boundaries (top-left corner of the Flower Garden, plane in the left in Venus).
 Figure 1: Comparison with TV-L1 [29] on  X  X enus X  from [2] and  X  X lower Garden. X  The first column Other frames of the Flower Garden sequence are shown in Fig. 2, where we have regularized the occluded region by minimizing a unilateral energy on e 1 with graph-cuts. We have also compared Figure 2: Motion estimates for more frames of the Flower Garden sequence (left), residual e (mid-dle), and occluded region (right). motion estimates obtained with our method and [29] in the co-visible regions for the Middlebury dataset (Table 1). Since occlusions can only be determined at the finest scale absent proper sam-pling conditions, in this experiment we minimize the same functional of [29] at coarse scales, and switch to (14) at the finest scale. To evaluate occlusion detection performance, we again use the Middlebury, and compare e 1 to ground truth occlusions using precision/recall curves (Fig. 3) and average precision values (Table 2). We also show the improvement in detection performance when we use reweighted-` 1 , in Table 2. We have compared our occlusion detection results to [14], us-ing the code provided online by the authors (Table 3). Comparing motion estimates gives an unfair AAE (ours) 4.37 5.42 2.35 2.32 5.72 3.60 6.41 AAE (L1TV) 5.28 4.49 2.44 3.45 7.66 3.57 7.12 AEPE (ours) 0.30 0.18 0.19 0.16 0.59 0.39 0.84 AEPE (L1TV) 0.33 0.13 0.20 0.24 0.74 0.46 0.89 Table 1: Quantitative comparison of our algorithm with TV-L1 [29]. Average Angular Error (AAE) and Average End Point Error (AEPE) of motion estimates in co-visible regions. Figure 3: Left to right: Representative samples of motion estimates from the Middlebury dataset, labeled ground-truth occlusions, error term estimate e 1 , and precision-recall curves for our occlusion detection. advantage to our algorithm because their approach is based on quantized disparity values, yielding lower accuracy. ` 1 0.67 0.48 0.55 0.70 0.60 0.72 0.80 reweighted-` 1 0.69 0.49 0.57 0.70 0.61 0.73 0.80 Table 2: Average precision of our approach on Middlebury data with and without re-weighting. It takes 186 seconds for a Matlab/C++ implementation of Nesterov X  X  algorithm to converge to a solution on a 288  X  352 frame from Flower Garden sequence. We have also compared Nesterov X  X  algorithm to split-Bregman X  X  method [9] for minimization of (14) in terms of convergence speed and reported the results in [20].
 Precision [14] 0.61 0.46 0.68 0.72 0.79 0.26 0.56 Recall [14] 0.66 0.20 0.20 0.55 0.45 0.50 0.51 Precision(ours) 0.69 0.91 0.96 0.96 0.86 0.95 0.94 Table 3: Comparison with [14] on Middlebury. Since Kolmogorov et al. provide a binary output, we display our precision at their same recall value. We have presented an algorithm to detect occlusions and establish correspondence between two im-ages. It leverages on a formulation that, starting from standard assumptions (Lambertian reflection, constant diffuse illumination), arrives at a convex optimization problem . Our approach does not as-sume a rigid scene, nor a single moving object. It also does not assume that the occluded region is simply connected: Occlusions in natural scenes can be very complex (see Fig. 3) and should therefore, in general, not be spatially regularized. The fact that occlusion detection reduces to a two-phase segmentation of the domain into either occluded (  X  ) or visible ( D \  X  ) should not confuse the reader familiar with the image segmentation literature whereby two-phase segmentation of one object (foreground) from the background can be posed as a convex optimization problem [6], but breaks down in the presence of multiple objects, or  X  X hases. X  Note that in [6] the problem can be made convex only in e 1 , but not jointly in e 1 and v . We focus on inter-frame occlusion detection; temporal consistency of occlusion  X  X ayers X  was addressed in [12].
 The limitations of our approach stand mostly in its dependency from the regularization coefficients  X  and  X  . In the absence of some estimate of the variance coefficient  X  , one is left with tuning it by trial-and-error. Similarly,  X  is a parameter that, like in any classification problem, trades off missed detections and false alarms, and therefore no single value is  X  X ptimal X  in any meaningful sense. These limitations are shared by most variational optical flow estimation algorithms.
 Acknowledgement : This work was supported by AFOSR FA9550-09-1-0427, ARO 56765-CI, and ONR N00014-08-1-0414.

