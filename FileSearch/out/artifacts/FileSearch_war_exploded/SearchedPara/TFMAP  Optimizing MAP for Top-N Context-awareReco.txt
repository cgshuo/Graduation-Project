 In this paper, we tackle the problem of top-N context-aware recommendation for implicit feedback scenarios. We frame this challenge as a ranking problem in collaborative filtering (CF). Much of the past work on CF has not focused on eval-uation metrics that lead to good top-N recommendation lists in designing recommendation models. In addition, previous work on context-aware recommendation has mainly focused on explicit feedback data, i.e. , ratings. We propose TFMAP, a model that directly maximizes Mean Average Precision with the aim of creating an optimally ranked list of items for individual users under a given context. TFMAP uses tensor factorization to model implicit feedback data ( e.g., purchases, clicks) with contextual information.

The optimization of MAP in a large data collection is com-putationally too complex to be tractable in practice. To ad-dress this computational bottleneck, we present a fast learn-ing algorithm that exploits several intrinsic properties of av-erage precision to improve the learning efficiency of TFMAP, and to ensure its scalability. We experimentally verify the effectiveness of the proposed fast learning algorithm, and demonstrate that TFMAP significantly outperforms state-of-the-art recommendation approaches.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Collaborative filtering, context-aware recommendation, mean average precision, implicit feedback, tensor factorization
Collaborative Filtering (CF) methods are at the core of most recommendation engines. Most of the data traces left by online users come in the form of implicit feedback, i.e. , we know which items a user interacted, e.g. , purchased, used, or  X 
This work was conducted when the first author was an intern at Telefonica Research, Barcelona.
 clicked, etc., and possibly also the count of each interaction; however, we do not have an explicit rating, i.e. , a relevance score, that represents the strength of the user X  X  interest in that item [13]. Learning the suggestion function from im-plicit feedback data, such as purchase or usage logs, can either be considered a classification problem, where items are classified to relevant or irrelevant, or a ranking problem where an optimal list of items is to be computed.

Top-N recommendation has recently attracted increased research interest because it generates a ranked list of results, which is directly connected to the end-user satisfaction [9]. Conventionally, recommender systems have been optimized to produced scores. A predicted score reflects the system X  X  hypothesis of the strength of a particular user X  X  preference for a particular item. In an overwhelmingly large number of recommender system use scenarios, users do not want prefer-ence strength information on all the items in the collection, but rather a compact list of top recommended items.
Although ranking-oriented CF approaches have been pro-posed for explicit feedback domains, e.g., EigenRank [19] and CoFiRank [34], those approaches are difficult to apply to implicit feedback domains, since they require training exam-ples that are derived from the users ratings on various items. In particular, implicit feedback is often binary in nature. We notice that in top-N recommendation, the quality of a rec-ommendation list that contains items of binary relevance can be quantified using Mean Average Precision (MAP), a well known evaluation measure in the information retrieval (IR) community. MAP provides a single-figure measure of quality across recall levels, has especially good discrimina-tion and stability properties, and roughly corresponds to the average area under the precision-recall curve [21]. It is thus a good measure of performance when a short list of the most relevant items is shown to users [27]. A state-of-the-art approach, Bayesian Personalized Ranking (BPR) [24], has been recently proposed to train recommendation mod-els by optimizing the measure of the Area Under the ROC Curve (AUC), which is based on pairwise comparisons be-tween items. Note that in the AUC measure mistakes at the top of the list carry equal weight to mistakes in the bottom of the recommendation list. In contrast to AUC, MAP is a list-wise measure, for which mistakes in the recommended items at the top of the list carry a higher penalty than mistakes at the bottom of the list [10, 39]. Users typically consider only few (5 -10) top-ranked items in the recommendation list, it is thus particularly important to get the recommendations at the top of the list right. The top-heavy bias of MAP is thus particularly important in the recommendation prob-lem. For this reason, we propose a recommendation model for implicit feedback domains by directly optimizing MAP.
Typically, recommender systems have access to additional information about the user-item interactions, such as the context that is associated with the user-item interaction [1]. The context could be the location where the user listened to a song on his/her mobile phone or the time of the user-item interaction. Context-aware recommendations (CARs) are a new paradigm that can significantly improve the recom-mendation relevance and quality, compared to conventional recommendations solely based on user-item interactions [1, 4, 14, 25]. In this paper we present a generic CF model that is based on a generalization of matrix factorization to ad-dress context-aware recommendations. We extend the con-cept of matrix factorization to tensor factorization . A tensor is a generalization of the matrix concept to multiple dimen-sions. In the example above the user-item two-dimensional matrix is converted into a three-dimensional tensor of user-item-location interactions (see Figure 1).

Two key issues need to be considered in CARs: (1) Con-text Integration . The contextual information needs to be integrated in the recommendation model to be able to bene-fit the quality of the recommendation; and (2) Optimiza-tion Function . The recommendation model needs to be optimized under an objective function that corresponds to the recommendation quality for each user under each given context. Previous work in CARs has extensively studied the context integration issue, such as using tensor factor-ization [14] (TF) and factorization machines [25]. However, the second issue ( optimization function ) has only been ad-dressed in a simplistic way. In the work of [14] and [25], the objective function in the recommendation model consists of minimizing the rating prediction error. This is an effective strategy where explicit feedback data is available from users, however, optimizing this objective is infeasible for scenarios with only implicit feedback data. In these scenarios, the quality of a recommendation list for a user is solely depen-dent on the positions of the relevant items in the list under the given context.

Here we propose a new context-aware recommendation ap-proach based on tensor factorization for MAP maximization (TFMAP) that is designed to work with implicit feedback datasets. Taking insights from the area of learning to rank , TFMAP directly optimizes MAP for learning the model pa-rameters, i.e. , latent factors/features of users, items and context types, which are then used to generate item rec-ommendations for users under different types of context.
Directly optimizing MAP across all the users in a data collection is an expensive and non-trivial task. Therefore, we also propose a fast learning algorithm that exploits sev-eral properties of the average precision (AP) measure. We show that the computational complexity of the fast learning algorithm for TFMAP is linear in the number of observed items in a given data collection. Our contributions in this paper can be summarized as: 1) We propose a new gen-eralized CF approach, TFMAP, that directly optimizes for MAP and leverages contextual information when available. We demonstrate that TFMAP outperforms state-of-the-art context-aware and context-free approaches. We observe sig-nificant improvements not only in MAP but also in precision at the top-N ranked recommendations. 2) To the best of our knowledge, TFMAP is also the first approach that can exploit datasets with implicit user feedback and contextual information. 3) We propose a fast learning algorithm that ensures the scalability of TFMAP and that exploits several properties of the AP measure.

The paper is organized as follows: in Section 2 we dis-cuss the most relevant previous work and position our paper with respect to it. The research problem and the terminol-ogy used throughout the paper are presented in Section 3. In Section 4, we present the detail of TFMAP and the fast learning algorithm. Our experimental evaluation is reported in Section 5. Finally, Section 6 summarizes our main con-tributions and highlights a few areas of future work.
The work in this paper closely relates to three research areas: CF with implicit feedback, context-aware recommen-dation, and learning to rank. In the following, we present the most relevant related work in each of them.

CF with Implicit Feedback. Most CF approaches in the literature deal with the rating prediction problem, as de-fined in the Netflix prize competition 1 . A common approach to CF is to fit a latent factor model to the data, e.g. , latent semantic models [12, 28], and matrix factorization models, which learns a latent feature/factor vector for each user and item in the dataset such that the inner product of these features minimizes an explicit or implicit loss function [5]. Factor models have been shown to perform well in terms of predictive accuracy and scalability [2, 18, 26].

One of the first studies that used latent factor models for large implicit feedback datasets was introduced in [13]. It uses a least squares loss function and exploits the structure of the data (dominated by zero entries that correspond to negative preference), such that observed user-item interac-tions are weighted proportionately to the count of the in-teractions. Some extensions following this approach are in-troduced in [23] and [29]. In [24] a factorization approach based on the optimization of a smoothed pairwise ranking objective function was proposed. Optimizing the proposed objective function corresponds to maximizing the AUC. In this paper, we propose to learn a recommendation model by optimizing MAP, whose top-bias property is a significant advantage over AUC for recommender systems, as discussed in Section 1. In addition, our work is substantially different from the aforementioned work, since various types of con-textual information are exploited for the recommendation.
Context-aware recommendation (CAR). Early work in CAR utilized contextual information for pre-processing, where context drives data selection, or post-processing, where context is used to filter recommendations [1, 4]. Recent work has focused on building models that integrate contextual in-formation with the user-item relations and model the user, item and context interactions directly. Two state-of-the-art approaches have been proposed to date, one based on tensor factorization [14, 35] and the other on factorization machines [25] (FM). However, both approaches have been designed for the explicit rating prediction problem.
In this paper we utilize a tensor factorization approach, i.e. , the CANDECOMP/PARAFAC (CP) model [15], to represent the interactions among the user, the item and the context type. Our approach includes two substantial in-novations, compared to the state of the art in CARs: (1) It targets recommendation scenarios with implicit feedback; and (2) it takes the evaluation metric (MAP) into account for learning the recommendation model.

Note that recommendation approaches have been proposed to take into account additional information (also referred as metadata, side information, or attributes) about users or items, e.g. , collective matrix factorization [30], localized fac-http://www.netflixprize.com/ tor models [3] and graph-based approaches [16]. However, this type of information would go beyond our definition of  X  X ontext X , since we refer to context as information that is as-sociated with both the user and the item at the same time. Finally, note that a recommended item set from a recom-mender is regarded as the  X  X ontext X  of user choice in the work of [38]. However, this type of context is still extracted from the user-item relations, and thus, does not fall in the scope of the context studied in this paper.

Learning to Rank. Learning to rank has been an at-tractive research topic in both the machine learning and the information retrieval communities [20]. Our work in this paper is closely related to recent research where proxies for common IR evaluation measures, such as NDCG and MAP, are used as the objective functions. The main difficulty of directly optimizing evaluation measures lies in their non-smoothness [7], i.e. , they are dependent on the rank values of ranked documents/items but not directly on the predicted relevance scores.

Ranking approaches can be broadly classified into two cat-egories, those that implicitly optimize the IR measure and those that formulate an explicit approximation of the mea-sure. LambdaRank [7] is a popular implicit optimization method, which was proposed to apply gradient descent on an implicit loss function, that is related to IR measures. Methods that explicitly optimize IR measures include struc-tured estimation techniques [32] that minimize convex upper bounds of loss functions based on evaluation measures [37], e.g. , SVM-MAP [39] and AdaRank [36]. In the case of CF, CoFiRank [34] introduced a matrix factorization method where structured estimation was used to minimize over a convex upper bound of NDCG. SoftRank [31] was the first approach that proposed an explicit smoothed version of an evaluation measure, in which a rank distribution was em-ployed, resulting in the expected values of document ranks that are smooth to the predicted relevance scores. In ad-dition, a more general extension of SoftRank was presented by Chapelle et al. [8].

In this paper, we also employ an explicit approximation of MAP, which is a smooth function of model parameters. Our work is different from aforementioned research, since we target context-aware recommendation rather than query-document search, and we propose a fast learning algorithm, which is critical for large-scale recommender systems.
The research problem studied in this paper is stated as follows: Given implicit feedback and contextual information on user-item interactions, recommend to each user and un-der a given context, an optimal (from a MAP perspective) item list.
 We denote the implicit feedback data from M users to N items under K types of context as a binary tensor Y , i.e. , a 3-dimensional tensor, with M  X  N  X  K entries which are denoted with y mik : (1) y mik = 1 indicates that user m has interacted ( i.e. purchased, used) with item i under context type k . We can thus assume that the user has a preference for this item; and (2) y mik = 0 indicates the absence of an interaction and thus the preference of user m to item i under context type k is unknown. | Y | denotes the number of nonzero entries in Y . Y mk denotes a binary vector that indicates the user m  X  X  preference on all the items under context type k .

As mentioned in Section 2, the main idea behind factor models is to fit the original user-item interaction matrix with a low rank approximation. In this work we use tensor fac-torization (TF) as a generalization of the classical matrix factorization methods that accommodates for the contex-tual information. The latent features are stored in three correspond to users, items, and context types, respectively. We use U m to denote a D -dimensional row vector, which represents the latent features for user m . Similarly, V resents the latent features of item i , and C k represents the latent features of context type k .

We use the CP model [15], as illustrated in Fig. 1, for tensor factorization, in which user m  X  X  preference to item i under context type k is factorized as the inner product of the latent feature vectors, as shown below:
Based on user X  X  m preference over all the items under context type k , we can then generate a recommendation list by ranking all the items in a descending order of the computed scores. Then, the AP of this list is defined as: where r mik denotes the rank of item i in the list of user m under context type k and I (  X  ) is an indicator function, which is equal to 1 if the condition is satisfied, and otherwise 0.
The MAP is defined as the average of AP across all the users and all the context types, as shown below: MAP = 1
In this section, we present the main technical contribu-tions of this paper: (1) our proposed smooth approximation of MAP , its optimization and associated complexity analy-sis; and (2) a novel fast learning algorithm for optimizing over the smooth MAP measure in a context-aware setting.
It is apparent from Eq. (2) and (3), that AP (or MAP) depends on the rankings of the items in the recommendation lists. The rankings of the items change in a non-smooth way with respect to the predicted user preference scores and thus, the AP measure ends up being a non-smooth function with respect to the latent features of users, items and context types. We thus cannot use any of the standard optimization methods that require smoothness in the objective function.
As previously mentioned, significant progress has been made in the area of learning to rank regarding the explicit optimization of evaluation metrics, such as MAP. The key issue is to approximate r mik and I ( r mjk  X  r mik ) in Eq. (2) and (3) by smoothed functions with respect to the model parameters, i.e. , U , V , and C .

Based on insights in [8], we approximate I ( r mjk  X  r mik by the following logistic function:
I where g ( x ) = 1 / (1 + e  X  x ). The basic assumption is that the condition of item j being ranked higher than item i is more likely to be satisfied, if item j has relatively higher relevance score than item i . The authors in [8] also proposed a sophis-ticated approximation for r mik , which, to the best of our knowledge, has not been deployed in practice. In the case of MAP, we argue it is not necessary to approximate r mik since only 1 /r mik is in use. For this reason, we propose to directly approximate 1 /r mik with another logistic function: Note that the larger the predicted relevance score f mik the closer g ( f mik ) gets to 1, resulting in a low value of r Reversely, the lower f mik , the larger is r mik . Substituting Eq. (4) and (5) into Eq. (3), we obtain a smoothed approx-imation of MAP: MAP = 1
Since Eq. (6) is smooth with respect to U m , V i , and C can now optimize it using standard methods, such as gradi-ent ascent. In order to avoid overfitting , we add the Frobe-nius norms of the latent factors for regularization. Hence, the resulting TFMAP objective function is given by: L ( U,V,C ) =
Note that we neglect the constant coefficient in MAP, since it has no influence on the optimization. Given a set of training data Y , a local maxima of Eq. (7) can be ob-tained by alternatively performing gradient ascent on one of the latent feature vectors at each step, while keeping the other latent vectors fixed. The gradients with respect to U , C , and V are given by Eq. (8  X  10). Note that for notation convenience, we have performed the following substitutions:  X  X   X  X   X  X   X  X  where denotes element-wise product, and g 0 ( x ) denotes the derivative of g ( x ). Note that since neither U m or C coupled with other latent feature vectors as in Eq. (6), the derivation of Eq. (8) and (9) is straightforward. However, V i is coupled with other latent feature vectors in Eq. (6), resulting in a more complicate derivation of Eq. (10). We leave the detailed derivation of Eq. (10) in the Appendix.
In order to understand the practical utility of TFMAP, we analyze the complexity of the learning process for one iteration. Given the data sparseness in the tensor Y and the fact that we usually have | Y | &gt;&gt; M,K , the computational complexity of calculating the gradients in Eq. (8) and (9) is O ( D | Y | ), which is linear to the number of observed user-item interactions in the given tensor. Hence, the computation of the gradients with respect to the latent user features and latent context features is tractable, and able to scale up for large-scale use cases. However, the complexity of Eq. (10) is O ( DN | Y | ). Considering that we usually have | Y | &gt;&gt; N , this complexity is even larger than quadratic in the number of items in the given collection. Thus, the computation of gradients regarding latent item features could be intractable in practice.

In the next section, we propose a novel fast learning algo-rithm to address the computational bottleneck in Eq. (10), reducing its complexity to O ( D | Y | ).
The proposed fast learning algorithm is outlined in Al-gorithm 1. Note that according to the definition of AP in Eq. (2), it is not necessary to optimize the latent features of all the items in order to maximize AP (as explained below).
The key idea of speeding up the learning process is to optimize, for each fixed pair of user m and context type k , the latent features of only a set of representative items, denoted as a buffer B mk .

The gradient of the objective in Eq. (7) with respect to the latent features of item i in B mk can be computed as:  X  X   X  X 
The computational complexity then depends on the size of the buffer, i.e. , the number of items selected for each pair of user-context type. When all items are included in the buffer, Eq. (11) is equal to Eq. (10), while selecting fewer items in the buffer results in lower complexity.

The key issue with this approach is finding the right items to include in the buffer, as the quality of the learning process and hence the resulting model directly depends on the items included in the buffer. The buffer needs to be constructed in such a way that it both reduces the computational complex-ity of the learning algorithm and conserves the necessary information to yield a high quality model.
Relevant Items. For each user in a given context, we first include in the buffer all the items that have been ob-served by the user in that context, i.e. , for which we have the user X  X  implicit feedback. These items are the basis for the computation of AP. Note that AP is defined based on the ranks of relevant items. Updating the latent features of relevant items should improve ( i.e. , reduce) their rankings, thus, resulting in improved AP.

Irrelevant Items. Note that the ranking of irrelevant items influences AP indirectly, since their rankings are rel-ative to the rankings of relevant items. Updating the latent features of irrelevant items will also improve ( i.e. , raise) their rankings, thus, resulting in overall improved AP.

However, in practice, there are many more irrelevant items than relevant items for a user under a given context. The quantity of irrelevant items thus becomes the computational bottleneck in the learning algorithm of TFMAP.

For this reason, we choose to select only a relatively small number of irrelevant items in the buffer, n mk , for user m and context type k . AP is a top-heavy list-wise ranking measure such that the lower the ranking of an item (the closer it is to the top of the list), the higher its influence in the final score. Top-ranked irrelevant items are the most influential items for AP optimization, yielding the following lemma:
Lemma 1. If we try to improve the AP of a ranking list by optimizing ( i.e. , raising) the ranks of n irrelevant items, then raising the ranks of the top n irrelevant items should yield the largest improvement in AP.
 The proof in the case of n = 1 is provided in the Appendix. The proof for the case of n &gt; 1 can be obtained in a similar way. Note that we could first sort all the irrelevant items for user m under context k in a descending order, according to the preference scores computed by the current model, i.e. , U m , V and C k in current iteration, and then select the top-ranked n mk irrelevant items into the buffer.

In this work, we choose the set of irrelevant items in the buffer, n mk , to be equal to the number of observed/relevant items for user m under context k , resulting in a total of 2 n items in the buffer.

We now optimize Eq. (7) for the latent features of the items within the buffer only. The complexity of Eq. (11) over each iteration is O (2  X  n 2 MKD ), where  X  n denotes the average number of observed items per user and context type. Note that we have  X  nMK = | Y | and | Y | &gt;&gt;  X  n . Therefore, the complexity of Eq. (11) is O ( D | Y | ), which is linear to the number of observed items in the given collection.
In order to select the top-ranked irrelevant items in each iteration, we need to make a prediction for each item and sort them according to the current predicted scores. Consid-ering that most recommender systems contain large numbers of items, the computational cost for the prediction and sort-ing process would be very high. For this reason, we propose to sample a small set of irrelevant items and to select the top-ranked irrelevant items within the sampled set into the buffer.

We can maintain the representativeness of the top-ranked irrelevant items from the sampled set by using a key property of AP: The items below the last relevant item in a ranked list have no contribution to AP . This property can be easily understood from the definition of AP (see Equation 2).
Therefore, for each user under a given context type, we first find the relevant item with the lowest score. This oper-ation is computationally cheap since the number of relevant items is usually very small. We then sample n s irrelevant items from those irrelevant items (assuming that most unob-served items are irrelevant) that have higher predicted rele-vance scores than the minimum predicted relevance score of the relevant items. This sampled set has higher probability to contain the globally top-ranked irrelevant items than a randomly sampled set. Note that the relevance scores are calculated by the model in each iteration. We illustrate the buffer construction for user m under context type k in an single iteration in Fig. 2.

In addition, since the model will become more accurate with each iteration, the minimum predicted score of the rel-evant items will also increase gradually. In other words, the position of the last relevant item in the ranked list will grad-ually move to the top of the list. As another by-product, this effect also helps to reduce the buffer construction time with each iteration. An experimental analysis confirming this property will be presented in Section 5.

Note that the sampling size for the irrelevant items does not only influence the buffer construction time, but also the quality of the learned latent item features. We investigate this tradeoff between buffer size (i.e., computational cost) and performance in Section 5.
Since Eq. (6) is an approximation of MAP for the training data Y , we can use MAP (given by Eq. 3) as another termi-nation criterion apart from conventional criteria, such as the number of iterations or the convergence rate. We stop the optimization process when we observe deteriorating values of MAP. Degrading values of MAP on the training data in-dicates that further optimizing the approximation of MAP as in Eq. (6) may not contribute to raising the true MAP.
In this section we present a collection of experiments that evaluate the proposed TFMAP. We first give a detailed de-scription of the datasets and setup that are used in the ex-periments. Then, we investigate the impact of several pa-rameters in the proposed fast learning algorithm that are critical for TFMAP, as mentioned in Section 4.3. Finally, we evaluate the recommendation performance of TFMAP, compared to several baselines, and analyze its scalability.
The experiments were designed to address the following research questions: 1) Does the proposed fast learning al-gorithm benefit TFMAP in achieving MAP maximization? 2) Does TFMAP outperform state-of-the-art context-aware and context-free approaches? 3) Is TFMAP scalable for large-scale context-aware recommendation?
The main dataset we use in this paper is from the Ap-pazaar project 2 [6]. Appazaar recommends mobile applica-tions to users from the Android Market. The application usage data is recorded in the form of implicit feedback since Appazaar logs which apps are run by each user. In addi-tion, Appazaar also tracks available contextual information from the phone sensors, such as motion sensor and GPS. We use two contextual factors in the experiments, i.e., mo-tion (unavailable, slow, fast) and location (workplace, home, elsewhere). Note that both of the contextual factors were inferred from a GPS trace. Hence, the context variable has http://appazaar.net/ 9 possible types that take into account all the combinations of the two contextual factors, i.e. , K = 9 for C in Eq. (1). For example, context type  X 1 X  denotes that implicit feedback about a user running an application was observed when the user was at work and his/her motion status was unavail-able. Finally, we represent one observation in the dataset as a triplet ( UserID,ItemID,ContextTypeID ). The dataset contains 300469 triplets, 1767 users, 7701 items, 9 combina-tions of contextual features. On average, there are 18.9 app usage events per user and context type. A more detailed description of the dataset and its collection procedure can be found in [6].

Note that conventional CF benchmark datasets, e.g. , Net-flix dataset, are not enriched with contextual information. Although the Appazaar dataset is not as large as these bench-mark datasets, it is still much larger than datasets that have been used in previous context-aware recommendation work [14, 25]. Moreover, the datasets previously used in the CAR literature are all based on explicit ratings rather than implicit feedback, thus, not ideal for our study.
We separate the dataset into a training set and a test set, according to the timestamps. The training set consists of the first 80% implicit feedback data, while the test set contains the remaining 20% data. The target is to use the training set to learn a recommendation model, i.e. , U , V and C , which is then used to generate recommendation lists for each user under each type of context.

We use the MAP measure as in Eq. (3) to evaluate on the testset  X  Y . Note that in order to have fair comparison with context-free approaches, we only preserve one context type for each user in the test set, i.e. , we randomly select one con-text type for each user in the test set and preserve the user X  X  feedback within the selected context type, while excluding all the user X  X  feedback data under other context types. To further clarify this design choice, we give a negative example in which a user in the test set has implicit feedback on the items under two different types of context. In this case, the MAP of context-aware approaches, such as TFMAP, should be measured according to AP under the two different types of context, while context-free approaches would only calcu-late AP based on the items and ignore the context. For this reason, our choice is necessary in order to attain fair comparative results to other context-free approaches.
In addition, note that since we only have implicit feedback from users, we cannot treat all the items that have no feed-back in the test set as irrelevant/negative ones, in which case the recommendation performance could be severely under-estimated. For this reason, we adopt a conventional widely-used evaluation strategy [9, 17], in which we randomly select 1000 items that have no feedback as irrelevant ones for each user in the test set. The performance is measured according to the recommendation list that only contains these 1000 items together with relevant items, i.e. , the items for which there is implicit feedback for that user.

In order to carry out our validation experiments, we ran-domly select 10% of all the implicit feedback data available in the training set. In our validation experiments we inves-tigate the impact of the parameters and the fast learning algorithm in TFMAP.

Finally, note that we empirically tune the following con-ventional parameters so they yield the best performance in the validation test: regularization parameter  X  =0.001, la-tent dimensionality D =10, and learning rate  X  =0.001.
As mentioned in Section 2, the state-of-the-art context-aware approaches, such as FMs [25], are designed to tackle the rating prediction problem (explicit feedback), and hence they are difficult, if not impossible, to apply to implicit feedback data. For this reason, we use another dataset, Food dataset [22], which has also been used in the work on FMs [25]. This dataset contains ca. 6K 5-scale ratings from 212 users on 20 menus/items, and each rating is associ-ated with 2 contextual factors, i.e. one factor about whether the user X  X  feeling about hunger is real or virtual (2 values: real, virtual) when she rated a menu, and the other factor about the user X  X  hunger degree (3 values: normal, hungry and full). By taking into account all the combinations of the two contextual factors, we obtain 6 types of context in the Food dataset.

In our experiments, we randomly select 80% of the ratings as the training set and the remaining ratings as the test set. Items with a rating higher than 3 in the test set are consid-ered to be relevant. Note that a different rating threshold could be set to define the relevant items. Under this setting, we use FM approach to first predict the ratings of the users on the items under each context type, and then generate the recommendation list according to the predicted ratings. For TFMAP, we train the model by converting the training set to an implicit feedback dataset, in which each rated item is regarded as an indicator of implicit feedback ( i.e. , the user tried the food item).
We investigate the properties of the fast learning algo-rithm in TFMAP, presented in Section 4.3. The experimen-tal results reported in this subsection are measured on the validation set previously described.
By varying the sampling size in the fast learning algorithm of TFMAP, we investigate the buffer construction time and the performance variation in terms of MAP in the validation set, i.e. , an issue discussed in Section 4.3.2. We measure the buffer construction time cumulatively across all the users under all the context types in the training set over one iter-ation. The result is shown in Fig. 3.

Note that the buffer construction time increases almost linearly as the sampling size increases. Hence, with a rela-tively small sampling size, we could significantly reduce the buffer construction time compared to the case where all the irrelevant items for each user under a given context need to be ranked. For example, in the Appazaar dataset we have over 7000 items, which means that a sampling size of 200 could save over 50% of the buffer construction time, as illustrated in Fig. 3. Also note that the recommendation performance in terms of MAP increases sharply as the sam-pling size increases up to 200, and then saturates. There-fore, even with a relatively small size of irrelevant items, e.g., 200, (compared to all the irrelevant items), the top-ranked irrelevant items within the sampled set are sufficiently rep-resentative to be used for MAP optimization.

In sum, these results empirically verify the selection of a small set of irrelevant items to create the buffer in the fast learning algorithm of TFMAP and justify our algorithm design choices. For the remaining experiments we will keep a sampling size of 200.
 Figure 3: The impact of sampling size on buffer con-
Here we aim to understand the the effectiveness of choos-ing the representative irrelevant items in the buffer. Rather than selecting representative irrelevant items to construct the buffer, an alternative is to use randomly selected irrele-vant items. To test the random procedure we abandoned the ordering step of the algorithm and instead we randomly se-lected n mk irrelevant items from the sampled set of size 200. In this case the accuracy yields a MAP of 0.083, dropping by 18.6% compared to the case where top-ranked irrelevant items are selected, i.e., MAP of 0.102 as shown in Fig. 3. Increasing the sampling size further emphasizes the bene-fit of carefully selecting the representative items. When we choose to sample 5000 irrelevant items, the benefit over the random strategy is 21.7%. This experiment validates the benefit of using representative irrelevant items in the buffer, as discussed in Section 4.3.1.
As discussed in Section 4.3.2, it is not necessary to sample from all the irrelevant items in order to construct the buffer for a user in a given context, since the items ranked below the lowest-ranked relevant item have no influence on AP. Thus, the sampling process could be more efficient by neglecting the items ranked below the lowest-ranked relevant item.
Here, we present an experimental study that examines the change of the position of the lowest-ranked relevant item, i.e. , the maximal rank of relevant items in a recommenda-tion list, during iterations, and also the change in the corre-sponding buffer construction time, as shown in Fig. 4. Note that this experiment is conducted on the validation set, with sampling size of 200 in TFMAP, and the results shown in Fig. 4 are the average values across all the users under all context types in each iteration.

We observe that the maximal rank of relevant items de-creases with each iteration as the model is gradually opti-mized, i.e. , the model is more likely to rank relevant items higher in the list along iterations. This observation provides empirical evidence that exploiting the lowest-ranked relevant item in the sampling process does contribute to improving the quality of the representative irrelevant items, and also the efficiency of the buffer construction with each iteration. For example, the buffer construction time reduces by over 10% in the second iteration, compared to the first iteration.
Our final validation experiment investigates the effective-ness of the proposed termination criterion for the fast learn-ing algorithm, as discussed in Section 4.3.3. We show the MAP measured in both the training (excluding the valida-Figure 4: The average maximal rank of relevant items Figure 5: The MAP of the training set and the valida-tion set) and the validation sets across the iterations, as in Fig. 5. Both MAP measures gradually improve towards an optimal value with only a few iterations (less than 20), in-dicating that TFMAP effectively learns latent features for users, items and context types for MAP optimization. Also note that both MAP measures start dropping consistently after a few iterations, indicating that it is effective to use the MAP measured in the training set as a termination criterion for the learning process to avoid model overfitting.
From all the findings described in this section, we can give a positive answer to our first research question.
We now compare the performance of TFMAP with that of 5 baseline algorithms, according to the recommendation per-formance measured on the test set. The baseline approaches involved in this comparative experiment are listed below: Table 1: Performance comparison of TFMAP and Table 2: Performance comparison of TFMAP and FM
Based on the Appazaar dataset, the recommendation per-formance of TFMAP and all the baselines except FM is shown in Table 1, from which we obtain three observations.
First, the context-free version of the proposed TFMAP, i.e. , TFMAP-noC significantly outperforms the other base-lines in terms of MAP. Note that in our experiments, sta-tistical significance is measured based on AP and precision values of all the users in the test set, according to Wilcoxon signed rank significance test with p &lt; 0.01. This result in-dicates that in the case that contextual information is un-available, directly optimizing MAP as proposed in TFMAP could still lead to substantial improvement over state-of-the-art context-free approaches, such as iMF and BPR-MF.
Second, we can see that both BPR-MF and TFMAP-noC attain dramatic improvement in MAP over the other two baselines, Pop and iMF. As mentioned in Section 2, BPR is designed to optimize the evaluation metric AUC. The su-perior performance of BPR-MF and TFMAP-noC suggests that directly optimizing an evaluation metric that measures the recommendation performance in implicit feedback sys-tems would yield significant improvements in the recommen-dation performance. In addition, note that TFMAP-noC achieves a significant improvement in MAP of 3% over BPR-MF, and 4% improvement of P@1. This result indicates that optimizing MAP is a better choice for recommender systems than optimizing AUC, since the top-heavy bias in MAP is a critical factor that provides substantial benefit for the rec-ommendation performance.

Third, as can be seen, TFMAP achieves an additional sig-nificant improvement over TFMAP-noC, e.g. , 5% in MAP and P@1. This result indicates that TFMAP succeeds in utilizing contextual information together with user-item im-plicit feedback for maximizing MAP. In addition, the ex-ploitation of context could greatly improve implicit feedback recommenders; a similar conclusion was reached by previous work on CAR with explicit feedback [25, 14].

As mentioned before, we compare TFMAP with FM us-ing the Food dataset, according to the protocol described in Section 5.1.3. The results are shown in Table 2. As can be observed, TFMAP significantly improves over FM to a large http://www.libfm.org/ extent, i.e., by more than 40% in MAP, 100% in P@1 and 50% in P@5 and 8% in P@10, showing a great competitive-ness for top-N context-aware recommendation. From all the experimental results presented in this section, we confirm a positive answer to our second research question.
The last experiment investigates the scalability of TFMAP by measuring the model training time against the amount of data used for training the model. We use from 10% to 100% of the training data (the observed implicit feedback data in the training set) for learning the latent features, and the corresponding training times are shown in Fig. 6. Note that we have normalized the training time by the time that is required for training the model with all the data in the training set. It can be observed that the training time increases almost linearly with the amount of the training data, empirically verifying the property of linear computa-tional complexity. This finding also allows us to answer our last research question positively.
We have presented TFMAP, a novel top-N context-aware recommendation approach for implicit feedback domains. This approach utilizes tensor factorization to model each user X  X  preference for each item under each type of context, and the factorization model is learned by directly optimiz-ing MAP. We also propose a fast learning algorithm that exploits several properties of AP to keep the complexity of TFMAP linear to the number of implicit feedback data in a given collection, thus, making TFMAP scalable. Our ex-perimental results verify the effectiveness of the proposed fast learning algorithm for TFMAP, and demonstrate that TFMAP could outperform several state-of-the-art context-aware and context-free recommendation approaches.

Taking insights from recent statistical analysis on evalua-tion measures [33], one line of our future work is to investi-gate the potential of optimizing other measures for context-aware recommendation, since different measures may repre-sent different aspects of the recommendation quality. An-other interesting topic of future work is to integrate contex-tual information together with metadata of users and items, as discussed in Section 2, to further advance the state-of-the-art in recommender systems. We are very grateful to Matthias B  X  ohmer for making the Appazzar data available. This work is funded as part of a Marie Curie Intra European Fellowship for Career Develop-ment (IEF) awards held by Alexandros Karatzoglou (CARS, PIEF-GA-2010-273739).
