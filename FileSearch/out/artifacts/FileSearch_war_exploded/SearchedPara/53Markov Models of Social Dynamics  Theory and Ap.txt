 Agent-based models often illuminate complex social system dynamics [Tesfatsion and Judd 2006; Gintis 2007]. However, these models have an ambiguous scientific status because they generally lack analytical specificity. In this article I propose a rigorously analytical conception of such models, and apply this conception to a historically in-tractable problem in economic theory: understanding the dynamics of decentralized market production and exchange. The agent-based model is simply a finite Markov process. The application to market exchange proves the existence of a stationary dis-tribution of the Markov process, which captures the long-run behavior of the market system. A famous outstanding problem in economic theory is determining the condi-tions under which market dynamics lead to a stable equilibrium in which supply equals demand in all sectors of the economy (so-called Walrasian general equilibrium). I show that a Markov process model of market dynamics is stable under a wide range of pa-rameters, and the stationary distribution of the Markov process represents a stochastic market-clearing equilibrium of the economy. A general proof of the stability of general equilibrium models of the type developed in this article is given in Gintis and Mandel [2013]. A finite Markov process M consists of a finite number of states S ={ 1 ,... n } ,andan n -dimensional square matrix P ={ p ij } such that p ij represents the probability making t = 1 ,..., then it is in state j in period t + 1 with probability p this definition, finite Markov processes are remarkably flexible in modeling dynamical systems, and characterizing their long-run properties becomes highly challenging for systems with more than a few states.

To illustrate, consider a rudimentary economy in which agents in each period produce goods and sellers are randomly paired with buyers who offer money in exchange for the seller X  X  good. Suppose there are g distinct types of money, each agent being willing to accept only one type of money in trade. Trade will be efficient if all agents accept the same good as money, but in general inefficiencies result from the fact that a seller may not accept a buyer X  X  money.

What is the long-run distribution of the fraction of the population holding each of the types as money, assuming that one agent in each period switches to the money type of another randomly encountered agent? Let the state of the economy be a g -vector ( w number of states in the economy is thus the number of different ways to distribute n indistinguishable balls (the n agents) into g distinguishable boxes (the g types), which objects from a set of n objects.

To verify this formula, write a particular state in the form where the number of x  X  X  before the first A is the number of agents choosing type 1 as money, the number of x  X  X  between the ( i  X  1) th A and the i th A is the number of agents choosing type i as money, and the number of x  X  X  after the final A is the number agents choosing type k as money. The total number of x  X  X  is equal to n , and the total number of A  X  X  is g  X  1, so the length of s is n + g  X  1. Every placement of the g  X  1 A  X  X  represents particular state of the system, so there are C ( n + g  X  1 , g  X  1) states of the system. For instance, if n = 100 and g = 10, then the number of states S in the system is S = C (109 , 9) = 4,263, 421, 511, 271.

Suppose in each period two agents are randomly chosen and the first agent switches to using the second agent X  X  money type as his own money. This gives a determinate probability p ij of shifting from one state i of the system to any other state j . The matrix P ={ p clearly a finite Markov process.

What is the long-run behavior of this Markov process? Note first that if we start in state i at time t = 1, the probability p (2) ij of being in state j in period t = 2issimply This is true because to be in state j at t = 2 the system must have been in some state k means that the two-period transition probability matrix for the Markov process is just P , the matrix product of P with itself. By similar reasoning, the probability of moving from state i to state j in exactly r periods, is P r . Therefore, the time path followed by the system starting in state s 0 = i at time t = 0 is the sequence s 0 , s 1 ,..., where The matrix P in our example has S 2  X  1 . 818  X  10 15 entries. The notion of calculation P t for even small t is quite infeasible. There are ways to reduce the calculations by many orders of magnitude [Gintis 2009 Chapter 13], but these methods are completely impractical with so large a Markov process.

Nevertheless, we can easily understand the dynamics of this Markov process. We first observe as that if the Markov process is ever in the state where all n agents choose type r money, then s r  X  will be the state of the system in all future periods. We call such a state absorbing . There are clearly only g absorbing states for this Markov process.

We next observe that from any nonabsorbing state s , there is a strictly positive probability that the system moves to an absorbing state before returning to state s . For instance, suppose w i = 1 in state s . Then there is a positive probability that w i increases by 1 in each of the next n  X  1 periods, so the system is absorbed into state s i  X  without ever returning to state s .Nowlet p s &gt; 0 be the probability that the Markov process never returns to state s . The probability that the system returns to state s at least q times is thus at most (1  X  p s ) q . Since this expression goes to zero as q  X  X  X  ,it follows that state s appears only a finite number of times with probability one. We call s a transient state.

We can often calculate the probability that a system starting out with w r agents choosing type r as money, r = 1 ,..., g is absorbed by state r . Let us think of the Markov process as that of g gamblers, each of whom starts out with an integral number of coins, there being n coins in total. The gamblers represent the types and their coins are the agents who choose that type for money, there being n agents in total. We have shown that in the long run, one of the gamblers will have all the coins, with probability one. Suppose the game is fair in the sense that in any period a gambler with a positive number of coins has an equal chance to increase or decrease his wealth by one coin. Then the expected wealth of a gambler in period t + 1 is just his wealth in period t . being the winner is just q w = w/ n .

We now can say that this Markov process, despite its enormous size, can be easily described as follows. Suppose the process starts with w r agents holding type r . Then in a finite number of time periods, the process will be absorbed into one of the states 1 ,..., g , and the probability of being absorbed into state r is w An n -state Markov process M has a stationary distribution u = ( u 1 ,..., u n )if u is a probability distribution satisfying or more simply uP = u . This says that for all states i , the process spends fraction u i of the time in state i , so the fraction of time in state j is the probability it was in some state i in the previous period, times the probability of transiting from i to j , summed over all states i of M . We show next that every finite Markov process has at least one stationary distribution.

If state i  X  S in M has a positive probability of making a transition to state j in a from i . If states i and j are mutually accessible, we say that the two states communicate . A state always communicates with itself because for all i ,wehave p (0) ii = 1 &gt; 0. If all states in a Markov process mutually communicate, we say the process is irreducible . More generally, if A is any set of states, we say A is communicating if all states in A mutually communicate, and no state in A communicates with a state not in A .A Markov process M with at least two states, one of them absorbing, as was the case in our previous example, cannot be irreducible, because no other state is accessible from an absorbing state. By definition a set consisting of a single absorbing state is communicating.

The communication relation is an equivalence relation of S . To see this, note that if i communicates with j ,and j communicates with k , then clearly i communicates with k . Therefore the communication relation is transitive. The relation is symmetric and reflexive by definition. As an equivalence relation, the communication relation partitions S into communicating sets S 1 ,..., S k .

We say a set of communicating states A is leaky if some state j /  X  A is accessible from a state in A , in which case j is, of course, accessible from any state in A .Ifin a communicating set the partition, say S r , is leaky, then with probability one M will eventually transit to an accessible state outside S r and M will never return to S r .To see this suppose the contrary, and let i  X  S r and j /  X  S r with p ij &gt; 0. Suppose from i  X  S accessible from j .Butthen i and j communicate, which is a contradiction. Therefore a leaky closed set S r consists wholly of transient states, and with probability one there a finite number of closed sets in the partition of S , there is a time t  X  &gt; 0 such that no member of a leaky closed set appears after time t  X  . This proves that there must be at least one nonleaky closed set. We call a nonleaky closed set an irreducible set . An irreducible set of states in M is obviously an irreducible Markov subprocess of M , meaning that the states of the set themselves form an irreducible Markov process with the same transition probabilities as defined by M .

We thus know that a finite Markov process can be partitioned into a set S tr of transient states, plus irreducible Markov subprocesses S 1 ,..., S m . S tr is then the union of all the leaky closed sets in M . The Markov process may start in a transient state, but eventually transits to one of the irreducible subprocesses S 1 ,..., S m . The long-term behavior of M depends only on the nature of these irreducible subprocesses.
It is desirable to have the long-run frequency of state i of the Markov process be the historical average of the fraction of time the process spends in state i , because in this case we can estimate the frequency of a state in the stationary distribution by its historical frequency in a series of runs of the process. When this is the case, we say the Markov process is ergodic . We must add one condition to irreducibility to ensure Markov process, we say it is aperiodic . It usually is possible, as we will see, to ensure the aperiodicity of a Markov process representing complex dynamical phenomena. We have the following theorem [Feller 1950].

T HEOREM 1(E RGODIC T HEOREM ). Let M be an n-state irreducible aperiodic Markov process with probability transition matrix P. Then M has a unique stationary distri-have Eq. (3) implies that u j is the long-run frequency of state s j in a realization { s t }= { s 0 , s 1 ,... } of the Markov process. By a well-known property of absolutely convergent sequences, (3) implies that u j is also the limit of the average frequency of s j from period t onwards, for any t . This is in accord with the general notion in a dynamical system that is ergodic, the equilibrium state of the system can be estimated as a historical average over a sufficiently long time period [Hofbauer and Sigmund 1998].

If a Markov process M is aperiodic but not reducible, we know that it has a set of transient states S tr and a number of irreducible aperiodic subprocesses S 1 ,..., S k .Each of these subprocesses S r is an ergodic Markov process derived from M by eliminating all the states not in S r , and so has a strictly positive stationary distribution u r over its states. If we expand u r by adding zero entries for the states in M but not in S r , this clearly gives us a stationary distribution for M . Because there is always at least one ergodic subprocess for any finite aperiodic Markov process, this proves that every aperiodic Markov process has a stationary distribution. Moreover, it is clear that there are as many stationary distributions as there are ergodic subprocesses.

The ergodic theorem and the preceding remarks allow us to fill out the general picture of behavior of the finite aperiodic Markov process. Such a process may start in a transient state, but ultimately it will enter one of the ergodic subprocesses, where it will spend the rest of its time, the relative frequency of different states being given by the stationary distribution of the subprocess. We thus have the following. cess. Then there is a probability transition matrix P ={ p ij } of M such that i and all r = 1 ,... k, we have Eq. (4) asserts that u ij is the long-run probability of being in state j when starting from state i . Eqs. (5) and (6) assert that for the states j belonging to an ergodic subprocess S Eqs. (7) and (8) assert that transient states eventually transit to an ergodic subprocess of
M . A Markov process by construction has only a one-period memory, meaning that the probability distribution over states in period t depend only on the state of the process in period t  X  1. However, we will show that, if we consider a finite sequence of states { i the process remains a finite Markov process and is ergodic if the original process was ergodic. In this way we can deal with stochastic processes with any finite memory. Because any physically realized memory system, including the human brain, has finite capacity, the finiteness assumption imposes no constraint on modeling systems that are subject to physical law.
 A stochastic process S consists of a state space S and probability transition function P with the following properties. Let H S be the set of all finite sequences of elements of which is the probability of being in state i in time t if the history up to time t is h t .We histories h k t as S as H k S .
 We say a stochastic process S with state space S and transition probability function P with k -period memory and stochastic process T with state space S and transition probability function P with k -period memory are isomorphic if there is a bijection  X  state space S and transition probability function P with k-period memory, where k &gt; 1 . Then S is isomorphic to a Markov process M with state space S , where i  X  S is a canonical isomorphism from H k S to S k .
 S k in M as i probability transition matrix for M ,and M is isomorphic to S , proving the theorem.
Note that we can similarly transform a finite Markov process M with state space S into a finite Markov process M k with a k -dimensional state space S k for k &gt; 1, and if M is ergodic, M k will also be ergodic. For ease of exposition, let us assume k = 2and the previous period. Then if { u 1 ,..., u n } is the stationary distribution associated with M ,then defines a stationary distribution { u ij } for M 2 . Indeed, we have for any pair-state kl , independent from ij .Wealsohave,forany ij , It is straightforward to show that pairs of states of M correspond to single states of M 2 . These two equations imply the ergodic theorem for { p ij , kl } because Eq. (11) implies { u equations of a stationary distribution; for any pair-state ij ,
Let M be a Markov process with state space S , transition probability matrix P = { p first state assumed by the system is i is given by q i . The probability that a sequence ( i , i space S, transition matrix P ={ p ij | i , j  X  S } , and an initialization probability dis-tribution q on S. Let M  X  be the stochastic process given by running M for  X   X  periods, reinitializing the process, running M again for  X   X  periods, and so on. Then M  X  is a finite Markov process. If q i &gt; 0 for all i  X  S, the M  X  is ergodic.

P ROOF . We set the state space for M  X  to be S  X  Z  X   X  , where Z k ={ 1 ,..., k } . The transition probabilities are given by Then M  X  is clearly a finite Markov process, and because q is strictly positive on S , M  X  has no transient states. Because there is a positive probability of remaining in the same state for two periods, M  X  is aperiodic, and since it is also irreducible, by the ergodic theorem (Theorem 1), M  X  is ergodic.

An important question is the nature of aggregations of states of a finite Markov process. For instance, we may be interested in total excess demand for a good without caring how this breaks down among individual agents. We have the following. space S has a set of states A  X  Swithallj  X  A identically situated in the sense that p probabilities as M , except the states in A are replaced by a single state.
P ROOF . From the case of two states j and k it will be clear how to generalize to any finite number. Let us make being in either state j or in state k into a new macrostate m .If P is the transition matrix for the Markov process, the probability of moving Then we have However, the probability of a transition from m to a state i is given by If j and k are identically situated, then (18) implies where r ranges over all states except j and k , plus the macrostate m . In other words, if we replace states j and k by the single macrostate m , the resulting Markov process has one fewer state, but remains ergodic with the same stationary distribution, except that u situated states can be aggregated into a single in this manner.

More generally, we may be able to partition the states of M into cells m 1 ,..., m l such that, for any r = 1 ,..., l and any states i and j of M , i and j are identically situated with respect to each m k . When this is possible, then m 1 ,..., m l are the states of a derived Markov process, which will be ergodic if M is ergodic.

For instance, in a particular market model represented by an ergodic Markov process, we might be able to use a symmetry argument to conclude that all states with the same aggregate demand for a particular good are interchangeable. Note that in many Markov models of market interaction, the states of two agents can be interchanged without changing the transition probabilities, so such agents are identically situated. In this situation, we can aggregate all states with the same total excess demand for this good into a single macrostate, and the resulting system will be an ergodic Markov process with a stationary distribution. In general this Markov process will have many fewer states, but still far too many to permit an analytical derivation of the stationary distribution. For a Markov process with a small number of states, there are well-known methods for solving for the stationary distribution [Gintis 2009, Chapter 13]. However, for systems with a large number of states, as is typically the case in modeling social processes, these methods are impractical. Rather, we must construct an accurate computer model of the Markov process, and ascertain empirically the dynamical properties of the irreducible Markov subprocesses. We are in fact often interested in measuring certain aggregate properties of the subprocess rather than their stationary distributions. These properties are the long-run average price and quantity structure of the economy, as well as the short-run volatility of prices and quantities and the efficiency of the process X  X  search and trade algorithms. It is clear from the expanded ergodic theorem that the long-term behavior of any realization of aperiodic Markov process is governed by the stationary distribution of one or another of the stationary distributions of the irreducible subprocesses S 1 ,..., S k . Generating a sufficient number of the sample paths { s t } , each observed from the point at which the process has entered some S r , will reveal the long-run behavior of the dynamical system.

Suppose an aperiodic Markov process M with transient states S tr and ergodic sub-processes S 1 ,..., S k enters a subprocess S r after  X   X  periods with high probability, and suppose the historical average over states from t = 0to t = t  X  is a close approximation to the stationary distribution of S r . The existence of  X   X  is guaranteed by the expanded ergodic theorem (Theorem 2). Consider the Markov process M + consisting of running M , reinitializing M every  X   X  periods. By the stacking theorem (Theorem 4), M + is ergodic, so a sufficiently large sample of historical averages starting  X   X  periods after reinitialization and continuing until the next initialization will reveal the stationary distribution of M + . This is the methodology we will use in estimating the aggregate properties of a Markov model of a market economy.
 Adam Smith [2000 (1759)]] envisioned a decentralized economy that sustains an effi-cient allocation of resources through the  X  X nvisible hand X  of market competition. Smith X  X  vision was formalized by L  X  eon Walras [1954 (1874)], and has become the standard model of market exchange in economic theory. Such economies are particularly attrac-tive because they capture the basic structural characteristics of market economies, and because a Walrasian equilibrium always entails an efficient allocation of resources, abstracting from certain conditions that require nonmarket regulation, such as ex-ternalities (e.g., air pollution), natural monopolies (such as the supply of water in a city), and public goods (such as national defense). Bator [1957], Katzner [1992], and Ellickson [1994] provide accessible introductions to the Walrasian model for mathe-matically sophisticated readers.

The Walrasian economy consists of households and firms. Firms acquire production inputs (labor, raw materials, and capital) at given market prices and combine them to produce outputs (goods and services) which they sell at given market prices to the households. Labor and capital inputs are rented from the households that own them, so the firm itself owns nothing; all wealth is in the hands of households. The inputs also include raw materials and the outputs of other firms, which firms also purchase on markets. The labor and raw material inputs, as well as shares of the net profit of the firms, are owned by the households, and form their wealth.

Households buy the output of the various firms, some of which they consume, and some of which they add to their stock of wealth. The economy is in equilibrium when the vector of prices p for all goods and services is set so that the supply equals the demand in each market.

Consider the following highly simplified Walrasian economy. There are two goods, which we will call apples ( a ) and nuts ( n ), two households ( x and y ), and two factor inputs, labor ( l ) and capital ( k ). Suppose l x and l y are the amounts of labor owned by households x and y , l a and l n are the amounts of labor used in producing apples and nuts, k x and k y are the amounts of capital owned by households x and y ,and k a and k n are the amounts of capital used in producing apples and nuts. Then we have the following equations. The equations say that the total amount of labor and capital demanded by firms to use in production equals the total amount supplied by households.

Now suppose the wage rate is w and the interest rate (which is the rental price of x consumes a x of apples and n x of nuts, while household y consumes a y of apples and n y of nuts. Finally, we assume household x owns a share  X  a x of the profits of the apple firm and  X  n x of the nut firm, while household y owns a share  X  a y of the profits of the apple firm and  X  n y of the nut firm, where because all profits are distributed to the owners.

Then if m x and m y are the incomes of households x and y , we have the following two equations where  X  a and  X  n are the profits generated in the two firms.

The next two equations are production functions for the apples and nuts firms. They say that each good is produced by using capital and labor. We assume the firm maximizes profits, given by Choosing inputs to maximize profits (that is, setting the partial derivatives of  X  a and  X  n to zero and solving the resulting equations), we find where subscripts on the production functions f and g refer to partial derivatives.
We assume households have utility function u x ( a x , n x )and u y ( a y , n y ), which they maximize subject to their income constraints. The income constraints are given by mizing utility given these income constraints gives where subscripts on u x and u y represent partial derivatives. Finally, we can take one price as numeraire, since both firms and households care only about price ratios (there is no money or monetary wealth in this model). the structure of ownership in the economy. There remain eighteen variables to be are ostensibly nineteen equations (Eqs. (29), (30), and (22) are each two separate equations). However, if we add up (27) and (28), then substitute in (25) and (26), we get the sum of (23) and (24). This means one equation is superfluous, giving us a system of sixteen equations in sixteen unknowns.

A market equilibrium is a solution to these equations with nonnegative prices and quantities. If these equations were linear, this system would then generically have exactly one solution, although even then the nonnegativity conditions would not be guaranteed. But of course these equations are not linear, so there could be zero or many solutions. Thus proving the existence of a market equilibrium is nontrivial. An existence proof for a simplified version of the Walrasian economy was provided by Wald [1951 (1936)]. Soon after, Debreu [1952], Arrow and Debreu [1954], Gale [1955], Nikaido [1956], McKenzie [1959], Negishi [1960], and Arrow and Hahn [1971] and others provided rather complete proofs of the existence of equilibrium in Walrasian economies very similar to the model given before, but with arbitrary finite numbers of goods, households, firms, capital goods, types of labor, and raw materials. The con-ditions that make this possible, roughly speaking, are that consumers have concave preferences (declining marginal utility) and firms have convex production functions (declining marginal productivity). We live in a period of financial fragility exacerbated by increasingly interdependent national economies, thus transforming local into global instability. Standard macroe-conomic models cannot address these problems because they are highly aggregated  X  X epresentative agent X  versions of the Walrasian model that do not treat the inter-action of heterogeneous agents [Kirman 1992; Guilmi et al. 2012]. We must thus go beyond the currently static Walrasian model showing that under a plausible dynamic exhibiting the conditions under which the general equilibrium model is locally and glob-ally stable. The only dynamics that have been proposed follow Walras X  t  X  atonnement analysis, which assumes that the adjustment process out of equilibrium is carried out on a centralized institutional level beyond the control of economic agents. Walras as-sumed there is an  X  X uctioneer X  (like the famous crieur of the Paris Bourse), who calls out prices, calculates excess demand or supply for each good, based on the reaction of firms and households, and adjusts the price by lowering the price of a good in excess supply and raising the price of a good in excess demand. The auctioneer repeats this process of  X  X   X  atonnement X  until prices clear all markets, at which time the auctioneer broadcasts this equilibrium price vector, and permits firms and household to make plans based on it. Of course, Walras could not show that this process converges, despite its intuitive plausibility.

Twentieth century economists were not satisfied with Walras X  nineteenth century argument. The question of stability of the Walrasian economy thus became a cen-tral concern of mathematical economists in the years immediately following the proof of existence of equilibrium [Arrow and Hurwicz 1958, 1959, 1960; Arrow et al. 1959; McKenzie 1960; Morishima 1960; Nikaido 1959; Nikaido and Uzawa 1960; Uzawa 1961, 1962]). The models studied by these researchers conformed to Walras X  t  X  atonnement framework, assuming that out of equilibrium, there is a system of public prices shared by all agents. These researchers implemented an ordinary differential equation dy-namic, in which the time rate of change of price for each good is a function of excess demand for that good. They had only extremely limited success, even in this highly implausible stability framework.

This quest for a general stability theorem was derailed by Herbert Scarf X  X  examples of unstable Walrasian equilibria [Scarf 1960]. Indeed, more recent studies have shown that the t  X  atonnement dynamic resulting from public prices adjusted by an auctioneer who knows only the structure of excess demand is stable only under extremely stringent and implausible conditions imposed on the aggregate dynamics of the system. These conditions cannot be derived from the underlying market structure or the behavior of producers and consumers [Kirman 1992], and chaos in price movements is the generic case for the t  X  atonnement adjustment processes [Saari 1985; Bala and Majumdar 1992].
General equilibrium theorists in the early 1970 X  X  harbored some expectation that plausible restrictions on utility functions might entail stability. However, Sonnenschein [1973], Mantel [1974, 1976], and Debreu [1974] showed that virtually any continuous function is the excess demand function for some Walrasian economy. More recently, Saari [1995] and others have shown that the information needed by a price adjustment mechanism that can ensure stability includes virtually complete knowledge of all cross-elasticities of demand in addition to excess demand quantities.

Surveying the state-of-the-art some quarter century after Arrow and Debreu X  X  sem-inal existence theorems, Fisher [1983] concluded that little progress had been made towards a cogent model of Walrasian market dynamics. This remains the case today. Despite the centrality of the general equilibrium model to economic theory, little about real-world market dynamics in realistic settings can be inferred from the differentiable manifold approach.

Even if a well-behaved centralized institutional price adjustment had been found, this would not have solved the problem of real-world economic dynamics. This is true even in principle and even accepting a highly idealized framework. This is because in the approach taken to stability in twentieth century general equilibrium theory, a single price vector is assumed to govern all agents. We call this the public prices assumption. This assumption precludes the attainment of stability through a price-adjustment process in the hands of households and firms. No Walrasian agent can have any effect whatsoever on any price. Indeed, this is the very definition of a  X  X ompetitive X  Walrasian equilibrium. Therefore there is no possible revision of the t  X  atonnement process that operates the level of decentralized individual decision-making.

Only a dynamic based on agents adjusting prices to maximize profits or utility while producing and consuming out of equilibrium can be a plausible candidate for a general Walrasian stability theory. I will show that a Markov process model of market dynamics can succeed where a differential equation approach has failed, although because of the large size of the resulting Markov model, in our current, and highly incomplete, state of knowledge of Markov processes, its properties can be ascertained only through computer simulation.

There is surprisingly little precedent for this research strategy. There are several agent-based models described in the economics literature [Tesfatsion and Judd 2006], but none deals with several sectors, disaggregated to the level of heterogeneous agents. Chen et al. [2000] use Swarm software [Stefansson 1997] to model a one-sector econ-omy using labor, the only endogenous variable being the single product price. Epstein and Axtell [1997] model a highly complex multiagent system, but have one good and no firms. Lian and Plott [1998] implement a laboratory experiment with human subjects, with one good, labor, and fiat money, and Anderson et al. [2004] implement a similar ex-periment with three goods and three consumers with Leontief consumption functions, based on Scarf [1960]. Weddepohl [1997] simulates a global t  X  atonnement process in an economy with two goods plus labor, one firm producing each good, and three consumers who also supply a fixed amount of labor. Other than these papers, I have been able to find only examples of sector-level models that assume aggregate demand function, such as Taylor and Uhlig [1990]. There are several quite elegant models of bilateral trade in durable goods (that is, there is no consumption until the trade process is completed), without assuming public prices, leading to market-clearing Pareto-optimal allocations [Smale 1976; Friedman 1979; Foley 1994; Axtell 2005]. These models, how-ever, assume that agents trade only in goods that they consume plus perhaps money. An acceptable model of real-world market exchange must assume that agents consume out of equilibrium and trade in goods that they do not consume.

My goal here is to present a Markov process model of a market economy with de-centralized production, consumption, and trade in many goods. We find that such economies have stationary distributions close to market-clearing Walrasian equilib-rium, with significant short-run excursions away from equilibrium generated by the inherent stochasticity of the Markov process. Consider a market economy with many goods, many agents, and only one institution: the marketplace. We assume each agent produces one good, in fixed amount, using only personal labor, but consumes a variety of goods. Agents are endowed with private prices, and they have no information about the economy other than that gathered from private experience in trade. These assumptions lack realism, but each can be replaced by more realistic assumptions when necessary. For instance, we could add a labor market, a capital market, firms, and a central bank without difficulty [Gintis 2007].
We assume there are n sectors. Sector k = 1 ,..., n produces good k in  X  X tyles X  s = 1 ,..., m . We use  X  X tyles X  to ensure that our Markov process economies have large numbers of goods, but only a limited number of prices. This is for the sake of compu-tational convenience only, and does not affect the dynamics of the model. Each agent consumes a subset of his nonproduction goods, but only a single style of any good. In effect, then, there are nm distinct goods g k s produced in sector k with style s ,butonly n production processes and correspondingly n prices, since goods g k s and g k t with styles s and t , respectively, have the same production costs and hence the same price in equi-g = g k when g = g k
A producer of good g k s , termed a g k s -agent , produces with personal labor and no other inputs an amount q k of good g k s which depreciates to zero if it remains in inventory at the close of a trading period. A trade inventory for an agent can include any good acquired through production or trade.

The Markov process is initialized by creating N agents, each of whom is randomly assigned a production good g k s . Thus, in an economy with goods in m styles, there are Nnm agents. Each of these agents is assigned a private price vector by choosing each price from a uniform distribution on the open unit interval, then normalizing so that g
The utility function of each agent is rendered unique by randomly setting several parameters of a hybrid CES utility function, explained in Appendix A. These utility functions, which are generalizations of a functional form widely used in economic models, do not satisfy the gross substitutability assumption [Arrow et al. 1959], so stability in the t  X  atonnement dynamic generally does not hold.

For each good g k s  X  G there is a market m [ k , s ] of agents who sell good g k s . In each period, the agents in the economy are randomly ordered and are permitted one-by-one to engage in active trading. When the g h s -agent A is the current active agent, for each good g h t for which A has positive demand, A is assigned a random member B  X  m [ h , t ] who consumes g k s . A then offers B the maximum quantity y k of g k s , subject y is accepted, A will receive in value at least as much as he gives up, according to A X  X  that is, he offers B an equivalent value of good g k s , the valuation being at A X  X  prices. B accepts this offer provided the exchange is weakly profitable at B X  X  private prices; that is, provided p B k y k  X  p B h y h . However, B adjusts the amount of each good traded downward if necessary, while preserving their ratio, to ensure that what he receives does not exceed his demand, and what he gives is compatible with his inventory of g h t . The code for this trading algorithm is rather complex, but the interested reader can download it from my Web site: http://people.umass.edu/gintiis. 1 If A fails to trade with this agent, he still might secure a trade giving him g k s , because A  X  m [ k , s ]mayalso be on the receiving end of trade offers from g h t -agents at some point during the period. period.

After each trading period, agents consume their inventories provided they have a positive amount of each good that they consume, and agents replenish the amount of their production good in inventory. Moreover, each agent updates his private price vector on the basis of his trading experience over the period, raising the price of a consumption or production good by 0.05% if his inventory is empty (that is, if he failed to purchase any of the consumption good or sell all of his production good), and lowering price by 0.05% otherwise (that is, if he succeeded in obtaining his consumption good or sold all his production inventory). We allow this adjustment strategy to evolve endogenously according to an imitation process.

After a number of trading periods, the population of agents is updated using a standard replicator dynamic, in which agents who have high scores for trading and consuming have a high probability of reproducing, while unsuccessful trades are elim-inated from the economy. In all cases, the new agents inherit the price vector of their parent, perhaps mutated a bit. The resulting updating process is a discrete approximation of a monotonic dynamic in evolutionary game theory. In differential equation systems, all monotonic dynamics have the same properties as the simplest, which is the replicator dynamic [Taylor and Jonker 1978; Samuelson and Zhang 1992]. Other monotonic approximations, including choosing a pair of agents in m [ k , s ]andlet-ting the lower-scoring agent copy the higher-scoring agent, produce similar dynamical results.

The result of the dynamic specified by the preceding conditions is the change over time in the distribution of private prices. The general result is that the system of private prices, which at the outset are randomly generated, in rather short time evolves to a set of quasi-public prices with very low inter-agent variance. Over the long term, these quasi-public prices move toward their equilibrium, market-clearing levels. I will illustrate this dynamic assuming n = 9, m = 6, and N = 300, so there are good for each agent, so p A 9 = 1 for all agents A. A g k -agent produces one unit of good k per period. We assume that there are equal numbers of producers of each good from the outset, although we allow migration from less profitable to more profitable sectors, so in the long run profit rates are close to equal in all sectors. The complexity of the utility functions does not allow us to calculate equilibrium properties of the system perfectly, but we will assume that market-clearing prices are approximately equal to unit costs, given that unit costs are fixed, agents can migrate from less to more profitable sectors, and utility functions do not favor one good or style over another, on average. Population updating occurs every ten periods, and the number of encounters per sector is 10% of the number of agents in the sector. The mutation rate is  X  = 0 . 01 and the error correction is = 0 . 01.

The results of a typical run of this model are illustrated in Figures 1 and 2. Figure 1 shows the passage from private to quasi-public prices over the first 20,000 trading periods of a typical run. The mean standard error of prices is computed as follows. For each good g we measure the standard deviation of the price of g across all g -agents, where for each agent, the price of the numeraire good g 9 unity. Figure 1 shows the average of the standard errors for all goods. The passage from private to quasi-public prices is quite dramatic, the standard error of prices across individuals falling by an order of magnitude within 300 periods, and falling another order of magnitude over the next 8500 periods. The final value of this standard error is 0.029, as compared with its initial value of 6.7.

Figure 2 shows the movement of the absolute value of excess demand over 50,000 periods for nine goods in 6 styles each. Using this measure, after 1500 periods excess demand has decreased by two orders of magnitude, and it decreases another order of magnitude by the end of the run.

The distinction between low-variance private prices and true public prices is signifi-cant, even when the standard error of prices across agents is extremely small, because stochastic events such as technical changes propagate very slowly when prices are highly correlated private prices, but very rapidly when all agents react in parallel to price movement. In effect, with private prices, a large part of the reaction to a shock is a temporary reduction in the correlation among prices, a reaction that is impossible with public prices, as the latter are always perfectly correlated.

There is nothing special about the parameters used in the previous example. Of course, adding more goods or styles increases the length of time until quasi-public prices become established, as well as the length of time until market quasi-equilibrium is attained. Increasing the number of agents increases the length of both of these time intervals. Agent-based models have been interpreted either as a way to study the behavior of mathematical models that have no closed-form solution, or as an alternative to math-ematical modeling altogether [Tesfatsion and Judd 2006]. This article develops a third interpretation, and applies it to a long-standing problem in economic theory: charac-terizing the dynamical property of general market exchange.

In this alternative, an agent-based model is a well-known mathematical struc-ture, the finite Markov process. I develop several theorems, including an expanded ergodic theorem (Theorem 1), a finite history theorem (Theorem 3), a stacking theorem (Theorem 4), and an aggregation theorem (Theorem 5), all of which relate to the con-struction and estimation of a finite Markov process, and when appropriately applied, ensure that the resulting Markov process is ergodic. This implies that the process has a stationary distribution, and that we can empirically estimate this distribution.
I then showed that agent-based models of social processes can generally be treated as finite Markov processes with analytically determinate stationary distributions that can be estimated using empirical sampling techniques. I then considered a decentralized system of exchange with rather generic properties and heterogeneous agents with hybrid Constant Elasticity of Substitution (CES) utility functions (see Appendix A), so the classical conditions for stability of equilibrium (gross substitutability) do not pertain [Arrow et al. 1959]. The Markov process dynamic for this economy swiftly converges to quasi-public prices and a quasi-Walrasian equilibrium. These results are not due to the simplicity of the economy, because similar results are obtained with a considerably more institutionalized economy with firms, labor, and credit markets, and a government sector that taxes and provides unemployment insurance [Gintis 2007]. The proof of stability of general equilibrium models of the type studied in this article is given in Gintis and Mandel [2013].
 The utility function of each agent is the product of powers of CES utility functions of the following form. For each consumer, we partition the n consumer goods into k segments for all j ,and j m j = n . We randomly assign goods to the various segments, and for each segment, we generate a CES consumption with random weights and elasticity. Total utility is the product of the k CES utility functions to random powers f j such that
For example, consider a segment using goods x 1 ,..., x m with private prices p 1 ,..., p m and elasticity of substitution s , and suppose the power of this segment in the overall utility function is f . It is straightforward to show that the agent spends a fraction f of his income M on goods in this segment, whatever prices he faces. The utility function associated with this segment is then where  X  = ( s  X  1) / s ,and  X  1 ,..., X  m &gt; 0 satisfy l  X  l = 1. The income constraint is and assuming  X  = 0 (that is, the utility function segment is not Cobb-Douglas), this gives where When  X  = 0 (which occurs with almost zero probability), we have a Cobb-Douglas utility function with exponents  X  l , so the solution becomes The utility function of each agent is the product of powers of CES utility functions of the following form. For each consumer, we partition the n consumer goods into k segments for all j ,and j m j = n . We randomly assign goods to the various segments, and for each segment, we generate a CES consumption with random weights and an elasticity randomly drawn from a uniform distribution. Total utility is the product of the k CES utility functions to random powers f j such that j f j = 1. In effect, no two consumers have the same utility function.

For example, consider a segment using goods x 1 ,..., x m with prices p 1 ,..., p m and (constant) elasticity of substitution s , and suppose the power of this segment in the overall utility function is f . It is straightforward to show that the agent spends a fraction f of his income M on goods in this segment, whatever prices he faces. The utility function associated with this segment is then where  X  = ( s  X  1) / s ,and  X  1 ,..., X  m &gt; 0 satisfy l  X  l = 1. The income constraint is and assuming  X  = 0 (that is, the utility function segment is not Cobb-Douglas), this gives where When  X  = 0 (which occurs with almost zero probability), we have a Cobb-Douglas utility function with exponents  X  l , so the solution becomes
