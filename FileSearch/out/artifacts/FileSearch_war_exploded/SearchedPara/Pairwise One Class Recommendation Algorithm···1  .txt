 As the concept of personalization is becoming prevailing, recommender systems have been widely used in various Internet Service[ 4 , 7 ]. Recommendation algo-rithms may differ as the scenario changes with service. Generally, there exist two categories: explicit and implicit scenarios. Under the former scenario, explicit rat-ings are given by users, such as a 1-5 scale in Netflix, and ratings is a measure of preference. Lots of researchs have been done on this issue, a representative work was done by [ 1 ] in Netflix prize. However, this kind of data is hard to achieve, for that it X  X  a bad experience for user to be compelled to provide ratings. On the other hand, implicit scenario indicates the situation where only user X  X  implicit feedback can be got. However, there are two kinds of implicit feedback. One kind of implicit feedback can be transferred into ratings, e.g., the counts of a user purchasing a brand, the counts of a user browsing a website, etc. Since that the counts of user behavior can be interpreted as a measure of preference, just as ratings do, this scenario is easier to tackle with. The other kind implicit feedback has no  X  X ount X  information and is usually represented by binary relevance data, which indicates a user X  X  attitude to an item, such as the followship between users in social network. Though Lots of research has been done for implicit feedback, few attention has been paid to the situation where only binary relevance data can be obtained, which is exactly we focus on in this paper.
 able is short for binary implicit scenario. To figure this scenario out, we take the followship in social network as an specific example. If a user follows someone else, he is assumed to like that person, which is also called a positive example. As for persons who are not in his follow list, it X  X  not sure whether he like or dislike them, which are missing examples. Obviously, we can only know part of positive exam-ples from user feedback, with the remaining hidden in the missing part, which is a mix of positive and negative examples. Hence, the dataset is sparse and has one class ambiguity, which are two main challenges in binary implicit scenario. Various solutions have been proposed to settle with this, such as considering it as a one class classification problem[ 5 , 12 , 14 ] or completing missing data accord-ing to a certain strategy[ 6 ]. Taking missing data as unknown, one class classifi-cation learn only from known positive examples and use EM-like algorithms to iteratively learn the classifier and then predict on the unknown. While the com-pleting method assign fixed values to missing examples according to weighting or sampling strategies. However, it is too arbitrary to take all missing data as unknown or assign unchangeable values to them. In this paper, we try to figure out a compromise by dealing with training data in a new method.
 based on a rank-biased measure raised in Information Retrieval. We choose the rank-biased measure as the basis of our model because that we expect our model to achieve a better recommend list. As stated in [ 3 , 10 ], rank-biased measures penalize mistakes of top items more than other items, which leads to a better topN performance than traditional measures that take mistakes of all items as equally important. This is also proved by [ 9 , 13 ], etc. What X  X  more, to be tailored for binary implicit scenario, we do two improvements to achieve the compromise we mentioned before, which are also contributions of this paper:  X  We construct a new pairwise rank-biased measure, in which rank differences  X  We add a constrained condition to refine the pairwise rank-biased measure. The paper is organized as follows. In section 2 we review the related work. Model we propose is presented in section 3, which is followed by the optimization process and a fast leaning method which targets at reducing the computation complexity of optimization stated in section 4. In section 5, we empirically eval-uate the efficiency of our approach by comparing with some baselines on two public datasets. Finally, we conclude the paper. The most popular optimization measure for recommender is error metric[ 1 ]. However, it is barely suit for explicit feedback or implicit feedback that can be transformed into ratings and not for the binary implicit scenario which we are targeted at. Recently, a new kind of measure has emerged, rank-biased mea-sures [ 9 , 11 , 13 ]. This kind of measures optimize on rank information, and as the comparison done in [ 15 ] shows, they have a better topN performance. In addi-tion, Mean Average Precision (MAP), a common rank-biased measure, is a more suitable measure for binary implicit scenario, which is shown in [ 2 ]. That why we choose MAP as the basis of our model.
 Generally, recommendation work that targets at binary implicit scenario can be divided into several directions. One direction is one class classification. Machine leaning algorithms that optimize model only on limited positive exam-ples are proposed, such as [ 5 , 12 , 14 ]. Another direction is one class collabora-tive filtering (OCCF)[ 6 ], where missing data are completed according to certain strategy. Then traditional CF model, such as Matrix Factorization and k-nearest neighbor (KNN), can be trained on the completed dataset. In contrast to these, our model is a pair-wise rank-biased model. Similar work have been done by [ 8 , 9 ]. [ 9 ] is based on smoothed mean reciprocal rank, a rank-biased measure, however, it only estimates the thought of ranking and didn X  X  consider much about the sparse and ambiguity problems of dataset. [ 8 ] utilizes pairwise com-parisons between item pairs, while its criterion is Area Under the Curve (AUC). However the AUC can X  X  reflect the topN performance well[ 15 ] because it is not a top-biased measure. In our paper, we mainly go into the sparsity and one class ambiguity problems, and try to construct a tailored rank-biased measure. 3.1 Problem Definition The problem setting in this paper is as following: Suppose that we are doing recommendation for a social network, which is a representative binary implicit scenario, and we want to provide a list of persons who a user may interest most to him. Notice that for a user in social network, his items are all other persons except himself instead of common goods like books, radio or something else. Thus, if the number of user is M, we can got a M  X  N (N is equal to M) matrix Y by taking all user item pairs X  relationship as entries. Obviously, this matrix is binary and diagonally meaningless. If user i follows item j, we indicate this user item pair i, j by y ij = 1, otherwise we are not sure the relationship, used to note it.
 cept drawing insight from Information Retrieval field, where various measures have been proposed, such as Normalized Discounted Cumulative Gain (NDCG), Mean Average Precision (MAP) etc.. However, some of them are not suitable for the binary implicit scenario, because graded relevance is needed. Take this into consideration, we choose MAP, which has been used in many paper, as our model X  X  basis. A common form of MAP measure utilized in recommendation[ 9 ] is as following: for user i. I( r ik  X  r ij ) is a pre-defined function: if the condition in the bracket is true, it returns 1, otherwise 0. The maximum of AP i promotes the relevant items of user i and depresses the irrelevant items, which optimizes a user X  X  item ranks according to item relevance. Then MAP is the sum of all users X  AP, which ensures the item ranks of all users is optimized. The detail of how to utilize MAP will stated in next two section. 3.2 Pairwise Ranking In this section, a new measure, pairwise ranking (PWR), is proposed based on MAP, which alleviates the ambiguity problem of training matrix mentioned before. Traditional methods optimize directly on pointwise train data, and gener-ally they assign fixed values to missing examples to complete the original dataset. However, an arbitrary assignment will cause the error of dataset, which will lead to an inaccurate model. To avoid this, we utilize item pairs as training inputs and construct a new pairwise rank-biased measure. This different approach liberates us from the assignment, and utilizes relationship between item pairs which is more reliable.
 pair: for a user, it is more likely that, 1). known positive examples are assigned higher values than missing ones. 2). known positive examples X  values are closer. For the convenience of stating, we use N + i , N  X  i and N item set, missing item set and integral item set of user i. Eq. (1) can be divided into two parts: ranks of N + i and comparisons between N + by this equation, we derive our pairwise rank-biased measure, PWR, which is shown in Eq. (2).
 However, problem arises when it comes to optimization. Optimizations are done on continuous function, however, Eq.(2) depends on the rank and is piece-wise constant and non-differentiable. There exists different approaches to deal with this, one of which is smoothing the function and preforming gradient descent optimization on the smoothed version. Borrowing thought from [ 2 ], we derive the pair i, j , and rank can be gotten by sorting score ascending. With a sigmoid function g ( x )= 1 1+ e  X  x , a common monotonous function, the indicator function can also be transferred into continuous function g ( f ij all users into consideration, we can get the integral function: 3.3 Constrained Pairwise Ranking With pairwise rank-biased model mentioned in last section, ambiguity and spar-sity problems of training dataset is alleviated. However, we can still mine more useful information from the limited train matrix, and it  X  X  promising to get a more accurate model with more information used properly. We all know that users and items are all different to some extent. We can also find that different users may have different selectivity and different items may own different pop-ularity, which is a valuable information. This viewpoint has been proposed and proved by [ 6 ]. We approve the definition of selectivity and popularity in [ 6 ], and interpret and utilize it in a new method. To make concepts clear, we give the formula of selectivity and popularity first: common sense that a user who select more items has a higher selectivity, which also means that items he didn X  X  select have higher confidence to be disliked by him, vice versa. It X  X  also obvious that if an item is more popular, it will be more likely to be disliked by users who didn X  X  select it. Therefore we can merge these two factors into a value C ij which indicates the confidence of predicted value for user item pair i, j . In the end, we can deduced a weighted measure function: factors, can be gotten from experiment. Since C ij is the confidence coefficient, borrowing the thought of error metric, we can view C ij as the weight of error and then get a weighted error metric  X  C ij . To stay the same form with PWR, we continue to use g ( f ij ) to indicate the predicted value of be 0 or 1, the error of predicted value is calculated respectively. Generally the more accurate the model is, the smaller the value of error metric is. To stay monotonic,  X  C ij is added to PWR as a negative item: 4.1 Optimization The key task of optimizing is to approximate f ij in cPWR. Note that matrix F is a predicted score matrix, which contains predicted scores for all user item pairs. Based on the latent factor model, we replace F matrix with two lower dimension matrixes: user matrix U and item matrix V. Thus, f ij is the inner product of user vector U i and item vector V j . Usually, regularized penalty should be added to avoid over-fitting problem. After finishing these replacements, we can get the final objective function: stochastic gradient ascend to maximize this function. ( U, V all (
U i ,V ), which is determined only by history data of user i. Hence, With respect to U and V, we can derive gradient formulas of them by taking other parameter as fixed. For user vector and item vector respectively: Our model aimed at solving practical application problem, hence the scale of calculation must be limited. At first, we should analyze the complexity of current training procedure. Suppose that matrix Y has M  X  N is equal to M, and the dimension of latent factor is K. Note that number of known positive examples for all user i. For each iteration, the learning process training across all users, and for each user, gradient is calculated for every item vector and this user X  X  vector. Due to the comparisons between item pairs, the complexity of user-fact gradient formula is O( N + i  X  of item-fact gradient formula is approximately O(N  X  N). Although matrix Y is sparse enough to make complexity of user-fact gradient calculation tractable. With every update of user vector, all item vectors are updated, which is exactly the computational bottleneck of our algorithm. In next section, we will propose a fast learning method to address this computational bottleneck. 4.2 Fast Learning The key idea of speeding up the optimizing process is to update item vectors selectively and the main reason leads to the untractable calculation is that the times of item vectors update is quadratic of the number of items. To improve this, we propose a sampling strategy, which can sampling a small portion of items to update during each iteration. For the convenience of statement, we use two items pair sets: pos pos and pos neg pair set and what we want is that the difference between pos pos pair to be smaller and pos neg pair bigger. Hence, we can choose item pairs which have bigger differences from pos pos pair set and item pairs which have smaller differences from pos neg set. At last, representative items can be selected for next iteration loop. The detailed sampling strategy and the integral algorithm in presented in Algorithm 2 and 1.
 5.1 Dataset Description We evaluate our algorithm on two public available social network dataset, which all provide binary implicit feedback. The first Epinions dataset is the trust relationships interact for a who-trust-whom online social network Epinions which contains 75879 users and 508837 directed friendships.The second dataset are collected on Slashdot 2 , which is a technology-related new website allowing user to tag each other as friends or foes. The number of users is 77360 and the number of friendships is 905467, which makes it a less sparse dataset. 5.2 Evaluation Both datasets are be processed in the same method. We adopt 10-fold cross validation method on our datasets. Detailed to say, we divide datasets for 10 times at the ratio of 9:1 from the perspective of every user randomly, and we take the bigger part as the train data and the remaining as the test data. Differ-ent datasets ensure that our model X  X  performance is universal. In addition, the algorithm run across on different train set for 10 times, which make the average measure more compellent.
 The measure we optimized for is a good substitute for top-N performance, but too complex to be intuitive. Hence the evaluation measure we adopt in our exper-iment is Precise@n (p@5, p@10), the precision rate of the topN recommend list. Precise@n is the proportion of positive examples in the topN recommend list. 5.3 Comparison We evaluate our approach X  X  performance by comparing with three representative baselines: Item-based KNN, LFM and CLiMF, which are described as following:  X  Item-based KNN: First, the similarities between all items are calculated  X  LFM: Latent Factor Model, is in fact an improved matrix factorization app- X  CliMF: This is a similar algorithm with ours for it also adopt ranking-performance of all compared models showed in Figure 1. On one hand, we can see that when compared with traditional models, ranking-oriented models have an obvious superior precision rate. Especially when the size of training data get bigger, traditional models X  performance are even worse. This proves that rank-biased measure is a more effective for topN performance. On the other hand, our model outperforms another ranking-oriented model CliMF. Different from CliMF, our model do more deep exploration on binary implicit scenario and construct a tailored pairwise ranking-oriented measure. The higher precision rate indicates that our exploration is valuable and feasible. In addition, Figure 2 shows the computing speed and stability of our proposed fast learning algorithm. We did experiment with 50000 persons of Slatdot and keep trace of precise@5 (p@5) rate along the iteration process. It shows that two methods reach the convergence point almost at the same iteration, while the fast learning method takes less time in every iteration because the sampling strategy it adopts. Hence, the training procedure is speeded up. At the same time, we can see that the fast learning method only lower the precision rate to a tolerable level, which is still higher than other baselines. Generally speaking, the fast learning method makes our model more suitable for practical application. In this paper, we go into the binary implicit scenario. Confronted with one class ambiguity and sparsity problems, we find that a deeper comprehension of train data can achieve a better approach to fix it. On this basis, we derive our pairwise rank-biased model: First, we utilize the train data in the form of pairs. Second, we add a constrained condition to refine the optimizing process. For future work, we plan to address the problem of how to simply define parameters in our model.
