 M.A.Walker@sheffield.ac.uk It is well kno wn that utterances con v e y information about the speak er in addition to their semantic con-tent. One such type of information consists of cues to the speak er X  s per sonality tr aits , typically assessed along fi v e dimensions kno wn as the Big Fi v e (Nor -man, 1963):
Findings include that e xtra v erts talk more, louder , and f aster , with fe wer pauses and hesitations, and more informal language (Scherer , 1979; Furnham, 1990; He ylighen and De w aele, 2002; Gill and Ober -lander , 2002). Neurotics use more 1 st person sin-gular pronouns and ne g ati v e emotion w ords, while conscientious people a v oid ne g ations and ne g ati v e emotion w ords (Pennebak er and King, 1999). The use of w ords related to insight and the a v oidance of past tense indicate intellect, and swearing and ne g-ati v e emotion w ords mark disagreeableness. Cor -relations are higher in spok en language, possibly especially in informal con v ersa tion (Mehl et al., in press).

Pre vious w ork has modeled emotion and person-ality in virtual agents, and classified emotions from actor X  s speech (Andr  X  e et al., 1999; Liscombe et al., 2003). Ho we v er , to our kno wledge no one has tested whether it is possible to automatically recognize per -sonality from con v ersation e xtracts of unseen sub-jects. Our h ypothesis is that automatic analysis of con v ersation to detect personality has application in a wide range of language processing domains. Identification of leaders using personality dimen-sions could be useful in analyzing meetings and the con v ersations of suspected terrorists (Hog an et al., 1994; T uck er and Whittak er , 2004; Nunn, 2005). Dating websites could analyze te xt messages to try to match personalities and increase the chances of a successful relationship (Donnellan et al., 2004). Di-alogue systems could adapt to the user X  s personality , lik e humans do (Ree v es and Nass, 1996; Funder and Sneed, 1993). This w ork is a first step to w ard indi-vidual adaptation in dialogue systems.

W e present non-linear statistical models for rank-ing utterances based on the Big Fi v e personality traits. Results sho w that the models perform sig-nificantly better than a random baseline, and that prosodic features are good indicators of e xtra v er -sion. A qualitati v e analysis confirms pre vious find-ings linking language and personality , while re v eal-ing man y ne w linguistic mark ers. Our approach can be summarized in fi v e steps: (1) collect indi vidual corpora; (2) collect personality ratings for each participant; (3) e xtract rele v ant fea-tures from the te xts; (4) b uild statistical models of the personality ratings based on the features; and (5) test the learned models on the linguistic outputs of unseen indi viduals. 2.1 Spok en language and personality ratings The data consists of daily-life con v ersation e xtracts of 96 participants wearing an Electronically Acti-v ated Recorder (EAR) for tw o days, collected by Mehl et al. (in press). T o preserv e the participants X  pri v ac y , random bits of con v ersation were recorded, and only the participants X  utterances were tran-scribed, making it impossible to reconstruct whole con v ersations. The corpus contains 97,468 w ords and 15,269 utterances. T able 1 sho ws utterances for tw o participants judged as intro v ert and e xtra v ert. T able 1: Extracts from the corpus, for participants rated as e xtremely intro v ert and e xtra v ert.
Between 5 and 7 independent observ ers scored each e xtract using the Big Fi v e In v entory (John and Sri v asta v a, 1999). Mehl et al. (in press) report strong inter -observ er reliabilities for all dimensions ( r = 0 . 84 , p &lt; 0 . 01 ). A v erage observ ers X  ratings were used as the scores for our e xperiments. 2.2 F eatur e selection Features are automatically e xtracted from each e x-tract (see T able 2). W e compute the ratio of w ords in each cate gory from the LIWC utility (Pennebak er et al., 2001), as those features are correlated with the Big Fi v e dimensions (Pennebak er and King, 1999). Additional psychological characteristics were com-puted by a v eraging w ord feature counts from the MRC psycholinguistic database (Coltheart, 1981). In an attempt to capture initiati v e-taking in con v ersa-tion (W alk er and Whittak er , 1990; Furnham, 1990), we introduce utterance type features using heuristics on the parse tree to tag each utterance as a command, prompt, question or assertion. Ov erall tagging accu-rac y o v er 100 randomly selected utterances is 88%. As personality influences speech, we also use Praat T able 2: Description of all features, with feature la-bels in brack ets. (Boersma, 2001) to compute prosodic features char -acterizing the v oice X  s pitch, intensity , and speech rate. 2.3 Statistical model By definition, personality e v aluation assesses rela-ti v e dif ferences between i nd i viduals, e.g. one per -son is described as an e xtra v ert because the a v erage population is not. Thus, we formulate personality recognition as a ranking problem: gi v en tw o indi-viduals X  e xtracts, which sho ws more e xtra v ersion?
Personality models are trained using RankBoost, a boosting algorithm for ranking, for each Big Fi v e trait using the observ ers X  ratings of personality (Fre-und et al., 1998). RankBoost e xpresses the learned models as rules, which support the analysis of dif-ferences in the personality models (see section 3). Each rule modifies the con v ersation e xtract X  s rank-ing score by  X  whene v er a feature v alue e xceeds e x-perimentally learned thresholds, e.g. Rule 1 of the e xtra v ersion model in T able 4 increases the score of an e xtract by  X  = 1 . 43 if the speech rate is abo v e 0.73 w ords per second. Models are e v aluated by a ranking error function which reports the percentage of misordered pairs of con v ersation e xtracts. The features characterize man y aspects of lan-guage production: utterance types , content and syn-tax (LIWC), psycholinguistic statistics (MRC), and prosody . T o e v aluate ho w each feature s et con-trib utes to the final result, we trained models with the full feature set and with each set indi vidually . Results are summarized in T able 3. The baseline is a model ranking e xtracts randomly , producing a rank-ing error of 0.5 on a v erage. Results are a v eraged o v er a 10 fold cross-v alidation.
 T able 3: Ranking errors o v er a 10 fold cross-v alidation for dif ferent feature sets (T ype=utterance type, Pros=prosody). Best models are in bold.
P aired t-tests sho w that models of e xtra v ersion, agreeableness, consci entiousness and intellect using all features are better than the random ordering base-line (tw o-tailed, p &lt; 0 . 05 ) 1 . Emotional stability is the most dif ficult trait to model, while agreeableness and conscientiousness produce the best results, with ranking errors of 0.31 and 0.33 respecti v ely . T able 3 sho ws that LIWC features perform significantly bet-ter than the baseline for all dimensions b ut emo-tional stability , while emotional stability is best pre-dicted by MRC features . Interestingly , prosodic fea-tures are v ery good predictors of e xtra v ersion, with a lo wer ranking error than the full feature set (0.26), while utterance type features on their o wn ne v er out-perform the baseline.

The RankBoost rules indicate the impact of each feature on the recognition of a personality trait by the magnitude of the parameter  X  associated with that feature. T able 4 sho ws the rules with the most impact on each best model, with the associated  X  v alues. The feature labels are in T able 2. F or e x-ample, the model of e xtra v ersion confirms pre vious findings by associating this trait with a high speech rate (Rules 1 and 4) and longer con v ersations (Rule 5). But man y ne w mark ers emer ge: e xtra v erts speak with a high pitch (Rules 2, 6 and 7), while intro v erts X  pitch v aries a lot (Rules 15, 18 and 20). Agreeable people use longer w ords b ut shorter sentences (Rule 1 and 20), while swear w ords reduce the agreeable-ness score (Rules 12, 18 and 19). As e xpected, con-scientious people talk a lot about their job (Rule 1), while unconscientious people swear a lot and speak loudly (Rules 19 and 20). Our models contain man y additional personality cues which aren X  t identified through a typical correlational analysis. W e sho wed that personality can be recognized auto-matically in con v ersation. T o our kno wledge, this is the first report of e xperiments testing trained mod-els on unseen subjects. There are models for each dimension that perform significantly better than the baseline. Combinations of these models may be use-ful to identify important personality types in dif-ferent NLP applications, e.g. a combination of e xtra v ersion, emotional stability and intellect indi-cates leadership, while lo w intellect, e xtra v ersion and agreeableness are correlated with perceptions of trustw orthiness.

One limitation for applications in v olving speech recognition is that recognition errors will introduce noise in all features e xcept prosodic features, and prosodic features on their o wn are only ef fecti v e in the e xtra v ersion model. Ho we v er , our data set is rel-ati v ely small (96 subjects) so we e xpect that more training data w ould impro v e model accuracies and might also mak e additional features useful. In fu-ture w ork, we plan to inte grate these models in a di-alogue system to adapt the system X  s language gener -ation; we will then be able to test whether the accu-racies we achie v e are suf ficient and e xplore methods for impro ving them.
 Thanks to Matthias Mehl and James Pennebak er for sharing their data.

