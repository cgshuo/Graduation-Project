 Typically, users interact with database systems by formu-lating queries. However, many times users do not have a clear understanding of their information needs or the exact content of the database, thus, their queries are of an ex-ploratory nature. In this paper, we propose assisting users in database exploration by recommending to them additional items that are highly related with the items in the result of their original query. Such items are computed based on the most interesting sets of attribute values (or faSets) that appear in the result of the original user query. The inter-estingness of a faSet is defined based on its frequency both in the query result and in the database instance. Database frequency estimations rely on a novel approach that employs an -tolerance closed rare faSets representation. We report evaluation results of the efficiency and effectiveness of our approach on both real and synthetic datasets.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query formulation, Search process Algorithms, Experimentation, Design, Performance
Typically, users interact with a database system by formu-lating queries. This interaction mode assumes that users are to some extent familiar with the content of the database and also have a clear understanding of their information needs. However, as databases get larger and become accessible to a more diverse and less technically-oriented audience, explo-ration or recommendation style database interactions seem attractive and useful.

A step towards this direction is offered by facet queries that provide a form of navigational search, where users re-strict their results by selecting interesting facets of the orig-inal results (e.g., [11]). With facet search, users start with a general query and progressively narrow its results down to  X 
Supported by the research program  X  X RAKLEITOS II X  co-funded by the European Union and National Sources. a specific item. Other related research includes addressing the many-or empty-answers problems. Approaches to the many-answers problem range from reformulating the origi-nal query so as to restrict the size of its result (for example, by adding additional constraints to it (e.g., [15]) to auto-matically ranking the query results and presenting to the user only the top-k most highly ranked among them (e.g., [7]). The empty-answers problem is commonly handled by relaxing the original query (e.g., [12]).

In this paper, we propose a novel exploration mode of in-teraction: we present to the users additional items which, although not part of the answer of their original query, may be of interest to them. This way users see information that they may be unaware that exists. For instance, when asking for movies directed by F.F. Coppola, we guide exploration by recommending movies by other directors that have directed movies similar to those of F.F. Coppola, i.e., with similar characteristics, such as, genre or production year. We also consider expanding the original query with additional at-tributes, by finding correlations with other relations. For example, when asking for the title of a movie, we also look into its genre or other characteristics.

The computation of recommended results is based on the most interesting sets of (attribute, value) pairs, called faSets, that appear in the result of the original user query. The in-terestingness of a faSet expresses how unexpected it is to see this faSet in the result. The computation of interestingness is based on the frequency of the faSet both in the user query result and in the database instance. Since computing the frequencies of faSets in the database instance on-line has prohibitively high cost, we opt to maintain statistics that allow us to estimate those frequencies when needed. More specifically, we propose a novel approach that is based on storing an -tolerance closed rare faSets representation as a summary of such frequencies and exploit these summaries to estimate the interestingness of the faSets that appear in theresultofanygivenuserquery.

We also present a two-phase algorithm for computing the top-k faSets. In the first phase, the algorithm uses the pre-computed statistics to set a frequency threshold that is then used to run a frequent itemset based algorithm on the result of the query. We evaluate the performance of our approach using both real and synthetic datasets.

The rest of this paper is organized as follows. Sec. 2 presents the overall framework, Sec. 3 its implementation and Sec. 4 an experimental evaluation. Finally, related work is presented in Sec. 5 and conclusions are offered in Sec. 6.
Let D be a relational database with n relations R = { R 1 ... , R n } and A be the set of all attributes in R . Without loss of generality, we assume that relation and attribute names are distinct. To locate items of interest, users pose queries. In particular, we consider Select-Project-Join (SPJ) queries of the following form: where rel ( Q )isasetofrelations, sel ( Q ) is a conjunction of selection conditions, join ( Q ) is a set of join conditions among the relations in rel ( Q )and proj ( Q )isthesetofpro-jected attributes. For simplicity, we shall focus on equality conditions, i.e., sel ( Q )=( A 1 = a 1 )  X  ...  X  ( A m = a  X  1, where A i  X  X  and a i  X  domain ( A i ). The result set , Res ( Q ), of a query Q is a relation with schema proj ( Q ).
Since users must specify in their queries the conditions that the searched items need to satisfy, they must have a somewhat clear understanding of the information they are seeking. In this paper, we propose an exploratory way of discovering interesting information based on identifying po-tentially interesting pieces of information based on the initial result set and then using these pieces to explore the database further by recommending additional results to the users. Let us first define pieces of information in the result set:
Definition 1 (Facet and m -FaSet). A facet condi-tion ,orsimply facet , is a condition of the form ( A i = a where A i  X  X  and a i  X  domain ( A i ) .An m -set of facets or m -faSet, m  X  1, is a set of m facet conditions on m different attributes.
 We shall also use the term faSet when the size of the m -faSet is not of interest.

For a faSet f ,weuse Att ( f ) to denote its attributes. Let t be a tuple from a set of tuples S with schema R ;wesay that t satisfies a faSet f ,where Att ( f )  X  R ,if t [ A for all facets ( A i = a i )  X  f . We call the percentage of tuples in S that satisfy f , support of f in S . In the following, we use the term faSet to mean both the conditions and the list of the associated values appearing in the conditions. Example : Consider the movies database in Fig. 1 and the query and its corresponding result set in Fig. 2. Then {
G.genre =  X  X rama X  } or simply {  X  X rama X  } is a 1-faSet and {
M.year =  X 1972 X  , G.genre =  X  X rama X  } or simply {  X 1972 X  ,  X  X rama X  } is a 2-faSet.

We are looking for interesting pieces of information at the granularity of a faSet: this may be the value of a single attribute (i.e., a 1-faSet) or the values of m attributes (i.e., an m -faSet).
 Example : Consider the example in Fig. 2, where a user poses a query to retrieve movies directed by F.F. Coppola. {  X  X rama X  } is a 1-faSet in the result that is likely to inter-est the user, since it is associated with many of the movies directed by F.F. Coppola. The same holds for the 2-faSet {  X 1983 X  ,  X  X rama X  } .

To define faSet relevance formally, we take an IR-based approach and rank faSets in decreasing order of their odds of being relevant to a user information need. For a user information need u Q expressed through a query Q ,let R u be the set of tuples that are relevant to u Q and R u Q be the set of tuples that are not relevant to u Q . Then, the relevance score of a faSet f for u Q is defined as: where p ( R u Q | f )(resp. p ( R u Q | f )) is the probability that a tuple satisfying f is relevant (resp. not relevant) to u Q ing the Bayes rule we get: Since p ( R u Q )and p ( R u Q ) have the same value for all faSets, and thus do not affect their ranking, they can be ignored.
We make the assumption that all relevant to u Q results are those that appear in Res ( Q ), thus p ( f | R u Q )isequalwith the probability that f is satisfied by a tuple in the result set, that f is satisfied by a tuple that is not relevant, that is, a tuple that does not belong to the result set. We make the logical assumption that the result set is small in comparison with the size of the database, and approximate the non-relevant tuples with all tuples in the database, that is, all tuples in the global relation, denoted by D , with schema A . Based on the above motivation, we provide the following definition for the relevance of a faSet:
Definition 2 (Interestingness Score). Let Q be a query and f be a faSet with Att ( f )  X  proj ( Q ) .Theinter-estingness score, score ( f, Q ) ,of f for Q is defined as:
The term p ( f | Res ( Q )) is estimated by the support of f in Res ( Q ), that is, the percentage of tuples in the result set that satisfy f .Theterm p ( f |D ) is a global measure that does not depend on the query. It serves as an indication of how frequent the faSet is in the whole dataset, i.e., it measures the discriminative power of f .
 Example : In the example in Fig. 2,  X  X rama X  appears more frequently than  X  X hriller X  in the result set. However, if  X  X hriller X  appears only a handful of times in the database, then it would be considered more interesting than  X  X rama X  .
In general, a faSet stands out when it appears more fre-quently in Res ( Q ) than expected. Clearly, the sel ( Q ) part of a query is also a faSet. Therefore, another way of interpret-ing the interestingness score of f for Q is as the confidence of the association rule: sel ( Q )  X  f . High confidence indi-cates a strong dependency of the faSet f on the selection conditions of Q .

Finally, note that in particular, for a faSet f with Att ( f ) Att ( sel ( Q )), that is, for a faSet that includes only attributes whose values are specified in the selection conditions, it holds that score ( f, Q )  X  1, since p ( f | Res ( Q )) = 1. Attribute Expansion: Def. 2 provides a means of ranking the various faSets that appear in the result set of a query Q and discovering the most interesting among them. How-ever, there may be interesting faSets that include attributes not in proj ( Q ) and thus do not appear in Res ( Q ). For ex-ample take a query Q that just returns the titles of movies directed by F.F. Coppola. All faSets appear only once in the result set of Q . However, including for instance the relation  X  X ountries X  in rel ( Q ) (and modifying join ( Q ) accordingly) may disclose interesting information, e.g., that many of the movies directed by F.F. Coppola are related to Romania.
To this end, we extend the definition of interestingness to include faSets with attributes not in proj ( Q ), by intro-ducing an extended query Q with the same sel ( Q )asthe original query Q but with additional attributes in proj ( Q ) and additional relations in rel ( Q ).
 Definition 3 (Extended Interestingness Score).
 Let Q be a query and f be a faSet with Att ( f )  X  X  .The interestingness score of f for Q is equal to: where Q is an SPJ query with proj ( Q ) = proj ( Q )  X  Att ( f ) , rel ( Q )= rel ( Q )  X  X  R | A i  X  R ,for A i  X  Att ( f ) } = sel ( Q ) and join ( Q )= join ( Q )  X  ( joins with { R R ,for A i  X  Att ( f ) } ) .
Besides locating interesting faSets, we also use interesting faSets to discover additional pieces of data that are poten-tially related to the user needs. In particular, we aim at con-structing exploratory queries that retrieve results strongly correlated with those of the original user query Q by replac-ing the selection conditions, sel ( Q ), of Q with related ones. Recall that a high interestingness score for f means that the confidence of sel ( Q )  X  f is high, indicating replacing sel ( Q ) with f ,since sel ( Q ) seems to impose f .

For example, by replacing sel ( Q )of Q in Fig. 2 with its interesting faSet {  X  X rama X  } , we get the exploratory query: which retrieves other directors that have also directed drama movies, which is an interesting value appearing in the origi-nal query result set.

Definition 4 (Exploratory Query). Let Q be a user query and f be an interesting faSet for Q . The exploratory query  X  Q that uses f is an SPJ query with proj (  X  Q )= Attr ( sel ( Q )) , rel (  X  Q ) = rel ( Q )  X  X  R | A i  X  R ,for A sel (  X  Q ) = f  X  X  sel ( Q ) and join (  X  Q ) = join ( Q ) { R | A i  X  R ,for A i  X  Att ( f ) } ) .

Then, interesting faSets for the exploratory  X  Q are recom-mended to the user. Clearly, one can use the interesting faSets in the results of an exploratory query to construct other exploratory queries. This way, users may start with an initial query Q and gradually discover other interesting information in the database through results attained by ap-plying exploratory queries progressively. ions.
 Framework Overview: In summary, ReDRIVE database exploration works as follows. Given a query Q , the top-k most interesting faSets for Q are computed and presented to the users. Such faSets may be either interesting pieces (sub-tuples) of the tuples in the result set of Q or extended tuples that include additional attributes not in the origi-nal result. Interesting faSets are further used to construct exploratory queries that lead to discovering additional infor-mation related to the initial user query. This process may be repeated for each exploratory query.
In this section, we present algorithms for finding inter-esting faSets. In particular, first, we present an approach to maintaining statistics for estimating p ( f |D ) for each faSet f . Then, we present a two-phase algorithm for computing the top-k most interesting faSets for a query Q . Proofs omitted can be found in [9].
To compute the interestingness of a faSet f for a query Q according to Def. 2 (resp. Def. 3), we need to compute two quantities: p ( f | Res ( Q )) (resp. p ( f | Res ( Q ))) and p ( f Whereas p ( f | Res ( Q )) (resp. p ( f | Res ( Q ))) is different for each Q , and thus needs to be computed on-line, p ( f is the same for all user queries. The straightforward ap-proach would be to also compute p ( f |D ) on-line for each query Q , by counting for each examined faSet f the number of database tuples that satisfy it. Given the large number of such faSets and the size of the database, the cost of such computations may become prohibitively expensive. We pro-pose pre-computing and storing some form of information that will allow us to estimate p ( f |D ), thus avoiding such on-line computations. Next, we discuss available options.
Let m max be the maximum number of projected attributes of any user query, i.e., m max = |A| . An exhaustive approach would be to generate all possible faSets of size up to m max and pre-compute their support in D . Such an approach, however, is infeasible even for small databases due to the exponential number of possible faSets.

A first approach is to pre-compute and store the support of all 1-faSets in D . Then, assuming that facet conditions are satisfied independently from each other, the support of a higher-order m -faSet is equal to: p ( f |D )= p ( { A 1 = a 1 ,...,A m = a m }|D )= This approach requires maintaining information for a rel-atively small number of faSets, i.e., A i  X  X  | domain ( A faSets. However, the independence assumption is unrealis-tic in real-world applications.

Now, let us assume that we maintain the support of all faSets up to size . In this case, we can attain a more ac-curate estimation of the support of a high-order m -faSet f , m&gt; , using a more sophisticated method such as Iterative Proportional Fitting (IPF) [4] used in [15]. The supports of low-order faSets provide some knowledge for the distri-bution of the supports of high-order faSets. IPF is based on the Principle of Maximum Entropy, which states that, since there is no reason to bias the estimated distribution towards any specific form, then the estimation should be as close to the uniform distribution as possible. The maximum entropy criterion smooths the estimated distribution. This may lead to the loss of interesting information. Consider for example that the faSets { G.genre = X  Sci-Fi  X  } , { M.year = X  2000  X  } , { M.year = X  2005  X  } have similar supports, while the supports of { G.genre = X  Sci-Fi  X , M.year = X  2000  X  } {
G.genre = X  Sci-Fi  X , M.year = X  2005  X  } differ a lot. IPF (for = 1) will estimate similar values for these two faSets.
We propose a different form of statistics aiming at cap-turing fluctuations in the support of related faSets. To do this, we extend the notion of  X  -tolerance frequent itemsets [8] and define -tolerance closed rare faSets.
 Preliminaries: In data mining, the term itemset refers to a set of items. An itemset is said to be frequent in a dataset if its frequency is above a specific threshold. Otherwise it is called rare . Clearly, an m -faSet is an itemset whose items are facets. An itemset { A 1 = a 1 ,...,A m = a m } appears in exactly the same set of tuples that satisfy the m -faSet f = { A 1 = a 1 , ..., A m = a m } . Therefore, we say that a faSet f is frequent (resp. rare (RF)) for a set of tuples S if its support in S is above (resp. below) a specific threshold. Also, we define a faSet f to be closed rare (CRF) for S if it is rare and has no proper subset f , f  X  f , such that, f has the same support as f in S . A faSet f is minimal rare (MRF) for S , if it is rare and has no subset f such that f is rare for S .
 Statistics based on -tolerance: Maintaining the sup-port of a number of representative faSets can assist us in estimating the support of a given faSet f . Generally, faSets that appear frequently in the database D are not expected to be interesting, even if they appear often in the result of user queries, since this is expected. Therefore, it is useful to maintain information about the support of rare faSets in D .Weuse count ( f, S ) to denote the absolute number of appearances of a faSet f in a set of tuples S .
 If we maintain the MRFs, we can derive all corresponding RFs but not their actual support, while if we keep the CRFs we can retrieve these supports as well. However, the number of CRFs is in practice very large, since any RF that has a distinct support is a CRF. Thus, our goal is to store a tunable amount of rare faSets from which we will be able to retrieve a bounded estimation of the support of a given faSet in the database. This is achieved by relaxing the definition of CRFs to maintain only those RFs whose support differs from their rare subsets based on a threshold .Inparticular, we define -tolerance closed rare faSets ( -CRFs) as follows:
Definition 5 ( -CRF). AfaSet f is called -CRF for a set of tuples S , if and only if, it is rare for S and it has no proper immediate rare subset f , i.e., | f | = | f | X  1 ,such that, count ( f ,S ) &lt; (1 + ) count ( f, S ) ,where  X  0 . Intuitively, a rare faSet f is an -CRFif,evenifweincrease its count by a constant , all its subsets still have a larger fre-quency than f . This means that f has a different frequency from all its subsets and cannot be estimated (or represented) by any of them.

Let us assume that a set of -CRFs is maintained for some value of . We denote this set C .AnRF f either belongs to C or not. If f  X  C , then the support of f is stored and its count is readily available. If not, then, according to Def. 5, there is some subset of f that belongs to C whose support is close to that of f .Weuse C ( f ) to denote the faSet in C that is the most suitable one to estimate the count of f , i.e., the largest subset of f in C . The following lemma holds: Lemma 1. Let C be a set of -CRFs for a set of tuples S and f be a faSet, f/  X  C . Then, there exists f , f  X  C , such that, count ( f ,S )  X   X  count ( f, S ) ,where  X  =(1+ )
To provide estimations, each -CRF is stored along with its frequency extension defined as follows:
Definition 6 (Frequency Extension). Let C be a set of -CRFs for a set of tuples S and f be a faSet in C .Let also X ( f ) be the set of all RFs represented in C by f .Then, X ( f )= { x | x  X  X  ( f )  X | x | X  X  f | = i } , 1  X  i  X  m ,where m =max { i | X i ( f ) =  X  X  . The frequency extension of f for i , 1  X  i  X  m , is defined as: Intuitively, the frequency extension of f for i is the average count difference between f and all the faSets that f rep-resents whose size difference from f is equal to i . Given a faSet f , the estimation of p ( f |D ), denoted  X  p ( f |D It holds that:
Lemma 2. Let f be an -CRF. Then,  X  i , it holds that  X  ext ( f, i )  X  1 ,where  X  =(1+ ) i .

It can be shown that the estimation error is bounded by  X  , i.e., by . More specifically, let f be an RF and | f | X  X  C ( f ) i . The estimation error for p ( f |D ) is bounded as follows:
Given a query Q , our goal is to locate the k faSets with the highest interestingness scores. Clearly, the brute-force method of generating all possible faSets in Res ( Q )andcom-puting their score is exponential on the number of distinct values that appear in Res ( Q ). Applying an a-priori ap-proach for generating and pruning faSets is not applicable either, since score is neither an upwards nor a downwards closed measure. Recall that, a measure d is upwards closed if for any two sets S and S , S  X  S  X  d ( S )  X  d ( S )and downwards closed if S  X  S  X  d ( S )  X  d ( S ).

Proposition 1. Let Q be a query and f afaSet. score ( f, Q ) is neither an upwards nor a downwards closed measure. This implies that we cannot employ any subset or superset relations among the faSets of Res ( Q ) to prune the search space.

As a baseline approach to reduce the number of examined faSets of Res ( Q ), we consider only the most frequent faSets of Res ( Q ), motivated by the fact that faSets that appear in Res ( Q ) frequently are likely to be highly interesting to the user. To this end, we apply an adaptation of a frequent itemset mining algorithm to generate all frequent faSets of Res ( Q ), that is, all faSets with support larger than some pre-specified threshold minsupp f . Then, for each frequent faSet f , we use the maintained statistics to estimate p ( f and compute score ( f, Q ).

This baseline approach has the problem of being highly dependent on minsupp f .Alargevalueof minsupp f may lead to losing some less frequent in the result but very rarely appearing in the database faSets, whereas a small value may result in a very large number of candidate faSets being examined. Therefore, we propose a Two-Phase Algorithm (TPA), described next, that addresses this issue by setting minsupp f to an appropriate value so that all top-k faSets are located without generating redundant candidates. TPA assumes that the maintained statistics are based on keeping rare faSets of the database D .Let minsupp r be the support threshold of the maintained rare faSets.

In the first phase of the algorithm, all facet conditions, or 1-faSets, that appear in Res ( Q ) are located. TPA checks which rare faSets of D , according to the maintained statis-tics, contain only facet conditions from Res ( Q ). Let X be the set of faSets. Then, in one pass of Res ( Q ), all faSets of Res ( Q ) that are supersets of some faSet in X are generated and their support in Res ( Q ) is measured. For each of the located faSets, score ( f, Q ) is computed. Let s be the k highest score among them. TPA sets minsupp f equal to s  X  minsupp r and proceeds to the second phase where it executes a frequent itemset mining algorithm with thresh-old equal to minsupp f .AnyfaSetin Res ( Q ) less frequent than minsupp f has score smaller than the k th faSet located in the first phase and thus can be safely ignored. To see this, let f be a faSet examined in the second phase of the algorithm. Since the score of f has not been computed in the first phase, then p ( f |D ) &gt; minsupp r . Therefore, for score ( f, Q ) &gt;s to hold, it must be that p ( f | Res ( Q )) &gt;s p ( f |D ), i.e., p ( f | Res ( Q )) &gt;s  X  minsupp r .TPAisshown in Alg. 1. Algorithm 1 Two-Phase Algorithm (TPA).
 2: for all faSets f  X  C do 3: if all 1-faSets g  X  f are contained in A then 4: f.score = score ( f, Q ), S  X  S  X  X  f } 5: end if 6: end for 7: for all tuples t  X  Res ( Q ) do 8: generate all faSets f  X  t ,s.t.  X  g  X  S with g  X  f 9: for all such faSets f do 10: f.score = score ( f, Q ), S  X  S  X  X  f } 11: end for 12: end for 15: for all faSets f in candidates do 16: f.score = score ( f, Q ), S  X  S  X  X  f } 17: end for 18: return The k faSets in S with the highest scores
In this section, we present experimental results of the de-ployment of our approach. We use two real datasets: (i)  X 
AUTOS  X , a single-relation database consisting of 41 charac-teristics for 15,191 used cars from Yahoo!Auto [2] and (ii)  X 
MOVIES  X , a database with 13 relations whose sizes range from around 10,000 to almost 1,000,000 tuples, containing information extracted from the Internet Movie Database [1]. We use also synthetic datasets consisting of a single relation with 5 attributes and 1,000 tuples, taking values generated using a zipf distribution from a 5-value domain.
 Statistics Generation : First, we evaluate the proposed method for maintaining statistics based on -CRFs in terms of (i) storage, measured as the number of stored faSets and (ii) generation time. We report results for all intermedi-ate computation steps, i.e., locating MRFs, RFs and CRFs. We base our implementation for locating MRFs and RFs on the MRG-Exp and Arima algorithms [18] and use an adapted version of the CFI2TCFI algorithm [8] for produc-ing -CRFs. For a given minsupp r , all MRFs are located. However, locating all RFs is inefficient due to the exponen-tial nature of algorithms such as Apriori. To overcome this, we use a random walk based approach [10]: instead of pro-ducing all RFs, we produce only a subset of them discovered by random walks initiated at the MRFs.

Table 1(a) reports the number of produced faSets for dif-ferent values of minsupp r and . In the reported results, we kept the number of random walks fixed (equal to 20). As increases, an -CRF represents faSets with larger sup-port differences and, thus, the number of maintained statis-tics decreases. As minsupp r increases, more faSets of the database are considered to be rare and, thus, the number of maintained faSets should also increase. However, this is not always the case because of the random walks technique employed to retrieve RFs. Note also that the number of -CRFs is much smaller than the number of RFs, even for values of as low as 0 . 5. For comparison, we also report the number of 2-faSets (Table 1(b)with id attributes excluded) that could alternatively be used for estimating frequencies, as discussed in Sec. 3, which is considerably large for the real databases. Finally, in terms of execution time, the main overhead was induced by the stage of generating RFs which can take up many minutes, while all other stages require a couple of seconds for all datasets (see [9] for details). Estimation Accuracy : Next, we evaluate the accuracy of estimating the support of rare faSets using the support of the stored -CRFs. For this, we employ our synthetic datasets and probe our statistics to retrieve estimations for the frequency of 10 rare faSets for each possible size. We observed that, even though we do not maintain the com-plete set of -CRFs, because of our random walks approach, the estimation error remains low and below the theoretical bound. For example, for =0.9,and minsupp r =10%,the absolute error was 3.0 to 4.0 on average. The same holds for the real datasets (see [9] for details).

We also experimented using IPF. This approach turned out to be very inefficient for estimating the frequency of rare faSets. This was mainly due to two reasons. Take for example rare 3-faSets. When they consist of rare 2-faSets, their estimated support was too small (most often equal to zero) due to the maximum entropy principle that tends to considers faSet co-occurrences independent. On the other hand, when rare 3-faSets consist of frequent 2-faSets, their support was over-estimated (often at a ten-fold order). Top-k FaSet Discovery : We compare the baseline and the Two-Phase (TPA) algorithms. For the synthetic datasets, we generate random queries, while for the real databases we use predefined queries selected so that their result sets include various combinations of rare and frequent faSets. Fig. 3 shows the 1st and 20th highest ranked interestingness score retrieved. For TPA we set k = 20 and for the baseline approach we start with a high minsupp f and gradually de-crease it until we get at least 20 results. TPA retrieves more interesting faSets, mainly due to the first phase where rare faSets in Res ( Q ) are examined. For the reported results was equal to 0.5. In general, the value of did not affect the interestingness scores of the top-k results considerably. In most cases TPA located k results during phase one and, thus, phase two was not executed.
 Exploring the two Real Databases: We experimented with the exploration of the real databases. Due to space lim-itations, we just present two of our observations about the acquired results. For example, take a query in the AUTOS database about car models with navigation systems which is a query whose result set includes many rare faSets, all hav-ing a high interestingness score, e.g., the car models  X  Land Rover Discovery II HSE7  X  X nd X  Mercedes-Benz G55 AMG  X . Expanding the query towards the  X  X tate X  attribute reveals interesting faSets not present in the original result, such as the  X  Land Rover Range Rover  X  model in VA and the  X  Cadil-lac  X  model in DE, suggesting that such combinations are highly related with navigation systems but only in specific states. As another example take the query in the MOVIES database for the countries and genres of movies directed by F.F. Coppola. FaSet {  X  Switzerland  X ,  X  Sci-Fi  X  } is retrieved as the most interesting, since this is extremely rare in the database, and it is very interesting that it was located by the user query. Another highly ranked faSet for this query is {  X  Romania  X  } (and its supersets).
In this paper, we have proposed a novel database explo-ration model. A common exploration technique is faceted search (e.g., [14, 11]), where query results are classified into different multiple categories, or facets, and the user refines these results by selecting one or more facet condition. Our approach is different in that we do not tackle refinement, instead, our goal is to discover other interesting results re-lated to the results of the original query. There is also some relation to query reformulation , where a query is relaxed or restricted when its results are too few or too many respec-tively, using term rewriting or query expansion to increase recall and precision (e.g., [15]). Again, our aim is locating interesting results that are highly related to the results of the original query. Besides restricting the query, another com-mon method of addressing the too-many answers problem is ranking its results and presenting only the top-k ones to the user. This line of research is extensive; the work most re-latedtooursisresearchon automatically ranking the results [7, 3]. Besides addressing a different problem, our approach is also different in that the granularity of ranking is at the level of faSets as opposed to whole result tuples. We also propose a novel method for frequency estimation. In terms of the interestingness score, similar measures have been used in the literature, such as unexpectedness [21] and  X  2 [5].
Yet another method of exploring results relies on why queries that consider the presence of unexpected tuples in the result and why not queries that consider the absence of expected tuples in the result. For example, ConQueR [19] proposes posing follow-up queries for why not by relaxing the original query. In our approach, we find interesting faSets in the result based on their frequency and other faSets highly correlated with them. Another line of research considers how to  X  X utput X  a query whose execution will yield results equivalent to a given result set [20, 16]. Our work differs in that we do not aim at constructing queries to match given result sets but rather guiding the users towards novel results.
Finally, in some respect, exploration queries may be seen as recommendations . In a previous position paper [17], we have discussed various approaches for making recommen-dations in relational databases. Extending database queries with recommendations has been studied in two recent works, namely [13] and [6]. In [13], a general framework and a re-lated engine are proposed for the declarative specification of the recommendation process. Recommendations in [6] are based on the past behavior of similar users, whereas we consider only the content of the database and the result.
In this paper, we introduced ReDRIVE, a novel database exploration framework for recommnding to users items which may be of interest to them although not part of the results of their original query. The computation of such additional re-sults is based on identifying the most interesting sets of (at-tribute, value) pairs, or faSets, that appear in the result of the original user query. The computation of interestingness is based on the frequency of the faSet in the query result and in the database instance. We also proposed a frequency es-timation method based on storing an -CRF representation and a two-phase algorithm for computing the top-k faSets. There are many directions for future work, such as, extend-ing our work to more general types of facet conditions and considering that a history of previous database queries and results exists.
