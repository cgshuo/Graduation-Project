 Media seems to have become more partisan, often providing a biased coverage of news catering to the interest of specific groups. It is therefore essential to identify credible information content that provides an objective narrative of an event. News communities such as digg, reddit, or newstrust offer recommendations, reviews, quality ratings, and further insights on journalistic works. However, there is a complex interaction between different factors in such online communities: fairness and style of reporting, language clarity and objectivity, topical perspectives (like political viewpoint), expertise and bias of community members, and more.

This paper presents a model to systematically analyze the dif-ferent interactions in a news community between users, news, and sources. We develop a probabilistic graphical model that leverages this joint interaction to identify 1) highly credible news articles, 2) trustworthy news sources, and 3) expert users who perform the role of  X  X itizen journalists X  in the community. Our method extends CRF models to incorporate real-valued ratings, as some communities have very fine-grained scales that cannot be easily discretized with-out losing information. To the best of our knowledge, this paper is the first full-fledged analysis of credibility, trust, and expertise in news communities.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Information Filtering ; I.2.7 [ Computing Method-ologies ]: Artificial Intelligence -Natural Language Processing Credibility; News Community; Probabilistic Graphical Models Motivation: Media plays a crucial role in the public dissemination of information about events. Many people find online information and blogs as useful as TV or magazines. At the same time, however, people also believe that there is substantial media bias in news coverage [24, 8], especially in view of inter-dependencies and cross-ownerships of media companies and other industries (like energy).
Several factors affect the coverage and presentation of news in media incorporating potentially biased information induced via the fairness and style of reporting. News are often presented in a polar-ized way depending on the political viewpoint of the media source (newspapers, TV stations, etc.). In addition, other source-specific properties like viewpoint, expertise, and format of news may also be indicators of information credibility.

In this paper, we embark on an in-depth study and formal model-ing of these factors and inter-dependencies within news communities for credibility analysis . A news community is a news aggregator site (e.g., reddit.com, digg.com, newstrust.net) where users can give explicit feedback (e.g., rate, review, share) on the quality of news and can interact (e.g., comment, vote) with each other. Users can rate and review news, point out differences, bias in perspectives, unverified claims etc. However, this adds user subjectivity to the evaluation process, as users incorporate their own bias and perspec-tives in the framework. Controversial topics create polarization among users which influence their ratings. [30, 6] state that online ratings are one of the most trusted sources of user feedback; however they are systematically biased and easily manipulated.
 Problem Statement: Given a set of news sources generating news articles, and users reviewing those articles on different qualitative aspects with mutual interactions  X  our objective is to jointly rank the sources, articles, and users based on their trustworthiness, credibility, and expertise respectively.

In this process, we want to analyze the influence of various factors like the writing style of a news article, its topic distribution, type of media and format of news, political viewpoint and expertise, and other user traits on the credibility analysis of the community. Our Approach: To analyze the factors and inter-dependencies in a news community, we have developed a sophisticated probabilistic graphical model, specifically a Continuous Conditional Random Field (CCRF) model, which exploits several moderate signals of interaction jointly between the following factors to derive a strong signal for information credibility (refer to Figures 1a and 1b). In particular, the model captures the following factors.  X  Language and credibility of a news article : objectivity , rationality, and general quality of language in the news article. Objectivity is the quality of the news to be free from emotion, bias and prejudice of the author. The credibility of a news article refers to presenting an unbiased, informative and balanced narrative of an event.  X  Properties and trustworthiness of a news source : trustworthiness of a news source in the sense of generating credible articles based on source properties like viewpoint, expertise and format of news.  X  Expertise of users and review ratings : expertise of a user, in the news community, in properly judging the credibility of news ar-ticles. Expert users should provide objective evaluations  X  by reviews and/or ratings  X  of news articles, corroborating with the evaluations of other expert users. This can be used to identify potential  X  X itizen journalists X  [17] in the community.

We show that the CCRF performs better than sophisticated col-laborative filtering approaches based on latent factor models, and regression methods that do not consider all these interactions.
Although this work is focused on news communities, the frame-work can also be used for instance, in health communities (e.g. healthboards.com ) where users write posts on drug usage  X  the objective being to jointly rank posts, drug side-effects, and users based on their quality, credibility, and trustworthiness respectively.
In this work, the attributes credibility and trustworthiness are always associated with a news article and a news source, respectively. The joint interaction between several factors also captures that a source garners trustworthiness by generating credible news articles, which are highly rated by expert users. Similarly, the likelihood of a news article being credible increases if it is generated by a trustworthy source.

Some communities offer users fine-grained scales for rating dif-ferent aspects of news articles and news sources. For example, the newstrust.net community analyzes an article on 15 aspects like in-sightful, fairness, style and factual. These are aggregated into an overall real-valued rating after weighing the aspects based on their importance, expertise of the user, feedback from the community, and more. This setting cannot be easily discretized without blow-up or risking to lose information. Therefore, we model ratings as real-valued variables in our CCRF.
 Contributions: The paper introduces the following novel elements:  X  A continuous CRF that captures the mutual dependencies between credibility of articles, trustworthiness of sources, expertise of users, and expresses real-valued ratings.  X  An inference method for the CCRF that allows us to jointly (a) predict ratings; and (b) rank articles, sources, and users by their credibility, trustworthiness, and expertise, respectively.  X  A large experimental study with data from newstrust.net , one of the most sophisticated news communities with a focus on quality journalism.

The rest of the paper is organized as follows. Section 2 presents how we model news communities, and which factors we include in the model. Section 3 develops the CCRF that captures the interaction between all the factors. Section 4 introduces the dataset that we use for experimental evaluation and further studies. Section 5 presents our experimental results followed by discussion.
Our approach exploits the rich interaction taking place between the different factors in a news community. We propose a proba-bilistic graphical model that leverages the interplay between news credibility, language objectivity, source trustworthiness, and user expertise. Refer to Figure 1 for the following discussion.
Consider a set of news sources  X  s  X  (e.g., s 1 in Figure 1c) generat-ing articles  X  d  X  which are reviewed and analyzed by users  X  u  X  for their credibility. Consider r ij to be the review by user u d . The overall article rating of d i is given by y i .

In our model, each news source, news article, user and her rating or review, and overall article rating is associated with a continuous random variable r.v.  X  [1 ... 5] , that indicates its trustworthiness, objectivity, expertise, and credibility, respectively. 5 indicates the best quality that an item can obtain, and 1 is the worst. Discrete ratings, being a special case of this setting, can be easily handled.
Each node is associated with a set of observed features that are extracted from the news community. For example, a news source has properties like topic specific expertise, viewpoint and format of news; a news article has features like topics, and style of writing from the usage of discourse markers and subjective words in the article. For users we extract their topical perspectives and exper-tise, engagement features (like the number of questions, replies, reviews posted) and various interactions with other users (like up-votes/downvotes) and news sources in the community.

The objective of our model is to predict credibility ratings  X  y  X  of news articles  X  d  X  by exploiting the mutual interactions between different variables. The following edges between the variables capture their interplay:  X  Each news article is connected to the news source from where it is extracted (e.g., s 1  X  d 1 , s 1  X  d 2 )  X  Each news article is connected to its review or rating by a user (e.g., d 1  X  r 11 , d 1  X  r 12 , d 2  X  r 22 )  X  Each user is connected to all her reviews (e.g., u 1  X  r u  X  Each user is connected to all news articles rated by her (e.g., u d 1 , u 2  X  d 1 , u 2  X  d 2 )  X  Each source is connected to all the users who rated its articles (e.g., s 1  X  u 1 , s 1  X  u 2 )  X  Each source is connected to all the reviews of its articles (e.g., s  X  For each article, all the users and all their reviews on the article are inter-connected (e.g., u 1  X  r 12 , u 2  X  r 11 , u 1  X  u 2 user-user interactions (e.g., u 1 upvoting/downvoting u 2 d 1 ) influencing the overall article rating.

Therefore, a clique (e.g., C 1 ) is formed between a news article, its source, users and their reviews on the article. Multiple such cliques (e.g., C 1 and C 2 ) share information via their common news sources (e.g., s 1 ) and users (e.g., u 2 ).
 News topics play a significant role on information credibility. Individual users in community (and news sources) have their own perspectives and expertise on various topics (e.g., environmental pol-itics). Modeling user-specific topical perspectives explicitly captures credibility judgment better than a user-independent model. However, many articles do not have explicit topic tags. Hence we use Latent Dirichlet Allocation (LDA) [1] in conjunction with Support Vector Regression (SVR) [4] to learn words associated to each (latent) topic, and user (and source) perspectives for the topics. Documents are assumed to have a distribution over topics as latent variables, with words as observables. Inference is by Gibbs sampling. This LDA model is a component of the overall model, discussed next. We use a probabilistic graphical model, specifically a Conditional Random Field (CRF), to model all factors jointly. The modeling approach is related to the prior work of [23]. However, unlike that work and traditional CRF models, our problem setting requires a continuous version of the CRF (CCRF) to deal with real-valued ratings instead of discrete labels. In this work, we follow an ap-proach similar to [26, 27, 32] in learning the parameters of the CCRF. We use Support Vector Regression [4] to learn the elements of the feature vector for the CCRF.

The inference is centered around cliques of the form  X  source, article,  X  users  X  ,  X  reviews  X  X  . An example is the two cliques C 1 : s 1  X  d 1  X  X  u 1 ,u 2  X  X  X  X  r 11 ,r 12  X  and C 2 : s 1  X  d in the instance graph of Figure 1c. This captures the  X  X ross-talk X  between different cliques sharing nodes. A news source garners trustworthiness by generating multiple credible articles. Users attain expertise by correctly identifying credible articles that corroborate with other expert users. Inability to do so brings down their exper-tise. Similarly, an article attains credibility if it is generated by a trustworthy source and highly rated by an expert user. The inference algorithm for the CCRF is discussed in detail in Section 3.
In the following subsections, we discuss the various feature groups that are considered in our CCRF model.
The style in which news is presented to the reader plays a pivotal role in understanding its credibility. The desired property for news is to be objective and unbiased. In this section, we examine the different stylistic indicators of news credibility. All the lexicons used in this section are compiled from [28, 23].
 Assertives : Assertive verbs (e.g.,  X  X laim X ) complement and modify a proposition in a sentence. They capture the degree of certainty to which a proposition holds.
 Factives : Factive verbs (e.g.,  X  X ndicate X ) pre-suppose the truth of a proposition in a sentence.
 Hedges : These are mitigating words (e.g.,  X  X ay X ) to soften the degree of commitment to a proposition.
 Implicatives : These words trigger pre-supposition in an utterance. For example, usage of the word complicit indicates participation in an activity in an unlawful way.
 Report verbs : These verbs (e.g.,  X  X rgue X ) are used to indicate the attitude towards the source, or report what someone said more accurately, rather than using just say and tell .
 Discourse markers : These capture the degree of confidence, per-spective, and certainty in the set of propositions made. For instance, strong modals (e.g.,  X  X ould X ), probabilistic adverbs (e.g.,  X  X aybe X ), and conditionals (e.g.,  X  X f X ) depict a high degree of uncertainty and hypothetical situations, whereas weak modals (e.g.,  X  X hould X ) and inferential conjunctions (e.g.,  X  X herefore X ) depict certainty. Subjectivity and bias : News is supposed to be objective: writers should not convey their own opinions, feelings or prejudices in their stories. For example, a news titled  X  X hy do conservatives hate your children? X  is not considered objective journalism. We use a subjectivity lexicon 1 , a list of positive and negative opinionated words 2 , and an affective lexicon 3 to detect subjective clues in arti-
Table 1: Latent topics (with illustrative labels) and their words. cles. The affective features capture the state of mind (like attitude and emotions) of the writer while writing an article or post (e.g., anxiousness, confidence, depression, favor, malice, sympathy etc.).
We additionally harness a lexicon of bias-inducing words ex-tracted from the Wikipedia edit history from [28] exploiting its Neutral Point of View Policy to keep its articles  X  X airly, proportion-ately, and as far as possible without bias, all significant views that have been published by reliable sources on a topic  X .
 Feature vector construction : For each stylistic feature type f and each news article d j , we compute the relative frequency of words of type f i occurring in d j , thus constructing a feature vector F
L ( d j ) =  X  freq ij = #( words in f i ) / length ( d j )  X  . Consider the review r j,k written by user u k on the article d j . For each such review, analogous to the per-article stylistic feature vector  X  F we construct a per-review feature vector  X  F L ( r j,k )  X  .
Topic tags for news articles play an important role in user-perceived prominence, bias and credibility, in accordance to the Prominence-Interpretation theory [7]. For example, the tag Politics is often viewed as an indicator of potential bias and individual differences; whereas tags like Energy or Environment are perceived as more neutral news and therefore invoke higher agreement in the commu-nity on the associated articles X  credibility. Obviously, this can be misleading as there is a significant influence of Politics on all topics in all format of news.

Certain users have topic-specific expertise that make them rate articles on those topics better than others. News sources also have expertise on specific topics and provide a better coverage of news on those topics than others. For example, National Geographic provides a good coverage of news related to environment , whereas The Wall Street Journal provides a good coverage on economic policies. However, many news articles do not have any explicit topic tag. In order to automatically identify the underlying theme of the article, we use Latent Dirichlet Allocation (LDA) [1] to learn the latent topic distribution in the corpus. LDA assumes a document to have a distribution over a set of topics, and each topic to have a distribution over words. Table 1 shows an excerpt of the top topic words in each topic, where we manually added illustrative labels for the topics. The latent topics also capture some subtle themes not detected by the explicit tags. For example, Amy Goodman is an American broadcast journalist, syndicated columnist and investigative reporter who is considered highly credible in the community. Also, associated with that topic cluster is Amanda Blackhorse , a Navajo activist and plaintiff in the Washington Redskins case.
 Feature vector construction : For each document d j and each of its review r j,k , we create feature vectors  X  F T ( d j )  X  and  X  F respectively, using the learned latent topic distributions, as well as the explicit topic tags. Section 3.1 discusses our method to learn the topic distributions.
A news source is considered trustworthy if it generates highly credible articles. We examine the effect of different features of a news source on its trustworthiness based on user assigned ratings in the community. We consider the following source features (sum-marized in Table 2): the type of media (e.g., online, newspaper, tv, blog), format of news (e.g., news analysis, opinion, special report, news report, investigative report), (political) viewpoint (e.g., left, center, right), scope (e.g., international, national, local), the top topics covered by the source, and their topic-specific expertise . Feature vector construction : For each news source s l , we create a feature vector  X  F S ( s l )  X  using features in Table 2. Each element f ( s l ) is 1 or 0 indicating presence or absence of a feature. Note that above features include the top (explicit) topics covered by any source, and its topic-specific expertise for a subset of those topics.
A user X  X  expertise in judging news credibility depends on many factors. [5] discusses the following traits for recognizing an expert. Community Engagement of the user is an obvious measure for judging the user authority in the community. We capture this with different features: number of answers, ratings given, comments, ratings received, disagreement and number of raters.
 Inter-User Agreement : Expert users typically agree on what con-stitutes a credible article. This is inherently captured in the proposed graphical model, where a user gains expertise by assigning credibil-ity ratings to articles that corroborate with other expert users. Topical Perspective and Expertise : The potential for harvesting user preference and expertise in topics for rating prediction of re-views has been demonstrated in [22, 21]. For credibility analysis the model needs to capture the user X  X  perspective and bias towards certain topics based on their political inclination that bias their rat-ings, and their topic-specific expertise that allows them to evaluate articles on certain topics better as  X  X ubject Matter Experts X . These are captured as per-user feature weights for the stylistic indicators and topic words in the language of user-contributed reviews. Interactions : In a community, users can upvote ( digg, like, rate ) the ratings of users that they appreciate, and downvote the ones they do not agree with. High review ratings from expert users increase the value of a user; whereas low ratings bring down her expertise. Similar to this user-user interaction, there can be user-article , user-source and source-article interactions which are captured as edges in our graphical model (by construction). Consider the following anecdotal example in the community showing an expert in nuclear energy downvoting another user X  X  rating on nuclear radiation:  X  X on-Feature vector construction : For each user u k , we create an en-gagement feature vector  X  F E ( u k )  X  . In order to capture user sub-jectivity , in terms of different stylistic indicators of credibility, we consider the per-review language feature vector  X  F L ( r u k (refer to Section 2.1). To capture user perspective and expertise on different topics, we consider the per-review topic feature vector  X  F T ( r j,k )  X  of each user u k .

In this section we incorporate the discussed features and insights into a joint probabilistic graphical model. The task is to identify credible news articles, trustworthy news sources, and expert users jointly in a news community. Table 3 summarizes the important notations used in this section.
Consider an article d consisting of a sequence of { N d } words denoted by w 1 ,w 2 ,...w N d . Each word is drawn from a vocabulary V having unique words indexed by 1 , 2 ,...V . Consider a set of topic assignments z = { z 1 ,z 2 ,...z K } for d , where each topic z can be from a set of K possible topics.

LDA [1] assumes each document d to be associated with a multi-nomial distribution  X  d over topics Z with a symmetric dirichlet prior  X  .  X  d ( z ) denotes the probability of occurrence of topic z in docu-ment d . Topics have a multinomial distribution  X  z over words drawn from a vocabulary V with a symmetric dirichlet prior  X  .  X  notes the probability of the word w belonging to the topic z . Exact inference is not possible due to intractable coupling between  X  and  X  . We use Gibbs sampling for approximate inference.

Let n ( d,z,w ) denote the count of the word w occurring in doc-ument d belonging to the topic z . In the following equation, ( . ) at any position in the above count indicates marginalization, i.e., sum-ming up the counts over all values for the corresponding position in n ( d,z,w ) . The conditional distribution for the latent variable z (with components z 1 to z K ) is given by:
Let  X  T E  X  and  X  T L  X  be the set of explicit topic tags and latent topic dimensions, respectively. The topic feature vector  X  F article or review combines both explicit tags and latent topics and is constructed as follows: F t ( d ) =
So for any word in the document matching an explicit topic tag, the corresponding element in the feature vector  X  F T  X  is set to its occurrence count in the document. If the word belongs to any latent topic with probability greater than threshold  X  , the probability of the word belonging to that topic (  X  t ( w ) ) is added to the corresponding element in the feature vector, and set to 0 otherwise.
We use Support Vector Regression (SVR) [4] to combine the different features discussed in Section 2. SVR is an extension of the max-margin framework for SVM classification to the regression problem. It solves the following optimization problem to learn weights w for features F : Article Stylistic Model : We learn a stylistic regression model SVR L using the per-article stylistic feature vector  X  F L rating y j (or, y j,k ) as the response variable.
 Article Topic Model : Similarly, we learn a topic regression model SVR T using the per-article topic feature vector  X  F T ( d d (or,  X  F T ( r j,k )  X  for review r j,k ), with the overall article rating y (or, y j,k ) as the response variable.
 Source Model : We learn a source regression model SVR s i the per-source feature vector  X  F S ( s i )  X  for source s all source rating as the response variable .
 User Model : For each user u k , we learn a user regression model SVR u k with her per-review stylistic and topic feature vectors  X  F
L ( r j,k )  X  F T ( r j,k )  X  for review r j,k for article d review rating y j,k as the response variable.

Note that we use overall article rating to train article stylistic and topic models. For the user model, however, we take user assigned article ratings and per-user features. This model captures user sub-jectivity and topic perspective. The source models are trained on news-source specific meta-data and its ground-truth ratings.
We model our learning task as a Conditional Random Field (CRF), where the random variables are the ratings of news articles  X  d news sources  X  s i  X  , users  X  u k  X  , and reviews  X  r j,k to predict the credibility ratings  X  y j  X  of the articles  X  d
The cliques in the CRF consist of an article d j , its source s set of users  X  u k  X  reviewing it, and the corresponding user reviews  X  r j,k  X   X  where r j,k denotes the review by user u k on article d Different cliques are connected via the common news sources, and users. There are as many cliques as the number of news articles. j . Each clique has a set of associated vertex feature functions. In our problem setting, we associate features to each vertex.The fea-tures constituted by the stylistic, topic, source and user features ex-plained in Section 2 are: F L ( d j )  X  F T ( d j )  X  F S F
A traditional CRF model allows us to have a binary decision if a news article is credible ( y j = 1 ) or not ( y j = 0 ), by estimating the conditional distribution with the probability mass function of the discrete random variable y : Pr ( y | D,S,U,R ) =
But in our problem setting, we want to estimate the credibility rating of an article. Therefore, we need to estimate the conditional distribution with the probability density function of the continuous random variable y :
Given a news article d j , its source id s i , and a set of user ids  X  u k  X  who reviewed the article, the regression models SVR L rating of d j . For notational brevity, hereafter, we drop the argument d from the SVR function. These SVR predictors are for separate feature groups and independent of each other. Now we combine the different SVR models to capture mutual interactions, such that the weight for each SVR model reflects our confidence on its quality. Errors by an SVR are penalized by the squared loss between the predicted article rating and the ground-truth rating. There is an additional constraint that for any clique only the regression models corresponding to the news-source and users present in it should be activated. This can be thought of as partitioning the input feature space into subsets, with the features inside a clique capturing local interactions, and the global weights capture the overall quality of the random variables via the shared information between the cliques (in terms of common sources, users, topics and language features)  X  an ideal setting for using a CRF. Equation 5 shows one such linear combination. Energy function of an individual clique is given by: Indicator functions I u k ( d j ) and I s i ( d j ) are 1 if u and s i is the source of article d j respectively, and are 0 otherwise.
As the output of the SVR is used as an input to the CCRF in Equa-tion 5, each element of the input feature vector is already predicting the output variable. The learned parameters  X  =  X   X , X , X  1 (with dimension (  X  ) = | U | + | S | + 2 ) of the linear combination of the above features depict how much to trust individual predictors. Large  X  k on a particular predictor places large penalty on the mis-takes committed by it, and therefore depicts a higher quality for that predictor.  X  u corresponding to user u can be taken as a proxy for that user X  X  expertise , allowing us to obtain a ranked list of expert users. Similarly,  X  s corresponding to news source s can be taken as a proxy for that source X  X  trustworthiness , allowing us to obtain a ranked list of trustworthy news sources.
 Overall energy function of all cliques is given by: (Substituting  X  j from Equation 5 and re-organizing terms) Organizing the bracketed terms into variables as follows: We can derive: Substituting  X  in Equation 4: Equation 7 can be transformed into a multivariate Gaussian distri-bution after substituting R  X   X  X  X  exp (  X  1 2 y T  X   X  1 y + y Q represents the contribution of  X  to the covariance matrix  X  . Each row of the vector b and matrix Q corresponds to one training instance, representing the active contribution of features present in it. To ensure Equation 8 represents a valid Gaussian distribution, the covariance matrix  X  needs to be positive definite for its inverse to exist. For that the diagonal matrix Q needs to be a positive semi-definite matrix. This can be ensured by making all the diagonal elements in Q greater than 0 , by constraining  X  k &gt; 0 .
Since this is a constrained optimization problem, gradient ascent cannot be directly used. We follow the approach similar to [27] and maximize log-likelihood with respect to log  X  k , instead of  X  as in standard gradient ascent, making the optimization problem unconstrained as:
Taking partial derivative of the log of Equation 8 w.r.t  X 
Substituting the following in the above equation: where, X ( . ) ,k indicates the k th column of the feature matrix X .
We can derive the gradient vector:  X  X ogP ( y | X )
Let  X  denote the learning rate. The update equation is given by:
Once the model parameters are learned using gradient ascent, the inference for the prediction y of the article credibility rating is straightforward. As we assume the distribution to be Gaussian, the prediction is the expected value of the function, given by the mean of the distribution: y 0 = argmax y P ( y | X ) =  X  =  X  b . Note that  X  and b are both a function of  X  =  X   X , X , X  1 , X  represents the combination weights of various factors to capture mu-tual interactions. The optimization problem determines the optimal  X  for reducing the error in prediction.
We performed experiments with data from a typical news com-munity: newstrust.net 4 . This community is similar to digg.com and reddit.com , but has more refined ratings and interactions. We chose NewsTrust because of the availability of ground-truth ratings for credibility analysis of news articles; such ground-truth is not available for the other communities.

We collected stories from NewsTrust from May, 2006 to May, 2014. Each such story features a news article from a source (E.g. BBC, CNN, Wall Street Journal) that is posted by a member, and reviewed by other members, many of whom are professional jour-nalists and content experts 5 . We crawled all the stories with their explicit topic tags and other associated meta-data. We crawled all the news articles from their original sources that were featured in any NewsTrust story. The earliest story dates back to May 1, 1939 and the latest one is in May 9, 2014.

We collected all member profiles containing information about the demographics, occupation and expertise of the members along with their activity in the community in terms of the posts, reviews and ratings; as well as interaction with other members. The members in the community can also rate each others X  ratings. The earliest story rating by a member dates back to May, 2006 and the most recent one
Code and data available at http://www.mpi-inf.mpg.de/impact/credibilityanalysis/ http://www.newstrust.net/help#about_newstrust is in Feb, 2014. In addition, we collected information on member evaluation of news sources, and other information (e.g., type of media, scope, viewpoint, topic specific expertise) about source from its meta data .
 Crawled dataset: Table 4 shows the dataset statistics. In total 62 K unique news articles were reviewed in NewsTrust in the given pe-riod, out of which we were able to extract 47 K full articles from the original sources like New York Times, TruthDig, ScientificAmeri-can etc  X  a total of 5 . 6 K distinct sources. The remaining articles were not available for crawling. There are 84 . 7 K stories featured in NewsTrust for all the above articles, out of which 52 . 5 K stories refer to the news articles we managed to extract from their original sources. The average number of reviews per story is 1 . 59 . For general analysis we use the entire dataset. For experimental evalua-tion of the CCRF and hypotheses testing, we use only those stories ( 18 . 5 K) with a minimum of 3 reviews that refer to the news articles we were able to extract from original sources.
 Generated graph: Table 5 shows the statistics of the graph con-structed by the method of Section 2.
 Ground-Truth for evaluation : The members in the community can rate the credibility of a news article on a scale from 1 to 5 regarding 15 qualitative aspects like facts, fairness, writing style and insight, and popularity aspects like recommendation, credibility and views. Members give an overall recommendation for the article explained to them as:  X ... Is this quality journalism? Would you recommend this story quality journalism." Each article X  X  aspect ratings by different members are weighted (and aggregated) by NewsTrust based on findings of [16], and the member expertise and member level (described below). This overall article rating is taken as the ground-truth for the article credibility rating in our work. A user X  X  member level is calculated by NewsTrust based on her community engagement, experience, other users X  feedback on her ratings, profile transparency and validation by NewsTrust staff. This member level is taken as the proxy for user expertise in our work. Members rate news sources while reviewing an article. These ratings are aggregated for each source, and taken Table 6: MSE comparison of models for predicting users X  credibility rating behavior with 10 -fold cross-validation. Improvements are statistically significant with P-value &lt; 0 . 0001 .
 Table 7: MSE comparison of models for predicting aggregated arti-cle credibility rating with 10 -fold cross-validation. Improvements are statistically significant with P-value &lt; 0 . 0001 . as a proxy for the source trustworthiness in our work.
 Training data: We perform 10 -fold cross-validation on the news articles. During training on any 9 -folds of the data, the algo-rithm learns the user, source, language and topic models from user-assigned ratings to articles and sources present in the train split. We combine sources with less than 5 articles and users with less than 5 reviews into background models for sources and users, respectively. This is to avoid modeling from sparse observations, and to reduce dimensionality of the feature space. However, while testing on the remaining blind 1 -fold we use only the ids of sources and users reviewing the article; we do not use any user-assigned ratings of sources or articles. For a new user and a new source, we draw parameters from the user or source background model. The results are averaged by 10 -fold cross-validation, and presented in the next section.
 Experimental settings: In the first two experiments we want to find the power of the CCRF in predicting user rating behavior, and credibility rating of articles. Therefore, the evaluation measure is taken as the Mean Squared Error (MSE) between the prediction and the actual ground-rating in the community. For the latter experi-ments in finding expert users (and, trustworthy sources) there is no absolute measure for predicting user (and, source) quality; it only makes sense to find the relative ranking of users (and, sources) in terms of their expertise (and, trustworthiness). Therefore, the evalu-ation measure is taken as the Normalized Discounted Cumulative Gain (NDCG) [13] between the ranked list of users (and, sources) obtained from CCRF and their actual ranking in the community.
First we evaluate how good our model can predict the credibility ratings that users assign to news articles using the Mean Squared Error (MSE) between the prediction and the actual rating. Table 8: NDCG scores for ranking trustworthy sources.
 Baselines : We consider the following baselines for comparison: 1. Latent Factor Recommendation Model (LFM) [15]: LFM consid-ers the tuple  X  userId,itemId,rating  X  , and models each user and item as a vector of latent factors which are learned by minimizing the MSE between the rating and the product of the user-item latent factors. In our setting, each news article is considered an item and rating refers to the credibility rating assigned by a user to an article. 2. Experience-based LFM [21]: This model incorporates experience of a user in rating an item in the LFM. The model builds on the hypothesis that users at similar levels of experience have similar rating behaviors which evolve with time . The model has an extra dimension: the time of rating an item which is not used in our SVR model. Note the analogy between the experience of a user in this model, and the notion of user expertise in the SVR model. However, these models ignore the text of the reviews. 3. Text-based LFM [20]: This model incorporates text in the LFM by combining the latent factors associated to items in LFM with latent topics in text from topic models like LDA. 4. Support Vector Regression (SVR) [4]: We train an SVR model SVR u k for each user u k (refer to Section 3.2) based on her reviews  X  r j,k  X  with language and topic features  X  F L ( r j,k )  X  F the user X  X  article ratings  X  y j,k  X  as the response variable. We also incorporate the article language features and the topic features, as well as source-specific features to train the user model for this task. The other models ignore the stylistic features, and other fine-grained user-item interactions in the community.

Table 6 shows the MSE comparison between the different meth-ods. Our model (User SVR) achieved the lowest MSE and thus performed best.
As a second part of the evaluation, we investigate the predictive power of different models in order to find credible news articles based on the aggregated ratings from all users . The above LFM models, unaware of the user cliques , cannot be used directly for this task, as each news article has multiple reviews from different users which need to be aggregated. We find the Mean Squared Error (MSE) between the estimated overall article rating, and the ground-truth article rating. We consider stories with at least 3 ratings about a news article. We compare the CCRF against the following base-lines: 1. Support Vector Regression (SVR) [4]: We consider an SVR model with features on language (bag-of-all-words, subjectivity, bias etc.), topics (explicit tags as well as latent dimensions), and news-source-specific features. The language model uses all the lexicons derived and used in [28, 23]. The source model also includes topic features in terms of the top topics covered by the source, and its topic-specific expertise for a subset of the topics. 2. Aggregated Model (SVR) [4]: As explained earlier, the user features cannot be directly used in the baseline model, which is agnostic of the user cliques . Therefore, we adopt a simple aggre-gation approach by taking the average rating of all the user ratings | u k | for an article d j as a feature. Note that, in contrast to this simple average used here, our CCRF model learns the weights  X   X  per-user to combine their overall ratings for an article. Table 7 shows the MSE comparison of the different models. MSE Comparison : The first two models in Table 6 ignore the textual content of news articles, and reviews, and perform worse than the ones that incorporate full text. The text-based LFM considers title and text, and performs better than its predecessors. However, the User SVR model considers richer features and interactions, and attains 23% MSE reduction over the best performing LFM baselines.
The baselines in Table 7 show the model performance after incor-porating different features in two different settings: 1) with news article titles only as text, and 2) with titles and the first few para-graphs of an article. The language model, especially the bias and subjectivity features, is less effective using only the article titles due to sparseness. On the other hand, using the entire article text may lead to very noisy features. So including the first few paragraphs of an article is the  X  X weet spot X . For this, we made an ad-hoc decision and included the first 1000 characters of each article. With this setting, the language features made a substantial contribution to reducing the MSE.

The aggregated SVR model further brings in the user features, and achieves the lowest MSE among the baselines. This shows that a user-aware credibility model performs better than user-independent ones. Our CCRF model combines all features in a more sophisti-cated manner, which results in 19 . 5% MSE reduction over the most competitive baseline (aggregated SVR). This is empirical evidence that the joint interactions between the different factors in a news community are indeed important to consider for identifying highly credible articles.
We shift the focus to two use cases: 1) identifying the most trust-worthy sources, and 2) identifying expert users in the community who can play the role of  X  X itizen journalists X .

Using the model of Section 3, we rank all news sources in the community according to the learned  X   X  s i  X  in Equation 5. The baseline is taken as the PageRank scores of news sources in the Web graph. In the experience-based LFM we can consider the sources to be users, and articles generated by them to be items. This allows us to obtain a ranking of the sources based on their overall authority. This is the second baseline against which we compare the CCRF.
We measure the quality of the ranked lists in terms of NDCG using the actual ranking of the news sources in the community as ground-truth. NDCG gives geometrically decreasing weights to predictions at the various positions of the ranked list:
Table 8 shows the NDCG scores for the different methods.
Similar to news sources, we rank users according to the learned  X   X  u k  X  in Equation 5. The baseline is the average rating received by a user from other members in the community. We compute the NDCG score for the ranked lists of users by our method. We also compare against the ranked list of users from the experience-aware LFM [21]. Table 9 shows the NDCG scores for different methods. Hypothesis Testing : We test various hypotheses under the influence of the feature groups using explicit labels, and ratings available in the NewsTrust community. A summary of the tests is presented in Table 10 showing a moderate correlation between various factors which are put together in the CCRF to have a strong indicator for information credibility.
 Language : The stylistic features (factor (a) in Table 10) like as-sertives, hedges, implicatives, factives, discourse and affective play a significant role in the credibility detection of news, in conjunction with other language features like topics . Table 10: Pearson X  X  product-moment correlation between various factors (with P-value &lt; 0 . 0001 for each test).
 Topics : Topics are an important indicator for news credibility. We measured the influence of the Politics tag on other topics by their co-occurrence frequency in the explicit tag sets over all the news articles. We found significant influence of Politics on all topics, with an average measure of association of 54% to any topic, and 62% for the overall news article. The community gets polarized due to different perspectives on topical aspects of news. A moderate correlation (factor (b) in Table 10) indicates a weak trend of dis-agreement, measured by the standard deviation in article credibility rating among users, increasing with its political content. In general, we find that community disagreement for different viewpoints are as Users : User engagement features are strong indicators of expertise. Although credibility is ultimately subjective, experts show moderate agreement (factor (c) in Table 10) on highly credible news. There is a moderate correlation (factor (d) in Table 10) between feedback received by a user on his ratings from community, and his expertise. Sources : Various traits of a news source like viewpoint, format and topic expertise are strong indicators of trustworthiness. In gen-eral, science and technology websites (e.g., discovermagazine.com, nature.com, scientificamerican.com), investigative reporting and non-partisan sources (e.g., truthout.org, truthdig.com, cfr.org), book sites (e.g., nybooks.com, editorandpublisher.com), encyclopedia (e.g., Wikipedia) and fact checking sites (e.g., factcheck.org) rank among the top trusted sources. Table 11 shows the most and least trusted sources on four sample topics. Overall, news sources are considered trustworthy with an average rating of 3 . 46 and variance of 0 . 15 . Tables 12 and 13 show the most and least trusted sources on different viewpoints and media types respectively. Contents from blogs are most likely to be posted followed by newspaper, magazine and other online sources. Contents from wire service, TV and ra-dio are deemed the most trustworthy, although they have the least subscription, followed by magazines .
 Interactions : In principle, there is a moderate correlation between trustworthy sources generating credible articles (factor (e) in Ta-ble 10) identified by expert users (factor (f) in Table 10). A negative sign of correlation indicates decrease in disagreement or MSE with Table 12: Most and least trusted sources with different viewpoints. Table 13: Most and least trusted sources on different types of media. increase in expertise. In a news community, we can observe moder-ate signals of interaction between various factors that characterize users, articles, and sources. Our CCRF model brings all these fea-tures together to build a strong signal for news credibility. Rating prediction in online communities: Collaborative filtering based approaches [15] for rating prediction exploit user and item similarities by latent factors. [21] further studies the temporal evo-lution of users and their rating behavior in this framework. Recent works [20, 22] also tap into user review texts to generate user-specific ratings of reviews. Other papers have studied temporal issues for anomaly detection [10].Prior work that tapped user review texts focused on other issues. Sentiment analysis over reviews aimed to learn latent topics [18], latent aspects and their ratings [35], and user-user interactions [36]. Our model unifies several dimensions to jointly study the role of language, users, topics, and interactions for information credibility.
 Information credibility in social media : [3] analyzes micro-blog postings in Twitter related to trending topics, and classifies them as credible or not based on features from user posting and re-posting behavior. [14] focuses on credibility of users, harnessing the dy-namics of information flow in the underlying social graph and tweet content. [2] analyzes both topical content of information sources and social network structure to find credible information sources in social networks. Information credibility in tweets has been studied in [11]. [33] conducts a user study to analyze various factors like contrasting viewpoints and expertise affecting the truthfulness of controversial claims. However, none of these prior works analyze the interplay between sources, language, topics, and users .
The works closest to our problem and approach are [34, 23]. [34] presents an algorithm for propagating trust scores in a heteroge-neous network of claims, sources, and documents. [23] proposes a method to jointly learn user trustworthiness, statement credibility, and language objectivity in online health communities. However, these works do not analyze the role of topics, language bias, user perspective, expertise , and fine-grained interactions in community. Bias in social communities and media : The use of biased lan-guage in Wikipedia and similar collaborative communities has been studied in [9, 28]. Even more broadly, the task of characterizing subjective language has been addressed, among others, in [37, 19]. The influence of different kinds of bias in online user ratings has been studied in [30, 6]. [6] proposes an approach to handle users who might be subjectively different or strategically dishonest. Citizen journalism : [29] defines citizen journalism as  X  X he act of a citizen or group of citizens playing an active role in the process of collecting, reporting, analyzing and dissemination of news and information to provide independent, reliable, accurate, wide-ranging and relevant information that a democracy requires. X  [31] focuses on user activities like blogging in community news websites. Although the potential of citizen journalism is greatly highlighted in the recent Arab Spring [12], misinformation can be quite dangerous when relying on users as news sources (e.g., the reporting of the Boston Bombings in 2013 [25]).
In this work, we analyzed the effect of different factors like language, topics and perspectives on the credibility rating of articles in a news community. These factors and their mutual interactions are the features of a novel model for jointly capturing credibility of news articles, trustworthiness of news sources and expertise of users. From an application perspective, we demonstrated that our method can reliably identify credible articles, trustworthy sources and expert users in the community.

As future work, we plan to model and analyze the temporal evolution of the factors associated with each of the components in our model. We have a strong intuition that time has a significant influence on the trustworthiness of sources and credibility of news. [1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [2] K. R. Canini, B. Suh, and P. Pirolli. Finding credible [3] C. Castillo, M. Mendoza, and B. Poblete. Information [4] H. Drucker, C. J. C. Burges, L. Kaufman, A. J. Smola, and [5] H. J. Einhorn, R. M. Hogarth, and E. Klempner. Quality of [6] H. Fang, J. Zhang, and N. Magnenat Thalmann. Subjectivity [7] B. J. Fogg. Prominence-interpretation theory: explaining how [8] Gallup.com. Americans X  confidence in newspapers continues [9] S. Greene and P. Resnik. More than words: Syntactic [10] S. G X nnemann, N. G X nnemann, and C. Faloutsos. Detecting [11] A. Gupta and P. Kumaraguru. Credibility ranking of tweets [12] P. N. Howard, A. Duffy, D. Freelon, M. Hussain, W. Mari, and [13] K. J X rvelin and J. Kek X l X inen. Cumulated gain-based [14] B. Kang, J. O X  X onovan, and T. H X llerer. Modeling topic [15] Y. Koren. Factorization meets the neighborhood: A [16] C. Lampe and R. K. Garrett. It X  X  all news to me: The effect of [17] S. C. Lewis, K. Kaufhold, and D. L. Lasorsa. Thinking about [18] C. Lin and Y. He. Joint sentiment/topic model for sentiment [19] C. Lin, Y. He, and R. Everson. Sentence subjectivity detection [20] J. McAuley and J. Leskovec. Hidden factors and hidden [21] J. J. McAuley and J. Leskovec. From amateurs to [22] S. Mukherjee, G. Basu, and S. Joshi. Joint author sentiment [23] S. Mukherjee, G. Weikum, and C. Danescu-Niculescu-Mizil. [24] Nber.org. Media bias and voting. [25] Nytimes.com. Should reddit be blamed for the spreading of a [26] T. Qin, T. Liu, X. Zhang, D. Wang, and H. Li. Global ranking [27] V. Radosavljevic, S. Vucetic, and Z. Obradovic. Continuous [28] M. Recasens, C. Danescu-Niculescu-Mizil, and D. Jurafsky. [29] B. Shayne and W. Chris. We media: How audiences are [30] Sloanreview.mit.edu. The problem with online ratings. [31] A. Stuart. Citizen journalism and the rise of  X  X ass [32] B. Tadas, P. Robinson, and L. Morency. Continuous [33] V. Vydiswaran et al. BiasTrust: Teaching biased users about [34] V. V. Vydiswaran, C. Zhai, and D. Roth. Content-driven trust [35] H. Wang et al. Latent aspect rating analysis without aspect [36] R. West, H. S. Paskov, J. Leskovec, and C. Potts. Exploiting [37] J. Wiebe and E. Riloff. Creating subjective and objective
