 Online reviews are immensely valuable for customers to make informed purchase decisions and for businesses to improve the quality of their products and services. However, cus-tomer reviews grow exponentially while varying greatly in quality. It is generally very tedious and difficult, if not im-possible, for users to read though the huge amount of review data for decision-making. Fortunately, review quality eval-uation enables a system to recommend automatically the most helpful reviews to users. Previous studies predict only the overall review utility about a product, and often focus on developing different data features to learn a quality function for the problem. In this paper, we aim to select the most helpful reviews not only at the product level, but also at a fine-grained product aspect level. We propose a novel super-vised joint aspect and sentiment model (SJASM), which is a probabilistic topic modeling framework that jointly discov-ers aspects and sentiments guided by a review helpfulness metric. One key advantage of SJASM is its ability to infer the underlying aspects and sentiments, which are indicative of the helpfulness of a review. We validate SJASM using publicly available review data, and our experimental results demonstrate the superiority of SJASM over several compet-ing models.
 H.3.3 [ Information Search and Retrieval ]: Text Mining; I.2.7 [ Artificial Intelligence ]: Natural language Process-ing X  Text Analysis Algorithms, Experimentation review selection; review helpfulness; supervised joint topic model; sentiment analysis
Nowadays, customers readily create textual reviews to share their hands-on experiences and opinions on the pur-chased products or services on websites such as Amazon 1 . Online reviews are immensely valuable because: 1) They have become an inevitable part of the decision making pro-cess on product purchases, hotel bookings, etc. According to a survey, a massive 88% of respondents agreed that they  X  X ometimes or always X  consult customer reviews prior to making a purchase 2 ; and 2) They collectively form a low-cost and efficient feedback channel for businesses to keep track of their reputation and customer sentiments, which can be used to improve the quality of their products and services.

However, customer reviews are constantly growing in quan-tity, while varying greatly in quality or helpfulness. A pop-ular product can easily accumulate hundreds or even thou-sands of online reviews within a very short period of time. For instance, the book  X  X arry Potter and the Half-Blood Prince X  on Amazon had received 4,193 customer reviews by January 24, 2014. Among the large number of reviews, the helpful and high-quality reviews are usually intermixed with the useless ones. It is thus practically impossible for users to read through such large number of reviews for good decision-making.

Some existing e-commerce websites already provide a crowd-source mechanism to evaluate review quality. For instance, Amazon allows customers to vote each product review as helpful or unhelpful . As a matter of fact, a good many of reviews of the unpopular products receive very few or no votes at all. As a result, decisions made using the online sparse voting information alone tend to suffer from bias, and are perhaps unreliable. Moreover, no websites currently provide a mechanism for assessing the review utility at the fine-grained aspect level.

By formulating the review utility prediction simply as a regression or classification problem, previous studies mainly focus on defining data features, on which a review utility function can be then learnt [7, 20, 11, 13, 3]. Further, all the existing approaches are proposed for review utility pre-diction at the product level. In other words, the approaches cannot be used to detect product aspects and therefore to select the most useful reviews at the fine-grained product aspect level. In reality, savvy consumers not only want to read the most helpful reviews for a product, but also are ht tp://www.amazon.com/ http://www.reevoo.com/about-us/press-releases/half-consumers-find-social-content-useful-when-shopping-online eager to know what aspects are evaluated in reviews, and wh ich reviews are the most useful for learning the individual aspects of the reviewed product. Such fine-grained review utility information may very well tip the balance in customer purchase decisions. Additionally, in opinion summarization system, incorporating the selected useful reviews with the summarized compact sentiment analysis results could pro-vide much more informative first-hand experiences to users.
In this work, we focus on the problem of review help-fulness/utility prediction and review selection from coarse grain (product-level) to fine grain (aspect-level), namely, coarse-to-fine review selection . In particular, we study three closely related problems as described below: 1. Overall review helpfulness prediction. We predict the 2. Aspect detection. We detect the individual product as-3. Aspect-based review utility estimation. For each de-
It is observed that online customer reviews often come with helpfulness voting, for instance, in the form of  X  X  of y people found the following review helpful X  on Amazon. Typ-ically, a customer review is helpful in the sense that the review: 1) mentions the particular attributes, components, or aspects of a commented product, and 2) expresses perti-nent sentiments, opinions, and evaluations on such specific aspects. We propose to model the helpfulness voting of a review in a unified framework to supervise the inference pro-cess of underlying aspects and sentiments in the review. In addition, the vast majority of existing topic modeling ap-proaches use the bag-of-words (BOW) representation of a document. Differently, we reduce each review document as a bag of opinion pairs (BOOP), and then model each pair of aspect term and its associated opinion word simultaneously in the unified framework.

We propose a novel supervised joint aspect and senti-ment model (SJASM), which is a probabilistic topic mod-eling framework that jointly detects aspects and sentiments from reviews under the supervision of the helpfulness voting data. One key advantage of SJASM is that it can discover the underlying sentimental aspects which are predictive of the review helpfulness voting. We then apply it to the re-view helpfulness/utility prediction to address the coarse-to-fine review selection problem. We evaluate SJASM using three publicly available review collections, and experimen-tally show the improved effectiveness of the proposed model against benchmark models.

We summarize our contributions as follows:
Previous work typically focuses on manually coming up with data features, and then formulating review helpful-ness/utility prediction as a regression or classification prob-lem on these features.

Kim et al. [7] proposed to utilize five classes of textual features to estimate the helpfulness of a review. They found that the most useful features were the length of review, un-igrams, and ratings. Zhang and Varadarajan [20] built re-gression models by incorporating a diverse set of textual features. They claimed that the shallow syntactic features turned out to be the most influential predictors, which in-dicates that the utility of a review highly depends on its linguistic style. To predict the helpfulness of online reviews, Liu et al. [12] used a regression model based on the data fea-tures like the reviewer X  X  expertise, the review writing style, and the timeliness of a review. Ghose and Ipeirotis [3] pro-posed to exploit the text-related features, such as subjectiv-ity, readability, and linguistic correctness, to estimate the helpfulness of product reviews. Two other classification-based approaches were developed to recommend the most helpful reviews by filtering out the low-quality ones in [11, 16]. Further, to improve the textual feature based review quality predictor, Lu et al. [13] proposed to exploit social contextual information about reviewers X  identities and social networks.

All of the aforementioned existing studies focus on only predicting the review helpfulness/utility/quality with regard to a whole reviewed product, with the objective to recom-mend/select the most helpful reviews at the product level. However, when faced with fine-grained aspect-level helpful review selection problem, the previous studies may become useless.
Topic modeling algorithms aim to uncover the hidden top-ical structure of a document collection [2, 5]. Blei et al. [2] proposed the first latent Dirichlet allocation (LDA), in which a document is modeled as a mixture over a latent set of topics, where each topic is modeled by a distribution over words. Based on LDA, many other topic models have been developed to address review mining problems.

Titov and McDonald [17] developed a joint topic model of text and aspect ratings, called multi-aspect sentiment model (MAS). MAS can identify latent topics in customer reviews and extract textual evidence from the reviews supporting each of the aspect ratings. But the assumption of MAS that every aspect-based sentiment rating is present in review data may lead to its limited use in reality. This is because a large quantity of online reviews have not been annotated with aspects as well as the aspect-specific sentiment ratings by cu stomers.

Lin and He [9] extended LDA by designing a new sen-timent layer, and proposed a joint sentiment-topic model (JST), which is based on the assumption that topic gen-eration depends on sentiments, and word generation is de-pendent on the sentiment-topic pairs. Lin et al. [10] then extended JST by incorporating sentiment priors, and intro-duced a weakly supervised joint sentiment-topic model. The supervision knowledge comes from a domain independent sentiment lexicon. The weakly supervised JST model may yield improved performance compared to the unsupervised one, however suffers from two problems: 1) The inference of the sentiment labels for the out-of-lexicon expressions be-comes unsupervised, negating the supervised advantage; and 2) The detection of underlying topics is completely unsuper-vised.

Jo and Oh [6] proposed a sentence-LDA model, and then extended the model to an aspect and sentiment unification model (ASUM), which detects sentiments toward different aspects in a unified framework. A sentiment lexicon was also incorporated in the model. One limitation of ASUM is its assumption that each review sentence contains exactly one aspect is often violated when modeling the long and complicated real-world reviews. Moghaddam and Ester [15] developed an interdependent LDA model (ILDA) to jointly detect hidden aspects and sentiments from product reviews. Wang et al. [19] proposed a latent aspect rating analysis model (LARAM) to discover latent aspects and their senti-ment ratings. But one challenge that remains in LARAM is the aspect segmentation, which may provide inaccurate segments for the subsequent aspect-specific rating analysis task.

All of the topic models mentioned above were introduced primarily for classifying the sentiments on the latent aspects in each review, but not for predicting the helpfulness of the review. Though benefitting from the modeling of the sub-jective and objective information in individual reviews, they cannot model the review helpfulness voting information in their frameworks, and will be thus less successful for dis-covering the topical structure of review data for the review helpfulness analysis tasks.

Blei and McAuliffe [1] developed a supervised latent Dirich-let allocation model (sLDA), a statistical model of labelled documents. Though sLDA can be used to model the review document and helpfulness voting pairs, it cannot discover the sentiments expressed towards the hidden topics in re-views, simply due to no sentiment analysis module designed in the structure.

Our supervised joint topic model SJASM is related to but different from the aforementioned topic models. The in-corporation of review helpfulness voting into the modeling framework enables SJASM to exploit the supervision infor-mation to guide the inference process of underlying aspects and aspect-specific sentiments in each review. One key ad-vantage of our proposed model is the identified sentimental aspects are predictive of review helpfulness response.
We define some terminologies, followed by the definitions of the problems that we will address in this paper.
Aspect Term: An aspect term t indicates an attribute, a component, or a feature of an entity (e.g., product), which appears typically as noun or noun phrase in customer re-views. For example, in this review sentence,  X  X he price is too expensive for me X , the noun  X  X rice X  is an aspect term.
Opinion Word: An opinion word o refers to the word used to express subjectivity, opinion, and sentiment in a re-view. It occurs typically as an adjective in review sentences. The adjective X  X xpensive X  X n the above example is an opinion word.

Aspect: An aspect a refers to a unique ratable attribute or component of an entity. In our model setting, it is also known as an underlying topic, and typically clusters a set of semantically related aspect terms and opinion words. For instance, we can infer a hidden aspect X  X rice X  X ia the opinion word  X  X ricey X  in this sentence  X  X t is really too pricey X .
Sentiment: A sentiment s refers to the opinion/sentiment orientation expressed on the aspects of an entity or the en-tity itself. In our work it also indicates a sentimental cluster which groups the opinion words with the same sentimen-tal orientation. Typically, the sentiment orientation can be represented in sentimental labels such as positive, negative, and neutral, or in sentimental ratings like 1-to-5 star rat-ings. For instance, a negative sentiment is expressed on the underlying aspect  X  X rice X  via the opinion word  X  X ricey X  in the above example.

Opinion Pair: An opinion pair op = h t,o i is defined as a pair of aspect term t and its corresponding opinion word o extracted from a customer review. For instance, we can extract an opinion pair h price,expensive i from this review sentence  X  X he price is really expensive for me X .
Helpfulness: The helpfulness h of a review indicates the utility or usefulness of the review to fellow users for making decisions.

Next, given a product from a category, there is a collection of M customer reviews R = { r 1 ,r 2 ,...,r M } for the product, where each review r m is reduced to a set of N m opinion pairs r m = {h t 1 ,o 1 i , h t 2 ,o 2 i ,..., h t N m ,o problems to be addressed in this work below:
Overall Review Helpfulness Prediction: This task is to predict the overall helpfulness score h m of a review r m with regard to a reviewed product. The most helpful reviews will be then selected in terms of the scores h m for the product itself.

Aspect Detection: This task aims to discover the K rat-able product aspects a k evaluated in the collection of reviews R , typically by clustering the synonymous or semantically related keywords (aspect terms or opinion words) appearing in the reviews. For example, the aspect  X  X rice X  can be in-ferred from such semantically related keywords like  X  X rice X ,  X  X ost X  X  X ricey X , and  X  X xpensive X .

Aspect-based Review Utility Estimation: This task is to estimate the fine-grained aspect-based utility score h of the review r m with regard to a particular aspect a k . Then, a list of useful reviews will be recommended based on the utility scores h mk for the detected aspect a k .
By incorporating the review helpfulness voting informa-tion into a unified framework, we propose a novel proba-bilistic graphical model called Supervised Joint Aspect and Sentiment Model (SJASM) to address the problems defined above. SJASM simultaneously models the pairwise aspect terms and their corresponding opinion words in a review, and jointly detects the underlying aspects and sentiments Figure 1: Graphical model representation of Super-vi sed Joint Aspect and Sentiment Model. under the supervision of the helpfulness voting of the re-view. One key advantage of SJASM is that it can identify the sentimental aspects that are predictive of the helpfulness of a customer review.

We make the following assumptions for the generative pro-cess of SJASM:
Based on the assumptions, to generate a review document and the helpfulness response by SJASM, underlying aspects are first generated conditioned on the document-specific as-pect distribution. The sentiments are then generated con-ditioned on the generated aspects as well as the document-specific sentiment distribution. Next, the aspect term and opinion word in every opinion pair of the review are gen-erated conditioned on their corresponding aspect and senti-ment. Review helpfulness response is finally generated con-ditioned on the realized aspect and sentiment assignments in the review.

The graphical model representation of SJASM is shown in Figure 1, and the notations used in this model are listed in Table 1. The generative process of the graphical model is as follows: 1. For each aspect k  X  { 1 , ...,K } 2. For each review r m and its helpfulness response h m
In Equation 1,  X  z m represents the combined empirical fre-quencies of the underlying aspects and sentiments in a re-view r m , where C is a normalization constant, and  X  is a weight vector for sentiment orientations (labels/ratings), which can be obtained experimentally from data.

The real-valued helpfulness response h m is drawn from a normal linear model, where the quantity  X  z m works as the covariates, and  X  indicates the regression coefficients, while the parameters  X  T  X  z m and  X  2 are the mean and variance of the normal distribution. We regress the helpfulness re-sponse on the empirical frequencies of the hidden aspects and sentiments generated in the review. This means that the aspect terms and opinion words as well as their aspect and sentiment assignments in the review are generated first, then, based on the aspects and sentiments of the review, the he lpfulness response is generated.

The formulation agrees with the intuition that reviews that clearly convey positive or negative evaluations on the specific aspects of a product could be more constructive and informed, and should be selected for use.
In this section, we describe the approximate inference and parameter estimation procedure for SJASM. We also de-scribe how to apply SJASM to review helpfulness prediction and review selection problem.
Our goal of inference is to evaluate the posterior distribu-tion P ( a,s | t,o,h ), as shown below (parameters are omit-ted): The exact inference for this distribution is intractable, due to the difficulty in the denominator of Equation 2.
At this point, the Gibbs sampling technique comes into play. Following Griffiths and Steyvers [4] we use a collapsed Gibbs sampling algorithm for the approximate inference of SJASM.
 We compute the full conditional distribution as follows: 3  X , X , X , X  2 )  X  where a m,  X  n and s m,  X  n are all aspect and sentiment assign-ments, excluding a m,n and s m,n , respectively, n ( k ) m count of aspect k assigned to words in review document r m n m,k is the count of sentiment l allocated to words that are also assigned to aspect k in review r m , n ( u ) k is the number of times unique aspect word u is assigned to aspect k , and n k,l is the number of times unique opinion word v is as-signed to sentiment l as well as to aspect k . The subscript  X   X  n  X  in a quantity indicates that the quantity excludes the data at the index of n . For example, { n ( u ) k } count of the unique aspect word u being assigned to aspect k , excluding the aspect term instance of the word u and the corresponding aspect assignment at the index n . The notations in Equation 3 are listed in Table 1.

Based on the samples from the full conditional distribu-tion, we compute document aspect distribution as below:
De rivation of the conditional distribution is omitted due to page limitation.

The document-aspect sentiment distribution is computed by:
The aspect word distribution is computed by:
We compute the aspect-sentiment opinion word distribu-tion as follows:
Previous work has shown that an asymmetric Dirichlet prior over the document topic distribution has substantial advantages over a symmetric prior, while an asymmetric prior over the topic word distribution provides no real bene-fit [18]. We thus use an asymmetric prior  X  for the document aspect distribution, while using symmetric priors  X  and  X  for the aspect word distribution and aspect-sentiment opinion word distribution, respectively. Note we use symmetric prior  X  for the sentiment distribution. In particular, we apply a fixed-point iteration scheme [14] for the estimation of the prior  X  . The symmetric prior  X  is set as 1 /L , while both priors  X  and  X  are specified as the same value 0 . 01.
We follow Blei and McAuliffe [1] to approximately evalu-ate the normal linear model parameters  X  and  X  2 .
Let Z be the M  X  K matrix whose rows are the vectors  X  z . Then  X  is approximated as follows: where h indicates the helpfulness response vector.
We approximate  X  2 as follows:
Next, we apply SJASM to the review helpfulness predic-tion and review selection problem.
Given a new unlabeled review r m  X  and a fitted model {  X  k , X  kl , X , X , X , X , X , X  2 } ( k : 1 ,...,K ; l : 1 ,...,L ), our idea for the overall review helpfulness prediction is to first infer all the evaluated aspects of the product and their associ-ated sentiments in the review, and then approximately form the regression function on the posterior mean  X  z m  X  , as shown below:
Note that we approximate the posterior mean of  X  z m  X  by applying Gibbs sampling as described in the previous sec-tion. However, the terms relying on the helpfulness response are removed from the sampling formula, as testing reviews contain no helpfulness annotations.

We estimate the overall helpfulness scores of all the testing reviews using Equation 10, and recommend the most helpful reviews for the commented product to users for decision-making.
As for the fine-grained aspect-level review selection, we need to fix two problems, one is to detect aspects, the other is to estimate the aspect-based utility score of each review.
The aspects are recognized via the aspect word distribu-tion and aspect-sentiment opinion word distribution. Then, for each aspect, we estimate the aspect-based review utility score based on two criteria: document aspect distribution and the predicted review helpfulness. This is because the reviews to be recommended for an aspect are required to be not only useful but also relevant to the aspect.
In particular, we approximate the aspect-based utility score h m  X  k of the review r m  X  for the aspect k by weighting the doc-ument aspect distribution  X  m  X  k with the predicted review helpfulness  X  h m  X  , as given in the function below:
We then recommend the most useful reviews for each as-pect in terms of the estimated aspect-based utility scores.
We evaluated SJASM on the problem of review utility prediction and coarse-to-fine review selection. In particular, we conducted three types of experimental evaluations:
We compared SJASM against three well-established bench-mark models: a supervised topic model called supervised latent Dirichlet allocation (sLDA) [1], a weakly supervised topic model called joint sentiment-topic (JST) model [10], as well as a classic linear regression model (LR). Note that: 1) JST is weakly supervised in the sense that it incorporates a pre-compiled sentiment lexicon to supervise the generation of sentiment label, but for the topic/aspect detection, it is unsupervised; and 2) LR is used only for the evaluation of overall review helpfulness prediction, as it cannot discover the latent topical structure of data.
We tested SJASM against the baselines using publicly available review data from three product categories, namely, Audio CD, Video Games, and Books, which were collected from Amazon 4 . Some statistics of review data sets are listed in Table 2. Note each data set contains only the reviews of one product from each category 5 . ht tp://liu.cs.uic.edu/download/data/ Audio CD:  X  X merican Idiot X ; Video Games:  X  X rand Theft Auto: San Andreas X ; Books:  X  X arry Potter and the Half-Blood Prince X .

Amazon users are allowed to vote whether a review is help-fu l or not, and the helpfulness voting is represented in the form  X  X  of y people found the following review helpful X  . In our experiments, we used only the reviews with at least 10 votes (i.e., y  X  10) in order to conduct a fair and reliable evaluation. We simply estimated the helpfulness h of a re-view as: h = x/y , and used the score as a golden standard for the evaluation of overall review helpfulness prediction.
All reviews in each of the three data sets were analyzed and parsed using the Stanford Parser [8]. We then sim-ply applied the grammatical dependency relations adjec-tival modifier ( X  X mod X ), direct object ( X  X obj X ), and nomi-nal subject ( X  X subj X ) to opinion pair extraction from each parsed review. We then extended the extracted set of opin-ion pairs via applying the dependency relations negation modifier ( X  X eg X ) and conjunct ( X  X onj X ).

For each corpus we held out 20% of the data for testing and trained all the models on the remaining 80% of the data.
The fitted supervised SJASM and sLDA models were di-rectly employed to form the overall review helpfulness pre-diction for unlabeled testing reviews. Since JST is weakly supervised, we relied on a separate regression procedure on the detected JST topics to do the prediction. We utilized unigram textual features to learn LR model for prediction. We first evaluated SJASM and the baseline models via Pearson correlation versus the number of aspects ( K ) while keeping the sentiment orientation count at 3 ( L = 3). Figure 2: Correlation versus number of aspects on Au dio CD reviews.

Figure 2 plots the correlation curves against the aspect number on Audio CD reviews. Only one correlation value was shown for LR as it cannot mine the hidden topical struc-ture of data. SJASM outperforms benchmark models sLDA, JST, and LR across all the numbers of aspects. The average correla-tion of SJASM over all the observations is 43.79%, which is 7.23%, 10.86%, and 25.36% better than that of sLDA, JST, and LR, respectively. The curve of SJASM overall improves with increasing number of aspects. The largest performance gain of SJASM over sLDA is 12.47% at aspect number 30, while the largest gain of SJASM over JST is 15.99% at as-pect number 10. Figure 3: Correlation versus number of aspects on Vi deo Games reviews.

Figure 3 plots the correlation of SJASM versus the bench-mark models on Video Games reviews. SJASM again per-forms better than the baseline models. As the number of aspects grows, the SJASM curve increases, exhibiting a sim-ilar trend as Figure 2. The average correlation of SJASM across all the six observations is 46.53%, which is 8.65%, 11.30%, and 25.92% better than that of sLDA, JST, and LR, respectively. Figure 4: Correlation versus number of aspects on Bo oks reviews.
 Figure 4 plots the results on the Books review data. Again, SJASM results in better performance compared to sLDA, JST, and LR. The average correlation score of SJASM across all the observations is 28.13%, which is 5.79%, 9.59%, and 18.78% larger than that of sLDA, JST, and LR, respectively.
The proposed SJASM outperforms the state-of-the-art topic models sLDA and JST, as well as one classic linear regres-sion model for the overall review helpfulness prediction. Next, we used mean squared error (MSE) to evaluate SJASM against baseline models for overall review helpful-ness prediction, as shown in Table 3.

SJASM leads to consistently better prediction performance in MSE (the lower, the better) across all six observations on the Audio CD reviews. The largest performance gap between SJASM and sLDA is found at aspect number 15, where the MSE of sLDA increases by 7.8% with respect to SJASM. The largest gap between SJASM and JST is located at aspect number 10, where the MSE of JST increases by 15.2% over SJASM.

On the Video Games review category, the best perfor-mance gains of SJASM against the sLDA and JST are lo-cated at the same aspect number of 30, where the MSE val-ues of sLDA and JST exceed by 15.3% and 23.4% compared to the MSE of SJASM.

The best performance gaps of SJASM over sLDA and JST on the Books category are found at the aspect numbers of 10 and 15, where the MSE values of sLDA and JST exceed by 8.6% and 8.4% over SJASM, respectively.

The LR model results in MSE scores 0.0639, 0.0609, and 0.1862 on the Audio CD, Video Games, and Books cate-gories, respectively, and loses out to SJASM for the overall helpfulness prediction.

The experimental results again demonstrated the improved effectiveness of SJASM compared to the benchmark models sLDA, JST, and LR on the three review categories. The main reasons for the improvement of SJASM over the bench-mark models may lie in:
Next, we selected the most helpful reviews for each prod-uct in terms of the predicted review helpfulness scores. Ex-ample results (from testing review data) were listed in Table 4. Due to page limitation, we just showed the major sen-tences and URLs for the selected reviews (note online review data may be updated).
In this section, we qualitatively evaluated the aspect de-tection of SJASM against sLDA and JST on the Audio CD, Video Game, and Books categories. For every category, we showed one same aspect detected by each model, given the aspect number K at which the minimum MSE was achieved for that model.

Table 5 lists an example aspect  X  X yrics X  on Audio CD re-views. Note for SJASM we showed the aspect terms and opinion words semantically related to the aspect in column 1 and column 2 (first 5 opinion words are positive, the follow-
Table 5: Example Aspect on Audio CD Reviews ing 5 are negative), respectively, since SJASM models sep-ar ately both types of words in its unified framework. Both sLDA and JST fail to do this, the aspect terms and opinion words recognized for the aspect by the two models are mixed together, as shown in column 3 and 4, respectively.
In particular, the aspect terms recognized for the aspect  X  X yrics X  by SJASM (column 1), such as  X  X yrics X ,  X  X iews X ,  X  X ife X ,  X  X overnment X , X  X ush X , etc., reflect the content of lyrics, and the keywords are coherent as well as are indicative of the aspect  X  X yrics X . The opinion words (column 2), such as  X  X yrical X ,  X  X ebel X , and  X  X onservative X , are also semantically related to the  X  X yrics X  aspect. sLDA identifies some relevant keywords like X  X yrics X , X  X ush X ,  X  X onservative X , etc., however, it also recognizes incorrectly the keywords like  X  X ock X  and  X  X etal X  which are typically mentioned in the aspect  X  X enre X . The keywords recognized for the aspect by JST contains non-specific terms like  X  X D X  and  X  X asterpiece X  which usually indicate the audio CD it-self.
 Table 6 lists a typical example aspect X  X ameplay X  X n Video Games category. SJASM again detects a coherent  X  X ame-play X  aspect which covers the aspect terms, such as  X  X ap X ,  X  X eatures X , and  X  X ameplay X , as well as the semantically re-Table 6: Example Aspect on Video Games Reviews lated opinion words, such as  X  X raphic X ,  X  X layed X ,  X  X ealistic  X , and  X  X loody X . sLDA recognizes the semantically related words like  X  X issions X ,  X  X ap X , and  X  X eatures X , but mixes to-gether the general terms like  X  X ice X  and  X  X ine X . Similar to sLDA, the aspect keywords clustered by JST are not as spe-cific as that by SJASM.
 Table 7 lists an example aspect  X  X tory X  on Books reviews. Th e aspect detected by SJASM is specific and coherent enough in itself, which contains aspect terms, such as  X  X tory X  itself,  X  X ife X ,  X  X vents X ,  X  X nding X , and  X  X limax X , as well as the se-ma ntically related opinion words like  X  X eal X ,  X  X maginative X ,  X  X ark X , and  X  X vil X , compared to the aspect detection results by both sLDA and JST, which recognize some non-specific words like  X  X ight X ,  X  X ense X , and  X  X ook X .

The improvement of SJASM over sLDA and JST for un-derlying aspect detection is mainly attributed to:
The recommendation of the most useful reviews for each detected product aspect is required to satisfy two conditions: the review must be helpful, and the aspect must be relevant to the helpful review.

For each aspect, the aspect-based review utility score was estimated using Equation 11, which incorporates two crite-ria corresponding to the aforementioned requirements: the predicted review helpfulness and document-specific aspect distribution. We selected the most helpful and relevant re-views for each aspect in terms of the aspect-based review utility scores.
 We tested the aspect-based review utility estimation of SJASM using precision at top N ( P @ Top  X  N ) selected re-views for each detected aspect, as shown in Table 8. Table 8: Aspect-based Review Utility Estimation Performance
For the aspect X  X yrics X  X n Audio CD category, all evaluated mo dels achieved 100% precision at the top-1 selected review. SJASM achieves 100% precision, while both sLDA and JST have precision of 60% and 40%, respectively, at the top-5 recommended reviews. For the top-10 selected review for the aspect, SJASM achieves 80% precision, while the two baseline models sLDA and JST have only 50% precision. That is, 8 out of top-10 reviews selected by SJASM are truly useful for the aspect, while only 5 out of 10 reviews selected by sLDA or JST are useful.

On the Video Games reviews, all models achieve 100% precision at top-1 recommended review for the aspect X  X ame-play X . SJASM reaches 80% precision at top-5 and top-10 se-lected reviews, while sLDA has only 40% precision for both cases. JST reaches 60% precision for its top-5 reviews, then decreases to 40% precision at its top-10 selected reviews for the aspect.

All the models achieve 100% precision at top-1 selected review for the aspect  X  X tory X  on Books category. sLDA re-sults in 40% and 60% precision at top-5 and top-10 selected reviews, while JST leads to 60% and 50% precision, respec-tively. Overall, SJASM achieves the best performance with 100% and 80% precision at top-5 and top-10 selected useful reviews for the aspect.
 Table 9: Aspect-based Review Utility Estimation Performance on Books Reviews
Further, we evaluated the aspect-based review utility esti-ma tion for three more aspects  X  X haracter X ,  X  X lot X , and X  X rit-ing X  on Books category, as shown in Table 9. SJASM again achieves the best performance ( P @ Top  X  N ) compared to sLDA and JST.

The improved effectiveness of SJASM over sLDA and JST for the aspect-based review utility estimation can be at-tributed to the following reasons:
In addition, we listed the example results for aspect-based review selection in Table 10.
In this paper, we focus on selecting the most helpful re-views not only for a reviewed product itself but also for the evaluated aspects of the product. We propose a novel super-vised joint topic model called SJASM to address the coarse-to-fine review selection problem. SJASM jointly discovers underlying aspects and sentiments guided by review help-fulness voting information. One key advantage of SJASM is that it can detect the sentimental aspects which are pre-dictive of review helpfulness. The evaluation results on the three publicly available review data sets demonstrated the superiority of SJASM over a supervised topic model sLDA, a weakly supervised model JST, as well as a classic LR model. For future work, we plan to evaluate SJASM on other dif-ferent product categories for coarse-to-fine review selection problem. We would like to thank Dr Chenghua Lin and Dr Yulan He for providing the code of joint sentiment-topic model (JST). This work was supported in part by a grant awarded by a Singapore MOE AcRF Tier 2 Grant (ARC30/12) and a Singapore MOE AcRF Tier 1 Grant (RG 66/12). [1 ] D. M. Blei and J. D. McAuliffe. Supervised topic [2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent [3] A. Ghose and P. Ipeirotis. Estimating the helpfulness [4] T. L. Griffiths and M. Steyvers. Finding scientific [5] T. Hofmann. Probabilistic latent semantic analysis. In [6] Y. Jo and A. H. Oh. Aspect and sentiment unification [7] S.-M. Kim, P. Pantel, T. Chklovski, and [8] D. Klein and C. D. Manning. Accurate unlexicalized [9] C. Lin and Y. He. Joint sentiment/topic model for [10] C. Lin, Y. He, R. Everson, and S. Ruger. Weakly [11] J. Liu, Y. Cao, C.-Y. Lin, Y. Huang, and M. Zhou. [12] Y. Liu, X. Huang, A. An, and X. Yu. Modeling and [13] Y. Lu, P. Tsaparas, A. Ntoulas, and L. Polanyi. [14] T. Minka. Estimating a dirichlet distribution. In [15] S. Moghaddam and M. Ester. Ilda: Interdependent lda [16] M. P. OMahony and B. Smyth. Learning to [17] I. Titov and R. T. McDonald. A joint model of text [18] H. M. Wallach, D. M. Mimno, and A. McCallum. [19] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating [20] Z. Zhang and B. Varadarajan. Utility scoring of
