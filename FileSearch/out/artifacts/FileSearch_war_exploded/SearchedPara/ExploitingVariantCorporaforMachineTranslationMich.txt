 Corpus-based approaches to machine translation (MT) have achie ved much progress over the last decades. Despite a high performance on average, these approaches can often produce translations with severe errors. Input sentences featuring linguistic phenomena that are not suf ficiently covered by the utilized models cannot be translated accurately .
This paper proposes to use multiple variant cor -por a , i.e., parallel text corpora that are equal in meaning, but use dif fer ent vocab ulary and grammat-ical constructions in order to express the same con-tent. Using training corpora of the same content with dif ferent sources result in translation models that fo-cus on specific linguistic phenomena, thus reducing translation ambiguities compared to models trained on a lar ger corpus obtained by mer ging all variant corpora. The proposed method applies each variant model separately to an input sentence resulting in multiple translation hypotheses. The best translation is selected according to statistical models. We sho w that the combination of variant translation models is effecti ve and outperforms not only all single vari-ant models, but also is superior to translation models trained on the union of all variant corpora.
In addition, we extend the proposed method to multi-engine MT . Combining multiple MT engines can boost the system performance further by exploit-ing the strengths of each MT engine. For each vari-ant, all MT engines are trained on the same corpus and used in parallel to translate the input. We first select the best translation hypotheses created by all MT engines trained on the same variant and then verify the translation quality of the translation hy-potheses selected for each variant.
 The outline of the proposed system is given in Figure 1. For the experiments described in this pa-per we are using two variants of a parallel text cor -pus for Chinese (C) and English (E) from the tra vel domain (cf. Section 2). These variant corpora are used to acquire the translation kno wledge for seven corpus-based MT engines. The method to select the best translation hypotheses of MT engines trained on the same variant is described in Section 3.1. Fi-nally , the selected translations of dif ferent variants are combined according to a statistical significance test as described in Section 3.2. The effecti venes s of the proposed method is verified in Section 4 for the Chinese-English translation task of last year X  s IWSL T 1 evaluation campaign. The Basic Travel Expr essions Corpus (BTEC) is a collection of sentences that bilingual tra vel experts consider useful for people going to or coming from another country and cover utterances in tra vel situ-ations (Kikui et al., 2003). The original Japanese-English corpus consists of 500K of aligned sen-tence pairs whereby the Japanese sentences were also translated into Chinese.

In addition, parts of the original English corpus were translated separately into Chinese resulting in a variant corpus comprising 162K CE sentence pairs. Details of both, the original ( BTEC O ) and the variant ( BTEC V ) corpus, are given in Table 1, where wor d tok en refers to the number of words in the corpus and wor d type refers to the vocab ulary size.
Only 4.8% of the sentences occured in both cor -pora and only 68.1% of the BTEC V vocab ulary was covered in the BTEC O corpus.

The comparison of both corpora revealed fur -ther that each variant closely reflects the linguistic structure of the source language which was used to produce the Chinese translations of the respecti ve data sets. The dif fer ences between the BTEC O and BTEC V variants can be cate gorized into: (1) literalness: BTEC O sentences are translated on the basis of their meaning and conte xt resulting in freer translations compared to the BTEC V sentences which are translated more literally; (2) syntax: The degree of literalness also has an im-pact on the syntactic structure lik e word order vari-ations (C V sentences reflect closely the word order of the corresponding English sentences) or the sen-tence type ( question vs. imper ative ); (3) lexical choice: Alternations in lexical choice also contrib ute lar gely to variations between the cor -pora. Moreo ver, most of the pronouns found in the English sentences are translated explicitly in the C
V sentences, but are omitted in C O ; (4) orthograph y: Orthographic dif fer ences espe-cially for proper nouns ( Kanji vs. transliter ation ) and numbers ( numer als vs. spelling-out ). The dif ferences in variant corpora directly effect the translation quality of corpus-based MT approaches. Simply mer ging variant corpora for training in-creases the coverage of linguistic phenomena by the obtained translation model. Ho we ver, due to an in-crease in translation ambiguities, more erroneous translations might be generated.
 In contrast, the proposed method trains separately MT engines on each variant focusing on linguistic phenomena covered in the respecti ve corpus. If spe-cific linguistic phenomena are not covered by a vari-ant corpus, the translation quality of the respecti ve output is expected to be significantly lower .
Therefore, we first judge the translation quality of all translation hypotheses created by MT engines trained on the same variant corpus by testing statis-tical significant dif ferences in the statistical scores (cf. Section 3.1). Ne xt, we compare the outcomes of the statistical significance test between the trans-lation hypotheses selected for each variant in order to identify the variant that fits best the given input sentence (cf. Section 3.2). 3.1 Hypothesis Selection In order to select the best translation among outputs generated by multiple MT systems, we emplo y an SMT -based method that scores MT outputs by using multiple language (LM ) and translation model (TM ) pairs trained on dif ferent subsets of the training data. It uses a statistical test to check whether the obtained TM  X  LM scores of one MT output are significantly higher than those of another MT output (Akiba et al., 2002). Given an input sentence, potheses are produced by the element MT engines, whereby each hypothesis. In order to check whether the high-est scored hypothesis is significantly better then the other MT outputs, a multiple comparison test based on the Kruskal-W allis test is used. If one of the MT outputs is significantly better , this output is selected. Otherwise, the output of the MT engine that per -forms best on a develop set is selected. 3.2 Variant Selection In order to judge which variant should be selected for the translation of a given input sentence, the out-comes of the statistical significance test carried out during the hypothesis selection are emplo yed.
The hypothesis selection method is applied for each variant separately , i.e., the BTEC O corpus is used to train multiple statistical model pairs (SEL O ) and the best translation (MT O lation hypotheses created by the MT engines trained on the BTEC O corpus is selected. Accordingly , the SEL V models are trained on the BTEC V corpus and applied to select the best translation (MT V MT outputs trained on the BTEC V corpus. In addi-tion, the SEL O models were used in order to verify whether a significant dif ference can be found for the translation hypothesis MT V SEL V models were applied to MT O
The outcomes of the statistical significance tests are then compared. If a significant dif ference be-tween the statistical scores based on one variant, but not for the other variant is obtained, the significantly better hypothesis is selected as the output. Ho we ver, if a significant dif ference could be found for both or none of the variants, the translation hypothesis pro-duced by the MT engine that performs best on a de-velop set is selected. The effecti veness of the proposed method is veri-fied for the CE translation task (500 sentences) of last year X  s IWSL T evaluation campaign. For the ex-periments, we used the four statistical (SMT) and three example-based (EBMT) MT engines described in detail in (Paul et al., 2005).

For evaluation, we used the BLEU metrics, which calculates the geometric mean of n-gram precision for the MT outputs found in reference translations (Papineni et al., 2002). Higher BLEU scores indi-cate better translations. 4.1 Perf ormance of Element MT Engines Table 2 summarizes the results of all element MT engines trained on the BTEC O and BTEC V corpora. The result sho w that the SMT engines outperform Table 2: BLEU evaluation of element MT engines the EBMT engines whereby the best performing sys-tem is mark ed with bold-f ace.

Ho we ver, depending on the variant corpus used to train the MT engines, quite dif ferent system per -formances are achie ved. Most of the element MT engines perform better when trained on the smaller BTEC V corpus indicating that the given test set is not covered well by the BTEC O corpus. 4.2 Effects of Hypothesis Selection The performance of the hypothesis selection method (SEL) is summarized in Table 3 whereby the ob-tained gain relati ve to the best element MT engine is given in parentheses. In addition, we performed an  X  X racle X  translation experiment in order to inves-tig ate in an upper boundary for the method. Each input sentence was translated by all element MT en-gines and the translation hypothesis with the lowest word error rate 2 relati ve to the reference translations was output as the translation, i.e., the ORA CLE sys-tem simulates an optimal selection method accord-ing to an objecti ve evaluation criterion.
 Table 3: BLEU evaluation of hypothesis selection
The results sho w that the selection method is ef-fecti ve for both variant corpora whereby a lar ger gain is achie ved for BTEC V . Ho we ver, the ORA-CLE results indicate that the method fails to tap the full potential of the element MT engines.

In addition, we trained the statistical models of the hypothesis selection method on the corpus obtained by mer ging all variant corpora (BTEC O  X  V ). Despite the lar ger amount of training data, the BLEU score decreases drastically which sho ws that an increase in training data not necessarily leads to impro ved translation quality . Moreo ver, the ORA CLE selec-tion applied to all translation hypotheses based on the BTEC O as well as the BTEC V corpus indicates that both variants can contrib ute significantly in or-der to impro ve the overall system performance. 4.3 Effects of Variant Selection The effects of combining selected variant hypothe-ses by testing whether significant dif ferences in sta-tistical scores were obtained are summarized in Ta-ble 4. The variant selection method is applied to the translation outputs of each element MT engine (MT O potheses (MT O posed variant selection method relati ve the best ele-ment MT output based on a single variant corpus is given in parentheses.

The results sho w that the variant selection method is effecti ve for all element MT engines. The high-est BLEU score is achie ved for MT O gaining 4.2% in BLEU score. Moreo ver, the pro-posed method outperforms the hypothesis selection method based on the mer ged corpus BTEC O  X  V by 11.2% in BLEU score.

A comparison of the proposed method with the best performing system (C-ST AR data track, BLEU=0.5279) of the IWSL T 2005 workshop sho wed that our system outperforms the top-rank ed system gaining 4.8% in BLEU score. This paper proposed the usage of variant corpora to impro ve the translation quality of a multi-engine-based approach to machine translation. The ele-ment MT engines were used to translate the same input whereby the best translation was selected ac-cording to statistical models. A test on the signifi-cance of dif ferences between statistical scores judg-ing the translation quality of a given hypothesis was exploited to identify the model that fits the input sen-tence best and the respecti ve translation hypothesis was selected as the translation output.

The proposed method was evaluated on the CE translation task of the IWSL T 2005 workshop. The results sho wed that the proposed method achie ving a BLEU score of 0.5765 outperformed not only all el-ement MT engines (gaining 3.6% in BLEU score), but also a selection method using a lar ger corpus obtained from mer ging all variant corpora (gaining 11.2% in BLEU score) due to less ambiguity in the utilized models. In addition, the proposed method also outperformed the best MT system (C-ST AR data track) of the IWSL T 2005 workshop gaining 4.8% in BLEU score.

Further investig ations should analyze the charac-teristics of the variant corpora in more detail and fo-cus on the automatic identification of specific lin-guistic phenomena that could be helpful to measure how good an input sentence is covered by a spe-cific model. This would allo w us to select the most adequate variant beforehand, thus reducing com-putational costs and impro ving the system perfor -mance. This would also enable us to cluster very lar ge corpora according to specific linguistic phe-nomena, thus breaking down the full training corpus to consistent subsets that are easier to manage and that could produce better results.

