 In this paper, we report a de ployed data mining application system for Motorola. Originally, its intended use was for identifying causes of cellular phone failures, but it has been found to be useful for many other engineer ing data sets as well. For this report, the case study is a data set containing cellular phone call records. This data set is like an y data set used in classification applications, i.e., with a set of attributes which can be continuous or discrete, and a discrete class a ttribute. In our application, the classes are normally ended calls, ca lls which failed to setup, and calls which failed while in progress. However, the task is not to predict any failure, but to identify possible causes that resulted in failures. Then, engineering e fforts may focus on improvements that can be made to the phones. In the course of the project, various classification technique s, e.g., decision trees, na X ve Bayesian classification and SVM we re tried. However, the results were unsatisfactory. After severa l demonstrations and interaction with domain experts, we finally designed and implemented an effective approach to perform the task. The final system is based on class association rules , general impressions and visualization . The system has been deployed and is in regular use at Motorola. In this paper, we first describe our experiences with some existing classification systems and discuss why they are not suitable for the task. We then present our techniques. As an illustration, we show several visualization screen s in the case study, which reveal some important knowledge. Due to confidentiality, we will not give specifics but only present a general discussion about the results. H.2.8 [Information Systems]: Data Management  X  Data Mining. 1.3.m [Computer Graphics]: Mi scellaneous  X  Visualization. Human Factors, Ma nagement, Design. General impressions, visual data mining, class asso ciation rules. In many engineering applications, the task is to find causes of problems so that improvements can be made to the design or the manufacturing process in order to produce better products in the future. Our application belongs to this type. In the case study, Motorola X  X  goal was to discover possible causes of cellular phone failures, i.e., to identify situations in which all phones or even a particular model of phones are more likely to fail. Engineers can use this information to focus their efforts to determine what may be the root causes of the failures in the phone designs through further laboratory simula tion and investigation. We began this project in Aug 2004 when we were asked to build a system to solve the problem. The data set we obtained is like any classification data set, except that it is very large. It has more than 600 attributes and more than 200G B of data every month. Some of the attributes are continuous and some are categorical. One attribute indicates the final dis position of the call such as failed during setup, dropped while in pr ogress, and ended successfully. and it takes categorical/discrete values. The classes are highly skewed in the data because successfully ended calls represent a very large proportion of the data and the failure cases are rare. However, it is the rate of incidence of the failure classes that is interesting to our users. Unbala nced sampling is used but it still results in millions of data points. Since the data set is a typical cla ssification data set, we first tried several classification algorithms af ter sampling. However, none of them were satisfactory. We also tried class association rules generated by CBA [11] and displa yed them using a sophisticated visualization tool which employed several rule ranking and rule query techniques. We had some success [25][26]. However, the approach still took extensive human e ffort to interpret the results. It was not considered satisfactory because it was not well suited for systematic exploration in or der to find interesting knowledge. By working closely with a Motoro la subject matter experts, we finally developed a new and ve ry successful approach. Our system, which is called Opportunity Map, has been deployed and is in regular use at Motorola. Our new approach is based on class association rules , general impressions and effective visualization . Class association rule mining [11] [1] produces all the rules in data to give a complete picture of the domain. This turn s out to be extremely important because it allows the user to find everything that may be of interest and to see each rule in context. General impressions, which are summarized knowledge of the discovered rules, enable the user to quickly focus on interesting and important knowledge in context. As our application s hows, a rule is only interesting when it is compared with its peers or neighbors and shows a significant deviation from them. Effective visualization facilitates the whole discovery process and enables convenient exploration of the discovered knowledge. In the rest of the paper, we will discuss why existing methods, such as classification technique s and interestingness techniques (which help the user find useful rules from a large set of rules) were not successful for our appli cations. We then present our new approach. After that, we use our application to demonstrate the proposed system, and describe the visualization sub-system. In this section, we discuss our experiences with several existing techniques, which were only help ful in limited ways, but were found not ultimately suitable for our applications. Since the data set is a typical classification data set, classification techniques [17][9][11] were tried first. We tried decision trees, and na X ve Bayesian classification (SVM [23] was also tried in Motorola, but with little success). These techniques were not successful due to the following reasons: 1. A typical classification algorithm, e.g., decision trees, rule 2. Since the rules are generated for classification purposes, they 3. Individual rules have no contex t information. An important The key issue is the completeness problem. If the completeness problem is solved, we will be able to find short rules and give each rule a context. We tried class association rules generated using our CBA system [11] sin ce class association rule mining aims to find all rules. Our initial system [25][26] based on such rules met some success, but it was still not sufficient. Class association rules (CAR) [11] are a special kind of association rules [1] with only a class on the right-hand-side of each rule. It is of the form: X  X  y , where X is a set of conditions ( attribute-value pairs ), and y is a class. Mining of CAR rules means to generate all such rules that satisfy the user specified minimum support and confidence constraints. Thus, CAR rules help deal with the completeness problem. However, there are two issues. 1. If the minimum support is greater than zero (0), some of the 2. The number of CAR rules generated can be huge, which There are many methods that help the user find interesting knowledge from a large set of disc overed rules. Next, we discuss our experiences with some of the existing methods. We experimented with several methods with limited success. Unexpectedness : In this method, the user is asked to give some existing knowledge and the system then finds those unexpected rules [7][13][15][16][18][20][24]. This did not work well because our application is huge and the users were not sure what to expect. They wanted our system to fi nd interesting knowledge for them. [4] studied neighborhood unexpectedne ss of rules. However, the neighborhood (similar to our context) is a set of syntactically similar rules, which is not applicable to our application. Rule ranking : Ranking rules according to some interestingness measures [2][6][19][27] did not work either because the top ranked rules may not be intere sting. Moreover, given each individual rule without a context to compare with is not useful as discussed in Section 2.1. We also tried a few other me thods, e.g., organizing rules hierarchically, querying rules, and using some rule operators, etc, [5][8][14][21][22][24][27]. All these methods had some limited success but were not sufficient. Th e first version of our system [25][26] was based on ranking and visualizing rules. It also organized rules hierarchically a nd allowed some rule querying. This initial system kept our domain experts interested in our work, but was not ready as a final product for deployment. This section presents the propos ed approach for our deployed application. We first discuss the guiding principles for our system, which we discovered from many interactions with domain experts. We then discuss how to improve class association rule mining in order to meet our requi rements. Finally, we discuss how to help users find interesting knowledge based on the idea of mining general impressions. The visu alization will be discussed in Section 5 where we show how the user interacts with our system. After a whole year of work, we realized that ranking rules in various ways was not sufficient even combined with sophisticated visualization [25][26]. Although occasionally some interesting rules were found, it was not an approach that users can work with to find interesting knowledge system atically. A different approach was needed. After numerous interactions with domain experts, we learned the following: 1. How domain experts describe knowledge: Domain experts 2. What constitutes a piece of interesting knowledge: A piece of 3. What kinds of user interactions with the system are needed: These critical findings form the gui ding principles for us to design the new approach. The second and the third principles clearly point to class association rules, which give all the regularities in the data. However, some improvements to the existing system are needed to meet the requirements. The first point, in fact, coincides with the idea of general impressions as a form of summarized knowledge given in [10]. However, in [10], the general impressions have to be provided by the user. In this project, the system discovers them automatically from CAR rules, which constitutes meta-mining or second order data mining, i.e., mining knowledge from discovered rules (fi rst order mining is to mine rules from the data). The general impression idea in [10] also needs to be extended. In the ne xt subsection, we first discuss some extensions to the class association rule miner CBA. To deal with the problem of finding all class association rules (CAR) to provide a context for every rule, we have to set both the minimum support and minimum c onfidence to 0. This causes combinatorial explosion. So a compromise is needed:  X  We set the minimum support and minimum confidence to 0 in It is also important to note that a single minimum support for the whole data set is not sufficient for our application in generating longer rules because the data is highly skewed. The most interesting classes are rare. Thus, fo r different classes, we need to use different minimum supports [12]. This ensures that rules are generated for rare (failure) cla sses without causing the frequent class to produce too many meaningless rules. We note that CAR mining requires every attribute in the data to be discrete. This is not a probl em as there are many existing discretization algorithms that can be used to discretize a continuous attribute into interv als. Manual and special data dependent discretization are supported through a simple GUI. This flexible CAR mining framework is used in our system, which is an extension of the CBA system [11]. Now, the problem knowledge can be found easily. This leads us to the mining of general expressions. As we discussed in Section 3. 1, we found that when domain experts exchange knowledge, they typically use summarized knowledge, which we call general impressions. The question is how to let a data mining system find such knowledge in the first place. Below we define some ge neral impressions and describe how to mine them. Human users generally express th eir knowledge in a hierarchical manner from summaries to details. The general impressions form the summarized knowledge and the specific rules are the details. In this work, we use the following hierarchy (Figure 1). This hierarchy has three levels representing knowledge of different granularities. The first level is called the Summarized Knowledge level . This level provides summarized information about the data. It aims to help th e user locate the most interesting attributes within the context of the overall data set. It provides general impressions in the forms of discriminative attributes and trends attributes. We will discuss them in next section. The second level is the Intermediate Knowledge level, which provides the supporting inform ation (e.g., data counts, percentages and other numbers ) to compute the summarized knowledge. All the supporting info rmation is designed to be provided with the context to facilitate knowledge understanding. It includes the general impre ssions in the forms of: class distribution (CD) rules, unit tr ends, and exceptions. The details will be given in the next sub-section. The lowest level contains unorga nized data mining rules. Rules are basic units of knowledge providing information for the computation of general impre ssions at the higher levels. General impression (GI) mining is an incremental process with respect to the length of GI. The length of a GI corresponds to the number of different attributes used in the GI. Length k GIs are mined from length k rules. In effect, a length k +1 GI can be considered as a length k GI plus one additional condition to called data constraints : Definition (data constraint): A data constraint (DC) is a set of conditions. Each condition is an attribute-value pair A where A i is an attribute and a ij is one of its values. A data constraint is used to narrow down the data to be analyzed. constraint. A data point satisfi es a data constraint if its corresponding attributes have th e corresponding specified values. DC may be empty . For simplicity, in the following sections, we assume that the data in question is a subset of data afte r the constraint is applied. That is, GI can have data constrai nts added in front of them. We now define and compute various types of general impressions. Each sub-section focuses on one type. Our experiences show that domain experts are always interested in knowing the main attributes th at affect the classes most. We call such attributes discriminative attributes . We will compute them based on exceptions of rule confidences. Let the set of classes in the data be C = { c 1 , c 2 , ..., c and the subset of the data be D DC  X  D after a data constraint is applied. For simplicity, we do not explicitly mention the data constraint, we only use D DC . Definition (expected confidence): Given the data D expected confidence of a rule on class c k Conf Expt ( c k ), is the class c k 's prior probability in D Let the values of attribute A i be a i1 , a Conf Obs ( A i =a ij , c k ) to denote the actual or observed confidence of the rule, A i =a ij  X  c k . If the values of attribute A random or not related to class c k , then Conf Obs to the same as Conf Expt ( c k ) . However, in reality Conf and Conf Expt ( c k ) can be very different, which indicates whether A =a ij is positively or negatively correlated to class c such a rule ( A i =a ij  X  c k ) an exception . We use the degree of exception to measure the difference. Definition (degree of exception): Given the data D DC , the degree of exception , denoted by DE(A i =a ij , c k ), of the rule A is measured by how the observe d confidence is different from the expected confidence: If one class has a large degree of exception for an attribute value, it is very likely that other classes will have large degrees of exceptions as well (because the observed confidence values add up to 1 for all classes) for each attribute value. So we can combine them together to produce the discriminative power of A =a ij , denoted by DP ( A i = a ij ). Definition (discriminative power of A i =a ij ): Given the data D the discriminative power of A i = a ij is defined as: where w c The discriminative power of A i =a ij shows how discriminative A a is with respect to all classes (weighted by w c classes is important because of the skewed distribution of our data. Likewise, we can also define the discriminative power of an attribute, which shows how usef ul this attribute is to the classification of classes. Definition (discriminative pow er of an attribute on class c
Given the data D DC , the discriminative power of an attribute A class c k and other classes. It is computed with: where r is the total number values of attribute A a ij , c k ) is the support count of the rule A i = a Definition (discriminative power of an attribute) : Given the data D DC , the discriminative power of attribute A i is the ability of this attribute to distinguish data of all classes: Figure 1. Knowledge hierarchy with general impressions Ranking can be performed based on the results. For convenience, in applications, we call an attribute a discriminative attribute if it is ranked high by its discriminative power. We should note that these are not the only ways to compute different discriminative powers. Other methods are possibl e. Our current methods work quite well in our applications. Another piece of summarized knowledge that domain experts increase/decrease, the phone is mo re/less likely to fail. We call such knowledge trend general impression . Note that trend is only applicable to continuous attri butes and ordinal attributes. Definition (unit trend of A i on class c k ): Given the data D unit trend of attribute A i on class c k , denoted by UT ( A a iy ], b l , c k ), is a trend of the rule confidences of a set of consecutive values [ a ix , ..., a iy ] of attribute A (called a trend type ) is decided by a statistical test, and takes one of the types from the set { increasing-trend , decreasing-trend , stable-trend }. The consecutive values from a such that any larger range will not have the trend b l . That is, the trend is maximal . over the values of the attribute. For example, it can have an increasing trend from value1 to value5 , and a decreasing trend from value6 to value10 . In applications, we require the value range of a unit trend to cover at least 3 consecutive values (or intervals). An example trend is: Here, " loan approved " is the class c k that we are interested in. The attribute " salary " is the trend attribute A increasing trend b l as its values go from small a ix to large a A unit trend is derived from a set of rules based on their confidences. For example, the above simple trend may be derived from the following rules: Rule 1: salary = 20K  X  loan_approved, Confidence: 20% Rule 2: salary = 30K  X  loan_approved, Confidence: 35% Rule 3: salary = 40K  X  loan_approved, Confidence: 40% Rule 4: salary = 50K  X  loan_approved, Confidence: 45% Rule 5: salary = 60K  X  loan_approved, Confidence: 56% By using the trend relationship, a ll the five rules (or even more) can be summarized into a single piece of knowledge. This unit trend has the value range from 20K to 60K. Our domain experts really like this notion because that is what they are interested in and is exactly the format that they are familiar with. The type of a trend is calculated using a statistical test called reverse arrangement test [3]. For example, to test whether it is an increasing trend, we first calcula te how many times that a later value is strictly greater than an earlier value. Each time that happens, we call it a reversal . If there are a lot of reversals (more than are likely from pure chance with no trend), we have significant evidence of an increasing trend. If there are too few reversals we have significant evidence of decreasing trend. Formally, it works as follows: 1. Given r ordered values as v 1 , v 2 ,..., v r 2. For r values, the maximum possibl e number of reversals is 3. With value r and R , we can lookup the statistic tables [3] to For each unit trend, we also compute two statistical properties. Support : It is the sum of the data points this trend covers (can be the raw count). It can also be e xpressed as a percentage of the total number of data points in D DC . Confidence : It is used to indicate how likely the trend is reliable. 
A value of 1.0 indicates a perfect trend of that type without exception. Otherwise, it is calcu lated based on how many data values and their covered data points satisfy the trend. where Abnormal_data is the data count which does not follow the trend. We use an exampl e to illustrate this below. The data set D DC has 1200 points, and a num ber of classes. The trend attribute A i has 6 possible values. The data counts as well as the confidence values for each class are given in Table 1. DataCount 200 200 200 200 200 200 
Class c 1 20(10%) 30(15%) 40(20%) 50(25%) 60(30%) 40(20%) For class c 1 , it displays an increasing trend having confidence values of 10%, 15%, 20%, 25% and 30% over the first five values. It shows an important prope rty of the data: as the values increase, it is more likely to result in class c support count is the sum of the data counts for class c 1 five values, i.e., 20+30+40+50+60 = 200. The confidence is 1.0 as the increasing trend is on all five values with no exception. Definition (trend value of an attribute on class c data D DC , the trend value of attribute A i , denoted as TV ( A c k ), on class c k for trend type b l is defined by: unit trends. We can also define the trend value for an attribute with respect to all classes. Definition (trend value of an attribute): Given the data D trend value of attribute A i , denoted as Trend ( A type b l is defined by: where m is the number of classes. Finally, we can use the trend values ( TV and Trend ) to rank attributes according to different types of trends ( increasing-trend , decreasing-trend or stable-trend ). For convenience, in our application, we call the top ranked attributes the trend attributes . In the preceding sub-sections, we discussed general impressions as summarized knowledge. We now discus general impressions that are directly related rules. We note that a rule is only interesting in comparison with its neighbors. Definition (class distribution rule): Given the data D distribution rule ( CD Rule ) is a rule with all the classes on the right-hand-side (RHS) of the rule. It is expressed as A CD rule extends the concept of class association rule ( CAR ) [11] by showing the class distri bution as the consequence. An example CD Rule is (the data set has only two classes): salary = 30K  X  loan_approved, Confidence: 35% The CD rule is easily displayed in a visualization screen as we will see in the next section. Th e user can visually compare the confidences for different classes to find interesting rules. In effect, a CD rule gives the user the necessary context information for each individual rule among differe nt classes. This was very important in our application as it is usually not interesting to find the confidence of a single class w ithout knowing for other classes. Note that we use only one condition in the rule. It, in fact, can have more conditions as we use the data D DC , which is obtained after some conditions (a data constraint) have been applied. Besides the classes, there is a nother dimension, in which the context is important for finding interesting rules. Definition (attribute-class rule group): Given the data D attribute-class rule group is the set of all rules of A Let the number of values of A i be r . The attribute-class rule group of A i on class c k is the set all r rules: ..., Displaying all these rules together allows the user to compare them to find interesting rules (e.g., exceptions). The system can also sort the rules according to their confidences (or supports) to find similar rules. The user is sometimes interested in values of an attribute that behave similar to another value. This is mainly useful for an attribute with a large number of values. For example, in our application, the number of phone mode ls is large. If the user finds a weak phone, he also wants to find other similar phones. Manually going through all the rules is difficult. Definition (value similarity on class c k ): Given the data D the rule A i =a ij  X  c k , the value similarity of another value a A i on class c k is computed with = 1  X  | Conf Obs ( A i =a ij , c k )  X  Conf Obs ( A Definition (value similarity): Given the data D attribute value A i =a ij , the value similarity of another value a
A i on all classes is computed with Based on these similarity values, we can sort attribute values to suit different needs. Those ranked on the top can be called similar values of A i =a ij , or behave similarly to A i =a ij It is difficult to have an objective measure of the effectiveness of our system. As evidence of its effectiveness, the system has been deployed in Motorola, and it is in daily use. Apart from the original application, the system has also been used by Motorola engineers to analyze other engineer ing data sets. This section first gives the architecture of the propos ed system and then presents a case study based on the real-life application use of the system at Motorola X  X  Mobile Devices business unit. The system architecture of Opportunity Map is given in Figure 2. Raw data are fed into the data preprocessing module. Besides data cleaning, an important task of this module is to perform attribute creation , which creates new attributes from existing attributes. For example, the user may be more interested in the ratio of two raw attributes A k and A l . So a new attribute A i Also, some attribute values ar e renamed from raw sensor input formats to more meaningful and user friendly numbers or strings. Data hashing and structuring m odule converts and segments the data into small pieces to enable efficient scanning and retrieval. The rule miner uses a modified CBA program to mine class association rules. The extensions to CBA have been discussed in Section 3.2 (CBA has an attri bute discretization sub-system). General impression miner perform s all the tasks described in Section 4. The visual user interface provides a rich set of operations that enable the user to interact with the system very easily and to identify interesting knowledge quickly. This case study aims to show user interactions with the system and how interesting knowledge is found in practice. The data comes from Motorola mobile phone usage log. The goal of the data mining is to discover possi ble causes of call failures and ways to further improve the performance of Motorola phones. This is a large and high dimensiona l data set. It has seventy six million (76,049,178) data records. And it has about 600 attributes. After the initial analysis by domain experts, the number of attributes was reduced to slightly more than 200, in which one attribute is the target (class) attr ibute. The class attribute has three values (classes), and it is highly unbalanced. The majority class covers a very large proportion of the data points. Due to confidentiality, we are unable to give the specific percentage. For the same reason, all attributes, values, and classes in our discussion below are replaced by generic names and values. To save space, images are cropped and resized. The visualization system s upports automatic scaling among classes to address the class imbalance issue. The scaling basically increases relative proportions, and trends are preserved in the scaled visualization. Figure 3 show s the visualization of the data without scaling. Because of the highly skewed class distribution, nothing can be seen about the minority classes, which are of the greatest interest to our users. Figure 4 shows the visualization with scaling, which allows trends and distributions to be seen clearly. Scaling is a crucial step in the visualization system. The visualization uses a matrix layout, and has two main modes, overall visualization mode , and drill down visualization mode . In the overall visualization mode (Figure 4), the X axis is associated with attributes in the data. The Y axis is associated with the classes. For each attribute (one column), each grid shows all one conditional rules of the correspondi ng class value. Each rule is visualized as a thumbnail bar. The height of the bar is the rule confidence value. We note that the first two levels of rules mining use the minimum support and minimum confidence of 0. Thus everything is found. Blue color is us ed by default. Some attributes may have many possible values (e .g., Att002, Att003, etc.) that the grid size may be inadequate to draw them all. Light blue is used to indicate this. In order to see all the values, the user can either increase the grid size, or use drill down visualization (see below). Various data counts a nd proportions (rule supports) are written out on the screen or on the Information Panel on the right when the user moves the mouse over the screen. This overall visualization mode is able to summarize and show a number of important properties of the data immediately: 1. The data distribution of each attribute is illustrated by the 2. For each attribute, the data distributions of its values with 3. One-condition class association rules are visualized for all 4. Trends are easily detectable from the shape in each grid. 5. Strong trends are indicated using color arrows: red for 6. Since the user can see the property of the data easily with a After seeing the overall visualization, the user may be interested in trends and want to see which attributes are related to the classes. For example, if the user is interested in seeing increasing trends with respect to the first class (first row, class Value4733), using a sorting command from the menu produces the visualization in Figure 5. Attributes are sorted so that those with strongest increasing trends on cl ass Value4733 appear first on the X axis. With this screen, the user can easily confirm previous knowledge, or find interesting new knowledge quickly. For example, it clearly shows that as the values of attribute Att951 increase from small to large, th e chance of failure increases (failure class Value4733). This may be a vital piece of knowledge which could be used in product de sign to satisfy the desired goals. Visualization of sorted trend attr ibutes for other trend types and classes is easily viewable using similar commands. Another sorting shows the discri minative attributes (Figure 6). Please note that the pink color is used to indicate that the scaling produced some very small values that can hardly be seen on current screen (for that grid). The top ranked attributes all ha ve strong discriminating powers on the classes. For example, the valu es of the first attribute (Att021) clearly discriminate data into di fferent classes. Attribute Att020 also has strong discriminating power except for the middle 4 values. Our users confirmed that this kind of knowledge was much more useful than rules produced by classification systems. A classification system may only use one attribute (e.g., Att021) but miss the others which may be more useful to the user. Also crucial is the fact that the user can view all the details side-by-side. This provides contexts for visual knowledge discovery, which is shown to be crucial in practice. The summarized information in the overall visualization is very useful in practice to get the users started and to pick the right attributes for further study using drill down visualization. In a drill down visualization, the X axis is associated with values of a given attribute. The Y axis is associated with another attribute (usually the class attribute). Figure 7 shows a drill down visuali zation of one attribute (Att001, on the X axis) with all classes (t he Y axis). This visualization reveals the following detailed pieces of knowledge: 1. All the class distribution (CD) rules of the given attribute. Att210=Value4734, 0.6263% 2. The exact trends of this attribute with respect to all classes (if 3. Exceptions of this attribute. The dotted dark blue horizontal For each piece of knowledge discovered here, the user is able to see all the related classes (in the vertical direction) and all the related values (in the horizontal di rection) from the visualization. They act as the context. Now, suppose the user is interest ed in seeing what will happen if another condition is added. This can be easily visualized by adding a data constraint to the visualization so that the subset of data can be visualized and studied. Figure 8 shows the result of using "Att012 = Value0497" as the data constraint (Value0497 is a particular product model). Thus , all the information shown in this visualization has 2 attri butes involved (plus the class attribute), i.e., two conditional rules. For example, for the last column, the corresponding CD rule now is: Att012=Value0497, Att001=Value0232  X  Att210=Value4733, 0.6612% Att210=Value4734, 1.3914% Att210=Value4735, 97.9472% Comparing with Figure 7, we can see that adding the above data constraint affects the last column greatly. It changed the class Value4734 from below expected confidence (in Figure 7) to far above expected confidence (Figure 8). This piece of information could be used by engineers to modify product designs. Another drill down visualization can be used for comparative study, as shown in Figure 9. It "stacks" two or more drill down visualizations by drawing the bars for each corresponding grid side by side into one grid, creating a clear contrast view in each constraints represent two differe nt products, this visualization clearly show that the second product (Value0498) has a lower failure rate than the first one, by having consistently tall bars in the row of Value4735 (the class for  X  X uccess calls X ). Other rows and bars show how the products perform on different values of Att012 as well as the co mparisons between them. Please note that the Y axis can be assigned to any attribute, not only the class attribute. Due to space limitations, we are unable to show a screen-dump and an example. The system also has another interesting feature. When it sorts the attributes using a criterion (e.g., trend value), the attributes are listed in the sorted order on the le ft of the screen. When the user moves the mouse over one of them, the corresponding drill down visualization is shown instantly on the right. This enables the user to quickly glance through all the attributes for details without issuing any command. Figure 10 demonstrates this idea by sorting attributes based on the increas ing trend on class Value4734. In summary, the overall visualiza tion gives the user summarized knowledge. It shows various sorti ng results for different general impressions. This allows the user to pin down interesting attributes easily. The drill down visualization gives further information and enables more detailed analysis. What is crucial is that all the pieces of information and rules are shown in context, which enables fast discovery of interesting knowledge. Our users confirm that the system is able to give them significant help and enable them to easily and quickly analyze their data effective. Finally, note that we did not show any long rules in this section. Although they can be shown as well, since they are less useful in our application we omit them due to space limitations. Through this project, we learned valuable lessons. We summarize them below: 1. Working with domain experts closely. They not only provide 2. Class association rules are very useful for finding causes of 3. Traditional classification algorithms such as decision trees, 4. A piece of knowledge is only interesting in context. Without 5. User driving interactive knowledge discovery is the best In this paper, we examined a deployed data mining system for identifying interesting knowledge from a large data set. The system is now in regular use at Motorola for finding causes of problems with mobile devices. Due to the success of the system, it is also being used for analyzing other types of data. The success of the Opportunity Map system indicates that GI mining combined with effective visualization represents a systematic approach to helping the user find interesting knowledge from a large number of rules. Our next step is to further improve the system to enhance its data pre-processing capability and to incorporate some more methods to help the user find useful knowledge quickly. [1] Agrawal R., and Srikant R. Fast algorithms for mining [2] Bayardo R., and Agrawal R. Mining the most interesting [3] Bendat J., Persol A. Random da ta: analysis and measurement [4] Dong G., Li J. Interestingness of discovered association rules [5] Han J., Fu Y., Wang W., Koperski, K. and Zaiane, O. [6] Hilderman R., Hamilton H. Ev aluation of Interestingness [7] Jaroszewicz S., and Simovici D. Interestingness of Frequent [8] Klemetinen M., Mannila H., R onkainen P., Toivonen H., and [9] Langley P., Lba W., and Thom pson K. An Analysis of [10] Liu B., Hsu W., and Chen S., Using General Impressions to [11] Liu B., Hsu W., and Ma Y. In tegrating Classification and [12] Liu B., Hsu W., Ma Y. Mining Association Rules with [13] Liu B., Hsu W., Mun L., and Lee H. Finding interesting [14] Meo R., Psaila G., and Ceri S. A New SQL-like operator for [15] Padmanabhan B., and Tuzhilin A. Knowledge Refinement [16] Piatesky-Shapiro G., and Math eus C. The interestingness of [17] Quinlan, J.R. C4.5: Programs for Machine Learning. Morgan [18] Suzuki E. Autonomous discovery of reliable exception rules. [19] Tan P-N., and Kumar V. Interestingness measures for [20] Tuzhilin A., and Adomavicius G. Handling Very Large [21] Tuzhilin A., and Liu B. Querying multiple sets of discovered [22] Virmani A., and Imielinski T. M-SQL: A query language for [23] Vapnik V. The Nature of Statistical Learning Theory. [24] Wang K., Jiang Y., and Lakshmanan L. Mining unexpected [25] Zhao K., Liu B., Tirpak T., Schaller A. V-Miner: Using [26] Zhao K., Liu B., Tirpak T. and Xiao W. A Visual Data [27] Zhong N., Yao Y.Y., Ohshima M., and Ohsuga S. 
