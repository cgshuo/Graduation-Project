 As Twitter 1 has grown, many different kinds of user accounts have emerged. At a general level, we roughly classify them into two categories: (i) Personal Communication Account (PCA) and (ii) Public Dissemination Account (PDA). PCAs are accounts that are usually operated by unique individuals and used for interpersonal communication (e.g., to share personal experiences and opinions). PDAs, in contrast, are typically linked to and operated by a company 2 ,aweb site 3 or a program 4 and used to disseminate specific news and information (e.g., locations of car accidents, shopping deals, crimes).

Existence of PDA may cause problems when attempting to study human behavior using Twitter data. Recently, a Twitter-based analysis in Science sug-gested that changes in overall tweet sentiment over time (hours of the day) may be interpreted as evidence of biologi cally-based diurnal cycles in the mood patterns of humans [7]. However, an underlying assumption is that the tweets were produced by human individuals as part of their natural daily lives. If the data stream is a mixture of PCAs (humans) and PDAs (corporate/entity), the conclusion may be unwarranted. To illustrate it, In Figure 1 we plot the time evolution of average sentiment for 2,787 PCAs and 389 PDAs that were labelled manually. As can be seen, the daily diurnal cycle, i.e., the mood increases in the early morning and decrease later, is easily discernable in the overall data (Figure 1(a)) as similar to the previously published analysis. However, contrary to expectations, we find that the cycles are much less prominent in the PCA (hu-man individual) sub-sample (Figure 1(b)) than in the PDA (corporate/entity) sub-sample (Figure 1(c)). The importance of separating the different account types for reaching accurate conclusions is clear.
Beyond potentially adding noise to researchers X  data streams, PDAs are po-tentially very useful for various types of data consumers. For instance, an indi-vidual looking for jobs may follow PDAs that publish job postings of a particular type (e.g., web development) in a particular geographic area (e.g., New York). Similarly, shoppers may follow PDAs that provide timely notification of nearby sale events and hot deals. In sum, as PDAs X  tweets are often focused on a very specific topic and formatted in a uniform manner, they are relatively easy to process and may thus provide rich content for individuals, researchers, and the recommendation engines that support those populations.

The enormous size of the Twitter data stream makes it highly impractical to manually check the account type. In th is paper we develop and test a variety of techniques for automatic classification of PDAs and PCAs using multiple temporal, spatial, and textual features of accounts X  tweet publishing patterns.
Figure 2 gives an overview of the propo sed framework for PDA detection. As shown, tweets are continuously sent to the database. Once a new user arrives, her profile of raw data is checked and different types of features are extracted. Specifically as illustrated in Figure 2, there are temporal, spatial and textual features (details are discussed in Sectio n 2). With extracted features, a classifi-cation model is then employed to determine the account type. After a PDA is detected, the system checks its posted t weets to model its topic as well as catego-rizing its spatial characteristics. Finally, all extracted features and topic models are also saved in the database. Twitter applications, e.g., user recommendation, can then be built upon the knowledge mined in this framework.

The rest of the paper is organized as follows. Section 2 describes the feature extraction. Section 3 provides details of our models. Section 4 reports the eval-uation of our model and shows some PDAs found using our model. Section 5 reviews relevant research and finally S ection 6 concludes the whole paper. In this section we discuss the extract ion features used to identify PCAs and PDAs. The work makes use of an archive of geo-tagged tweets published between March 1, 2011 and January 18, 2012 [1]. During this time, 39,994,126 geo-tagged tweets (with latitude and longitude attached) were posted by 1,506,937 users. Ground truth classification data were g enerated by randoml y selecting 5,000 accounts that published at least 200 tweets and manually labeling them as PCA, PDA, or unknown. Of the 5,000 randomly selected accounts 2,787 were PCAs, 389 PDAs, 0 spam accounts and 1,824 unknown accounts 5 . These data were then used to extract and analyze the temporal, spatial and textual features of PCAs and PDAs. 2.1 Temporal Feature PDAs are, by definition, regularly disseminating useful information. Often this task is facilitated by use of automated computer programs that publish tweets at specific times or at regular intervals [23]. In contrast, PCAs, being human, may be less regimented in their communication of daily live events and feelings. Figure 3(a) and 3(b) show the timing (minutes by seconds) of tweets published by two Twitter accounts. The specific times at which tweets were sent by the user depicted in the Figure 3(a) are spread relatively uniformly across the space. That is, the user does not appear to have a preference for specific minute-second combinations. In contrast, the user dep icted in the right panel tweets at very specific times. While this program/bot-controlled PDA is not able to get the tweet out at exactly the same second each hour, the temporal distribution is clearly non-uniform.
Consider the two-dimensional time space shown in Figure 3(a) and 3(b) where the x -axis is the exact minute (0-59) within the hour that the tweet was pub-lished, and the y -axis is the exact second (0-59) of that minute. Tweets X  time-stamp information can be used to locate each tweet as a point in this space. For each account, we count the number of tweets within each section of the grid and compute the sum of the difference between the observed frequency and the expected uniform frequency to obtain a temporal feature. Formally, let g denote the total number of grids and each time stamp can be converted to a g -dimensional vector x =( x 1 ,  X  X  X  ,x g ), where x i { 0 , 1 } and g i =1 x i =1.This vector indicates which grid the time stamp belongs to. Suppose there are N tweets and the expected number of tweets falling in each grid should be N/g for a uniform distribution. We define a time uniformity metric du to measure the difference between the observed time distribution and a uniform one. where I =(1 ,  X  X  X  , 1 Thelowervalueof du suggests a higher probability of uniform distribution. As can be seen in Figure 3(c) and 3(d) the distribution of du for PCAs satisfies a log-Gaussian distribution centered around 6, while the PDAs du are skewed from 6 upwards. 2.2 Spatial Feature PCA X  X  and PDA X  X  tweets may also exhibit different spatial distributions. As people go about their daily lives, they often tend to move around within a limited area, periodically switch between previously visited locations (e.g., home and work), and are constrained by the physical parameters bounding how fast they can travel between locations [8,20,5,4]. In contrast, PDAs, by their very nature, are not constrained. Twitter APIs can be used to tweet from multiple locations simultaneously and/or purposively designate the geo-locations that should be attached to each tweet. Figure 4(a) and 4(b) show the footprints of geo-located tweets respectively published by a PCA and a PDA. It can be seen that the PCA tweets from a small area (303 . 0233 km 2 ) in New York, while the PDA tweets from all across the United States (about 9 . 6302  X  10 6 km 2 ). The narrow and sharp peak in Figure 4(c) indicates a PCA v isits the same locations repeatedly. In contrast, the density distribution of a PDA in Figure 4(d) is much flatter, indicating that this account rarel y tweets from the same locations.
We define two metrics, namely Mobility Area (MA) and Unit Mobility Entropy (UME) to capture the spatial features. MA is a measure of an account X  X  mobility range. For a set of points in geographic space p 1 ,  X  X  X  ,p n ,where p i =( x i ,y i ) consists of a longitude x i and a latitude y i , we can find a minimum bounding box p min =( x min ,y min ) ,p max =( x max ,y max ) that covers all points. MA is defined as the surface area of the bounding box in the earth.
 where R is constant representing the radius of the earth.
UME measures the diversity of spatial locations visited during a specific unit of time. A smaller value indicates a higher probability of revisiting the same location. Formally, given a unique set of locations p 1 ,  X  X  X  ,p n that appear in one X  X  tweets and a minimum bounding box ( p min ,p max ) that covers these points, the UME is defined in Equation (3).
 where f i represents the frequency of tweets t hat contains the geographical point p i and  X T is the time interval between the earliest tweet and the most recent one.

Furthermore, we can calculate the  X  X o ving X  speed of the account by checking the time stamp and geo-coding of its su ccessive tweets. For some PDAs, where account holders may publish tweets from multiple, distant locations within a short interval, moving speed may be quite large. In contrast, PCAs are bounded by the physical constraints on human mobility. 2.3 Textual Feature Content of PDA X  X  tweets may also differ from that of PCA X  X . Given that PDAs X  main objective is to disseminate a specific kind of information, they may reuse particular words. In contrast, PCAs tend to share a more diverse set of infor-mation and thus use a wider variety of words. Here we define a metric tweet coverage of a word as the proportion of tweets that contain the word.
We focus on two textual features: word -usage size and tweet coverage. The former measures the number of unique words appearing in an account X  X  tweets. Since tweets of PDA aim to propagate one particular type of information, the word set is constrained towards a specific topic. In this case, the size of word set is relatively small compared to that of PCAs.

Formally, let W = w 1 ,  X  X  X  ,w n denote the global word set and f u i denote the number of user u  X  X  tweets that contain the word w i .For N posted tweets of an account, the word-usage size of the user ws u is defined in Equation (4). Tweet coverage is the probability of a single word appearing in the tweet. Given a user u  X  X  N tweets, the tweet coverage for a word w i can be computed by . Particularly, we are focused on the mean of top-k ( k  X  n ) words (referred to as top-k mean) and tweet-coverage variance of all words (referred to as global variance) for that user. Suppose we sort the words in a non-ascending order The top-k mean  X  u and global variance  X  2 u of tweet coverage for the user account u are defined in Equation (5).
Figure 5(a) and 5(b) show the words X  tweet coverage of 1,000 randomly sam-pled tweets for a PCA and a PDA. It can be easily seen that the tweet coverage for a PCA is quite low and the maximal one is about 0.04, i.e., the most frequent word appears in 4% of her published tweets. In contrast, the PDA (Figure 5(b)) uses some words in almost every tweet. In this example the PDA is a corporate account that tweets jobs for mobile phone retail in different US cities. The words with 100% tweet coverage are job , mobile and retail .
Moreover, since PCA X  X  tweets are a refl ection of their daily life, the sentiment of the tweets are more likely to fluctuate than that of PDAs. By adopting the lexicon for word-sentiment in existing works [16,17], we estimate a sentiment score for each tweet. Figure 5(c) and 5(d) show the standard deviation of PCA X  X  and PDA X  X  sentiment in Tweets covering a 24 hour time period. It can be seen that on average the PDA X  X  tweets display less fluctuation of sentiment than the PCA X  X . Therefore, the deviation of sent iment is also extracted as a feature. In this section we describe details of ou r detection model, including model de-velopment, parameter learning and detection function. Specifically to fit the temporal, spatial and textual features of PCAs, we propose a generative model that is adapted for stream training data. Classification of PDAs is solved by detecting the outliers of the fitted model. 3.1 Model Development Without loss of generality, let D = x 1 ,  X  X  X  ,x n denote the values of extracted features. Here each element x i represents the feature value of an account. The semantics depends on the feature types. For instance, x i could indicate the log-value of du (see Equation (1) for definition) for a temporal feature, or ma (Equation (2)) for a spatial feature, or ws (Equation (4)) for a textual feature. Based on maximum-likelihood theory, to learn the model parameter  X ,  X  , we need to maximize the probability Pr (  X ,  X  | D ). Using Bayesian inference,
Under the assumption that the data D is generated by some Gaussian distri-bution N (  X ,  X   X  2 ), we can write the probability as in Equation (6).
Furthermore, since Pr (  X ,  X  )= Pr (  X  |  X  ) Pr (  X  ), we use a Gaussian and Gamma distribution as the conjugate prior distribution Pr (  X  |  X  )and Pr (  X  ), as shown in Equation (7) and (8).
 where  X  0 , X  are prior distribution parameters for  X  .

Therefore, the prior distribution is rep resented by a product of a Gaussian and a Gamma distribution. Conversion to match the format of posterior distribution in Equation (6) gives us Note that in Equation (9), we define for simplicity new parameters  X  =  X  X  0 ,  X  =  X  X  2 0 2 + b to. Also, to maintain consistency with the posterior distribution, we constrain a =  X  +1 2 .

After unifying the posterior and prior distribution, we can represent the prob-ability Pr (  X ,  X  | D )asbelow: 3.2 Model Training for Stream Data In previous subsection we unified the prior and posterior distribution in Equation (10). Now we can define the objective f unction and learn the parameters by maximizing it.

Let  X  =  X ,  X ,  X  denote the parameters for prior distribution and we define the objective function as the log of the probability Pr (  X ,  X  | D ), i.e., L (  X ,  X  )= the value for model parameters. Without loss of generality, suppose there are two sets of training samples coming in a str eam, where X = x 1 ,  X  X  X  ,x n 1 arrives firstanditisfollowedby Y = y 1 ,  X  X  X  ,y n 2 . Also, let (  X  x , X  x ) denote the model parameters learned purely based on X , the sequential learning process is then illustrated in Equation (11) and (12).
From the Equation (11) and Equation (12) we can see good characteristics of the model. Suppose the model has been trained based on the dataset X and anewdataset Y comes. With such sequential learning equations, instead of re-training on the whole dataset, we can simply update the model parameters with the new dataset. 3.3 Detection Function Given the extracted features of a target account, we use the trained model to compute the probability that this account is generated by the model. The higher the value is, the more likely the account is a PCA.
 Formally, suppose there is an unknown account with features u 0 = f 1 ,  X  X  X  ,f 6 . The parameters of corresponding Gaussian distribution are denoted by M = (  X  X  X  , (  X  given feature vector is generated by the model M .
 where C is a constant that is independent of the target account u 0 and model parameters.

The final detection is a voting pro cess. Given the threshold vector  X  ,the detection function will judge whether the given account is PDA in each feature dimension. If the number of votes exceeds a threshold v  X  , the function will output 1, indicating the account is classified as PDA.
 3.4 Other Classifiers Besides the proposed probabilistic model, we also examine the utility of other widely used classifiers in this framework. Particularly we examine Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Decision Tree and Naive Bayes. The latter two are both implemented by Weka [10].

The SVM we adopt is developed by LIBSVM [2]. Since the number of PDA is far smaller than that of PCA, we develop three variant SVM for imbalanced classification problem. The first one over-samples minor class and is denoted as DUP-SVM . The second one under-samples the major class and is referred to as RED-SVM . Finally we increase the misclassification cost of the minority class to 100 times than that of the majority class and is referred to as Biased-SVM . This section we evaluate the classifiers in terms of both effectiveness measured by F  X  and efficiency measured by training time. All evaluation are based on four-fold cross-validation and average performance is reported. Then we run our generative model on the unlabeled data to mine new PDAs. The data set we use for evaluation is a collection of manually labeled accounts, 389 PDAs and 2,787 PCAs. For F  X  ,weset  X  =0 . 25 because precision is relatively more important than recall in our case. 4.1 Experiments Figure 6(a) shows the impact of threshold on the performance of the generative model. Generally, small threshold can achieve high accuracy PDA detection but may miss many PDAs. On the other hand, big threshold may reduce missing rate but lead to false identification. Figure 6(b) shows the general comparison of different methods on PDA/PCA classification. Particularly we choose the feature threshold  X  and vote threshold v  X  with regarding to maximize PDA X  X  and PCA X  X  F-measure, which a re respectively denoted as Mdf and Mcf .The tuning process is not shown in this paper due to the page limit. We can see that our probabilistic model is either better than or close to the best performance of other classifiers. We also use synthetic data to evaluate the efficiency. Figure 6(c) shows the result and it can be seen that the time cost of training our model increases slowest as the data set grows. Note that the time cost for KNN mainly comes from classification where all training data is scanned for each classification task. The experiment shows it takes KNN 1.0334 seconds to classify one account when the training data set is 100,000. For SVM, the time cost is 401.785 seconds for 20,000 training samples in our experiment. 4.2 Exploration In this section we run our trained model on the unlabeled data to explore new possible PDAs. By the time the paper is written, we have detected 13,871 PDAs.
Table 1 shows some of the detected PDAs. In the table, some twitter account has such symbols as XXX and YYY . They mean there is a bunch of twitter accounts with similar naming rules, where XXX means the type of jobs while YYY stands for a particular area name, e.g., tmj tx intern is a PDA that tweets internship in Texas, sp arizona tweets about deals and coupons in Arizona. Two areas are related, (i) human mobility modeling, and (ii) spam detection.
As more and more people use geo-enabled smart phones to share their loca-tions via social media, there is a large number of studies on modeling individ-ual X  X  mobility pattern. Generally there are two categories: (i) predicting user X  X  location [3,11,12], and (ii) modeling continuous moving behavior [4,5,14]. These works and our work are of mutual benefit to each other. On one hand, observa-tions of these works serve as a guideline for us to design spatial features for our detection model. On the other hand, these existing works do not differentiate common user accounts and non-human accounts. Our work can facilitate them to reduce  X  X oise X  in the data.

Many works studied the methods to battle with spammer in Twitter. In [19,18,6,22,15,21], following/followee structure was exploited.Also, spammers are usually controlled by some program and thus the times tamp of their published tweets can be used for detection [9,23,6 ,13]. Since one of the spammer X  X  moti-vations is to propagate some information, content-based features (e.g., ratio of URLs, number of hash tags, etc) were also used in some works [18,9,9,13].
These spammer-detection works are complementary to ours. Firstly, some features (e.g., minute-second distri butionin[23])canbeusedtodetectPDA. Also, some spammers may disguise themselves as a PDA (e.g., adding random geo-tag in their tweets) and techniques of these works can be of great help to our framework to refine the detection result. The Twitter data stream is an immensel y rich data resource to which many different types of entities are contributing. As such, effective use may require separation of tweets by account type. We identified types of accounts that may be especially interesting to researchers and information consumers, with specific concentration on Public Dissemination Account (PDA) and Personal Communi-cation Account (PCA) . To separate PDAs from millions of PCAs in Twitter, we defined and extracted temporal, spatial and textual features of each account X  X  tweets and compared our proposed probabilistic model to other conventional classifiers including SVM, KNN, Decision Tree and Naive Bayes. The experiment showed while the probabilistic model displays better or similar performance with these classifiers, it shows higher efficiency in training and is more adapted for stream data.

In future work we plan to strengthen our current system so that it can auto-matically build a detailed and dynamic taxonomy of PDAs, thus turning gold specks into nuggets that are more easily mined out of the Twitter stream.
