
Association rule-based classier s have recently emer ged as competitive classication systems. Howe ver , ther e are still deciencies that hinder their performance . One de-ciency is the use of rules in the classication sta ge. Cur -rent systems assign classes to new objects based on the best rule applied or on some predened scoring of multi-ple rules. In this paper we propose a new tec hnique wher e the system automatically learns how to use the rules. We achie ve this by developing a two-sta ge classication model. First, we use association rule mining to disco ver classica-tion rules. Second, we employ another learning algorithm to learn how to use these rules in the prediction process. Our two-sta ge appr oac h outperforms C4.5 and RIPPER on the UCI datasets in our study , and outperforms other rule-learning methods on mor e than half the datasets. The ver -satility of our method is also demonstr ated by applying it to text classication, wher e it equals the performance of the best known systems for this task, SVMs. Classication is an important task in man y applications. A classier is a system that assigns, or predicts, one or more class labels for a given object. One way to create a classier is to use a learning algorithm to construct a classier from a training set of objects whose classication(s) is kno wn.
Associati ve classiers [2, 18, 19] consist of a set of rules, with each rule predicting that an object belongs to a specic class if it has certain properties. The rules are disco vered using association rule mining algorithms [1]. The associ-ation rule mining problem has been thoroughly studied in the data mining community [13 ], thus there are several fast algorithms for disco vering these types of rules.
To classify a given object, an associati ve classier pro-ceeds in three steps. First, it determines which of its rules apply to the object. Then it selects a subset of the applica-ble rules (possibly all of them) based on some measure of their  X strength X  or precedence. Finally , if it chooses more than one rule, it combines the class predictions of all the selected rules to produce a nal classication.

For example, CB A [19 ] classies an object using only the highest ranking rule that applies to the object, where rank is dened by the rule' s condence on the training set. This method has two shortcomings. The rst is that by bas-ing its classication on only the highest ranking rule, CB A might be ignoring a lar ge number of high ranking, appli-cable rules that might agree with each other and disagree with the highest ranking rule. Secondly , because each rule predicts just a single class, CB A is incapable of assigning a given object to multiple classes simultaneously , which is essential in some applications.

CMAR [18 ] and ARC [2] overcome CB A's shortcomings by selecting the K highest ranking applicable rules, not just the rst. The key issue now is, how to combine the class predictions of the selected rules to produce a nal classica-tion? Both systems use a weighted voting scheme, the y dif-fer in the details of how weights are calculated. CMAR uses a chi-square weighting scheme, while ARC weighs classes based on the average condence of the selected rules that predict that class. These systems trade part of their compre-hensibility inherited from the association rules for impro ved performance. This tradeof f is the results of using a weight-ing score on the rules.

In this paper we also use a weighted voting scheme to combine the class predictions of the selected rules to pro-duce a nal classication, but instead of pre-dening the way in which weights are computed, we use a second learn-ing algorithm to determine the weights. Learning in our system therefore tak es place in two stages. First, an asso-ciati ve classier is learned using standard methods. Second, predened features computed on the outputs of the rules in the learned associati ve classier are used as the inputs to a neural netw ork, which is trained, using a separate training set, to weigh the features appropriately to produce highly accurate classications.

This two-stage system, with a layer of feature denitions interposed between the output of the rst learned system and the input of the second, is the paper' s main contrib ution. Another signicant contrib ution of the paper is the use of a statistical analysis of the experimental data that is more rigorous than pre vious studies.

The performance of our two-stage system is evaluated experimentally on two distinct classication tasks, single la-bel classication and multiple label classication. In single label classication, the task is to assign an object to exactly one of the classes. This is the standard classication task studied in machine learning, and a variety of test datasets and systems are available for comparison. We use twenty of the UCI datasets[5], and compare our approach to seven existing systems. Our approach outperforms C4.5 and RIP-PER on all the datasets in our study , and outperforms the other rule-learning methods on about half the datasets.
In multiple label classication, an object can be as-signed to several of the classes simultaneously . The stan-dard testbed for this task is classifying news articles into subject cate gories, where it is necessary for some news ar-ticles to be assigned to multiple cate gories. For example, an article about selling a sports franchise should be put into at least two cate gories,  X sports X  and  X business X . The best kno wn algorithms for this text classication task are SVMs [16 ]. Our experiments using the Reuters dataset establishes our two-stage system as the rst classication method to equal the performance of SVMs on this task.
A classier is built by applying a learning method to a training set of objects. This model is further used to predict the labels to new incoming objects. With all the effort in this domain there is still place for impro vement and a great deal of attention is paid to develop highly accurate classiers.
The use of association rule mining for building classi-cation models is very new. Recent studies have proposed the use of association rules in building effecti ve classiers. These classication systems disco ver the strongest associa-tion rules in the dataset (associating attrib ute values to class labels) and use them to build a cate gorizer .
Mining association rules from data is the process of nd-ing interesting relationships or associations that exist be-tween objects in the collection to be mined.

Association rule mining is a data mining task that disco v-ers relationships between items in a transactional database. Association rules have been extensi vely studied in the lit-erature. The efcient disco very of such rules has been a major focus in the data mining research community , given their popularity in mark et bask et analysis. From the original apriori algorithm [1] there have been a remarkable number of variants and impro vements [13 ].
 Formally , association rules are dened as follo ws: Let I = f i 1 ; i 2 ; :::i m g be a set of items. Let D be a set of transactions, where each transaction T is a set of items such that T I . A transaction T is said to contain X , a set of items in I , if X T . An association rule is an implication of the form  X  X ) Y  X , where X I ; Y I , and X \ Y = ; . The rule X ) Y has a support s in the transaction set D if s % of the transactions in D contain X [ Y . In other words, the support of the rule is the probability that X and Y hold together among all the possible presented cases. It is said that the rule X ) Y holds in the transaction set D with condence c if c % of transactions in D that contain X also contain Y . In other words, the condence of the rule is the conditional probability that the consequent Y is true under the condition of the antecedent X . The problem of disco vering all association rules from a set of transactions D consists of generating the rules that have a support and condence greater than given thresholds. These rules are called str ong rules and represent interesting patterns in data.
The rst reference to using association rules as classi-cation rules is credited to [4], while the rst classier us-ing these association rules was CB A introduced in [19 ] and later impro ved in CMAR [18 ], and ARC-A C [2] and ARC-BC [2]. The idea is relati vely simple. Given a training set modelled with transactions where each transaction contains all features of an object in addition to the class label of the object, we can constrain the mining process to generate as-sociation rules that always have as consequent a class label. In other words, the problem consists of nding the subset of strong association rules of the form X ) C where C is a class label and X is a conjunction of features.

The main steps in building an associati ve classier when a training set is given are the follo wing: 1. Modeling the data into transactions. 2. Gener ating the set of association rules from the train-3. Pruning the set of disco ver ed rules: In the pre vious 4. Classication phase: At this level a system that can
We consider that associati ve classiers have two stages where more research is required to fully tak e adv antage of their capabilities. First, the number of rules generated by an associati ve classiers is very lar ge. Better pruning tech-niques have to be studied and devised to select a small set of quality rules. Associati ve classiers have the adv antage over other rule-based classication systems that the y guar -antee to nd all interesting rules (in the support-condence frame work). Ho we ver, more research is required to weed out those rules that are not useful or even detrimental in the classication process. Second, the rule selection and their scoring in the classication process follo ws either some na  X  ve techniques or use predened schemes for scoring a new instance to be classied. Ho we ver, a good selection strate gy is fundamental for good accurac y.

In this paper , we focus our efforts on impro ving the clas-sication phase by automatically learning to use the rules in the model. Ne xt section gives a detailed description of our proposed technique.
This section introduces our two-stage classication ap-proach. Most of the classication techniques work as fol-lows: given a set of examples with cate gories attached, a learning model is developed from a subset of the data (train-ing set); the model created is then tested and validated on the remaining data (testing set).

Once developed, the purpose of a classication system is to classify new instances. In the case of associati ve classi-ers, this step deals with using the rules to cate gorize a new object. The next example will describe a rule-base model. It uses dif ferent classication strate gies.

Example 1. Table 1 sho ws a hypothetical rule-based model that was generated from a given training set using an association rule learning method. Suppose we are given an object O to classify that has features A, B, and C. The subset of rules applicable to O is sho wn in Table 2.
Dif ferent methods can be used to classify new instances when a set of rules apply . These rules have measures at-tached, such as condence in this example. Let us consider now dif ferent approaches for prediction:
The preceding prediction schemes are just simple exam-ples to illustrate that there is not a unique way to combine the indi vidual conclusions of a set of rules to create a nal classication. The actual schemes used by existing systems are as follo ws. CB A [19 ] classies a new object with the class of the highest condence-based rank ed rule. In [18 ], the authors use a weighted chi-square over the rules that apply and chooses the class with the highest score. In our pre vious work [2], we base our prediction on a set of rules by using the average of the condences. We also experi-mented with other measures such as cosine measure, Jac-card coef cient, etc. [22 ]. Some have also experimented with the size of the rule [8]. Bagging [7] and boosting [24] are two ensemble methods that achie ve a better classica-tion performance by combing the conclusion of multiple classiers. These classiers are generated by using the same learning method on dif ferent distrib utions of data. Bagging uses dif ferent replicas of the training set, while boosting uses the same training examples for all the classiers but attaches dif ferent weights to them. The classiers gener -ated are combined by voting to obtain a nal decision. In bagging, all classiers have equal weight in the voting pro-cess. Boosting weighs each classier' s vote by its accurac y on the training set.

All these methods can be thought of as a weighted voting schemes, where the weights for each rule, or class, are de-ned by specic scoring schemes. In this paper we propose to automatically learn the scoring scheme for weighted vot-ing after rst learning the set of rules. Thus we propose a two stage learning process. The rst stage is standard association rule mining. When applied to a given object, this stage produces as output a set of rules that apply to the object (possibly a subset selected from among all the rules that apply), along with each rule' s conclusion and associ-ated measures such as the rule' s condence. The second learning stage consists of a neural netw ork whose inputs are a set of features deri ved from the rst stage output. Given a data collection for classication purposes, we have a training and a testing set. These sets are either gen-erated (cross-v alidation) or are given apriori with the ap-plication to solv e. The associati ve classication methods described before learn a set of classication rules from the training set and then uses them in dif ferent fashions (de-pending on the method emplo yed) to classify the testing set.
Our method to learn to use the generated rules and select the appropriate ones works as follo ws: 1. split the training set into two subsets: trainSta ge1 and 2. use trainSta ge1 to extract the classication rules using 3. for each instance in trainSta ge2 , use ARC Model to 4. apply a neural netw ork learning (or another learning 5. classify the objects in the testing set using ARC Model
As one may see from Example 1, to score and mak e a decision for a new object is a dif cult task. The second learning method in our technique acts as a scoring scheme. The adv antage of using this intermediary step is twofold: it tak es into account more information than using just one or few rules for prediction; treating the scoring scheme as a learning problem we create an automated process to learn it from data (dif ferent scoring schemes are automatically generated for dif ferent applications).

Given that there is a numerical scoring scheme that we have to learn, we chose as the second learning algorithm a neural netw ork. The netw ork consists of a standard 3-layer , feedforw ard neural netw ork whose inputs are the set of features deri ved from the rst stage output. The num-ber of outputs equals the number of classes in the applica-tion, each output neuron corresponding to a class. A logistic function is used to compute the weights inside the netw ork. The output of the function ranges from 0 to 1. When a sin-gle class has to be predicted for an object the output neuron (i.e., class) with the highest value is chosen as the winner . If multiple classes have to be predicted every class abo ve a threshold is considered a winner .

There are two approaches that we developed and tested for our two stage associati ve classication system (2SARC). The y dif fer in the feature space generated and are detailed in the follo wing sections.
Given a classication problem that has n classes to be learned, we use association rules mining to disco ver clas-sication rules. Let us consider that our disco vered model consists of N rules, ordered by their condence and support. Each rule R c . When a new instance is to be classied, a subset of K rules applies R = cable to a new instance if the antecedent of the rule matches the new object and its condence is within the condence mar gin [2]. Naturally , a scoring scheme has to be used in or-der to mak e the classication decision. This scoring scheme has to be a function that represents the strength of the de-cision and it has to tak e into account all applicable rules. The rules are characterized by support, condence and their class. The scoring scheme has to produce a score for all the classes to be considered.

From the set of rules that apply to the new object, M measures m computed for each class c ( m 1 ( c 1 ) ; :::; m M ( c 1 ) ; m 1 ( c 2 ) ; :::m M ( c these measures could be the average condence, number of rules applied and maximum condence. All these aggre gations are done by class. At this stage each class will have several measures associated. All these measures will be the input to the second learning method, which is a neural netw ork in our case.
 Considering Example 1, the features collected for object O are average condence and number of rules by class as sho wn in Table 3. For each class a set of features is gen-erated (e.g., Class1: average condence is 85%, # rules supporting this class is 1). These class-based features are generated for the objects in the trainStage2 set. Along with the class label these features represent now the input to the second learning stage.
In our pre vious approach, we collected aggre gated mea-sures per class. These measures represented a new feature space. From this space a scoring scheme is learned.
In our second approach we learn how to use the rules in the model instead of learning how to use the measures. The feature space in this case is represented by the rules. Given our rule-based ARC model, we input into the second learning method the characteristics of the rules in the ARC model. For each new object, a rule either applies or not. We introduce this information along with the rule' s condence into the model for the second stage.

For the example in Table 1, given object O, we can gen-erate a set of rule-based features as presented in Table 4. The second learning algorithm has to learn how to use the rules given these type of features.

Generally , association-based models generate a lar ge number of rules, thus creating for 2SARC2 a very lar ge feature space. To reduce the dimension of the feature set we experimented with choosing only k best rules per class (e.g., k=2 for our example, R1, R3 for Class 1; R2 and R5 for Class 2; R8 and R9 for Class 3).

Although the architecture of our proposed system may seem similar to stacking [26 ] the y dif fer as follo ws. In stacking level one is represented by one or more classica-tion methods. Their classication results represent the input space for the second level classier . In our approaches, the rst level is a rule-based method that disco vers classica-tion rules. The input to the next level are features generated using the model built in the rst level. This feature layer is what distinguishes our techniques from stacking.
First, we evaluated our method against other associati ve classiers and rule-based classication methods on 20 UCI datasets [5]. Second, we studied the performance of our system in the text classication conte xt. This type of ap-plication is more challenging given that the feature space is very lar ge and it requires multi-label classication (i.e., one or more class labels are attached to each object to be classi-ed). UCI datasets are single-label classication problems.
We evaluated our algorithm against other associati ve classiers (see Section 2.2) on several UCI datasets [5]. In addition we compare our method with two rule-based classication methods (C4.5 rules [21 ] and RIPPER [9]), a boosting algorithm [24] and a hybrid between rule-based methods and associati ve classiers (CP AR) [28 ].
Rule-based classication approaches have been devel-oped for decades in the machine learning community due to their readability when compared to other classiers. These algorithms use greedy techniques in the rule generation pro-cess. C4.5 searches the space for the best attrib ute accord-ing to the heuristic used, divides the search space according to the values of the attrib ute and then continues the process recursi vely in those subspaces. Rules are generated follo w-ing the paths that cover the feature space. RIPPER (Re-peated Incremental Pruning to Produce Error Reduction) [9] is built upon IREP (Incremental Reduced Error Pruning) al-gorithm [12 ]. Follo wing IREP' s strate gy, RIPPER splits the training set in two sets. One of them is used to gro w the rules and the other to prune the rules. The algorithm starts with an empty rule and it repeatedly adds conditions that maximize the information gain criterion. Once the rule is gro wn, conditions are deleted to maximize a function dur -ing pruning phase. When a rule has been disco vered, all the examples that are covered by this rule are remo ved from the training set. The abo ve process continues to learn rules for the remaining training set.

CP AR [28 ] (Classication based on Predicti ve Associa-tion Rules) is a hybrid between associati ve classiers and rule-based classiers that use greedy techniques. It uses a greedy algorithm to search the space of attrib utes.The main dif ference is that it keeps all close-to-the-best attrib utes in rule generation, unlik e rule-based methods which use only the best attrib ute.

On each UCI dataset we performed C4.5' s shuf e util-ity [21 ]. A 10-fold cross validation was performed on each dataset and the reported results are averages of the accura-cies over the 10 folds. In addition, we used the same dis-cretization method for continuous attrib utes as in [19 ] to have a fair comparison with the other algorithms.
All classication methods should be evaluated on the same randomly generated folds to ensure a fair comparison of the methods. As the code for CP AR has the cross vali-dation incorporated and it does not allo w one to specify the folds we could not guarantee that CP AR was evaluated on the same folds as the other algorithms. CMAR code is not available. Thus the results presented in our table are the best results for CP AR and CMAR as reported by their authors. All the other results were obtained in our study . For CB A we used the code pro vided by their authors, while for the other algorithms (C4.5, RIPPER, boosted RIPPER) we used their Weka [25 ] implementations (W eka version 3.4.8). The parameters for all the algorithms were set to their def ault values. Weka' s def ault settings follo w the best parameter setup as proposed by their respecti ve authors [9, 21].
It is well-kno wn that the support threshold plays a funda-mental role in association rule disco very . Since associati ve classiers are based on association rule mining the y inher -ited the sensiti vity to the support threshold. It is hard to kno w apriori the best support threshold and its value is usu-ally set experimentally . In our evaluation, we ran our al-gorithms with support values of 1%, 5% and 10% for each dataset and we reported the best result. The minimum con-dence was set to 50% and the condence mar gin was set at 10%. Our proposed technique used a split ratio of 50/50 or 75/25 between trainStage1 and trainStage2 sets. 2SARC2 technique used 10, 20 or 30 rules per class. The algorithm used for the second stage was a backpropag ation algorithm with 1 hidden layer . For the backpropag ation algorithm we used Bor gelt' s implementation [6]. The number of neurons in the hidden layer was the average number between the in-put and output neurons.
 Table 5 presents the accurac y of the follo wing methods: C4.5, RIPPER, boosted RIPPER, CB A, CMAR, CP AR, ARC and the results for the two techniques proposed in this paper (2SARC1 and 2SARC2). Along with the accurac y result, the name of the dataset, the number of records in the datasets and the number of classes are given. The standard deviation is not reported as our statistical analysis uses non-parametric tests. 2SARC1 obtains best overall performance for 5 datasets, follo wed by CMAR (4 datasets) and C4.5 and boosting (3 datasets each). 2SARC2 performs best on 2 datasets. Rip-per and CB A are the algorithms that do not have any overall win. On some datasets the dif ferences in accurac y between the winner and the second best are quite small (e.g., aus-tra), while for other the impro vement in the performance is lar ge (e.g., hepati, heart). Some datasets are very small (e.g., labor , zoo), which unf avours our algorithms given that we need enough examples for the two learning stages. 2SARC1 has the best overall performance, as it can be see fromT able 5. Table 6 sho ws the count of wins, losses and ties for 2SARC1 when compared to the rest of the meth-
Tab le 6. Method 2SARC1 compared to the rest of the algorithms on UCI datasets; (*) in-dicates statistical signicant diff erence ods. If we consider the win to loss ratio, the algorithm second in performance to 2SARC1 is CP AR, follo wed by boostingR and 2SARC2. 4.1.1 Statistical Analysis The results presented in Table 5 give some insight in the performance of the algorithms. Ho we ver, those results do not pro vide enough support for dra wing a strong conclusion in favour or against any of the studied methods. There is no overall dominance over the entire range of datasets.
To better understand the results of our techniques when compared to the other classication approaches we per -formed a statistical analysis of our results. In our experi-mental study we collected classication results for 9 classi-cation methods on 20 datasets. In this type of experimental design a careful consideration has to be given to choosing the appropriate statistical tools. When a lar ge number of comparisons is made (i.e., 180 in our design) the lik elihood of nding signicance by accident increases. The signi-cance level has to be controlled such that it accounts for the multiple comparisons. This issue is kno wn in statistics as controlling the family-wise error .

Demsar discusses in [11 ] the issue of multiple hypothe-sis testing and recommends the use of several statistical pro-cedures for this problem. Follo wing Demsar' s recommen-dation, we rst tested if there is any signicant dif ference among the classication methods studied. Demsar recom-mends the use of Friedman test to compare several classi-ers on multiple datasets.
 Let us assume that we have k algorithms to compare on N datasets. The Friedman test can be applied as follo ws:
By applying Friedman test [11] we concluded that there is a signicant dif ference among the methods. Since the null hypothesis is rejected we have to proceed with further analysis to better understand the beha viour of the classica-tion algorithms. We are interested in the performance of our proposed technique. Thus, we perform a series of Wilcoxon signed rank ed tests between our best method (2SARC1) and the other classication methods. Friedman test and Wilcoxon tests are non-parametric tests, the y do not mak e any assumptions about the distrib utions of the values.
For single-label classication results Friedman test nds signicant dif ference among the classication methods studied. The only strong conclusion that we can dra w when paired Wilcoxon signed rank ed tests are performed is that 2SARC1 performs signicantly better than C4.5 and Rip-per . The mixture of wins and losses when compared to the other algorithms (see Table 6) mak es it impossible to single out one of the algorithms as the best one.
Associati ve classiers are more suitable for cate gorical data, rather than numerical. Therefore, text classication is a good application to study the performance of our method.
Most of the research in text cate gorization comes from the machine learning and information retrie val communi-ties. Rocchio' s algorithm [15] is the classical method in in-formation retrie val, being used in routing and ltering docu-ments. Researchers tackled the text cate gorization problem in man y ways. Classiers based on probabilistic models have been proposed starting with the rst presented in liter -ature by Maron [20 ] and continuing with na  X  ve-Bayes [17] that pro ved to perform well. ID3 and C4.5 are well-kno wn packages whose cores are making use of decision trees to build automatic classiers [10 ]. K-nearest neighbor (k-NN) is another technique used successfully in text cate goriza-tion [27 ]. Another method to construct a text cate goriza-tion system is by an inducti ve rule learning method. This type of classiers is represented by a set of rules in disjunc-tive normal form that best cover the training set [3]. In the last decade neural netw orks and support vector machines (SVM) were used in text cate gorization and the y pro ved to be powerful tools [16].

We used the ModApte version of Reuters-21578 text col-lection [23] as benchmark. This split leads to a corpus of 12,202 documents consisting of 9,603 training documents and 3,299 testing documents, and is the most used split in the literature. We tested our classiers on the ten most pop-ulated cate gories with the lar gest number of documents as-signed to them in the training set. On these documents we performed stopw ord elimination but no stemming.
 For evaluating the effecti veness of our system we used F1 measure and precision/recall break even point [2]. To report the performance over multiple classes we used micro-average and weighted average.

In our experiments, we ran our algorithms with support values of 10%, 15% and 20% and we reported the best re-sult. The minimum condence was set to 50% and the con-dence mar gin was set at 10%. Our proposed technique used a split ratio of 80/20 between trainStage 1 and train-Stage2 sets. 2SARC2 technique used 10, 25, 50 or 100 rules per class. The algorithm used for the second stage was a backpropag ation algorithm with 1 hidden layer . The num-ber of neurons in the hidden layer was the average number between the input and output neurons.

Table 7 sho ws the performance for several well-kno wn text cate gorizers and our algorithms. The evaluation is done using precision/recall break-e ven point. Results are pre-sented by cate gory for the ten most populous cate gories in Reuters collection. Except for our algorithms, the re-sults are presented as reported in [16 ]. Given that the micro-a verage value for the other algorithms was computed on a dif ferent set of classes we used a weighted average scheme to approximate the micro-a verage. The formula for weighted average is: where N stands for the number of classes and test resents the number of test examples in class j .

SVM performs best for 6 out of 10 classes in the Reuters collection. 2SARC1 wins in 3 classes, while 2SARC2 gets the best break even point for trade class. SVM ranks rst based on weighted-a verage and macro-a verage, follo wed closely by 2SARC1. Corn and wheat are two cate gories that are dif cult to be learned by most classiers due to their unique characteristics in this collection; both of them highly overlap with grain cate gory . Winning overall in this cat-egories is a good indication for our algorithm that the new automated scoring is able to pick up data characteristics that would have been missed by a static scoring scheme.
Table 8 sho ws the count of wins, losses and ties over the 10 classes in Reuters for 2SARC1 when compared to the other algorithms. 2SARC1 losses on 6 cate gories to SVM. 2SARC1 outperforms the rest of the algorithms winning in at least 7 out of the 10 classes. 4.2.1 Statistical Analysis We performed the same statistical analysis as discussed in Section 4.1.1 to the text classication results. Friedman' s test indicates that the methods evaluated are not equal. When the Wilcoxon tests are applied to the results of text classication for pairwise comparisons between 2SARC1
Tab le 8. Method 2SARC1 compared to the rest of the algorithms on Reuter s collection; (*) indicates statistical signicant diff erence and the rest of the algorithms, we can conclude the follo w-ing: 2SARC1 is signicantly better than Bayes, Rocchio, C4.5, ARC at a signicance level of 0.05. When compared with SVM, the test can not reject the null hypothesis, thus it can be stated that 2SARC1 and SVM perform statistically similar on the Reuters dataset.
Rule-based classication systems classify a new instance based on a set of rules that apply to this new object. In pre vious works, the scoring schemes under which the sys-tem tak es a classication decision are predened. In this paper we proposed a two-stage classication method. Our system (2SARC) learns automatically the scoring scheme in the second stage. In addition, we investig ate two tech-niques. 2SARC1 learns the scoring scheme from class fea-tures while 2SARC2 learns it from rule features.

The proposed system is versatile, it sho ws good perfor -mance over a lar ge and dif ferent set of applications. We tested our method for single-label and multiple-label clas-sication, using both small and lar ge datasets. In addition, association rule mining is a mature domain with fast algo-rithms that can handle lar ge dimensionality , thus making the classication rule disco very fast and reliable. 2SARC1 performs best on most UCI datasets or it ranks very close to the best as Table 5 sho ws. There are only 3 datasets where the performance is much lower than the best ( labor , waveform , zoo ). Labor and zoo are very small datasets with 57 and, respecti vely , 101 examples. Small datasets may hinder the performance of our system given that it needs enough examples to train the models for the two stages. Waveform is a dataset where all the initial at-trib utes are numerical. Association rules are more suitable for nominal attrib utes, thus for this particular dataset the mining has to rely on the discretization process. The in-uence of the discretization process on the performance of association-rule based systems needs further study .
On Reuters dataset 2SARC1 has good overall perfor -mance, and excellent results for three cate gories ( corn , wheat and mone y-fx ). Corn and wheat are two cate gories that are highly overlapped with grain . The y are hard to learn by other classiers (including the state of the art SVM) due to this characteristic. On top of the overlapping property the y are also two small classes, thus adding the imbalance issue to the classication process. By automatically learn-ing the scoring scheme our system can pick up on existing relations between classes that a pre-dened scoring scheme would miss (especially if the y solv ed the multi-label prob-lem as binary subtasks).

Our method has two stages, each stage emplo ying a clas-sication algorithm. It may appear that the training time is higher than for each algorithm applied alone or for other algorithms. This is not necessarily the case, as each stage uses only a partition of the data. 2SARC2 sho ws lower performance than 2SARC1. This may be due to the limit that we enforce on the number of rules to be used as features. This constraint is used in the second stage as neural netw orks do not handle a lar ge number of inputs well. A direction to be investig ated fur -ther is the use of other classication methods in the second stage that would handle better the lar ge dimensionality . In-corporating all the rules disco vered could be of benet to 2SARC2 as seen for the iris dataset where 2SARC2 per -forms best. The set of rules is very small for this dataset thus making possible the use of all rules in the second stage.
Rule-based classiers use predened weighted voting schemes to combine the class predictions of the applicable rules. By contrast, the methods described in this paper au-tomatically learn the scoring scheme. We achie ve this by developing a two-stage system, with a layer of feature def-initions interposed between the output of the rst learning model and the input of the second. Our two stage classi-cation with class-based features (2SARC1) sho ws a good performance both for UCI datasets and text classication, under rigorous statistical analysis. The most accurate text classier , particularly when multi-label classication is in-volv ed, is by far SVM. Our two stage associati ve classier 2SARC1 is the rst to equal its performance on the com-monly used and challenging Reuters testset.

