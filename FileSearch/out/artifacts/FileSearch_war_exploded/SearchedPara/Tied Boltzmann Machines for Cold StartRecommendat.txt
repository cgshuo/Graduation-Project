 We describe a novel statistical model, the tied Boltzmann machine, for combining collaborative and content informa-tion for recommendations. In our model, pairwise interac-tions between items are captured through a Boltzmann ma-chine, whose parameters are constrained according to the content associated with the items. This allows the model to use content information to recommend items that are not seen during training. We describe a tractable algorithm for training the model, and give experimental results evaluat-ing the model in two cold start recommendation tasks on the MovieLens data set.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  information filtering ; G.3 [ Probability and Statistics ]: correlation and regression analysis ; I.2.6 [ Artificial Intelligence ]: Learning X  parameter learning Algorithms, Performance recommender systems, collaborative filtering, content-ba sed filtering, cold start, Boltzmann machines
Recommender systems attempt to suggest items of inter-est to users based on information including their own pre-vious usage patterns, the usage patterns of other users, and features of the items themselves [10]. Collaborative filter ing techniques provide recommendations by using the prefer-ences of other users that have historically had similar pref er-ences to the target user [2, 9, 15]. These preferences may be expressed either explicitly (e.g. by rating movies at an onl ine movie rental service) or implicitly (e.g. by browsing an ite m description or buying an item at an online retailer). For example, the familiar Amazon item-to-item recommender system [9] recommends items that were bought significantly more often by users buying a given item to a target user buying that given item. Such systems have the drawback that they suffer from the item cold start problem X  X n item cannot be recommended until it has been rated by a number of existing users.

This problem can be alleviated by using information about the content of items. This information can be quite broad, ranging from words in a document to metadata such as ac-tors of movies. While many content-based techniques, as well as hybrid techniques that use both collaborative infor -mation and content information exist [10], we use the col-laborative information to learn to predict preferences fro m content information. The work of [18] is a step in this direc-tion, where user ratings and content information are used to learn user preferences for content. The content informatio n of a new item is then used to predict the users X  votes for that item. We present a novel hybrid approach that does this in an arguably more direct manner. The collaborative data is used to learn how well different content information predict s user ratings of items. We treat ratings of items by users as binary random variables indexed by users and items, and explicitly model correlations between these binary random variables using a Boltzmann machine. In order to alleviate the cold-start problem, we tie the parameters of this Boltz-mann machine through constraints in terms of the content information associated with the items.

The remainder of the paper is organized as follows. Sec-tion 2 discusses some related work. Section 3 describes the details of our model. We present the use of Boltzmann machines for modeling pairwise correlations of item rating s in section 3.1, followed by our content information-based parameter-tying scheme in section 3.2. In section 3.3 we present the use of a regularized pseudo-likelihood criteri on for tractable parameter estimation, along with a stratified sampling technique for further computational gains. Sec-tion 4 describes the benchmarking of our model against an aspect model based recommender system on two movie rec-ommendation tasks. We conclude with some discussion in section 5.
In contrast to previous work such as [18], we treat rat-ings of items by users as binary random variables indexed by users and items, rather than as a contingency table to be modeled through a joint distribution over user-item pairs. This distinction in probabilistic approaches to content-b ased recommendation systems is discussed in [12]. The approach in [18] extends the work of [7] which models the joint dis-tribution of users and items through an aspect model that clusters users and items in a latent space. In order to deal with cold start items, the approach of [18] models the joint distribution of users and content features instead of the jo int distribution of users and items. Then, a  X  X olding-in X  tech-nique [6] is used to embed items into the latent space so that items rather than content features can be recommended. However, this approach can only yield a conditional distri-bution over users given an item, rather than the desired join t distribution over items and users. Our approach avoids this difficulty by modeling the joint distribution of ratings of al l items by all users in terms of the content of the items. Since the model predicts preferences of items directly, we can avo id the difficulties associated with  X  X olding-in. X 
We also contrast our approach to the superficially similar literature on the use of restricted Boltzmann machines for collaborative filtering [14]. Tied Boltzmann machines are fully connected, and have weights constrained through the use of content information. In contrast, restricted Boltz-mann machines are constrained to have a bipartite topol-ogy, but the weights on legal links are unconstrained. Fur-thermore, restricted Boltzmann machines do not make use of content information, and as such, are vulnerable to cold start problems.

There has been some recent work on using filter-bots [4] for improving cold start recommendations [11]. This work attempts to use bots implementing various heuristics, some based on content information, to generate synthetic data for training recommender systems on. However [11] reports that the use of content based bots did not improve perfor-mance. Our approach uses data to learn how content data can be used to predict vote correlation, rather than using such heuristics.

Finally, we note that tied Boltzmann machines can also be viewed as dependency networks [5] where the conditional probabilities are logistic regressions instead of regress ion trees, and where the parameters are tied across nodes. It is this parameter tying that allows generalization to unseen items .
We treat the problem of generating recommendations as one of predicting a user X  X  vote on an item given his votes on other items as well as the votes of other users. In the case of implicit ratings, an action such as buying an item is taken to be an implicit vote for that item, and the problem is to predict what other items a user might act on in the future. In the case of explicit ratings, the user explicitly rates some subset of items, and the problem is to predict the user X  X  ratings of other items.

We denote the vote for an item i  X  1 ,  X  X  X  , N by a user u  X  1 ,  X  X  X  , M by v ( u ) i . In the case of implicit ratings v when user u has acted on item i , and is 0 otherwise. In the case of explicit ratings , v ( u ) i takes on a value given by their rating. In this paper, we will assume that votes are binary. Non-binary ratings can still be handled by binarizing as don e in [18] X  X .g. v ( u ) i = 1 if user u rates item i 4 or higher. We denote a user u  X  X  votes for all N items by a vector v ( u ) key challenge is to model the interactions between the votes v Figure 1: Example Boltzmann machine for three movies. The ovals represent a user X  X  votes on each of the movies. The solid squares represent the weights of the Boltzmann machine, which capture the pop-ularity of each movie and how correlated a user X  X  votes on each movie are.
Boltzmann machines are a simple model for modeling in-teractions between variables. We assume that users X  vote vectors are i.i.d., with the joint distribution of a user X  X  v ote vector v modeled using a Boltzmann machine: Here, we use  X  to denote the collection of all  X  i and  X  ij use P i&lt;j to denote the sum over unordered pairs ( i, j ). Note that the per-item weights  X  i are distinct from the per-item-pair weights  X  ij . Since  X  ij is only defined for i &lt; j , we abuse notation somewhat and use  X  ij and  X  ji interchangeably to denote the weight associated with the unordered pair ( i, j ) without introducing any ambiguity. The partition function z (  X  ) is chosen to ensure that p ( v ) is properly normalized over all configurations of the vote vector v . We note that the pairwise weights  X  ij capture pairwise collaborative effects X  X  high value of  X  ij indicates that users with v i = 1 also tend to have v j = 1. The per-item weights  X  i capture popularity effects X  X  high value of  X  i indicates a higher likelihood of v = 1 irrespective of the user X  X  other votes.

Figure 1 shows an example of a Boltzmann machine for three movies, The Circus , City Lights , and White Fang . The and v White Fang , which are a randomly chosen user X  X  votes for  X 
White Fang capture the popularity of these movies X  X .e. the likelihood that the user would vote for these movies, inde-pendently of what else they voted for. The pair-wise weights  X  White Fang capture how likely the user X  X  votes for these pairs of votes are to be correlated.

Note that the partition function z (  X  ) is expensive to com-pute. It requires summing over all configurations of the vote vector. However, the conditional probability of a user X  X  vo te on a single item given his votes on all other items is easy to compute, and is given by
This is natural in the case of implicit votes, where a value of v j is always available for every item X  X ither a user acted on an item or he didn X  X . In the case of explicit ratings, we typically observe the user X  X  ratings for only a small set O of items, and do not have ratings for the other items (i.e. O
C ). In this case, the conditional probability of v i given the observed votes v O is given by Note that j and k range over all items, including i , all other items in O C (i.e. all other items with unknown votes), and all the items in O . This probability is expensive to compute, because it involves a summation over all configurations of th e unobserved votes. This difficulty can be averted by explicitl y modeling unobserved votes in the values of v i . For example, if v i = 1 encodes a positive (e.g. 4-star or higher) rating for item i , and v i = 0 encodes the lack of a positive rating (i.e. no rating or a negative rating), equation (1) remains valid for explicit ratings.
One weakness of the model discussed in section 3.1 is that reliable estimation of the model parameters  X  , in particu-lar the pairwise weights  X  ij , requires sufficient observations. This is because the number of weights to be estimated scales quadratically with the number of items we need to be able to model correlations between. Since real data tends to be sparse, with many items having low probability of oc-currence, these weights are difficult to estimate in practice . Thus, the Boltzmann machine model described above is not directly applicable to real large-scale applications. In p artic-ular, if an item is not seen during training, we have the item cold start problem, where none of the weights associated with that item can be reliably estimated.

We use parameter tying to alleviate these difficulties. In order to retain the ability to model the interactions betwee n items, we use content information to guide the parameter tying. We assume that the content associated with item i is represented by a feature vector f ( i )  X  R D composed of D components. For example, features could be counts or TF-IDF weights of words in documents, or binary flags indicating whether specific actors appeared in a movie. Fea-tures with different semantics could be combined in a single vector. For example, some feature components could corre-spond to actors in a movie, while others could correspond to genres, while still others could take on numerical values such as movie length in minutes. We constrain  X  to satisfy where  X   X  R D and  X   X  R D  X  D is symmetric. In this paper, we will only consider diagonal  X  , although none of our the-oretical results depend on this simplification. In effect, th is reparametrizes the model through the content,  X  and  X  : p ( v ;  X ,  X  ) = 1 Figure 2: The example of Figure 1, showing how the movies are connected through content. The rectan-gles represent actors, and the links between actors and movies indicate that the actor appears in the movie. where  X  k denotes the k th diagonal component of  X  and z (  X ,  X  ) = z (  X  (  X ,  X  )).

Figure 2 shows the content associated with the movies considered in the example of Figure 1. In this example, the content information consists of actors appearing in the movies, and the feature vectors have a component for each actor, which is 1 when the actor appears in the movie and 0 otherwise. The fact that Charlie Chaplin appears in City Lights affects its popularity while the fact that Steve Mur-phy appears in White Fang affects its popularity. Our model assumes that the popularity weights of the movies are the sums of the effects of the actors appearing in them. Thus, the popularity weight  X  The Circus is the sum of the popularity effect  X  Charlie Chaplin of Charlie Chaplin and the popularity effect  X  Steve Murphy of Steve Murphy. However, the model makes no assumption about the relative magnitude of the ef-fects that each actor can have. Thus,  X  Charlie Chaplin may be higher than  X  Steve Murphy if movies including Charlie Chap-lin happen to be more popular than movies including Steve Murphy. Similarly, the fact that Charlie Chaplin appears in both The Circus and City Lights may cause the votes for these movies to be correlated while the appearance of Steve Murphy in both The Circus and White Fang may cause the votes for those movies to be correlated. While the model as-sumes that the correlation weight of two movies is the sum of the correlation effects of the actors they have in common, it makes no assumption about the magnitude of these ef-fects. If people who like Charlie Chaplin movies tend to like other Charlie Chaplin movies more than people who tend to like Steve Murphy movies tend to like other Steve Murphy
The conditional probability of v i given all other votes v is given by p ( v i | v  X  i ;  X ,  X  ) =
We note that instead of constraining  X  to be a determin-istic function of the content feature vectors f and the pa-rameters  X  and  X  , we could have specified a distribution on  X  , to yield a Bayesian model. However, we restrict attention to the more simple case of deterministic constraints on  X  in this paper.

Generating recommendations for a user from this model once it is trained is simple. Equation (3) is used to compute the probability of v i = 1 for an item i not yet seen by a user. This is the likelihood that the user would vote for item i . Ranking all items not yet seen by this probability gives a ranked list of recommendations. Thus, the remaining difficulty is in training the model.
We assume that we have a training set consisting of votes v i for all N items i  X  1 ,  X  X  X  , N by all M users u  X  1 ,  X  X  X  , M . We also assume that the feature vectors f ( i ) are available for all items. We assume that missing votes are encoded by v = 0 as discussed above. The log likelihood of the training set is given by  X  log ` z (  X ,  X  )  X  + X This likelihood is hard to optimize because it requires the evaluation of the partition function z (  X ,  X  ) for all candidate parameters.

Because of this, we approximate the log likelihood of the training set by its log pseudo-likelihood [1]: As discussed above, the conditional likelihood p ( v i | v easily computed using equation (3). If we treat each user u  X  X  vote for each item i as an independent training event given that user X  X  other votes, the pseudo-likelihood can be interpreted as the conditional likelihood of the training s et under a conditional model given by equation (3). In fact, equation (3) can be interpreted as the output probability of a logistic regression on v i with inputs given by f ( i ) P of the tied Boltzmann machine model is equivalent to train-ing a set of logistic regression classifiers with a very parti c-ular input parametrization and parameter tying scheme to predict individual votes. By the same argument, we note that the pseudo-likelihood is convex in the parameters, and therefore easily optimized via gradient methods.

In order to get robust estimates, we train the parameters  X ,  X  by maximizing the regularized pseudo-likelihood
L (  X ,  X  ) = X This can be viewed as MAP estimation of the set of tied logistic regressions mentioned above under a Gaussian prio r [3].

The regularized pseudo-likelihood is alo convex in the pa-rameters, and can easily be optimized using gradient meth-ods. The gradients used can be computed according to:  X   X  X  k L (  X ,  X  ) = and
With large data sets, optimizing the training criterion of equation (4) may be too expensive since it requires com-puting a conditional likelihood for each of M  X  N user-item pairs, where M and N may both be large. Since the set of items for which v ( u ) i = 1 is sparse, a further speedup is possible. Denote this sparse set of positive training items by I ( u ) + and its complement by I ( u )  X  . Sample items from I with probability  X  to yield a sampled set of negative items I  X  (  X  ). Choose  X  so that the total number of sampled nega-positive items P u | I ( u ) + | . The regularized pseudo-likelihood of equation (4) is then approximated by
L (  X ,  X  )  X  X Now, evaluating the training criterion only requires compu t-ing the conditional likelihood for O ( V ) items, where V is the number of votes observed. Of course, the speedup depends on how sparse votes are, and the loss in accuracy is data dependent.

The gradients then become  X  X  k L (  X ,  X  )  X  and  X  X  k L (  X ,  X  )  X  + 1
We evaluate our model on two movie recommender tasks, and compare performance with that of the aspect models described in [18]. In this case, the feature vectors will be a s described for the examples in Figures 1 and 2 X  X e will have a feature component for each actor, which will be 1 if the actor plays a headlining role in the movie and 0 otherwise.
We use the 1,000,000 rating MovieLens data set for all ex-periments (see www.movielens.org). This data set contains 1,000,209 ratings of 3706 movies by 6040 users. A rating consists of an assignment of one to five stars to a movie. Not all movies are rated by all users. The MovieLens movie description pages were crawled to obtain the headlining ac-tors of each of these movies. This yielded 8406 actors.
We randomly divided the movies into 2962 training movies and 744 test movies, thereby simulating a cold start situa-tion. We randomly selected 500 users to evaluate recom-mendations on, yielding a test set of 372,000 possible rec-ommendations. We evaluate using two tasks on this data set. The first is to predict which of the test movies a user rated given the set of training movies he rated. There were 16,717 ratings in the test set. The second is to predict which of the test movies a user rated four stars or higher given the training movies he rated four stars or higher. There were 9592 ratings of four stars or higher in the test set. Thus, the first task is an implicit rating one and the second is an explicit rating one. In the terminology of [18], the first is a  X  X eak occurrence prediction X  task while the second is a  X  X ating prediction X  task.

We measure performance on these tasks using global ROC (GROC) and customer ROC (CROC) curves as described in [18]. The GROC is an ROC curve that measures perfor-mance when the system is allowed to recommend a different number of items (even no items) to some users. The CROC is a modified ROC curve that measures performance when the system is forced to make the same number of recommen-dations to each user. We recall that ROC curves plot the sensitivity vs. (1  X  specificity) of a statistical test. While sensitivity is equivalent to the recall measure used in in-formation retrieval, specificity differs from precision in t hat it measures the proportion of negative examples correctly identified (i.e., 1  X  false positive rate) in contrast to precision which measures the proportion of examples labeled as posi-tive that are correctly labeled. Thus, the GROC and CROC curves are subtly different measures than the precision-rec all curves that are used in information retrieval problems. In addition to the areas under the curves (AUCs), [18] notes that it is important to focus attention on the left-hand por-tion of the GROC and CROC curves which corresponds to the low false positive region of operation.

We note that our evaluation differs from that of [18] in the following three ways. First, we evaluate on the full 1,000,0 00 rating MovieLens data set instead of the 100,000 rating MovieLens data set. Second, we use staring actors from MovieLens movie description pages instead of first billed ac -tors from the Internet Movie Database (IMDB) for content information. MovieLens typically lists fewer staring acto rs per movie that IMDB lists as first billed actors. Since we use less content information, ours is arguably a more stringent evaluation. Third, we evaluate on a  X  X ating prediction X  tas k where the goal is to predict the rating a user would give a movie rather than a  X  X ating imputation X  task where the goal is to predict the rating a user gave a movie given that they saw it . Rating imputation is arguably less useful in recom-mender systems X  X he user gets little utility from a predicti on of his rating after he has already watched the movie. How-ever, we note that solutions of both the  X  X eak occurrence prediction X  and  X  X ating prediction X  tasks necessarily giv e a solution to the  X  X ating imputation X  task as well.
We use the user-actor aspect model described in [18] as our baseline. While more complicated models are discussed in [17] we used the user-actor model since the more compli-cated approaches were not reported to significantly improve performance. We now outline the approach of [18].
The user-actor aspect model fits a joint distribution of the form to a user-actor contingency table. The aspect model is trained using the tempered EM algorithm [6]. Given a novel movie i , it is  X  X olded in X  to the latent space through the fol-lowing EM algorithm: E-Step: M-Step: where n ( a, i ) is the number of times actor a appears in movie i , to yield p ( z | i ). This enables the computation of Items i are ranked according to p ( u | i ) in order to recommend items to user u . We used the PennAspect implementation for our experiments [16]. Runtime was on the order of hours on a 3 GHZ Xeon workstation with 16GB of memory.
In order to train tied Boltzmann machines for these tasks, we represent the movie content using vectors of actors. In other words, we set the dimensionality D of the content feature vectors to the total number of actors, and identify each dimension of the feature vectors with an actor. Then, we have Thus, our model has parameters  X  k that model the popu-larity of movies starring actor k and parameter  X  k modeling the co-occurrence of movies starring actor k . While com-ponents of the feature vectors f ( i ) given here correspond to the same kind of content, this is not necessary in general. Because we train the model conditionally, it is easy to com-bine content features of different kinds in the same vector [8]. For example, we could have components corresponding to actors, directors, writers, and genres.
We train our model using the RPROP [13] algorithm to optimize the regularized sampled pseudo-likelihood train ing criterion of equation (5). This is a non-linear gradient tec h-nique that maintains an adaptive step size for each dimen-sion. The step size during optimization was initialized to 1 /D , the inverse dimensionality of the feature vector, the step growth and shrinkage parameters of the RPROP algo-rithm were set to 1 . 2 and 0 . 5, while backtracking was en-abled. The algorithm was run for at most 100 iterations. The regularization parameter  X  was set to 1000, but we ob-served that the results were not very sensitive to this value .
The sampling parameter  X  was set to 0 . 05 for the  X  X eak occurrence prediction X  task and to 0 . 03 for the  X  X ating pre-diction X  task to balance the number of positive and nega-tive examples in the training set. The sampling reduces the number of training examples considered, and therefore the training time, by a factor of about 100 for these data sets. Actual runtime was a few minutes on a 3 GHZ Xeon work-station with 16GB of memory. While formal evaluation of the resulting accuracy loss is left for future work, increas ing  X  by a factor of four, thus increasing training complexity by a factor of four, resulted in no change in the CROC and GROC curves. This strongly suggests that sampled training results in little accuracy loss.
Figure 3 shows GROC and CROC curves comparing the tied Boltzmann machine model to the user-actor aspect model on the implicit rating prediction problem. The AUCs for the curves are also indicated in the figure. While the ideal GROC curve would follow the left and upper boundaries of the plot, having AUC 1.0, the ideal CROC curve is on the in-terior of the plot, having AUC less than 1.0. This is because not all the users rate the same number of items, while the CROC evaluation forces the system to recommend the same number of items to each user. For this reason, we also show the CROC curve of an ideal recommender to give an upper bound on performance. The GROC and CROC curves for random recommendations with AUC 0.5 are also shown.
The tied Boltzmann machine outperforms the aspect model in terms of area under the GROC and CROC curves, as well as in terms of the GROC and CROC performance in the low false positive region. The difference is particularly strik ing in the case of the CROC curves. Figure 4 repeats the anal-ysis for the explicit rating prediction problem. Once again , the tied Boltzmann machine outperforms the aspect model, particularly in the case of the CROC curves. Although we did not perform a formal statistical significance test, we no te that out test sets contained 372,000 test cases of which on the order of 1000 were positive for each task.

The aspect models tended to over-train on our sparse data set, as remarked upon in [18]. We found that when the an-nealing weight (inverse temperature) was reduced enough to prevent over-training, the resulting models did not dis-criminate between the latent classes. That is, at this point , the models were effectively using a single latent class. We verified this by training the model with various numbers of latent classes, including a single class. These models were identical in terms of performance. Since the aspect mod-els rank recommendations by the probability of users given movies, the resulting degenerate models recommend all the movies to each user in turn, ordering users in terms of their weight in the training set.
We have shown that tied Boltzmann machines are ef-fective at generating cold start recommendations, even on sparse data sets. We conjecture that the superior perfor-mance of tied Boltzmann machine over aspect models in the tasks we have presented can be attributed to two fac-tors. First, tied Boltzmann machines have a relatively par-simonious parametrization that is easily regularized to co m-bat over-training. Second, tied Boltzmann machines pro-vide conditional distributions over ratings. In contrast, the folding-in procedure for new items means that content-user aspect models only provide a distribution over users, when what is desired is a distribution over items.

We also propose three directions for extending the ideas present in this paper. First, as mentioned briefly in sec-tion 4.2, tied Boltzmann machines provide a simple frame-work for combining different kinds of content information. In addition, given a recommendation, a sensitivity analy-sis of the conditional probability of the recommended item with respect to the different content features f ( i ) k can be used to determine which content information was most responsi-ble for producing the recommendation. This could be used in explaining the reasons behind the system X  X  recommen-dations to users, making the system interpretable. Second, since Boltzmann machines can model pairwise collaborative effects directly while tied Boltzmann machines estimate col -laborative effects from content information, it is natural t o investigate the combination of these two approaches throug h softening the parameter-tying constraints. Third, the mod el can be extended to multinomial votes. Such an extension could attempt to model the product space of possible pair-wise interactions, or could use interaction terms that depe nd on the difference of the vote pair. The authors thank David Maxwell Chickering and Guy Shani for their assistance, as well as the PennAspect team for making their software available online. [1] J. Besag. Statistical analysis of non-lattice data. The [2] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [3] S. F. Chen and R. Rosenfeld. A Gaussian prior for [4] N. Good, J. B. Schafer, J. A. Konstan, A. Borchers, [5] D. Heckerman, D. M. Chickering, C. Meek, [6] T. Hofmann. Probabilistic latent semantic indexing. In [7] T. Hofmann and J. Puzicha. Latent class models for [8] J. Lafferty, A. McCallum, and F. Pereira. Conditional [9] G. Linden, B. Smith, and J. York. Amazon.com [10] M. Montaner, B. L  X opez, and J. L. de la Rosa. A [11] S.-T. Park, D. Pennock, O. Madani, N. Good, and [12] M. J. Pazzani and D. Billsus. Content-based [13] M. Riedmiller and H. Braun. A direct adaptive [14] R. Salakhutdinov, A. Mnih, and G. Hinton. Restricted [15] B. Sarwar, G. K. nad Joseph Konstan, and J. Reidl. [16] A. I. Schein, A. Popescul, and L. H. Ungar.
 [17] A. I. Schein, A. Popescul, L. H. Ungar, and D. M. [18] A. I. Schein, A. Popescul, L. H. Ungar, and D. M.
