 In this paper, we aim to jointly extract aspects and aspect-specific sentiment knowledge from online reviews, where the sentiment knowledge refers to the aspect-specific opinion words along with their aspect-aware sentiment polarities. To this end, we propose a Joint Aspect/Sentiment model (JAS). JAS detects aspect-specific opinion words by integrating opinion word lexicon knowledge to explicitly separate opinion words from factual words. More importantly, JAS exploits sentiment prior and aspect-contextual sentence-level co-occurrences of opinion words in reviews to further identify aspect-aware sentiment polarities for the opinion words. Experimental results show the effectiveness of JAS in learning aspect-specific sentiment knowledge and the practical value of this knowledge when applied to aspect-level sentiment classification. I.2.7 [ Artificial Intelligence ]: Natural language processing  X  text analysis Algorithms, Performance, Experimentation. Online reviews, Aspect-level sentiment analysis, Aspect-specific sentiment knowledge, Joint Aspect/Setniment model. With the emergence of Web 2.0, customers can freely write reviews about various entities, such as products and hotels, on online E-Commerce sites. Automatic sentiment analysis techniques help users quickly digest opinions in a large number of reviews. Aspect-level sentiment analysis techniques [7, 2] are especially appealing since they could help users effectively navigate into detailed information of their interesting aspects by organizing the opinions in a structured form. High-quality sentiment knowledge plays a fundamental role in such sentiment analysis tasks. However, the general-purpose sentiment knowledge is usually not favorable due to the highly aspect-dependent nature of sentiment [12, 10]. This paper goes beyond only extracting aspects, and aims to further learn aspect-specific sentiment knowledge, i.e. aspect-specific opinion words along with their aspect-aware sentiment polarities. We argue that this knowledge would be potentially useful for improving aspect-level sentiment analysis. 1) Firstly, the customers tend to use opinion words specific to the aspect to comment on the aspect, e.g. using  X  X ozy X  and  X  X omantic X  to comment on the ambience of a restaurant. And these words could thus, in turn, provide rich clues for inferring the target a spects when they are not explicitly gi ven (i .e. implicit aspects, such as the  X  X ood X  aspect in  X  X o de licious X ). Furthermore, aspect-s pecific opinion words could a lso help extract more informative opinions from reviews. Indeed, these opinion words usually provide more meaningful descriptions about the aspect [12] rather than giving only general i nformation such as  X  X ood X  or  X  X ad X  as the general opinion words. 2) Secondly, the sentiment polarities of many opinion words are sensitive to the aspect [10] , which means that one s ingle word may deliver different sentiment polarities according to the aspects in context or deliver a sentiment only for a specific aspect. For instance, for a hotel we enjoy a  X  X arge X  room, but not expect  X  X arge X  noise; it is desirable for the ambience of a restaurant to be  X  X rivate X , although  X  X rivate X  is generally neutral, etc. Identifying aspect -a ware polarities for these opinion words c ould improve aspect-l evel sentiment classification [10]. 
In this paper we pr opose a Joint Aspect/Sentiment model (JAS) t o extract aspects and aspect-s pecific sentiment knowledge from r eviews in a unified framework. Specifically, JAS extends classic LDA [3] in the following ways. 1) Firstly, we adapt LDA to make t he extracted topics correspond to the reviewable aspects of entities by constraining that all words of each sentence are assigned to a single topic. 2) Secondly, we introduce sentiment-re lated variables into the unified model and integrate opinion word lexicon a nd sentiment prior knowledge to learn aspect-spe cific sentiment knowledge. Specifically, JAS detects aspect-spe cific opinion words by integrating opinion word lexicon know ledge to explicitly separate sentiment-be aring opinion w ords from factual words. M ore importantly, JAS integrates s entiment prior and co-o ccurrence information in reviews to f urther identify aspect-a ware sentiment polarities for the opinion w ords. Int uitively speaking, JAS propagates the sentiment prior, v ia aspect-c ontextual sentence-level co-occurrences of opinion w ords in rev iews, in a bootstrapping-like manner to adapt and e xtend the sentiment prior with respect to the aspect. To the best of our knowledge, this is the first attempt to j ointly and explicitly ext ract aspects and aspect-s pecific sentiment knowledge, where t he sentiment knowledge refers to the aspect-specific opinion w ords along with their aspect-a ware sentiment polarities. Some w ork extracts aspect-s pecific sentiment in a separate stage [4, 10 ]. There are also several joint models involving topic/aspect a nd s entiment [11, 9, 12, 8], and the most related models include M axEnt-L DA [12] and AUSM [8]. However MaxEnt-LDA do esn X  X  further identify sentiment polarities for opinion words, while AUSM aims to detect sentiment-c oupled aspects c onditioned on different sentiments, rather than detecting s entiments specific to the aspects, without explicitly s eparating s entiment f rom factual information. Assume we have a corpus of D customer reviews in a specific domain (e.g. restaurant reviews), each review is a list of sentences, each sentence is a list of words, and each word is an entity from a vocabulary with V distinct words denoted by w =1, variable: the aspect , d s z which is shared by all words in the sentence. And the n th word , , d s n w in the sentence s of review d is associated with two indicator variables: the subjectivity label  X  and the sentiment label whether , , d s n w is a sentiment-conveying opinion word  X  = opn ) or a factual word ( follows: 
Figure 1 shows the graphical representation of the generation process, where T is the number of aspects, S =2 and J =2 are the numbers of sentiment labels and subjectivity labels respectively, M is the number of sentences in the review d , and N d,s number of words in the sentence s of the review d . Note that, the subjectivity label assignment for , , d s n w , we will discuss in details how to set this distribution in Section 2.2. Also note that, convey any sentiment in that case, and will actually be ignored for generating , , d s n w . We here draw it just for completeness of the generation process, and not drawing it is also reasonable. for , , d s n w .However, fully-unsupervised topic models, which mainly exploit co-occurrences, cannot effectively separate opinion words from factual words. Inspired by Zhao et al.[12], (presented by  X  ) to the context features of the word (presented by , , d s n c ) to indicate the probability of whether or not w conveys a sentiment (see Figure 1). Currently, we consider only the word itself as its context, and integrate the knowledge is encoded into the over subjectivity labels for the word w , and For each word w in the opinion lexicon, we set opn w  X  to a value approaching 1, e.g. 0.95 as in our experiments; while for each word w not contained by the lexicon, we set opn approaching 0, e.g. 0.05 as in our experiments. Based on the 
P  X   X  w Explanations for the notations used in this subsection are given in Table 1. We first use the collapsed Gibbs sampling [6] to estimate the posterior distributions over z ,  X  , l . According to the collapsed Gibbs sampling, each variable of interest (  X  , and probability distribution conditioned on current assignments of all other variables and the observed data. Here, we first draw the below conditional probability. All the numbers represented by c in the below equation exclude sentence s of review d . ( | , , , ) ( ) ( ) P z t  X   X   X   X   X   X   X   X   X   X  X  X   X   X   X   X   X   X   X   X   X   X  conditional probabilities. Note that, all the numbers represented by c in the following two equations exclude the word , , d s n ( fact | , , , )
P  X   X   X  ( opn, | , , , ) Based on the last sample of z ,  X  , l after N Gibbs sampling iterations, the word distributions for the factual aspect (i.e. t  X  ), and the aspect-specific positive and negative sentiments follows: 
Top words in ,neg t w  X  and ,pos t w  X  could be considered as aspect-specific opinion words. And if ,pos t w  X  &gt; ,neg t positive sentiment for the aspect t ; otherwise negative. Sentiment prior (SP) serves as guidance for identifying sentiment polarities of the opinion words. Here, sentiment prior means a set of SP words (usually a subset of an opinion word lexicon) along with their prior sentiment labels. We here have two parts of SP words: Soft SP words and Hard SP words. A Hard SP word, such as  X  X xcellent X , will convey the same sentiment as the prior in any context. A Soft SP word will deliver the sentiment as the prior in most contexts, but with exceptions. 
We incorporate the sentiment prior into our model by using which describe our prior assumptions of the word distributions for the positive and negative sentiments for any aspect. Specifically, for each positive (negative) Hard SP word w , sampling, all Hard SP words are assigned to their prior sentiment labels. In this way, we could impose the hard-constraints that Hard SP words could only be assigned to their prior sentiment labels in the Gibbs sampling process. For each positive value compared with pos w  X  ( neg w  X  ). In this way, we impose the soft-constraints that Soft SP words are more probable to be assigned to their prior sentiment labels. Data. To evaluate our model, we use the two freely available data sets, the restaurant reviews and the hotel reviews initially used in [5] and [1], respectively. The restaurant reviews have been preprocessed with sentence segmentation and part-of-speech tagging. For hotel reviews, we use a NLP toolkit segment reviews into sentences, and use the Stanford POS Tagger 2 to conduct part-of-speech tagging over sentences. We add a negation prefix,  X  X ot_ X , to a word modified by a negating word. We then remove stop words based on a stop word list Finally, each sentence is converted to a sequence of POS tagged words with possible negation prefix. Opinion Word Lexicon &amp; Sentiment Prior. The opinion word lexicon (see Section 2.2) are extracted from two widely used knowledge bases: MPQA Subjectivity Lexicon 4 (MPQA in short) and SentiWordNet 5 . The SP words (see Section 2.4) are a subset of the opinion word lexicon. We select SP words from only the MPQA part with words of  X  X eutral priorpolarity X  filtered out, and use their  X  X riorpolarity X  in MPQA as their prior sentiment labels. From SP words, we further select words with all senses (i.e. synsets in SentiWordNet) sharing the same polarity according to the SentiWordNet. We then manually check these selected words, trying to ensure that they deliver consistent sentiment in any context, and finally obtain the Hard SP words. The remaining SP words are Soft SP words. Note that, the development of sentiment prior is totally domain-independent and aspect-independent.
 Parameters Settings. We run 200 iterations of Gibbs sampling, which is adequate for obtaining good and stable results in our experiments. We set 50 / t = T  X  for each aspect t and each word w in the vocabulary. The default value for pos  X  is 0.1, but for each positive (negative) Hard SP word w, sentiment label l . The aspect number T is set to 10 with which we could detect all major aspects, and no more meaningful aspects has been detected by increasing T . Table 2 and Table 3 show sample results with restaurant and hotel reviews, respectively. We only show some major aspects, and discard some miscellaneous or similar aspects to save the room. Seen from the tables, we could observe that: 1) our model could effectively detect major aspects from both restaurants and hotel reviews. And the extracted factual words are quite coherent and meaningful with respect to the aspects. 2) The discovered opinion words (either positive or negative) are quite specific and informative with respect to the aspects. For instance, the staff is  X  X nowledgeable X , the cream is  X  X our X , the location of the hotel is  X  X entral X , etc. 3) Generally speaking, JAS could effectively identify sentiment polarities for opinion words with respect to the aspects. For instance, in restaurant reviews,  X  X ong X  waiting time is not acceptable for reservation, it is desirable for the ambience to be  X  X rivate X , etc. In hotel reviews, people prefer for  X  X entral X  and  X  X lose X  hotels,  X  X mall X  room is not desirable, the waiter is  X  X oung X  means he/she is not experienced, etc..
 Aspect-level sentiment classification is to classify the sentiment of opinions about the specific aspect in texts [10]. The evaluations are based on a set of approximately 3400 sentences manually annotated with aspect and sentiment polarity information by Ganu et al. [5] in the restaurant reviews. We select from the gold standard aspect set three major aspects:  X  X taff X ,  X  X ood X , and  X  X mbience X . In order to avoid ambiguity, we only use sentences annotated with  X  X ositive X  or  X  X egative X  polarity discarding those with  X  X eutral X  or  X  X ix X  polarity. Then, the specified task is to determine the sentiment polarity, either positive or negative, of opinions in the sentences annotated with the specific aspect. To use this gold standard data for evaluations, we manually find automatically detected aspects that correspond to each gold standard aspect. Since JAS could detect quite fine-grained aspects, there may be multiple detected aspects, such as  X  X ood-Bakery X  and  X  X ood-Main dish X , for one gold standard aspect, such as  X  X ood X . Given a gold standard aspect a  X  our model could learn an aspect-specific sentiment lexicon. This lexicon contains all words in the opinion word lexicon used in Section 2.2 with their aspect-aware sentiment polarities learned as follows. We first learn positive and negative aspect-specific sentiment models: ( | ) {pos,neg} a P w l where a T is the detected aspects by JAS that corresponds to a . Then the aspect-specific sentiment polarity of an opinion word w could be defined as: If opn,pos ( | ) a P w  X  &gt; opn,neg ( | ) is positive for the aspect a ; otherwise it is negative. 
Based on the aspect-specific sentiment lexicon, our approach classifies the sentiment by just counting positive and negative opinion words in the sentence. 
As comparisons, we have some general-purpose sentiment lexicons based baselines: MPQA , SWN , and Union , which use following sentiment lexicon respectively: MPQA , SWN and Union . MPQA is exactly the sentiment prior used in our model (see Section 3.1). SWN contains words from the SentiWordNet part with their polarities inferred by SentiWordNet. Union is the union of MPQA and SWN . It actually contains all words in the opinion word lexicon, and we address possible conflicting polarities in Fusion by considering MPQA first. Order Taking Reception Condition Breakfast 
We also adapt ASUM [8] to learning aspect-aware sentiment lexicon. The opinion words are the same as our approach, and the sentiment polarities are learned as follows. We first learn sentiment-coupled aspect models for aspect a as follows: ( | ) {pos,neg} l a P w l
Here, where l a T is the detected aspects that corresponds to a under sentiment l , STW jkw C is the total number of times word w assigned to aspect t under sentiment l . Note that, since ASUM detects aspects under different sentiments independently, usually different from neg a T .For an opinion word w, the sentiment P w  X  , the word w is positive; otherwise negative. There are two variables for ASUM based approaches. ASUM incorporate the same sentiment prior as the original ASUM, the aspect number is set to 10 as our approach, and the other parameters are the same as in [8]. ASUM+ improves ASUM by using the same sentiment prior as our approach. 
Besides lexicon-based unsupervised approaches, we also apply the supervised approach, Support Vector Machine ( SVM ). We use the LibSVM 6 to for training and testing with all default options but a linear kernel. Each sentence is represented by Vector Space Model with Term Frequency word weighting. The reported results are based on 7-fold cross validation over the annotated sentences. 
Seen from Table 4, we observe that: 1) MPQA perform reasonably well and significantly outperforms both SWN and Union . This shows that MPQA could provide high precision polarities for opinion words in most contexts, and is very reliable be used as sentiment prior. 2) Our approach further outperforms MPQA over all three aspects. This is because our model effectively exploits aspect-contextual sentence-level co-occurrences of opinion words in reviews to adapt and extend the knowledge of MPQA with respect to the aspect. 3) In spite of its simplicity, our approach is comparable to, if not better than, the state-of-art supervised learning approach SVM over the three aspects. SVM suffers from both high computational complexity and intensive labeling labors. Furthermore, we expect a promising potential of our model in improving aspect-level sentiment classification when combined with supervised learning approach. 4) Both ASUM and ASUM+ perform poorly. We argue the reason is that, ASUM essentially aims to detect sentiment-coupled aspects without explicitly distinguishing between sentiments and factual aspects. Thus, AUSM couldn X  X  fully exploit aspect-contextual co-occurrences of sentiment-bearing words to learn sentiment polarities with respect to a specific aspect. Table 4. Results of aspect-level sentiment classification in precision (%).
 http://www.csie.ntu.edu.tw/~cjlin/libsvm/ In this paper, we attempt to extract aspects and aspect-specific sentiment knowledge using a proposed Joint Aspect/Sentiment model. In future, we plan to consider more context features and more sources of knowledge to better identify opinion words. We also plan to incorporate more sources of signals, such as  X  X nd X  rules in linguistics heuristics and synonym/antonym [10] in WordNet, to better identify sentiment polarities of the opinion words. This work was supported by following funds: National Natural Science Foundation of China under Grants No. 60903139, No. 60933005, No. 61003166, No. 60803085, No.61100083; National High-Tech R&amp;D Program of China (863 Program) with Grant No. 2010AA012502, and No. 2010AA012503. 5. REFERENCES [1] S. Baccianella, A. Esuli, and F. Sebastiani. Multi-facet [2] S. Blair-goldensohn, T. Neylon, K. Hannan, G.A. Reis, R. [3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet [4] S. Brody, and N. Elhadad. An unsupervised aspect-[5] G. Ganu, N. Elhadad, and A. Marian. Beyond the stars: [6] T. L. Griffiths, and M. Steyvers. Finding scientific topics. [7] M. Hu, and B. Liu. Mining and summarizing customer [8] Y. Jo, and A. H. Oh. Aspect and sentiment unification model [9] C. Lin, and Y. He. Joint sentiment/topic model for sentiment [10] Y. Lu, M. Castellanos, U. Dayal, and C. Zhai. Automatic [11] Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. Topic [12] W. X. Zhao, J. Jiang, H. Yan, and X. Li. Jointly modeling 
