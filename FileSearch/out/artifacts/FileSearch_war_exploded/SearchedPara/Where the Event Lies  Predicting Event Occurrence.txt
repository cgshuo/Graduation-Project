 Manually inspecting text in a document collection to assess whether an event occurs in it is a cumbersome task. Although a manual inspection can allow one to identify and discard false events, it becomes infeasible with increasing numbers of automatically de-tected events. In this paper, we present a system to automatize event validation , defined as the task of determining whether a given event occurs in a given document or corpus. In addition to support-ing users seeking for information that corroborates a given event, event validation can also boost the precision of automatically de-tected event sets by discarding false events and preserving the true ones. The system allows to specify events, retrieves candidate web documents, and assesses whether events occur in them. The vali-dation results are shown to the user, who can revise the decision of the system. The validation method relies on a supervised model to predict the occurrence of events in a non-annotated corpus. This system can also be used to build ground-truths for event corpora.
Event descriptions can provide concise summaries of news arti-cles, making the seek for event related information more enjoyable for general readers and more effective for professionals like histori-ans and journalists. We do not focus on how events are detected or extracted from text, but rather tackle the problem of assessing their occurrence within a given corpus. In line with both the basic def-inition of event given by the Topic Detection and Tracking (TDT) project [1] and with more recent works on event detection, e.g. [5, 6, 8], we model events as a set of participants related within a given time period. For instance, the event {( Novak Djokovic , Roger Fed-erer , US Open ), 2015-08-30 to 2015-09-15 } would represent the participation of two tennis players in the 2015 US Open.
Manually assessing whether an event occurs in a document col-lection becomes infeasible in scenarios where events are contin-uously and automatically detected from news streams on a large-scale. In this paper, we present a system to automatize the event validation process by predicting whether a given event has evidence within a set of unannotated documents retrieved from a corpus. Our system can find documents that corroborate the occurrence of an input event, thus simplifying the task of manually searching for event-related information to confirm or deny its verity. In more detail, the developed system allows to specify one event, retrieves candidate Web documents, and assesses what are the documents (if any) where it occurs. The validation judgments are shown to the user, who can explore the documents and possibly revise the deci-sion of the system. Given the possibility for users to provide their own validation judgments, which are made persistent along with events and documents, the application can also be used to acquire ground truth data for a given set of input events. Event validation can also be applied as a post processing step of event detection to boost the precision within the detected set of events by reducing the number of false events with respect to a given corpus.

To validate events, the system relies on a state of the art method [4] that extracts features from events and documents and exploits them to train a model via supervised machine learning. Once trained, the model predicts event occurrence in terms of the mutual confor-mation of the event participants within the event timespan. Al-though our system uses the Web as a source for documents due to its easy accessibility and wide event coverage, any document col-lection could be used in principle owing to the lack of assumptions on the nature of events and documents within the validation model.
To the best of our knowledge our system is the first of its kind, showcasing automatic event validation and supporting users in look-ing for evidence corresponding to the verity of events.
The automatic detection of events within text has been widely studied, e.g. in [1, 5, 6]. However, event detection is different from event validation, since the output of the former (i.e., a set of events ) constitutes the known input for the latter. Although the task of event validation with respect to a corpus can be modeled as the task of retrieving documents relevant to input events, checking the mere appearance of event participants in text has been proved to be insufficient to validate the occurrence of events in documents while establishing mutual relationships and temporal conformation [4].
Besides the method showcased by our system [4], which com-bines a wide set of features extracted from events and documents within a supervised model, another attempt to event validation has been proposed in [3], where the occurrence of events in documents is evaluated based on hand-crafted rules. Araki et al. [2] performed historical fact validation by casting the problem as Passage Re-trieval : they assess event validity in terms of the textual similarity between facts and passages of fixed length. Figure 1: Approach overview of automatic event validation.
Available system implementations do not tackle event validation, but they rather consider other event-related applications like extrac-tion [7], tracking [12], retrieval of event-related information [10], visualization [9], and retrospective exploration [11].
The event validation process is depicted in Figure 1 and it con-sists of three phases. These are: query formulation , which gener-ates queries from the event specified by the user and retrieves candi-dates documents from the Web; feature extraction , which extracts features from (event,document) pairs; document-level validation , to identify documents containing evidence of the event (if any).
The Query Formulation phase takes an event specified by the user as input. An event is made of (i) a set of participants, repre-senting the participants of the event, and (ii) a start and end date, indicating the timespan within which the event occurred. This is in line with event definitions used in previous works [5, 6, 8].
Given an event, queries are constructed by concatenating the event participants along with month and year of the event timespan (one distinct query for each month). The Bing Search API is used to perform queries and to retrieve the top-20 Web pages for each query in terms of URLs. We chose the Web as a source for doc-uments due to its easy accessibility and wide event coverage, but any document collection could be used. After removing duplicates and discarding non-crawlable Web pages, plain text is extracted by using BoilerPipe 1 . Finally, events and documents are logically cou-pled and stored as (event, document) pairs for later use.
The features described in [4] are extracted from pairs to form the input to the validation model. These are logically split into three groups: event features describe the event without coupling it with any document; document features are extracted from the plain text of each document, independent of the event to be validated; pair features are extracted from pairs to give information about the ex-tent to which a document contains evidence of the event. Stanford CoreNLP 2 is used for POS tagging, named entity recognition, and dates extraction. The features extracted from each pair p are con-catenated in a feature vector f p as input to the validation.
The last step of event validation consists of assessing the validity of pairs, i.e. whether the document in the pair contains evidence of the event. Note that we do not aim at stating whether an event is true or false in general, but whether it occurs in the retrieved docu-ments. Formally, an event is said to be valid (i.e. to have evidence of its occurrence in a document) with a threshold  X , 0 &lt;  X   X  1 , iff at least  X  % of the event participants conform together in an event reported in the document, strictly within the timespan of the event. This implies that an event can exhibit different degrees of evidence within the same document, depending on the imposed ev-idence threshold. For instance, if 75% of the participants relate to-gether in a document and within the event timespan, then the event would have evidence in the document if a threshold  X  = 50% is considered, but would not have evidence for  X  = 100% . Imposing an evidence threshold makes the validation a classification task and allows to have a more intuitive notion of document-level validity: a document (and then the corresponding pair) is judged as valid if the number of event participants that conform together within it is equal to or greater than the threshold, and invalid otherwise.
Given the feature vectors f p extracted from (event,document) pairs p and an evidence threshold  X  , an SVM with RBF Kernel trained considering  X  as threshold is used to predict the validity  X  p = SV M f p ,  X  of each pair, where the validation judgment  X  p is binary and can assume the values { valid ; invalid } . In our system, the user can choose among three evidence thresholds (50%, 65%, 100%) and the SVM trained with the chosen value is used accordingly. Refer to [4] for further details on the training process.
We implemented a publicly available Web application 3 , 4 the JSF framework. For a given input event, candidate documents are retrieved through the Bing Search API and then posed as input to the back-end validation model [4], implemented in Java. It uses the Stanford CoreNLP parser for feature extraction and SVM clas-sifiers trained with the LibSVM library to validate each (event,doc-ument) pair. The user can review the documents and possibly revise the validity judgments given by the system. This feedback is stored in a MySQL database for future re-training of the validation model.
The user interface of our application is shown in Figure 2. The user can specify an input event by filling the form on the left-hand side. The required information consists in the event participants, it start and end dates, the validity threshold, and the number of candidate documents to retrieve. On the right-hand side is the list of retrieved documents along with their validation judgments (either valid or invalid ), given with respect to the input event and evidence threshold. For each document, the user can inspect the plain textual content extracted with BoilerPipe and actually used for validation (Figure 3), as well as visit its original URL. When reviewing the text, the user has the chance of changing the original validation judgment, possibly marking cases of uncertainty. To simplify the review process of the user, the occurrences of event participants and dates detected by the Stanford CoreNLP parser are highlighted.
The main usage scenario that we consider consists of a user will-ing to retrieve information related to a given event, possibly pro-vided by a certain news agency or an event detection algorithm, to either corroborate or deny its occurrence. Given the possibility for the users to provide and store their own validation judgments, the application can also be used to acquire ground truth data for a set of input events. The judgments about event validity are not absolute: they relate to the Web as ground truth and to the documents that have been thus retrieved. For instance, an event having no evidence in any retrieved Web pages might still occur in other documents in the Web that were not retrieved, or in corpora disjoint from the Web. In the rest of this section we discuss three examples of usages of the application, namely in presence of true, false, and less news-worthy input events. Since the system relies on the Bing Search API for retrieval and the set of documents populating the Web is continuously evolving, the set of documents shown in the figures and discussed in this section might be different from the ones got when performing the same queries at future points in time.
The validity judgments given for pairs always refer to the speci-fied evidence threshold  X  (Section 3.3). An (event, document) pair is said to be valid with a threshold  X  if at least  X  % of the event par-ticipants relate together in the document, strictly within the event timespan. For instance, if 3 out of 4 participants conform together in a document, the occurrence of the event in it will be valid for  X  = 50% and  X  = 65% , but invalid for  X  = 100% (all participants are required). We consider  X  = 50% in the rest of this section. Let us assume that a user wants to check whether the entities Sukhoi Su-24 , Vladimir Putin , Syria , and Recep Tayyip Erdogan have been related to each other within the period from 23-11-2015 to 30-11-2015. Actually they were, since on 24 th November 2015 a Russian Sukhoi Su-24M bomber aircraft flying at the Syria-Turkey border was shot down by a Turkish fighter jet, leading to tensions between the two leaders Putin and Erdogan. The input form as well as the retrieved and validated Web pages representing this scenario are shown in Figure 2. The top-5 retrieved documents have been all judged as valid, which means that all of them are declared to con-tain evidence of the input event. Inspecting their content, one can observe that they report the description of the actual event as well as political discussions generated from it. An excerpt of the first document reporting the event is shown in Figure 3, where match-ing event participants and dates are highlighted in the application for sake of inspection and review.

Note that the mutual conformation of the event participants to the same event in the document is not a sufficient condition for the (event,document) pair to be declared as valid (i.e. the event occurs in the document). It has to be integrated by the temporal valid-ity, which means that the event participants relate together strictly within the specified timespan of the event. As we will show in Section 4.2.2, (event,document) pairs exhibiting mutual occurrence and relation of event participants not explicitly within the event timespan are judged as invalid .
 Figure 3: Excerpt of a retrieved document reporting the input event.
We focus on two reasons of event invalidity: (i) when event par-ticipants are not reported in the retrieved documents as they do not relate to each other, and (ii) when the participants did relate to each other but not within the specified event timespan.

Starting from the event mentioned in Section 4.2.1, let us mod-ify the set of participants by replacing Syria and Sukhoi Su-24 with two  X  X ntruders X , namely Spain and Foxtrot-class Submarine (patrol submarines built in the Soviet Union). The retrieved documents along with their validation judgments are reported in Figure 4a, which shows that all retrieved documents have been judged as not containing the event. The input entities did not participate in a com-mon event, and consequently, the system did not find any evidence.
To show temporal invalidity, let us keep the original participant set of the event in Section 4.2.1 and let us shift the event timespan one month in advance, namely from 23-10-2015 to 30-10-2015. The output of the system is shown in Figure 4b, where the result list differs from the one in Figure 2 because a different month has been used to formulate the query. All the retrieved documents have been declared as not containing the event, although participants actually occur in them, because no signal about temporal validity was found. As stated by the problem definition itself (Section 3.3), event vali-dation strictly takes the temporal dimension of events into account when making decisions about their occurrence within documents.
Besides newsworthy events with a large amount of corroborating documents, as the one considered in Section 4.2.1, event validation also has to cope with less popular events, whose occurrences in documents might be less frequent or unclear. As an example, let us consider an event with participants SIGIR , Chile , Ricardo Baeza-Figure 5: Top-5 retrieved documents for a low newsworthy event. Yates from 04-08-2015 to 16-08-2015. This validation scenario is different from the previous ones because (i) the event has a high impact only for a particular community of researchers and (ii) the periodicity of the SIGIR conference might introduce documents referring to other venues outside the specified period. The top-5 retrieved documents and their validation judgments are shown in Figure 5, which shows that only a part of the documents contain evidence of the event. The others refer either to previous SIGIR venues, or contain works of Ricardo Baeza-Yates, or even com-pletely unrelated documents.
Automatically determining whether an event occurs in a docu-ment collection is a challenging task. The usage of the Web itself as ground truth poses further challenges; due to its ubiquitous accessi-bility and wide event coverage, it can be regarded as a noisy source owing to the presence of unstructured and potentially untrustworthy sources (like blogs and forums) with questionable verity. There-fore, our application keeps users in the loop by allowing them to review the plain text extracted from the retrieved Web pages. By highlighting the event participants and dates detected in the text, our system simplifies the inspection and presents the user with the possibility of revising a potentially incorrect validity judgment de-duced by the system (Figure 3). Such feedback is stored and can be used for future re-training of the validation model. Besides errors committed by the back-end classifier, other possible misclassifica-tions can be caused by errors introduced during boilerplate removal and named entity or temporal expression extraction (e.g. important content of a Web page might not be included in the plain text or temporal expressions might not be detected by the NLP parser). Background information known to a user but not explicitly present in the text might be a further source of judgment discrepancy.
In this paper, we presented a system to automatize the event val-idation process by predicting whether a given event has evidence within a set of unannotated documents, thus simplifying the task of manually searching for event-related information to confirm or deny its verity. The developed system allows to specify an event, retrieves candidate web documents, and assesses what are the doc-uments (if any) where it occurs. The validation method relies on a state of the art model for event validation. The user can review the documents and revise the validation judgments given by the sys-tem. Given the possibility for users to provide their own validation judgments, the application can also be used to acquire ground truth data for a given set of input events. By coupling our system with the powerful crowdsourcing paradigm, one can build large event corpora with corresponding ground truths in a scalable and cost-effective manner. Although we chose the Web as a source for doc-uments, due to its easy accessibility and wide event coverage, other document collections could be explored and included in the system. Acknowledgments This work was partially funded by the Euro-pean Commission in the context of the FP7 project QualiMaster (grant No: 619525) and H2020 project AFEL (grant No. 687916).
