 The junction tree approach, with applications in artificial in-telligence, computer vision, machine learning, and statistics, is often used for computing posterior distributions in prob-abilistic graphical models. One of the key challenges associ-ated with junction trees is computational, and several paral-lel computing technologies -including many-core processors -have been investigated to meet this challenge. Many-core processors (including GPUs) are now programmable, unfor-tunately their complexities make it hard to manually tune their parameters in order to optimize software performance. In this paper, we investigate a machine learning approach to minimize the execution time of parallel junction tree al-gorithms implemented on a GPU. By carefully allocating a GPU X  X  threads to different parallel computing opportunities in a junction tree, and treating this thread allocation prob-lem as a machine learning problem, we find in experiments that regression -specifically support vector regression -can substantially outperform manual optimization.
 I.2.m [ Computing Methodologies ]: ARTIFICIAL IN-TELLIGENCEMiscellaneous Algorithm belief propagation, parallel computing, regression
Parallel processing is becoming increasingly important in all areas of computing, including in knowledge discovery and machine learning. This is to a large extent due to recent developments in hardware, and in particular a key difference between Moore X  X  law and clock frequency of CPUs. Moore X  X  law, which states that the number of transistors that can be placed on an integrated circuit will increase exponentially, is as of 2013 still going strong. However, the clock frequency of CPUs has stalled, due to physical limits on heat dissipation in integrated circuits. As a consequence, computers are now multi-core (CPUs) or many-core (GPUs), and algorithms that take advantage of this fact will be at an advantage. The importance of parallel, and also distributed, computing in data mining is further increased due to Big Data; the size of the data sets available for analytical processing has recently been increasing drastically.

In this paper, we discuss parallel computing for belief propagation in junction trees. Belief propagation (BP) over junction tree can be used to compute posterior marginals in Bayesian networks (BNs) [9]. However, belief propagation is computationally hard, and the computational difficulty in-creases dramatically with the density of the BN, the number of states of each network node and the BN treewidth, which is upper bounded by the generated junction tree [12]. This computational issue may hinder the application of BNs in cases where real-time inference is required. Paral-lelization of Bayesian network computation is a feasible way of addressing this computational issue [8, 13, 17, 16, 7, 10, 6, 11, 2]. These parallel BP algorithms are implemented on various state of the art parallel computing platforms. How-ever, due to the complexity of these modern platforms, the junction tree algorithm, and the way they interact with each other, it is not trivial to make parallel BP algorithms work efficiently on these platforms.

Many-core computers including GPUs, which are built around an array of processors running many threads of ex-ecution in parallel, are among the most popular platforms. However, it is non-trivial to optimize GPU programs. The challenges with GPU optimization for parallel BP includes:
In this paper, we focus on minimizing compute time of n ode level parallel BP on many core system, in particular GPUs, using system performance modeling. We expand on research using GPU to implement node level parallelism of belief propagation [18][6]. Our work is done on top of a parallel BP algorithm [18]. Our contribution in this work includes
This work is relevant to data mining and machine learning in two distinct ways. First, we investigate parallel computa-tion using probabilistic graphical models, in particular junc-tion trees [1], which are applied in many data ming contexts, including Expectation Maximization. Second, in order to solve the central problem of thread allocation for parallel junction tree computation, we take a machine learning ap-proach.

Our paper is organized as follows: In Section 2, we briefly review previous research and formulate the problem we are going to solve. In Section 3, we describe the two-dimensional parallel belief propagation algorithm, where GPU parame-ter optimization dicussed in Section 4 is key to good perfor-mance. In Section 5, we describe our approach of using sta-tistical models for system performance prediction and use it for GPU parameter optimization. Experimental results are discussed in Section 6. We conclude in Section 7.
A BN is a compact representation of a joint distribution over a set of random variables X . A BN is structured as a directed acyclic graph (DAG) whose vertices are the ran-dom variables and the directed edges represent dependency relationship among the random variables. The evidence in a Bayesian network consists of instantiated variables.
The junction tree algorithm propagates beliefs (or poste-riors) over a derived graph called a junction tree. A junction tree is generated from a BN by means of moralization and triangulation [9]. Each vertex C i of the junction tree con-tains a subset of the random variables that forms a clique in the moralized and triangulated BN, denoted by X i  X  X . Associated with each vertex of the junction tree there is a potential table  X  X i . With the above notations, a junction tree can be defined as J = ( T ;  X ), where T represents a tree and  X  represents all the potential tables associated with this tree. Assuming C i and C j are adjacent, a separator S ij induced on a connecting edge. The variables contained in S ij are defined to be X i  X  X j .

The computation of belief propagation can be measured by treewidth , which is defined to be the minimal size of the largest set in junction tree minus one. Considering a junc-tion tree with a treewidth t w , the amount of computation is lowered bounded by O (exp( c  X  t w )) where c is a constant.
Belief propagation is invoked when we get new evidence e for a set of variables E  X  X . We need to update the potential tables  X  to reflect this new information. To do this, belief propagation over the junction tree is used, this is a two-phase procedure: evidence collection and evidence distribution. For the evidence collection phase, messages are collected from the leaf vertices all the way up to a designated root vertex. For the evidence distribution phase, messages are distributed from the root vertex to the leaf vertices. A recursive algorithm of collecting and distributing evidence is shown in Algorithm 1 and 2. In the following sections, we are going to focus on parallelizing each message passing in Algorithm 1 and 2.
 Algorithm 1 C ollect Evidence( J ; C i ) for e ach child of C i do end for return( C i ) Algorithm 2 D istribute Evidence( J ; C i ) for e ach child of C i do end for
GP Us are designed for compute-intensive, highly parallel computations. In GPUs, more transistors are devoted to data processing rather than data caching and flow control. GPUs are especially well-suited to problems that can be ex-pressed as data-parallel computations where data elements are mapped to parallel processing threads. GPUs are mainly used as accelerators for compute-intensive parts of an appli-cation, and therefore attached to a host CPU that performs control-dominant computations.

The GPU is programmed using the CUDA programming framework [14]. An application is organized into a sequential host program that is run on a CPU, and one or more parallel GPU kernels that are run on a GPU.

In GPUs, threads launched are partitioned into thread blocks. There is a limit on the number of threads per block, since all threads of a block are expected to reside on the same processor core and must share the limited memory resources of that core. On current GPUs, a thread block may contain up to 1024 threads [14]. For a GPU to run efficiently and effectively, the concurrency provided by the platform should match the parallel opportunities in the application. The challenge in our work, detailed in Section 3, is that we have two dimensions of parallelism and therefore we need to allocate threads in each block to the two dimensions of parallel opportunities. A poor split may result in waste of computing resources and low efficiency.
We parallelize the atomic operation of belief propagation X  message passing for junction trees. The advantage of doing so is that this node level parallelism can be embedded in dif-ferent belief propagation algorithms unobtrusively, without any change of those algorithms.

Associated with each junction tree vertex C i and the con-tained set of variables X i , there is a potential table  X  taining non-negative real numbers that are proportional to the joint distribution of X i . If each variable can take s states, the size of the potential table is |  X  X i | = Q |X where |X i | is the cardinality of X i .

Message passing from vertex C i to an adjacent vertex C k with separator S ik , involves two steps: 1. Reduction . The potential table  X  S ik of the separator 2. Scattering . The potential table of C k is updated using
A close look at Equation (1) and (2) reveals two dimen-sions of parallelism opportunity in a message passing. The first dimension of parallelism is the separator potential ta-ble (SPT) element-wise parallelism . The second dimension of parallelism is the arithmetic parallelism .

Element-Wise Parallelism: An index mapping table  X 
X ; S stores the index mappings from  X  X to  X  S [5]. We create |  X 
S ik | mapping tables. In each mapping table  X  X i ; X  S ik store the indices of the elements of  X  X i mapping to the j -th separator table element. Mathematically,  X  X i ; X  S [0 ; |  X  X i |  X  1] :  X  X i ( r ) is mapped to  X  S ik ( j ) } .
With the index mapping table, element-wise parallelism can be obtained by assigning a specific group of threads to handle the computation related to a specific separator potential table.

Arithmetic Parallelism: Arithmetic parallelism needs to be explored in different ways for reduction and scattering, and also integrated with element-wise parallelism, as we will discuss now.

For reduction, given a certain fixed element j , Equation (1) is essentially a summation over all the clique potential table (CPT)  X  X i elements indicated by the corresponding mapping table  X  X i ; X  S We compute the summation in parallel by using an existing approach [4]. The summation is done in several iterations. In each iteration, the numbers are divided into two groups and the corresponding two numbers in each group are added in parallel.

For scattering, note that (2) updates the elements of  X  X independently despite that  X  S ik and  X   X  S date different elements. Therefore, we can compute each multiplication in (2) with a single thread.

Given the two dimensions of parallelism, our parallel mes-sage passing approach is illustrated in Figure 1. Denote  X  i [ m ] to be the m -th element in table  X  X i and  X  S ik n -th element in table  X  S ik . If the size of mapping table  X  parallel reduction algorithm can be written as in Algorithm 3. If  X  X i ; S ik is not integer power of 2, we can use techniques such as zero-padding to make it integer power of 2. Algo-rithm 3 integrates the two dimensions of parallelism for the reduction step -the element-wise parallelism determined by |  X 
S ik | and the arithmetic parallelism determined by the size of mapping table |  X  X i ; S ik | . The scattering step is shown in Algorithm 4.
 Algorithm 3 R eduction(  X  X i ;  X  S ik ;  X  X i ; S ik ) Ensure:  X  X i for m = 1 to |  X  S ik | in parallel do end for Algorithm 4 S cattering(  X  X k ;  X  S ik ;  X  X k ; S ik ) for m = 1 to |  X  X k | in parallel do e nd for
Belief propagation is essentially a sequence of message M is the number of nodes in the junction tree. Each message passing has a reduction step and a scattering step. The par-allel algorithms for reduction (Algorithm 3) and scattering (Algorithm 4) assume infinite threads available for parallel computing. However, a parallel computing platform such as a GPU has only limited number of threads available.
GPU message passing is repeatly called by the CPU. Each time the GPU is called, the thread block size as well as the thread allocation can be set from the CPU side. Therefore, when implementing Algorithm 3 and Algorithm 4 on a GPU, a programmer faces the problem of how to set thread block size and allocate the GPU parallel threads to the two di-mensions of parallelism, i.e., we need to find a sequence of GPU run-time parameters for each message passing.
Intrinsic Junction Tree Parameters: Consider a mes-sage passing from C i to C k through a separator S . From the computational perspective, the input cliques and separators can be characterized by a set of Intrinsic Junction Tree Pa-rameter P intr = {|  X  X i | ; |  X  X k | ; |  X  S |} , where |  X  represent the size of potential tables of C i , C k , and S respec-tively. Figure 1: Two parallelism opportunities in a junc-t ion tree: element-wise and arithmetic parallelism. Arithmetic parallelism (tree structure at the bot-tom) is added on top of the element-wise parallelism (look up table at the top).
GPU Parameters: B efore invoking a GPU kernel func-tion for message passing, two question should be resolved on the CPU side: (1) What should thread-block size be? (2) In each thread block, how should threads be divided between element-wise and arithmetic parallelism? To efficiently com-pute the message passing, we need to carefully choose the set of GPU parameters: P gpu = { K r ; K s ; p r a ; p where K r and K s are the total threads of one thread block for reduction and scattering respectively; p r a and p s a number of threads used for arithmetic parallelism in reduc-tion and scattering respectively; and p r e and p s e are the num-ber of threads used for element-wise parallelism used by each thread block in reduction and scattering.
Thread allocation optimization is very important for par-allel message passing in junction tree. Due to the variability of cliques and separators involved in message passing, the performance surfaces have greatly varying shapes.
Figure 1 suggests if a mapping table is large, it is better to assign more threads to the arithmetic parallelism; if a separator table is large, it would be wise to assign more threads to the element-wise parallelism.

Figure 2 shows three examples of different performance surfaces with respect to GPU parameters p r e and K r . For these examples, we get several intuitions about choosing GPU parameters: 1) The search space is so diverse that using the same set of parameters for all message passings can seldom achieve optimal performance. Good parameters for one message passing could work inefficiently for another. 2) For a given message passing, optimal GPU parameters can result in huge improvement over a poor choice of GPU parameters (in some cases, more than 20x difference).
The metrics for measuring system performance vary. In our work, we use the execution time for belief propagation to all the cliques in junction tree as our metric. Since belief propagation over a junction tree is a sequence of message passings, in our node level parallel BP algorithm, minimiz-ing the total BP execution time can be broken down to a sequence of tasks, minimizing the execution time for each message passing.

It requires N = 2( M  X  1) message passings to complete belief propagation over a junction tree J with M cliques. Let f n : P intr  X  P gpu  X  R be the execution time for one message passing. The total BP time is where P n intr and P n gpu are the parameters of the n -th message passing.

Thus, the GPU optimization problem can be modeled as:
Unfortunately, traditional optimization techniques can not be applied to this optimization problem since an analytical form of f n (  X  ) is usually not available due to the complexity Figure 2: Examples of how GPU execution time (y-a xis) varies with different GPU parameters, specif-ically the thread block size (TBS) and number of arithmetic threads (x-axis).
 Figure 3: Statistical model of many-core system per-f ormance.
 of the hardware platform. Fortunately, statistical learning c an provide approximations for f n (  X  ), as we discuss next.
Before we proceed to the black-box modeling approach with pre-execution parameters and post-execution perfor-mance, as our first attempt to characterizes the relationship between the message passing workload, GPU parameters and the output performance (execution time), we develop a simple mathematical model.

For simplicity, assume that the GPU takes a constant time  X  and  X  m for the add and multiplication operations respec-tively. We ignore memory access time, device set up time, etc. Suppose the GPU can accommodate N b thread blocks to run simultaneously. Consider a message passing from C i to C k using GPU parameter p s a , p s e , p r a and p r a Define g (  X ; p ) = l |  X  | p m . The time for reduction is the time for scattering is
The total message passing time between C i and C k is given by T = T r + T s . Due to this decomposition of message passing time into reduction time and scattering time, we can optimize the GPU parameters related to reduction and scattering separately. For reduction, we have: and for scattering we get:
It is analytically and numerically hard to optimize (7) and (8) due to the irregular form of both the objective and con-straint functions. In addition, the overly simplified assump-tions make them not practically useful for the purpose of parameter selection. Consequently, we turn to a regression approach as discussed below.
In this subsection, we develop statistical models for mes-sage passing. The models used are Polynomial Regression and Support Vector Regression (SVR) . Essentially, we want to establish a statistical relationship between the GPU con-fi guration parameters and the performance as illustrated in Figure 3.

Polynomial Regression: For the polynomial model, in or-der to get better insight about how the thread allocation affects the GPU execution time, we use the Lasso method to shrink the model and compare the resulting model with (7) and (8). A polynomial Lasso has the form where P oly j ( x ) is a polynomial function of the feature vector x . The Lasso in the equivalent Lagrangian form is  X   X  where  X  is the Lagrangian multiplier.

Support Vector Regression (SVR): A second regression model we use is support vector regression [3]. In SVR, the input is first mapped onto a high-dimensional feature space using some fixed (nonlinear) mapping, and then a lin-ear model is constructed in this feature space. The linear model (in the feature space) f ( x ;  X  ) is given by formations, and b is the bias term. The loss function of SVR is called  X  -insensitive loss function defined as
L  X  ( y; f ( x ;  X  )) =
SVR performs linear regression in the high-dimensional feature space using  X  -insensitive loss and, at the same time, tries to reduce model complexity by minimizing k  X  k 2 . Thus SVR is formulated as minimization of the following function:
The features we collected for regression model training are shown in Table 1. There are two possible ways that statis-tical modeling can help us with run-time GPU parameter selection: 1) We can directly approximate the function where T : N  X  N  X  N  X  N  X  R is the GPU execution time as a function of K; p a ; |  X  S | and |  X  X | . Practically, the num-ber of possible values K and p a is finite, therefore, we can model (12) as a classification problem. Or 2) we can alterna-tively take an indirect approach by first training a regression m odel for GPU execution time and then search the regres-sion model to obtain the best run-time GPU parameters. In this paper, we use the regression method.
Since the trained model is used to optimize GPU param-eters, we want to find a regression model whose minimum point is the same as or close to that of the real GPU perfor-mance surface. Residual squared sum (RSS) is often used to measure the quality of a regression model X  X  fit to the train-ing data. However, RSS is not a direct metric for the quality of a regression model in our thread allocation optimization problem. In other words, small RSS does not necessarily guarantee a good model.

Our goal is to find optimal estimated parameters K  X  and p a for reduction and scattering with given |  X  S | and |  X  Thus, we propose to use the squared deviance (SD) from the real optimal value as a metric for model training quality, e.g., where T r (  X  )/ T s (  X  ) is the measured GPU reduction/scattering time with respect to junction tree parameters |  X  S | , |  X  GPU parameters K and p and  X  K  X  and  X  p  X  a are the optimal parameters obtained from the statistical model with given |  X  S | and |  X  X | .
Aside from the squared deviance from the optimal value, we also use the miss rate (MR) as a measurement of model quality. The miss rate is defined as where 1 (  X  ) is the indicator function, K  X  and p  X  a are the real optimal GPU parameters for a given |  X  S | and |  X  X | , and N is the total number of message passings in the training set. Practically, we exhaustively try all the small number of possible GPU configurations on GPUs to find K  X  and p  X  a
In this section, we address the following questions:
Data Statistics Regression Figure 7: GPU execution times for different parame-ter optimization methods both manual (0-threshold and 1-threshold) and regression (lasso and SVR).
 Optimization using SVR is best in all cases.

In Figure 4, 5 and 6, we plot three examples of statistical models emulating measured GPU execution time T r for the reduction step. In each figure, |  X  X | and |  X  S | are fixed and the GPU parameters K and p a change. These three exam-ples correspond to the three examples in Figure 2. In Figure 4, both SVR and lasso approximate the GPU time nicely. However, in Figure 5, neither SVR nor lasso approximate the GPU time well, because of an abrupt drop of GPU time when p a increases. However, a closer look shows that the minimum points of both the SVR and lasso models are lo-cated not far from the minimum point of the measured GPU time. In Figure 6, lasso approximates the GPU time better than SVR, but both statistical models X  minimum points are close to that of the real GPU execution time surface.
Table 3 shows the residual sum of squares (RSS), the squared deviance (SD) from the optimal value, and the miss rate (MR) of models. From the table, we see that GPU execution time for reduction is harder to emulate than scat-tering. This suggests that reduction is likely to be the bottle-neck of parallel message passing. Also from the table we see that even though SVR does not have the lowest miss rate, its squared deviance is the smallest for reduction. That is to say, even though SVR might have missed some optimal pa-rameters, its parameter choices are not much worse than the optimal. Thus we expect SVR to perform the best in thread allocation, which is illustrated experimentally in Table 4.
In this section we compare different GPU parameter set-tings and show that regression-based GPU parameter opti-mization can achieve much better performance than (exten-sive) manual parameter optimization. We use 0-threshold and 1-threshold parameter selection scheme, suitable for man-ual optimization, as benchmarks. In the 0-threshold param-eter setting, where there is no threshold on the mapping table size, we set K = 256 and q a = 16 for all the message passings throughout belief propagation. The 0-threshold parameter setting is perhaps the most straightforward and widely used GPU parameter selection scheme. A program-mer just sets a group of reasonable GPU parameters which do not change at run time.

In the 1-threshold parameter selection with threshold t 1 90, we still keep K = 256, but we set p a in the following way: where  X  X is the mapping table size. The rationale behind this 1-threshold parameter optimization is that in reduc-tion/scattering cases where there is a long mapping table (see Figure 1), there are many opportunities for arithmetic parallelism and therefore we should assign many threads (in (17), p a = 128). In cases where the mapping table is  X  X hort X , many threads should be assigned to element-wise parallelism, leaving  X  X ew X  to arithmetic parallelism (in 17, p = 4). In (17), t 1 = 90 is chosen as a reasonable threshold to differentiate short and long mapping tables.

In experiments, we used the SVR and polynomial-lasso models to select GPU parameter for each BP message pass-ing. Results are summarized in Table 4 and Figure 7. On average over all data sets, we get a speedup of 10.70x (arith-m etic average) or 8.68x (geometric average) as compared to that of 3.43x (arithmetic average) or 2.44x (geometric av-erage) achieved previously only using the element-wise par-allelism [18]. We also compare the parallel junction tree algorithm with SMILE, the improvement is still significant as shown in Table 4.

We highlight several points in Table 4: 1) Across the columns, we see that parallelism opportunity determines the GPU performance. The GPU in general performs well for data sets that have big cliques (which means more arithmetic parallelism) or big separators (which means more element-wise parallelism). For the data-sets that have neither big cliques nor big separators, such as  X  X unin2 X  and  X  X unin3 X , the GPU speedup is smaller. 2)Across the different statistical models, we see that SVR is best for all the data sets we have, which coincide with our observation for squared deviation from optimal value and miss rate in Table 3. Lasso(  X  = 0) is comparable to the 1-threshold parameter optimization; Lasso(  X  = 1 se ), with a severe punishment on model complexity, performs the worst of all. The difference between the best and worst statistical model parameter settings can be as large as 5-7x.
In this paper, we discuss a two-dimensional parallel al-gorithm for belief propagation over junction trees, and im-plement the algorithm on a GPU. Due to the great variety in clique and separator sizes in junction trees from applica-tions, the parallel opportunity for both dimensions of paral-lelism varies. Since the GPU performs best when the con-currency provided by the GPU matches the parallel oppor-tunity in the algorithm, it is necessary to carefully optimize the thread allocation for both dimensions of parallelism as well as for thread blocks. Experiments show a large dif-ference in GPU performance given different thread alloca-tions. Therefore, we use statistical models to approximate the parameter space, for the purpose of searching for opti-mal parameters. Among the models we used, SVR performs best, and outperforms manual GPU optimization. We show that our approach is an effective way to improve the GPU performance when seeking for fast junction tree belief prop-agation. [1] A. Basak, I. Brinster, X. Ma, and O. J. Mengshoel. [2] R. Bekkerman, M. Bilenko, and J. Langford, editors. [3] H. Drucker, C. Burges, L. Kaufman, A. Smola, and [4] W. D. Hillis and J. G. L. Steele. Data parallel [5] C. Huang and A. Darwiche. Inference in belief [6] H. Jeon, Y. Xia, and V. K. Prasanna. Parallel exact [7] K. Kask, R. Dechter, and A. Gelfand. BEEM: bucket [8] A. V. Kozlov and J. P. Singh. A parallel [9] S. L. Lauritzen and D. J. Spiegelhalter. Local [10] M. D. Linderman, R. Bruggner, V. Athalye, T. H. [11] Y. Low, J. Gonzalez, A. Kyrola, D. Bickson, [12] O. J. Mengshoel. Understanding the scalability of [13] V. K. Namasivayam and V. K. Prasanna. Scalable [14] NVIDIA. NVIDIA CUDA C programming guide. [15] U. of Pittsburgh. GeNIe and SMILE documentation. [16] M. Silberstein, A. Schuster, D. Geiger, A. Patney, and [17] Y. Xia and V. K. Prasanna. Node level primitives for [18] L. Zheng, O. J. Mengshoel, and J. Chong. Belief
