 This paper presents a system ( DanVideo ) that is implemented using J2SE and JMF to annotate manually the macro and micro features of the dance videos by the dance experts. As MPEG-7 has reached a matured state for the description of the multimedia structure and semantics through the Descriptors and Description Schemes, DanVideo generates a MPEG-7 instance that conforms to the MPEG-7 schema, semi-automatically and effortlessly from the dance annotations. J.5 [ Arts and Humanities ]: Performing arts; H.5.4 [ Information Interfaces and Presenting ]: Hypertext/Hypermedia. Management, Documentati on, Design, Languages. Multimedia applications; Agents; MPEG-7 MDS; Video annotation; Dance videos. Dance data are essentially multimedia by nature consisting of visual(dance steps), audio(music) and textual(lyrics of a song) materials. Also, dance steps of a song, song components like stanza and chorus and one line of lyrics of a song component abstract compound scene, scene and shot respectively. Dance videos exhibit rich semantics such as dance steps, spatio-temporal relationships between dancers, a nd emotion of dancers. The most challenging problem here is the se mi-automatic generation of the MPEG-7 instance document corre sponding to the annotations, such that the relevant semantics are consistent with the perception of the real world. In [1], Ricoh movie tool is used to segment a dance video into several shots and obtain their MPEG-7 descriptions. Then, the MPEG-7 descriptions of the shot s are further manually annotated with keywords. The important feat ures such as the character the dancer plays spatio-temporal relationships between the characters and settings are not considered. Some of the content modeling sc hemes use MPEG-7 standard to annotate the videos, such as IBM VideoAnnEx [2]. Semi Video Annotator is a module developed for annotating the macro and micro features of the dance steps of the song. The dance expert annotates the features manually by looking at the video clip that is running. Macro annotator describes the macro features initially. The set of semantics that are annotated are, the details of the dancers (such as ID, GivenN ame, PostalAddress, Telephone and Email), details of the musician (that are similar to dancers), music, song, accompaniments, background, tempo of the delivery of the dance steps( slow, medium or fast), dance origin, dance type, context(live, rehearsal, professional play, competition etc), date and time of recording and type of performance venue (like theatre, beach etc). The tree view of the visualizer interactively updates the selected annotations. The screen shot depicting the rendering of the dance and Macro annotator is shown in Fig.2. Micro annotator annotates the dance step specific features of every dance step of a song. Micro annotator annotates the semantics in the order: event, actor s(character roles) of this event, agents(body parts) of the actors and concepts(emotions) revealed by the actors. But, one can swap the annotation of agents and concepts depending on his interest. The tree view of the visualizer updates the extracted annotations concurrently. Micro annotator also describes the various rela tionships that exist among the events, actors, agents and concepts such as spatial, temporal, motion and semantic relationships. MPEG-7 Instance Generator genera tes MPEG-7 metadata for the dance annotations. It produces MPEG -7 elements in the form of XML documents using DDL which is an extended language of the XML Schema. DanVideo is not only a content modeling environment, with the interfaces that were developed for annotation, but also an appli cation for producing MPEG-7 xml output through the MPEG-7 Instance Generator. There is no need to use DDL to create new DSs and Ds, as the mapping of DanVideo annotations into MPEG-7 format can be performed with the existing DS tools. All th at needed is just choosing the appropriate schemes representi ng events, actors, agents and concepts. 
