 (referred to as the partial feedback or  X  X andit X  case).

Lower Bound
Upper Bound Efficient Algo N/A N/A Sometimes Yes Sometimes ? with what might be termed the price of bandit information  X  how much worse the regret is in the partial information case as compared to the full information case. exponentially worse than the full information case (as a function of K ). There are a number of issues that we must address in obtaining sharp convergence for the online obtain a sharp upper bound we need a new argument to get an upper bound that is stated only in terms of n and T (and we do this via a relatively straightforward appeal to Hedge ). mation case. Here, for the K -arm bandit case, the regret is O  X  ( est in the literature [Awerbuch and Kleinberg, 2004, McMahan and Blum, 2004, Dani and Hayes, results here [Awerbuch and Kleinberg, 2004, Dani and Hayes, 2006] are stated in terms of only n case [Gyorgy et al., 2007] in the literature where an O  X  ( poly ( n ) sult is for Path Planning (where D is the set of paths on a graph and n is the number of edges) O  X  ( poly ( n ) in particular, our algorithm has an expected regret that is O  X  ( n 3 / 2 are tight, up to log factors.
 feedback case is only worse by a factor of information case does exponentially better as a function of K .
 is only provided an upper bound on the regret of only O  X  ( n for the K -arm case (in the i.i.d. setting).
 with only this oracle access. However, as our algorithms use the Hedge algorithm of Freund and namic programming. Examples include problems such as Path Planning (for instance, in routing planning in AI. This idea has been developed by Takimoto and Warmuth [2003] and also applied Problems is relatively straightforward (based on dynamic programming). Table 1 (along with previous work). x t in D , which results in a loss of ` t = L ` (and not the vector L t ) is revealed.
 cumulative regret is defined by respect to the learner X  X  randomness). The lower bounds provided hold with high probability. the set { ~e 1 ...~e n } as the spanner . Note that with this assumption, k x k 2  X  poses of designing algorithms with sharp regret bounds, the following lemma shows that we need only concern ourselves with finite decision sets  X  the lemma shows that any decision set may be approximated to sufficiently high accuracy by a suitably small set (which is a 1 / within an additive 1 /  X  Since an admissible loss vector has norm at most see that the optimal loss for e D is within an additive can be implemented efficiently for these special cases. 3.1 With Full Information In the full information setting, the algorithm Hedge of Freund and Schapire [1997] guarantees a this gives us regret O  X  ( implementations are in fact possible, as discussed in the Introduction. However, it appears that that their regret is O ( n which leads to the O ( n 3.2 With Bandit Information We now present the Geometric Hedge algorithm (shown in Algorithm 3.1) that achieves low ex-use Hedge (with estimated losses) along with a  X  probability of exploration.
Algorithm G EOMETRIC H EDGE ( D, X , X  )  X  x  X  D,p 1 ( x )  X  1 | D | for t  X  1 to T round (motivated by Awerbuch and Kleinberg [2004]). The estimated losses we feed into Hedge non-singular. The following lemma shows why this estimator is sensible. Lemma 3.2. On each round t , b L t is an unbiased estimator for the true loss vector L t . where all the expectations are over the random choice of x t drawn from algorithm of Auer et al. [1998].
 the distributions p t and cases of interest, this can actually be implemented efficiently.
 We now state the main technical result of the paper.
 admissible loss vectors, let R denote the regret of Algorithm 3.1 on this sequence. Then  X  nT , the regret is O  X  ( n 3 / 2 online shortest path problem, then E R = O ( n 3 / 2 3.3 Analysis of Algorithm 3.1 the estimated loss vectors used by Algorithm 3.1.
 Lemma 3.4. For each x  X  D and 1  X  t  X  T , the estimated loss vector b L t satisfies corresponding (orthonormal) eigenvectors. Since C t := E and so It follows that the eigenvalues  X   X  1 1 ,... X   X  1 n of C  X  1 t are each at most n  X  . Hence, for each x where we have used the upper bound on the eigenvalues and the upper bound of instead of gains). We state it here without proof. Denote  X  M (  X  ) := e M X   X  1  X  M X  M 2 . b L ,..., b L T and the probability distributions p 1 ,...p T satisfy where M = n 2 / X  is an upper bound on | b L  X  x | .
 Before we are ready to complete the proof, two technical lemmas are useful. Lemma 3.6. For each x  X  D and 1  X  t  X  T , Proof. Using that E ( b L t  X  x ) 2 = x  X  E b L t b L  X  t x , we have Lemma 3.7. For each 1  X  t  X  T , This implies that x  X  C  X  1 t x = P i  X   X  1 i ( x  X  v i ) 2 . Using Equation 1, it follows that
X We are now ready to complete the proof of Theorem 3.3.
 Proof. We now have, for any x  X   X  D , X where the last step uses (1  X   X  ) p t ( x )  X  E " where we have used Lemmas 3.6 and 3.7 in the last step.
 where the inequality comes from that for  X   X  1 , e  X   X  1 +  X  +  X  2 . With the above, we have The proof is completed by noting that
E " is the expected total loss of the algorithm. 4.1 With Full Information We now present a family of distributions which establishes an  X ( most a factor of 2 .) and  X  1 otherwise. Set Let D S, X  denote the distribution of L .
  X (  X  according to D S, X  is the vector ( x 1 ,...,x n ) where x i =  X  1 if i  X  S and 1 otherwise. of loss vectors  X  e i (in case of a tie, the value of x i doesn X  X  matter).  X ( n (  X /n ) min { T,n/ X  2 } =  X (min {  X T,n/ X  } ) . Setting  X  = p n/T yields the desired bound. 4.2 With Bandit Information establish an  X ( n according to D S, X  is just the indicator vector for the set S .
 Suppose S is chosen uniformly at random. Unlike the proof of Theorem 4.2, we do not attempt to characterize the optimal algorithm for this setting.
 expected regret of  X (min {  X T,n 2 / X  } . Setting  X  = n/
