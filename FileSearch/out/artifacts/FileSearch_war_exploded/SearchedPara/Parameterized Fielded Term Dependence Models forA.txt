 Accurate projection of terms in free-text queries onto struc-tured entity representations is one of the fundamental prob-lems in entity retrieval from knowledge graph. In this pa-per, we demonstrate that existing retrieval models for ad-hoc structured and unstructured document retrieval fall short of addressing this problem, due to their rigid assumptions. Ac-cording to these assumptions, either all query concepts of the same type (unigrams and bigrams) are projected onto the fields of entity representations with identical weights or such projection is determined based only on one simple statistic, which makes it sensitive to data sparsity. To address this issue, we propose the Parametrized Fielded Sequential De-pendence Model (PFSDM) and the Parametrized Fielded Full Dependence Model (PFFDM), two novel models for en-tity retrieval from knowledge graphs, which infer the user X  X  intent behind each individual query concept by dynamically estimating its projection onto the fields of structured entity representations based on a small number of statistical and linguistic features. Experimental results obtained on several publicly available benchmarks indicate that PFSDM and PFFDM consistently outperform state-of-the-art retrieval models for the task of entity retrieval from knowledge graph.  X  Information systems  X  Structured text search; Entity Retrieval; Structured Document Retrieval; Feature-based Models; Learning-to-rank Models; Knowledge Graph  X  T he first two authors provided equal contribution.
Recent studies [16, 22] indicate that more than 75% of queries issued to Web search systems aim at finding infor-mation about entities, which could be material objects or concepts that exist in the real world or fiction (e.g. people, products, scientific papers, colors). Most common informa-tion needs underlying this type of queries include finding a certain entity (e.g.  X  X instein relativity theory X  ), a particu-lar attribute or property of an entity (e.g.  X  X ho founded Intel? X  ) or a list of entities satisfying a certain criteria (e.g.  X  X ormula 1 drivers that won the Monaco Grand Prix X  ). Such information needs can be efficiently addressed by presenting the target entity or a list of entities, either directly as search results or in addition to the ranked list of documents. This scenario gives rise to the problem of ad-hoc entity retrieval from knowledge graph, when the output of retrieval models is a list of entities given their (potentially verbose) textual description.

Recent successes in the development of Web information extraction methods have resulted in the emergence of a num-ber of large-scale publicly available and proprietary knowl-edge repositories, such as DBpedia 1 , Freebase 2 , Google X  X  Knowledge Graph and Microsoft X  X  Satori. All these reposi-tories adopt a simple knowledge representation model based on subject-predicate-object triples that can be conceptual-ized as a directed labeled multi-graph (commonly referred to as a knowledge graph), in which the nodes correspond to entities and the edges denote typed relations between enti-ties. This model makes knowledge graphs a natural choice for addressing different types of entity-centric information needs. However, since the structure of knowledge graphs has been optimized for automated reasoning and answering structured graph pattern queries, finding entities in knowl-edge graphs that conceptually match unstructured free-text queries presents certain challenges to existing retrieval mo-dels.

First, since entities in knowledge graphs are designated only by an identifier (e.g. machine ID /m/0jcx , in the case of Freebase, or URI http://dbpedia.org/page/Albert Einstein , h ttp://dbpedia.org http://freebase.com in the case of DBpedia), there is no notion of document in t his retrieval scenario. A simple workaround for this issue used in recent work is to aggregate the objects and pred-icates in all the triples, which include each distinct entity as a subject, into the fields of a structured document for that entity. Such aggregation can be done by predicate type [21], according to the importance weights manually assigned to predicates [6], based on a flat structure with fixed num-ber of fields (e.g. title and content [19] or entity name, at-tributes, categories, similar and related entity names [33]) or a two-level hierarchy, in which the first level corresponds to predicate types, while the second level corresponds to in-dividual predicates [18]. Accurately matching unstructured keyword queries with such structured entity representations, however, is another fundamental theoretical problem, which has received much less research attention.

In particular, existing retrieval models are based on a set of rigid assumptions, which limit their effectiveness for re-trieval of structured entity documents. On one hand, re-trieval models incorporating term dependencies, such as Se-quential Dependence Model [17] (which allows to assign dif-ferent importance weights to matching query concepts of dif-ferent type), Weighted Sequential Dependence Model (WSDM) [4] (which estimates the importance of each matching query concept individually) and retrieval model based on copulas [10] disregard entity document structure by considering the matches of the same query concept in different fields of en-tity documents as equally important. On the other hand, although existing models for ad-hoc structured document retrieval, such as the Mixture of Language Models (MLM) [20] and BM25F [23], factor in document structure when de-termining the degree of relevance of queries to documents, they do not take into account term dependencies (i.e. are agnostic to bigram query concepts). Furthermore, these mo-dels calculate the retrieval score of a structured document as a sum of the matching scores of each query term in a linear combination of the language models (LMs) for each document field. As a result, the field weights in this lin-ear combination, which effectively determine the projection of query terms onto document fields, are the same for all query terms. Although the recently proposed Fielded Se-quential Dependence Model (FSDM) [33] partially addressed this limitation by allowing different importance weights to the matches of a query concept in different fields of struc-tured entity documents, such parametrization still lacks flex-ibility, as those weights are the same for all query concepts of the same type (unigrams, ordered and unordered bigrams). This can create a problem, which is illustrated by an ex-ample query  X  X apitals in Europe which were host cities of summer Olympic games X  . First, contrary to the assumption of FSDM, query concepts of the same type in this query should be projected onto different fields of relevant entity documents (e.g.  X  X apitals X  should be mapped onto the cate-gories field, while  X  X urope X  should be mapped onto the at-tributes field). Incorrect projection of any query concept (e.g. mapping  X  X urope X  and  X  X lympic games X  to the entity names field) is likely to substantially degrade the accuracy of retrieval results for this query. Probabilistic Retrieval Model for Semistructured Data (PRMS) [14] is a unigram bag-of-words model for ad-hoc structured document retrieval that learns a simple statistical relationship between the intended mapping of terms in free-text queries and their frequency in different document fields. Robust estimation of this relation-ship, however, requires query terms to have a non-uniform distribution across document fields and is negatively affected by data sparsity, particularly in the case of entity represen-tations with a large number of fields. As a result, PRMS has inferior performance on entity retrieval tasks not only relative to FSDM [33], but also to both MLM and BM25F [2, 33].

To overcome the limitations of existing retrieval models, we propose the Parametrized Fielded Sequential Dependence Model (PFSDM) and the Parametrized Fielded Full Depen-dence Model (PFFDM), two novel feature-based retrieval models, which infer the user X  X  intent behind each individual query concept (unigram or bigram) by dynamically estimat-ing its probabilistic mapping onto the fields of structured en-tity representations using a small number of statistical and linguistic features. We also provide a learning-to-rank algo-rithm to learn the weights of these features that maximize the target retrieval metric from the training data. The key contributions of this work are as follows: 1. We proposed PFSDM and PFFDM, two novel feature-based models for structured document retrieval , which ac-count for sequential and full term dependencies as well as provide flexible parametrization allowing to dynamically project each query concept onto document fields. To the best of our knowledge, there are no previous studies of feature-based models for structured document retrieval, in general, and ad-hoc entity retrieval from knowledge graph, in particular; 2. We propose a set of statistical and linguistic features of query concepts that enable their accurate projection onto the fields of structured entity documents; 3. We experimentally demonstrate that, for the task of ad-hoc entity retrieval from knowledge graph, dynamic pro-jection of query concepts onto entity representations is more effective than dynamic estimation of their impor-tance. We also found out that retrieval models accounting for all dependencies between query terms provide more ac-curate retrieval results for this task than the models that account only for sequential dependencies.

The rest of this paper is organized as follows. Section 2 provides a brief overview of previous research along the di-rections relevant to the present work. Ranking functions of PFSDM and PFFDM, features to estimate the mapping of query concepts onto the fields of entity documents along with the method to learn the weights of those features are presented in Section 3. Experimental results are reported and analyzed in Section 4, while Section 5 concludes the paper and outlines the directions for future work.
In this section, we provide an overview of the recent work in ad-hoc entity retrieval from knowledge graph as well as term dependence and feature-based retrieval models, the three research directions most closely related to this work. Ad-hoc Entity Retrieval from Knowledge Graph .
 Every information access task involving knowledge graphs requires finding entities matching a keyword query, either as an intermediate step or a final goal. Entity retrieval meth-ods are typically designed to address one particular entity-centric information need, such as entity search [29, 32, 33], list search [7] or entity-based question answering [26, 31], and consist of two stages. Entities retrieved in the first stage of those methods using a standard retrieval model, such as B M25 [2, 29], BM25F [6, 11, 29] or MLM [18, 32], are re-ranked or expanded in the second stage with their immediate neighbors in the knowledge graph, which can be obtained us-ing SPARQL queries [29] or through random walk [24].
In particular, Tonon et al. [29] proposed a hybrid method combining IR and structured graph search that starts by re-trieving an initial set of entities using BM25 retrieval model and then extends it using SPARQL queries with the enti-ties that are directly related to the ones in the initial search results. Zhiltsov and Agichtein [32] proposed a learning-to-rank method for re-ranking the results of MLM using query term and structural entity similarity features calculated in la-tent space. The SemSets method [7] proposed for entity list search utilizes the relevance of entities to automatically con-structed categories (i.e. semantic sets) measured according to structural and textual similarity. This approach combines a basic TF-IDF retrieval model with spreading activation over the link structure of a knowledge graph and evaluation of membership in semantic sets. Sawant and Chakrabarti [25] proposed a learning-to-rank method for handling Web queries aimed at finding entities that belong to a particular category. Several approaches that translate free-text ques-tions into structured SPARQL queries have been proposed for question answering over linked data [26, 31]. The pro-posed retrieval models can be leveraged in the first stage of the above methods to improve their overall performance. Models designed specifically for ad-hoc entity retrieval can also be leveraged to obtain a set of entities related to a key-word query (a process known as entity linking [12]), which is an important step for the methods utilizing knowledge bases for query expansion in ad-hoc document retrieval [9, 15, 30].
Several entity representation schemes, in which the objects from RDF triples involving an entity are grouped into the fields of a structured entity document based on the predi-cates in those triples, have also been proposed [6, 18, 19]. In [6], objects are grouped into three fields based on manually designated predicate type (important, neutral, and unim-portant). A simple scheme, in which the entities are rep-resented as documents with two fields (title and content) was proposed in [19]. Experimental comparison of a struc-tured entity representation scheme based on four fields with an unstructured and more complicated hierarchical scheme indicated superior performance of a simple structured repre-sentation [18].

Term Dependence and Feature-based Retrieval Mo-dels . Markov Random Fields (MRF) based retrieval frame-work [17], proposed by Metzler and Croft, provided a the-oretical foundation for incorporating term dependencies (in the form of query bigrams and unordered two-word phrases) into retrieval models. Sequential Dependence Model (SDM), which only considers two-word sequences of query terms, and Full Dependence Model (FDM), which considers all possible two-word combinations of query terms, are the two most popular variants of the MRF retrieval models for ad-hoc document retrieval. Subsequent work along this direction [1, 8] demonstrated strong positive effect of accounting for query term dependencies and proximity on both ad-hoc and Web document retrieval.

SDM was later extended into WSDM by Bendersky et al. [4]. WSDM estimates the relative importance of query con-cepts as a linear combination of statistical features based on the frequency of occurrence of these concepts in the collec-tion and external resources. Superior retrieval performance of different variants of WSDM for ad-hoc document retrieval has been demonstrated through extensive experimental eval-uation in [13]. The utility of linguistic analysis for accurate processing of verbose queries in ad-hoc document retrieval has been demonstrated in [3]. While feature-based retrieval models have been shown to be effective for weighting con-cepts in verbose queries [4, 5], this work examines their ef-fectiveness for ad-hoc entity retrieval from knowledge graph.
In this section, we introduce the ranking functions of Pa-rameterized Fielded Sequential Dependence (PFSDM) and the Parameterized Fielded Full Dependence (PFFDM) re-trieval models, the features used by these models to deter-mine the projection of query concepts onto the fields of entity documents along with an algorithm to learn the weights of those features that maximize the target retrieval metric.
The quality of retrieval results for entity-centric free-text queries depends on the correctness of inference of implicit query structure and the accuracy of matching the intent be-hind each query concept with different aspects of semantics of relevant entities encoded in their structured representa-tions. However, the ambiguity of natural language can lead to many plausible interpretations of a keyword query, which combined with the requirement to accurately project those interpretations onto entity representations, makes entity re-trieval from knowledge graph a challenging IR problem.
PFSDM is a parametric extension of FSDM [33], a re-cently proposed MRF-based entity retrieval model, which takes into account both term dependencies and document structure . FSDM uses the following function to score each entity profile E with respect to a given keyword query Q : where  X  f T ( q i , E ),  X  f O ( q i , q i +1 , E ),  X  tential functions and  X  T ,  X  O ,  X  U are the relative importance weights for unigram, ordered and unordered bigram query concepts, respectively. The potential function for unigrams is defined as:  X  f ( q i , E ) = log w here F is the number of fields in structured entity docu-ments,  X  E j is the language model of field j in structured doc-ument for entity E smoothed using the field-specific Dirich-let prior  X  j ; | E j | is the length of field j in E and w the field weights for unigrams with the following constraints: P igram q i in field j of E ; cf q i ,j is the frequency of q field j across structured documents for all entities in the col-lection; | C j | is the total number of terms in field j across all entity documents in the collection. The potential function f or ordered bigrams is defined as:  X  f w hile the potential function for unordered bigrams is defined as:  X  f in field j of structured document for entity E , cf #1( q the collection frequency of q i q i +1 in field j and tf # uw is the number of times the terms q i and q i +1 co-occur within a window of n words in field j of E , regardless of their order.
In the case of entity descriptions with F fields, FSDM has 3  X  F + 3 parameters: F field mapping weights plus  X  T ,  X  and  X  U . We believe that this parametrization lacks the nec-essary degrees of freedom, which can potentially limit the accuracy of this retrieval model. We propose to address this issue by dynamically estimating w T q tion of each individual query unigram q i , and w O,U q relative contribution of each individual query bigram q i,i +1 that are matched in field j of structured entity document for E towards the retrieval score of this entity, as a weighted lin-ear combination of features: under the following set of constraints: X non-negative feature function for query unigram q i and bi-gram q i,i +1 in field j of entity document, respectively. w query unigram q i and bigram q i,i +1 onto the fields of struc-tured entity representations (to reduce the number of pa-rameters in the model, we set w O q determines this projection based on multiple features, unlike PRMS [14], which estimates it directly from the data based only on the total number of occurrences of a query term in a particular field across all documents in a collection. Feature-based estimation of this projection increases its robustness by overcoming the issues of sparsity and uniform distribu-tion of occurrences of a query concept across the fields of entity documents.

PFFDM is different from PFSDM in that it accounts for all dependencies between the query terms, rather than only sequential ones.
The features of different type that we propose to estimate the projection of a query concept  X  onto field j of structured entity representations are presented in Table 1. In particu-lar, PFSDM and PFFDM use two types of features: the ones whose value depends on a query concept and a field of entity representation and the ones that depend only on a query concept itself. The intuition behind also having the latter type of features is that the relation between them and the fields will be learned in the process of estimating their weights. For example, one can expect that the weight of a feature indicating whether a query concept is plural non-proper noun ( NNS ) will be higher in the categories field than in all other fields. For the features that depend on a field, one can expect that the value of the feature in that field will indicate the likelihood of a concept to be mapped to it. Nevertheless, we still learn the weights for these fea-tures, since: (1) ranges of values for particular features can be different in different fields and optimizing their weights is one of the ways to perform adequate scaling (2) contribution of the feature to the relevance of a field can be different for different fields.

Two of the features ( F P , T S ) depend on the collection statistics of a particular field. During optimization and re-trieval, these two real-valued features ( F P , T S ) were rescaled to [0 , 1] range. The F P feature was rescaled logarithmically. The other group of field mapping features ( NNP , NNS , JJS , NP P , NNO ) are binary and take particular values based on the output of Standford POS Tagger or Parser. NNP takes positive values for the query concepts that are proper nouns (e.g. entity names) and, thus, should be mapped to the names , similar entity names and related entity names fields. The NNS , NP P , and NNO features take positive values for the concepts that designate a broader class or type of the desired entities and, therefore, should be mapped to the categories field, while the JJS feature should project su-perlative adjectives to the attributes field. Constant feature ( INT ), which has the same value for all concepts, is known to be useful for mapping bigrams concepts.
In total, PFSDM and PFFDM have F  X  U + F  X  B + 3 parameters ( F  X  U + F  X  B feature weights as well as  X  T  X  O and  X  U ), where F is the number of fields, while U and B are the number of field mapping features for unigrams and bigrams, respectively. An efficient two-stage block opti-mization algorithm for learning the parameters of PFSDM and PFFDM with respect to the target retrieval metric is presented in Algorithm 1.
 Algorithm 1 A n algorithm for learning the feature weights in PFSDM and PFFDM. 1: Q  X  T rain queries 2: e U = { 1 , 0 , 0 } , e B = { 0 , 1 , 1 } 3: for s  X  X  U, B } do 4:  X  = e s 5:  X   X  s  X  CA ( Q,  X  ) 6: end for 7:  X   X   X  CA ( Q,  X   X  U ,  X   X  B )
In the first stage (lines 3-6), the algorithm optimizes field m apping feature weights  X  separately for unigrams and bi-grams. During optimization of the feature weights for un-unigrams, BG stands for bigrams).
 Collection statistics | w ) obtained through Bayesian inversion of Stanford POS Tagger 3 igrams, the feature weights for bigrams are not considered a nd vice versa. This is achieved by setting the corresponding  X  weights to 0. After the algorithm is finished with optimiz-ing the  X  weights, it proceeds to optimize the weights of MRF potential functions for different query concept types (  X 
T ,  X  O and  X  U in Eq. 1).
Experimental results reported in this work were obtained on a publicly available benchmark developed by Balog and Neumayer [2], which uses DBpedia as the knowledge graph. For fair comparison, we used the same five field entity rep-resentation scheme and the same query sets as in [33] (Sem-Search ES consisting primarily of named entity queries, List-Search consisting primarily of entity list search queries, QALD-2 consisting of entity-focused natural language questions, and INEX-LD containing a mix of entity-centric queries of different type). We pre-processed both entity documents and queries by applying the Krovetz stemmer and removing the stopwords in the INQUERY stopword list.
First, to evaluate the effectiveness of the proposed fea-tures, we performed an exploratory analysis of distributions of their values (for the features whose values depend on doc-ument fields) or frequencies of their occurrences (for the features whose values are independent of document fields) in different fields of entity representations. Specifically, we manually annotated each concept in all queries according to the user X  X  intent with respect to a particular aspect of target entities as an attribute concept, entity concept, re-lation concept, or type concept. Our intuition is that the attribute query concepts (e.g. when a user is searching for an entity attribute rather than an entity itself) should be h ttp://nlp.stanford.edu/software/tagger.html http://nlp.stanford.edu/software/lex-parser.html frequently occurring or have relatively higher feature val-ues in the attributes field of entity representations. Query terms or phrases marked as entity concepts (e.g. when a user is searching for a particular named entity) should be primarily occurring in the names and similar entity names fields, while the relation concepts (when a query is about a relation between the two named entities) should be primar-ily occurring in the similar entity names and related entity names fields of entity representations. Finally, query con-cepts marked as type (when a query is about several entities with the same type) should be frequently occurring or have relatively greater feature values in the categories field. Figure 1 visualizes the distributions of values of the Field Probability ( F P ) and Top Score ( T S ) features for the query concepts of different types in different fields of structured en-tity representations. As can be observed in Figure 1 (left), the median values of the F P feature for the query concepts of type entity in all three entity fields ( entity names , simi-lar entity names and related entity names ) are significantly greater than the median values of the same feature for the query concepts of the same type in both the attributes and categories fields. The median values of the F P feature for the query concepts of type attribute in the attributes and cat-egories fields are significantly greater than the median values of the same feature for the query concepts of the same type in all three entity fields. Furthermore, for the type and relation query concepts, the median values of the same feature in the categories and related entity names fields, respectively, are significantly greater than the median values of this feature in all other fields. It can also be observed in Figure 1 (right), that the median values of the T S feature for the query con-cepts of type entity in the similar entity names and related entity names fields are significantly greater than the median values of the same feature for the query concepts of the same type in all other fields. Furthermore, the median values of the T S feature for the type and attribute query concepts in the attributes field are greater than the median values of the same feature in all other fields.

To formally validate these observations, we conducted sta-tistical significance tests. In particular, the Kruskal-Wallis types in different fields of entity documents.
 feature values in different fields of entity documents. test [27] indicated that the null hypothesis of the F P and T S feature values having the same median in different fields of entity representations for all concept types should be re-jected ( p &lt; 0 . 05). Following the Kruskal-Wallis test, we performed a multiple comparison test (kruskalmc), which be-sides confirming the above empirical observations, indicated other statistically significant differences in feature values. In particular, the values of the T S feature for the query con-cepts of type relation in the related entity names field are different from its values in the categories and all three en-tity fields. This test also indicated that for all concept types the values of the F P feature in all three entity fields ( entity names , similar entity names and related entity names ) are significantly different from the values of the same feature in both attributes and categories fields, which in turn are sig-nificantly different from each other for the query concepts of type relation .

Figure 2 visualizes the distributions of normalized frequen-cies of query concepts with negative and positive values of the features that do not depend on a field in different fields of structured entity representations. Examining the prop-erties of these distributions for concepts with positive and negative feature values in the same field as well as across different fields can give us an intuition about whether the concepts having positive values for a particular feature are more likely to occur in certain fields of entity representations than in the others. This in turn can give us an insight about whether certain linguistic properties of query concepts are in-dicative of the user X  X  intent with respect to the projection of those concepts onto specific aspects of relevant entities. As follows from Figure 2, the query concepts that are superla-tive adjectives ( JJS is true) much more frequently occur in the attributes field and are very likely to designate the at-tributes of relevant entities; plural non-proper unigrams and bigrams ( NNS is true), bigrams ( NP P is true) or singular non-proper nouns ( NNO is true) that are part of a noun phrase are more likely to represent the categories of rele-vant entities, while singular or plural proper nouns ( NNP is true) more frequently occur in three entity fields, than in any other field of entity documents and, thus, typically the performance of FSDM [33]. designate the target entities directly. These observations in-dicate that entity-centric keyword queries have an implicit structure, with each element in that structure designating a particular aspect in multi-fielded representation of relevant entities.
To determine the combination of features, which results in the best performance of PFSDM and PFFDM, we conducted a feature selection study. First, we determined the combi-nations of only unigram and only bigram features (using simplified versions of PFSDM that consider only unigrams or bigrams, respectively), which result in the best retrieval performance in terms of MAP (target retrieval metric). In particular, we identified 6 most effective unigram and 7 most effective bigram feature sets. Then we evaluated the perfor-mance of PFSDM using each possible combination of uni-gram and bigram feature sets to determine the best perform-ing combined feature set. Retrieval effectiveness of different feature combinations for PFSDM is illustrated in Figure 3. As follows from Figure 3, most feature combinations result in higher MAP than FSDM. PFSDM achieves the highest MAP of 0.240 in conjunction with F P , NNS , NNP features for unigram query concepts and T S , NNS , NP P features for bigram ones. The weights of these features that result in the highest MAP of PFSDM are presented in Table 3.
From Table 3, it follows that the learned feature weights are similar to the distribution of frequencies of manually marked up query concept types across the fields of struc-tured entity representation.
Retrieval accuracy of PFSDM and PFFDM using the best feature combination is compared with that of state-of-the-art retrieval models for ad-hoc document (SDM [17] and WSDM [4] with cf and df features) and structured docu-ment (BM25F [23], PRMS [14], MLM [20] and FSDM [33]) retrieval in Table 2. Parameters of both the proposed re-trieval models and the baselines have been optimized using 5-fold cross validation (except PRMS, which does not require optimization).

Several important conclusions can be made based on the results in Table 2. First, WSDM shows minor improvement and, on some query sets, is even worse than SDM, which indi-cates that feature-based query concept importance weight-ing is less effective for entity retrieval than for document retrieval. On the other hand, dynamic feature-based estima-tion of relative importance of matching query concepts in different fields of entity documents provides significant im-provement of retrieval accuracy on verbose queries, such as the ones in QALD-2 query set. Second, the relatively small difference in performance between PFSDM and FSDM on SemSearch ES and ListSearch query sets can be explained by the fact that all concepts in those query sets map to only a few fields. In particular, most concepts in SemSearch ES queries map onto the entity field, while most concepts in ListSearch queries map onto the categories and attributes fields. In such cases, estimating field mapping degenerates to estimating relative importance of matching concepts in a particular field of entity representation, which nullifies the advantages of PFSDM. We can also observe that tak-ing into account all dependencies between query terms can partially mitigate this problem, as evidenced by superior performance of PFFDM on both ListSearch and INEX-LD query sets. Third, although it can be seen that PFSDM achieves improvement over FSDM in terms of MAP, MRR and NDCG@5 at the expense of decreased P@10, taking into account all dependencies between the query terms al-lows PFFDM to achieve consistent improvement over both FSDM and FFDM in terms of all retrieval metrics.
 Table 4 compares the retrieval accuracy of PFSDM and PFFDM with the same baselines on the knowledge graph from the 2009 Billion Triple Challenge (BTC-2009). This kn owledge graph consists of 1.14 billion RDF triples and contains entities from other knowledge bases besides DB-pedia. For this experiment, we used the queries from the Entity Search (ES) track of 2010 5 and 2011 6 Yahoo! Sem-h ttp://km.aifb.kit.edu/ws/semsearch10/ http://km.aifb.kit.edu/ws/semsearch11/ between PFFDM and FFDM.
 Search Challenge and publicly available relevance judgments for those queries 7 . We used the same 5-field entity represen-tation scheme for this knowledge graph, as we did for the DB-pedia one. As can be seen in Table 4, PFSDM and PFFDM demonstrate significant and consistent improvement relative to PRMS, as well as FSDM and FFDM, respectively.

From Figures 4a and 4b, it also follows that parameter-izing the field importance weights in PFSDM and PFFDM results in more improved topics and greater magnitude of im-provements than using static weights in FSDM and FFDM.
Next, we provide a brief qualitative analysis of sample queries illustrating the strengths and weaknesses of PFSDM and PFFDM. The ability to map query concepts of the same type onto different fields of entity documents allows PFSDM to promote the correct entities for verbose and question queries. For example, for the query  X  X ho produces Orang-h ttps://github.com/nzhiltsov/YSC-relevance-data ina? X  , PFSDM returns the correct result A.G. Barr at the top, unlike FSDM, which ranks it as the 18th result. For this query, PFSDM correctly assigns higher weights to the matches of the query term produce in the attributes (0 . 49) and categories (0 . 41) fields, of the query term Orangina in the related entity names field (0 . 55) and of the bigram pro-duce Orangina in the categories (0 . 45) field, unlike FSDM, which uses the same field weighting scheme (0 . 40 for at-tributes , 0 . 20 for categories , 0 . 30 for related entity names and 0 . 10 for similar entity names fields) for all query un-igrams. The correct field mapping weights for these query concepts are determined by the F P and NNP features. The same effect was observed for the query  X  X ho is the governor of Texas? X  . PFSDM promoted Rick Perry , the only correct answer for this query, from the second to the first position by boosting the matches of query concepts governor (cap-tured by the F P and NNP features) and governor Texas (captured by the T S feature) in the categories field.
Another type of queries with the highest relative MAP gain of PFSDM over FSDM are list search queries, such as  X  Give me a list of all American inventions X  (from 0.032 to 0.232),  X  X om Hanks movies where he plays a leading role X  (from 0.073 to 0.181) and  X  X ive me all companies in Mu-nich X  (from 0.114 to 0.252). For the first query, PFSDM promotes the correct entities Aberdeen Chronograph , Lisp programming language by boosting their matching scores in the categories field, while FSDM ranks The Heroic Age of American Invention , a science book for children, as the high-est entity, by not taking into account the absence of an im-portant term invention in its categories field.

We also observed that the common causes of PFSDM fail-ures are assignment of uniform field weights to query con-cepts and a lack of concept statistics. For example, for the query  X  X ive me all people that were born in Vienna and died in Berlin X  , PFSDM underestimates the importance of rela-tively rare concepts Vienna and Berlin , but overestimates the importance of very popular concepts born and die . The issue can be addressed by using a minimum support match-ing strategy or by introducing additional features.
In this paper, we proposed two novel models for ad-hoc en-tity retrieval from knowledge graph, which account for term dependencies and perform feature-based projection of query concepts onto the fields of entity documents. By demonstrat-ing the possibility of inferring implicit structure of keyword queries using linguistic attributes and simple field statistics of query concepts, the proposed models constitute an impor-tant step in the evolution of models for structured document retrieval. We hypothesize that the proposed models can be effective in other structured information retrieval scenarios, such as product and social graph search, and leave verifica-tion of this hypothesis to future work.
 This work was partially supported by the subsidy from the government of the Russian Federation to support the pro-gram of competitive growth of Kazan Federal University and by the Russian Foundation for Basic Research (grants # 15-07-08522, 15-47-02472).
