 Topic-focused multi-document summarization has been a challenging task because the created summary is required to be biased to the given topic or que ry. Existing methods consider the given topic as a single coarse unit and then directly incorporate the relevance between each sentence and the single topic into the sentence evaluation pro cess. However, the given topic is usually not well-defined and it consists of a few explicit or implicit subtopics. In this study, the re lated subtopics are discovered from the topic X  X  narrative text or docu ment set through topic analysis techniques. Then, the sentence re lationships agains t each subtopic are considered as an individua l modality and the multi-modality manifold-ranking method is proposed to evaluate and rank sentences by fusing the multiple modalities. Experimental results on the DUC benchmark datasets show the promising results of our proposed methods. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing  X  abstracting methods ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing  X  text analysis General Terms : Algorithms, Experimentation, Performance Keywords: Topic-focused multi-document summarization, topic analysis, multi-modality manifold-ranking Topic-focused (or query-based) multi-document summarization aims to create from a document set a summary which answers the need for information expressed in a given topic or query. Topic-focused summarization has dr awn much attention in recent years and it has been one of the main tasks in recent Document Understanding Conferences (DUC). Topic-focused summary can be used to provide personalized news services for different users. In a Question/Answering system, a question-focused summary is usually required to answer the information need in the issued question. As compared with generic multi-document summarization, the challenge for topic-focused multi-document summarization is that a topic-focused summary is not only expected to deliver the important information contained in the whole document set as much as possible, but also is expected to guarantee that the information is biased to the given topic. Therefore, we need characteristic during the summarization process. To date, a variety of methods have been proposed for topic-focused multi-document summarization by incorporating the topic information into the process of sentence evaluation and selection [1, 5, 6, 8, 9, 10, 11]. For example, graph-based methods have been recently exploited for topic-focused multi-document summarization [8, 9, 10]. The gra ph-based methods fi rst construct a granularities and then evaluate the topic-biased saliency of the sentences based on the graph. Wan et al. [8] have used the basic manifold-ranking algorithm for topic-focused multi-document summarization by considering the topic as a single query unit. And Wan et al. [9] further use the two-modality manifold-ranking algorithm for extracting topic-focused summary by considering the within-document sentence relati onships and the cross-document sentence relationships as two sepa rate modalities (graphs). Almost all the methods consider the given to pic or query as a single coarse unit and then directly evaluate and incorporate the relevance between each sentence and the single topic. However, the given few explicit or implicit subtopics (or aspects). These subtopics are comprehensive and vivid descripti ons of the coarse topic. The subtopics can be extracted explicitly from the topic X  X  narrative text or implicitly from the document set. We believe that it will benefit subtopics. In this study, we propose a novel graph-based summarization method to make use of the multiple subtopics in a multi-modality learning process. First, the related subtopics for a given topic/query are discovered from the topic X  X  narrative text or the document set through different topi c analysis techniques. Second, the sentence relationships against each subtopic are considered as an individual modality, and we propose the more general multi-modality manifold-ranking algorithm to evaluate and rank the sentences by fusing the multiple modalities. Two fusion schemes are proposed for fusing the multiple modalities, i.e. the linear fusion scheme and the score combination scheme. Experiments have been performed on the DUC2005 and DUC2006 benchmark datasets, and the results demonstrate that the proposed multi-modality learning methods outperform the baseline manifold-ranking methods. Both the two fusion schemes are effective. The proposed summarization method c onsists of three steps: topic analysis, sentence ranking and sentence selection. The step of topic analysis aims to discove r the related subtopics from the given topic description or the docu ment set. The step of sentence ranking aims to make use of the discovered subtopics to better evaluate the topic-biased saliency of the sentences by exploiting the multi-modality manifold-ranking algorithm. The step of sentence selection aims to sele ct both highly salient and novel sentences into the summary as in [8], by penalizing the sentences highly overlapping with other informative sentences, whose details will be ignored in this paper due to page limit. A DUC topic usually consists of a title and a narrative text. The title is usually a short phrase c oncisely describing the focused object that the users have interest in. The narrative text is a further description of the title, and it usually reflects a few aspects of the object. The title and the narrative text together describe the information need to which the su mmary should be biased, and the narrative text is much more detailed than the short title. In this study, two topic analysis methods are employed for discovering subtopics related to a given topic. By analysis of the narrative text , we can discover a few subtopics related to the given topic. The subtopics discovered directly from the narrative text are called explicit subtopics , and the explicit subtopic discovery is very similar to complex question decomposition in question answering systems. In this study, our aim is not to decompose the given topic into all possible subtopics at a very fine granularity as in question decom position. Instead, we take a straightforward algorit hm by simplifying the syntactic question decomposition method in [2, 3, 4]. The algorithm first splits the narrative text into sentences and then applies heuristic syntactic rules to split each compound sentence into simple sentences by using conjunctions (e.g. and , or ) or punctuations. Each simple sentence is used as a subtopic. In the DUC dataset, the narrative text for each DUC topic has already been provided by NIST a nnotators. However, in practical applications, we cannot require users to input the long narrative text to explain their information need. The users often issue only a most search engines. Therefore, in real applications, the only representation of each given topic is its title. In this study, we will investigate this real circumstance . The problem is how to discover the related subtopics from the title and the document set. Such subtopics are called implicit subtopics . We adopt the clustering techniques for implicit subtopic di scovery from the document set. We first collect all sentences in the document set that share some terms with the title, and then Group the sentences into a few clusters by applying the k-means clustering algorithm, where the cluster number is hard to predict a nd we simply set it to the square root of the sentence number. Finall y we sort the clusters by size and use several largest clusters as subtopics and then use the central term vector of each cluster to represent the corresponding subtopic. Given the discovered subtopics, we consider the sentence relationships against e ach subtopic as an i ndividual modality, and thus we have multiple modalities based on multiple subtopics. We believe that it will benefit the sentence ranking process at the finer And we propose the multi-moda lity manifold-ranking algorithm for sentence ranking by extending the manifold-ranking algorithms text and image ranking in [7, 13].  X  , where the first point x 0 represents the given subtopic (query point) and the rest n points represent all the sentences in the document set (data points to be ranked). Let relationships for the n +1 data points, where W ij similarity value if x i or x j is x 0 , otherwise, W similarity value between x i and x j against the subtopic x defined as follows: where respectively. term in term in combination of two sources: the original sentence similarity and the topic-biased similarity.  X  is a weighting parameter to specify different weights to the two sources and we simply set  X  =0.5. Note that we let W ii =0 to avoid self loops. matrix with ( i , i )-element equal to the sum of the i-th row of W . Assume we have discovered total m subtopics for the given topic, constructed in the k-th modality based on the k-th subtopic. In total, there are m matrix tuples {( W { k } , D { k } , S { k } In addition, we let R f  X   X  : denote a ranking function which assigns to each point x i (0  X  i  X  n ) a ranking value f a vector f =[ f 0 ,..., f n ] T . We also define a prior vector y =[ y the remaining points that we want to rank. With the above notation, the multi-modality learning task is to infer the ranking function f from W {1} , ..., W { k } S learning task, where 1) if two points ( x i and x similar by any S k , they should receive similar ranking values in f ( f points, its ranking value f i should be as consiste nt as possible with the initial value y i . learning schemes for fusing the multiple modalities based on different optimization strategies. This scheme is the most intuitive method for fusing the multiple modalities. It first computes the ranking score by using the basic manifold-ranking algorithm in each individual modality, and then linearly combines all the ranking scores into the final scores. For the k-th individual ranking process, we use f { k } ranking function in this process, and the cost function associated with f { k } is defined to be 1 where  X  [0,1) ,  X  (0,1] are the regularization parameters and we have  X  +  X  =1. The first term and second term of the right-hand side constraint , respectively. The above equation can be re-written in a more concise form as follows: manifold-ranking algorithm: According to [12, 13], the ranking values can be obtained by iterating the following computation until convergence: The theorem in [13] guarantees that the sequence { converges to Although * } { k f can be expressed in a closed form, for large scale problems, the iteration algorithm in Equation (5) is preferable due to computational efficiency. After we obtain the ranking scores of sentences in each modality, the final ranking function f * is defined as follows: where  X  k [0,1] is the combination weight and we have In this scheme, the regularization parameter  X  for the fitting constraint is fixed at 0.01, as in [7, 12, 13].  X  normalized cosine similarity value between the subtopic representation and the whole document set. This scheme fuses the constraints from S {1} ,..., S simultaneously by a weighted sum. The cost function associated with f is defined to be: 
W ) ( } { refers to the ( i , j )-th element in matrix W refers to the j -th element in vector f { k } . where  X  1,...,  X  k ,...,  X  m,  X  capture the trade-off between the constrains, usually we have 0  X   X  1,...,  X  k ,...,  X   X  +...+  X  k +...+  X  m +  X  = 1. The first terms of the right-hand side in the cost function are the smoothness constraints for the multiple modalities, and the last term is the fitting constraint , respectively. The above equation can be written in a more concise form as follows With the above optimizat ion criterion, the optimal ranking function f is achieved when Q ( f ) is minimized: Similar to [12], solving the above optimization problem by differentiating Q ( f ) defined by Equation (9) with respect to f leads to the following optimal ranking function f * : In practice, the following iterative form is more preferable than the above close form to get the ranking function f * : And we have ) ( * lim t In this scheme, the regularization parameter  X  for the fitting constraint is fixed at 0.01, the same as in [7, 12, 13]. Therefore, we value between the subtopic representation and the whole document set. Topic-focused multi-document summarization has been the main task on DUC2005 and DUC2006, so we used the two DUC datasets for evaluation in this study. We used the ROUGE-1.5.5 toolkit for evaluation, which was officially adopted by DUC for automatic summarization evaluation. In this study, we show three ROUGE F-measure scores in the experimental results: ROUGE-1 (unigram-based), ROUGE-2 (bigram-based), and ROUGE-W (based on weighted longest co mmon subsequence, weight=1.2) In the experiments, the proposed multi-modality manifold-ranking methods with the score combination scheme and the linear fusion scheme are denoted as  X  X ultiMR-COM X  and  X  X ultiMR-LIN X , respectively. Because the multi-modality learning algorithms rely on the subtopic discovery algorithm s, we combine each subtopic discovery algorithm with each learning algorithm. Therefore, there are total four multi-modality summarization methods. For example, We used the  X -l 250 X  and  X -m X  options in the ROUGE toolkit. we use  X  X ultiMR-COM(Explicit) X  to denote the summarization method using the explicit subtopic discovery algorithm for discovering subtopics and then using the score combination scheme for multi-modality ranking. manifold-ranking method (i.e.  X  X  ingleMR X ) [8] and the recent two-modality manifold-ranking methods (i.e.  X  X woMR-COM X  and  X  X woMR-LIN X ) in [9] 3 . All the three manifold-ranking the single topic, without using t opic analysis. We also show the baseline. Tables 1 and 2 show the comparison results on DUC2005 and DUC2006, respectively. In the tables, S4-S31 are the system IDs of the top performing systems. Seen from the tables, the proposed multi-modality learning methods with different fusion schemes and different subtopic discovery algorithms all outperform the basic manifold-ranking method a nd the advanced two-modality manifold-ranking methods. The results demonstrate that the subtopics are more appropriate for evaluating the biased informativeness of the sentences than the original coarse topic. manifold-ranking methods outperform the top performing systems on the DUC2005 dataset, and they achieve comparable performance with the best performing systems on the DUC2006 dataset. The  X  X ultiMR-LIN(Explicit) X  method outperforms the top performing systems on both datasets. The results demonstrate the effectiveness of the proposed methods, as compared with many other summarization methods. The TwoMR-COM and TwoMR-LIN methods correspond to the 
MultiMR(COM) and MultiMR(LIN) methods in [9], respectively. Note that the term  X  X ulti-modality X  in [9] actually means  X  X wo-modality X . This work was supported by NSFC (60873155), RFDP (20070001059), Beijing Nova Program (2008B03), National High-tech R&amp;D Program (2008AA01Z421) and NCET (NCET-08-0006). [1] H. Daum X  and D. Marcu. Bayesian query-focused summarization. In [2] S. Harabagiu, A. Hickl and F. Lacatusu. Satisfying information needs [3] B. Katz, G. Borchardt and S. Fe lshin. Syntactic and semantic [4] F. Lacatusu, A. Hickl, S. Harabagiu. Impact of question [5] V. Nastase. Topic-driven multi -document summarization with [6] Y. Ouyang, S. Li, W. Li. Developing learning strategies for [7] H. Tong, J. He, M. Li, C. Zh ang and W.-Y. Ma. Graph based [8] X. Wan, J. Yang and J. Xiao. Ma nifold-ranking based topic-focused [9] X. Wan and J. Xiao. Graph-Ba sed Multi-Modality Learning for [10] F. Wei, W. Li, Q. Lu and Y. He. Query-sensitive mutual [11] J. Zhang, X. Cheng, G. Wu, and H. Xu. AdaSum: an adaptive model [12] D. Zhou, O. Bousquet, T. N. Lal, J. Weston and B. Sch X lkopf. [13] D. Zhou, J. Weston, A. Gretton, O. Bousquet and B. Sch X lkopf. 
