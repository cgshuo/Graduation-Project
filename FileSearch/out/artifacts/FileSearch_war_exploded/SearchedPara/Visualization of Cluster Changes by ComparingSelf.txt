 In today X  X  fast-moving world, organizations need knowledge of change so that they can quickly adapt their strategies. If an organization has devised marketing strategies based on a clustering of the past year X  X  customer data, it is important to know if the current year X  X  clustering differs from the last, in order to review, and perhaps revise, those strategies. Knowing what has changed, particularly if this has not been discovered by competitors, would be a major advantage [1]. user must be able to relate the new clustering result to the previous one. It is difficult simply to compare cluster centroids obtained by a using a k -means technique X  X articularly if the number of clusters has changed X  X r to compare dendrograms obtained by hierarchical clustering algorithms. This is particularly problematic if the organization has already implemented a strategy based on an earlier clustering result. If users cannot relate new clustering results to older ones, it is difficult to revise existing strategies. Therefore, methods that can relate and contrast new clustering results with earlier ones are needed. viduals between clusters, the introduction of new clusters, and the disappearance of clusters. We introduce Self-Organizing Map (SOM) based techniques that can reveal structural cluster changes in two related data sets from different time periods in a way that can explain the new result in relation to the previous one. Change mining, in general, can be categorized as change point detection, or change mining via the comparison models obtained via data mining. In change point detection, finding the time points at which something changed is more im-portant than discovering the causes of the changes. Approaches to change point detection include fitting segmented models [2], where change points are defined as the points between consecutive segments. This has been applied to traffic data. Another approach is to compare values estimated using a learned model to actual observations [3], where large moving-average deviation is interpreted as evidence of change. This has been applied successfully to stock market data. to the approach we presented. Since a data mining model is designed to capture specific characteristics of the data set, changes in the underlying data sets can be detected by comparing the models learned from the data sets [4]. In the field of association rule discovery (ARD),  X  X merging patterns X  have been defined as rules the supports of which increase significantly from one data set to another [5]. Others have compared decision trees learned with two related data sets. Several C4.5-based variants of this technique have been introduced [6].
 changes in map structure, and changes in the mapping of data vectors. A dis-similarity measure for two maps has been proposed, based on the expected value of distances between pairs of representative data points on both maps [7]. This approach can determine how much two maps differ, but it cannot pinpoint the differences. The similarity between two data sets in terms of a SOM can be shown using data hit histograms [8], that show the frequency with which data vectors are mapped to nodes. This can indicate changes in the data mapping, but it is difficult to interpret these simply by comparing the data hit histograms. If a vector is mapped into a dense area of the SOM, a small change in the data may cause it to be mapped to a different node. In a spare area, however, the same magnitude of change might not cause a different mapping. Another drawback is that it cannot identify the origin of the  X  X igrants X  in the previous map. A SOM is an artificial neural network that performs unsupervised competitive learning [9]. Importantly, SOMs allow the visualization and exploration of a high-dimensional data space by non-linearly projecting it onto a lower-dimensional manifold, most commonly a 2-D plane [10]. Artificial neurons are arranged on a low-dimensional grid. Each neuron has an n -dimensional prototype vector, m i , also known as a weight or codebook vector, where n is input data dimensionality. Each neuron is connected to neighbouring neurons, determining the topology of the map. In the map space, neighbours are equidistant.
 adjusting the prototype vectors accordingly. The prototype vectors are initialized to differing values, often randomly. The training vectors can be taken from the data set in random order, or cyclically. At each training step t , the BMU (Best Matching Unit) b i for training data vector x i , i.e. the prototype vector m j closest to the training data vector x i , is selected from the map according to Equation 1: The prototype vectors of b i and its neighbours are then moved closer to x i : where  X  ( t ) is the learning rate and h b i j ( t ) is the neighbourhood function (often Gaussian) centered on b i . Both  X  and the radius of h b i j decrease after each step. SOMs have been shown to cope with large, high-dimensional data sets. prototype vectors and the sequence of training vectors [10]. Various training runs with the same data can produce rotated or inverted maps, since node indices are not related to initial prototype vector values. 3.1 Clustering of SOMs Clustering is often used to simplify dealing with the complexities of real, large data sets. For example, it may be easier to devise marketing strategies based on groupings of customers sharing similar characteristics because the number of groupings/clusters can be small enough to make the task manageable.
 direct clustering and two-level clustering (hybrid). In direct clustering, each map unit is treated as a cluster, its members being the data vectors for which it is the BMU. This approach has been applied to market segmentation [11]. A disadvan-tage is that the map resolution must match the desired number of clusters, which must be determined in advance. In contrast, in two-level clustering the units of a trained SOM are treated as  X  X roto-clusters X  serving as an abstraction of the data set [12]. Their weight vectors are clustered using a traditional clustering technique, such as k -means, to form the final clusters. Each data vector belongs to the same cluster as its BMU. Adding an extra layer simplifies the clustering task and reduces noise, but may yield higher distortion. We now propose training and visualization techniques that allow cluster changes such as migration of individuals between clusters, the introduction of new clus-ters, and the disappearance of clusters to be detected and interpreted. 4.1 Training the Maps We consider two data sets, the first containing data from period t and the second data from period t + 1. For maps trained using different data sets to be compa-rable, their orientations must be the same. As seen in  X  3, this is sensitive to the initial values of the prototype vectors and the sequence of training vectors. To preserve the orientation of the map, some data points can be mapped onto fixed coordinates in map space [10]. However, this can distort the map, so that it does not follow the distribution of the data set. This approach thus cannot be used to detect changes in cluster structure. Consequently, we propose a joint method to preserve the orientations of the maps. First, a map trained with the first data set is used as the initial map for the second. The orientation of the second map will thus match that of the first. Secondly, batch, rather than sequential, training is used: all training vectors are presented to the map and the prototype vectors are updated  X  X imultaneously X  using averages. There is thus no sequence of training vectors that can change map orientation during training. In summary: 1. Normalize both data sets using the same techniques and parameters 2. Initialize a SOM for the first data set 3. Train the SOM using the first data set 4. Initialize a SOM for the second data set using the trained first SOM 5. Train the second SOM using the second data set 6. Map data vectors from each data set to the trained maps 7. Cluster both maps using the k -means clustering algorithm.
 Since k -means is sensitive to the initial cluster centroids and can get trapped in local minima, multiple runs of k -means are performed and the optimal result is chosen for each number of clusters. The optimal clustering result for different numbers of clusters is selected using the Davies-Bouldin index [13]. 4.2 Visualizing Changes in the Maps It is not possible to compare the prototype vectors of the maps based on unit location in map space, since a given unit might be represent a different part of the data space in each map. This can be caused by SOM sensitivity or a change of data distribution. Other techniques are needed for linking the maps. Linking the Maps Using Colours. The units of the second map can be labelled in terms of the units in the first. The units of the first map are labelled using indices from 1 to n , as shown in the left map in Figure 1. For each prototype vector x in the second map, the BMU of x in the first map is found, and the unit labelled using the index of the BMU, as shown in the right map in Figure 1. The second map can thus be explained in terms of the first map.
 can be used as a basis for others. Rather than using the index of the BMU in the first map, its colour can be used. For example, if the first map is coloured using a different colour for each cluster, as shown in the top-left map in Fig-ure 2, the second map, as shown in the top-right map, can be coloured using this technique.
 Visualizing Changes of Cluster Structure. Three map visualizations are produced, as shown in Figure 2. The first (top left) illustrates the clustering result of the first map, acquired using two-level clustering. The second (top right) is a visualization of the second map in terms of the first clustering result, i.e. the second map coloured using the cluster borders of the first map in the data space. The last (bottom right) is a visualization of the independent clustering result of the second map.
 If the cluster area becomes larger in the second map, it means that more data is assigned to that cluster in the second data set than in the first. For example, in Figure 2, the light green cluster shrank, the blue cluster grew, and the magenta cluster almost vanished in the second data set.
 clustering result of the second map visualized using of the clustering result of the first. However, since both visualizations are based on the same map, the units are linked by position. These maps are not linked by colours, as the independent clustering result have a different number of clusters or different cluster colours. In Figure 2, it can be seen that the second map has only three clusters: the magenta cluster from the first data set has indeed vanished.
 Two types of data set were used in these experiments. Synthetic data sets were used to evaluate the ability of the proposed technique to visualize known cluster changes, such as migration of individuals between clusters, the introduction of new clusters, and the disappearance of clusters. Experiments on these data sets showed that the proposed approach can reveal changes of distribution, detect new clusters, and indicate the disappearance of clusters. Full descriptions of these experiments can be found in [14].
 World Bank was used to test the approach using real-world data. The WDI data is multi-variate time-series data with 574 indicators covering 205 countries, from 1960 to 2003. This experiment clustered countries based on selected indicators that reflect different aspects of development. Cluster changes from one period to another period were then visualized.
 indicators are not recorded for every year, since this would not be cost-effective. Secondly, the same indicator might be recorded at different years for differ-ent countries; therefore, comparing year-by-year is not possible. Moreover, some countries started recording the indicators later than others. In fact, some coun-tries did not record some indicators at all.
 selected based on the work of Kaski and Kohonen [15] and the Millennium Development Goal of the United Nations 2 . This set of indicators was then filtered based on the availability of the indicators in terms of the missing values described earlier. The resultant set of indicators is shown in Table 1.
 training, since it may disturb the ordering process [15]. Therefore, the several strategies were used to handle missing values. Yearly values were grouped for 10-year periods, and latest available value available used. Indicators with missing values for more than 1 / 3 of the countries in the chosen periods were removed. Since some countries start recording late, or did not record some indicators at all, countries for which more than 1 / 3 of the values are missing in all periods were removed from the training data set. Further details of this preprocessing can be found in [14].
 the most complete and recent data sets. Country names were replaced with 3-digit ISO 3166 country codes 3 for visualization purposes. This research was implemented using SOM Toolbox 4 ,MATLAB,andMSAccess. Figure 3 shows the mapping of 1980s data points onto the 1980s map. If countries are mapped nearby, they have similar characteristics, in this case similar devel-opment status. For example, the bottom-right corner consists of OECD (Orga-nization for Economic Co-operation and Development) and developed countries, such as the United States of America, Australia, and Japan.
 1980s map (Figure 4, top right), shows that the blue cluster in the bottom-left corner of the 1980s map disappeared, while the magenta cluster grew. magenta region consists of the OECD countries. Since the magenta region grew in the 1990s map, it can be said that more countries in the 1990s had similar development status to that of OECD countries in the 1980s.
 Argentina, Nicaragua, and Peru. Figure 5 shows the mapping of the countries from the 1990s data set onto the first map. In this map, the new locations of these countries can seen: all have moved towards OECD countries, except Nicaragua that has moved towards African nations. In the 1980s, these countries were suffering economic difficulties due to debt crisis X  X his period is known as the  X  X ost decade X  for many South American countries. However, South America was the world X  X  second fastest-growing region between 1990 and 1997 [16]. This explains the missing cluster in the 1990s.
 and real-world data sets. The results show that they can reveal lost clusters, new clusters, and changes in the size of clusters. The methods can explain the new clustering result in terms of the previous clustering results. If there is a new cluster in the second data set, one can detect which cluster this new cluster came from in the first data set. can show changes in the data distribution in terms of the previous clustering. It can indicate if clusters disappear, but cannot show new clusters.
 of the first map is not easy, since they are not linked. However, the visualization of the second map in terms of the clustering of the first map can be used to relate the independent clustering of the second map with the clustering result of the first map. This comparison can reveal new or missing clusters. one can experiment with any number of clusters, without having to recluster the whole data set. Only the SOM prototype vectors need to be clustered. The proposed SOM-based visualization methods are capable of revealing various types of cluster changes in two related data sets from different time periods. They are capable of explaining the clustering result of the second data set in terms of the clustering result of the first data set, by using colour and positional linking. They can show structural changes such changes in distributions, new clusters, and missing clusters. Experiments using a real-world data set have shown that the methods are capable of indicating actual changes such as the the change in economic fortunes of South American countries between the 1980s and 1990s.
