 Vehicle trajectories are one of the most important data in location-based services. The quality of trajectories directly affects the ser-vices. However, in the real applications, trajectory data are not always sampled densely. In this paper, we study the problem of recovering the entire route between two distant consecutive loca-tions in a trajectory. Most existing works solve the problem with-out using those informative historical data or solve it in an empirical way. We claim that a data-driven and probabilistic approach is ac-tually more suitable as long as data sparsity can be well handled. We propose a novel route recovery system in a fully probabilistic way which incorporates both temporal and spatial dynamics and addresses all the data sparsity problem introduced by the proba-bilistic method. It outperforms the existing works with a high ac-curacy (over 80%) and shows a strong robustness even when the length of routes to be recovered is very long (about 30 road seg-ments) or the data is very sparse.
 Trajectory; route recovery; spatio-temporal; location-based services
With the development of GPS devices, more and more trajectory data are generated every day which brings the bloom of Location-Based Services (LBSs) [21]. To improve the quality of service, most, if not all, applications prefer a large volume of data with zero uncertainty. However, most of the data in the real world have uncer-tainty. Consequently, recovering the routes of uncertain trajectory data can help enhance the utility of data and reduce the uncertainty which can improve the performance and service quality of those trajectory-data-driven applications.

Route recovery is an important building block for many real-life applications, and we list two scenarios where route recovery could make an impact. i) According to a statistical analysis on the GPS data collected from 10,000+ taxis by [19], more than 60% taxi trajectories are in low sampling rate (e.g., a GPS point every 2+ minutes) and reducing the uncertainty of those low sampling rate trajectories is an urgent issue. ii) Digital cameras and sensors installed in the roads are able to capture certain information of ve-hicles with high accuracy but those devices are still not universal. Route recovery can help to recover the trajectories passing by roads without devices installed.

In the literature, there are several works related to route recov-ery and they can be categorized into two groups, non-data-driven approaches without relying on historical data [5, 9, 12, 13, 19], and data-driven approaches that are based on historical data [3, 16, 20]. Non-data-driven approaches recover the routes according to geometric properties of digital map. They utilize certain exter-nal properties of road networks (e.g., the turning count, length and number of lanes) as the cost and return the optimal route having the minimum cost. These approaches model the cost empirically with-out any guarantee on the effectiveness as they have no historical data to infer from. Data-driven approaches recover the routes by leveraging historical data. A typical approach of finding the most popular route is introduced in [3], which is applicable to the route recovery problem, under the assumption that people tend to use the route that most people prefer. [16] tries to calibrate trajectories to some anchor points. If we use turning points as the anchor points, we can also apply the complementary component of this approach to solve route recovery problem. Another example is presented in [20], which finds the candidate routes through dynamic program-ming based on route popularity. To the best of our knowledge, this approach, as the state-of-the-art solution directly designed for route recovery problem, makes a comprehensive usage of historical data and outperforms many existing approaches.

We also adopt a data-driven approach to tackling route recovery problem, because data-drive approaches can draw more informa-tive inference than geometric-based approaches, as stated in [20]. In addition, we propose to solve the problem from a probabilistic view instead of an empirical view. Empirical approaches solve the problem by intuition while probabilistic approaches can guarantee the effectiveness of solutions via sound theoretical models.
However, building a probabilistic model based on historical tra-jectory data will definitely suffer from data sparsity. It is well-known that more than 80% of the traffic in a typical city runs on only 10% to 20% of the roads hence the trajectory data are ex-pected to be sparse. Besides, as mentioned before, given a set of trajectories, the volume of high sampling rate data based on which a probability model will be built is often much smaller than that of low sampling rate data. Inferring the probability distribution (e.g., the transition probability between roads) is essential for ev-ery probability model, which can be addressed by traditional sta-tistical frequency-based approaches. However, when the data are sparse and the volume of data is insufficient, directly counting the road frequency will result in a poor estimation according to the theory of probability. Moreover, as it is guaranteed that some roads are less frequent with insufficient trajectories passing by, missing value problem is also expected. Thus, how to address data sparsity issue will be the main challenge that our approach needs to address. Note that we will explain different types of data sparsity that route recovery has to address in details in Section 4 when we present our solution.

We summarize the key points to the route recovery problem in the following. 1) The approach should be data-driven. 2) The approach should be fully based on probability. 3) The approach should take care of the data sparsity problem. To our best knowl-edge, none of the existing works fulfills these three conditions si-multaneously.

Motivated by this, we propose a novel route recovery system fully based on probabilistic models. Our system incorporates both temporal dynamics and spatial dynamics according to the theoret-ical probabilistic derivation and addresses all the challenges intro-duced by the data sparsity mentioned above. We include in our sys-tem a temporal model and a spatial model as the key components. The temporal model aims to estimate the travel time of a candidate route to quantify the likelihood of the candidate route being the an-swer. Our spatial model estimates how reasonable a candidate route is via inverse reinforcement learning that can learn the latent cost (reward) of a road through historical data. To summarize, we make three main contributions in this paper.

Non-Empirical Approach : We study the problem in a prob-abilistic view and incorporate both spatial and temporal dynamic with the theoretical probabilistic derivation.

Data Sparsity Solution : We propose multiple strategies to ad-dress the data sparsity problem. Our temporal model includes a new regression model to estimate the travel time of temporal-sparse trajectories, and also proposes a static-temporal separation matrix factorization approach to deal with data sparsity; the spatial model adopts inverse reinforcement learning to solve the data sparsity problem against traditional statistical frequency-based approach.
Large Improvement : We conduct extensive experiments using real taxi trajectories to demonstrate both the effectiveness and the robustness of our system when facing data sparsity issue. The re-sults show that our system largely outperforms existing approaches. It achieves a high accuracy consistently (over 80%), even when the pair of GPS locations are far away from each other (e.g., about 30 road segments apart) while other approaches can only achieve an accuracy about 40%.
Many existing works [12, 13, 22] adopt shortest path to return a route with minimum weight. [22] is based on geometric and topo-logical information of the road network; [12] defines the cost as a heuristic cost function which is related with the delay of traffic lights and left turns; [13], as an extension of [12], uses the same cost function to build a candidate graph and finds the path with as many straight lines as possible. These approaches fail to capture the preference of drivers when choosing a route, as many drivers select roads not based on whether roads are straight or not but based on the traffic condition. Differently, our system can capture the spatial dynamics by learning from historical trajectories. Map matching algorithms for low-sampling rate trajectories are proposed in [8, 19]. Although these approaches have also used the concept of tran-sition probability, they only use this probability as a factor in a score function but the real frameworks are still empirical-based. In brief, they are all non-data-driven approaches, and the probabilities are empirically set.

On the other hand, some existing works including [5, 7, 16, 20] adopt model-based approaches to solve the route recovery. [5] in-fers the route between two GPS samples by a binary logit model utilizing hidden Markov model. However, the performance of this model deteriorates when there are more than two candidate routes. [7] uses absorbing Markov chain model to synthesize routes for low sampling trajectories. Although it is a probabilistic approach, it suffers from the problem of data sparsity, as it counts the frequency in historical data to estimate the transition probability between two states. [16] constructs the transition matrix without considering the destination information which is fatal in the route recovery prob-lem. Besides, it needs to enumerate all the possible paths which makes the computation cost extremely high when the route to be recovered is long. [20] constructs the traverse graph from histori-cal trajectories and finds the optimal route in the graph via dynamic programming. This approach deals with data sparsity but the whole framework is empirically designed. As an contrast, each compo-nent of our system is designed with the guarantee of probability while taking great care of data sparsity. Besides, the query process of our system is optimized to support online search.
We first present the formal definitions of road network , route and trajectory as following.

D EFINITION 1(R OAD N ETWORK ). A road network is mod-eled as a directed graph G ( V,E ) , where V refers to the set of vertices (i.e., crossroads) and E refers to the set of edges (i.e., road segments). We assume each edge r  X  E is from a vertex v  X  another vertex v  X  V , where r.s = v and r.e = v represent the source and the end of the edge respectively, r.s  X  r.e refers to the direction, and r.len is the length of the edge r .

D EFINITION 2(R OUTE ). A route R is a list of adjacent road segments, r 1  X  r 2  X   X  X  X  r m , where each two consecutive road segments are connected in G , i.e., r i .e = r i +1 .s . We use denote the i-th road segment in R .

D EFINITION 3(T RAJECTORY ). A trajectory Tr is a sequence of GPS positions with timestamps, i.e, Tr = { ( p 1 ,t 1 ) , ( p  X  X  X  , ( p n ,t n ) } , where p i in the form of ( x i ,y i ) captures the lati-tude and longitude of the i -th GPS position and t i is the timestamp.
D EFINITION 4(M AP M ATCHING ). Map matching is a pro-cedure to match the trajectory Tr to a route R . R ( p i ) returns the road segment to which point p i is mapped.

When the sampling rate is low, two continuous GPS sample points p , p 2 might be mapped to two road segments r 1 , r 2 that are not adjacent (i.e., r 1 .e = r 2 .s ). In other words, the moving object must pass certain unknown road segment(s) after r 1 but before r Figure 1 as an example. Given a trajectory Tr = { ( p s ,t both routes R 1 and R 2 are possible. In this paper, we study the problem of route recovery defined in Problem 1, which locates the route R  X  that has the highest possibility of being taken by a given trajectory Tr . Note that although we focus on the recovery of the route between two consecutive locations, the techniques developed can be easily extended to recover the route passed by several con-secutive locations in a sparse sampled trajectory.

P ROBLEM 1(R OUTE R ECOVERY ). Given a set of (high sam-pling rate) historical trajectories T and a road network G , the route recovery query takes two GPS positions with timestamps (i.e., ( p ,t s ) and ( p e ,t e ) ) as input, and tries to recover the real route from p s to p e that is passed by Tr as accurate as possible. Note that there is no restriction that p s /p e can only be the source/destination of a trajectory, any two consecutive positions in a trajectory are le-gal to be the input.
In this section, we introduce a novel system as our solution to perform Route Recovery , namely S patio-T emporal-based R oute Re-covery S ystem ( STRS ). STRS consists of three main components, preprocessor , spatio-temporal model and route search engine ,as shown in Figure 2.

Preprocessor performs preprocessing of trajectories, including map matching and trajectory temporal partitioning. Spatio-temporal Model , as the essential part of STRS , tries to learn and model prop-erties of routes from historical data via a probability approach. This component contains two separate models, i.e., the spatial model and the temporal model . Route Search Engine computes the pos-terior probability of a candidate route which can be regarded as the score of a route and returns a route with the highest score.
The main objective of system STRS is to solve the route recovery problem via a pure probabilistic approach. To facilitate following discussion, we summarize the main notations used in this paper in Table 1. Given a start GPS position p s with its timestamp t an end GPS position p e with its timestamp t e , the route recovery problem is equivalent to find the route R  X  with the highest posterior probability w.r.t. the input information, i.e., where T is the set of historical trajectories and  X  t = t on Bayes X  theorem,
P ( R| p s ,p e ,t e ,  X  t, T ) = P ( R ,p s ,p e ,t e ,  X  t, T ) /P ( p s ,p e ,t e ,  X  t,  X  P ( R ,p s ,p e ,t e ,  X  t, T ) = P ( X  t |R ,p s ,p e ,t e , T )  X  P ( R| p s ,p e ,t e ,  X  P ( X  t |R ,p s ,p e ,t e , T )  X  P ( R| p s ,p e ,t e , Since P ( p s ,p e ,t e ,  X  t, T ) and P ( p s ,p e ,t e , ities of input information, they can be regarded as constants. In the following, we omit the notation T in all the representations of probabilities for presentation clarity.

Based on Equation (1), we understand that the posterior consists of two probabilities, the time interval likelihood part P ( X  t p ,t e ) and the time interval-invariant posterior part P ( The former describes how likely the time interval will be if route and t e is the end time; the latter quantifies the existence prob-ability of R if the route starts from p s and ends in p e
The preprocessor of STRS performs two processes, map match-ing and temporal partitioning . We first adopt map matching al-gorithm to get the ground truth of historical data, i.e., the actual route. We consider all the trajectories that can be mapped to routes without uncertainty as useful historical samples. E.g., according to [10], when the sampling rate is 1  X  30 s per point, map matching can achieve an accuracy about 99%, indicating that these trajecto-ries can obtain the ground truth route without uncertainty.
It is known that the properties of historical trajectory data may vary over time [1]. This observation motivates us to partition the trajectories based on the temporal dimension. We then introduce a parameter  X  which determines the temporal duration within when the trajectories shall be gathered into one class. By default, we set  X  to 60 minutes in our experiments. Accordingly, there are 48 parti-ing day and T 25 , T 26 ,  X  X  X  , T 48 corresponding to weekends. For those trajectories crossing multiple time slots, we distribute them according to the time slot which t e is in. The effects of different time slot granularity will be studied in Section 5.3.1.
As introduced previously, spatio-temporal model is the essential component of STRS . Recall that Equation (1) consists of two prob-abilities, i.e., P ( X  t |R ,p s ,p e ,t e ) , and P ( R| p mer is to model the likelihood of the time interval that is taken care by the temporal model and the latter is the posterior of a route re-gardless of time information  X  t which accounts for a spatial model to model existence of the route.
In the following, we introduce our temporal model to model the likelihood P ( X  t |R ,p s ,p e ,t e ) . The key is to model the distribu-tion of the observed time interval  X  t , conditioned by a candidate route R ,given p s and p e under time slot  X  ( t e ) , where  X  ( t to the time slot that end time stamp t e falls in. Intuitively, the dis-tribution will be strongly correlated with the expected time of  X  ( t e ) , i.e., the closer  X  t and the expected time of R are, the higher the likelihood will be. The connection between the expected time and the distribution will be further demonstrated in Section 4.3. To be more comprehensive, we call the expected time as estimated time (denoted as  X  t E ) to emphasize that we want to perform esti-mation on the time cost of a candidate route R , which is achieved by two steps, including Regression Estimation Model and Static-dynamic-separation Matrix Factorization , as detailed below. Regression Estimation Model. This step is to estimate the time taken by a given R in time slot  X  ( t e ) through historical trajectories. There are several existing works on solving the travel time estima-tion. Most of them can be categorized into road segment-based and route-based . However, both categories face some problems in sup-porting route recovery. Road segment-based approaches, e.g., [4, 15], first estimate the average speed and then get the time cost of individual road segment. The travel time of a route is the summa-tion of the time cost of road segments passed by the route. These approaches face issues when the speed is not available or the sam-pling rate is not high enough. Take p 1 and p 2 in Figure 3 as an example. The ratio of the total travel distance between p to the time interval does not provide a good estimation of the travel speed as the route passes two junctions and it is very likely that the speed varies. However, this sample is a useful historical trajectory. Although the corresponding road segment of p 1 and p 2 , i.e., r r , are not adjacent, it is still easy to infer that r 2 should be in-cluded in the route. On the other hand, route-based approaches, e.g., [1, 11], collect the same routes in the historical dataset and return their mean time cost as the answer. This kind of approaches can avoid estimating the speed thus they can address the problem faced by road segment-based approaches. However, they face sig-nificant data sparsity problem. Note that data sparsity is severe in route recovery as the number of historical routes that are same as R presented in  X  ( t e ) could be very small or even zero. In other words, although route-based approaches have better performance, they are not applicable in route recovery due to the small number of historical routes that are same as R presented in  X  ( t brid approach that combines both road segment-based and route-based approaches is proposed in [18]. It estimates the time cost of individual driver which is over-grained and will deteriorate the data sparsity problem. Hence, we propose an approach to combine these two types of approaches by a regression model to solve the data sparsity problem.
The main idea of our solution is that we adopt a road segment-based approach to estimate the total time cost of a route and employ a route-based approach to train the time cost of each road segment by minimizing the error of the estimation in historical data. As we intend to consider the time spent on the crossroads, notation r de-notes not only road segments but also crossroads , which is different from its original meaning used in Definition 2. For simplicity, we name r sas road elements .

In detail, we first construct a matrix H X  R |T  X  | X  ( m + n ) m and n refer to the total number of road segments and crossroads respectively. H i  X   X  R m + n denotes the i th row of H and resents each historical training sample. For each historical route R ( i ) processed from T  X  (for simplicity, in this section we use  X  to indicate  X  ( t e ) ), we construct each training sample based on follow-ing criteria. We use superscript with parentheses, e.g., ( i ) , to index the training sample. Note that R ( i ) [1] and R ( i ) [ k first and the last road segment of R ( i ) with corresponding length k H Here, dist G ( a, b ) refers to the network distance from a to b via road network G , and proj ( p, r ) refers to the projection position of a point p on the road segment r . We represent a historical route R ( i ) by setting the element of H i  X  to 1 corresponding to the road segments passed by R ( i ) . Note that although a route is represented by a set of complete road segments, the training input representa-tion H i  X  is different. As the start position p ( i ) s and the end position p e may lay on the middle of the road segment, elements in H of length within the road segment passed by the trajectory. Equa-tion (2) gives out the criteria for road segments and for crossroads we set corresponding elements in H to 1 if the crossroad is passed by
For all of the training data, we set the cost function as the squared error between the estimated travel time and the observed time in-terval as Equation (3). The first component represents the error in a matrix form, where  X  T =( X  t (1) ,  X  t (2) ,  X  X  X  ,  X  t ( |T  X   X   X  R m + n . Note that  X   X  ( j ) is the estimated time cost spent on r in time slot  X  . Because the value of  X   X  may be odd in some road segments as it can be set to any value to fit the training data, we add the second component to restrict the solution so it can only vary around a given value, i.e.,  X   X  .  X   X  denotes a rough estimation of the time cost, which is estimated by the road segment-based ap-proach. Although this estimation is not accurate, we can infer that the actual time cost of each road segment shall be not too far from this estimation. Moreover, we also exert a regularization on  X  further avoid over-fitting.

C (  X   X  )=
We use stochastic gradient decent (SGD) [2] to train the model and the gradient can be computed by:
After training  X   X  for each individual time slot, we combine them together in column-wise, i.e.,  X =(  X  1  X  2  X  X  X   X  48 )  X  R ( m + n )  X  48 Note that in order to achieve low variance, we train the road ele-ments with the number of historical trajectories passing by larger than certain support count (5 in our experiment). Besides, as the dataset will further be partitioned into 48 time slots and we under-stand that 80% of the traffic in a typical city runs on only 10% to 20% of the roads, a new data sparsity problem emerges. Actually, after the training, an incomplete time cost matrix  X   X  with some el-ements being null is generated and we will visualize the missing elements in Section 5.3.2.
 Static-dynamic-separation Matrix Factorization. This step is to infer the value of missing elements in the cost matrix  X  to other elements. We assume the time cost of a road element con-sists of two costs, including a static cost and a temporal-dynamic cost , as presented in Equation (4). Static cost models the time cost that is influenced by the explicit features of the road element, such as the length of the road, the degree of a crossroad and so on. This cost is invariant over time. The temporal-dynamic cost captures the dynamic cost which varies over time.
 where  X  s ,  X  t  X  R ( m + n )  X  48 .  X  s is the static time cost ma-trix and ( X  s ) ij denotes the static time cost of road element i in time slot j . As the static time cost matrix is temporal-invariant, ( X  s ) i 1 =( X  s ) i 2 =  X  X  X  ( X  s ) i 48 . We factorize it into FW where F  X  R ( m + n )  X   X  is the feature matrix of all road elements and  X  denotes the number of explicit features. The i th row F i the features of r i . The road segment features used in our system include i) the length of a road segment; ii) the level of the road seg-ment (e.g., highways, parkways); and iii) the number of POIs near the road segment; while the features of crossroads used in our sys-tem are i) the degree of the crossroad; ii) the number of POIs near the crossroad; and iii) the average level of the road segments that are connected to the crossroad. W  X  R  X   X  48 is the weight matrix which is to be trained, with stacking 48 equivalent weight vectors w s in the column-wise, i.e., W =( w,w,  X  X  X  ,w ) .
 X  t  X  R ( m + n )  X  48 is the temporal-dynamic cost matrix and ( X  denotes the temporal-dynamic cost of r i in time slot j . We factor-ize  X  t into two low rank matrices, i.e.,  X  t = R  X  . We propose a latent road element factor matrix R  X  R ( m + n )  X  , where each row of R , i.e., R i  X   X  R  X  1 , represents the latent factors of road segment r i and denotes the dimension of latent factors. Similarly, we introduce a latent temporal factor matrix  X   X  R 48  X  with each row  X  j  X   X  R  X  1 representing the latent factors w.r.t. time slot j . Figure 4 illustrates the factorization.

By approximating the incomplete matrix  X   X  based on Equation (4) and reconstructing the cost matrix according to learned W , R and  X  , we can fill in the missing elements in  X   X  . The cost function is the square error between the reconstructed elements and the elements.
Here, M indicates not-null elements in  X   X  and it is a 0-1 matrix satisfying that M ij =0 if  X   X  ij is null and 1 otherwise. The gradient is computed as follows:
We can optimize the cost function by gradient-based optimization methods [2]. After learning the weight matrix W and two latent factor matrices R and  X  , we can reconstruct the complete time cost matrix according to Equation (4) and estimate the travel time of a route by constructing H i  X  according to Equation (2) and perform inner product to the  X  th column of  X  , i.e.,  X  t E = H i detail of how to use the estimated time to model the probability P ( X  t |R ,p s ,p e ,t e ) will be introduced in Section 4.3. Why data sparsity can be solved. i) For those sparse-sampled his-torical trajectories, although the route segment-based estimation is inaccurate, our regression model can leverage the time information of the entire path to adjust the cost of road elements to minimize the estimation error of routes. ii) For the sparsity of identical routes, we perform the final estimation through a road segment-based view to avoid the sparsity of historical routes. iii) For the sparsity of missing values in the matrix, matrix factorization enables the infer-ring of the missing value based on other values, and we separate the static cost which can even work for the roads without any car passed by in any time slot.
The spatial model is to model P ( R| p s ,p e ,t e ) without consid-ering the time interval  X  t . Since this probability is only relevant to the start position p s and the end position p e with respect to the time slot  X  ( t e ) , we can observe that it only depends on the spa-tial influence under the dataset of T  X  ( t e ) . For clarity of formulas, we omit the conditional variable t e or T  X  ( t e ) in the following dis-cussion. Recall that in Section 4.2.1 notation r denotes both road segments and crossroads, here we just change back the notation, i.e., r refers to only road segments now. Suppose R consists of k road segments, P ( R| p s ,p e ) can be equally represented as
Markov assumption is often adopted on the driving behavior to facilitate the modeling [7, 10, 21]. A straightforward approach to model the transition probability is to perform the statistic. where N is the count of historical trajectories starting from and ending in R ( p e ) while passing R [ i  X  1]  X  X  [ i ] . N is the count of trajectories starting from R ( p s ) and ending in R ( p ing R [ i  X  1] . However, this naive method suffers from a data spar-sity problem. To be more specific, for some R ( p e ) , we might not be able to find many trips that pass R [ i  X  1] and are ended in If N is not large enough, the estimation of the transition probability can be largely affected by randomness. The effects of data sparsity when using this frequency-based approach to compute the transi-tion probability will be illustrated in Section 5.3.3.
 Markov Decision Process and Reinforcement Learning. In our system, we adopt a better model to address the data sparsity prob-lem. The decision process that makes each decision based on Markov property can be modeled as a Markov Decision Process (MDP) [17]. An (deterministic) MDP is a tuple ( S, A,  X , ) , where S is state set of the system, A is the action set ,  X   X  [0 , 1] is a discount factor , and is the reward function where ( s ) denotes the re-ward at state s . An MDP works as following. It starts at some state s with reward ( s 0 ) and performs an action and the state of sys-tem transits to s 1 with collecting reward ( s 1 ) . It continues until it reaches the goal. Making decision at certain state is irrelevant to all of the previous states, i.e., Markov property. Reinforcement learning is a learning algorithm in AI to make an optimal decision with maximized expected rewards in the future [17] in an MDP. This model is similar to making decision in the crossroads when driving. We can regard each road segment r as a state and the tran-sition r i  X  r j between two adjacent road segments as action. The reward of each state is the negative latent cost of each road as the larger the cost is, the smaller the reward will be. Specifically, given an MDP, reinforcement learning can be performed to figure out the best policy of each state. Optimal Value function V  X  ( s ) defines the maximum reward the agent can get in the future if the current state is s , i.e., V  X  ( s ) = arg max Note that the reward of each state is often set to a negative value and the reward of the destination/goal is set to 0 to avoid perform-ing MDP infinitely through a ring. Besides,  X  is often empirically set between 0.95 to 1.0 (0.95 in our experiments) to exert an dis-count on the future. Q-function is a function S  X  S  X  R with the definition that Q ( r i  X  r j | )= ( r i )+  X V  X  ( r j ) . It is not hard to find that Q ( r i  X  r j | ) means that the reward can be received in the future if the agent makes the decision by transferring from current state r i to another state r j . According to [14], the transition probability from r i to r j can be modeled as:
The larger the future reward is if the agent decides to drive from r to r j , the larger the probability to make a decision from r be. Z i is the normalization coefficient to ensure it is a probability.
As the reward (negative latent cost) is unavailable, if we can learn through historical routes by maximizing the likelihood or posterior using Equation (7), we can derive all the transition proba-bilities between any two adjacent road segments. This draws our attention to inverse reinforcement learning (IRL) . Therefore, we adopt Bayesian inverse reinforcement learning (BIRL) [14] to han-dle this task, because BIRL has fewer hyper-parameters, easy im-plementation, and quick convergence. The main idea of BIRL is to compute the mean of the posterior distribution of the reward as the answer, given observations O which is the set of historical routes.
 The likelihood part P ( R ( i ) | ) is the simple production of Equa-tion (7) w.r.t. each two adjacent road segments in a historical route R ( i ) . We choose uniform distribution to be the prior of . [14] proposes PolicyWalk to get , which is a Markov Chain Monte Carlo method designed for high dimension parameters. Briefly speaking, the sampler first starts from a random initial value of and then samples a new drawn uniformly at random from the neighbors of current with distance no more than the step  X  , i.e., with probability min 1 , P ( |O ) P ( |O ) . The mean of last few samples drawn from the Markov chain will be returned as the answer when the Markov chain converges. Please refer to [14] for the details of PolicyWalk and BIRL.
 Why Data Sparsity Can Be Solved : Unlike frequency-based ap-proaches, IRL aims to fit the whole historical routes by assigning rewards of each state (road segments). The likelihood of each ob-servation is not only based on the reward of the next status but also considers the whole rewards towards the destination, i.e., the Q-function. Consequently, the entire preference towards the desti-nation will be taken into consideration which is different from the edge-centric approaches that only count the ratio of transition be-tween two consecutive edges. Thus, for those roads that are passed by a very small number of historical trajectories, IRL will assign the feasible rewards to those roads so the model can generate the historical data as likely as possible.
The last component accounts for locating the result of a route recovery query. It searches the routes that start from p s p in the road network. For each candidate route R , it computes the posterior probability of R according to Equation (1). The route with the highest posterior is returned as the answer. In the follow-ing, we first explain how to compute the temporal and spatial proba-bility in Equation (1) by our novel spatio-temporal model proposed in Section 4.2, and then present how to perform the search. Compute P ( X  t |R ,p s ,p e ,t e ) . At the first glance, one may tend to assume the distribution of the time interval of a route P ( X  t R ,p s ,p e ,t e ) follows a Gaussian. However, [6] claims that the dis-tribution of the time does not follow a Gaussian. Instead, the distri-bution of the speed does follow a Gaussian. i.e., v  X  X  (  X  where  X  v =1 / X  2 v is the precision of the Gaussian. Thus, according to [2], given the distribution of v , the distribution of  X  t = can be derived by
For better representation, we denote R .len as  X  . Equation (9) implies that the distribution of  X  t has two parameters  X   X   X  as  X  is the length of the route and  X  v is the average speed of the route. Note that till now, we only have obtained the expected time  X  t
E of a route according to our temporal model. Thus, we next study the correlation between  X  t E and  X 
Figure 5 plots the relation between  X  t E and the parameter  X  as well as  X  v (a) Scatters of (  X  t E , X  frequently passed to ensure that the estimation is accurate enough. From Figure 5(a) we can find a strong linear correlation between  X   X   X  v and  X  t E thus  X   X  v is the mean of the distribution of v of a certain route can approximate  X  v by the division of the length of R and the corresponding expected time cost  X  t E , i.e.,  X  v  X   X /  X  t  X   X  ear regression. In summary, for a candidate route R , we can get  X   X  tion (9), using the corresponding  X  t E computed in our temporal model and parameters a and b .
 Compute P ( R| p s ,p e ,t e ) . We construct the MDP with the re-ward  X  ( t e ) learned by our spatial model in time slot  X  ( t the reward of destination to zero. Then we perform value iteration [17] on the MDP to get the optimal value function and Q-function of each state. According to Equation (5) and Equation (7), the prob-ability of R given p s and p e can be derived as P ( R| p s ,p e ,t e )= P ( R [1] | p s ,p e ) 1 Route Search. After explaining how to compute the posterior of a candidate route R , we now discuss how to find a route as the answer, including a simple greedy search algorithm and an exact search algorithm. Recall that we have computed the Q-function of each state by value iteration before. Accordingly, the greedy algo-rithm starts from the start state R [1] and then selects an transition action R [1]  X  r among the road segments adjacent to R [1] with the highest transition probability, i.e., r = arg max r P ( r | )= 1 next road segment with the highest transition probability and so on. It performs state transition based on the transition probability un-til the destination state r e is reached. The state sequence traversed is returned as the answer of greedy search. Note that the greedy search algorithm, in short GreedyIRL , is simple and fast, but the returned route might not be the optimal one as it does not consider the temporal dynamics.

Alternatively, we also propose an exact search algorithm to re-turn the route with the highest posterior probability P ( t ) based on dynamic programming. We first discretize the domain of time which is real number into integer. Assuming T max maximum time duration of route, we construct the status matrix used in dynamic programming which is denoted as S  X  R m  X  T max The status S [ r i ,t j ] refers to the log maximum route probability with constraint that the route should start from R [1] and end in r with expected time cost t j , i.e., S [ r i ,t j ]=max R log P ( where R .first = R [1] , R .last = r i and t j  X   X  t ( R ) &lt;t Here, for simplicity, we denote the notation  X  to the input obser-vations { p s ,p e ,t e } . Thus, the optimal substructure can be derived as: S [ r i ,t j ]= where adj ( r )= { r | r.e = r .s } . We use a Dijkstra-like algo-rithm to find the route with the highest posterior probability which is detailed in Algorithm 1.

Directly performing the above algorithm will suffer from great computation cost as the algorithm will not stop until all the statuses have been updated. To address this problem we maintain a lower bound S LB of the result to prune the states which are impossible to have the final probability higher than S LB . Notice that the prob-ability value is always smaller than 1, which implies that the log-probability value is negative. Thus, for the status popped from the priority queue, the final log-probability of this status is definitely smaller than current status value as it will be added several log-probabilities that decrease the value. According to this property, if the value of the top status in the priority queue is already smaller than S LB , we can safely confirm that all the statuses in the prior-ity queue are impossible to be extended as the answer, as listed in Line 6-7 in Algorithm 1. We first perform the greedy route search algorithm GreedyIRL() to return an approximate optimal route as the lower bound (Line 1) and update the lower bound when the states are extended to r e (Lines 12-14). Note that the complexity of the algorithm without pruning is O ( CmT max  X  log( mT Algorithm 1 Exact Route Search 3: pq .push( S [ R [1] ,  X ( R [1])] ); 4: while !pq.empty do 7: break; 15: else
In order to evaluate the performance of our STRS system, we conduct a comprehensive evaluation study and report the results and our findings in this section.
 Dataset Description. We employ the real dataset generated by taxis from Porto as the main dataset, and select the central of the city which contains 2 , 412 edges and 1 , 410 crossroads where his-torical trajectories are densely distributed. The road network data is processed from OpenStreetMap. The whole dataset contains 785 , 705 trajectories. As mentioned in Section 4.1, we set  X  to 60 minutes in our experiments and there are accordingly 48 time units T 1 , T 2 ,  X  X  X  , T 48 . In average, there are 16 , 368 trajectories in each time unit T i . The average sampling rate of the original dataset is 15s per point. We split the dataset into two equal subsets, one for training and the other for testing; while we do study the impact of the size of training set in our experimental study.
 Ground Truth. For the ground truth of a trajectory, we use the map matching algorithm of [10] to get the route in the form of a sequence of edges. For the sampling rate of 15s, it is enough to accurately (  X  99% ) map a series of GPS positions to a road network. Thus, we use the result of map matching as the ground truth route.
 Test Cases. For a complete trip generated by a taxi, we subsample it by different scales ( 1  X  30 segments) between two consecutive GPS positions in the subsampled trajectory. We use consecutive points in a subsampled trajectory as the input of the query. For each scale, we randomly generate 1,000 test samples. We conduct our experiments to see how the performance changes over differ-ent scales of route recovery queries, while the scale of a query is set to the total number of road segments passed by the route. Ac-cordingly, we partition the test data based on different scales and evaluate all the approaches under different scales.
 Evaluation Criteria. We adopt accuracy of route recovery as the main performance metric. It is defined as the ratio of the length of correctly inferred road segments to the length of the ground truth route R G or the inferred route R I whichever is longer, i.e., to penalize a long inferred route as the longer the route, the higher the chance that it contains the correct road segments. First, we compare the performance of STRS with its competitors. To have a better demonstration of the effectiveness of STRS ,we implement five approaches as competitors, including HRIS, MPR, calibration, SP, FP and GreedyIRL.

History based Route Inference System (HRIS) is a typical data-driven route recovery approach [20]. It first locates k candidate routes between two consecutive GPS samples and then uses dy-namic programming to find out the global route by picking up one route from top-k routes w.r.t. each two consecutive GPS samples. As HRIS is designed to return a series of candidate routes, we con-duct the evaluation on HRIS by returning different top-k candidate routes, denoted as HRIS@ k with k set to 1, 5 and 10. Most Pop-ular Route (MPR) [3] is a data-driven approach which returns the route between two locations by observing the traveling behavior of many previous users. Trajectory calibration [16] is also a data-driven approach which matches the trajectory points to the anchor points and complements the missing anchor points which are very likely to be passed by the trajectory. By selecting crossroads as the anchor points, the approach can be trivially modified to solve the route recovery problem. Shortest Path (SP) uses the shortest path to recover the route between two locations which is commonly adopted by many applications because of its simplicity. Similar as SP, Fastest Path (FP) returns the route with the minimum time cost. Last but not the least, we include greedy search algorithm (GreedyIRL), introduced in Section 4.3, as our final competitor. Note that GreedyIRL is a simplified version of STRS which does not take temporal dynamics into consideration.

We evaluate the accuracy of different algorithms under various query scales from 1 to 30 segments. It is observed from Figure 6 that with the increase of the length (scale) of the query route, the ac-curacy of all the approaches drops. This is because, as query scale increases, the number of the possible routes between two locations increases which makes route recovery more difficult. However, among all approaches, STRS demonstrates the most robust accu-racy, especially when the scale of query route is large. To be spe-cific, when scale is 30, STRS still achieves an accuracy over 80% while others (except GreedyIRL) have their accuracy below 50%. This justifies the fact that a full probabilistic approach that can deal with data sparsity is essential. In addition, GreedyIRL, a sim-plified version of STRS , also demonstrates a stable performance. As the query scale becomes larger, the performance gap between GreedyIRL and STRS shrinks. This is because when the query route is short, the relative difference of time interval of different routes is large. Hence, the temporal probability P ( X  t |R has influence on route selection. Accordingly, the advantage of STRS over GreedyIRL by considering the temporal dynamics be-comes more significant. When the query route contains more seg-ments, the relative difference of time interval of different routes is shorter. Accordingly, the temporal probability of different routes becomes more similar. In other words, the temporal influence is weakened which explains the reason that the performance gap shrinks.
Calibration performs the worst among all approaches. The main reason is that it constructs the transition matrix, i.e., the matrix de-noting the transition probability from one anchor point to another one, without considering the destination. It is intuitive that the de-cision of turning left or right is largely depended on where the des-tination is. Consequently, we can utilize MDP to model the driving decision process as we also consider the destination. Besides, as calibration will enumerate all the possible routes from p computation cost scales up exponentially. Thus, when the missing route is longer than 22 road segments, we can not even get the result as the estimation of the time cost of each test sample will exceed 10 4 seconds.

When a query route contains less than 9 segments, all the ap-proaches except GreedyIRL and calibration can achieve almost 100% accuracy. This is because when the query route is not too long, the ground truth of the missing route is often a direct connection of several road segments. For GreedyIRL, when the route is short, the Q-values of states for each action near the terminal do not dif-fer much, which results in the similar transition probabilities. This explains why GreedyIRL does not achieve 100% accuracy.

HRIS recoveries the route by constructing traverse graph and finding the shortest path in the traverse graph. Most of roads in the dense area are passed by historical trajectories which makes the traverse graph almost equivalent to the original road network. Thus, HRIS@1 will be reduced to SP. Our experimental results also prove this, as the accuracy difference between SP and HRIS@1 is bounded by 3%. When the route is not too long (&lt;18), HRIS@10 performs best among all the competitors as it leverages the infor-mation of historical data. When the length of the route becomes longer, HRIS becomes inferior to MPR. This is because HRIS is designed to recover the whole low sampling rate trajectory with GPS positions in the middle of the trajectory given; while MPR is designed to return the most popular route between two positions. Therefore, when the length of route increases, the advantage of MPR gradually emerges and finally outperforms HRIS.

MPR performs similar to FP in most of cases which indicates that popular routes are mostly fastest which is consistent with intu-ition. When the query route contains not too many segments (e.g. &lt; 18), SP has a higher accuracy, as compared with FP and MPR. The reason is that when the trip is not too long, the time cost of different routes could be similar. When the query route is long, FP and MPR outperform SP since the difference of time cost of different routes becomes innegligible which affects the route selection.
We next present two cases of route recovery to show how and why STRS performs better. In the first case shown in Figure 7(a), the route recovered by SP or HRIS is greatly different from that of STRS and calibration while the route recovered by STRS is the same as the ground truth. We also present the street view of some places in each route. From the photos we can figure out that the road of the route recovered by STRS is quite wide while the road is extremely narrow in the route of SP/HRIS. STRS can capture the fact that people are reluctant to drive the route generated by SP/HRIS as it is more dangerous and unpleasant. This is because IRL can capture the reward of the road through the tendency of historical data and the reward of road segment in the dashed blue route will be assigned a relatively low value as most of drivers tend to drive the red solid route. Note that although calibration can re-cover the route, it takes about half an hour to return the answer.
In the second case shown in Figure 7(b), FP and MPR recover a route which seems to be reasonable and the street view also shows that the road condition of the route returned by FP/MPR is also bet-ter than STRS . However, only STRS returns a route that is the same as the ground truth. The reason is that the duration (i.e.,  X  t ) of this query is actually much longer than the estimated time of the route recovered by FP/MPR since FP always returns the route with mini-mum time cost. As analyzed in Section 5.1, MPR performs similar to FP in most of time thus MPR also returns the same route as FP. From the ground truth , we intend to infer that this test sample may be generated by a driver who is unfamiliar with the road network. This case shows that the temporal model of STRS can correct the route according to the information of time duration even though the route is not efficient and natural.
 Experiments of Time Slot Granularity First, we study the im-pact of time slot granularity in the preprocessor component. As explained in Section 4.1, parameter  X  determines the temporal du-ration. In our study, we set  X  to half an hour, 1 hour, 2 hours, 8 hours, 12 hours, and 24 hours. Accordingly, there are in total of w.r.t. weekends. We also test a special case where there is only one time slot, denoted as  X  = 48h . The results are shown in Fig-ure 8(a). We can find that with the decrease of  X  , the performance of STRS improves. As mentioned previously, information of histor-ical data with regard to different time slots is very different. When  X  becomes larger, the time span of each time slot is enlarged and more data are distributed into the same slot. This causes a high variance of data, which has a negative impact on STRS . When  X  is small enough, the performance starts to converge as the variance of data does not decrease any longer. Figure 8: Results of different time spans and sampling intervals
Recall that STRS proposes a temporal model to approximate the likelihood of time duration  X  t . In this set of experiments, we first study the effectiveness of our temporal model.
 Robustness of Time Estimation approach. First, we conduct the experiments to show the performance of our time cost estimation approach. As route-based approaches will inevitably face the data sparsity problem in route recovery and sometimes they even cannot find any answer, we compare our approach only with road segment-based approaches and the speed of a GPS sample is estimated by the ratio of the network distance between this GPS sample and the previous one to the sampling rate. We employ the relative time cost error of a given testing route as the main metric. To be more specific, for a set of testing routes R ( i ) having time interval  X  t the relative time cost error is = depicts the results. Our temporal model has its error rate around 20% and it consistently outperforms its competitor. This is because we adopt a regression model to adjust the cost of each road element through minimizing the error for the whole route which is invariant to the sampling rate. The road segment-based approach has a large error rate as the sampling interval becomes longer. Accordingly, the quality of the speed estimation drops significantly which affects the accuracy of road segment-based approach.
 Visualization of Time Cost Matrix. Recall that to avoid high vari-ance, STRS tries to avoid training those road segments with no or very few historical trajectories passing by. Figure 9(a) visualizes the missing value in  X   X  . Elements in black are the missing values, i.e., those road segments in corresponding time slots have very few or even zero historical trajectories passing by. We can observe that data sparsity problems do exist. For example, people travel more frequently during the daytime (9:00 to 20:00) of weekdays. Ac-cordingly, there are less missing values between 9:00 to 20:00, as compared with other time slots. In weekends, many people may stay at home which leads to the increase of missing values. Note that road segment IDs in the range of [0, 2412] represent road seg-ments, and the IDs larger than 2,412 represent the crossroads.
After filling the missing elements in  X   X  using static-dynamic sep-aration matrix factorization, we have the entire time cost matrix  X  . Here, we visualize the elements of  X  via heatmap. For each row  X   X   X  R 1  X  48 of  X  , which represents the time cost of road element i in different time slots, we normalize the elements of  X   X  time cost of the same road element in different time slots, with the normalized time cost matrix  X  shown in Figure 9(b). The intenser the color, the smaller the time cost and vise versa. For example, we can observe that between 0:00 to 8:00 of a weekday, the color remains dark; when it reaches 9 a.m, the rush hour, the time cost in-creases until 20:00, which further demonstrates that our time model works and the influence of time slots can not be ignored. (a) Elements with null value (b)  X  Effects of Data Sparsity. We have pointed out in Section 4.2.2 that the key problem of spatial model is how to model the transi-based estimation (i.e., Equation (6)) does not work, as it inevitably suffers from data sparsity problem. In the following, we conduct experiments under different degrees of data sparsity to show that our spatial model can handle the data sparsity while traditional frequency-based estimation will have problems. In detail, we use the subset of the training dataset as the sparse training dataset, with the size set to 1/2, 1/5 and 1/10 of the original training dataset.
Figure 10(a) shows when training data become sparser, the ac-curacy of frequency-based estimation drops drastically which jus-tifies our analysis on data sparsity problem. On the other hand, STRS maintains a high accuracy regardless of data sparsity, which demonstrates its robustness under various quality of historical data. As explained in Section 4.2.2, performing IRL on MDP model can avoid the data sparsity problem as it is based on fitting the histor-ical data by assigning rewards to each road and it will assign the feasible reward to those roads with no/few trajectories passed by. Convergence of IRL. Next, we conduct experiments to demon-strate how an IRL model can be trained. Recall that when using PolicyWalk sampling algorithm, the step  X  is involved. We vary the parameter  X  to see how fast the Markov chain converges. We compute the posterior probability according to Equation (8) over training data to observe how IRL model fits the data. We vary the update step  X  from 0.05 to 51.2, as shown in Figure 10(b).
With the increase of the number of training iterations, the pos-teriors P ( |O ) on the training data also increases w.r.t all the set-tings of  X  which means the model increasingly fits the training data. When  X  =0 . 8 , the Markov chain converges fastest and when  X  becomes smaller, the convergence slows down. This is consistent with our expectation. When  X  is very small, is moved slightly in each iteration, which makes it slower to reach the position near the maximum posterior. When  X  becomes larger, it also increases the hardness of convergence. This is because t +1 is drawn uniformly from the neighbours of previous reward t and most of the sam-ples t +1 drawn may be very far away from the optimal which results in a very low acceptance ratio. Thus, many samples are rejected which directly results in the poor convergency. Effects of Pruning Strategy Note that we have adopted pruning strategies in the exact route search algorithm. Here, we study the efficiency of our exact route search algorithm. To have a better illustration of the pruning strategy, we plot the query time using the exact route searching without pruning, in short ERS NoPrune Recall that the result of GreedyIRL serves as the initial value of the lower bound S LB . We also plot the execution time of IRL by initializing S LB to the result of shortest path. We set T to 2000 in our experiment. In Figure 11(a), both search algorithms with pruning take less time, in average about 10 times faster than ERS NoPrune . The significant improvement on search time justi-fies the effectiveness of the pruning strategies. As ERS NoPrune updates the whole status matrix S [ , ] , query scale has a less sig-nificant impact on the computation time. For ERS GreedyIRL ERS SP , their search time changes w.r.t. the query scale. The rea-son is that when the query route contains many segments, it is very likely that the start road and the end road are far away from each other. Accordingly, the number of status that need extension or up-date will also increase. From the observation that ERS GreedyIRL performs faster than ERS SP , we can further conclude that the re-sult of GreedyIRL does provide a better lower bound than SP and our MDP model trained by IRL is more effective.
 Efficiency Comparison We conduct the experiment to show the time cost of online part of STRS (the route search engine) in order to see whether it can be applied in the real scenarios. The competi-tors are three data-driven approaches mentioned above, i.e., HRIS, MPR and calibration. As non-data-driven approaches do not re-quire data processing and can be transfered to a shortest path algo-rithm, they have very small time cost (in several milliseconds) and hence are skipped in this set of experiments. Figure 11(b) depicts the result. We can see when the query scale is small, calibration is the fastest as the number of possible routes is small. However, with the query scale increases, the number of possible routes drastically increases. Thus, the cost increases exponentially, as stated in Sec-tion 5.1. MPR stays consistent with the query scale. The reason is that MPR needs a data preprocessing step for each query which costs much more than the query phase. STRS performs similar as HRIS. When scale is too large the scalability of STRS reduces for the reason that the sizes of discretized time and the states both in-crease. For the sake of the high accuracy STRS brings, we claim that the additional cost is worth to spend.
In this paper, we study the problem of recovering the missing route of a trajectory using historical data in a probabilistic way. We propose a system based on fully probabilistic derivation showing that what kind of temporal and spatial dynamics should be taken into consideration theoretically. We have addressed all the data sparsity problems brought by the probabilistic view and thus we can take full advantages of probabilistic methods. Evaluation results show that our system outperforms all of the competitors and main-tains the accuracy over 80% even when the route contains 28 road segments. The results also show that our system is robust for the data sparsity. In the future work, we plan to extend the route recovery to not only vehicles but also other transportations such as buses, bikes and walking to make route recovery more general. This research is supported in part by National Natural Science Foundation of China (NSFC) under grant 61073001, Shanghai Nat-ural Science Foundation under grant 14ZR1403100. Weiwei Sun is the corresponding author. [1] R. K. Balan, N. X. Khoa, and L. Jiang. Real-time trip [2] C. M. Bishop. Pattern recognition and machine learning . [3] Z. Chen, H. T. Shen, and X. Zhou. Discovering popular [4] C. D. Fabritiis, R. Ragona, and G. Valenti. Traffic estimation [5] G. R. Jagadeesh and T. Srikanthan. Robust real-time route [6] M. Li, A. Ahmed, and A. J. Smola. Inferring movement [7] C. Liao, J. Lu, and H. Chen. Synthesizing routes for low [8] Y. Lou, C. Zhang, Y. Zheng, X. Xie, W. Wang, and Y. Huang. [9] T. Miwa, D. Kiuchi, T. Yamamoto, and T. Morikawa.
 [10] P. Newson and J. Krumm. Hidden Markov map matching [11] M. Rahmani, E. Jenelius, and H. N. Koutsopoulos. Route [12] M. Rahmani and H. N. Koutsopoulos. Path inference of [13] M. Rahmani and H. N. Koutsopoulos. Path inference from [14] D. Ramachandran and E. Amir. Bayesian inverse [15] J. Rice and E. V. Zwet. A simple and effective method for [16] H. Su, K. Zheng, J. Huang, H. Wang, and X. Zhou.
 [17] R. S. Sutton and A. G. Barto. Reinforcement learning: an [18] Y. Wang, Y. Zheng, and Y. Xue. Travel time estimation of a [19] J. Yuan, Y. Zheng, C. Zhang, X. Xie, and G. Sun. An [20] K. Zheng, Y. Zheng, X. Xie, and X. Zhou. Reducing [21] Y. Zheng. Trajectory data mining: An overview. ACM TIST , [22] Y. Zheng and M. A. Quddus. Weight-based shortest-path
