 1. Introduction
In process industries, many operations include set-point changes and/or the co-existence of multiple operating modes.
As an example, one can consider greenhouse control for which night or daylight workout is quite different, while other considerations such as crop ripeness, outdoor temperature/ humidity strongly influence the dynamical evolution of the plant whole nonlinear system, it is often preferred to simplify the model considering a set of well-known operating points, for which the subsystems are linear or not. The main difficulty appears to be the monitoring of the plant between two different operating modes, which needs the blending of models and/or the corresponding controls across different operating domains, known as multimodel systems/control ( Delmotte et al., 1996; Johansen and Foss, 1999 ).

The blending of a priori known linear models and control has using linearization methods. However, the multimodel represen-tation is more difficult to obtain when the subsystems are nonlinear and/or should be determined from raw input X  X utput estimating the models parameters. Last, the blending functions between several models should be estimated in the common case where the operating domains overlap.

Several neural and fuzzy clustering algorithms have shown to et al., 2008 ). For example, neural networks have been able to represent and control such systems as a non-linear output-to-neural network using a direct representation of the nonlinear multimodel representation and control from data using for example the Kohonen Self Organizing Map as a clustering their ability to classify data and their simplicity, K-means algorithms have been shown to be efficient for data clustering Kanzawa et al., 2008 ).

In short, whereas many architectures using multiple models and neural networks have been proposed, there has not been much work on clustering techniques, based on neural networks multimodel representation using only input/output data. In this context, most of the proposed studies use clustering algorithms for the identification of the Takagi X  X ugeno models (e.g. Kukolj tedious issues are related to the size of the model-base and the data clustering procedure which aims to the determination of the operating domains of the process. This paper thus studies the complex systems, which has not been commonly addressed by appropriate clustering method called Rival Penalized Competitive proposed to handle this classical issue. Besides, the clustering procedure, which aims to build the model base from input X  X utput data, is improved here. A quite rough clustering method based on of the K-means and fuzzy K-means algorithms. This allows to make some interpretations about the selection of the appropriate clustering method and to distinguish two kinds of models, those these domains strongly overlap. Simulation examples will confirm the relevance of the suggested approach. 2. Multimodel structure determination using clustering algorithms
The multimodel structure was introduced as a global approach based on multiple local LTI models (linear or affine). Conse-quently, it assumes that it is possible to replace a unique nonlinear representation by a combination of simpler models thus building a so-called model-base. Each model of this base describes the behavior of the considered process at a specific operating point. The interaction between the different models of the base through normalized activation functions allows the modeling of the global non-linear and complex system. Therefore, the multimodel approach aims at lowering the system complexity by studying its behavior under specific conditions. The multi-model principle is given in Fig. 1 .

The different models of the base could be of different structures and orders but no model can represent the system in its whole operating domain. The decision unit allows the estimation of the weight of each model and thus the selection multimodel output which is obtained by the contribution of the different models X  outputs. 2.1. Model-base construction procedure
The proposed approach allows the construction of the model-base by using some clustering algorithms ( Du, 2010 ). The the number of models: this will be handled by using a two-layers competitive neural network and a Rival Penalized Competitive RPCL will influence the choice of the appropriate K-means algorithm (K-means, fuzzy K-means) for data clustering. Once the operating domains generated, a structural and parametric identi-strategy using an adequate method for validity computation allowing the generation of the multimodel output which will be 2.2. Determination of the number of models with a neural network and a Rival Penalized Competitive Learning (RPCL) algorithm
This first step requires experimental data which are obtained when the considered system is excited by applying an appropriate input sequence. In order to generate the different operating domains of the process, the measurements must be merged into a with unsupervised learning. Most existing clustering algorithms of the appropriate number of clusters, which is, however, essential to estimation and clustering performance in the multi-model approach when no information is available about the operating domains and their number. However, many experi-mental results have shown that the RPCL algorithm automatically allocates an appropriate number of units for an input data set when they are used for clustering. 2.2.1. System excitation and data collecting
The excitation of the system consists in applying an input signal and then collecting the useful measurements (output or input/output). The number of measured variables depends on the system complexity. The excitation signal must be rich enough and persistently exciting with well-chosen parameters in order to consideration the non-linear aspect of the considered process. 2.2.2. Selection of the number of models via RPCL
For tackling the issue of determination of the number of models in the multimodel representation, via input X  X utput data, we propose to use a neural network and to apply the learning algorithm called RPCL which allows the selection of the adequate number of operating clusters for an input data set, where the the data set when the number of units is larger than the real number of clusters in the input data set.

RPCL is an unsupervised learning strategy (proposed by Xu et al., 1993 and renewed by Tambe et al., 1996 ), that auto-matically determines the optimal number of nodes. The principle underlying RPCL can be considered as an extension of the competitive learning based on Kohonen (1990) rule. The specifi-only of the winner weights, but also of the weights of its rival (called second winner) so that the rival will be moved or penalized. The rate at which the rival is penalized is much smaller than the learning rate ( Borne et al., 2007 ).
Given a competitive learning neural network ( Fig. 2 ), i.e. a w can be described by the following steps. 1. Initialize weight vectors w i randomly. u  X  such that
J x w c J 2  X  min j g j J x w j J 2  X  2a  X  J x w r J 2  X  min j a c g j J x w j J 2 ,  X  2b  X 
J J : Euclidean distance; w c : weight vector of the winner; w r : weight vector of the rival; g j : conscience factor (relative winning frequency) used to 3. Update the weight vectors as follows: w  X  t  X  1  X  X  w j  X  t  X  X  D w j ,  X  4  X  where
D w j  X  rate and the rival de-learning rate. In practice, the rates are fixed small numbers or depend on time (starting from not so small initial values and are then reduced to zero in some way) been proposed for the update of the learning and de-learning rates ( King et al., 1998; Nair et al., 2003 ). 4. Repeat steps 2 and 3 until the whole learning process has converged.

Referring to the learning results, the number of clusters is set must be considered and the number of clusters could be so deduced as equal to the number of the retained units. This step could be, however, automated by considering the position of the improvement with respect to heuristic methods as considered in clusters X  number. 2.3. Determination of the operating clusters using K-means algorithms (K-means and fuzzy K-means)
After the selection of the appropriate number of clusters, the next step consists in splitting up the measurements collected on the system into clusters in order to generate the different operating domains from which the base-models will be identified.
For this, K-means and fuzzy K-means clustering algorithms have been chosen according to their easy working out and their efficiency. 2.3.1. K-means algorithm
K-means ( Forgy, 1965; MacQueen, 1967 ) is one of the simplest unsupervised learning algorithms that solve the well known clustering problem. The procedure follows a simple and easy way fixed a priori. It can be shown that this algorithm aims at minimizing an objective function, in this case a squared error function, given by J  X  where:
J J : a chosen distance measure between a data point and a x : i th data point; c : center vector of the cluster j ; u : degree of membership of x i to cluster j such as u ij A N : number of data points; K : number of clusters  X  2 r K o N  X  .

The algorithm is composed of the following steps. are being clustered. These points represent initial group centroids. of the K centroids. 4. Repeat steps 2 and 3 until the centroids no longer move. This produces a separation of the objects into groups from which
Although it can be proved that the procedure will always terminate, the K-means algorithm does not necessarily find the optimal configuration, corresponding to the global objective function minimum. The algorithm is also significantly sensitive to the initial randomly selected cluster centers. The K-means algorithm can be run multiple times to reduce this effect. 2.3.2. Fuzzy K-means algorithm
Fuzzy K-means algorithm (developed by Dunn, 1973 and improved by Bezdek, 1981 ) is a data clustering technique which allows each data point to belong to more than one cluster with different membership degrees (between 0 and 1) and vague or fuzzy boundaries between clusters. The aim of this method is to find an optimal fuzzy K-partition and corresponding prototypes minimizing the following objective function:
J  X  where:
J J : any norm expressing the similarity between any measured x i : i th data point; c j : center vector of the cluster j ; u ij : degree of membership of x i to cluster j such as u ij A m : weighting exponent (real number greater than 1) which is a N : number of observations; K : number of clusters  X  2 r K o N  X  .
 of the objective function shown above, with the update of membership u ij and the cluster centers c j ( Nascimento et al., 2000 ).

This procedure will stop when max i , j fj u ij  X  k  X  1  X  u where e is a termination criterion belonging to [0,1] and k are the iteration steps. This procedure converges to a local minimum of J m .

The algorithm is composed of the following steps. 1. Initialize the matrix U  X  [ u ij ], U (0). 2. At k -step, calculate the centers vectors C ( k )  X  [ c 3. Update U ( k ), U ( k +1): the greatest membership degree. 2.3.3. Hypothesis
The implementation of the two clustering algorithms, previously the appropriate clustering algorithm will depend on the way in to clustering results obtained by the application of the RPCL algorithm, if we have an overlapping between clusters without this paper, we will try to validate this hypothesis through a comparison between results given by the considered clustering algorithms applied for the modeling of two different systems. 3. Multimodel parameters estimation 3.1. Model orders and parameters estimation
The application of the appropriate clustering algorithm (K-means or fuzzy K-means) results in some repartition of the data set. Each cluster is represented by a set of input/output measurements which will be exploited for the identification of the estimation of the model orders by using the so-called instrumental determinants X  ratio-test. This method is mainly based on the conditions concerning a matrix called  X  X  X nformation matrix X  X  which contains the input/output measurements ( Abden-nour et al., 2001 ). This matrix is described as follows: Q where N H is the number of observations. The instrumental determinants X  ratio ( RDI ) is given by RDI  X  m  X  X  det  X  Q m  X  det  X  Q For every value of m , the determination procedure of the order ratio RDI ( m ) quickly increases for the first time.
Given the order of the model, the parametric identification corresponding model-equation, given several experimental mea-the Recursive Least-Squares (RLS) method ( Abdennour et al., 2001 ) is applied to achieve the parameters estimation. 3.2. Validity computation
The steps described in the previous paragraphs allow the construction of the model-base. The purpose is to test the efficiency and the precision of the proposed modeling structure. are different from those used for clustering are fed into the system. Then, the multimodel output is computed and compared to the real output of the process. The multimodel output y obtained through a fusion of the models X  outputs y i weighted by and Fig. 3 ( K is the number of models in the base): y mm  X  k  X  X  3.2.1. Computation of validity indexes represents the relevance degree of each model calculated at each on the distance measurement between the process and the considered model. For example, the residue can be given by the following expression: r  X j y y i j , i  X  1 , ... , K ,  X  14  X  where:
K : number of models in the base; y : process output; y : output of the model M i .

If the residue value is equal to zero, the corresponding model M process partially. The normalized residues are given by r u  X 
Within the context of the residues X  approach, several methods have been proposed for the calculation of validities ( Delmotte two methods will be considered: the simple and the reinforced v  X  1 r u i :  X  16  X 
Using the previous expression, the simple and the reinforced validities are defined as follows.

Simple validities: the normalized simple validities are defined so that their sum must be equal to 1 at each time: v  X  expression is introduced as  X  v i v  X  computation (simple or reinforced), a comparative study between the two considered methods has been carried in Elfelly et al. the clusters structure and repartition. In fact, when there are important variations in the same cluster and when an overlapping method since it takes account of different models X  outputs referring to the expression (17). In this case, no model could represent ideally the process at any time. But when the clusters validities X  method is better adapted. The application of this method, thanks to the reinforcement expression (19), promotes the contribution of the most dominant model which represents at best the process behavior. 3.2.2. Validation of the proposed modeling scheme
Once the appropriate method of validity computation selected, the validation of the global modeling scheme is carried out through a comparison between the real and the multimodel outputs for different input sequences. 4. Simulation examples
In order to underline the interest and the performance of the proposed modeling approach, some simulation examples have been considered. 4.1. Example 1: second order discrete system with time-dependent parameters
This first example is a complex discrete system whose evolution is described by the following equation: by a  X  k  X  X  0 : 04sin  X  0 : 035 k  X  0 : 8 ,  X  21a  X  a  X  k  X  X  0 : 005sin  X  0 : 03 k  X  X  0 : 1 ,  X  21b  X  b  X  k  X  X  0 : 02sin  X  0 : 03 k  X  X  0 : 5 ,  X  21c  X  b  X  k  X  X  0 : 01sin  X  0 : 035 k  X  X  0 : 2 :  X  21d  X  the measurements y ( k ) and y ( k 1) are collected at different instants. These numerical data are used for the determination of the appropriate number of operating clusters by using a neural from the observation space, which allows to conclude that the adequate number of clusters is equal to three.

Then, the two clustering algorithms (K-means and fuzzy K-by application of the K-means algorithm, are given in Fig. 5 . 2.5 3.5 4.5 y (k) resulting from the implementation of the proposed clustering algorithms, the orders and the parameters of the transfer the three models given by the RDI method, are equal to two. This result is consistent with the real order of the system which is equal to two. The application of the Recursive Least-Squares models.

The selection of the adequate method of validity computation was based on a comparison done in Elfelly et al. (2008) which which show well-separated clusters with few variations.
For the validation of the so proposed process modeling, let us consider the following input sequence: u  X  k  X  X  1  X  sin  X  0 : 06 k  X  :  X  22  X 
Results obtained by the implementation of each of the proposed clustering methods (K-means and fuzzy K-means) are compared and in consequence the hypothesis formulated in Section 2.3.3 is model-base, the multimodel output is computed (by fusion of the where: y e km , e fkm : absolute errors between the real and the multimodel means algorithm are better than those resulting from the application of the fuzzy K-means algorithm, which allows to that when its question of a low overlapping between clusters ( Fig. 4 ), the K-means algorithm is more efficient for data clustering.

On the other hand, Fig. 7 shows that the implementation of the proposed multimodel approach allows a good modeling of the system. In fact, by considering the input sequence given by expression (22), the multimodel output tracks the real output with a very small error. dependent parameters
As a second simulation example, we consider the system whose evolution is described by the following equations: a y  X  a 1 _ y  X   X  y  X  u  X  b _ u ,  X  24  X  where a  X  k  X  X  0 : 3  X  sigm  X  y 2  X  ,  X  25a  X  a  X  y  X  X  sat  X  y 2  X  ,  X  25b  X  b  X  u  X  X  sat  X  u  X  ,  X  25c  X  sigm is the sigmoid function; sat is the saturation function.
The considered system is complex and strongly non-linear which makes the modeling task difficult.
 a random uniform signal since this input is richer than a simple random signal and allows considering the complex and non-linear y (k) e (t),ef (t) y(t),y (t) u (t) (frequency, amplitude) need to be adjusted in order to obtain the input data u ( k 1).

The determination of the number of clusters was carried out through a neural network and the RPCL by considering three neurons in the input layer and K neurons in the output layer. number of clusters is all the time equal to four ( Fig. 9 ).
Once the number of models computed, the measurements are algorithms: K-means and fuzzy K-means. The implementation of the fuzzy K-means algorithm gives the results shown in Fig. 10 . technique, the application of the instrumental determinants X  ratio-test method for order estimation and the least squares method for model identification allows us to write the four transfer functions.

For the selection of the validity computation method, the than the reinforced validities. This could be justified by the clustering results ( Fig. 10 ) which present an important over-lapping between clusters.

In order to give prominence to the capacity of the identified models to reproduce the operating system in different domains, let us consider the following input sequence: u  X  k  X  X  1 : 2  X  1 : 5sin  X  2 k  X  :  X  26  X 
For each clustering algorithm, the model base is elaborated and the multimodel output is computed through a fusion of the models X  outputs weighted by their respective simple validities. and (23b)) between the real output of the system and the multimodel outputs obtained through the application of the two K-means algorithms.

It appears that the error e fkm is smaller than the error e
Consequently, it can be concluded that contrary to the first example, the clustering of the measurements carried out by using the fuzzy K-means algorithm gives the best results, which allows which assumes that in the presence of an important overlapping between clusters ( Fig. 9 ), the fuzzy K-means algorithm is more convenient for data clustering.

Fig. 12 vouches for the precision and the performance of the proposed modeling strategy for the considered system. In fact, when considering the input sequence given by expression (26), the multimodel output y fkm (obtained by the application of the
It is to note that this second example is shared with Elfelly from the suggested approach, considering three items: model base size, overall modeling results, algorithmic complexity and computation time. A better selection of clusters X  number (four and location has lead to an enhancement of the modeling tion time and memory) when using Kohonen maps are more important, compared to fast and simple to use K-means-like algorithms. 5. Conclusion
In this paper, a new multimodel approach based on both is applicable when dealing with complex, strongly non-linear and uncertain systems. It allows the determination of the model-base by using different clustering techniques and two methods of  X 2  X 1 0 1 2 3 u (k-1)  X 2  X 1 0 1 2 u (k-1) 0.05 0.1 0.15 e (t),e (t) 0.5 1.5 2.5 y(t),y (t) mination of the number of models is resolved by using a neural network and a Rival Penalized Competitive Learning (RPCL). Once this number computed, the measurements collected on the system are clustered by using an appropriate K-means algorithm (K-means or fuzzy K-means). The clustering results, giving the the model-base. A validation procedure is then worked out, which aims to demonstrate the ability of the proposed modeling structure to approximate the system response in different operating domains. The suggested approach has been implemen-two of which were described in this paper, prove the efficiency and the precision of the proposed modeling strategy and show that the method works well with various systems even when be applied for data clustering (K-means or fuzzy K-means), some interpretations have been made, showing that fuzzy K-means gives better results when a strong overlapping of the operating domains exists.
 References
