 1. Introduction
Giving suggestions to users of Web search engines is a common practice aimed at driving users toward the information bits they may need. Suggestions are normally provided as queries that are, to some extent, related to those recently submit-enced ones. The knowledge mined for making this possible is contained in Web search engine logs which store all the past interactions of users with the search system. More the users that satisfied the same information need in the past, the more precise and effective the related suggestions provided by any query recommendation technique. On the other hand, to gen-erate effective suggestions for user queries which are rare or have never been seen in the past is an open issue poorly ad-dressed by state-of-the-art query suggestion techniques.

In a previous work, an interesting framework for the query suggestion problem is provided by the Search Shortcut model, and an evaluation metric for assessing the effectiveness of suggested queries by exploiting a query log is proposed ( Baraglia satisfy their information need. In the same work the use of Collaborative Filtering (CF) algorithms is investigated. However, the work highlights some limitations in the query recommendations solutions based on collaborative filtering mainly due to rences, click information for low-frequency queries is rare and very sparse. Since implicit feedback information given by  X  be exploited to generate the recommendation model ( Adomavicius &amp; Tuzhilin, 2005 ). This issue affects CF-based solutions, but also many other query recommendation techniques discussed in the literature.

In this paper we propose an efficient and effective query recommendation algorithm that can cover also queries in the long tail. We adopt the Search Shortcuts model and its terminology, and re-conduct the shortcut generation phase to the from most state-of-the art proposals, our shortcut generation algorithm aggregates implicit feedback information present in is then combined during the suggestion generation process in order to provide recommendations also for queries that are data-sparsity problem, is both very efficient and scalable, making it suitable for a large-scale deployment in real-world search engines.

Another contribution of this paper consists in the methodology adopted for manually assessing the effectiveness of query suggestion techniques. The methodology exploits the query topics and the human judgements provided by the National
Institute of Standards and Technology (NIST) for running the TREC Web Track X  X  diversity task. For the purposes of the diver-on information extracted from the logs of a commercial search engine. We claim that given a query topic A with all its sub-propose to simply ask human editors to count how many subtopics are actually covered by the suggestions generated by
T for the TREC diversity track queries. This methodology is entirely based on a publicly-available data. It can be thus con-sidered fair and constitute a good shared base for testing and comparing query recommendation systems. We shall define the above concept better in Section 4 .

The experimental evaluation conducted shows that the proposed solution outperforms remarkably two state-of-the-art algorithms chosen for performance comparison purposes (presented in Baeza-Yates &amp; Tiberi (2007), Boldi et al. (2008) &amp; evant suggestions for a vast majority of the 50 TREC queries, and the suggested queries cover a high percentage of possible the query log used for training the recommendation model. Moreover, the proposed algorithm outperforms the competitor ing to the metric used in Baraglia et al. (2009) .

The main original contributions of this work are thus: 1. A novel algorithm to efficiently and effectively generate query suggestions that is robust to data sparsity. 2. A novel evaluation methodology with which we can compare the effectiveness of suggestion mechanisms. 3. An extensive evaluation comparing on the same basis the proposed solution with two state-of-the-art algorithms.
The rest of the paper is organized as follows. The next Section shows a brief overview of the state of the art in query rec-ommendation. Section 3 briefly sketches the shortcuts model and describes the efficient algorithm designed for generating query shortcuts. The evaluation methodology based on the TREC diversification track data is discussed in Section 4 which also presents the encouraging results obtained by our solution in the performance comparisons tests conducted. Finally, Sec-tion 5 draws some conclusions and outlines future work. 2. Related work
The problem addressed in this paper is related to two related research fields that have been traditionally addressed from different points of view. We are talking about query suggestion algorithms and recommender systems.

Recommender systems are used in several domains, being specially successful in electronic commerce. They can be di-filtering approaches base their recommendations on the content of the items to be suggested. They face serious limitations when dealing with multimedia content and, more importantly, their suggestions are not influenced by the human-perceived two main families of collaborative filtering algorithms: memory-based and model-based. Memory-based approaches use the or both ( Wang, de Vries, &amp; Reinders, 2006 ). Generally, memory-based algorithms are quite simple and produce good recom-mendations, but they usually face serious scalability problems. On the other hand, model-based algorithms construct in ad-vance a model to represent the behavior of users, allowing to predict more efficiently their preferences. However, the model building phase can be highly time-consuming, and models are generally hard to tune, sensitive to data changes, and highly dependent on the application domain. Different approaches can be adopted based on linear algebra ( Canny, 2002; Rennie &amp;
Srebro, 2005 ), clustering ( Ungar &amp; Foster, 1998 ), latent class models ( Hofmann, 2004 ), singular value decomposition ( Paterek, 2007 ). An analysis of the use of collaborative filtering algorithms to the query suggestion problem can be found in Baraglia et al. (2009) , where the problem descending from the poor and very sparse scoring information available in query logs is highlighted.

On the other side, query suggestion techniques address specifically the problem of recommending queries to Web search engine users, and propose specific solutions and specific evaluation metrics tailored to the Web search domain. Techniques proposed during last years are very different, yet they have in common the exploitation of usage information recorded in query logs ( Silvestri, 2010 ). Many approaches extract the information used from the plain set of queries recorded in the log, although there are several works that take into account the chains of queries that belong to the same search session ( Radlinski &amp; Joachims, 2005 ). In the first category we have techniques that employ clustering algorithms to determine
Baeza-Yates and Tiberi (2007) exploit click-through data as a way to provide recommendations. The method is based on the concept of Cover Graph . A Cover Graph is a bipartite graph of queries and URLs, where a query q and an URL u are con-nected if a user issued q and clicked on u that was an answer for the query. Suggestions for a query q are thus obtained by accessing the corresponding node in the Cover Graph and by extracting the related queries sharing more URLs. The sharing of clicked URLs results to be very effective for devising related queries, and the Cover Graph solution has been chosen as one of the two query suggestion algorithms considered in this paper for experimental performance comparison.
 Among the proposals exploiting the chains of queries stored in query logs, ( Fonseca, Golgher, P X ssas, Ribeiro-Neto, &amp;
Ziviani, 2005 ) use an association rule mining algorithm to devise frequent query patterns. These patterns are inserted in a query relation graph which allows  X  X  X oncepts X  X  (queries that are synonyms, specializations, generalizations, etc.) to be iden-tified and suggested.

Boldi et al. introduce the concept of Query Flow Graph , an aggregated representation of the information contained in a query log ( Boldi et al., 2008 ). A Query Flow Graph is a directed graph in which nodes are queries, and the edge connecting node q 1 to q 2 is weighted by the probability that users issue query q model in two concrete applications, namely, devising logical sessions and generating query recommendation . The authors refine query suggestion scheme based on a random walk with restart model on the Query Flow Graph is proposed. Such suggestion algorithm is the second algorithm considered in this paper for experimental performance comparison.
 A approach similar to our is represented by the query refinement/substitution technique discussed in Jones et al. (2006) .
The goal of query refinement is to generate a new query to replace a user X  X  original ill-formed search query in order to en-hance the relevance of retrieved results. The technique proposed includes a number of tasks such as spelling error correction, word splitting, word merging, phrase segmentation, word stemming, and acronym expansion. Our approach instead aims at suggesting users a set of queries that better specify their information needs.

The importance of rare query classification and suggestion recently attracted a lot of attention from the information re-logs.

Downey, Dumais, and Horvitz (2007) describe search log studies aiming at explaining behaviors associated with rare and common queries. They investigate the search behavior following the input of rare and common queries. Results show that search engines perform less well on rare queries. The authors also study transitions between rare and common queries high-lighting the difference between the frequency of queries and their related information needs.

Song and He (2010) propose an optimal rare query suggestion framework by leveraging implicit feedbacks from users in the query logs. The proposed model is based on the pseudo-relevance feedback. It assumes that clicked and skipped URLs contain different level of information, and thus, they should be treated differently. Therefore, the framework optimally com-bines both click and skip information from users, and uses a random walk model to optimize (i) the restarting rate of the random walk, and (ii) the combination ratio of click and skip information. Experimental results on a log from a commercial search engine show the superiority of the proposed method over the traditional random walk models and pseudo-relevance feedback models.

Mei et al. propose a novel query suggestion algorithm based on ranking queries with the hitting time on a large scale ries and the original query. Empirical results on a query log from a real world search engine show that hitting time is effec-tive to generate semantically consistent query suggestions. The authors show that the proposed method and its variations are able to boost long tail queries, and personalized query suggestion.

Broder et al. propose to leverage the results from search engines as an external knowledge base for building the word features for rare queries ( Broder et al., 2007 ). The authors train a classifier on a commercial taxonomy consisting of 6000 nodes for categorization. Results show a significant boost in term of precision with respect to the baseline query expansion 2009 ). The approach builds an expanded query representation by leveraging offline processing done for related popular queries. Experimental results show that the proposed technique significantly improves the effectiveness of advertising on rare queries with only a negligible increase in computational cost.

The idea we present in this paper follows a completely new approach. First, we infer the relevance of a query based on she was looking for. Recent research results have shown in fact that user behavior recorded in query log allows effective pre-satisfactory sessions are considered in this paper as the key factor for generating useful query recommendations. All the que-is likely that these queries were issued by different users trying to satisfy a similar information need. Thus, our technique queries which are the representatives of the clusters closest to the submitted query. 3. An efficient algorithm for the query shortcuts problem
In the following we briefly recall the basis of the Search Shortcuts Problem (SSP) proposed in Baraglia et al. (2009) , and we introduce our novel shortcuts generation algorithm. 3.1. The Search Shortcuts Problem
The SSP is formally defined as a problem related to the recommendation of queries in search engines and the potential reductions obtained in the users session length. This problem formulation allows a precise goal for query suggestion to to prefetching, search shortcuts anticipate requests to the search engine with suggestion of queries that a user would have likely issued at the end of her session.
 We now introduce the notations and we recap the formal definition of the SSP.

Let U be the set of users of a Web search engine whose activities are recorded in a query log, and Q be the set of queries in that query log. We suppose the query log is preprocessed by using some session splitting method (e.g. Jones &amp; Klinkner, which are related to the same user search task. Formally, we denote by S the set of all sessions in a query log. Moreover, let us denote with r i the i th query of r . For a session r of length n its final query is the query r by the user in the session.

We say that a session r is satisfactory if and only if the user has clicked on at least one link shown in the result page returned by the Web search engine for the final query r n we denote r t j the head of r , i.e., the sequence of the first t , t &lt; n , queries, and r the remaining n t queries.

Definition 1. We define k-way shortcut a function h taking as argument the head of a session r set h ( r t j )of k queries belonging to Q .

Such definition allows a simple ex-post evaluation methodology to be introduced by means of the following similarity function:
Definition 2. Given a satisfactory session r 2S of length n , and a k -way shortcut function h , the similarity between h ( r and a tail r j t is defined as: where f ( m ) is a monotonic increasing function, and function s q = r
For example, to evaluate the effectiveness of a given shortcut function h , the sum (or average) of the value of s computed on all satisfactory sessions in S can be computed.

Definition 3. Given the set of all possible shortcut functions H , we define Search Shortcut Problem (SSP) the problem of finding a function h 2H which maximizes the sum of the values computed by Eq. (1) on all satisfactory sessions in S .
A difference between search shortcuts and query suggestion is actually represented by the function s q =( r
By relaxing the strict equality requirement, and by replacing it with a similarity relation  X  i.e. s q ( r similarity between q and r m is greater than some threshold  X  the problem reduces, basically, to query suggestion. By defining appropriate similarity functions, the Equation in (1) can be thus used to evaluate query suggestion effectiveness as well.
Finally, we should consider the influence the function f ( m ) has in the definition of scoring functions. Actually, depending constant function f ( m )= c , we measure simply the number of queries in common between the query shortcut set and the queries submitted by the user. A non-constant function can be used to give an higher score to queries that a user would have submitted later in the session. An exponential function f ( m )= e cuts suggested early. Smoother f functions can be used to modulate positional effects. 3.2. The search shortcuts generation method
Inspired by the above SSP, we define a novel algorithm that aims to generate suggestions containing only those queries in our view is a good strategy to accomplish this task. In order to validate this hypothesis, we analyzed the Microsoft RFP 2006 dataset, a query log from the MSN Search engine containing about 15 million queries sampled over one month of 2006.
First, we measured that the number of distinct queries that appear as final query in satisfactory sessions of the query log is relatively small if compared to the overall number of submitted queries: only about 10% of the total number of distinct queries in the query log occur in the last position of satisfactory user sessions. As expected, the distribution of the occur-the set of final queries actually used by people is limited.

Queries which are final in some satisfactory sessions may obviously appear also in positions different from the last in other satisfactory sessions. We verified that, when this happens, these queries appear much more frequently in positions very close to the final one. About 60% of the distinct queries appearing in the penultimate position of satisfactory sessions are also among the final queries, about 40% in positions second to the last, 20% as third to the last, and so on. We can thus valued and high quality short pieces of text expressing actual user needs.

The SSP algorithm proposed in this paper works by computing, efficiently, similarities between partial user sessions (the one currently performed) and historical satisfactory sessions recorded in a query log. Final queries of most similar satisfac-tory sessions are suggested to users as search shortcuts.

Let r 0 be the current session performed by the user, and let us consider the sequence s of the concatenation of all terms tion d ( s , r s ), which for each satisfactory session r itively, this similarity measures how much a previously seen session overlaps with the user need expressed so far (the concatenation of terms s serves as a bag-of-words model of user need). Sessions are ranked according to d scores and from the subset of the top ranked sessions we suggest their final queries. It is obvious that depending on how the function d is chosen we may have different recommendation methods. We opt for d to be a linear combination of the BM25 metric in r 0 t j , we define
We exploit an IR-like metric (BM25) because we want to take into much consideration words that are discriminant in the context of the session to which we are comparing. BM25, and other IR-related metrics, have been designed specifically to account for that property in the context of query/documents similarity. We borrow from BM25 the same attitude to adapt to this conditions. We also exploit the frequency of final queries in the scoring formula. By doing so we aim at promoting sessions containing final queries that are frequently used by users. The shortcuts generation problem has been, thus, reduced to the information retrieval task of finding highly similar sessions in response to a given sequence of queries. In our exper-iments we set a = b = 1/2. Furthermore, we compute the similarity function d only on the current query issued by the user instead of using the whole head of the session. We do this in order to be fair with respect to our competitors as they produce recommendations starting from a single query. We leave the study of the use of the whole head of the session for producing query recommendations as a future work.

The idea described above is thus translated into the following process (see Algorithm 1 ). For each unique final query con-posedof all the termsthat have appearedinqueries ofall the satisfactorysessionsendingwiththe finalquery. Atthe endof this make things more clear, let us consider a toy example. Consider the two following satisfactory sessions: ( gambling , gambling tual document actually contains also repetitions of the same term that are considered in the context of the BM25 metrics. Algorithm 1. Offline generation of the recommendation model.
 Require: a set S of user sessions recorded in the query log.

Ensure: an inverted index vd index built over the virtual documents obtained from satisfactory sessions. 1: for all r 2 S do 2: if sessionIsSatisfactory ( r ) then 3: s getTermsFromSession ( r ) 4: vd [ r n ] s { given current satisfactory session r , the occurrences of all the query-terms in r are added to the 5: end if 6: end for 7: vd index buildInvertedIndex ( vd ) {we build the inverted file indexing all the obtained virtual documents.}
All virtual documents are indexed with the preferred Information Retrieval system, and generating shortcuts for a given user session r 0 becomes simply processing the query r 0 t j rithm 2 ). We know that processing queries over inverted indexes is very fast and scalable, and these important character-istics are inherited by our query suggestion technique as well.
 Algorithm 2. Suggestion retrieval.

Require: the head r 0 t j of length t of the current user session r 0 , and the recommendation model vd
Ensure the set R of top-k scored recommendations for the given query. 1: s getTermsFromSession r 0 t j 2: D getMatchingVirtualDocuments ( vd index , s ) 3: R new heap ( k ) 4: for all d 2 D do 5: shortcut getTitle ( d ) 6: R . insert ( shortcut , a BM 25( s , d )+ b freq ( shortcut )) 7: end for 8: return R .
 The other important feature of our query suggestion technique is its robustness with respect to rare and singleton queries. in each session, we are not bound to look for previously submitted queries as in the case of other suggestion algorithms.
Therefore we can generate suggestions for queries in the long tail of the distribution whose terms have some context in the query log used to build the model. 4. Assessing search shortcuts quality
The effectiveness of a query recommender systems can be evaluated by means of user-studies or through the adoption of some performance metrics. Unfortunately, both these methodologies may lack of generality and incur in the risk of being over-fitted on the system object of the evaluation. The evaluation methodology used in this paper tries to address pragmat-ically the above issues.

For what concerns the methodology based on a performance metrics, we used the one defined in Eq. (1) , and we com-puted the average value of similarity over a set of satisfactory sessions. This performance index objectively measures the effectiveness of a query suggestion algorithm in foreseeing the satisfactory query for the session.

In particular, we measured the values of this performance index over suggestions generated by using our Search Shortcuts (SS) solution and by using in exactly the same conditions two other state-of-the-art algorithms: Cover Graph (CG) proposed by Baeza-Yates and Tiberi (2007) , and Query Flow Graph (QFG), proposed by Boldi, Bonchi, Castillo, Donato, et al. (2009) . These algorithms are recent and highly reputed representatives of the best practice in the field of query recommendation.
To test QFG-based query suggestion we used the original implementation kindly provided us by the authors. In the case of CG, instead, we evaluate our own implementation of the technique.

For what concerns the methodology based on user-studies, we propose a approach that measures coverage and the effec-tiveness of suggestions against a manually assessed and publicly available dataset.
 To this purpose, we exploited the query topics and the human judgements provided by NIST for running the TREC 2009
Web Track X  X  Diversity Task ( http://www.trec.nist.gov/data/web09.html ). For the purposes of the TREC diversity track, NIST provided 50 queries to a group of human assessors. Assuming each TREC query as a topic, assessors were asked to identify a representative set of subtopics covering the whole spectrum of different user needs/intentions. Subtopics are based on infor-mation extracted from the logs of a commercial search engine, and are roughly balanced in terms of popularity. Obviously overall performance of diversification methods to be evaluated and compared. Since diversity and topic coverage are key issues also for the query recommendation task ( Ma, Lyu, &amp; King, 2010 ), we propose to use the same third-party dataset for evaluating query suggestion effectiveness as well.
 Let X  X  now introduce the definitions of coverage , and effectiveness .

Definition 4. [Coverage] Given a query topic A with subtopics { a that T has coverage equal to c if n c subtopics match suggestions generated by T .

In other words, a coverage of 0.8 for the top-10 suggestions generated for a query q having 5 subtopics means that 4 sub-topics of q are covered by at least one suggestion.

Definition 5. [Effectiveness] Given a query topic A with subtopics { a generating k suggestions, we say that T has effectiveness equal to e if k e suggestions cover at least one subtopic.
In other words, an effectiveness of 0.1 on the top-10 suggestions generated for a query q means that only one suggestion is relevant for one of the subtopics of q .

The methodology just described has some net advantages. It is based on a publicly-available test collection which is pro-vided by a well reputed third-party organization. Moreover, it grants to all the researchers the possibility of measuring the performance of their solution under exactly the same conditions, with the same dataset and the same reproducible evalu-ation criterium. In fact, even though the matching between suggestions and topics is still human-driven the process has a very low ambiguity as we shall discuss in the next section. 4.1. Experimental settings
The experiments were conducted using the Microsoft RFP 2006 query log which was preliminary preprocessed by con-verting all queries to lowercase, and by removing stop-words and punctation/control characters.

The queries in the log were then sorted by user and timestamp, and segmented into sessions on the basis of a splitting algorithm which simply groups in the same session all the queries issued by the same users in a time span of 30 min. We of our technique, we did not observe a significant variation in terms of quality of the generated suggestions.
Noisy sessions, likely performed by software robots, were removed. The remaining entries correspond to approximately 9M sessions. These were split into two subsets: training set with 6M sessions and a test set with the remaining 3M sessions.
The training set was used to build the recommendation models needed by CG and QFG and used for performance comparison.

Instead, to implement our SS solution we extracted satisfactory sessions present in the training set and grouped them on the basis of the final query. Then, for each distinct final query its corresponding virtual document was built with the terms (with possible repetitions) belonging to all the queries of all the associated satisfactory sessions. Finally, by means of the Terrier search engine ( http://www.terrier.org/ ), we indexed the resulting 1,191,143 virtual documents. The possibil-ity of processing queries on such index is provided to interested readers through a simple web interface available at the address http://www.searchshortcuts.isti.cnr.it . The web-based wrapper accepts user queries, interact with Terrier to get the list of final queries (id of virtual documents) provided as top-k results, and retrieves and visualizes the associated query strings. 4.2. TREC queries statistics We measured the popularity of the 50 TREC 2009 Web Track X  X  Diversity Task queries in the training set obtained by the Microsoft RFP 2006 dataset as described in the previous section. Fig. 2 shows the cumulative frequency distribution of the 50
TREC queries. While 8/50 queries are not present in the training set, 2/50 queries occur only one time. Furthermore, 23/50 queries have a frequency lower than 10 and 33/50 queries occur lower than 100 times. The TREC dataset thus contains a valid popular queries are represented as well. Table 2 shows some queries with their popularity measured in the training set. 4.3. Search Shortcuts metric
We used Eq. (1) to measure the similarity between the suggestions generated by SS, CG, and QFG for the first queries is-sued by a user during a satisfactory session belonging to the test set, and the final queries actually submitted by the same user during the same session. We conducted experiments by setting the number k of suggestions generated to 10, and, as in
Baraglia et al. (2009) , we chose the exponential function f ( m )= e the metric used to assess the similarity between two queries was the Jaccard index computed over the set of tri-grams of characters contained in the queries ( J X rvelin, J X rvelin, &amp; J X rvelin, 2007 ), while the similarity threshold used was 0.9.
Due to the long execution times required by CG, and QFG for generating suggestions, it was not possible to evaluate sug-gestion effectiveness by processing all the satisfactory sessions in the test set. We thus considered a sample of the test set constituted by a randomly selected group of 100 satisfactory sessions having a length strictly greater than 3. The histogram in Fig. 3 plots the distribution of the number of sessions vs. the quality of the top-10 recommendations produced by the three algorithms. Results in the plot are grouped by quality range. As an example, the second group of bars shows the number of sessions for which the three algorithms generated suggestions having a quality (measured using Eq. (1) ) ranging from 0.1 to 0.2. Results show that recommendations produced for the majority of sessions by QFG and CG obtains a quite low score (in the interval between 0 and 0.1), while SS produces recommendations whose quality is better distributed among all the range.

In particular, SS produces recommendations having a quality score greater than 60% for 18 sessions out of 100. Moreover, in 36 cases out of 100, SS generates useful suggestions when its competitors CG and QFG fails to produce even a single effec-tive suggestion. On average, over the 100 sessions considered, SS obtains an average quality score equal to 0.32, while QFG and CG achieves 0.15 and 0.10, respectively. 4.4. Suggestions quality on TREC topics
The relevance of the suggestions generated by SS, CG, and QFG w.r.t. the TREC query subtopics was assessed manually.
Seven volunteers were chosen among CS researchers working in different research groups of our Institute. The evaluation consisted in asking assessors to assign, for any given TREC query, the top-10 suggestions returned by SS, CG, and QFG to their related subtopic. Editors were also able to explicitly highlight that no subtopic can be associated with a particular recom-mendation. The evaluation process was blind, in the sense that all the suggestions produced by the three methods were pre-sented to editors in a single, lexicographically ordered sequence where the algorithm which generated any specific suggestion was hidden. Given the limited number of queries and the precise definition of subtopics provided by NIST asses-sors, the task was not particularly cumbersome, and the evaluations generated by the assessors largely agree. Table 1 shows the outcome of one of the editors for the TREC query no. 8. The note in bold after each suggestion indicates the subtopic to which the particular suggestion was assigned (e.g. employee appraisals in the CG column matches subtopic S3). Thus for this topic this editor gave to both SS and CG a coverage of 3/4 (3 subtopics covered out of 4), while QFG was rated 1/4. Moreover, topic appraisals SS and QFG score an effectiveness equal to 1 (all suggestions generated were considered relevant), whereas CG score was 4/5 (2 non relevant suggestions out of 10).
 number of sessions
The histogram shown in Fig. 4 plots, for each of the 50 TREC topics, the average coverage ( Definition 4 ) of the associated subtopics measured on the basis of assessor X  X  evaluations for the top-10 suggestions returned by SS, CG, and QFG. By looking half of the subtopics, while CG only in two cases reached the 50% of coverage, and QFG on 8 queries out of 50. Moreover, SS covers the same number or more subtopics than its competitors in all the cases but 6. Only in 5 cases QFG outperforms SS in subtopic coverage (query topics 12, 15, 19, 25, 45), while in one case (query topic 22) CG outperforms SS. Furthermore, while
SS is always able to cover one or some subtopics for all the cases, in 15 (27) cases for QFG (CG) the two methods are not able to cover any of the subtopics. The average fraction of subtopics covered by the three methods is: 0.49, 0.24, and 0.12 for SS, QFG, and CG, respectively.
 performancemetricourSearchShortcutssolutionresultsthe clearwinner.SSoutperformsitscompetitorsin31casesoutof50.
Theaverageeffectivenessis0.83,0.43,and0.42forSS,QFG,andCG,respectively.Thelargedifferencemeasuredismainlydueto the fact that both CG and QFG are not able to generate good suggestions for queries that are not popular in the training set. Regarding this aspect, the histogram in Fig. 6 shows the average effectiveness of the top-10 suggestions returned by SS,
CG and QFG measured for groups of TREC queries arranged by their frequency in the training set. SS remarkably outperforms its competitors. SS is in fact able to produce high-quality recommendations for all the categories of query analyzed, while CG and QFG can not produce recommendations for unseen queries. Furthermore, while SS produce constant quality recommen-dations with respect to the frequency of the TREC queries, CG and QFG show an increasing trend in the quality of recommen-dations as the frequency of the TREC queries increases.

For this reason, we can assert that the SS method is very robust to data sparsity which strongly penalizes the other two algo-the Web search engine . We recall that singleton queries account for almost half of the whole volume of unique queries sub-mitted to a Web search engine, and are often the hardest to answer since they ask for  X  X  X are X  X  or badly expressed information needs. The possibility of suggesting relevant alternatives to these queries is more valuable than the one of suggesting rele-vant alternatives to frequent queries, which express common and often easier to satisfy needs.

Just to give an example of the results we obtained and the data on which we evaluated the quality, Table 3 reports the top-10 suggestions provided by SS, CG, and QFG for some TREC Web Track X  X  diversity task query topics. For each query topic,
SS computed mostly relevant suggestions covering a significant subset of the subtopics. CG, on the other hand, performed worst and returned three suggestions only for a single query among the five reported in the table, and one single suggestion in another case. QFG returned instead 10 suggestions for three topics, and no suggestions in two cases. 5. Conclusions
We proposed a very efficient solution for generating effective suggestions to Web search engine users based on the model of Search Shortcut . Our original formulation of the problem allows the query suggestion generation phase to be re-conducted to the processing of a full-text query over an inverted index. The current query issued by the user is matched over the in-verted index, and final queries of the most similar satisfactory sessions are efficiently selected to be proposed to the user as query shortcuts. The way a satisfactory session is represented as a virtual document, and the IR-based technique exploited, allow our technique to generate in many cases effective suggestions even to rare or not previously seen queries. to generate at least a suggestion.

By using the automatic evaluation approach based on the metric defined in Eq. (1) , SS outperformed QFG in quality of a 0.17, while the improvement over CG was even greater (0.22). In 36 evaluated sessions out of 100, SS generated useful sug-gestions when its competitors CG and QFG failed to produce even a single useful recommendation.

An additional contribution of the paper regards the evaluation methodology used, based on a publicly-available test col-lection provided by a highly reputed organization such as the NIST. The proposed methodology is objective and very general, and, if accepted in the query recommendation scientific community, it would grant researchers the possibility of measuring the performance of their solution under exactly the same conditions, with the same dataset and the same evaluation criterium.

On the basis of the evaluation conducted by means of the user-study, SS remarkably outperformed both QFG and CG in almost all the tests conducted. In particular, suggestions generated by SS covered the same number or more TREC subtopics than its two counterparts in 44 cases out of 50. In 36 cases the number of subtopics covered by SS suggestions was strictly greater. Only in 5 cases QFG outperformed SS, while this never happens with CG. Also when considering effectiveness, i.e. the number of relevant suggestions among the top-10 returned, SS resulted the clear winner with an average number of relevant to be very robust w.r.t. data sparsity, and can produce relevant suggestions also to queries which are rare or not present in the query log used for training.

All the queries suggested by the three algorithms for the 50 TREC queries given as input to assessors are available along with the associated subtopic lists at http://www.searchshortcuts.isti.cnr.it/TREC_results.html . Moreover, a simple web-based wrapper that accepts user queries and computes the associated top-20 SS recommendations is available at http:// www.searchshortcuts.isti.cnr.it .
 As future works we intend to evaluate the use the whole head of the user session for producing query recommendations. the satisfactory user sessions. By studying such relation which is at the basis of our query shortcut implementation, we could probably find ways to improve our methodology. Finally, it would be interesting to investigate how IR-like diversification der to obtain diversified query suggestions (Bordino, Castillo, Donato, &amp; Gionis, 2010; Ma et al., 2010). Acknowledgments This work was partially supported by the EU-PSP-BPN-250527 (ASSETS), the EU-FP7-215483 (S-CUBE), and the POR-FESR-63748 (VISITO Tuscany) projects. We also acknowledge the authors of Boldi et al. (2008) and the Yahoo! Research Lab of Barcelona for providing us the possibility of using their Query Flow Graph implementation for evaluation purposes. References
