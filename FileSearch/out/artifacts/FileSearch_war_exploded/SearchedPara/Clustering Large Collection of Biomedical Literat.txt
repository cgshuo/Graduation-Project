 Document clustering was initially investigated for improving information retrieval (IR) performance (i.e. precision and recall) because similar documents grouped by document clustering tend to be relevant to the same user queries [1] [2]. However, because document clustering was too slow or infeasible for very large document sets in early days, it was not widely used in IR systems [3]. As faster clustering algorithms have been introduced and those have been adopted in document clustering, document topic structures [7]. Thus, as information grows exponentially, document clustering plays a more important role for IR and text mining communities. However, traditional document clustering approaches have four main problems. First, when the approaches represent documents based on the bag of word model, they use all words/terms in documents. As Wang et al pointed out [8], only a small number of words/terms in documents have distinguishable power on clustering documents. Words/terms with distinguishable power are normally the concepts in the domain related to the documents. Second, the approaches do not consider semantically related words/terms (e.g. synonyms or hyper/hyponyms). For instance, they treat {Cancer, Tumor, Neoplasm, Malignancy} as the different terms even though all these words have similar meaning. Third, the approaches cannot provide an explanation of why a document is grouped into one of document clusters [9] because they pursue similar-ity-based mechanism on clustering, which does not produce any models or rules for document clusters. Lastly, the approaches are based on vector space model. The use of vector space representation on document clustering causes the two main problems. space are considered independently. In other words, the model assumes that words/terms are mutually independent in a document. However, most words/terms in dimensional space significantly hampers the similarity detection for objects (here, documents) because the distance between every pair of objects tends to the same regardless of data distributions and distance functions [10]. Thus, it dramatically de-creases clustering performance. 
These problems have motivated this study. In this paper, we introduce a novel document clustering approach that solves all the four problems stated above. The rest of the paper is organized as follows. Section 2 surveys the related work. In section 3, we propose a novel graph-based document clustering approach that uses domain knowledge in ontology. An extensive experimental evaluation on MEDLINE articles is conducted and the results are reported in section 4. Finally, we conclude the paper with the three main contributions and future work. Many document clustering approaches have been developed for several decades. Most of document clustering approaches are based on vector space representation and apply various clustering algorithms to the representation. To this end, the approaches can be categorized according to what kind of cluste ring algorithms are used. Thus, we clas-sify the approaches into hierarchical and partitional [11]. 
Hierarchical agglomerative clustering al gorithms were used for document cluster-ing. The algorithms successively merge the most similar objects based on the pairwise distances between objects until a termination condition holds. Thus, the algorithms can be classified by the way they pick the pair of objects for calculating the similarity measure; for example, single-link, complete-link, and average-link. Partitional clus-tering algorithms (especially K-means) are the most widely-used algorithms in docu-ment clustering [12]. Most of the algorithms first randomly select k centroids and then decompose the objects into k disjoint groups through iteratively relocating objects based on the similarity between the centroids and the objects. The clusters become optimal in terms of certain criterion functions. 
There are some hybrid document clustering approaches that combine hierarchical and partitional clustering algorithms. For instance, Buckshot [3] is basically K-means but Buckshot uses average-link to set cluster centroids with the assumption that hier-archical clustering algorithms provide supe rior clustering quality to K-means. In order average-link algorithm; to make the overall complexity linear, Buckshot selects kn objects. However, as Larsen &amp; Aone [13] pointed out that using hierarchical algo-rithm for centroids does not significantly improve the overall clustering quality, com-pared with the random selection of centroids. 
Recently, Hotho et al. introduced the semantic document clustering approach that uses background knowledge [9]. The authors apply ontology during the construction of vector space representation by mapping terms in documents to ontology concepts and then aggregating concepts based on th e concept hierarchy, which is called con-cept selection and aggregation (COSA). As a result of COSA, they resolve a synonym problem and introduce more general concepts on vector space to easily identify re-lated topics [9]. Because they cannot reduce the dimensionality (i.e. the document features) on vector space, it still suffers from  X  Curse of Dimensionality  X . In addition, COSA cannot reflect the relationships among the concepts on vector space due to the limitation of vector space model. We present a novel approach for C lustering O ntology-enriched B ipartite G r aph Rep-resent a tion, called COBRA. The proposed approach consists of three main steps: (1) bipartite graph representation for documents through concept mapping, (2) initial clustering by combining co-occurrence concepts based on their semantic similarities on concept hierarchy and document subsets th at share co-occurrence concepts, and (3) mutual refinement strategy for concept groups and document clusters. Before discuss-ing these three main components in detail we first briefly discuss Medical Subject Headings (MeSH) as a biomed ical ontology due to its importance in our approach. 
Medical Subject Headings (MeSH), published by the National Library of Medicine in 1954, mainly consists of the controlled vocabulary and MeSH Tree. The controlled vocabulary contains several different types of terms. Among them Descriptor and Entry terms are used in this research because only they can be used for graph repre-sentation. Descriptor terms are main concepts or main headings. Entry terms are the synonyms or the related terms to descriptors. For example,  X  X eoplasms X  as a descrip-tor has the following entry terms { X  X ancer X ,  X  X ancers X ,  X  X eoplasm X ,  X  X umors X ,  X  X umor X ,  X  X enign Neoplasms X ,  X  X eoplasms, Benign X ,  X  X enign Neoplasm X ,  X  X eo-plasm, Benign X  X . MeSH descriptors are organized in MeSH Tree, which can be seen as MeSH Concept Hierarchy. In MeSH Tree there are 15 categories (e.g. category A for anatomic terms) and each category is further divided into subcategory. For each subcategory, corresponding descriptors are hi erarchically arranged from most general to most specific. In fact, because descriptors normally appear in more than one place in the tree, they are represented in a graph rather than a tree. In addition to its ontol-ogy role, MeSH descriptors were originally used to index MEDLINE articles. For this purpose around 10 to 20 MeSH terms are manually assigned to each article (after reading full papers). On the assignment of MeSH terms to articles around 3 to 5 MeSH terms are set as  X  X ajorTopic X  which primarily represent an article. 3.1 Bipartite Graphical Representa tion for Document s Through Concept Every document clustering method first needs to convert documents into proper for-mat (e.g. document*term matrix). Since we recognize documents as a set of concepts that have their complex internal semantic relationships and assume that documents could be clustered based on what concepts they contain, we represent a set of docu-ments as a bipartite graph to indicate the relationships between concepts and docu-ments on the graph. 
This procedure takes the following three steps: concept mapping in documents, de-tection of co-occurrence concepts, and construction of bipartite graph representations with co-occurrence concepts. Firstly, it maps terms in each document into MeSH concepts. In order to reduce unnecessary search for MeSH concepts, it removes stop words from each document and generates three gram-words as the candidates of MeSH Entry terms. After matching the candidates with Entry terms it replaces Entry terms with Descriptor terms, which is called concept aggregation . Then it filters out some MeSH terms that are too general (e.g. HUMAN, WOMEN or MEN) or too common over MEDLINE articles (e.g. ENGLISH ABSTRACT or DOUBLE-BLIND METHOD); see [14] for details. We assume that those terms do not have distinguish-able power on clustering documents. 
In the second step, it finds out co-occurrence concepts from sets of concept pairs in each document based on the number of times they appear in documents. Co-occurrence terms have long been used in document retrieval systems to identify in-dexing terms during query expansion [15] [16]. We use co-occurrence concepts in-stead of concepts because co -occurrence concepts contain some semantic associations between concepts and thus they are regarded more important than single concept. 
The remaining problem for co-occurrence co ncepts is how to set the threshold value for co-occurrence counts; concept pa irs whose co-occurrence counts equal or bigger than the value are considered as co -occurrence concepts. Because the threshold value fairly depends on documents or query to retrieve documents, we develop a sorts the data, takes as centroids the two end objects, and then assigns the remaining objects to the two centroids based on the distances with dynamic centroids update; because the data (co-occurrence counts) was already sorted, it does not need any itera-co-occurrence concepts are mirrored as ed ges on the graph and their co-occurrence counts are used as edge weights. In the third step, it constructs a bipartite graph. Given the graph G = (V D +V CC , E) , V documents and E indicates the relationships between two vertices. Weights can be optionally specified on edges. In that case one should provide a sophisticated weight scheme to measure the contribution of con cepts to each document. However, such a weight scheme may not be appropriate especially for small size of documents, such as draw an unweighted bipartite graph. 3.2 Initial Clustering by Combining Co-occurrence Concepts Here, COBRA generates initial clusters for the next step by combining co-occurrence concepts. Since similar documents share the same or semantically similar co-occurrence concepts, COBRA combines co-o ccurrence concepts and then cluster documents based on their similarities to k co-occurrence concept groups. On combin-ing them there are two ways to measure the similarity between co-occurrence con-their document sets ( sim doc ). We integrate the two measures with weights. Given two periments) sim CC CC sim CC CC sim CC CC =+ X  ii ,with  X  [0,1] as weights  X 
The semantic similarity between two co-occurrence concepts ( CC i &amp; CC j ) on con-information theoretic based measure [17]. It is defined as the ratio between the amount of information needed to state th e commonality of co-occurrence concepts terms of the number of relevant documents. where 
Based on average-link clustering algorithm that uses the integrated similarity func-tion, COBRA combines co-occurrence concepts until we get k co-occurrence concept groups. For initial document clusters COBRA links each document to k co-occurrence concept groups based on its similarity to k groups. This similarity is simply measured by the number of times co-occurrence concep ts in each document appear in each of k groups. A document is assigned to the most similar co-occurrence concept group. For example, suppose there are two co-occurrence concept groups (CCG 1 ={CC 1 , CC 2 , CC 3 }, CCG 2 ={CC 4 , CC 5 }) and a document has CC 2 , CC 3 , and CC 5 . Then, the docu-ment is assigned to CCG 1 . 3.3 Mutual Refinement Strategy for Document Clustering Through the procedures above COBRA generates initial clusters. However, this clus-tering cannot correct erroneous decisions li ke hierarchical clustering methods. In other words, once clustering procedures are performed, the clustering results are never refined further even if the procedures are based on local optimization. 
In this procedure COBRA  X  X urifies X  the initial document clusters by mutually re-fining k co-occurrence concept groups and k document clusters. The basic idea of the mutual refinement strategy for document clustering is the followings.  X  A co-occurrence concept should be linked to the document cluster to which the  X  A document cluster should be related to co-occurrence concepts that make sig-
For this mutual refinement strategy we draw another bipartite graph. Given the a set of co-occurrence concepts in documents and E indicates the relationships be-tween two vertices. We specify weights on edges so that we measure the contribution of co-occurrence concepts to each document cluster. This contribution is defined as the ratio between the amount of informatio n needed to state the co-occurrence con-cepts in a document cluster and the total information in the document cluster in terms of the number of documents. set of documents with co-occurrence concept ( CC i ) in the document cluster ( DC k ). 
After each refinement, using k new co-occurrence concept groups, each document is reassigned to the proper document cluster in the same way used for generating initial clusters. This mutual refinement iteration continues until no further changes occur on the document clusters. In order to measure the performance of COBRA, we conduct experiments on public MEDLINE documents (abstracts). For the experiments first we collect several ab-stract sets about various diseases from PubMed. Specifically, we use  X  X ajorTopic X  tag in detail). Table 1 shows each document set and its size. After retrieving the data sets, we generate various document combinations whose numbers of classes are 2 to 10 using the document sets. Each document set used for the combinations is later used as an answer key on the performance measure. 
There are a number of clustering evaluation methods. Among them we use mis-classification index (MI) [18] as a measure of cluster quality since MI intuitively shows the overall quality of generated clusters. MI is the ratio of the number of mis-classified objects to the size of the whole da ta set [18]; thus, 0% MI means the perfect clustering. 
We evaluate our approach to see how much COBRA provides better clustering re-sults compared with two leading document clustering approaches, and to check if the mutual refinement strategy is able to improve clustering quality. 4.1 Comparison of COBRA, BiSecting K-Means and CLUTO We apply COBRA to MEDLINE articles to compare its performance with two lead-ing document clustering approaches BiSecting K-means and CLUTO X  X  v cluster (http://www-users.cs.umn.edu/~karypis/cluto). Two recent document clustering stud-ies showed BiSecting K-means outperforms traditional hierarchical clustering method and K-means on various document sets from TREC, Reuters, WebACE, etc, [12] [19]. A recent comparative study showed CLUTO X  X  v cluster outperforms several model-based document clustering algorithms [20]; none of studies have compared the two approaches. 
For the experiments we generated the various document collections using docu-ment sets in Table 1. These corpora include very large corpus sets (Cx.3 as Corpus ID in Figure 1) whose size are more than 50k; most document clustering studies [13][19][20][21] used at most 8.3k to 20k size corpora for their experiments. Figure 1 shows MI results (smaller is better) for the three approaches. Table 2 shows averages clustering performance consistence index for the approaches. These experiment re-sults indicate that COBRA outperforms BiSecting K-means and CLUTO. As Table 2 shows, COBRA consistently produces better clustering results for various corpus sets. CLUTO yields more or less comparable clustering results with COBRA. But some-times (for C2.2, C4.1, C6.1, C10.2, C3.3, &amp; C10.3) CLUTO outputs poor clusters. We believe that a prestigious document clustering should consistently produce high-quality clustering results for various document sets. 4.2 Evaluation of Mutual Refinement Strategy on Document Clustering We evaluate mutual refinement strategy (MRS) to check if MRS is able to improve overall clustering quality. For this evaluation we measured MIs before and after MRS process. Table 3 shows MI improvement through mutual refinement strategy (MRS). We notice that MRS significantly improves the performance of COBRA. We also observe that, without this iterative MRS, COBRA still yields comparable performance with CLUTO. In this paper, we mainly discussed how ontology is incorporated into document clus-tering procedures and how ontology-enriched bipartite graph representation and mu-tual refinement strategy improves the document clustering results. The main contribu-tions of this paper are fourfold. Firs t, COBRA becomes a new leading document clustering approach in terms of performance. Second, we introduce a new way of the use of domain knowledge in ontology on document clustering without depending on vector space model. Third, COBRA provides a meaningful explanation for each document cluster by identifying its most co ntributing co-occurrence concepts. Fourth, we introduce mutual refinement strategy to improve clustering quality. The strategy can be applied to virtually every document clustering approach. 
