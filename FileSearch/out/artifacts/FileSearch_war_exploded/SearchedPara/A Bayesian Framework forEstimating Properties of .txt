 The analysis of network connections, diffusion processes and cascades requires evaluating properties of the diffusion net-work. Properties of interest often involve variables that are not explicitly observed in real world diffusions. Connection strengths in the network and diffusion paths of infections over the network are examples of such hidden variables. These hidden variables therefore need to be estimated for these properties to be evaluated. In this paper, we pro-pose and study this novel problem in a Bayesian framework by capturing the posterior distribution of these hidden vari-ables given the observed cascades, and computing the expec-tation of these properties under this posterior distribution. We identify and characterize interesting network diffusion properties whose expectations can be computed exactly and efficiently, either wholly or in part. For properties that are not  X  X ice X  in this sense, we propose a Gibbs Sampling frame-work for Monte Carlo integration. In detailed experiments using various network diffusion properties over multiple syn-thetic and real datasets, we demonstrate that the proposed approach is significantly more accurate than a frequentist plug-in baseline. We also propose a map-reduce implemen-tation of our framework and demonstrate that this can an-alyze cascades with millions of infections in minutes. H.2.8 [ Database Management ]: Database Application X  Data mining Social Influence Analysis; Information Cascades; Networks of Diffusion; Bayesian Analysis; Gibbs Sampling
The study of networks and diffusions over them has a long history in epidemiology, sociology, econometrics and market-The first two authors have contributed equally to this work ing. Interest in the problem has increased many fold over the last two decades in the context of information diffusion and social networks, first because of the growth of the in-ternet, and then the social media revolution [2, 13]. The study typically involves three different objects of interest: a network that defines connection strengths between entities, a diffusion process that defines how  X  X nfections X  spread ran-domly over the network, and cascades that trace the spread of specific infections over the network. Many different prob-lems have been studied in the context of these three objects of interest. A problem that has received a lot of attention where the task is to infer the hidden network of connection strengths from the cascades.

However, inferring the network of diffusions is often an intermediate task in the analysis. The main objective is often to compute some property of the network and/or the cascades, such as centrality and reach of individual nodes, optimal seeds for viral marketing [14, 12, 10], community structures [17, 1], the likelier diffusion mechanism [18], etc.
An example of such a property is the identity of  X  X ribe leaders X  [10], who are well connected to a large tribe of nodes in the network, and whose tribe members follow their ac-tions frequently in the cascades. Computing this notion of node influence is expensive even when the cascades are com-pletely observed, but consider a simplification that is still in-teresting. Consider the out-degree of a node in the network, counting only those edges that are strong and also frequently used in the cascades. This influence score is much simpler to compute given completely observed networks and cascades, and yet is useful for marketers and epidemiologists.
In Fig. 1, we show the strength-frequency distribution of edges in four different synthetically-generated network dif-fusions. The x -axis shows edge strength (  X  ) and the y -axis transmission frequency (  X  ), which is the number of times an edge was used to transmit infections in the cascades. The distribution only considers actual edges used in the cas-cades. Fig. 1(a) through Fig. 1(d) correspond to Forest Fire, Core-Periphery, Random and Hierarchical graphs re-spectively, each with 1024 nodes and  X  2000 edges. In each case, we generated 20 splitting, independent cascades [22] over these graphs with 2 randomly chosen seeds for each cascade. The plots can also be interpreted as the distribu-tion of the simpler node influence score discussed above. The plots clearly show that these distributions look very differ-ent depending on the underlying network connections and possibly also the diffusion mechanism. Thus, given network diffusion data from some network with unknown structure and diffusion mechanism, it is clearly of interest to construct and study such distributions.

In this paper, we investigate such joint properties of net-works and cascades. The main difficulty in evaluating such properties for real-world network diffusions is that the con-nections strengths in the network are unknown. Addition-ally, the diffusion edges are also unknown  X  the cascades only record the catchers of the infections and the infection times, but not the actual path traced by specific infections. For example, in social information flows, the friends and fol-lowers are known, but not the extent of influence between them, and often users do not reveal the sources of infor-mation. Therefore, to evaluate the properties, these hidden variables need to be inferred from the observed cascades.
One way to evaluate a property is to take the  X  X requentist plug-in approach X , that finds point estimates of the network and the diffusion edges in the cascades, and then evaluates the property using these point estimates. The most popular point estimate used for network inference is the maximum likelihood estimate [6, 22]. This approach for evaluating properties has two drawbacks. The first is the well known problem of overfitting for a frequentist approach. More im-portantly, for properties that are not one-to-one functions of the network and the diffusion paths, the most likely value of the property need not correspond to the most likely network and diffusion paths. Fig. 2(a) shows the reconstructed edge distribution for the Core-Periphery diffusion data using this frequentist approach. It has failed to recover the signature shape of the distribution.

In this paper, we motivate and propose a Bayesian solu-tion to this problem, where both the network and the dif-fusion paths are modeled as random variables. This makes network diffusion properties functions of random variables, and our problem becomes one of computing the expecta-tion of the property under the posterior distribution of the hidden variables given the observed features of the cascade.
An obvious challenge for the Bayesian approach is the cost of computing expectations. This seems daunting for the net-work inference problem with its large number of coupled dis-crete and continuous hidden variables. However, our analy-sis shows that for the popular independent cascade model, many interesting network diffusion properties are  X  X ice X , in that their expectations can be computed exactly and effi-ciently, at least in part. For parts of the expectations that are not  X  X ice X , we propose a Gibbs Sampling technique for efficient Monte Carlo integration. Fig. 2(b) shows the re-construction of the Core-Periphery strength-frequency dis-tribution using our proposed approach. It has recovered the distinctive shape to a much better extent.

In detailed experiments using various network diffusion properties over multiple synthetic and real datasets, we demon-strate that the proposed approach is significantly more accu-rate than the MLE plug-in baseline, and is useful for tradi-tional network inference as well. We show that the approach scales easily to very large datasets using a map-reduce im-plementation.
Different problems have been studied in the context of diffusion networks [2, 13]. The network inference problem [21, 7, 6, 8, 4, 9, 19, 22, 15] has been investigated in depth, starting with stationary discrete time models [19], to the more recent models that consider features [22] and time-varying networks [9]. The solutions have mostly been based on maximum-likelihood estimation.

Apart from inferring the complete network structure, there has been work on inferring summaries of the network, such as community structures [17, 1]. Other investigated proper-ties are estimating influence of nodes [3], and subsequently selecting a subset of nodes that maximize influence [12]. Sadikov et. al. [20] study various properties of cascades assuming completely missing infections.

Milling et. al. [18] study the problem of deciding which of two given networks caused a specific diffusion with its path properties observed. Efficient algorithms have been designed for identifying leaders and tribes [10] and mining propaga-tion summaries [16] from cascades, assuming the underlying network and the diffusion paths to be known. These prob-lems may be seen as computing joint properties of networks and cascades, with all variables observed.

In summary, we are not aware of any general framework for estimating joint properties of networks and diffusion pro-cesses in the context of hidden network and diffusions paths. We are also not aware of any Bayesian framework for net-work diffusion analysis.
In this section, we first review the network diffusion prob-lem and the independent cascade model. Then we define network diffusion properties and their expectations. Network Diffusion and Independent Cascade Model: We assume a network G = ( V,E ) with nodes V and edges E . For ( u,v )  X  E , let  X  uv  X  X  + denote the connection strength between nodes u and v . We have a set C of cascades corre-sponding to spreading infections over the network G . Each cascade c  X  C consists of a set of time-stamped infections: c = { ( u i ,z i ,t i ) } . The i th infection records that node u infected at time t i by its parent infection z i . We will assume that t i &lt; t j for i &lt; j . Let  X  i  X  { 1 ...i  X  1 } denote the set of  X  X otential parents X  for the i th infection, so that z i Observe that the infecting parent z i provides edge informa-tion for reconstructing the infection paths over the network. We also know that the cascades were observed for time T , which is at least as large as the final infection time.
The joint distribution p ( C |  X  ) on the cascades C given the network strengths is typically defined using a generative process that captures the dynamics of spreading infections. While many diffusion models have been proposed, we follow the popular Continuous-Time Independent Cascade Model [6]. Under this model, each cascade starts with an initial set of seed nodes getting infected. Each infected node proposes an infection times for each currently uninfected neighbor in the network. An uninfected node catches its infection from that infected neighbor who has proposed the earliest infection time for it. We consider the setting where nodes can get infected multiple times in the same cascade, and the splitting model for this [22], where all infections between the current and the previous infections of a node are considered as its potential parents.

The main building block of the model is the probability ditional likelihood of node u i getting infected at time t node u j which got infected at time t j for t j &lt; t i . [6, 22]: where S ( t ) = 1  X  F ( t ) is the survival function, H ( t ) = f ( t ) /S ( t ) is the hazard function corresponding to the CDF Assuming cascades to be generated iid , the likelihood of C becomes p ( C |  X  ) = Q c  X  C p ( c |  X  ).

In real-world network diffusions, many of the variables above are unobserved. We will assume that the observed trace C o = { c o } of the cascade C only contains the infected node u i and the infection time t i : c o = { ( u i ,t i ) } . The in-fecting parent z i is not observed. The posterior distribution p ( z |{ c o } , X  ) over infection parents, conditioned on observed cascades { c o } and  X  , has the following form: Observe that this decouples into terms involving individual infection parents z i . This will be a key property for efficient computation of network diffusion properties in Sec. 5.
The network connection strengths  X  uv are also typically unobserved. Further, we assume that the set of network edges E is also not known. Therefore, we consider  X  to be a | V | X | V | matrix of unknown variables. The goal of the popular network inference problem is to reconstruct this  X  matrix using { c o } [6, 22]. The state-of-the-art approach is to obtain a maximum likelihood estimate:
For modeling f ( t i | u i ,u j ,t j ;  X  ), the Exponential, Power-law and Rayleigh distributions have been proposed [6, 22]. For the Exponential distribution, and for the Rayleigh distribution, Network Diffusion Properties and Expectations: Given this background, we now define our problem. We are interested in computing properties f (  X ,C ) of the cascades C and the network connections  X  . Two examples properties are the strength-frequency distribution of edges, and influence of leader nodes. We will see more examples in Sec. 5.
Since  X  and z are unobserved, the properties are not di-rectly computable. We investigate a fully Bayesian solu-tion to the problem, where we model both  X  and z to be random variables, so that the property f (  X ,z ) is a func-tion of random variables. Assuming a joint distribution p ( C, X  ) to be defined on the cascade C and the network con-nections strengths  X  , we consider the posterior distribution p ( z, X  |{ c o } ) over the hidden variables z and  X  conditioned on the observed trace c o = { ( u i ,t i ) } of the cascades. Then we evaluate the expectation  X  f ( C, X  ) of f ( C, X  ) under this posterior distribution: For properties that do not involve z , we consider the expec-tation under the marginal posterior distribution p (  X  |{ c P z p ( z, X  |{ c erties that do not involve  X  .

Recall that existing approaches for network inference only model the conditional distribution p ( C |  X  ) assuming  X  to be given. In the rest of this paper, our goal is two fold: (a) augment this conditional using a prior p (  X  ) to model the joint distribution p ( C, X  ), (b) investigate tractability of this expectation for interesting network diffusion properties. We look at the first aspect in Sec. 4 and the second in Sec. 5.
In this section, we introduce a Bayesian framework that will enable us to compute expectations of network diffusion properties. For a Bayesian analysis, we need to model  X  as a random variable, with a prior distribution. Assuming an iid prior p (  X  ) = Q uv p (  X  uv ), the joint distribution is simply p ( C, X  ) = p ( C |  X  ) Q uv p (  X  uv ), and the posterior distribution p (  X  |{ c o } ,z ) looks as follows: u i = v,u z i = u } denoting infections of v by u ,  X  S uv Q u = u,u j = v ; j  X   X  i } denoting potential infections of v by u and T uv = { j : u j = u,l v &lt; t j } denoting survivals of v from u . Observe that this decouples into terms involving individual network strengths  X  uv . Efficient computation of network properties in Sec. 5 hinges critically on this, as on the decoupling in Eqn. 1.

Another requirement for efficient computation is analyt-ical integration of network properties with respect to  X  uv For this, we need conjugate priors . Both Rayleigh and Ex-ponential are special cases of the Weibull distribution (cor-responding to shape parameters 1 and 2) [3]. For likelihoods involving the Weibull distribution with given shape param-eter, the conjugate distribution is the Gamma distribution :
Substitution into Eqn. 4 gives us the following: where  X  uv ( z ) = | A uv ( z ) | ,  X  uv = P i,j tial distribution and 1 2 ( t i  X  t j ) 2 for the Rayleigh distribution. From now on we refer to  X  uv ( z ) as  X  uv .

This posterior is suitable for the network inference prob-lem. Consider a &lt; 1. Then using a suitable b , for no trans-missions across an edge,  X  uv = 0, and the posterior distribu-tion is peaked sharply at 0. This implies that in the absence of any transmission evidence in the cascade, there is very little belief in the existence of an edge. Once an observation is made and we have  X  uv  X  1, the posterior distribution is unimodal and peaked at ( a +  X  uv ) / ( b +  X  uv ).

When we have large volumes of data so that  X  uv a and  X  uv b , the mean of the posterior approaches the MLE. While the parameterization a &lt; 1 models prior belief in sparse network connections, it is also possible to make the Gamma prior noninformative if necessary, using a,b 1 [5].
In this section, we consider multiple types of network diffusion properties, and analyze the tractability of com-puting their expectations under the posterior distribution p ( z, X  |{ c 0 } ). Consider, as a motivation, the network dif-fusion property in the introduction that counts leaders of tribes. Computing this properties is hard even when all the network diffusion variables are observed, and we will see that computing the expectations with unobserved variables is not tractable. However, we will investigate simplifications of this properties that are interesting and useful, and at the same time allow their expectations to be computed efficiently.
We consider two different categories of network diffusion properties  X  network centric and cascade centric. In a network-centric property, the focus is on entities in the net-work, such as nodes, or edges, which satisfy some constraints in the network as well as in the cascade. The  X  X ounting lead-ers X  property is an example in this category, with nodes in the network being the focus. A cascade-centric property, on the other hand, is about entities in the cascade, such as individual infections, which satisfy certain cascade con-straints and additionally some network constraints. Before discussing more about such properties in Sec 5.2 and Sec 5.3, we first investigate conditions under which expectations of network diffusion properties are efficiently computable.
Given the large size of real-world network diffusion data, in all of the following discussion, we consider a computa-tion to be efficient if it is linear in the size of the network and the size of the cascade. Computing the expectation in-volves marginalizing out two variables: an integration over possible network strengths  X  , and a summation over possi-ble network paths defined by the infection parent variables z . We first analyze these two marginalizations separately, before looking at computing the complete expectation.
Integrating over  X  : First, we characterize properties for which the integration over  X  can be performed efficiently. We call such properties nice- X  . Intuitively, a nice- X  property decomposes into terms that involve the parent variables z , and individual connection strengths  X  uv . Additionally, the functions involving  X  uv should be amenable to analytical integration with p (  X  uv | z, { c o } ) which is in the Gamma form.
Definition 5.1. A property f (  X ,z ) is nice- X  if it can be written as g ( z ) Q u,v h uv (  X  uv ,z ) or as g ( z ) P alytically  X  u,v .

Theorem 5.1. Let f (  X ,z ) be nice- X  . Then computing the z -marginal  X  f z ( z ) = R  X  f (  X ,z ) p (  X  | z, { c
The notion of nice- X  can be extended to properties that depend only on  X  and not on z . Such properties f (  X  ) need to be of the form Q u,v h uv (  X  uv ) or P u,v h uv (  X  R h uv (  X  uv ) p (  X  uv | z, { c o } ) d X  uv can be performed analytically for all z . Note that the z -marginal  X  f z ( z ) is still a function of z through p (  X  | z, { c o } ) Also, properties that are indepen-dent of  X  are trivially nice- X  . Finally, this complexity corre-sponds to the scenario when no edge information is available. Given a set E of potential edges, the complexity is O ( | E | ).
Summing over z : Now we characterize properties for which the summation over infection parents z can be per-formed efficiently. We call such properties nice-z . Recall from Eqn. 1 that the posterior distribution p ( z |  X , { c composes into terms involving individual z i variables. Intu-itively, the summation over z can be performed efficiently if the property f (  X ,z ) also decomposes over z .

Definition 5.2. A property f (  X ,z ) is nice-z if it can be written either as g (  X  ) Q i h i ( z i , X  ) or as g (  X  ) P
Theorem 5.2. Let f (  X ,z ) be nice-z . Then the  X  -marginal  X  f time, where  X  = max i  X  i is the maximum number of poten-tial parents over all infections.

As for nice- X  , the notion of nice-z can be extended to properties that involve only z and ignore  X  . Note that for such properties, the  X  -marginal  X  f  X  (  X  ) still depends on  X  through the posterior distribution p ( z |  X , { c o } ). Also, a func-tion which is independent of z is trivially nice-z .
Marginalizing both  X  and z : For computing the com-plete expectation in Eqn. 3, both marginalizations need to be performed. We now investigate strategies for dong this. Interestingly, it turns out that the complete expectation can be computed efficiently and exactly for some network diffu-sion properties, which we call nice-z, X  .

Definition 5.3. A property f (  X ,z ) is nice-z, X  if it can lutions exist for R g uv (  X  uv ) p (  X  uv | z, { c o } ) d X 
Lemma 5.3. A property that is nice-z, X  is both nice- X  according to Defn. 5.1 and nice-z according to Defn 5.2.
In addition to being nice- X  and nice-z , nice-z, X  properties require decoupling of  X  and z variables, not just in the prop-erty, but also in the posterior distribution p (  X ,z |{ c is achieved by the  X  u z These cancel out the corresponding terms in p (  X ,z |{ c which are responsible for the coupling.

Theorem 5.4. Let f (  X ,z ) be nice-z, X  . Then the expec-tation  X  f (  X ,z ) can be computed in O (  X  | C | )) + O ( | V | up to a multiplicative constant.

The multiplicative constant in question is the inverse of the likelihood p ( { c o } ) of the observed variables in the cas-cades. This implies that we may not be able to compute the exact value of any nice-z, X  efficiently, but we may efficiently compare two different nice-z, X  properties.

In general, there will be properties for which any one or both marginalizations cannot be performed analytically or efficiently. In such cases, we resort to Monte Carlo tech-niques. Here, we will assume that it is possible to draw iid samples (  X  ( s ) ,z ( s ) ) from the joint distribution p (  X ,z |{ c and similarly (  X  ( s ) )  X  p (  X  |{ c o } ) and ( z ( s ) the marginal distributions. In Sec 6, we describe a Gibbs Sampling algorithm for drawing such samples.

First consider properties which are nice- X  but for which the subsequent marginalization P z f z ( z ) p ( z |{ c o not be performed efficiently. For such properties, we first obtain the z -marginal  X  f z ( z ) efficiently, and then use Monte Carlo summation for z :  X  f (  X ,z )  X  1
Similarly, consider properties which are nice-z but for which the subsequent marginalization R f  X  (  X  ) p (  X  |{ c over  X  cannot be performed efficiently. For such properties, we first obtain the  X  -marginal  X  f  X  (  X  ) efficiently, and then use Monte Carlo integration for  X  :  X  f (  X ,z )  X  1
Finally, for properties where neither of the two marginal-izations can be performed efficiently, we use Monte Carlo integration for both  X  and z :
Having characterized the notion of niceness for network diffusion properties in terms of computing expectations, we now return to our motivating properties, and analyze them in this light.
We first discuss network-centric properties, which involve computing scores for specific entities in the network, such as nodes, edges, etc. These scores are functions of the network connection strengths  X  and also of the cascade C . Recall that the network and the cascades are connected through the node index u i in the individual infections.

The basic building block for network scores of network en-tities is the direct connection strength  X  uv between nodes u and v . Using this, we can define the second-order network connection strength  X  (2) uv between u and v as P w  X  uw  X  its approximation max w min(  X  uw , X  wv ). Generalizing fur-ther, the r th -order connection strength  X  ( r ) uv between them
On the other hand, the building block for cascade scores of network entities is the direct transmission frequency  X  between u and v in the cascades, defined as P ij I ( u v,z i = j,u j = u ). This can be similarly generalized to define the second-order transmission frequency  X  (2) uv between u and v in the cascades as P w  X  uw  X  wv or its approximation max w min(  X  uw , X  wv ). The interpretation is that u frequently infects some node w , who in turn frequently infects v in the cascades. This can be similarly generalized further to define the r th -order transmission frequency  X  ( r ) uv , and finally  X 
Node-centric Properties: We now formally define our first motivating network diffusion property, that of find-ing influential nodes considering both network strengths  X  and transmission frequencies  X   X  uv .

Node influence score: Intuitively, a node X  X  influence score f (  X ,z ) is high if it has many  X  X ollowers X  v with high  X   X  high  X   X  uv . One way to capture this is to define Alternatively, we may couple  X   X  uv and  X   X  uv as P v  X   X  P  X  nor nice-z even when we consider only first and second order infections ( R = 2). So their computation requires sampling over both  X  and z . But it turns out that the definition for R = 1 is more tractable, as we see next.
Node influence score for direct infections: This is the special case of node influence score considering only directly connected nodes in the network who are also directly in-fected in the cascades: It turns out that this property is nice- X  , so that the ex-pectation can be calculated efficiently and exactly, in part. Though  X  uv ( z ) is itself nice-z , Eqn. 8 is not nice-z since discretization of  X  uv ( z ) through I (  X  uv ( z )  X  r ) leads to cou-pling across z i variables. This implies that the alterna-tives f u (  X ,z ; a ) = P v I (  X  uv &gt; a )  X  uv ( z ) and f P z, X  , providing two different routes for partly approximating their expectations.

As a further simplification of Eqn. 8, we may restrict the node influence score to consider only the network connec-tions and ignore the cascade: Interestingly this still remains nice- X  and (trivially) nice-z , but not nice-z, X  . Alternatively, we could consider only the transmission frequencies: This is (trivially) nice- X  but not nice-z because of the dis-cretization.

Edge-centric Properties: Edge-centric properties com-pute scores for an edge ( u,v ) in the network. As before, we will focus on scores involving connection strengths  X  uv and transmission frequencies  X  uv .

Edge Distribution: Given a range ( r 1 ,r 2 ) for the trans-mission frequency, and a range ( a 1 ,a 2 ) for the connection strength, this counts the number of edges ( u,v ) in the net-work whose connection strength  X  uv and transmission fre-quency  X  uv lie in this range. f (  X ,z ) = X The resultant distribution of the edges over the (  X , X  ) space can be suggestive of the effectiveness of viral marketing strate-gies for this network, or the susceptibility of this network to epidemics. Eqn. 11 can also be viewed as the distribution of the summed (or averaged) direct node influence scores. Recall that the plots in the introduction correspond to this property.

Marginals or projections of this distribution along the  X  and  X  dimensions can also be useful. f ( z ) = X The first two edge-centric properties are nice- X  but not nice-z . The last property is both nice- X  and nice-z but not nice-z, X  .

Observe that removing the binning for the  X  -projection recovers the well studied network inference problem. Computing the expectation of this score is the Bayesian for-mulation of the network inference problem, where we are seeking the expected network connection strengths given the cascades. This is again nice- X  , and nice-z .

All the network-centric properties introduced so far are at best partly nice . We conclude this discussion by presenting an interesting property that is nice-z, X  . Imagine that we are interested in finding strong edges that are not frequent, and weak edges that are frequent. For this, the following score is useful: This function satisfies Def. 5.3, and therefore the complete expectation can be computed efficiently upto a multiplica-tive constant.
For cascade centric properties, the focus is on entities in the cascade, such as individual infections, for which we com-pute some score based on the network as well as the cascade. We illustrate such properties using individual infections.
Infections due to Strongest Neighbor: The strongest neigh-bor of a node v in the network is the one with the maximum connection strength  X  uv . We may count the number of in-fections for which the infecting parent u z i is the strongest neighbor for u i in the network: We can similarly count number of infections by the n strongest neighbor, for n &gt; 1. Both properties are nice-z , but not nice- X  .

As an even simpler example of a cascade property, we can consider checking the parents nodes for individual infections.
Infection parent identification : This indicates if node u is the parent of infection i . This is equivalent to computing the diffusion paths for a cascade. This infection-centric property is nice-z and also trivially nice- X  .

It is worth observing that the complete likelihood p ( { c  X  ) of a cascade C given network strengths  X  can be seen as a cascade-centric property, where the entity of interest is the entire cascade. The likelihood can be viewed similarly as a cascade-centric property. Unlike complete likelihood, the likelihood is a function of only the observed infection variables, and the parent variables z are summed out. Both of these properties are nice-z (the likelihood trivially so), but not nice- X  . In the context of test cascades, the expectation of this property can be interpreted as consider-ing the entire posterior distribution over  X  , learnt from the training cascades, to explain the test cascades. In contrast, the frequentist strategy uses only a point estimate.
We have seen in Sec. 5 that computing the expecta-tion for network diffusion properties that are not completely nice requires drawing samples from the posterior distribu-tion p (  X ,z |{ c o } ) over network strengths  X  and infection par-ents z conditioned on the observed cascades { c o } . In this section, we propose a Gibbs Sampling framework for this. In this framework, we iterate over all latent variables, sampling a new value for it from its conditional distribution, given the current values of all other variables. Asymptotically, the samples are from the joint posterior distribution over all latent variables. For our problem, we need to draw samples from p ( z i |{ c o } , X ,z  X  i ) and from p (  X  uv |{ c o z  X  i and  X   X  uv denote variables other than z i and  X  uv . All expressions below are for the Exponential Distribution. Ex-pressions for Rayleigh can be derived in a similar manner.
First, the posterior distribution p ( z, X  |{ c o } ) over both z and  X  looks as follows:
Given this, the conditional distribution for the i th infec-tion parent z i turns out to have a very simple form: The conditional distribution for individual network strengths  X  uv also has a simple Gamma density form:
For network properties that are nice- X  , only samples of z are required. In such cases, an alternative is to perform collapsed Gibbs Sampling , by analytically integrating out  X  : p ( z |{ c o } )  X 
Given this conditional, the conditional distribution for in-dividual infection parents z i looks as follows: where  X   X  i u j u i ( z ) ignores the i th infection for pair-wise infec-tion counts over nodes. The collapsed Gibbs Sampling al-gorithm is remarkably simple. It repeatedly samples the parents of the individual infections from Multinomial distri-butions and updating infection counts for pairs of nodes.
The posterior over  X  uv when  X  uv = 0 is given by Gamma(a,b +  X  uv ). Since this is peaked sharply at 0, we sample  X  only when  X  uv &gt; 0. This is significantly smaller than | V |
Recently, the independent cascade model has been ex-tended to handle features of individual infections [22], which is useful to capture contents of social media posts when infer-ring influences. Our approach can be extended in a straight-forward manner to incorporate features in this way. The analysis in Sec. 5 remains unchanged since the decoupling in Eqns. 1 and 6 still hold. The Gibbs Sampling conditional distributions acquire an additional feature term. We omit further details due to space constraints.
 Map-Reduce Implementation: For computing the  X  uv val-ues, each cascade can be processed in parallel. The final value for each for each u,v pair can be obtained by adding across cascades. This is exploited by the Mapper. Each Mapper computes  X  uv for the set of cascades given to it and emits ( v : X  uv ) pairs. Each Mapper also generates a list of possible parents for each infection and emits ( v :[ i ,  X 
Sampling a parent for an infection of node v requires  X   X  v and  X   X  v in case of collapsed sampler, and  X   X  v in the case of uncollapsed sampler. Sampling  X   X  v requires only  X   X  v  X   X  v . Moreover, after sampling only  X   X  v and  X   X  v are needed to be updated. As a result, the sampler for each node v can be run in parallel if the set of possible parents of each infec-tion is known. The sampling is performed in the Reducer, which exploits this parallelism. Each Reducer performs sam-pling for a subset of nodes. For each node v assigned, a Re-ducer combines information from different mappers to com-pute the final  X  uv , and the complete list of infections of node v . It performs sampling for these infections and generates the samples. The samples from all Reducers are combined to get the complete set of samples.
In this section, we present experimental evaluations of var-ious network diffusion properties defined in Sec. 5 using our Bayesian approach on synthetic and real world datasets. We focus on the accuracy of the properties computations and on the scalability of our algorithms for large datasets.
Baseline: We note at the outset that this general prob-lem has not been studied before, and that there exists no baseline for comparison. However, one potential strategy is to first recover a point estimate  X   X  (e.g. MLE) of the network strengths  X  using a state-of-the-art approach, consider the most likely infection parents  X  z = arg max z p ( z |  X   X , { c this suffers from deficiencies outlined in Sec. 3, this is the best possible baseline using existing network inference tech-niques. As the state-of-the-art network inference approach for the continuous time independent cascade model, we used the featureless version of MONET [22]. We do not use NE-TRATE [6], since it does not support multiple infections of a node in a cascade. In the rest of this section, we will refer to this approach as the frequentist plug-in approach ( FP ), and to our proposed approach of computing expectations as the Bayesian Expectation approach ( BE ). We have used the Exponential distribution for all experiments. For the Gamma prior we use a = 0.00001 and b = 0.1.

Synthetic data experiments: We first conducted experiments on multiple synthetic datasets. These experi-ments allowed us to evaluate accuracy against a gold-standard, which is unavailable for most real-world network diffusion datasets. Secondly, these helped us analyze our proposed approach for different families of graphs. Following earlier experiments on network inference [7, 6], we created synthetic graphs with 1024 nodes using Forest Fire (FF), Random (Rnd), Hierarchical (HI) and Core-Periphery (CP) Graph models, the last three being instances of Kronecker Graph models. We used parameter values [0.5, 0.5; 0.5, 0.5] for Rnd, [0.9,0.1;0.1,0.9] for HI, [0.9,0.5;0.5,0.9] for CP, follow-ing Gomez-Rodriguez et. al. [6]. To generate weights  X  for each edge ( u,v ), we sampled uniformly from (0 . 01 , 10) [3]. We then generated 20 splitting cascades over these graphs with 2 randomly chosen seeds for each cascade. Finally, we obtained 2046 edges and 48947 infections for the Random graph, 1496 and 38046 for the Hierarchical, 2042 and 58062 for the Core-Periphery, and 2023 and 55274 for the Forest Fire graph.

Recall that one of the reasons behind the synthetic data experiments is to be able to evaluate accuracy. For the in-fection parents z , we considered the true parents as the gold-standard. However, for the real-valued network connections  X  uv , the true values are not always possible to recover from finite length cascades. For example, it is impossible to re-cover the strength for any edge that has no transmission in the cascade. Therefore, we considered as our gold-standard the best achievable  X  uv given the true infection parents in the cascades:  X   X  = arg max  X  f ( { c o } ,z  X  ;  X  ). For accuracy in case of a scalar property, we used absolute error between the gold-standard f (  X   X  ,z  X  ) and the computed value of the prop-erty, and for vectors and matrices the root mean squares of the individual errors. (A) Network-centric Properties: In this category, we first evaluate the edge-distribution (Eqn. 11) as an example of a property on edges . Evaluating accuracy for this property is challenging because of the threshold parameters a and r . We discretized the  X  and the  X  ranges, and within each region of the (  X , X  ) space, computed the actual, BE and FP values of these properties, and the errors for BE and FP.
Figure 3: Reconstructed edge distribution: FF Figure 4: Reconstructed edge distribution: Rnd
The actual plots for the four networks were introduced in Fig. 1. The FE and BE reconstructions for the Core-Periphery graph were also introduced earlier in Fig. 2. The reconstructions for the other three graphs are shown in Figs. 3, 4, and 5. It can be seen quite clearly that while BE is able to reconstruct the actual distributions to a reasonable extent for all 4 graphs, FP does quite poorly. In fact, the FP reconstruction looks similar in all 4 cases, and fails to pick up the signatures for the different graphs.

We also calculated the actual errors for the two approaches over the (  X , X  ) space. Since it is difficult to visualize the plots in 2D, we evaluated the projections on the  X  -dimension and z -dimension (Eqn. 5.2) for the edge distribution for the 4 graphs.
 Table 1:  X  -proj. for edge distribution: abs. error Table 2:  X  -proj. for edge distribution: abs. error
In Tab. 1, we record the errors for BE  X  -projection and the FP  X  -projection for different  X  -intervals. We can see
Figure 5: Reconstructed edge distribution: HI that for the  X  -projection, the FP errors are an order of mag-nitude bigger for all intervals, except for  X   X  (7 , 8) for Hier-archical. Similarly, in Tab. 2, we record the errors for BE  X  -projection and the FP  X  -projection for different  X  -intervals. In this case as well, FP error is significantly lower only for the (10 , 20) interval for CP and Rnd.

Finally, we come to properties of nodes . We evaluated direct node influence (Eqn. 8), and indirect node influence for 2 nd -order neighbors (Eqn. 7) for the 4 graphs. Again, we partitioned the (  X , X  )-space into regions. However, re-porting detailed results is even harder here, since we have actual, BE and FP scores for each node in each  X , X  -region. We consider the sum (or average) of the influence scores over all nodes. Recall that one interpretation of the edge-distribution is the distribution of the sum of direct influence scores over all nodes. So the edge-distribution evaluation above additionally serves as an evaluation of the direct node influence scores at an aggregate level. Figure 6: Indirect node influence distribution: HI
For indirect node influence , due to space constraints, we show the (averaged) indirect node influence distribution only for the Hierarchical graph in Fig. 6. Again, we see that BE is able to pick up the signature of the distribution to a reasonable extent, whereas FP has failed completely.
In Tab. 3, we report the aggregated errors over all nodes and over all (  X , X  ) regions for both direct and indirect influ-ence scores. We have scaled down the values by the total number of nodes, which is 1024. We again see that the BE errors are significant smaller than the FP errors across the board. (B) Cascade-centric Properties: Under cascade-centric properties, we evaluate infections due to n th strongest neigh-bor (Eqn. 14) for n = 1 , 2 , 3.
 Table 4: Infections by n th -strongest nbr: abs. error
Tab. 4 records the absolute error for the number of infec-tions by the n th -strongest neighbor for n = 1 , 2 , 3. Notice that FP has very high errors for n = 1. There are just two instances where FP works better than BE: for n = 2 in Forest Fire and for n = 1 in Core-Periphery, where the val-ues are comparable. In all other cases, FP has significantly higher error than BE.
 Likelihood, Network Inference and Parent Identification: The performance improvement of BE over FP in the experi-ments so far is attributable to two reasons: (a) the Bayesian approach of using the full posterior distribution instead of the frequentist point estimate, and (b) many-to-one map-ping of network variables to property values. We now look at experiments using the basic inference problems for net-work analysis, and generalization ability on held-out data, which are one-to-one network diffusion properties in our for-mulation.

In Tab. 5, we record the train and test likehoods for the 4 synthetic datasets. We see that BE consistently has higher test likelihood, while the train likelihood is higher for FP, suggesting overfitting.
 Table 6: Network Inf. (NI) &amp; Parent Id. (PI)
In Tab. 6, we record the errors in recovery of  X  for BE and FP. Observe that the errors are consistently lower for BE across the 4 datasets. In fact, the FP errors are very high for the Random and Forest Fire datasets. In Tab. 6, we also see that parent identification accuracy of BE is consistently around 10% more than that of FP. These three experiments demonstrate that the Bayesian approach for network diffu-sion analysis has advantages even for one-to-one properties. (C) Iterations vs Error: Before moving on to experiments on real-world data, we make a note about Gibbs Sampling iterations. Gibbs Sampling algorithms often take thousands of iterations to converge, which can be a serious problem for large real-world datasets. The number of iterations required for the Gibbs Sampler to converge can be greatly reduced by choosing a good initialization. We use  X  z = arg max z { c o } ;  X   X  ) as the initial z , where  X   X  uv = | P ( u,v ) | /  X  an approximation of  X  MLE where we use | P ( u,v ) | which is purely a function of that data instead of  X  uv in the nu-merator. In our experiments, we observe that the accuracy increases very sharply in the initial iterations, and is close to the best value within 100-200 iterations.

Experiments on real-world data: We now report experiments on real-world data, where the graph structures are more complex than the synthetic settings. The under-lying diffusion process is also likely to be different from the Independent Cascade model, which our models assume, and which we used for generating the synthetic cascades.
The Meme Tracker dataset 1 records the diffusion of  X  X emes X  or catch-phrases across 5000 most active blogs and news sites between March 2011 and February 2012. The flow of each meme corresponds to one cascade. Related memes are grouped into one topics. For our experiments, we selected 5 topics, 2 of which have been used in earlier experiments involving non-stationary networks [9], and 3 others for which the networks are likely to be stationary. Basketball has 1187 Nodes, 130317 Infections and 2663 cas-cades, Alcohol has 1549 nodes, 151136 infections and 3018 cascades, Technology has 1797 nodes, 338931 infections and 6658 cascades, NBA has 1891 nodes, 179864 infections and 3637 cascades, and Occupy has 1601 nodes, 147135 infec-tions and 2851 cascades. In each topic, we consider all suf-ficiently long cascades (length &gt; 30). We split the cascades randomly to generate the training and test cascades(80-20), and then prune infections of those users in test cascades who are not present in the training cascades.

Since no gold-standard is available for  X  or z for this dataset, we compared BE and FP using loglikelihood on held-out test data, with the knowledge of  X  learnt from training data. In Tab. 7, we report the loglikelihood val-ues for the 5 selected topics. We can see that the BE values are significantly better than the FP values. Recall that this is the best scenario for the baseline since likelihood, as a net-work diffusion property, is a one-to-one function of  X  for this problem. This suggests that BE is likely to outperform FP to a larger extent for other properties on real-world datasets.
We also computed the proposed network-centric and cascade-centric properties for Meme Tracker using BE. In Fig. 7, we plot the edge distribution for two of the topics. Recall that there is no gold-standard for this. We can see that the na-ture of the plots is different from all of the synthetic datasets. The mass is more concentrated towards weaker, infrequent edges. We suspect that this is because of the way users were sampled for this dataset.
 Scaling experiments: We also experimented with larger vol-umes of the Meme Tracker data using our map-reduce im-plementation. We created increasingly larger dataset sizes by randomly sampling cascades and checking the execution http://snap.stanford.edu/infopath//data.html Figure 7: Edge distribution for Meme Tracker topics time for 100 iterations of Gibbs Sampling. We performed ex-periments on a Intel Xeon server with 100GB RAM, which supports 12 mapper/ reducer tasks in parallel.

In Tab. 8, we record execution time with increasing data size on 12 processor nodes and compare against the time taken on a single node. We can see that the map-reduce implementation allows us to scale our analysis by providing a (roughly) linear speed-up in terms of number or processor nodes.

In summary, the experiments clearly demonstrate that computing expectations under the posterior distribution leads to significantly better reconstruction of a wide variety of network diffusion properties. The proposed Bayesian frame-work that combines exact efficient computation with Gibbs Sampling based approximations outperforms state-of-the-art algorithms even for the well-studied network inference and parent identification problems, and in generalizing to held-out test data. The map-reduce implementation is promis-ing in terms of scaling up the analysis to study properties of large network diffusion datasets.
In this paper, we have investigated the novel problem of computing expectations of properties of network diffusions involving hidden variables. We have proposed a Bayesian framework for computing such expectations, and proposed and characterized network diffusion properties that can be handled efficiently in this framework. In experiments over synthetic and real world datasets, we have shown that we are able to reconstruct network properties significantly more accurately than a frequentist baseline. [1] N. Barbieri, F. Bonchi, and G. Manco. Influence-based [2] F. Bonchi. Influence propagation in social networks: A [3] N. Du, L. Song, M. Gomez-Rodriguez, and H. Zha. [4] N. Du, L. Song, A. Smola, and M. Yuan. Learning [5] A. Elfessi and D. Reineke. A bayesian look at classical [6] M. Gomez-Rodriguez, D. Balduzzi, and B. Sch  X  olkopf. [7] M. Gomez-Rodriguez, J. Leskovec, and A. Krause. [8] M. Gomez-Rodriguez, J. Leskovec, and B. Sch  X  olkopf. [9] M. Gomez-Rodriguez, J. Leskovec, and B. Sch  X  olkopf. [10] A. Goyal, F. Bonchi, and L. Lakshmanan. Discovering [11] A. Goyal, F. Bonchi, and L. Lakshmanan. Learning [12] A. Goyal, F. Bonchi, and L. Lakshmanan. A [13] A. Guille, H. Hacid, C. Favre, and D. A. Zighed. [14] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [15] K. Kutzkov, A. Bifet, F. Bonchi, and A. Gionis. Strip: [16] L. Macchia, F. Bonchi, F. Gullo, and L. Chiarandini. [17] Y. Mehmood, N. Barbieri, F. Bonchi, and [18] C. Milling, C. Caramanis, M. S., and S. Shakkottai. [19] P. Netrapalli and S. Sanghavi. Finding the graph of [20] E. Sadikov, M. Medina, J. Leskovec, and [21] K. Saito, M. Kimura, K. Ohara, and H. Motoda.
 [22] L. Wang, S. Ermon, and J. Hopcroft.

