 Online advertising is increasingly becoming more performance ori-ented, where the decision to show an advertisement to a user is made based on the user X  X  propensity to respond to the ad in a pos-itive manner (e.g., purchasing a product, subscribing to an email list, etc). The user response depends on how well the ad campaign matches the user X  X  interest, as well as the amount of the user X  X  past exposure to the campaign  X  a factor shown to be impactful in con-trolled experimental studies. Past exposure builds brand-awareness and familiarity with the user, which in turn leads to a higher propen-sity of the user to buy/convert on the ad impression. In this paper we propose a model of the user response to an ad campaign as a function of both interest match and past exposure, where the inter-est match is estimated using historical search/browse activities of the user.

The goal of this paper is two-fold. First, we demonstrate the role played by the user interest and the past exposure in modeling user response by jointly estimating the parameters of these factors. We test this response model over hundreds of real ad campaigns. Second, we use the findings from this joint model to identify more relevant target users for ad campaigns. In particular, we show that on real advertising data this joint model identifies better target users compared to conventional targeting models.
 I.2.6 [ Artificial Intelligence ]: Learning; G.3 [ Mathematics of Com-puting ]: Probability and Statistics Algorithms, Experimentation Advertising, Targeting, User Modeling, Latent Factors
Online advertising is growing at a rapid pace with more and more advertisers using the internet to reach out to their potential customers. This is not surprising given that users are spending an unprecedented amount of time performing online activities rang-ing from sending emails, searching and browsing, to dating and shopping. The advertisers (or intermediaries such as ad networks, online exchanges) use these past online activities of the users to identify those who are most likely to respond positively to their ad-vertising campaigns. This is called behavioral targeting [15, 12, 7, 19], whereby models are built based on past user behavior to target likely potential customers. Behavioral targeting benefits both the parties involved: it allows advertisers to spend their money effec-tively, while it helps users by providing them more relevant ads.
Effective targeting requires deeper understanding of the factors influencing a user response to an ad. Broadly speaking, for a given advertising campaign this involves: (a) understanding user interests and identifying whether she is likely to be interested in the prod-ucts/services offered by the advertiser (called  X  X nterest match X ), and (b) making the user  X  X ware X  of the advertiser X  X  product by repetitively exposing her to the ad so as to elicit a positive response (called  X  X ast exposure X ). Previous work has shown how each of these factors can influence the likelihood of a user to pursue the ad. While the effect of the  X  X nterest match X  factor is fairly natural and intuitive (e.g., the more relevant the ad campaign is to the user, the more likely she is to pursue it), the effect of past exposure is more complex. Controlled experiments have been done by economists and social scientists to identify the effect of past exposure [16, 13, 9]. While the results from these studies differ in some aspects, largely it has been shown that with increased past exposure the user is more likely to pursue the ad. Intuitively,  X  X ast exposure X  to an ad might help in several ways such as increased brand-awareness and familiarity with the advertised product, or even an increased prob-ability of the user to notice the ad. At the same time, some studies have also shown an  X  X d fatigue X  effect where users might tire of an ad if it is displayed too often [1].

Our goal in this paper is to improve user targeting by account-ing for the hidden interplay of the interest match and past exposure factors in a real world advertising environment. This is challeng-ing for several reasons. First, when we receive a positive response from a user for an ad campaign, it is unclear how much of this is due to repeated past exposure of the ad, as opposed to the user interests matching with the campaign objectives. Most previous work has been limited to investigating these factors individually in a controlled experimental setting. Second, these past exposure and interest match factors themselves are complex and difficult to characterize precisely. For example, as discussed in [17], inferring user interests from their profiles requires dealing with millions of features and is challenging technically as well as computationally. Third, the contribution of these factors to a positive user response might be different for different advertising campaigns. For exam-ple, past exposure might play a positive role for certain campaigns, be unrelated to user response for other campaigns, and might even lead to ad fatigue for a third set of campaigns. Lastly, in our study we define a positive user response in terms of  X  X onversions X , which represent desired user actions as specified by the advertiser in the form of purchases and product information request. While con-versions are advertiser-defined and thus are clearly more tangible indicators of user interest compare to clicks, time spent or other implicit feedback, conversions are much rarer as well. Thus, we have to take necessary precautions while performing inference or learning from such sparse data.

We deal with the above mentioned issues by using mathemati-cal models that jointly account for the two factors involved: past exposure and interest match. Our models use three sources of in-formation for a given user and advertising campaign: (a) the num-ber of previous ads that the user has seen from the campaign in consideration, (b) a rich user profile in terms of her past online ac-tivities that include, but are not limited to, search queries issued, pages browsed and the associated timestamps and (c) users who have responded well to the campaign in the past (called positive users). The number of previously viewed ads is used to model the past exposure factor, while the user profile is leveraged for gaug-ing interest match with the advertiser. By jointly accounting and optimizing for past exposure and interest match with respect to the given positive and negative users, we are able to separate their in-fluence [16, 13, 9]. Intuitively speaking, given a set of users with similar interest match but with different past exposure, the role of past exposure can be estimated and vice versa. However, doing so makes the model for characterizing interest match to depend on the given model for past exposure and vice versa, thus requiring a joint optimization.

Our work can have significant implications for display advertis-ing and user targeting. We show how the two factors, past exposure and interest match, can be modeled jointly to perform more ac-curate prediction of potential converters. Current state of the art in targeting is largely focused on matching interested users with advertisers, but does not give deserved attention to past exposure. Through our experiments on hundreds of real advertising campaigns, we show how past exposure, along with interest match, can sub-stantially improve the targeting performance. Also, understanding the effect of past exposure allows advertisers to allocate and spend their advertising budget more judiciously. For example, if their campaigns require large amount of past exposure, then it makes sense for them to find interested users and pursue them for a rea-sonable period before expecting a positive response. On the other hand, advertisers who only need small past exposure should shuffle through users quickly and avoid spending much resources on any particular user (since if the user is likely to convert, she would con-vert promptly for such advertisers). On our dataset we find, through our modeling approach, that different campaigns have sufficiently different needs in terms of past exposure and interest match. Contributions. We make the following contributions in this paper:
Behavioral targeting systems for display advertising are rapidly increasing on the Internet. Utilizing historical online user informa-tion to target users with display ads has been shown to be highly ef-fective, resulting in an increase in the performance of ad-campaigns [19]. Several optimization techniques have been suggested [15, 12, 7] which use different user features such as demographics, past views, past searches, pseudo social-networks, etc. to differentiate between converters and non-converters.

Different statistical models can be applied to capture the user be-havior effectively. Regression models have been introduced in [3, 4, 10] in this domain. Bayesian factor-based models [2, 6] have also been proposed in literature. In [2] the authors used ad factors whose parameters are derived from different types of Markov mod-els to generalize user behavior patterns for ad-campaigns. The goal of this study was on providing additional insight about the users to the advertisers. In [6] the authors use latent factor models simi-lar to LDA for targeting [5], but do not consider the effect of past user exposure. Also, there is related work on user browsing mod-els (UBM) which, for organic and sponsored search, separates the click-through rate into an  X  X xamination X  probability and perceived relevance probability. However, these models apply for search re-sults and do not consider any effect due to repeated exposure [18].
The effect of user exposure has been studied in [9, 13, 16] in a controlled setting, where it has been shown that multiple expo-sure to an advertisement can have varying effects on the purchasing decision of the users. In [16] the authors study the effect of tem-poral spacing between ads and show that at a purchase occasion, the probability of a product purchase increases if its past ads are spread apart rather than bunched together. In [13] the authors show that the purchase probability of a user varies as a function of banner advertising exposure. They also show that the number of websites and number of pages on which a user is exposed to advertisements can have an effect on the purchase probabilities.
Before we explain our modeling approach, we next describe the problem setup in detail.
The focus of our study is performance based display advertising campaigns, which are set up with conversions goals, where conver-sions are advertiser specified actions (e.g., email subscription, form fill, product purchase) that show positive user intent. For each cam-paign, the goal is to identify and target users who are most likely to convert, also known as converters . In the following section, we formulate this task mathematically.

We use the following sources of information for a given cam-paign:
We denote the user response using binary variable y i . A y of 1 represents a converter, and 0 represents a non-converter.
Let us denote the probability of user u i converting by the time she has been served x i ad impressions by P[ y i = 1 | f i the goal of ad targeting is to identify users with the largest values of P[ y i = 1 | f i ,x i ] . There are several technical questions involved in doing so. For instance, it is worth investigating the gain achieved by accounting for the number of adviews x i versus ignoring it (see Section 2.2). How does the user profile vector f i interact with x As described in Section 2.4, a naive solution is to treat x feature in the profile vector, but this leads to over-simplification and does not model the effect of x i correctly. Note that, in our setting, the dimension of f i is extremely large since it represents sparse user activities. Furthermore, the number of positive examples (i.e., y =1) in the given seed set S is typically small since conversions are rare events, making the problem harder.

Next we describe our proposed factor model for user targeting that accounts for both past exposure and interest match.
We believe that the user conversion for a campaign comes from a two-stage process. In the first stage, the user is repeatedly exposed to the ad to get her attention. According to past work, this may lead to increased user awareness about the product/brand, making her more familiar with the ad offering and increasing her trust in the advertisement. Of course, an excess of repeated exposure to the ad can negatively affect the user sentiments about the advertiser. Once the user has become aware, denoted by the awareness random variable  X  i (defined precisely in Section 2.2.1), she moves to the second stage.

In the second stage, the user evaluates the offering and decides whether to pursue the ad or not. This decision is based on sev-eral other variables such as whether the user is interested in the offered product, whether the timing and price is appropriate,etc. We call this the intrinsic conversion probability and denote it by P[ y i = 1 | f i , X  i = 1] . Thus, our model factorizes the probability of user conversion into the product of two probabilities, the aware-ness probability ( P[  X  i = 1 | x i ] ) and intrinsic conversion probabil-ity ( P[ y i = 1 | f i , X  i = 1] ). In other words,
P[ y i = 1 | f i ,x i ] = P[  X  i = 1 | x i ]  X  P[ y where the last equation arises since the user cannot convert unless she is aware of the ad.

Note that our model decouples the effect of previous ad impres-sions x i and profile vector f i , whereby x i influences the awareness probability while the profile vector is used for modeling the intrin-sic conversion probability. While we can envision the awareness probability to be a function of the profile vector as well (i.e., differ-ent users may build awareness in different manners) and the intrin-sic probability to depend on the number of impressions, this could make the two stages fairly similar and mathematically unidentifi-able. Hence, for the ease of model interpretation we keep the two stages decoupled as described above.
 We refer to this model as the Exposure-based Factor Model for User Targeting ( EFM ). Next we describe the two factors in more detail.
For a given advertising campaign and a user, the awareness prob-ability captures the likelihood with which the user is aware of the campaign and considers it for evaluation (i.e., moves to the second stage). We represent this as a function of the number of previous ad impressions x i of the campaign that the user has been exposed to.

Below we describe two possible distributions that can be used to model the awareness probability. 1. Geometric Process : Let us assume that each time the user 2. Poisson Process : Here we model the number of times a user
Both the above models are intuitive in nature and capture the fact that with increased exposure, the awareness probability increases (as found in previous studies). In other words, the more ads the user is exposed to, the higher is her awareness probability. While this is largely true, it is possible that with excess exposure the user gets annoyed and does not consider the ad for evaluation (i.e., the second stage). More specifically, the awareness may decrease due to negative sentiments.

We account for such negative sentiments by proposing a Multi-nomial distribution for awareness probability where P[  X  i {  X  1 , X  2 ,... } . Here  X  x denotes the awareness probability after x number of previous ad impressions and is learned from the data during joint optimization (parameter estimation is described in Sec-tion 3). Hence, if there is excess exposure which leads to negative sentiments,  X  x would start decreasing beyond a certain number of ad impressions ( x ).
As describe earlier, the intrinsic conversion probability for user u represents the likelihood with which the user converts on the ad when she evaluates it. The probability depends on many user attributes such as demographics, her interests (short-term and long-term), online shopping tendency. We model this using a logistic function of the features from the user profile vector: In other words, logit (P[ y i = 1 | f i , X  i = 1]) = w w = { w 1 ,w 2 ,...,w n } denotes the unknown weight vector. The weight vector is campaign specific since it models the targeting constraints of a campaign and needs to be learned separately for each campaign.

Note that the choice of logistic regression for modeling intrinsic conversion probability is not central to our factor model and can be easily substituted by other approaches. Methods for identifying user interests is a research topic by itself and has been focus of many previous work on advertising and other applications such as news browsing, personalized search, etc (see related work). Many models such as Logistic regression, SVM, Naive-Bayes, Nearest-neighbor have been studied in this context and can potentially be used for our work.
In our factor model we described how the user converts on a campaign in a two step process  X  in the first step the user becomes aware of the ad and the advertiser, while in the second step she eval-uates the ad and decides whether to convert on it or not. Another dimension that is worth investigating is the time delay between the first and the second step. For example, say the user is exposed to the ads from a cruise line and after a few exposures she becomes aware of it. Since she is not planning any vacation for the next few months, she decides to not react or evaluate the ad at the time. But when she finally gets to the vacation period, the awareness might have faded away. We make this more formal next.

Suppose the user has been targeted with a display advertisement for the campaign x i times so far. Let the timestamp for the x -th adview for this user be t i ( x ) , and suppose we know that the user has converted by time  X  i . 1 Let us denote the probability of this conversion event by P[ y i = 1 | f i ,x i , X  i ] . Our generative model for the conversion is as follows: first, the user becomes aware at the time of the x -th adview (where 1  X  x  X  x i ). After that she waits for a time interval t (where 0  X  t  X   X  i ), before deciding whether to convert or not convert. In other words, the probability of conversion is the product of the following three terms -the probability of the user becoming aware at the x -th adview (denoted by P[  X  i,x the probability of the user incurring a delay of time t in making her decision (denoted by P[ X  i = t ] ), and the intrinsic conversion probability of the user given that she has noticed the ad and is ready to make a decision (denoted by P[ y i = 1 | f i , X  i = 1] ). Thus, we have
P[ y i = 1 | f i ,x i , X  i ] =
Assuming that the impressions are shown to users uniformly over time, we can approximate the time interval  X  i  X  t i ( x ) in terms of the difference in the ad impression counts, that is,  X  i
Note that the precise time of a user conversion is difficult to deter-mine in practice since the conversion, unlike click, does not happen right after the ad impression; the user may evaluate the ad, like it and then buy the product few days later. Note that awareness probability P[  X  i = 1 | x ] = P x k =1 1] . For the Geometric model described in Section 2.2.1, P[  X  1] = (1  X   X  ) x  X  1  X  . proportional to x i  X  x . Hence,
If it is the case that the user, after becoming aware, immediately decides whether to convert (without waiting for future ad impres-sions), i.e., P[ X  i = 0] = 1 , then P[ y i = 1 | f i ,x P[ y i = 1 | f i , X  i = 1]  X  P[  X  i = 1 | x ] . Thus, we obtain the model described in Section 2.2 as a special case of this delay model.
More generally, if the probability P[ X  i = t ] decays obeys an exponentially decaying probability distribution, i.e., P[ X   X e  X   X t , where  X  is the exponential parameter, then we get:
We denote this model by EFMD .
We start by describing the conventional targeting strategy which does not take exposure into account [3, 4]. In other words, this ap-proach only accounts for the intrinsic conversion probability, P[ y 1 | f i , X  i = 1] . The probability is typically modeled using a SVM or Logistic function of the user features including geographic, de-mographic, behavioral and/or social attributes (see Section 4.1 for more details about the type of features used). We refer to this base-line model by LR (for logistic regression). Note that this is a spe-cial case of our factor model from Section 2.2 where the bernoulli probability  X  is set to 1.

We propose another baseline method which takes exposure into account but in a rather simplistic manner. In particular, we can think of the past impression count x i as another feature in the pro-file vector f i . Hence, instead of doing logistic regression over just the profile features as in LR , now we regress over both x We denote this by LR+ and study its performance in the experi-ment section. As we will see in the results section, while leverag-ing past exposure benefits LR+ over LR , it is substantially outper-formed by our factor models.
We now present optimization methods for estimating the model parameters (  X  and w ) for our factor model. Note that the parame-ters  X  and w are specific to each campaign and are estimated sepa-rately.

We provide two different optimization approaches for this prob-lem: an Alternate Maximization method and an Expectation Maxi-mization method.
For the ease of explanation, we consider the zero-delay factor model from Section 2.2. Also, let us assume P[  X  i = 1 | x ] to be a Geometric process with parameter  X  and P[ y i = 1 | f i , X 
Given a set of users U = { u i ,...,u n } along with correspond-ing labels Y = { y i ,...,y n } , feature vectors F = { f and past ad impression counts X = { x i ,...,x n } , our goal is to find the unknown logistic parameters w and the Geometric Param-eter  X  . Using  X  = { w , X  } to represent the model parameters, D = { Y,F,X } to represent the observed data, and using the ex-pression for P[ y i = 1 | f i , X  i = 1] from Section 2.2, we can express the log-likelihood function for the data as: L [ X ; D ] =
To solve this maximum-likelihood optimization problem, we use an alternating maximization algorithm consisting of a sequence of iterations, each comprising of two steps: in the first step (  X  -step), we optimize for  X  while keeping w constant, and in the second step ( w -step), we optimize for w while keeping  X  constant.
While the above function f ( w ) is not concave, we can approxi-mate it by another function that is concave: Essentially, we are approximating (1  X  P[  X  i = 1 | x 1 | f i , X  i = 1]) by (1  X  P[ y i = 1 | f i , X  i = 1]) P[  X  i is known to be a good approximation if P[ y i = 1 | f i , X  small. Since this approximation is performed only in the case of those users for which y i = 0 , we expect P[ y i = 1 | f i indeed be small for such users.

We can now solve the optimization problem argmax w f efficiently, since f 0 ( w ) is a concave function of w . Specifically, we performed L-BFGS gradient descent using the MALLET pack-age [14].
 L EMMA 3.1. f 0 ( w ) is a concave function of w .
 Proof. Let l i ( w ) = 1 f ( w ) =
The second term is the Logistic Regression log-likelihood func-tion, which is concave. For the first term, it suffices to show that  X  log l i ( w ) is convex.
 x
Thus, the Hessian 5 (  X  log l i ( w )) = l i ( w )(1  X  l where x = [ x 1 ,x 2 ,...,x n ] T . This is clearly a positive-semidefinite matrix, and hence  X  log l i ( w ) is convex.

Hence, f 0 ( w ) is concave. We can also perform model estimation using the Expectation Maximization framework. We use the same definitions for U , Y , F ,  X  and X as before. In addition, for each user u i we have an associated hidden (or latent) variable z i that takes a value of 1 if the user is aware of the ad (with probability P[  X  i = 1 | x 0 otherwise. We define Z = { z 1 ,z 2 ,...,z n } . For ease of nota-tion, we denote P[ y i = 1 | f i , X  i = 1]) = 1 P[  X  i = 1 | x i ] by q i .

Given the hidden variables Z = { z i } and data D = { Y,F,X } , we first compute the log-likelihood of the model L [ X ; D,Z ] . For each user, clearly P[ y i = 1 | z i = 1] = q i p i , P[ y q (1  X  p i ) , P[ y i = 1 | z i = 0] = 0 and P[ y i = 0 | z Thus, L [ X ; D,Z ] = where we use G i = z i q i p i and H i = z i q i (1  X  p i
Then, in the E-step we consider the expected value of the like-lihood w.r.t. the conditional distribution of Z given the data and model parameters, i.e., E Z/  X  ,D [ L [ X ; D,Z ]] . Thus, E
Z/  X  ,D [ L [ X ; D,Z ]] = P Z P[ Z |  X  ,D ]  X  L [ X ; D,Z ] = P Z P[ Z |  X  ,D ]  X  P n i =1 ( y i log( G i ) + (1  X  y i )) where, the last equality follows since P[ z i = 1 |  X  ,y and P[ z i = 0 |  X  ,y i = 1] = 0 . Also, we have Thus, we can further simplify: E Z/  X  ,D [ L [ X ; D,Z ]] = Thus we obtain the E-step expression: E Z/  X  ,D [ L [ X ; D,Z ]] =
In the M-step, we aim to estimate the model parameters  X  and w that maximizes the above expression. Notice that p i is a function of w and q i is a function of  X  . Hence, in the M-step we can again use an alternating maximization algorithm consisting of a sequence of iterations, each comprising two steps: in the first step (  X  -step), we optimize for  X  while keeping w constant, and in the second step ( w -step), we optimize for w , keeping  X  constant.
In this section we describe the experimental setup and the data used to test our user targeting models proposed in Section 2.1.
Our goal in these experiments is to build a conversion model for online display advertisement campaigns. Essentially, this amounts to training a discriminative classifier for identifying potential con-verters versus non-converters, using a training dataset comprising of previous converters and non-converters (similar to [3, 4]). We collect 4 weeks of advertisement data for a set of 200 campaigns from a historical time period. The campaigns were chosen in a non-uniform manner to ensure adequate representation of campaigns across the full range of conversion volumes, where the conversion volume of a campaign denotes the number of conversions obtained by the campaign over a fixed time period (more details below). The data consists of the online activity of users (such as page views, search queries) over a period of 4 weeks, along with information about whether a user converted on a campaign or not, and how many times (within the 4 week period) that the user was exposed to the ads for that campaign.

The activities of the users are a sequence of events collected from server logs. The user X  X  feature vector comprises both raw and cate-gorized event counts for that user for the following types of events:
For each campaign, we therefore have a dataset of users ( u along with their user feature vectors ( f i ) , the number of times the user was targeted with the campaign ad ( x i ), and whether the user converted or not ( y i ).

Since the total dimension of the above feature space can be very high (of the order of millions), we use a Mutual-Information filter to select the top 30 , 000 user features in each campaign for the subsequent modeling experiments. We further down-sample the total number of users (i.e., training and test instances) used by our models to around 100 , 000 users per campaign.
For a thorough empirical analysis of our models, we run our ex-periments over the entire set of  X  200 display advertising cam-paigns described in subsection 4.1, using an efficient Map-Reduce implementation [8]. We bin each campaign into one of 6 buck-ets (based on the conversion volume in the campaign). Instead of showing performance over individual campaigns, to avoid clutter-ing we present the average performance of models for campaigns in each bucket. The buckets correspond to an increasing log-scale in the number of conversions, and span a few orders of magnitude in conversion volume. Figure 1 plots the histogram of the number of campaigns in each bucket.
We note here that users that opt out of targeting are not profiled and are therefore not included in the experiments or in the actual campaigns. Figure 1: Number of campaigns in each conversion-volume bucket (the buckets correspond to an increasing log-scale in terms of the number of conversions).

In all our experiments, 66% of the data from each campaign is used for training the models, and the remaining 34% is used for testing, with 2 -fold cross-validation. We train and evaluate the per-formance of the models independently for each campaign, and also estimate the average performance across all the 200 campaigns.
We use the area under the Receiver Operating Characteristic (ROC) curve to evaluate the ranked list of users produced by the different targeting models. The Area Under Curve (AUC) gives the proba-bility that the targeting model assigns a higher score to a random positive example than a random negative example (i.e., probabil-ity of concordance) [11]. So, a purely random selection method will have an area under the curve of exactly 0.5. An algorithm that achieves AUC of 0.6 can distinguish a positive user from a negative user with 60% probability, and is thus 20% better than a random method.

An alternative metric could be to measure precision/recall at a certain rank in the list. Note that different campaigns may have different requirements in terms of precision and recall. For exam-ple, a small campaign whose reach is limited would prefer higher recall, while a large campaign that reaches out to many users might prefer higher precision. Consequently, selecting a rank at which to evaluate precision such that it would be suitable for all campaigns, is not possible. Hence, we use the AUC as a performance metric since it summarizes the prediction performance over all ranks in a single number.
In this section, we show and discuss the AUC performance of the various models described in Section 2.1. This includes the baseline approaches such as logistic regression without and with the number of past impressions as a feature (denoted by LR and LR+ respectively). Our model variants include the geometric fac-tor model ( EFMG ), the poisson factor model ( EFMP ) and the delayed factor model ( EFMD ) with alternate maximization being used for model inferencing. Lastly, EFMG EM is the geometric model learned using the EM based inference method. We do not report the multinomial model from Section 2.1 since it did not per-form well (primarily due to too many parameters being estimated). Table 1 provides a high-level overview of the average AUC perfor-mance of each of these methods over the full set of 200 campaigns. In the remainder of this section, we discuss the results of each of these methods separately, and also analyze their performance and model parameters for each stratified bucket of campaigns. Table 1: Average AUC for the various models over the full set of 200 campaigns.
We first obtain a baseline by using the Logistic Regression ( LR ) model (specified in Section 2.4), that uses L 1 -regularized logistic regression over the user feature vectors to model conversions for each campaign (ignoring information about past exposure of the user to the ad campaign in consideration). Figure 2 plots the AUC performance of this model for each stratified bucket of campaigns. The average AUC for LR over all the 200 campaigns is 0 . 67 , and as seen from the figure, the AUC increases as the number of con-versions available for training increases.

Next, we compare the performance of the LR+ model that addi-tionally uses the number of past impressions ( x i ) as another feature in the user feature vector f i , which is then modeled using logistic regression. As we see from Figure 1, using this simple method alone increases the AUC by 2 . 5% to 0 . 687 . This demonstrates that past user exposure clearly has some discriminative signal for pre-dicting user conversions, and suggests scope for exploiting this sig-nal better by using a richer model.
We now move on to experiments using our factor models for user exposure: EFMG (that uses a Geometric prior for P[  X  i = 1 | x and EFMP ( that uses a Poisson prior for P[  X  i = 1 | x i in Table 1, EFMG yields an average AUC value of 0 . 716 , and out-performs LR , LR+ , and EFMP by around 7% , 4 . 2% and 2 . 5% , respectively. The fact that the EFMG factor model gives a substan-tial improvement over the LR+ and even the EFMP model, even though all of them use the past user campaign exposures, suggests that the Geometric model for modeling awareness might be a more accurate framework for accounting the effect of user exposure on conversion propensity.

While the EFMP model also improves over LR and LR+ by around 4 . 3% and 1 . 5% respectively, it does not perform as well as EFMG on average.
 Figure 2 shows the average AUC performance for EFMG and EFMP for each campaign bucket. Interestingly, we see that the difference in performance among the models is more pronounced in campaigns with a smaller number of conversions (smaller bucket indices). In bucket 6 all the models perform nearly the same (except EFMP ), while in bucket 1 EFMG has about a 20% higher AUC compared to the LR .
Figure 3 shows the average value of the optimal Geometric pa-rameter  X  (which represents the Bernoulli probability of noticing an ad) computed by the Alternate Maximization algorithm in the EFMG model, and the optimal Poisson parameter  X  in the EFMP model, in different buckets. Except for bucket 2 in the EFMP model, campaigns with a larger number of conversions (larger bucket indices) generally have higher  X  values. Recall from Section 2.2.1 that as  X  goes to 1 , P[  X  i = 1 | x i ] moves closer to 1 regardless of x . Hence, in such cases P[ y i | f i ,x i ] is relatively unaffected by the past impression count x i , and all the user exposure models perform similarly in this situation (including the LR model that does not include user exposure).

We believe that the  X  parameter for each campaign is a measure Figure 2: Average AUC of the campaigns in each conversion volume bucket for the LR, LR+, EFMG and EFMP models. Figure 3: Average probability of noticing the ad (  X  parame-ter) for campaigns in each conversion volume bucket, for the EFMG (Geometric Distribution) model and EFMP (Poisson) models. of the required past exposure and is unrelated to how well the cam-paign matches the user interest. The  X  parameter (noticeability) of the ad campaign depends on many hidden campaign characteristics such as brand awareness of the campaign, the product trustworthi-ness as well as other observable campaign characteristics such as the ad image attributes (e.g., size, color, text), the context where the ad is displayed, the location on the page where the ad is displayed (e.g. at the top of the page, above/below the fold). Modeling the ad noticeability as a function of these non-user attributes is a subject for future research.
We repeat the above experiment for the EFMD model, which in-corporates an additional exponentially decaying delay factor with parameter  X  in the conversion model. As described in Section 2.3, we build this delay model on top of the Geometric distribution with parameter  X  , and solve the resulting maximum likelihood estima-tion problem using alternate maximization. Table 1 shows that the performance of EFMD (AUC of 0 . 717 ) is almost identical to that of the EFM model (AUC of 0 . 716 ). Figure 4 also shows that the Figure 4: Average AUC of the campaigns in each conversion volume bucket for EFMG and EFMP models, with and with-out the additional delay factor (drawn from an exponential distribution) between the user noticing an ad and deciding whether or not to convert on it. Figure 5: Top: Average probability of noticing the ad (  X  pa-rameter) for campaigns in each conversion volume bucket, for the EFMD delay model. Bottom: Average value of the param-eter (  X  ) in the exponential distribution of the delay between the user noticing an ad and making a conversion decision. average AUC of the EFMD model and the EFM models are very similar over all campaign buckets. Figure 5 shows the delay pa-rameter  X  across all buckets, and this variation is non-monotonic. We believe that the delay period represents a phase when a user is considering whether to convert or not, and that our EFMD model without using any additional data source may not be rich enough to effectively model this consideration phase. Figure 5 shows the geometric parameter  X  (noticeability) for the EFMD model, and as with the case for EFMG and EFMP models,  X  increases with the number of conversions.
All the previous results for the factor models used Alternate Max-imization (AM) for estimating the unknown model parameters. Next we explore whether the use of other optimization techniques such Figure 6: Average AUC of the campaigns in each conversion volume bucket for the EFMG models, with parameters esti-mated using Alternate Maximization ( EFMG AM ) and Expecta-tion Maximization ( EFMG EM ), compared with the LR model as Expectation Maximization (EM) affects the performance of the models. For this experiment we first learned the geometric factor model using the alternate maximization (denoted by EFMG ) and then using the expectation maximization (denoted by EFMG EM
Figure 6 compares the AUC performance of EFMG EM and EFMG across all the buckets, on campaigns that converged successfully (a few models in EFMG EM did not successfully converge). We ob-serve that EFMG significantly outperforms EFMG EM in all the buckets: the average AUC for EFMG EM is 0 . 675 compared to 0 . 716 for EFMG . Further, in our experiments with EFMG we observed that EM was much slower to converge than the AM approach and often encountered numerical stability issues with the M-step iterations. The reason for this poor performance with EM is likely due to the fact that we use a gradient-descent method for the M-step iterations even though the optimization objective is not convex.
In this paper we have presented an ad-exposure based factor model framework for capturing the joint effect of past ad exposure and user interest on conversion propensity for display ads. Our experimental results over a large set of 200 real-world online ad campaigns provide insights into the role that a user X  X  past exposure to an ad campaign plays in predicting her response to the cam-paign. Our EFM models obtain more than a 4 to 7% gain in AUC over traditional targeting schemes that either do not consider past exposure at all, or use it naively as yet another user feature. This suggests that our models can indeed effectively factor out the sepa-rate components in terms of the interest-match component and the past-exposure component.

We can leverage this capability in two ways: first, this allows our models to target potential converters more accurately, as evident in the AUC performance. More interestingly, the  X  parameter that we obtain from the joint modeling of two factors in EFMG and EFMP , gives us a single metric for capturing the  X  X ffectiveness X  of different ad campaigns. Advertisers can potentially use this in-formation to determine aspects of their campaign strategy such as finding the right amount of past exposures needed by an ad to ef-fectively target an interested user. [1] Zo X  Abrams and Erik Vee. Personalized ad delivery when [2] N. Archak, V. S Mirrokni, and S. Muthukrishnan. Mining [3] Abraham Bagherjeiran, Andrew O. Hatch, and Advait [4] Abraham Bagherjeiran, Andrew O. Hatch, Advait [5] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent [6] Ye Chen, Michael Kapralov, Dmitry Pavlov, and John F. [7] Ye Chen, Dmitry Pavlov, and John F. Canny. Large-scale [8] Jeffrey Dean and Sanjay Ghemawat. Mapreduce: simplified [9] Xiang Fang, Surendra Singh, and Rohini Alhuwalia. An [10] Thore Graepel, Joaquin Quinonero Candela, Thomas [11] J. A. Hanley. Receiver Operating Characteristic (ROC) [12] Wei Li, Xuerui Wang, Ruofei Zhang, Ying Cui, Yun Jiang, [13] Puneet Manchanda, Jean-Pierre Dube, Khim Yong Goh, and [14] Andrew Kachites McCallum. Mallet: A machine learning for [15] Foster Provost, Brian Dalessandro, Rod Hook, Xiaohan [16] Navdeep Sahni. Effect of temporal spacing between [17] Xiaoxiao Shi, Kevin L. Chang, Vijay K. Narayanan, Vanja [18] Ramakrishnan Srikant, Sugato Basu, Ni Wang, and Daryl [19] Jun Yan, Ning Liu, Gang Wang, Wen Zhang, Jianchang Mao,
