 ORIGINAL PAPER Roger D. Boyle  X  Hazem Hiary Abstract We consider the problem of locating a watermark in pages of archaic documents that have been both scanned and back-lit: the problem is of interest to codicologists in identifying and tracking paper materials. Commonly, docu-ments of interest are worn or damaged, and all information is victim to very unfavourable signal-to-noise ratios X  X his is especially true of  X  X idden X  data such as watermarks and chain lines. We present an approach to recto removal, followed by highlighting of such  X  X idden X  data. The result is still of very low signal quality, and we also present a statistical approach to locate watermarks from a known lexicon of fragments. Results are presented from a comprehensively scanned nine-teenth century copy of the Qur X   X  an. The approach has lent itself to immediate exploitation in improving known water-marks, and distinguishing between twin copies.
 Keywords Wa t e r m a r k  X  Recto removal  X  Back-lighting 1 Introduction
The study of watermarks is a seductive if somewhat esoteric pastime. While it is normally the beauty and aesthetic quality of watermarks that initially attract the researcher, they are more than just pretty affectations and can shed light on historic trends and events [ 46 ].
This comment by Pavelka acquires more veracity as time passes. Watermarks are indeed compelling viewing in their own right, especially when extracted from ancient and unu-sual documents X  X ig. 1 illustrates just one example. Mod-ern opportunities for high quantity and high quality digital repositories suddenly make available many documents hith-erto only selectively available (our own prototype is just one small example [ 30 ]); at the same time, image analysis and understanding techniques continue to grow in sophistication and the modern codicologist has new horizons in studying these beautiful and informative patterns.

Paper watermarks, which are changes in paper thickness, have been in use for over 700 years, with the oldest known watermarked paper produced in 1282 in Fabriano [ 9 , 10 , 57 ]. They have been used as trademarks of paper-makers, as iden-tification marks for sizes of moulds used in manufacture, as symbols of religious groups called  X  X lbigenses X , as an aid to illiterate workmen, and as an exercise in imagination by paper-makers, just to show their artistic skills. Their use spread and came to be used to trademark paper, a proof of the date of manufacture, and an indication of paper size, cul-minating in use as a mark against counterfeiting on money and other documents [ 33 ].

Two main types of paper watermarks exist: line (typi-cally known as wire), and shadow (light and shade). Com-bined watermarks have both. Further types are described in [ 34 , 39 ]. Wire watermarks are made using lines to form var-ious patterns, such as letters, numbers, portraits, or other designs; they appear lighter than surrounding paper area. Light and shade watermarks have patterns resulting from relief sculptures on the mould; these designs give the water-mark further variations to support more features, and may appear lighter or darker than the surrounding area. They offer more details compared to wire watermarks, but are rela-tively expensive, depending on the size and the quality of the mould model [ 33 ]. In many mills, paper making was often accelerated by making pairs of moulds with two very similar but not identical watermark designs; watermarks are gener-ally twins [ 57 , 60 ].

Watermarks in paper have attracted a wide range of inter-est from researchers for centuries; their study is helpful in tracing and studying old documents and artefacts to provide plausible historical relationships and background informa-tion. Even when they do not bear explicit dates, the tempo-ral and other evidence they provide can be significant X  X ee, designs are available not only in several different forms, but also dynamically change over time. This has introduced some complications that have hindered more systematic study of the artefacts.

We present here an approach for identifying and locat-ing watermarks in  X  X ifficult X  artefacts, characterised by thick uneven paper and significant quantities of thick-stroke recto and verso inscription. One side effect of the approach is to reveal other details of the original mould such as chain lines, which have been found to be as useful as the watermark in some examples of paper identification [ 61 , 69 ]. We seek to do this with equipment of modest cost with an approach that minimises hazard to the original artefact while generating good resolution, easily distributable digital images.
This paper proceeds as: Sect. 2 presents recent and related work in watermark study. Section 3 describes the data used in our approach, with the capture system used. Section 4 presents our approach in removing recto information, while Sect. 5 focuses on localisation of watermarks. Section 6 pro-vides results from the approach, and Sect. 7 develops these further. We conclude in Sect. 8 . 2 Background Watermarks only become visible to the eye when faced against light, and are usually obstructed by writing ink and other noise in paper. Many approaches have been developed in order to reproduce and exploit them; a survey appears in [ 29 ].
 Image collection techniques fall under four broad heads:
Manual: The most primitive techniques would either place a document on a light table and a user would copy the water-mark onto tracing paper laid on top, or alternatively a clean sheet is placed over the document and a pencil is rubbed over it with long diagonal strokes. The former is simple and easy but is time consuming and highly subjective X  X ell-known catalogues of traced watermarks include [ 9 , 13 , 28 ]. The lat-ter is quick, easy, and does not require special equipment, but it does not produce good results, and may damage the paper [ 2 ]. Examples of watermark reproduction by rubbing can be found in [ 27 ].

Back-lighting: This requires a high resolution digital CCD camera and a light source. The camera captures reflected (with normal light) and transmitted (with back-light from 70 ]. It is quick and relatively low cost, and produces good image quality without darkroom conditions. It differs from other techniques in that it is digital, making it very attrac-tive to scholars [ 58 ]. However, it captures all the details of paper, including the watermark and any other designs that may interfere with it.

Radiographic techniques: The advantage of radiography matter what is printed on it [ 58 ]. X-rays are useful because of not being absorbed by the writing ink (usually Carbon) on paper [ 1 ]. 1. Beta-radiography uses beta-isotopes (Carbon-14) to 2. Soft (or low voltage) X-radiography uses a low volt-3. Electron-radiography uses high energy X-rays to pen-Special purpose techniques: A range of other, specialist 1. The  X  X ylux X  method which uses paper differently 2. The  X  X lkley X  method requires two glass plates, a light 3. Phosphorescence watermark imaging requires ultra-4. Thermography, or thermal photography, is a
A number of web archives of watermarks exists [ 5 , 15 , 37 , 72 , 73 ].

To date, most work on watermark extraction has been in pursuit of the compilation of databases. Clearly, manual techniques represent an end in themselves, but the more sophisticated approaches have been subject to further com-puter-based manipulation. Commonly, combinations of edge detection, region extraction and morphology are used to try to isolate clean watermark representations: examples of such be found.

Enhanced approaches deploy reflectance models [ 64 ], or seek identifiable properties of paper such as [regular] chain lines (where Fourier techniques are of use), for example [ 22 , 67 , 71 ]. Work is also in hand on matching extracted water-marks to existing databases [ 47 , 48 ].

Common to most work to date have been problems with noise in images, attributable to paper quality and interfer-ence from recto and verso inscription. Self evidently, this will hamper work on many of the most interesting artefacts to be found in libraries. We also observe in many solutions to date a reliance on certain parameter settings in a range of algorithms, which hinders their broader applicability.
Our work is interested in addressing these, and related, problems in seeking watermarks. Specifically:  X  We mean to develop techniques that will work on mate- X  We mean to attempt to extract complete, or near-complete,  X  We mean to develop tools that may be useful in distin-
This work should be done in a context of parameter selec-tion that is, as far as possible, automatic or adaptive. As a side effect, we will be able to make available via the WWW some materials that may be of benchmark value in future study, and are of immediate interest to scholars of Arabic [ 30 ]. 3 Data and digitisation We have chosen to use back-lighting, because it is simple, rel-atively quick, and cheap, generating output that is natively digital. The system we use is mounted using a stand with lights by Kaiser Fototechnik [ 35 ] and a FUJIFILM FinePix S1 Pro camera [ 18 ]. It uses a slim light sheet for back-lighting to provide even homogeneous illumination behind the paper. Each sheet is captured three times, reflected images of front and back, and a transmitted image; the recto and the back-lit scans are co-registered. In these experiments a resolution of 258dpi was used.

The data used has been selected from the Arabic holdings of the University of Leeds, which include a number of rare, unusual and little-known texts. Those chosen all carry wire watermarks, represented by a relative thinning of the paper. Specifically:  X  The  X  X ahdiyya X  Qur X   X  an [ 11 ]: written in 1881 in Sudan.  X  The  X  X est African X  Qur X   X  an: This is a complete copy of the  X  A long Islamic Prayer: Kit  X  ab Durrat  X  X qd al-nah .
Of these, the most challenging by far is the first and it is on this document that we have done most development: an example is at Fig. 2 . The others provide regular verification that  X  X asier X  scans are indeed more easily accessible.
Each of these volumes carries different watermarks and in aggregate represent over 800 sheets. We see merit in estab-lishing benchmark datasets for the work we have done; since creation of such data may be non-trivial in time and library permissions, we have made these scans publicly available online [ 30 ]. 4 Recto removal In earlier work [ 31 ] we have located watermarks using an image processing bottom-up approach that deploys back-ground estimation and morphology, and is comparable in automatic parameter selection. On the very difficult data of the  X  X ahdiyya X  Qur X   X  an we found these approaches less than successful and in some cases wholly unproductive as a result of the noise levels and very faint watermark evidence [ 29 ]. We chose instead to build a model of back-lighting to take a top-down view.
 This model is illustrated in simplified form in Fig. 3 .The RGB vector detected at a particular pixel is dependent on the paper properties (absence or presence of watermark or other manufactured feature), recto features and verso features. In an ideal world, blank featureless paper (labelled  X  X  X  in the figure) would always produce the same output, but we do not have to assume that the same is true of inked regions (e.g.,  X  X  X ), paper features, or combinations thereof.

For clarity, we shall define at this point a feature to be vis-ible if it is visible on the recto X  X hus, recto writing and other paper features visible to the reader. Other features betrayed in the back-lit image (watermark, verso writing, dirt on the verso face etc.) we shall collectively call hidden . Back-lit pixels at which no hidden data are evident we shall call uncorrupted .
In fact, the noise and damage that we experience produce significant variations across all regions that we might wish to be internally homogeneous, as may be clear from Fig. 2 .This however is not critical X  X hat we can exploit is the difference between pixels that represent just blank paper or recto fea-tures, and those representing verso or other features, such as internal ones.

Consider momentarily a blank, featureless page which we scan as image S and back-light as image B , and define an image D in which pixels are given by the difference between their detected back-lit intensity (in B ), and the intensity we might expect given the corresponding location in S .Inthe ideal case this page will be of uniform intensity ( r , g S and, say, ( X , X , X ) in B . We hypothesise some transform T which describes the back-lighting, and subtract T ( r , from the corresponding ( X , X , X ) in B . We should see (0, 0, 0) at all locations. If there are paper or verso features (invisible in S ), these will be revealed by this differencing process.
In fact, of course, regions are not uniform in intensity and blank paper will scan and back-light as a range of ( r , g ( X , X , X ) vectors X  X hese may, however, be expected to clus-ter reasonably tightly, and to be related to each other. If we define ( X  ( X   X  , X   X  , X   X  ) = mean ( X  then a simple approach is to seek a linear relationship ( X  for some 3  X  3matrix A that models the back-lighting. Light-ing effects are often subtle and it is most unlikely that the effect we observe will indeed be linear, but we proceed with this simplification on the understanding that it is applied only to pixels that are  X  X imilar X , and in the ideal case identical.
In the event that there are no internal or verso features, we can derive an optimal A by considering Eq. 2 for all pixels p as an over-determined system and  X  X nverting X  1 A = ( X  Then, for the simple case of a blank page, D = ( X  and we will expect significant differences from ( 0 , 0 , betray hidden information.

In the event that the image does contain hidden features, this approach lends itself to an immediate improvement. Assuming that there exist uncorrupted pixels in B and the relative number of hidden features is small, we shall expect the (wire) watermark to exhibit a high magnitude response in D , and the uncorrupted areas to be low (ideally 0). There-fore, we may recompute A by reducing the set of pixels from which it is derived to those we expect to be featureless; thus, Eq. 3 may be re-employed;  X  D ={ p :| D p | &lt; t }
For p  X   X  D , A new =[ ( X  p , X  p , X  p ) where | D p | is a measure of the magnitude of the difference vector at p  X  X uclidean length is an obvious choice. A choice for the threshold t is given in Sect. 6 . This procedure is open, of course, to iteration in attempting only to compute A from pixels which are uncorrupted.

In the general case we shall expect scans to carry recto material and so the preceding assumptions about a  X  X lank piece of paper X  are invalid. Nevertheless, the approach is sound if we can apply it to pixels of S that are similar in intensity. This is straightforwardly achieved by clustering the data of S in RGB space, and deriving a matrix A for each such cluster. Formally; 1. Using K-means [ 56 ] or similar, cluster the RGB data of 2. For each cluster C i derive a matrix A i according to The iterative refinement approach of Eq. 5 is applicable to each such cluster.

The choice of K 1 is interesting: in many applications it is desirable to minimise the number of clusters chosen, lead-ing to a more compact data encoding. Here, the problem is somewhat different: the more clusters we define, the bet-ter the subtraction process is likely to perform, provided the matrices A i are approximating uncorrupted pixels. This issue is considered further in Sect. 6 . Figure 4 illustrates this procedure. 5 Watermark location Recto removal is robust and successful (see Sect. 6 ). In pur-suit of specific features we make two further assumptions: 1. We might expect verso inscription to be dark relative to 2. We assume we know a set of possible or likely water-
The output of the differencing phase contains very signif-icant noise in addition to information of value; Fig. 4 illus-trates this. The presence of fragments of value is clear, but the information of interest is not among the strongest responses, and simple thresholding approaches are unlikely to assist. On the other hand, pixels of the watermark are similar in RGB intensity, and to exploit this we re-cluster the D image.
We generate K 2 binary images D 1 , D 2 ,..., D K 2 by parti-tioning D  X  X he choice of K 2 is discussed in Sect. 6 . Figure 5 illustrates some of these for the example of Fig. 4 . Some of these clusters will represent binary images that include good representations of fragments of the watermark, while others may not. In particular the  X  X ackground X  X  X ncluding the nulled pixels X  X ill. We proceed by selecting informa-tive fragments of the watermark and seeking a binary match in each of these partitions of D . Figure 6 illustrates two such fragments from the watermark of Fig. 1 .  X  X atching X  here is a binary templating task. We proceed for a given template (watermark fragment) W i by assuming it contains N pixels, of which w i are 1 X  X . When the template is offered at a particular offset in the image D j , we count the number of pixels that match (both 1 X  X  or both 0 X  X ) and inter-pret this  X  X core X  in the light of what may be expected in noise. If at this offset in D j there are d 1 X  X , and these are chosen randomly, we have an instance of sampling without replace-ment to which the hyper-geometric distribution is applicable [ 42 ]. If at template offset p we write u ( p ) = {Number of pixels at which both template and image are 0 or 1}, then (see Appendix)  X ( u ( p )) = N + 2  X  2 ( u ( p )) = 4  X  X oth mean and variance depending on the properties of the template fragment and the position in the image.

In seeking plausible locations for the fragment, we are interested in significant deviations from the mean expected in noise  X ( u ) .  X  X ignificance X  might be measured with respect to the standard deviation  X ( u ) . Thus at pixel position p in image D j we will compute m ( p ) = u Herein, high positive responses will represent plausible match positions. The exception is the binary image D 0 repre-senting  X  X ackground X  (zero pixels) which might be expected to generate a strong negative response at matching positions. For the background data, we thus negate m ( p ) .

An example result M i = m ( p ) is illustrated in Fig. 7 . ( a ) (b) At this stage we can accumulate the M i ; M ( p ) = Significant peaks in this array represent evidence for the fragment in the original image. In fact, we have valuable additional evidence from second, or further, fragments of the watermark: applying this procedure for each such fragment we can exploit their known geometric relationship in inspect-ing peaks in the M array; this is explored in Sect. 6 . 6 Results We have tested this approach with 346 pages of data from the  X  X ahdiyya X  copy of the Qur X   X  an. An evaluative measure is necessary in judging levels of success, and we have chosen to use the signal-to-noise ratio (SNR) [ 56 ] of known data in a small number of samples. If a watermark and its position are known, we split image pixels into two groups: watermark features W , and all others which we regard as noise N . Then SNR may be calculated as SN R = i  X  W (where x denotes the mean RGB value of each pixel). This considers the watermark to be a binary feature; this is based on all the watermarks here considered to be wire. 6.1 Recto removal As discussed, we compute a transform A that approximates the intensity effect of back-lighting; this is then used to remove all recto information in a differencing operation. Using the simple computation of A (Eq. 3 ), Fig. 8 a illustrates the distribution of differences (computed as the average of the RGB channels) for a sample image pair. We expect high differences to correspond to hidden, bright features in the back-lit image B (region X on the horizontal axis), small differences (region Y ) to be due to uncorrupted pixels, and dark features in B , such as verso writing, to be negative dif-ferences (region Z ). This distribution is asymmetric, with verso features appearing prominently as negative; low mag-nitude pixels are modal, suggesting that the transform was good enough to model the back-lighting. High magnitude pixels in this distribution are relatively small in number, and represent the watermark and some other hidden features.
Adopting the approach outlined in Sect. 4 , we have itera-tively refined A by recomputing the pixels from which it is derived. We have selected pixels between the means of pos-itive and negative observations in the differences. This is a simple way of trying to restrict the computation to uncor-rupted areas of the image in the light of the distribution being asymmetric. Figure 8 b illustrates the distribution after this iteration has been conducted; observe that region Y in this new distribution is narrowed, while regions X and Z (which hold verso and hidden features) were pushed to right and left respectively. With foreknowledge of the watermark, we can draw its distribution before and after improving A . Figure 9 a, b illustrate such distributions; pixel intensities were increased after iterating A  X  X he watermark signal has been strengthened.

It is not clear in the general case whether the iteration will converge or when it should be halted, but we can demon-strate its beneficial effect from data with known ground truth. Figure 10 shows the SNR as the matrix A is iterated, show-ing that X  X s anticipated X  X he signal improves. In this case, the watermark signal improves monotonically until there is convergence: we have seen this effect in all examples we have studied.
In the unknown case, SNR cannot be measured. Figure 11 plots the Frobenius norm [ 23 ] of the difference between suc-cessive iterations of A for just two examples (others are similar) suggesting that this adequately mirrors the signal improvement we wish to see.

We therefore adopt a convergence criterion that iterates until the matrix A stabilises, so the norm of the difference between successive iterations becomes 0. In the event this is not observed, we may halt the iteration either when the norm reaches a minimum, or at the  X  X lbow X  in the plot of Fig. 11 , calculated for example by the L-method [ 51 ].

To observe the effect of recomputing the transform, the initial matrix A , and after 30 iterations, for a specific cluster, are  X   X   X  0 . 013 0 . 213 0 . 084
In this example, values in the first and second columns (red and green) have increased, while the third column (blue) has decreased. These observations vary among different clusters.
In selecting K 1 , most literature, e.g. [ 17 , 51 ], seeks a trade off that seeks the lowest value which is simultaneously high enough to capture the nature of the data. Plotting cluster-ing cost (summed distances from data to centroids) against K (see Fig. 12 ), one seeks the point of diminishing returns where the cost starts to decrease slowly: the L-method of Salvador [ 51 ] is a well-known approach.

The problem here is different: the more clusters we define, the better the subtraction process is likely to perform pro-vided we do not develop clusters in which hidden features are numerically dominant.
 To avoid this, we choose a lower bound for K 1 using the L-method and iterate it until reaching an unacceptability cri-terion. Having knowledge of the mean of image B (Eq. 1 ), we can similarly compute a mean from B for each cluster C ,..., C  X  , X  i  X  , X  i  X  ) = mean ( X  p , X  p , X  p ) : p  X  C i , i = By experiment we discover that the condition  X  &gt; X   X  AND  X  i  X  &gt; X   X  AND  X  i  X  &gt; X   X  is sufficiently strict X  X hould a cluster channel mean exceed the global one on all three colour channels, we decrement K and accept it as the value with which to proceed.

Having foreknowledge of the watermark design and its position, we can verify the applicability of the preceding algorithm. At each iteration, we consider the pixel locations of each cluster in B , and compare them with the location of the known watermark. If most pixels of a single cluster represent watermark features, we can compare K 1 with the best value obtained from the algorithm. This verification was successful with 30 randomly chosen test pages.
 Characteristically, for the difficult data of the  X  X ahdiyya X  Qur X   X  an, starting values of K 1 chosen by the L-method were in the range 9 X 11, and the final values using our algorithm were in the range 20 X 25 clusters. An example of a sample input S and a transform of it are shown in Fig. 13 . It is clear that background features vary from one region to another, but the transform has compensated for this. 6.2 Watermark location The differenced image D is improved by setting negative pixel values to 0 X  X e set a pixel value to 0 if any of its RGB channels is negative. Figure 14 shows an example resulting D . While the watermark features are partially evident here, noise is still very considerable. We find a partial segmenta-tion by clustering to K 2 centroids the RGB data in D ;this time the L-method [ 51 ] is a suitable approach as we seek to minimise computational load while maximising information retention. In all experiments we have performed, on data of a range of qualities, the number of clusters so determined has been of the order of 10. Figure 15 illustrates the cluster dis-tribution of D : the zoomed window shows that these clusters do successfully pick out watermark features, in addition to many noise and other artefacts.

We now construct the array M (Eq. 7 ) which aggregates the evidence of fit. With well-chosen templates, we find a thresholding approach successful at this stage, but it is sen-sitive to threshold choice in the event of significant noise. Figures 16 and 17 illustrate this response M for two water-mark fragments, where dots denote significant peaks, and squares their centroids (zoomed for better viewing).
A simple remedy is to exploit the fragments X  known geo-metric relationship (offset from one another) in inspecting these peaks. In other words, we seek co-occurrences of peaks in accumulated M arrays that match the known geometric relationship of the fragments.

After locating the centroids of significant peaks for each fragment, we find the geometric relations (offsets) between each pair. Known geometric relations are inspected between significant peaks in a generalised Hough transform-like approach [ 56 ], and the match with the highest combined non-zero response accepted as best possible. If no suitably offset peaks are found, a negative ( X  X o fit X ) result is gener-ated.

It will be clear that the existence of three or more frag-ments from a watermark would improve the potential of this approach further, and we have demonstrated this with three fragments in a few cases [ 29 ]. It turns out that two are suffi-cient for nearly all the data we have processed; further, it is often the case that not all three are discernible, and a pairwise search is more productive.

Our classifier works very well in recognising watermarks, even those of weak signal, with a very high percentage of true positives and no false positives. Table 1 shows retrieval results for four design parts: the double-headed eagle water-mark  X  X  X , and a moonface-within-shield countermark  X  X  X  used in the  X  X ahdiyya X  Qur X   X  an.

There remain a few false negatives when the signal is very weak, due to the very poor signal evident in the original scans. Various approaches allow boosting of this signal in manipulations of the D image, but these usually have a side effect of generating many false positives X  X ven deploying the known geometric relationship of fragments leaves this problem. Nevertheless, the results we have to hand are most encouraging since they are extracted with negligible interac-tion. The  X  X orrect X  answer does always show evidence, leav-ing open the opportunity for a swift interactive confirmation in very difficult cases.

We proceeded to test the approach with the other data sets and it gave perfect scores for both. This is doubly encour-aging since X  X espite being simpler X  X hese data are of sig-nificant scholarly interest and have not to date been studied. It is thus our belief that libraries hold a wealth of material that will be susceptible to the algorithms we present here, implying that the publication of systematic backlit scanning is a worthwhile exercise. 7 Watermark aggregation and  X  X wins X  The output of Sect. 6.2 provides many examples of the same watermark. Individually, they are incomplete, often seriously so, and we have experimented with aggregating them to improve the signal: this has then been trialled for known watermarks using the SNR measure discussed in Sect. 6 . A simple statistical model suggests that this measure will either improve or deteriorate as the reciprocal of the number of images used X  X ee Appendix.

The value and interest of this procedure is well demon-strated by example, since it has revealed details of water-marks that we could not observe before. Figure 1 illustrates the superimpositions of the double-headed eagle: we could not detect the  X  X  G X  countermark below it in single sheets before applying this process. Many other details of the design also become clear that cannot be detected in individual sheets. We also observe chain lines have developed high response in the aggregated image.

The more superimpositions, the clearer the watermark details. Experiments confirm that adding more samples pro-vides a better SNR than individual images X  X ig. 18 shows SNR values of superimposing 2 and more differenced images D k of the double-headed watermark.

It is clear that some parts of the superimposed watermarks in Fig. 1 are brighter than others; lower quality areas are attributable to the (removed) presence of recto features, and the nulling of pixels associated with verso features.
The aggregation operation may also be useful in the study of  X  X wins X : when similar designs are superimposed, it could be easy to identify the differences between them. To illus-trate this, we isolated 3 tre lune watermarks taken from dif-ferent sheets of the Prayer. Figure 19 shows two different pairwise aggregations: in this example, the first two water-marks were observed as  X  X dentical X , where the third shape was  X  X win X  X  X his is obvious by looking into the slight changes of the crescents X  edges. This figure is magnified for better visu-alisation. 8 Conclusion This paper has considered the location and extraction of watermarks from paper. Its contributions are  X  An approach aimed at challenging data: variable paper  X  An approach to extracting representations of a full water- X  Consequent on this, an approach to distinguishing
Success has been demonstrated in these on a large and dif-ficult data set bearing four different individual watermarks, and further demonstrated on two different volumes (with different marks) which X  X hile less challenging X  X ave not to date been analysed for watermark content. Algorithms require negligible interaction and most parameters are derived automatically. The same algorithms applied to eas-ier data provide very good results where more traditional techniques [ 31 ] are often seen to fail.

We see opportunities for improving and streamlining the ideas presented here in several ways. Among these are:  X  We have not to date used knowledge of the verso scan to  X  The cluster-by-cluster linearity assumption developed in  X  We see scope for more intelligent extraction of the water- X  Of longer term interest is to explore the image D when the These represent work in hand.

We are confident that the work we present here is easily applicable to a range of historically interesting documents: our current work means to exploit further some of the scarce holdings in the University of Leeds collection.
 Appendix A: Mean and variance of a match measure on two binary vectors of known  X  X ally X  Suppose we have two binary vectors of dimension N : v = (v 1 We are told that there are I 1 X  X  in v 1 and J in v 2 : Count w( v 1 , v 2 ) as the number of times corresponding vector components are both 1 or 0; then 0  X  w( v 1 , v 2 )  X  N : w( v 1 , v 2 ) = Given v 1 , suppose v 2 is chosen randomly X  X e seek the mean and variance of w . Suppose 11 a 10 b 01 c 00 d where then
I = a + b , N  X  I = c + d
J = a + c , N  X  J = b + d N = a + b + c + d
Then we seek w = a + d = a + ( N  X  a  X  b  X  c ) = a + ( N  X  a  X  ( I  X  a )  X  ( J  X  a )) = 2 a + N  X  I  X  J Now the distribution of a is hyper-geometric (see, e.g., [ 42 ]) giving  X ( a ) =  X  2 ( a ) = IJ So  X (w) = 2  X ( a ) + N  X  I  X  J  X  2 (w) = 4  X  2 ( a ) Appendix B: Expected SNR from aggregating responses Suppose a window of N pixels contains S pixels of signal, distributed with mean  X  s and variance  X  2 s . The remaining N  X  S pixels are noise with mean  X  Using Eq. 8 to calculate SNR, the expected value will be (
N  X  S )( X  2 n +  X  2 n ) and when k such images are superimposed, will be (
N  X  S )( k 2  X  2 n + k  X  2 n )
This is thus reciprocal in k , with the sign provided by the relative magnitudes of the signal and noise parameters. References
