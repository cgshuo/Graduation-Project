 Real-life data is often dirty: Up to 30% of an organization X  X  data could be dirty [2]. Dirty data is costly: It costs the US economy $3 trillion+ per year [1]. These highlight the importance of data quality management in businesses. Data cleaning is the process of identifying and (possibly) fixing data errors. In this paper, we will focus on discussing dependency based data cleaning tech-niques, and our research atte mpts in each direction [5].
 Error Detection . There has been a remarkable series of work to capture data (see [17] for a survey). A violation is a set of data values such that when putting together, they violate some ICs , thus considered to be wrong. However, ICs can-not tell, in a violation, which values are correct or wrong, thus fall short of guiding dependable data repairing. Fix ing rules [30] are proposed recently that can precisely capture which values are wrong, when enough evidence is given. Data Repairing . Data repairing algorithms have been proposed [7,8,12 X 15,23,24, 26,28,31]. Heuristic methods are developed in [6,8,13,26], based on FDs [6,27], FDs and INDs [8], CFDs [18], CFDs and MDs [23] and denial constraints [12]. Some works employ confidence values placed by users to guide a repairing pro-cess [8,13,23] or use master data [24]. Statistical inference is studied in [28] to derive missing values, and in [7] to find possible repairs. To ensure the accuracy of generated repairs, [24,28,31] require to consult users. Efficient data repairing algorithms using fixing rules have also been studied [30].
 Data Cleaning Systems . Despite the increasing importance of data quality and the rich theoretical and practical contributions in all aspects of data cleaning, there is a lack of end-to-end off-the-shelf solution to (semi-)automate the de-tection and the repairing of violations w.r.t. a set of heterogeneous and ad-hoc quality constraints. Nadeef [14, 15] was presented as an extensible, general-ized and easy-to-deploy data cleaning platform. Nadeef distinguishes between a programming interface and a core to achieve generality and extensibility. The programming interface allows the users to specify multiple types of data quality rules, which uniformly define what is wrong with the data and (possibly) how to repair it through writing code that implements predefined classes.
 Organization . We describe error detection tec hniques in Section 2. We discuss data repairing algorithms in Section 3. We present a commodity data cleaning system, Nadeef , in Section 4, followed by open research issues in Section 5. In this section, we start by illustrating how integrity constraints work for error detection. We then introduce fixing rules.
 Example 1. Consider a database D of travel records for a research institute, specified by the following schema: where a Travel tuple specifies a person, identified by name , who has traveled to is shown in Fig. 1. All errors are highlighted and their correct values are given between brackets. For instance, r 2 [ capital ]= Shanghai is wrong, whose correct value is Beijing .

A variety of ICs have been used to capture errors in data, from traditional ( e.g., conditional functional dependencies [18]).
 Example 2. Suppose that a functional dependency ( FD ) is specified for the Travel table as: which states that country uniquely determines capital . One can verify that in carry different capital values,sodo( r 1 ,r 3 )and( r 2 ,r 3 ).

Example 2 shows that although ICs can detect errors ( i.e., there must exist errors in detected violations), it reveals two shortcomings of IC based error de-with any tuple w.r.t.  X  1 , but t 4 cannot be considered as correct. Fixing Rules. Data cleaning is not magic; it cannot guess something from nothing. What it does is to make decisions from evidence. Certain data patterns of semantically related values can provide evidence to precisely capture and rectify data errors. For example, when values ( China, Shanghai ) for attributes China ,and Shanghai should be Beijing ,the capital of China . In contrast, the values ( China, Tokyo ) are not enough to decide which value is wrong.
Motivated by the observation above, fixing rules were introduced [30]. A fixing rule contains an evidence pattern ,asetof negative patterns ,anda fact value. Given a tuple, the evidence pattern and the negative patterns of a fixing rule are combined to precisely tell which attribute is wrong, and the fact indicates how to correct it.
 Example 3. Figure 2 shows two fixing rules. The brackets mean that the corre-sponding cell is multivalued.
 are China , { Shanghai, Hongkong } ,and Beijing , respectively. It states that for a tuple t ,ifits country is China and its capital is either Shanghai or Hongkong , capital should be updated to Beijing . For instance, consider the database in r [ capital ]is Shanghai . It will then update r 2 [ capital ]to Beijing .
Similarly, the second fixing rule  X  2 states that for a tuple t ,ifits country is Canada , but its capital is Toronto ,thenits capital is wrong and should be paired.
 Notation. Consider a schema R defined over a set of attributes, denoted by attr ( R ). We use A  X  R to denote that A is an attribute in attr ( R ). For each attribute A  X  R , its domain is specified in R , denoted as dom ( A ). Syntax. A fixing rule  X  defined on a schema R is formalized as (( X,t p [ X ]) , ( B,T  X  p [ B ]))  X  t + p [ B ]where
Intuitively, the evidence pattern t p [ X ]of X , together with the negative pat-on B .Thefact t + p [ B ] in turn indicates how to correct this error.
Note that condition (4) enforces that the correct value ( i.e., the fact) is dif-ferent from known wrong values ( i.e., negative patterns) relative to a specific evidence pattern.
 t matches rule  X  indicates that  X  can identify errors in t .
 Example 4. Consider the fixing rules in Fig. 2. They can be formally expressed as follows:  X  : (([ country ] , [ China] ) , ( capital , { Shanghai, Hongkong } ))  X  Beijing  X  : (([ country ] , [ Canada ]) , ( capital , { Toronto } ))  X  Ottawa
In both  X  1 and  X  2 , X consists of country and B is capital . Here,  X  1 states that, if the country of a tuple is China and its capital value is in { Shanghai, Hongkong } ,its capital value is wrong and should be updated to Beijing . Similarly for  X  2 .

Consider D in Fig. 1. Tuple r 1 does not match rule  X  1 ,since r [ country ]= China but r 1 [ capital ]  X  X  Shanghai, Hongkong } .Asan-other example, tuple r 2 matches rule  X  1 ,since r 2 [ country ]= China ,and r [ capital ]  X  X  Shanghai, Hongkong } . Similarly, we have r 4 matches  X  2 . Semantics. We next give the semantics of fixing rules.

We say that a fixing rule  X  is applied toatuple t , denoted by t  X   X  t ,if( i ) t t [ B ]toupdate t [ B ]. This yields an updated tuple t with t [ B ]= t + p [ B ]and t [ R \{ B } ]= t [ R \{ B } ].
 Example 5. As shown in Example 3, we can correct r 2 by applying rule  X  1 .As r [ capital ]= Beijing and the other attributes of r 2 remain unchanged.
Similarly, we have r 4  X   X  2 r 4 where the only updated attribute value is r [ capital ]= Ottawa .
 Fundamental problems associated with fixing rules have been studied [30]. Termination. The termination problem is to determine whether a rule-based process will stop. We have verified that applying fixing rules can ensure the process will terminate.
 Consistency. The consistency problem is to determine, given a set  X  of fixing rules defined on R ,whether  X  is consistent.
 Theorem 1. The consistency problem of fixing rules is PTIME .

We prove Theorem 1 by providing a PTIME algorithm for determining if a set of fixing rules is consistent in [30].
 Implication. The implication problem is to decide, given a set  X  of consistent fixing rules, and another fixing rule  X  ,whether  X  implies  X  .
 Theorem 2. The implication problem of fixing rules is co NP -complete. It is down to PTIME when the relation schema R is fixed.
 Please refer to [30] for a proof.
 Determinism. The determinism problem asks whether all terminating cleaning processes end up with the same repair.

From the definition of consistency of fixing rules, it is trivial to get that, if a and the updated t is deterministic ( i.e., a unique result). In this section, we will discuss several classes of data repairing solutions. We will start by the most-studied problem: computing a consistent database (Sec-tioin 3.1). We then discuss user guided repairing (Section 3.2) and repairing data with precomputed confidence values (Section 3.3). We will end up this section with introducing the data repairing with fixing rules (Section 3.4). 3.1 Heuristic Algorithms A number of recent research [4,8,12] have i nvestigated the data cleaning problem introduced in [3]: repairing is to find another database that is consistent and minimally differs from the original database. They compute a consistent database by using different cost functions for value updates and various heuristics to guide data repairing.

For instance, consider Example 2. They can change r 2 [ capital ]from Shanghai to Beijing ,and r 3 [ capital ]from Tokyo to Beijing , which requires two changes. One may verify that this is a repair with the minimum cost of two up-r [ country ]. Worse still, they mess up the correct value in r 3 [ capital ]. 3.2 User Guidance It is known that heuristic based solutions might introduce data errors [22]. In order to ensure that a repair is dependable, users are involved in the process of data repairing [22,29,31].

Consider a recent work [24] that uses edi ting rules and mast er data. Figure 3 shows a master data D m of schema Cap ( country , capital ), which is considered to be correct. An editing rule eR 1 defined on two relations ( Travel , Cap )is: eR 1 :(( country , country ) and it matches s [ country ]froma Cap table, we can update r [ capital ]withthe for the other tuples. 3.3 Value Confidence Instead of interacting with users to e nsure the correctness of some values or to rectify some data, some work employs pre-computed or placed confidence values to guide a repairing process [8, 13, 23]. The intuition is that the values with high confidence values should not be changed, and the values with low confidence values are mostly probably to be wrong and thus should be changed. These information about confidence values will be taken into consideration by modifying algorithms e.g., those in Section 3.1. 3.4 Fixing Rules There are two data repairing algorithms using fixing rules that are introduced in Section 2. Readers can find the details of these algorithms in [30]. In this paper, we will give an example about how they work.
 Example 6. Consider Travel data D in Fig. 1, rules  X  1 , X  2 in Fig 2, and the following two rules.  X   X  : (([ capital , conf ] , [ Beijing, ICDE ]) , ( city , { Hongkong } )  X  Shanghai Rule  X  3 states that: for t in relation Travel ,ifthe conf is ICDE ,heldat city Tokyo and capital Tokyo , but the country is China ,its country should be updated to Japan .

Rule  X  4 states that: for t in relation Travel ,ifthe conf is ICDE ,heldat some country whose capital is Beijing , but the city is Hongkong ,its city should be Shanghai . This holds since ICDE was held in China only once at 2009 ,in Shanghai but never in Hongkong .

Before giving a running example, we shall pause and introduce some indices, which is important to understand the algorithm.
 Inverted Lists . Each inverted list is a mapping from a key toaset  X  of fixing rules. Each key is a pair ( A,a )where A is an attribute and a is a constant value. Each fixing rule  X  in the set  X  satisfies A  X  X  X  and t p [ A ]= a .
For example, an inverted list w.r.t.  X  1 in Example 4 is as:
Intuitively, when the country of some tuple is China , this inverted list will help to identify that  X  1 might be applicable.
 Hash Counters . It uses a hash map to maintain a counter for each rule. More the number of attributes that a tuple agrees with t p [ X  X  ].

For example, consider  X  1 in Example 4 and r 2 in Fig. 1. We have c (  X  1 )=1 Canada but t p 1 [ country ]= China .

Given the four fixing rules  X  1  X   X  4 , the corresponding inverted lists are given are built similarly.

Now we show how the algorithm works over tuples r 1 to r 4 ,whichisalso depicted in Fig. 4. Here, we highlight th ese tuples in two colors, where the green tuples containing errors ( i.e., r 2 , r 3 and r 4 ). r not in the negative patterns { Shanghai, Hongkong } of  X  1 . Also, no other rules can be applied. It terminates with tuple r 1 unchanged. Actually, r 1 is a clean tuple. r : It initializes and finds that  X  1 might be applied. In the first iteration, rule  X  1 is applied to r 2 and updates r 2 [ capital ]to Beijing . Consequently, it uses inverted lists to increase the counter of  X  4 and finds that  X  4 might be used. In terminates since no other rules can be applied. r : It initializes and finds that  X  3 might be applied. In the first iteration, rule  X  3 is applied and updates r 3 [ coutry ]to Japan . It then terminates, since no more applicable rules. r : It initializes and finds that  X  2 might be applied. In the first iteration, rule  X  2 is applied and updates r 4 [ capital ]to Ottawa . It will then terminate.
At this point, we see that all the fours errors shown in Fig. 1 have been corrected, as highlighted in Fig. 4. to (semi-)automate error d etection and correction w.r.t. asetof heterogeneous and ad-hoc quality rules. In particular, ther e is no commodity platform simi-lar to general purpose DBMSs that can be easily customized and deployed to solve application-specific data quality problems. Although there exist more ex-pressive logical forms ( e.g., first-order logic) to cover a large group of quality rules, e.g., CFDs , MDs or denial constraints, the main problem for designing an alternative ways about how to repair data errors. Most of these existing rules only have static semantics , i.e., what data is erroneous.

Emerging data quality applications place the following challenges in building a commodity data cleaning system.
 Heterogeneity: Business and dependency theory based quality rules are expressed in a large variety of formats and languages from rigorous expressions ( e.g., functional dependencies), to plain natural language rules enforced by code embedded in the application logic itself (as in many practical scenarios). Such diversified semantics hinders the c reation of one uniform system to accept heterogeneous quality rules and to enforce them on the data within the same framework.
 Interdependency: Data cleaning algorithms are normally designed for one spe-cific type of rules. [23] shows that interacting two types of quality rules ( CFDs and MDs ) may produce higher quality repairs than treating them independently. However, the problem related to the interaction of more diversified types of rules is far from being solved. One promising way to help solve this problem is to pro-vide unified formats to represent not only the static semantics of various rules fix the wrong data).
 Deployment and Extensibility: Although many algorithms and techniques have been proposed for data cleaning [8,23,31], it is difficult to download one of them and run it on the data at hand without tedious customization. Adding to this difficulty is when users define new types of quality rules, or want to extend an existing system with their own impl ementation of cleaning solutions. Metadata Management and Data Custodians: Data is not born an orphan. Real customers have little trust in the machines to mess with the data without human consultation. Several attempts have tackled the problem of including humans in the loop ( e.g., [24, 29, 31]). However, they only provide users with information in restrictive formats. In practice, the users need to understand much more meta-information e.g., summarization or samples of data errors, lineage of data changes, and possible data repairs, before they can effectively guide any data cleaning process.

Nadeef 1 is a prototype for an extensible and easy-to-deploy cleaning system that leverages the separability of two main tasks: (1) isolating rule specification that uniformly defines what is wrong and (possibly) how to fix it; and (2) devel-oping a core that holistically applies these routines to handle the detection and cleaning of data errors. 4.1 Architecture Overview Figure 5 depicts of the architecture of Nadeef . It contains three components: (1) the Rule Collector gathers user-specified quality rules; (2) the Core com-ponent uses a rule compiler to compile heterogeneous rules into homogeneous constructs that allow the development of default holistic data cleaning algo-rithms; and (3) the Metadata management and Data quality dashboard modules are concerned with maintaining and querying various metadata for data errors and their possible fixes. The dashboard allows domain experts and users to easily interact with the system.
 Rule Collector. It collects user-specified data quality rules such as ETL rules, CFDs ( FDs ), MDs , deduplication rules, and other customized rules. Core. The core contains three components: rule compiler , violation detection and data repairing . (i) Rule Compiler. This module compiles all heterogeneous rules and manages them in a unified format. (ii) Violation Detection. This module takes the data and the compiled rules as input, and computes a set of data errors. (iii) Data Repairing. This module encapsulates holistic repairing algorithms that take violations as input, and computes a set of data repairs, while (by default) targeting the minimization of some pre-defined cost metric. This module may in-teract with domain experts through the data quality dashboard to achieve higher quality repairs.

For more details of Nadeef , please refer to the work [14]. 4.2 Entity Resolution Extension Entity resolution (ER), the process of identifying and eventually merging records that refer to the same real-world entities, is an important and long-standing problem. Nadeef/Er [16] was an extension of Nadeef as a generic and in-teractive entity resolution system, which is built as an extension over Nadeef . Nadeef/Er provides a rich programming interface for manipulating entities, which allows generic, efficient and extensible ER. Nadeef/Er offers the fol-lowing features: (1) Easy specification  X  Users can easily define ER rules with a browser-based specification, which will then be automatically transformed to various functions, treated as black-boxes by Nadeef ;(2) Generality and extensi-bility  X  Users can customize their ER rules by refining and fine-tuning the above functions to achieve both effective and efficient ER solutions; (3) Interactivity  X  Nadeef/Er [16] extends the existing Nadeef [15] dashboard with summariza-tion and clustering techniques to facilitate understanding problems faced by the ER process as well as to allow users to influence resolution decisions. 4.3 High-Volume Data In order to be scalable, Nadeef has native support for three databases, Post-greSQL, mySQL, and DerbyDB. However, to achieve high performance for high-volume data, a single machine is not enough. To this purpose, we have also built Nadeef on top of Spark 2 , which is transparent to end users. In other words, users only need to implement Nadeef programming interfaces in log-ical level. Nadeef will be responsible to translate and execute user provided functions on top of Spark. 4.4 High-Velocity Data In order to deal with high-velocity data, we have also designed new Nadeef interfaces for incremental processing of streaming data. By implementing these new functions, Nadeef can maximally avoid repeated comparison of existing data, hence is able to proces s data in high-velocity. Data cleaning is, in general, a hard pr oblem. There are many issues to be ad-dressed or improved to meet practical needs.
 Tool Selection. Given a database and a wide range of data cleaning tools ( e.g., FD-, DC-or statistical-based methods), the first challenging question is which tool to pick for the given specific task.
 Rule Discovery. Although several discovery algorithms [11,19] have been de-veloped for e.g., CFDs or DCs, rules discovered by automatic algorithms are far from clean themselves. Hence, often tim es, manually selecting/cleaning thou-sands of discovered rules is a must, yet a difficult process.
 Usability. In fact, usability has been identified as an important feature of data management, since it is challenging for humans to interact with machines. This problem is harder when comes to the specific topic of data cleaning, since given detected errors, there is normally no ev idence that which values are correct and which are wrong, even for humans. Hence, more efforts should be put to usability
