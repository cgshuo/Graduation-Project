 SHORT PAPER Gilbert L. Peterson  X  Brent T. McBride Abstract In security-related areas there is concern over novel  X  X ero-day X  attacks that penetrate system defenses and wreak havoc. The best methods for counter-ing these threats are recognizing  X  X onself X  as in an Artificial Immune System or recognizing  X  X elf X  through clustering. For either case, the concern remains that something that appears similar to self could be missed. Given this situation, one could incorrectly assume that a preference for a tighter fit to self over generaliz-ability is important for false positive reduction in this type of learning problem. This article confirms that in anomaly detection as in other forms of classifica-tion a tight fit, although important, does not supersede model generality. This is shown using three systems each with a different geometric bias in the decision space. The first two use spherical and ellipsoid clusters with a k -means algorithm modified to work on the one-class/blind classification problem. The third is based on wrapping the self points with a multidimensional convex hull (polytope) al-gorithm capable of learning disjunctive concepts via a thresholding constant. All three of these algorithms are tested using the Voting dataset from the UCI Ma-chine Learning Repository, the MIT Lincoln Labs intrusion detection dataset, and the lossy-compressed steganalysis domain.
 Keywords Clustering  X  Anomaly detection  X  Convex polytope  X  Ellipsoid 1 Introduction Many popular data classification methods are not blind, indicating that for deci-sions with two or more classifications the training set must consist of instances of each classification. If they are tested against an unfamiliar class instance, the learned hypothesis is unable to reliably distinguish the foreign instance from the classes of the training set. A blind classification method, often handled through clustering, recognizes that a foreign instance is not a member of any of its training classes and identifies it as an anomaly given a learned model from a single class X  data. This kind of anomaly detection is useful when there is incomplete domain knowledge available for training, or when we hope to block anomalies that have never been seen previously.
 work traffic, we compare the benefits of the casting of the search problem as a gen-eralization of the normal data and whether generalization reduces anomaly detec-tion accuracy and if there should be a preference toward fitting the normal  X  X elf X  data more closely. Here, generalization, as defined by Mitchell [ 39 ], is the process that takes a large number of samples and creates a hypothesis (inductive bias) that retains the important features of each class. Figure 1 shows the results of applying the modified k -means sphere, ellipse, and the convex polytope algorithms to each class separately for a simple two-class problem. As can be seen from this example, the generalizability of the model decreases as the model improves its tightness to the data points, apparently by the amount of attribute space each shape covers. At the same time as the model fits self tighter, there is less overlap with the other classes and fewer false positives. Given a domain in which the attackers attempt to craft an attack that appears as close to normal (self) as possible, a blind learn-ing approach which fits the model closely could be seen as important. Although a tight fit is important for anomaly detection, the reduction in generality results in an adverse effect in which the percentage of false alarms increases.
 approximation [ 46 ], explanation-based learning [ 10 , 40 ], and classification [ 4 , 5 ], but has previously not been explored for anomaly detection. This paper presents an empirical comparison of three geometric constructs, spherical, elliptical, and hy-perconvex polytope representations, each with decreasing bias and generalizabil-ity for anomaly detection on several problems demonstrating that some generality is required for best performance. Results show that the elliptical bias performs best due to its capability of accurately estimating a convex polytope [ 38 ] while retaining the best performance due to its simpler bias. These results are important because only by learning the best model of normal are we going to be able to detect and prevent previously unseen security attacks. 2 Related work The application of anomaly detection as a classification technique has become widespread as the number of application areas increases. Anomaly detection has been most valuable in security domains such as Intrusion Detection Systems (IDS) UNIX process list [ 25 , 30 ], and for detecting novel steganography in JPEG images [ 37 ]. Beyond anomaly detection X  X  application in security domains, it has also been applied to the domains of hyperspectral imagery [ 8 ], and prognostics and health management of embedded hardware systems [ 7 ].
 as extensive. Two of the most popular algorithms are the single class support vector machine in which a kernel function is used to separate the normal sam-ples from the spatial origin [ 18 , 19 , 31 ], and k -means [ 18 , 36 , 37 , 44 ], or mix-ture models [ 18 ], which make use of a geometric representation or distribution to classify normal around the model means. Other learning algorithms applied to an anomaly detection problem have consisted of self-organizing maps [ 7 ], k -Nearest Neighbor [ 31 ], Artificial Immune Systems [ 12 , 25 ], and Hidden Markov Models [ 9 , 30 ].
 damental research issues. Similar to other machine learning problems, one of the fundamental research issues concerns the data set. The data set must consist of a representative sampling from the decision, and each item must be represented by an applicable set of features in order to learn a good model for classification [ 16 ]. two very difficult problems that must be addressed. The first of these is the of-ten used assumption that for training, the normal data is clean and contains no anomalies [ 12 , 19 , 37 ]. This is an assumption that for real-world domains, such as intrusion detection systems may not be achievable, and instead requires that the anomaly detection system attempt to statistically separate the anomalies from noise in the normal network traffic [ 17 , 18 ]. normal and abnormal data samples in most datasets. For example, in the week 2 Lincoln Labs IDS data set, only 1.06% of the samples are anomalous [ 28 ]. The re-sult of this imbalance is that often algorithms will either not identify the anomalies because the overall accuracy of classifying all data as clean is often higher than systems which have even a small percentage of false positives mixed with missed detections. Because of this, in addition to trying to increase anomaly detection algorithm accuracy, much of the anomaly detection research focuses on finding a balance between reducing the number of false positives while increasing the num-ber of detections [ 12 , 14 , 18 , 31 , 44 ]. Another effect of the data skew concerns balancing the costs associated with incorrect classifications [ 15 ]. For example, does falsely labeling a normal object as an anomaly have the same operational costs as missing a true anomaly.
 tures. Many anomaly detection systems are faced with an abundance of possi-ble attributes and make use of statistical features in order to reduce the scale ability of the algorithms to scale to ever larger datasets, or draw inferences from the data on their own, often the feature development becomes more promi-nent than the learning algorithm, as techniques to detect specific anomalies are created [ 1 , 19 , 21 ].
 ments, whether it be represented as concept drift [ 47 ], or lifelong learning [ 45 ]. For example, if an anomaly detection algorithm were to function as a biometric security system based on a users X  typing rhythm and the user were to come back a day later having injured their hand and disrupted their own typing rhythm is this an anomaly or is this just a change in the rhythm that the anomaly detection system must track. Because the system must separate the noise from the actual concept drift, this is most often handled through some form of feedback [ 13 ]. 3 The blind classifiers This section discusses the geometric biases used in each of the blind classifiers. The three geometric biases are convex polytopes, hyperspheres, and hyperellip-soids. 3.1 Convex polytope Central to the first geometric classifier algorithm is the concept of a polytope. A d-polytope is a closed geometric construct bounded by the intersection of a finite set of hyperplanes, or halfspaces, in d dimensions [ 11 ]. As the number of dimensions rises, the polytope structure becomes increasingly complex and unintuitive. lies either within the polytope or on its boundary. A convex hull of a set of points S in d dimensions is the smallest convex d -polytope that encloses S [ 42 ]. Each vertex of this enclosing polytope is a point in S (Fig. 2 ). The qhull program [ 3 ], version 2002.1, is used with this convex polytope classifier which has a worst time complexity of O( n d / 2 )for n input points in d -space [ 2 ].
 for a particular class C to a set T of d -vectors. A test point p is declared to be amemberofclass C iff it is bounded by the polytope defined by computing the convex hull of T . This is determinable by computing the convex hull of T unioned with p . If the new polytope is the same as the previous then p matches the model and is part of class C .
 than contiguous exists. To compensate for disjunctions and lessen the impact of statistical outliers, a tolerance feature controlled by parameter 0  X   X   X  1 is added. The samples are partitioned into unconnected sets where the distance squared be-tween the two closest samples of each set is greater than  X  2 d ( MAX i  X  MIN i ) 2 where MAX and MIN are the largest and smallest values for each attribute dimen-sion ( i ).
  X  values that produce unique partitionings of the data. This method works by sort-ing the upper-triangular distance-squared matrix for all instances of the training class. Each of these squared distances are then mapped to distinct  X  2 values. This set of values, B , then represents the significant  X  values as only they may yield distinct polytopes [ 37 ].
 around training data of the three algorithms. However, its exponential-in-d time complexity limits its feasibility to classification problems containing a relatively small number of attributes. 3.2 k -means with hyperspheres The k -means algorithm assigns points to clusters by attempting to minimize the sum of squared within-group errors [ 34 ]. The algorithm performs iterations re-assigning points to different clusters and adjusting the centroids until it can no longer reduce the sum of squared within-group errors by further shuffling. Selec-tion of the number of means k can be done via the Bayesian Information Criterion ( x -means) [ 43 ], Gaussian means ( G -means) [ 24 ], or experimentation, as is done here in the interest of achieving the best results. The time complexity of the k -means algorithm is O( knr )for k clusters, n points, and r iterations [ 48 ]. of the k hyperspheres in class model S . The radius of each hypersphere is given by the distance between the corresponding centroid and the most distant point in its cluster. Point p is bounded by a hypersphere with center point c and radius r iff dist ( p , c )  X  r . A point is declared a member of class if it is enclosed by any of the k hyperspheres in S .
 obvious advantage the hypersphere model has over a convex polytope is that its time complexity is linear, not exponential, in d . However, because of the sphere X  X  greater bias, the algorithm does not fit the normal samples as closely and has a greater chance for classifying false positives. Thus, a third classifier is presented that attempts to strike a balance between these two paradigms and leverage their relative strengths (i.e., the tighter fit of a convex polytope and the computational feasibility of a hypersphere). 3.3 k -means with hyperellipsoids A hyperellipsoid, as observed by Nguyen et al. [41], can be used to approximate a convex polytope. Hyperellipsoids have been used to classify high-dimensional data in previous work. Specifically, Melnik [38] makes use of a special kind of el-lipsoid, the Minimum Volume Ellipsoid (MVE), in which the size of the ellipsoid, s , is equal to the dimensionality of the space and the shape of the ellipsoid,  X  1 ,is a scatter matrix of points. This research differs from the MVE ellipsoid definition in that  X  1 is instead an inverse covariance matrix of points, which relates to the scatter matrix via a calculation of the mean and covariances and for the number of samples in the datasets requires far less space. Additionally, our methodology differs in that instead of the ellipsoid representing the entire decision space, mut-liple ellipses represent the decision space and better represent the training sample topology.
 ing set T of class C into k clusters using the k -means algorithm. Each cluster ellipsoid is defined by ( x  X   X ) T  X  1 ( x  X   X ) = s where s specifies the ellipsoid size,  X  specifies the center point as a vector in the attribute space, the ellipse shape, and x is a d -vector representing a point on the border (locus) of the ellip-soid. At this stage,  X  1 and  X  are computed, but s is still an unknown quantity. The size of each cluster ellipsoid must be chosen carefully, as it affects the fit and generality of the resulting class model.
 the minimum s for each cluster point as x ,where s = L | L | defines the smallest ellipsoid size that encloses all cluster points. If the cluster contains extreme points (statistical outliers), then using L | L | as the s value results in an ellipsoid that en-closes too much of the attribute space and that has a high probability of declaring false-positive matches. Therefore, a tolerance parameter, 0  X   X   X  1, is applied to allow the user to tweak the size of the hyperellipsoid.
 upper-tenth percentile of cluster points (the 10% that create the largest s values) are not enclosed by the hyperellipsoid, which prevents the most extreme points from affecting the size of the hyperellipsoid model. To purge their influence from the ellipsoid shape and location parameters as well,  X  1 and  X  must be recom-puted for the cluster subset containing only the bottom  X  -percentile of points. Then, L is recomputed for the new hyperellipsoid parameters and the remaining cluster points. Now that the effects of the discarded points are completely purged, the final cluster s value is set to L | L | .
 member of class C iff ( p  X   X ) T  X  1 ( p  X   X )  X  s for any of the k ellipsoids of C . The time complexity of testing a point for inclusion in the k clusters of C takes O( k [ d 2 + d ] )  X  O( kd 2 ) time, while creating the k ellipsoid models has a time complexity of O( kn 2 d 2 ).
 are determined experimentally for each test domain. Where increases in k and de-creases in  X  coincide with a decrease in generality in the interest of increased prob-ability of detection and vice versa for a decrease in probability of false alarms. It is possible that the approach could be automated to make use of G -means method-ology [ 43 ] for determining k where a Gaussian mean for each dimension is deter-mined based on the covariance matrix.
 domains. However, this research focuses mostly on evaluating anomaly classifica-tion. The next section describes the testing regimen used for evaluating these three techniques and demonstrating the importance of the tradeoff between a tight fit to normal with generality. 4 Testing methodology and results The convex polytope, hypersphere, and hyperellipsoid are tested against the Vot-ing dataset from the UCI Machine Learning Repository [ 6 ] to evaluate their strengths and weaknesses. The classifiers are then tested on the MIT Lincoln Laboratories Intrusion Detection dataset and the lossy-compression steganalysis domain to show performance on realistic anomaly detection problems.
 are used to create the class model. Next, the model is tested against the remaining 10% of the class instances plus a randomly-selected 10% sampling of the other class(es). This random model creation and test process is repeated 10 times for each class. The means and standard deviations for the Probability of Detection ( P
D ) of the anomalous class(es) and the Probability of False Alarms ( P F )onthe normal class are collected. These statistics are of interest as they demonstrate both how well each technique identifies anomalies as well as the percentage of normal samples misclassified.
 0.05. For the hypersphere and hyperellipsoid k -means variants, k is tested at 1 X 5 in steps of 1, and 5 X 100 in steps of 5, with  X  set to 0.9, 0.95, and 1.0. Because of the use of  X  to make the spherical and elliptical models fit normal as closely as possible, the choice was made to not use a k prediction method [ 24 , 43 ]. The interactions of these variables are shown with respect to the Voting database in the following subsection. 4.1 Voting database The Voting database contains the voting records of members of the 1984 U.S. House of Representatives on 16 key votes. Each instance in the database represents an individual member of Congress who belongs to one of two classes: Democrat or Republican. The database includes 267 Democrat and 168 Republican instances. The instance attributes are the choice of each Congress member X  X  16 votes. Each attribute has one of three values:  X  X ea, X   X  X ay, X  and  X  X nknown X  arbitrarily mapped to 1,  X  1, and 0, respectively.
 Republican). Due to the dimensional complexity of the convex hull algorithm, the convex polytope classifier trains on only the first seven of the 16 attributes. tection and false alarm probabilities, for the Republican blind model range roughly between 0.45 and 1.0, shown in Fig. 3 . The best  X  for the Democrat model is at about 0.3. At these  X  values, both models exhibit good and stable classification accuracy with low incidence of false positive and false negative matching errors. The Republican model has a P D = 95 . 7% and P F = 24 . 5% at  X  = 0 . 75, versus the Democrat model X  X  P D = 95 . 6% and P F = 9 . 8% at  X  = 0 . 3(Table 1 ). It is also important to note that there are only a few  X  values that modify the clustering of the convex polytope appearing as plateaus in Fig. 3 .
 every value of k , the models exhibit inferior balancing of false positive and false negative errors, shown in Figs. 4 and 5 . The best accuracy for the blind Republican and Democrat models results in a P D = 75 . 2% and P F = 22 . 8at k = 15 and P reflect that the hypersphere model is not sufficiently stable as the k value changes can cause dramatic change in the accuracy.
 are summarized in Table 1 and Figs. 4 and 5 . The best performing models for all  X  values (highlighted in the table) occur at k = 1, which suggests that the attribute space of each class is not disjunctive and is well represented by a single convex shape. The Democrat class appears to have a number of statistical outliers that cause false-positive problems when included in the class model (  X  = 1). When 5% of the most extreme points are discarded (  X  = 0 . 95), performance increases dramatically from 66.3 to 90.8%. It seems there are a few Democrats whose vot-ing records are more typical of Republicans. The Republican model, on the other hand, performs best when no points are discarded (  X  = 1), indicating greater con-sistency within the class. Overall, as seen in Figs. 4 and 5 ,thevalueof k has a large effect on the performance of the hyperellipse where the setting of  X  reduces the false alarms and detection probabilities for smaller values.
 general (hypersphere) and the more specific (convex polytope) classifiers. This underlines the importance of the balancing of the degree of generalization, and is also evident in results from the Iris and Diabetes UCIMLR datasets (?). 4.2 IDS experiment The dataset used in this experiment was obtained from the Lincoln Laboratory of the Massachusetts Institute of Technology [ 23 ]. Although this dataset has been shown to be statistically different from normal traffic [ 35 ], its many uses by the research community allow for comparison with other approaches. For this experi-ment, we used the 1999 dataset, with week 1 (normal traffic) to train our classifiers, and week 2 (normal traffic mixed with attacks) for testing. Abnormal activity in-cludes both internal (misuse) and external (hacking or denial of service) attacks, but not the external use of operating system or application exploits, as shown in Ta b l e 2 .
 tics on the number of bytes per second, number of packets per second, and number of Internet Control Message Protocol (ICMP) packets per s for classification fea-tures. This results in 4800 normal data samples from week 1 for training, and 5202 data samples from week 2 for testing, of which 64 of these represent the attacks from Table 2 . These features were sampled each minute from the raw tcpdump data files. Dasgupta and Gonzalez showed that while none of these features alone reliably detects the five attacks, combining the features was quite effective. They also explored overlapping the time series as a means of detecting temporal pat-terns, with their best results generated using a sliding window of 3 s. Detection and false alarm probabilities were calculated by comparing the classifier output with the Week 2 attack data. Table 3 shows the results of testing the k -means sphere and ellipse classifiers, the convex polytope, and the Artificial Immune Sys-tem (AIS) results [ 12 ]. The table contains the best results found for Probability of False Alarm, and Probability of Detection, for each algorithm with the exception of the AIS which includes the results for 1 and 3 time slices from [ 12 ]. eralizing beyond the strict sampling better fits the training data over the convex polytope. In addition, the results show that the sphere version of k -means per-forms poorly predominantly because it inaccurately covers the training attribute space by also enclosing space including anomalous data points. This continues even as k increases and each cluster decreases in size. The reason the sphere does not perform as well as the other two geometric constructs is that the k -means clas-sifier uses the point furthest from the mean to estimate the size of the hypersphere, resulting in an overgeneralization. This contrasts with the ellipse and convex poly-topes which maintain a closer fit to the training data. These results imply that the convex polytope and the hyperellipse k -means had little trouble fitting the training data, and that their ability to more tightly fit the self-space improves their overall performance for classification based on these three statistical attributes. Addition-ally, this shows that although both models fit the data closely the added generality of the hyperellipse k -means reduces the false positives which is counter to the assumption that one would want the closest fit to the training data for anomaly detection. 4.3 Steganalysis experiment Steganography refers to hiding information in an innocuous place so that it may be transmitted without notice. With digital images, the message is hidden within a cover image. The steganograpy process varies the image X  X  pixels in such a way that the changes are virtually undetectable to the human eye. The cover images that provide the most difficulty for message detection are JPEG images.
 fact that the eye cannot detect subtle changes in an image. In a JPEG image, a message is stored using the least significant bit (LSB) or by manipulating the rounding errors of the quantized discrete cosine transform (DCT) coefficients of each 8  X  8 image block.
 of learning models for normal images, and none have used any type of clustering. Approaches which make use of both self and nonself data have used Fisher X  X  linear discriminant, Support Vector Machines with image quality metrics, and wavelet statistics calculated from the suspect images [ 1 , 19 , 32 , 33 ]. Reference [ 27 ] pro-vides a survey of the metrics available and their utility for steganalysis. fier requires examples from the anomalous class in order to detect the anomaly, but may not have examples in the case of a novel embedding technique. In this case, anomaly detection provides the best means of detecting the novel embed-ding technique, and the blind or one-class learning methodologies applied to this learning problem have consisted of Artificial Immune Systems [ 26 ] and single class Support Vector Machines [ 33 ].
 from a database of 1,100 grayscale images. The best three of the 36 coefficients determined by J -score are extracted from each image. In addition to clean images, the testing set includes steganographic images created with Jsteg, and Outguess with (OutguessS) and without (OutguessNS) statistical correction. For each of these three steganography methods, images are created using 100, 50, 25, and 12.5% of the cover image X  X  embedding capacity. Ten iterations of training and testing are performed, where for each iteration, 18% of the clean image class is randomly selected for training and a random 9% of each class clean and dirty is used for testing. Testing is conducted on one embedding percentage at a time, and the results from the best performing parameter settings are averaged. The best performing parameters are for the convex polytope  X  = 0 . 1, for the hypersphere k = 40, and for the hyperellipse k = 1and  X  = 0 . 85.
 pacities from the steganography testing compared with the results using the same testing domain and an AIS from [ 26 ]. As seen with the IDS problem, the closer fit to self provided by both the convex polytope and ellipse k -means outperforms the more general sphere k -means. However, just as the results in the previous datasets show, striving for the closest fit possible, i.e., the convex polytope, creates a lack of generality, especially on the Jsteg dataset, that is detrimental to the convex polytope over the ellipse k -means. 4.4 Summary of results Of the test results shown, the steganalysis results are the most revealing because the information hiding community specifically strives to make the embedded cover image appear as normal as possible. Additionally, they have had a lot more prac-tice at it than the network attackers as seen in the IDS dataset. The outcome of the steganographer X  X  experience results in an extremely difficult domain in which to perform anomaly detection. classes and attributes in the domain as well as the probability of detection P D and the probability of false alarms P F for each class. The bolded values highlight the model which achieved the best overall accuracy. In the steganalysis domain as in the other datasets, the highest overall accuracy occurs with the hyperellipsoid. The reason for this is that while seeking to fit the normal space, the algorithm retains generality provided by the bias of its geometric representation.
 while the more complex models increase the detection probability. This aligns with the bias complexity of each of the geometric models wherein the bias de-creases from sphere to polytope, the model fits the self space more closely with less generality. For anomaly detection against an adversary attempting to resem-ble normal behavior, a close fit to self-space could be considered advantageous. However, as is shown in Table 4 , rarely does the most general (hypersphere) or most specific model (convex-polytope) outperform the other models. Because the hyperellipse is a good approximation of the convex polytope, it provides the bene-fits of approaching a tight fit of the space while maintaining the advantages of the more general model. 5Conclusion For security anomaly detection domains, a concern prior to fielding a detection system is whether it can be defeated by an attacker manipulating their attack to appear as normal traffic. From an anomaly detection problem view, we have com-pared the benefits of the casting of the search problem as a generalization of the normal data and whether generalization reduces the anomaly detection accuracy and if there should be a preference toward fitting the normal  X  X elf X  data more closely. This has been tested on two security domains, intrusion detection and ste-ganalysis, and additionally on the Voting, Iris, and Diabetes datasets. The results for all of these datasets demonstrate that for anomaly detection, generality is re-quired to reduce the false alarm probability, but one must select a bias that fits self closely to improve the detection probability.
 fication with different geometric biases in the decision space. This paper shows that while the more complex convex polytope provides the tightest fit to self, the hyperellipse provides the best balance between fit and generality, and that both outperform the simplest hypersphere model. The small amount of generality pro-vided by the ellipse results in the hyperellipse k -means outperforming the other methods on 91% of the datasets.
 capability of accurately estimating a convex polytope [ 38 ] while retaining gen-erality due to its simpler bias. This indicates that in learning models of normal the investigator must examine the learning technique being used; ensuring that the normal space closely fits normal and that the technique used does not have an overly complex bias, still providing generality in order to best detect and prevent previously unseen security attacks.
 References Author Biographies
