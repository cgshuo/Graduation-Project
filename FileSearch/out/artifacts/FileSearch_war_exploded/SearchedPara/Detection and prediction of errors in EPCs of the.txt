 1. Introduction
There has been extensive work on formal foundations of conceptual process modeling and respective lan-guages. However, little quantitative research has been reported on the actual use of conceptual modeling in practice [1] . Moreover, literature typically discusses and analyzes languages rather than evaluating enterprise models at a larger scale (i.e., beyond  X  X  X oy examples X  X ). A fundamental problem in this context is that large enterprise models are in general not accessible for research as they represent valuable company knowledge that enterprises do not want to reveal. In particular, this problem affects research on reference models, i.e., models that capture generic design that is meant to be reused as best practice recommendation in future modeling pro-jects. Accordingly, it is so far neither clear how many errors can be expected in real-life business process mod-els; nor is it clear why modelers introduce errors in process models.
One case of a model that is, at least partially, publicly available is the SAP reference model. It has been described in [2,3] and is referred to in many research papers (see e.g. [4 X 8] ). The SAP reference model was meant to be used as a blueprint for roll-out projects of SAP X  X  ERP system. It reflects Version 4.6 of SAP
R/3 which was marketed in 2000. The extensive database of this reference model contains almost 10,000 sub-models, several of them EPC business process models [2,9,3] . Building on recently developed techniques to verify the formal correctness of EPC models as reported in [10] , we aim to acquire knowledge about how many formal modeling errors can be expected in a large repository of process models in practice, assuming that the SAP reference model can be regarded as a representative example. We will map all EPCs in the
SAP reference model onto YAWL models [11] and use the WofYAWL tool [10] as a means to verify their correctness using the relaxed soundness criterion [12,13] . In a relaxed sound process there is a proper execution sequence for every element, but a proper completion is not guaranteed. We have to stress that this analysis yields a lower bound for errors since there are process models that are relaxed sound but not correct against the more restrictive soundness criterion [14] . To be more concise, our analysis covers only formal control flow errors that affect relaxed soundness. Beyond verification of formal correctness, a process model must also be validated to make sure that all real-world scenarios are handled as expected [15] . Since WofYAWL cannot check whether real-world processes are modeled appropriately, validation is not subject of our analysis. As a consequence, it has to be expected that there are more errors than those that we actually identify using the WofYAWL verification approach.

It is a fundamental insight of software engineering that errors should be detected as early as possible in order to minimize development cost (see e.g. [16,17] ). Therefore, it is important to understand why and in which circumstances errors occur. Several research in software engineering was conducted on complexity met-recently be formulated in [23] in the context of business process modeling. Yet, there is no evidence to support it. Even measuring complexity of business processes is still too little understood. We will use the sample of the 604 EPC business process models of the SAP reference model to test whether errors in terms of relaxed sound-ness can be statistically explained by complexity metrics.

The remainder of this article is organized as follows. Section 2 describes the design of our quantitative study. In particular, we discuss the mapping of EPCs from the SAP reference model to YAWL models, the analysis techniques employed by WofYAWL, and the identification of how the models can be corrected. In
Section 3 we focus on the analysis of the EPCs in the SAP reference model. First, we calculate descriptive sta-tistics that allow us to get a comprehensive inventory of errors in the SAP reference model. Secondly, we inves-tigate the hypothesis that more complicated models have more errors. This hypothesis was suggested in [23] , and we analyze it using different complexity measures and by testing whether they are able to explain the var-iance of errors, i.e. how errors are distributed across EPCs with different measures. The results allow us to conclude which complexity metrics are well suited to explain error variance and that the impact of complexity on error probability is significant. Subsequently, we discuss our findings in the light of related research (Sec-tion 4 ) and conclude with a summary of our contribution and its limitations (Section 5 ). 2. Detection of errors in EPCs
In this section, we present the way we evaluated the SAP reference model. In Section 2.1 , we start with an introduction to EPCs by the help of an example that we also use to illustrate the verification. As an input for the different analysis steps, we use the ARIS 1 XML export of the reference model (see Fig. 1 ). In a first step, the EPC to YAWL transformation program generates a YAWL XML file for each EPC in the reference model (see Section 2.2 ). These YAWL models are then analyzed with WofYAWL that produces an XML error report highlighting the design flaws that have been discovered (see Section 2.3 ). Independent from these steps, the Model Analyzer extracts descriptive information such as the number of elements of a certain element type and whether there are cycles for each EPC model. An XML file of these model characteristics is then merged with the output of WofYAWL based on the ID of each EPC, and written to an analysis table in HTML format. Then, this table is imported in the software package SPSS to do the statistical analysis. Additionally,
Section 2.4 reports on how erroneous EPC models can be corrected. 2.1. Introduction to EPCs Event-driven Process Chains (EPCs) are frequently used in large scale modeling projects in practice. In the
SAP reference models, EPCs model the business processes which are supported by the SAP system. Fig. 2 shows the EPC model for  X  X  X ertificate creation X  X  as an example of one of these models. It is taken from the quality management branch of the SAP model and documents when and how a quality management certificate is created by the help of an information system. The EPC contains three different types of elements: functions, events, and connectors.

Function type elements capture activities of a process (rounded boxes). In the EPC there are three functions capturing the  X  X  X ertificate Profile and Profile Assignment X  X ,  X  X  X reation of a Quality Certificate X  X , and  X  X  X dit Recipient of Quality Certificate X  X  activities.

Event type elements describe pre-and post-conditions of functions (as hexagons). Accordingly, the EPC model for  X  X  X ertificate Creation X  X  in Fig. 2 illustrates the temporal and logical dependencies between the three functions by giving their various pre-conditions and post-conditions as events. For example, the  X  X  X er-tificate Profile and Profile Assignment X  X  function results in the event  X  X  X ertificate profile assignment exists X  X  to be true as a post-condition. This event serves as one of the pre-conditions for the  X  X  X dit Recipient of Quality Certificate X  X  to be executed.

Connector types: Furthermore, there are three kinds of connector types including AND, OR, and XOR for the definition of complex routing rules. Connectors have either multiple incoming and one outgoing arc (join connectors) or one incoming and multiple outgoing arcs (split connectors). The informal semantics of an EPC can be described as follows. The AND-split activates all subsequent branches in concurrency. The XOR-split represents a choice among several alternative branches, i.e., precisely one branch is selected.
The OR-split triggers one, two or up to all of the branches, i.e., for each branch a condition is evaluated and depending on the result this branch is taken. In both cases of the XOR-and OR-split, the activation con-ditions are given in events subsequent to the connector. Accordingly, splits after events followed by multiple functions are forbidden with XOR and OR as the activation conditions do not become clear in the model.
The AND-join waits for all incoming branches to complete, after which it propagates control to the sub-sequent EPC element. The XOR-join merges alternative branches. The OR-join synchronizes all active incoming branches. This feature is called non-locality since the state of all transitive predecessor nodes has to be considered (see e.g. [24] ). It poses a major verification challenge since standard Petri nets analysis techniques are not directly applicable. For a formalization of EPC semantics the reader is referred to [24] . 2.2. Transformations of EPCs to YAWL
Several mappings from EPCs to Petri Nets have been proposed in order to verify formal properties, see e.g. [24] for an overview. In this paper, we use a transformation from EPCs to YAWL that has been recently defined in [25] . The advantage is that each EPC element can be directly mapped to a respective YAWL element without changing the behavior (see Fig. 3 ). Furthermore, we can use YAWL verification tools to analyze
EPCs. Even though EPCs and YAWL are very similar in terms of routing elements, there are three differences that have to be considered in the transformation: (1) state representation, (2) connector chains, and (3) multi-ple start and end events.

EPC functions can be mapped to YAWL tasks following mapping rule (a) of Fig. 3 . The first difference between EPCs and YAWL is related to state representation . EPC events can be interpreted as states that define pre-conditions for the start of functions and post-conditions after their completion. Though this definition might suggest a direct mapping of events to YAWL conditions (the YAWL equivalent to places in Petri nets), things are a bit more complicated. In an EPC it is syntactically correct to model one event followed by an
AND-connector that splits control flow to two functions. In YAWL there are actually two conditions required as pre-conditions for the two functions. Accordingly, EPC events are related to states, but there is not a direct one-to-one correspondence between events in EPCs and conditions in YAWL. Therefore, rule (b) in Fig. 3 defines that events are not mapped to YAWL taking advantage of the fact that arcs in YAWL represent impli-cit conditions if they connect two tasks. Please note that this mapping does not have any impact on the routing between different functions. In EPCs connectors are independent elements. Therefore, it is allowed to build so-called connector chains , i.e. paths of two or more consecutive connectors (cf. Fig. 2 ). In YAWL there are no connector chains since splits and joins are part of tasks. The mapping rules (c) X (h) map every connector to a dummy task with the matching join or split condition (see Fig. 3 ). The third difference stems from multiple start and end events . An EPC is allowed to have more than one start event. Multiple end events represent impli-cit termination: the triggering of an end event does not terminate the process as long as there is another path still active. In YAWL there must be exactly one start condition and one end condition. Therefore, the mapping rules (i) and (j) generate an OR split for multiple starts and an OR-join for multiple ends. This implies that any combination of start and end events is considered to be correct even if only a restricted set of combinations is meaningful. By using such an interpretation, this mapping yields a YAWL model that includes all execution paths that can be taken in the EPC. We will exploit this later when using the relaxed soundness criterion. Fig. 4 gives the result of applying the transformation to the  X  X  X ertificate Creation X  X  EPC of the first section. Note that connectors are mapped onto dummy tasks. To identify these tasks they are given a unique label extracted from the internal representation of the EPC, e.g., task  X  X  X nd (c8z0) X  X  corresponds to the AND-split connector following event  X  X  X ustomer requires certificate X  X . 2.3. WofYAWL analysis
After mapping the EPC onto YAWL, we can use the verification tool WofYAWL [10] . WofYAWL inter-nally uses a Petri-net representation 2 of the YAWL model for the analysis and translates the result back to warnings that relate to the elements of the YAWL net. As indicated before, we use a correctness criterion based on relaxed soundness [12,13] . Relaxed soundness is a  X  X  X eaker version X  X  of the classical soundness notion defined for workflow nets [29,30] . Workflow nets are Petri nets with a single source place (i.e., the start of the process) and a single sink place (i.e., the end of the process). A workflow net is sound if any token put into the source place finally results in a token in the sink place. More precise: From any state reachable from this initial state it is possible to reach the desired end state. Note that soundness excludes deadlocks (the process gets stuck and nothing can happen) and livelocks (the process is trapped in a loop it cannot escape from). Clearly soundness is desirable. However, EPCs are frequently used in such a way that the expected behavior is cap-tured, but exceptional situations are not explicitly handled. In such a setting the EPC should be able to ter-minate properly, but it is not necessary to terminate properly in all possible paths. Therefore, we use relaxed soundness since it precisely matches this requirement. In particular, relaxed soundness demands that any transition (i.e., a task or function) is involved in at least one  X  X  X ound execution X  X , i.e., for any transition there should be an execution path moving the process from the initial state (one token in the source place) to the desired final state (one token in the output place) [12,13] .

As a first step of the relaxed soundness analysis, WofYAWL maps a YAWL model onto a Petri net using the mapping defined in [13] . Fig. 5 sketches a small fragment of the Petri net that results from a translation of the YAWL model shown in Fig. 4 . The fragment only considers the dummy tasks resulting from the mapping the arcs connected to these four dummy tasks. Note that when mapping this OR-split onto transitions all pos-sible interpretations are generated (2 3 1 = 7 transitions). Similarly, all other XOR/OR-splits/joins are unfolded.

Using the notion of relaxed soundness we can label elements of the Petri net using  X  X  X appy smileys X  X  and  X  X  X ad smileys X  X . The  X  X  X appy smileys X  X  are used to identify net elements that are involved in so-called  X  X  X ood execution paths X  X , that is, the execution paths in the Petri net that lead from the initial state to the desired final state. Consider for example Fig. 5 . In this Petri net there are two  X  X  X ood execution paths X  X  which join at the XOR-join named  X  X  X or (c8zg) X  X : the first path passed two black transitions at the very top of the model, reaches the OR-join (c8yr), and arrives at the XOR-join (c8zg) via another black transition. The second path passes the transitions at the bottom of the model including the OR-join (c8z9). The  X  X  X ad smileys X  X  visu-alize relevant parts in the Petri net that are not covered by some good execution path: if only the place before the AND has a token, a firing produces one token on each of the output places of the AND. These can be propagated in such a way that the end place receives one of these tokens while the other one is still in the net. If additionally one of the places below or above the AND input place have a token, they can synchronize with the respective tokens at the AND output places. But here as well, the path at the top and the path at the bottom are also not synchronized. Accordingly, there are in any execution path involving the AND two tokens that reach the XOR. As a result, the AND can in no way contribute to reaching the desired final state from the initial state. WofYAWL issues the following warnings for this fragment:  X 
Task  X  X  or (c8yr)  X  X  may not receive control from task  X  X  and (c8z0)  X  X ,  X 
Task  X  X  or (c8z9)  X  X  may not receive control from task  X  X  and (c8z0)  X  X ,  X 
Task  X  X  or (c8yr)  X  X  may be an XOR-join instead of an OR-join ,  X 
Task  X  X  or (c8z9)  X  X  may be an XOR-join instead of an OR-join .
These warnings indicate that there is a problem involving the top four connectors in Fig. 2 . Since the AND-split connector splits the flow into two paths that join with an XOR-join, these two paths cannot be involved in a good execution as indicated by first two warnings. Moreover, if the AND-split connector is not allowed to occur, the two OR-joins could as well be XOR-joins. In Section 2.4 we will show how these diagnostics can be used to repair the problem.
 In the analysis we use transition invariants to avoid constructing large or even infinite state spaces [10] .
However, the mapping shown in Fig. 3 tends to generate very large models. For example, in the SAP refer-ence model there are EPCs with 22 end events. Using the naive translation shown in Fig. 3 this results into 4 million transitions just to capture the final OR-join. Therefore, we have used a more refined mapping which scales much better. Moreover, we have used soundness-preserving reduction rules [27] to further reduce the complexity of the models without losing any information. For additional details on this approach, we refer to [10] . 2.4. Implications of errors
Errors in EPCs can be identified in an automated way using WofYAWL. However, being able to detect problems is not enough. In practice, these problems should be repaired by the process owner. While Wof-
YAWL points to the elements causing the problem, there are often several choices for correcting the errors, and the process owner has to identify the solution that matches the desired behavior. Take for example the EPC of Fig. 2 . In Section 2.3 , we have shown that there were four error messages coming from WofYAWL.
From this, it is rather trivial to conclude that the XOR-join does not match the preceding connectors. To repair this mistake, the process owner should decide whether to change the AND-split into an XOR-split, or to change the XOR-join into an AND-split. The decision cannot be made without explicit domain-knowl-edge of the process under consideration, and might even be different for each implementation of the process.
Furthermore, in this example WofYAWL generated a message suggesting that an OR-connector could be changed to an XOR. If such a message is generated for a connector in isolation (i.e. there are no other messages regarding the same connector), then this connector can indeed be changed without disturbing the model. However, if other messages relate to the same connector (which is the case in our example) special care has to be taken. In the  X  X  X ertificate Creation X  X  model for example, the connectors can only be changed to an
XOR-join under the assumption that the event  X  X  X ustomer requires certificate X  X  cannot occur. Since this is not a valid assumption, we propose to repair the EPC as shown in Fig. 6 . Fig. 7 shows another example of an error found by WofYAWL. The EPC is taken from the treasury branch of the SAP reference model. In this model there are basically two choices to cure the problem: either make the OR-split an XOR, or make the XOR-join an OR. WofYAWL proposes the first option, and now, since no other message relates to the mismatch con-nectors, it is safe to follow this proposal. 3. Prediction of errors in the SAP reference model
Using the approach depicted in Fig. 1 we analyze the SAP reference model. First of all, we locate the parts of the reference model where errors occur most frequently (Section 3.1 ). Second, in Section 3.2 , we formulate hypotheses relating correctness to properties of the EPC (e.g., larger models are more likely to contain errors).
Finally, we test these hypotheses using logistic regression (Section 3.3 ). 3.1. Descriptive statistics
The sample of the SAP reference model that was available for this research is organized in two orthogonal dimensions: hierarchy levels and branches. Table 1 illustrates that five levels of abstraction are used to arrange the models. Each model at a lower level is a sub-model of a model on a higher level. On the top level there is one model which serves as the root for the model hierarchy. Most of the 9844 models are of model type extended EPC ( X  X  X EPC X  X ), but only a fraction of them represent proper EPCs with at least one start event and one function. There are 604 of such process models as listed in the column  X  X  X PC X  X . These EPCs have been the starting point of our analysis. Using the transformations and the WofYAWL tool described in Section 2 , we discovered that at least 34 models have errors (5.6% of 604 analyzed EPCs).

Table 2 summarizes the SAP reference model subdivided into its 29 branches. It can be seen that the num-ber of EPC models varies substantially (from none in Position Management to 76 in Sales and Distribution).
Furthermore, the EPCs are of different size indicated by the mean number of events, functions, connectors, and  X  X  X rror X  X  for how many models WofYAWL reports an error. It is interesting to note that branches with more than 10% of faulty models tend to be larger. For example, refer to the Real Estate Management branch: 16.7% of the EPCs have errors and the mean number of events (12.7) per EPC is higher than the overall mean number of events (11.5). Similar observations can be made for functions (6.5 X 4.0), connectors (7.3 X 5.2), and arcs (27.0 X 20.8). In the following subsection, we test whether such characteristics of an EPC can be used to predict errors.
 3.2. Hypotheses and related error determinants
Determinants of errors in EPCs can be related to several aspects. In this subsection we discuss model size, model complexity, and typical error patterns. 3.2.1. Model size
The size of the model can be considered as a potential error determinant if the model is produced by a human modeler. Simon [31] points to the limited cognitive capabilities and concludes that humans act only rational to a limited extent. In the context of modeling, this argument would imply that human modelers lose track of all interrelations of a large model due to their limited cognitive capabilities, and then introduce errors that they would not insert in a small model. Accordingly, we define the following hypotheses:  X  S 1 : A higher number of events E increases the error probability.  X  S 2 : A higher number of functions F increases the error probability.  X  S 3 : A higher number of connectors C increases the error probability.  X  S 4 : A higher number of arcs A increases the error probability. 3.2.2. Model complexity
Recent work by Cardoso [23] discusses complexity as an error source. Similar to large models, the modeler is expected to introduce errors more likely in complex models due to limited cognitive capabilities. Yet, com-plexity may differ from size, e.g., a large sequence may be less demanding for a modeler than small model con-taining several joins and splits. In EPCs complexity is introduced by connectors . This supports S two EPCs can have the same number of connectors, but differ in complexity if the second model introduces additional arcs between the connectors. Therefore, S 4 is also backed up from a complexity point of view.
Cycles represent an additional aspect of complexity. Arbitrary cycles can lead to EPC models without clear semantics as shown in [24] . Cardoso introduces a complexity metric based on the observation that the three split connector types introduce a different degree of complexity. According to the number of potential post-states an AND-split is weighted with 1 , an XOR-split with the number of successors n , and an OR-split with 2 n 1. We refer to the sum of all connector weights of an EPC as split-complexity SC (called control-flow complexity CFC in [23] ). Analogously, we define the join-complexity JC as the sum of weighted join connec-tors based on the number of potential pre-states. Furthermore, we assume that a mismatch between potential post-states of splits and pre-states of joins can be modeled with the split X  X oin-ratio JSR = JC/SC. Based on this we formulate the following hypotheses:  X  C 1 : EPCs with cycles have a higher error probability than EPCs without.  X  C 2 : A higher SC value of an EPC increases the error probability.  X  C 3 : A higher JC value of an EPC increases the error probability.  X  C 4 : A JSR value different from one increases the error probability. 3.2.3. Error patterns
In contrast to hypotheses on complexity, error pattern point to structural properties of the model that may be the reason for problems. EPCs lack an explicit notion for the initial state, i.e. it is not clear in which com-bination of start events are allowed. This is reflected by the initial OR-split when translating an EPC to
YAWL that covers all possible combinations. Clearly, this may be the source of misinterpretations by the modeler, and therefore the number of start events may influence the likelihood of errors being introduced.
A similar observation may be made for the number of end events. A well-known source of errors are the so-called PT-and TP-handles in Petri nets [32] . A PT-handles starts with a place with multiple outgoing arcs joining later in a single transition. In terms of EPCs this means that an XOR-split connector corresponds to an AND-join connector. Clearly, this may indicate a deadlock problem: the process gets stuck just before AND-join. Similarly, an OR-split connector corresponding to an AND-join connector may be problematic.
TP-handles are the reverse of PT-handles and start with a transition (AND-split) where outgoing arcs come together in a place (XOR-join). In terms of EPCs this corresponds to an AND-split or OR-split connector with a matching XOR-join connector. This establishes the following hypotheses:  X  EP 1 : A higher number of start events increases the error probability.  X  EP 2 : A higher number of end events increases the error probability.  X  EP 3 : A higher number of XOR/OR-splits and AND-joins in an EPC increases the error probability.  X  EP 4 : A higher number of AND/OR-splits and XOR-joins in an EPC increases the error probability.
Please note that EP 3 and EP 4 only indicate the possibility of a mismatch: if the numbers of splits and joins of the same type are high but equivalent, it could be that there is no mismatch. Still considering potential com-binations of a high number of connectors implies several ways to introduce a mismatch. Table 3 summarizes the input variables that we will investigate. The table also shows how these variables can be linked to the dis-cussed hypotheses. 3.3. Testing of error determinants 2We now utilize the analysis table of the SAP reference model (cf. Fig. 1 ) to test the significance of our hypotheses. The potential determinants listed in Table 3 serve as input variables to explain the variance of the dependent variable  X  X  X asError X  X . As the dependent variable is binary, we use a logistic regression (logit) model. The idea of a logit model is to model the probability of a binary event by its odds, i.e., the ratio of event probability divided by non-event probability. These odds are defined as logit  X  p b  X  b 1 x 1 ; i  X  X  b k x k ; i for k input variables and i observations, i.e. EPC i in our context. From this follows that
The relationship between input and dependent variables is represented by an S-shaped curve of the logistic function that converges to 0 for 1 and to 1 for 1 (see Fig. 8 ). The cut value of 0.5 defines whether event or non-event is predicted. Exp( b k ) gives the multiplicative change of the odds if the input variable b creased by one unit, i.e. Exp( b k ) &gt; 1 increases and Exp( b
The significance of the overall model is assessed by the help of two statistics. Firstly, the Hosmer and Lem-eshow Test should be greater than 5% to indicate a good fit based on the difference between observed and pre-dicted frequencies (cf. [33] ). Secondly, Nagelkerke X  X  R 2 determination indicating which fraction of the variability is explained [34] . Furthermore, each estimated coef-nificance should be less than 5%. We calculate the logistic regression model based on a stepwise introduction of those variables that provide the greatest increase in likelihood. For more details on logistic regression, see [33] .

Our analysis was done in two steps. In the first step we analyzed the individual variables (univariate anal-ysis) while in the second step we looked a combinations of variables (multivariate analysis).

As a first step we calculated univariate logit models for each of the 15 input variables. Each model for the 11 variables that indicate the number to elements of a specific type in the EPC had a Wald statistic at a signif-icance level of 0.6% or better. The binary variable for cycles showed a significance of 10.6% in the Wald test which is not as good as the frequently used 5% significance level. The three complexity metrics all had a very poor Wald value with a significance between 70.8% and 78.1%. Accordingly, the null hypothesis that they have no impact on the odds of an error cannot be rejected. So based on the univariate logit models we can conclude that the various metrics related to the size of the model seem to be the best predictors for errors.
In a second step we tested multivariate logit models combining all input variables. Table 4 summarizes the results of this analysis. We started with all 15 variables yielding the results given in the  X  X  X omplete Model X  X  column. Together they are able to predict 95.2% correctly, i.e., without looking at the model and just observ-ing the input variables, we can accurately predict whether a model has errors or not in 95.2% percent of the cases. Table 4 also shows the number of correctly predicted errors and the number of incorrectly predicted errors, e.g., using the  X  X  X omplete Model X  X  three of the 604 models were predicted to have errors but did not have any. Table 4 shows that in the  X  X  X omplete Model X  X  the number of OR-joins is significant (Wald sig. is 0.3%) and has a considerable impact (Exp( B ) is 2.209). As SC and JC were both estimated to be 1 (having no impact on the odds), we reduced the model to 13 variables. The result is given in column  X  X  X ithout SC and JC X  X . The other two columns list the model with the maximum number of variables that all have Wald sig. better than 11% ( X  X 8-Step Model X  X ) and better than 5% ( X  X 5-Step Model X  X ), respectively. The columns show that the estimated coefficients have a stable tendency and a relatively stable value. All Hosmer and Lemeshow and Nagelkerke R 2 values indicate good fit of the statistical model to the data. The 8-Step model yields a pre-diction of 0.143 for our  X  X  X ertificate Creation X  X  EPC from the running example. This is below the 0.5 cut-off value and leads to an incorrect prediction of the model having no errors. The model with the highest predic-tion value (0.945) is a large EPC with 122 arcs, 24 connectors, 40 events, and 43 functions. This model includes errors which is correctly predicted.

The different multivariate logit models suggest the following conclusions. First, the complexity metrics pro-posed by [23] seem to have no impact on the odds of an error at all. The Wald test has both a bad significance and also predicts coefficients very close to zero. An explanation could be that OR-connectors get a weight that depends exponentially on the connector cardinality. Consider the example of an AND-split-join block with five parallel threads. Both SC and JC would result in a complexity metric of 1. Changing the connector types from AND to OR changes both metrics to 32. This great change in the metric based on state complexity obvi-ously does not reflect the perceived conceptual complexity by the modeler. As the modeler is the one who introduces errors, these metrics seem to be misleading when used for the prediction of errors. Furthermore, the fact that a model includes cycles is not significant in the Wald statistic. Moreover, the number of arcs does not seem to have a huge impact on the odds, may be because size is also captured by the number of other model elements and complexity by the number of connectors. The number of start events has a coefficient that reduces the odds. This might be related to the way how start events are used in the SAP reference models.
There are several EPC models with lots of start events that are directly joined for representing alternative start triggers. This leads to a very simplistic join structure that is unlikely to produce errors. The coefficient for number of functions is not significantly different from zero with a tendency to a  X  X  X egative X  X  impact on the error probability. In contrast to that, both the number of end and internal events increase error probability, but not very strongly. Furthermore, it is interesting to see that all join connectors tend to have a  X  X  X ositive X  X  impact on the odds of an error. The OR join has the highest coefficient of about 2. On the other hand, all split connectors have a  X  X  X egative X  X  impact. Interestingly, each pair of connectors has coefficients that have almost the same impact, but in a different direction. As an example, consider the coefficients for OR connectors of the 8-Step model. Introducing a pair of OR join and split connectors would have an impact on the odds of 0.473 * 2.233 = 1.056. With respect to the error patterns of EP
AND join increases error probability by 0.654 * 1.321 = 0.864 or 0.473
EP 4 the values are above one if we consider the 13-variable model. Since not all coefficients are significant, an interpretation is difficult. Clearly speaking, there is no support for EP constant of about 0.025 indicates that the probability of an error is very small. This is consistent with the observation that you need at least a split and a join connector that do not match in order to introduce an error.

Beyond the significance of each individual coefficient, multivariate logistic regression appears to be a suit-able tool to predict error probability in the SAP reference model. Based on only five coefficients we are able to classify 95% of the EPCs correctly without looking into the model (with a Nagelkerke R
Accordingly, complexity seems to be a major source of error probability, yet not in shape of complexity met-rics but rather related to the number of join connectors in the EPC. 4. Related research
This section discusses the work that is most related for the research areas verification (Section 4.1 )and quantitative analysis in process modeling (Section 4.2 ). 4.1. Verification
Since the mid-1990s, a lot of work has been done on the verification of process models, and in particular workflow models [35 X 39] . Sadiq and Orlowska [40] were among the first to point out that modeling a busi-ness process (or workflow) can lead to problems like livelock and deadlock. In their paper, they present a way to overcome syntactical errors, but they ignore the semantical errors. Nowadays, most work that is conducted is focusing on semantical issues, i.e.,  X  X  X ill the process specified always terminate X  X  and similar questions. The work on verification that has been conducted in the last decade can roughly be put into three categories: (1) verification of formal models, (2) verification of informal models, and (3) verification by design.

In the category verification of formal models we consider the work that has been done on the verification of modeling languages with formal semantics. One of the most prominent examples of such a language are Petri nets [26,27] . Especially in the field of workflow management , Petri nets have proven to be a solid theoretical foundation for the specification of processes. This, however, led to the need of verification techniques, tailored towards Petri nets that represent workflows. In the work of Van der Aalst and many others [29,41,42,12,43,30] , these techniques are used extensively for verification of different classes of workflow def-initions. Verification tools based on these approaches provide an answer in terms of  X  X  X orrect X  X  or  X  X  X ncorrect X  X .
Besides Petri nets also other established formal languages have been used, e.g., process algebras, temporal log-ics and Turing machines. Moreover, some authors proposed the use of dedicated (typically graph based) lan-guages. Examples are the metagraphs in [44] and the logic-based approach in [45,46] .
 However, not all modeling languages have formal semantics, in particular, UML activity diagrams and EPCs. The verification of such informal models can benefit from Petri net analysis techniques by translation.
For EPCs several translations to Petri nets have been proposed, e.g. [13,47,48] . In our approach we utilize a translation to YAWL as reported in [25] . The formalization of EPCs as a state-transition-system is exten-sively discussed in [24] . It is shown that interacting OR-joins can lead to EPCs that do not have formal seman-tics. These EPCs are called unclean. In [49] an approach is presented to efficiently calculate the state space of a clean EPC, thereby providing executable semantics for the EPC.

The last category verification by design is somewhat of an outsider. Instead of verifying a model given in a specific language, it is also possible to define a language in such a way that the result is always correct. An example of such a modeling language is IBM MQSeries Workflow [39] . This language uses a specific structure for modeling, which will always lead to a correct and executable specification. However, modeling processes using this language requires advanced technical skills and the resulting model is usually far from intuitive.
Besides the three categories, there are some verification approaches that are more or less a combination of others. Consider for example the approach presented in [50] , where EPCs are verified using an interactive ver-ification approach. However, instead of generating a subclass of EPCs for which the approach works, the pro-cess designer or process owner is actively involved in the verification process by using his knowledge about the process which is not made explicit in the model. The latter is the reason why this approach could not be used for the automatic verification of the entire SAP reference model since it depends upon the knowledge of the process owners. The approach we use in this article, i.e. the WofYAWL approach, is described in detail in [10] . Again, this approach is somewhat of an outsider. The approach takes a model with a formal semantics (i.e., a
YAWL model) to check relaxed soundness which is a minimum correctness criterion for YAWL models. Still, there might be models that are relaxed sound, but not correct against the more strict soundness criterion.
Nevertheless, it finds errors in the YAWL model that should be corrected. By translating EPCs to YAWL models, we could use this approach. 4.2. Quantitative research on process modeling
In contrast to the rich set of work on formal aspects of process modeling, only little research has been ded-icated to quantitative aspects. In [51] the understandability of join and split representation in EPCs is com-pared to Petri nets from a modeler perspective. According to this study, users seem to understand the EPC notation easier. A recent survey reported in [1] identifies the most popular conceptual modeling languages and tools in Australia. Furthermore, the authors identify a set of motivations why modeling is used in practice and summarize prior quantitative work on observed advantages and disadvantages of modeling. Beyond that, we are not aware of quantitative research that aims at identifying determinants for errors in process models.
There has been some research on complexity metrics for process models motivated by the idea that complexity would increase probability of errors [23] . While the empirical validation of complexity metrics for predicting software errors has been investigated for a while (see e.g. [52,22] ), there is no evidence up to now for business process models.

To summarize this overview of related work, we point out that this article uniquely combines error detec-tion based on formal methods with quantitative analysis of potential error determinants. This way, we have been able to provide a lower bound of 5.6% for the percentage of errors in the SAP reference model and evi-dence that complexity indeed has a significant impact on error probability. 5. Contributions and limitations
In this article, we presented an approach to automatically identify errors in the SAP reference model. This formal analysis builds on a mapping from EPCs to YAWL and the analysis tool WofYAWL. It is one of the few studies using formal methods for quantitative research. We provided an in-depth analysis of errors in the
SAP reference model which yields a lower bound for the number of errors (5.6% of the 604 EPCs). As far as we know, this is the first systematic analysis of the EPCs in the SAP reference model. Our findings demon-strate the need for formal analysis of process models in practice.

Moreover, we used a multivariate logistic regression model to test whether certain model characteristics related to complexity can serve as error determinants. Beyond the significance of each individual coefficient we can conclude that multivariate logistic regression appears to be a suitable tool to predict error proba-bility in the SAP reference model. Based on only five coefficients we were able to classify 95% of the EPCs correctly, i.e., without analyzing the model in detail we can predict the presence of an error quite accurately based on simple criteria. Therefore, complexity seems to be a major source of error probability, yet not in the shape of the complexity metrics defined in [23] but rather related to the number of joins in the EPC.
This is an important finding that motivates further research on the measurement of business process model complexity.
 Yet, our approach still has some limitations. It is a shortcoming for the estimation of a logit model that
WofYAWL finds only those errors that can be related to relaxed soundness, and not those that affect the more strict soundness criterion. Therefore, we need further research on automatic identification of errors. Beyond that, we need to analyze errors in business processes that have been modeled in different languages than EPCs. While the relaxed soundness analysis could be also applied to languages like UML activity diagrams and
BPMN models, the different set of modeling elements might have an impact on the contribution of different elements to error probability. Future research will also have to investigate how those potential determinants that are not significant in the test perform in the context of other business process model samples. Accord-ingly, we aim to reuse this research design for other large enterprise models in order to test whether the coef-ficients are stable. A systematic analysis of more large enterprise models could result in a theory explaining when human modelers are likely to introduce errors in a process model. Such a theory would offer valuable insights for the teaching of process modeling languages in companies and universities making people aware of situations where errors occur more frequently. The 5.6% found in this paper can be considered as a first bench-mark for error probability in business process model collections.
References
