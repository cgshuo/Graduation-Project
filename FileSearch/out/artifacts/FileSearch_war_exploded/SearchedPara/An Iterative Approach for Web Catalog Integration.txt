 Web catalog integration is an emerging problem in current digital content management [1,6,7,8]. For example, a B2C company such as Amazon may want to merge catalogs from several on-line vendors into its catalog to provide customers versatile contents. As noted in [1], catalog integration is more than a classification task because if some implicit source information can be exploited, the integration accuracy can be highly improved. In [1], an enhanced Naive Bayes classifier (NB-AS) is proposed and its im-provements are justified.
 achieves better classification accuracy on average. In [2], a cross-training SVM (SVM-CT) approach is proposed to improve the accuracy by extracting the implicit relation-ships between the source and the destination catalogs. However, SVM-CT outperforms SVM in only nearly half the cases. In additi on, the cross-training process is very time-consuming. In [4], a topic restriction approach is proposed to improve NB and SVM by restricting the classification of any document to a small set of candidate destina-tion categories. A candidate category is decided if more than a predefined number of common documents appear in both source and destination categories. Although this approach can significantly improve the performance of NB, it only slightly improves the performance of SVM. In [5], Zhang and Lee propose a Cluster Shrinkage approach in which the documents of the same category are shrunk into the cluster center. The conducted transductive SVM called CS-TSVM can consistently outperform NB-AS. However, because the shrinking process is applied to all documents, it suffers from tentatively misclassifying a document into an improper destination category. for catalog integration with pseudo releva nce feedback. In SVM-IA, the training set is iteratively expanded with newly integrated items to retrain the SVM classifier. With these adapted hyperplanes, the integration accuracy is thus improved. Since the ex-pended features are classified first, the possibility of misclassification is reduced. Google. We have also compared SVM-IA with SVM and SVM-CT. The results show that SVM-IA outperforms SVM-CT on average, and the performance of SVM-IA is very stable in most cases. In SVM-IA, the flattened source catalog S with a set of m categories S 1 , S 2 , ..., S m is intended to be merged into the flattened destination catalog D with a set of n cat-egories D 1 , D 2 , ..., D n . Since a binary SVM can solve only two-class classification problems, we adopt a  X  X ne-against-all X  strategy to decompose a multi-class problem into a set of binary SVM problems. Positive training data are composed of the feature information extracted from the destination class, and negative training data from other non-destination classes as in [9]. A set of binary SVM classifiers are then trained for the integration process of each destination category. 2.1 Iterative Integration Process Figure 1 shows the catalog integration process of SVM-IA. The set of documents in the destination catalog is parsed first to extract the feature words as the training input of the SVM. In feature extraction, the stopwords are removed and the remaining words are the features for training. The SVM classifier is trained with the positive and negative training examples extracted from the target category and other destination categories. After the training process, a cutting hyperplane is formulated for future classification tasks. When the classification is finished, an integration iteration is completed. adaptation is performed by iteratively adding the newly integrated source documents into the training set. Since these integrated source documents may have implicit infor-mation of the source catalog, the hyperplane can be adapted to have better separation performance. In our study, the well-known linear kernel function was used in the SVM classifier. SVM light [11] was used as our SVM tool. 2.2 Feature Expansion In the integration phase, the feature words of the source documents that have been integrated are incorporated as the implicit catalog inf ormation to re-tr ain the SVM clas-sifiers. There are two thresholds to control the number of expanded feature words. One is the term frequency, the number of term occurrences in the integrated source docu-ments. Another is the document frequency, the number of documents in which the term appears. If two documents belong to the same category in S , they may have strong semantic relationships and are more likely to belong to the same category in D .There-fore, iteratively expanding new features from the source documents will be beneficial for the SVM classifiers to learn the se mantics between feature information and enhance the classifiers in the destination catalog.
 tive examples by iteratively training new items from the source catalog with a maximum margin. After new items are iteratively added into the classifier and retrained, new sup-port vectors are created to adjust the hyperplane. Since the hyperplane is supported by the combination of new source documents, the cutting hyperplane is automatically adjusted by the new support vectors and woul d be beneficial for catalog integration. We have conducted experiments with real-world catalogs from Yahoo! and Google to study the performance of SVM-IA with SVM light . The experimental results show that SVM-IA consistently improves SVM in all cases, and outperforms SVM-CT on aver-age. 3.1 Data Sets Five categories from Yahoo! and Google were extracted in our experiments. Table 1 shows these categories and the number of the extracted documents after ignoring the documents that could not be retrieved and removing the documents with error messages. As in [1,2], the documents appearing in only one category were used as the destination catalog D , and the common documents were used as the source catalog S . The number of distinct common documents is 2870. However, because some documents may appear in more than one category of the same catalog, the number of test documents may slightly vary in Yahoo! and Google. Thus, we measured the accuracy by the following equation.
 In the processing, we used the stopword list in [10] to remove the stopwords. 3.2 Experimental Settings In our experiments, both the cross-training and iterative-adapting techniques were em-ployed on SVM to test how much they can enhance a purely text-based SVM learner. In [2], the label attributes extracted from the D A catalog are considered useful predictors for the D B catalog by adding extra | A | labels. Therefore, in the SVM-CT implemen-tation, a document d  X  D B  X  D A is submitted to the SVM ensemble S ( A, 0) ,which gives a score w c A  X  d + b c A for each class c A  X  A . These scores are inserted into the |
A | columns as label attributes. To convert the scores into the term attributes, ordinary term attributes are scaled by a factor of f ( 0  X  f  X  1 ) and label attributes are scaled by 1  X  f . We followed the origin SVM-CT settings with f =0 . 95 and 1  X  f =0 . 05 .After the transformation of label attributes, every document d  X  D A  X  D B gets a new vector representation with | T | + | A | columns where | T | is the number of term features. Then, these new term vectors are trained as S ( B, 1) to classify the test documents. As the algorithm reported in [2], the cross-tr aining process can be repeated like a ping-pong way. 3.3 Results Table 2 lists the experimental results of integrating Google X  X  pages into Yahoo! X  X  cat-egories. Table 3 lists the experimental results of reversely integrating Yahoo! X  X  pages into Google X  X  categories. As listed in the two tables, we have measured the accu-racy achieved by the following classifiers: SVM, cross-training SVM (SVM-CT), and iterative-adapting SVM (SVM-IA). IA1, IA2, and IA3 separately represent the result by first, second, and third iterations of adding new features from the source catalog and retraining. Similarly, CT1 is the result of fi rst cross-training with the label attributes extracted from the source catalog. The result of CT2 is based on the SVM-CT1 classi-fiers proceeding with the second cross-training, and so is the result of CT3 based on the SVM-CT2 classifiers.
 three iterations. In Table 2, the SVM-IA classifiers not only have sustaining improve-ments but also outperform SVM-CT in most categories. In /Recreation/Outdoors and /Arts/Photography, SVM-CT is even worse than pure SVM and the improvements are very unstable. Although in Table 3 SVM-CT have effective improvements in most cat-egories after CT3, the overall improvements are not stable, and the accuracy in /En-tertainment/Movies Film is even worse than pure SVM. Figure 2 and Figure 3 further indicate that the accuracy of SVM-IA is stably improved, but SVM-CT has unstable accuracy performance. The reason of vastly unstable performance is that a large num-ber of label attributes are altered in the subcategories of /Entertainment/Movies Film in Yahoo! after cross-training process. The same situation also happened in /Recre-ation/Outdoors and /Arts/Photography in Google. These label changes resulted in wrong mappings between the subcategories, and would thus decreased the accuracy. Moreover, we found that the cross-training process was very time-consuming. This makes SVM-CT less feasible for large catalog integration. In this paper, we have studied the effects of iterative-adapting approach to enhance the integration accuracy. We compared our approach with SVM and SVM-CT. The exper-imental results are very promising. It shows that our approach consistently achieves improvements on SVM classifiers and is on average superior to cross-training that has been proposed to improve SVM.
 assumption to the hierarchical catalog model is of the major interest for the catalog integration because hierarchical catalogs are more practical in real cases. Second, how to construct a systematical mechanism combining effective auxiliaries to enhance the power of SVM is a more difficult problem but needs further investigation. To conclude, we believe that the accuracy of catalog integration can be further improved with the assistance of more effective auxiliary information.
 We would like to especially thank S. Godbole for his great help in our SVM-CT imple-mentation.

