 There is much recent work on detecting and tracking change in clusters, often based on the study of the spatiotemporal properties of a cluster. For the many applications where cluster change is relevant, among them customer relation-ship management, fraud detection and marketing, it is also necessary to provide insights about the nature of cluster change: Is a cluster corresponding to a group of customers simply disappearing or are its members migrating to other clusters? Is a new emerging clu ster reflecting a new target group of customers or does it rather consist of existing cus-tomers whose preferences shift? To answer such questions, we propose the framework MONIC for modeling and track-ing of cluster transitions. Our cluster transition model en-compasses changes that involve more than one cluster, thus allowing for insights on cluster change in the whole clus-tering. Our transition tracking mechanism is not based on the topological properties of clusters, which are only avail-able for some types of clustering, but on the contents of the underlying data stream. We present our first results on monitoring cluster transitions over the ACM digital library. Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications  X  Data Mining; I.5.3 [Pattern Recognition]: Clustering General Terms: Algorithms, Theory Keywords: Cluster change detection, cluster transitions, data streams, clusters, temporal analysis
Clusters upon the data of many real applications are af-fected by changes in the underlying population of customer transactions, user activities, network accesses or documents. Much research has been devoted in adapting the clusters to the changed population. Recently, research has expanded to encompass tracing and understanding of the changes them-selves, as means of gaining insights on the population and supporting strategic decisions.
 Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00. location [1]; he considers different types of change, with em-phasis on computing change  X  X elocity X  and finding the loca-tions with the highest velocity. Such methods assume that the trajectory does not change. Thus, they cannot be used if the feature space changes, e.g. in text stream mining, where features are usually frequent words. Further, hierarchical clusterers cannot be coupled with such a method, as they use ultra-metrics, i.e. a dataset defines its own trajectory.
Kalnis et al propose a special type of cluster change, the  X  X oving cluster X , whose contents may change while its den-sity function remains the same during its lifetime [6]. They find moving clusters by tracing common data records be-tween clusters of consecutive timepoints. MONIC is more general, since it encompasses several cluster transition types, allows for the  X  X geing X  of old objects and does not require that the density function of a moving cluster is invariant.
Cluster change detection is also relevant for  X  X opic evolu-tion X  in text streams, as dealt with in [8, 7], where a  X  X opic X  is a cluster label, consisting of the dominant words inside the cluster. In [8], the emphasis is on adapting the clus-ters, while in [7] a topic evolution graph is built and used to trace topic transitions, i.e. changes in the cluster labels rather than the cluster themselves. These methods are ap-plicable whenever a human-understandable cluster label can be extracted and traced. Cluster labeling is not feasible for all applications though. For this reason, MONIC detects cluster transitions rather than cluster label transitions.
MONIC models and traces cluster transitions upon data that are collected and clustered at timepoints t 1 ,...,t n . A  X  X ata ageing X  function may assign lower weights to old records. The feature space may also change. MONIC as-sumes re-clustering rather than cluster adaptation at each timepoint, so that both changes in existing clusters and new clusters can be monitored. Moreover, transitions can be detected even when the underlying feature space changes, i.e. when cluster adaptation is not possible. To do so, we first specify the notion of  X  X ame X  cluster or rather cluster  X  X atch X  across the time axis.
We observe clustering as a partitioning of the dataset into homogeneous groups. We separate the cluster construction algorithm from the data ageing function that specifies the weights of the records processed by the algorithm. Definition 1. A X  X lustering X   X  is a partitioning of dataset D into partitions/clusters X 1 ,...,X k such that (a)  X  u = w : X u  X  X w =  X  ,(b)  X  k u =1 X u = D and (c) some optimization criterion is satisfied, e.g. the members of each cluster are more similar to each other than to other data records.
In MONIC, a cluster transition at a given timepoint is a change experienced by a cluster that has been discovered at an earlier timepoint. Such a transition may concern the content and form of the cluster, i.e. be  X  X nternal X  to it, or it may concern its relationship to the rest of the clustering, i.e. be an  X  X xternal transition X . We define these types of transitions and introduce heuristics that trace them.
The  X  X xternal transitions X  of cluster X  X   X  i with respect to  X  j at t j &gt;t i aredefinedinTable1. Acluster X  X   X  i survives in  X  j if (a) there is a match for it in  X  j subject to  X  and (b) this match does not cover any further cluster of  X  . If the match covers at least one further cluster in  X  i , then X has been absorbed. If no match exists, then a split mayhaveoccurred: Thecontentsof X are in more than one clusters of  X  j . Then, the overlaps must be no less than  X  split (obviously:  X  split &lt; X  ), to prevent degenerate cases. Moreover, all those clusters together must form a match for X . If none of these cases occur, then X has disappeared.
All but the last transitions in Table 1 refer to changes of a given cluster . Emerging clusters are detected after tracing all external transitions for each cluster in  X  i :Theyarethe clusters in  X  j that are not the result of external transitions.
In Fig. 2 we present our transition detector. For the clus-ters in clustering  X  i of t i (  X  i in the Figure), it detects their external transitions on the clustering  X  j  X   X  j of t j &gt;t i .
For each cluster X  X   X  i , the detector performs some ini-tializations and then computes the overlap of X to each cluster of  X  j (line 5). In line 7, the best match for X is se-lected, according to some tie breaking criterion as discussed after Def. 4. So, each cluster in  X  i has at most one survival candidate. If X has none, clusters overlapping with it for more than  X  split are found (lines 10 X 12). If neither exist, then X is marked as disappeared (lines 15 X 16).

Split detection involves building a list of split candidate clusters (line 11), which must form a match for cluster X when taken together (cf. Table 1). The operation of  X  X aking the clusters together X  (line 12) is currently the set union of the records, i.e. without considering their weights. However, weights are still considered in the overlap test performed at line 18. If the test succeeds, cluster X is marked as split (line 20), otherwise it is marked as disappeared (line 22).
The cases of absorption and survival are initially treated together:  X  i clusters and their survival candidates are added to a list of absorptions and survivals (line 24). When all  X  i clusters are processed, this list is completed (line 26). Then, for each  X  j cluster Y , the detector extracts from this list all  X  clusters for which Y is a survival candidate (line 28). If this sublist contains more than one clusters, then these have been absorbed by Y : They are marked as such (lines 30 X 31) and removed from the original list (line 32). Otherwise, the single member of the sublist is a cluster X that has survived as Y (line 35). Again, the original list is updated (line 36). Several improvements of this base algorithm are possible. First, instead of computing the overlap for each pair of clus-ters (line 5), MONIC computes the matrix M of the overlap values and retrieves the appropriate cell Mcell ,whenever the overlap of two clusters is needed. Furthermore, split de-tections (lines 12, 18) can be performed more effectively, if one observes that two clusters in  X  j cannot have common members. Then, the split test can be computed from the become more diffuse. Other statistics can be used instead of the standard deviation, e.g. kurtosis, while a significance test can be applied instead of using a constant  X  .
Location transitions over a static metric space are cluster  X  X ovements X  inside the invariant trajectory. If there is no static metric space, then we define location transitions as shifts in the distribution: Indicator I1 detects shifts of the mean, I2 traces changes in the skewness  X  ().
Intuitively, if most clusters in a clustering survive from one period to the next, then the population is static and the clustering describes it well. If transitions are frequent, then thepopulationisvolatileandtheclusteringcannotdescribe it well. We model the lifetime of clusters and clusterings and use them to gain insights on the evolution of the population.
Definition 5. Let C be a cluster and t i be the first time-point where it emerged (as part of clustering  X  i ). The life-time of C is the number of timepoints, in which C has sur-vived. We define (i) a  X  X trict lifetime X  lifetimeS as the num-ber of consecutive survivals without internal transition, (ii) a  X  X ifetime under internal transitions X  lifetimeI for which all survivals are counted and (iii) a  X  X ifetime with absorptions X  lifetimeA that further counts absorptions of C .

We compute cluster lifetime in a backward fashion: We start with  X  n and set the lifetime of its clusters to 1. At an earlier timepoint t i , the strict lifetime of cluster X is 1 if X did not survive in t i +1 .Ifthereisa Y  X   X  i +1 with X  X  Y , then lifetimeS ( X )= lifetimeS ( Y )+1. If there is a Y  X   X  i +1 with X  X  Y , then the lifetime of X under internal transitions is lifetimeI ( X )= lif etimeI ( Y )+1. If there is a Y  X   X  i +1 with either X  X  Y or X  X   X  Y ,thenthelifetime of X with absorptions is lifetimeA ( X )= lifetimeA ( Y )+1.
The survival of a clustering built at t i is reflected on the number of its clusters that survive or are absorbed at t i +1 : Definition 6. Let  X  i betheclusteringat t i ,i =1 ...n  X  1 . Its  X  X urvival ratio X  is the portion of its clusters that survived (possibly with internal transitions) in  X  i +1 . Its absorption For clustering, we have experimented with Expectation-Maximization [10], with a hierarchical clusterer using single linkage, with CLUTO and with bisecting K-means. Best results were obtained with bisecting K-means for K=10. Document vectorization and clustering were then performed with the DIAsDEM Workbench open source text miner 2 . For data ageing, we used a sliding window of size 2.
We first set  X  split =0 . 1, varied the threshold  X  from 0.45 (rather than 0.50) to 0.7 in steps of 0.05 and counted the clusters with internal or external transitions. For  X  larger than 0.7, there were hardly any cluster survivals, so we omit these values. In Fig. 3(a) we see that the number of sur-viving clusters drops as  X  increases, while there are more disappearing clusters and splits, as shown in Fig. 3(b), (c). For  X  larger than 0.6, the number of splits does not change any more, so it is not shown. All surviving clusters expe-rience changes in size. There are no absorptions, i.e. the passforward ratio is equal to the survival ratio.

Fig. 3(a), (b), (c) show that there are more disappear-ances than splits in early timepoints, while the trend re-verses later. A possible explanation is that there are larger homogeneous cluster chunks at late timepoints. To study thiscloser,wehavefixed  X  =0 . 5andvaried  X  split from 0.1 to 0.35 with a step of 0.05. We see the results in Fig. 4: Splits still occur only for small values of  X  split ,i.e.thereare no large chunks. Indeed, the dominant class  X  X ata Mining X  grows substantially in the recent timepoints but is not ho-mogeneous enough to produce clusters with a long lifetime. We have next studied the persistence of the clusterings. The passforward ratios (cf. Def. 6) are shown in Table 3, using asbolute numbers of clusters for simplicity. The clus-terings at some timepoints have a high passforward ratio, independently of the  X  values. At 2002, the passforward ra-tio is very low, indicating a drastic change in the population of documents after a rather stable period of two years. The nature and origin of this shift are discussed below. Table 3: Passforward ratios for different values of  X 
The population shift detected by MONIC in 2002 called for inspection of the cluster semantics. We have labeled each cluster with its two most frequent words and mapped these labels/ X  X opics X  to the ACM classes; details can be found in [9]. For cluster transition detection, we have set  X  =0 . 5and  X  split =0 . 1 and concentrated on splits, dis-appearances and cluster lifetime with internal transitions (lifetimeI), since there were no strict survivals and no ab-sorptions. On this basis, we have checked whether cluster
Registered under http://sourceforge.net/projects/hypknowsys Figure 4: Cluster transitions for different values of  X  split : (a) Splits and (b) disappearances One of the emerging clusters of 2004 (  X  C 2004 3 ) has again the label  X  X ssociation rules X . (c) The other clusters on data mining have less specific la-bels, such as  X  X nowledge discovery X  or  X  X ata mining X . Their lifetime does not exceed 3 timepoints, during which they ex-perience splits and size transitions. (d) At the early timepoints, there are clusters labeled  X  X patial X  and  X  X mage X  (later:  X  X mage retrieval X ). The labels appear in several periods but are associated with different clusters, so the cluster lifetime is low. Clusters associated to classes other than  X  X ata Mining X  appear only until 2002.
Hence, MONIC detected a remarkable shift in the accum-mulating H.2.8 section between 2001 and 2002, signalled by cluster splits and disappearances. The history of H.2.8 con-tains at least one event that may explain this shift: Starting with KDD X 2001, the proceedings of the conference and of some adjoint workshops are being uploaded in the ACM Digital Library, enriching the H.2.8 section with a lot of documents on many subtopics of data mining.
We have presented the framework MONIC for the moni-toring of cluster transitions. MONIC encompasses a cluster transition model and a transition detection algorithm, oper-ating upon clusterings over an accummulating dataset. We have applied MONIC on a section of the ACM library and have shown how cluster transitions give insights to changes of the data population. Currently, we work on heuristic en-hancements of the transition detection algorithm to reduce the matrix computation overhead at each timepoint. This includes the use of summary data, as discussed below.
