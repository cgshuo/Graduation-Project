 This paper presents a user intent method to generate blacklists for collaborative cyberporn filtering. A novel porn detection framework that finds new pornogra phic web pages by mining user search behaviors is proposed. It employs users X  clicks in search query logs to select the suspected web pages without extra human efforts to label data for training, and determines their categories with the help of URL host name a nd path information, but without web page content. We adopt an MSN porn data set to explore the effectiveness of our method. This user intent approach achieves high precision, while maintaining favorably low false positive rate. In addition, real-life filtering simulation reveals that our user intent method with its accumulative update strategy achieves 43.36% of blocking rate, while maintaining a steadily less than 7% of over-blocking rate. H.3.3 [ Information Search and Retrieval ]: Information filtering. Experimentation, Human Factors Query log analysis, pornographic blacklists, search es-and-clicks. Filtering the wide spreading objectionable web content, e.g., pornography, violence, drug and gamb ling, has attracted intensive attention for child protection or anyone else from inappropriate materials. URL blocking relies on a blacklist to reject undesirable requests [2]. Content analysis selects features from text, image, and linking structure for training pornography classifier [1]. The URL-based features were empirically shown as an effective approach for correctly identifying pornographic websites [4]. Moreover, query-URL click pair s were also exploited for clustering the similar pornographic images [3]. Different from web content and stru cture mining in the past work, we only exploit implicit collective intelligence from query logs for web usage mining. Filtering cyberporn is challenging due to its variability. Traditional filtering techniques regard this problem as categorization with statically crawled data sets. Since it is difficult to know the actual changing trail of objectionable web content, we attempt to explore those successfully accessed in search query logs to keep up with the change of the web approximately. Our user intent model can capture the newly-appearing objectionable web content or the variants of the original ones for avoiding being filtered, if someone has visited them via searches-and-clicks. Submitting queries to search engi nes and clicking search results, two common operations in daily life, provide implicit tagging on web pages. We employ click data in search query logs to classify web pages and generate a pornogr aphic blacklist based on user intents. The algorithm is composed of 3 stages: (1) query identification , (2) majority voting , and (3) category recognition . In query identification stage, the user intent model identifies suspected queries along with their clicked URLs from search query logs with a lexicon. The lexicon is constructed automatically as follows. We first select terms from the catalog of pornographic web sites as seed queries, and then regard any five seeds as a combination for term expansion by Google Sets. In total, there are 410 expanded terms and seeds in the lexicon for suspected query identification. In majority voting stage, we count the clicks of a page for the same queries issued within a tim e period, e.g., one month, and identify the URL candidates which satisfy either one of the majority rules proposed as follows. (1) Absolute majority rule : A URL is selected if its total number of clicks is more than a half of total issues of a query. The physical meaning of this rule is: users X  clicks on a URL show that the URL has similar intents in more than a half of query submissions. (2) Relative majority rule : A URL is selected if its total num ber of clicks is more than the average number of clicks among a ll URLs. The physical meaning of this rule is: a URL with higher tendency to be clicked than other URLs will be more related to the query. In category recognition stage, we use words in hostname and path to tell out different intents. A candidate whose URL contains at least one categorical keyword will be proposed. A categorical keyword set is formulated automa tically as follows. We first employ the blacklist released pub licly in URLBlacklist.com to collect categorical keywords common used in URLs of pornographic web pages, then remove  X  X ttp:// X  and  X / X  from URLs, further segment the remaini ng part of host name and path into all possible n-grams, and finally compose a 172-categorical-keyword set by consulting a pornographic dictionary. Besides, we also propose an accumulative update strategy , i.e., to use all query logs up to now, to explore the change of collective intelligence and update the blacklist. The accumulative time periods imply that the same query can be issued at different time and different search results may be clicked by users with similar intents. The newborn objectionabl e web pages or the variants of the original ones for avoiding being filtered can be included in the updated blacklist if users have accessed them with similar intent. The data set comes from the MSN 2006 RFP data. It consists of an MSN search query log excerpt with 15 million queries from US users during May 2006. Data made available include the issued queries, the clicked URLs and the time-stamps. We randomly selected 1% of MSN search query logs and removed those queries issued only once. After sampling, we manually labeled the pages as ground truth by examining their contents. Those pages which could not be accessed successfully at the labeling time were ignored. Th e numbers of unique queries issued in our testing data se t are 43,198. Total 5,821 and 10,135 unique URLs are annotated in porn and non-porn categories, respectively. To examine the effects of the three st ages in user intent model, i.e., (1) query identification , (2) majority voting , and (3) category recognition , we experiment different combinations of stages on the testing data set, where the time period is set to one month. Table 1 shows the experimental results. Strategy (1) achieves the highest recall, but a very bad false positive rate and precision. It reveals the category of queries does not always represent the category of web pages. Comparing Strategies (1)+(2) and (1)+(3), category recognition in URLs performs better than majority voting , due to clear categorical keywords of host names and paths in URLs. The disadvantage of majority voting is that even the same query was issued, different search results were proposed by search engines at different time. The proposed user intent model, i.e., Strategy (1)+(2)+(3), performs the best. It achieves high precisions of 0.7418, while maintaining favorably low false positive rate 0.0707. We analyze the reason of lower recall, and find that the number of clicks will be distributed among different URLs of the same pornographic content. In such a case, the c licks cannot satisfy any majority voting rules. Because pornographic content is the major target for objectionable web content filtering, the content providers tend to create more hosts and redirections to avoid being filtered. (1)+(2)+(3) 0.7418 0.3539 0.0707 Comparing Strategies (1) and (1)+(2)+(3), the former is an aggressive method for achieving a higher recall without concerning false positive rate; a nd the latter is a conservative method in which false positive rate is an important consideration. The user intent method achieves the lowest false positive rate of all the four methods. Obviously, this method is more proper to incorporate collective intelligence to search engines to mask pornographic search results before they are clicked. We further evaluate the filtering effects by real-life simulation using query logs. Figure 1 shows the blocking rates of three update strategies when time period is set to one day. The without update strategy, i.e., query logs of the first time period are used to generate a blacklist, performs the worst. Its blocking rate decreases with the passage of the time. The preceding update strategy, which iteratively updates a blacklist with the query logs of the preceding time period, performs better than the without update strategy because similar search results will be reported for the same query with similar intent in the following day. The accumulative update strategy achieves the macro-averaging blocking rate 43.36%, which is better than 28.44% and 20.56% with the preceding update and the without update strategies, respectively. In addition, its blocking rates vary between 40% and 50% with standard deviati on 0.04. The over-blocking rate, which is the proportion of normal accesses incorrectly blocked as pornographic ones, of all the three strategies is less than 7%. This paper proposes a simple but effective intent-based method for cyberporn filtering. Query ambiguity is a challenging issue for intent-based approach. Alternative suspected query identification methods such as considering a porn dictionary as seed queries will be investigat ed in the future for improving filtering performance. This research was partially supported by National Science Council, Taiwan under grant NSC99-2221-E-002-167-MY3. We are also grateful to Microsoft Research Asia for the support of MSN Search Query Log excerpt. [1] Hammami, M., Chahir, Y., and Chen, L. 2006. WebGuard: a [2] Lee, L.-H., and Luh, C.-J. 2008. Generation of pornographic [3] Szummer, M. and Craswe ll, N. 2008. Behavioral [4] Zhang, J., Qin, J., and Yan, Q. 2006. The role of URLs in 
