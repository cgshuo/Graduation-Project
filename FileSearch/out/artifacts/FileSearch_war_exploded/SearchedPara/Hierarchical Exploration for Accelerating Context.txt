 Yisong Yue yisongyue@cmu.edu Sue Ann Hong sahong@cs.cmu.edu Carlos Guestrin guestrin@cs.cmu.edu User feedback (e.g., ratings and clicks) has become a crucial source of training data for optimizing recom-mender systems. When making recommendations, one must balance the needs for exploration (gathering in-formative feedback) and exploitation (maximizing es-timated user utility). A common formalization of such a problem is the linear stochastic bandit problem ( Li et al. , 2010 ), which models user utility as a linear func-tion of user and content features.
 Unfortunately, conventional bandit algorithms can converge slowly with even moderately large feature spaces. For instance, the well-studied LinUCB algo-rithm ( Dani et al. , 2008 ; Abbasi-Yadkori et al. , 2011 ) achieves a regret bound that is linear in the dimension-ality of the feature space, which cannot be improved without further assumptions. 1 Intuitively, any bandit algorithm make recommenda-tions that cover the entire feature space in order to guarantee learning a reliable user model. Therefore, a common approach to dealing with slow convergence is dimensionality reduction based on prior knowledge, such as previously learned user profiles, by represent-ing new users as linear combinations of  X  X tereotypical users X  ( Li et al. , 2010 ; Yue &amp; Guestrin , 2011 ). However, if a user deviates from stereotypical users, then a reduced space may not be expressive enough to adequately learn her preferences. The challenge lies in appropriately leveraging prior knowledge to reduce the cost of exploration for new users, while maintaining the representational power of the full feature space. Our solution is a coarse-to-fine hierarchical approach for encoding prior knowledge. Intuitively, a coarse, low-rank subspace of the full feature space may be suf-ficient to accurately learn a stereotypical user X  X  pref-erences. At the same time, this coarse-to-fine feature hierarchy allows exploration in the full space when a user is not perfectly modeled by the coarse space. We propose an algorithm, CoFineUCB, that automat-ically balances exploration within the coarse-to-fine feature hierarchy. We prove regret bounds that de-pend on how well the user X  X  preferences project onto the coarse subspace. We also present a simple and general method for constructing feature hierarchies us-ing prior knowledge. We perform empirical valida-tion through simulation as well as a live user study in personalized news recommendation, demonstrating that CoFineUCB can substantially outperform con-ventional methods utilizing only a single feature space. We study the linear stochastic bandit problem ( Abbasi-Yadkori et al. , 2011 ), which formalizes a rec-ommendation system as a bandit algorithm that iter-atively performs actions and learns from rewards re-ceived per action. At each iteration t =1 ,...,T , our algorithm interacts with the user as follows: Rewards  X  y t are modeled as a linear function of actions x  X  D such that E [ X  y t | x ]= w  X  x , where the weight vector w  X  denotes the user X  X  (unknown) preferences. We assume feedback to be independently sampled and bounded within [0 , 1], 2 and that x  X  1 holds for all x . We quantify performance using the notion of regret which compares the expected rewards of the selected actions versus the optimal expected rewards: where x  X  t = argmax x  X  X We further suppose that user preferences are dis-tributed according to some distribution W . We can then define the expected regret over W as and the goal now for the bandit algorithm is to perform well with respect to W . We will present an approach for optimizing ( 2 ) given a collection of existing user profiles sampled i.i.d. from W . To learn a reliable user model (i.e., a reliable esti-mate of w  X  ) from user feedback, bandit algorithms must make recommendations that explore the entire D -dimensional feature space. Conventional bandit al-gorithms such as LinUCB place uniform a priori im-portance on each dimension, which can be ine ffi cient in practice, especially if additional structure can be assumed. We now motivate and formalize one such structure: the feature hierarchy.
 For example, suppose that two of the D features corre-spond to interest in articles about baseball and cricket. Suppose also that our prior knowledge suggests that users are typically interested in one or the other, but rarely both. Then we can design a feature subspace where baseball and cricket topics project along oppo-site directions in a single dimension. A bandit algo-rithm leveraging this structure should, ideally, first ex-plore at a coarse level to determine whether the user is more interested in articles about baseball or cricket. We can formalize the di ff erent levels of exploration as a hierarchy that is composed of the full feature space and a subspace. We define a K -dimensional subspace using a matrix U  X  D  X  K , and denote the projection of action x  X  D into the subspace as Likewise, we can write the user X  X  preferences w  X  as where we call w  X   X  the residual, or orthogonal compo-nent, of w  X  w.r.t. U .Then, Figure 1 illustrates a feature hierarchy with a two di-mensional subspace. Here, w  X  projects well to the sub-space, so we expect w  X  x  X   X  w  X   X  x (i.e., w  X   X  is small). In such cases, a bandit algorithm can focus exploration on the subspace to achieve faster convergence. 3.1. Extension to Deeper Hierarchies For the -th level, we define the projected w  X  as Then, Algorithm 1 CoFineUCB For simplicity and practical relevance, we focus on two-level hierarchies. We now present a bandit algorithm that exploits fea-ture hierarchies. Our algorithm, CoFineUCB, is an upper confidence bound algorithm that generalizes the well-studied LinUCB algorithm, and automatically trades o ff between exploring the coarse and full feature spaces. CoFineUCB is described in Algorithm 1 .At each iteration t , CoFineUCB estimates the user X  X  pref-erences in the subspace,  X  w t , as well as the full feature space, w t . Both estimates are solved via regularized least-squares regression. First,  X  w t is estimated via where  X  x  X   X  U x  X  denotes the projected features of the action taken at time  X  .Then w t is estimated via w t = argmin which regularizes w t to the projection of  X  w t back into the full space. Both optimization problems have closed form solutions (Lines 7 &amp; 9 in Algorithm 1 ). CoFineUCB is an optimistic algorithm that chooses the action with the largest potential reward (given some target confidence). Selecting such an action requires computing confidence intervals around the mean estimate w t . We maintain confidence intervals for both the full space and the subspace, denoted c t (  X  ) and  X  c t (  X  ), respectively. Intuitively, a valid 1  X   X  confi-dence interval should satisfy the property that holds with probability at least 1  X   X  .
 We will show that the following definitions of c t (  X  ) and  X  c (  X  ) yield a valid 1  X   X  confidence interval: must be set properly (Lemma 1 ).
 Broadly speaking, there are two types of uncertainty a ff ecting an estimate, w t x , of the utility of x : vari-ance and bias. In our setting, variance is due to the stochasticity of user feedback  X  y t . Bias, on the other hand, is due to regularization when estimating  X  w t and w . Intuitively, as our algorithm receives more feed-back, it becomes less uncertain (w.r.t. both bias and variance) of its estimates,  X  w t and w t . This notion of uncertainty is captured via the inverse feature covari-ance matrices  X  M t and M t (Lines 6 &amp; 8 in Algorithm 1 ). Table 1 provides an interpretation of the four sources of uncertainty described in ( 7 ) and ( 8 ).
 Lemma 1 below describes how to set the coe ffi cients Lemma 1. Define  X  S =  X  w  X  and S  X  = w  X   X  , and let Then ( 6 ) is a valid 1  X   X  confidence interval. With the confidence intervals defined, we are now ready to present our main result on the regret bound. Lemma 1 .For  X   X  max x x 2 and  X   X   X  max x  X  x 2 , with probability 1  X   X  , CoFineUCB achieves regret where Lemma 1 and Theorem 1 are proved in Appendix A . Theorem 1 essentially bounds the regret as ignoring log factors. In contrast, the conventional Lin-UCB algorithm only explores in the full feature space and achieves an analogous regret bound of Comparing ( 11 )with( 12 ) suggests that, when K&lt;&lt; D and w  X   X  is small, CoFineUCB su ff ers much less regret due to more e ffi cient exploration. Depending on U ,  X  w  X  can also be much smaller than w  X  . Section 5 describes an approach for computing such a U . Intuitively, CoFineUCB enjoys a superior regret bound to LinUCB due to its use of tighter confidence regions. Figure 2 depicts a comparative example. LinUCB em-ploys ellipsoid confidence regions. CoFineUCB utilizes confidence regions that are essentially the convolution of two smaller ellipsoids, which can be much smaller than the confidence regions of LinUCB. We now show how to construct a subspace U using pre-existing user profiles W = { w  X  i } N i =1 , where each profile is sampled independently from a common distribution w i  X  W . In this setting, a reasonable objective is to find a U that minimizes an empirical estimate of the bound on R T ( W ), which comprises  X  w and w  X  . Our approach is outlined in Algorithm 2 . We assume that finding a K -dimensional subspace with low resid-ual norms w  X   X  is straightfoward. In our experiments, we simply use the top K singular vectors of W . Algorithm 2 LearnU: learning projection matrix Given an orthonormal basis U 0  X  K  X  D , one can choose U  X  span ( U 0 ) to minimize its total contribu-tion to the regret bound in ( 11 )overtheusersin W : where  X  w  X  ( U U )  X  1 U w , and  X  C = max x U x con-strains the magnitude of U .
 It is di ffi cult to optimize ( 13 ) directly, so we approxi-mate it using a smooth formulation, 4 where we now constrain U via U 2 Fro = K .
 We further restrict U to be U  X  U 0  X  1 / 2 for  X  0. Under this restriction, ( 14 ) is equivalent to where  X  w 0  X  ( U 0 U 0 )  X  1 U 0 w = U 0 w . This formula-tion is akin to multi-task structure learning, where W 0 would denote the various tasks and  X  denotes feature relationships common across tasks ( Argyriou et al. , 2007 ; Zhang &amp; Yeung , 2010 ). One can show that ( 15 ) is convex and is minimized by where  X  W 0  X  ( U 0 U 0 )  X  1 U 0 W = U 0 W . See Appendix B for a more detailed derivation. We evaluate CoFineUCB via both simulations and a live user study in the personalized news recommenda-tion domain. We first describe alternative methods, or baselines, for leveraging prior knowledge (pre-existing profiles W  X  D  X  N ) that do not use a feature hierar-chy. These baselines can conceptually be phrased as special cases of CoFineUCB. The key idea is to alter the feature space such that w  X  in the new space is small. Thus, running LinUCB in the altered feature space yields an improved bound on the regret ( 12 ), which is linear in w  X  . 6.1. Baseline Approaches Mean-Regularized One simple approach is to reg-ularize to  X  w (e.g., the mean of W ) when estimating w t in LinUCB. The estimation problem can be written as w t = argmin Typically, w  X   X   X  w &lt; w  X  , implying lower regret. Reshape Another approach is to use LinUCB with a feature space  X  X eshaped X  via a transform U D  X  D  X  D : As in the mean-regularization approach above, here we would like the representation of w  X  in the reshaped space to have a small norm. In our experiments, we use U D = LearnU( W, D ) (Algorithm 2 ).
 We can incorporate such reshaping into CoFineUCB. We first project W into the space defined by U D ,de-noted by  X  W , 5 then compute U via LearnU(  X  W,K ). During model estimation, we replace ( 5 )with w t = argmin Incorporating reshaping into CoFineUCB can lead to a decrease in S  X  =  X  w  X   X  . We found the modification to be quite e ff ective in practice; all our experiments in the following sections employ this variant of CoFineUCB. SubspaceUCB Finally, we can simply ignore the full space and only apply LinUCB in the subspace. While the method seems to perform well given a good subspace (as seen in ( Li et al. , 2010 ; Chapelle &amp; Li , 2011 ; Yue &amp; Guestrin , 2011 ), among others), it can yield linear regret if the residual of the user X  X  prefer-ence is strong, as we will see in the experiments. 6.2. Experimental Setting We employ the submodular bandit extension of linear stochastic bandits ( Yue &amp; Guestrin , 2011 )tomodel the news recommendation setting. Here, the algorithm must choose a set of L actions and receives rewards based on both the quality as well as diversity of the ac-tions chosen ( L = 1 is the conventional bandit setting). Using this structured action space leads to a more real-istic setting for content recommendation, since recom-mender systems often must recommend multiple items at a time. It is straightforward to extend CoFineUCB to the submodular bandit setting (see Appendix C ). 6.3. Simulations We performed simulation evaluations using data col-lected from a previous user study in personalized news recommendation by ( Yue &amp; Guestrin , 2011 ). The data includes featurized articles ( D = 100) and N = 77 user profiles. We employed leave-one-out validation: for each user, the transformations U D and U ( K = 5) were trained using the remaining users X  profiles. For each user, we ran 25 simulations ( T = 10000). All algorithms used the same U and U D projections, where applicable. We also compared with a variant of CoFineUCB, CoFineUCB-focus, which scales down exploration in the full space c t by a factor of 0 . 25. Figure 3 (a) shows the cumulative regret of each al-gorithm averaged over all users when recommending one article per iteration ( L = 1). All algorithms dramatically outperform Naive LinUCB, with the ex-ception of Mean-Regularized which performs almost identically. While Reshape shows good eventual con-vergence behavior, it incurs higher initial regret than the CoFineUCB algorithms and SubspaceUCB. The trends also hold when recommending multiple articles per iteration ( L = 5), as seen in Figure 3 (b) . The performance of the two variants of CoFineUCB and SubspaceUCB demonstrate the benefit of explor-ing in the subspace. However, Figure 3 (c) reveals the critical shortfall of SubspaceUCB by comparing aver-age cumulative regret for the ten users with the largest residual w  X   X  . For these atypical users, the subspace is not su ffi cient to adequately learn their preferences, resulting in linear regret for SubspaceUCB.
 Figure 3 (d) shows the behavior of CoFineUCB as we vary K . Larger subspaces require more exploration, which in general leads to increased regret.
 Figure 3 (e) shows the behavior of CoFineUCB as we vary the scaling of exploration in the full space c t (CoFineUCB-focus is the special case where the scal-ing factor is 0 . 25). More conservative exploration in the full space tends to reduce regret. However, no ex-ploration of the full space can lead to higher regret. Synthetic Dataset . We used a 25-dimensional syn-thetic dataset to study the e ff ect of mismatch between w  X  and U . This dataset allows for a more system-atic analysis by forcing every x and w  X  to have unit norm. For residual magnitude  X   X  [0 , 1], we sampled w  X  uniformly in a 5-dimensional subspace with magni-tude 1  X   X  2 , and uniformly in the remaining dimen-sions with magnitude  X  . Figure 3 (f) shows the regret of both SubspaceUCB and CoFineUCB-focus increase with the residual, with SubspaceUCB exhibiting more dramatic increase, beyond that of even Naive LinUCB. 6.4. User Study Our user study design follows the study conducted in ( Yue &amp; Guestrin , 2011 ). We presented each user with ten articles per day over ten days from January 21, 2012 to February 8, 2012. Each day comprised approx-imately ten thousand articles. We represented articles using D = 100 features corresponding to topics learned via latent Dirichlet Allocation ( Blei et al. , 2003 ). For each day, articles shown are selected using an interleav-ing of two bandit algorithms. The user is instructed to briefly skim each article and mark each article as  X  X nterested in reading in detail X  X r  X  X ot interested X . We conducted the user study in two phases. Prior to the first phase, we conducted a preliminary study to collect preferences for constructing U ( K = 5). In the first phase, we compared CoFineUCB with Naive. Af-terwards, we took all the user profiles learned so far to estimate a reshaping of the full space U D , and com-pared against Reshape. Due to the short duration of each session ( T = 10), we did not expect a meaningful comparison between CoFineUCB and SubspaceUCB, so we omitted it (We expect both methods to perform equally well in early iterations, as seen in the simula-tion experiments.). For each user session, we counted the total number of liked articles recommended by each algorithm. An algorithm wins a session if the user liked more articles recommended by it.
 Table 2 shows that over the two stages, about 80% of the users prefer CoFineUCB. We see a smaller gain against Reshape, a stronger baseline. On average, users liked over half an additional article per day from CoFineUCB over Naive, and about a quarter addi-tional per day over Reshape. These results show that CoFineUCB is e ff ective in reducing the amount of ex-ploration required.
 Figure 4 shows a representation of four dimensions of U learned from user profiles. Each dimension is a combination of features, i.e., topics from LDA. In the top row, the i -th word cloud contains represen-tative words from topics associated with high positive weights in i -th column of U , and the bottom row those with high negative weights. Examining Figure 4 can reveal tendencies in the user preferences collected in our study; for example, the third column shows that users interested in Republican politics also tend to fol-low healthcare debates, but tend to be uninterested in videogaming. Figure 4 also shows a comparison of weights estimated by CoFineUCB and Naive LinUCB for one user. Since Naive LinUCB does not utilize the subspace, the weights it estimates tend to have much higher residual norm, whereas CoFineUCB puts higher weights on the subspace dimensions. Optimizing recommender systems via user feedback has become increasingly popular in recent years ( El-2011 ; Ahmed et al. , 2012 ). Most prior work do not ad-dress the issue of exploration and often train with pre-collected feedback, which may lead to a biased model. The exploration-exploitation tradeo ff inherent in learning from user feedback is naturally modeled as a contextual bandit problem ( Langford &amp; Zhang , 2007 ; Li et al. , 2010 ; Slivkins , 2011 ; Chapelle &amp; Li , 2011 ; Krause &amp; Ong , 2011 ). In contrast to most prior work, we focus on principled approaches for encoding prior knowledge for accelerated bandit learning.
 Our work builds upon a long line of research on linear stochastic bandits ( Dani et al. , 2008 ; Rusmevichien-tong &amp; Tsitsiklis , 2010 ; Abbasi-Yadkori et al. , 2011 ). Although often practical, one limitation is the assump-tion of realizability. In other words, we assume that the true model of user behavior lies within our class. The use of hierarchies in bandit learning is not new. For instance, the work of ( Pandey et al. , 2007b ; a )en-code prior knowledge by hierarchically clustering arti-cles into a taxonomy. However, their setting is feature-free, which can make it di ffi cult to generalize to new articles and users. In contrast, our approach makes use of readily available feature-based prior knowledge such as the learned preferences of existing users. Another related line of work is that of sparse linear bandits ( Abbasi-Yadkori et al. , 2012 ; Carpentier &amp; Munos , 2012 ). The assumption is that the true w  X  is sparse, and one can achieve regret bounds that de-pend on the sparsity of w  X  . In contrast, we consider settings where user profiles are not necessarily sparse, but can be well-approximated by a low-rank subspace. It may be possible to integrate our feature hierar-chy approach with other bandit learning algorithms, such as Thompson Sampling ( Chapelle &amp; Li , 2011 ). Thompson Sampling is a probability matching algo-rithm that samples w t from the posterior distribution. Using feature hierarchies, one can define a hierarchical sampling approach that first samples  X  w t in the sub-space, and then samples w t around  X  w t in the full space. Our approach can be applied to many structured classes of bandit problems (e.g., ( Streeter &amp; Golovin , 2008 ; Cesa-Bianchi &amp; Lugosi , 2009 )), assuming that actions can be featurized and modeled linearly. For in-stance, our experiments demonstrated substantial im-provements upon naive UCB algorithms for the linear submodular bandit problem ( Yue &amp; Guestrin , 2011 ). The problem of learning a good subspace U is related to finding a good regularization structure for multi-task learning ( Argyriou et al. , 2007 ; Zhang &amp; Yeung , 2010 ). Given a sample of user profiles (task weights), our goal is essentially to learn a regularization struc-ture so that future users (tasks) are solved e ffi ciently. However, the coarse subspace of our feature hierarchy was estimated using a relatively small number of im-perfectly estimated existing user profiles. A more gen-eral problem would be to learn the feature hierarchy on-the-fly as an online learning problem itself. We have presented a general approach to encoding prior knowledge for accelerating contextual bandit learning. In particular, our approach employs a coarse-to-fine feature hierarchy which dramatically reduces the amount of exploration required. We evaluated our approach in the setting of personalized news recom-mendation, where we showed significant improvements over existing approaches for encoding prior knowledge.
