 Accurate knowledge of a patient X  X  disease state and trajec-tory is critical in a clinical setting. Modern electronic health-care records contain an increasingly large amount of data, and the ability to automatically identify the factors that influence patient outcomes stand to greatly improve the ef-ficiency and quality of care.

We examined the use of latent variable models (viz. La-tent Dirichlet Allocation) to decompose free-text hospital notes into meaningful features, and the predictive power of these features for patient mortality. We considered three prediction regimes: (1) baseline prediction, (2) dynamic (time-varying) outcome prediction, and (3) retrospective outcome prediction. In each, our prediction task differs from the familiar time-varying situation whereby data accumulates; since fewer patients have long ICU stays, as we move for-ward in time fewer patients are available and the prediction task becomes increasingly difficult.

We found that latent topic-derived features were effective in determining patient mortality under three timelines: in-hospital, 30 day post-discharge, and 1 year post-discharge mortality. Our results demonstrated that the latent topic features important in predicting hospital mortality are very different from those that are important in post-discharge mortality. In general, latent topic features were more pre-dictive than structured features, and a combination of the two performed best.

The time-varying models that combined latent topic fea-tures and baseline features had AUCs that reached 0.85, 0.80, and 0.77 for in-hospital, 30 day post-discharge and 1 year post-discharge mortality respectively. Our results agreed with other work suggesting that the first 24 hours of patient information are often the most predictive of hospital mortality. Retrospective models that used a combination of latent topic features and structured features achieved AUCs of 0.96, 0.82, and 0.81 for in-hospital, 30 day, and 1-year mortality prediction.

Our work focuses on the dynamic (time-varying) setting because models from this regime could facilitate an on-going severity stratification system that helps direct care-staff re-sources and inform treatment strategies.
 Primary: Data mining for social good.
 Secondary: Healthcare and medicine; Topic, graphical and latent variable models; Text; Support vector machines.
In a fragmented healthcare system of patients, doctors, caregivers, and specialists, an accurate knowledge of a pa-tient X  X  disease state is critical. Electronic monitoring sys-tems and health records facilitate the flow of information among these parties to effectively manage patient health. However, information is not knowledge, and often only some of the information will be relevant in the context of pro-viding care. Expert physicians want to sift through these extensive records to discover the data most relevant to a pa-tient X  X  current condition. As such, systems that can identify these patterns of relevant characteristics stand to improve the efficiency and quality of care.

This work focused on the task of on-going mortality pre-diction in the intensive care unit (ICU). The ICU is a partic-ularly challenging environment because each patient X  X  sever-ity of illness is constantly evolving. Further, modern ICUs are equipped with many independent measurement devices that often produce conflicting (and even false) alarms, ad-versely affecting the quality of care. Consequently, much recent work in ICU mortality models [8, 10, 17] has aimed to consolidate data from these devices (primarily structured data and physiological waveforms) and transform these in-formation streams into knowledge. However, these works omit perhaps the most descriptive sources of medical infor-mation: free-text clinical notes and reports.

The narrative in the clinical notes, recorded by expert care staff, is designed to provide trained professionals a quick glance into the most important aspects of a patient X  X  phys-iology. Combining features extracted from these notations with standard physiological measurements results in a more complete representation of patients X  physiological states, thus affording improved outcome prediction. Unfortunately, free-text data are often more difficult to include in predictive models because they lack the structure required by most machine learning methods. To overcome the obstacles in-herent in clinical text, latent variable models such as topic models [1, 2] may be used to infer intermediary representa-tions that can in turn be used as structured features for a prediction task.

We demonstrate the value of incorporating information from clinical notes, via latent topic features, in the task of in-hospital mortality prediction as well as 30 day and 1 year post-discharge mortality prediction. Specifically, we eval-uated mortality prediction under three prediction regimes: (1) baseline regime, which used structured data available on admission (2) time-varying regime, which used baseline features together with dynamically accumulated clinical text using increasigly large subsets of the patient X  X  narrative record, and (3) retrospective regime, which used all clinical text gen-erated from a hospital stay to supplement the baseline fea-tures. In all targeted outcomes, we demonstrate that adding information from clinical notes improves predictions of mor-tality.
Mortality models for acute (i.e. ICU) settings constitute a broad area of research. Siontis et al. [16] reviewed 94 stud-ies with 240 assessments of 118 mortality prediction tools from 2009 alone. Many of these studies evaluated estab-lished clinical decision rules for predicting mortality, such as APACHE [9], SAPS-II [10], and SOFA [17] (with median re-ported AUCs of 0.77, 0.77, and 0.84, respectively). Sionitis et al. also noted a large variability of these measures across various diseases and population subgroups. Other acuity scores have also been proposed, including the recent OASIS score [8] which uses machine-learning algorithms to identify the minimal set of variables capable of yielding an accurate severity of illness score (AUC 0.88).

Work by Hug et al. [7] used several hundred structured clinical variables to create a real-time ICU acuity score that reported an AUC of 0.88-0.89 for in-hospital mortality pre-diction. Notably, most of the predictive power of their mod-els was from data gathered within the first 24 hours of the ICU stay. For example, their computed acuity score re-ported an AUC of 0.809 for in-hospital mortality prediction based on information during the first 24 hours of ICU stays in 1,954 patients.

Several recent works have used information from clinical notes in their model formulations. Saria et al. [15] com-bined structured physiological data with concepts from the discharge summaries to achieve a patient outcome classifi-cation F1 score of 88.3 with a corresponding reduction in error of 23.52%. Similarly, [5] described preliminary results indicating that topic models extracted from clinical text in a subgroup of ICU patients were valuable in the prediction of per-admission mortality. They found that common topics from the unlabeled clinical notes were predictive of mortal-ity, and an RBF SVM achieved a retrospective AUC of 0.855 for in-hospital mortality prediction using only learned top-ics. Finally, Lehman et al. [11] applied Hierarchical Dirichlet Processes to nursing notes from the first 24 hours for ICU patient risk stratification. They demonstrated that unstruc-tured nursing notes were enriched with clinically meaningful information, and this information could be used for clinical support. Using topic proportions, the average AUC for hos-pital mortality prediction was 0.78 (  X  0.01). In combination with the SAPS-I variable, their average AUC for hospital mortality prediction was 0.82 (  X  0.003).
Figure 1 gives a general overview of our experimental pro-cess. First, we extract clinical baseline features, including age, sex, and SAPS-II score, from the database for every patient. We also extract each patient X  X  de-identified clini-cal notes. We use these notes as the observed data in an LDA topic model, and infer a total of 50 topics. We normal-ize the word counts associated with each note, so that each note is represented by a 50-dimension vector, summing to 1. These per-note topic distributions are then aggregated on a 12 hour semi-continuous timescale (e.g. notes within 0-12 hours, notes within 0-24 hours, etc.). A linear kernel SVM is trained to create classification boundaries with combina-tions of the structured clinical features and latent topic fea-tures to predict in-hospital mortality, 30 day post-discharge mortality, and 1 year post-discharge mortality.
We used ICU data from the MIMIC II 2.6 database [13], a publicly-available, de-identified medical corpus which in-cludes electronic medical records (EMRs) for 26 , 870 ICU pa-tients at the Beth Israel Deaconess Medical Center (BIDMC) collected from 2001 to 2008. Patient age, sex, SAPS-II scores, International Classification of Diseases-Ninth Revi-sion (ICD-9) diagnoses, and Disease-Related Group were extracted. Medical co-morbidities were represented by the Elixhauser scores (EH) for 30 co-morbidities as calculated from the ICD-9 codes. Patient mortality outcomes were also queried to determine which patients died in-hospital, or lived past the most recent query of Social Security records.
We extracted all clinical notes recorded prior to the pa-tient X  X  first discharge, including notes from nursing, physi-cians, labs, and radiology. The discharge summaries them-selves were excluded because they typically stated the pa-tient X  X  outcome explicitly. Vocabularies for each note were generated by first tokenizing the free text and then removing the Structured Features matrix v ( v p,f is the value of feature f in the p post-discharge mortality (i.e. Structured SVM Model ). stopwords using the Onix stopword list 1 . A TF-IDF met-ric [14] was applied to determine the 500 most informative words in each patient X  X  notes, and we then limited our over-all vocabulary to the union of the most informative words per-patient. This pre-processing step reduced the overall vo-cabulary down to 285,840 words from over 1 million terms while maintaining the most distinctive features of each pa-tient. 2
Patients were excluded if they had fewer than 100 non-stop words or were under the age of 18. Specific notes were excluded if they occurred after the the end of the day in which a patient died or was discharged (e.g. radiology or lab reports whose results were reported afterwards). The resulting cohort consisted of 19,308 patients with 473,764 notes. We held out a random 30% of the patients as a test set. The remaining 70% of patients were used to train our topic models and mortality predictors. Table 1 summarizes the number of notes and patients in the training and test sets.
Onix Text Retrieval Toolkit, API Reference, http://www.lextek.com/manuals/onix
Some medical term canonicalization parsers were also ex-amined, but we found their outputs to be fairly unreliable for this task.
In total, we extracted and derived 36 structured clinical variables for each patient: the age, gender, SAPS II score on admission, minimum SAPS II score, maximum SAPS II score, final SAPS II score, and the 30 EH comorbidities. Data were scaled to avoid the range of a feature impacting its classification importance. This formed a feature matrix v , where the element v p,f was the value of feature f in the p th patient.
Instead of considering each note separately, we used the set of all of notes that occurred in a particular time period as features for that period. We examined the distribution of note times, and found three peaks in note entry for any given day in a patient X  X  stay (e.g. day 1, day 2, etc.): around 06:00, 18:00 and 24:00. 3 Given this distribution, we used 12-hour windows for our time windows.
 Topics were generated for each note using Latent Dirichlet Allocation [2,6]. Our initial experiments found no significant difference in held-out prediction accuracy across a range of 20 to 100 topics. We set hyperparameters on the Dirichlet priors for the topic distributions (  X  ) and the topic-word dis-We used 50 topics in our final experiments, and topic distri-butions were sampled from an MCMC chain after 2,500 iter-ations. This topic-modeling step resulted in a 50-dimensional vector of topic proportions for each patient for each note.
The increases in note submission at 06:00 and 18:00 were likely due to the current 12 hour nursing shift cycle. The large number of notes submitted at end-of-day were likely due to a previously common 14:00 -midnight nursing shift.
We concatenated the topic vectors into a matrix q where the element q n,k was the proportion of topic k in the n note. Of particular interest was whether certain topics were enriched for in-hospital mortality and long-term survival. We used an enrichment measure defined by Marlin et al [12], where the probability of mortality for each topic is calculated come (0 for a patient that lives, and 1 for a patient that dies). These enrichment measures are reported in section 4.1.
The time windows were used to construct feature vectors for each prediction task, where (at each step) we extended the period of consideration forward by 12 hours. From the previously constructed per-note matrix q that describes the distribution over topics in each note, we collapse into an-other matrix q 0 where q 0 m,k describes the overall proportion of topic k in time-window m . The element q 0 m,k is given by the mean of that topic X  X  proportions of all the notes in time-window m : mean n  X  m q n,k .
We considered three prediction regimes with the inferred topic distributions: baseline prediction, dynamic (time-varying) outcome prediction and retrospective outcome prediction for the outcomes of in-hospital, 30-day, and 1-year mortality.
A separate linear SVM [4] was trained for each of the three outcomes, and each set of model features evaluated. The loss and class weight parameters for the SVM were se-lected using five-fold cross-validation on the training data to determine the optimal values with AUC as an objective. The learned parameters were then used to construct a model for the entire training set, and make predictions on the test data.

All outcomes had large class-imbalance (mortality rates of 10.9% in-hospital, 3.7% 30 day post-discharge, and 13.7% 1 year post-discharge 4 ). To address this issue, we randomly sub-sampled the negative class in the training set to pro-duce a minimum 70%/30% ratio between the negative and positive classes. Test set distributions were not modified to reflect the reality of class imbalance during prediction, and reported performance reflects those distributions.

First, we established a static baseline model using only structured features present at admission (i.e. clinical base-line features and derived features thereof). We then ran dynamic outcome prediction in intervals of 12 hours at each step by including larger sets of patient notes in a step-wise manner. We finally performed retrospective outcome predic-tions, where we included structured features and all notes written during the stay as a static entity for prediction. Sig-nificantly, predictions of mortality with this type of feature set are a retrospective exercise only: it is not possible to first select all notes that occur before a patient X  X  death, and then predict in-hospital mortality, because the time of mor-tality is not known a-priori. The observer would have to  X  X now X  that the patient X  X  hospital record was about to fin-ish (either by death or discharge). The following settings were evaluated:
This includes those who die within the first 30-days post-discharge, so two of the prediction targets have overlap.
We compare the prediction results for all models on each of the outcomes in Figure 3 and Table A.2. We again em-phasize that retrospective models are retrospective exercises only to establish the isolated and combined prediction abil-ity of clinical notes and features. We also note that our Time-varying Topic Model is time-varying only in its appli-cation. We do not use other possible latent variable models such as  X  X ynamic topic models X  [3], because we do not want to model the time evolution of topics, but rather the time evolution of membership to a given set of topics.
Table 2 lists the top words for the topics which had the tality, the smallest enrichment for in-hospital mortality, and the highest enrichment for 1 year mortality. The relative dis-tributions of the in-hospital mortality probabilities for each of the 50 topics are shown in Figure 2. There were a wide variation in the in-hospital mortality concentration for the different topics, ranging from 3% -30%. (See Table A.3 for a listing of top ten words for all topics.) in-hospital mortality based on the value of  X  k for each topic k .
The topics enriched for in-hospital mortality presented a detailed view of the possible causes of death in the ICU. For example, patients in a modern ICU rarely die suddenly. Often patient life is sustained for some time in order for their family to express their wishes regarding terminal care and death. This could be one interpretation for Topic 27, which pertains to the discussion of end-of-life care options. Other topics with in-hospital mortality enrichment pertained to top causes of ICU mortality: respiratory infection (Topic 7), respiratory failure (Topic 15), and renal failure (Topic 5).

Hospital survival was also marked by topics which seem relevant to factors tied closely to the ability to recover from physiological insults: patients who are admitted for cardio-vascular surgery (Topic 1) are often not allowed as surgical candidates until they are in very good health; patients who are able to respond to their care staff and the ICU envi-ronment (Topic 26, Table A.3) are adequately dealing with the known stress of ICU admission; patients with trauma-based injuries such as fracture and pneumothorax (Topics 8, 40); and patients with chronic conditions like diabetes (Topic 16).

The topics enriched for 1 year post-discharge mortality suggested that patients who are discharged but die within a year have conditions with a low chance of long-term survival. For example, cancer (Topic 4), the need for long-term IV access while in the ICU (Topic 3), and the use of coronary catheterization (Topic 45) to diagnose activity in coronary arteries or other valvular/cardiac issues.
We evaluated the predictive power of each model and out-come pair. Figure 3 shows the AUCs achieved by each model for the three targeted outcomes. Table A.2 lists a more com-plete set of the SVM classification metrics.

As shown in Table A.2, the prevalent class imbalance resulted in a bias toward low specificities in the Admis-sion Baseline Model . The balance between sensitivity and specificity generally leaned towards favoring higher specifici-ties for in-hospital and 30 day mortality prediction as time moved forward in the Time-varying models, but this was not uniformaly true in all cases. In general, the Retrospec-tive Derived Features Model had a high sensitivity and low specificity, the Retrospective Topic Model had good speci-ficity, and the combined models tended to have a more even set of both measures.

For 30 day and 1 year post-discharge mortality predic-tion, the Admission Baseline Model was very steady, av-eraging an AUC of 0.68 over all time windows for both outcomes. The Combined Time-varying Model achieved an average/best performance of 0.77/0.8 for 30 day mortality and 0.75/0.77 for 1 year mortality. In both outcomes the Time-varying Topic Model performed strictly better than the Admission Baseline Model until the available patient subset became minimal (the 204 -216 hour windows), and the Combined Time-varying Model was always better than either alone.

As expected, the four Retrospective models were generally more predictive than any of the Time-varying models. Ret-rospective models tended to increase performance as more features were added. For in-hospital and 30 day mortality prediction, the Retrospective Topic Model performed better than the Retrospective Derived Features Model (AUCs in-creased from 0.90 to 0.94 and 0.75 to 0.78 respectively). For 1 year mortality this was reversed (AUC decreased from 0.78 to 0.76). positives for in-hospital mortality). (Table A.1)
In the in-hospital mortality setting, it seemed that admis-sion features were not needed once latent topic features are known, but the derived features did provide extra informa-tion 6 . However, in the 30 day setting, latent topic features were similarly improved by either the admission features or the derived features 7 . This is likely because the derived features included EH comorbidities derived from the ICD-9 codes, and the ICD-9 codes themselves are often transcribed after a patient X  X  discharge with the most actionable (or bill-able) conditions a patient presented. It is possible that these features are most relevant to in-hospital mortality risks (e.g. EH scores for myocardial infarction, congestive heart fail-ures, etc.).
Adding the admission features did not improve the Ret-rospective Topic Model , but adding the derived features boosted AUC slightly to 0.96. Adding the admission features to the Retrospective Topic Model improved AUC to 0.81 but adding the derived fea-tures did not improve AUC further.
Models that incorporated latent topic features were gen-erally more predictive than those using only structured fea-tures, and a combination of the two feature types performed best. Notably, the combination provides a robustness that is able to perform well initially, leveraging primarily the struc-tured information, and then continue to improve over the first 24 hours by incorporating the latent topic features. This resilience is particularly important since we observed that the first 24 hours of clinical notes appear to be the most meaningful toward predicting in-hospital mortality, while the baseline begins to steadily decrease.

Our observation of the importance of early data agrees with other reported results. Recall that, using topics de-rived from the first 24 hours of notes only, Lehman et al ob-tained an average AUC for in-hospital mortality prediction of 0.78 (  X  0.01), and this was increased to 0.82 (  X  0.003) with the SAPS-I variable. Further, Hug et al. obtained an AUC of 0.809 for in-hospital mortality prediction based on information during the first 24 hours of ICU. As such, we Table 2: Top ten words in topics enriched for in-hospital mortality, hospital survival (any number of days post-discharge), and 1 year post-discharge mortality.

In-hospital
Mor-tality Hospital
Sur-vival 1 Year
Mor-tality examined our results for in-hospital mortality when using topics derived from the first 24 hours of notes only (predic-tion time of 36 hours in Figure 3), and obtained correspond-ing AUCs of 0.77 for the Time-varying Topic Model , and 0.841 for the Combined Time-varying Model . Compared to Lehman et al X  X  result, this implies that (with enough data) neither the extra hierarchical machinery added with HDPs nor the knowledge-based cleansing of medical terms before modeling improve prediction results (i.e. an AUC of 0.78 vs. 0.77). Compared to Hug et al X  X  results, this implies that the addition of clinical text provides reasonable performance boosts to the power of gold-standard structured information like SAPS-II score (i.e. an AUC of 0.809 vs. 0.841).
Further, when predicting in-hospital mortality, we ob-served that the Admission Baseline Model  X  X  predictive power (i.e. information acquired on admission) becomes much less valuable to predicting mortality as patients stay longer. This is likely because those who are not discharged within the first day of hospital admission are significantly sicker than those who are. Note that the average ICU stay time in the MIMIC II database is 3 days, and Figure 3 shows that after this time there was no additional predictive power gained by adding the structured admission information to the latent topic fea-tures (i.e., the Time-varying Topic Model and the Combined Time-varying Model converge).

This convergence draws attention to another interesting observation. Namely, both of the Time-varying models trended up in their ability to predict in-hospital mortality until 120 hours, and then trended down until the end of prediction. While initially counterintuitive, this is likely due to the loss of a significant number of patients (from both death and dis-charge) in the available patient cohort. For example, the test set population goes from 4,030 patients (3,626 control/404 positive for in-hospital mortality) to 3570 patients at this point (3,210 control/360 positive for in-hospital mortality).
Additionally, the predictive power of each topic changed depending on the target outcome. This appeals to intuition asIn a modern ICU, conditions that lead to in-hospital mor-tality are very different from those that would allow for a live discharge leading to a 30 day or 1 year mortality. As such, information about which topics tend to bias a patient towards any set of outcomes in useful for clinicians, when compared to the typical  X  X lack-box X  approach to feature se-lection.

Finally, much work focuses on retrospective prediction of mortality outcomes. We also performed these predictions to compare the relative predictive power of different fea-ture types and were able to achieve retrospective AUCs of 0 . 9, 0 . 94 and 0 . 96 for in-hospital mortality prediction us-ing the Retrospective Derived Feature Model , Retrospective Topic Model , and combined Retrospective Topic + Dervied Features Model . However, we re-emphasize that predictions of mortality with retrospective feature sets are not helpful or relevant for clinical staff because statistical functions of signals or features (e.g. min/max) and other structured data (such as ICD-9 codes and EH comorbidities) are not known a-priori.
Modern electronic healthcare records contain an increas-ingly large amount of data including high-frequency signals from biomedical instrumentation, intermittent results from lab tests, and text from notes. Such voluminous records can make it difficult for care-staff to identify the information rel-evant to diagnose a patient X  X  condition and stratify patients with similar characteristics.

Standard approaches to hospital mortality prediction use features such as gender, age, SAPS and SOFA score. In this work, we examined the utility of augmenting these standard features with textual information X  X pecifically in the form of topic-based features X  X or predicting mortality in the ICU. Features extracted by latent variable models are attractive in this clinical application because scientific understanding is as important as clinical utility.

Qualitatively, the discovered topics correlated with known causes of in-hospital and post-discharge death. Further, adding latent topic features to structured clincal features increased classification performance in a variety of predic-tion scenarios: in-hospital mortality, 30-day mortality, and 1-year mortality.

The models and results explored in this work could ul-timately be useful for interpretable models of disease and mortality. This research was funded in part by the Intel Science and Technology Center for Big Data and the National Library of Medicine Biomedical Informatics Research Training grant (NIH/NLM 2T15 LM007092-22) which supported Marzyeh Ghassemi and Tristan Naumann.
 The authors would like to thank Abbas Benjamin Munson-Ghassemi for many nights of heartburn and kick-fueled writ-ing. [1] C. Arnold et al. Clinical case-based retrieval using [2] D. Blei, A. Ng, and M. Jordan. Latent dirichlet [3] D. M. Blei and J. D. Lafferty. Dynamic topic models. [4] C.-C. Chang and C.-J. Lin. LIBSVM: A library for [5] M. Ghassemi, T. Naumann, R. Joshi, and [6] T. Griffiths and M. Steyvers. Finding scientific topics. [7] C. W. Hug and P. Szolovits. Icu acuity: real-time [8] A. E. Johnson, A. A. Kramer, and G. D. Clifford. A [9] W. A. Knaus, D. Wagner, E. e. a. Draper, [10] J. Le Gall, S. Lemeshow, and F. Saulnier. A new [11] L.-w. Lehman, M. Saeed, W. Long, J. Lee, and [12] B. M. Marlin, D. C. Kale, R. G. Khemani, and R. C. [13] M. Saeed et al. Multiparameter Intelligent Monitoring [14] G. Salton and C. S. Yang. On the specification of term [15] S. Saria, G. McElvain, A. K. Rajani, A. A. Penn, and [16] G. Siontis, I. Tzoulaki, and J. Ioannidis. Predicting [17] J.-L. Vincent, R. Moreno, J. Takala, S. Willatts, Table A.1.
 Table A.1: Patient cohort size at each time tested by time-varying models. Note that patients are removed from a pre-diction time if they are discharged or die prior to that time.
Time (Hours) 0 5784 5157, 627 5597, 187 5058, 726 12 5784 5157, 627 5597, 187 5058, 726 24 5749 5128, 621 5563, 186 5026, 723 36 5563 4998, 565 5382, 181 4855, 708 48 5497 4937, 560 5318, 179 4795, 702 60 5161 4664, 497 4986, 175 4480, 681 72 5084 4591, 493 4911, 173 4407, 677 84 4691 4241, 450 4524, 167 4043, 648 96 4587 4140, 447 4421, 166 3945, 642 108 4116 3710, 406 3963, 153 3530, 586 120 4030 3626, 404 3877, 153 3448, 582 132 3570 3210, 360 3427, 143 3023, 547 144 3496 3141, 355 3354, 142 2956, 540 156 3026 2707, 319 2898, 128 2533, 493 168 2967 2652, 315 2840, 127 2479, 488 180 2580 2291, 289 2468, 112 2138, 442 192 2541 2254, 287 2431, 110 2109, 432 204 2215 1953, 262 2117, 98 1825, 390 216 2186 1925, 261 2090, 96 1802, 384 228 1925 1681, 244 1837, 88 1575, 350 Table A.2.

Table A.3. 1 year post-discharge mortality. This also appears in Figure 3.
