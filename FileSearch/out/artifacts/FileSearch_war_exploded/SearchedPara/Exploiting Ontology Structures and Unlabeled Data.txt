 Maria-Florina Balcan ninamf@cc.gatech.edu Avrim Blum avrim@cs.cmu.edu Yishay Mansour mansour@tau.ac.il Overview In a number of modern applications of ma-chine learning (including text understanding, medical diagnosis, search, and vision), one would like to learn multiple related tasks from primarily, or even solely, unlabeled data. One approach to this task (Carlson et al., 2010b) is to take advantage of known relation-ships among the classes being learned, which are often captured by an ontology ; such an ontology can either be provided by domain experts or learned from past data. In this work, we develop and analyze a theoret-ical model aimed at providing a mathematical under-standing of learning methods of this type.
 More specifically, we propose and analyze a model for the following setting. Suppose we would like to solve L different classification problems, which potentially have very different sets of features, given only a large supply of unlabeled data. In order to help us with this difficult task, we are supplied with an ontology specifying relations among the L categories. For in-stance, this ontology might say that an example to be classified cannot be both a company and a product , or that if someone is an athlete , then they are also a person . The question our model aims to address is how learning these multiple concepts ( company, product, person, athlete, etc.) in parallel , aided by constraints provided by the given ontology, can be done using unlabeled data.
 Motivation A prime example motivating our work is the NELL Never-Ending-Language-Learning sys-tem (Carlson et al., 2010a;b) ( rtw.ml.cmu.edu ) which has had substantial success in learning a wide-range classification of objects in the world from primarily unlabeled data. These include facts such as that am-gen is a biotechcompany , that a porsche boxster is a vehicle and more specifically an automobile-model , etc. It learns propositions such as these start-ing from only a small number of seed instances of each category, by identifying patterns observed on the web and bootstrapping from a large amount of un-labeled data. This bootstrapping is aided by con-straints provided from a given ontology: for example that something cannot be both a person and a com-pany, that an automobile is a special kind of vehicle, and so on. These constraints are used to prevent over-generalization by classifiers for each of the categories. Other examples of this type abound. In medical diag-nosis, we often have readily available known relation-ships concerning the different concepts (corresponding to different diseases) we are trying to learn to predict. For example if a patient presents with chest pain, this might be due to a heart attack or gastroesophageal reflux but very unlikely both; a patient with diabetic neuropathy must also have diabetes. Note that in this setting, different diseases often have different sets of relevant tests (which would lead to different features for the concepts we are trying to learn).
 Another motivating example is machine reliability : given a machine with multiple parts, we want to detect which part failed. The ontology specifies which parts (say, gear wheel) belong to a larger part (say, engine). Again, different tests are often aimed at different parts. Our Results We model a classifier h as an L -tuple ( h 1 ,...,h L ) over the L categories, with each h i providing an up-or-down prediction on category i and each having its own feature space. An ontology R  X  { 0 , 1 } L specifies which L -tuples of labelings are legal and which are not. We can analyze the incom-patibility between a classifier and a given ontology by examining the probability the classifier assigns a label-ing that violates the ontology; we call this its unlabeled error rate . Clearly, this is also a lower bound on its true error rate. Our first result shows that for the ontology in which each example belongs to exactly one category, if L  X  3 and no category is dominant, then for a product distribution (given the labels), unlabeled error is also (up to a factor of 2) an upper bound on true error, for hypotheses that also produce no overly dominant category. This implies that by optimizing on unlabeled data we can find a near optimal hypothesis. Our second result involves the ontology in which each example belongs to at most one category. In this case we find unlabeled error is closely related to false-positive error. As a result, we can achieve a near opti-mal hypothesis by optimizing on unlabeled data sub-ject to both upper and lower bounds on prediction rates for each category.
 Next, we extend these results to the case of a general graph-based ontology described by binary NAND and subset relationships between categories (a NAND rela-tion between categories i,i 0 indicating that an object cannot be both type i and i 0 , and a subset relation in-dicating that an object of type i must also be of type i ), and also relax the independence condition. We show that the classifier of minimum unlabeled error that maximizes a measure we call tightness (that can be estimated from unlabeled data alone) will be a good approximation to the target function. We further give efficient algorithms for the case of discrete domains, corresponding to settings where data within each view falls into a small number of high-quality clusters. Fi-nally, we provide finite sample guarantees, extending VC-dimension to apply to unlabeled error.
 Related Work This type of constraint-aided learning is reminiscent of co-training (Blum &amp; Mitchell, 1998) and multi-view learning more generally (Sridharan &amp; Kakade, 2008; Chapelle et al., 2006; Zhu &amp; Goldberg, 2009); however in those settings the multiple views correspond to a single task, whereas in our framework the views correspond to different tasks related by an ontology. The use of unlabeled error is also related to the semi-supervised learning framework of (Balcan &amp; Blum, 2005). (Cavallanti et al., 2010) study multi-task learning where the tasks have different feature spaces in the context of online supervised learning, and (He &amp; Lawrence, 2011) study multi-task semi-supervised learning where the individual tasks involve multiple views; however, these do not use an ontology among tasks. Empirical work on using ontologies for semi-supervised and unsupervised learning in the NELL sys-tem appears in (Carlson et al., 2010a;b; Verma &amp; Hr-uschka Jr., 2012), and empirical work on learning on-tologies from data appears in (Mohamed et al., 2011). Learning model: We assume there are L categories . Let X = X 1  X  X  X  X  X L be the instance space where X i denotes the instance space for category i . An example is an L -tuple ~x = ( x 1 ,...,x L ) where x i  X  X i . We have a hypothesis class C such that each classifier is ~c = ( c 1 ,...,c L )  X  C L where c i : X i  X  { 0 , 1 } . The classification of ~c of ~x is ~c ( ~x ) = ( c 1 ( x 1 ) ,...,c We assume that the target function c  X   X  C L . Given the target function c  X  , let X + i = { x i  X  X i : c  X  i and X  X  i = { x i  X  X i : c  X  i ( x i ) = 0 } . We assume a joint distribution D over X . For cate-gory i , the distribution D induces on X i is D i . D + and D  X  i are the induced distributions on X + i and X  X  i respectively. Let p i = Pr D ( c  X  i ( x i ) = 1). We will often make the assumption that each category is meaningful (for all i , p i  X   X  for some  X  &gt; 0) and no category is dominant (e.g., p i  X  1 / 3 for all i ).
 Ontology: An ontology R  X  { 0 , 1 } L is the set of legal labelings. We assume that c  X  ( ~x )  X  R for any ~x  X  X . A broad class of ontologies we will focus on are graph based ontologies , where the ontology is given by a graph over the L categories, where each edge corre-sponds to a binary relation between pairs of categories indicating which relations are disallowed. We focus specifically on two relationships: A  X  X AND X  relation-ship ( i,i 0 ) implies that for any z  X  R we never have z = z i 0 = 1. A  X   X   X  relationship ( i,i 0 ) implies that for any z  X  R if z i = 1 then z i 0 = 1. 2.1. Intuition and high-level idea The high-level idea for how the ontology R enables the use of unlabeled data in our model is that it induces a natural notion of the unlabeled error rate of a proposed classifer. Specifically, fixing R , given a classifier h = ( h 1 ,...,h L ), we define In other words, the unlabeled error rate of a classifier h is the probability mass of data for which it assigns an illegal labeling. Since any labeling disallowed by R must also be an incorrect vector of predictions, unla-beled error rate is a lower bound on labeled error rate; that is, err unl ( h )  X  err( h ), where What we will show is that under appropriate assump-tions we can get bounds in the other direction as well. This will imply that unlabeled error rate can be used as a proxy for labeled error rate in a global optimiza-tion procedure. It actually will be a bit more compli-cated than this: for example, a classifier h such that h ( x 1 ) = 1 for every example x , and h i ( x i ) = 0 for all x and all i &gt; 1, would be perfectly consistent with an on-tology that is the complete graph of NAND edges; yet such an h would presumably have high labeled error (so in this case, err unl ( h ) is not at all upper-bounding err( h )). However, notice that in this case we could discard such an h due to violating an assumption that no category is overly dominant. What we will show is that this, and a few other cases that can also be ad-dressed from unlabeled data only, are the only types of obstacles that arise, at least for the portion of err( h ) caused by overgeneralizing. This motivates algorithms that aim to generalize as much as possible subject to the ontology and category constraints.
 Of course, the ease or difficulty of optimizing for low unlabeled error rate depends on the form of the clas-sifiers. After discussing general results under the as-sumption of an optimization oracle, we then consider a more specific cluster-based setting where we will be able to solve this problem efficiently. In this section we analyze the relationship between un-labeled and labeled error rates under natural condi-tions. We begin by assuming data satisfies indepen-dence given the labeling (IGL). In Section 3.3 we will relax that assumption to a notion of weak dependence. We begin by considering the ontology R 1 where ev-ery example is positive for exactly one of the L cat-egories. For this ontology we have P i p i = 1 and under IGL we can view the generation of examples as follows. Examples are drawn by first selecting a label i  X  ( p 1 ,...,p L ), and then selecting x i 0  X  D for each i 0 6 = i and selecting x i  X  D + i . We will then relax this to a complete graph of NAND edges (ev-ery example positive for at most one category), i.e., R 01 = { z  X  { 0 , 1 } L , P i z i  X  1 } . Finally we will relax it to an arbitrary ontology of NAND and  X   X   X  edges, subject only to very mild conditions such as each cate-gory having at least one incident edge and each relation being nontrivial (see Section 3.3).
 For a hypothesis h = ( h 1 ,...,h L ), for a,b  X  X  0 , 1 } , we define p i,a | b as the probability that h i ( x i ) = a given that c  X  i ( x i ) = b . 3.1. Each example positive for exactly one For ontology R 1 , where each example is positive for exactly one category, we have: err unl ( h ) = Pr x  X  D [ h i ( x ) = 0 for all i OR  X  i 6 = i 0 s . t . h 1 ,h i 0 ( x ) = 1] .
 As a warmup we begin by analyzing the case that the different views all look like identical copies of the same learning problem. In particular, D 1 = ... = D L and c = ... = c  X  L , and D satisfies independence given the labeling. We call this the independent-identical model. In this case we can shorten the notation p i,a | b to simply p a | b . We will show that for ontology R 1 , if err( h )  X  then err unl ( h ) =  X ( ). That is, all the hypotheses of large labeled error rate have large unlabeled error rate as well, and thus these hypotheses can be discarded by using unlabeled examples.
 To get an intuition of why this might be true note that simplicity assume below that  X   X  1. 1 We will consider a few cases based on p 1 | 0 and p case we will consider the probability of having at least two positive predictions, which is, Now we consider the case that p 0 | 1  X   X / 2. Consider the unlabeled accuracy, namely the probability of hav-ing a single positive label, Since this is decreasing with p 0 | 1 , the unlabeled accu-racy is at most 1  X  (  X / 2) + (  X / 2)(  X   X   X / 2). So, the unlabeled error rate is at least  X / 2  X   X  2 / 4  X   X / 4  X  err( h ) / 4. We have derived the following theorem. Theorem 1 In the independent-identical model with ontology R 1 and L  X  3 , if err( h )  X  then err unl ( h ) =  X ( ) .
 We now remove the (artificial) restriction that all the D i and D that p i  X  1 / 3 can be viewed as requiring that we need at least three non-trivial categories.
 Theorem 2 For ontology R 1 , if D satisfies IGL and we have p i  X  1 / 3 and Pr [ h i = 1]  X  1 / 3 for all i , then err unl ( h )  X  err( h ) / 2 .
 Proof: Let us write the labeled error rate as: The unlabeled error rate is, err unl ( h ) = err( h )  X  X Intuitively, the difference between the unlabeled error rate and the true error rate are the cases when we have an outcome with a single one, but it is the incorrect one. We would like to lower bound the ratio between the unlabeled error rate and the true error rate, i.e., err unl ( h ) err( h ) F ( x 1 ,y 1 ,...,x L ,y L ) = For each i , the function F is increasing in x i , so it will get its maximum value at 1 (the maximum value of x i ). This implies that we need to maximize
G ( y 1 ,...,y L ) = X Since each p i  X  1 / 3 and h i is 1 with probability at most 1 / 3 then p i, 1 | 0  X  1 / 2.
 We know that the maximizing solution to G out of all y  X  [0 , 1 / 2] will have a certain number, say k , of y  X  X  equal 1 / 2 and the rest are zero. Therefore, This implies that err unl ( h ) / err( h )  X  1 2 . 3.2. Each example positive for at most one We now consider the more general ontology R 01 , which allows for the all-negative labeling. We start with the following important lemma, that relates the error of switching 0 to 1, with some  X  X bservable event X . Lemma 3 Given ontology R 01 , assume D satisfies IGL and that P i p i = 1  X   X   X  3 / 4 , and p i  X  1 / 4 for all i . Consider a hypothesis h such that P i p i, 1 | 0 Then, for any  X   X  1 / 4 one of the following holds: (1) the probability of two or more positive labels is at least  X  (1  X   X   X   X  ) / 6000 (2) The probability the hypothesis h predicts all categories negative is more than  X  +  X  , or (3) for some category i , the probability that h i ( x i ) = 1 is at least 0 . 982(1  X   X   X   X  ) Proof: Assume that the probability that h predicts all categories negative is at most  X  +  X  (otherwise we are done). Let s = arg max i p i, 1 | 0 . We consider two cases depending on the magnitude of p s, 1 | 0 . In the first case, where p s, 1 | 0 &lt;  X / 6, we show that the unlabeled error rate is significant. In the second case, where p s, 1 | 0  X   X / 6, we show that either the unlabeled error rate is significant or that h predicts positive in category s with a very high probability.
 Case 1: Assume p s, 1 | 0 &lt;  X / 6. Then we can partition the categories into three subsets S 1 , S 2 and S 3 such one of the three sets we have P i  X  S assume that this is S 1 . Then the probability that the true label is in S 1 and in each other set we have at least one positive label (and hence at least two positive labels overall) is at least, ( X where the first inequality uses the fact that having k independent events of probability q j each implies that the probability some event occurs is at least P j q j /e . This implies that the probability of an unlabeled error in this case is  X (  X  2 (1  X   X   X   X  )).
 Case 2: Assume that p s, 1 | 0  X   X / 6. Then  X   X  6. Con-sider the probability of observing a 1 in s and also a label 1 in some i 6 = s . Note that the probability that c ( x ) = 0 is at least 3 / 4. The only way the unlabeled error rate can be less than  X  2 (1  X   X   X   X  ) / 6000 is if Namely, given that c  X  s ( x ) = 0, the probability of pre-dicting 1 in any i 6 = s is at most the above bound. Since  X   X  6 this implies that the probability that h s = 1 is at least 1  X  Pr [  X  ih i ( x ) = 0]  X  err unl ( h )  X  &gt; 0 . 982(1  X   X   X   X  ).
 Unlike the case of the ontology R 1 , for R 01 there can be a hypothesis that has zero unlabeled error and a very high labeled error: for example, a hypothesis that pre-dicts negative always for every category. To overcome this, we will focus on a set of  X  X lausible X  hypothe-ses. Let Good (  X , X  ) be the set of hypotheses h  X  C such that Pr [  X  ih i ( x i ) = 0]  X   X  and for any category Pr [ h i ( x i ) = 1]  X   X  .
 Theorem 4 Suppose P i p i = 1  X   X   X  4 / 5 and for any i we have p i  X   X  = 1 / 5 . If h  X  Good (  X  + / 20 , X  + / 20) and err( h )  X  then err unl ( h ) =  X ( 2 ) . In addition Good (  X  + / 20 , X  + / 20) 6 =  X  .
 Proof: First, note that c  X   X  Good (  X , X  ). Now, consider h  X  Good (  X  + / 20 , X  + / 20) and let P i p i, 1 | 0 =  X  . Assume that err( h )  X  . We consider two cases de-pending on the value of  X  .
 Case 1: Assume  X   X  0 . 25 . By Lemma 5, with  X  = / 20, we have three possible outcomes: (1) the probability of two or more positive labels is  X  2 (1  X   X   X  / 20) / 6000, (2) The probability that h predicts all categories negative is more than  X  + / 20, or (3) for some category i , the probability that h i ( x i ) = 1 is at least 0 . 982(1  X   X   X  / 20).
 Since h  X  Good (  X  + / 20 , X  + / 20), outcome (2) is impossible. For outcome (3), since  X  + / 20  X  1 / 5 + 1 / 20 = 1 / 4, then 0 . 982(1  X   X   X  / 20) &gt; 0 . 7. Since the probability that h  X  Good (  X  + / 10 , X  + / 10) labels any category positive is at most  X  + / 20 = 1 / 4 &lt; 0 . 7, outcome (3) is also impossible. Therefore, the unlabeled error rate of h is  X (  X  2 (1  X   X   X  / 20)) =  X ( 2 Case 2: Assume  X  &lt; 0 . 25 . Since err( h )  X  , this implies that  X  = P i p i p i, 0 | 1  X  0 . 75 . The probability that h predicts negative in all categories is at least  X   X   X  +  X  &gt;  X   X  0 . 25 + 0 . 75 =  X  + 0 . 5 , which is a contradiction that h  X  Good (  X  + / 20 , X  + / 20). 3.3. General Graph-Based Ontologies The previous analysis demonstrated an extremely tight connection between labeled and unlabeled error, allowing for learning from unlabeled examples only, and moreover (see Section 4) from a number of unla-beled examples not much larger than the sample com-plexity of supervised learning. However, these results required an ontology such that any example is positive for at most one category. They also assumed full inde-pendence given the labeling. In this section we extend these results to show we can learn from purely unla-beled data given an arbitrary graph based ontology of NAND and  X   X   X  edges, subject only to the following conditions on the ontology and the distribution: (1) For some given  X  &gt; 0, we have  X   X  p i  X  1  X   X  for (2) The ontology has no isolated vertices. That is, for (3) For some given  X  2 &gt; 0, for any edge ( i,i 0 ) in the Finally, we replace independence given the labeling with the following much weaker condition related to the  X  X eak dependence X  of (Abney, 2002): (4) For some given  X  &gt; 0, for any edge ( i,i 0 ), any For additional intuition, conditions (2) and (3) above would be satisfied if every category were contained in a triangle of NAND edges. 2 Under the above conditions we will still be able to learn from unlabeled data only. However, we will need a larger sample size than for a complete graph. In order to describe the algorithm and present its anal-ysis, we need a few more definitions. First, if category i has either an incident NAND edge or an incident  X   X   X  edge for which it is on the subset-side, say that it is positive-constrained (because the ontology is limiting when it can be positive). If category i has an inci-dent  X   X   X  edge for which it is on the superset-side, we say that it is negative-constrained (because the ontol-ogy is limiting when it can be negative). Note that by condition (2) above, for every category at least one applies. If both cases apply to some category i , then for convenience we will just call it positive-constrained. Let cat + denote the set of positive-constrained cate-gories and cat  X  denote the set of negative-constrained categories. We now define how tightly constrained a hypothesis h = ( h 1 ,...,h L ) is as: tightness ( h ) =
X Finally, for a NAND edge ( i,i 0 ) define err unl ( h,i,i define err unl ( h,i,i 0 ) = Pr D [ h i ( x ) = 1  X  h i 0 The optimization procedure for learning from unla-beled data is now simply this: given an unlabeled sam-ple S , find the most tightly constrained hypothesis h possible (maximizing tightness ( h )) subject to satisfy-ing  X   X  Pr [ h i ( x i ) = 1]  X  1  X   X  for all i and h having zero empirical unlabeled error over S . To analyze this procedure, we begin with two key lemmas.
 Lemma 5 For a NAND edge ( i,i 0 ) , for any h : Proof: We will expand err unl ( h,i,i 0 ) by looking at two conditions (3) and (4) of our assumptions to achieve our desired lower bound. For compactness of notation, let  X  c  X  ii 0 = ab  X  denote the event  X  c  X  i ( x i ) = a  X  c b  X , and similarly for h ii 0 . Then we have: err unl ( h,i,i 0 ) = Pr [ h i = 1  X  h i 0 = 1]  X  Pr [ c  X  ii 0 = 01]  X  Pr [ h i = 1 | c  X  ii 0 = 01]  X   X   X  2 (  X  Pr [ h i = 1 | c  X  i = 0]  X   X  Pr [ h i 0 = 1 | c
The first inequality above is from considering just two of the three possible settings of c  X  i ( x i ) and c the second comes from applying condition (3) to the events involving c and (4) to the events involving h , and finally the last inequality is using Pr [ h i 0 = 1]  X  Lemma 6 For a  X   X   X  edge ( i,i 0 ) , for any h we have: Proof: Using conditions (3) and (4) as in the proof of Lemma 5, we can expand err unl ( h,i,i 0 ) as: We also similarly have: We now use these to show that for any plausible hy-pothesis h (one such that  X   X  Pr [ h i ( x i ) = 1]  X  1  X   X  for all i ), if h has high error then either its unlabeled error will be high or else its tightness will be low com-pared to the target function. This then will imply that maximizing tightness subject to low unlabeled error must lead to a hypothesis of low labeled error. Theorem 7 Suppose  X   X  Pr [ h i ( x i ) = 1]  X  1  X   X  for all i . If err( h )  X  then either err unl ( h )  X   X  X  2  X  2 / (4 L ) or tightness ( h )  X  tightness ( c )  X  / 2 . Proof: Suppose err( h )  X  . We have three cases. Case 1: Suppose for some positive-constrained cate-gory i , we have p i, 1 | 0  X  4 L . By definition of positive-constrained, there must be some NAND or  X   X   X  edge ( i,i 0 ). So, by Lemmas 5 and 6, we have err unl ( h )  X  err unl ( h,i,i 0 )  X   X  2  X  2 ( 4 L )  X  =  X  X  2  X  2 / (4 L ). Case 2: Suppose for some negative-constrained cat-egory i 0 , we have p i 0 , 0 | 1  X  4 L . By definition of negative-constrained, there must be some  X   X   X  edge ( i,i 0 ). So, by Lemma 6, we again have err unl err unl ( h,i,i 0 )  X   X  2  X  2 ( 4 L )  X  =  X  X  2  X  2 / (4 L ). Case 3: Suppose neither of the above two cases oc-have: Therefore, since err( h )  X  , Putting these together we have: tightness ( c )  X  tightness ( h ) as desired. 3.4. Implications We now show how the above results can be used to analyze an idealized form of a natural iterative learn-ing algorithm motivated by algorithms used in systems such as NELL (Carlson et al., 2010a;b).
 We consider here the same asumptions (1-4) used in Section 3.3 and additionally assume each category is incident to at least one NAND edge. Define a hy-pothesis h i to be  X  X afe X  if h i  X  c  X  i , i.e., p i, 1 | 0 Say that g i is an  X   X  1 -extension X  of h i if h i  X  g i and Pr [ g i = 1]  X  Pr [ h i = 1] +  X  1 . We now consider the following idealized iterative learning procedure. Let  X  , X  1 &gt; 0 and k  X  Z + . Suppose: 1. Given an initial set of positive labeled examples for 2. For any category i such that p i, 0 | 1  X   X  1 (i.e., we 3. The procedure then is just to greedily replace any Corollary 8 The above procedure correctly maintains safe hypotheses and halts after at most L/ X  1 steps with a hypothesis of total error at most L X  1 .
 Proof: Assume inductively that h 1 ,...,h L are safe and suppose g j i is not a safe extension of h i . We are given that category i is connected by a NAND edge to at least one other category i 0 . Since Pr [ h i 0 = 1]  X   X  Lemma 5 we have err unl ( h,i,i 0 )  X   X  2  X  2  X  1  X  0 any unsafe extension will not be taken. On the other hand, if g j i is a safe extension, then replacing h i with g maintains the inductive property that h 1 ,...,h L are safe and thus no NAND edge will incur unlabeled error. So the algorithm will not halt until no safe extension exists, which happens only if total error  X  L X  1 . In this section we derive bounds relating empirical un-labeled error to true unlabeled error, in order to apply the results of Section 3 to finite sample sizes. To do so we will analyze the VC dimension of the unlabeled error sets.
 We start with the identical-independent model. Re-call that in this setting we select only a single hypoth-esis h  X  C . We need to compute the VCdim( C,L ) which is the VC dimension when we have L points for each example. Recall that a point is an L -tuple ~x = ( x 1 ,...,x L ). We first need to define ` ( h,~x ), the loss of h on ~x . Let R be an ontology, i.e., the set of legal label-ings. We define ` ( h,~x ) = 0 if ( h ( x 1 ) ,...,h ( x and otherwise it is 1.
 Theorem 9 Let d = VCdim( C ) . For any ontology R we have VCdim( C,L ) = O ( d log L ) .
 Proof: Consider a set T = { ~x 1 ,...,~x m } that C shat-ters. Let S = { x | X  i,x  X  ~x i } be the set of inputs which appear in some category. Clearly, | S |  X  Lm . By Sauer X  X  lemma we have that the number of differ-ent labelings of the set S is at most ( mL ) d . Any such labeling can induce at most one labeling on the points in T . Therefore, for T to be shattered we need that 2 m  X  ( mL ) d , which implies that m = O ( d log L ). It is worth noting that there is indeed a difference be-tween VCdim( C,L ) and VCdim( C ).
 Claim 1 Consider the class TH 1 the threshold functions on [0 , 10] . Then VCdim( TH 1 ) = VCdim( TH 1 , 1) = 1 and VCdim( TH 1 , 2) = 2 . Proof: We show that for L = 2, TH 1 shatters 2 points. Consider x 1 = (0 . 5 , 4) and x 2 = (2 , 6). For  X  = 8 the  X  = 5 the labeling is (0 , 1), and for  X  = 0 the labeling is (0 , 0). Therefore TH 1 shatters { x 1 ,x 2 } . The fact that no three points is shattered can be shown by case analysis.
 We can now use Theorem 9 to derive generalization bounds based on Theorem 1. The result follows since the observed unlabeled error rate is close to the true unlabeled error rate, given our bound on the VC di-mension.
 Corollary 10 In the independent-identical model with ontology R 1 and L  X  3 , a sample of m u = O 1 VCdim( C ) log L ln 1 + ln 1  X  unlabeled ex-amples (and no labeled examples) are sufficient to achieve error  X  . In particular, with probability 1  X   X  , all h with h 1 = ... = h L  X  C satisfying have err( h )  X  .
 We now need to derive a generalization bound for the general case, that will relate the observed and the true unlabeled error rates. The main difference is that we consider the hypothesis class C L where each hypoth-esis is ~ h = ( h 1 ,...,h L ) and h i  X  C . As before, the examples are L -tuples ~x = ( x 1 ,...,x L ) and the loss is ` defined using the set R of legal labelings. (The the-orem holds for any ontology R .) We need to compute the VCdim( C L ,L ).
 Theorem 11 Let d = VCdim( C ) . For any ontology R we have VCdim( C L ,L ) = O ( dL log dL ) .
 Proof: Consider a set T = { ~x 1 ,...,~x m } that C L shat-ters, where ~x i = ( x i, 1 ,...,x i,L ). Let T j = { x i,j j  X  L } be the set of inputs which appear in category i . By Sauer X  X  lemma we have that the number of dif-ferent labelings by C for T j is at most m d , and hence the total number of labelings for T using C L is at most m dL . Therefore, for T to be shattered we need that 2 m  X  m dL , which implies that m = O ( dL log dL ). We can therefore derive the following.
 Corollary 12 Consider ontology R 1 , and assume p i  X  1 / 3 and Pr [ h i = 1]  X  1 / 3 for all i . Then, m u = O 1 dL log( dL ) ln 1 + ln( 1  X  ) unlabeled ex-amples (and no labeled examples) are sufficient to achieve error  X  , where d = VCdim( C ) . In particu-lar, with probability 1  X   X  , all h  X  C L with have err( h )  X  .
 We now consider the difference between the observed tightness ( h ), denoted by \ tightness ( h ), and the true tightness ( h ). The following theorem follows by con-sidering a generalization bound for each category, inde-pendently, and using the union bound over categories. Theorem 13 For an unlabeled sample size we have that with probability 1  X   X  , for any h  X  C we have | tightness ( h )  X  \ tightness ( h ) | X  . In this section, we assume the different domains X are discrete and small: specifically, X i = { 1 ,...,N } , where N is not too large, and let class C consist of all boolean functions over N elements. For example, this could model data satisfying the condition that points within each view can be easily grouped into at most N clusters, with each cluster having a single label. Note that even though we view N as small, the total number of examples possible is N L and could be quite large. Our goal here will be to learn from unlabeled data using time and samples polynomial in N and L .
 We will assume here the same conditions (1-4) used in Section 3.3, namely (1) each category has at least some nonnegligible probability mass  X  , (2) the ontol-ogy graph has no isolated vertices, (3) for any edge ( i,i 0 ), any pair of labels not disallowed by the ontol-ogy has probability mass at least  X  2 , and (4) weak dependence. We begin with the following lemma. Lemma 14 For any edge ( i,j ) of the ontology, any pair of labels ` i ,` j not disallowed by this edge, and any pair of values a i ,a j s.t. c  X  i ( a i ) = ` i and c  X  j
Pr [ x i = a i ,x j = a j | c  X  i = ` i ,c  X  j = ` j ] Proof: Since C contains all boolean functions over { 1 ,...,N } , using condition (4) we have:
Pr [ x i = a i ,x j = a j | c  X  i = ` i ,c  X  j = ` j ] We now present the algorithm, using Lemma 14. The idea is simple. First, we sample enough unlabeled ex-amples. Next, examine each edge ( i,j ) of the ontology graph. For each such edge, if two values that indi-vidually have reasonably high probability mass never co-occur, then this must be because they form the dis-allowed labeling for that edge (e.g., both are positive if it is a NAND edge or the first is positive and the second is negative for a subset edge).
 Algorithm LearnDiscrete : Given error bound , confidence bound  X  , values  X , X  2 : 1. Let 0 = min( , X L ). Draw a sample S of m = 2. Define  X  p i ( a i ) to be the empirical frequency of a 3. Let T i include all values if X i that have empirical 4. For each NAND edge ( i,j ), for each a i  X  T i and 5. For each category i , for each value a i  X  X i The following theorem shows that the error rate of the algorithm is low.
 Theorem 15 Under assumptions (1-4) of Section 3.3, Algorithm LearnDiscrete produces a labeling of the domain with error at most with probability 1  X   X  . Proof: First, condition (1) implies that each category must have at least one positive value a i of probability at least  X /N  X  0 / ( NL ) and at least one negative value a i of probability at least  X /N  X  0 / ( NL ). By Cher-noff bounds, the sample size m is sufficient so that with probability 1  X   X / 2, all values with probability at least the sets T i , and furthermore no values with probability less than 0 / (4 NL ) will fall into the sets T i . Assume for the remainder of the argument that this indeed is the case. This in turn implies that in step 4, in each category i incident to a NAND edge or on the subset side of a  X   X   X  edge, Algorithm LearnDiscrete cor-rectly marks all positive values a i of probability mass at least 0 / ( NL ) as positive , and in each category i on the superset side of a  X   X   X  edge, the algorithm correctly marks all negative values a i of probability at least 0 / ( NL ) as negative .
 Next, ignore all values not in sets T i since together they have probability at most . For the remain-der, we need to show that with probability at least 1  X   X / 2 we correctly mark the negative values a i in positive-constrained categories and the positive val-ues in negative-constrained categories. (We may ig-nore categories that are both positive-and negative-constrained since they are covered by the previous analysis.) For this, we use Lemma 14. Specificially, pick one such a i  X  T i . Consider any edge ( i,j ) and any a j  X  T j . By definition, ( a i ,a j ) is not disallowed by the ontology, so, by condition (3), the probabil-ity of the associated labeling is at least  X  2 . There-fore, the probability of observing the pair ( a i ,a at least  X  2  X  2 ( 0 / (4 NL )) 2 by Lemma 14. The sample size m is therefore sufficient so that with probability at least 1  X   X / (2 N 2 L 2 ), we indeed have  X  p ij ( a i Applying the union bound, with high probability all such pairwise events occur. Therefore, such values a i are marked only in step 5 of the algorithm and so are marked correctly. It would be interesting to extend the results of Sec-tion 3.4 to remove the assumption that extensions will never be  X  X arely safe X , as well as to extend these re-sults (using perhaps a different idealized algorithm) to the case where not all categories are incident to a NAND edge. It would also be of interest to further weaken the limited independence conditions used in Section 3.3.
 This work was supported in part by NSF grants CCF-0953192, CCF-1116892, and IIS-1065251, AFOSR grant FA9550-09-1-0538, ONR grant N00014-09-1-0751, by a Microsoft Faculty Fellowship, and by grants from the Israel Science Foundation, the US-Israel Bi-national Science Foundation, the Israeli Ministry of Science and the Israeli Centers of Research Excellence (I-CORE) program (Center No. 4/11). We thank Tong Zhang and Lev Reyzin for early discussions on mod-els of multiple-task learning, and Tom Mitchell for a number of exciting discussions of the NELL system. Abney, S. Bootstrapping. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics , ACL  X 02, pp. 360 X 367, 2002.
 Balcan, M.-F. and Blum, A. A PAC-style model for learning from labeled and unlabeled data. In Pro-ceedings of the 18th Annual Conference on Compu-tational Learning Theory (COLT) , 2005.
 Blum, A. and Mitchell, T. Combining labeled and unlabeled data with co-training. In The 11th An-nual Conference on Computational Learning Theory (COLT) , 1998.
 Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hr-uschka Jr., E. R., and Mitchell, T.M. Toward an architecture for never-ending language learning. In AAAI , 2010a.
 Carlson, A., Betteridge, J., Wang, R. C., Hruschka Jr.,
E.R., and Mitchell, T.M. Coupled semi-supervised learning for information extraction. In Proceedings of the Third ACM International Conference on Web Search and Data Mining , 2010b.
 Cavallanti, G., Cesa-Bianchi, N., and Gentile, C. Lin-ear algorithms for online multitask classification.
Journal of Machine Learning Research , 11:2901 X  2934, 2010.
 Chapelle, O., Sch  X olkopf, B., and Zien, A. (eds.). Semi-
Supervised Learning . MIT Press, Cambridge, MA, 2006. URL http://www.kyb.tuebingen.mpg.de/ ssl-book .
 He, Jingrui and Lawrence, Rick. A graphbased frame-work for multi-task multi-view learning. In ICML , pp. 25 X 32, 2011.
 Mohamed, T., Hruschka Jr., E.R., and Mitchell, T. Discovering relations between noun categories. In Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing , pp. 1447 X  1455, July 2011.
 Sridharan, K. and Kakade, S.M. An information the-oretic framework for multi-view learning. In COLT , pp. 403 X 414, 2008.
 Verma, S. and Hruschka Jr., E.R. Coupled bayesian sets algorithm for semi-supervised learning and in-formation extraction. In Proceedings of the European
Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD 2012) , Bristol, UK, September 2012.
 Association for Computing Machinery.
 Zhu, Xiaojin and Goldberg, Andrew B. Introduction to Semi-Supervised Learning . Synthesis Lectures on
Artificial Intelligence and Machine Learning. Mor-
 Maria-Florina Balcan ninamf@cc.gatech.edu Avrim Blum avrim@cs.cmu.edu Yishay Mansour mansour@tau.ac.il Overview In a number of modern applications of ma-chine learning (including text understanding, medical diagnosis, search, and vision), one would like to learn multiple related tasks from primarily, or even solely, unlabeled data. One approach to this task (Carlson et al., 2010b) is to take advantage of known relation-ships among the classes being learned, which are often captured by an ontology ; such an ontology can either be provided by domain experts or learned from past data. In this work, we develop and analyze a theoret-ical model aimed at providing a mathematical under-standing of learning methods of this type.
 More specifically, we propose and analyze a model for the following setting. Suppose we would like to solve L different classification problems, which potentially have very different sets of features, given only a large supply of unlabeled data. In order to help us with this difficult task, we are supplied with an ontology specifying relations among the L categories. For in-stance, this ontology might say that an example to be classified cannot be both a company and a product , or that if someone is an athlete , then they are also a person . The question our model aims to address is how learning these multiple concepts ( company, product, person, athlete, etc.) in parallel , aided by constraints provided by the given ontology, can be done using unlabeled data.
 Motivation A prime example motivating our work is the NELL Never-Ending-Language-Learning sys-tem (Carlson et al., 2010a;b) ( rtw.ml.cmu.edu ) which has had substantial success in learning a wide-range classification of objects in the world from primarily unlabeled data. These include facts such as that am-gen is a biotechcompany , that a porsche boxster is a vehicle and more specifically an automobile-model , etc. It learns propositions such as these start-ing from only a small number of seed instances of each category, by identifying patterns observed on the web and bootstrapping from a large amount of un-labeled data. This bootstrapping is aided by con-straints provided from a given ontology: for example that something cannot be both a person and a com-pany, that an automobile is a special kind of vehicle, and so on. These constraints are used to prevent over-generalization by classifiers for each of the categories. Other examples of this type abound. In medical diag-nosis, we often have readily available known relation-ships concerning the different concepts (corresponding to different diseases) we are trying to learn to predict. For example if a patient presents with chest pain, this might be due to a heart attack or gastroesophageal reflux but very unlikely both; a patient with diabetic neuropathy must also have diabetes. Note that in this setting, different diseases often have different sets of relevant tests (which would lead to different features for the concepts we are trying to learn).
 Another motivating example is machine reliability : given a machine with multiple parts, we want to detect which part failed. The ontology specifies which parts (say, gear wheel) belong to a larger part (say, engine). Again, different tests are often aimed at different parts. Our Results We model a classifier h as an L -tuple ( h 1 ,...,h L ) over the L categories, with each h i providing an up-or-down prediction on category i and each having its own feature space. An ontology R  X  { 0 , 1 } L specifies which L -tuples of labelings are legal and which are not. We can analyze the incom-patibility between a classifier and a given ontology by examining the probability the classifier assigns a label-ing that violates the ontology; we call this its unlabeled error rate . Clearly, this is also a lower bound on its true error rate. Our first result shows that for the ontology in which each example belongs to exactly one category, if L  X  3 and no category is dominant, then for a product distribution (given the labels), unlabeled error is also (up to a factor of 2) an upper bound on true error, for hypotheses that also produce no overly dominant category. This implies that by optimizing on unlabeled data we can find a near optimal hypothesis. Our second result involves the ontology in which each example belongs to at most one category. In this case we find unlabeled error is closely related to false-positive error. As a result, we can achieve a near opti-mal hypothesis by optimizing on unlabeled data sub-ject to both upper and lower bounds on prediction rates for each category.
 Next, we extend these results to the case of a general graph-based ontology described by binary NAND and subset relationships between categories (a NAND rela-tion between categories i,i 0 indicating that an object cannot be both type i and i 0 , and a subset relation in-dicating that an object of type i must also be of type i ), and also relax the independence condition. We show that the classifier of minimum unlabeled error that maximizes a measure we call tightness (that can be estimated from unlabeled data alone) will be a good approximation to the target function. We further give efficient algorithms for the case of discrete domains, corresponding to settings where data within each view falls into a small number of high-quality clusters. Fi-nally, we provide finite sample guarantees, extending VC-dimension to apply to unlabeled error.
 Related Work This type of constraint-aided learning is reminiscent of co-training (Blum &amp; Mitchell, 1998) and multi-view learning more generally (Sridharan &amp; Kakade, 2008; Chapelle et al., 2006; Zhu &amp; Goldberg, 2009); however in those settings the multiple views correspond to a single task, whereas in our framework the views correspond to different tasks related by an ontology. The use of unlabeled error is also related to the semi-supervised learning framework of (Balcan &amp; Blum, 2005). (Cavallanti et al., 2010) study multi-task learning where the tasks have different feature spaces in the context of online supervised learning, and (He &amp; Lawrence, 2011) study multi-task semi-supervised learning where the individual tasks involve multiple views; however, these do not use an ontology among tasks. Empirical work on using ontologies for semi-supervised and unsupervised learning in the NELL sys-tem appears in (Carlson et al., 2010a;b; Verma &amp; Hr-uschka Jr., 2012), and empirical work on learning on-tologies from data appears in (Mohamed et al., 2011). Learning model: We assume there are L categories . Let X = X 1  X  X  X  X  X L be the instance space where X i denotes the instance space for category i . An example is an L -tuple ~x = ( x 1 ,...,x L ) where x i  X  X i . We have a hypothesis class C such that each classifier is ~c = ( c 1 ,...,c L )  X  C L where c i : X i  X  { 0 , 1 } . The classification of ~c of ~x is ~c ( ~x ) = ( c 1 ( x 1 ) ,...,c We assume that the target function c  X   X  C L . Given the target function c  X  , let X + i = { x i  X  X i : c  X  i and X  X  i = { x i  X  X i : c  X  i ( x i ) = 0 } . We assume a joint distribution D over X . For cate-gory i , the distribution D induces on X i is D i . D + and D  X  i are the induced distributions on X + i and X  X  i respectively. Let p i = Pr D ( c  X  i ( x i ) = 1). We will often make the assumption that each category is meaningful (for all i , p i  X   X  for some  X  &gt; 0) and no category is dominant (e.g., p i  X  1 / 3 for all i ).
 Ontology: An ontology R  X  { 0 , 1 } L is the set of legal labelings. We assume that c  X  ( ~x )  X  R for any ~x  X  X . A broad class of ontologies we will focus on are graph based ontologies , where the ontology is given by a graph over the L categories, where each edge corre-sponds to a binary relation between pairs of categories indicating which relations are disallowed. We focus specifically on two relationships: A  X  X AND X  relation-ship ( i,i 0 ) implies that for any z  X  R we never have z = z i 0 = 1. A  X   X   X  relationship ( i,i 0 ) implies that for any z  X  R if z i = 1 then z i 0 = 1. 2.1. Intuition and high-level idea The high-level idea for how the ontology R enables the use of unlabeled data in our model is that it induces a natural notion of the unlabeled error rate of a proposed classifer. Specifically, fixing R , given a classifier h = ( h 1 ,...,h L ), we define In other words, the unlabeled error rate of a classifier h is the probability mass of data for which it assigns an illegal labeling. Since any labeling disallowed by R must also be an incorrect vector of predictions, unla-beled error rate is a lower bound on labeled error rate; that is, err unl ( h )  X  err( h ), where What we will show is that under appropriate assump-tions we can get bounds in the other direction as well. This will imply that unlabeled error rate can be used as a proxy for labeled error rate in a global optimiza-tion procedure. It actually will be a bit more compli-cated than this: for example, a classifier h such that h ( x 1 ) = 1 for every example x , and h i ( x i ) = 0 for all x and all i &gt; 1, would be perfectly consistent with an on-tology that is the complete graph of NAND edges; yet such an h would presumably have high labeled error (so in this case, err unl ( h ) is not at all upper-bounding err( h )). However, notice that in this case we could discard such an h due to violating an assumption that no category is overly dominant. What we will show is that this, and a few other cases that can also be ad-dressed from unlabeled data only, are the only types of obstacles that arise, at least for the portion of err( h ) caused by overgeneralizing. This motivates algorithms that aim to generalize as much as possible subject to the ontology and category constraints.
 Of course, the ease or difficulty of optimizing for low unlabeled error rate depends on the form of the clas-sifiers. After discussing general results under the as-sumption of an optimization oracle, we then consider a more specific cluster-based setting where we will be able to solve this problem efficiently. In this section we analyze the relationship between un-labeled and labeled error rates under natural condi-tions. We begin by assuming data satisfies indepen-dence given the labeling (IGL). In Section 3.3 we will relax that assumption to a notion of weak dependence. We begin by considering the ontology R 1 where ev-ery example is positive for exactly one of the L cat-egories. For this ontology we have P i p i = 1 and under IGL we can view the generation of examples as follows. Examples are drawn by first selecting a label i  X  ( p 1 ,...,p L ), and then selecting x i 0  X  D for each i 0 6 = i and selecting x i  X  D + i . We will then relax this to a complete graph of NAND edges (ev-ery example positive for at most one category), i.e., R 01 = { z  X  { 0 , 1 } L , P i z i  X  1 } . Finally we will relax it to an arbitrary ontology of NAND and  X   X   X  edges, subject only to very mild conditions such as each cate-gory having at least one incident edge and each relation being nontrivial (see Section 3.3).
 For a hypothesis h = ( h 1 ,...,h L ), for a,b  X  X  0 , 1 } , we define p i,a | b as the probability that h i ( x i ) = a given that c  X  i ( x i ) = b . 3.1. Each example positive for exactly one For ontology R 1 , where each example is positive for exactly one category, we have: err unl ( h ) = Pr x  X  D [ h i ( x ) = 0 for all i OR  X  i 6 = i 0 s . t . h 1 ,h i 0 ( x ) = 1] .
 As a warmup we begin by analyzing the case that the different views all look like identical copies of the same learning problem. In particular, D 1 = ... = D L and c = ... = c  X  L , and D satisfies independence given the labeling. We call this the independent-identical model. In this case we can shorten the notation p i,a | b to simply p a | b . We will show that for ontology R 1 , if err( h )  X  then err unl ( h ) =  X ( ). That is, all the hypotheses of large labeled error rate have large unlabeled error rate as well, and thus these hypotheses can be discarded by using unlabeled examples.
 To get an intuition of why this might be true note that simplicity assume below that  X   X  1. 1 We will consider a few cases based on p 1 | 0 and p case we will consider the probability of having at least two positive predictions, which is, Now we consider the case that p 0 | 1  X   X / 2. Consider the unlabeled accuracy, namely the probability of hav-ing a single positive label, Since this is decreasing with p 0 | 1 , the unlabeled accu-racy is at most 1  X  (  X / 2) + (  X / 2)(  X   X   X / 2). So, the unlabeled error rate is at least  X / 2  X   X  2 / 4  X   X / 4  X  err( h ) / 4. We have derived the following theorem. Theorem 1 In the independent-identical model with ontology R 1 and L  X  3 , if err( h )  X  then err unl ( h ) =  X ( ) .
 We now remove the (artificial) restriction that all the D i and D that p i  X  1 / 3 can be viewed as requiring that we need at least three non-trivial categories.
 Theorem 2 For ontology R 1 , if D satisfies IGL and we have p i  X  1 / 3 and Pr [ h i = 1]  X  1 / 3 for all i , then err unl ( h )  X  err( h ) / 2 .
 Proof: Let us write the labeled error rate as: The unlabeled error rate is, err unl ( h ) = err( h )  X  X Intuitively, the difference between the unlabeled error rate and the true error rate are the cases when we have an outcome with a single one, but it is the incorrect one. We would like to lower bound the ratio between the unlabeled error rate and the true error rate, i.e., err unl ( h ) err( h ) F ( x 1 ,y 1 ,...,x L ,y L ) = For each i , the function F is increasing in x i , so it will get its maximum value at 1 (the maximum value of x i ). This implies that we need to maximize
G ( y 1 ,...,y L ) = X Since each p i  X  1 / 3 and h i is 1 with probability at most 1 / 3 then p i, 1 | 0  X  1 / 2.
 We know that the maximizing solution to G out of all y  X  [0 , 1 / 2] will have a certain number, say k , of y  X  X  equal 1 / 2 and the rest are zero. Therefore, This implies that err unl ( h ) / err( h )  X  1 2 . 3.2. Each example positive for at most one We now consider the more general ontology R 01 , which allows for the all-negative labeling. We start with the following important lemma, that relates the error of switching 0 to 1, with some  X  X bservable event X . Lemma 3 Given ontology R 01 , assume D satisfies IGL and that P i p i = 1  X   X   X  3 / 4 , and p i  X  1 / 4 for all i . Consider a hypothesis h such that P i p i, 1 | 0 Then, for any  X   X  1 / 4 one of the following holds: (1) the probability of two or more positive labels is at least  X  (1  X   X   X   X  ) / 6000 (2) The probability the hypothesis h predicts all categories negative is more than  X  +  X  , or (3) for some category i , the probability that h i ( x i ) = 1 is at least 0 . 982(1  X   X   X   X  ) Proof: Assume that the probability that h predicts all categories negative is at most  X  +  X  (otherwise we are done). Let s = arg max i p i, 1 | 0 . We consider two cases depending on the magnitude of p s, 1 | 0 . In the first case, where p s, 1 | 0 &lt;  X / 6, we show that the unlabeled error rate is significant. In the second case, where p s, 1 | 0  X   X / 6, we show that either the unlabeled error rate is significant or that h predicts positive in category s with a very high probability.
 Case 1: Assume p s, 1 | 0 &lt;  X / 6. Then we can partition the categories into three subsets S 1 , S 2 and S 3 such one of the three sets we have P i  X  S assume that this is S 1 . Then the probability that the true label is in S 1 and in each other set we have at least one positive label (and hence at least two positive labels overall) is at least, ( X where the first inequality uses the fact that having k independent events of probability q j each implies that the probability some event occurs is at least P j q j /e . This implies that the probability of an unlabeled error in this case is  X (  X  2 (1  X   X   X   X  )).
 Case 2: Assume that p s, 1 | 0  X   X / 6. Then  X   X  6. Con-sider the probability of observing a 1 in s and also a label 1 in some i 6 = s . Note that the probability that c ( x ) = 0 is at least 3 / 4. The only way the unlabeled error rate can be less than  X  2 (1  X   X   X   X  ) / 6000 is if Namely, given that c  X  s ( x ) = 0, the probability of pre-dicting 1 in any i 6 = s is at most the above bound. Since  X   X  6 this implies that the probability that h s = 1 is at least 1  X  Pr [  X  ih i ( x ) = 0]  X  err unl ( h )  X  &gt; 0 . 982(1  X   X   X   X  ).
 Unlike the case of the ontology R 1 , for R 01 there can be a hypothesis that has zero unlabeled error and a very high labeled error: for example, a hypothesis that pre-dicts negative always for every category. To overcome this, we will focus on a set of  X  X lausible X  hypothe-ses. Let Good (  X , X  ) be the set of hypotheses h  X  C such that Pr [  X  ih i ( x i ) = 0]  X   X  and for any category Pr [ h i ( x i ) = 1]  X   X  .
 Theorem 4 Suppose P i p i = 1  X   X   X  4 / 5 and for any i we have p i  X   X  = 1 / 5 . If h  X  Good (  X  + / 20 , X  + / 20) and err( h )  X  then err unl ( h ) =  X ( 2 ) . In addition Good (  X  + / 20 , X  + / 20) 6 =  X  .
 Proof: First, note that c  X   X  Good (  X , X  ). Now, consider h  X  Good (  X  + / 20 , X  + / 20) and let P i p i, 1 | 0 =  X  . Assume that err( h )  X  . We consider two cases de-pending on the value of  X  .
 Case 1: Assume  X   X  0 . 25 . By Lemma 5, with  X  = / 20, we have three possible outcomes: (1) the probability of two or more positive labels is  X  2 (1  X   X   X  / 20) / 6000, (2) The probability that h predicts all categories negative is more than  X  + / 20, or (3) for some category i , the probability that h i ( x i ) = 1 is at least 0 . 982(1  X   X   X  / 20).
 Since h  X  Good (  X  + / 20 , X  + / 20), outcome (2) is impossible. For outcome (3), since  X  + / 20  X  1 / 5 + 1 / 20 = 1 / 4, then 0 . 982(1  X   X   X  / 20) &gt; 0 . 7. Since the probability that h  X  Good (  X  + / 10 , X  + / 10) labels any category positive is at most  X  + / 20 = 1 / 4 &lt; 0 . 7, outcome (3) is also impossible. Therefore, the unlabeled error rate of h is  X (  X  2 (1  X   X   X  / 20)) =  X ( 2 Case 2: Assume  X  &lt; 0 . 25 . Since err( h )  X  , this implies that  X  = P i p i p i, 0 | 1  X  0 . 75 . The probability that h predicts negative in all categories is at least  X   X   X  +  X  &gt;  X   X  0 . 25 + 0 . 75 =  X  + 0 . 5 , which is a contradiction that h  X  Good (  X  + / 20 , X  + / 20). 3.3. General Graph-Based Ontologies The previous analysis demonstrated an extremely tight connection between labeled and unlabeled error, allowing for learning from unlabeled examples only, and moreover (see Section 4) from a number of unla-beled examples not much larger than the sample com-plexity of supervised learning. However, these results required an ontology such that any example is positive for at most one category. They also assumed full inde-pendence given the labeling. In this section we extend these results to show we can learn from purely unla-beled data given an arbitrary graph based ontology of NAND and  X   X   X  edges, subject only to the following conditions on the ontology and the distribution: (1) For some given  X  &gt; 0, we have  X   X  p i  X  1  X   X  for (2) The ontology has no isolated vertices. That is, for (3) For some given  X  2 &gt; 0, for any edge ( i,i 0 ) in the Finally, we replace independence given the labeling with the following much weaker condition related to the  X  X eak dependence X  of (Abney, 2002): (4) For some given  X  &gt; 0, for any edge ( i,i 0 ), any For additional intuition, conditions (2) and (3) above would be satisfied if every category were contained in a triangle of NAND edges. 2 Under the above conditions we will still be able to learn from unlabeled data only. However, we will need a larger sample size than for a complete graph. In order to describe the algorithm and present its anal-ysis, we need a few more definitions. First, if category i has either an incident NAND edge or an incident  X   X   X  edge for which it is on the subset-side, say that it is positive-constrained (because the ontology is limiting when it can be positive). If category i has an inci-dent  X   X   X  edge for which it is on the superset-side, we say that it is negative-constrained (because the ontol-ogy is limiting when it can be negative). Note that by condition (2) above, for every category at least one applies. If both cases apply to some category i , then for convenience we will just call it positive-constrained. Let cat + denote the set of positive-constrained cate-gories and cat  X  denote the set of negative-constrained categories. We now define how tightly constrained a hypothesis h = ( h 1 ,...,h L ) is as: tightness ( h ) =
X Finally, for a NAND edge ( i,i 0 ) define err unl ( h,i,i define err unl ( h,i,i 0 ) = Pr D [ h i ( x ) = 1  X  h i 0 The optimization procedure for learning from unla-beled data is now simply this: given an unlabeled sam-ple S , find the most tightly constrained hypothesis h possible (maximizing tightness ( h )) subject to satisfy-ing  X   X  Pr [ h i ( x i ) = 1]  X  1  X   X  for all i and h having zero empirical unlabeled error over S . To analyze this procedure, we begin with two key lemmas.
 Lemma 5 For a NAND edge ( i,i 0 ) , for any h : Proof: We will expand err unl ( h,i,i 0 ) by looking at two conditions (3) and (4) of our assumptions to achieve our desired lower bound. For compactness of notation, let  X  c  X  i = a  X  denote the event  X  c  X  i ( x i ) = a  X , and  X  c ab  X  denote the event  X  c  X  i ( x i ) = a  X  c  X  i 0 ( x i 0 similarly for h i and h ii 0 . Then we have: err unl ( h,i,i 0 ) = Pr [ h i = 1  X  h i 0 = 1]  X  Pr [ c  X  ii 0 = 01]  X  Pr [ h i = 1 | c  X  ii 0 = 01]  X   X   X  2 (  X  Pr [ h i = 1 | c  X  i = 0]  X   X  Pr [ h i 0 = 1 | c
The first inequality above is from considering just two of the three possible settings of c  X  i ( x i ) and c the second comes from applying condition (3) to the events involving c and (4) to the events involving h , and finally the last inequality is using Pr [ h i 0 = 1]  X  Lemma 6 For a  X   X   X  edge ( i,i 0 ) , for any h we have: Proof: The proof is essentially the same as for Lemma 5, and omitted due to space limitations.
 We now use these to show that for any plausible hy-pothesis h (one such that  X   X  Pr [ h i ( x i ) = 1]  X  1  X   X  for all i ), if h has high error then either its unlabeled error will be high or else its tightness will be low com-pared to the target function. This then will imply that maximizing tightness subject to low unlabeled error must lead to a hypothesis of low labeled error. Theorem 7 Suppose  X   X  Pr [ h i ( x i ) = 1]  X  1  X   X  for all i . If err( h )  X  then either err unl ( h )  X   X  X  2  X  2 / (4 L ) or tightness ( h )  X  tightness ( c )  X  / 2 . Proof: Suppose err( h )  X  . We have three cases. Case 1: Suppose for some positive-constrained cate-gory i , we have p i, 1 | 0  X  4 L . By definition of positive-constrained, there must be some NAND or  X   X   X  edge ( i,i 0 ). So, by Lemmas 5 and 6, we have err unl ( h )  X  err unl ( h,i,i 0 )  X   X  2  X  2 ( 4 L )  X  =  X  X  2  X  2 / (4 L ). Case 2: Suppose for some negative-constrained cat-egory i 0 , we have p i 0 , 0 | 1  X  4 L . By definition of negative-constrained, there must be some  X   X   X  edge ( i,i 0 ). So, by Lemma 6, we again have err unl err unl ( h,i,i 0 )  X   X  2  X  2 ( 4 L )  X  =  X  X  2  X  2 / (4 L ). Case 3: Suppose neither of the above two cases oc-have: Therefore, since err( h )  X  , Putting these together we have: tightness ( c )  X  tightness ( h ) as desired. 3.4. Implications We now show how the above results can be used to analyze an idealized form of a natural iterative learn-ing algorithm motivated by algorithms used in systems such as NELL (Carlson et al., 2010a;b).
 We consider here the same asumptions (1-4) used in Section 3.3 and additionally assume each category is incident to at least one NAND edge. Define a hy-pothesis h i to be  X  X afe X  if h i  X  c  X  i , i.e., p i, 1 | 0 Say that g i is an  X   X  1 -extension X  of h i if h i  X  g i and Pr [ g i = 1]  X  Pr [ h i = 1] +  X  1 . We now consider the following idealized iterative learning procedure. Let  X  , X  1 &gt; 0 and k  X  Z + . Suppose: 1. Given an initial set of positive labeled examples for 2. For any category i such that p i, 0 | 1  X   X  1 (i.e., we 3. The procedure then is just to greedily replace any Corollary 8 The above procedure correctly maintains safe hypotheses and halts after at most L/ X  1 steps with a hypothesis of total error at most L X  1 .
 Proof: Assume inductively that h 1 ,...,h L are safe and suppose g j i is not a safe extension of h i . We are given that category i is connected by a NAND edge to at least one other category i 0 . Since Pr [ h i 0 = 1]  X   X  Lemma 5 we have err unl ( h,i,i 0 )  X   X  2  X  2  X  1  X  0 any unsafe extension will not be taken. On the other hand, if g j i is a safe extension, then replacing h i with g maintains the inductive property that h 1 ,...,h L are safe and thus no NAND edge will incur unlabeled error. So the algorithm will not halt until no safe extension exists, which happens only if total error  X  L X  1 . In this section we derive bounds relating empirical un-labeled error to true unlabeled error, in order to apply the results of Section 3 to finite sample sizes. To do so we will analyze the VC dimension of the unlabeled error sets. Proofs are omitted due to space limitations. We start with the identical-independent model. Re-call that in this setting we select only a single hypoth-esis h  X  C . We need to compute the VCdim( C,L ) which is the VC dimension when we have L points for each example. Recall that a point is an L -tuple ~x = ( x 1 ,...,x L ). We first need to define ` ( h,~x ), the loss of h on ~x . Let R be an ontology, i.e., the set of legal label-ings. We define ` ( h,~x ) = 0 if ( h ( x 1 ) ,...,h ( x and otherwise it is 1.
 Theorem 9 Let d = VCdim( C ) . For any ontology R we have VCdim( C,L ) = O ( d log L ) .
 It is worth noting that there is indeed a difference be-tween VCdim( C,L ) and VCdim( C ).
 Claim 1 Consider the class TH 1 the threshold functions on [0 , 10] . Then VCdim( TH 1 ) = VCdim( TH 1 , 1) = 1 and VCdim( TH 1 , 2) = 2 . We can now use Theorem 9 to derive generalization bounds based on Theorem 1.
 Corollary 10 In the independent-identical model with ontology R 1 and L  X  3 , a sample of m u = O 1 VCdim( C ) log L ln 1 + ln 1  X  unlabeled ex-amples (and no labeled examples) are sufficient to achieve error  X  . In particular, with probability 1  X   X  , all h with h 1 = ... = h L  X  C satisfying have err( h )  X  .
 We now need to derive a generalization bound for the general case, that will relate the observed and the true unlabeled error rates. The main difference is that we consider the hypothesis class C L where each hypoth-esis is ~ h = ( h 1 ,...,h L ) and h i  X  C . As before, the examples are L -tuples ~x = ( x 1 ,...,x L ) and the loss is ` defined using the set R of legal labelings. (The the-orem holds for any ontology R .) We need to compute the VCdim( C L ,L ).
 Theorem 11 Let d = VCdim( C ) . For any ontology R we have VCdim( C L ,L ) = O ( dL log dL ) .
 We can therefore derive the following.
 Corollary 12 Consider ontology R 1 , and assume p i  X  1 / 3 and Pr [ h i = 1]  X  1 / 3 for all i . Then, m u = O 1 dL log( dL ) ln 1 + ln( 1  X  ) unlabeled ex-amples (and no labeled examples) are sufficient to achieve error  X  , where d = VCdim( C ) . In particu-lar, with probability 1  X   X  , all h  X  C L with have err( h )  X  .
 We now consider the difference between the observed tightness ( h ), denoted by \ tightness ( h ), and the true tightness ( h ). The following theorem follows by con-sidering a generalization bound for each category, inde-pendently, and using the union bound over categories. Theorem 13 For an unlabeled sample size we have that with probability 1  X   X  , for any h  X  C we have | tightness ( h )  X  \ tightness ( h ) | X  . In this section, we assume the different domains X are discrete and small: specifically, X i = { 1 ,...,N } , where N is not too large, and let class C consist of all boolean functions over N elements. For example, this could model data satisfying the condition that points within each view can be easily grouped into at most N clusters, with each cluster having a single label. Note that even though we view N as small, the total number of examples possible is N L and could be quite large. Our goal here will be to learn from unlabeled data using time and samples polynomial in N and L .
 We will assume here the same conditions (1-4) used in Section 3.3. Proofs omitted due to space limitations. Lemma 14 For any edge ( i,j ) of the ontology, any pair of labels ` i ,` j not disallowed by this edge, and any pair of values a i ,a j s.t. c  X  i ( a i ) = ` i and c  X  j
Pr [ x i = a i ,x j = a j | c  X  i = ` i ,c  X  j = ` j ] We now present the algorithm, using Lemma 14. The idea is simple. First, we sample enough unlabeled ex-amples. Next, examine each edge ( i,j ) of the ontology graph. For each such edge, if two values that indi-vidually have reasonably high probability mass never co-occur, then this must be because they form the dis-allowed labeling for that edge.
 Algorithm LearnDiscrete : Given error bound , confidence bound  X  , values  X , X  2 : 1. Let 0 = min( , X L ). Draw a sample S of m = 2. Define  X  p i ( a i ) to be the empirical frequency of a 3. Let T i include all values if X i that have empirical 4. For each NAND edge ( i,j ), for each a i  X  T i and 5. For each category i , for each value a i  X  X i The following theorem shows that the error rate of the algorithm is low.
 Theorem 15 Under assumptions (1-4) of Section 3.3, Algorithm LearnDiscrete produces a labeling of the domain with error at most with probability 1  X   X  . It would be interesting to extend the results of Sec-tion 3.4 to remove the assumption that extensions will never be  X  X arely safe X , as well as to extend these re-sults (using perhaps a different idealized algorithm) to the case where not all categories are incident to a NAND edge. It would also be of interest to further weaken the limited independence conditions used in Section 3.3.
 This work was supported in part by NSF grants CCF-0953192, CCF-1116892, and IIS-1065251, AFOSR grant FA9550-09-1-0538, ONR grant N00014-09-1-0751, by a Microsoft Faculty Fellowship, and by grants from the Israel Science Foundation, the US-Israel Bi-national Science Foundation, the Israeli Ministry of Science and the Israeli Centers of Research Excellence (I-CORE) program (Center No. 4/11). We thank Tong Zhang and Lev Reyzin for early discussions on mod-els of multiple-task learning, and Tom Mitchell for a number of exciting discussions of the NELL system. Abney, S. Bootstrapping. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics , ACL  X 02, pp. 360 X 367, 2002.
 Balcan, M.-F. and Blum, A. A PAC-style model for learning from labeled and unlabeled data. In Pro-ceedings of the 18th Annual Conference on Compu-tational Learning Theory (COLT) , 2005.
 Blum, A. and Mitchell, T. Combining labeled and unlabeled data with co-training. In The 11th An-nual Conference on Computational Learning Theory (COLT) , 1998.
 Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hr-uschka Jr., E. R., and Mitchell, T.M. Toward an architecture for never-ending language learning. In AAAI , 2010a.
 Carlson, A., Betteridge, J., Wang, R. C., Hruschka Jr.,
E.R., and Mitchell, T.M. Coupled semi-supervised learning for information extraction. In Proceedings of the Third ACM International Conference on Web Search and Data Mining , 2010b.
 Cavallanti, G., Cesa-Bianchi, N., and Gentile, C. Lin-ear algorithms for online multitask classification.
Journal of Machine Learning Research , 11:2901 X  2934, 2010.
 Chapelle, O., Sch  X olkopf, B., and Zien, A. (eds.). Semi-
Supervised Learning . MIT Press, Cambridge, MA, 2006. URL http://www.kyb.tuebingen.mpg.de/ ssl-book .
 He, Jingrui and Lawrence, Rick. A graphbased frame-work for multi-task multi-view learning. In ICML , pp. 25 X 32, 2011.
 Mohamed, T., Hruschka Jr., E.R., and Mitchell, T. Discovering relations between noun categories. In Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing , pp. 1447 X  1455, July 2011.
 Sridharan, K. and Kakade, S.M. An information the-oretic framework for multi-view learning. In COLT , pp. 403 X 414, 2008.
 Verma, S. and Hruschka Jr., E.R. Coupled bayesian sets algorithm for semi-supervised learning and in-formation extraction. In Proceedings of the European
Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD 2012) , Bristol, UK, September 2012.
 Association for Computing Machinery.
 Zhu, Xiaojin and Goldberg, Andrew B. Introduction to Semi-Supervised Learning . Synthesis Lectures on
Artificial Intelligence and Machine Learning. Mor-
