 In the last decade, query tuning using relevance feedback (RF) has gained much attention in the research area of content-based image retrieval (CBIR) systems. This is largely due to RF X  X  ability to refine the user query through a sequence of interactive sessions. Various approaches [2] have been introduced and they have yielded certain degrees of success. However, most research works have focused on query tuning in a single retrieval session. This is commonly known as intra-query learning. In contrast, inter-query learning , also known as long-term learning, attempts to analyze the relationship between the current and past retrieval sessions. By accumulating knowledge learned from the previous sessions, inter-query learning aims at further improve the retrieval performance of the current and future sessions. One may view that inter-query is an extension of the intra-query. Although intra-query in CBIR has been a topic of research for the last decade, inter-query in CBIR has only begun to attract interests in the last few years and it is yet to be fully explored. 
Previously, the authors have developed an inter-query learning framework based on the statistical discriminant analysis approach to represent the characteristics of a visual group during a retrieval session [1]. Such approach is more suitable for database applications where images are added or removed on a regular basis. It is because that the approach avoids the needs of establishing relationships between each image in the database. This is a common approach used in most inter-query learning frameworks. A weakness with this framework is that it can only merge clusters with similar visual characteristics. The framew ork is unable to capture the semantic relationship between clusters. Thus, it lacks the capability of establishing relationships between clusters that are semantically similar and yet visually different. 
This paper extends the existing framework by introducing a semantic structure to used to explore the semantic structure for the maximum coverage on possible images that are semantically similar to the query image. This paper begins with a discussion on the background of the problem studied in this study. It is then followed by a description of the overall proposed framework. Experiment results are then presented and followed by the conclusion. A feature vector based inter-query learning framework has been proposed in [1]. In the proposed framework, a cluster is formed after each retrieval session. The cluster is described by the feature space created by st atistical discriminant analysis and the boundary of the cluster is defined by the furthest positive labeled image from the positive centroid. Since the cluster contains the visual information common to the previously selected positively labeled images, it is assumed that the two retrieval sessions are similar when the majority of the images gathered from the short-term learning algorithm fall within the boundary of a selected cluster. One may view this as a way measuring visual similarity between se lected cluster and the short term learning algorithm. Experiments in [1] have shown that the developed framework improves the retrieval accuracy of the system. 
At the end of a retrieval session, a cluster merging policy has been proposed. The decision for merging is based on two criteria: based on the measurement of the visual similarity, and, the visual similarity between the two positive centroid points. Table 1 is the summary of the cluster merging policy as proposed previously. From the table, two clusters will only be merged when both are semantically and visually similar. While such strategy is appropriate for condition 3 and 4 where the clusters are not semantically related, it may not be totally suitable for condition 2. In other words, although they are cases that the clusters are not visually similar, they may be semantically related. Such information can be valuable for future retrieval process. Thus, such information should also be recorded by the system. 
To resolve the issue with the condition 2, one may apply the same merging algorithm as used in condition 1 but with a more relax merging condition. However, this may be problematic. In statistical discriminant analysis, a visual group is generally captured and represented by a distribution function. A single distribution modal may not be able to capture image samples that are not visually related. Thus, merging of the two clusters which are not visually related may result in losing the visual characteristics of the original clusters. 1 Yes Yes Yes 2 Yes No No 3 No Yes No 4 No No No 
One may consider this issue as a multimodal density analysis problem [3, 4]. Such approach is often based on heuristic rules and manual interaction is usually required to set the parameters which are necessary in analyzing the number of distribution modals needed. Moreover, the values of the parameters are often derived through trial and error. Thus, it may not be suitable for generic database. Furthermore, such approach is assuming that a visual group will only belong to a semantic group. This is not necessarily true as a visual group may belong to multiple semantic groups and each semantic group may not be directly related to each other. For instance, Figure 1 shows that while the semantic groups  X  X nimal X  and  X  X ater X  both contain the visual group  X  X ish in the Water X , but  X  X nimal X  may not be directly related to  X  X ater X . 
Alternatively, one may record the semantic relationship of clusters via a semantic link. The semantic relationship of the two clusters can be determined through the labeled image samples as gathered through user feedback cycles. The use of semantic relationship has the advantage of recording the relationship of the two clusters while preserving the visual characteristics of the clusters. Such approach will be discussed in more detail in the following section. 3.1 Cluster Merging Scheme Figure 2 depicts the logical flow of the proposed clustering merging process which an extension of the original framework with the additional semantic link module for establishing semantic links between the selected clusters. The selected clusters are only visually merged if and only if both clusters are semantically and visually similar. two clusters will be semantically link by the additional module. 
In this paper, the proposed semantic structure is represented by a tree hierarchy structure and each cluster acts as a visual node in the tree. If a tree contains only one node is used if the tree contains more than one visual node. The semantic node is merely a connection node which acts as a connection bridge between all the visual nodes that are semantically related. One may view this as a two layer tree structure framework where the semantic and visual nodes are the root and leaf of the tree respectively. 
Figure 3 presents the logical view of a typical semantic tree structure and also, the merging product of the two semantic trees. When two visual nodes are tested to be semantically similar such as visual node 3 and 4 as shown in the figure, the trees containing the nodes will be merged. The merging process is intuitive. A new merged tree is merely the collection of all the visual nodes under the two original trees. Such relationship implies that all the visual nodes under the same tree are either directly or indirectly related to each other. 3.2 Cluster Search and Explore Schemes Figure 4 depicts the flow sequence of the proposed clusters searching and exploring scheme of the new semantic framework. The proposed framework is an extension from the existing searching framework with two additional modules. The two additional modules are mainly used for iden tifying the visual nodes to be explored and the implementation of the visual node exploring strategy. The visual nodes can be mathematically expressed as: where N p denotes the total number of positive samples gathered during the feedback cycle, and cluster i . 
It should be noted that the two additional modules are only activated when no more visual nodes are selected. The system will always explore the visual content first before semantic relationship is considered. There are two reasons to support this design. Firstly, an assumption is made that if certain numbers of positive samples fall within a selected node, then it is very likely that the selected node contains information related to the searched topic. Secondly, it is required to gather as many visual nodes as possible before the system can effectively select visual nodes which are semantically related to the explored nodes. The selection strategy of the visual nodes with related semantic content is described in the following paragraph. 
To explore the semantic relationship of the visual nodes, one has to first rank the explored trees. This is based on the fact that a semantic tree consists of visual nodes that are likely to be semantically related to each other. This implies while each visual node is semantically related to each other while they are not necessary interpreted with the same semantic content. Thus, it is possible for the system to explore the wrong node under the same tree. The ranking of the trees is a mechanism designed to minimize chances of exploring visual nodes with different semantic content. 
In this paper, it is proposed the ranking of the tree is done by employing a scoring system. The scoring system is based on the ratio of the number of verified visual nodes, explored by the system within the same tree. The mathematical expression can be written as: 
Such scoring system is used as an indication on the number of nodes that have been explored, and within these nodes, how many have been falsely explored. The minimum score is zero and it implies that all the visual nodes under the selected tree have been falsely explored. Conversely, the maximum score of one indicates that all the nodes within the tree have been correctly explore. Thus, a semantic tree with a higher score will always rank higher than one with a comparatively lower score. For consistency purpose, the searching criterion expressed in (1) is used for node verification. Once the trees have been ranked, the system will then choose the top trees for the exploring of the semantically related nodes. To explore the nodes, one first has to select a node exploring strategy. The traditional most probable approach often results in limiting the selection of the images into a narrow region near the query images. This restricts the system for exploring images with different visual characteristics. This is in conflict with the goal of the proposed semantic structure. On the other hand, active learning is a strategy with an objective to gather the most informative samples from the given data available. This implies that instead of selecting a narrow region of images, active l earning strategy aims to select images in the unexplored regions where the images are possibly semantically related. As for this framework, active learning can be implemented by selecting visual nodes that have the biggest visual differences from the gathered samples. This can be determined by the number of labeled samples that are clustered by the selected visual node. The node with the least clustered samples will be the one with the biggest visual differences. 4.1 Test Environment In order to test the performance of the proposed approach, three systems have been implemented. They are (i) the proposed semantic framework, (ii) the visual merging framework as proposed in [1], and (iii) a short term learning framework based on KBDA as reported in reference [5]. To evaluate the validity of the experiment, the environment and parameters used by all three systems are identical. The image features and the generalized eigenvector calculation method are the same and the same parameters are also used in the kernel transformation algorithm for all three systems. In this experiment, five visual features have been selected for the analysis of shape, color and texture of the images. Th e five features are the water-filling edge histogram algorithm [6], HSV color coherent vector [7], HSV histogram , global edge detection algorithm [8], HSV color moments [9] and color intensity histogram. Each feature comprises a number of elements. A total number of sixty-five feature elements have been used. Lastly, Gaussian Radial Basis Function (RBF) is selected as the kernel transformation matrix for the KBDA approach. This is suggested by literatures [5, 10] as both claimed that RBF yields the best accuracy performance out of all the other kernel transformation approaches. 4.2 Experiment Procedures and Test Data In this experiment, 500 images of the Corel image database were used. Within these images, 300 images are classified under seven different themes and each consists of several different visual groups. The inter-relationship of each theme is depicted in Figure 5. The themes  X  X ird X  and  X  X at X  are subset of  X  X nimal X ,  X  X ish X  is the subset for both the  X  X nimal X  and  X  X ater X , while  X  X ater X  also comprise of  X  X ater scene X . Lastly,  X  X ellow flower X  is independent from all the other themes. The inter-relationship between each theme is designed to emulate the complexity of the semantic relationship between each object in the real world. 
The retrieval performance of the frameworks was measured via three different tests. The tests were generated by randomly selecting 300 positive labeled images from the labeled images as an input entry point to the system. The same data set was then applied to two more tests with different random sequences. The average of the used as the main factor to compare the performance of the systems. 
Figure 6 shows the average retrieval accuracies of the three frameworks after three random sequences of 300 search sessions. As shown from the figure, the test framework with the semantic framework is the most effective of the three in terms of retrieval accuracy. With the exception of the theme  X  X ellow flower X , the average retrieval accuracies for the semantic structure are all better than the visual merging as proposed from the previous work. From the figure, it shows that the average retrieval result of the theme  X  X ellow flower X  for the visual merging framework is slightly better than the semantic framework. However, the advantage of visual merging framework is only marginal. Furthermore, Table 2 shows that the advantage of the visual merging scheme on the theme  X  X ellow flower X  is inconclusive. Of the three sequences, the performance of the semantic structure in the first sequence was actually better than the visual merging scheme. Thus, one may only conclude that the performance of the two frameworks on  X  X ellow flower X  is compatible, neither can claim to be more accurate over the other. A semantic structure framework for inter-query learning in CBIR system has been introduced. The proposed framework provides the building block for constructing complicated relationship between visual clusters. The complex relationships between different image groups are captured by using a semantic structure to connect different visual image groups that are semantically related. In addition, active learning has also been introduced as the strategy for the selection of visual nodes with related semantic content. The test results have demonstrated that while the retrieval performance between the two frameworks is compatible for simple data sets, the proposed semantic framework is more superior in handling data sets with a more complex relationship. Such framework can be easily modified and expanded by associating keywords to the selected clusters using during the image during retrieval session. The keyword, in turn, may also link to word dictionary database to further improve the rigor of keywords used in the search session. The incorporation of keyword annotation to the user log is one of the future research directions for this study. 
