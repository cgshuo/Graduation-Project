 Active learning traditionally assumes that labeled and un-labeled samples are subject to the same distributions and the goal of an active learner is to label the most infor-mative unlabeled samples. In reality, situations may exist that we may not have unlabeled samples from the same do-main as the labeled samples ( i.e. target domain), whereas samples from auxiliary domains might be available. Under such situations, an interesting question is whether an active learner can actively label samples from auxiliary domains to benefit the target domain. In this paper, we propose a transfer active learning method, namely Transfer Active SVM (TrAcSVM), which uses a limited number of target instances to iteratively discover and label informative aux-iliary instances. TrAcSVM employs an extended sigmoid function as instance weight updating approach to adjust the models for prediction of (newly arrived) target data. Ex-perimental results on real-world data sets demonstrate that TrAcSVM obtains better efficiency and prediction accuracy than its peers.
 I.5.4 [ Pattern Recognition ]: Applications X  computer vi-sion, text processing Algorithms Transfer learning, active learning, classification  X  Corresponding author.

Active learning methods traditionally assume that a rich set of unlabeled samples, which are subject to the same distribution as labeled samples, are provided for an active learner to label the most informative ones to improve the classifiers built from the labeled set. In many applications, one may find that samples for target domains are very dif-ficult to collect, whereas plenty of unlabeled samples from auxiliary domains may exist. Under such situations, an im-mediate question is whether an active learner can selectively label samples from auxiliary domains to improve the learn-ing for the target domain.
 Indeed, given two sets of labeled samples S and D ,where S is identified as the target domain and samples in D are from similar but not identical distributions as S ,transfer learning [1, 6, 7] and cross-domain learning [8] have shown to be very successful in transferring knowledge from auxiliary domains D to improve the learning for the target domain S . Accordingly, if unlabeled samples from auxiliary domains are suitably labeled, existing transfer learning methods have the capacity to utilize their knowledge to benefit the learn-ing for the target domain. As a result, the problem becomes that which of the unlabeled samples in the auxiliary do-mains should be labeled such that they can help improve the learning for the target domain.

In this paper, we formulate the above problem as transfer active learning , and propose a transfer active learning model, TrAcSVM, to solve the problem. The proposed method uses several labeled target data to iteratively project aux-iliary data to low dimensional spaces and label informative auxiliary data, by employing an instance weighting mecha-nism. Experimental comparisons with some baseline meth-ods, demonstrate that TrAcSVM is efficient for obtaining better prediction accuracies and faster convergence speed by actively labeling auxiliary data.
Denote S =[ s 1 ,s 2 ,  X  X  X  ,s t ]  X  R m  X  t the same-distribution ( target ) data matrix consisting of t instances in m -dimensional spaces and the column vector L S =[ l 1 ,l 2 ,  X  X  X  ,l t ] assign a class label +1 or  X  1 for each instance in S . Similar to S ,symbol D =[ d 1 ,d 2 ,  X  X  X  ,d n ]  X  R m  X  n ( t is a small inte-ger and t n )isthe different-distribution ( auxiliary )data matrix consisting of n instances in m -dimensional spaces. In addition, the symbol Z denotes the labeled training data.
For traditional active learning, both labeled and unlabeled data are assumed to share the same distributions. To build prediction models, one can actively select and label infor-mative samples from S . For some applications, the num-ber of same-distribution data t might be too small to pro-duce strong training model, or it is difficult/expensive or time-consuming to label the same-distribution instances. As a result, it may be difficult to obtain a rich set of same-distribution labeled data, whereas finding a large number of different-distribution samples from auxiliary domain might be easily achieved. Accordingly, the problem described above can be regarded as discovering and labeling auxiliary data, such that their knowledge can be properly transferred to the target domain and help build a classifier with maximum prediction accuracy.
To integrate transfer learning into active learning, two fundamental challenges include (1) how to determine and select informative auxiliary data for labeling, and (2) how to transfer knowledge in the labeled auxiliary data to the target data. In this paper, the former is solved by using a small number of labeled target data to find useful auxil-iary data. For the latter, we use an instance-level weighting mechanism to achieve transfer learning. More specifically, when initializing the prediction model by employing proxi-mal support vector machine (PSVM) method [3], the train-ing set Z consists of target set S with only t instances. In each iteration, we utilize the initial model to project auxil-iary data to low-dimensional spaces and actively select an informative auxiliary instance d  X  D for labeling and adjust weight values of all labeled instances in Z . Accordingly, the training model is improved gradually.

In the following sections, we first introduce PSVM method as a basic classifier. Based on this approach, we further describe the method for finding informative auxiliary in-stances, followed by detailed procedures on sample weight updating for transfer active learning.
Proximal Support Vector Machine (PSVM) method is a simplified SVM classifier [3]. Assume the instance matrix X is equal to [ x 1 ,x 2 , ..., x n ]  X  R m  X  n ,thelabelvector L  X  R n  X  1 is used to assign a class label +1 or  X  1foreach instance, and e  X  R n  X  1 is a column vector of ones in n -dimensional space. The classifier based on PSVM can be simplified as follows,  X  =(  X I + ZZ T )  X  1 ZL =(  X I + A )  X  1 ZL =  X  A  X  1 ZL, (1) where Z =[ X ;  X  e ]( z =[ x T ,  X  1] T  X  Z ),  X  is the regulariza-tion parameter, and  X  determines a decision boundary, i.e. a classifier, which can be used for prediction.
Intuitively, for transfer learning, informative auxiliary in-stances should be those which are similar to the target data, so we can use several target instances to determine whether an auxiliary data is worth of labeling. Accordingly, when using  X  1 as class labels and considering the model param-eter  X  as projection matrix, we believe that informative in-stances in the one dimensional projection space should be those which are near to the zero value. In fact, one only needs to make the projection P equal to D X  . To this end, we can maximize Eq. (2) to discover this type of instances.
Using labeled target set Z  X  S , we can easily train an initial projection model. Once a useful auxiliary instance is labeled and included in the training set Z ,werecalculate the weight values for the target data and newly included auxiliary data by left multiplying a weight matrix  X  to be updated on Z T and L . The weight matrix  X  , with the initial values is given as follows. where I is the unit matrix and  X  is used to conveniently adjust the model parameter  X  like Eq. (4).
During the weight updating process,  X  is adjusted by us-ing the feedback mechanism based on the prediction errors on matrix Z , which includes target and auxiliary data.
For the weight updating method in TrAdaBoost [2], in each iteration, the instance weight for auxiliary data de-creases by multiplying a value which is less or equal to 1, and the weight value for target data increases by multiply-ing a value witch is greater than or equal to 1. As a result, the weight values for auxiliary data and target data fall into the range (0, 1] and [1, Max ), respectively, where Max may be much larger than 1. Because the weight values are not bounded in a certain range, the weight updating of the target instance might result in over-fitting. To solve the problem, we employ and reconstruct a sigmoid function as follows. where P ( z j ) is the predicted label of the instance z j [ S, d 1 ,d 2 ,  X  X  X  ,d i ], with the label set denoted by
For binary classification problem using  X  1aslabels,ifthe label is correctly predicted, the multiplication P ( z j ) l positive value. Otherwise, it is a negative one. Accordingly, for target data, the value 1+ 1 1+ e x falls into the range (1, 2), and for auxiliary data, the value 1 1+ e  X  x falls into the range (0, 1). As a result, Eq. (5) explicitly limits the weight of auxiliary and target instances into different bounded ranges.
Algorithm 1 lists detailed procedures of TrAcSVM, which contains two main steps including finding informative aux-iliary instances (Step 6) and adjusting model parameter  X  (Step 12).

In Algorithm 1, the target data S which only include sev-eral instances, are provided in a batch format to initialize the model parameters (as show on Step 4), whereas the auxiliary data D are incrementally included into the learning process. Once the first active auxiliary instance d i  X  D is acquired (Step 6), TrAcSVM uses Eq. (5) to update  X  on Step 11, followed by the updating of  X  on Step 12. The For loop between Steps 5 and 13 repeats until all n instances in the auxiliary set D are processed. The final model parameter  X  is used to predict test samples. Algorithm 1 Pseudocode of TrAcSVM algorithm Benchmark Methods: Presumably, a simple transfer ac-tive learning method is to apply a random labeling mod-ule to an existing transfer learning method, such as TrAd-aBoost [2]. In each iteration, we randomly label one auxil-iary instance and adjust weight values of all labeled instances by using TrAdaBoost algorithm. Then, we can use Eq. (4) to generate new prediction result. We call this benchmark method RTrSVM, namely random sampling transfer SVM.
The proposed method TrAcSVM is compared with RTrSVM and a boosting-based transfer learning algorithm TrAdaBoost [2]. For fairness of the comparisons, we use PSVM [3] as the ba-sic classifier for all methods. In the paper, we mainly report learning efficiency and prediction accuracy with respect to different benchmark data sets. Our test bed consists of two real-world data sets: 20 News Group (20NG) [4] and USPS image data [5].
 20NG data sets have a hierarchical structure. To sim-ulate transfer learning reality, we reassign the hierarchical structure like that in [2].
 Figure 1: Samples for printed (1st-5th columns) and hand-written digits (6th-10th columns)
USPS Digit data sets are collected from the US Postal Ser-vice (USPS) database which consists of hand-written images (digits). To enable active learning, we treat hand-written digit recognition as the learning task and use printed digits to enhance the prediction on the hand-written images. Fig.1 demonstrates some image samples. Because digit pairs 3 and 8 are visually similar, we select them to demonstrate the al-gorithm performance.

In our experiments, the auxiliary and target data are sim-ilar to each other. Therefore, their roles can be switched. In the paper, we also report the reverse (from target data to auxiliary ones) transfer active learning results. To compare the performance of the three methods (RTrSVM, TrAcSVM, and TrAdaBoost), we use PSVM as the base learner for all methods and report their average performance over ten time repetitions for each data set. In each repeti-tion, the number of labeled instances for the target set is fixed to 10 instances and the remaining instances in the tar-get set are used as test samples. The transfer active learning modules are applied to label auxiliary data set which con-tains 200 instances and generate prediction models. (a) Runtime comparison on 20NG 1 Figure 2: Average runtime on 20NG 1 and 3&amp;8, re-spectively.

In Fig.2, we report the system runtime comparison on two data sets. As we have explained in the experimental settings, in each experiment, the training set consists of 210 training instances. For RTrSVM and TrAcSVM, they incrementally label and include one auxiliary instance into the training process and record the system runtime once the processing for one auxiliary instance is done. For TrAdaBoost, we use all 200 randomly selected auxiliary instances in each itera-tion to train a weak classifiers with the number of iterations equal to that of different-distribution training instances used by RTrSVM and TrAcSVM. As a result, we can obtain a curve for each method to report the system runtime w.r.t. the increase of the auxiliary instances.

The results in Fig.2 show that all methods linearly scale up to the increasing size of the auxiliary instances. In each iteration, TrAdaBoost must adjust the weight and model parameter on all labeled training data, therefore, the run-time of TrAdaBoost is linearly increasing with respect to the number of iterations. For RTrSVM and TrAcSVM, the num-ber of training instances gradually increases and approaches to that of TrAdaBoost. As a result, their runtime is a lit-tle less than that of TrAdaBoost and also linearly increases with respect to the number of auxiliary instances n .
In Fig.3 we report the algorithm performance for transfer active learning, including forward transfer learning and re-verse transfer learning (from target data to auxiliary data).
From the results showing in the figures, it is clear that (a) Transfer learning for 20NG 1 (c) R. Transfer learning for 20NG 1 Figure 3: Average prediction accuracies on 20NG 1 and 3&amp;8 pair. Transfer active learning from auxil-iary to target data (a) 20NG 1, (b) 3&amp;8, as well as the reverse learning from target to auxiliary data (c) 20NG 1and(d)3&amp;8. the prediction accuracies of TrAcSVM are constantly better than others, and its accuracy gain is particularly significant when only a very limited number of auxiliary instances are labeled for training. For most data sets in our experiments, the results of TrAdaBoost are relatively poor at the begin-ning. After a sufficient number of iterations, the results of TrAdaBoost can pick up and eventually become comparable to others. For RTrSVM, in most situations, the increase of labeled auxiliary data is not useful for improving the predic-tion performance, which asserts that randomly labeling aux-iliary samples, like RTrSVM does, is ineffective for boosting the learner performance for target data.

In Figs.3(c) and (d), we also report the reverse transfer active learning results where the target and the auxiliary sets switch their roles and the objective is to learn a prediction model for the auxiliary data by transferring knowledge from the target data. Our results indicate that knowledge transfer between target and auxiliary data is largely bidirectional, as long as the two tasks are relevant to each other.
When comparing results across Figs.3(a), (b), (c) and (d) for different target set sizes, it is clear that the smaller the size of the labeled auxiliary set, the better the transfer ac-tive learning can help improve the learning on the target set. Note that Fig.3(b) shows slightly different trends from oth-ers. This is mainly because the target data (hand-written digits) have more generalization performance than auxiliary samples (printed digits). For RTrSVM and TrAcSVM, when the initial labeled target data already produces a strong model (the prediction accuracy is 100%), labeling more aux-iliary data does not bring additional improvement. For TrAd-aBoost, all labeled auxiliary data and target data are used together to train initial classifiers. Because the number of labeled auxiliary data is much more than that of target in-stances, the initial classifiers are strongly dominated by the auxiliary data. As a result, the prediction accuracy of TrAd-aBoost is low at the beginning of the iteration. With more iterations and more classifiers combined together, the in-stance weighting mechanisms of TrAdaBoost can help ad-just the weight values for auxiliary instances, and improve TrAdaBoost X  X  prediction accuracy.

In summary, by actively selecting informative auxiliary data and employing the proposed instance level weighting mechanism, TrAcSVM achieves much better prediction ac-curacies and faster convergence speed than its opponents, thenon-activemethods. In this paper, we proposed a transfer active learning method TrAcSVM. We argued that traditional active learning merely focuses on labeling samples which are from the same distri-butions as the target data but does not have mechanisms to actively select samples from auxiliary domains to im-prove the learning for target data. To solve the problem, we proposed TrAcSVM which combines transfer learning and active learning in an effective way. TrAcSVM uses a small number of target data to obtain labeling information for auxiliary instances, such that labeled auxiliary instances can help build accurate prediction models for the target data. Experimental results on text and image data demon-strated that TrAcSVM can obtain better runtime perfor-mance, faster convergence speed and higher prediction ac-curacy than its peers.
 This work was partially supported under Australian Re-search Council X  X  Future Fellows hip funding scheme (project number FT100100971), and by National 973 Program (No. 2010CB327906), NSF of Chin a under Gra nt (No.60773048, No. 60873178, No. 60875003, and No. 60674109), the State Key Laboratory P rogram under Grant(No. RCS2009K003), the National High Technology Research and Development Program of China (No. 2009AA01A346). [1] R. Caruana. Multitask learning. Mach. Learn. , [2] W.Dai,Q.Yang,G.-R.Xue,andY.Yu.Boostingfor [3] G. Fung and O. L. Mangasarian. Proximal support [4] K. Lang. Newsweeder: Learning to filter netnews. In [5] Y. LeCun, Y. B. L. Bottou, and P. Haffner.
 [6] S. J. Pan and Q. Yang. A survey on transfer learning. [7] S. Thrun. Is learning the n -th thing any easier than [8] X. Zhu. Cross-domain semi-supervised learning using
