 In this paper we study asymmetric proximity measures on directed graphs, which quantify the relationships between two nodes or two groups of nodes. The measures are useful in several graph min-ing tasks, including clustering, link prediction and connection sub-graph discovery. Our proximity measure is based on the concept of escape probability . This way, we strive to summarize the mul-tiple facets of nodes-proximity, while avoiding some of the pit-falls to which alternative proximity measures are susceptible. A unique feature of the measures is accounting for the underlying directional information. We put a special emphasis on computa-tional efficiency, and develop fast solutions that are applicable in several settings. Our experimental study shows the usefulness of our proposed direction-aware proximity method for several appli-cations, and that our algorithms achieve a significant speedup (up to 50,000x) over straightforward implementations.
 H.2.8 [ Database Management ]: Database Applications  X  Data Mining Algorithm, experimentation Proximity, random walk, directionality, fast solution
Measuring node proximity is a fundamental problem in many graph mining settings. While most of existing measurements are (implicitly or explicitly) designed for undirected graphs; edge di-rections in the graph provide a new perspective to proximity mea-surement: measuring the proximity from A to B; rather than be-tween A and B (See Figure 1). Here, we study the role of direction in measuring proximity on graphs. To be specific, we will try to answer the following questions in this paper: Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00.
Q1 Problem definitions: How to define a direction-aware prox-
Q2 Computational issues: How to compute the proximity score
Q3 Applications: How can direction-aware proximity benefit Figure 1: On undirected graphs (a) we are interested in the proximity between A and B, whereas in a directed graph (b) we make the distinction between the proximity from A to B, or fromBtoA
We begin (Section 2) by proposing a novel direction-aware prox-imity definition, based on the notion of escape probability of ran-dom walks. It is carefully designed to deal with practical prob-lems such as the inherent noise and uncertainties associated with real life networks. Moreover, the proposed definition is general-ized to measure group proximities by defining group escape prob-ability. Then, in Section 3, we address computational efficiency, by concentrating on two scenarios: (1) the computation of a single proximity on a large, disk resident graph (with possibly millions of nodes). (2) The computation of multiple pairwise proximities on a medium sized graph (with up to a few tens of thousand nodes). For the former scenario, we develop an iterative solution to avoid matrix inversion, with convergence guarantee. For the latter sce-nario, we develop an efficient solution, which requires only a single matrix inversion, making careful use of the so-called block-matrix inversion lemma. Finally (Sections 4-5), we apply our direction-aware proximity to some real life problems. We demonstrate some encouraging results of the proposed direction-aware proximity for predicting the existence of links together with their direction. Other applications include directed center-piece subgraphs, and attribute graphs.
Here we give the main definitions behind our proposed node-to-node proximity measure, namely, the escape probability ; then we give the justification for our modifications to it; and finally we generalize our definition to handle the group-to-group proximity.
Let us start with the node-to-node proximity score, or simply node proximity . (We will introduce a more general, group proxim-ity score, in Subsection 2.3.) Following some recent works [6, 15, 19], our definition is based on properties of random walks associ-ated with the graph. Random walks mesh naturally with the ran-dom nature of the self-organizing networks that we deal with here. Importantly, they allow us to characterize relationships based on multiple paths. Random walk notions are known to parallel proper-ties of corresponding electric networks [5]. For example, this was the basis for the work of Faloutsos et al. [6] that measured nodes proximity by employing the notion of effective conductance. Since electric networks are inherently undirected, they cannot be used for our desired directed proximity measure. Nonetheless, the effective conductance can be adequately generalized to handle directional information by using the concept of escape probability [5]:
D EFINITION 1. The escape probability from node i to node ep i,j , is the probability that the random particle that starts from node i will visit node j before it returns to node i
Thus we adopt the escape probability as the starting point for our direction-aware node-to-node proximity score. That is, for the moment, we define the proximity Prox( i, j ) from nodes i exactly ep i,j .

An important quantity for the computation of ep i,j is the gen-eralized voltage at each of the nodes, denoted by v k ( i, j defined as the probability that a random particle that starts from node k will visit node j before node i . This way, our proximity measure can be stated as: where p i,k is the probability of a direct transition from node node k .
 For example, in Figure 1(b), we have Prox( A, B )=1 and Prox( B, A )=0 . 5 , which is consistent with our intuition that con-nections based of longer paths should be weaker. Table 1 gives a list of symbols used in this paper. Following standard notation, we use calligraphic font for sets (e.g., V ), bold capitals for matrices (e.g., W , P ), and arrows for column vectors (e.g., 1 ).
Given a weighted directed graph W , there is a natural random walk associated with it whose transition matrix P is the normal-ized version of W , defined as P = D  X  1 W . Recall that D is Symbol Definition
W =[ w i,j ] the weighted graph, 1  X  i, j  X  n , w i,j A T the transpose of matrix A D n  X  n diagonal matrix of out-degrees: P =[ p i,j ] the transition matrix associated with the graph G =[ g i,j ] the G-matrix associated with P : V the whole set of the nodes V = { 1 , .., n } A , B two groups of nodes A = { i 1 , ...i |A| } ,
P ( A , B ) a block of matrix P : P ( A , B )= [ p i,j ] , P ( i, :) i th row of matrix P P (: ,j ) j th column of matrix P Prox( i, j ) node proximity from node i to node j
Prox( A , B ) group proximity from group A to group B 1 a (column) vector whose all elements are 1 X  X  e i a column vector whose i th element is 1 c 1  X  c is the transition probability from n the total number of the nodes in the graph m the maximum number of iterations the diagonal matrix of the node out-degrees (specifically, sum of outgoing weights). However, for real problems, this matrix leads to escape probability scores that might not agree with human intu-ition. In this subsection, we discuss three necessary modifications, to improve the quality of the resulting escape probability scores. Figure 2: Nodes F and E have no influence on the A  X  B escape probability
When measuring the escape probability from i to j we assume that the random particle must eventually reach either i or means that no matter how long it wanders around, it will make unlimited tries, till reaching i or j .

This ignores any noise or friction that practically exist in the sys-tem and causes the particle to disappear or decay over time. In par-ticular, this problem is manifested in dead-end paths, or degree-1 nodes, which are very common in practical networks whose degree distribution follows a power law. We demonstrate this in Figure 2 where, intuitively, nodes E and F, distract the A-D-B connection, so the proximity from A to B in (a) should be larger than that in (b). However, in terms of the escape probability, they are the same (both equal 1). In other words, the influence of those degree-1 nodes ( and F ) is not taken into account. To address this issue, we model the friction in the system by augmenting it with a new node with a zero out degree known as the universal sink (mimicking an absorb-ing boundary): Now, each node has some small transition proba-bility, 1-c, to reach the sink; and whenever the random particle has reached the sink, it will stay there forever. For example, if we add a sink to Figure 2 with c =0 . 9 , Prox(A,B) is 0.81 in (a), but only 0.74 in (b), which is consistent with our intuition. Note that in this case, equation (1) becomes:
A weakly connected pair is two nodes that are not connected by any directed path, but become connected when considering undi-rected paths (see, e.g., Figure 3(a)). For such weakly connected pairs, the direction-aware proximity will be zero. However, in some situations, especially when there are missing links in the graph, this might not be desirable. In fact, while we strive to account for di-rectionality, we also want to consider some portion of the directed link as an undirected one. For example, in phone-call networks, the fact that person A called person B, implies some symmetric rela-tion between the two persons and thereby a greater probability that B will call A (or has already called A but this link is missing).
A random walk modeling of the problem gives us the flexibil-ity to address this issue by introducing lower probability backward edges: whenever we observe an edge w i,j in the original graph, we put another edge in the opposite direction w j,i  X  w i,j . In other words, we replace the original W with (1  X   X  ) W +  X  W T ( 0  X &lt; 1 ). For example, in Figure 3(b), by introducing backward edges with  X  =0 . 1 , we get Prox( B, A )=0 . 009 , which is much smaller than Prox( A, B )=0 . 081 , but nonetheless greater than zero. Note that  X  =0 . 5 is equivalent to ignoring edge directions. Figure 3: Dealing with weak connections by partial sym-metrization
Many of the graphs we deal with are huge, so when computing the proximity, a frequently used technique is to limit its computa-tion to a much smaller candidate graph , which will significantly speed-up the computation. Existing techniques [6, 15], are look-ing a for a moderately sized graph that contains the relevant por-tions of the network (relatively to a given proximity query), while Figure 4: Dealing with size bias: (a) is the original graph; (b) and (c) are candidate graphs with and without out-degree preservation, respectively. still enabling quick computation. These techniques can be directly employed when computing our proximity measure.

As pointed out in [15], for a robust proximity measure, the score given by the candidate graph should not be greater than the score which is based on the full graph. The desired situation is that the proximity between two nodes will monotonically converge to a sta-ble value as the candidate graph becomes larger. However, this is often not the case if we compute the escape probability directly on the candidate graph (see Figure 4(a) and (b) for an example)
To address this issue, we should work with degree preserving candidate graphs. That is, for every node in the candidate graph, its out degree is the same as in the original graph. Now in Figure 4(c), by preserving degrees, the proximity from A to B is smaller than that in (a). More precisely, we have the following lemma:
L EMMA 1. Consider two nodes i and j , and let Prox Ori be be the one computed on the degree preserving candidate graph. Then we have Prox Ori  X  Prox Cand , for any pair of nodes j .
 Proof: Omitted for brevity
Now, let us generalize our directed proximity measure to mea-sure the proximity between two groups of nodes. To this end, we define the group escape probability as: Analogously, we define: Therefore our group proximity is defined as follows: Prox( A , B ) gep A , B = 1 |A|
From equations (2) and (3), we see that the node-to-node prox-imity is a special case of the group-to-group proximity, by setting A = { i } and B = { j } .
Here we deal with the computational aspects of the directed prox-imity measures defined by equations (2) and (3). First, we will show that straight-forward ways to compute these proximities cor-respond to solving a specific linear system, which involves a ma-trix inversion. Then, we will propose fast solutions for computing a single proximity on a large graph or all pairwise proximities on a medium sized graph. Notice that these fast solutions will be also beneficial for measuring undirected proximity.
Node proximity is based on the linear system [5]: By solving the above linear system, we have [5]: where I = V X  X  i, j } ; P ( i, I ) is the i th row of P without j th elements; P ( I ,j ) is the j th column of P without i elements; and
Using a similar procedure, we reach the following lemma for computing group proximity: L EMMA 2. Let C = A X  X  .If C = X  , the group proximity  X  Prox( A , B ) of equation (3)  X  is determined by equation (7) ; other-wise, it is determined by equation (8) .

Prox( A , B )= 1 T ( c where I = V X  ( A X  X  ) , A X  X  = { i, i  X  X  ,i/  X  X } , B X  X  = { i, i  X  X  ,i/  X  X } , and G =( I  X  c P ( I ))  X  1 Proof: Omitted for brevity. Both equations (5) and (7) involve G  X  an inversion of a matrix. Suppose |A| n and |B| n , 1 the major computational cost in both cases is the inversion of an n  X  n matrix, which brings up two computational efficiency challenges: 1. ( Setting 1 ) For a large graph, say with hundreds of thousands 2. ( Setting 2 ) The above computation requires a different ma-
We propose FastOneDAP (Table 2), a fast iterative solution for computing one node proximity.

In FastOneDAP , the major computational cost lies in the iter-ative step. Let m be the maximum number of iterations and the number of total edges in the graph, The complexity of Fas-tOneDAP is O ( mE ) . In other words, FastOneDAP is linear in the number of edges in the graph. Often, real graphs are very sparse, which means that E is much less than n 2 (e.g., for typical graphs that obey power law [7]: E  X  n 1+ ). Thus, FastOneDAP is signif-icantly more efficient than the straightforward solver, whose run-ning time is O ( n 3 ) due to matrix inversion.

Before discussing the correctness of FastOneDAP , we need the following block matrix inversion lemma, which plays an essential role in our fast solutions:
L EMMA 3. Block Matrix Inversion Lemma : Partition the ma-trix M into four blocks: Prox( A , B ) by equation (7) efficiently. Thus, throughout this pa-per, we suppose that the size of the group is always much smaller than that of the whole graph. Then, where S = D  X  CA  X  1 B Proof: See, e.g., [10] Based on the block matrix inversion lemma, the correctness of FastOneDAP is guaranteed by the following lemma.

L EMMA 4. The value Prox( i, j ) , as computed by FastOneDAP con-verges to the proximity Prox( i, j ) defined in equation (5) . Proof: Without loss of generality, we only need to prove the case when i = n  X  1 and j = n . Let V n  X  1 = V X  X  j } = { 1 , ..., n and V n  X  2 = V X  X  i, j } = { 1 , ..., n  X  2 } . (for uniformity, from now on, we refer V as V n .) With this notation, we have i
First, Note that as the iteration k of step 2 goes to infinite: which proves the convergence of step 2 in FastOneDAP .

Next, by Taylor expansion, we have the following equation: which proves that at the end of step 2, v T will converge to the row of G .

Furthermore, by the lemma for block matrix inversion, we have: Finally, we have: which completes the proof of lemma 4. Similarly, we can develop the following fast algorithm ( FastOneG-DAP ; Table 3) for computing one group proximity on a large graph. where I = V X  ( A X  X  )
As in FastOneDAP , let m be the maximum number of itera-tions and E the total number of edges in P , the complexity of FastOneGDAP is O ( mE ) . Suppose |A| n and |B| n ,we have E  X  E . Thus, the complexity of FastOneGDAP is O ( mE Similarly, we can prove the following lemma for FastOneGDAP .
L EMMA 5. The group proximity Prox( A , B ) by FastOneGDAP con-verges to the proximity Prox( A , B ) by equation (7) . Proof: Omitted for brevity.
Earlier we showed how to make the computations efficient, when we have only one pair of nodes (or one pair of groups) for which we want the proximity score. Here we show how to estimate multiple such pairs of scores very efficiently.
Suppose that we want to compute all n ( n  X  1) pairwise node proximities. There are various situations where one might want to compute all (or many) proximities. First, collecting all proximi-ties and studying their distribution can reveal interesting features of the network and tell us about its global structure. In addition, some algorithms  X  such as distance based clustering  X  require the knowledge of all (or at least many) pairwise proximities.
Computation of many pairwise proximities in the same network involves solving many linear systems (in fact, one matrix inversion for each proximity). However, there is a lot of redundancy among different linear systems. In fact, we propose a much more efficient method, that need only solve one linear system (or, invert a sin-gle matrix) and leverage its result to quickly solve all the others. Consequently, we suggest the FastAllDAP algortihm (Table 4).
The major benefit of FastAllDAP is the dramatic reduction of matrix inversion operations from n ( n  X  1) to a single one. Its correctness is guaranteed by the following lemma:
L EMMA 6. FastAllDAP gives exactly the same result as equa-tion (5) . Proof: Without loss of generality, we only need to prove that when i = n  X  1 and j = n , Prox( n  X  1 ,n )=Prox( n  X  1 ,n ) holds. Let G be defined as in equation (11).
 According to the proof of Lemma 4 (Eq. 15), we have
Furthermore, by applying the lemma of block matrix inversion [10] on G and G , we have:
G ( n  X  1 , :) c P ( V n  X  1 ,n )= g n  X  1 ,n Combining equations (17) and (18) we have the proof.
Let {A 1 , ..., A n 1 } , {B 1 , ..., B n 2 } be two sets of groups. To compute all n 1  X  n 2 induced group proximities, we employ the FastManyGDAP algorithm (Table 5).

Suppose that |A i | n and |B j | n . Then, compared with step 1, the computational cost of Step 2.1.1 and 2.1.3 can be ig-nored. Thus, if we take matrix inversion as the basic operation, FastManyGDAP reduces the computational cost from O ( n 1  X  to
O (1) . By extending the proof of Lemma 6, we have the follow-ing lemma:
L EMMA 7. FastManyGDAP gives exactly the same result as equation (5) .
 Proof: Omitted for brevity.
We focus on three graph mining applications, to illustrate the ef-fectiveness of our proposed proximity functions. The applications are (a) link prediction (b)  X  X enter Piece Subgraphs X  for the directed case and (c) the creation of  X  X ttribute Graphs X .
As a proximity measurement, our direction-aware proximity can be directly used for link prediction. More specifically, it can be used for the following two tasks:
T1: ( Existence ) Given two nodes, predict the existence of a link
T2: ( Direction ) Given two adjacent (linked) nodes, predict the For T1 , we use the simple rule:
A1: Predict a link between i and j iff Prox( i, j )+Prox( Alternatively, we can use group proximity for T1 : A1 X : (Node Expansion) Predict a link between i and j iff As for directionality prediction, T2 , we use the rule:
A2: Predict a link from i to j if Prox( i, j ) &gt; Prox(
Related experimental results will be given in Section 5.
The concept connection subgraphs, or center-piece subgraphs, was proposed in [6, 19]: Given Q query nodes, it creates a sub-graph H that shows the relationships between the query nodes. The resulting subgraph should contain the nodes that have strong con-nection to all or most of the query nodes. Moreover, since this sub-graph H is used for visually demonstrating node relations, its visual complexity is capped by setting an upper limit, or a budget on its size. These so-called connection subgraphs (or center-piece sub-graphs) were proved useful in various applications, but currently only handle undirected relationships.

With our direction-aware proximity, the algorithm for construct-ing center-piece subgraphs (CePS) can be naturally generalized to handle directed graphs. A central operation in the original CePS algorithm was to compute an importance score, r ( i, j ) for a sin-gle node j w.r.t. a single query node q i . Subsequently, these per-query importance scores are combined to importance scores w.r.t. the whole query set, thereby measuring how important each node is relatively to the given group of query nodes. This combination is done through a so-called K softAND integration that produces r ( Q ,j )  X  the importance score for a single node j w.r.t. the whole query set Q . For more details please refer to [19].

The main modification that we introduce to the original CePS al-gorithm is the use of directed proximity for calculating importance scores. The resulting algorithm is named Dir-CePS and is given in Table 6.

Directional information must also involve the input to Dir-CePS , through the token vector f =[ f 1 , ...f Q ] , ( f i =  X  1) , which splits the query set into  X  X ources X  and  X  X argets X , such that each proximity or path are computed from some source to some target. The re-maining parts of Dir-CePS are exactly the same as in [19]; details are skipped here due to space limitations.

Figure 5 presents an example of our Dir-CePS on a citation net-work (see Subsection 5.1.1 for a description of the data). Given two papers as the query nodes, by setting different token vectors can visually explore different perspectives on how these two papers relate: (1) let f =[+1 ,  X  1] , we can examine how the former paper influences the latter one (Figure 5(a)); (2) let f =[+1 , can visually show how these papers influence other papers (Fig-ure 5(b)); and (3) let f =[  X  1 ,  X  1] , we can examine how these papers are influenced by other papers (Figure 5(c)). Prox( j, i ) is closed with each other(say, by some threshold), we can always predict a bi-directional edge. paper that initiated the research areas of the query papers/nodes.
For graphs whose nodes are associated with discrete attributes, we would like to explore the relationships among these attributes, and find, e.g., which attributes are close and whether we can find symmetric attributes. For example, consider an who-mails-whom network, where nodes/people are labeled by their job title -we want to find whether and how  X  X anagers X  are related to  X  X ales-persons X , and conversely. We propose to use our group proximity scores, to construct an Attribute Graph (AG) :
D EFINITION 2. Let W be a directed graph, where the nodes have an attributed with n categorical values ( a 1 , ..., a be the group of nodes whose attribute value is a i . The associated attribute graph AG is an n  X  n weighted digraph where every node corresponds to an attribute and the edge weights show the group-to-group proximity scores: AG ( a i ,a j )=Prox( A i
The Web Link dataset (WL) is described in Subsection 5.1.1. It consists of web pages pointing to each other, and every web page has one of the labels:  X  X aculty X ,  X  X roject X ,  X  X taff X  etc. We show its attribute graph in Figure 6. All edges of weight less than 0.05 were removed for visual clarity. This graph reveals interesting re-lationships among the attributes. For example, we can observe the roles of different attributes:  X  X epartment X  as the  X  X ore X ,  X  X taff X  as the  X  X ent-out guy X , and  X  X tudent X  as the  X  X ink X . Closely related attributes include  X  X aculty X  X  X  X ourse X , and  X  X taff X  X  X  X roject X . How-ever, we can see that while  X  X aculty X  and  X  X ourse X  are symmetrically close, the  X  X taff X  X  X  X roject X  closeness is asymmetric.

We present experiments on large, real datasets. Our goals are to do an evaluation of our design decisions, to illustrate the effective-ness of our approach on real tasks like link prediction, and to study the scalability of our methods. We start with the description of our datasets. We experimented with the following directed networks:
WL (Web Link Graph) 3 . In this unweighted graph, nodes de-note web pages, and edges correspond to web links. The nodes are associated with one of the seven attributes:  X  X epartment X ,  X  X taff X ,  X  X tudent X ,  X  X aculty X ,  X  X ourse X ,  X  X roject X  and  X  X ther X . Totally, there are  X  4 K nodes and  X  10 K edges.

PC Personal Contact Network This dataset is a subset of an anonymized who-contacts-whom network. Nodes correspond to users, and edges are weighted by the corresponding average daily contact time. Totally, there are  X  36 K nodes and  X  64 K edges.
CN (Citation Network) 4 . This is an unweighted citation net-work, containing a subset of the arXiv dataset. Nodes are papers and edges are citations. It has  X  28 K nodes and  X  353 K edges. 20/www/data/
EP (Epinions Who-Trusts-Whom Network) 5 . Unweighted net-work, used in [4]. Nodes denote users, and edge ( i, j ) means that user i trusts user j . It has  X  76 K nodes and  X  509 K edges.
AE (Anonymous Email Network). This network describes un-weighted relations among email accounts from a large research or-ganization. Nodes are (anonymized) accounts, and edge ( i dicates that account i has sent one or more e-mail messages to ac-count j . There are  X  38 K nodes and  X  115 K edges.
After a parametric study (details skipped for space limitation), we set low values to the parameters c (strength of sink connec-tions) and  X  (the symmetrization factor), and specifically and  X  =0 . 001 for all the experiments. We stop the iterations in both FastOneDAP and FastOneGDAP when we reach m =80 it-erations, or when the L 2 difference between successive values of v is below some threshold (  X  =10  X  9 ). All experiments were per-formed on the same machine with a 3.2GHz Pentium CPU and 2GB memory. First, we evaluate the ability to predict the existence of a link. We compare four methods: A1 (plain node-to-node comparisons, see Subsection 4.1) utilizing directionality ( ND ), and ignoring di-rectionality ( NU ); A1 X  (Node Expansion -see Subsection 4.1) uti-lizing directionality ( GD ), and ignoring it ( GU ). For all the meth-ods, the threshold ( th ) is determined by leave-one-out cross valida-tion [12]. For all the experiments, the number of test pairs with link between them roughly equals the number of unlinked test pairs. In addition to the prediction accuracy, we also use average margin (
AM ): 6 . Suppose we have n test pairs: ( i 1 ,j 1 ) ,..., Let Sc ( k )=Prox( i k ,j k )+Prox( j k ,i k ) when using A1 or average margin (AM) is defined as: where y ( k )=1 if there exists a link between i k and j k y ( k )=  X  1 otherwise. Basically, AM estimates the confidence of the prediction by measuring how far the test pair is from the threshold (further is better).

The results are shown in Tables 7 and 8. It can be seen that while all four methods are effective for link prediction, the direction-aware proximity (both node and group versions) is usually better than the undirected proximity. E.g., in terms of prediction accuracy, the winning method is always based on direction-aware proximity. Another interesting observation is that the methods based on group proximity (GD and GU) usually outperform those based on node proximity (PD and PU). In particular, GD and GU tend to lead to much higher margins ( AM ) than PD and PU.

We also evaluated the performance on predicting the direction of a link; see Table 9. Please notice that here comparison with an undirected version is inherently impossible. Our method seems to be effective on all datasets, though its degree of success varies a lot among the datasets . Additionally, we construct a test set ( i ,j 1 ) ,..., ( i n ,j n ) , such that for each pair ( i k set, there exists a link from i k to j k and there is no link in the opposite direction. Figure 7 plots the histogram of Prox( Prox( j k ,i k ) for WL . It can be seen that as desired, the histogram logistic regression and boosting [3, 8] Table 7: Existence of link (Accuracy); percents indicates frac-tion of successful predictions. Directionality-aware methods (GD, ND) outperform the rest Table 8: Existence of link (Average Margin); higher values in-dicate greater confidence. Again, directionality-aware methods win (GD,ND); Node expansion also helps (GD method).
 is biased w.r.t. the origin: there are many more pairs in the positive zone.

We measured the efficiency of the proposed fast solutions. A subset of the EP network is adopted to verify how the fast solutions scale with the size of the graph. Let N be the number of nodes in the subset. We fix the group size to be 0 . 01 N . To test Fast-ManyGDAP , we generate two sets of groups, each of them contains 0 . 25 N groups; and we compute totally 0 . 25 N  X  0 . 25 N group proximities. Figure 8 plots the mean running times vs. the number of the nodes. Notice that the y axis is logarithmic , to accommodate the huge performance savings of our methods. In all cases, our so-lutions are 1-4 orders of magnitude faster than the straight-forward ones. For example, for a graph with 61 K nodes and 484 K edges, FastOneDAP is 59,000 times faster than the straight-forward meth-ods (2.2 sec vs. 114K sec), and FastOneGDAP is 18,000 times faster(6.2 sec vs. 111K sec); for a graph with 5 K nodes and 25 edges, FastAllDAP is 3 , 000 times faster (57 sec vs. 167K sec), and FastManyGDAP is 57 faster (2.8K Sec vs. 163K Sec). We stress that, in all cases, our proposed methods do not lose accuracy since they either converge ( FastOneDAP and FastOneGDAP )or are exactly equal ( FastAllDAP and FastManyGDAP ) to the true proximity value. Figure 7: Density histogram of Prox( i k ,j k )  X  Prox( j the WL dataset. Successful predictions correspond to the posi-tive values of the x axis, and they clearly outnumber the wrong predictions (the negative x -values). In the literature, there are several measures of node proximity. Most standard measures are based on basic graph theoretical con-cepts -the shortest path length and the maximum flow. However the dependency of these measures on a single element of the graph  X  the shortest path or the minimum cut  X  makes them more suitable to managed networks, but inappropriate for measuring the random nature of relationships within social networks or other self orga-nizing networks. Consequently, some works suggested more in-volved measures such as the sink-augmented delivered current [6], cycle free effective conductance [15], survivable network [11], ran-dom walks with restart [14, 17] and more. Notice that none of the existing methods meets all the three desirable properties that our approach meets: (a) dealing with directionality, (b) quality of the proximity score and (c) scalability.

Graph proximity is an important building block in many graph mining settings. Representative work includes connection subgraph [6, 15, 19], personalized PageRank [13], neighborhood formulation in bipartite graphs [18], content-based image retrieval [14], cross modal correlation discovery [17], the BANKS system [1], link pre-diction [16], detecting anomalous nodes and links in the graph [18], ObjectRank [2] and RelationalRank [9].
In this work, we study the role of directionality in measuring proximity on graphs. We define a direction-aware proximity mea-sure based on the random walk notion of escape probability. This measure naturally weights and quantifies the multiple relationships which are reflected through the many paths connecting node pairs. Moreover, the proposed proximity measure is carefully designed to deal with practical situations such as accounting for noise and facing partial information. A useful generalization of the measure deals with proximity between groups of nodes.

Given the growing size of networked data, a good proximity measure should be accompanied with a fast algorithm. Conse-quently we offer fast solutions, addressing two settings. First, an it-erative algorithm, with convergence guarantee, to compute a single node-to-node proximity value on a large graph. Second, an accurate algorithm that computes all (or many) pairwise proximities on a medium sized graph. These proposed algorithms achieve orders of magnitude speedup compared to straightforward approaches, with-out quality loss.

We have studied the applications of the proposed proximity mea-sure to real datasets. Encouraging results demonstrate that the mea-sure is effective for link prediction. Importantly, being direction-aware, it enables predicting not only the existence of the link but also its direction. Another application is the so-called directed center-piece subgraph, where we employ the proposed proximity measure to carefully select presentable subgraphs that capture rela-tions among a set of query nodes. In addition, our proposed group proximity is useful to explore the relationship among attributes by building Attribute Graph. [1] B. Aditya, G. Bhalotia, S. Chakrabarti, A. Hulgeri, C. Nakhe, [2] A. Balmin, V. Hristidis, and Y. Papakonstantinou.
 [3] M. Collins, R. Schapire, and Y. Singer. Logistic regression, [4] P. Domingos and M. Richardson. Mining the network value [5] P. Doyle and J. Snell. Random walks and electric networks , [6] C. Faloutsos, K. S. McCurley, and A. Tomkins. Fast [7] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On power-law [8] J. Friedman. Greedy function approximation: A gradient [9] F. Geerts, H. Mannila, and E. Terzi. Relational link-based [10] G. Golub and C. Loan. Matrix Computation . Johns Hopkins, [11] M. Gr  X  otschel, C. L. Monma, and M. Stoer. Design of [12] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of [13] T. H. Haveliwala. Topic-sensitive pagerank. WWW , pages [14] J. He, M. Li, H. Zhang, H. Tong, and C. Zhang.
 [15] Y. Koren, S. C. North, and C. Volinsky. Measuring and [16] D. Liben-Nowell and J. Kleinberg. The link prediction [17] J.-Y. Pan, H.-J. Yang, C. Faloutsos, and P. Duygulu. [18] J. Sun, H. Qu, D. Chakrabarti, and C. Faloutsos.
 [19] H. Tong and C. Faloutsos. Center-piece subgraphs: Problem There are some plausible variants of the proposed direction-aware proximity. One possibility is to multiply the escape probability by the out-degree of the origin node:
By multiplying by the degree, we measure absolute connectiv-ity instead of relative connectivity. This way, proximities related to high degree nodes become more prominent. Interestingly, for undi-rected graphs multiplying the escape probability by the origin X  X  de-gree is equivalent to effective conductance [5].

Some recent works [17, 19] relied on another random work no-tion for measuring node proximity on graphs -random walk with restart . This notion considers a random walk that starts wander-ing in the graph beginning at an origin node i , and at each step has some probability 1  X  c to retract back to i . Then, Prox( be defined as the steady state probability r i,j that the particle will finally stay at node j .

Based on the proof of Lemma 6, the relationship between ran-dom walk with restart and escape probability ( ep ) is made explicit by the following lemma:
L EMMA 8. Let r i,j be the steady-state probability for node w.r.t. node i , then: This material is based upon work supported by the National Sci-ence Foundation under Grants No. IIS-0326322 IIS-0534205 and under the auspices of the U.S. Department of Energy by University of California Lawrence Livermore National Laboratory under con-tract No.W-7405-ENG-48. This work is also partially supported by the Pennsylvania Infrastructure Technology Alliance (PITA), an IBM Faculty Award, a Yahoo Research Alliance Gift, with addi-tional funding from Intel, NTT and Hewlett-Packard. Any opin-ions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily re-flect the views of the National Science Foundation, or other funding parties. The authors give their sincere gratitude to Chris Volinsky, Jure Les kovec, Pedro Domingos and Matt Richardson for helping us collect some of the datasets.
