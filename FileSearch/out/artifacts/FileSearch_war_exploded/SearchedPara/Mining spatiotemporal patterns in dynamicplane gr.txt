
Universit X  de Lyon, CNRS, INSA-Lyon, LIRIS, France
Universit X  de Lyon, Universit X  de St-Etienne, UMR CNRS 5516, Laboratoire Hubert-Curien, France Alcatel-Lucent Bell Labs, Centre de Villarceaux, Nozay, France 1. Introduction
Graph mining is a popular data mining task with many applications in, for example, analysis of (social, gene, protein) networks. The idea of this task is to search for all subgraphs that frequently appear in a dataset of graphs or even within a single large graph. In some cases, however, this dataset may consist of a series of graphs representing the evolution of a single graph over time, that is, a dynamic graph. Here, frequent subgraphs must capture the evolution of such graph, such as the insertion or deletion of edges or nodes.

In this paper, we are interested in mining dynamic graphs applied to videos. We regard a video as a dynamic graph, whose evolution over time is represented by a series of graphs, one graph for each video frame. More precisely, we represent each frame as a plane graph , that is, a planar graph already drawn in the plane without edge intersections, by means of region adjacency relationships [4] or Delaunay corresponding graph, and an edge exists between two nodes if the regions are adjacent in the frame. Some example video frames along with their respective triangulated and region adjacency representations are illustrated in Fig. 8.
By representing a video as a series of plane graphs, subgraph patterns in this series may correspond associating spatial information to each node in these graphs, such as the barycenter of the originating frame regions, it becomes possible to track a given object through the video being mined. In this context, we present two graph mining algorithms, called P LAGRAM ( Pla ne Gra ph M ining) and D
Y P LAGRAM ( Dy namic Pla ne Gra ph M ining), which are dedicated to mine frequent plane subgraphs from a database of plane graphs. One of the main characteristics of these algorithms is that they can be used as the basis for the extraction of what we called spatiotemporal patterns . A spatiotemporal pattern is a set of occurrences of a given pattern which are not too far apart w.r.t time nor space.
We have therefore divided the paper in the following way. The next section is dedicated to the related work on frequent (dynamic) graph mining. In Section 3, we formally de fi ne the problem studied in this paper. The algorithms P LAGRAM and D Y P LAGRAM , along with a complexity study, are presented in Section 4. In Section 5, we report on some experiments on the ef fi ciency of the proposed algorithms. We also discuss their usefulness in tackling the problem of object tracking in videos. We conclude in Section 6. 2. Related work
Typical frequent graph mining algorithms generate plausible pattern subgraphs and then compute their frequency while fi nding all their occurrences in a database of target graphs. Afterwards, frequent patterns (w.r.t. a user-de fi ned threshold) are extended in a valid way such that bigger patterns can also be evaluated.

Due to the numerous necessary NP-complete subgraph isomorphism tests, current graph mining ap-proaches, such as G ASTON [15], G S PA N [18], FSG [13], and AGM [9] can only deal with applications where the subgraph isomorphism test is not too costly or when there are not too many such tests, e.g., when the target graphs are small, their nodes have low degree, have many node (or edge) labels, have a low number of cycles, etc.

Indeed, most of the recent work on the subject has been dedicated to fi nding subclasses of graphs (outer planar graphs [8], graphs with a different label for each node [12], acyclic graphs, sparse graphs etc.), which lead to more ef fi cient algorithms. Following the same line, the focus of our algorithms, P
LAGRAM and D Y P LAGRAM , is on plane subgraphs. Plane graphs are particularly interesting since the subgraph isomorphism test for this type of graphs is known to be polynomial (see, for example, [5]). In addition, we impose a restriction on graph extensions such that a graph can only be extended with faces. This technique is related to that used in AGM [9], which searches for all frequent node-induced less ef fi cient than G S PA N and our algorithms.

Yet, current general-purpose graph mining algorithms do not computationally bene fi t from the plane property of target graphs and therefore cannot tackle in a satisfactory way our video application. As pointed out in the experimental section, the popular algorithm G S PA N could not fi nish its executions on our video datasets within 3 days of computation. In addition, we observed that the extension building phase of G S PA N was, on average, 90% of its total execution time. This is due to the fact that G S PA N extends the pattern graphs by adding a single edge at a time, which led to an extremely high number of extensions, even for the lowest tested minimum frequency.

Regarding the research on dynamic graph mining, current algorithms consider a dynamic graph with only edges insertions or deletions, i.e., the time series of graphs share the same set of nodes over time (see, e.g. [14]), or in which nodes and edges are only added and never deleted (see, e.g. [2]). In our approach, however, there is no information about the correspondence between the nodes in one graph (video frame) and those in the others. Instead, we know, for each node in a plane graph, the barycenter as presented in the introduction.

Our algorithms borrow many features from the algorithm G S PA N . G S PA N performs a depth-fi rst search in a space of canonical codes, which are computed such that two isomorphic graphs are not evaluated twice. One of the most acknowledged bottleneck of this algorithm (we show in the experimental section that this is not the main one) comes from the subgraph isomorphism tests. In particular, G S PA N is not well suited to mine graphs with many cycles as their presence increases exponentially the number of fre-quent subgraphs. However, the particular plane subgraphs considered in this paper are far less numerous than the subgraphs considered by G S PA N , which makes our approach not only unsurprisingly faster, but also capable of dealing with much more complex graphs (in terms of degrees and size) than G S PA N .
The algorithm P LAGRAM was introduced in [16]. Here, we extend it to D Y P LAGRAM , in the context patterns. To the best of our knowledge, the papers that are the closest to ours are [6,11]. In the former, the authors use combinatorial maps to represent images and propose an algorithm to mine frequent submaps. Although we use similar structures to represent video frames, i.e., plane graphs, our work goes much further since we consider dynamic aspects applied to videos. In [11], the authors use the algorithm SUBDUE [7] to extract the background from videos fi lmed by a static surveillance camera. They assume that the background appears more frequently than the foreground in such videos. Differently from our approach, a video is represented by one single graph (dynamic aspects are not taken into account), and the goal is to extract only the most relevant subgraph w.r.t a ranking measure based on the MDL principle. In our approach, we are interesting in identifying the most interesting objects w.r.t their frequency in a dynamic environment. 3. De fi nitions 3.1. Plane graphs
We use ordered graphs to represent plane graphs. Ordered graphs are not necessarily planar, but here we restrict ourselves to planar ordered graphs [10].
 De fi nition 1 (Labeled ordered graph) . A labeled ordered graph G =( V,N,L e ,L n ) is a set of nodes V functions L e and L n map, respectively, each edge and each node of the graph to a label. De fi nition 2 (Plane graph) . Given a planar embedding of a labeled graph, a labeled ordered graph is constructed by de fi ning N ( v ) as the list of neighbors of v in an anti-clockwise order around v .This labeled ordered graph is called a plane graph .
 De fi nition 3 (Face) . Given a plane graph, a face is a connected region of the plane which is bounded by a circuit of edges. It is represented by the list of nodes encountered when following the circuit such that the face is always on the left-hand side. The unbounded region in the embedding of the graph is called the outer face of the graph. The other faces are called internal faces . Example 1. Figure 1 presents three plane graphs and Table 1 gives their lists of neighbors. Notice that faces 1 , 2 , 3 and 2 , 4 , 5 , 3 , and its outer face is 1 , 3 , 5 , 4 , 2 . 3.2. Plane subgraph isomorphism
A plane graph is a plane subgraph of another plane graph if there exists a correspondence between their nodes which preserves the labels, the edges and also the internal faces (if the outer face is also preserved, then the graphs are plane isomorphic).
 De fi nition 4 (Plane subgraph isomorphism) . Let G =( V,N,L e ,L n ) and G =( V ,N ,L e ,L n ) be two plane graphs. Graph G is plane subgraph isomorphic to G (or G is a plane subgraph of G ), denoted G  X  G , if there is an injective function f from V to V such that: for all nodes u of G , L F = v 1 , ..., v k of G , f ( F )= f ( v 1 ) , ..., f ( v k ) is a face of G .
 De fi nition 5 (Occurrence of a plane graph in a larger graph) . Let G =( V,N,L e ,L n ) and G = (
V ,N ,L e ,L n ) be two plane graphs. If G is plane subgraph isomorphic to G , the corresponding injective function f is called an o ccurrence of G in G .
 g f (4) = 6 and f (5) = 7 . Graph g 2 has three internal mutually adjacent faces, one with four edges and two with three edges. Since such con fi guration of faces does not exist in G , g 2 is not a plane subgraph of G .
 3.3. Dynamic graphs and spatiotemporal patterns De fi nition 6 (Dynamic graph) . A dynamic graph D is an ordered set of plane graphs { G 1 ,G 2 ,...,G n } in which each node of these graphs is associated to spatial coordinates ( x, y ) and a weight w . Example 3. In our video application, each plane graph G i represents a video frame. Each node in a graph represents a segmented frame region, and is associated to the coordinates ( x, y ) of the barycenter of the pixels of this region along with its size in pixels (weight).
 De fi nition 7 (Occurrences of a plane graph in a dynamic graph) . Given a plane graph P and a dynamic graph D = { G 1 , ..., G n } , the set of occurrences of P in D is de fi ned as Occ ( P )= { ( i, f ) | f is an occurrence of P in G i } .

The spatial coordinates ( x o ,y o ) of an occurrence o =( i, f )  X  Occ ( P ) is de fi ned as the weighted average of the spatial coordinates ( x, y ) of the nodes in f ( P ) .
 De fi nition 8 (Frequency of a plane graph in a dynamic graph) . The frequency freq ( P ) of a plane graph P in a dynamic graph D is the number of graphs G i  X  X  in which there is an occurrence of P , i.e., |{ i | X  f, ( i, f )  X  Occ ( P ) }| .

In typical subgraph mining problems, where the input collection of graphs does not represent a dy-namic graph, the frequency of a pattern graph P is computed regardless of the fact that its occurrences notion of spatiotemporal pattern in which occurrences of the same pattern that are close to one another are aggregated.
 De fi nition 9 (Spatiotemporal pattern) . Two occurrences of a plane graph P in a dynamic graph D , o =( i, f ) and o =( i ,f ) , are close if the distance between their coordinates is lower than a spatial threshold and their time distance | i  X  i | is lower than a time threshold  X  . Then, given a plane graph P and a dynamic graph D ,wede fi ne the occurrence graph of P as a graph where the set of nodes is graph of P is a spatiotemporal pattern S based on P .
 De fi nition 10 (Frequency of a spatiotemporal pattern) . The frequency of a spatiotemporal pattern S based on a plane graph P in a dynamic graph D , denoted freq st ( P,S ) ,is |{ i | X  f, ( i, f )  X  S }| . Example 4. Figure 2 shows 7 occurrences of a pattern P in a video with four frames. Therefore, freq ( P )=4 . Since occurrences 1 and 2 are close to each other, i.e., they appear in consecutive frames at a similar position, there is an edge (1 , 2) in the occurrence graph of P . Conversely, the edge (1 , 5) does not exist in the occurrence graph, as occurrences 1 and 5 are far from each other. There are 3 are: freq st ( P,S 1 )= freq st ( P,S 2 )=3 , and freq st ( P,S 3 )=1 . 3.4. Problem de fi nition
Given a frequency threshold  X  (also called minimum support), a spatial threshold and a time thresh-old  X  , the problem we tackle in this paper is to compute all spatiotemporal patterns with freq st greater than  X  . 4. Plagram and DyPlagram algorithms
Given two plane graphs such that P  X  P , if there is an occurrence of P in G i , then there is also an Given this behavior, we say that freq has the anti-monotonicity property. Such property can certainly be exploited to prune non-promising candidate subgraphs, as in classical graph mining algorithms.
However, freq st is not anti-monotone. Suppose that two occurrences a and b of P are close to each other, leading to a single frequent spatiotemporal pattern S . Conversely, two occurrences a  X  a and b  X  b of P may be far from each other, possi bly resulting in two non-fre quent spatiotem poral patterns S and S . In other words, two spatiotemporal patterns S and S based on P may be infrequent, while the spatiotemporal pattern S based on P is frequent.

Nevertheless, the frequency of a spatiotemporal pattern S based on a plane graph P (i.e., freq st ( P,S ) ) can be upper bounded with two anti-monotone measures as follows: where freq seq ( P ) is the subsequence frequency of P de fi ned below.
 De fi nition 11 (Subsequence frequency) . The subsequence frequency of a plane graph P in D , denoted freq seq ( P ) ,isde fi ned as the size of the longest subsequence G i (a) for all j , G i  X  .
 an occurrence of S satis fi es (a) and (b) in De fi nition 11. Moreover, if P  X  P then any sequence of G therefore freq seq has the anti-monotonicity property.

To solve the problem de fi ned in Section 3.4, the idea is to fi rst mine for all frequent pattern graphs frequent pattern to compute the spatiotemporal patterns, as described in De fi nition 9. The algorithm that uses freq is called P LAGRAM and the one that uses freq seq is D Y P LAGRAM .
 4.1. Extensions
Our algorithms use a depth-fi rst exploration strategy: each time a frequent pattern is found, it is ex-tended into a bigger candidate pattern for further evaluation. As G S PA N , our algorithms only generate promising candidate graphs, that is, subgraphs that actually occur in D . However, our extension strat-egy limits the number of different extensions that can be generated from a given frequent pattern, as described below.
 De fi nition 12 (Valid extension) . Given a plane graph g and two nodes u = v on the outer face of g , g can only be extended by the addition of a new path P =( u = x 1 ,x 2 ,...,x k = v ) to g between u and v . This path must lie in the outer face of g . Nodes x 2 ,..., x k  X  1 are ( k  X  2) 0 new nodes with N ( x i )= x i  X  1 ,x i +1 . This new graph is denoted g  X  P . Given a plane graph G such that g  X  G , P is a valid extension of g in G if g  X  P  X  G .

In other words, this de fi nition states that any pattern graph g composed of aggregated faces can only one edge with g (since u = v ). A consequence of this extension strategy is that the generated patterns are always 2-connected (this means that for any two nodes of the pattern, there is always a cycle that contains both).
 Example 5. In Fig. 1, there is only one occurrence of g 1 in G and, for this occurrence, there are three valid extensions of g 1 in G . Since these extensions have two edges, a new node 6 is added in the outer P 4 =(1 , 5) is not a valid extension since g 1  X  P 4 is the graph g 2 , which is not a plane subgraph of G (see Section 3.2).
 Given a pattern graph g and a graph G i in D , our algorithms compute all occurrences of g in G i . Then, for each occurrence, they generate all possible extensions. For each occurrence of g in G i and from each node of the external face of g , there is only one possible extension. This is one reason why P
LAGRAM and D Y P LAGRAM generate fewer extensions than G S PA N ,asweshowinSection5. G S PA N extends pattern graphs edge by edge, and several extensions may be generated from one node. 4.2. Graph codes To avoid multiple generations of the same pattern, p attern graphs are represented by canonical codes. Therefore, to fi nd the frequent patterns, our algorithms explore a code search space.

A code for a plane graph g is a sequence of the edges of g . Each edge is represented by a 5-tuple ( number of nodes in g ). The nodes are numbered as they fi rst appear in the code.
 De fi nition 13 (Valid code for a plane graph) . If g =( V,N,L n ,L e ) is a plane graph with only one (2 5-tuple representing an edge of g .If g = g  X  P and P is a valid extension of g in g , then a valid code for g is the concatenation of a valid code for g and the code of P .
 It is not obvious from De fi nition 13 that every 2-connected plane graph g has at least one valid code. face of g and then iteratively adding valid extensions to it. Example 6. Table 2 shows four valid codes of graph g 1 in Fig. 1 (among seven valid codes). Figure 3 shows the corresponding node numbering on graph g 1 (recall that there is a different numbering of nodes for each code). Codes  X  ,  X  ,  X  start with the 4-edge face and then a 2-edge extension is added to build the second face. Code  X  starts with the 3-edge face and then a 3-edge extension is added. In each column, the line separates the edges of the fi rst face from the edges of the valid extension. A valid code code can start with any of the two faces, hence the seven possible codes. 4.3. Code search space and canonical codes
The set of valid codes is organized in a code tree . A code C is a child of C in the code tree if there is a valid extension P of C such that C is the concatenation of C with the codes of the edges of P .The root of the code tree is the empty code.
 Example 7. An example tree rooted at code  X  (of Table 2) is represented in Fig. 4. Notice that the codes at a given level of the tree represent graphs that have one more face than the codes of the level just above. In this code tree, each graph is represented by several codes (for instance, we have already seen that graph g 1 has seven valid codes). In Fig. 4 we also see that codes  X .A.D and  X .C.F represent the same graph.

Naturally, exploring several codes that represent the same graph is not ef fi cient. We therefore de fi ne canonical codes such that each graph has exactly one such code: we start by de fi ning an order on the valid codes. We assume that there exists an order on the labels. Then, we de fi ne an order on the edges by taking the lexicographic order derived from the natural order on node indices and the order on labels. It lexicographic order on the codes. We thus de fi ne the canonical code of a graph as the biggest code that can be constructed for this graph.
 biggest valid code that can be constructed for this graph.
 Example 8. In Fig. 3, we assume that a&lt;b&lt;c . Therefore,  X &gt; X  since they have the same fi rst two edges and the third edge of  X  is smaller than the third edge of  X  . Because of the second edge,  X &gt; X  code for graph g 1 .

P LAGRAM and D Y P LAGRAM do a depth-fi rst exploration of a code tree. The next theorem states that, if they fi nd a non-canonical code C , then it is not necessary to explore the descendants of C ; the whole subtree rooted at C can be safely pruned.
 Theorem 1. In the code search tree, if a code is not canonical, then neither are its descendants. Proof. Let C be a non-canonical code of a graph G and C.E a code of a descendant G of G .Let C c be the canonical code of G . As such, code C c can be extended to a new code C c .F for G .Since C c is the canonical.
 Example 9. In Fig. 4,  X .A.D and  X .C.F are two codes for the same graph. Since  X .A.D &gt;  X .C.F , any extension of  X .A.D will be bigger than any extension of  X .C.F . Therefore, the latter code can be safely pruned. 4.4. Pseudo-codes
The pseudo-codes of P LAGRAM and D Y P LAGRAM are shown, respectively, in Figs 5 and 6. The a plane graph and the way extensions are generated. It is a depth-fi rst recursive exploration of the code ef fi ciency reasons, P LAGRAM and D Y P LAGRAM start their exploration with frequent edges. In both algorithms, the function mine explores the part of the code tree rooted at a code given by its parameter. It computes their extensions on every target graph in D (lines 1 X 4) and make a recursive call on the frequent and canonical ones (line 9).

The difference between P LAGRAM and D Y P LAGRAM is on the exploited frequency measure in func-tion mine (line 6). The subsequence frequency used by D Y P LAGRAM needs the time threshold  X  ,which freq freq seq , the number of extensions that are pruned (in line 6) is higher in D Y P LAGRAM than in P
Next, we present a complexity study of the main steps of function mine . We denote m the number of edges of a given pattern P ,and m i the number of edges of every target graph G i .

Pattern matching (line 3): For each pattern P , function mine must fi nd all occurrences of P in every target graph G i . Each occurrence is found with a subgraph isomorphism test [5], which works as follows: complexity of matching the remaining edges of P is O ( m ) . So, the complexity of fi nding one occurrence is, in the worst case, O ( m.m i ) .

Function mine uses an optimization that makes this subgraph isomorphism test linear: it stores, along cost of a matching becomes O ( m ) . Since the number of occurrences of P in a target graph G i cannot be higher than 2 m i (the fi rst edge of P may match each edge of G i in two  X  X irections X ), the complexity of computing all occurrences of P in all target graphs G i is O ( m m i ) (which is bounded later by O ( m 2 i ) in Theorem 2).

Extension building (line 4): For every occurrence f of P in a target graph G i , function mine builds all possible extensions. This is done by fi nding a valid extension starting from every node of the outer face of of P in all target graphs G i is O ( m 2 i ) .

Every time a new extension is added to the list LE , its frequency is updated. This enables the test in for the computation of freq seq .The LE list is implemented in a way such that the addition of a new extension (together with its frequency counting) is done with a logarithmic complexity (as a function of the number of edges of the extension). Therefore, for a fi xed pattern P , we bound this complexity by the total size of all its extensions in all G i s, i.e, by O ( m 2 i ) .

According to the conducted experiments, the extension building step of function mine was found to be the most expensive.

Canonical test (line 7): This test is done by comparing code P.E with the canonical code of the graph represented by P.E . Since two plane graphs are isomorphic if their canonical codes are the same, the complexity of this test is at least as high as an isomorphism test. The complexity of graph isomorphism, in the general case, is unknown, but for plane graphs, polynomial algorithms exist (see, for instance [5], and considering that each edge belongs to at most two faces, there are at most 2 m such choices. Then, the code is extended with the biggest valid extension code. Each of these steps has a complexity of O ( m ) and must be repeated as many times as the number of faces in P , which is lower than m . Therefore, the experimental evaluations show that the canoni cal tests are not the bottleneck of our algorithms. Theorem 2 (Complexity) . The total complexity of function mine (excluding the complexity of recursive calls in line 9) is O ( m 3 + m 2 i ) ,where m is the size of the pattern P (in number of edges) and m i is the size of the target graph G i (in number of edges). A consequence of this theorem is that, contrary to general graph mining algorithms as G S PA N ,P LA -GRAM and D Y P LAGRAM have a polynomial output delay, i.e., the time between the output of two frequent patterns is polynomial in the size of the input m i (since, of course, m&lt; m i ). Theorem 3 (Correctness) . P LAGRAM and D Y P LAGRAM fi nd and output exactly once all frequent 2-connected plane subgraphs in D (using, respectively, freq and freq seq as the frequency measure). Proof. Since there is a one-to-one correspondence between canonical codes and 2-connected plane graphs, we must show that the algorithms do not miss any frequent canonical code. The algorithms prune a branch of the tree either because the code is not frequent (line 6) or because it is not canonical (line 7). The frequency of the descendants of a code C cannot be higher than the frequency of C .There-the code is not canonical, we know from theorem 1 that its descendants cannot be either. So, the pruning in line 7 is safe as well. In this way, the algorithms can never miss a frequent canonical code. Finally, every output code (line 8) is frequent and canonical and, since there is only one canonical code for each graph, a graph is output only once. 4.5. Generation of spatiotemporal patterns
When the algorithms output a frequent pattern P (line 8, in function mine ), they also output a list occurrence (see De fi nition 7), and k is the index of G k  X  X  where this occurrence appear. From this list, the algorithm of Fig. 7 computes the spatiotemporal patterns based on P as follows: Given an occurrence ( x, y, k ) , the algorithm computes its distance between every other occurrence in the  X  previous graphs G j . The number of these occurrences is at most O (  X . max i ( m i )) ,where max i ( m i ) is the maximal size of the graphs in D . Therefore, the complexity of building the occurrence graph of The computation of the connected components and their frequency (line 7) is done by a traversal of the occurrence graph (linear complexity). Finally, the complexity of computing all frequent spatiotemporal patterns based on a pattern P is O (  X . max i ( m i ) . i m i ) .
 5. Experiments We now present the computational results obtained by our proposed algorithms P LAGRAM and D Y -P
LAGRAM . Since, to the best of our knowledge, P LAGRAM is the fi rst frequent plane graph mining algorithm, we could not compare it with any other algorithm with the same purpose. Nevertheless, to check how ef fi cient our dedicated algorithm is in comparison with a general-purpose one, we report here a comparison between P LAGRAM and G S PA N . We also compare D Y P LAGRAM with P LAGRAM in terms of ef fi ciency. In summary, the conducted experiments aimed to answer four main questions: 1. How do P LAGRAM and G S PA N scale on video data? 3. How ef fi cient is D Y P LAGRAM in comparison with P LAGRAM ? 4. Are the spatiotemporal patterns meaningful on video data?
For G S PA N , we asked the authors of [3] for their C++ code. For D Y P LAGRAM and P LAGRAM ,we adapted the source code of G S PA N to implement their features and to allow a fair comparison. The experiments were carried out on a 3.08 GHz CPU with 8 GB of RAM memory under Debian GNU/Linux (2.6.26-2-amd64 x86_64) operating system. 5.1. Ef fi ciency Here, we evaluate how ef fi cient P LAGRAM is in comparison with the general-purpose algorithm 5.1.1. Video datasets
The datasets we used for these experiments were created from a set of frames of a synthetic video. The choice of making a synthetic video was bene fi cial to our experiments, since we did not have to deal with common video artifacts that occasionally disturb the segmentation process. The video has 721 frames in total. Three identical objects (airplanes) are moving in the video such that they may overlap or even get partially out of the video frames (this helped us to evaluate how well spatiotemporal patterns can be used to represent the trajectory of the airplanes individually, as reported in Section 5.3).
After generating the video, we represented each frame as a plane graph. For this task, we used 2 different methods, which led to 2 different datasets of such graphs, as described below:
Triangulation: Assuming that the video frames were already segmented by their different pixel colors, for each frame, the barycenters of the segmented regions became nodes and a Delaunay triangulation of this set of nodes was constructed. The fi nal graphs had, on average, 197.33 nodes with an average degree of 2.93. The labels of the nodes were generated based on the size of the regions (in number of pixels). The size of the regions were discretized into 10 equal bins, which led to 10 possible node labels. The graph.
 RAGs (Region Adjacency Graphs): We also represented each frame as a RAG (Region Adjacency Graph). More precisely, the nodes are computed in the same way as for the Triangulated dataset, except that there is also one node representing the outer region. An edge exists between two regions (or nodes) if these regions are adjacent in the frame. On average, each frame led to a graph with 245.2 nodes, with an average degree of 2.23, and the labels of the nodes were discretized in the same way as for the Triangulated dataset. Here, the fi nal set of graphs formed the RAG dataset.
Contrary to the graphs in the Triangulated dataset, the edges of the target graphs are more meaningful, since they represent adjacencies between regions. Moreover, if different regions have the same barycen-ters, they are not discarded as for the Triangulated dataset. This explains the higher number of nodes in this new dataset.
 One disadvantage of the RAG dataset, however, is that the generated graphs may not be 2-connected. Since P LAGRAM mines only 2-connected patterns, it is not able to fi nd a pattern that spans on several 2-connected components. Indeed, in the experiments, we found bigger patterns in the Triangulated dataset. Nevertheless, interesting patterns were also found by P LAGRAM in the RAG dataset.

Some example frames (left) along with their triangulated (middle) and RAG (right) representations are illustrated in Fig. 8. 5.1.2. Results
Several factors may in fl uence the ef fi ciency of P LAGRAM in comparison with G S PA N .AsP LAGRAM is dedicated to plane graphs, two patterns that are different for P LAGRAM (due to the order of their edges) may be only one pattern for G S PA N . In this way, our algorithm would fi nd more patterns than
S PA N . However, since our extension building step is restricted to faces instead of single graph edges as in
G S PA N , we would expect to generate fewer extensions as well as patterns. In any case, the complexity of our isomorphism test is lower. Therefore, in order to understand the most important of these factors, we considered the following in our experiments:  X  The total execution time.  X  The number of output patterns.  X  The number of generated extensions.

We also considered the following ratios in order to make a fair comparison between the pattern match-ing and the extension building steps of P LAGRAM and those of G S PA N :  X  The ratio of the total pattern matching step time to the total size of the matched patterns (in number  X  The ratio of the total extension building step time to the total size of the generated extensions (in
Figures 9 and 10 present the results obtained on the Triangulated and RAG datasets, respectively. In each graph, the x-axis represents absolute minimum supports, which were lowered while the computa-tion time of P LAGRAM was below 2 hours. Each point on each graph is the average result of 8 executions of the algorithms.

G S PA N could not fi nish its executions, even for the highest tested minimum support (721) on both datasets (in fact, it was interrupted after 3 days of computation). However, to better understand its be-havior, we stopped it after 2 hours of execution and plotted here the intermediate results obtained with the highest minimum support of 721 (which is approximately the same for the other minimum supports). This 2-hour execution of G S PA N is referred to here as G S PA N 2.

Triangulated dataset: Graph (a) presents the total execution time of P LAGRAM . Graphs (b) and (c) present, respectively, the number of extensions and the number of output patterns of P LAGRAM and
Contrary to G S PA N ,P LAGRAM fi nished its executions for every tested support. As presented in graphs (b) and (c), the total execution times increased along with the number of extensions and patterns, respec-tively. Considering G S PA N 2, observe that its number of extensions was higher than that of P LAGRAM for almost all tested minimum supports (remember that P LAGRAM only considers 2-connected plane graphs). In addition, for the minimum support of, e.g., 688, the patterns output by P LAGRAM had on average 30 edges, while, in the same period of time (two hours), G S PA N 2 output fewer patterns with at most 10 edges.

What is worth observing as well are the results given by graph (d). It presents the ratio of the total time higher for P LAGRAM than for G S PA N 2, it is worth noting that the patterns generated by G S PA N 2were smaller (at most 10) than those generated by P LAGRAM . If the complexity of the subgraph isomorphism ratio of P LAGRAM would be a lot higher.

Finally, graph (e) presents the ratio of the total extension step time to the total size of the generated extensions, in number of edges. Note that P LAGRAM had slightly better results in comparison with
RAG dataset: As shown in Fig. 10, on this dataset the behaviors of P LAGRAM and G S PA N 2were quite similar to those on the Triangulated one. Here, however, P LAGRAM had a slightly better matching ratio than G S PA N 2 for lower minimum supports. Since P LAGRAM mines only 2-connected patterns, the average size of the patterns found in the Triangulated dataset was higher than that in the RAG dataset, for the same minimum supports. For example, if we consider the support of 721 frames, the patterns found in the Triangulated dataset had on average 8 edges. Here, the patterns had 4 edges, on average. Step times: We also measured the relative times of the main steps of the algorithms P LAGRAM and execution time, whereas the matching step was always less than 5%, and the canonical-test step was negligible. For P LAGRAM , the most expensive step was also the extension building step, which varied from 40% to 60% of the total execution time. The pattern matching step, in its turn, was around 20%, while the canonical-test step was almost always less than 5%. Figure 11 presents the computed relative times of P LAGRAM (y-axis) on the Triangulated (left) and RAG (right) datasets, for all tested minimum supports (x-axis).

In conclusion, we believe that the main reason why P LAGRAM is more ef fi cient than G S PA N is the lower number of extensions produced by P LAGRAM rather than only the lower complexity of pattern matching as one could expect. 5.2. DyPlagram vs. Plagram
We now present a comparison between D Y P LAGRAM and P LAGRAM on the video described in Sub-instead of just freq.

Figure 12 shows the total execution time and the number of patterns generated by D Y P LAGRAM and P LAGRAM on the datasets Triangulated (graphs (k) and (l)) and RAG (graphs (m) and (n)) for different minimum supports. Observe that D Y P LAGRAM generated fewer patterns than P LAGRAM on both datasets, which makes its total execution time shorter than that of P LAGRAM . This is particularly clear on the Triangulated dataset, where it was possible to mine patterns with D Y P LAGRAM with much lower minimum supports in lower execution times. 5.3. Meaningfulness of the spatiotemporal patterns 5.3.1. Object tracking
Computer vision researchers are struggling for more than 30 years with the dif fi cult problem of rec-ognizing objects in images and more recently with the problem of tracking objects in videos [17,19]. In this context, to evaluate how meaningful our (spatiotemporal) patterns are, we study whether they can be used to track a given object in a video.

We start by introducing two measures which assess how precise a (spatiotemporal) pattern p corre-sponds to a given target object o in the video frames. These measures are adaptations of the popular measures precision and recall as described below:  X  precision : fraction of the occurrences of p (in the target graphs) of which every node maps to o in  X  recall :Let n be the number of frames in which o is present. The recall is de fi ned as the fraction of
Since our algorithms are exhaustive, that is, they mine for all frequent (spatiotemporal) patterns in the graph database without supervision, the mining result may consist of different (spatiotemporal) patterns corresponding to different objects, or even to no speci fi c one (w.r.t. the proposed measures). Therefore, to follow a speci fi c object in the video, the user should be able to select from the entire set of out-put (spatiotemporal) patterns those that correspond to this object. A basic strategy for this task is the following: 1. First, the user selects a frame area where there exists an object he or she is interested in tracking, 2. Afterwards, the user starts the graph mining process by executing either P LAGRAM with a given 3. Next, the (spatiotemporal) patterns that have no occurrences in the user-selected area, in frame f , 4. Finally, all the occurrences of the target (spatiotemporal) patterns are mapped to the video frames, 5.3.2. Simple video
We have evaluated this strategy in a preliminary study [16] for a basic video with 721 frames and only one airplane which was standing still in a moving background. In this simplistic context, we used only non-spatiotemporal patterns to check whether we could track this airplane through the video.
The target patterns returned by P LAGRAM had very high average precision and recall (above 96% for the most frequent ones). Furthermore, the most frequent obtained patterns corresponded to the target airplane. Some examples of the obtained patterns are given in Fig. 13. In (b) and (c), we show 2 different occurrences of a pattern with 100% support, 52% precision, and 100% recall in the RAG dataset. On the other hand, the graph in (d) illustrates an occurrence of a patte rn with support of 378 frames in the RAG dataset. Note that this occurrence had a node that is outside the airplane area; this pattern did not that every node of the pattern matches the target object). This fi rst series of experiments showed that with a simple video, P LAGRAM could track objects. 5.3.3. Complex video
However, if we apply the same strategy to track a single airplane in the example video used in this paper (see Fig. 8), the precision will drop dramatically. Indeed, in this more complex video, there are three identical moving airplanes. Therefore, a pattern matching one of the airplanes will also match the other two. This means that a given target pattern will never have a precision higher than 1 / 3 .There-fore, to track a given airplane in this video, the use of spatiotemporal constraints becomes necessary to distinguish one airplane from another.

To check whether the de fi ned spatiotemporal patterns can well represent the trajectory followed by the 3 airplanes individually, we used the previously described strategy on the RAG dataset, on which threshold of 721 and a temporal constraint  X  =1 to focus on patterns that appear in every frame (note that some occurrences of the same pattern may correspond to different spatiotemporal patterns). Then, we post-processed them to generate spatiotemporal patterns. Next, the precision and recall of every spatiotemporal pattern whose fi rst occurrence maps to an airplane o in a video frame i were computed w.r.t o . This means that each frame i of the video was in turn considered as frame f de fi ned in our as the fraction of video frames in which o appears and that are covered by at least one of the selected spatiotemporal patterns.

Table 3 summarizes the results. The spatiotemporal patterns were generated with minimum freq st of 10 and 50, and 3 different spatial thresholds of 10, 20, and 170 pixels (from 20 to 160 pixels, the results were quite similar and thus are not reporte d here). For each expe rimented pair (freq st , ) and for each target airplane in the video, the fi rst two columns give the average precision and recall computed for its associated spatiotemporal patterns (as de fi ned in our strategy). In addition, the third column shows the total number of such patterns, and the last column gives the coverage recall of this set of patterns.
As can be seen in Table 3, the constraint has an important impact on the obtained results. Indeed, if it is set too low (to 10 pixels, in our example), we obtain spatiotemporal patterns with high average precision for each airplane, as different occurrences of patterns which map to different airplanes are very well distinguished. However, this leads to a low average recall: since only very close occurrences of the using a spatial constraint = 10, no spatiotemporal patterns with freq st = 50 were found for airplane 2, which explains why we use a minimum freq st of 10 in this case. Conversely, for a higher of 170 pixels, the average precision drops as the different airplanes are not well distinguished anymore. For example, it was possible to obtain spatiotemporal patterns with higher recall for airplane 1 (when comparing to the other experiments). However, they had low average precision. Since airplane 1 gets partially out of the video frames around 6 times, a higher number of spatiotemporal patterns were derived for this airplane for freq st = 50 and of at least 20, which represent the different time intervals where this airplane is visible through the video. As another example, airplane 2 is hidden only twice by airplane 3 (during around 15 frames) and never goes out of the video frames. This explains the lower number of patterns (and the higher coverage recall) found for this object, also for freq st = 50 and higher than or equal to 20. The coverage recall drops when some occurrences of target patterns disappear completely (which happens more often for airplanes 2 and 3). Note that, in the case of our example video, increasing the time constraint  X  could increase the length of the spatiotemporal patterns and thus their (coverage) recall but this would lead to a lower precision. Finally, for = 20 pixels, the computed spatiotemporal patterns leads to a good coverage recall, while keeping a high average precision, which shows that spatiotemporal patterns are well suited to track objects in this more complex video. 6. Conclusions We presented a frequent plane graph mining algorithm called P LAGRAM and its extension D Y P LA -GRAM to mine spatiotemporal patterns. Our conducted experiments showed that P LAGRAM (and, con-sequently, D Y P LAGRAM ) was able to ef fi ciently run on graph-based video datasets, on which a general-purpose graph mining algorithm failed to fi nish its computations. The experiments also showed that besides improving ef fi ciency, the 2-connectedness restriction on the patterns imposed in our algorithms does not limit the meaningfulness of the fi nal patterns. On the contrary, we believe that these algorithms may be a useful tool to track objects in videos using spatiotemporal patterns.
 would like to add more complex labels to the nodes and edges of the graphs to describe, e.g., different characteristics of the frame regions. This would allow us to use a partial matching technique instead of the typical subgraph isomorphism test used in our algorithms. That is, two nodes (or edges) will be to track an object in a video, we proposed a strategy in which one should post-process the entire set of frequent patterns to select those that map to the object of interest. An interesting way to enhance the following the same line of reasoning as for the popular frequent itemset mining problem [1], a natural direction for further work is to adapt P LAGRAM and D Y P LAGRAM to mine directly maximal or closed patterns.
 Acknowledgments
The authors would like to thank Siegfried Nijssen for providing the source code of G S PA N and for his helpful remarks at the beginning of this research. The program at http://www.cs.cmu.edu/ ~ quake/ triangle.html was used to build the Triangulated dataset. This work has been supported by the project BINGO2 (ANR-07-MDCO 014-02). When this research was performed Adriana Prado was working at the Universit X  de St-Etienne.
 References
