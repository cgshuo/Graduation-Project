 Sentiment classification is a task of identifying the polarity orientation for a given text or document. Usually, the polarity orientation can be either positive or negative. Product review is one of the most popular text genres in previous researches. Various methods have been proposed for addressing this task, includ-ing lexicon-based methods and corpus-based methods. In this study, we focus on corpus-based methods for revi ew sentiment classification.

For corpus-based methods, the labeled training corpus is the most valuable resource and the task is usually addressed by training a classifier on the corpus and then applying the classifier to predict the polarity orientation of unlabeled reviews. Generally speaking, there are the following two ways for constructing the training corpus: 1) The corpus is manually labeled by human subjects; 2) The corpus is automatically constructed by using web mining and statistical learning techniques. The first way is very time-consuming and labor-intensive, and the second way is more preferable than the first way. Fortunately, on a few online shopping web sites, users usually write reviews for a particular product and they also attach a tag to each review for indicating the polarity orientation of the review. The reviews and the associated tags can be automatically crawled and used to construct the training corpus. For example, on a popular Chinese online shopping web site (www.amazon.cn), a user can write a review about a particular product, and then assign one or more stars to the product. The number of the stars indicates the review X  X  polarity orientation. Based on our observation and analysis, if the star number is equal to or less than two, the review is negative, and if the star number is equal to or larger than three, the review is positive.

However, some users assign the tags to the reviews in an arbitrary way and not all users assign the tags consistently, and thus a few tags are incorrectly assigned. For example, we manually check the consis tency between the polarity orienta-tion of 1000 reviews and the associated stars on the web site (www.amazon.cn), and we find that the stars for 95 reviews are incorrectly assigned, and some negative reviews are assigned with three or more stars, while some positive re-views are assigned with two or less sta rs. For example, a negative review for Nokia 1616 is  X  X he order made on Nov. 4, 2010 has not shipped yet, and the service by Joyo is lacking X  1 , but it is inconsistently assigned with four stars. These reviews are called noisy reviews i n the corpus, and th ey can deteriorate the classifier X  X  classification performance because the proportion of noisy re-views is not small, and current classifiers can not tolerate such a noisy training corpus.

In order to address the above problem, we propose novel algorithms (i.e. co-cleaning and tri-cleaning) to find and remove the noisy reviews from the training corpus, and thus improve the sentiment classification performance based on the cleaned corpus. The proposed algorithms use multiple classifiers to iteratively identify and remove the most confidently noisy reviews. In particular, at each iteration in the co-cleaning and tri-cleaning algorithms, the noisy reviews are identified in a collaborative way by using two or three classifiers to help each other. Experimental results verify the effectiveness of the proposed algorithms. The tri-cleaning algorithm is validated to be the best one for corpus cleaning. The cleaned corpus can be provided as a valuable resource for the community of sentiment analysis.

The rest of this paper is organized as fo llows: Section 2 introduces related work. Sections 3 and 4 introduce the problem and propose our novel solu-tions, respectively. The empirical evalua tion is presented in Section 5. Lastly, we conclude this paper in Section 6. 2.1 Sentiment Classification The methods for document sentiment cla ssification can be generally categorized into lexicon-based and corpus-based. Lexicon-based methods usually involve deriving a sentiment measure for text based on sentiment lexicons [7, 13, 16, 17, 31]. In this section, we focus on corpus-based methods. Corpus-based methods consider the sentiment analysis task as a classification task and they usually use a labeled sentiment corpus to train a sentiment classifier. Since the seminal work of [26], various classification models and linguistic features have been in-vestigated [23, 27, 28, 34]. Most recently, a structured model has been proposed for jointly classifying the sentiment of text at varying levels of granularity [21]. Domain adaptation for sentiment classifiers has been investigated in [4], focusing on online reviews for different types of products. Andreevskaia and Bergler [2] present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Li et al. [20] propose a novel approach to learn from lexical prior knowledge in the form of domain-independent sentiment-laden terms, in conjunction with domain-dependent un-labeled data and a few labeled documents. Kim et al. [18] propose an approach to utilizing term weights for sentiment analysis tasks and shows how various term weighting schemes improve the performance of sentiment analysis systems. Dasgupta and Ng [6] propose a semi-supervised approach to sentiment classifi-cation where they first mine the unambiguous reviews using spectral techniques and then exploit them to classify the a mbiguous reviews via a novel combina-tion of active learning, transductive learning, and ensemble learning. Chinese sentiment analysis has also been studied [19, 30] and most such work uses sim-ilar lexicon-based or corpus-based method s for Chinese sentiment classification. In the most recent years, several studies have been performed to leverage rich English resources for sentiment analysis in other languages [3, 22, 32, 33]. 2.2 Data Cleaning Data cleaning is a traditional research area in the fields of database and data mining [12]. Several works have used data cleaning techniques in the filed of com-putational linguistics. For example, previous works have used task-dependent or task-independent data cleaning techniques for the NLP tasks of POS tagging [1, 8, 9, 25], verb modality identification [24], PP-attachment [1] and word seg-mentation [29]. Data cleaning methods have also been used for improving text categorization. Fukumoto and Suzuki [11] address the problem of dealing with category annotation errors which deteriorate the overall performance of text clas-sification, by integrating information from two different classification algorithms: NB and SVM. The proposed method is strictly learner-dependent, because it only works with SVMs as learners, and i t is limited to cleaning the support vectors. Esuli and Sebastiani [10] pres ent different techniques for performing training data cleaning in the context of boosting-based learning methods. The techniques correspond to different ways of estimating the likelihood of being mislabeled for each training instance. They evaluate them on two widely used text categorization benchmarks by their capability of spotting misclassified texts purposefully inserted in the training set. And the confidence-based technique has the overall best performance.
 Given an crawled sentiment corpus consisting of N reviews and the associated x i is a review in the review set X , y i is the user-assigned polarity tag. We let y =+1iff x i is a positive review and y i =  X  1iff x i is a negative review. Based on the training corpus C , a sentiment classifier f C : X  X  R can be learned by using a basic classifier f , and the classifier X  X  prediction value for an unlabeled review x on f C ( x i ). In this study, we use the SVM classifier as f , and thus the sign of f on a test set T is measured as A ( f C ,T ).

Because there are many noisy instances in the original corpus C , the learned classifier is deemed to be not very eff ective and the performance value A ( f C ,T ) is deemed to be not high. The problem is how to clean the original corpus C by removing the noisy instances R noise from C . The cleaned corpus is denoted as C  X  = C  X  R noise , and we expect that the perform ance of the classifier learned on C  X  can be improved, i.e., A ( f C  X  ,T ) &gt;A ( f C ,T ). 4.1 Overview In this study, we propose three algorithms for training data cleaning in the task of sentiment classification. The common aim of the algorithms is to find the most confidently mislabeled instances from the original corpus and then remove them. The first algorithm (Self-Cleaning) is an improvement of the pre-vious confidence-based technique in [10], and it leverages only one classifier for identifying and removing noisy instances in an iterative way. The second algo-rithm (Co-Cleaning) is inspired by the co-training algorithm [5], and it leverages two classifiers to collaboratively find the noisy instances for each other. The third algorithm (Tri-Cleaning) is an improvement of the second algorithm, and it leverages three classifiers for collaborative data cleaning. The details of the three techniques are described in next sections, respectively.

Note that all the three algorithms require a basic text classifier and they are independent of a specific classifier. That is to say, any existing text classifier can be used in the three algorithms. Typical text classifiers include Support Vector Machine (SVM), Na  X   X ve Bayes (NB), Maximum Entropy (ME), K-Nearest Neighbor (KNN), etc. In this study, we adopt the widely-used SVM classifier [15] with the linear kernel and default parameter values. Viewing input data as two sets of vectors in a feature space, SVM constructs a separating hyperplane in the space by maximizing the margin between the two data sets. And the features used for sentiment classification include all unigrams and bigrams, and the feature weight is simply set to term frequency as in [32]. Note that for Chinese text, a unigram refers to a Chinese word and a bigram refers to two adjacent Chinese words after word segmentation. The sign of the SVM prediction value is used for predicting the polarity labels and the absolute value is used for indicating the confidence level of the prediction.

After we obtain the cleaned corpus by applying one of the above data cleaning algorithms, we can learn a SVM classifie r based on the cleaned corpus, and then apply the learned classifier to predict the polarity orientation for the reviews in the test set. 4.2 Self-cleaning This algorithm is an extension of the previous confidence-based technique in [10] by iteratively applying the confidence-based technique to identify and remove the noisy instances in the corpus. It leverages only one classifier to iteratively train on the current corpus and then select and remove the noisy instances to further refine the corpus.
 C  X  = C , and the basic learner f , the self-cleaning algorithm loops for I iterations as follows: 1. Learn the classifier f C  X  from C  X  using the basic learner f ; 2. Use f C  X  to label all the reviews in C  X  ; 3. Identify from C  X  the potentially noisy instan ces whose predicted labels are and select the top k instances into R noise ; 5. Remove the instances in R noise from C  X  , i.e. C  X  = C  X   X  R noise ; In the algorithm, I is a parameter controlling the iteration number, and k is a parameter controlling the number of noisy instances removed at each iteration. We can deduce that at most I  X  k instances can be remov ed from the original corpus.

The rationale of the algorithm lies in that the noisy instances can be selected based on the prediction values of the learner, and after each iteration, the learner can be refined and improved, and its predictions are more reliable, and thus the corpus can be further refined.

Finally, a classifier is learned based on C  X  and then the classifier is applied to predict for the reviews in the test set. 4.3 Co-cleaning In the above self-cleaning algorithm, the classifier is learned based on the noisy corpus and then the classifier is applied to predict for each review in the same corpus. Thus some mislabeled reviews can be potentially predicted to be consis-tent with their original labels because they have been already used for training the classifier. We call it as  X  X oise fitting X .

In order to address the above problem of the self-cleaning algorithm, we pro-pose the co-cleaning algorithm by splitting the original corpus into two sets and leveraging two classifiers to collaboratively find noisy instances for each other. The proposed co-cleaning algorithm is inspired by the famous co-training algo-rithm [5]. The co-training algorithm is a typical bootstrapping method, and it starts with a set of labeled data, and increase the amount of annotated data using some amounts of unlabeled data in an incremental way. One important aspect of co-training is that two views a re required for co-training to work, and two classifiers are learned based on the two views and they choose confident training examples from the unlabeled data for each other. Different from the co-training algorithm, our proposed co-cleaning algorithm aims to use one clas-sifier X  X  prediction results to help iden tify and remove noisy instances from the training set for the other classifier, and the co-cleaning algorithm do not require two independent views of the data.

Given the original corpus C = { &lt;x i ,y i &gt; | i =1 , 2 , ..., N } and the basic learner f , the co-cleaning algorithm first randomly split C into two sets C 1 , C 2 with equal sizes, and we have C = C 1  X  C 2 . Two refined training sets are defined as C  X  1 = C 1 , C  X  2 = C 2 . The algorithm then loops for I iterations as follows: 1. Learn the first classifier f C  X  2. Learn the second classifier f C  X  3. Refine C  X  1 as follows: a) Use f C  X  b) Identify from C  X  1 the potentially noisy instan ces whose predicted labels are inconsistent with the original labels: R 1 = { &lt;x i ,y i &gt; | f C  X  x ,y i &gt;  X  C  X  1 } ; c) Rank the instances in R 1 in decreasing order of the confidence value | f d) Remove the instances in R noise 1 from C  X  1 , i.e. C  X  1 = C  X  1  X  R noise 1 ; 4. Similarly refine C  X  2 by using f C  X  In the algorithm, I is a parameter controlling the iteration number, and p is a parameter controlling the number of noisy instances removed from each set at each iteration. And we can deduce that at most 2  X  I  X  p instances can be removed from the original corpus.

The rationale of the algorithm lies in that the noisy instances in one review set are selected based on the predicti on values of the learner trained on the other review set, and after a few iterations, the two learners can be refined and improved, and thus their predictions are more reliable for each other. We believe that the prediction values are more reliable than that in the self-learning algorithm, because the training set for one classifier is different from the review set to be predicted by the classifier in the co-cleaning algorithm.

Finally, a classifier is learned based on C  X  1 C  X  2 and then the classifier is applied to predict for the reviews in the test set. 4.4 Tri-cleaning In the above co-cleaning algorithm, the prediction of a review in one set is decided only by one another classifier, which may be potentially not very reliable, because the classifier is still trained on a noisy corpus.
In order to address the above problem of the co-cleaning algorithm, we further propose the tri-cleaning algorithm by splitting the original corpus into three sets and training three classifiers, and then using the voting of two classifiers to find noisy instances in the third set. The underlying idea is that the prediction based on two classifiers is usually more reliable than that based on only one classifier.
Given the original corpus C = { &lt;x i ,y i &gt; | i =1 , 2 , ..., N } and the basic learner f , the tri-cleaning algorithm first randomly split C into three sets C 1 , C , C 3 with equal sizes, and we have C = C 1 C 2 C 3 . Three refined training iterations as follows: 1. Learn the first classifier f C  X  2. Learn the second classifier f C  X  3. Learn the third classifier f C  X  4. Refine C  X  1 as follows: a) Use f C  X  b) Identify from C  X  1 the potentially noisy instan ces whose labels are consis-tently predicted by the two classifiers, but inconsistent with the original la-bels: R 1 = { &lt;x i ,y i &gt; | f C  X  0 ,and &lt;x i ,y i &gt;  X  C  X  1 } ; c) Rank the instances in R 1 in decreasing order of the confidence value | f d) Remove the instances in R noise 1 from C  X  1 , i.e. C  X  1 = C  X  1  X  R noise 1 ; 5. Similarly refine C  X  2 by using f C  X  6. Similarly refine C  X  3 by using f C  X  In the algorithm, I is a parameter controlling the iteration number, and m is a parameter controlling the number of noisy instances removed from each set at each iteration. During each iteration, at most 3  X  m noisy instances can be removed, and thus we can deduce that at most 3  X  I  X  m instances can be removed from the original corpus.

The rationale of the algorithm lies in that the noisy instances in one review set are selected based on the  X  X oting X  of two learners trained on the other two review sets. We believe that the predicted labels are more reliable than that in the co-cleaning algorithm, because the labels are voted by two classifiers, and thus in the tri-cleaning algorithm, the noisy instances selected from one set by the other two classifiers can be more trusted.

Finally, a classifier is learned based on C  X  1 C  X  2 C  X  3 and then the classifier is applied to predict for the reviews in the test set. 5.1 Evaluation Setup The training review set and the test re view set were constructed as follows: Original Training Set: We crawled a large number of product reviews and their associated tags from a popular Chinese online shopping web site -AmazonChina (www.amazon.cn). The dataset consi sts of 45898 positive reviews and 24146 negative reviews. The reviews are about various products, such as consumer electronics, mobile phones, digital products, books, and so on. The polarity tag of each review was automatically judged by the number of the assigned stars of the review. If the star number is equal to or less than two, the review is labeled as negative, and otherwise, the review is labeled as positive.
 Test Set: We used the same test set as in [33]. The test set contained 886 product reviews downloaded from another popular Chinese IT product web site IT168 (www.it168.com). The sentiment polarity of each review was manually labeled. The dataset consisted of 451 positive reviews and 435 negative reviews. The reviews focused on IT products.

We used the standard precision, recall and F-measure to measure the perfor-mance of positive and negative class, respectively, and used the accuracy metric to measure the overall performance of the system. The metrics are defined the same as in general text categorization.

In the experiments, the proposed algorithms are compared with the following threebaselinemethods: Baseline1 (Lexicon-Based): It is a lexicon-based method used in [32]. The semantic orientation value for a review is computed by summing the polarity values of all words in the review, making use of both the word polarity defined in the positive and negative lexicons and the contextual valence shifters defined in the negation and intensifier lexicons. The lexicons are derived from HowNet 2 . Baseline2 (NoCleaning): It directly uses the original training corpus to train the SVM classifier, without training data cleaning.
 Baseline3 (BasicCleaning): It use a basic cleaning method to remove po-tentially noisy instances from the original training set, and then learn a SVM classifier based on the refined training corpus. The basic training data cleaning method is similar to the confidence-based technique in [10]. The method first from the original corpus. n is empirically set to 1000 when the performance is the best. 5.2 Evaluation Results In the experiments, for the three proposed algorithms, we let k =2 p =3 m to guarantee that the total numbers of nosy instances to be removed for the three algorithms are equal after ea ch iteration. We investi gate three typical sets of parameter values: ( k = 300 ,p = 150 ,m = 100), ( k = 150 ,p =75 ,m = 50), ( k =90 ,p =45 ,m = 30). We report the best accuracy for each algorithm after a few iterations. Table 1 shows the comparison results. The actual iteration numbers for the algorithms are given in the table.
Seen from the table, we can see that all the data cleaning algorithms (includ-ing the BasicCleaning algorithm) can improve the classification accuracy. And the proposed three data cleaning algorithms can outperform the BasicCleaning algorithm. In particular, the proposed three algorithms can significantly outper-form the baseline NoCleaning method by using sign test, and the tri-cleaning algorithm can significantly outperform the BasicCleaning algorithm by using sign test. For the proposed three algorithms, we can see that the co-cleaning al-gorithm outperforms the self-cleaning algorithm, and the tri-cleaning algorithm outperforms the co-training algorithm. The results demonstrate that our pro-posed algorithms are effective and the tri-cleaning algorithm is the best one for training data cleaning because two classifiers X  voting is more reliable than one single classifier X  X  prediction when the training corpus contains noises.
We further investigate how the classification performance of the proposed three algorithms is influenced by the iteration number I . Figures 1, 2, 3 present the accuracy curves of the three algorit hms with the three parameter settings, respectively. Note that when I is equal to 0, the proposed three algorithms are actually the same with the baseline NoCleaning method.

Seen from the figures, the accuracy values of the three algorithms first increase with the iteration number, and then tend to decrease after a few iterations. The performance curves are very similar to that for the original co-training algorithm. The reason is that when the iteration number is large, the algorithms may incor-rectly select and remove some normal ins tances from the training corpus, after all the noisy instances have been removed.

We can also see that the performance of the self-cleaning algorithm drops more quickly than the other two algorithms, and the co-cleaning algorithm can outper-form the self-cleaning algorithm after a few iterations. The tri-cleaning algorithm can almost always outperform the self-cleaning and co-cleaning algorithms. The results further demonstrate that the co-cleaning algorithm is more effective and robust than the self-cleaning algorithm, and the tri-cleaning algorithm is more effective and robust than the self-cleaning and co-cleaning algorithms. In this paper, we propose novel algorithms for finding and removing noisy in-stances in the training corpus automatically crawled on the web. The three algorithms can improve the sentiment classification accuracy. The proposed tri-cleaning algorithm is the best choice in the experiments.

Though we focus on the task of sentiment classification in this study, the proposed algorithms can also be used for the more general text categorization task, and we will investigate to apply the proposed algorithms for general text categorization tasks to further demonstrate the robustness of the algorithms. This work was supported by NSFC (60873155), Beijing Nova Program (2008B03) and NCET (NCET-08-0006).

