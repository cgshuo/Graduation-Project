 Sponsored search has become one of the most profitable business models on the Internet. It helps the advertisers achi eve a considerable amount of revenue by bringing search users, i.e. potential customers, to the advertisers X  websites.
In sponsored search, when a query is submitted, the search engine will show some selected ads along with the organ ic search results. If an ad is shown on the search result page, we say that the ad has an impression . The selection of such ads is based on several factors such as the bid keywords, the bid prices, and the ad quality (including ad relevance). If an ad is clicked by a user, the search engine will charge the advertiser a certain amount of money (i.e., the cost for that click), according to the pricing model in the auction mechanism. This is the major revenue source for the search engine. Thus it can be seen that the revenue of the search engine is related to the number of impressions , click-through rate (CTR), and the cost per click (CPC) of the ads. Very limited study has been done on increasing search engine revenue by identifying the advertisers with high potential in revenue contribution and he lping them improve their performance.
In a sponsored search system, it is difficult for all the advertisers to achieve their desired campaign goals. As a result, their contributions to the search engine revenue vary largely. Furthermore, t he bad performances (and small revenue contributions) of the advertisers may lie in different situations. For example, some advertisers are satisfied though no t so much traffic is achieved; however, some advertisers are ambitious and they desire more attentions. In order to level up the effectiveness of the entire sponso red search system, we argue that the first step to help low-performance advertisers is to identify the unsatisfied advertisers who have potential to be improved.

In this paper, we make investigations on advertisers X  performances and con-duct potential head advertiser identification and diagnosis in sponsored search. In particular, we would like to answer the following four questions by our study.  X  What are the most significant differences between advertisers with large  X  Which group of advertisers has the great potential to improve their perfor- X  What are the reasons for these advertisers X  low performances?  X  How can the sponsored search system identify the primary cause for the bad We have conducted an intensive study on a large-scale sponsored search dataset from a commercial search engine. Characteristics of the two groups are in-vestigated (see Section 3). Specifically we find that less than 10% advertisers contribute 90% revenue to the search engine. We call these advertisers head advertisers. The remaini ng advertisers are called tail advertisers.
Tail advertisers with budgets no less than those of the head advertisers can be regarded as potential head advertisers 1 . They are willing to perform like the head advertisers but finally failed in doing so. An interesting observation by our diagnosis on potential head advertiser is that the biggest gap between head and tail advertisers lies in the number of im pressions, while the differences between other aspects (i.e., CTR and CPC) are not so significant.

We design different improvement strategies and conduct simulations on the real sponsored search data to verify the effectiveness of the improvement strate-gies. The experimental results show that the performances of the potential head advertisers are greatly boosted in all s cenarios. In the end, we implement a de-cision tree model to identify the primary failure reason for these potential head advertisers. With such a methodology, the search engine can provide personal-ized suggestions (e.g., keyword suggestions) for the potential head advertisers and help them achieve the campaign goals as much as possible.

To sum up, the main contributions of our work are listed as follows. (i) We conduct an intensive comparison between head and tail advertisers according to their contributions to the search engine revenue. To the best of our knowledge, it is the first piece of work on this kind of study in the literature. Our study shows that the biggest difference between head and tail advertisers is the number of impressions but not CTR or CPC. (ii) It is the first reported study, as far as we know, that cares about identifying and helping the advertisers with high potential to contribute more revenue to the search engine. It is always an essential goal for search engines to improve their revenue in sponsored search. To achieve the goal, there are two branches of approaches: one is to optimize the search engine ads delivery system, and the other is to help the advertisers improve their performance.

In the first branch, a lot of work has been done on optimizing auction the-ory, ranking strategy, ads relevance calc ulation, click-through rate prediction, and keyword matching algorithm. Some work focuses on auction and ranking mechanisms [4,11,7,1,14,6]. For example, Feng et al [7] compared several mech-anisms for allocating sponsored slots and proposed a rank-revision strategy that weighted clicks on lower ranked items more than those on higher ranked ones. Some other work [1,2,16,5] focuses on optimizing the search engine X  X  ad recom-mendation in order to satisfy the users and get optimized revenue at the same time. Besides, a lot of work focuses on the prediction of relevance or CTR and the construction of the click model [15,8,12,17,9]. Hillard et al [9] presented a rel-evance prediction method using translation models to learn user click propensity from sparse click logs.

In the second branch, only a little work has been done on improving ad-vertiser performance. In [3], Brogs et al studied a natural bidding heuristic in which advertisers attempt to optimize their utility by equalizing their return-on-investment (ROI) across all keywords. They come up with good results based on an assumption that advertisers are well-informed and familiar with sponsored search. However, this assumption is no t as sound in many cases as expected. Our preliminary study on a commercial search engine log shows that a large fraction of advertisers aim to achieve good performance by committing a lot of budgets but eventually fail in doing so due to wrongly-selected bid strategy and/or low-quality ads.

To sum up, (i) there is little work in the literature analyzing the impact of different factors to sponsored search advertisers in terms of their contribution on search engine revenue; quite a lot of work has been done on CTR prediction and relevance prediction, while little is emphasized on the significant impact of impressions. (ii) We have not found previous work that scientifically makes intensive study on helping advertisers with small revenue. (iii) We proposed a system to diagnose the advertiser performance on sponsored search, separate them into different categories, and find the most primary issues for them to improve. To the best of our knowledge, such kind of diagnosis has not been reported before in sponsored search. We have performed an intensive study on the performances of the advertisers based on the sponsored search data obtained from a commercial search engine. We use two kinds of data in our study: one is the auction log that records the submitted queries and the corresponding ad impressions and clicks, and the other is the advertiser database that records bid keywords, bid prices, and the budget for each advertiser. The data was collected in four successive weeks in Oct 2010, containing more than two hundred thousand active advertisers 2 . 3.1 Definitions of Head and Tail Advertisers As discussed in the introduction, we divide the advertisers into two groups in our study, according to their contributions to the search engine revenue. The criterion is as follows.  X  Head advertiser : if an advertiser contributes more than R revenue to the  X  Tail advertiser : if an advertiser contributes no more than R revenue to Thus, the selection of R is crucial to the analysis of head and tail advertisers. Different settings of R will significantly influence the properties of the two groups. For example, it will affect the portion of search engine revenue contributed by head advertisers (denoted as RevCoverage for ease of reference), the percentage of head advertisers among all the advertisers (denoted as AmtCoverage ), and the stability of the definitions on head and tail advertisers along with time (denoted as Stability ).

Mathematically, the above properties can be defined as follows. Suppose we have a series of successive periods (e.g., weeks) of data on the budget and spend-ing of the advertisers. Let H i ( R ) be the set of head advertisers in the i -th week given R , and let A i denote the set of all advertisers in the same week. Let a denote a single advertiser and Rev i ( a ) denote his/her contribution to the search engine revenue in the i -th week. Then we have According to Figure 1, R decreases fast as RevCoverage increases, indicating that a small R is needed if we want to obtain a large revenue coverage. Based on information in Figure 2, sponsored search seems to be a long-tail market: no more than 10% advertisers contribute more than 90% revenue to the search engine. According to Figure 3, as RevCoverage raises, the stability first rises and then drops, and the RevCoverage of 90% corresponds to a peak on the curves with different pairs of successive weeks.

From the above observations, we find the RevCoverage of 90% seems to be a good threshold to distinguish head and tail advertisers. The corresponding R can be determined by its monotonous relationship with RevCoverage in Figure 1. In our study 3 , R = 339 . 8. Thus, we get these head advertisers (6.75%) and the tails (93.24%). 3.2 Reason for Bad Performance After dividing the advertisers into head and tail, we want to identify the main reason for these advertisers X  low performances. As we know, the contribution of an advertiser a to the revenue of search engine can be approximately computed as where CTR a denotes the advertiser X  X  average click-through rate, and CPC a denotes the advertiser X  X  average cost per click.

Therefore, we should study the three fa ctors when analyzing the performance of an advertiser. We compute the average values of these factors from the data used in our study in Table 1.
We may find the average impressions of head and tail advertisers differ largely, while the average CTR and CPC do not have significant differences. Similar observations can be drawn from not only average value but also their distribution (see Figure 4). We also calculated the correlation between the distributions by following formula.
 Here X = { x 1 ,x 2 ,  X  X  X  ,x n } and Y = { y 1 ,y 2 ,  X  X  X  ,y n } are the vectors of two distributions, and  X  x and  X  y are the mean of the elements in the two vectors.
Figure 4 illustrates the distribution of Impressions, CTRs, and CPCs. The distributions are calculated from advertiser database for one week. We divide the number of Impression/CTR/CPC into logarithmic intervals. Specifically, the correlation between head and tail is -0.21. CTR and CPC do not have large difference between head and tail, and the corresponding correlations are 0.942 and 0.873 respectively. P-HEAD denotes the group of potential head advertisers, which will be discussed in next subsection.
Thus, the impression number is regarded as the major difference. The small revenue contribution of the tail advertisers is mainly caused by limited impres-sions. In order to increase the revenue contribution, we need to find effective ways to help some of tail advertisers increase their impressions. 3.3 Potential Head Advertisers After we find the main reason for bad performance, we focus on finding the group of advertisers that has potential to get improved. Though tail advertisers are in bad performances, not all of the m have the incentive to increase their impressions. For example, some advertisers would not like to pay much in spon-sored search because they have achieved their goals even in the limited traffic or they cannot afford more clicks. Meanwhile, the number of budget is set by each advertiser so that the search engine cannot charge the advertiser more than it. Thus, the budget might reflect the maximum willing cost of an advertiser. The advertisers with high enough budgets are regarded as the candidates with high potential to get improved performance. We call them potential head advertisers.  X  Potential head advertiser : if the budget of a tail advertiser is larger We can see from Figure 4 that the properti es of potential head advertisers are similar to those of the tail advertisers.

In our real world data, we find some agency-related advertisers. As some agencies might use other means but not budget (e.g., principled bidding and keyword selection strategies) to contro l the cost, we filtered these advertisers out of our potential head advertiser corpus. After that, the average impression number, CTR, and CPC of the potential head advertisers do not have significant difference from those of the tail advertisers (as following table shows).
Thus, our selected potential head advertisers are in bad performance but they are willing to perform well. Search engines should pay special attention to them because they might become head ad vertisers if their potential revenue contribution can be fully utilized (i.e., fully consuming their budgets). We will validate the effectiveness of such e xpectation in the next section. To improve the advertisers X  performances, we analyze the reasons for the bad performance and proposed some algorithms to deal with these problems. The experiment results show that potential head advertisers are very likely to be improved towards better performance. 4.1 Analysis for Low Impressions In sponsored search, low impressions might be caused by several factors. To bet-ter understand these factors, let us have a look at the process of ad selection and delivery strategies. In a typical sp onsored search system, when a user sub-mits a query, the ad platform in the search engine will first check the ads and the keywords in its ad database. The ads which bid keywords match the query (according to a specific matching algorit hm) will be selected as candidates for the auction. With a ranking mechanism [7], a rank score will be computed for each candidate ad based on the ad quality [8] (including the ad relevance to the keywords) and the bid price of the ad. Then the candidate ads are ranked according to the descending order of the scores, and the top-ranked ads will be shown to the users in the search result page.

From the above process, we can see that three factors will affect whether an ad will be shown or not: bid keyword (which affects the matching and filtration), bid price (which affects the ranking score), and the ad quality (which affects the ranking score). Then a question arises for a potential head advertiser, i.e., which of the above three factors is the primary cause of his/her bad performance? In other words, if the advertiser wants to improve his/her campaign performance, which factor(s) should he/she consider with the highest priority? We will try to answer this question in the next subsection. 4.2 Distribution of Different Reasons We sampled 2,000 advertisers from the set of potential head advertisers, each of which are with plentiful information in their performance data and search log data. We asked three human experts to label the advertisers to the following five categories (with distribution percentage in the bracket). The experts were experienced advertiser ca mpaign analysts in the customer service group of the commercial search engine.  X  Success : the advertisers are judged to be in healthy status and no improve- X  Bad Keywords : the advertisers should impro ve their keyword selection  X  Low Prices : the advertisers should increase their bid prices (33%).  X  Low Quality : the advertisers should improve their ad quality (31%).  X  Uncertain : the human experts cannot identify the primary problem for the 4.3 Validation of Potential Head Advertisers Firstly, we propose an example method to simulate the endogenous improvement of the advertisers for each of the reasons in Section 4.1. Then we conduct our simulation experiments in the real one-week auction log. Specifically, We denote historical CTR as quality score of the ad and the rank score is set as bid price multiplied by quality score .Adswhicharerankedattop8positionsineach auction will have one impression. By implementing the same methods on different advertiser sets (head, tail, and potential head), we validate that potential head advertisers can be better improved. Keyword Suggestion. We improve keyword selection by adding ten extra key-words into each order 4 according to their similarities with the original keywords. In particular, we compute the keyword similarity using the algorithm proposed by Glen Jeh et al in [10]. The ten queries that have top similarities with the original bid keywords in the order are selected as additional bid keywords to participate in the related auctions. 5 Bid Price Tuning. Bid prices are set by the advertisers themselves, and thus it is unreasonable to select an ad-hoc new price for an advertiser directly. Though it is difficult to guess the advertisers X  acceptable maximum bid price, the price changes should obey the rules or the habits of the advertisers. We build a matrix M to record the probabilities of bid price switch 6 along with time. Thus we have, P t stands for the bid price in time t . The condition j&gt;i is to make sure this is a bid price incremental switch.
 Quality Improvement. Quality score is calculated by complex methods like [8]. It might be very difficult to quantitatively calculate these improvement po-tentials. For simplicity, in our experiments, we simply use the best quality score in the ad X  X  history as its improved quality score, which is achievable for the corresponding advertiser.
 Result Analysis. To evaluate the effectiveness o f the improvement strategies, we define a special metric denoted as M 1. Suppose G , T ,and P denote the adver-tiser set of Head, Pure Tail (Potential H ead Advertisers excluded from Tail Ad-vertisers), and Potential Head, respectively. For each set s  X  X  G , T , P } and each method m  X  X  Keyword Suggestion, Bid Price Tuning, Quality Improvement } , M 1 is defined as, In the above definition, OriImp and NewImp m denote the impression number before and after applying the improvement method m .Thus, M 1 reflects the performance improvement on each advertiser set.

From Table 3, we can see that the performances of potential head advertisers are better improved than the other two groups by all three improvement meth-ods. Among the three methods, we can find that Keyword Selection provides the best improvement. The most probable reason is that most of the queries in key-word similarity matrix are popular ones. It means that once an advertiser wins auctions on these keywords the impressi on number will increase a lot. As the long tail theory holds in query submission, it is reasonable that head advertisers are also improved significantly. For the oth er two methods, as head advertisers have been competitive enough, high performance improvement is hard to achieve. However, potential head advertisers are better improved than both head and pure tail advertisers. Therefore, potential head advertisers are easily found by simple rules and can be improved by much via certain strategies.
Figure 5 illustrate the improvement results (using M1 metric) by improving keyword selection, bid price, and quality s core respectively, throughout different original impression numbers. Specifically, we put the advertisers into different buckets according to their original impression numbers, and then we calculated the logarithmal M1 values on different sets and plot these figures. We can find that potential head advertisers are better improved compared with the other groups.
 Diagnosis System. In order to identify the primary factor for a potential head advertiser to improve, we build an advertiser diagnosis system according to the labeled data mentioned in Section 4.2.

Firstly, we extracted different categories of features for the potential head ad-vertisers. That is, Key performance indicators (impression number, click number, CPC, etc.), Advertiser account attributes (budget, campaign numbers, etc.), Ad-vertiser ads attributes (average quality score, average bid, etc.), and Advertiser auction properties (number of auctions the advertiser participated in, etc.).
Then, we trained a C4.5 [13] decision tree model from the label data. The average precision of the model was 92% in five-fold cross validation, showing that the diagnosis classifier works well in identifying the primary factors for the potential head advertisers.

To further investigate the effectivenes s of the proposed advertiser diagnosis system, we conducted a set of comparison experiments. We randomly select 1,000 advertisers from the categories Bad Keywords , Low Prices ,and Low Qual-ity respectively as three target sets , and applied the corresponding improving strategies as described above. These improving strategies were also applied in a comparison set , which contained another 1,000 advertisers randomly selected from the potential head advertisers. The experimental results are shown in Figure 6. We can see that the target suggestions work very effectively: the improvement obtained on the three target sets are much larger than those obtained on the comparison set.
 This paper is a study on the sponsored search advertisers who perform badly but still have high potential to get improved. We made an intensive analysis on the differences of head and tail advertise rs, and proposed a simple way to iden-tify the potential head advertisers. To ev aluate the effectiveness of our method, we conducted a group of simulation experiments on a real world dataset. We also proposed a decision tree model to diagnose the primary reason of the bad performing advertisers and thus to provide suggestions for the advertisers to get improvements. The experiment results show that potential head advertisers have better properties and the improvement can be enlarged by our diagnosis system.
For future study, there are two aspects to improve our work. On one hand, we will conduct more study on our improvement methods. On the other hand, we will focus on enhancing the diagnosis system. First, we will consider more fea-tures and employing advanced classifiers. Then we will investigate the diagnosis in the ad level instead of in the advertiser level.

