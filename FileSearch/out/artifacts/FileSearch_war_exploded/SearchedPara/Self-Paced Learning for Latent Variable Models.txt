 Latent variable models provide an elegant formulation for s everal applications of machine learning. For example, in computer vision, we may have many  X  X ar X  image s from which we wish to learn a  X  X ar X  model. However, the exact location of the cars may be un known and can be modeled as latent variables. In medical diagnosis, learning to diagnose a dis ease based on symptoms can be improved by treating unknown or unobserved diseases as latent variab les (to deal with confounding factors). Learning the parameters of a latent variable model often req uires solving a non-convex optimization problem. Some common approaches for obtaining an approxima te solution include the well-known EM [8] and CCCP algorithms [9, 23, 24]. However, these approaches are prone to getting stuck in a bad local minimum with high training and generalization err or.
 Machine learning literature is filled with scenarios in whic h one is required to solve a non-convex optimization task, for example learning perceptrons or dee p belief nets. A common approach for avoiding a bad local minimum in these cases is to use multiple runs with random initializations and pick the best solution amongst them (as determined, for e xample, by testing on a validation set). However, this approach is adhoc and computationally e xpensive as one may be required to use several runs to obtain an accurate solution. Bengio et al. [3] recently proposed an alternative method for training with non-convex objectives, called cur riculum learning. The idea is inspired by the way children are taught: start with easier concepts (f or example, recognizing objects in simple scenes where an object is clearly visible) and build u p to more complex ones (for example, cluttered images with occlusions). Curriculum learning su ggests using the easy samples first and gradually introducing the learning algorithm to more compl ex ones. The main challenge in using the curriculum learning strategy is that it requires the ide ntification of easy and hard samples in a given training dataset. However, in many real-world applic ations, such a ranking of training samples may be onerous or conceptually difficult for a human to provid e  X  even if this additional human supervision can be provided, what is intuitively  X  X asy X  for a human may not match what is easy for the algorithm in the feature and hypothesis space employed f or the given application. To alleviate these deficiencies, we introduce self-paced learning . In the context of human education, self-paced learning refers to a system where the curriculum is determined by the pupil X  X  abilities rather than being fixed by a teacher. We build on this intuitio n for learning latent variable models by designing an iterative approach that simultaneously selec ts easy samples and updates the parameters at each iteration. The number of samples selected at each ite ration is determined by a weight that is gradually annealed such that later iterations introduce mo re samples. The algorithm converges when all samples have been considered and the objective function cannot be improved further. Note that, in self-paced learning, the characterization of what is  X  X a sy X  applies not to individual samples, but to sets of samples; a set of samples is easy if it admits a good fit in the model space . We empirically demonstrate that our self-paced learning ap proach outperforms the state of the art algorithm for learning a recently proposed latent variable model, called latent structural SVM , on four standard machine learning applications using publicl y available datasets. Self-paced learning is related to curriculum learning in th at both regimes suggest processing the samples in a meaningful order. Bengio et al. [3] noted that curriculum learning can be seen as a type of continuation method [1]. However, in their work, they cir cumvented the challenge of obtaining such an ordering by using datasets where there is a clear dist inction between easy and hard samples (for example, classifying equilateral triangles vs. squar es is easier than classifying general triangles vs. general quadrilaterals). Such datasets are rarely avai lable in real world applications, so it is not surprising that the experiments in [3] were mostly restrict ed to small toy examples.
 Our approach also has a similar flavor to active learning, whi ch chooses a sample to learn from at each iteration. Active learning approaches differ in their sample selection criteria. For example, Tong and Koller [21] suggest choosing a sample that is close t o the margin (a  X  X ard X  sample), corresponding to anti-curriculum learning . Cohn et al. [6] advocate the use of the most uncertain sample with respect to the current classifier. However, unli ke our setting, in active learning the labels of all the samples are not known when the samples are chosen.
 Another related learning regime is co-training, which work s by alternately training classifiers such that the most confidently labeled samples from one classifier are used to train the other [5, 17]. Our approach differs from co-training in that in our setting the latent variables are simply used to assist in predicting the target labels, which are always obs erved, whereas co-training deals with a semi-supervised setting in which some labels are missing. variables (which we refer to as input) for the i th sample and y i  X  Y are the unobserved variables (which we refer to as output), whose values are known during t raining. In addition, latent variable models also contain latent, or hidden, variables that we den ote by h i  X  H . For example, when learning a  X  X ar X  model using image-level labels, x represents an image, the binary output y indicates the presence or absence of a car in the image, and h represents the car X  X  bounding box (if present). Given the training data, the parameters w of a latent variable model are learned by optimizing an objective function, for example by maximizing the likeliho od of D or minimizing the risk over D . Typically, the learning algorithm proceeds iteratively, w ith each iteration consisting of two stages: (i) the hidden variables are either imputed or marginalized to obtain an estimate of the objective function that only depends on w ; and (ii) the estimate of the objective function is optimize d to obtain a new set of parameters. We briefly describe two such we ll-known algorithms below. EM Algorithm for Likelihood Maximization. An intuitive objective is to maximize likelihood: max A common approach for this task is to use the EM method [8] or one of its many variants [12]. Outlined in Algorithm 1, EM iterates between finding the expected value of the latent var iables h and maximizing objective (1) subject to this expectation. W e refer the reader to [8] for more details. CCCP Algorithm for Risk Minimization. Given the true output y , we denote the user-specified very difficult to minimize. An efficient way to overcome this d ifficulty is to use the recently proposed latent structural support vector machine (hereby referred to as latent SSVM ) formulation [9, 23] that minimizes a regularized upper bound on the risk. Latent SSVM provides a linear prediction rule of input D = { ( x 1 , y 1 ) ,  X  X  X  , ( x n , y n ) } , w 0 ,  X  . 1: t  X  0 2: repeat 3: Obtain the expectation of objective (1) under the distribut ion Pr( h i | x i , y i ; w t ) . 4: Update w t +1 by maximizing the expectation of objective (1). Specificall y, 5: t  X  t + 1 . 6: until Objective function cannot be increased above tolerance  X  . instance, in our  X  X ar X  model learning example, the joint fea ture vector can be modeled as the HOG [7] descriptor extracted using pixels in the bounding box h .
 The parameters w are learned by solving the following optimization problem: For any given w , the value of  X  i can be shown to be an upper bound on the risk  X ( y i ,  X  y i ( w )) (where  X  y ( w ) is the predicted output given w ). The risk function can also depend on  X  h i ( w ) ; that is, it can be of the form  X ( y i ,  X  y i ( w ) ,  X  h i ( w )) . We refer the reader to [23] for more details. Problem (2) can be viewed as minimizing the sum of a convex and a concave function. This obser-vation leads to a concave-convex procedure ( CCCP ) [24] outlined in Algorithm 2, which has been shown to converge to a local minimum or saddle point solution [19]. The algorithm has two main steps: (i) imputing the hidden variables (step 3), which cor responds to approximating the concave function by a linear upper bound; and (ii) updating the value of the parameter using the values of the hidden variables. Note that updating the parameters req uires us to solve a convex SSVM learning problem (where the output y i is now concatenated with the hidden variable h  X  i ) for which several efficient algorithms exist in the literature [14, 20, 22].
 input D = { ( x 1 , y 1 ) ,  X  X  X  , ( x n , y n ) } , w 0 ,  X  . 1: t  X  0 2: repeat 3: Update h  X  i = argmax h 4: Update w t +1 by fixing the hidden variables for output y i to h  X  i and solving the corresponding 5: t  X  t + 1 . 6: until Objective function cannot be decreased below tolerance  X  . Our self-paced learning strategy alleviates the main diffic ulty of curriculum learning, namely the lack of a readily computable measure of the easiness of a sample. In the context of a latent variable model, for a given parameter w , this easiness can be defined in two ways: (i) a sample is easy i f we are confident about the value of a hidden variable; or (ii) a sample is easy if it is easy to predict its true output. The two definitions are somewhat related: if we are more certain about the hidden variable, we may be more certain about the prediction. They a re different in that certainty does not imply correctness, and the hidden variables may not be direc tly relevant to what makes the output of a sample easy to predict. We therefore focus on the second defi nition: easy samples are ones whose correct output can be predicted easily (its likelihood is hi gh, or it lies far from the margin). In the above argument, we have assumed a given w . However, in order to operationalize self-paced learning, we need a strategy for simultaneously selec ting the easy samples and learning the parameter w at each iteration. To this end, we note that the parameter upd ate involves optimizing an objective function that depends on w (for example, see step 4 of both Algorithms 1 and 2). That is, where r ( . ) is a regularization function and f ( . ) is the negative log-likelihood for EM or an upper bound on the risk for latent SSVM (or any other criteria for parameter learning). We now modif y the above optimization problem by introducing binary variable s v i that indicate whether the i th sample is easy or not. Only easy samples contribute to the objective function. Formally, at each iteration we solve the following mixed-integer program: K is a weight that determines the number of samples to be consid ered: if K is large, the problem prefers to consider only  X  X asy X  samples with a small value of f ( . ) (high likelihood, or far from the margin). Importantly, however, the samples are tied togeth er in the objective through the parameter w . Therefore, no sample is considered independently easy; ra ther, a set of samples is easy if a w can be fit to it such that the corresponding values of f ( . ) are small. We iteratively decrease the value of K in order to estimate the parameters of a latent variable mode l via self-paced learning. As K approaches 0 , more samples are included until problem (4) reduces to prob lem (3). We thus begin with only a few easy examples, gradually introducing more un til the entire training dataset is used. To optimize problem (4), we note that it can be relaxed such th at each variable v i is allowed to take any value in the interval [0 , 1] . This relaxation is tight ; that is, for any value of w an optimum value function value. Similarly, if f ( x i , y i ; w ) &gt; 1 /K then the objective is optimal when v i = 0 . Relaxing problem (4) allows us to identify special cases whe re the optimum parameter update can be found efficiently. One such special case is when r ( . ) and f ( . ) are convex in w , as in the latent SSVM parameter update. In this case, the relaxation of problem (4 ) is a biconvex optimization problem. Recall that a biconvex problem is one where the variables z can be divided into two sets z 1 and z 2 such that for a fixed value of each set, the optimal value of the other set can be obtained by solving a convex optimization problem. In our case, the two sets of var iables are w and v . Biconvex problems have a vast literature, with both global [11] and local [2] op timization techniques. In this work, we use alternative convex search ( ACS ) [2], which alternatively optimizes w and v while keeping the other set of variables fixed. We found in our experiments that ACS obtained accurate results. Even in the general case with non-convex r ( . ) and/or f ( . ) , we can use the alternative search strategy to efficiently obtain an approximate solution for problem (4 ). Given parameters w , we can obtain problem (4) has the same form as problem (3). Thus, the optimi zation for self-paced learning is as easy (or as difficult) as the original parameter learning alg orithm.
 Self-Paced Learning for Latent SSVM. As an illustrative example of self-paced learning, Algo-rithm 3 outlines the overall self-paced learning method for latent SSVM , which involves solving a modified version of problem (2). At each iteration, the weigh t K is reduced by a factor of &gt; 1 , introducing more and more (difficult) samples from one itera tion to the next. The algorithm con-verges when it considers all samples but is unable to decreas e the latent SSVM objective function value below the tolerance  X  . We note that self-paced learning provides the same guarant ees as CCCP : Property: Algorithm 3 converges to a local minimum or saddle point solu tion of problem (2). This follows from the fact that the last iteration of Algorit hm 3 is the original CCCP algorithm. Our algorithm requires an initial parameter w 0 (similar to CCCP ). In our experiments, we obtained an estimate of w 0 by initially setting v i = 1 for all samples and running the original CCCP algorithm for a fixed, small number of iterations T 0 . As our results indicate, this simple strategy was sufficien t to obtain an accurate set of parameters using self-paced lea rning. We now demonstrate the efficacy of self-paced learning in the context of latent SSVM . We show that our approach outperforms the state of the art CCCP algorithm on four standard machine learning Algorithm 3 The self-paced learning algorithm for parameter estimatio n of latent SSVM . input D = { ( x 1 , y 1 ) ,  X  X  X  , ( x n , y n ) } , w 0 , K 0 ,  X  . 1: t  X  0 , K  X  K 0 . 2: repeat 3: Update h  X  i = argmax h 5: t  X  t + 1 , K  X  K/ . 6: until v i = 1 ,  X  i and the objective function cannot be decreased below tolera nce  X  . applications. In all our experiments, the initial weight K 0 is set such that the first iteration selects more than half the samples (as there are typically more easy s amples than difficult ones). The weight is reduced by a factor = 1 . 3 at each iteration and the parameters are initialized using T 0 = 2 iterations of the original CCCP algorithm. 5.1 Noun Phrase Coreference Problem Formulation. Given the occurrence of all the nouns in a document, the goal o f noun phrase coreference is to provide a clustering of the nouns su ch that each cluster refers to a single object. This task was formulated within the SSVM framework in [10] and extended to include latent variables in [23]. Formally, the input vector x consists of the pairwise features x ij suggested in [16] between all pairs of noun phrases i and j in the document. The output y represents a clustering of the nouns. A hidden variable h specifies a forest over the nouns such that each tree in the for est consists of all the nouns of one cluster. Imputing the hidden variables involves finding the maximum spanning forest (which can be solved by Kruskal or Prims algo rithm). Similar to [23], we employ two different loss functions, corresponding to the pairwis e and MITRE scores.
 Dataset. We use the publicly available MUC6 noun phrase coreference d ataset, which consists of 60 documents. We use the same split of 30 training and 30 test d ocuments as [23].
 Results. We tested CCCP and our self-paced learning method on different values of C ; the average training times over all 40 experiments ( 20 different values of C and two different loss functions) for the two methods were 1183 and 1080 seconds respectively. Fig. 1 compares the two methods in terms of the value of the objective function (which is the mai n focus of this work), the loss over the training data and the loss over the test data. Note that self-paced learning significantly improves the objective function value in 11 of the 40 experiments (compared to only once when CCCP outperforms self-paced learning; see Fig. 1(a)). It also provides a bett er training and testing loss for both MITRE and pairwise scores when using the optimal value of C (see Fig. 1(b)-(c)). 5.2 Motif Finding Problem Formulation. We consider the problem of binary classification of DNA sequences, which was cast as a latent SSVM in [23]. Specifically, the input vector x consists of a DNA sequence of length l (where each element of the sequence is a nucleotide of type A, G, T or C) and the output space Y = { +1 ,  X  1 } . In our experiments, the classes correspond to two differen t types of genes: those that bind to a protein of interest with high affinity and those that do not. The positive sequences are assumed to contain particular patterns, called motifs , of length m that are believed to be useful for classification. However, the starting position of the mo tif within a gene sequence is often not known. Hence, this position is treated as the hidden variabl e h . For this problem, we use the joint feature vector suggested by [23]. Here, imputing the hidden variables simply involves a search for the starting position of the motif. The loss function  X  is the standard 0-1 classification loss. Dataset. We use the publicly available UniProbe dataset [4] that prov ides positive and negative DNA sequences for 177 proteins. For this work, we chose five proteins at random. The total number of sequences per protein is roughly 40 , 000 . For all the sequences, the motif length m is known (provided with the UniProbe dataset) and the background Mar kov model is assumed to be of order k = 3 . In order to specify a classification task for a particular pr otein, we randomly split the sequences into roughly 50% for training and 50% for testing. Table 1: Mean and standard deviations for the motif finding experimen ts using the original CCCP algorithm Results. We used five different folds for each protein, randomly initi alizing the motif positions for all training samples using four different seed values (fixed for both methods). We report results for each method using the best seed (chosen according to the valu e of the objective function). For all experiments we use C = 150 and  X  = 0 . 001 (the large size of the dataset made cross-validation highly time consuming). The average time over all 100 runs for CCCP and self-paced learning are 824 and 1287 seconds respectively. Although our approach is slower than CCCP for this application, as table 1 shows, it learns a better set of parameters. While i mprovements for most folds are small, for the fourth protein, CCCP gets stuck in a bad local minimum despite using multiple rand om initializations (this is indicated by the large mean and sta ndard deviation values). This behavior is to be expected: in many cases, the objective function landscap e is such that CCCP avoids local optima; but in some cases, CCCP gets stuck in poor local optimum. Indeed, over all the 100 runs ( 5 proteins, 5 folds and 4 seed values) CCCP got stuck in a bad local minimum 18 times (where a bad local minimum is one that gave 50% test error) compared to 1 run where self-paced learning got stuck. Fig. 2 shows the average Hamming distance between the motifs of the selected samples at each it-eration of the self-paced learning algorithm. Note that ini tially the algorithm selects samples whose motifs have a low Hamming distance (which intuitively corre spond to the easy samples for this ap-plication). It then gradually introduces more difficult sam ples (as indicated by the rise in the average Hamming distance). Finally, it considers all samples and at tempts to find the most discriminative motif across the entire dataset. Note that the motifs found o ver the entire dataset using self-paced learning provide a smaller average Hamming distance than th ose found using the original CCCP algorithm, indicating a greater coherence for the resultin g output. 5.3 Handwritten Digit Recognition Problem Formulation. Handwritten digit recognition is a special case of multi-la bel classifica-tion, and hence can be formulated within the SSVM framework. Specifically, given an input vector x , which consists of m grayscale values that represent an image of a handwritten di git, our aim is to predict the digit. In other words, Y = { 0 , 1 ,  X  X  X  , 9 } . It is well-known that the accuracy of digit recognition can be greatly improved by explicitly modeling the deformations present in each image, for example see [18]. For simplicity, we assume that the defo rmations are restricted to an arbitrary rotation of the image, where the angle of rotation is not know n beforehand. This angle (which takes a value from a finite discrete set) is modeled as the hidden var iable h . We specify the joint feature Figure 2: Average Hamming distance between the motifs found in all sel ected samples at each iteration. Our of the image x rotated by the angle corresponding to h . In other words, the joint feature vector is the rotated image of the digit which is padded in the front and back with the appropriate number of zeroes. Imputing the hidden variables simply involves a sea rch over a discrete set of angles. Similar to the motif finding experiment, we use the standard 0-1 class ification loss.
 Dataset. We use the standard MNIST dataset [15], which represents each handwritten digit as a vector of length 784 (that is, an image of size 28  X  28 ). For efficiency, we use PCA to reduce the dimensionality of each sample to 10 . We perform binary classification on four difficult digit pai rs 5 , 851 to 6 , 742 , and the test sets range from 974 to 1 , 135 digits. The rotation modeled by the hidden variable can take one of 11 discrete values, evenly spaced between  X  60 and 60 degrees. Results. For each digit pair, we use C values ranging from 25 to 300 , set  X  = 0 . 001 , and set K = 10 4 C . Modeling rotation as a hidden variable significantly impro ves classification performance, allowing the images to be better aligned with each other. Acr oss all experiments for both learning methods, using hidden variables achieves better test error ; the improvement over using no hidden variables is 12%, 8%, 11%, and 22%, respectively, for the fou r digit pairs. CCCP learning took an average of 18 minutes across all runs, while self-paced learning took an a verage of 53 minutes. The above figure compares the training and test errors and obj ective values between CCCP and self-paced learning. Self-paced learning achieves significantl y better values in 15 runs, and is worse in 4 runs, demonstrating that it helps find better solutions to th e optimization problems. Though training and test errors do not necessarily correlate to objective va lues, the best test error across C values is better for self-paced learning for one of the digit pairs ( 1 -7 ), and is the same for the others. 5.4 Object Localization Problem Formulation. Given a set of images along with labels that indicate the pres ence of a particular object category in the image (for example, a mamm al), our goal is to learn discriminative object models for all object categories (that is, models tha t can distinguish between one object, say bison, from another, say elephant). In practice, although i t is easy to mine such images from free photo-sharing websites such as Flickr, it is burdensome to o btain ground truth annotations of the exact location of the object in each image. To avoid requirin g these human annotations, we model the location of objects as hidden variables. Formally, for a given image x , category y and location h , the score is modelled as w T  X ( x , y , h ) = w T y  X  h ( x ) , where w y are the parameters that corresponds to the class y and  X  h (  X  ) is the HOG [7, 9] feature extracted from the image at position h (the size of the object is assumed to be the same for all images  X  a reasonab le assumption for our datasets). For Figure 4: The top row shows the imputed bounding boxes of an easy and a ha rd image using the CCCP the above problem, imputing the hidden variables involves a simple search over possible locations in a given image. The loss function  X ( y ,  X  y ) is again the standard 0-1 classification loss. Dataset. We use images of 6 different mammals (approximately 45 images per mammal) that have been previously employed for object localization [13] . We split the images of each category into approximately 90% for training and 10% for testing.
 Results. We use five different folds to compare our method with the stat e of the art CCCP algo-rithm. For each fold, we randomly initialized the location o f the object in each image (the initializa-tion was the same for the two methods). We used a value of C = 10 and  X  = 0 . 001 . The average training time over all folds were 362 seconds and 482 seconds for CCCP and self-paced learning respectively. Table 2 shows the mean and standard deviation of three terms: the objective value, the training loss and the testing loss. Self-paced learning provided a significantly lower (more than tolerance) objective value than CCCP for all folds. The better objective value resulted in a subst antial improvement in the training (for 4 folds) and testing loss (an improvement of approximately 4% for achieved for 2 folds). In these experiments, CCCP never outperformed self-paced learning for any of the three measures of performance.
 Fig. 4 shows the imputed bounding boxes for two images during various iterations of the two algo-rithms. The proposed self-paced learning algorithm does no t use the hard image during the initial iterations (as indicated by the red bounding box). In contra st, CCCP considers all images at each iteration. Note that self-paced learning provides a more ac curate bounding box for the hard im-age at convergence, thereby illustrating the importance of learning in a meaningful order. In our experience, this was a typical behavior of the two algorithm s. We proposed the self-paced learning regime in the context of parameter estimation for latent variable models. Our method works by iteratively solving a biconvex o ptimization problem that simultane-ously selects easy samples and updates the parameters. Usin g four standard datasets from disparate domains (natural language processing, computational biol ogy and computer vision) we showed that our method outperforms the state of the art approach.
 In the current work, we solve the biconvex optimization prob lem using an alternate convex search strategy, which only provides us with a local minimum soluti on. Although our results indicate that such a strategy is more accurate than the state of the art, it i s worth noting that the biconvex problem can also be solved using a global optimization procedure, fo r example the one described in [11]. This is a valuable direction for future work. We are also curr ently investigating the benefits of self-paced learning on other computer vision applications, wher e the ability to handle large and rapidly growing weakly supervised data is fundamental to the succes s of the field.
 Acknowledgements. This work is supported by NSF under grant IIS 0917151, MURI co ntract N000140710747, and the Boeing company. [1] E. Allgower and K. Georg. Numerical continuation methods: An introduction . Springer-[2] M. Bazaraa, H. Sherali, and C. Shetty. Nonlinear Programming -Theory and Algorithms . John [3] Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Cur riculum learning. In ICML , 2009. [4] M. Berger, G. Badis, A. Gehrke, and S. Talukder et al. Vari ation in homeodomain DNA binding [5] A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In COLT , [6] D. Cohn, Z. Ghahramani, and M. Jordan. Active learning wi th statistical models. JAIR , 4:129 X  [7] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In CVPR , 2005. [8] A. Dempster, N. Laird, and D. Rubin. Maximum likelihood f rom incomplete data via the EM [9] P. Felzenszwalb, D. McAllester, and D. Ramanan. A discri minatively trained, multiscale, [10] T. Finley and T. Joachims. Supervised clustering with s upport vector machines. In ICML , [11] C. Floudas and V. Visweswaran. Primal-relaxed dual glo bal optimization approach. Journal [12] A. Gelman, J. Carlin, H. Stern, and D. Rubin. Bayesian Data Analysis . Chapman and Hall, [13] G. Heitz, G. Elidan, B. Packer, and D. Koller. Shape-bas ed object localization for descriptive [14] T. Joachims, T. Finley, and C.-N. Yu. Cutting-plane tra ining for structural SVMs. Machine [15] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient based learning applied to document [16] V. Ng and C. Cardie. Improving machine learning approac hes to coreference resolution. In [17] K. Nigam and R. Ghani. Analyzing the effectiveness and a pplicability of co-training. In CIKM , [18] P. Simard, B. Victorri, Y. LeCun, and J. Denker. Tangent Prop -a formalism for specifying [19] B. Sriperumbudur and G. Lanckriet. On the convergence o f concave-convex procedure. In [20] B. Taskar, C. Guestrin, and D. Koller. Max-margin Marko v networks. In NIPS , 2003. [21] S. Tong and D. Koller. Support vector machine active lea rning with applications to text classi-[22] I. Tsochantaridis, T. Hofmann, Y. Altun, and T. Joachim s. Support vector machine learning for [23] C.-N. Yu and T. Joachims. Learning structural SVMs with latent variables. In ICML , 2009. [24] A. Yuille and A. Rangarajan. The concave-convex proced ure. Neural Computation , 15, 2003. [25] K. Zhang, I. Tsang, and J. Kwok. Maximum margin clusteri ng made practical. In ICML , 2007.
