 Occupation is a very important attribute in sociology. In social surveys, data samples on occupation are mainly collected as responses to open-ended questions. Researchers then assign one of nearly 200 occupation codes to each sample [3]. The reason why respondents are not supposed to choose an occupation code in a questionnaire is that they often misunderstand their own occupation codes. This classification task by researchers is called occupation coding ,whichmustbe conducted immediately and accurately to statistically process occupations data as well as other variables [5]. The manual occupation coding has two problems. First, for coders, the task is time-consuming and complicated especially in large-scale surveys. Second, the results are not always consistent when coders are not experts of the occupation coding.
 a rule set derived from the definitions of the occupations and heuristic knowl-edge of domain experts [12]. In this system, most of the rules are expressed as the form of case frames (i.e., verb-object structures). The system tries to trans-form responses to open-ended questions into case frames. The system has been applied to 6 surveys including JGSS surveys (Japan General Social Surveys) 1 . Although the accuracy of the system is 65  X  70%, it saves coders X  labor and pro-duces consistent coding results [13, 14, 15, 16]. However, the system still has three problems. First, creating accurate rules is quite difficult, because formalization of all the knowledge about respondents X  occupations used in the occupation coding is almost beyond our power. Second, the system can hardly deal with responses which are not transformed into the form of case frame. 2 Third, the system requires constant efforts to maintain the rule set and the thesaurus, because both terms and expressions which respondents use in describing their occupa-tions change with the times. Therefore, we apply a machine learning method to the occupation coding. We select SVMs, which show high performance in docu-ment classification [7, 11], since this task can be regarded as classification of very short documents. For example, the average length of occupation data in JGSS is approximately 15 characters, while that of a newspaper article in the Mainichi Shinbun Newspaper in Japanese published in 2000 [20] is approximately 550 characters. However, the rule-based system has many effective rules containing domain experts X  knowledge. We apply various combination methods of SVMs and the rule-based method to the occupation coding, making use of information provided by this system.
 pation coding system based on SVMs, which is superior to the rule-based method in accuracy. Second, we show that SVMs are also effective in the classification task of very short  X  X ext X  such as the occupation coding. Third, we show that the combination of SVMs and the rule-based method works well in the classification task. When we apply these methods to the occupation coding, we have to pre-pare a large training data set with correct codes. Although we expect that the more amount of a training data set, the higher an accuracy, it is desirable that the amount of a training data set is smaller for coders. Therefore, we investigate the relationship between the amount of the training data set and an accuracy. Giorgetti and Sebastiani proposed a method for automatically assigning a proper code to the response to an open-ended question in a survey [2]. As survey coding is a difficult task, they formulated the problem of automated survey coding as a text categorization task using supervised machine learning techniques. Compar-ing the supervised machine learning approaches, which were Naive Bayesian clas-sifiers and SVMs, with the dictionary-based approaches through an experiment using a corpus of social surveys (namely, General Social Surveys (GSS)), they have shown that supervised machine learning approaches significantly outper-formed dictionary-based approaches. In dictionary-based approaches, response were classified according to the similarity between the feature vectors of the re-sponse and the category vectors, whose elements were the manually collected words. Park and Zhang [10] applied a combination method to Korean chunk-ing. They forwarded the samples that could not be handled well by their rule-based method to a machine-learning method. They showed that the combination method was better in F-score than the rules or various machine learning meth-ods alone. Isozaki and Hirao [6] applied a combination method to Zero Pronoun Resolution in Japanese. They first sorted antecedent candidates by using rules, which ranked candidates in the order of priority for applying. Second, they ap-plied SVMs to the candidates in the order. Third, if SVMs judged that a can-didate was a positive example, they selected the candidate and stopped there. They showed that this combination gave better performance than either of the two previous approaches. The occupation coding is a task in which researchers assign proper occupation codes to occupation data collected in social surveys. One of the most common occupation code sets in Japan is the SSM code set [3], which is based on a national census. It is quite hard for coders to completely learn the definitions of all the occupation codes, because the number of occupation codes is nearly 200 in both SSM and JGSS. 3 A data sample on occupation consists of responses to various questions regarding the respondents X  occupations [4]:  X   X  X ob task X  (open-ended),  X   X  X ndustry X  (open-ended),  X   X  X mployment status X  (close-ended),  X   X  X ob title X  (close-ended),  X   X  X irm size X  (close-ended).
 an occupation data is as follows:  X   X  X ob task X  is  X  X o arrange the delivery vehicles X ,  X   X  X ndustry X  is  X  X oad and unload of luggage X ,  X   X  X mployment status X  is  X 2: Regular employee X ,  X   X  X ob title X  is  X 1: No managerial post X ,  X   X  X irm size X  is  X 8: From 500 to 999 X , then the occupation code is determined to  X 563 X  (a transportation clerk). to consider other responses. Coders cannot readily get skill in the occupation coding, because the task is complicated. In large-scale surveys such as JGSS or SSM, coding work is conducted to the same data more than twice in order to make the results more reliable. Furthermore, in addition to the current occupa-tions of respondents, their first occupations, current occupations of their spouses and the occupations of their parents are often asked in such surveys. Therefore, coders X  labor is huge. Consequently, since the task is conducted by many coders over a long period of time, the results of the occupation coding are sometimes inconsistent with each other. In this paper, we call the previous system using rules of the form of case frame a rule-based method. At first the system was experimentally developed using a part of occupation data of SSM in 1995 [12] and has manually been improved every time a survey was conducted. In the system, it is supposed that a number of responses are represented by a verb and the noun sub-categorized by the verb. For example,  X  X each a tea-ceremony X  corresponds to  X 539 X  (a tea master), while  X  X each at a primary school X  corresponds to  X 521 X  (a primary school teacher). verb, the sub-categorized noun and the case of the noun from the response to  X  X ob task X . The case is a shallow case such as  X  X o X  or  X  X e X , which are postpositional particles in Japanese. Second, the system generalizes the verb to a verb class using a thesaurus [1]. Then the system searches for a rule that matches the generalized triplet. We call this type of rule rule- X  4 : If a rule- X  is found, the occupation code is assigned to the sample, otherwise the noun is also generalized using a thesaurus. If no rule matches the generalized triplet,  X  X ndetermined X  is assigned. The system also use information of responses to  X  X ndustry X , if necessary. Finally, for some occupation codes, the system checks other occupation variables such as  X  X mployment status X ,  X  X ob title X  and  X  X irm size X . 5 We call this type of rule rule- X  6 : the system extracts a triplet that verb is  X  X rrange X , case is  X  X o (accusative) X  and noun is  X  X aisha (delivery vehicle) X . Second, the verb  X  X rrange X  is generalized to a verb-class  X  X lass-arrange X  by a thesaurus. Then the system finds a rule- X  occupation code  X 563 X  to the response. In this case, the system does not need to generalize the noun because a rule matching the triplet is found before the noun is generalized. For this occupation code, the system does not need to change the first determined occupation code by the rule- X  . The final output of the rule-based method is  X 563 X .
 thesaurus. We have to make a constant effort to maintain them, because new words or expressions with which respondents describe their jobs are frequently created. Moreover, this system has another problem that it can deal with only the responses transformed into the form of case frames.
 Table 1 shows the performance of the rule-based method applied to JGSS [15, 16, 17]. Both total accuracy and accuracy for the label-assigned samples of the other 3 surveys are similar to those of JGSS [13]. The accuracy in this paper is defined as the number of correctly-classified samples divided by the number of all samples. The accuracies in Table 1 are not so high, because this system does not produce any codes for some samples. If the accuracy is measured for only the samples to which the system assigns a code, its value reaches nearly 80%. Compared with the rule-based method, machine learning methods have the ad-vantage that human is not required to create rules. Consequently, we do not have to make effort to maintain rules. Furthermore, machine learning methods are applicable to many domains. Although machine learning requires a large amount of training data for learning, there are both data samples on occupation and correct codes available, because in social surveys, the occupation codes have been manually checked after an automatic coding and we can use the labeled data of the previous years as training data.
 ral network. Among them, we use SVMs in the occupation coding, because SVMs [18] are superior to the other methods in accuracy in many tasks including the document classification and the dependency structure analysis [9]. 5.1 Application of SVMs We apply SVMs to the occupation coding in the following way. First, we create basic features from responses:  X  words in responses to  X  X ob task X   X  words in responses to  X  X ndustry X   X  responses to  X  X mployment status X  and  X  X ob title X  Next, we train SVMs, which then determine the occupation codes of test samples. because SVMs are a binary-classifier. We use the one-versus-rest method [8]. 5.2 The Combinations of SVMs and Rule-Based Method Although the accuracy of the rule-based method is not satisfiable, its precision for  X  X ode-assigned samples X  (i.e., the samples to which the rule-based method assigned a unique label) is quite high (see Table 1). We therefore propose the following four combination methods of the rule-based method and SVMs. In the first three methods, the output of the rule-based method is used as features for SVMs. In the last method, the rule-based method and SVMs are used sequen-tially. The proposed methods are as follows :  X  add-code : the occupation codes provided by the rule-based method are added  X  add-rule : the rules used to determine occupation codes in the rule-based  X  add-code-rule : both the occupation codes and the used rules are added to  X  seq : SVMs are applied only when the rule-based method cannot determine new feature  X 563 X , which is determined as occupation code by the rule-based system, to basic features of SVMs. Second, add-rule adds the ID of rule- X  that is used in decision by the rule-based system as a new feature to basic features of SVMs. Although only one rule is used in this case, two rules are added if rule- X  is used also. Third, add-code-rule adds two new features, which are  X 563 X  and the ID of rule- X  , to basic features of SVMs. Finally, seq outputs  X 563 X  as the final occupation code, without proceeding to SVM classification, because the rule-based system can determine one occupation code in this case. If the rule-based system outputs two different codes or if it outputs the undetermined occupation code  X 999 X , seq uses SVMs.
 results of more than two methods, although it is not a combination of machine learning methods [11]. Similarly, we consider that add-code is a sort of stack-ing [19]. 6.1 Experimental Settings and Preliminary Experiments We conduct two kinds of experiments. In the first experiment (Experiment 1), we compare SVMs 8 with the rule-based system in terms of accuracy. We also investigate effective combinations of SVMs and the rule-based method. In the second experiment (Experiment 2), we investigate the relationship between the size of a training data set and categorization accuracy.
 and JGSS-2002. Each dataset has approximately 6000 to 7000 samples 9 , and the total number of the samples is 20066. In Experiment 1, we use JGSS-2000 and JGSS-2001 as the training data set and JGSS-2002 as the test data set. ing data in order to conduct coding work smoothly. We examine two cases; one is the case where the coded samples of the previous surveys are available (Case 1), and the other is where coders have to conduct coding work from the scratch (Case 2). In Case 1, the training dataset is JGSS-2000, JGSS-2001 and a part of JGSS-2002. The test dataset is the rest of JGSS-2002. In Case 2, the training dataset is a part of JGSS-2002, and the test dataset is the rest of JGSS-2002. Thus, both cases are the simulation of coding JGSS-2002 with or without JGSS-2000 and JGSS-2001. In both cases, we conduct n-fold cross validations (n=2,  X   X  X  , 10), splitting JGSS-2002 in two parts in each fold. The two parts are later exchanged for experiments with small training datasets. We conduct Experiment 2 with four methods: add-code, add-rule, add-code-rule and SVMs.
 within the range from 0.1 to 1.0 in Experiment 1, while we set C as the best value tuned to each method in Experiment 2. A soft margin parameter C represents a degree of allowance for exceptional samples. The smaller the value, the lighter the weight for exceptional samples.
 using JGSS-2001.  X  Experiment 2-gram/3-gram+basic features :  X  Experiment kana-basic features :  X  Experiment 2-gram/3-gram+kana-basic features : In these experiments, no significant improvements in results have not been ob-served. Feature selection by Information Gain [11] did not increase accuracy, either. Therefore, we use basic features in the following experiments. 6.2 Experiment 1: Results and Discussion At C =1 . 0, the accuracy of SVMs is 71.9%, which is 5.8 % higher than that of the rule-based method. One of the reasons is that according to the strategy of the rule-based method, the rule-based method does not assign any occupation code to difficult samples, while SVMs automatically assigns a code to all the samples. The rule-based method assigns a code to only 74.6% of all the samples, and 79.8% of them are correct (see Table 1). For those code-assigned samples, SVMs yield the accuracy of 78.5%, which is slightly less than that of the rule-based method.
 as well as SVMs. These methods are, in terms of accuracy at C =1 . 0, ranked in rule-based method). We call SVMs that are not combined with the rule-based method as SVM. because the combination methods are superior to SVMs at each point of C .The accuracy of add-code is superior to that of add-rule at each point of C . A possible reason is that the added features of add-rule are more widely distributed and the reliable learning is not successful due to the lack of enough training data. 10 The accuracy of add-code-rule is mostly the same as that of add-code. This fact shows that little additional information is provided by the features of add-rule in case there are add-code features. of
C , we need to select the best value of C beforehand. Therefore, we conducted additional experiments for tuning the value of C , splitting the training dataset into two, where we use JGSS-2000 as a temporary training dataset and JGSS-2001 as a temporary test dataset. Table 2 shows the accuracy at the predicted best value of C in each method. The accuracy of each method at these values of C corresponds to nearly the maximum accuracy.
 and henceforth forwarded to SVMs. Approximately, 30% of these forwarded samples have been assigned to multiple codes and 70% to  X  X ndetermined X . When seq uses SVMs, two types of samples can be used as a training data set. One consists of all the samples, and the other consists of only undetermined samples. Table 3 shows that accuracy of the former is higher than that of the latter. 6.3 Experiment 2: Results and Discussion Figure 2 shows the relationship between the size of a training data set and the accuracy of add-code, add-rule, add-code-rule and SVM in Case 1 and Case 2 ( C is set to the best value in each method).
 difference between accuracies of Case 1 and those of Case 2 decreases as the size of the training data set becomes larger. In both cases, add-code and add-code-rule are constantly better than add-rule and SVM. That difference is clearer in Case 2 than in Case 1. Therefore, it is strongly recommended to use add-code or add-code-rule especially when no previously coded samples are available. In each method, the accuracy in Case 2 with the half of the newly-added training data approximately equals to the accuracy in Case 1 without any newly-added train-ing samples (left-most of Figure 2). Therefore, if we cannot use coded samples, conducting the occupation coding by a half size of all the samples is effective. We have applied SVMs to the occupation coding and shown that SVMs are su-perior to the rule-based method in terms of categorization accuracy also when a document is very short. We have also applied the combinations of SVMs and the rule-based method to the occupation coding and shown that each of the combina-tion methods is superior to SVMs. Furthermore, we have conducted experiments to investigate effects of feedback and shown that a feedback is effective. In future work, we would like to find a method for measuring confidence for each output of these automatic methods, in order to support manual check of the results. We will also adopt active learning in the feedback process.
 The Japanese General Social Surveys JGSS are designed and carried out at the Institute of Regional Studies at Osaka University of Commerce in collaboration with the Institute of Social Science at Tokyo University under the direction of I. TANIOKA, M. NITTA, H. SATO and N. IWAI. The project is financially assisted by Gakujutsu Frontier Grant from the Japanese Ministry of Education, Culture, Sports, Science, and Technology for 1999-2003 academic years.
