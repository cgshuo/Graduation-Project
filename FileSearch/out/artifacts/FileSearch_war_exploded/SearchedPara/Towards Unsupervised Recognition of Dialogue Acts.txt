 People proceed in their conversations through a se-quence of dialogue acts to yield some specific com-municative goal. They can ask for information, agree or disagree with their partner, state some facts and express opinions.

Dialogue Acts (DA) attracted linguistics (Austin, 1962; Searle, 1969) and computational linguistics research (Core and Allen, 1997; Traum, 2000) since long time. With the advent of the Web, a large amount of material about natural language inter-actions (e.g. blogs, chats, conversation transcripts) has become available, raising the attractiveness of empirical methods analyses on this field. There is a large number of application domains that could benefit from automatically labeling DAs: e.g. con-versational agents for monitoring and supporting human-human remote conversations, blogs, forums and chat logs analysis for opinion mining, interper-sonal stances modeling by mean of conversational analysis, automatic meeting summarizations and so on. These applications require a deep understanding of the conversational structure and the ability of the system to understand who is telling what to whom.
This study defines a method for automatically la-beling dialogues with the proper speech acts by re-lying on empirical methods. Even if prosody and intonation surely play a role (e.g. (Stolcke et al., 2000; Warnke et al., 1997)), nonetheless language and words are what the speaker uses to convey the communicative message and are just what we have at disposal when we consider texts found on the Web. Hence, we decided to simply exploit lexical semantics of the sentences. We performed some ex-periments in a supervised and unsupervised frame-work on both an English and an Italian corpora of dialogue transcriptions, achieving good results in all settings. Unsupervised performance is particularly encouraging, independently from the used language.
The paper is organized as follows. Section 2 gives a brief sketch of the NLP background on Dialogue Acts recognition. In Section 3 we introduce the En-glish and Italian corpora of dialogues, their charac-teristics and DA labeling. In Section 4 we describe the preprocessing of the data sets. Then Section 5 explains the supervised and unsupervised settings, showing the experimental results obtained on the two corpora and providing an error analysis. Finally, in Section 6 we conclude the paper with a brief dis-cussion and some directions for future work. A DA can be identified with the communicative goal of a given utterance (Austin, 1962). Researchers use different labels and definitions to address this con-cept: speech act (Searle, 1969), adjacency pair part (Schegloff, 1968) (Sacks et al., 1974), game move (Power, 1979) Traditionally, the NLP community has employed DA definitions with the drawback of being do-main or application oriented. Recently some efforts have been made towards unifying the DA annotation (Traum, 2000). In the present study we refer to a domain-independent framework for DA annotation, the DAMSL architecture (Dialogue Act Markup in Several Layers) by (Core and Allen, 1997).

Recently, the problem of DA recognition has been addressed with promising results: Poesio and Mikheev (1998) combine expectations about the next likely dialogue  X  X ove X  with information de-rived from the speech signal features; Stolcke et al. (2000) employ a discourse grammar, formal-ized in terms of Hidden Markov Models, combining also evidences about lexicon and prosody; Keizer et al. (2002) make use of Bayesian networks for DA recognition in dutch dialogues; Grau et al. (2004) consider naive Bayes classifiers as a suitable ap-proach to the DA classification problem; a partially supervised framework has also been explored by Venkataraman et al. (2005)
Regardless of the model they use (discourse grammars, models based on word sequences or on the acoustic features or a combination of all these) the mentioned studies are developed in a supervised framework. In this paper, one goal is to explore also the use of a fully unsupervised methodology. In the experiments of the present paper we exploit two corpora, both annotated with DAs labels. We aim at developing a recognition methodology as general as possible, so we selected corpora which are different in content and language: the Switch-board corpus (Godfrey et al., 1992), a collection of transcriptions of spoken English telephone con-versations about general interest topics, and an Ital-ian corpus of dialogues in the healthy-eating domain (Clarizio et al., 2006).

In this section we describe the two corpora, their features, the set of labels used for annotating the di-alogue acts with their distributions and the data pre-processing. 3.1 Description The Switchboard corpus is a collection of English human-human telephone conversations (Godfrey et al., 1992) between couples of randomly selected strangers. They were asked to choose one general interest topic and to talk informally about it. Full transcripts of these dialogues are distributed by the Linguistic Data Consortium. A part of this cor-pus is annotated (Jurafsky et al., 1997) with DA labels (overall 1155 conversations, for a total of 1 shows a short sample fragments of dialogues from the Switchboard corpus.

The Italian corpus had been collected in the scope of some previous research about Human-ECA inter-action. A Wizard of Oz tool was employed (Clarizio et al., 2006) and during the interaction, a conver-sational agent (i.e. the  X  X izard X ) played the role of an artificial therapist. The users were free to inter-act with it in natural language, without any partic-ular constraint. This corpus is about healthy eating and contains (overall 60 dialogues, 1448 users X  ut-terances and 15,500 words). 3.2 Labelling Both corpora are annotated following the Dialogue Act Markup in Several Layers (DAMSL) annotation scheme (Core and Allen, 1997). In particular the Switchboard corpus employs a revision (Jurafsky et
Table 2 shows the set of labels employed with their definitions, examples and distributions in the two data sets. The categories maintain the DAMSL main characteristic of being domain-independent and can be easily mapped back into SWBD-DAMSL ones, and maintain their original semantics. Thus, the original SWBD-DAMSL annotation had been automatically converted into the categories included To reduce the data sparseness, we used a POS-tagger and morphological analyzer (Pianta et al., 2008) for preprocessing both corpora. So we considered lem-mata instead of tokens in the format lemma#POS . In addition, we augment the features of each sentence with a set of linguistic markers, defined according to the semantic of the DA categories. We hypothesize, in fact, these features could play an important role in defining the linguistic profile of each DA. The ad-dition of these markers is performed automatically, by just exploiting the output of the POS-tagger and of the morphological analyzer, according to the fol-lowing rules:  X  WH-QTN , used whenever an interrogative de- X  ASK-IF , used whenever an utterance presents  X  I-PERS , used for all declarative utterances  X  COND , used for conditional form is detected.  X  SUPER , used for superlative adjectives.  X  AGR-EX , used whenever an agreement ex- X  NAME , used whenever a proper name follows  X  OR-CLAUSE , used for or-clauses, that is ut- X  VB , used only for the Italian, when a dialectal We conducted some experiments both in a super-vised and unsupervised settings. 5.1 Supervised Regarding the supervised experiments, we used Support Vector Machines (Vapnik, 1995), in partic-ular SVM-light package (Joachims, 1998) under its default configuration. We randomly split the two corpora into 80/20 training/test partitions. SVMs have been used in a large range of problems, in-cluding text classification, image recognition tasks, bioinformatics and medical applications, and they are regarded as the state-of-the-art in supervised learning. We got .71 and .77 of F1 measures respec-tively for the Italian and English corpus. Table 4 reports the performance for each direct act. 5.2 Unsupervised It is not always easy to collect large training, partly because of manual labeling effort and moreover be-cause often it is not possible to find it.

Schematically, our unsupervised methodology is: (i) building a semantic similarity space in which words, set of words, text fragments can be repre-sented homogeneously, (ii) finding seeds that prop-erly represent dialogue acts and considering their representations in the similarity space, and (iii) checking the similarity of the utterances.

To get a similarity space with the required charac-teristics, we used Latent Semantic Analysis (LSA), a corpus-based measure of semantic similarity pro-posed by Landauer (Landauer et al., 1998). In LSA, term co-occurrences in a corpus are captured by means of a dimensionality reduction operated by a singular value decomposition (SVD) on the term-by-document matrix T representing the corpus.
 SVD decomposes the term-by-document matrix T into three matrices T = U X  the diagonal k  X  k matrix containing the k singu-lar values of T ,  X  and V are column-orthogonal matrices. When the three matrices are multiplied together the original term-by-document matrix is re-composed. Typically we can choose k 0 k obtaining the approximation T
LSA can be viewed as a way to overcome some of the drawbacks of the standard vector space model (sparseness and high dimensionality). In fact, the LSA similarity is computed in a lower dimensional space, in which second-order relations among terms and texts are exploited. The similarity in the result-ing vector space is then measured with the standard cosine similarity. Note also that LSA yields a vec-tor space model that allows for a homogeneous rep-resentation (and hence comparison) of words, sen-tences, and texts. For representing a word set or a sentence in the LSA space we use the pseudo-document representation technique, as described by Berry (1992). In practice, each text segment is repre-sented in the LSA space by summing up the normal-ized LSA vectors of all the constituent words, using also a tf.idf weighting scheme (Gliozzo and Strappa-rava, 2005).
 The methodology is completely unsupervised. We run the LSA using 400 dimensions (i.e. k 0 , as suggested by (Landauer et al., 1998)) respectively on the English and Italian corpus, without any DA label information. Starting from a set of seeds (words) representing the communicative acts (see the complete sets in Table 3), we build the corre-sponding vectors in the LSA space and then we com-pare the utterances to find the communicative act with higher similarity. To compare with SVM, the performance is measured on the same test set parti-tion used in the supervised experiment (Table 4).
We defined seeds by only considering the commu-nicative goal and the specific semantic of every sin-gle DA, just avoiding as much as possible the over-lapping between seeds groups. We wanted to design an approach which is as general as possible, so we did not consider domain words. The seeds are the same for both languages, which is coherent with our goal of defining a language-independent method. 5.3 Experimental Results and Discussion We evaluate the performance of our method in terms of precision, recall and f1-measure (see Table 4) ac-cording to the DA labels given by annotators in the datasets. As baselines we consider (i) most-frequent label assignment (respectively 37% for Italian, 57% for English) for the supervised setting, and (ii) ran-dom DA selection (11%) for the unsupervised one.
Results are quite satisfying (Table 4). In particu-lar, the unsupervised technique is largely above the baselines, for both the Italian and the English exper-iments. The methodology is independent from the language and the domain: the Italian corpus is a col-lection of dialogue about a very restricted domain while the Switchboard conversations are essentially task-free. Moreover, in the unsupervised setting we use in practice the same seed definitions. Secondly, it is independent on the differences in the linguis-tic style due to the specific interaction scenario and input modality. Finally, the performance is not af-fected by the difference in size of the two data sets. Error analysis. After conducting an error analy-sis, we noted that many utterances are misclassi-fied as STATEMENT. One possible reason is that statements usually are quite long and there is a high chance that some linguistic markers that character-ize other dialogue acts are present in those sen-tences. On the other hand, looking at the corpora we observed that many utterances which appear to be linguistically consistent with the typical structure of statements have been annotated differently, accord-ing to the actual communicative role they play. For similar reasons, we observed some misclassifica-tion of S-OPINION as STATEMENT. The only sig-nificative difference between the two labels seems to be the wider usage of  X  X lanted X  and affectively loaded lexicon when conveying an opinion. Another cause of confounding is the confusion among the backchannel labels (GEN-ANS, AGREE-ACC and REJECT) due to the inherent ambiguity of common words like yes , no , yeah , ok .

Recognition of such cases could be improved (i) by enabling the classifiers to consider not only the lexical semantics of the given utterance (local con-text) but also the knowledge about a wider context window (e.g. the previous n utterances), (ii) by en-riching the data preprocessing (e.g. by exploiting in-formation about lexicon polarity and subjectivity pa-rameters). We intend to follow both these directions in our future research. This study aims at defining a method for Dialogue Acts recognition by simply exploiting the lexical se-mantics of dialogue turns. The technique had to be independent from some important features of the corpus being used such as domain, language, size, interaction scenario. In a long-term perspective, we will employ the technique in conversational analysis for user attitude classification (Martalo et al., 2008).
The methodology starts with automatically en-riching the corpus with additional features, such as linguistic markers. Then the unsupervised case con-sists of defining a very simple and intuitive set of seeds that profiles the specific dialogue acts, and subsequently performing a similarity analysis in a latent semantic space. The performance of the unsu-pervised experiment has been compared with a su-pervised state-of-art technique such as Support Vec-tor Machines, and the results are quite encouraging.
Regarding future developments, we will investi-gate how to include in the framework a wider con-text (e.g. the previous n utterances), and the intro-duction of new linguistic markers by enriching the preprocessing techniques. In particular, it would be interesting to exploit the role of slanted or affective-loaded lexicon to deal with the misclassification of opinions as statements. Along this perspective, DA recognition could serve also as a basis for conver-sational analysis aimed at improving a fine-grained opinion mining in dialogues.

