 Gradient descent is a widely used paradigm for solving many optimization problems. Stochastic gradient descent per-forms a series of iterations to minimize a target function in order to reach a local minimum. In machine learning or data mining, this function corresponds to a decision model that is to be discovered. The gradient descent paradigm un-derlies many commonly used techniques in data mining and machine learning, such as neural networks, Bayesian net-works, genetic algorithms, and simulated annealing. To the best of our knowledge, there has not been any work that extends the notion of privacy preservation or secure multi-party computation to gradient-descent-based techniques. In this paper, we propose a preliminary approach to enable privacy preservation in gradient descent methods in general and demonstrate its feasibility in specific gradient descent methods.
 H.2.8 [ Database Management ]: Database Applications X  Data mining ; H.2.7 [ Database Management ]: Database Administration X  Security, integrity, protection Theory, Algorithms, Security Privacy Preservation, Gradient Descent Method, Secure Multi-party Computation, Regression  X  This work is supported in part by grant P0520095 from the Agency for Science, Technology and Research (A*STAR), Singapore.
 Copyright 2007 ACM 978-1-59593-609-7/07/0008 ... $ 5.00.
Many techniques in data mining and machine learning follow a gradient descent paradigm in the iterative process of discovering a target function or decision model. For in-stance, neural networks generally perform a series of iter-ations to converge the weight coefficients of edges in the network; thus, settling into a decision model. Linear re-gression is a basic statistical method that finds a function to correlate two or more attributes. Linear regression can also be resolved through a gradient descent method that it-eratively minimizes the error of the target function. Other gradient-descent-based methods include Bayesian networks induction, genetic algorithms, and simulated annealing.
Secure multi-party computation and privacy preservation have attracted much attention recently in incorporating se-curity into data mining and machine learning algorithms. A key issue in multi-party secure methods is to allow in-dividual parties to preserve the privacy of its data, while contributing to the computation of a global result together with other parties. Many methods have been proposed to perform Secure Multi-party Computation (SMC) on various basic operations required in data mining. For instance, the scalar product is a basic operation in inducing decision trees and association rule mining that can now be performed se-curely involving two or more parties [1, 3]. Basic matrix op-erations such as matrix multiplication and matrix inversion have also been extended in a secure manner for preserving privacy in various statistical methods [2].

To the best of our knowledge, there has not been any work that extends privacy preservation or secure multi-party com-putation to gradient descent methods. Our contributions in this paper are as follows: 1. We propose a generic formulation of gradient descent 2. With this formulation, we propose a secure two-party We demonstrate how the generic secure gradient descent formulation we propose can be used by specific iteration-based algorithms such as linear regression and neural net-works. We believe this work is significant as the gradient-descent paradigm is widely used.

The organization of this paper is as follows: In Section 2, we discuss related work. As there is no work on secure gra-dient descent, the related work is on secure computations in general and privacy-preserving data mining techniques. In Section 3, we briefly introduce the general method of gradi-ent descent and identify the convergence of weight vectors as the core problem. We propose a formulation of gradient descent that enables us to perform the weight vector conver-gence securely. Section 4 describes a secure two-party proto-col to perform stochastic gradient descent. The correctness, security, computational complexity and communication cost are analyzed in Section 5. In Section 6, we briefly describe how the protocol can be extended to multiple parties. The last section concludes the paper with a summary.
In this section, we review work that is related to secure computation, privacy preservation and data mining. Much of the work focused on conventional data mining techniques (Apriori algorithm, k -means, Na  X  X ve Bayes, etc.) that work on horizontally, vertically partitioned and/or arbitrarily par-titioned data involving two or more parties.

Du and Zhan [3] addressed the secure decision tree con-struction problem for vertically partitioned data involving only two parties. They used one semi-trusted party to se-curely compute scalar products X  X n operation that is central to decision tree induction. Vaidya and Clifton [12] extended the secure decision tree induction problem to vertically par-titioned data involving multiple parties based on the secure set intersection cardinality.

Vaidya and Clifton [9] proposed an algorithm that se-curely mines association rules in vertically partitioned data held by two parties. The algorithm makes use of the secure scalar product operation. An algorithm for association rule mining in horizontally partitioned data has been proposed by Kantarcioglu and Clifton [6] that incorporates crypto-graphic techniques to minimize the information shared with little overhead to the mining task.

Vaidya and Clifton proposed a secure k -means clustering algorithm [10] for vertically partitioned data held by multi-ple parties. The algorithm makes use of secure sum compu-tation to compute distance between two points and compare the difference among point-centroid distances. The authors also proposed an algorithm for the Na  X  X ve Bayes classifier [11] that makes use of the scalar product operation to determine the probability estimate of each class label.
 Yu, Jiang, and Vaidya [14] addressed privacy-preserving SVM for horizontally partitioned data involving multiple parties. The algorithm uses a secure set intersection car-dinality protocol. Vertically partitioned data have been ad-dressed by Yu, Vaidya and Jiang [15] using generic circuit evaluation technique [13] developed for secure multiparty computation.

Du, Han and Chen [2] presented two protocols for per-forming two-party privacy-preserving linear regression and classification on vertically partitioned data. They defined basic matrix operations that are used in the computation in linear regression and classification and showed how they can be performed securely. Thus, these secure matrix operations form basic secure building blocks for linear regression and classification. Their protocols also require a semi-trusted third party. In this paper, we adopt a secure iteration-based approach that allows the solution to be evolved se-curely over a series of iterations. Hence, our method can be applied to linear regression where the target function is securely evolved, rather than computed based on matrix op-erations. In addition, our method does not require any third party.

Du and Atallah [1] presented two protocols for secure scalar production. The general idea of the first protocol is to hide data by partitioning one vector into many par-titions and mixing them with random vectors. The scalar product operation is then performed on these mixed vectors and privacy is preserved. The second protocol is based on the idea that the same mutations of two vectors do not al-ter the scalar product value. The authors showed how the protocol can be applied to perform secure statistical com-putations such as mean and correlation coefficient. Du and Atallah X  X  protocol is among the various protocols proposed to date that perform secure scalar product. Although our proposed protocol is for secure gradient descent, we make use of one of these secure scalar product protocols as a basic operation.

To the best of our knowledge, there has not been any work on privacy-preserving gradient descent methods. We note that most of the current approaches to privacy-preservation isolated some common and basic operations in the data min-ing/knowledge discovery algorithm so that if these basic op-erations can be performed securely, then the algorithm on the whole is also secure. Two of the basic operations are the scalar product and sum computation. There exist known ap-proaches to perform these two operations securely, without each participating party compromising its data privacy [1, 4, 5, 13]. Our protocol makes use of the secure scalar product operation.
In this section, we introduce general gradient descent meth-ods and identify linear regression and neural networks as two instances of stochastic gradient descent which we show how privacy preservation can be introduced. Gradient descent [7] is a general paradigm that underlies many algorithm in machine learning and knowledge discovery. In neural net-works, updating the weight value of the output and hidden nodes is a form of gradient descent. An important advan-tage of the gradient descent method is that it may process the input data set one row at a time, so that memory re-quirement is low as only the row and weight vectors need be stored during the computation. attributes of the i -th sample and y i corresponds to the target attribute, we wish to determine a target function f ( x i yields the lowest error when predicting an unknown sample X  X  y value. This is equivalent to finding a set of weight values {  X  1 ,  X  2 , . . . ,  X  m } such that the overall error of prediction is minimized.

Gradient descent approaches search the space of error functions for the optimal function that minimizes the pre-diction error with respect to the given set of data samples. If the set of data samples is linearly separable, gradient de-scent approaches are able to determine an optimal set of weight values for the weight vector. In general, a gradient descent approach performs a series of iterations to converge to the optimal weight vector. It uses an initial weight vector to determine the prediction error. If the error is not satis-factorily low, the weight vector is modified to reduce the error. At each iteration, the weight vector guides the error function search in the direction of steepest descent. This process continues until the global minimum error point is reached.

In standard gradient descent, all data samples are pro-cessed at each iteration to determine the steepest descent. If the data samples are linearly separable, the global mini-mum point is reachable. However, if the data samples are not linearly separable, then standard method will never con-verge as the optimum point does not exist. The standard gradient descent method has another weakness. In terms of computational complexity, it requires all data samples to be processed at each iteration. This has practical limitations when the data set is very large.

In practice, the stochastic version of gradient descent is used. At each iteration, the stochastic version processes only one data sample to determine the steepest descent and update the weight vector. The significant advantage of the stochastic approach is that the method will converge (and at a much faster rate) even when the data samples are not lin-early separable. However, only a local minimum is reached.
In this paper, we use the stochastic version of gradient descent. The convergence speed does not depend on the fraction of partitions held by each party as stochastic gra-dient descent processes data in a row-wise manner. In our case, data is vertically partitioned. This has no effect on the convergence speed.
We note that the error function in gradient descent meth-ods provides the means to perform descent and the weight vector update function determines the way to perform the steepest descent. In general, as long as the error function is any form of partially differentiable function, a weight up-date function can be derived to effectively perform gradient descent. This includes machine learning algorithms that in-volve multiple error functions (and correspondingly multiple update functions), such as multi-layer neural networks.
In this section, we provide a formulation of gradient de-scent methods in general by generalizing the influence of weight values for each attribute as a function of the at-tribute X  X  value and its corresponding weight parameter. This allows us to introduce a secure protocol in Section 4 to evolve a set of values for the weight parameter.

For any generic gradient descent method and a given error function e : R 2  X  X  X R , the total error E between the target y and predicted output f ( x i ) = f ( x i, 1 , x i, 2 , . . . , x respect to all N samples is defined as: Define the prediction function f as a composition of two functions g and h as follows: Function h should be a linearly separable function such that: where h j ( a,  X  ), 1 6 j 6 m , and  X  is a parameter that bares on the attribute a . In many gradient descent methods, function h i ( a,  X  ) =  X   X  a is a simple multiplication. Here, we express this as a function of a and  X  for generality. Note that the values of the  X  j parameters constitute the actual form of prediction function f . Their optimum set of values will yield an accurate prediction function f .

In determining the set of optimum values for  X  j  X  X , the stochastic gradient descent approach starts with an initial set of random values, and gradually refine (update) these values through a series of iterations. At each iteration, the  X  j values are updated with respect to a particular sample i from the training data set in the direction of steepest descent as follows: where  X  is constant parameter corresponding to the learning rate and  X   X  j =  X  X / X  X  j , which is determined as follows:  X  X 
Therefore, the above show how the steepest descent can be computed for any general error function that is partially differentiable and any prediction function f that satisfies the requirements expressed in Equations 1 and 2.
In this section, we demonstrate the generality of the for-mulation in the previous section by showing the form of pre-diction function f in neural networks and linear regression X  two specific gradient descent methods.
 Linear Regression . For a set of data samples D = { ( x i get function f that best maps each attribute set x into its target output y with minimum error. A commonly used er-ror function is the squared error: E = 1 2 For an arbitrary sample x i , the prediction function f is de-fined as: Steepest descent is achieved by taking the partial derivative of E with respect to each weight element  X  j , 1 6 j 6 m : It has been shown that  X  X / X  X  j =  X  x i,j ( y i  X  f ( x i )) in stochastic gradient descent methods [7]. The weight vector is updated until the error function E reaches a reasonably low value or no further improvements can be made. Neural Networks . For neural networks, the two compo-nent functions for the prediction function f are: h j ( x  X  x j and g ( z ) = 1 / (1 + e  X   X z ). We show below how the up-date function can be computed with respect to the formula-tion of the general case described earlier:  X  X 
In this section, we propose a protocol to perform two-party privacy preserving gradient descent. This protocol will be extended to multi-party gradient descent in the next section.
Given a data set M of size N  X  m and target vector Y as shown below: such that each row x i = ( x i, 1 , x i, 2 , . . . , x i,m M is associated with element y i of Y . We say that y i is x observed target value.

Suppose Alice and Bob each holds partition M 1 and M 2 respectively of M as follows ( m = m 1 + m 2 ), in addition to also holding the target vector Y :
With ( M 1 , Y ) and ( M 2 , Y ) forming Alice and Bob X  X  re-spective training data sets, the task now is for Alice and Bob to jointly discover a target function f ( x , y ) that most accurately predicts an unknown sample x  X  X  target value y using a gradient descent method, while preserving the pri-vacy of their respective data partitions M 1 and M 2 .
Given the general form of target function f (Eq. 1) as described in Section 3.2, where function h ( a 1 , a 2 , . . . , a any linearly separable function and g ( z ) is any differentiable function, discovering function f becomes a problem of find-ing the values for parameters  X  j in h j ( a j ,  X  j ), 1 6 j 6 m .
In order to achieve the task, Alice and Bob need to follow a protocol that will allow them to jointly compute f ( x , y ) without comprising the privacy of their respective M 1 and M 2 . As we assume that Alice and Bob are semi-honest parties [5], they will follow the protocol and perform the correct computations; however, they may retain records of the intermediate computation results which they may use later to derive the other party X  X  data.
We propose the following protocol to perform secure two-party gradient descent. We define the component function of h as follows: h j ( a,  X  ) =  X a (Eq. 2). As described in Section 3.3, this definition suffices for conventional gradi-ent descent methods such as linear regression and neural networks. The definitions of component functions of target function f , functions g and h j (1 6 j 6 m ) are known to Alice and Bob.
 Input . Alice holds a N  X  m 1 matrix M 1 = { a i,j } . Bob holds a N  X  m 2 matrix M 2 = { b i,j } . Both M 1 and M 2 the same as that defined in Section 4.1. The target vector Y is known to both Alice and Bob.
 Output . Weight vector W = [  X  1 ,  X  2 , . . . ,  X  m 1 ,  X   X  W 1. Alice randomly generates a (1  X  m 1 ) vector W 1 and a 2. For each row i (1 6 i 6 N ) of matrix M (equivalently, The protocol is summarized in Figure 1. When the protocol terminates, Alice and Bob have two options on how they can use the securely computed weight vector to perform predic-tion.

Without loss of generality, we denote Alice X  X  final weight vector as: W 1 = [  X  a 1 ,  X  a 2 , . . . ,  X  a m and her random vector as: R 1 = [ r a m Likewise, we denote Bob X  X  final weight vector W and his random vector as: R 2 = [ r b 1 , r b 2 , . . . , r Option 1 . Using W 1 , R 1 , W 2 , and R 2 , Alice and Bob jointly compute the final weight vector W for prediction function f with respect to original data set M as follows:
W = [(  X  a 1 + r b 1 ) , (  X  a 2 + r b 2 ) , . . . , (  X  This option is useful to scenarios whereby two parties come together to securely compute a result (weight vector) which they can use individually later; they can part ways after the joint computation.
 Option 2 . In this option, Alice and Bob do not com-pute the final weight vector representing the prediction func-tion. Instead, they use information ( W 1 , R 1 , W 2 , and R 2 ) that they each hold to jointly perform on-demand pre-diction whenever an unknown sample X  X  target value is re-quired. Hence, each party X  X  private information (i.e., Alice X  X  K a = { W 1 , R 1 } and Bob X  X  K b = { W 2 , R 2 } ) functions like a secure key, and an additional level of security is created whereby Alice and Bob must come together whenever some information/task needs to be unlocked/predicted, using the key-pair ( K a , K b ). This joint-unlocking process is described as follows:
Let each new unknown sample be P = [ p 1 , p 2 , . . . , p p [ p , p 2 , . . . , p m 1 ] and P 2 = [ p m 1 +1 , p m 2 +2 , . . . , p ice and Bob jointly predict P  X  X  target value as follows: 1. Alice computes c = P 1  X  W 1 + P 2  X  R 1 2. Bob computes d = P 2  X  W 2 + P 1  X  R 2 3. Alice and Bob exchange c and d . Each of them now Depending on the domain of interest, the true target value of P may be known at a later point in time. In this case, Alice and Bob may use the true target value to update their own weight vector W 1 and W 2 as in Steps 2(c) and 2(d) of Protocol 1. For instance, Alice and Bob may be predict-ing the atmospheric humidity 7 days from now. The true atmospheric humidity will be known 7 days later.
Protocol 2 securely computes the sum of two scalar prod-ucts between two parties. It is used in Step 2(b) of Proto-col 1. We denote the two parties by Party A and Party B to avoid any confusion with Alice and Bob in Protocol 1. Input . Party A has a (1  X  n ) vector X 1 and a (1  X  m ) vector R 1 . Party B has a (1  X  m ) vector X 2 and a (1  X  n ) vector R Output . Sum of two scalar products X 1  X  R 2 + X 2  X  R 1 v + v 2 where v 1 is held by Party A and v 2 is held by Party B. 1. Party A and Party B compute X 1  X  R 2 using existing 2. Party A and Party B securely perform a similar com-3. Party A sends the sum v 1 = v a + v 0 a to Party B while 4. Party A and Party B compute v 1 + v 2 individually. Throughout this protocol, each party does not know the information held by the other party; neither are they able to speculate the value of X 1  X  R 2 in Step 2 and X 2  X  R Step 3. There exist many protocols [1, 4, 9] for the secure computation of scalar product X  X  Y .
In this section, we show that Protocol 1 is correct and privacy-preserving.
We show (i) if Alice and Bob follow Protocol 1, they will jointly derive a prediction function f in terms of its weight vectors through an iterative gradient descent process; and (ii) if Alice and Bob did not share their respective weight vector information ( W 1 , R 1 , W 2 , R 2 ), then function f can be used to predict the target value of an unknown sample. Part (i): We show that Steps 2(a) X (c) computes f ( x i ) = g (  X  i +  X  i +  X  i ). This is equivalent to showing that h ( x  X  +  X  i +  X  i . h ( x i ) = weight vector is updated using  X   X  j =  X  X / X  X  j =  X  X  ( f ( x i ) , y i ) / X  X  j . Step 2(e) determines whether the pro-tocol terminates in the way conventional gradient descent methods do. Therefore, Protocol 1 performs gradient de-scent correctly.
 Part (ii): We show how the prediction function determines the target value of an unknown sample P ; i.e., f ( P ) = g ( P  X  W ) = g ( c + d ).

P  X  W = Thus, f ( P ) = g ( P  X  W ) = g ( c + d ).
In this section, we show that Protocol 1 and Protocol 2 are privacy preserving.
 Protocol 2 . We show that Protocol 2 securely computes the sum of two scalar products X 1  X  R 2 + X 2  X  R 1 = v 1 without either party knowing X 1  X  R 2 and X 2  X  R 1 . We note that Protocol 2 requires the secure scalar product operation, where there already exist many protocols that are correct and secure [1, 4, 9].
 In Step 1, Party A and B securely perform scalar product X 1  X  R 2 = v a + v b . As neither party share their private values, they do not know the value of X 1  X  R 2 . Step 2 is similar, Party A and B perform X 2  X  R 1 and obtain values v a and v 0 b respectively. As they do not share these values, neither of them know the value of X 2  X  R 1 .

In Step 3, each party discloses only the partial sum of the final result to the other party. Neither of them knows the only have the sum of v 1 + v 2 = X 1  X  R 2 + X 2  X  R 1 without knowing other useful information of the other party. Protocol 2 can also be proved using a simulation method [5]. The basic idea is to show that the view (value received) of each party during the execution of the protocol can be effec-tively simulated given the input and output of that party. Here, we show that both parties are not able to learn any-thing other than the final result. We assume that the secure scalar product protocol used in Protocol 2 is secure and cor-rect. By this assumption, we have the following: 1. Party A is able to effectively simulate the value re-2. Party A is able to effectively simulate the value re-
We now show that Party A learns nothing from the com-putation other than X 1  X  R 2 + X 2  X  R 1 . The proof for Party B is similar. Party A generates random value r as follows: 1. Generate a random number r 1 with probability density 2. Generate a random number r 2 with probability density 3. r = r 1 + r 2 .
 The probability density function of random value r is: The probability density function of the message received in view = x is: For party A, the probability function that simulates r = x is the same as the probability distribution of the received message. We can now conclude that Party A learn nothing from the computation other than the computation result.
In the case when dot products are known to any party at every iteration, the party may discover the other party X  X  random vector value. This is not fair to the other party when gradient descent terminates and both parties choose the sec-ond option. We discuss this minor result in Appendix A. Protocol 1 . We show (i) the secureness of each step in the protocol and then (ii) show that the overall iteration is also secure.
 Part (i): In Step 2(a), Alice and Bob exchange the values of  X  and  X  . As these value are scalar products (singular values) computed from each party X  X  private weight and data vectors, each party would not be able to discover the other party X  X  private weight and data vector using only a single value. In Step 2(b), Alice and Bob follow Protocol 2, which we have shown earlier to be secure. In Step 2(c), Alice and Bob individually compute o i . Hence, there is no privacy issue in this step. In Step 2(d), there is no exchange of information between Alice and Bob as they each update their own weight vector. Hence, there is no privacy issue.

In Step 2(e), Alice and Bob jointly compute the overall error of the joint data set. This requires the computation of Hence, Steps 2(a) X (c) are repeated for each sample i of the original data set. We have shown above that the Steps 2(a) X  (c) are secure, so overall, Step 2(e) is secure.
 Part (ii): We show that the overall set of iterations of gradi-ent descent is secure. Let W 2 ( t ) and  X  ( t ) denote the value of Bob X  X  weight vector and  X  value at the t -th iteration. The initial iteration ( t 0 ) consists of randomly initialized weight vector. The final iteration occurs at t T . We show that if Alice were to keep records of all computation results and erations, she would not be able to derive any information of Bob X  X  data set ( M 2 ), with an extreme exception. In part (i) above, we showed that the  X  value received by Alice from Bob will not compromise Bob X  X  data privacy. We now show that the sequence of  X  ( t 0 ) ,  X  ( t 1 ) , . . . ,  X  ( t received from Bob will likewise not compromise Bob X  X  data privacy. The argument for Bob receiving  X  ( t 0 ) ,  X  ( t values from Alice is identical and is omitted.

Alice knows that each  X  is the dot product of Bob X  X  weight vector W 2 and one row of its data matrix M 2 . We enumer-ate all such dot products corresponding to all iterations of the gradient descent convergence process as follows: where u = t k mod N and s = t T mod N .

As the value of W 2 changes at each iteration, it is impos-sible for Alice to know W 2 . Hence, Alice will also not know any information regarding each row of Bob X  X  data matrix. Hence, the gradient descent iteration of Steps 2(a) to 2(e) is secure.

When the protocol terminates, Alice and Bob have two options: (i) Share the weight and random vectors in order to obtain the final weight vector, or (ii) Use their private weight and random vectors to perform on-demand predic-tion. If Alice and Bob choose Option 1, then Alice knows Bob X  X  W 2 . At the last iteration t T , in the extreme case when Bob X  X  data matrix M 2 has only one column; i.e., m 2 1, then Alice will know the s -th row of M 2 , as  X  ( t T W  X  ( t T ) / X  m 1 +1 . If Bob X  X  M 2 has more than one columns, then no data privacy is compromised. Likewise for all other iterations before the final one, no data privacy is compro-mised.
In this section, we derive the computational complexity and communication cost of Protocol 1.
 Computational Complexity . We determine the compu-tational complexity of one iteration of Protocol 1 as follows: In Step 1, Alice and Bob generate the weight and random vectors of lengths m 1 and m 2 . So the computational com-plexity is O ( m 1 + m 2 ). In Step 2(a), Alice and Bob perform the scalar product of data and weight vectors. The compu-tational complexity for Alice and Bob is O ( m 1 ) and O ( m respectively. In Step 2(b), Alice and Bob executes the secure scalar product protocol (Protocol 2) for two vectors of length of m 1 and two vectors of length of m 2 . If we define the com-putational complexity of secure scalar product as O (  X  ( z )) where z is the number of elements in the multiplicand vec-tors and  X  ( z ) is an expression for computational complexity of z with respect to some secure scalar product protocol used. The computational complexities for Alice and Bob in this step are O (  X  ( m 1 ) +  X  ( m 2 )) and O (  X  ( m respectively.

In Step 2(c), the computational complexity is O ( g ) as it involves the computation of function g . In Step 2(d), the weight vectors of Alice and Bob are updated once. Hence, the computational complexity is O (max { m 1 , m 2 } ). In Step 2(e), the overall prediction error is computed using all the rows of data matrix M . Hence, the complexity is it is not necessary to compute the overall prediction error at every iteration. It can be performed only with a probability.
The overall complexity for the entire iteration is: O ( N  X  (  X  ( m 1 ) +  X  ( m 2 ) + O ( g ))).
 Communication Cost . In Step 1, Alice and Bob generate the weight and random vectors of lengths m 1 and m 2 . No communication is needed. Thus, there is no communication cost.

In Step 2(a), Alice and Bob exchange  X  and  X  values. The communication cost is O (1).

In Step 2(b), Alice and Bob executes the secure scalar product protocol (Protocol 2) for two vectors of length of m 1 and two vectors of length of m 2 . If the communica-tion cost of secure scalar product is O (  X  0 ( z )), where z is the number of elements in the multiplicand vectors and  X  0 ( z ) is an expression for the communication cost of z with re-spect to some secure scalar product protocol used. The com-putational complexities for Alice and Bob in this step are O (  X  0 ( m 1 ) +  X  0 ( m 2 )) and O (  X  0 ( m 1 ) +  X  0 ( m In Step 2(c), there is no communication cost as Alice and Bob compute function g locally. In Step 2(d), there is no communication cost as Alice and Bob update their weight vector locally. In Step 2(e), the overall prediction error is computed using all the rows of data matrix M . Hence, the complexity is O ( N  X  ( O (  X  0 ( m 1 ) +  X  0 ( m 2 ))).
The overall complexity for the entire iteration is: O ( N  X  (  X  ( m 1 ) +  X  0 ( m 2 ))).
The secure two-party gradient descent protocol presented in Section 4 can be extended to multi-parties as follows: Let there be P 0 , P 1 , . . . , P K  X  1 parties cooperating to perform stochastic gradient descent with respect to a ( N  X  m ) data matrix M . Each party P i holds a ( N  X  m i ) partition M the matrix so that protocol executes as follows: 1. Each party P i generates a (1  X  m i ) weight vector W i 2. Each party P i also generates a (1  X  m i +1 mod K ) ran-3. The remaining steps: Computing secure scalar prod-As the extension is straightforward, it can be easily shown that the multi-party version of Protocol 1 is also correct and privacy-preserving.
Gradient descent is a widely used method for solving many optimization and learning problems. So far, there has not been any work that extends privacy preservation to gradi-ent descent methods. In this paper, we presented a generic formulation of secure gradient descent methods by defining differentiable function and h = separable. The latter property of function h allows the  X  to be updated locally.

With this formulation, we propose a secure two-party pro-tocol for performing gradient descent. We showed that the protocol is correct and privacy preserving. We also analyzed its computational and communication cost. We extended the protocol to perform secure multi-party gradient descent. We believe the work presented in this paper is significant as gradient descent is a widely used.

For future work, we intend to apply the secure gradient descent protocol to two-or multi-party Bayesian network induction. Arising from our investigations in this paper, we are also interested in looking into the following problem: We have formulated h j ( a j ,  X  j ) as a product of two values  X  j  X  a j . This definition suffices for many gradient descent-based algorithms such as neural networks, linear regression, Bayesian networks, and so on. In the case when function h j is not a multiplication and the secure protocol requires random values to be used to hide the weight vectors, how to define a general protocol that will work for this scenario? [1] W. Du and M. Atallah. Privacy-Preserving [2] W. Du, Y. S. Han, and S. Chen. Privacy-preserving [3] W. Du and Z. Zhan. Building Decision Tree Classifier [4] B. Goethals, S. Laur, H. Lipmaa, and T. Mielik. On [5] O. Goldreich. The Foundations of Cryptography . [6] M. Kantarcioglu and C. Clifton. Privacy-Preserving [7] T. Mitchell. Machine Learning . McGraw-Hill, 1997. [8] S. Russell, J. Binder, D. Koller, and K. Kanazawa. [9] J. Vaidya and C. Clifton. Privacy Preserving [10] J. Vaidya and C. Clifton. Privacy Preserving K-means [11] J. Vaidya and C. Clifton. Privacy Preserving Na  X  X ve [12] J. Vaidya and C. Clifton. Privacy-Preserving Decision [13] A. Yao. How to Generate and Exchange Secrtes. [14] H. Yu, X. Jiang, and J. Vaidya. Privacy-Preserving [15] H. Yu, X. Jiang, and J. Vaidya. Privacy Preserving
In Section 5 when we analyzed Protocol 2, we mentioned that in the case when the dot products are known to any of the party at every iteration, the party might discover the other party X  X  random vector value. We show how this is possible in this section.

Alice and Bob uses Protocol 2 in Step 2(b) to jointly com-pute the sum of two dot products  X  ( t i ) =  X  a ( t i ) +  X  where  X  b = X 2  X  R 1 and  X  a = X 1  X  R 2 at each iteration t of the gradient descent convergence process.

If Alice knows the  X  a ,  X  b values for all iterations, she could form the following set of expressions corresponding to all the iterations to infer information about Bob X  X  R 2 : where u = t k mod N and s = t T mod N . There are N equivalence classes for the above expressions as the gradient descent convergence process repeatedly cycles through every row of the data matrix. Note that for each dot product in the above expressions, the left vector R 2 is identical and does not change. The right vector repeatedly cycles through each row of Alice X  X  matrix M 1 . Since  X  a and the right vector is known to Alice, an expression can be formed to deduce the elements of R 2 . As there are m 1 elements in R 2 , as long as there are at least m 1 iterations, the m 1 expressions will be able to completely reveal R 2 . That is, if N &gt; m 1 R 2 will be found out by Alice. The same argument holds when Bob knows the  X  a ,  X  b values for all iterations; he will likewise be able to infer Alice X  X  R 1 .

Despite of the above consequence, Alice (Bob) will not know Bob (Alice) X  X  data. Consider the following set of ex-pressions arising from the iterations: where u = t k mod N and s = t T mod N . Note that the right vector in each dot product above is different. For those iterations t i and t j where i mod N = j mod N , the right vector of the dot product comes from the same row of Bob X  X  M 2 matrix. Hence,  X  b ( t i ) =  X  b ( t j ); so Alice would not be able to find out the elements of this row. So although Alice knows  X  b and R 1 , she would not be able to infer Bob X  X  data matrix. Hence, Bob X  X  data privacy is not compromised.
Instead of knowing each  X  a and  X  b values, consider the case when Alice (Bob) knows the  X  i value for all iterations. Then each iteration yields an expression:  X  ( t k ) = R 2  X  [ a u, 1 , a u, 2 , . . . , a u,m 1 ]+ R It is quite obvious that Alice would neither know R 2 nor Bob X  X  data.

