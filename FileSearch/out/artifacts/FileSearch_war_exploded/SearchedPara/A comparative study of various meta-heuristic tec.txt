 1. Introduction
Image thresholding is widely used as a popular tool in image segmentation. It is useful in separating objects from background, or discriminating objects from objects that have distinct gray levels. Thresholding involves bi-level thresholding and multilevel thresholding. Bi-level thresholding classifies the pixels into two groups, one including those pixels with gray levels above a certain threshold, the other including the rest. Multilevel thresholding divides the pixels into several classes. The pixels belonging to the same class have gray levels within a specific range defined by several thresholds. Both bi-level and multilevel thresholding methods can be classified into parametric and nonparametric approaches. The nonparametric approach is based on a search of the thresholds optimizing an objective function such as the between-class variance (Otsu X  X  function) ( Otsu, 1979 ), entropy (Kapur X  X  function) ( Kapur et al., 1985 ).

In parametric approach, the gray-level distribution of each class has a probability density function that is assumed to obey a given distribution. An attempt to find an estimate of the parameters of the distribution that best fits the given histogram data is made by using the least-squares method. It typically leads to a nonlinear optimization problem, of which the solution is computationally expensive and time-consuming. A great number of thresholding methods belonging to parametric and nonpara-metric approaches have been proposed in order to perform bi-level thresholding ( Sezgin and Sankur, 2004 ; Lievers and Pilkey, 2004 ; Chu et al., 2004 ; Gonzales-Baron and Butler, 2006 ). They are extendable for multilevel thresholding as well. However, the amount of thresholding computation significantly increases with this extension. To overcome this problem, several techniques have been proposed. Some of them are designed especially for computation acceleration of a specific objective function, such as the Otsu X  X  function ( Lin, 2001 ; Dong et al., 2008 ; Riddi et al., 1987 ; Ng, 2004 ; Liao et al., 2001 ), while other techniques are designed to be used with a general purpose. Among the last category, we can find those that involve a sequential dichotomiza-tion technique ( Yen et al., 1995 ; Sezgin and Tasaltin, 2000 ; Wu et al., 2004 ) and those that use an iterative scheme ( Yin and Chen, distributions by using a bi-level thresholding and the distribution with the largest variance is further dichotomized in two more distributions by applying the same bi-level thresholding. This dichotomization process is repeated until a stopping criterion is satisfied. The dichotomization techniques are faster algorithms. Unfortunately, they are sub-optimal techniques and they do not provide the optimal threshold values. The second approach starts with initial thresholds. Then, these thresholds are adjusted iteratively to improve the value of the objective function. This improvement process stops when the value of the objective function does not increase between two consecutive iterations.
The implementation of this method is similar to the one presented by Luo and Tian (2000) , where the Kapur X  X  function is maximised by using the iterated conditional modes (ICM) algorithm. How-ever, the iterative schemes are sensitive to initial values of thresholds and can converge to the local optimum. Other strategies can also be applied for fast multilevel thresholding, as the one proposed in Kim et al. (2003), where the resolution of the histogram is reduced using the wavelet transform. From the reduced histogram, the optimal thresholds are determined faster by optimizing the objective function based on an exhaustive search. The selected threshold values are then expanded to the original scale.

Another alternative to fast multilevel thresholding uses a new class of algorithms, called meta-heuristics. A meta-heuristic is a set of algorithmic concepts that can be used to define heuristic methods applicable to a wide set of various problems ( Blum and
Roli, 2001 ; Glover and Kochenberger, 2003 ). In other words, a meta-heuristic can be seen as a general-purpose heuristic method, designed to guide an underlying problem specific heuristic toward promising regions of the search space, containing high-quality solutions. A meta-heuristic therefore is a general algorithmic framework, which can be applied to different optimization problems at the price of relatively few modifications.
The meta-heuristic techniques are able to escape from local optima and their use has significantly increased the ability of finding very high-quality solutions to hard, practically relevant combinatorial optimization problems in a reasonable time. This is particularly true for large and poorly understood problems.
Several different meta-heuristics have been proposed and new ones are under constant development. Some of the most famous ones are Genetic Algorithms (GA) ( Goldberg, 1989 ), Particle
Swarm Optimization (PSO) ( Kennedy and Eberhart, 1995 ), Differ-ential Evolution (DE) ( Storn and Price, 1995 ), Ant Colony
Optimization (ACO) ( Dorigo and St  X  utzle, 2000 ), Simulated Anneal-ing (SA) ( Kirkpatrick et al., 1983 ), Tabu Search (TS) ( Glover and Laguna, 1997 ) and explorative local search methods, including Adaptive Search Procedure (GRASP), Variable Neighborhood
Search (VNS), Guided Local Search (GLS) and Iterated Local Search (ILS) ( Blum and Roli, 2001 ; Glover and Kochenberger, 2003 ).
Taking into account the advantages of the meta-heuristics to escape from local optima with a reasonable time, some meta-heuristic techniques have been extensively employed to search more fastly the optimal thresholds. These techniques are designed to be used with a general purpose, with either the parametric or the non-parametric approaches, for the multilevel thresholding problem. This problem, which consists in searching the various thresholds, can be considered as a nonlinear optimization problem and the objective functions can have several local optima. For solving such NP-hard problems, enumerative search methods are practically inappropriate because of the presence of several local minima. Their performance deteriorates with the complexity of the problem related to the number of thresholds.
For example, the complexity of an exhaustive search grows exponentially with the number k of thresholds as O  X  L  X  k 1  X   X  , L representing the number of gray levels in the image.

Indeed, the optimization techniques based on GA have been widely applied to solve the multilevel thresholding ( Yin, 1999 ; al., 2008 ; Hammouche et al., 2008 ; Lai and Tseng, 2004 ; Tao et al., al. (2003) , Chang and Yan (2003), Cao et al. (2008), Hammouche et al. (2008) , the GA uses binary encoding while in Lai and Tseng (2004) , Tao et al. (2003) and Bazi et al. (2007) , the floating encoding is used. In addition to the way of coding the vectors solutions, these techniques differ by their fitness function. In Yin (1999) and Cao et al. (2008) the objective function is similar to
Otsu X  X  or Kapur X  X  functions. In Jinsong et al. (1999) the objective function is the Kapur X  X  function and in Yang et al. (2003) it is assimilated to the relative entropy ( Chang et al., 1994 ). Chang and
Yan (2003) have employed a GA to maximize the conditional probability entropy (CPE) based on Bayesian theory, in order to determine the optimal thresholds. CPE considers that the pixels with the same gray level in an image may belong to different classes with different probabilities. An optimal classification method for these pixels is to classify them in the class with higher probability. More recently, the GA presented in Ham-mouche et al. (2008) determines the threshold number as well as the optimal threshold values, by using an objective function derived from a correlation function ( Yen et al., 1995 ). In Lai and
Tseng (2004) , the intensity distributions of objects and back-ground in an image are assumed to be Gaussian distributions with distinct means and standard deviations. The histogram of a given image is fitted to a mixture Gaussian probability density function.
The GA is used to estimate the parameters in the mixture density function, so that the square error between the density function and the actual histogram is minimal. Tao et al. (2003) use a GA in order to find the optimal combination of all the fuzzy parameters by maximizing the fuzzy entropy. The fuzzy parameters describe the membership functions of three parts of the image, namely dark, gray and white parts. The optimal parameters are then used to define two threshold values. Bazi et al. (2007) use a genetic algorithm to provide the initial parameters to the expectation-maximization (EM) algorithm. The parameters of the objects and background classes are assumed to follow generalized Gaussian distributions. Each chromosome is viewed as a vector represent-ing statistical parameters defining the mixture of the class distributions.
 thresholding. The proposed method in Rahnamayan et al. (2006) splits the input image in n sub-images and assigns a threshold level to each sub-image. Then the DE algorithm is applied to find the optimal threshold values by minimizing the dissimilarity between the input image and its binary version. Finally, the sub-images, thresholded by the corresponding threshold optimal values, are assembled to form the binary image. Unfortunately, this method which is specifically designed in the case of local and bilevel thresholding, cannot be applied to the global multilevel thresholding.
 technique, which is used for the multilevel thresholding ( Zahara et al., 2005 ; Yin, 2007 ; Feng et al., 2005 ; Maitra and Chatterjee, conjunction with the simplex method for the Gaussian curve fitting and for the Otsu X  X  function optimization. It is used in Yin (2007) , for optimizing the cross entropy ( Li and Lee, 1993 ) and for determining the single threshold value maximizing the 2-D entropy ( Feng et al., 2005 ). The strategy developed in Maitra and Chatterjee (2008) uses the Kapur X  X  function as criterion; it employs a cooperative learning that consists in decomposing a high-dimensional swarm into several one-dimensional swarms.
The comprehensive learning allows discouraging convergence in each one-dimensional swarm. In Fan and Lin (2007) , the histogram is approximated by a mixture Gaussian model. The
Gaussian X  X  parameter estimates are iteratively computed by combining the PSO with the EM algorithm.
 2006 ; Nakib et al., 2007 ) and ACO ( Tao et al., 2007 ) have been, also, exploited in image thresholding. In Nakib et al. (2007) , the SA is used as a multiobjective optimization technique to find the optimal threshold values of three criteria, namely the within-class criterion, the entropy and the overall probability of error criterion. The same paper proposes a variant of SA in order to solve the
Gaussian curve-fitting problem. As in Tao et al. (2003), the SA find the optimal combination of all the fuzzy parameters by maximizing the fuzzy entropy. The fuzzy parameters describe also the membership functions of two parts of the image, namely dark and bright parts.

Despite the intensive use of the meta-heuristics in threshold-ing, no paper related to the ACO applied specifically to global multilevel thresholding was found in our bibliography search. In addition, no work would be published concerning Tabu-based multilevel thresholding and DE algorithm allowing the direct computing of the threshold values. So, in this paper, three new multilevel thresholding techniques based on the DE, ACO and TS are developed in order to determine directly the values of thresholds. A comparative study between six meta-heuristic techniques, namely a GA, PSO, DE, ACO, SA and TS, is then conducted in the multilevel thresholding framework. The choice of these six meta-heuristics, contrary to the other methods, as explorative local search methods, is motivated by their use of nature inspired concepts. For each of the six meta-heuristics quoted previously, more sophisticated versions have been devel-oped. However, to carry out an equitable comparison between these meta-heuristics, only the standard versions will be used in this paper.

The remainder of this paper is organized as follows. In Section 2, the problem of the multilevel thresholding is formulated as an optimization problem and the objective function treated are briefly presented. The Section 3 deals with a review of the meta-heuristic optimization techniques and their application for the resolution of the multilevel thresholding problem. Section 4 gives comparative results of the six implemented meta-heuristic techniques. Concluding remarks are given in Section 5. 2. Multilevel thresholding problem formulation
The optimal thresholding methods search for the thresholds such that the segment classes on the histogram satisfy the desired property. This is performed by minimizing or maximizing an objective function which uses the selected thresholds as para-meters.

For thresholding purpose, the pixels of an image I having N pixels with L gray levels L ={0,1, y , L 1}, are classified into K
T =( t , t 2 , y , t k , y ,t K 1 ) such that t 1 o t 2 o y o t K 1 nience, we assume two extreme thresholds t 0 = g min and t where g min and g max are the lower and higher gray level in the image, respectively (typically g min =0 and g max = L 1).
A pixel with gray level g is assigned to class C k if t k 1 k= 1,2 , y , K .

The thresholding problem consists in selecting the set of thresholds T n which optimizes an objective function F ( T ), such that:
T  X  argmax F  X  T  X 
Several objective functions have been proposed in the literature devoted to the thresholding ( Sezgin and Sankur, 2004 ). These functions are determined generally from the represents the number of pixels having the gray level i . The normalized probability at level j is defined by the ratio p  X  X  h  X  i  X  = N  X  .

Among these functions, the objective function defined by Otsu is the most popular ( Otsu, 1979 ). It defines the weighted sum of within-class variances of the classes: F  X  T  X  X  s 2 B  X  where o k and m k are the probability and the mean, the gray level of the class C k , respectively.  X  3. Review of meta-heuristic optimization techniques
Meta-heuristic techniques are optimization algorithms which, in order to escape from local optima, drive some basic heuristic: either a constructive heuristic starting from a null solution and adding elements to build a good complete one, or a local search heuristic starting from a complete solution and iteratively modifying some of its elements in order to achieve a better one. The meta-heuristic feature permits the low level heuristic to obtain solutions better than those it could have achieved alone, even if iterated. Usually, the controlling mechanism is achieved either by constraining or by randomizing the set of local neighbor combining elements taken by different solutions as is the case of GA, DE, PSO or ACO.

In the following sub-sections, these six above-mentioned meta-heuristic techniques used for multilevel thresholding are described in detail. 3.1. The genetic algorithm
GA is a search technique developed by Holland which mimics the principle of natural evolution ( Goldberg, 1989 ). In the  X  X  X imple GA X  X  technique, the decision variables are first decoded into binary numbers (0 and 1) and hence create a population pool. Each of these vectors or chromosomes is then mapped into its real value using specified lower and upper bounds. A model of the process then computes an objective function for each chromosome and gives the fitness of the chromosome. The optimization search proceeds by using three operators: reproduction, crossover and mutation. The reproduction (selection) operator selects good strings in a population and forms the mating pool. The chromo-somes are copied based on their fitness value. No new strings are produced in this operation. The crossover allows for a new string formation by exchanging some portions of a string (chosen randomly) with a portion of a string of another chromosome, generating child chromosome in the mating pool. If the child chromosomes are less fitted than the parent chromosomes, they will slowly die in the subsequent generation. The effect of crossover can be detrimental or good. Hence, not all the strings are used for crossover. A crossover probability P c is used, where only 100 P c percent of the strings in the mating pool are involved in crossover operation, while the rest of them are kept unchanged in the next generation. Mutation is the last operation. It is used to further perturb the child vector using mutation probability P The mutation alters the string locally to create a better string. Mutation is needed to create a point in the neighborhood of the current point, thereby achieving a local search and maintaining the diversity in the population. The entire process is repeated till some termination criterion is met.

For the multilevel thresholding, we have chosen a numerical optimization version of the GA with floating point encoding,
Gaussian mutation, arithmetic crossover and tournament selec-tion. In our GA implementation (see Table 1 ), first a population of
N individuals containing the vector solutions encoded in floating point numbers is created (initialization) and the fitness of each individual is evaluated by the fitness function (evaluation). As mentioned above, for the initialization of the population, the GA uses randomly chosen threshold values from the range [ g min
Each individual j of the population pop contains K threshold values noted pop(j)_t k ( k =1,2, y , K ), such that pop(j)_t [ g min g max ], where g min and g max are the minimum and the maximum gray values in the image, respectively.

After initialization, we evaluate the individuals stored in variable pop according to the fitness function and determine the best individual T n (elite). The population is iteratively refined by selection of individuals, application of mutation and crossover operators, re-evaluation of the new population according to the fitness function and updating of the best solution T n . We use tournament selection. We first save the current population pop as oldpop and for each individual j we choose another individual m randomly from oldpop , compare the fitnesses, and substitute j by m in population pop if m X  s fitness is better. Before applying crossover, we save again the current population pop as oldpop , and then apply arithmetic crossover, as follows: pop  X  j  X  _ t k  X  cw oldpop  X  j  X  _ t k  X  X  1 cw  X  oldpop  X  m  X  _ t where pop(j) _ t k is the k th solution parameter (threshold value) of individual j , pop(j) is the offspring of the parents oldpop(j) and oldpop(m) , cw is a uniform random weight cw A  X  01 , which is generated for each problem parameter (threshold) k . Gaussian mutation was chosen, such that pop ( j )_ t k = pop ( j )_ t ( g max g min ) , where N (0 , 1) is the Gaussian normal distribution with mean 0 and variance 1, and s is the variance parameter of the mutation operator which is fixed to 0.05 in our experiments. individual in the population, with a probability P m for mutation and P c for crossover, respectively. The algorithm terminates after a fixed number of iterations. The optimization result is given by the best individual T n in the last generation. 3.2. Particle swarm optimization flocking, was introduced by Kennedy and Eberhart (1995) .A particle swarm is a population of particles, where each particle is a moving object that  X  X lies X  through the search space and is attracted to previously visited locations with high fitness. In contrast to the individuals in evolutionary computation, particles neither reproduce nor get replaced by other particles. the candidate solution to the optimization problem, the fitness the best vector solution encountered by the particle with its recorded fitness.

T  X  t  X  1  X  X  T  X  t  X  X  V  X  t  X  X  5  X  and its velocity according to
V  X  t  X  1  X  X  V  X  t  X  X  j 1 Tbest T  X  t  X   X  j 2 T T  X  t  X   X  6  X  where j 1 , j 2 are uniform distributed random numbers within [ j min , j max ] (typically j min =0 and j max =2) that determine the weight between the attraction to position Tbest , which is the best position found by the particle so far and T n the overall best position found by all particles. Note that j 1 and j 2 are generated for each component of the velocity vector. Moreover, the so-called inertia weight w controls how much the particles tend to follow their current direction compared to the memorized positions
Tbest and T n . Finally, the velocity of the particles is limited by a maximum velocity v max .
 level thresholding methods based on the PSO have been proposed with different strategies. In our study, we use a simple PSO algorithm for a fair comparison with other meta-heuristic techniques. The algorithm works as outlined in the pseudo-code of Table 2 . Denoting the number of particles by N and the swarm particles by the population pop , the position vector T of each swarm particle j , which contains the threshold values t k ( k =1,2, y , K ), is denoted by pop(j)_t k and the velocity vector
V =( v 1 , v 2 , y , v K ) of each swarm particle j is noted pop(j)_v another population denoted by bestpop .

GA above (using randomly chosen threshold values), but addi-tionally requires the initialization of the velocity vectors, which are uniformly distributed random numbers in the interval [0 , v max ]. After initialization, the memory of each particle is updated and the velocity and position update rules are applied. The velocity of each swarm particle is updated using the following equation: pop _ n k  X  w pop _ n k  X  f 1 bestpop _ tb k pop _ t k  X  X  f swarm particle j is also updated as follows: pop  X  j  X  _ t k  X  pop  X  j  X  _ t k  X  pop  X  j  X  _ v k  X  8  X 
If a component k of the new position vector is outside the domain, it is truncated to the limit values g min and g max population of the best position encountered by each particle and by all particles is updated. This process is applied to all particles and repeated for a fixed number of iterations. The best recorded optimization result. 3.3. Differential evolution
DE is another evolutionary optimization technique developed by Storn and Price (1995) . It is simple to implement, requires little or no parameter tuning, and is known for remarkable perfor-mance. A number of recent studies comparing DE with other heuristics, such as GA and PSO, indicate superiority of DE (Vesterstrom and Thomsen, 2004 ; Paterlini and Krink, 2006 ).
The outlines of the proposed algorithm for thresholding are presented in Table 3 .

After generating and evaluating an initial population, exactly in the same way as described for the GA and PSO above, three operators named mutation; crossover and selection are succes-sively applied in each generation. The mechanics of mutation and crossover differ from those used in GA. Basically, the mutation creates a mutant vector Y by adding the weighted difference between two population vectors to a third vector population.
Hence, for each vector solution j, choose three other vector solutions l, m and n randomly from the population (with j a l a m a n ), calculate the difference of l and m , scale it by multiplication with a parameter f and add the result to n in order to create a candidate solution Y =( y 1 ,y 2 , y ,y k , y y  X  pop  X  n  X  _ t k  X  f pop  X  m  X  _ t k pop  X  l  X  _ t k  X  9  X 
Afterwards create another vector solution C by crossover of Y and vector solution j , as follows: c  X  where Cr is predefined crossover constant and rand is uniform pseudo-random real number in the interval [0 , 1].

The crossover process used in DE is somewhat similar to uniform crossover in GAs, such that the result of the crossover contains a certain proportion of consecutive solution parameters of each parent. Finally, evaluate the new candidate solution with the fitness function and apply tournament selection by substituting vector solution j with the new vector solution C and its fitness, in case the fitness of C is better than the fitness of vector solution j. This description which refers to the so-called Rand/1/Exp DE operator, which is the most successful, is adopted in our implementation. Different other strategies have been suggested. These strategies can vary based on the vector to be perturbed in the mutation process, the number of difference vectors considered for perturbation and the type of crossover used (Storn and Price, 1997 ). The process is repeated for a fixed number of iterations and the optimization result is the best recorded vector solution and fitness at the end of the run.

In DE algorithm, just three factors control evolution: the population size, N ; the weight applied to the random differential, diversity in the generated population and lower values in faster convergence. The scaling factor f is a user supplied constant in the range (0 o f r 1.2). The constant Cr belongs to the range [0, 1]. 3.4. Ant colony optimization
ACO meta-heuristic, a population-based approach was pro-posed by Dorigo et al. to solve several discrete optimization problems ( Dorigo and St  X  utzle, 2000 ). The ACO mimics the way of the real ants to find the shortest route between a food source and their nest. The ants communicate with one another by means of pheromone trails and exchange information about which path should be followed. The more the number of ants traces a given path, the more attractive this path (trail) becomes and is followed by other ants by depositing their own pheromone. This auto catalytic and collective behavior results in the establishment of the shortest route. This real-life search behavior was the key motivation factor leading to the formulation of artificial ant algorithms to solve several large-scale combinatorial and function optimization problems. In all these algorithms, a set of ant-like agents or software ants solve the problem under consideration through a cooperative effort. This effort is mediated by exchanging information on the problem structure the agents concurrently collect while stochastically building solutions. The first ACO algorithm proposed in the literature was called Ant System (AS).
Its computational results were promising but not competitive with other more established approaches. Therefore, improved versions, such as Ant Colony System (ACS) ( Dorigo and Gambar-della, 1997 ) and Max X  X in Ant System ( St  X  utzle and Hoos, 1998 ), has been proposed. These algorithms differ mainly with the AS by the way of pheromone global updating. In the ACS, the manage-ment of the trails is subdivided into two levels: a local update and a global update. Hence, we have chosen in this paper to use, as basic version of ACO, the ACS without the local updating rule, like in the ant system. In the proposed ACO algorithm for multilevel thresholding, a set of concurrent distributed agents collectively discover the optimal threshold values. The summary of the proposed ant algorithm for multilevel thresholding is depicted in Table 4 .

In the proposed ACO, a colony of N simple agents or artificial ants search for good solutions at every generation. The ants evolve a set of solutions and form a population of threshold values like for the GA, PSO and DE algorithms. The threshold values produced j of a generation builds up a solution T =( t 1 ,t 2 , y ,t using the information provided by the pheromone matrix denoted t , where each element t ik is pheromone trail that lies the gray level i to the k th threshold, i =0,2; y , L 1 and k =1,2,
Initially, the trail pheromones t ik are randomly generated in the range [0, 1].

To generate a solution T , the agent selects the threshold value for each element of string T according to the following rule: using probability q 0 , the gray value having the maximum pheromone concentration is chosen as threshold value, i.e. pop  X  j  X  _ t k  X  argmax t ik determined using a stochastic distribution with a probability (1 q 0 ), such that: pop  X  j  X  _ t k  X  rand g min g max . q defined number, 0 o q 0 o 1, q 0 is fixed to 0 . 98 in our simu-lations. In ACS, this rule is called pseudo-random-proportional rule.
 evaluated according to the objective function. The value of best solution in memory ( T n ) is updated with the value of the solution obtained as  X  X  X urrent iteration best solution X  X , if it has a best objective function value than that of the best solution in memory.
The pheromone trails are then updated. The trail updating process applied in this algorithm is performed as follows: the evaporation rate. Higher value of r suggests that the information gathered in the past iterations is forgotten faster.
D t denotes the amount of pheromone trail added to t ik by the best ant corresponding to the best solution found so far: D t = F where is the fitness of the best solution T n .
 dynamic information provided by the artificial ants. Thus, the pheromone matrix is a kind of adaptive memory that contains information provided by the previously found superior solutions, and is updated at the end of the iterations. At any iteration level, the algorithm essentially executes two steps, viz., (1) generation of new N solutions by artificial ants using the modified pheromone trail information available from previous iteration and (2) updating pheromone trail matrix. The algorithm repeatedly carries out these two steps for a maximum number of given iterations, and solution having the best function value represents the optimal threshold values. 3.5. Simulated annealing heuristics and surely one of the first algorithms that has an explicit strategy to avoid local minima. The term simulated annealing derives from the roughly analogous physical process of heating and then slowly cooling a substance to obtain a strong crystalline structure. It was first presented as a search algorithm for optimization problems in Kirkpatrick et al. (1983) . The fundamental idea is to allow moves resulting in solutions of worse quality than the current solution (uphill moves) in order to escape from local minima. The probability of doing such a move is decreased during the search.
 randomly or heuristically constructed) and by initializing the so-called temperature parameter temp . Then the following process is repeated until the termination condition is satisfied: A solution T 0 from the neighborhood V ( T ) of the solution T is randomly sampled probability which is a function of temp and F ( T 0 ) X  F ( T ). The probability is generally computed following the Boltzmann distribution exp  X  X  F  X  T 0  X  T  X  T  X  X  = temp  X  : thus at the beginning of the search the probability of accepting uphill moves is high and it gradually decreases, converging to a simple iterative improvement algorithm. The temperature is reduced using a geometric rule temp  X  t  X  1  X  X  temp  X  t  X  a . ized in Table 5 .
 3.6. Tabu search
The TS proposed by Glover and Laguna (1997) is a well-known meta-heuristic that guides a local heuristic search procedure to explore the solution space beyond local optimality. Its major components are a set of moves for generating a set of trial solutions, a set of tabu restrictions (recorded in a tabu memory) for forbidding some moves, and a set of aspiration criteria for releasing some forbidden moves. For a given solution, a given tabu memory recording the given solution, and a given set of aspiration criteria, the TS regards the given solution as the current solution and the best solution visited. It then iteratively operates according to the following steps, until the termination condition is satisfied.
First, the TS performs a set of moves on the current solution to generate a set of trial solutions. Based on the tabu memory, the TS checks whether each newly generated trial solution is tabu. If the newly generated trial solution is identical to one of the solutions in the tabu memory, it is tabu; otherwise, it is an allowable the TS then restores the tabu solution to an allowable solution.
The TS selects the best among all allowable trial solutions as the next solution, and then, inserts the next solution into the tabu memory. If the tabu memory is full, the oldest solution in the tabu memory is removed. Finally, the next solution replaces the best solution visited, if the next solution is better.
The role of the tabu restrictions is to prevent solution cycling (repeatedly visiting the same points in the search space), which forces the search in different directions instead of trapping it into local optima. The aspiration criteria enable the generation of better solutions from the tabu solutions because the tabu solutions may contain good attributes. Two important compo-nents of TS are intensification and diversification strategies ( Blum and Roli, 2001 ). Intensification strategies encourage the explora-tion of the search space around good solutions already found, while the diversification strategies seek to spread the search towards previously unexplored regions of the search space. Some advanced mechanisms exploiting information collected during the whole search process are commonly introduced in tabu search to deal with the intensification and the diversification of the search ( Gendreau, 2002 ).

TS has exhibited great success in many applications; however, in our knowledge, no paper has until now treated the problem of thresholding through the TS. Hence, we propose an application of this algorithm to optimize an objective function related to the multilevel threshold purpose. Although there are more or less sophistical variants of the TS algorithm, we have considered the standard version, in order to keep the requirement of an equitable comparison. The proposed algorithm is described in Table 6 .
In this proposed algorithm, the tabu memory of size N is noted pop . The set of trial solutions are denoted by V  X  T  X  X  X  v v ;::: v Nv  X  , they correspond to the neighborhoods of the vector solution T . A trial solution v ik can be created, as in SA, by modifying locally and randomly the threshold values t k ,as follows: v  X  t k 7 rand INT  X  0 ;  X  L 1  X  = 32  X  12  X 
The number N v of neighbors is fixed, after several experi-mentations, to 20. The interval  X  0 ;  X  L 1  X  = 32 constitutes a small part of number L of gray values present in the image. 4. Experimental results and comparison study
In this section, we will evaluate the performance on the multilevel thresholding methods based on the six meta-heuristic techniques presented in the previous section. Some experiments with real images are presented to illustrate the key features of each optimization technique in the efficiency of the thresholding computation. Six well-known images named Lena, peppers, house, airplane, lake and boats with 256 gray levels are used. These images of size (256 256) are shown in Fig. 1 . Fig. 2 shows their respective histograms.

In order to compare the quality of the solutions provided by the six meta-heuristic techniques for the multilevel thresholding, the value of the best fitness F ( T n ) corresponding to the best threshold solution T n is used as comparative criterion. Of course, the smaller the objective function value, the better the algorithm. Additional results are presented in order to investigate the influence of the time computation of each optimization technique.
The meta-heuristic techniques presented in the Section 3 have several parameters of which values considerably affect the performance of the algorithms. We have done preliminary testing on these algorithms for the purpose of getting good combinations of parameters and results are listed in Table 7 . Broadly speaking, these preliminary tests consisted in tuning, one by one, each parameter of each algorithm. For each algorithm, we varied the values of the parameter to be tuned while fixing the values of the other parameters (initially these values were selected in accordance with the recommendations mentioned in the literature). The optimal value of the parameter to be tuned is that which gives the smallest value of the objective function. The size N of the population and the number of iterations have a great influence on the computing time and on the convergence. As these two parameters are linked, the population size N was kept unchanged, while the number of iterations was taken as a variable for all algorithms, in order to further facilitate the comparison between them for time convergence. The size N of population is also linked to the number of thresholds (i.e. the number of variables) to be determined, as it is explained later in this section.
A common value of N equal to 100 for all algorithms was a good choice for all tests carried out in this paper.

Since the heuristic algorithms are of stochastic type, the six algorithms are run 50 times. Table 9 reports the mean and the standard error of the mean fitness over 50 runs, for each image with a threshold number varying from 1 to 4. These mean values of the fitness can be compared to the optimal values of the objective functions found by an exhaustive search (Table 8 ).

We can see that all the algorithms give good results both in terms of accuracy (mean fitness) and robustness (small variance, i.e. similar results of repeated runs), when the number of thresholds is small. The TS give mean fitness values equal to the optimal values when only one threshold is searched, while the
ACO and SA are efficient only when the number of thresholds do not exceed 2. For a great threshold number, the results obtained by GA, PSO and DE are much better than the others. These three algorithms converged consistently to the same solution with the same fitness value and very lower variance. However, in few situations, these techniques become less robust since the variance values are relatively high. It is the case when the number of thresholds is equal to 4 for the GA with House, Lake and Airplane images; for PSO with the Peppers, House and Airplane images and the DE with the Boats image. DE maintains a robust convergence for all images (except for Boats image). Thus, the DE seems the most efficient. However, in a general way, we can say that the results of the GA, PSO and DE are comparable and are close to those provided by the exhaustive search.
 used as stopping criterion, differs from an algorithm to another one. However, this parameter considerably affects their time computation. In order to compare the convergence time of the six meta-heuristic algorithms, we have computed the iteration number and the time necessary to ensure the convergence to the optimum for each algorithm. The run of each algorithm was stopped when the fitness value F ( T n ) of the best solution reached i.e. 9 F  X  T  X  F op 9 r e  X  10 9 , where e is a threshold value which fixes the accuracy of the measurement. We note then the number of iterations and time taken by each algorithm to achieve the desired accuracy. Therefore, the stopping criterion of all algo-rithms ( Tables 1 X 6 ) is modified; it is based on the value of the fitness and not on the number of iterations. Each algorithm was run 50 times, the Table 10 gives the mean number of iterations and the average of the CPU time taken by each algorithm to meet the stopping criteria. Our experiments are performed on a HP Pentium IV-2.8 GHz PC with 256 Mb RAM.
 the number of iterations and the run time increase with the threshold number but not of the same manner. The convergence times of the GA, PSO and DE are faster than those of the exhaustive search except for one threshold. This exception can be explains by the size N of the population which is fixed to 100 for all algorithms. Indeed, the size N of the population has a great influence on the run time. However, when the threshold number is small, it not necessary to use a great size of the population.
Therefore, for one or two thresholds, the run times of the meta-heuristic algorithms can be significantly shorted by reducing the size of the population. The GA, PSO and DE converge in little iterations. However, by comparing these three algorithms between them, we can see that the PSO is the most efficient in terms of time execution, followed by the GA and the DE. The GA, PSO and DE converge much faster comparatively to the ACO, SA and TS. The iteration numbers necessary to ensure of the
ACO, SA and TS are higher to those of the GA, PSO and DE. The convergence times of the ACO, SA and TS are also shorter than those of the exhaustive search except for one or two thresholds for the same raisons previously explain.

GA, PSO and DE in terms of precision, robustness and time convergence are much better comparatively to the ACO, SA and TS.
Among the first three algorithms, the DE is the most efficient with respect to the quality of the solution and the PSO converges the most quickly. 5. Conclusion based on DE, ACO and TS were proposed in order to determine directly the values of thresholds. Furthermore, we considered three other meta-heuristic algorithms for solving the multilevel thresholding problem, namely GA, PSO and SA.
 testing them on various images. We have found that all algorithms 550 500 450 400 350 300 250 200 150 100 50 4500 4000 3500 3000 2500 2000 1500 1000 500 900 800 700 600 500 400 300 200 100 700 600 500 400 300 200 100 1300 1200 1100 1000 900 800 700 600 500 400 300 200 100 2000 1800 1600 1400 1200 1000 800 600 400 200 are comparable in term of solution quality when the threshold number is small, i.e. less than or equal to 2. While this number increases, the GA, PSO and DE provide better results than ACO, SA and TS with a little advantage to the DE.

In term of execution time, the GA, PSO and DE are most efficient than other algorithms with a great speed for the PSO.
Finally, it turned out that, in the multilevel thresholding framework, the PSO is superior compared to other meta-heuristics both respect to precision, as well as robustness of the results and runtime.

One can see through this study that, except for ACO, the population based meta-heuristics like GA, PSO and DE outperform the meta-heuristics like TS and SA, which handle a single solution.
Several local optima of the objective function appear when the number of thresholds increases and TS and SA found difficulties to escape from these local optima. Further works consist in applying sophistical versions of ACO and TS to solve the multilevel thresholding problem. This comparison can also be extended to other meta-heuristics, such as the iterated local search, the variable neighborhood search, or by using a hybridization between two or several meta-heuristics.
 References
