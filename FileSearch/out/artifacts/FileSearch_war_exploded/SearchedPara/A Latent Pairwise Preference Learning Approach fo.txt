 Most of the current recommender systems heavily rely on explicit user feedback such as ratings on items to model users X  interests. However, in many applications, it is very hard to collect the explicit feedback, while implicit feedback such as user clicks may be more available. Furthermore, it is often more suitable for many recommender systems to ad-dress a ranking problem than a rating predicting problem. This paper proposes a latent pairwise preference learning (LPPL) approach for recommendation with implicit feed-back. LPPL directly models user preferences with respect to a set of items rather than the rating scores on individual items, which are modeled with a set of features by ana-lyzing clickthrough data available in many real-world rec-ommender systems. The LPPL approach models both the latent variables of group structure of users and the pairwise preferences simultaneously. We conduct experiments on the testbed from a real-world recommender system and demon-strate that the proposed approach can e ff ectively improve the recommendation performance against several baseline algorithms.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering Recommender systems, Implicit feedback, Pairwise prefer-ences
Recommender systems utilize di ff erent types of user in-put. The most common one is the high quality explicit feed-back such as movie ratings. This is the explicit input by users regarding their interests in items. The vast majority of the literature in the field is focused on explicit feedback, due to the convenience of using this kind of explicit infor-mation. However, in many real-world applications, these explicit ratings are hard to collect and user feedback can be implicitly expressed by user behaviors such as clicks, book-mark, purchase history and even mouse movement. In the past decade, the implicit feedback, mainly in the form of clickthrough, has been heavily studied and utilized in web search to improve the relevance of the ranking models. Con-sequently, an active research field in information retrieval, learning to rank [9], has emerged.

In fact, it is more suitable for many recommendation ap-plications to address a ranking problem than a rating pre-dicting problem [8]. For example, most real-world recom-mender systems provide the services of the Top-N recom-mendation, which essentially involves solving a ranking prob-lem. The rating prediction accuracy, which is the objec-tive in many existing methods, is not always consistent with ranking e ff ectiveness. Ratings are often predicted indepen-dently for each item while rankings characterize relations among multiple items. Therefore, models for relations and preference comparisons are more desirable than models for individual ratings in recommendation algorithms.

In this paper, we propose a latent pairwise preference learning (LPPL) approach for recommendation from im-plicit feedback. LPPL directly models user preferences with respect to a set of items rather than the rating scores on indi-vidual items. Pairwise preference relations over items are de-rived from clickthrough data which are abundantly available in many real-world recommender systems. In particular, the pairwise preferences are modeled by a logistic function over a set of features. The latent variables in LPPL can capture the group structure of users. The experiments on the testbed from an online scientific community (i.e., nanoHUB) show that the proposed models can e ff ectively improve the rec-ommendation performance. To the best of our knowledge, this is the first learning to rank work proposed for real-world recommender systems with implicit feedback.
To address the implicit feedback, matrix factorization tech-niques are proposed in [4] to incorporate rich user and item information into recommendation, but the work mainly tar-gets on solving a prediction problem, not a ranking prob-lem. In the recent years, Learning to rank (L2R) has been intensively investigated for web search. The goal is to con-struct a model or a function for ranking entities. Three main classes of L2R approaches are pointwise, pairwise and list-wise approaches, respectively [9]. These methods are built on a solid foundation because it has been shown that they are closely related to optimizing the commonly used ranking criteria. Although valuable work has been done for learning to rank for ad-hoc retrieval, very limited research has been conducted for recommender systems.

A more general formulation, which is called preference learning, has been studied in the machine learning commu-nity. Preference learning is about inducing predictive pref-erence models from empirical data, and L2R can be viewed as one of its special cases. A review paper on preference learning for recommender systems can be found in [3]. A more related work to ours is the probabilistic latent prefer-ence analysis for collaborative filtering [8] which is based on the Bradley-Terry model for modeling preferences on pairs of items. However, they only use the collaborative infor-mation, while our LPPL models utilize both collaborative and content information such as item and user profiles. Fur-thermore, their evaluations are still based on explicit user feedback, while our experiments are conducted on implicit feedback collected from a real-world recommender system.
The recommendation task in this paper is motivated by the one in nanoHUB 1 .nanoHUBisapopularonlinescien-tific community for research, education and collaboration in nanotechnology. It comprises numerous resources with an active user base. These resources include lectures, seminars, tutorials, publications, events and so on. There exists very rich information about resources and users. Most resources contain detailed information such as titles, abstracts and tags. Many registered users also provide detailed profiles about themselves such as their research interest, education and a ffi liation. The recommendation task is to show a list of other useful resources to the user when he/she is view-ing a specific resource, which is something like a  X  X ee Also X  functionality. This task is similar to Top-N recommendation where a few specific items are suggested to the user so that they are likely to be very appealing to him/her. While our models are presented in the context of the  X  X ee Also X  rec-ommendation, they can be readily adapted to more general recommendation tasks such as Top-n recommendation. In fact, for both tasks, a ranking problem is a more natural for-mulation than a rating prediction problem. In addition, the users in the scientific communities such as nanoHUB tend not to give explicit ratings to the resources, even though they may have clear preference in their minds.
One simple choice of utilizing implicit feedback is to as-sume that clicked resources are relevant resources and re-sources not clicked are irrelevant. However, this is not an optimal choice because clicked resources may not be equally relevant and some resources are not clicked due to some other reasons. For example, in a list of 10 recommended re-sources, a user may only carefully look at the top 2 resources, access the second one and ignore all of the rest 8 resources. It is not reasonable to assume all the 8 resources are irrele-vant. Based on the above observation, we adopt a pairwise comparison approach to utilizing implicit feedback. In par-ticular, the pairwise approach compares the probability of relevance of two resources. If a resource in the recommen-dation list is accessed by the user, the resource tends to be more relevant than the other resources that are not accessed but ranked higher in the list than the accessed resource. A similar assumption was adopted to utilize implicit feedback information for improving accuracy in web search [7].
In this section, we propose two latent pairwise preferences learning models (i.e., LPPL 1 and LPPL 2) for learning from pairwise preferences derived from implicit feedback.
For a user u viewing the resource c , if resource i is labeled as being more relevant than resource j ,wedenote l u,c i,j otherwise l u,c i,j =  X  1. We let  X  denote the set of ( u ; c ; i ; j ) quadruples for which the preference l u,c i,j is observed.
Similar to probabilistic latent semantic indexing (pLSA) [5], we introduce a hidden state variable z to capture the group structure of the users. P ( l u,c i,j | u, c, i, j )canthenbe decomposed as: where z is a multinomial variable ( z  X  K )thatdenotes the user groups while the mixing proportions P ( z | u )cap-ture the strength of a user X  X  membership with each group. P ( l u,c i,j | c, i, j, z ) is the mixture component with each compo-nent belonging to the same parametric family of distribu-tions. In pLSA for collaborative filtering [5], Gaussian dis-tribution is often assumed to model rating values which are of numeric scale. In LPPL 1, we designate a logistic function where  X  ( x )=1 / tion and  X  zv is the weight of the user group z for the v feature f v ( c, i ).

Di ff erent types of features can be incorporated in f v ( c, i ) for making pairwise comparison between a pair of resource candidates. For example, one type of features can be used to measure the content similarity between a resource candidate i and the current resource c being accessed. The intuition of this type of features suggests that users may prefer resource candidates that is more similar to the current resource that the user is accessing. Another type of features can be used to measure the authority of the authors for di ff erent resource candidates. The intuition of this type of features suggests that users may prefer resource candidates from authoritative creators than less authoritative creators.

Similar to pLSA, we can derive an Expectation-Maximization (EM) algorithm to estimate the parameters by iterating E-step and M-step until convergence as follows [5]. In E-step, we compute the posterior probability of z given the quadru-ple ( u ; c ; i ; j )as: By optimizing the auxiliary Q-function, we can derive the following M-step update rules:  X  As there is no closed form solution to the optimization prob-lem of  X  z  X  , we can resort to Quasi-Newton methods [10].
In LPPL 1, P ( z | u ) is modeled with a separate non-parametric multinomial distribution for each user. In consequence, the model cannot easily generalize P ( z | u ) to unseen users be-yond the training collection, because each parameter in multi-nomial distribution specifically corresponds to a training in-stance. pLSA encounters a similar problem and a  X  X old-in X  process is suggested in [5] by re-learning all training docu-ments with the new document to generate an updated pa-rameter estimation. However, the  X  X old-in X  process is time-consuming, and moreover, we do not have any relevance judgment for new users to learn from.

To address this problem, we propose LPPL 2 to model the mixing proportions by a soft-max function, i.e., P ( z | u )= that scales the exponential function to be a proper proba-bility distribution (i.e., Z u = LPPL 2, user u is represented by a bag of user features ( g 1 ,...g S ) which can be derived from the user X  X  profile and usage information.  X  zs is the parameter associated with the features. The mixture component is still a single logistic function as in Eqn. (2). By plugging the soft-max function into Eqn. (1), we can get
Because  X  zj is associated with each user feature instead of each training instance, the above model allows the esti-mated  X  zs to be applied to any unseen user. The advan-tage of LPPL 2 over LPPL 1 is that LPPL 2 is inherently generalizable to new users and it can exploit the rich user information such as those in nanoHUB by conveniently in-corporating them as features.

A similar EM algorithm can be derived as follows (the update equation for  X  z is the same as LPPL 1): E-step: M-Step:
Based on the pairwise preferences, finding the optimal ranking turns out to be a NP-complete problem, which can be shown via reduction from the cyclic-ordering problem [2]. Similar to the approximation strategy in [8], we can use the following scoring function to e ffi ciently produce a ranking Table 1: Features used in the LPPL models.  X  X  X  denotes the feature takes boolean values and  X  X  X  represents numerical values for LPPL: We test our proposed models on the nanoHUB dataset. We use the clickthrough data from March 1, 2011 to June 30, 2011 as training data, and use the month of July, 2011 as test data. The training set contains 3,064 users and 2,335 resources and the test set includes 1,609 users and 1,928 re-sources. We use the strategy described in Section 3.2 to extract the pairwise preferences from the clickthrough data. One baseline method is content based (CB): rank candi-date resources according to the descending order of cosine similarity between the resource being viewed and the candi-date resources. The tf-idf weighting scheme is used after the stop words are removed. Another baseline includes wAMAN proposed in [6] for weighting implicit feedback, which is a collaborative filtering based approach. In addition, a hybrid model (CB+wAMAN) is also adopted as a baseline, which is a heuristic linear combination of CB and wAMAN.
As discussed in Section 3.3, LPPL 1 needs to infer the group membership P ( z | u ) for the unseen user u in the test set. In the experiments, we estimate P ( z | u )basedontheav-erage of the group memberships of the user X  X  5 most similar neighbors that appear in the training set. The user simi-larity is also computed in the same way with the resource similarity (based on the vector space model (VSM) by de-fault). Table 1 contains the features f and g that are used in the experiments for the LPPL models.

We use Mean Percentage Ranking (MPR) [6] to evalu-ate the prediction accuracy, which is a typical evaluation metric for recommendation with implicit feedback. MPR is recall-oriented because precision based metrics are not very suitable as they require knowing which resources are unde-sired to a user. Lower values of MPR are more desirable. Figure 1: Impact of varying the number of latent factors in LPPL 1 and LPPL 2 The expected value of MPR for random predictions is 50%, and thus MPR &gt; 50% indicates an algorithm no better than random.
Figure 1 shows the evaluation results of the LPPL models with various number of latent user groups ( K ), ranging from 1to20. When K = 1, both models are degenerated to the same model with the single component of logistic function, and thus give the identical results. LPPL 1 and LPPL 2 achieve their best performance at K =7and K = 5, respec-tively. After that, the performance of the models tends to degrade as K increases, probably due to over-fitting. When K&gt; 16, the performance of LPPL 2 deteriorates much faster than LPPL 1. This indicates that LPPL 2 may su ff er more from over-fitting when the number of latent factors increases. We will explore a regularization approach to alleviate the over-fitting problem in the future work.
In this subsection, we compare the LPPL models with other methods. From Table 2, we can see that both mod-els perform better than the baselines (CB, wAMAN and CB+wAMAN), with LPPL 2 showing more substantial im-provement. It is worth noting that the initial recommenda-tion results in nanoHUB are based on CB and thus there is a presentation bias in favor of the CB method. It is expected that LPPL can show better results when the presentation bias is eliminated. In addition, wAMAN performs much worse than the other methods, probably due to the lack of collaborative information in the training data. An ensemble of CB and wAMAN cannot achieve as good results as CB. Table 2: Comparison of various methods in MPR
The evaluations rely on the computation of document sim-ilarity, such as in extracting features for LPPL, in identi-fying similar users, and in the content-based (CB) recom-mendation method. In this section, we investigate the ef-fect of document similarity. Specifically, we compare three models of document similarity: Vector space model (VSM), Language model (LM), and Jaccard Index frequency-based model (Jaccard) [1]. Table 3 shows the results. LM seems not a desired choice as all the three methods have the worst performance on LM. On Jaccard, CB obtains a worse result than on VSM, but both LPPL models get better perfor-mance than on VSM while the improvement is not substan-tial.
 Table 3: Comparison of various document similarity models in MPR.

This paper proposes a latent pairwise preference learn-ing approach for recommendation from implicit feedback. We conduct the experiments on the testbed from an online scientific community and demonstrate that the proposed ap-proach can e ff ectively utilize implicit feedback. In the future work, we will conduct more comprehensive evaluations for the proposed models. We will also extend the models to capture latent groups of resources.
We thank the anonymous reviewers for their valuable com-ments. This research was partially supported by the NSF research grants IIS-1017837 and EEC-0634750. Any opin-ions, findings, conclusions, or recommendations expressed in this paper are the authors X , and do not necessarily reflect those of the sponsors.
