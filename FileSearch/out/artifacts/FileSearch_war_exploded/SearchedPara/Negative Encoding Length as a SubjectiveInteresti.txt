 The most serious problem in rule discovery would be the interestingness problem: typically many rules are discovered but mo st of them are uninteresting [4,13]. So-lutions for this problem can be classified into the objective approach [11,12,13], which uses only data as input, and the subjective approach [3,4], which uses also user-supplied information in addition to data. In both approaches, an interest-ingness measure [3,11,12,13], which is a function for estimating the degree of the interestingness of a rule, is actively studied.

Despite the numerous studies on interestingness measures, few of them have a theoretical background, are parameter-free, can discover a group of rules which are mutually related, and can exploit an initial hypothesis. We attribute the reasons to the subjective nature of interestingness and the high time complexity. [3,4,11,12] are exceptions for some of them but none satisfy these four conditions. Moreover, as far as we know, no study has ever made a systematic investigation on the discovered rules under noisy data and incorrect user-supplied information.
The Minimum Description Length Principle (MDLP) is a principle that the best hypothesis that can be inferred from data is the one that has the shortest  X (code length of the hypothesis) + (code length of the data using the hypoth-esis) X  [5,8,9,15]. The MDLP is based on a solid theoretical framework, has a clear interpretation, is robust to noise, and requires no parameter specification. In association rule discovery, the MDLP has been applied to the problem of dis-covering frequent itemsets [11]. However , the discovered patterns are still large in number and are unrelated. Moreover, the method belongs to the objective approach thus a theoretical framework which can be integrated for exploiting user-supplied information is unknown.

We restrict our attention to the classification rule [4], which has a class label in its conclusion and has been well-studied due to its importance. It is not obvi-ous how to apply the MDLP for classification to the classification-rule discovery problem since a classifier can be applied to any example unlike a typical group of rules. Moreover, the standard MDLP cannot exploit an initial hypothesis and the MDLP extended for this purpose [14] has problems such as a redundancy in its encoding method. In summary, the MDLP has problems to be used in devel-oping a method with a theoretical background for discovering a group of rules which are mutually related by exploiting user-supplied information. To resolve these problems we formalize the discovery problem of interesting classification rules as an estimation problem of a partial decision list, extend the MDLP for classification so that it can exploit an initial hypothesis, invent an encoding method, and use the negative encoding length as our interestingness measure. 2.1 MDL for Classification Adataset D consists of n examples d 1 ,d 2 ,...,d n .Eachexample d i is described A classifier is a function which outputs a class label given an attribute value vector. We call the process o f learning a classifier from D classification.
As a principle for preferring a classifier in classification, the MDLP states that the best classifier T MDL is given as follows [5,8,9,15].
 where P ( T )and P ( D | T ) represent the probability that T occurs and the condi-tional probability that D occurs given T , respectively. Consider the problem of encoding T as a binary string. According to the coding theory [10], the length of thecodestringfor T using an optimally efficient code is  X  log P ( T ). Similarly,  X  log P ( D | T ) may be regarded as the length of the code string for D encoded using T . In the MDLP for classification, these code lengths are calculated in a problem where the receiver has D except for the class labels. The sender first sends T then the class labels of examples in D using T .

It is straightforward to show T MDL coincides with the maximum a posteriori hypothesis. The MDLP can be interpreted as assigning priors to theories based on a compact coding: P ( T ) is defined by the encoding method for  X  log P ( T ). 2.2 Preliminaries for Encoding Firstly we consider a problem of sending a binary string of length x which consists of y binary 1s and ( x  X  y ) binary 0s. A common method first sends the number y of binary 1s with code length log( x + 1) then specifies the positions of binary 1s [8,15]. The required code length is denoted with  X  ( x, y ).
 For example,  X 1110010 X  is sent with a code length  X  (7 , 4) = 8 . 13 bits. Note that we do not have to generate the binary message for our purpose.

If we know that y&gt; 0, the number y of binary 1s can be sent with code length log x . The required code length in this case is denoted with  X  0 ( x, y ).
Likewise, we consider a problem of sending a string of length x described with M symbols where the i th symbol occurs x i times. The sender first sends symbol. We denote the required code length with H ( x, ( x 1 ,x 2 ,...,x M ) ,M ). H ( x, ( x 1 ,x 2 ,...,x M ) ,M )  X  For example,  X  X ACBBAB X  is sent in H (7 , (3 , 3 , 1) , 3) = 12 . 45 bits.
Lastly we consider a problem of sending a positive integer x under the assump-tion that x = y is most likely and the occurrence probability P ( i )of x = i is with  X  ( x, y ), is given as follows.
 2.3 Classification-Rule Discovery Problem We call an assignment a = v of a value v to an attribute a an atom. A literal is defined as either a single atom or a conjunction of multiple atoms. An example ( v { a a probabilistic distribution P 1 ,P 2 ,...,P M over the classes 1 , 2 ,...,M .
A partial decision list T , which may be interpreted as a decision list without the default class label, consists of  X  distribution rules r 1 ,r 2 ,...,r  X  i.e. T  X  r an example e iff. (if and only if) e does not satisfy  X  ( r i )( i =1 , 2 ,...,j  X  1) but satisfies  X  ( r j ). We believe that a partial decision list is adequate as the representation of a hypothesis as it represents a group of rules which are mutually related in a separate-and-conquer manner. The set of examples each of which is
A null partial decision list B consists of  X  distribution rules b 1 ,b 2 ,...,b  X  list is adequate as the representation of an initial hypothesis since it is easier to be obtained from domain experts or textb ooks. A partial decision list (or a null partial decision list) which satisfies  X  =0(or  X  = 0) is denoted with  X  and is called a null hypothesis.

Partial classification [1] has been mainly studied in the context of decision making. As the objective of a data mining process is not usually restricted to prediction, neither a utility function nor a cost function is adequate for evaluating the goodness of our partial decision list T . In a domain where there is a ground truth i.e. for our case a  X  X orrect X  partial decision list T true , we define, as an evaluation index, the discovery accuracy E ( M ) of a rule-group discovery method  X  ( T M = T true ) is the number of trials in each of which the hypothesis T M returned by M is equivalent to T true . [Classification-rule Discovery Problem] Given a data set D and a null The goodness of a discovery method M is evaluated with its discovery accuracy E (
M ) if a correct partial decision list T 3.1 Incorporating Ba ckground Knowledge The MDLP for classification (1) cannot handle an initial hypothesis B thus cannot be applied to our discovery problem directly. We have extended the original MDLP for classification so that T is inferred from D and B .Thebest hypothesis T EMDL chosen by our extended MDLP is stated as follows.
 A unique feature of our method is the term  X  log P ( B | T ), which allows us to consider B rigorously. We calculate the code length L ( T ) in a problem setting where the receiver has D except for the class labels. The sender first sends T , then the class labels of examples in D using T ,and B using T .
 Note that the smaller L ( T ) is the more interesting T is thus the negative code length  X  L ( T ) can be considered as our i nterestingness measure.

We assume that B and D are independent because B is typically given by the user and not inferred from D .Inthiscase, T EMDL is shown to coincide with the maximum a posteriori hypothesis i.e. T EMDL =argmin T (  X  log P ( T )  X  log P ( D, B | T )) = arg max T P ( T | D, B ). 3.2 Encoding Method Here we propose how to calculate (4). A hypothesis T is sent by first sending the number  X  of distribution rules in T then the premise  X  ( r i )ofeach r i in T .The of possible values of an attribute a j and the number of atoms in a literal x .
The initial hypothesis B is sent by first sending the number  X  of distribution rules without conclusions in B then each distribution rule b i without conclusions using T . The former is sent with code length  X  (  X ,  X  ). We say that a conjunction x of atoms is more general than a conjunction y of atoms iff. each atom in x is found in y and y has at least one atom which does not exist in x , and denote with x y . For instance, a 1= v 1 ,a 3= v 3 a 1= v 1 ,a 2= v 2 ,a 3= v 3, where a 1 ,a 2 ,a 3are are the respective numbers of the four cases.  X  log P ( B | T ) =  X  (  X ,  X  )+ H (  X , (  X  1 ( B, T ) , X  2 ( B, T ) , X  3 ( B, T ) , X  4 ( B, T )) , 4)
The class labels in D is sent using T : they are decomposed into those covered by each r i and those in D \ D ( T ). For the former, we use (2) with a small modification to avoid inconveniences 1 .Let n ( T,i ) ,n j ( T,i )bethenumberof examples covered by the i -th rule in T and the number of examples of class j covered by the i -th rule in T , respectively. Let j NTH( T,i,d ) be the d -th most numerous class for its number n j NTH( We assume that the message which specifies the new order of the class labels c length for simplicity. For the latter, we assign the code length  X  log M ,which is the longest code length for an event with M possible states, to each class label. This assignment represents the indifference of a partial decision list to its uncovered examples. It helps us avoid obtaining a counterintuitive hypothesis of which rules try to  X  X et rid of X  examples to have a D \ D ( T ) which is nearly homogeneous with the majority class. We omit the reason due to lack of space. 3.3 Desirable Properties Studying (4) for two similar hypotheses T and T reveals that (4) exhibits attrac-tive properties. This fact is important because it differentiates (4) from many empirical interestingness measures which are designed to exhibit attractive prop-erties. Due to space constraint, we just show the following without proof. Theorem 1. Let  X  ( T 0 ) be the number of distribution rules in a hypothesis T 0 . Let two distinct hypotheses T and T satisfy If T is more accurate than T and covers the same number of examples for each rule, i.e. then T is judged better with our interestingness measure i.e. L ( T ) &lt;L ( T ) . 3.4 Practical Heuristic Search Since an exhaustive search for all possible partial decision lists is prohibitive due to its time-inefficiency, CLARDEM applie s three heuristic search methods then outputs the partial decision list with the minimum code length. The first two methods are hill climbing from B and  X  where a step is an addi tion/deletion of a rule/atom, where an added rule has a single atom in its premise.
Separate-and-conquer is frequently used for learning a rule-based classifier (e.g. [7]). Here we use a modified version which never returns a hypothesis with a longer code length. It is a double-loop algorithm which searches rules with se-quential covering in its outer loop. It sea rches conjunctions of atoms as premises of the rule with greedy search which checks up to conjunctions of m atoms. Below we show its pseudo-code, where r  X  ( T )representsthe  X  -th rule of T . algorithm Separate-and-conquer
T =  X  , min =  X  ,  X  =1, T = T do // outer loop while( f == TRUE) // outer loop output T procedure SacInnerLoop(  X  , min , T , T , f ) f =FALSE, T = T ,  X  ( r  X  ( T )) = TRUE for  X  =1 ,...,m // decide the  X  -th atom in the  X  -th rule
In the hill climbing method from B , an addition of a rule, which has a single atom in its premise, at each step takes O ( mn X  MAX ), where  X  MAX represents the maximum number of values that an attribute can take. A deletion of a rule at each step takes O ( n X  MAX ), where  X  MAX represents the maximum number of rules in a hypothesis during the search. An addition of an atom at each step takes O ( mn X  MAX  X  MAX ). A deletion of an atom at each step takes O ( n X  MAX  X  MAX ), where  X  MAX represents the maximum number of atoms in a premise during the search. We assume that the number of search steps is O ( |  X   X   X  | ), O (  X  )= O (  X  )= O (  X  MAX ), and O (  X  MAX )= O (1). Thus the time complexity is given by O ( mn X  MAX  X  2 ). The same result holds even if the starting point is  X  . For our Separate-and-conquer, the time complexity is given by O ( m 2 n X  MAX  X  2 ). 4.1 Application to Benchmark Data Sets We use for comparison MDL, which a method based on the MDLP. It employs L ( T )  X  X  X  log P ( T )  X  log P ( D | T ) as its coding length for T and is equivalent to our method for other points. We also use e-Jmeasure, which is an exten-sion of the J-measure [12] to evaluate the goodness of T with the amount  X  ( T ) sets because such a method requires parameters such as support and confidence thresholds, and lacks of a theoretical b ackground and a clea r interpretation.
We first apply the three methods to ten benchmark data sets from [2] to investigate their tendencies except dis covery accuracies as there is no ground truth. An initial hypothesis is generat ed by deleting the default class label of the decision list obtained with C4.5rules [6]. We show the characteristics of the data sets and the initial hypotheses in Table 1.

The results of the experiments and the names of the data sets are shown in Table 2. We see that the number  X  of the distribution rules in the output hypothesis often increases in the order of MDL, CLARDEM, and e-Jmeasure. Theses results make sense as MDL has a preference bias for  X  ,CLARDEMfor the initial hypothesis, and e-Jmeasure for hypotheses which compress a large amount of information. These reasons explain that recall and precision often improve in this order, though their differences are often small.

In terms of search, we see that the method chosen as best most frequently is the hill climbing from the initial hypothesis (HC2). We attribute the reason to the excellence of C4.5rules [6]. As CLARDEM has a preference bias for the initial hypothesis, HC2 is always chosen as the best method. For computation time, CLARDEM is the fastest among the three methods for most of the cases. This result may be explained by the fac t that the discovered hypotheses are often most similar to the initial hypotheses. As MDL has a preference bias for an empty hypothesis, the similarity is often the least hence it was the slowest. The number of the searched nodes gives a rough estimate of the computation time for the same data sets (e.g. nursery) thus it will be used as an index.
Due to lack of space we just show exampl es of the discovered hypotheses from the vote data set. MDL discovered a simple one with two rules, where class 1 and class 2 correspond to democra t and republican, respectively.
 CLARDEM discovered the initial hypot hesis and e-Jmeasure a complex one, which are shown in Table 3. Their preference biases explain these results. 4.2 Robustness of the Three Methods We report the robustness of the methods to noisy data sets and incorrect initial hypotheses, where each result is an average performance on 100 data sets. For Mushroom, T true is assumed to be the hypothesis generated by C4.5rules minus the default class label. Artificial data sets of n = 1000, M =  X  =2, m = 32 with 5 , 10 , ..., 30 % of random noise in the class labels are generated using hand-coded concepts. We have a lso generated smal ldatasetswith n = 950 , 900 , ..., 500 without noise. Class labels of uncovered examples are set randomly.

We consider problems of completing approximate initial hypotheses, which fits the nature of the partial decision list. The results of the experiment with correct concepts and the in correct initial hypotheses are shown in Figure 1, where we also show  X  1.5*(standard deviations) for discovery accuracies. We see that CLARDEM is almost always the best method due to its capability of exploiting the initial hypothesis even if it is approximate. MDL is often the sec-ond method while e-Jmeasure is almost always the worst. We think e-Jmeasure always shows discovery accuracy 0 % for a rtificial data sets because it tries to compress the  X  X andom X  parts not covered by T true .AnywayCLARDEMisalso the best method for mushroom, which has no random part. CLARDEM shows high discovery accuracies even if the ini tial hypothesis is complex and contains strongly related rules. The numbers of the searched nodes show that CLARDEM and MDL are often one order of magnitude faster than e-Jmeasure. Compression and learning are known to be highly related with each other [5]. The MDLP [5,9] is considered to be amon g the most successful works along this philosophy due to its performance and theoretical foundation. This paper has presented the first attempt to apply the MDLP and hence the philosophy of data compression to the discovery problem for a group of classification rules.
There are many evidences that the MDLP for classification is robust against noise [8,15]. Our method inherits this nice property and in addition can borrow strength from an initial hypothesis, which are shown through extensive experi-ments. Our method is adequate for discovering groups of rules even from a small amount of noisy data and an approximate initial hypothesis.
 This work was partially supported by the grant-in-aid for scientific research on fundamental research (B ) 18300047 from the Japanese M inistry of Education, Culture, Sports, Science and Technology.

