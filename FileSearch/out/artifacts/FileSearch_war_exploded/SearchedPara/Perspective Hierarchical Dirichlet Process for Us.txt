 In this paper, we proposed a perspective Hierarchical Dirichlet Process (pHDP) model to deal with user-tagged image modeling. The contribution is two-fold. Firstl y, we associate image features with image tags. Secondly, we incorporate the user X  X  perspectives into the image tag generation process and introduce new latent variables to determine if an image tag is generated from user X  X  perspectives or from the image content. Therefore, the model is able to extract both embedded se mantic components and user X  X  perspectives from user-tagged images. Based on the proposed pHDP model, we achieve automatic image tagging with users X  perspective. Experimental resu lts show that the pHDP model achieves better image tagging performance compared to state-of-the-art topic models. I.2.6 [ Artificial Intelligence ]: Learning  X  Parameter learning ; H.2.8 [ Database Management ]: Database applications  X  Data mining ; Image databases ; H.1.2 [ Models and Principles ]: User/Machine Systems  X  Human factors, Human information processing Algorithms, Experimentation, Human Factors, Design. Image tagging, Probabilistic generative model, Hierachical Dirichlet process, User perspective modeling. The prevalence of digital imaging devices, such as digital cameras and digital video cameras, has brought an increasingly large amount of unlabeled multimedia data, especially unlabeled image data. To face the challenge of enormous explosi on of unlabeled online image resources, it is importa nt to achieve automatic image tagging for online image resources . The desirable image tagging system should not only be able to interpret the image content but Breakthroughs in automatic image tagging algorithms will help with organizing the massive am ount of online image resources, promote developing and studying of image storage and retrieval systems, and serve for applications such as interest sharing among online image resource users. Due to its social annotation nature , Flickr image tags have various functional purposes [6]. For example, the topic tags may refer to any object or person displayed in th e picture, such as sky, lake, plant life; the time tags indicate the time when a picture was taken; the location tags provide information about sights, like which country it is from; the type tags include camera settings and photographic styles; the usage context tags suggest the context the picture was collected in, while the self reference tags contain highly personal information for th e tagger himself, such as  X  X iamond class photographer X . Stud y on different tag categories suggests that topic and location are two most intensively used tag categories in Flick.com [6]. Further study in social tagging categories identified in [6]) are more closely related to resource content, while the subjective tags and personal tags are more influenced by users X  perspectives. Generally speaking, compared image content. The subjective and personal tags, on the other hand, are usually free-form texts, but they also provide valuable contextual information of users X  tagging preference which can be utilized to customize automatic image tagging for different users. It should be noted that, some factual tags (which carry on the semantic meanings) are not vi sible from image contents. For example, the image content usually provides little clues about its location and it is not easy to infer the camera settings and photographic styles. Therefore, in automatic image tagging, one challenging problem is how to bri dge over the  X  X emantic gap X  [4] between image features and hi gh-level semantic meanings. Specifically, it requires identifying a set of image features that well preserve the semantic consistency of image content. It also requires using generative probabilistic models to infer the less visible semantic concepts (like locations) from the visible parts. The Correspondence Latent Di richlet Allocation (CorrLDA) model [1] has been intensively used to model image features with multiple types of associated semantic entities (such as tags) [8, 9]. However, the CorrLDA model re quir e s specifying the exact number of mixture components. In real-world applications, the number of semantic components in an image is unknown. For example, a picture of clear blue sky tend to have less semantic components than an image show ing a crowd of people in the street. Therefore, the Hieratical Dirichlet Process (HDP) model [5], a nonparametric extension of the LDA-based topic models, was proposed. It enables us to represent image content with unbounded number of semantic com ponents, thus provides the flexibility of modeling differ ent image categories in one generative process. In this pape r, we extend the HDP model to deal with both users X  perspect ive and the semantic components derived from image contents. We name the new model as  X  X erspective Hierarchical Dirichlet Process (pHDP) model X  as it integrates the user X  X  perspectives into the image tag generation process. The pHDP model introduces new latent variables to determine if an image tag is gene rated from user X  X  perspectives or from the image contents. Experimental results show that the pHDP model not only generate s useful information about semantic components and user pe rspectives from tagged images, but also achieves better performance in the task of automatic image tagging compared to state-of-the-art topic models. The remainder of this paper is organized as follows. In Section 2, we review related works in generative topic models. In Section 3, we present the generative proce ss of the proposed pHDP model. Section 4 provides the collapse Gibbs sampling algorithms for model estimation. Secti on 5 reports the experimental results of the automatic image tagging and compares our approach with several existing models. We conclude the paper in Section 6. On automatic image tagging, one major task is to identify semantic mixture components from the co-existing image content and text descriptions. In the data mining and information retrieval community, there has been a long time focus on using probabilistic topic models to study the correlation between image and text descriptions. Specifi cally, the Correspondence LDA (CorrLDA) model [1], which imposes correspondence between text word and other semantic entities, provides a natural way to learn latent semantic components (topics) from image features and associate them with text descriptions. Many recent studies, including sophisticated topic models that associate image features with multiple types of semantic entities (such as protein entities [8], ontology-based biomedical concepts [9]), still follow a similar generative process to the protot ype CorrLDA model. In CorrLDA model, each image document has different distribution over semantic mixture components; this feature provides the model a flexibility of adapting to different image contents. However, the CorrLDA model requires specifying the exact number of mixture components, which is fixed for each image document and remains unchanged during the model estimation. In practice, in order to get an optimal number, the researchers have to try out different mixture components numbers and make a choice by comparing the log-likelihood, perplexity and other criteria that indicate how good the model fits the data. The Hieratical Dirichlet Process (HDP) model [5], is a nonparametr ic extension of the Latent Dirichlet Allocation (LDA)-based topic models, it enables modeling documents with countable infinite mixture components, thus provides the flexibility of modeling images whose actual semantic component numbers are unknown. Study of social tagging in web-based applications has gained increased popularity in the data mining community. Specifically, several probabilistic generative models have been proposed to study users X  tagging patterns [10, 11]. In [11], a topic-perspective (TP) model is proposed to infer how both users X  perspective and the resource content relate to th e generation of social annotations. It improves the generative process of social annotations by separating the tag generation pro cess from the generation process of the resource content. While th e resource content (such as text words) is only generated from res ource topics, the social tags are generated by both resource topic and user perspective. In this but also covers the user X  X  expertise, motivation, language and other personal factors. In this section, we introduce the perspective HDP (pHDP) model for user-tagged images. We pres ent graphical representation of pHDP model in Fig. 1. Follow ing the convention in depicting graphical representation of topi c models, we use round nodes to represent random variables, in which the white nodes stand for latent random variables, whil e the gray nodes denote observed ones during the model training. The rounded boxes are used to represent fixed hyper-parameters of the model, while the edges illustrate the conditional dependency in the generative process. For clarity, we name each tagged image as a document . Some the number of image documents, K and K X  (both are countable infinite) indicate the number of semantic mixture components; when K is a finite number, the m odels become LDA-like models. To represent the image content, we utilize the saliency features (including visual code-words [12] and MSER feature [13]) as a complement part of the holistic GIST features [3]. Our motivation comes from the fact that the mechanism of human visual perception allows for very rapid holistic image analysis to provide a coarse context of image scene (special layout model), yet it also (saliency model) that needs to be in tensively studied [2]. In Fig. 1, N is the number of tags in document j , while N j v and N the total number of extracted visual code-words and MSER regions in document j , respectively. In the model, the holistic representation of an image is replicated 10 times to enable the posterior sampling, so N j h denoted the h th replication of the holistic image representation in document j . In both models, we assume fixed value for Dirichlet process concentration parameters  X  and  X  . We also assume symmetric priors  X  u ,  X  v ,  X  Dirichlet distributions in the models. Detailed explanations of notations in following discussi ons are summarized in Table 1.  X   X   X  J, T,U, L Number of documents, tags, users, user X  X  perspectives z K,K' The number of components at a certain time point. N , N j r , N C , C  X  ,  X  Concentration parameters of Dirichlet process.  X   X   X   X  ,  X  v ,  X  t ,  X  ,  X   X   X   X  The global weight of semantic component indicators As shown in Fig. 1, this model primarily comprises of two parts split by the dash line. The part on the right hand side is essentially the standard HDP model. The gene rative process of this part begins with drawing a global probability measure G and for each document j , draw a child Dirichlet process G equivalent to firstly drawing a global weight  X  ~ GEM(  X  ) for semantic component indicators k , then for each document j , draw the document-level weights of semantic compone nt indicators  X  repeatedly drawing semant ic component indicator z ji  X  and then draw each data observation (i.e. each MSER region and each visual code-word) from the conditional probability of the sampled semantic component. The left half of the model is fo r the generation of image tags. As mentioned in Section 1, image tags have various functional purposes. For example, some tags (like most factual tags) are closely related to the contents displayed in images, while other indicate user X  X  contextual inform ation as well as his/her subjective perspectives X . Accordingly, the generative process of user-tagged images should be able to ta ke into account both user X  X  perspectives and semantic com ponents from image contents. In pHDP model, each tag t created by user u for document j can be either drawn from the semantic components associated with j  X  X  image content or from u  X  X  perspectives. To de cide the source of from a multinomial distribution  X  j (with a Dirichlet prior  X  ). When the value of x jt equals 0 or 1, the topical indicator of tag t is draw uniformly from the semantic components learned from the image contents (the red dashed arrows in Fig. 1 show this process). perspective distribution  X  u for user u , and tag t will be drawn from the tag distribution  X  p of perspective p (the blue arrows in Fig. 1 illustrate this procedure). The switch variable x plays a critical role in the pHDP model; it is a personalized factor that indicates in which extent the user X  X  perspectives influence the tagging results. It provides the model a flexibility to determine if a specific image tag relates to the semantic components displayed in an image, or it relates to user X  X  context information as well as his/her subjective feeling and preference (user X  X  perspective). The generative process of the pHDP model is represented in Table 2. 1. Draw a global weight  X  ~ GEM(  X  ); 2. For each semantic component k , draw  X  k ~ Beta(1,  X  ) ,  X  3. For each semantic component k , sample Gaussian-parameters 4. For each user u , sample  X  u ~ Dirichlet(  X  u 5. For the j th document, draw  X  j ~ DP(  X  0 ,  X  ),  X  ' 6. For the holistic scene representation of the j th tagged image , 7. For the i th of the N j v visual code-words in the j 8. For the l th of the N j r MSER salient regions in the j 9. For each document j, sample  X  j ~ Dirichlet (  X  ); 10. For each tag t in document j created by user u ; In this section, we describe the Gibbs sampling scheme for the proposed pHDP model. The samp ling scheme consists of two steps. The first step is sampling for semantic component indicators z as well as the corresponding HDP hyper-parameters  X  . In order to sample a HDP-like model, one may either follow the Chinese restaurant franchise (CRF ) or use direct assignment [5]. In our work, the direct assignm ent is used (Table 3). Table 3. The posterior sampling of semantic components Preliminaries: Suppose that at current st age of the sampling, only K of L  X  X  X  semantic components have been assigned to the observations, define:  X  ={  X  1 ,...,  X  k ,  X  u }~Dirichlet(  X  r ,...,  X  r ,  X  Repeat for each data observation until convergence: Sampling z (may either equals to an existing k or k new Firstly, integrate out  X  j to get the marginal probability p( z |  X  ): Secondly, get the posterior probability of z observations (not counting the current observation v ji ) ( |,, ,) ( |,)(|,, ,) pz k v pz k pv z For visual word v ji , , Similarly, for both MESR feature vector and GIST feature vector, mean u , variance 2 / s n and n-1 degree of freedom. Sampling m (feasible when n jk &lt; 200) For each j , the auxiliary variable m (0  X  m  X  n jk ) is sampled as: for m &gt; n , s( n +1, m )=s( n , m -1)+ n s( n , m ) Sampling  X  : accumulate m jk for all document j to get m m .K , then draw  X  ~ Dirichlet( m .1 , m .2 , ..., m .K ,  X  ) The second step is sampling for switch variable x , perspective sampling equation of switch variable x jt for each tag t=q in document d=j as follows: px z kt q nnn NN C T px z k t q nn n N C T px z pt q nn n C L C T After a set of sampling proce sses based on the posterior distribution calculated above, othe r parameters can be sampled using the following equations:  X   X   X   X  In this section, we investigat e the performance of the proposed pHDP model in automatic image tagging experiments using the MIR-Flickr dataset, which is co mposed of 25000 images covering a wide spectrum of image categories (contributed by a total of vocabulary size (number of un ique tags) of 64037; thus the average number of tags per image is 8.94. In the image tagging experiment, we use a 50% subset of the MIR-Flickr collection as removed). On constructing the two s ubsets, we ensure that tagged images from the same user are equally split to both subsets. The values of global concentration parameter and the user  X  perspective number L are determined by perplexity comparison on a serial of values. Other hyper-parameters (such as Dirichlet during the experiments. The prediction of image tags for the testing images is achieved by performing another Gibbs sampling on testing images to estimate the document-level distribution of switch variable and semantic components, with a fixed set of semantic components and user pe rspectives estimated from the training dataset. On the convergence of Gibbs sampling, the probability of tagging an image j from user u with tag t j The performance is evaluated by perplexity and tagging accuracy. The perplexity is a standard criterion for generative probabilistic models that evaluates how well the model predicts the testing data. The perplexity of a testing image dataset D test is: The perplexity score for a model is the lower the better. Fig. 2(a) shows the perplexity changing of the proposed pHDP model and baseline modes (Co rrLDA model and HDP model) over the iterations during the Gi bbs sampling process. We test pHDP model on a serial of  X  values. For CorrLDA model and HDP model, we only show their perplexity scores under the optimal parameter settings (i.e . CorrLDA model with 75 topics and HDP model with  X  =15.0). The results show that pHDP model achieve best performance with  X  =15.0 and it outperforms both HDP model and CorrLDA model. Fig 2(b) represents the perplexity of pHDP model under different perspective numbers. The optimal perspect ive number is L=75. Using Eq. (4), we calculate the probability of tagging an image j used for tagging. After that, the predicted top-ranked image tags are compared with the ground truth for validation. If a predicted considered as one hit. The ratios of hit numbers over the predicted tag numbers are averaged to produce the final annotation accuracy. Fig. 3 illustrates exampl es of image tagging results. Fig. 3(a) is an image shows a winter night in Toronto, Ontario, Canada. The ground truth image tags involve both location tags ( X  X ntario X ,  X  X anada X ) and topic tags (such as  X  X louds X ,  X  X ake X ,  X  X ight X , sky and  X  X ater X ). However, the image content alone provides little clues about the location. Further studie s indicate that other images contributed by the same user are also tagged with  X  X ntario X  and  X  X anada X . This may suggest that th e user lives in Ontario, Canada and contribute pictures taken from the same location. During the pHDP modeling, this user contextu al information is captured as a part of the user X  X  perspectives . When tagging a new image from the same user, the pHDP model will smooth the document-level predictive tag distribution with us er X  X  perspective and allow for tagging with location tags (Fig. 3(a) and 3(b), highlighted in bold). Fig 3(c) is contributed a user fr om Malaysia. Similarly, the user contextual information is captured in user X  X  perspectives. Thus the pHDP model succeeds in tagging image with both location tags (such as  X  X alaysia X ) and type tags (camera settings, like  X  X ikon X ). As shown in Fig. 3(c), tags pr edicted by the pHDP model also involve subjective tag, like  X  X nterestingness X , which demonstrates that the pHDP model is also capab le of modeling user X  X  subjective feelings. As a comparison, the HDP model fails to predict either location tags or subjective tags since it onl y relies on image content to make tag predictions. (c) tagging results of image entitled  X  X pread your wings and Fig 2(c) shows the overall image tagging accuracy (averaged over the testing dataset) of different models under their optimal calculated based on exact match, so it won X  X  take into account the synonym tags. In other words, pr edicted tags like  X  X uman X  and  X  X emale X  will be considered as unmatched with respect to the ground truth tag  X  X irl X . According to the result, the HDP model doesn X  X  show much improvement in the tagging accuracy compared to the CorrLDA model. It X  X  reasonable because the CorrLDA model is in essence a fi nite case of HDP model. Under optimal parameter settings, thei r performance should be similar. The pHDP model, as it integrates the user perspective information, significantly outperforms both CorrLDA model and HDP model in predicting image tags for different users. In this paper, we proposed a perspective Hierarchical Dirichlet Process (pHDP) model to deal with user-tagged image modeling. The contribution is twofold. Firstly, we associate image features with image tags. Secondly, we incorporate the user X  X  perspectives into the image tag generation process and introduce new latent variables to determine if an image tag is generated from user X  X  perspectives or from the image content. Therefore, the model is capable of extracting both em bedded semantic components and user X  X  perspectives from use r-tagged images. Based on the proposed pHDP model, we achieve automatic image tagging with users X  perspective. Experimental results show that the pHDP model achieves better image tagging performance compared to state-of-the-art topic models. This work was supported in part by NSF CCF 0905291, NSF CCF 1049864, NSFC 90920005. [1] D.M. Blei, and M.I. Jordan, Modeling annotated data The [2] Henderson, J.M. and Hol lingworth, A. High level scene [3] C. Siagian and L. Itti, Rapid Biologically-Inspired Scene [4] A. W. M. Smeulders, M. Worring, S. Santini, A. Gupta, and [5] Y. Teh, M. Jordan, M. Beal, and D. Blei. Hierarchical [6] K. Bischoff, C.S. Firan, W. Nejdl, and R. Pa iu, Can All Tags [7] S. Sen, S.K.T. Lam, A.M. Rashid, D. Cosley, D. Frankowski, [8] Amr Ahmed, Eric P. Xing , William W. Cohen, Robert F. [9] X. Chen, C. Lu, Y. An, and P. Achananuparp. Probabilistic [11] C. Lu, X. Hu, X. Chen and J. Park. The topic-perspective [12] Sivic, J., Zisserman, A.: Video Google: A Text Retrieval [13] J. Matas, O. Chum, U. M., T. Pajdla. Robust wide baseline 
