 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Theory axiomatic constraint, TDC constraint
Axiomatic methods were pioneered by Fang et al. [5] and used since then in several studies including [3, 2]. In a nut-shell, axiomatic methods provide formal constraints that IR functions should satisfy in order to be valid, i.e. to perfom well on IR tasks. According to [2], the four main constraints for an IR function to be valid can be phrased as: the weight-ing function should (a) be increasing and (b) concave wrt term frequencies, (c) have an IDF effect and (d) penalize long documents. In addition to these four basic constraints, Fang et al. [5] introduced additional constraints to regulate the relative importance of different parameters, as TF and IDF for example.

The IDF effect mentioned above relates to the constraint referred to in [5] as the TDC constraint, which can be for-mulated as follows: TDC: Let q be a query and w 1, w 2betwoqueryterms. As-If idf(w1)  X  idf(w2) and c ( w 1 ,d 1)  X  c ( w 1 ,d 2), then RSV ( d 1 ,q )  X  RSV ( d 2 ,q ). where c ( w, d ) denotes the number of occurrences of w in d . This constraint aims at capturing the fact that, ceteris paribus , rarer terms (i.e. terms with a large IDF) should be preferred over more frequent ones. However, there are sev-eral ways to define the context ( ceteris paribus )inwhichto place this constraint, and the study presented in [2] relies on a stricter context corresponding to a special case of the TDC constraint, where w 1 only occurs in d 1and w 2onlyin d 2. This constraint, referred to as speTDC can be formulated as: speTDC: Let q be a query and w 1, w 2 two query terms. As-0. If idf(w1)  X  idf(w2) ,then RSV ( d 1 ,q )  X  RSV ( d 2 ,q ). If it has been show in previous studies (as [5, 2]) that most IR models satisfy most IR constraints, the situation of the TDC constraint is unclear, and the goal of this short paper is to show that several state-of-the-art IR models indeed do not comply with the general TDC constraint, but do satisfy the speTDC one. We will review here the recently intro-duced log-logistic model [2], as well as the Jelinek-Mercer and Dirichlet language models.
The log-logistic model proposed in [2] is specified by: where N w is the number of documents in the collection con-taining the term w and N the total number of documents in the collection; l d is the length of document d ,andavg( l the average document length in the collection.

Let us examine the TDC constraint for this model, and for that let us consider two documents d 1 and d 2 of equal length l ;let  X  = log(1 + c avg ( l ) l ). For simplification, we use a to denote w 1 , b to denote w b and a 1 (resp. a 2 ) for c ( a, d (resp. c ( a, d 2 )). For a query q consisting of only a and b , the difference in score between d 1 and d 2 amounts to:  X = RSV ( q, d 1)  X  RSV ( q, d 2) = log( r a + a 1  X  Now, let us place ourselves in the conditions specified in the TDC constraint and let us assume that r a &lt;r b , a 1 &gt;a a + b 1 = a 2 + b 2 (and thus b 2 &gt;b 1 ). The TDC constraints stipulates in that case that  X   X  0, that is: Setting: a 1 =7 ,b 1 =4 ,a 2 =6 ,b 2 =5 ,r a =0 . 001 and r =0 . 01 shows that the above inequality is true iff :  X &lt; 0 . 0045. Hence,  X  must be very small for the TDC constraint to be verified. Indeed, for documents of average length,  X  log(1 + c )and c should be chosen smaller to 0 . 005 for the above inequality to be satisfied.

We now provide a more formal proof that the log-logistic model does not comply with the TDC constraint. Let X  X  first Table 1: Pair of query terms (short query) below mean corpus language model consider the following optimization problem: where s is a pre-defined, positive value. As the log is con-cave, the overall objective funciton is concave, and the so-lution to the above optimization problem correspond to the values maximizing the following Lagrangian:  X = for which the partial derivatives are defied as: Setting these derivatives to 0 leads to the following solution Now let us consider a query q with two words ( a and b ) occurring only once, and let d 1 a,d d 2 be two documents of equal length. Let us furthermore assume that: idf( a )= for sufficiently small for all the quantities to be positive. In this case, all the conditions of the TDC constraint are verified, and thus one should observe that RSV ( q, d 1 ) RSV ( q, d 2 ), which is in contradiction with the fact that the values for d 2 are the ones that maximize A which corre-sponds in this case to the retrieval status value. This shows that the log-logistic model is not compliant with the TDC constraint. However, as shown in [2], the log-logistic model is compliant with the speTDC constraint, which represents a stricter version of the TDC constraint.

The situation for language models wrt the TDC and speTDC constraints is identical to the one of the log-logistic model. Indeed, it has been shown in [1] that the Jelinek-Mercer model could be seen as a special case of the log-logistic model. All the development made above in the context of the log-logistic model applies to the Jelinek-Mercer model, which is not compliant with the TDC constraint (it is how-ever compliant with the speTDC constraint).

As shown in [5], and using the notations introduced previ-ously, the Dirichlet language model agrees with the TDC constraint in the following case:
As r a t a and r b t b ,both t a and t b are  X  0. where p ( a | C ) represents the collection probability. Table 1 shows for several collections the mean value of p ( w | C )for query terms (denoted m ), the optimal values obtained for the Dirichlet smoothing parameter  X  and the percentage of pairs of query terms for which the corpus language model diff &lt; m ). As one can note, in almost two third of the cases, the numerator of equation 1 is very small. So, for the bound given in equation 1 to hold, one needs to rely on large values for  X  (larger than 2,000 when the numerator is one). As shown in table 1, we are far from these values in practice, and the Dirichlet language model is in general not compliant with the TDC constraint. Furthermore, using the analytical formulation of the speTDC constraint proposed in [2], one can show that the Dirichlet language model is compliant with the speTDC constraint.
We have shown here that several state-of-the-art IR mod-els do not satisfy the TDC retrieval constraint introduced in [5]. The IR models we have considered are the recently introduced log-logistic model, and two standard versions of the language model, namely the one based on Jelinek-Mercer smoothing, and the one based on Dirichlet smoothing. Fur-thermore, we have seen that all these models satisfy speTDC , a stricter version of the TDC constraint introduced in [2] to directly formalize the IDF effect. Because of the good be-havior of the models we have reviewed, we believe that the above development suggests that the TDC constraint is not valid, and should be replaced with the speTDC one.
Directly assessing the validity of a particular retrieval con-straint is not straightforward. The work presented in [4] shows that it is possible to experimentally assess whether a particular IR model complies or not with a given constraint. It is however not clear whether all constraints can be taken into account. We have followed here a different line, based on a theoretical analysis of the behavior orf IR models wrt a particular constraint. [1] S. Clinchant and E. Gaussier. Bridging language [2] S. Clinchant and E. Gaussier. Information-based [3] R. Cummins and C. O X  X iordan. An axiomatic [4] R. Cummins and C. O X  X iordan. Measuring constraint [5] H. Fang, T. Tao, and C. Zhai. A formal study of
