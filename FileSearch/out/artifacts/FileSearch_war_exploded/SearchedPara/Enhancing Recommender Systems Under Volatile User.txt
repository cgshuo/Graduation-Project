 This paper presents a systematic study of how to enhance recom-mender systems under volatile user interest drifts. A key devel-opment challenge along this line is how to track user interests dy-namically. To this end, we first define four types of interest pat-terns to understand users X  rating behaviors and analyze the proper-ties of these patterns. We also propose a rating graph and rating chain based approach for detecting these interest patterns. For each users X  rating series, a rating graph and a rating chain are constructed based on the similarities between rated items. The type of a given user X  X  interest pattern is identified through the density of the corre-sponding rating graph and the continuity of the corresponding rat-ing chain. In addition, we propose a general algorithm framework for improving recommender systems by exploiting these identified patterns. Finally, experimental results on a real-world data set show that the proposed rating graph based approach is e ff ective for de-tecting user interest patterns, which in turn help to improve the per-formance of recommender systems.
 H.3.3 [ Information Storage and Retrieval ]: Information Filter-ing; H.3.5 [ On-line Information Services ]: Web-based Services Experimentation, Algorithms Recommender system, interest pattern, interest drift
Recommender systems [2, 18] identify user interests and pro-vide personalized suggestions from overloaded information by ex-ploiting the opinions of a community of users. Recent years, rec-ommender systems have been widely used in many business appli-cations [4, 12, 14]. In general, there are three ways to develop recommender systems. The first one is content-based (CB) [24] and targets on suggesting items which are similar to those a given user has liked in the past. The second way is based on collaborative filtering (CF) [3, 19]. In other words, recommendations are made according to the tastes of other users that are similar to the target user. Finally, a third way is to combine the above and have a hybrid solution [13].

However, traditional recommender systems usually do not con-sider the scenarios that users X  interests drift with time. Indeed, volatile user interest drifts have been a major hinder to the suc-cessful applications of recommender systems.

In the literature, there are some emerging studies that have lim-ited progress in detecting user interest drifts for improving recom-mender systems. For instance, Ding et al. [8] used a time weight method to give di ff erent weights to old and new rating data without explicitly detecting user X  X  interest drifts. Also, a Bayesian based approach for tracking user interest drifts was proposed to improve CB recommender systems [11]. In addition, cluster-changing and auto-similarity methods have been applied for detecting user in-terest drifts to improve CF recommender systems [15]. However, these approaches are designed for pure CB or CF recommender systems and need complex detection modules with high compu-tational cost. In practice, many real-world recommender systems have been developed based on hybrid methods in order to achieve better performance [2]. Therefore, it is expected to have a more flexible, and systematic method to detect user interest drifts for en-hancing recommender systems. Towards this goal, there are some open questions about user interest patterns that should be first an-swered. Specifically, which typical patterns can summarize di-verse users X  ratings? How to distinguish them from each other? Whether the detection of these patterns can help improve recom-mender systems? If the answer is  X  X es X , how much improvement can be achieved?
To this end, in this paper, we provide an organized study of how to improve recommender systems under volatile user interest drifts. Along this line, we first analyze time-related user rating data and introduce four types of user interest patterns to characterize the di-versity of user rating behaviors. These patterns are Single Interest Pattern (SIP) , Multiple Interests Pattern (MIP) , Interest Drift Pat-tern (IDP) , and Casual Noise Pattern ( CNP ). In the paper, we show that both IDP and CNP have negative impacts on the performance of recommender systems. Also, to identify these patterns, we de-sign a rating graph and rating chain based approach which includes a preprocessing stage and a detecting stage. In the preprocessing stage, given a user X  X  corresponding rating series, the corresponding rating graph and rating chain are constructed. Then in the detecting stage, the interest patterns of the given user are detected through the analysis of the rating graph and rating chain. Finally, to im-prove the performance of recommender systems, we remove user ratings identified as CNP and prune user ratings identified as IDP while building recommender systems. In this way, the noisy data are removed as much as possible and the learning quality of recom-mend systems and the recommendation quality are both improved. To validate the proposed approach, we carry out experiments on the MovieLens data set. The results show that the precision, recall and F1-measure of user interest pattern detection are higher than 90%, and the performance of recommender systems are improved through detecting and tackling interest patterns in terms of the Hit Ratio and Macro-DOA metrics.
 The contributions of this paper are summarized as follows.
Overview. The rest of this paper is organized as follows. Sec-tion 2 introduces four types of interest patterns. In Section 3, we propose an approach of detecting user interest patterns. Section 4 gives a general algorithm framework for improving existing rec-ommender systems by leveraging interest patterns. In Section 5, we show the experimental results. Section 6 provides a brief in-troduction of related work. Finally, in Section 7, we conclude this paper.
We argue that for each rated item in a user rating series, there is a latent user interest that motivates the user to make the rating, and we say this item reflects the latent user interest. The lasting time of an user interest is defined as follows.

D  X  X  X  X  X  X  X  X  X  X  X  X  X  1 (L  X  X  X  X  X  X  X  X   X  X  X  X  X   X  X   X  X  X  X  X  X  X  X  X  X  X  X  ). Given a user X  X  rating series I = I 1 I 2 ... I N , where I i (1  X  i  X  N ) means a rated item, the lasting time of an interest X is ( t end  X  t begin ) , where t timestamp of the first item reflecting X and t end is the timestamp of the last item reflecting X.

By considering lasting times of interests, we propose four pat-terns of user interests to summarize diverse rating series as follow: Table 1: Some movies in MovieLens data and some main attributes of them.
 Figure 1: The graph of similarities between movies listed in Table 1.

Table 1 lists some movies from a real movies rating data set named MoveLens [1] data set. Some main attributes of these movies are shown including the movie name, the cast, the genres the movie are assigned. Figure 1 illustrates the similarity graph of these movies. In this graph, if the similarity between two movies is bigger than a predefined threshold, an edge is established between them. Similar-ity between two movies is evaluated according to their correspond-ing attributes. For instance, movie A is similar to movie B because both of them are Romance movies. From a similarity graph, we can see whether two movies are similar intuitively. Given a group of movies, if most of them are mutually similar, they are regarded to represent one interest. Obviously, there are three interests in the figure labeled with di ff erent colors.

Given the movies in Table 1 and their similarity graph, we give some examples of di ff erent interest patterns as follows. In these ex-amples, we assume that the time intervals between adjacent ratings are same.
Among these interest patterns, IDP and CNP have negative ef-fects on the performance of recommender systems. If a user X  X  rat-ing series is identified as an IDP, it means the user X  X  interests drift at some time points and the old ratings are useless since they reflect out of time interests of the user. Moreover, if a user X  X  rating series is identified as a CNP, it means most of the user ratings are useless for characterizing the user X  X  interests since his (or her) interests drift so frequently. For a CF-based approach, IDPs and CNPs bring noisy data in the training step and the recommendation step. Therefore, IDPs and CNPs do not only impact the quality of learning but also the recommendation accuracy. For a CB-based approach, IDPs and CNPs bring noisy data in the recommendation step while using the user ratings to represent a given user X  X  preference model, and then impact the performance of recommender systems. For the similar reason, a hybrid approach also su ff ers the existences of IDPs and CNPs. In order to deal with IDPs and CNPs, we should firstly pro-pose an e ff ective approach for identifying di ff erent interest patterns given users X  rating series. Then we should design specific methods for tackling IDPs and CNPs when building recommender systems. In the following two sections, we present our solutions for these two tasks, respectively.
Since the interest patterns are distinguished in terms of some subjective metrics such as  X  X ost of the user ratings X  time range X , it is not a simple problem to automatically detect di ff erent types of interest patterns. Therefore, we need to exploit some properties of them which can help to distinguish them and can be captured easily.
Before introducing the properties for distinguishing di ff erent in-terest patterns, we define some related notions as follows:
D  X  X  X  X  X  X  X  X  X  X  X  X  X  2 (R  X  X  X  X  X  X  X  G  X  X  X  X  X  X  D  X  X  X  X  X  X  X  X  X  ). Given a user X  X  rating se-ries I = I 1 I 2 ... I N , the corresponding rating graph is G where V I is a node set containing I i (1  X  i  X  N ) , and E an edge set, where an edge between I i and I j is established if I and I j are similar. The density of G I is defined as max E = N 2 means the max number of possible edges in G I
D  X  X  X  X  X  X  X  X  X  X  X  X  X  3 (R  X  X  X  X  X  X  X  C  X  X  X  X  X  C  X  X  X  X  X  X  X  X  X  X  X  X  ). Given a user X  X  rat-ing series I = I 1 I 2 ... I N , the corresponding rating chain is C ( V I , L I ) , where V I is a node set containing I i (1  X  i  X  N ) , and L I = { l I } is a link set, where a link can only be established between I is established. The continuity of C I is defined as | L I means the max number of possible links in C I .

The rating graph and the rating chain are both specific cases of the similarity graph mentioned in Section 2. Di ff erent from simi-larity graph, they are proposed for capturing the interest coherence of rated items in a certain rating series but not all rated items. Ta-ble 2 shows the corresponding rating graphs and rating chains of the example interest patterns mentioned in Section 2.

For constructing the rating graph and rating chain of a given rat-ing series, we need to 1) choose a similarity measure for items and 2) choose a similarity threshold to determine whether any two items are similar given the similarity measure.

As mentioned above, the similarity of two items can be measured by considering the similarities between their attributes. Without the loss of generality, the similarity between two items I i and I defined as follows: where w l is the weight assigned to the l  X  th attribute and S im ( A represents the similarity between I i and I j on the l  X  th attribute. For di ff erent types of attributes, the methods of calculating similarity are di ff erent. For example, for a text attribute, such as cast, genre, and key words of a movie, the similarity is calculated through the ratio of shared words between two items. By contrast, for a nu-meric attribute, such as the publishing year of a book, the similarity is calculated through the normalized di ff erence of two values.
We use a method of learning the weights of similarities on each attribute proposed in Ref. [6]. Firstly, we build a training data set by selecting the items rated by enough users. Denoting the selected lish the following equation: where S im  X  ( I i , I j ) is the approximate similarity between I
In our method, S im  X  ( I i , I j ) is calculated by considering the ratio of co-ratings. Particularly, we calculate S im  X  ( I i , I where U i means the users who rated item I i and U j means the users who rated item I j . Some previous studies [19, 7] have demonstrated that two items are similar if they are usually co-rated by users. In our method, the items in I train are all rated by many times, which further improves the confidence of the co-rating measure.
One may argue why we do not directly use S im  X  ( I i , I ilarity between I i and I j . The problem of this method is S im  X  ( I only makes sense if both I i and I j have been rated by enough times. Otherwise, S im  X  ( I i , I j ) might not be a good approximation of the real similarity between I i and I j , because the sparseness of I results in that the value of S im  X  ( I i , I j ) may be largely impacted by noisy data.

Given a series of equations as Equation 2, we conduct a learning task for learning w l through the linear regression approach. Next, we choose a similarity threshold as follows. Firstly we randomly select some item pairs and some human volunteers are required for labeling  X  X imilar X  or  X  X ot similar X  for these item pairs. Then, for each labeled item pair we calculate their similarity by the learnt similarity measure function. Finally, a threshold is determined by making the maximum agreement between human labels and the automatic similarity measure.
We can identify SIPs and CNPs directly through their rating graph densities and their rating chain continuities. For a SIP, the corresponding rating graph must have high density because all rated items in a SIP reflect the same interest. As mentioned above, if a group of movies reflect the same interest, most of them must be mutually similar, and the number of edges in the corresponding rating graph must be close to the maximum possible number. It ex-plains why the density of a SIP X  X  rating graph is high. By contrast, for a CNP, the corresponding rating graph must have low density because its each interest only lasts for a very short time and the rated items are divided into many interests. Consequently, there are usually few similar item pairs in a CNP, which implies that the number of edges of the corresponding rating graph is small and the corresponding density is low. For the similar reason, a SIP X  X  rat-ing chain must have high continuity and a CNP X  X  rating chain must have low continuity. Table 3 shows the rating graph densities and rating chain continuities for each rating series in Table 2. We can clearly see that for a SIP ACDEB, its rating graph density and rat-ing chain continuity are both very high, and for a CNP AFOKN, both its rating graph density and rating chain continuity are very low. Notice that the ranges of rating graph density and rating chain continuity are both [0,1].
 Table 3: The rating graph densities and rating chain continu-ities of the rating series in Table 2
However, it is still a problem of determining appropriate thresh-olds of rating graph density and rating chain continuity for identify-ing CNPs and SIPs. For this concern, we firstly make the following assumptions: 1) In a CNP X  X  rating graph, the probability that there exists an edge between two given items is independent and identi-cally distributed (i.i.d.). We denote this probability as P a SIP X  X  rating graph, the probability that there exists an edge be-tween two given items is independent and identically distributed (i.i.d.). We denote this probability as P S I P .
 If we randomly rate N items, which corresponds to an ideal CNP, the number of edges of the corresponding rating graph is  X  P
CN P , following the above assumptions. According to Definition 2, the density of the rating graph is: Similarly, according to Definition 3 the continuity of an ideal CNP X  X  rating chain is:
Moreover, if we rate N items with the same interest, which cor-responds to a SIP, it X  X  easy to derive that in the ideal scenario the density of the rating graph is P S I P , and the continuity of rating chain is P S I P as well. However, we should consider noise because occa-sionally a user may carelessly rate items which look like in line with his (or her) interest but are actually not. Denote a user defined noisy factor as  X  , the density of an ideal SIP X  X  rating graph is as follow: where  X   X  N means the number of randomly rated items, and (1  X   X  )  X  N means the number of rated items that reflect the same interest. Similarly, the continuity of an ideal SIP rating chain is:
Therefore, the thresholds of rating graph density and rating chain continuity for distinguishing SIPs and CNPs from other interest patterns can be calculated through P CN P and P S I P ing series, if its rating graph density is smaller than Density and its rating chain continuity is smaller than Continuity identified as a CNP. Otherwise, if its rating graph density is big-ger than Density S I P and its rating chain continuity is bigger than Continuity S I P , it is identified as a SIP. We consider both of the rat-ing graph X  X  Density S I P and the rating chain X  X  Continuity ing series because both of them are approximate features of CN P and IS P . Combining them may enhance the precision of detecting CN P and IS P .

The values of P CN P and P S I P can be statistically estimated for a specific data set. For example, in our experiments on the Movie-Lens data, we randomly select 5,000 pairs of items and calculate the ratio that the corresponding similarity is bigger than a prede-fined threshold, where an edge can be established. The same sam-pling process is repeated ten times and we estimate P CN P the mean ratio. For P S I P , we take advantage of the item pairs la-beled  X  X imilar X  by volunteers, which is mentioned in Section 3.1. We randomly sample 500 item pairs from the item pairs labeled  X  X imilar X  by ten times, and estimate P S I P through the mean ratio that the similarity between a pair of items is bigger than the prede-fined threshold of similarity.
Though SIP and CNP can be directly identified through their rating graph densities and rating chain continuities, there is still a challenge to distinguish the last two interest patterns, i.e., MIP and IDP. Before presenting our algorithm for distinguishing them, let us look into an property of IDP. In an IDP, few interests last for the most of the whole time range. In other words, in an IDP, some interests disappear and some interests begin to appear as time goes on, which implies that there should be some interests transaction zones in the rating series where both old and new interests appear. If we split an IDP at some position in one of its interests transac-tion zones, the split segments X  rating graphs usually are more dense than the one of original rating series, because their ratings are more coherent in terms of interests. By contrast, MIP does not have this property since most of its interests last for the most of the whole time range. Based on this property, we propose a heuristic segmen-tation method for splitting the rating series at the positions where a split will cause large increase of rating graph density.

We use Splitting Density Increment(SDI) to measure the increase of rating graph density after splitting. Given a rating series I , if we split I at the i -th position, we denote the left sub-series as I i c and the right sub-series as Ib i , then the SDI at the i -th position is calculated as follows: where Density I i c means the density of I i c  X  X  rating graph, Density means the density of the Ib i  X  X  rating graph, and Density density of I  X  X  rating graph, respectively.

The main steps of our algorithm are listed as follows. Firstly, we find the position with the max SDI. If it is a drift point , the rating se-ries is split at this position. Then the same procedure is recursively performed for split rating sub-series. Otherwise, if the position with max SDI is not a drift point, the algorithm terminates. A drift point implies that the user X  X  interest probably drifts at this position. After executing the algorithm, if no drift point can be found, we regard the given rating series as a MIP. Otherwise, we regard it as an IDP and the drift points are used for further processing as mentioned in Section 4.

We determine whether the position with max SDI is a drift point by referring an approach proposed in Ref. [17]. The main idea of this approach is as follow. Given a series S , for the i -th position, we define: where  X   X  is a feature of  X  and F ( a , b ) is a bivariate function. Then a t series can be generated. Denoting the maximum value in the t series as t max , we define the probability that t max the maximum value of a random series with the same length as P ( t max ). If P ( t max ) is bigger than a predefined significance level P , the corresponding position of t max is regarded as a peak. In practice, P 0 is usually set to be 0.95. Given a numeric series with N elements, P ( t max ) can be calculated as follow: where B x ( a , b ) is the incomplete beta function, v = N  X  2,  X  =  X  lnN  X   X  , and  X  ,  X  ,  X  are constant values and usually approximated by Monte Carlo simulations.

This approach is widely used for determining whether or not seg-menting a series by the existence of a peak of t . In our application, the SDI corresponds to t . Given a rating series, the correspond-ing SDI series can be generated. Denote the position with SDI as p max , if P (SDI max ) is bigger than P 0 , we can state that p a peak, which implies the corresponding increase of rating graph density is significant and p max can be regarded as a drift point.
Examples in Figure 2 may help to understand the notions of SDI and drift points. These figures show the SDI series of some syn-thetic interest patterns. The method of generating synthetic interest patterns is introduced in Section 5.3. Figure 2 (a) shows the SDI series of a syntectic MIP with 60 rated items and 2 interests. We can see this SDI series has no obvious peak. Figure 2 (b) shows the SDI series a synthetic SIP with one interest drift. We can see there is a peak in this SDI series, which is a drift point. Figure 2 (c) shows the SDI series of a synthetic SIP with two interest drifts. We can see there are two peaks in this SDI series, which are both drift points.

When splitting the rating series, we need to constrain the mini-mum length of a sub-series because a too short rating series may not reflect the user X  X  interests well. Such a constraint depends on spe-cific applications. For example, GroupLens research group states that it at least needs 20 rated movies to reflect the interests of a user [19].

Algorithm 1 shows the details of the Density Based Segmenta-tion(DBS) method, where I is an item series sorted by rating time for a user, p begin is a subseries X  X  first position in I , and p series X  X  last position in I . Moreover, I 0 = I [ p begin subseries from p begin to p end , and L 0 means the predefined minimum length of a split sub-series. The sub-method S DI ( I 1 , I the SDI of two neighboring series I 1 and I 2 .

Time Complexity Analysis. Given a rating series I with N rated items, when calculating the SDI of each position i of I , we need to calculate Density I , Density I i c , and Density Ib i naive algorithm, the calculations of Density I i c and Density O ( i 2 ) and O (( N  X  i ) 2 ) time complexities, respectively. However, if the edge numbers of I i c and Ib i  X  X  rating graphs are remembered, the calculations of Density I i c and Density Ib i only need O ( i ) and O ( N  X  i ) time complexities, respectively. Because they can be com-puted as follow: where E I ( i  X  1) c means the edge number of I ( i  X  1) c  X  X  rating graph,
Algorithm 1 : DBS ( I , p begin , p end ) E Ib ( i  X  1) means the edge number of Ib ( i  X  1) X  X  rating graph, E + means the number of edges that connect the i -th item with it X  X  previous items, and E  X  I i means the number of edges that connect the i -th item with it X  X  following items. Obviously, the computa-tions of E + I i and E  X  I i need to scan i and N  X  i items. Thus, the time complexities of computing Equation 5 and Equation 6 are O ( i ) and O ( N  X  i ), respectively. Furthermore, the whole scan of I computes SDIs N times, so the corresponding time complexity is O ( N  X  O ( i ) + N  X  O ( N  X  i )) = O ( N 2 ). In the worst case, the original rating series can be split into single items, and the corresponding time complexity is O ( N 2 logN ). However, since we have the thresh-old of minimum length of rating sub-series and a split happens only when there is a drift point, the practical time cost is much less than that of the worst case.
We propose a general algorithm framework to improve the per-formance of recommender systems by detecting di ff erent types of interest patterns and invoking the corresponding operations. This framework consists of an o ff -line part and an on line part, as illus-trated in Figure 3.
 Figure 3: The framework of applying user interest pattern de-tection to improve recommender systems.

The o ff -line part has two steps, namely, the preprocessing step and the recommender constructing step. In the preprocessing step, we prune the users X  rating series for reducing noisy data. Firstly, we extract the attributes of items and calculate the similarities be-tween items. A N  X  N similarity matrix S imM is initialized as  X 
S imM [ i ][ j ] = 0. If the similarity between I i and I than a predefined threshold, we set S imM [ i ][ j ] = 1. Then we iden-tify di ff erent user interest patterns from all users X  rating series. If a user X  X  rating series is identified as a CNP, it will be removed. Oth-erwise, if it is identified as an IDP, we split it at the most recent drift point P recent and drop the sub-series in front of P because these sub-series are regarded as out of time for reflecting the user X  X  interests. For SIPs and MIPs, we do nothing with them since they have no negative e ff ect on recommender systems. In the recommender constructing step, we construct a recommender sys-tem based on an existing recommender algorithm from the pruned rating series. Any CF or Hybrid based recommender systems can benefit from the preprocessing step because the reduction of noisy data improves the quality of training data, so does the quality of learning.

In the on-line part, the framework makes recommendations for users by considering their rating series. Given a user, we firstly detect his (or her) interest pattern through the corresponding rating series. In the first case, if the user X  X  rating series is a SIP or MIP we make recommendations by considering whole of the corresponding rating series. In the second case, if the user X  X  rating series is a CNP we make recommendations without considering the corresponding rating series and just recommend the most popular items. In the final case, if the user X  X  rating series is an IDP, we make recom-mendations only considering the rating sub-series behind the most recent drift point. Any CF, CB, or Hybrid based recommender sys-tems can benefit from this part because the noisy data are removed from the user X  X  rating series.

The major advantage of this framework is that it can be used for improving a wide range of existing recommender systems. It is like a  X  X rapper X  which contains an existing recommender sys-tem as a module. Moreover, an additional interest pattern detection &amp; operation module is integrated to improve the performance of the original recommender system. Our experiments show that such improvements are usually significant.
In this section, we report the experimental results on a real data set and several semi-synthetic data sets, which show that our ap-proach for detecting interest patterns is e ff ective and the proposed interest pattern based algorithm framework can significantly im-prove a wide range of recommender systems.
We conduct extensive experiments on the MovieLens [1] data set, which is a widely used benchmark data set for evaluating the performance of recommender systems. The MovieLens data set includes over 1,000,000 ratings from 6,040 users for 3,900 movies. Each movie is associated with the ID, the movie name, the release year, the script writers, the directors and the genres. There are 18 genres for all the movies, and each movie belongs to one or more genres. The rating data contain one million ratings and each rating is associated with the user ID, the movie ID, the rating value, and the timestamp.
Our approach has several parameters for detecting interest pat-terns. In this section, we report how to determine these parameters for the MovieLens Data.
Constructions of rating graphs and rating chains are based on a similarity measure and the corresponding similarity threshold. As mentioned in Section 3.1, we use a linear similarity function on each attribute as the similarity measure of items. The weight of each attribute is learnt through the linear regression approach. In our experiments, the learnt weight for each attribute is shown in Table 4. From this table we can see, genres and cast are the most important attributes for distinguishing movies, which is consistent with common sense. Comparatively, the attribute of key words seem less important. It may be because in the MovieLens data, the key words of a movie are tagged by di ff erent users and there is no unified standard of tagging. As a result, two similar movies may be tagged with di ff erent key words by di ff erent users.
Then we randomly select 5,000 movie pairs and require three college volunteers to label whether the two movies in a movie pair are similar. These volunteers are all movie fans and can use search engine to retrieval the information of their unfamiliar movies. The labeled result shows 22% of movie pairs are labeled similar. The learnt similarity threshold is 0.3, which is surprisingly small at the first glance. But after careful analysis, we find that it is reasonable. Suppose two movies have the same genres but di ff erent cast, di ff er-ent names, and di ff erent directors. In practice, such two movies are usually considered similar while their similarity under our measure is just close to 0.35. In our approach, we identify SIPs and CNPs through Density Density CN P , Continuity S I P and Continuity S I P , respectively. Ac-cording to their definitions, all of these parameters are computed based on P CN P and P S I P . To estimate P CN P , we randomly select 5,000 pairs of items and calculate the ratio that the corresponding similarity is bigger than a predefined threshold. The same sam-pling process is repeated ten times and we estimate P CN P the mean ratio. To estimate P S I P , we take advantage of the item pairs labeled  X  X imilar X  by volunteers. After randomly sampling 500 item pairs from the item pairs which are labeled  X  X imilar X  by ten times, the mean ratio that the similarity between a pair of items is bigger than the predefined threshold of similarity (0.3) is used as the approximation of P S I P . Table 5 shows the ranges of rating graph density and rating chain continuity for each type of interest pattern.
 Table 5: The ranges of rating graph density and rating chain continuity for each type of interest patterns
To evaluate the e ff ectiveness of our approach for detecting inter-est patterns, we need a test data set which contains rating series with labels of the corresponding types of interest patterns. However, the rating series in MovieLens data have no such labels. Alterna-tively, we generate synthetic interest patterns based on the movies in MovieLens data. As mentioned in Section 5.2.1, both genres and cast are important attributes of movies. If several movies have the same genres, they probably reflect the same interest. Similarly, if several movies have the same cast, they also probably reflect the same interest. Since in practice it is more common that two movies have exactly the same genres than that they have exactly the same cast, we generate interest patterns by using genres to simulate in-terests. Particularly, to generate a SIP, we firstly randomly select a genre and then randomly select some movies with this genre to construct a rating series. To generate a MIP, we randomly select 2 or 4 genres and randomly select movies with these genres to con-struct a rating series. If the first or last five movies don X  X  cover all genres in the whole rating series, we drop this rating series and re-peat the above step. To generate a IDP, we firstly generate a MIP or IDP as a prefix. Then we generate another MIP or IDP with di ff er-ent genres and append it to the prefix. To generate a CNP, we just randomly select some movies to construct a rating series. In our ex-periment, each rated item is not associated with rating scores. For each type of interest patterns, we generate 100 synthetic samples with 60 movies. All generated interest patterns have been manu-ally checked to assure the correctness of their labels.

We generate three test data sets with the above approach to eval-uate our approach for detecting interest patterns. For each data set, we firstly identify CNPs and SIPs through their rating graph densi-ties and the rating chain continuities. Then, we omit the recognized CNPs and SIPs, and use the DBS algorithm to detect IDPs. Table 6 shows the precision, recall and F1-measure of our approach on each data set. From this table we can see the precision, recall, and F1-measure for each type of interest patterns are all higher than 90%, which means our approach for detecting interest patterns is e ff ective. Notice that even though the test data sets are generated by using genres to simulate interests, our approach is not aware of this knowledge. Instead, our approach works because the rating se-ries X  features, i.e., rating graph density and rating chain continuity, can capture the coherence of rated items on interests.

Figure 4 and Figure 5 show the SDI series for some synthetic interest patterns in the experiment. In each figure, we show the SDI series of 7 synthetic rating series which are the same interest patterns. From these figures we can see IDPs have obvious peaks of SDIs while MIPs have no such peaks, which intuitively explains why DBS algorithm works. Figure 5: An interest drift exists at the 30 th point, and SDI reaches the maximum value there.
In this Section, we evaluate the e ff ectiveness of enhancing rec-ommender systems with interest pattern detection. The proportion of negative interest patterns in the original Movie-Lens data is fixed. To study the e ff ect of detecting and tackling negative interest patterns on recommender systems with di ff erent proportions of negative interest patterns, we also generate some semi-synthetic data sets as follows. Firstly, we identify all SIPs, MIPs, IDPs, CNPs in the MovieLens data. Then we remove dif-ferent numbers of MIPs and SIPs from the original data to build additional data sets. The MIPs and SIPs to be removed are ran-domly selected with the same proportion in the original data.
Given a data set, for each rating series, we extract the last 20% ratings as the test set and use the sub-series containing the first 80% ratings as the training set. Recommender systems are built based on all users X  training sets and then tested for each user.
We carry out experiments for three basic k Nearest Neighbor ( kN N ) based recommender methods including a CB method and the other two CF methods. The CB method is the kN N -CB ( CB for short) proposed in Ref. [5]. The two CF methods are item-based kN N -CF ( IBCF for short) and user-based kN N -CF ( UBCF for short) [16], respectively. These methods are used as baseline methods. For each baseline method, we build the corresponding Interest Pattern Detection Based (IPDB) extension which firstly de-tects CNPs, IDPs and invokes the corresponding operations, then builds a recommender system by the baseline method.
To evaluate the performance of recommender systems, we use a coverage metric and a ranking metric as follow:
Firstly we compare the performance of CB and its IPDB exten-sion ( IPDB-CB for short). Figure 6 (a) and Figure 6 (b) show the HR and Macro-DOA of the two methods on data sets with di ff erent percentages of negative interest patterns, respectively. From these two figures we can see that the performance of CB drop slowly in terms of HR and Macro-DOA as the percentage of negative in-terest patterns increases, which illustrates that the negative interest patterns indeed have negative impacts on the performance of rec-ommender systems. We can also see that IPDB-CB always out-performs CB in terms of HR and Macro-DOA. The minimum and maximum improvements in terms of HR are 15.6% and 126.3%, and the minimum and maximum improvements in terms of Macro-DOA are 4.4% and 29.8% respectively. Moreover, the improve-ment of IPDB-CB to CB increases with the increase of the percent-age of negative interest patterns in terms of both HR and Macro-DOA. Figure 6: Compare the performance of CB and IPDB-CB in terms of HR and Macro-DOA.

Then we compare the performance of IBCF and its IPDB exten-sion ( IPDB-IBCF for short). Figure 7 (a) and Figure 7 (b) show the HR and Macro-DOA of the two methods on data sets with di ff erent percentages of negative interest patterns, respectively. From these two figures we can see that the performance of IPDB-IBCF and IBCF both drop in terms of HR and Macro-DOA as the percent-age of negative interest patterns increases. However, IPDB-IBCF always outperforms IBCF in terms of HR and Macro-DOA. The minimum and maximum improvements in terms of HR are 2.9% and 7.9%, and the minimum and maximum improvement in terms of Macro-DOA are 1.2% and 6.7%, respectively. Moreover, the improvement of IPDB-IBCF to IBCF increases with the increase of the percentage of negative interest patterns in terms of both HR and Macro-DOA. Figure 7: Compare the performance of IBCF and IPDB-IBCF in terms of HR and Macro-DOA.

Finally, we compare the performance of UBCF and its IPDB ex-tension ( IPDB-UBCF for short). Figure 8 (a) and Figure 8 (b) show the HR and Macro-DOA of the two methods on data sets with dif-ferent percentages of negative interest patterns, respectively. From these two figures we can see that the performance of IPDB-UBCF and UBCF both drop in terms of HR and Macro-DOA as the per-centage of negative interest patterns increases. However, IPDB-UBCF always outperforms UBCF in terms of HR and Macro-DOA. The minimum and maximum improvements in terms of HR are 2.0% and 9.3%, and the minimum and maximum improvement in terms of Macro-DOA are 0.3% and 2.1%, respectively. Moreover, the improvement of IPDB-UBCF to UBCF increases with the in-crease of the percentage of negative interest patterns in terms of both HR and Macro-DOA. Figure 8: Compare the performance of UBCF and IPDB-UBCF in terms of HR and Macro-DOA.

Based on above experimental results, we can state that negative interest patterns have negative impacts on recommender systems and our interest pattern detection based algorithm framework is ef-fective for improving a wide range of existing recommender algo-rithms, including CB-based algorithms and CF-based algorithms. Moreover, the bigger percentage of negative interest patterns is, the bigger improvement our approach can achieve. It is easy to under-stand because our approach is e ff ective for dealing with negative in-terest patterns and can ensure stable performance with the increase of negative interest patterns. By contrast, the base lines su ff er more as the percentage of negative interest patterns increases. Last, the improvement on CB-based algorithms is big than that on CF-based. It may be because CB-based algorithm only depends single user X  X  ratings and is sensitive to negative interest patterns, and CF-based algorithms is less sensitive to negative interest patterns by consid-ering collaborative information from similar users.
Related literature on recommender systems can be grouped into three categories based on how recommendations are made [2, 18]. Specifically, three categories are Content Based methods (CB) [6], Collaborative Filtering methods(CF) [3, 8, 12, 19] and Hybrid methods [13]. In the CB model, items are recommended to a user based on the preferred similar items of this user in the past. Due to limitations of textual analysis, this approach is domain sensitive, quality indistinguishable, and has the problem of overspecializa-tion [2]. Collaborative Filtering methods can be divided into two categories, namely, user-based CF and item-based CF. In the user-based CF, items are recommended to the users based on the choices of other users who have similar tastes and preferences as this user in the past. The goal is to find similarities among users using item ratings data so that items can be recommended based on the sim-ilarities [3]. In the item-based CF, similarities between items are calculated according to the rated items by the same user. Then rec-ommendations similar to one X  X  rated items are produced. A hybrid method is constructed by using both of CB and CF methods.
A few researchers have studied detecting users X  interest drifts in a recommender system. For example, Lam et al. [11] inves-tigated changes of user interests in information filtering systems, and a Bayesian-based technique for tracking users X  interest drifts is developed. Moreover, researchers have addressed the problem of changing user interests by decomposing an interest category into long-term and short-term interest models, relearning examples of recent window, applying decay functions, or employing evolution-ary algorithms [23]. However, none of these works made a system-atic study of di ff erent types of user interest patterns, where some types of interest patterns reflect user interest drifts. Indeed, in this paper, we not only propose four typical types of user interest pat-terns and the corresponding detection approach, but also propose a general algorithm framework that can improve a wide range of existing recommender systems by detecting user interest patterns.
Finally, recent years have witnessed increased interests in mining concept-drifting data. Concept-drifting means the concept that we try to learn from the data is constantly evolving. This is very simi-lar to the interest-drifting in the context of this paper. For instance, there have been some e ff orts dedicated to data selection in the envi-ronment of concept-drifting [9, 22]. In Ref. [9], the author pointed out that using old data blindly is not better than  X  X ambling X . In other words, using old data without selectivity helps to produce a more accurate hypothesis only if there is no concept-drifting and the amount of old data arbitrarily chosen just happens to be right. In contrast, the approach proposed in this paper can select data wisely and trace changes in user interest, thus alleviating the problem of user interest drifts.
In this paper, we provide an organized study of how to improve recommender systems under user volatile interest drifts. Specifi-cally, we propose four typical types of user interest patterns which can be detected by exploiting user rating graphs and rating chains. As shown in the paper, both interest drift patterns (IDP) and casual noise patterns (CNP) have negative impacts on the performance of a wide range of recommender systems, including CBs, CFs, and hybrid methods. Also, experimental results on a real-world data set show that, once these two types of patterns have been detected and processed with specific operations, the performance of these rec-ommender systems can be improved as measured by Hit Ratio and Macro-DOA metrics.
The work is supported by the National Natural Science Founda-tion of China (No. 60775037), the National High Technology Re-search and Development Program of China (863 Program) (No.2009 AA01Z123), Nokia Research Center China, and the Graduate In-novation Foundation of USTC. We also thank MovieLens group for sharing their data for research. [1] http: // www.grouplens.org / node / 73#attachments . [2] Adomavicius, G., Alexander, and Tuzhilin, Toward the next [3] Ahn, H. J., A new similarity measure for collaborative [4] Billsus, D., Brunk, C. A., Evans, C., Gladish, B., and [5] Chen, J., Yin, J., and Huang, J., Automatic content-based [6] Debnath, S., Ganguly, N, and Mitra, P., Feature weighting in [7] Deshpande, Mukund and Karypis, George, Item-based top-N [8] Ding, Yi, and Li, Xue, Time Weight Collaborative Filtering. [9] Fan, W., Systematic data selection to mine concept-drifting [10] Gori, Marco, and Pucci, Augusto, A random walk based [11] Lam, Wai, Mostafa, and Javed, Modeling user interest shift [12] Linden, G., Smith, B., and York, J., Amazon.com [13] Melville, P., Mooney, R.J., and Nagarajan, R., [14] Miller, B. N., Albert, I., Lam, S. K., Konstan, J. A., and [15] Min, Sung-Hwan, and Han, Ingoo, Detection of the customer [16] Mobasher, B., Dai, H., Luo, T., and Nakagawa, M., [17] Pedro, Bernaola-Galv X n, and Plamen, Ch. Ivanov, and Lu X s [18] Resnick, P., and Varian, H., Recommender systems. In [19] Sarwar, B., Karypis, G., Konstan, J., and Riedl, John, [20] Sarwar, B. M., Karypis, G., Konstan, J., and Riedl, J., [21] Song, H. S., Kim, J. K., and Kim, S. H., Mining the change [22] Wang, H., Fan, W., Yu, P. S., and Han, J., Mining [23] Widyantoro, D. H., Ioerger, T. R., Yen, J., Tracking changes [24] Zhang, Y., Callan, J., and Minka, T., Novelty and redundancy [25] Ziegler, C. N., McNee, S. M., Konstan, J. A., and Georg,
