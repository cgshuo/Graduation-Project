 T. RYAN HOENS, MARINA BLANTON, AARON STEELE, and NITESH V. CHAWLA , It is evident that the health of an individual significantly affects her quality of life. For this reason, finding appropriate physicians to diagnose and treat medical conditions is one of the most important decisions that a patient must make. Currently, patients have two options that can aid them in addressing this problem, but both are of limited applicability. The first option is to rely on friends and family for advice on where to seek treatment. While recommendations produced by a close circle of friends can be assumed to be very trustworthy, the likelihood that friends and family have experience with the same medical history as the patient is quite low. Furthermore, such advice can often be unavailable when, for instance, a patient moves to a new area and does not have an established network from which to seek advice; even when this is not the case, the number of physicians which friends and family have had contact with may not adequately cover the options in the given area. The second option for patients is to seek public information about and/or ratings for a physician available on, for example, the Internet. Such ratings, however, are sparse, as medical history is often treated as personal, confidential information. Public ratings also suffer from the problem of trustworthiness, as the likelihood of inaccuracies is higher.

In order to combat the problem of a paucity of experience among a patient X  X  trusted friends and the limited value of the existing types of rating systems, we propose a frame-work which enables patients to gather reliable doctor recommendations for their condi-tion(s) while protecting the privacy of both (i) the patients contributing their ratings to the system and (ii) the patients making inquiries. In this framework, patients can rate physicians based on their satisfaction (defined on a per-condition basis), affording the patients more fine-grained control over how to choose the physician who best suits their needs. It also protects the reliability of the results, meaning that (i) dishonest users can only minimally influence the outcome of a physician X  X  rating and (ii) no physician (or small group of users) has the ability to tamper with the ratings. This enables the system to maintain the integrity of its ratings and ensure they are as unbiased as possible.
As our privacy-friendly framework can be realized using a variety of techniques, we present two alternative architectures. Because each alternative has its own advan-tages and disadvantages, we provide a fair and detailed assessment of the properties of each option, giving the community the ability to evaluate both. Moreover, certain options might be preferable over others in different contexts or application scenar-ios. Finally, we describe specific realizations of the architectures X  X hich includes an implementation and experimental evaluation of the system X  X nd report the results.
Our contributions can therefore be summarized as follows.  X  X evelopment of a privacy-friendly framework for a reliable recommendation system of physicians using patient experience.  X  X resenting two architectures that realize the framework using different means from secure computation and anonymous communication and authentication techniques.  X  X evelopment of novel mechanisms for maintaining trustworthiness of the data in the presence of dishonest contributors.  X  X esign and implementation of specific protocols for the alternative architectures including experimental evaluation on a system prototype. There has been considerable research into privacy-preserving recommendation sys-tems. Originally, privacy was achieved in recommendation systems by giving user in-formation to a trusted third party who then performs the necessary calculations with other trusted agents.

One problem with this early approach is that, in addition to privacy, in order to be useful, recommendation systems must be robust against misbehaving users. One com-mon way misbehaving users may attempt to influence the rating of a specific physician is known as shilling attacks. Shilling attacks are said to occur when a user attempts to sabotage a competitor in order to make themselves look better. Lam and Reidl [2004] describe the attacks and discuss how they can affect the recommender system. Specif-ically, the authors consider various attack motivations (e.g., increasing/decreasing the rating of an item and hindering the credibility of the recommendation system as a whole) and their effect on recommendation systems. Importantly, they note that while observing sharp changes in scores is an obvious way to detect (some) shilling attacks, nontrivial attacks against the system could potentially succeed. Detecting such attacks is proposed as a future area of research. Chirita et al. [2005] provide further insight into shilling attacks and outline a detection algorithm which depends on the distribution of scores that each user has made so far. The algorithm proved to be quite robust, providing not many false positives while catching many of the shilling attacks. In this work, on the other hand, instead of trying to detect system abuse, we concentrate on abuse prevention.

While in shilling attacks competing physicians attempt to sabotage each other, bad mouthing [Bankovic et al. 2011] is said to occur when a (potentially offended) patient attempts to lower the score of a physician. Boosting (or ballot stuffing ) is said to occur if, instead of lowering a score, the patients collude to increase a rating [Dellarocas 2000; Srivatsa et al. 2005]. While we do not consider the implications of these attacks in this article, we note that the techniques in the literature to combat these attacks can be extended for our systems [Chirita et al. 2005; Burke et al. 2006; Mehta et al. 2007; Mobasher et al. 2006].

In addition to the problem of falsely modifying a score through illegitimate voting, another issue with the trust-based schemes is that they require users to trust the third parties to not misbehave with their data. In order to overcome this limitation, various techniques have been developed which do not require this third party. Two common ways of eliminating the need for the trusted third party are based on homomorphic encryption and data perturbation.

In the approaches based on homomorphic encryption [Canny 2002a, 2002b; Miller et al. 2004; Zhan et al. 2010; Berjani and Strufe 2011; Armknecht and Strufe 2011], users encrypt their data before sending it to any other party. This encrypted data is then used to compute the desired function without the underlying plaintexts be-ing made available to any party. In this way, the user X  X  privacy is preserved since no outside party is able to decrypt the ciphertexts (under certain constraints, e.g., when less than t participants collude). Note that these approaches based on homomorphic encryption all solve different problems than the one we solve here. That is, none of the approaches mentioned computing the weighted average; instead, they compute ratings based on similarity scores or some other function. Specifically, the method due to Canny [2002a, 2002b] addresses the problem of collaborative filtering which can be solved via expectation-maximization such that the update rules only require addition. PocketLens [Miller et al. 2004] is an alternative approach which is based on finding similar neighbors to a user who can, in turn, be used to compute good ratings for items. This is accomplished by computing the similarity of the ratings (via a dot product) of a user and various participants in the system. This similarity measure is then used to obtain accurate ratings for as-yet-unseen items. Zhan et al. [2010] propose a method for computing Pearson correlation. As the authors mention, the computation only requires multiplication and is therefore relatively easier than the one we describe in this article. Lastly, Armknecht and Strufe [2011] (building on the work of Berjani and Strufe [2011]) define a recommendation system based on Regularized Matrix Factorization (RMF). RMF was chosen because it provides accurate results and has many desirable proper-ties: most notably, RMF can be learned via stochastic gradient descent. The ability to be learned by stochastic gradient descent means that the method can be trained without all instances in memory and is easily adaptable for use with homomorphic encryption.
An alternative to the homomorphic encryption-based approaches are the data per-turbation approaches [Polat and Du 2005; Kargupta et al. 2003; Zhang et al. 2006]. In these approaches, users obfuscate their real data by adding noise to it before allowing it to be used in any computation. In this way, the users X  actual ratings remain protected; yet due to aggregation, the authors argue that data perturbation effects still allow for effective recommendations to be made [Polat and Du 2005].

Another recent notion of privacy related to data perturbation approaches which has been used in recommendation systems is called differential privacy. Loosely speaking, differential privacy [Dwork 2006, 2008] for statistical databases guarantees that the outputs of a statistical query over two databases which differ by one element will differ by at most a negligible quantity. Intuitively, this means that the function is not significantly affected by any minor changes to the database. Differential privacy can be achieved by adding noise to the query, the amount and type of noise being heavily dependent on the statistical queries that users are allowed to execute on the database. This results in a trade-off between accuracy and privacy. In application to recommendation systems, McSherry and Mironov [2009] built a system to achieve differential privacy over the Netflix dataset. Experiments on their system showed that the accuracy of results was not severely effected throughout the query execution by maintaining privacy of user data.

Specifically in the medical domain, one privacy-preserving recommendation system is due to Katzenbeisser and Petkovi  X  c [2008]. The authors developed a system in which a secure medical recommendation is obtained by first encoding all relevant information (symptoms, diseases, etc.) into a standardized binary vector. The system then uses a matching protocol to determine which doctors have the best matching expertise via a secure matching algorithm, with the most suitable result returned as the recom-mendation. This solves a slightly different problem than our solutions, as we match patients with the optimal physicians for their relevant conditions, whereas the system of Katzenbeisser and Petkovic [2008] makes no such guarantees.

Finally, as we codified requirements for privacy-preserving medical recommendation systems, Chen and Williams [2010] codified requirements for privacy-aware social recommender systems. In their architecture, the authors argue that control, choice, and consent are the three main issues when developing a privacy-aware recommendation system. Taking these three issues into account, the authors then suggest adopting the privacy principles put forth by the Organization for Economic Cooperation and Development (OECD), adapting them to the recommendation domain.

It is important to note that our work differs from these publications in a few im-portant ways. First, we describe a framework for medical recommendation systems which was designed to take the sensitivity of medical records into account. This in-cludes the ACA and SPA architectures (Sections 6 and 5, respectively), which provide concrete realizations of the goals set forth in the framework. Second, whereas previ-ous approaches obtain recommendations via collaborative filtering-based approaches, ACA and SPA allow for the computation of real-valued rankings of doctors (while still maintaining patient privacy), resulting in more fine-grained recommendations. These fine-grained recommendations also include the first instance of a description in the lit-erature of a weighted average computation combined with physician X  X  expertise using homomorphic encryption. Furthermore, while privacy-preserving recommendation sys-tems based on secure computation (and homomorphic encryption in particular) exist, the anonymous contributions architecture is unique to this work. In this section, we develop the conceptual model of a privacy-friendly and reliable medical recommendation system by specifying its requirements and functional struc-ture. These requirements will guarantee that patient privacy as well as system and recommendation integrity are maintained. In our framework, we assume that the system maintains a list of physicians and health conditions for which recommendations can be provided. 1 Each contributing patient i submits her rating r ijk for a specific physician j and specific health condition k .Each rating reflects the patient X  X  satisfaction with physician j treating condition k and is selected from a predefined and publicly known range. Without loss of generality, let this range be [1 , n ], with the value of 0 reserved for when no rating is available. The system will securely process or store the ratings to enable the following functionalities for any interested patient.  X  X  patient interested in health condition k should be able to obtain a physician recommendation for the condition based on the aggregated satisfaction information for all patients and all physicians treating the condition. Ideally, the recommen-dation is versatile enough to include alternative best-ranked physicians instead of providing only a single recommended name. That is, let s jk denote the aggregate score for physician j on condition k computed from individual ratings r ijk . (In this work, we use the term  X  X ating X  for individual values contributed by patients and the term  X  X core X  for the aggregate normalized value which is a function of individual contributions.) Then instead of learning the name of physician j with the highest score s jk , the patient will be presented with a list of alternatives.  X  X  patient interested in a combination of health conditions K ={ k 1 ,..., k } should be able to obtain a physician recommendation for the entire combination. Furthermore, the patient should be able to assign different weights v 1 ,...,v to the conditions based on their importance to the patient and obtain a recommendation that takes into account these weights. That is, the output will consist of best-ranked physicians where the ranks are determined using the weighted sum of the physicians X  scores for the individual conditions, weighted by the patient-provided importance values v i  X  X , that is, the combined scores are computed as s jK = i = 1 v i s jk preferred over a single recommendation. When creating a recommendation system, an important consideration is providing users with accurate and relevant recommendations. In our system, we assume that the average rating given to a physician by her patients fits these criteria. Such ratings, however, can be the result of a wide variety of questions (e.g., overall satisfaction, time until cured, etc.), which are outside the scope of this work. When evaluating our sys-tem, we therefore assume that some overall rating for a physician exists. Moreover, we presume the rankings are numeric in nature and have been normalized; this allows us to assume that an average rating makes sense and is consistent across the recommen-dation system. Since none of the solutions presented in this work are reliant on any specific representation or source of scores, this does not affect any of the observations made in the article.

In the rest of this work, we assume that a recommendation is given for a specific condition (or a combination of conditions) and is computed from ratings submitted by patients. That is, patient i who has seen physician j for condition k can submit a rating r ijk on the scale 1 to n .Weuse r jk j on condition k and weight w jk to denote the number of patients who contributed their ratings for physician j treating condition k . In the vast majority of existing recommendation systems, data contributed by users is assumed to be public information. In most cases, this is a reasonable assumption, as user preferences are usually not sensitive in nature. While for most applications public ratings are acceptable, in medical applications they are not. This is due to the fact that even the existence of certain medical conditions is extremely sensitive data which the patient is highly unlikely to divulge. Therefore, expecting users to publicly disclose their opinion for doctors treating the conditions, without any assertion of privacy, is impractical. As such, we believe that recommendation systems which require users to divulge their recommendation (or even its existence) without provable privacy guarantees should be treated with suspicion.

This leads to the first privacy requirement of a recommendation system for medical applications: This also means that if at any point in time the patient X  X  data is revealed to any entity, there should be no link between the patient X  X  identifying information (e.g., name, IP address, etc.) and the data the patient contributed to the system.

Similarly, a user querying the system for a recommendation for a specific condition should not be forced to reveal that condition to the system. This means that the user will be able to obtain a recommendation for a specific condition or a combination of conditions without communicating her preferences to the system in unprotected form. In addition to patient privacy, physicians must also be protected from unreasonable users or dishonest competitors. That is, a small group of users should not be able to sabotage a physician X  X  reputation. This is not limited to the patients whom the physi-cian treats, but also to those who are refused, as well as other physicians competing for the same patients. Protecting against such users has the added benefit of creat-ing a more robust recommendation system, thereby increasing its utility. Thus, the reliability requirement of medical recommendation systems can be stated as follows: This requirement immediately suggests two ways of dealing with dishonest users: malicious behavior can either (i) be prevented or (ii) be detected and compensated for. As with any system that solicits input from a number of parties, each user can enter any rating even if it does not fully reflect her true experience. It is, however, possible to recognize several types of user misbehavior as abuse of the system. For example, a user can influence the aggregate score of a physician treating a certain condition by repeatedly submitting ratings for that physician. A user can also submit a rating which is out of the range (i.e., negative or above n ) which has a larger effect on the physician X  X  score than a single correct rating (since normally the aggregate score is computed as the average of individual ratings). We therefore target a system design that can effectively block these and similar types of system abuse. Given the requirements just presented, we provide two broad classes of architectures which fit the framework. We call the first type the Secure Processing Architecture ( SPA ) and the second type the Anonymous Contributions Architecture ( ACA ). These architectures are described next, including their properties and engineering challenges associated with their realization. Concrete instantiations of the architectures, including implementation, are given in Sections 5 and 6, respectively. In this architecture, as the name suggests, patients contribute secured (e.g., encrypted) ratings, and the computation of all recommendations is performed over secured data. The architecture, depicted in Figure 1, employs secure multiparty computation, where a number of computational servers collect data from patients and jointly compute recom-mendations. While identifying information of patients (who contribute or query data) may be available to the servers running the system, all submitted data is processed in a protected form and is not available to any entity. In the figure, computational servers CS i maintain the system and process patients X  data. A contributing patient can properly secure her contribution and submit it to one or more computational servers. The servers engage in joint computation and make the recommendations available to queriers.
As customary in secure multiparty computation, a threshold scheme is used whereby the computation is performed by p computational servers with threshold t .Insuch schemes, any t  X  p servers are able to successfully carry out or finish the computation, while any number less than t servers cannot learn anything about the data they handle. In this way, the data remains secure assuming that t or more servers do not collude to learn any extra information. To maintain such security, in this framework, the compu-tational servers should be maintained by mutually distrustful or competing entities so that any t of them are unlikely to conspire. For example, the computational servers can be run by (i) competing physician offices or hospitals, (ii) insurance companies, (iii) con-sumer rights protection organizations or programs, or (iv) a combination of these.
In SPA , when a patient submits her secured rating for physician j and condition k , the computational servers should not be able to learn the value of j and k . The easiest way to hide this information is to have the patient submit a (secured) rating for each physician and each condition where only one submitted rating has the actual rating and carries a weight of 1, while all other submitted values have rating and weight 0. The servers will then be able to update the scores for all physicians and all conditions using the data received from the patient without the ability to know which particular value has been modified.

In particular, this can be accomplished as follows: the computational servers main-tain (protected) sums r jk and weights w jk for each valid combination of physician j and condition k (i.e., for each physician j only the conditions that the physician treats are maintained). When a new rating r ijk of weight w ijk is submitted, the sum of ratings is updated as r jk + r ijk and the weight is updated as w jk + w ijk .When r ijk and w ijk are both 0, nothing is modified. The scores s jk can then be computed as the average rating r /w
There are two common techniques for computing overprotected data: 2 (i) encryption with special properties, called homomorphic encryption, which allows for operations on ciphertexts to translate into certain operations on the underlying plaintexts, and (ii) splitting the value to be protected among multiple parties and computing using its shares. Either technique will enable us to perform the computations just outlined, as well as all other computations necessary in computing recommendations. We chose to use homomorphic encryption in our instantiation of this architecture and its prototype implementation (Section 5).

Now notice that in this architecture, the physicians X  scores s jk cannot be revealed because of the privacy requirements. That is, suppose that the computational servers post the scores which patients can use to compute necessary recommendations. Then when the next patient contributes her secured rating to the system and the scores get updated and published, it is likely trivial to find out what value and for which physician and condition the patient submitted a rating. Therefore, the aggregate scores must be protected as well, with only the recommendation data (such as a sorted list of best-ranked physicians) made available.

Because in this setup patients interested in learning recommendations have no impact on the way recommendation data is computed, there is a need to carefully design the function f ( r jk ,w jk ) for computing scores so that it is useful and appeals to as broad of a population of users as possible. We leave it to the community to determine what function is most meaningful for use in medical recommendation systems, but for the purposes of our realization, we propose to compute the scores as a combination of the average rating r jk /w jk and the number of patients treated w jk . That is, set s desired. The purpose of b jk is to let experienced physicians with a large number of patients have some advantage compared to physicians who treated a small number of patients for condition k . The value of m determines how much the extra factor b jk influences the final score, and we propose using nonlinear scale for the value of b jk . which will determine the value of b jk .Weset b jk = b i (that is, place w jk in bucket i )if values of t i  X  X  and b i  X  X  can be set to any meaningful numbers as long as the sequences are increasing and b q  X  m . Since the appropriate choice is not only disease dependent but location dependent as well, we leave it up to the community to determine the bins. ensures that physicians who treated a sufficient number of patients will have the same value for b jk (and thus the average ranking differentiates them), while physicians with a very limited number of visits will have a lower value of b jk , and thus have to be rated more highly in order to rank ahead of their more experienced colleagues.

Given this, a user who would like to learn a recommendation for condition k first obtains a list of the physicians sorted according to their scores s jk (or a sorted list of top physicians only). We note that this outcome sufficiently hides individual contributions, where the physicians X  ratings and the number of patients treated remain private. As secure multiparty techniques are relatively expensive, we suggest having the com-putational servers periodically compute the recommendations for all conditions and make that information publicly availably. In this way, a patient interested in a specific condition is instantly able to obtain the desired recommendation. This also has the added benefit of hiding the recommendation of any individual, as the periodic update, if spaced appropriately, will include a large number of new contributions from many patients. For example, the rankings can be recomputed once a month or less frequently if the number of contributions since the last update is not sufficiently high.
The system X  X  design also allows patients to determine a custom rating based on a combination of conditions (where the combination is to remain private). In such cases, we first note that the number of diseases in a combination will be small, since pa-tients will seek separate specialists for unrelated conditions rather than one physician who can effectively treat all of them. Let u be the maximum number of conditions in commonly queried combinations (e.g., u = 3). Then the following options can be imple-mented within SPA : (i) the servers precompute and make available recommendations for each combination of  X  u conditions for their choice of importance weights or (ii) the servers precompute recommendations for common combinations of  X  u conditions and compute recommendations for other combinations upon user request (note that the re-sults cannot be saved for any subsequent user to immediately obtain since the queried conditions are private). While the first option results in a higher load on the compu-tational servers (as the number of all possible combinations grows rapidly, i.e., O ( n u c ) for n c conditions), the second requires patients with nonstandard queries to experience delays. Also, combinations with nonstandard weights will result in custom queries in both cases. In addition, while the choice of the conditions in a queried combination can be secured, the recommendation given to the querier (i.e., a sorted list of physicians) is likely to leak some information about the conditions. Thus, precomputed recommenda-tions where a patient can retrieve information about all conditions at once is preferred from the patient privacy point of view.

In order to satisfy the reliability requirements of the framework, abuse of the sys-tem can be prevented using the following mechanisms. Each contributing patient can be required to submit only one rating r ijk at a time. This allows the computational servers to detect an abnormal number of contributions from a particular user, treat the contributions as malicious, and disregard them. Additionally, when a patient sub-mits a rating, she will have to prove that the submission is well formed. This can be done through Zero-Knowledge Proofs of Knowledge (ZKPK), which prove the validity of certain statements over secured data without revealing any other information. In this application, the patient uses ZKPKs to prove that (i) all submitted pairs ( r ijk ,w ijk ) except one are set to 0, and (ii) there is weight w ijk of value 1 and the corresponding rating r ijk is in the range [1 , n ]. ZKPKs for all necessary functions, such as OR, AND, equality, and a range, are known and can be combined to prove the overall statement. We provide additional details in Section 5.3.

While designing a specific system using SPA , it is important to realize that there is a trade-off between privacy and computational overhead on one side and data reliability on the other. That is, instead of submitting n p i = 1 n j pairs, where n p is the number of physicians (who are numbered 1 through n p )and n j is the number of conditions physician j treats, to contribute a single recommendation, a patient might choose to submit fewer pairs for a subset of physicians and/or conditions. This might allow the computational servers to reduce the patient X  X  physicians or conditions to a smaller set, but reduces the patient X  X  computational overhead of sending a rating. This will also allow the computational servers to more effectively detect abuse of the system by dishonest users who repeatedly submit ratings for the same physician. In this architecture, unlike the prior approach, the patients submit their ratings in the clear. In order to ensure that there is no connection between a patient X  X  identifying information and her contribution, all submissions are made anonymously. That is, patients use a system for anonymous routing to submit their contributions to the entity that receives all patient ratings and publishes information about them. Such anonymizer systems are readily available today (see, e.g., Tor anonymity network 3 and other anonymizer services and proxies such as Anonymizer, Inc. 4 and ShadowSurf 5 , among many others).

With this design, we can achieve the privacy requirements listed in Section 3. That is, the privacy of a patient who submits a rating r ijk for physician j and condition k is not compromised because the recommendation system service learns no information about the user X  X  identity and thus is unable to make any inferences about the health history of any particular patient. The service then processes all received ratings and makes aggregate information about the ratings available to all parties to use. This means that the privacy of all patients who would like to use the system is protected, as they can download the entire published table (i.e., information about all conditions) posted by the recommendation service and then disregard any irrelevant data. Alternatively, such users can use an anonymizer and retrieve only information about specific conditions from the published data.

To make the recommendation data available to the patients at least as flexible as in SPA , we suggest that the recommendation system service publish the following information: for each physician j and condition k , publish a pair r jk /w jk , b jk , where as before, w jk is the number of patients that contributed their rankings for physician j and condition k , r jk /w jk = i r ijk /w jk is the average rating for physician j and condition k ,and b jk is the bucket value for w jk . Availability of such data satisfies the functional requirements of Section 3. Furthermore, the data provides more information than the recommendations in SPA , as not only the ordering of physicians by their scores is known, but various other relevant information (e.g., the differences between the scores) can be computed as well. In particular, a patient can compute a recommendation for any combination of conditions using custom weights.

With respect to the reliability requirements, the anonymous nature of a patients X  sub-missions can make the system prone to abuse. That is, dishonest users might attempt to influence a physician X  X  overall rating by submitting bogus or repeated values. While it is trivial to defend against the former (i.e., all ratings are submitted in the clear, thus out-of-the-range or malformed values are immediately discarded as invalid), dealing with the latter requires architectural support. To aid this issue, it can be beneficial to split the recommendation system service into two entities, called the Certification Authority (CA) and the Tabulating Authority (TA). 6 The responsibility of the CA is to manage users, while the responsibility of the TA is to collect, process, and publish recommendation data.

The CA first registers users, issuing them anonymous credentials at the time of registration. Thus, users are required to register prior to submitting ratings to the TA. A registered user can then send her rating to the TA and authenticate the submission using her anonymous credentials issued by the CA. We note that the authentication is anonymous in the sense that the only information revealed is that the user has been registered with the CA and is authorized to submit a contribution. In particular, the TA (or any other entity) is unable to tell whether any two contributions have been made by the same or different users.

By using a type of anonymous authentication which allows for enforcement of access control policies, abuse of the recommendation system service can be mitigated. That is, if at the time of submission the TA verifies that the (anonymous) user is authorized to submit a rating for physician j and condition k , the contribution will be accepted. For this type of system, we consider two policies: (i) a bound on how many ratings a user is authorized to submit for a single (physician j , condition k ) pair and (ii) a bound on the total number of submissions by a user. This will ensure that a single user cannot alter the aggregate score of a particular physician beyond a normal use and that a single user cannot have a significant impact on the system as a whole. We develop two realizations of ACA that support enforcement of both of these policies. The first is based on one-time-use credentials that the TA can update and reissue after each submission and which use new zero-knowledge proof techniques (detailed in Section 6.2) and the second is based on the novel use of electronic cash, which has a natural support for a distributed TA (detailed in Section 6.3).

Finally, because new users normally contribute for the first time shortly after their registration, we would like to prevent the CA from making correlations between the users that register and the content of the messages transmitted to the TA over the network. For that reason, we assume that the TA has an encryption key and all con-tributions sent to the TA will be encrypted with that key. Furthermore, to prevent the CA from making similar correlations based on the updated information that the TA publishes, the updates by the TA to the published data should be infrequent, only after a significant number of new contributions (which will include contributions by both old and new users) has been accumulated. Note that this is not a major restriction of the system, as a small number of updates are unlikely to drastically affect the ratings of the physicians. Also, in the event that a malicious party conspires with a number of users or is able to obtain background knowledge about some of the ratings, the party will be able to reduce the set of observed changes in rankings between periodic updates to the remaining populace of the system.

The ACA architecture is depicted in Figure 2. A contributing patient interacts with the CA only during registration, and at that time, she is issued anonymous credentials. The rest of interaction occurs with the TA (which can be distributed and consist of multiple entities), and any querier would need to access only the published data. De-pending on the realization of this architecture, there may or may not be direct periodic communication between the CA and the TA to validate credentials used in patients X  submissions. Recall that the functional requirements of the system are met with this architecture since, given the published scores, a querier will be able to determine a ranked list of physicians for both individual conditions and a combination of conditions using weights of his choice. In this section, we describe our particular realization of SPA . We first present the necessary background information, then define the full protocol, and conclude the description with a system implementation.
 As previously mentioned, techniques for implementing data protection in SPA include homomorphic encryption and secret sharing. In our solution, we use a semantically secure additively homomorphic public key threshold encryption scheme as a building block. The additive homomorphic property of such encryption schemes means that when one multiplies two encrypted messages, the result is a ciphertext that corre-sponds to an encryption of the sum of the messages. This property also implies that an encrypted message can be multiplied by a constant c by raising the ciphertext to power c . Semantic security means that no information about the underlying text can be learned from a ciphertext.

Recall that in a threshold public key encryption scheme, anyone can encrypt using a public key, but decrypting values requires at least t out of p computational servers (for some t  X  p ) to combine their keys to decrypt the value. In order to provide more security, we require the ability to generate the key material used in homomorphic encryption (i.e., the encryption and decryption keys) in a fully distributed manner. This requirement removes the need for a trusted party who has access to more data (i.e., the full key material) than anyone else. This is especially important in the current application, as this means that the security of each patient X  X  data is not dependent upon any one party.

One scheme that encompasses these properties is the Paillier cryptosystem [Paillier 1999], which we use in our implementation. The Paillier cryptosystem is a semantically secure additively homomorphic encryption scheme which can be used as a threshold scheme [Fouque et al. 2000; Damg  X  ard and Jurik 2001] whose key generation can be performed in a fully distributed manner [Boneh and Franklin 1997; Damg  X  ard and Koprowski 2001].

In what follows, we use [ a ] to denote an encrypted value of a . With the techniques we employ, some operations on encrypted values (such as addition and multiplication by a constant) can be performed locally, while other operations (such as multiplication or comparison of encrypted values) require interaction of the computational servers. Furthermore, comparison requires the operands to be available in bitwise form, which means that an encrypted value first needs to be transformed into encryptions of its bits. We use [ a ] B to denote encryption of the individual bits of a ,thatis,[ a ] B = [ a explicit in the notation to permit a variable-length representation). It follows that our solution will need to rely on the following subprotocols from the literature (see, e.g., [Hoens et al. 2010a; Schoenmakers and Tuyls 2006; Bunn and Ostrovsky 2007]).  X 
MULT . A protocol that, on input [ a ]and[ b ], produces [ a  X  b ]. This is the simplest protocol that in our setting relies on additive splitting and additively homomorphic encryption. At a high level, the idea consists of splitting the (encrypted) second operand [ b ] into random additive shares b i such that b = i b i and making share b i available to the corresponding server i in the clear. Multiplication is performed by each server on its own share using the homomorphic properties of the encryption scheme to obtain [ a  X  b i ], after which the server assembles the product [ a  X  b ]inthe encrypted form.  X  b = 1 if and only if a 1  X  a 2 . For this functionality, we rely on the implementation described in Hoens et al. [2010a], in which the bit b is computed in the encrypted form from the (encrypted) bits of a 1 and a 2 by using a formula that consists of a number of additions, multiplications, and XOR operations. Since the XOR operation can be realized in terms of arithmetic operations as x  X  y = x + y  X  2 xy , the overall complexity of this protocol is dominated by O ( ) multiplications MULT .
  X 
BITS . A protocol that, on input [ a ]and , produces encryption of least significant bits of the underlying plaintext of [ a ], that is, [ a ] B . In this work, we utilize the protocol from Schoenmakers and Tuyls [2006], which has complexity proportional to random encrypted bits, and add and compare bit-decomposed values in encrypted form. In the description of the protocol, for simplicity of presentation, we assume that physi-cians 1 through n p are used to produce recommendations for any given condition k (in practice, some physicians with specializations far from condition k can be eliminated).
At a high level, the computation in the protocol proceeds as follows: first, for each physician, we compute her score s jk from the corresponding (aggregate) rating ( r jk , w jk ). This means that the weight as t i ?  X  w jk . After the results of the comparisons are available in the encrypted form as a binary vector of length q , we set the encryption of b jk to the sum of computed bits in the vector, where bit i is weighted by the value b i  X  b i  X  1 (and by b i when i = 1). Because the computed vector will always consist of a number of 1 X  X  followed by a number of 0 X  X  (if any), this approach computes the value of the bucket b jk correctly. This mechanism minimizes the amount of interactive computation and thus the amount of time for the computation.

As a result of this step, we store s jk as a numerator-denominator pair ([ s jk ] , [ w jk ]) = ([ r the scores without performing expensive division operations. That is, to compare the scores of two physicians j 1 and j 2 , we compare s j
This computation raises an interesting technical point in that the comparison must be performed correctly even if one or both of the scores have no contributions and are there-fore 0. That is, if a physician j 1 has no ratings for condition k , both r j thus s j physician is being compared to the score of another physician who has a patient ratings, both values being compared will become 0, and the resulting outcome (as defined by the comparison protocol) is random. To ensure that the result of such comparisons is always correct, we modify the computation to add a flag which indicates whether w jk is nonzero. That is, the comparison becomes s j output of nonzero( w jk ) is true (or 1) if and only if the OR of the bits of w jk is 1. In the protocol, we denote this additional function by OR ([ w jk ] B ), which will produce an en-crypted bit. Notice that the function is not difficult to implement using a number of multiplications and additions.

An important observation is that this modification does not affect other comparisons in the system, that is, when physicians j 1 and j 2 have ratings for condition k , s j 1  X  s no ratings, the result is unchanged.

In the protocol, we use various optimizations to ensure that its runtime is as low as possible. In particular, we use varying-length representation in bit decomposition BITS and comparison BIT -LE operations. Let w denote the maximum length of counts w jk , s denote the maximum length of scores s jk are in the range [1 , n ] and the bucket values in the range [1 , m ], s = log 2 ( n + m ) ), and = 2 w + s the maximum length of values used in the computation (i.e., for representation of s j w = 13, and s = 6.

To optimize the performance of comparing weights w jk to the thresholds t i ,notice that the weights w jk can generally be longer than a value t i , but by considering only representation of w jk , we leave the log 2 t i least significant bits of w jk unchanged and replace the remaining bit with the OR of the remaining w  X  log 2 t i most significant bits of w will always result in w jk being larger than t i ; otherwise the comparison proceeds as usual. When considering performance, note that such shortened representations of w jk for the lengths of t i  X  X  can be computed using O ( w ) multiplications, regardless of the number of thresholds q .

The preceding optimization due to the variable-length representations allows us to reduce the runtime of the protocol by at least 40%. We are now ready to present the protocol.
 R (1) The computational servers set  X  1 = b 1 and  X  i = b i  X  b i  X  1 .For j = 1 ,..., n p they In this protocol, step 1 corresponds to computing ratings for each physician-condition pair. In particular, we first bit-decompose each weight w jk in step 1(a), compute short-ened representations of each bit-decomposed w jk for performance reasons (by ORing the most significant bits which are being eliminated), as well as store the OR of all bits of w jk in f jk in step 1(b). The shortened representations allow us to faster compare (bit-decomposed) weights w jk to the thresholds t i in step 1(c), from which we compute the appropriate bucket values b jk in step 1(d), and by the end of step 1 form ratings in the form s jk ,w jk , f jk , where s jk = s jk + b jk w jk and f jk = nonzero( w jk ).
Step 2 sorts all rating tuples for each physician-condition pair, where a rating is during steps 2(a) and 2(b), bit decomposed in step 2(c), and compared to other ratings in step 2(d). The resulting ordering of ratings (i.e., physicians X  rankings) is made public.
Note that in the preceding protocol, the exact sorting algorithm is not defined. For our implementation, we chose merge sort due to its simplicity, speed, and ease of being parallelized. The results are presented in the next section.

It is not difficult to show the security of the R ANK protocol based on a standard definition of secure multiparty computation (see, e.g., [Goldreich 2004]). In particular, security in this context means that a protocol execution does not leak any information about the data being processed other than what can already be deduced by a partici-pating party from its inputs and outputs alone, as intended. In our case, the security follows from the fact that only secure building blocks are used, and the composition theorem [Canetti 2000] that states that composition of secure building blocks results in security of the overall construction. Because the computational servers carrying out the protocol can be assumed to comply with their prescribed functionality, it is sufficient to use building blocks secure in the semi-honest model (in which the servers follow their prescribed computation, but might try to learn additional information about the data they handle). This would significantly improve performance of the solution com-pared to the setting where the computational parties are fully malicious (and thus can arbitrarily deviate from the protocol or disrupt the computation).

To permit users to obtain recommendations for a combination of conditions K ,we briefly discuss the modifications to the preceding protocol for two options: (i) the servers pre-compute the recommendation for conditions K using their choice of importance weights v i  X  X  for the individual conditions in K and (ii) a patient asks the servers to compute a custom recommendation for her choice of conditions and corresponding weights which are to remain private. In the first case, the servers perform step 1 of the preceding protocol as specified for all physicians and all conditions in K . Then, for each physician j with scores ([ s jk ([ s form. Note that this computation uses only multiplications and additions but results in values of larger length, which has an impact on the performance of sorting in the protocol. Given such scores, step 2 of the protocol is then carried out unchanged using larger bit length.

To implement case (ii), the patient encrypts her weights v i for conditions k i in K .If the patient does not wish to reveal any information about the conditions in K , she can include all possible conditions and assign an importance weight of 0 to the irrelevant conditions. This will incur a significant overhead on the computational servers and unbearable wait time on the patient. To reduce the runtime, the patient instead can use only a few extra conditions in K to hide the ones in which she is interested. While this significantly reduces the computational overhead, this approach also leaks information about the patient X  X  conditions of interest. (Note that the query result also may leak information.) The rest of the computation then proceeds as with option (i) with the exception that the weights v i are processed encrypted. Prior literature provides efficient zero-knowledge proofs of knowledge (ZKPK) for a variety of statements, with several efficient proofs for encrypted values and the Paillier encryption scheme in particular (see, e.g., [Damg  X  ard and Jurik 2001; Baudron et al. 2001; Cramer et al. 2001; Lipmaa et al. 2002]). Camenisch and Stadler [1997] introduced notation for various proof of knowledge, and we adopt their notation to our context. For example, we use to denote a ZKPK of knowledge and equality of the plaintexts corresponding to the ciphertexts A and B . The variables in the parentheses are not known to the verifier, but certain statements about them are being proved in zero knowledge. For the purposes of this work, we rely on the following ZKPKs from prior literature.  X  Proof of Plaintext Knowledge , Denoted P K { (  X  ): A = [  X  ] } . Such proofs have been developed in Damg  X  ard and Jurik [2001] and Baudron et al. [2001].  X  Proof that a Ciphertext Encrypts a Given Value , Denoted P K { : A = [ v ] } . This proof can be executed as the preceding proof of plaintext knowledge followed by opening the plaintext value or by revealing the random coins used during ciphertext generation.  X  Proof that a Ciphertext Encrypts One Value from a Given Set , Denoted P K { (  X  ): A = [  X  ]  X   X   X  S } . Such proofs can be found in or follow from the techniques of Damg  X  ard and Jurik [2001] and Baudron et al. [2001].  X  Proof of a Random Permutation (Shuffle) of a Set of Ciphertexts , Denoted P K { (  X  ): that it is not feasible to link a ciphertext from the initial set to a ciphertext in the per-muted set. Such proofs have been developed (e.g., [Peng et al. 2005; Groth and Ishai 2008; Peng and Bao 2010; Groth 2010] among others). Groth and Ishai [2008] pro-vide the first solution with a communication complexity that grows sublinearly with the number of ciphertexts in the shuffle. Peng and Bao [2010] provide the first solu-tion to achieve perfect zero-knowledge. We provide a comparison of computation and communication costs of selected solutions from the literature for Paillier-encrypted values in Table I. The costs in the table are functions of the size u of the set being permuted, the work is measured in modular exponentiations, and the communica-tion cost shows the dominating term. In the table,  X  1 denotes a security parameter that determines the ciphertext length (i.e., the RSA modulus length), and  X  2 is a cor-rectness parameter for interactive proofs (where applicable), where the probability 2  X  1 . While Groth [2010] introduces several shuffling schemes, we list in the table the scheme for shuffling known contents.

The overall statement that a user will need to prove in zero knowledge when sub-mitting a rating r ijk in our solution is as follows.
 and ( B 1 , B 1 ) ,..., ( B u , B u ). She then shows that A 1 corresponds to an encryption of a w ijk ), and that the remaining ciphertexts encrypt 0. The user then randomizes and permutes the ciphertexts (preserving each pair) so that the pair ( A 1 , A 1 ) is placed in the location corresponding to physician j and condition k within the set of permuted ( B conditions. Each user X  X  contribution thus involves work (measured in cryptographic operations) linear in u = n p j = 1 n j with a low constant and can be substantially lowered if less stringent privacy guarantees are acceptable to the user.
 To test the feasibility of the R ANK protocol, which is periodically executed by the com-putational servers, we implemented it in Java using Paillier encryption with a 1024-bit key. Java was chosen due to its large number support and the ease of implementing distributed algorithms. All subprotocols (i.e., BITS , MULT , BIT -LE ) were implemented, as in Hoens et al. [2010a].

As the computations were distributed, we simulated each computational server as its own PC on a 100Mb LAN. The computers used were Dell workstations with 3.20 GHz Pentium 4 processors and 1 GB of memory. To make the tests more general and ap-plicable to a wider range of settings, we tested the computation separately in the two steps of the R ANK protocol. By presenting timing results for each step individually, we provide the ability to estimate performance of the protocol on a variety of different parameters (e.g., number of bits in each t i , number of buckets, etc.).

To test step 1, we varied the length of bucket thresholds t i used in determining the value of b jk . Specifically, we timed step 1 using thresholds of size 2, 5, 10, 15, and 20, as measured in bits. Note that the higher threshold sizes on this list are present only to demonstrate how the techniques scale to larger values, as they are unlikely to be applicable to a recommendation system in practice. We also varied the number of physicians in the experiments using 5, 10, 20, 50, 75, and 100 physicians. Given this, we provide a good estimate as to how long it would take to compute the scores for a specific number of physicians given an arbitrary number of buckets (with thresholds of varying sizes).

To test step 2, we timed how long it took to sort the various number of physicians when each was given a randomly assigned score and weight. The length = 32 was used for bit decomposition and comparison. Combining this with the results obtained from the timing of step 1, we can then estimate how long it would take to compute the full protocol.

The data used when measuring the timing results was simulated. The use of sim-ulated data does not adversely affect the timing results obtained, as the performance only depends on (i) the number and size of thresholds t and (ii) the performance of the sorting algorithm (as measured in the number of comparisons). The former is in-dependent of the data, and the sorting algorithm is not dependent on how the actual underlying data was obtained. Instead the number of comparisons required is the most important factor when timing the protocol. To ensure that the simulated data accu-rately reflected a real world scenario, we generated a sorted list of unique rating/weight pairs. We then permuted this list randomly, ensuring that the sorting algorithm had to perform the average number of comparisons to sort the list. This process was then repeated to determine the average time required to sort the list.

The results for step 1 are presented in Table II. In this table, the number of physi-cians is represented vertically, while the number of bits in threshold t i is represented horizontally. To estimate the performance for thresholds t , one first chooses the row cor-responding to the number of physicians (e.g., 5). One then chooses the columns which correspond to the number of bits in each t i . Thus, if buckets are defined by thresholds 3, 16, 31, 100, 520, and 1 , 000, the columns selected correspond to 2, 5, 5, 7, 10, and 10 bits, respectively. Note that this example is given for demonstration purposes only and is not meant as suggested values for t i . Given these columns, the approximate timing is obtained by adding the denominator for the first threshold, and the numerator for the remaining thresholds. The denominator represents timing for running step 1 of the protocol using a single threshold of the specified size and the numerator corresponds only to a single comparison with a threshold (of the specified size) in step 1(c) of the protocol. Thus in our example, we have 524 + 381 + 381 + 428 + 499 = 2212 seconds (approximately 36 minutes) for step 1 (using the same thresholds for 100 physicians requires approximately 12 hours).

In practice, we suggest using thresholds t = (0 , 3 , 5 , 10 , 20). While a practicing physi-cian is likely to treat a significantly larger number of patients, the number of users who contribute to a recommendation system is likely to be significantly lower. There-fore, even a few patient ratings indicate significant experience in treating a particular condition. In this example, the largest threshold uses only five bits.

The performance of step 2 is presented by the lower curve in Figure 3. We see that the amount of time spent sorting 100 physicians is quite high (approximately 1 day). Note, however, that this computation needs to be done quite infrequently (e.g., semi-annually or quarterly), as the score for a doctor is not expected to be highly volatile. As previously mentioned, this also has the added benefit of providing more security for each of the users, as the wider the spacing between updates, the less likely that any one recommendation will be recognized.

The upper curve in Figure 3 shows the results of the overall R ANK protocol. The difference corresponds to the runtime of step 1 using the five suggested threshold values. As we can see from this figure, the bucket computation time decreases in significance when compared to the amount of time used for sorting as the number of physicians grows. This is to be expected, as the sorting algorithm requires more comparisons than the bucket computation.

Finally, we note that while Paillier encryption is well known and commonly used in secure multiparty computation protocols, recent progress shows that additively homomorphic encryption schemes can result in significantly faster performance. In particular, Damg  X  ard et al. [2008b, 2008a] provide an encryption scheme with shorter ciphertext size and faster encryption, decryption, and operations on ciphertexts. The scheme supports plaintext of small size and was originally developed for computing on encrypting bits. Blanton and Gasti [2011], however, used the scheme for a general-purpose computation (using the plaintext size comparable to the values used in this work) and showed a performance gain by about an order of magnitude on average compared to Paillier encryption. A threshold version of the scheme was not provided by the authors, but it shows the feasibility of significant computation speedup of this type of computation in the near future. Similar to the previous section, here we describe our realization of ACA .Wefirst present the background information and then proceed with a description of two possible implementations of this architecture. 6.1.1. Signature with Protocols. For this architecture, we make use of Camenisch-Lysyanskaya (CL) signatures, or signatures with protocols [Camenisch and Lysyanskaya 2002, 2004]. As customary for signature schemes, a signature scheme consists of key generation, signing, and verification algorithms, which we define at high level as follows.  X 
SETUP . On input a security parameter  X  , creates and outputs a public-private key pair ( pk , sk ).  X 
SIGN . On input message m and private key sk , produces signature sig sk ( m ).  X 
VERIFY . On input message m , public key pk , and signature sig sk ( m ) outputs 1 if and only if sig sk ( m ) is a valid signature on m under the corresponding private key sk . What, however, distinguishes these CL schemes from ordinary signature schemes is that they come with additional protocols. Using the preceding schemes, it is possible to obtain a signature on a committed message m without disclosing it to the signer. In this case, a commitment to message m , denoted com ( m ), should be such that it hides the value of m (hiding property), but given com ( m ), it is infeasible to create another message m = m that matches the commitment com ( m ) (biding property). The Pedersen commitment scheme [Pedersen 1991] is commonly used with CL signatures for this purpose. We define the ability to sign committed messages by overloading the signing algorithm with an additional capability as follows.  X  SIGN . On input commitment com ( m ) and private key sk , produces signature sig sk ( m ). To be more precise, in this type of commitment, information about m is unconditionally (or information-theoretically) protected, which means that that regardless of how many values an adversary tries, she will not be able to learn information about the message included in the commitment. This is achieved by using randomness that protects the value of m . For that reason, a commitment to message m can be expressed as com ( m ; r ), where r explicitly defines the randomness used to form the commitment. Then, during signing, this randomness is used to form the signature, which more correctly should be defined as a signature on two messages, m and r , where as before, r protects m . More generally, a signature can be formed on any agreed upon number of messages m 1 ,..., m k , and we denote the corresponding signature by sig sk ( m 1 ,..., m k ). Similarly, one can commit to several messages m 1 ,..., m k in a single commitment, which we denote by com ( m 1 ,..., m k ; r ). Then by invoking the signing algorithm, one can produce a signature sig sk ( m 1 ,..., m k , r ) from that commitment. Because in our case, we always want the messages in a signature to be unconditionally protected (so that the signature can be consequently used without leaking any information about the values that it contains), we assume that the last message in a signature is always a random value and is not explicitly included in our notation. In other words, we, for instance, use notation sig sk ( m 1 , m 2 ) to denote a signature on three messages m 1 , m 2 , and implicit r . Similarly, we omit randomness from commitment notation.

Using these signature schemes, it is also possible to prove knowledge of a signature on a message in zero knowledge (i.e., without disclosing any information about the message itself or revealing the original signature). We denote this functionality using the notation for ZKPKs as follows.
 Similarly, for a signature on multiple messages, we use notation This property is achieved by randomizing an existing signature in such a way that the randomization process does not invalidate its verifiability. This is necessary to ensure that each time a signature is used in a ZKPK, it will appear differently and cannot be linked to the past uses of the same signature in previous invocations of the same or different protocols. The preceding proof can be combined with other statements about the message(s) contained in the signature. For instance, the statement proves two properties of the messages contained in a signature, namely, an inequality (or range) statement and a linear equation, solutions to both of which are known. In fact, we utilize both range proofs and proofs of linear relationships in our solution using the techniques of, for instance, Boudot [2000] and Camenisch and Stadler [1997], respectively.

In this context, the term anonymous credentials is used to refer to a signature issued by a certain authority on specific attributes that will allow the signature owner to anonymously prove certain statements about her attributes and obtain privileges based on such credentials.

In what follows, whenever the key is understood from the context, we omit it from the notation and, for instance, use sig ( m ) instead. 6.1.2. Other Tools. In our solution, we also utilize Tor anonymizing network, 3 which patients use to submit their contributions anonymously. In Tor, a message is routed through a number of participating hosts in such a way that each host knows only from what machine the message arrived and to which it should be sent next, but no other information (i.e., only the first Tor host will have information about the source and only the last one about the destination). This is achieved by multiple layers of encryption which are removed as the message moves through the network.

In ACA , the patients submit their information in an encrypted form. The easiest way to achieve this is to employ standard tools, such as the widely used SSL/TLS suite [Dierks and Allen 1999; Dierks and Rescorla 2006, 2008]. Therefore, we assume that the TAs support the means of establishing secure channels via SSL which the contributing patients can use.
 6.2.1. Description of the Technique. Blanton [2008] describes a mechanism for anony-mous online subscriptions that relies on anonymous credentials and mitigates abuse of anonymity. While anonymous credentials based on CL signatures can be used to en-force proper access control (e.g., by verifying the type of subscription and the fact that a subscription X  X  expiration date is in the future), they are prone to abuse by dishonest parties in that copies of the same subscription are valid credentials themselves which cannot be identified or linked to each other. Blanton [2008] proposed a mechanism in which chained one-time credentials are used for anonymous access. The idea is that at the registration time, a user obtains a CL signature on credentials as usual, but the signature also contains a randomly chosen message not known to the server. At the time of access, the user reveals that message to the server, who verifies that it has not been used before and verifies (in zero-knowledge) other credentials of the user. If the verification succeeds, the server grants the user access and reissues the anonymous credentials in the form of its signature on a new randomly chosen by the user message (not known to the server) and the remaining user credentials. With this design, there can be at most one chain of successful authentications to the server per user, which means that if the user duplicates her anonymous credentials and distributes them to other user, she denies herself access to the service. We build our first solution on this mechanism and propose novel zero-knowledge verification techniques that signif-icantly improve the efficiency of the solution compared to what is readily available today.

As previously mentioned, the conditions that should be checked in our system include a bound on the number of times a participant can rank a specific physician for a specific condition and a bound on the overall number of contributions to the system by a participant. Because at the time of rating, a patient submits in the clear both the physician and the condition for which she is rating the physician, it is trivial to ensure that a patient does not rate a physician for a condition that that physician does not treat. Similarly, because the rating itself is submitted in the clear, it is easy to verify that the rating is indeed from the correct range [1 , n ]. We, however, would like to enforce the limit on the number of times an individual submits rating for physician j and condition k that the physician in question does treat, to ensure that the physician X  X  score cannot be influenced by dishonest participants. For the same reason, we enforce the limit on the total number of contributions by a patient. We denote these two values for individual physician-condition and total contributions by c imax and c tmax , respectively.

Using anonymous credentials built from CL signatures, this can be achieved by issuing to a patient a signature on counts c jk = c imax for each valid (physician j , condition k ) pair and the count for the overall number of contributions c = c tmax at the registration time. Then during each submission, the TA learns the pair ( j , k )and rating r ijk that the (anonymous) patient intends to submit. Before accepting the rating, the TA verifies that indeed both counts c jk and c in the user X  X  credentials are greater than 0 (without learning any other information about them) and if the check succeeds, modifies the credentials by decrementing both c jk and c by 1 (once again, without any knowledge of their values) and accepts the rating. Because each credential can be used only once, the patient will be forced to consequently use the modified credential, thus complying with the policy that limits both the number of contributions per physician-condition and the number of total contributions by an individual.

This solution, however, suffers from inefficiency. In particular, a participant X  X  credential consist of a signature on n p i = 1 n j + 2 messages, where n j is the number of conditions that a physician treats. While a signature itself is compact and of constant size, proving that counts c jk and c are above 0, however, involves work linear in the number of messages. In other words, the first step of proof of knowledge for known i and j , is to show that A is a valid signature on u messages, which requires u modular exponentiations for both the prover and the verifier. We, however, ideally would like to have a patient X  X  work during submission of a single rating to be independent of the total number of physicians and conditions in the system.
To mitigate the problem, we propose packing several counts into a single message, which can significantly improve the efficiency of the necessary proofs of knowledge. To the best of our knowledge, this is the first time packing is used in signatures and zero knowledge protocols despite the popularity of such protocols. In detail, because each count can be represented using only a few bits and a signature can be issued on a message of significantly larger length, we combine several counts into a single message. Let ic denote the number of bits used to represent a count for an individual physician and condition and tc denote the number of bits used to represent a count for the total number of contributions. In our case, it is sufficient to set ic = log( c imax + 1) (i.e., to be able to represent values between 0 and c imax )and tc = log( c tmax + 1) , which will be justified later. Because the maximum number of contributions by a single user per physician and condition should be kept very low, we do not anticipate values greater than2tobeusedfor ic .Let q denote the maximum length of messages that can be signed using a CL signature scheme. For typical implementations, we expect q to range from 160 to 200. With our solution, we then pack q which reduces the total number of messages included into a signature by a factor of 80 X 100. For simplicity, the count for the total number of contributions c is included as an individual message.

We obtain that at high level, the (ZK) proof that a patient will need to execute at the time of submitting her rating can be expressed as follows.
 show how this functionality can be realized. 6.2.2. The Protocol. Prior to any data submission, the CA runs the SETUP algorithm of a CL signature scheme and announces the public parameters and key pk of the system. Additionally, each entity serving the role of the TA publishes her public key which enables the patients to establish secure communication channels with them. Public parameters of the system also include values c imax , c tmax , ic , tc , and the number of individual counts c jk per signature message n m = q (1) User U computes com ( m ) for a randomly chosen value m of bitlength q and sends it (2) The CA produces additional messages to be included in U  X  X  credentials by setting (1) When user U would like to submit rating r ijk for physician j and condition k , (2) U prepares a commitment com ( m ) to a randomly chosen message m of bitlength q . (3) U randomizes her credentials sig sk ( m , m 0 , m 1 ,..., m u ) and sends them and com ( m ) (4) U and the TA engage in a ZKPK during which U opens the first message, m ,inthe (5) Upon successful verification of the ZKPK and the fact m has not been previously Security and privacy of this interaction follows from the properties of the building blocks we use. In particular, the use of CL signatures and Pedersen commitments un-conditionally hides information that could be used to identify the users and ensures that each interaction is unlinkable to prior interactions of that user with the TA. Fur-thermore, unforgeability of signatures and security of zero-knowledge proofs ensures that a user cannot bypass the verification process without valid credentials, and by our protocol design, duplication of user credentials is not possible.

While the protocol for SPA required results from secure multiparty computation, this solution relies on CL signatures and secure communication with anonymous routing. Since the amount of required computation is low, we do not provide the results of a sample implementation, that is, computing scores by the TA incurs minimal overhead (no cryptographic operations). Similarly, retrieving scores and computing recommen-dations by queriers does not involve cryptographic operations either. Submitting a rating involves the number of cryptographic operations on the order of u ,whichwith our packing technique is not going to be high and can be performed in real time. 6.2.3. Proofs of Knowledge. In this section we focus on implementing a ZKPK of the form ( a &lt; X  mod B 1  X   X  mod B 2  X  b ) given a signed  X  , which is used in our protocol (and it is known how to implement the remaining portions of the overall zero-knowledge proof ). First of all, this statement can be decomposed into the following expression, where each clause can utilize a single proof technique.
 Proof techniques for all of these statements are known (namely, a proof of knowledge of a signed value, a range proof, a proof of linear relationship of variables, and a conjunction of proofs), with the exception of a proof of equality modulo a certain value. The latter is therefore the focus of this section.

An expression of the form  X  =  X  mod B can further be decomposed into a statement The difference is that the former expression uses a range proof, while the latter uses a set membership proof which will be more efficient for small B . We, however, design a proof of knowledge of a statement  X   X   X  (mod B ) , which has the cost of a single equality proof and therefore is more efficient than the preceding. Such a proof might also be of independent interest for other applications. With this type of proof, one can prove the statement  X  =  X  mod B as (  X   X   X  (mod B ))  X  (0  X   X &lt; B ).

Now we are ready to proceed with the proof that allows the prover to convince the verifier that  X   X   X  (mod B ) for unknown  X  and  X  in zero knowledge. As customary in the related literature, our solution is based on discrete logarithms. Informally, this means that the values about which we would like to prove a certain statement appear in the exponent. This is true for both commitment and signature schemes that we use. More formally, let G be a group of prime order p and g 1 and g 2 be generators of G . Then, for instance, with the Pedersen commitment scheme, commitment com ( m )to m  X  Z p is in G , i.e., use modular arithmetic). The CL signature schemes that we use also have a similar form. For that reason, we next describe a proof in which on input y 1 = ( g 1 ) x 1 and y 2 = ( g 2 ) x 2 , the prover shows that x 1  X  x 2 (mod B )for B &lt; p . It should be understood that we describe the proof in this form for simplicity of repre-sentation, and it achieves significantly weaker zero-knowledge guarantees than what our solution achieves. In particular, this proof is zero-knowledge in presence of a com-putationally bounded verifier and when x 1 and x 2 are large (i.e., the verifier cannot solve the discrete logarithm of y 1 to the base g 1 or of y 2 to the base g 2 and is also unable to brute force a significant portion of the overall space for  X  and  X  ). A better option (which is used in our solution) is to use a signature or commitment where the values x 1 and x 2 are information theoretically protected, for example, In this case, the proof becomes zero-knowledge in presence of a computationally un-bounded verifier. For simplicity of presentation we present a proof technique for state-ment in Equation (3), which can be compiled into this proof statement using known techniques for proving knowledge of a discrete logarithm representation (for y 1 and y 2 in this case).

We describe a standard type of a non-interactive proof which relies on a collision-purposes. Other types can be easily derived from our protocol. For security reasons, we hiding (i.e., some information about the x i  X  X  can be revealed with a probability near 1 / 2  X  2 ). Here, | x i | is the bit length of values used in such proofs, and the verifier is assumed to be honest. (1) The prover generates two random values v 1 ,v 2  X  Z p such that v 1  X  v 2 (mod B ) (5) If c = c and r 1  X  r 2 (mod B ), the verifier accepts the proof.
 Note that the probability of failure in step 3 is negligible in the security parameter  X  2 , which means that the prover will be able to successfully complete the proof on the first try with overwhelming probability.

We next need to show that this protocol is zero-knowledge proof of knowledge of the desired statement in presence of an honest verifier. To do so, we prove three standard properties sought of a ZKPK, namely, completeness (which states that an honest prover with possession of g x 1 1 and g x 2 2 , where x 1  X  x 2 (mod B ) can indeed successfully complete the proof), soundness (which states that a prover with x 1  X  x 2 (mod B ) cannot successfully complete the proof with a nonnegligible probability), and zero-knowledge (which states that a simulator without access to x 1 and x 2 can produce a verifier X  X  view indistinguishable from a real protocol execution).

Completeness. When x 1  X  x 2 (mod B ), the prover will be able to convince the verifier of this fact with probability 1. Since the prover X  X  claim is true, the verifier will compute the following. This means that c must be identical to c . Additionally, if x 1  X  x 2 (mod B )and v 1  X  v (mod B ), then it is straightforward to see that r 1  X  r 2 (mod B ). Therefore, the prover will be able to successfully complete the proof with probability 1.

Soundness. If x 1 is not congruent to x 2 mod B , to produce a forgery, the prover must generate x 1 and x 2 that will produce r 1 and r 2 that are congruent mod B . However, since the verifier will compute t 1 , t 2 to be different than t 1 , t 2 used by the prover, by our assumption that H () is a random function the probability that c = c is 1 / 2  X  1 . Therefore, the probability that a cheating prover can convince an honest verifier that x
Zero-Knowledge. We show that the verifier X  X  view can be simulated without any knowledge of x 1 and x 2 and can be performed as follows. (1) On input a random value c , the simulator chooses at random v 1 ,v 2  X  Z p con-(3) The simulator computes t 1 = g v 1 1 , t 2 = g v 2 2 , programs the random oracle for H to Now notice that under the assumption that the verifier is bounded (and the length of the x  X  X  is sufficiently large), the verifier X  X  view is computationally indistinguishable from the protocol execution. The values of r i  X  X  achieve stronger, statistical indistinguisha-bility. Also, as mentioned earlier, if the proof is modified to work with commitments or signatures that perfectly hide the values of x 1 and x 2 , the proof becomes statistical zero-knowledge in presence of a computationally unbounded verifier. This completes the security analysis of the proof.

The last part that remains is to show that the proofs of knowledge in Equations (1) and (2) do indeed enforce the necessary policy in our protocol. In particular, we want to show that a party with a signature on a count equal to 0 or less is unable to successfully pass the verification. In our case, this is necessary because the packed counts (and their negative values in particular) can interfere with each other within a single message.
With modular arithmetic, all values we operate on are positive, but if it is necessary to handle negative values, it is common to allocate half of the available space for negative values. For that reason, we might want to have the valid values [1 , c imax ]and[1 , c tmax ] In this case, even if  X  0 is decremented below 0, the proof will be successful only for users who are still authorized to contribute. In our implementation, however, the TA do not issue a renewed credential on a negative count (i.e., a credential is renewed and decremented only when the current count is above 0). This means that the lowest value that a credential can have is 0, which makes such cases even easier to handle in that support for negative counts is not needed. Similarly, we have that packed counts c jk  X  X  will not decrement below 0, but only negative values would affect other counts stored at lower bits within the same message. We thus obtain that ic and tc can safely be set to log( c imax + 1) and log( c tmax + 1) , respectively. Our second solution for implementing ACA consists of utilizing electronic cash (or e-cash) which can also be built from CL signatures [Camenisch and Lysyanskaya 2004]. E-cash schemes can vary widely in their implementations and properties, but in this work, we are interested in a particular type of e-cash that allows for offline spending of anonymous coins and can be built on CL signatures. Informally, in such schemes, a user obtains an electronic coin of denomination v by obtaining a signature from the bank sig ( s , id , t ,v ), after which the bank withdraws amount v from the user X  X  account. Here, s is the coin X  X  serial number unknown to the bank (included into the signature using a commitment), id is the user X  X  identity, and t is a random value. When the user would like to purchase goods from a merchant, she spends the coin anony-mously as follows. The user opens the serial number s and denomination v and also releases the value d = id  X  R + t computed on the merchant X  X  choice of R (the correctness of this value is accompanied by a zero-knowledge proof using a randomized version of the signature). At a later point, the merchant exchanges the coin it obtained from the user for monetary value v . To do so, the merchant submits s , v , R , d , and the proof of their correctness to the bank. If the value s has not been previously used, the bank pays amount v to the merchant. Otherwise, double spending took place. To determine whether the user double spent the coin (at a single or multiple merchants) or the mer-chant is trying to deposit the coin more than once, the bank retrieves the record it already has for s . If the current values d and R that the merchant is submitting differ from the previously stored values  X  d and  X  R , the bank concludes that the user is at fault. In this case, the bank recovers the user X  X  identity by solving a system of equations id  X  R + t = d and id  X   X  R + t =  X  d for two unknowns id and t and applies a penalty to the user X  X  account. Otherwise, if R =  X  R , the bank concludes that the coin was spent by the user only once, since it is the responsibility of the merchant to use unpredictable values of R . With such a solution, the user can anonymously spend coins offline. If the scheme is followed as prescribed, the user remains anonymous (i.e., the user X  X  identity is information theoretically protected when the equation id  X  R + t is evaluated only on a single point R ); if, however, the user double spends a coin, the anonymity is lost.
The preceding description demonstrates how two crucial features, namely, anony-mous offline coin spending and double spending prevention, can be achieved using anonymous credentials. In our system, however, double spending prevention alone is not sufficient, and a mechanism for enforcing a substantially more complex access con-trol policy need to be developed. The use of anonymous tokens that can be spent at a variety of entities, although, allows the TA to be realized in a distributed way and be run by multiple entities. In this section, therefore, we design a solution that utilizes electronic cash in a novel way to enforce nontrivial access control policy involving mul-tiple conditions. To the best of our knowledge, this is the first time e-cash is used for this purpose and for enforcement of the conjunction of access control rules in particular.
At a high level, our solution consists of issuing different types of tokens, each of which can be used only once. A patient is issued c tmax tokens that can be used to submit a rating for any physician and condition. For each physician j and condition k that that physician treats, the patient is also issued c imax tokens that can be only used for rating physician j and condition k . Then, at the time the patient would like to submit her rating, the patient will be required to submit two tokens: one for the individual ( j , k ) pair and another general token that can be used toward any rating. This will allow the system to enforce the proper mechanism for mitigating system abuse.

One important consideration that must be taken into account when issuing multi-ple credentials to a single user is that of collusion resilience . In our context, collusion resilience means that tokens belonging to different users cannot be successfully com-bined to obtain access to resources which each of the users are not authorized to have individually. Suppose a certain user exhausts one type of tokens she is issued, for ex-ample, for a specific physician j and condition k pair, but has an abundance of tokens that can be spent on any physician. If the user obtains another token for the same physician j and condition k pair from another user (which the second user does not intend to use), she should not be able satisfy the system requirements by submitting two tokens, each of the correct type, that were issued to different users. We achieve collusion resilience by requiring that two tokens (of different types) submitted at the time of rating correspond to the same user, without revealing the identity of that user.
We next describe our solution in detail. In what follows, a (physician j , condition k ) pair with the special value of (0, 0) will be interpreted as  X  X ny physician and any condition. X  (1) User U computes c tmax commitments com ( m i , t i ) for randomly chosen values m i and (3) Upon verifying U  X  X  identity id , the CA uses commitments com ( m i , t i ) and its secret (1) When user U would like to submit rating r ijk for physician j and condition k , the user (2) The user randomized these signed tokens; let A and B denote their randomized (3) The TA provides U with a random challenge R and receives two values d 1 and d 2 as (4) U and the TA engage in a ZKPK interaction, during which U proves the following (5) Upon successful verification, the TA records all values received from U as well as a (1) When a TA would like to test the validity of a submitted rating r ijk for physician j (2) The CA searches its database of spent tokens for m and m . If neither of them is (3) Otherwise, if at least one of m and m have previously been submitted, the CA (4) If m was also found in the CA X  X  database, the CA repeats step 3 for m using the As before, security and privacy of our solution primarily follow from the properties of the building blocks that we use. That is, each contributing user remains anonymous as long as he complies with the agreed upon usage rules. All queriers also retrieve necessary scores and recommendation data anonymously. In addition, the rules for mitigating system abuse are enforced properly, as the user is unable to reuse her tokens, and collusion resilience is achieved through zero-knowledge proofs at the time of each contribution.

This solution also has a light computational overhead, as all ratings are received and processed in the clear. The storage of a contributing user consists of c imax n p i = 1 + c tmax signatures and the same number of corresponding messages m i  X  X  and m ( jk ) i  X  X . Because signatures are only tens of bytes long, this storage is not going to be a burden for the user. Finally, the work associated with each submission and verification proto-col consists of a constant number of cryptographic operations and is thus very low. In particular, an implementation built on the signature scheme of Camenisch and Lysyanskaya [2004] would use bilinear maps with pairings implemented over elliptic curves. In such a setting, the equivalent of modular exponentiations is noticeably faster than in conventional cryptography, and the main overhead comes from performing a pairing operation (which for a typical set of parameters takes tens of milliseconds). The largest overhead of the solution then comes from signature verification that the server performs per contribution, while still allowing the server to perform all neces-sary computation within a second. The client X  X  overhead is noticeably lighter, which gives a solution that can support a very large number of users. This work puts forward a framework for building medical recommendation systems in which (i) privacy of patient data is provably preserved, (ii) reliability of data is main-tained by mitigating system abuse by dishonest users, and (iii) the functionality is flexible enough to provide recommendations on individual conditions as well as their combinations. We provide two alternative architectures, SPA and ACA , that satisfy the framework requirements. Our realization of the SPA architecture relies on secure multiparty techniques which we enhance with misuse prevention techniques. Our re-alization of the ACA architecture relies on anonymous credentials and utilizes new zero-knowledge proof of knowledge techniques and a novel use of electronic cash for effective misuse prevention, as well as has lightweight computational overhead.
While both architectures meet all of the functional, privacy, and reliability require-ments and can be deployed in practice, each has drawbacks in comparison to the other. For example, in SPA , the drawbacks are as follows.
 (1) Using modern secure multiparty computation techniques, computing recommen-(2) Custom queries for user-specified combinations of conditions and weights cannot (3) Finding mutually distrustful parties to perform the computations may not be easy; While in ACA , we have the following drawbacks. (1) Users must be willing to register with the system in order to make any contribu-(2) Privacy of user ratings is achieved by hiding among other users in the system. That Based on this comparison, we leave it for the community to decide which architecture may be most beneficial for a particular context.

