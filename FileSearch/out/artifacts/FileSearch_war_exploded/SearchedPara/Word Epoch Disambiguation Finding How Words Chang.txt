 Most current natural language processing works with language as if it were a constant. This how-ever, is not the case. Language is continually chang-ing: we discard or coin new senses for old words; metaphoric and metonymic usages become so en-grained that at some point they are considered lit-eral; and we constantly add new words to our vocab-ulary. The purpose of the current work is to look at language as an evolutionary phenomenon, which we can investigate and analyze and use when working with text collections that span a wide time frame.
Until recently, such task would not have been possible because of the lack of large amounts of to the Google books and Google Ngrams historical projects. They make available in electronic format a large amount of textual data starting from the 17th century, as well as statistics on word usage. We will exploit this data to find differences in word usage across wide periods of time.
The phenomena involved in language change are numerous, and for now we focus on word usage in different time epochs. As an example, the word gay , currently most frequently used to refer to a sexual orientation, was in the previous century used to ex-press an emotion. The word run , in the past used in-transitively, has acquired a transitive sense, common in computational circles where we run processes, programs and such.

The purpose of the current research is to quan-tify changes in word usage, which can be the ef-fect of various factors: changes in meaning (ad-dition/removal of senses), changes in distribution, change in topics that co-occur more frequently with a given word, changes in word spelling, etc. For now we test whether we can identify the epoch to which a word occurrence belongs. We use two sets of words  X  one with monosemous words, the other with poly-semous ones  X  to try and separate the effect of topic change over time from the effect of sense change.
We use examples from Google books, split into three epochs: 1800+/-25 years, 1900+/-25, 2000+/-25. We select open-class words that occur frequently in all these epochs, and words that occur frequently only in one of them. We then treat each epoch as a  X  X lass, X  and verify whether we can correctly pre-dict this class for test instances from each epoch for the words in our lists. To test whether word usage frequency or sense variation have an impact on this disambiguation task, we use lists of words that have different frequencies in different epochs as well as different polysemies. As mentioned before, we also compare the performance of monosemous  X  and thus (sensewise) unchanged through time  X  and polyse-mous words, to verify whether we can in fact predict sense change as opposed to contextual variation. The purpose of this paper is to look at words and how they change in time. Previous work that looks at diachronic language change works at a higher lan-guage level, and is not specifically concerned with how words themselves change.

The historical data provided by Google has quickly attracted researchers in various fields, and started the new field of culturomics (Michel et al., 2011). The purpose of such research is to analyse changes in human culture, as evidenced by the rise and fall in usage of various terms.

Reali and Griffiths (2010) analyse the similarities between language and genetic evolution, with the transmission of frequency distributions over linguis-tic forms functioning as the mechanism behind the phenomenon of language change.

Blei and Lafferty (2006) and Blei and Lafferty (2007) track changes in scientific topics through a discrete dynamic topic model (dDTM)  X  both as types of scientific topics at different time points, and as changing word probability distributions within these topics. The  X  X hotography X  topic for example has changed dramatically since the beginning of the 20th century, with words related to digital photog-raphy appearing recently, and dominating the most current version of the topic.

Wang and McCallum (2006), Wang et al. (2008) develop time-specific topic models, where topics, as patterns of word use, are tracked across a time changing text collection, and address the task of (fine-grained) time stamp prediction.

Wijaya and Yeniterzi (2011) investigate through topic models the change in context of a specific en-tity over time, based on the Google Ngram corpus. They determine that changes in this context reflect events occurring in the same period of time. We formulate the task as a disambiguation prob-lem, where we automatically classify the period of time when a word was used, based on its surround-ing context. We use a data-driven formulation, and draw examples from word occurrences over three different epochs. For the purpose of this work, we consider an epoch to be a period of 50 years sur-rounding the beginning of a new century (1800+/-25 years, 1900+/-25, 2000+/-25). The word usage examples are gathered from books, where the publi-cation year of a book is judged to be representative for the time when that word was used. We select words with different characteristics to allow us to in-vestigate whether there is an effect caused by sense change, or the disambiguation performance comes from the change of topics and vocabulary over time. Target Words. The choice of target words for our experiments is driven by the phenomena we aim to analyze. Because we want to investigate the behav-ior of words in different epochs, and verify whether the difference in word behavior comes from changes in sense or changes in wording in the context, we choose a mixture of polysemous words and monose-mous words (according to WordNet and manually checked against Webster X  X  dictionary editions from 1828, 1913 and the current Merriam-Webster edi-tion), and also words that are frequent in all epochs, as well as words that are frequent in only one epoch.
According to these criteria, for each open class (nouns, verbs, adjectives, adverbs) we select 50 words, 25 of which have multiple senses, 25 with one sense only. Each of these two sets has a 10-5-5-5 distribution: 10 words that are frequent in all three epochs, and 5 per each epoch such that these words are only frequent in one epoch. To avoid part-of-speech ambiguity we also choose words that are unambiguous from this point of view. This selection process was done based on Google 1gram historical data, used for computing the probability distribution
The set of target words consists thus of 200 open class words, uniformly distributed over the 4 parts of speech, uniformly distributed over multiple-sense/unique sense words, and with the frequency based sample as described above. From this initial set of words, we could not identify enough examples with a final set of 165 words.
 Data. For each target word in our dataset, we collect the top 100 snippets returned by a search on Google Books for each of the three epochs we consider.
All the extracted snippets are then processed: the text is tokenized and part-of-speech tagged using the Stanford tagger (Toutanova et al., 2003), and con-texts that do not include the target word with the specified part-of-speech are removed. The position of the target word is also identified and recorded as an offset along with the example.

For illustration, we show below an example drawn from each epoch for two different words, dinner : and surgeon : Disambiguation Algorithm. The classification al-gorithm we use is inspired by previous work on data-driven word sense disambiguation. Specifically, we use a system that integrates both local and topical features. The local features include: the current word and its part-of-speech; a local context of three words to the left and right of the ambiguous word; the parts-of-speech of the surrounding words; the first noun before and after the target word; the first verb before and after the target word. The topical features are determined from the global context and are implemented through class-specific keywords, which are determined as a list of at most five words occurring at least three times in the contexts defin-ing a certain word class (or epoch). This feature set is similar to the one used by (Ng and Lee, 1996). The features are then integrated in a Naive Bayes classifier (Lee and Ng, 2002).
 Evaluation. To evaluate word epoch disambigua-tion, we calculate the average accuracy obtained through ten-fold cross-validations applied on the data collected for each word. To place results in per-spective, we also calculate a simple baseline, which assigns the most frequent class by default. Table 1 summarizes the results obtained for the 165 words. Overall, the task appears to be feasible, as absolute improvements of 18.5% are observed. While improvements are obtained for all parts-of-speech, the nouns lead to the highest disambiguation results, with the largest improvement over the base-line, which interestingly aligns with previous obser-vations from work on word sense disambiguation (Mihalcea and Edmonds, 2004; Agirre et al., 2007).
Among the words considered, there are words that experience very large improvements over the base-line, such as  X  X omputer X  (with an absolute increase over the baseline of 42%) or  X  X nstall X  (41%), which are words that are predominantly used in one of the epochs considered (2000), and are also known to have changed meaning over time. There are also words that experience very small improvements, such as  X  X gain X  (3%) or  X  X aptivate X  (7%), which are words that are frequently used in all three epochs. There are even a few words (seven) for which the disambiguation accuracy is below the baseline, such as  X  X blige X  (-1%) or  X  X ruel X  (-15%).

To understand to what extent the change in fre-quency over time has an impact on word epoch dis-ambiguation, in Table 2 we report results for words that have high frequency in all three epochs consid-ered, or in only one epoch at a time. As expected, the words that are used more often in an epoch verb  X  X eassert X  has higher frequency in 2000, and it has a disambiguation accuracy of 67.25% compared to a baseline of 34.15%. Instead, the verb  X  X on-ceal, X  which appears with high frequency in all three epochs, has a disambiguation accuracy of 44.70%, which is a relatively small improvement over the baseline of 38.04%.

The second analysis that we perform is concerned with the accuracy observed for polysemous words as compared to monosemous words. Comparative re-sults are reported in Table 3. Monosemous words do not have sense changes over time, so being able to classify them in different epochs relies exclusively on variations in their context over time. Polysemous words X  X  context change because of both changes in topics/vocabulary over time, and changes in word senses. The fact that we see a difference in ac-curacy between disambiguation results for monose-mous and polysemous words is an indication that word sense change is reflected and can be captured in the context.

To better visualize the improvements obtained with word epoch disambiguation with respect to the baseline, Figure 1 plots the results. In this paper, we introduced the novel task of word epoch disambiguation, which aims to quantify the changes in word usage over time. Using examples collected from three major periods of time, for 165 words, we showed that the word epoch disambigua-tion algorithm can lead to an overall absolute im-provement of 18.5%, as compared to a baseline that picks the most frequent class by default. These re-sults indicate that there are significant differences between occurrences of words in different periods of time. Moreover, additional analyses suggest that changes in usage frequency and word senses con-tribute to these differences. In future work, we plan to do an in-depth analysis of the features that best characterize the changes in word usage over time, and develop representations that allow us to track sense changes.
 This material is based in part upon work sup-ported by the National Science Foundation CA-REER award #0747340. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.
