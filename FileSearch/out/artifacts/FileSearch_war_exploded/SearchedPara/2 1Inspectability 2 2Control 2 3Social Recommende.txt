 cuss related work on th e user -centric evaluation of recommender systems, and on personal characteristics of the user that may i n-fluence our results. Many aspects of the explanation process have been studied in the recommender syst ems literature. For example, an ea rlier approach in [22] discuss es a simple glass -box paradigm th at provides only min imal information to the user. In this paper our notion of in-spectability is similar to Tintarev and Masthoff  X  X  concept of transparency in [44], which is to  X  X x plain how the system works X  , and it is treated separately from control in our study. [46] also introduce s the concept of scrutability with the (more interactive) aim to  X  X llow users to tell the system it is wrong X , while Czarkowski and Kay [10] examine scrutability and control as separate mechanisms, in the context of a student model applic a-tion. Kay and Lum [26] also focus on scrutability, but in terms of providing explanations of why individual elements and relations in the underlying model have par ticular values . Herlocker [19] argues that explanation provides transparency,  X  X xposing the reasoning behind a recommendation X . The reaso n-ing and insight into the recommendation process exposed by an explanation interface can also increase the inspectability of the system as a whole. Tintarev and Masthoff [48] show that explan a-tions make it easier to judge the quality of recommendations. Consequently, such expla nations increase users X  trust in the rec-ommendations and, in turn, the perceived competence of the sy s-tem ([9, 12], see also [19, 50]). Sinha and Sweari ngen [44] demonstrate that users rate systems that provide detailed info r-mation about items as more useful and easier to use.
 In the realm of social recommenders, Groh et al. [18] present a study that outlines the  X  X xtensive need X  for explanation, and Gretarsson et al. [17] present a small -scale st udy of an explanation interface , finding that the explanation process has a positive effect on satisfaction with recommendations. Researchers have implemented various aspects of control in re c-ommender systems, ranging from simple preference elicitation at recommendation time [7] to more complex iterative process es such as dynamic critiquing which allow s users to tweak ordered nume rical attributes during the recommendation phase [6, 32, 33, 42] . More re cent work [17, 37, 39] discusses interactive graphical representations of the rec ommendation process , to enable control over both item -and user -level preferences in collaborative re c-ommender systems.
 Multiple studies highl ight the benefits of interactive interfaces that support control over the recommendation process. In a general compari son of user -controlled versus static recommendation inte r-faces, McNee et al. [35] found that study participants preferred user -contr olled interfaces because these systems  X  best understood their tastes X  . McNee et al. also showed that participants had hig h-er retention rates with the controlled interface. Knijnenburg et al. [30] found that controllable recommendations are typically deemed more varied than automatic ones, and Willemsen et al. [51] show that diver sifying recommendations can be useful to overcome choice overload.
 Other common methods of control include rating items [14, 41] and assigning weights to item attributes [20, 31] . Research shows that the choice between thes e different methods has a substantial impact on the user experience [6, 29, 31] . Previous studies have attempted to explain recommendations b y showing the link between the recommendation s and the  X  X earest neighbors X  on which the they are based [21, 35, 47] . An interes t-ing aspect o f social recommenders is that recommendations are based on users X  similarity with their friends rather than a set of anonymous nearest neighbors . In effect, social recommenders can leverage users X  acquaintance with the source of the recommend a-tion, which instantly attaches a wealth of established social info r-mation to the recommendations that can be further explored and exploited in the process es of inspection and control [18]. Specifically, we hypothesize that visualizing the link between recommendations and the nearest neighbors on which they are based increases the inspectability of social recommenders beyond regular recommenders , because the neigh bors are kn own.
 Furthermore, in social recommenders one could allow the user to not only rate items, but also their friends [5]. This would give certain friends additional (or less) weight beyond the weight co m-puted based on preference overlap. Arguably, this method allows users to indicate how much they  X  X rust X  their friends X  preferences in the recommendation domain. Se veral researchers have invest i-gated this idea of assigning trust scores to friends in collaborative recommenders, through explicit mechanisms such as in Golbeck X  X  FilmTrust system [15] which can support propagation of trust scores around a network of peers, and through automated mech a-nisms for modeling trust such as [11, 38] . Several recent studies have extended these ideas to prediction of personality, and by derivation, behavior of a user within the system [1] in terms of both trust and distrust [16].
 In this paper we take a step beyond existing work on social re c-ommenders by explicitly testing the effect of leveraging users X  know ledge about their friends to improve inspectability and co n-trol. By allow ing a user to inspe ct and control the elements of trust on which the re commendations are based , we can gain an understanding of the effect of inspectability and control on the user experience with the recommender system. In order to determine the impact of in spectability and control, we need to measure users X  experience with the recommender system. Specifically, we are not only interested in the quality of the re c-ommendations, but also in users X  satisfaction with the sys tem as a whole. Moreover, we need to con sider concepts like understand a-bility and perceived control to explain how inspectability and control influence the users X  experience.
 Knijnenburg et al. [30] developed a framework for user -centric evaluation of recommender systems through user experiments. It describes how certain manipulations (in our case: inspectability and control) influence subjective system aspects (i.e. unde r-sta ndability, perceived control and recommendation quality), which in turn influence user experience (i.e. system satisfaction). The framework also allows us to include the effect of personal characteristics on users X  experience. In social recommenders, the degree of trustfulness (or  X  X rusting propensity X ) could play an important role, because in order to accept the recommendations, users will need to trust their friends X  preferences [15, 38] . Users who are not trustful usually want to take matters in their own hands and therefore demand more control over the system [49]. Another personality trait that can have an influence on users X  ex-perience is choice persistence, a characteristic tha t divides users into satisficers and maximizers. Satisfic ers will stop their search when they encounter an item that meets their criteria, while ma x-imizers continue their efforts until they find the best possible o p-tion [43]. Maximizers may thus show more appreciation for sy s-tems that allow extensive control and inspection (although we do not find evidence for this in [29]).
 Finally, users X  domain knowledge can also have a significant i m-pact on their experience with a recommender system. Kamis and Davern show that domain experts perceive personalized reco m-menders as less useful than novices [24] , while other researchers have consistently found that experts have a higher appreciation for the recommendations as well as the recommender system itself [3, 30, 51] . In order to be satisfied with a recommender, however, domain experts want more control over their recommendations than novices [13, 29, 40, 45] . Novices, on the other hand, require a simple and understandable recommender system [31], and they may even prefer to give up control in return for simplicity [29]. The related work shows that inspectability and control hav e a positive influence on users X  experience with recommender sy s-tems in general, and we suspect that these benefits may be even more pronounced in social recommenders. A user study is needed to investigate the nature and extent of these benefits, and the f ac-tors that influence them. We therefore conducted an online user experiment with 267 participants employing a modified version of the TasteWeights [4, 17] social recommender. The TasteWeights system recommends new artists/bands based on the music  X  X ikes X  of the user and her Facebook friends. The TasteWeights system calculates its recom mendations in two steps. First, weights are computed for each friend based on their friend is given by the overlap in music  X  X ikes X  between them, as defined by Pear son X  X  correlation coefficient: where TWCIx,y is the total weight of the items ( X  X ikes X ) that users liked by user x . As Faceb ook users can only  X  X ike X  artists/bands without specifying how much, item weights are initialized to 0.5. Once all friend weights are computed, recommendations are gen-erated by assigning weights to all friends  X  music it ems (excluding the items that the user already  X  X ikes X  ): Here, the weight of a recommendation i is the sum of the weights of all frie nds that like i . The recommendations are displayed in decreasing order of recommendation weight. In terms of inspectability, the TasteWeights system displays a graph (Fi gure 1) that shows the users X  items, their friends, and the recommendations. By clicking at the graph, the connections b e-tween these entities can be explored. The system also shows a short description for each recommended band/artist with a link to their L astFM information page.
 The system allows two types of control over the recommend a-tions: users can adjust the weights of their items (initialized at 0.5) and their friends (initially weighted by similarity). Changing the weight of an item will influence th e similarity scores, and thus the recommendation weights. Changing the weight of a friend will add or subtract a proportion from that friend X  X  similarity score, and thus also influence the recommendation weights. The ori ginal TasteWeights system allows users to interactively inspect and control the recommendation graph (i.e. change the weights and inspect the graph simultaneously and iteratively). However, to investigate the effects of inspectability and control independe ntly, we let participants in our experiment interact with the system in two stages: a control stage and an inspection stage. In the control stage, participants are assigned to one of three co n-ditions (Figure 2): they either skip the control stage altogethe r (the  X  X o control X  condition), they are asked to adjust the weights of the items they  X  X ike X  (the  X  X tem control X  condition), or they are asked to adjust the weights of their friends (the  X  X riend control X  cond i-tion). Our primary interest is to see how thes e control conditions compare against the no control condition, but we are also interes t-ed in differences between the two control conditions.

Figure 2. The control phase of item control (left) and friend In the inspection stage, participants are assigned to one of two conditions: the system either shows only the list of recommend a-tions (the  X  X ist only X  condition), or the full recommendation graph (the  X  X ull graph X  condition). To give each participant a compar a-ble experience , we limited the number of music likes and friends to be considered by the recommender to 10 each (with a minimum of 5 each). The number of recommendations was fixed to 10. 267 participants were recruited using Craigslist and Ama zon M e-chanical Turk 1 . Only adult Facebook users living in the U.S. were allowed to participate. 156 participants were female, and 130 w ere between the ages of 18 and 2 5, 114 between 25 and 40, and 23 older than 40 2 . In order to provide a meaningful experie nce, we only allowed users to participate if their recommendation graph would show at least 5 music  X  X ikes X , showing overlap with at least 5 friends, and result ing in at least 10 recommendations. Denied In [27] we found no substantial differences between these two participant populations. These numbers reflect the general Facebook population, with a slight underrepresentation of the older demographic. See http://bit.ly/insidefacebook -20100104. participants were given the suggestion to populate th eir Facebook profile with more music  X  X ikes X  and then try again. Eligible participants were then asked to answer 15 questions about their personal characteristics (music expertise, trusting propensity and choice persistence). Questions were statements to which pa r-ticipants could agree or disagree on a five point scale. They su b-sequently completed the control stage (unless they were assigned to the  X  X o control X  condition), in which they were asked to adjust the weights of either their items or their friends (depending on the control condition). Next, they completed the inspection stage, where they were asked to carefully inspect the list of recomme n-dations or the recommendation graph (depending on the inspect a-bility condition). Finally, they were asked to in dicate whether they already knew each of the recommended band/artist or not , and subsequently to rate the recommendation on a 5-star scale . Users were encouraged to click on the provided LastFM link to improve their jud gment of unknown bands/artists . After the experiment, participants answered another 29 questions about their user exp e-rience. Full questionnaires can be found in [28]. The answers to the 44 questionnaire items were submitted to a confirmatory factor analysis 3 with categorical indicators and a weighted least squares estimator, estimating 7 factors:  X  Music expertise : 4 items adapted from [3], e.g.  X  Compared  X  Trusting propensity: 3 items adapted from [29], e.g.  X  In  X  Understandability : 3 new items, e.g.  X  The recommendation  X  Perceived control : 4 items adapted from [29], e.g.  X  Co m- X  Perceived recommendation quality : 5 items adapted from  X  System satisfaction : 7 items adapted from [30], e.g.  X  I can  X  Familiarity with recommenders : 2 new items, e.g.  X  I am f a-10 questionnaire items were excluded from the analysis due to low communality , high cross -loadings and/or high residual corr e-lations . Additionally, 5 items on choice persistence (taken from [36]) failed to converge to a stable factor. For the remaining fa c-tors the values of Cronbach X  X   X  and a verage variance extracted (AVE) were high 4 , indicating convergent validity. Moreover, the square root of the AVE is higher than the factor correlation for all factors, indicating discriminant validity. We subjected the 7 factors, the experimental c onditions, and s e-lected behaviors to structural equation modeling, which simult a-neously fits the factor measurement model and the struc tural rela-Factor analysis and structural equation modeling as applied in this paper are explained in Appendix A of [30].
AVE should be &gt;.50 for convergent validity. tions between factors and other variables. The model (Figure 3) 90% CI: [0.017, 0.034], CFI = 0.993, TLI = 0.992 . The model shows that the inspectability and control manipulations each have an independent positive effect on the understandability of the system: the full graph condition is more understandable than the list only condition, and the item control and friend control conditions are more understand able than the no control condition (see also Figure 4a). Understandability is in turn related to users X  perception of control, which is in turn related to the perceived quality of the recommendations. The perceived control and the perceived recommendation quality finally determine participants X  satisfaction with the system (for the marginal effects of control and inspectability on these factors, see Figure 4b,c,d). There exist additional effects of inspectability and control on u n-derstandabili ty, which are mediated by the inspection time (the amount of time users take to inspect the recommendations, see Figure 4e). In the full graph condition, participants take more time to inspect the recommendations (about 7.3 seconds more), and this results in an additional increase of understandability. For the two control conditions, however, the inspection time is shorter (about 10.9 seconds less in the item control condition and about A model should not have a non -significant  X  2 , but this statistic is regarded as too sensitive [2]. Hu and Bentler [23] propose cut -
RMSEA &lt; .05, with the upper bound of its 90% CI below 0.10. 23.3 seconds less in the friend control condition), which counters the positive effect on understandability.
 In the full graph condition, participants indicate that they already know more of the recommendations than in the list only condition (see Figure 4f). In turn, the more recommendations the participant already knows, the higher is the perceived control and perceived recommendation quality, but the lower is the satisfaction.
 The perceived recommendation quality and the number of known rec ommendations determine the average rating participants give to the recommendations. The marginal effects of the inspectability and control manipulations on the average rating (Figure 4g) ind i-cate that the ratings in the item control condition are somewhat lower (mean: 3.146) than the no control condition (mean: 3.267), whereas the ratings in the friend control condition are somewhat higher (mean: 3.384). The difference between the two control conditions is small but significant (p = .031). Participants who are familiar with recommenders find the system more understandable. Participants with music expertise perceive less control over the system, but perceive a higher recommend a-tion quality and system satisfaction . Finally, tru sting propensity influences participants X  satisfaction with the system. Based on the results of our experiment, we can describe in detail how the benefits of inspectability and control in social reco m-menders come about. We can also describe these results in the light of users X  personal characteristics. Finally, we can provide some preliminary suggestions on the relative effectiveness of controlling items versus friends.
 Both inspectability and control have a positiv e effect on the user experience, primarily because an inspectable and controllable recommender system is easier to understand. The increased u n-derstandability causes users to feel more in control over the sy s-tem, and this in turn increases the perceived qu ality of the reco m-mendations, also indicated by increased ratings. Finally, the hig h-er perceived control and recommendation quality cause users to be more satisfied with the system.
 Inspectability works partially due to a direct ef fect on under-standability, and partially due to its influence on user behavior. Specifically, users take more time for inspection in the  X  X ull graph X  condition (which increases understandability), and users in this condition already know more of the recomm endations (which increases perceived control and recommendation quality, but d e-creases system satisfaction). The effect of inspectability on the number of recommendations that the participant already knows may seem counterintuitive, because the inspectabil ity conditions do not influence the actual recommendations. However, in the  X  X ull graph X  condition users can see which friends are connected to the recommendations, and this may allow users to recognize more of the recommendations as already known (e.g.  X  X  remember John playing this band X  X  album for me X ) 6 . Arguably, this recognition effect is an important aspect of inspect -abil ity, because knowing recommendations may raise users X  trust in the recommender [8, 44] . In our experiment, known reco m-mendations increase users X  perceived control (total effect:  X  = 0.372, p = .001) and the perceived recommendation quality (total effect:  X  = 0.389, p = .002). On the other hand, known recomme n-dations are less useful, as they contain no novelty, which explains the decrease in system satisfaction (McNee at al. [34] show that users are happy with a set of recommendations as long as it co n-Conformity bias could be an alternative explanation:  X  X f all my friends know this band, I ought to know it too! X  tains at least one novel item). Des pite this negative effect of known items, the total effect of inspectability on system satisfa c-tion is however still statistically significant:  X  = 0.409, p = .001. Item control and friend control result in a more understandable system despite the shorter inspection time (total effects:  X  = 0.386, p = .063 and  X  = 0.578, p = .004, respectively). Note that although inspection time is shorter, participants in these conditions spend additional time controlling the recommendations. Seve ral personal characteristics have an effect on users X  exper i-ence when using our system. Trusting propensity has a positive effect on system satisfaction, which may be due to the fact that users with a higher general trusting propensity seem more likely to trust their friends X  music preferences. Arguably, then, trustfu l-ness is an important precondition for a social recommender to work for a user.
 Moreover , users with some expertise about music feel less in co n-trol, but they view the recommendations and the s ystem itself more positively. Music experts may feel that bands/artists are too crude of a building block for recommendations ( for them, bands may have both amazing and terrible albums), which could have caused the reduced perception of control (this effec t is consistent with findings in [24]). On the other hand, music experts are more capable of judging the quality of the recommendations, which may be t he reason for the increased perceived recommendation quality and satisfaction with the system (these effects are co n-sistent with findings in [3, 30, 51] ). Besides comparing the control conditions against the  X  X o control X  condition, we are also interested in comparing the control cond i-tions against e ach other, to determine which type of control users prefer. Figure 4 shows that the understandability, perceived co n-trol and perceived recommendation quality are consistently higher for the  X  X riend control X  condition than for the  X  X tem control X  co n-dition, but the difference between these two conditions is not st a--0,2 0,0 0,2 0,4 0,6 0,8 1,0 1,2 a) Understandability -0,2 0,0 0,2 0,4 0,6 0,8 1,0 1,2 c) Perc. rec. quality 0:00 0:20 0:40 1:00 1:20 1:40 e) Inspection time 2,8 3,0 3,2 3,4 3,6 3,8 g) Ratings tistically significant. The only significant difference between the two control conditions is in users X  ratings of the recommend a-tions:  X  X riend control X  results in higher ratings, but the difference is again very small (3.146 vs. 3.384 on a 5 -star scale). On the other hand, the  X  X riend control X  condition results in sligh t-ly more known recommendations, which may be one reason why the system satisfaction is also slightly worse in the  X  X riend co n-cant results, we can interpret these trends to conclude that the  X  X riend control X  condition may give the user more accurate co n-trol, but the  X  X tem control X  condition may lead to a perception of mor e novel recommendations. Our results show that social recommender systems (and arguably recommender systems in general) indeed benefit from facilities that improve their inspectability and control.
 Recommenders that display a recommendation graph result in a better user experience, partially because they encourage users to spend more time on inspecting the recommendations. Moreover, by inspecting the links between friends and recommendations, users get hints about their previou s encounters with the reco m-mended items, which allows them to more accurately evaluate the quality of the recommendations. In effect, the recommendation graph increases the understandability, perceived control, pe r-ceived recommendation quality, and system satisfaction. Recommenders that give users control over the item weights and friend weights are more understandable, which leads to higher perceived control, perceived recommendation quality and overall system satisfaction. As to which control method is pr eferred, the results suggest that giving users control over the friend weights results in slightly higher quality recommendations, but that co n-trolling the item weights may heighten users X  perception of re c-ommendation novelty. Arguably, making both control mech a-nisms available may preserve the best aspects of both methods. In fact, as we find that the effects of inspectability and control are additive , t he best user experience may arise when users can con-trol items and friends simultaneously and directly in the reco m-mendation graph. Such interactive control could arguably result in scrutability : allowing users to find and correct mistakes in the recommendation process [25, 47] . In this paper we purposefully disentangled inspectability and control to isolate their respective effects; in future work we purpose to investigate the benefits of scrutability in a f ully interactive social recommender. We thank Nikhil Rao for his extensive help conducting the study and Tobias H X llerer for his feedback throughout the process. [1] Adali, S., E scriva, R., Goldberg, M.K., Hayvanovych, M., [2] Bentler, P.M. and Bonett, D.G . Significance Tests and Goo d-[3] Bollen, D., Knijnenburg, B.P ., Willemsen, M.C. and Graus, [4] Bostandjiev, S. , O X  X onovan, J. and H X llerer, T. Taste-[5] Bourke , S., McCarthy, K. and Smyth, B. Power to the people: [6] Chen, L. and Pu, P . Critiquing -based recommenders: survey [7] Chen, L. and Pu, P . Survey of Preference Elicitation Met h-[8] Cooke, A.D.J., Suja n, H., Sujan, M. and Weitz, B.A . Marke t-[9] Cramer, H., Evers, V., Ramlal, S., Someren, M., Rutledge, [10] Czarkowski, M. and Kay, J . Bringing Scrutability to Ada p-[11] DuBois, T. , Golbeck, J. and Srinivasan, A. Predicting Trust [12] Felfernig, A . Knowledge -Based Recommender Technologies [13] Fitzsimons, G.J. and Lehmann, D.R . Reactance to Reco m-[14] Gena, C., Brogi, R., Cena, F. and Ver nero, F. The Impact of [15] Golbeck, J . Generating Predictive Movie Recommendations [16] Golbeck, J., Roble s, C. and Turner, K . Predicting personality [17] Gretarsson, B., O X  X onovan, J., Bostandjiev, S., Hall, C. and [18] Groh, G., B irnkammerer, S. and K X llhofer, V . Social Re c-[19] G uy, I., Ronen, I. and Wilcox, E . Do you know?: reco m-[20] Haubl, G. and Trifts, V . Consumer Decision Making in [21] Herlocker, J .L., Konstan, J.A. and Riedl, J. Explaining co l-[22] H X  X k, K., Karlgren, J., W X rn, A., Dahlb X ck, N., Jansson, C., [23] Hu, L. and Bentler, P.M . Cutoff criteria for fit indexes in [24] Kamis, A. and Davern, M.J . Personalizing to product categ o-[25] Kay, J . Stereotypes, Student Models and Scrutability. Intelli-[26] Kay, J. and Lum, A . Ontology -based user modelling for the [27] Knijnenburg, B.P. and Kobsa, A . Making Decisions about [28] Knijnenb urg, B.P., Rao, N. and Kobsa, A . Experimental M a-[29] Knijnenburg, B.P., Rei jmer, N.J.M. and Willemsen, M.C . [30] Knijnenburg, B.P., Willemsen, M.C., Gantn er, Z., Soncu, H. [31] Kramer, T . The Effect of Measurement Task Transparency [32] McCar thy, K., Salem, Y. and Smyth, B . Experience -Based [33] McGinty, L. and Reilly, J . On the Evolution of Critiquing [34] McNee, S.M., Albert, I., Cosley, D., Gopalkrishnan, P., Lam, [35] McNee, S.M., Lam, S.K., Konstan, J.A. and Riedl, J. Inte r-[36] Nenkov, G.Y., Morrin, M., Ward, A., Schwartz, B. and Hu l-[37] O X  X onovan, J., Gretarsson, B., Bostandjiev , S., Hollerer, T. [38] O X  X onovan, J. and Smyth, B . Trust in recommender systems. [39] O X  X onovan, J., Smyth, B., Gretarsson, B., Bostandjiev, S. [40] Pereira, R.E. Optimizing human -computer interaction for the [41] Pommeranz, A., Broekens , J., Wiggers, P., Brinkman, W. -P. [42 ] Pu, P., Chen, L. and Kumar, P . Evaluating product search and [43] Schwartz, B., Ward, A., Monterosso, J., Lyubomirsky , S., [44 ] Sinha, R.R. and Swearingen, K . Comparing Recommend a-[45] Spiekermann, S. and Paraschiv, C . Motivating human  X  X gent [46] Tintarev, N. and Mastho ff, J . A Survey of Explanations in [47] Tintarev, N. and Masthoff, J . Designing and Evaluating E x-[48] Tintarev, N. and Masthoff, J . Evaluating the effectiveness of [49] Vries, P . Trust in systems: effects of direct and indirect i n-[50] Wang, W. and Benbasat, I . Recommendation agents for ele c-[51] Willemsen, M.C., Graus, M.P., Knijnenburg, B.P. and Bo l-[52] Zhao, S., Zhou, M.X., Yuan, Q., Zhang, X., Zheng, W. and 
