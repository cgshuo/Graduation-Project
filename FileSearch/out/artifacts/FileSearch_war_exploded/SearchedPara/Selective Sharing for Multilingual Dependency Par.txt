 Current top performing parsing algorithms rely on the availability of annotated data for learning the syntactic structure of a language. Standard ap-proaches for extending these techniques to resource-lean languages either use parallel corpora or rely on annotated trees from other source languages. These techniques have been shown to work well for lan-guage families with many annotated resources (such as Indo-European languages). Unfortunately, for many languages there are no available parallel cor-pora or annotated resources in related languages. For such languages the only remaining option is to resort to unsupervised approaches, which are known to produce highly inaccurate results.

In this paper, we present a new multilingual al-gorithm for dependency parsing. In contrast to pre-vious approaches, this algorithm can learn depen-dency structures using annotations from a diverse set of source languages, even if this set is not re-lated to the target language. In our selective shar-ing approach, the algorithm learns which aspects of the source languages are relevant for the target lan-guage and ties model parameters accordingly. This approach is rooted in linguistic theory that charac-terizes the connection between languages at various levels of sharing. Some syntactic properties are uni-versal across languages. For instance, nouns take ad-jectives and determiners as dependents, but not ad-verbs. However, the order of these dependents with respect to the parent is influenced by the typological features of each language.

To implement this intuition, we factorize genera-tion of a dependency tree into two processes: selec-tion of syntactic dependents and their ordering. The first component models the distribution of depen-dents for each part-of-speech tag, abstracting over their order. Being largely language-universal, this distribution can be learned in a supervised fashion from all the training languages. On the other hand, ordering of dependents varies greatly across lan-guages and therefore should only be influenced by languages with similar properties. Furthermore, this similarity has to be expressed at the level of depen-dency types  X  i.e., two languages may share noun-adposition ordering, but differ in noun-determiner ordering. To systematically model this cross-lingual sharing, we rely on typological features that reflect ordering preferences of a given language. In addi-tion to the known typological features, our parsing model embeds latent features that can capture cross-lingual structural similarities.

While the approach described so far supports a seamless transfer of shared information, it does not account for syntactic properties of the target lan-guage unseen in the training languages. For in-stance, in the CoNLL data, Arabic is the only lan-guage with the VSO ordering. To handle such cases, our approach augments cross-lingual sharing with unsupervised learning on the target languages.
We evaluated our selective sharing model on 17 languages from 10 language families. On this di-verse set, our model consistently outperforms state-of-the-art multilingual dependency parsers. Per-formance gain, averaged over all the languages, is 5.9% when compared to the highest baseline. Our model achieves the most significant gains on non-Indo-European languages, where we see a 14.4% improvement. We also demonstrate that in the ab-sence of observed typological information, a set of automatically induced latent features can effectively work as a proxy for typology. Traditionally, parallel corpora have been a main-stay of multilingual parsing (Wu, 1997; Kuhn, 2004; Smith and Smith, 2004; Hwa et al., 2005; Xi and Hwa, 2005; Burkett and Klein, 2008; Snyder et al., 2009). However, recent work in multilingual pars-ing has demonstrated the feasibility of transfer in the absence of parallel data. As a main source of guid-ance, these methods rely on the commonalities in de-pendency structure across languages. For instance, Naseem et al. (2010) explicitly encode these similar-ities in the form of universal rules which guide gram-mar induction in the target language. An alterna-tive approach is to directly employ a non-lexicalized parser trained on one language to process a target language (Zeman and Resnik, 2008; McDonald et al., 2011; S X gaard, 2011). Since many unlexicalized dependencies are preserved across languages, these approaches are shown to be effective for related languages. For instance, when applied to the lan-guage pairs within the Indo-European family, such parsers outperform unsupervised monolingual tech-niques by a significant margin.

The challenge, however, is to enable dependency transfer for target languages that exhibit structural differences from source languages. In such cases, the extent of multilingual transfer is determined by the relation between source and target languages. Berg-Kirkpatrick and Klein (2010) define such a re-lation in terms of phylogenetic trees, and use this distance to selectively tie the parameters of mono-lingual syntactic models. Cohen et al. (2011) do not use a predefined linguistic hierarchy of language re-lations, but instead learn the contribution of source languages to the training mixture based on the like-lihood of the target language. S X gaard (2011) proposes a different measure of language related-ness based on perplexity between POS sequences of source and target languages. Using this measure, he selects a subset of training source sentences that are closer to the target language. While all of the above techniques demonstrate gains from modeling language relatedness, they still underperform when the source and target languages are unrelated.
Our model differs from the above approaches in its emphasis on the selective information sharing driven by language relatedness. This is further com-bined with monolingual unsupervised learning. As our evaluation demonstrates, this layered approach broadens the advantages of multilingual learning to languages that exhibit significant differences from the languages in the training mix. Language-Independent Dependency Properties Despite significant syntactic differences, human lan-guages exhibit striking similarity in dependency pat-terns. For a given part-of-speech tag, the set of tags that can occur as its dependents is largely consistent across languages. For instance, adverbs and nouns are likely to be dependents of verbs, while adjectives are not. Thus, these patterns can be freely trans-ferred across languages.
 Shared Dependency Properties Unlike dependent selection, the ordering of dependents in a sentence differs greatly across languages. In fact, cross-lingual syntactic variations are primarily expressed in different ordering of dependents (Harris, 1968; Greenberg, 1963). Fortunately, the dimensions of these variations have been extensively studied in lin-guistics and are documented in the form of typo-logical features (Comrie, 1989; Haspelmath et al., 2005). For instance, most languages are either dom-inantly prepositional like English or post-positional like Urdu. Moreover, a language may be close to dif-ferent languages for different dependency types. For instance, Portuguese is a prepositional language like English, but the order of its noun-adjective depen-dency is different from English and matches that of Arabic. Therefore, we seek a model that can express parameter sharing at the level of dependency types and can benefit from known language relations. Language-specific Dependency Variations Not every aspect of syntactic structure is shared across languages. This is particularly true given a limited number of supervised source languages; it is quite likely that a target language will have previously un-seen syntactic phenomena. In such a scenario, the raw text in the target language might be the only source of information about its unique aspects. We propose a probabilistic model for generating dependency trees that facilitates parameter sharing across languages. We assume a setup where de-pendency tree annotations are available for a set of source languages and we want to use these annota-tions to infer a parser for a target language. Syn-tactic trees for the target language are not available during training. We also assume that both source and target languages are annotated with a coarse parts-of-speech tagset which is shared across lan-guages. Such tagsets are commonly used in multilin-gual parsing (Zeman and Resnik, 2008; McDonald et al., 2011; S X gaard, 2011; Naseem et al., 2010).
The key feature of our model is a two-tier ap-proach that separates the selection of dependents from their ordering : 1. Selection Component: Determines the depen-2. Ordering Component: Determines the position
This factorization constitutes a departure from traditional parsing models where these decisions are tightly coupled. By separating the two, the model is able to support different degrees of cross-lingual sharing on each level.

For the selection component, a reasonable ap-proximation is to assume that it is the same for all languages. This is the approach we take here.
As mentioned in Section 3, the ordering of depen-dents is largely determined by the typological fea-tures of the language. We assume that we have a set of such features for every language l , and denote this feature vector by v l . We also experiment with a variant of our model where typological features are not observed. Instead, the model captures structural variations across languages by means of a small set of binary latent features. The values of these fea-tures are language dependent. We denote the set of latent features for language l by b l .

Finally, based on the well known fact that long distance dependencies are less likely (Eisner and Smith, 2010), we bias our model towards short de-pendencies. This is done by imposing a corpus-level soft constraint on dependency lengths using the pos-terior regularization framework (Grac  X a et al., 2007). 4.1 Generative Process Our model generates dependency trees one fragment at a time. A fragment is defined as a subtree com-prising the immediate dependents of any node in the tree. The process recursively generates fragments in a head outwards manner, where the distribution over fragments depends on the head tag. If the gen-erated fragment is not empty then the process con-tinues for each child tag in the fragment, drawing new fragments from the distribution associated with the tag. The process stops when there are no more non-empty fragments.

A fragment with head node h is generated in lan-guage l via the following stages:  X  Generate the set of dependents of h via a distri- X  For each element in S decide whether it should  X  Order the sets S R ,S L . For simplicity, we as-Figure 1 illustrates the generative process. The first step constitutes the selection component and the last two steps constitute the ordering component. Given this generation scheme, the probability P ( D ) of generating a given fragment D with head h will be: P sel ( { D }| h ) Where we use the following notations:  X  D R ,D L denote the parts of the fragment that  X  { D } is the unordered set of tags in D .  X  d D ( a ) is the position (either R or L ) of the de-
In what follows we discuss the parameterizations of the different distributions. 4.1.1 Selection Component
The selection component draws an unordered set of tags S given the head tag h . We assume that the process is carried out in two steps. First the number of dependents n is drawn from a distribution: where  X  size ( n | h ) is a parameter for each value of n and h . We restrict the maximum value of n to four, since this is a reasonable bound on the total number of dependents for a single parent node in a tree. These parameters are non-negative and sat-isfy P n  X  size ( n | h ) = 1 . In other words, the size is drawn from a categorical distribution that is fully parameterized.

Next, given the size n , a set S with | S | = n is drawn according to the following log-linear model: In the above, S i is the i th POS tag in the unordered set S , and  X  sel ( S i | h ) are parameters. Thus, large val-ues of  X  sel ( S i | h ) indicate that POS S i is more likely to appear in the subset with parent POS h .

Combining the above two steps we have the fol-lowing distribution for selecting a set S of size n : 4.1.2 Ordering Component The ordering component consists of distributions P ord ( d | a,h,l ) that determine whether tag a will be mapped to the left or right of the head tag h . We model it using the following log-linear model:
P ord ( d | a,h,l ) =
Note that in the above equations the ordering component depends on the known typological fea-tures v l . In the setup when typological features are not known, v l is replaced with the latent ordering feature set b l .

The feature vector g contains indicator features for combinations of a,h,d and individual features v li (i.e., the i th typological features for language l ). 4.2 Typological Features The typological features we use are a subset of order-related typological features from  X  X he World Atlas of Language Structure X  (Haspelmath et al., 2005). We include only those features whose val-ues are available for all the languages in our dataset. Table 1 summarizes the set of features that we use. Note that we do not explicitly specify the correspon-dence between these features and the model param-eters. Instead, we leave it for the model to learn this correspondence automatically. 4.3 Dependency Length Constraint To incorporate the intuition that long distance de-pendencies are less likely, we impose a posterior constraint on dependency length. In particular, we use the Posterior Regularization (PR) framework of Grac  X a et al. (2007). The PR framework incorporates constraints by adding a penalty term to the standard likelihood objective. This term penalizes the dis-tance of the model posterior from a set Q , where Q contains all the posterior distributions that satisfy the constraints. In our case the constraint is that the expected dependency length is less than or equal to a pre-specified threshold value b . If we denote the latent dependency trees by z and the observed sen-tences by x then where f ( x,z ) computes the sum of the lengths of all dependencies in z with respect to the linear order of x . We measure the length of a dependency relation by counting the number of tokens between the head and its modifier. The PR objective penalizes the KL-divergence of the model posterior from the set Q : where  X  denotes the model parameters and the first term is the log-likelihood of the data. This objective can be optimized using a modified version of the EM algorithm (Grac  X a et al., 2007). Our model is parameterized by the parameters  X  sel ,  X  size and w ord . We learn these by maximizing the likelihood of the training data. As is standard, we add ` 2 regularization on the parameters and tune it on source languages. The likelihood is marginalized over all latent variables. These are:  X  For sentences in the target language: all pos- X  For all languages: all possible values of the la-Since we are learning with latent variables, we use the EM algorithm to monotonically improve the likelihood. At each E step, the posterior over latent variables is calculated using the current model. At the M step this posterior is used to maximize the likelihood over the fully observed data. To com-pensate for the differences in the amount of training data, the counts from each language are normalized before computing the likelihood.

The M step involves finding maximum likelihood parameters for log-linear models in Equations 3 and 4. This is done via standard gradient based search; in particular, we use the method of BFGS.

We now briefly discuss how to calculate the pos-terior probabilities. For estimating the w ord param-eters we require marginals of the type P ( b li |D l ; w t where D l are the sentences in language l , b li is the i th latent feature for the language l and w t are the parameter values at iteration t . Consider doing this for a source language l . Since the parses are known, we only need to marginalize over the other latent features. This can be done in a straightforward man-ner by using our probabilistic model. The complex-ity is exponential in the number of latent features, since we need to marginalize over all features other than b li . This is feasible in our case, since we use a relatively small number of such features.

When performing unsupervised learning for the target language, we need to marginalize over possi-ble derivations. Specifically, for the M step, we need probabilities of the form P ( a modifies h |D l ; w t ) . These can be calculated using a variant of the inside outside algorithm. The exact version of this algo-rithm would be exponential in the number of depen-dents due to the 1 n ( S Although it is possible to run this exact algorithm in our case, where the number of dependents is limited to 4 , we use an approximation that works well in practice: instead of 1 n ( S the runtime is no longer exponential in the number of children, so inference is much faster.
Finally, given the trained parameters we generate parses in the target language by calculating the max-imum a posteriori derivation. This is done using a variant of the CKY algorithm. Datasets and Evaluation We test the effectiveness of our approach on 17 languages: Arabic, Basque, Bulgarian, Catalan, Chinese, Czech, Dutch, English, German, Greek, Hungarian, Italian, Japanese, Por-tuguese, Spanish, Swedish and Turkish. We used datasets distributed for the 2006 and 2007 CoNLL Shared Tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Each dataset provides manually an-notated dependency trees and POS tags. To en-able crosslingual sharing, we map the gold part-of-speech tags in each corpus to a common coarse tagset (Zeman and Resnik, 2008; S X gaard, 2011; McDonald et al., 2011; Naseem et al., 2010). The coarse tagset consists of 11 tags: noun, verb, ad-jective, adverb, pronoun, determiner, adposition, nu-meral, conjunction, particle, punctuation mark, and X (a catch-all tag). Among several available fine-to-coarse mapping schemes, we employ the one of Naseem et al. (2010) that yields consistently better performance for our method and the baselines than the mapping proposed by Petrov et al. (2011).
As the evaluation metric, we use directed depen-dency accuracy. Following standard evaluation prac-tices, we do not evaluate on punctuation. For both the baselines and our model we evaluate on all sen-tences of length 50 or less ignoring punctuation.
Training Regime Our model typically converges quickly and does not require more than 50 iterations of EM. When the model involves latent typological variables, the initialization of these variables can im-pact the final performance. As a selection criterion for initialization, we consider the performance of the final model averaged over the supervised source lan-guages. We perform ten random restarts and select the best according to this criterion. Likewise, the threshold value b for the PR constraint on the depen-dency length is tuned on the source languages, using average test set accuracy as the selection criterion.
Baselines We compare against the state-of-the-art multilingual dependency parsers that do not use par-allel corpora for training. All the systems were eval-uated using the same fine-to-coarse tagset mapping. The first baseline, Transfer , uses direct transfer of a discriminative parser trained on all the source lan-guages (McDonald et al., 2011). This simple base-line achieves surprisingly good results, within less than 3% difference from a parser trained using par-allel data. In the second baseline ( Mixture ), pa-rameters of the target language are estimated as a weighted mixture of the parameters learned from an-notated source languages (Cohen et al., 2011). The underlying parsing model is the dependency model with valance (DMV) (Klein and Manning, 2004). Originally, the baseline methods were evaluated on different sets of languages using a different tag map-ping. Therefore, we obtained new results for these methods in our setup. For the Transfer baseline, for each target language we trained the model on all other languages in our dataset. For the Mixture baseline, we trained the model on the same four lan-guages used in the original paper  X  English, Ger-man, Czech and Italian. When measuring the per-formance on these languages, we selected another set of four languages with a similar level of diver-sity. 5 Table 2 summarizes the performance for different configurations of our model and the baselines.
Comparison against Baselines On average, the selective sharing model outperforms both base-lines, yielding 8.9% gain over the weighted mixture model (Cohen et al., 2011) and 5.9% gain over the direct transfer method (McDonald et al., 2011). Our model outperforms the weighted mixture model on 15 of the 17 languages and the transfer method on 12 of the 17 languages. Most of the gains are ob-tained on non-Indo-European languages, that have little similarity with the source languages. For this set, the average gain over the transfer baseline is 14.4%. With some languages, such as Japanese, achieving gains of as much as 30%.

On Indo-European languages, the model perfor-mance is almost equivalent to that of the best per-forming baseline. To explain this result we con-sider the performance of the supervised version of our model which constitutes an upper bound on the performance. The average accuracy of our super-vised model on these languages is 66.8%, compared to the 76.3% of the unlexicalized MST parser. Since Indo-European languages are overrepresented in our dataset, a target language from this family is likely to exhibit more similarity to the training data. When such similarity is substantial, the transfer baseline will benefit from the power of a context-rich dis-criminative parser.

A similar trait can be seen by comparing the per-formance of our model to an oracle version of our model which selects the optimal source language for a given target language (column 7). Overall, our method performs similarly to this oracle variant. However, the gain for non Indo-European languages is 1.9% vs -1.3% for Indo-European languages.
Analysis of Model Properties We first test our hypothesis about the universal nature of the depen-dent selection. We compare the performance of our model (column 6) against a variant (column 8) where this component is trained from annotations on the target language. The performance of the two is very close  X  1.8%, supporting the above hypothesis.
To assess the contribution of other layers of selec-tive sharing, we first explore the role of typological features in learning the ordering component. When the model does not have access to observed typo-logical features, and does not use latent ones (col-umn 4), the accuracy drops by 2.6% 6 . For some languages (e.g., Turkish) the decrease is very pro-nounced. Latent typological features (column 5) do not yield the same gain as observed ones, but they do improve the performance of the typology-free model by 1.4%.

Next, we show the importance of using raw tar-get language data in training the model. When the model has to make all the ordering decisions based on meta-linguistic features without account for unique properties of the target languages, the performance decreases by 0.9% (see column 3).
To assess the relative difficulty of learning the ordering and selection components, we consider model variants where each of these components is trained using annotations in the target language. As shown in columns 8 and 9, these two variants out-perform the original model, achieving 61.3% for su-pervised selection and 63.7% for supervised order-ing. Comparing these numbers to the accuracy of the original model (column 6) demonstrates the dif-ficulty inherent in learning the ordering information. This finding is expected given that ordering involves selective sharing from multiple languages.

Overall, the performance gap between the selec-tive sharing model and its monolingual supervised counterpart is 7.3%. In contrast, the unsupervised monolingual variant of our model achieves a mea-ger 26%. 7 This demonstrates that our model can ef-fectively learn relevant aspects of syntactic structure from a diverse set of languages. We present a novel algorithm for multilingual de-pendency parsing that uses annotations from a di-verse set of source languages to parse a new unan-notated language. Overall, our model consistently outperforms the multi-source transfer based depen-dency parser of McDonald et al. (2011). Our ex-periments demonstrate that the model is particularly effective in processing languages that exhibit signif-icant differences from the training languages. The authors acknowledge the support of the NSF (IIS-0835445), the MURI program (W911NF-10-1-0533), the DARPA BOLT program, and the ISF (1789/11). We thank Tommi Jaakkola, Ryan Mc-Donald and the members of the MIT NLP group for their comments.
