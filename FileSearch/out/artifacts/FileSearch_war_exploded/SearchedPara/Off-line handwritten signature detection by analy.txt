 ORIGINAL PAPER Jos X  L. Esteban  X  Jos X  F. V X lez  X   X ngel S X nchez Abstract One fundamental step in off-line handwritten sig-nature verification is the detection of the signature position within the document image. This paper introduces an orig-inal approach for signature position detection. The method is based on an accumulative evidence technique, searching the region that maximizes some measure of correspondence with a given reference signature. This measure is based on the similarity of the slope marked out by each of the strokes in the signature. Experiments have shown that the method can be used on real documents, such as bank checks, where images have a high noise level due to background interfer-ences (i.e. machine or handwritten texts, stamps, and lines). The proposed method is robust to variability in the size of the signatures and has the advantage of using only one reference signature per person. 1 Introduction Historically, handwritten signatures have been used to authenticate documents, and they are in widespread use today for the payment of bank checks in many countries. A typi-cal way of committing fraud in bank checks consist in using forged signatures in falsified checks (28%), or in genuine checks (30%) [ 1 ]. That being so, financial institutions are very interested in detecting checks that carry forged sig-natures. A bank institution can process around one million checks per day in a country like Brazil [ 13 , 17 ].
This high volume of checks makes the task of signature verification a labor-intensive operation where the introduc-tion of automatic systems may be cost-effective.

Prior research on the problem of off-line signature has been focused almost exclusively on the aspects of signa-ture verification and identification [ 22 , 29 ] in the context of biometric authentication. Signature verification consists in deciding whether a sample signature is genuine or a forgery by comparing it with one stored reference signature. Signa-ture identification is essentially a problem of writer identifi-cation and the objective consists in finding the identity of the signer from a test sample given a database of signature exem-plars from different writers. In general, most work assumes that the issue of signature detection and segmentation has been solved [ 22 ], which is not realistic in practical applica-tions [ 32 ]. 1.1 Signature detection Detecting signatures and their exact position in real docu-ments is a challenging task in several ways. First of all, the detection needs to remain unaffected by intra-class varia-tions due to external factors (i.e. different pens, variable size of the signing region, and differences in the background). It must also be stable and robust when facing writer fac-tors (i.e. age, emotional state, and illness). Secondly, the method also needs to be hold its own where there are noisy backgrounds.

The signature detection problem presents some important aspects to be considered when applied to real documents (in special to bank checks):  X  Document backgrounds are not known beforehand. In the  X  Many kinds of documents are subject to restricted pro- X  Industrial-scale document scanning requires small image  X  Some documents (i.e. bank checks and/or different types
The automatic off-line handwritten signature detection problem in noisy documents has received very little attention in the literature, compared to the off-line signature verifica-tion problem [ 32 ]. However, a practical signature verification system working on real documents needs from a robust sig-nature location stage.

One of the first works that handled the signature detec-tion problem in checks was based on the filiformity criterion proposed by Djeziri et al. [ 8 ], where each pixel in the doc-ument image is firstly labeled as belonging or not to hand-written text. However, this approach does detect not only the signature in the documents but also other filiform adja-cent elements (i.e. lines and handwritten text). Hobby pre-sented a method for signature location in checks [ 12 ], which was based in a skeletonization of the document components. Later, these components are grouped and labeled as text lines, signatures, stamps, etc. This approach is general for many types of documents, but it does not consider the presence of noise, like the background check texture. Madasu et al. [ 19 ] proposed a simple pixel-based cropping algorithm to extract the signature from bi-tonal document images. However, this algorithm assumes that the signatures are free of noise and placed in a determined document position. The same authors presented in 2005 a more robust location method [ 20 ] that analyzed the local entropy (using a sliding window) in differ-ent document regions. Then, adjacent text components with similar entropy values are identified as a part of the signature. The effect of noise in the documents was not considered in this work. Jayavedan et al. [ 14 ], also in 2005, proposed an automatic signature extraction approach based on variance analysis in a grid placed on the probable signature position in gray-level check images. In 2006, Larrea et al. [ 16 ] proposed a signature verification system that addressed the elimination of noise placed near the signature. Due to the complexity of the noise, this last system was not fully automatic, but human assisted.
 All the mentioned works search for a generic signature. They do not consider that the signature detection is normally followed by a verification stage where the specific signature to be detected is known beforehand. An algorithm can take advantage of that fact searching for a specific shape, which can be very useful when the document has noise or contains several signatures. In 2008, this possibility was considered in the PhD Thesis of one of the authors [ 26 ]. More recently, Zhu et al. also have also considered it in an independent work [ 32 ]. 1.2 Evidence accumulation There are different practical applications in contexts of uncer-tain information where it is necessary to reason on the basis of data from multiple sources obtained by information fusion. The aim of this kind of reasoning is to identify the most likely alternatives from a set of options by accumulating evidence. This approach is related to Dempster X  X hafer theory and to Bayesian evidence accumulation. Different approaches based on evidence accumulation have been proposed to address problems related to different application domains successfully. Classical applications correspond to general-izations of Hough transforms to detect lines [ 23 ] and differ-ent types of curves [ 31 ]. The evidence accumulation method for detecting certain shapes in medical images can be found, for example, in the work by Chmielewski [ 6 , 7 ] for detecting blood vessels in mammograms or in the work by Lee et al. [ 18 ] for prosthesis control using EMG signals. Another inter-esting application corresponds to the data clustering domain, where the accumulation principle has been proposed to com-bine the results from multiple clusterings into a single data partition [ 10 ]. Some other application areas where evidence accumulation has been used to accomplish reasoning from uncertain data are the following: Image Understanding [ 2 , 5 ], Remote Sensing [ 3 ], Sensor-based Robotics [ 24 ] or Cogni-tive Psychology [ 28 ], among others.

Our work proposes a method, based on an evidence accu-mulation approach, to tackle the problem of detecting hand-written signatures in realistic conditions. Stockman [ 25 ] roughly classified the methods for object recognition in two types: sequential hypothesis test and evidence accumula-tion. A sequential hypothesis test (or template matching) directly matches the internal object model with an input image at all possible object poses. The information gathered during a failed test is usually neither "reused" nor "accu-mulated" in this approach. As a result, this strategy implies high computational costs. In contrast, evidence accumula-tion for object recognition aggregates partial matching evi-dences to form a global pose hypothesis. This method is computationally much more efficient and more suitable for parallelization than a template-matching approach. Evidence accumulation in Pattern Recognition started with the Hough transform [ 9 ], followed by a generalized Hough transform [ 4 ], pose clustering [ 25 ], and evidence accumulation itself [ 15 ]. This last approach has been applied in different con-texts, like the face detection system proposed by Park and Yang [ 21 ]. 1.3 Paper organization The paper is organized as follows. Section 2 presents our signature detection method based on evidence accumula-tion. Section 3 describes the complete experimental frame-work carried out. Finally, Sect. 4 outlines the conclusions and future work. 2 Proposed method The proposed method attempts to detect the position of a signature in a noisy test image from a real document, given a clean model signature. The method compares the distribu-tion of strokes in the model signature against the distribution of strokes in the test image using an evidence accumulation approach.

The method consists of two main stages: stroke extraction and characterization, and evidence accumulation. This sec-ond step is executed in a progressive refinement cycle. These steps are described in the following subsections. 2.1 Stroke extraction and characterization stage To extract the strokes, the first step is to obtain the internal and external contours of the binary image. This process is per-formed by applying a simple morphological contour extrac-tion operator [ 11 ]. Figure 1 shows the result for a zoomed region of a sample signature. The signature is then trans-formed into a list L of closed contours.

In a second step, each contour in L is tracked and par-titioned into segments of limited size. This process is con-trolled by two parameters: the length of the segment in pixels and the interval from the start of a segment to the start of the next segment, also measured in pixels.

Each segment is then characterized by a 4-tuple ( x , y , ,  X ) , where  X  x and y are the coordinates of the segment middle  X  is the angle of the tangent to the segment passing  X   X  corresponds to the curvature of the segment, determined In order to compute the angle and the curvature, we use an approximate calculation. Only three points from each seg-ment are considered: the initial point ( x ini , y ini dle point ( x mid , y mid ) , and the end point ( x end , points define an elliptical arc that approximates the shape of the segment.

The angle value can be obtained as = arctan y where x = x end  X  x ini (2) y = y end  X  y ini (3)
And the segment curvature value  X  , determined by the osculating circle, can be obtained as proposed by [ 30 ]:  X  = x y where
It must be observed that the number of segments obtained from an image can be very high. Considering the noise-free background sample of Fig. 3 a, and using a segmentation interval of one pixel, a total of 1,995 segments are obtained. In a real document image, the number of segments is much higher. Figure 3 b presents a sample obtained from a check scanned at 200 DPI.

As long as it is not known which segments belong to the signature and which ones belong to the background, it is nec-essary to compute all the segments in the region where the signature is expected, here after called the signature search region. In checks, the signature search region roughly cor-responds to the bottom-right quarter of the image. The seg-ment extraction method generates 13,048 segments from the sample in Fig. 3 b. Table 1 summarizes the expected number of segments that can be obtained by the segment extraction method at two different resolutions. 2.2 Evidence accumulation stage Once each image segment is characterized as previously described, a method based on the evidence accumulation approach is applied. The method consists in obtaining the cor-respondence vector from each segment in the model signature to each segment of the signature search region. As result, a set of 4-dimensional vectors is obtained. It is assumed that the larger cluster in such a set determines the position of the signature in the document.

Therefore, for each segment pair, one from the model sig-nature m and another from the signature search region s , a vector d ( m , s ) is computed using Eq. 7 . The subindexes m and s are related to the model and to the search region, respectively. d ( m , s ) = ( x s  X  x m , y s  X  y m ,( s  X  m +  X  / 2 ) Note that position and curvature differences are calculated straightforward by subtraction, while angle difference must be restricted to the interval [ X   X  / 2 ,  X  / 2 ) .
Consider from Table 1 a sample signature at 200 DPI, the model segment set S m has more than 10 3 segments, the signature search region segment set S s is in the order of 10 segments, and therefore the cardinality of the set S d , contain-ing all possible differences between S m and S s , is over 10 Moreover, a further clustering algorithm iterates on S d in an O ( n  X  ) process, so the total number of operations is over 10 Since the sets involved are quite large, a sub-sampling tech-nique is required. Using a randomly chosen sub-sampling in our experiments, only 10 6 elements from S d were considered, creating a new subset S d .

In a final step, an evidence accumulation process was applied on S d . In this process, the 4-dimensional space ( x , y ,, X ) was cropped and divided into classes in each dimension. A n 4 grid was generated to perform the accu-mulation of the S d vectors. The grid is determined by the maximum and minimum values for each dimension, which is divided into n equally spaced cells. The grid cell holding the maximum number of accumulated vectors determines the most likely position of the model signature within the signa-ture search region.

In order to improve the detection of the test signature, this process is repeated reducing the grid limits around the most populated cell in each iteration (see Fig. 4 ). The Algo-rithm 1 describes the method proposed. The stop criterion of this algorithm is based on a time budget. The iterative refinement cycle is applied until a fixed amount of time is consumed. This may seem arbitrary, but it complies with the time restrictions required by real industrial-scale appli-cations.
 Algorithm 1 Detection of a reference signature in a signature search region. The algorithm returns a rectangle of the same size as the reference image located on the test image. 3 Experiments Our experimentation is based on the public GAVAB signa-ture database [ 27 ]( http://www.gavab.es/recursos.html ) and on a set of check backgrounds. The signature database used contains 266 signatures from 54 individuals. There are between 4 and 8 signatures from each subject. Ten of them signed on different dates, with 2 years between the signings. The signatures were produced with different pens using col-ors black and blue to reproduce some of the intra-personal variabilities when signing.

The background set consists of five different check back-ground images obtained from real checks without signatures (see Fig. 5 ). A white background model is also considered in order to check the behavior of the method also in the best possible conditions.

As the signature can be placed in a wide region inside the check, all the 5 considered backgrounds present differ-ent practical problems (see Fig. 6 ), like overlapping with the MICR digits, reference lines, machine or handwritten texts, and background textures.

The signatures from only three individuals were used to set the parameters of the model (see Table 2 ). The signa-tures of the remaining 51 individuals were used for testing purposes. Basically, each signature was searched for in each synthetic test image. A synthetic test image consists of a signature placed over the background image in a random position within the signature search region (see Fig. 3 ). A synthetic test image was generated for each signature in the database and for each check background image. For exam-ple, having 4 signatures from one individual, and using one of them as model and the three remaining ones as tests, 4 possible comparisons can be performed, and using the 6 back-ground images, 72 tests are obtained. Given that the database contains individuals with a different number of signatures (from 4 to 8), the total number of signatures was 1,336, which multiplied by 6 possible backgrounds gives a total of 8,016 tests. 3.1 Results For each detection test, the proposed method generates a rect-angular region, which has the same size as the model signa-ture size. This region must be compared with the rectangle where the signature was positioned on the synthetic image. In order to obtain some quantitative results, the following overlapping measure between rectangles A and B has been defined: overlap ( A , B ) = area ( A  X  B )/ max  X  x  X  R  X  where the x subindex denotes translation.

Figure 7 shows different cases of overlapping. It could seem surprising that 100% of overlapping is assigned to both cases in Fig. 7 a. This is because no better overlapping option is possible between the rectangles involved if no other oper-ation than translation is allowed.

Like Zhu et al. [ 32 ], we have considered that the detection method produces a positive result if the overlapping region, between the region found and the expected one, is higher than 80%. The average results obtained, using this criterion, show around 78.9% of success. Table 3 summarizes the average results on the backgrounds considered. Note that when the signature used to create the synthetic image is identical to the model signature, the results come close to 100% of effective-ness, even with noisy backgrounds. However, the results fall to 80% when both signatures are different. Even in the case of the white background, the results give only 90.1% of success.
Our results are slightly better than 83.3% reported by Zhu et al. [ 32 ]. However, the noise corresponding to the back-ground images used in our work is much higher than that pre-sented in the Tobacco-800 documents used by these authors.
Intra-personal variability also has some influence on the results. In order to measure the robustness of the proposed method against this variability, three variables have been con-sidered: area, aspect ratio, and the date when the signature was produced. Both, area and aspect ratio, are computed with reference to the bounding box.

Given a reference and a test signature, we define the area rate by Eq. 9 and the aspect ratio by Eq. 10 . Note that the loga-rithm term is introduced in order to eliminate the asymmetric distribution coming about from the division effects. r  X  The distribution obtained for the area proportion (see Fig. 8 ) shows that most samples are located in the [  X  0 interval. These results also show that in this interval, the results are stable. In other words, our algorithm produces good results when the area of the test signature lies in the range between 0.7 and 1.4 its size, which is the usual case.

In a similar way, the distribution obtained for the aspect ratio proportion (see Fig. 9 ) shows that most of the correct results are located in the [  X  0 . 4, 0.3] interval. This means that the proposed algorithm produces good results again when the proportion between the aspect ratio of the test signature and that of the model aspect lies roughly between 0.75 and 1.25, which is also the usual case.

Table 4 shows the results when considering signature date variations. As it can be observed, best results are obtained when both, the model signature and the test image, come from the same date.

Moreover, our results have been analyzed as a function of the signer. From Fig. 10 , it can be observed that some signatures produced better detection results than other ones. Our analysis shows that there exists a correlation between the complexity of the signature (number of strokes and connected components) and the corresponding detection success. The method proposed works better on complex signatures, this is due to the fact that the accumulative evidence approach generates more evidence.

In our tests, the time window is configurable to achieve the time budget requirements of the real application. We used 1 s as our time limit and an Intel Centrino Duo 1.7 GHz with 2 GB of RAM memory for the experiments. ( a ) Total overlap-( a ) (b) 3.2 Comparison with other methods To validate the proposed approach, we compare it with two related methods in the literature proposed by Madasu et al. [ 19 , 20 ]: ( a ) (b)  X  The first one consists of a filtering process and a crop.  X  The second one, more robust to noise, is based on the Our evidence accumulation X  X ased approach is compared to both methods [ 19 , 20 ] using the same methodology men-tioned in the previous section. So, 6,680 images, using the 5 different backgrounds of Fig. 5 , were generated for test purposes.

The overlapping definition of Eq. 8 must be changed to allow the comparison with these two methods. As these meth-ods do not use any model signature, it is not possible to get the better overlapping option as a reference to compare. So, a new overlapping measure is defined using Eq. 11 , where A represents the minimum rectangle which contains the signa-ture and B represents the rectangle returned by the detection algorithm. overlap ( A , B ) = area ( A  X  B )/ area ( A  X  B ) (11)
In this case, the obtained overlapping value has no direct interpretation. However, using a threshold of 55% for the value from Eq. 11 yields similar results to those reported in Table 3 , obtained by Eq. 8 . So, using this threshold for the three methods on 6,680 synthetic test images, we obtain the results presented in Table 5 .

As it can be observed in Table 5 , the Crop method [ 19 ]pro-duced the worst results. The Entropy method [ 20 ] performed similar results to our method when the background is free from figures and textures (backgrounds b and d ). However, in the presence of figures (background a ) and particularly in presence of textures (backgrounds c and e ), the proposed method performed better results than the other two. 4 Conclusion An original approach for off-line signature position detection in real documents has been presented. The method is based on the evidence accumulation approach, and it is derived from the features of signature strokes. This is different from the common object detection approach that focuses on sets of local properties.

Our method has been designed to work in practical sig-nature detection conditions where only one reference signa-ture per person is captured. Moreover, due to its incremental design, the method is time limited. This means that the longer the processing time is allowed, the better detection results would be achieved.

The experiments have shown that the method achieved very competitive results on real documents with a high level of noise and with common variability conditions in the sig-natures on the documents.

As future work, we will study the influence of document image resolution on the method performance. Moreover, we will compare our approach with other using real documents, for example, the public Tobacco-800 dataset [ 32 ]. Another relevant study will be to analyze the behavior of the method on documents with more than one signature, including over-lapping ones. Finally, this method, like most evidence accu-mulation approaches, can be concurrently implemented very straightforward. Therefore, we are working on the algorithm parallelization using a GPU.
 References
