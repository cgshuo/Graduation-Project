 1. Introduction
Anger, fear, sadness, disgust, happiness, surprise. Any human being is able to relate to these emotions, give examples of situations when they can be felt and the possible manners in which they can be expressed. In many cases, such expressions contain little or no affect-related word [30]; they simply describe the experience, in a way in which it can be audience [3,4].

Using the common knowledge about the emotions felt in such a situation, the audience can deal with this task [39].

Bearing these considerations in mind, we can see that in order to detect affect from text, it is important to a) employ mechanisms to model the semantics of the situation it describes; and b) implement the mechanism governing the cause affect-eliciting situations.

For the first task, we chose ontologies. Until not long ago, to gather and model such knowledge on situations (in a manner in which it can gradually be enriched and new knowledge can be inferred based on it) was almost impossible. However, today, the extension and give the possibility to perform inferences on the data they contain: ontologies [25,11,22] .
For the second task, among the different psychological theories of emotion explaining the causes of affective states (see for (knowledge of the meaning of the situation, its implications), as well as on their goals and opportunities for action.
Employing these mechanisms, we created EmotiNet, a knowledge base that: 1. Can be used to model affective reaction to real-life situations described in text, based on the psychological model of the
Appraisal Theories. interaction, based on the proposed model. sources  X  lexical (e.g.,  X  Core WordNet  X  ,  X  VerbOcean  X  (e.g., new examples of situations that trigger emotion, such as the ones gathered by the 4. Can be employed to propose, validate and evaluate a method to detect emotion in texts that contain little or no explicit expressions of emotion, such as the situations described in the International Survey of Emotion Antecedents and Reactions ( [37] , ISEAR).

In this article, we describe the manner in which we gradually built EmotiNet, the different stages in which it was extended,
Additionally, we comparatively analyse the performance of employing other existing methods on such data, to demonstrate the usefulness of our new resource. Results of the evaluations show that our approach to detecting emotion from texts based on
EmotiNet outperforms existing methods, demonstrating its validity and the usefulness of the created resource for the emotion detection task. 2. State of the art
In Psychology, the major theories of emotion can be grouped into different categories. Traditionally, these categories are: state that the most important role in the formation of emotions is held by thoughts and other mental activity. In Artificial Intelligence (AI), the term affective computing (AC) was first introduced by [31] .
Previous approaches to spot affect in text include the use of models simulating human reactions according to their needs and desires [13] , fuzzy logic [41] , lexical affinity based on similarity of contexts [40] or SentiWordNet [14] , detection of affective keywords [34] and machine learning using term frequency [27] , or term discrimination [10] . Other proposed methods include the creation of syntactic patterns and rules for cause
Significantly different proposals for emotion detection in text are given in the work by [20] and the framework of sentic computing [8] , whose scope is to model affective reaction based on commonsense knowledge. For a survey on the affect models and their AC applications, see [7] .

The set of models in psychology known as the  X  Appraisal Theories GENESIS. The appraisal models have also been studied and employed in systemic functional linguistics [23] .
As far as knowledge bases are concerned, many NLP applications have been developed using manually created knowledge repositories such as WordNet [15] , CYC, 1 ConceptNet or SUMO. to extract ontology concepts. Finally, [18] proposes a model of representing emotions using ontologies. 3. Motivation and contribution
Existing models of emotion detection are able to spot mainly direct expressions of affect. The use of knowledge-rich methods (such as dictionaries) can lead to the correct classification of examples, such as (1) etc., because such dictionaries contain words like  X  happy
Examples containing negations, such as (4)  X  I am not feeling happy corresponding rules to pass from one emotion to the other.

Other types of examples would be more difficult to classify by dictionary-based models. (5) that the bigram wedding anniversary is associated to examples of sentences expressing
Another method to overcome this issue is proposed by [20] and [8] . The main idea behind these approaches is to acquire knowledge on the emotional effect of different concepts.

In this manner, the system would know not only that this specific bigram relates to the the concepts  X  anniversary  X  or  X  party  X  are related to  X  by using the concepts that are related to it instead.

Nonetheless, such examples would also fail to classify well the emotion expressed in more complex settings, such as (6) husband hadn't died, today we would be celebrating our 50th anniversary. the text cannot be considered as a mark that the respective sentence directly contains that emotion. whose general affective value is different (e.g., (7)  X  The man killed the mosquito climbed into my lap  X  versus (10)  X  The pig climbed into my lap started wagging his tail as I approached  X  ).
 criteria.

To be able to represent and apply inference to such contexts is not an easy task. The quantity of commonsense knowledge required is tremendous.

However, most of it is already present in existing commonsense knowledge bases (e.g., CYC, SUMO or ConceptNet). Given a external sources, resulting in a deep semantic representation of the situations, from which emotion can be detected in a more precise way. Bearing this in mind, we created EmotiNet [2] of the process employed is described in the following section. 4. Building a knowledge base of action chains: EmotiNet Our approach aims at modelling real situations and their corresponding emotional effect as chains of actions, using the
EmotiNet ontology and its corresponding knowledge base. According to the definition provided by [33] , ontologies capture of the managed knowledge needs to be widely accepted and to combine heterogeneous sources of common knowledge to avoid model the interaction of different events in the context in which they take place and add inference mechanisms to extract on the properties of emotions and the manner in which they combine. In this way, we can account for the differences in of concepts.

More specifically, our approach defines the EmotiNet ontology and knowledge base taking into account all the given sections. 4.1. ISEAR  X  Self-reported affect
In the International Survey of Emotional Antecedents and Reactions (ISEAR the questions covered the way that they had appraised the situation and how they reacted. An example of entry in the ISEAR databank is:  X  I felt anger when I had been obviously unjustly treated and had no possibility to prove they were wrong. attached to one single emotion. In order to have a homogenous starting base, we selected from the 7667 examples in the ISEAR by the output of the clusters, was to group examples that are similar, in vocabulary and structure. 4.2. Modelling situations with semantic roles
From each of the examples obtained from ISEAR, we extracted the actions described using the semantic role labelling (SRL) emotion), which we denote by T (the remaining examples are used for testing). The criteria for choosing this subset were the simplicity of the sentences and the variety of actions described. We processed these examples using the SRL system and, subsequently, we manually extracted the agent, the verb and the patient from the output. For instance, from the situation sister was saving money for her tuition fees and I took it to buy a new smartphone. After that, I felt very guilty. smartphone) and (I, feel, guilty).
 the text that is closest to the anaphoric reference and whose properties (gender, number) are compatible with the ones of the reference. The replacement of the references to the speaker, e.g. within the sentence, which actually specify the position of each action on a temporal line (e.g., 4.3. Modelling emotions
In order to describe the emotions and the way they relate and compose, our approach combines Robert Plutchik's wheel of comprised in the ISEAR databank and they explicitly model the relations among the emotions. Plutchik's wheel of emotions annotators in parallel, obtaining a kappa value of 0.83. Those cases in which the annotators disagreed were discussed and a common decision was taken.
 4.4. Designing the EmotiNet ontology
The process of building the core of the EmotiNet knowledge base of action chains started with the design of the core of knowledge, in our case an ontology, whose design process was divided in three stages: required in a general manner, which will allow it to be expanded and specialised by external knowledge sources. Specifically, the EmotiNet ontology needs to capture and manage knowledge from three domains: kinship membership, emotions (and their relations) and actions (characteristics and relations between them). representation: the ReiAction ontology, 4 which represents actions between entities in a general manner, and the family relations ontology, 5 which contains knowledge about family members and the relations between them. emotion, and the combination of the different knowledge sources into a single ontology: EmotiNet. We designed the emotion knowledge core based on the combination of the mentioned models of emotion. This core represents the concept of emotion, joy).

In the last step, these three cores were combined using new classes and relations between the existing members of these ontologies (see Fig. 1 ). 4.5. Extending and populating EmotiNet with real examples
Once the core ontology was designed, we extended it with new types of action and action chains (as instances of the ontology) using real examples from the ISEAR corpus. For this, we employed the T set. Once we carried out the processes described to the KB. When these did not exist, we created new concepts to represent them.
 as mentioned before, determine the final emotion felt by the main actor(s) of the chain.
 act1 (  X  daughter  X  ,  X  Save  X  ,  X  money  X  ,  X  Joy  X  ); instance act2 ( existed within EmotiNet and were reused from other chains: instance act3 ( (  X  daugther2  X  ,  X  Feel  X  ,  X  Guilty  X  ,  X  Guilt  X  ).

Subsequently, we grouped these instances into sequences using instances of the class Sequence, which is a subclass of Action that can establish the temporal order between two actions (which one occurred first). Fig. 2 shows an example of a RDF graph, instances that express different emotions and how actions triggered them.

In order to store and manage the EmotiNet knowledge base we used the Jena framework management system. 4.6. Expanding EmotiNet with existing NLP resources
In order to extend the coverage of the resource and, at the same time, reduce the dependency with the initial set of ISEAR domains.

In our preliminary experiments, we gradually extended EmotiNet using different types of resources. Some of them served for used for extending EmotiNet and the manner in which they were used. We briefly present the manner in which EmotiNet was extended with each of these resources. 5. Expanding EmotiNet with new knowledge from web sources
The resources used in the first experiments are high in accuracy and some of them, e.g., ConceptNet or WordNet, have a high on individual actions found in these chains.

In order to extend the knowledge on emotion-triggering situations in EmotiNet (whole action chains, as the ones contained in the EmotiNet core), we extracted the information of the WeFeelFine portal (wefeelfine.org) using its public API. world's newly posted blog entries for occurrences of the phrases sentence, up to the period, and identifies the  X  feeling  X 
We extracted a maximum number of 1500 examples per emotion per year, from 2004 to 2011 in order to have a sufficiently large the situations related to the emotion  X  joy  X  for the year 2004 (in WeFeelFine, the situations associated to 2004&amp;feeling=happy&amp;limit=1500 .
 Table 2 shows the number of examples retrieved by executing a collection of queries for all the 7 emotions found in ISEAR.
The examples obtained from WeFeelFine were processed in the same manner as the initial examples from ISEAR, included in process, we also eliminated those examples that contained only auxiliary verbs, only the verb negated modal verbs (e.g.,  X  shouldn t  X  ). Table 2 also illustrates the number of action chains resulting from the whole process with the WeFeelFine examples.
This collection of examples, which we subsequently use in our evaluations, is denominated WFF . 6. Experiments and evaluation 6.1. Using EmotiNet to detect affect from text: Experimental setup
The evaluation of our approach consists in testing if by employing the model we built and the knowledge contained in the core categories in ISEAR.

In order to assess the accuracy of the EmotiNet KB in the context of the implicit emotion detection task, we performed three types of experiments, which take into account the type of resource with which the KB was extended and the objective it serves i.e., to extend the knowledge on the actions or the emotions that they trigger. The goal is to analyse their differences and subsequently design a combined approach. These three types of approaches are:  X 
Experiments using the EmotiNet action chains and action similarity. When a new situation is assessed, we automatically obtain an action chain of the text and, subsequently, we compute the similarity between the emotion chain of the new situation and score. This type of experiments were performed by [2] on the EmotiNet core (EN), and on EN with different combinations of resources  X  VerbOcean (VO), WordNet Affect (WNA) and Core WordNet (WNC). Subsequently, we added the new situations in the WFF corpus to the core of knowledge in EmotiNet and added the same resources to extend the knowledge
WNC. A comparative analysis of these results is presented in Fig. 3 in terms of Precision, and in Fig. 4 in terms of Recall.  X 
Experiments using the EmotiNet emotion chains and emotion similarity. This second set of experiments is based on the use of the implies relationship, which associates an action to the possible emotions felt by the agents of that action. We have performed different experiments in which we have automatically annotated the actions contained in EmotiNet using a different to the first one.
 new situation and the EmotiNet emotion chains. The resulting emotion has the same label as the EmotiNet action chain with the highest similarity score. This type of experiments were performed by [2] on EmotiNet, on the extension of this core using ConceptNet (CN), as well as the extension using CN and SentiWordNet (SWN). The results are presented in Table 3 . Further on,
EmotiNet was extended with LIWC, WNA, VO and CWN and tested using this approach, in different combinations of the EmotiNet core with these resources. Due to the fact that the resource employed to assign emotions to the action links contained information on 3 emotions  X  anger, fear and sadness presented in Fig. 5 . 1. Experiments combining the two previous approaches, in which each situation was assigned one emotion, based on the action similarity, computed on the extension of EmotiNet with VO, WNA and CWN and the emotion similarity, computed based on the extension of EmotiNet with WNA, VO and CWN. The comparative results are presented in Fig. 6 . 7. Detecting Emotion in text using affect lexica and external knowledge 7.1. Emotion detection in text using affect lexica subsequently performed a series of experiments in which we represented the examples in test sets A, B and T as vectors whose features accounted for the presence of words from the two lexical resources and then applied SVM SMO. Table 4 presents the set T and testing on set B.
 ones obtained using EmotiNet. 7.2. Affect detection in text using external knowledge
In order to test the impact of the external knowledge we added from the WFF corpus on the performance of a supervised do this, we represented each example in the WFF collection as a vector that has as features the presence of n-grams (unigrams and unigrams and bigrams, respectively) that are found in all WFF examples. Subsequently, we represented the examples in the
ISEAR test set (T) according to the presence or absence (1 or 0, respectively) of the same unigrams and unigrams and bigrams, respectively contained in the WFF examples. The results of the experiments using the unigram representation are presented in
Table 6 and the results of the tests employing both unigrams, as well as bigrams as features are presented in Table 7 . 8. Discussion
Comparing the results obtained using the different extensions of EmotiNet with the ones obtained using lexicon-based methods, detection task.

The results obtained using EmotiNet, employing the same quantity of learning (or training) data, are overall better in all
Comparing the  X  Action Similarity  X  versus the  X  Emotion Similarity overall better, the results among the different categories of emotion remaining balanced. In contrast to that, the approaches linking actions to emotions (e.g. LIWC and WNA); and b) the resulting ambiguity of the examples when information about the or sadness and anger, is more difficult.

Based on the results obtained when extending the core of knowledge employed with new examples of emotion-triggering
Web brings much noise (an effect that is increased even further by the fact that the action chains are extracted using a SRL system). This type of extension also proves that EmotiNet is easily extendible (also as the core of knowledge is concerned), corrected).
 9. Conclusions and future work we proposed different methods to extend the EmotiNet, a knowledge base that we previously created and which contains action plain textual data sources. We further on presented three different methods to employ EmotiNet and its extensions to detect implicitly expressed emotion from text. Finally, we presented comparative experiments using traditional methods for emotion detection from text, with the purpose of showing the usefulness and appropriateness of EmotiNet in this context.
From our extensive evaluations, we can conclude that our approach is appropriate for detecting emotion in text, although additional elements should be included in the model and extra knowledge is required. Moreover, we found that the process of to improve the output. We must also test our approach on corpora where more than one emotion is assigned per context.
Future work aims at extending the model by adding properties to the concepts included, so that inference methods can be applied and a more abstract model of the emotion phenomena can be extracted. Alternatively, we plan to test new methods to assign affective value to the concepts and adding new knowledge from sources such as CYC and test the inclusion of massive the scheme to include linguistic markers that make for the structure of the text.
 Acknowledgments
The work of the authors affiliated to the Department of Software and Computing Systems at the University of Alicante has been supported by the Spanish Ministry of Science and Innovation (grant no. TIN2009-13391-C04-01), by the Spanish Ministry of
Education under the FPU Program (AP2007-03076), and by the Valencian Ministry of Education (grant no. PROMETEO/2009/119 and ACOMP/2010/288).

References
