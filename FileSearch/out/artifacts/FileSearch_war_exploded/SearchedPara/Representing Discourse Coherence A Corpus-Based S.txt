 University of Cambridge set of discourse relations introduced here is based on Hobbs (1985).
 annotate a database of 135 texts from the Wall Street Journal and the AP Newswire .Alltexts were independently annotated by two annotators. Kappa values of greater than 0.8 indicated good interannotator agreement.
 many different kinds of crossed dependencies, as well as many nodes with multiple parents. The claims are supported by statistical results from our hand-annotated database of 135 texts. 1. Introduction
An important component of natural language discourse understanding and production is having a representation of discourse structure. A coherently structured discourse here is assumed to be a collection of sentences that are in some relation to each other. This article aims to present a set of discourse structure relations that are easy to code and to develop criteria for an appropriate data structure for representing these relations. structure and coherence relations. These approaches differ with respect to what kinds of discourse structure they are intended to represent. Some accounts aim to represent tors X  intentions relates to the role played by another segment (e.g., Grosz and Sidner these accounts, coherence relations reflect how the meaning conveyed by one discourse segment relates to the meaning conveyed by another discourse segment (e.g., Hobbs 1985; Marcu 2000; Webber et al. 1999). Furthermore, accounts of discourse structure vary greatly with respect to how many discourse relations they assume, ranging from 2 (Grosz and Sidner 1986) to over 400 different coherence relations (reported in Hovy and
Maier [1995]). However, Hovy and Maier (1995) argue that, at least for informational-level accounts, taxonomies with more relations represent subtypes of taxonomies with fewer relations. This means that different informational-level-based taxonomies can be compatible with each other; they differ with respect to how detailed or fine-grained a manner they represent informational structures of texts. Going beyond the question of how different informational-level accounts can be compatible with each other, Moser and Moore (1996) discuss the compatibility of rhetorical structure theory (RST) (Mann and Thompson 1988) with the theory of Grosz and Sidner (1986). However, note that Moser and Moore (1996) focus on the question of how compatible the claims are that
Mann and Thompson (1988) and Grosz and Sidner (1986) make about intentional-level discourse structure.
 relations that hold between sentences or other nonoverlapping segments in a dis-course monologue. We describe an account with a small number of relations in order to achieve more generalizable representations of discourse structures; however, the number is not so small that informational structures that we are interested in are obscured. The goal of the research presented is not to encode intentional relations in texts. We consider annotating intentional relations too difficult to implement in practice at this time. Note that we do not claim that intentional-level structure of discourse is article.
 mostly based on Hobbs (1985). We try to make as few a priori theoretical assumptions about representational data structures as possible. These assumptions are outlined in the next section. Importantly, however, we do not assume a tree data structure to trees do not seem adequate to represent discourse structures.
 collect a database of 135 texts annotated with coherence relations. Section 3 describes in detail the descriptional inadequacy of tree structures for representing discourse coherence, and Section 4 provides statistical evidence from our database that supports this claim. Section 5 offers some concluding remarks. 2. Collecting a Database of Texts Annotated with Coherence Relations
This section describes (1) how we defined discourse segments, (2) which coherence relations we used to connect discourse segments, and (3) how the annotation procedure worked. 2.1 Discourse Segments There is agreement that discourse segments should be nonoverlapping spans of text.
However, there is disagreement in the literature about how to define discourse segments (cf. the discussion in Marcu [2000]). Whereas some argue that discourse segments should be prosodic units (Hirschberg and Nakatani 1996), others argue for intentional units (Grosz and Sidner 1986), phrasal units (Lascarides and Asher 1993; Longacre 1983; Webber et al. 1999), or sentences (Hobbs 1985).
 segments. We chose this method of segmenting discourse because it was easy to use. 250
However, we also assumed that contentful coordinating and subordinating conjunc-tions (cf. Table 1) can delimit discourse segments.
 to conjoin nouns in a conjoined noun phrase, like dairy plants and dealers in example (1) (from wsj 0306; Wall Street Journal 1989 corpus [Harman and Liberman 1993]) or if it was used to conjoin verbs in a conjoined verb phrase, like snowed and rained in example (2) (constructed):
We classified periods, semicolons, and commas as delimiting discourse segments. How-phrase, commas were not classified as delimiting discourse segments.
We furthermore treated attributions ( John said that . . . ) as discourse segments. This was empirically motivated. The texts used here were taken from news corpora, and there, attributions can be important carriers of coherence structures. For instance, consider a case in which some source A and some source B both comment on some event X .It should be possible to distinguish between a situation in which source A and source B make basically the same statement about event X and a situation in which source A and source B make contrasting comments about event X . Note, however, that we treated cases like example (4) (constructed) as one discourse segment and not as two separate ones ( ...cited and transaction costs . . . ). We separated attributions only if the attributed material was a complementizer phrase, a sentence, or a group of sentences. This is not the case in example (4): The attributed material is a complex NP ( transaction costs from its 1988 recapitalization ). 2.2 Discourse Segment Groupings
Adjacent discourse segments could, in our approach, be grouped together. For example, discourse segments were grouped if they all stated something that could be attributed to the same source (cf. section 2.3 for a definition of attribution coherence relations).
Furthermore, discourse segments were grouped if they were topically related. For example, if a text discussed inventions in information technology, there could be groups of a few discourse segments each talking about inventions by specific companies. There might also be subgroups, consisting of several discourse segments each, talking about specific inventions at specific companies. Thus, marking groups could determine a partially hierarchical structure for the text.
 another event or another group of events described by another (group of) discourse segments. In those cases, what was described by a group of discourse segments was in a temporal sequence relation with what was described by another (group of) discourse segments (cf. section 2.3 for a definition of temporal-sequence coherence relations). Note furthermore that in cases in which one topic required one grouping and a following topic required a grouping that was different from the first grouping, both groupings were annotated.
 partially overlapping groups of discourse segments. The idea behind this option was to allow groupings of discourse segments in which a transition discourse segment belonged to the previous as well as the following group. However, the option was not used by the annotators (i.e., in our database of 135 hand-annotated texts, there were no instances of partially overlapping discourse segment groups). 2.3 Coherence Relations
As pointed out in section 1, we aim to develop a representation of informational relations between discourse segments. Note one difference between schema-based approaches (McKeown 1985) and coherence relations as we used them: Whereas schemas are instantiated from information contained in a knowledge base, coherence relations as we used them do not make (direct) reference to a knowledge base. their basic definitions, to Hume, Plato, and Aristotle (cf. Hobbs 1985; Hobbs et al. 1993;
Kehler 2002). The coherence relations we used are mostly based on Hobbs (1985); below we describe each coherence relation we used and note any differences between ours and
Hobbs X  X  (1985) set of coherence relations (cf. Table 2 for an overview of how our set of coherence relations relates to the set of coherence relations in Hobbs [1985]). example (5) (constructed), in which discourse segment 1 states the cause for the effect that is stated in discourse segment 2: (5) Cause X  X ffect Our cause X  X ffect relation subsumed the cause as well as the explanation relation in
Hobbs (1985). A cause relation holds if a discourse segment stating a cause occurs 252 before a discourse segment stating an effect; an explanation relation holds if a discourse segment stating an effect occurs before a discourse segment stating a cause. We encoded this difference by adding a direction to the cause X  X ffect relation. In a graph, this can be represented by a directed arc going from cause to effect.
 dition relations from either cause or explanation relations. However, we felt that it might be important to distinguish between a causal relation describing an actual causal event discourse segment 1 also takes place: (6) Condition expectation in Hobbs [1985]), a causal relation between two discourse segments that normally would be present is absent. In example (7) (constructed), discourse segment 1 normally would be a cause for everyone X  X  being happy; this expectation is violated by what is stated by discourse segment 2: (7) Violated expectation contrast (also contrast in Hobbs [1985]) relations, in which similarities or contrasts are determined between corresponding sets of entities or events, such as between discourse segments 1 and 2 in example (8) (constructed) and discourse segments 1 and 2 in example (9) (constructed), respectively: (8) Similarity (9) Contrast
Discourse segments might also elaborate (also elaboration in Hobbs [1985]) on other sentences, as in example (10) (constructed), in which discourse segment 2 elaborates on discourse segment 1: (10) Elaboration
Discourse segments can provide examples for what is stated by another discourse segment. In example (11) (constructed), discourse segment 2 states an example ( exemplification in Hobbs [1985]) for what is stated in discourse segment 1: (11) Example [1985]), in which discourse segment 2 states an evaluation of what is stated in discourse segment 1. We decided to call such relations elaborations , since we found it too difficult in practice to reliably distinguish elaborations from evaluations (according to our annota-tion scheme, in example (12), what is stated in discourse segment 2 elaborates on what is stated in discourse segment 1): (12) Elaboration (labeled as evaluation in Hobbs [1985]) ple (13) (modified from Hobbs [1985]), in which what is stated in discourse segment 1 provides the background for what is stated in discourse segment 2. As with the evaluation relation, we found the background relation too difficult to reliably distinguish from elaboration relations (according to our annotation scheme, in example (13), what is stated in discourse segment 1 elaborates on what is stated in discourse segment 2): (13) Elaboration (labeled as background in Hobbs [1985]) ment (here discourse segment 2) states a generalization for what is stated by another discourse segment (here discourse segment 1): (14) Generalization attribution relations): (15) Attribution
Hobbs (1985) does not include an attribution relation. However, we decided to include attribution as a relation because, as pointed out in section 2.1, the texts we annotated are taken from news corpora. There, attributions can be important carriers of coherence structures. 254 segment (here discourse segment 1) states an event that takes place before another event stated by the other discourse segment (here discourse segment 2): (16) Temporal Sequence described by the two discourse segments. The temporal sequence relation is equivalent to the occasion relation in Hobbs (1985).
 of assuming contiguous distinct elements of text (Hobbs [1985] does not include a same intervening discourse segment. For instance, in example (17), discourse segment 1 is the subject NP of a predicate in discourse segment 3, and so there is a same relation between discourse segments 1 and 3; discourse segment 1 is the first and discourse segment 3 is the second segment of what is actually one single discourse segment, separated by the intervening discourse segment 2, which is in an attribution relation with discourse segment 1 (and therefore also with discourse segment 3, since discourse segments 1 and 3 are actually one single discourse segment): (17) Same of coherence relations in Hobbs (1985).
 symmetrical or undirected relations, on the other hand (Mann and Thompson 1988; tion , attribution ,and temporal sequence are asymmetrical or directed relations, whereas similarity , contrast ,and same are symmetrical or undirected relations. In asymmetrical or directed relations, the directions of relations are as follows:
This definition of directionality is related to Mann and Thompson X  X  (1988) notion of nucleus and satellite nodes (where the nodes can represent [groups of] discourse to nucleus node; by contrast, symmetrical or undirected relations hold between two nucleus nodes.
 either if there was a coherence relation between the complete content of two discourse segments. Consider the following example (from ap890104-0003; AP Newswire corpus; [Harman and Liberman 1993]): (18) 1. a [ Difficulties have arisen ] b [ in enacting the accord for the
For this example we would annotate an elaboration relation from discourse segment 2 to discourse segment 1 (discourse segment 2 provides additional details about the accord 256 mentioned in discourse segment 1), although the relation actually only holds between discourse segment 2 and the second part of discourse segment 1, indicated by brackets. investigate annotations with discourse segmentations that allow annotating rela-tions only between parts of discourse segments that are responsible for a coherence relation. For example, consider example (19) (from ap890104-0003; AP Newswire corpus [Harman and Liberman 1993]), in which brackets indicate how more-fine-grained discourse segments might be marked: (19) 1. a [ for which ] b [SWAPO] c [ has fought many years, ]
In our current project, we annotated an elaboration relation from discourse segment 2 to discourse segment 1 (discourse segment 2 provides additional details, the full name, for SWAPO , which is mentioned in discourse segment 1). A future, more detailed, annotation of coherence relations could then annotate this elaboration relation to hold only between discourse segment 2 and the word SWAPO in discourse segment 1. 2.4 Coding Procedure To code the coherence relations of a text, we used a procedure consisting of three steps. In the first step, a text was segmented into discourse segments (cf. section 2.1). grouped together. The criteria for this step are described in section 2.2.
 discourse segments and groups of discourse segments. Each previously unconnected (group of) discourse segment(s) was tested to see whether it connected to any of the (groups of) discourse segments that had already been connected to the already existing representation of discourse structure.
 segments, the annotators judged which, if any, of the contentful coordinating conjunc-tions in Table 1 resulted, when used, in the most acceptable passage (cf. Hobbs 1985; ments resulted in an acceptable passage, this was used as evidence that the coherence relation corresponding to the mentally inserted contentful conjunction held between the (groups of) discourse segments under consideration. This mental exercise was done only if there was not already a contentful coordinating conjunction that disambiguated the coherence relation.
 task) shows in more detail how the annotations were carried out: 1. Segment the text into discourse segments: 2. Generate groupings of related discourse segments: 3. Determine coherence relations between discourse segments and groups of 258 2.5 Annotators
The annotators for the database were MIT undergraduate students who worked in our lab as research students. For training, the annotators received a manual that described the background of the project, discourse segmentation, coherence relations and how to recognize them, and how to use the annotation tools that we developed in our lab (Wolf et al. 2003). The first author of this article provided training for the annotators. Training consisted of explaining the background of the project and the annotation method and of annotating example texts (these texts are not included in our database). Training took 8 X 10 hours in total, distributed over five days of a week. After completing the training, annotators worked independently. 2.6 Statistics on Annotated Database
In order to evaluate hypotheses about appropriate data structures for representing
Journal 1987 X 1989 (30 texts) and the AP Newswire 1989 (105 texts) (both from Harman and Liberman [1993]) in which the relations between discourse segments have been labeled with the coherence relations described above. Table 3 shows statistics for this database. the coding procedure described in section 2.4 were performed independently by two annotators. For step 1 (discourse segmentation), a pilot study on 10 texts showed that agreement on this step, as determined by number of common segments /( number of common segments + number of differing segments ), was never below 90%. Therefore, all 135 texts were segmented by two annotators together, resulting in segmentations that both annotators could agree on.
 for the database of annotated texts, we calculated kappa statistics (Carletta 1996). We used the following procedure to construct a confusion matrix: First, all groups marked by either annotator were extracted. Annotator 1 had marked 2,616 groups, and an-notator 2 had marked 3,021 groups in the whole database. The groups marked by the annotators consisted of 536 different discourse segment group types (for example, groups that included the first two discourse segments of each text were marked 31 times by both annotators; groups that included the first three discourse segments of each text were marked 6 times by both annotators). Therefore, the confusion matrix had 536 rows and columns. For all annotations of the 135 texts, the agreement was 0.8449, per chance agreement was 0.0161, and kappa was 0.8424. Annotator agreement did not differ as a function of text length, arc length, or kind of coherence relation (all  X  of the coding procedure. 1 For all annotations of the 135 texts, the agreement was 0.8761, per chance agreement was 0.2466, and kappa was 0.8355. Annotator agreement did not differ as a function of text length (  X  2 = 1 . 27, p &lt; 0.75), arc length (  X  for example, that much of the interannotator disagreement seems to have been driven by disagreement over how to annotate elaboration relations (in the whole database, annotator 1 marked 260 elaboration relations where annotator 2 marked no relation; annotator 2 marked 467 elaboration relations where annotator 1 marked no relation). of is that of Carlson, Marcu, and Okurowski (2002). 2 Since they use trees and split the annotation process into different substeps than those in our procedure, their annotator agreement figures are not directly comparable to ours. Furthermore, note that Carlson and her colleagues do not report annotator agreement figures for their database as a whole, but for different subsets of four to seven documents that were each annotated by different pairs of annotators. For discourse segmentation, they report kappa values ranging from 0.951 to 1.00; for annotation of discourse tree spans, their kappa values ranged from 0.778 to 0.929; for annotation of coherence relation nuclearity (whether a node in a discourse tree is a nucleus or a satellite, cf. section 2.3 for the definition of these terms), kappa values ranged from 0.695 to 0.882; for assigning types of coherence relations, they reported kappa values ranging from 0.624 to 0.823. 260 3. Data Structures for Representing Coherence Relations
In order to represent the coherence relations between discourse segments in a text, most accounts of discourse coherence assume tree structures (Britton 1994; Carlson, Marcu, and Okurowski 2002; Corston-Oliver 1998; Longacre 1983; Grosz and Sidner 1986; Mann and Thompson 1988; Marcu 2000; Polanyi and Scha 1984; Polanyi 1996; Polanyi et al. 2004; van Dijk and Kintsch 1983; Walker 1998); some accounts do not allow crossed dependencies but appear to allow nodes with multiple parents (Lascarides and Asher 1991). 3 Other accounts assume less constrained graphs that allow crossed dependencies as well as nodes with multiple parents (e.g., Bergler 1991; Birnbaum 1982; Danlos 2004;
Hobbs 1985; McKeown 1985; Reichman 1985; Zukerman and McConachy 1995; for dialogue structure, Penstein Rose et al. 1995).
 derive than less constrained graphs (Marcu 2000; Webber et al. 2003). We demonstrate that in fact many coherence structures in naturally occurring texts cannot be adequately represented by trees. Therefore we argue for less constrained graphs in which nodes represent discourse segments and labeled directed arcs represent the coherence rela-tions that hold between these discourse segments as an appropriate data structure for representing coherence.
 discourse structure that represents informational, intentional, and attentional discourse relations. For example, Moore and Pollack (1992) point out that rhetorical structure theory (Mann and Thompson 1988) has both informational and intentional coherence relations but then forces annotators to decide on only one coherence relation between any two discourse segments. Moore and Pollack argue that often there is an informa-tional as well as an intentional coherence relation between two discourse segments, which then presents a problem for RST, since only one of the relations can be annotated.
Instead, Moore and Pollack propose allowing more than one coherence relation between two discourse segments, which violates the tree constraint of not having nodes with multiple parents.
 for discourse structure. Instead, she argues that in order to account for the intentional structure of discourse, more general data structures are needed. We argue that the same is true for the informational structure of discourse.
 discourse structure. Note, however, that the focus of our work is on informational coherence relations, not on intentional relations. That does not mean that we think that structure. Rather, we would like to argue that whereas the above accounts argue against trees for representing informational, intentional, and attentional discourse structure together, we argue that trees are not even descriptively adequate to describe just in-formational discourse structure by itself. 262 (e.g., Bergler [1991] and Hobbs [1985] for monologue and Penstein Rose et al. [1995] for dialogue structure). However, none of these accounts provides systematic empir-ical support for using more general graphs rather than trees. Providing a systematic empirical study of whether trees are descriptively adequate for representing discourse coherence is the goal of this article.
 as a  X  X ackbone X  for discourse structure but allow certain violations of tree constraints (crossed dependencies or nodes with multiple parents). Examples of such accounts include Webber et al. (1999) and Knott (1996). Similarly to our approach, Webber et al. (1999) investigated informational coherence relations. The kinds of coherence relations they used are basically the same as those that we used (cf. also Hobbs 1985).
However, they argue for a tree structure as a backbone for discourse structure but have also addressed violations of tree structure constraints. In order to accommodate violations of tree structure constraints (in particular, crossed dependencies), Webber one hand, and  X  X onstructural X  or  X  X naphoric X  discourse relations on the other hand.
Structural discourse relations are represented within a lexicalized tree-adjoining gram-mar framework, and the resultant structural discourse structure is represented by a tree. However, more recently, Webber et al. (2003) have argued that structural discourse structure should allow nodes with multiple parents, but no crossed dependencies. It is unclear, however, why Webber et al. (2003) allow one kind of tree constraint violation (nodes with multiple parents) but not another (crossed dependencies).
  X  X onstructural X  discourse structure in Webber et al. (1999): According to Webber et al. (1999), nonstructural discourse relations are licensed by anaphoric relations and can be involved in crossed dependencies. However, Webber et al. (1999) also argue that one criterion for nonstructural coherence relations is that they can cross (non)structural is necessary to find an independent way to validate the difference between structural and nonstructural coherence relations. Knott (1996) might provide a way to empirically similar to those in Webber et al. (1999): Based on the observation that he cannot identify characteristic cue phrases for elaboration relations (e.g., because would be a characteristic cue phrase for cause X  X ffect ), Knott argues that elaboration relations are more permissive quence, Knott argues, elaboration relations would be better described in terms of focus structures (cf. Grosz and Sidner 1986), which Knott argues are less constrained, than in terms of rhetorical relations (cf. Hobbs 1985; Mann and Thompson 1988), which Knott argues are more constrained. This hypothesis makes testable empirical claims: Elabora-tion relations should in some way pattern differently from other coherence relations. We come back to this issue in sections 4.1 and 4.2.
 discourse coherence. Note, though, that the evidence does not support the claim that discourse structures are completely arbitrary. The goal of our research program is to first determine which constraints on discourse structure are empirically viable. To us, the work we present here seems to be the crucial first step in avoiding arbitrary constraints on inferences for building discourse structures. In other words, the point we wish to make here is that although there might be other constraints on possible discourse annotations that will have to be identified in future research, tree structure constraints do not seem to be the right kinds of constraints. This appears to be a crucial difference between approaches like Knott X  X  (1996), Marcu X  X  (2000), or Webber et al. X  X  (2003), on the one hand, and our approach, on the other hand. The goal of the former approaches seems to be to first specify a set of constraints on possible discourse annotations and then to annotate texts with these constraints in mind.
 discourse coherence structures. Section 3.1 shows that the discourse structures of nat-urally occurring texts contain crossed dependencies, which cannot be represented in trees. Another problem for trees, in addition to crossed dependencies, is that many nodes in coherence graphs of naturally occurring texts have multiple parents. This is shown in section 3.2. Because of these problems for trees, we argue for a representation such as chain graphs (cf. Frydenberg 1989; Lauritzen and Wermuth 1989), in which directed arcs represent asymmetrical or directed coherence relations and undirected arcs represent symmetrical or undirected coherence relations (this is equivalent to arguing graph-based analyses are given. RST analyses are given only for those examples that are also annotated by Carlson, Marcu, and Okurowski (2002) (in those cases, the RST analyses are those provided by Carlson, Marcu, and Okurowski). 3.1 Crossed Dependencies
Consider the text passage in example (20) (modified from SAT practice materials): (20) 1. Schools tried to teach students history of science.
Figure 1 shows the coherence graph for example (20). Note that the arrowheads of the arcs represent directionality for asymmetrical relations ( elaboration ) and bidirectionality for symmetrical relations ( similarity , contrast ).
 264 { 3, 1 } and { 4, 2 } .
 violating validity assumptions about tree structures (Diestel 2000), one might consider augmenting a tree either with feature propagation (Shieber 1986) or with a coindex-ation mechanism (Chomsky 1973). There is a problem, however, with both feature propagation and coindexation mechanisms: Both the tree structure itself and the fea-tures and coindexations as well represent the same kind of information (coherence text coherence structure should be represented by the tree structure and which part should be represented by the augmentation. Other areas of linguistics have faced this issue as well. Researchers investigating data structures for representing intrasentential and other aspects in some augmentation formalism (e.g., Chomsky 1973; Marcus dependency-based representation that drops the tree constraints of allowing no crossed approach falls into the latter group. As we point out, there does not seem to be a well-defined set of constraints on crossed dependencies in discourse structures. Without such constraints, it does not seem viable to represent discourse structures as augmented tree structures.
 in naturally occurring discourse. If there are only a very limited number of different provisions to account for these structures and otherwise assume tree structures.
Example (20), for instance, has a listlike structure. It is possible that listlike examples are exceptional in natural texts. However, there are many other naturally occurring nonlistlike structures that contain crossed dependencies. As an example of a nonlistlike structure with a crossed dependency (between { 4, 2 } and (21) (constructed): (21) 1. Susan wanted to buy some tomatoes The coherence structure for (21), shown in Figure 2, can be derived as follows:
Liberman 1993]) has a similar structure: (22) 1. The flight Sunday took off from Heathrow Airport at 7:52pm The coherence structure for example (22) can be derived as follows:
The resulting coherence structure, shown in Figure 3, contains a crossed dependency between { 4, 2 } and { 3, 1 X 2 } .
 and Liberman 1993]): (23) 1. 1 a [ Mr. Baker X  X  assistant for inter-American affairs, ] 266
The annotations based on our annotation scheme with the discourse segmentation based on the segmentation guidelines in Carlson, Marcu, and Okurowski (2002) are presented in Figure 4, and those with the discourse segmentation based on our segmentation guidelines from section 2.1 are presented in Figure 5. Figure 6 shows a tree-based RST annotation for example (23) from Carlson, Marcu, and Okurowski (2002). The only difference between our approach and that of Carlson, Marcu, and
Okurowski with respect to how example (23) is segmented is that Carlson and her colleagues assume discourse segment 1 to be one single segment. By contrast, based on our segmentation guidelines, discourse segment 1 would be segmented into two segments (because of the comma that does not separate a complex NP or VP), 1a and 1b, as indicated by the brackets in example (24): 4 (24) 1 a [ Mr. Baker X  X  assistant for inter-American affairs, ] The coherence structure for example (23) can be derived as follows: The resulting coherence structure, shown in Figure 5 (discourse segmentation from
Carlson, Marcu, and Okurowski [2002]) and Figure 6 (our discourse segmentation), contains a crossed dependency: The same relation between discourse segment 1 and dis-course segment 4 crosses the violated expectation relation between the group of discourse segments 2 and 3 and the group of discourse segments 4 and 5.
 metric coherence relations and continuous lines mark the end of asymmetric coherence relations; symmetric coherence relations have two continuous lines (cf. section 2.3 for the distinction between symmetric and asymmetric coherence relations and for the directions of asymmetric coherence relations). Carlson, Marcu, and Okurowski (2002) do not provide descriptions of how they derived tree-based RST structures for their based RST structures were derived, we show comparisons of the RST structure and our chain-graph-based structure; the comparison for (23) is provided in Table 5. Note expectation relation between 2 X 3 and 4 X 5; that relation could not be annotated without violating the tree constraint of not allowing crossed dependencies. 268 3.2 Nodes with Multiple Parents
In addition to including crossed dependencies, many coherence structures of natural texts include nodes with multiple parents. Such nodes cannot be represented in tree structures. Consider example (25) (from ap890103 = 0014; AP Newswire 1989 corpus [Harman and Liberman 1993]). (25) 1.  X  X ure I X  X l be polite, X  The coherence structure for example (25) can be derived as follows:
In the resultant coherence structure for example (25), node 1 has two parents X  X ne attribution and one condition ingoing arc (cf. Figure 7). parents, consider the structure of example (26) (from wsj 0655; Wall Street Journal 1989 corpus [Harman and Liberman 1993]): (26) (they in 4 and 6 = Contra supporters; this is clear from the whole text
Our annotations are shown in Figures 8 (discourse segmentation from Carlson, Marcu, and Okurowski [2002]) and 9 (our discourse segmentation); Carlson et al. X  X  (2002) tree-based RST annotation is shown in Figure 10. The only difference between our annotation and that of Carlson, Marcu, and Okurowski is that we do not assume two separate discourse segments for 1 and 2; 1 and 2 are one discourse segment in our annotation example (23)  X  X hat X  is not in a separate discourse segment; it is unclear why in example (26),  X  X hat X  is in a separate discourse segment (discourse segment 2) and not part of discourse segment 3. The discourse structure for example (26) can be derived as follows: 1. According to our discourse segmentation guidelines (cf. section 2.1), 1 and 270 2. Attribution relation between 1 or 1+2 and 3 X 4: 1 or 1+2 state the source (the 3. Condition relation between 3 and 4: 3 states the condition for what is stated 4. Attribution relation between 5 and 1 X 4: 5 states the source of what is stated 5. Attribution relation between 5 and 6: 5 states the source of what is stated in 6. 6. Evaluation-s 6 relation between 6 and 3 X 4: 3 X 4 state what is evaluated by
In the resultant coherence structure for example (26), node 3 X 4 has multiple parents or ingoing arcs: one attribution ingoing arc and one evaluation-s ingoing arc (cf. Figures 8 and 9).
 annotation for (26). Note in particular that the attribution relation between 5 and 6 cannot be represented in the RST tree structure. Note furthermore that the RST tree contains an evaluation-s relation between 6 and 1 X 5. However, this evaluation-s relation seems to hold rather between 6 and 3 X 4: What is being evaluated is a chance for the Contras to win a military conflict under certain circumstances. But a coherence relation between 6 and 3 X 4 could not have been annotated in a tree structure. 4. Statistics
We performed a number of statistical analyses on our annotated database to test our hypotheses. Each set of statistics was calculated for both annotators separately. How-ever, since the statistics for both annotators were never different from each other (as annotator in the following sections.
 sections are. The more frequent they are, the more urgent the need for a data structure that can adequately represent them. The following sections report statistical results on crossed dependencies (section 4.1) and nodes with multiple parents (section 4.2). 4.1 Crossed Dependencies
The following sections report counts on crossed dependencies in the annotated database dependencies, section 4.1.2 reports results concerning the question of what types of coherence relations tend to be involved in crossed dependencies, and section 4.1.3 dependencies. 4.1.1 Frequency of Crossed Dependencies. In order to track the frequency of crossed dependencies for the coherence structure graph of each text, we counted the minimum number of arcs that would have to be deleted in order to eliminate crossed dependen-cies in the coherence structure. Figure 11 illustrates this process. The example graph depicted in the figure contains the following crossed dependencies: { 2, 4 } , { 3, 5 } with { 2, 4 } ,and { 5, 7 } with { 6, 8 dependencies can be eliminated: the crossing of { 1, 3 } with { 3, 5 } with { 2, 4 } . By deleting either { 5, 7 } or { 6, 8 between { 5, 7 } and { 6, 8 } can be eliminated. Therefore two edges would have to be deleted from the graph in Figure 11 in order to make it free of crossed dependencies. 272 12.5% of arcs in a coherence graph have to be deleted in order to make the graph free of crossed dependencies. Seven texts out of the 135 had no crossed dependencies. The mean number of arcs for the coherence graphs of these texts was 36.9 (minimum: 8, maximum: 69, median: 35). The mean number of arcs for the other 128 coherence graphs (those with crossed dependencies) was 125.7 (minimum: 20, maximum: 293, median: 115.5). Thus, the graphs with no crossed dependencies had significantly fewer arcs than the graphs that had crossed dependencies (  X  2 had no crossed dependencies.
 a coherence graph and the number of crossed dependencies. The more arcs a graph has, the higher the number of crossed dependencies ( R 2 = 0.39, p &lt; 10 same linear correlation holds between text length and number of crossed dependencies:
The longer a text, the more crossed dependencies are in its coherence structure graph (for text length in discourse segments: R 2 = .29, p &lt; 10
R 2 = .24, p &lt; 10  X  4 ). 4.1.2 Types of Coherence Relations Involved in Crossed Dependencies. In addition to the question of how frequent crossed dependencies are, another question is whether there are certain types of coherence relations that participate more or less frequently in crossed dependencies than other types of coherence relations. For an arc to participate in a crossed dependency, it must be in the set of arcs that would have to be deleted from procedure outlined in section 4.1.1). In other words, the question is whether the fre-quency distribution over types of coherence relations is different for arcs participating in crossed dependencies compared to the overall frequency distribution over types of coherence relations in the whole database.
 participating in crossed dependencies is not different from the distribution over types of coherence relations overall. This is confirmed by the results of a linear regression, which show a significant correlation between the two distributions of percentages ( R p &lt; .0001). Note that the overall distribution includes only arcs with length greater than one, since arcs of length one cannot participate in crossed dependencies.
 of coherence relations occur considerably less frequently in crossed dependencies than of  X  X ercentage of overall coherence relations X  by  X  X ercentage of coherence relations participating in crossed dependencies. X  The proportion of same relations, for instance, is 15.23 times greater, and the percentage of condition relations is 5.59 times greater, overall in the database than in crossed dependencies. We do not yet understand the reason for these differences and plan to address this question in future research.
 others to crossed dependencies is to remove coherence relations of a certain type from the database and then count the remaining number of crossed dependencies. For exam-ple, it is possible that the number of crossed dependencies is reduced once all elaboration relations are removed from the database. Table 9 shows that by removing all elaboration relations from the database of 135 annotated texts, the percentage of coherence relations involved in crossed dependencies is reduced from 12.5% to 4.96% of the remaining coherence relations. That percentage is reduced even further, to 0.84%, by removing all elaboration and similarity relations from the database. These numbers seem to be partial support for Knott X  X  (1996) hypothesis: Knott argued that elaboration relations are less 274 constrained than other types of coherence relations (cf. the discussion of Knott [1996] in section 3).
 elaboration relations are very frequent (37.97% of all coherence relations; cf. Table 8). It is possible that removing elaboration relations from the database reduces the number of crossed dependencies only because a large number of coherence relations are removed when elaboration s are removed. In other words, an alternative hypothesis to that of dense coherence graphs (i.e., the less dense coherence graphs are, the lower the chance for crossed dependencies). We tested this hypothesis by correlating the percentage of coherence relations removed with the percentage of crossed dependencies that remain after removing a certain type of coherence relation. 7 Figure 14 shows that the higher the percentage of removed coherence relations, the lower the percentage of coherence relations becomes that are involved in crossed dependencies. This correlation is con-firmed by a linear regression ( R 2 = 0.7697, p &lt; .0005; after removing the elaboration data tion + similarity ). Thus, although removing certain types of coherence relations reduces the number of crossed dependencies, it results in a very impoverished representation of coherence structure (i.e., after removing all elaboration and all similarity relations, only 39.12% of all coherence relations would still be represented [cf. Table 8]; the figure is 52.13% based on the distribution over coherence relations including those with absolute arc length one [cf. Table 11]).
 276
In order to further reduce the proportion of remaining crossed dependencies, it is necessary to remove similarity relations in addition to removing elaboration relations (cf. Table 9). This is a pattern of results that is not predicted by any literature that we are aware of (including Knott [1996], among others, although he predicts these results partially). We believe this issue should be addressed in future research. 4.1.3 Arc Lengths of Coherence Relations Involved in Crossed Dependencies. An-other question is how great the distance typically is between discourse segments that participate in crossed dependencies, or how great the arc length is for coherence relations that participate in crossed dependencies. 8 crossed dependencies primarily involve long-distance arcs and that more local crossed dependencies are disfavored. However, Figure 15 shows that the distribution over arc lengths is practically identical for the overall database and for coherence relations par-ticipating in crossed dependencies (linear regression: R 2 a strong locality bias for coherence relations overall as well as for those participating in crossed dependencies. 9 The arc lengths are normalized in order to take into account the varying length of texts. Normalized arc length is calculated by dividing the absolute length of an arc by the maximum length that that arc could have, given its position in its text. For example, if there is a coherence relation between discourse segment 1 and discourse segment 4 in a text, the raw distance between them would be three. If these discourse segments are part of a text that has five discourse segments total (i.e., 1 to 5), the normalized distance would be 3/4 = 0.75 (because four would be the maximum possible length of an arc that originates in discourse segment 1 or 4, given that the text has five discourse segments in total). 4.1.4 Summary of Crossed-Dependencies Statistics. Taken together, the statistical re-sults on crossed dependencies suggest that crossed dependencies are too frequent to be ignored by accounts of coherence. Furthermore, the results suggest that any type of coherence relation can participate in a crossed dependency. However, there are some statistical results reported here also suggest that crossed dependencies occur primarily locally, as evidenced by the distribution over lengths of arcs participating in crossed dependencies. 4.2 Nodes with Multiple Parents
Section 3.2 provided examples of coherence structure graphs that contain nodes with multiple parents. In addition to crossed dependencies, nodes with multiple parents are another reason why trees are inadequate for representing natural language coherence structures. The following sections report statistical results from our database on nodes with multiple parents. As in the previous section on crossed dependencies, we report coherence relations ingoing to nodes with multiple parents (section 4.2.2), and the arc 278
Section 4.2.4 provides a short summary of the statistical results on nodes with multiple parents. 4.2.1 Frequency of Nodes with Multiple Parents. We determined the frequency of nodes with multiple parents by counting the number of nodes with in-degree greater than one. We assume nodes with in-degree greater than one in a graph to be the equiv-alent of nodes with multiple parents in a tree. The results of our count indicated that 41.22% of all nodes in the database have an in-degree greater than one. In addition to counting the number of nodes with in-degree greater than one, we determined the mean in-degree of the nodes in our database. Table 10 shows that the mean in-degree (= mean number of parents) of all nodes in the investigated database of 135 texts is 1.6. As for co-herence relations involved in crossed dependencies (cf. section 4.1.1), a linear regression showed a significant correlation between the number of arcs in a coherence graph and the number of nodes with multiple parents (cf. Figure 16; R length in discourse segments: R 2 = .6999, p &lt; 10  X  4 ; for text length in words: R p &lt; 10  X  4 ). The proportion of nodes with in-degree greater than one and the mean in-degree of the nodes in our database suggest that even if a mechanism could be derived for representing crossed dependencies in (augmented) tree graphs, nodes with multiple parents present another significant problem for trees representing coherence structures. 4.2.2 Types of Coherence Relations Ingoing to Nodes with Multiple Parents. As with crossed dependencies, an important question is whether there are certain types of coherence relations that are more or less frequently ingoing to nodes with mul-tiple parents than other types of coherence relations. In other words, the question is whether the frequency distribution over types of coherence relations is different for arcs ingoing to nodes with multiple parents compared to the overall frequency distribution over types of coherence relations in the whole database. Figure 17 shows a significant correlation between the two distributions of percentages ( R p &lt; 10  X  4 ).
 vidual coherence relations. Table 11 shows the data from Figure 17, ranked by the factor of  X  X ercentage of overall coherence relations X  by  X  X ercentage of coherence relations ingoing to nodes with multiple parents. X  coherence relations reduced the mean in-degree (number of parents) and/or the per-centage of nodes with in-degree greater than one (more than one parent). Table 12 shows that removing all elaboration relations from the database reduces the mean in-degree of nodes from 1.60 to 1.238 and the percentage of nodes with in-degree greater than one from 41.22% to 20.29%. Removing all elaboration as well as all similarity relations reduces these numbers further to 1.142 and 11.24%, respectively. As Table 12 also shows, removing other types of coherence relations does not lead to as great a reduction in the mean in-degree and the percentage of nodes with in-degree greater than one. the reduction in nodes with multiple parents could simply be due to removing more that there are nodes with multiple parents). We correlated the percentage of coherence relations removed with the mean in-degree of the nodes after removing different types of coherence relations. 11 Figure 18 shows that the higher the percentage of removed coherence relations, the lower the mean in-degree of the nodes in the database becomes.
This correlation is confirmed by the results of a linear regression ( R after removing the elaboration data point: R 2 = 0.8310, p &lt; .0005; note that these linear 280 the percentage of coherence relations removed with the percentage of nodes with in-degree greater than one after removing different types of coherence relations. Figure 19 shows that the higher the percentage of removed coherence relations, the lower the percentage of nodes with in-degree greater than one. This correlation is also confirmed by the results of a linear regression ( R 2 = 0.9574, p &lt; 10 data point: R 2 = 0.8146, p &lt; .0005; note that these correlations do not include the data point elaboration + similarity ).
 for crossed dependencies, i.e., elaboration and similarity ; cf. section 4.1.2) can reduce the mean in-degree of nodes and the proportion of nodes with in-degree greater than one, the result is a very impoverished coherence structure. For example, after removing both 282 elaboration and similarity relations, only 52.13% of all coherence relations would still be represented (cf. Table 11). Furthermore, note that this pattern of results is not predicted results partially (he predicts that removing elaboration relations but not that removing nodes with multiple parents; cf. the discussion in the last paragraph of section 4.1.2).
This issue will have to be investigated in future research. 4.2.3 Arc Lengths of Coherence Relations Ingoing to Nodes with Multiple Parents.
As for crossed dependencies, we also compared arc lengths. Here, we compared the length of arcs that are ingoing to nodes with multiple parents to the overall distribution normalization procedure). By contrast to the comparison for crossed dependencies, be ingoing to nodes with either single or multiple parents. Figure 20 shows that the arcs ingoing to nodes with multiple parents (linear regression: R participating in crossed dependencies. 4.2.4 Summary of Statistical Results on Nodes with Multiple Parents. In sum, the statistical results on nodes with multiple parents suggest that they are a frequent phe-nomenon and that they are not limited to certain kinds of coherence relations. However, as with crossed dependencies, removing certain kinds of coherence relations ( elaboration and similarity ) can reduce the mean in-degree of nodes and the proportion of nodes present do not distinguish whether this reduction in nodes with multiple parents is due to a property of the coherence relations removed ( elaboration and similarity )or whether it is just that removing more and more coherence relations simply reduces future research. In addition to the results on frequency of nodes with multiple parents and types of coherence relations ingoing to nodes with multiple parents, the statistical results reported here suggest that ingoing arcs to nodes with multiple parents are primarily local. 5. Conclusion
The goals of this article have been to present a set of coherence relations that are easy discourse coherence structures. We have developed a coding scheme with high interan-notator reliability and used that scheme to annotate 135 texts with coherence relations.
An investigation of these annotations has shown that discourse structures of naturally occurring texts contain various kinds of crossed dependencies as well as nodes with multiple parents. Neither phenomenon can be represented using trees. This implies that existing databases of coherence structures that use trees are not descriptively adequate. parents are not restricted phenomena that could be ignored or accommodated with a few exception rules. Furthermore, even if one could find a way of augmenting tree structures to account for crossed dependencies and nodes with multiple parents, there would have to be a mechanism for unifying the tree structure with the augmentation features. Thus, in terms of derivational complexity, trees would just shift the burden from having to derive a less constrained data structure to having to derive a unification of trees and features or coindexation.
 coherence structures nor easier to derive, we argue for less constrained graphs as a data structure for representing coherence structures. In particular, we argue for a representa-tion such as chain graphs (cf. final paragraph of section 3). Such less constrained graphs would have the advantage of being able to adequately represent coherence structures in 284 Furthermore, they are at least not harder to derive than (augmented) tree structures.
The greater descriptive adequacy might in fact make them easier to derive. However, this is still an open issue and will have to be addressed in future research. segmentation than in the current project. Although such a detailed annotation of co-herence relations was beyond the scope of the current project, future research should address this issue. More-fine-grained discourse segmentation could then also facilitate integration of discourse-level with sentence-level structural descriptions. constraints on inferences for building discourse structures. As pointed out in section 3, even though we have argued against trees as a data structure for representing discourse structures, that does not necessarily mean that discourse structures can be completely arbitrary. Future research should investigate questions such as whether there are struc-tural constraints on coherence graphs (e.g., as proposed by Danlos [2004]) or whether there are systematic structural differences between the coherence graphs of texts that belong to different genres (e.g., as proposed by Bergler [1991]).
 286
